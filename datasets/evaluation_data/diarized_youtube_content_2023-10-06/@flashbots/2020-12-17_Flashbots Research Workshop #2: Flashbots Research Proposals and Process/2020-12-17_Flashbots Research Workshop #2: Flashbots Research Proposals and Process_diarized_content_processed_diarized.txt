00:00:02.410 - 00:00:25.070, Speaker A: Hi, folks. I'm shruti apia. I am a research scientist with Block science building crypto economic models. And over there, I'm primarily interested in mathematical modeling of economic systems in such a way that we can actually eventually simulate them, but also find the sensitivities of the system. And I'm also helping build a Haskell based, domain specific language for financial instruments.
00:00:28.810 - 00:01:07.780, Speaker B: Awesome. And Sunny oh, we're doing a quick one liner intro of us because this is our first research workshop, but Sunny has been an OG in the Flashbots Discussions Treasure Map Roast. But this workshop is specifically research focused. If you can actually speak. Well, looks like Sunny may not necessarily be able to speak. So, Surya, do you want to do a quick intro?
00:01:08.390 - 00:01:33.562, Speaker C: Yeah, sure, surya. I'm a PhD student right now with Andrew Miller. My current research is largely in sort of UC stuff, so just on the side of cryptography and security. But in the past, I've done blockchain research largely in payment channels and just sort of had my hand around in.
00:01:33.616 - 00:01:37.706, Speaker D: A few different security papers as well.
00:01:37.808 - 00:01:41.020, Speaker C: And, yeah, I'm also slightly new to the.
00:01:43.150 - 00:01:44.400, Speaker E: Yeah, that's me.
00:01:45.650 - 00:01:58.420, Speaker B: Awesome. I think the number that's calling in is Dave, because his connection wasn't good. So, Dave, want to do one two line intro of your research direction and yourself?
00:01:59.270 - 00:02:00.020, Speaker F: Sure.
00:02:03.510 - 00:02:13.400, Speaker G: I currently work interested in how we negate programming attack. Would you, like.
00:02:16.810 - 00:02:17.880, Speaker E: Literally, like.
00:02:19.930 - 00:02:21.160, Speaker F: Research outside?
00:02:25.790 - 00:02:35.550, Speaker B: I'm not sure if it's my Internet connection or yours. You seem to be breaking up, but if anyone's breaking up, feel free to text in the chat box for anything.
00:02:35.620 - 00:02:44.926, Speaker D: I think it was feedback with your mic Tina, so I think you might have to mute yourself while Dave talks. At least that was my understanding of what Google was showing.
00:02:45.118 - 00:02:47.140, Speaker B: My apologies, guys.
00:02:48.870 - 00:02:51.954, Speaker G: It's surely my side being weird right now.
00:02:52.152 - 00:02:53.540, Speaker E: Going through a phone.
00:02:54.390 - 00:02:56.040, Speaker D: No, now that sounds great.
00:02:57.770 - 00:03:12.540, Speaker G: Okay, I should do the intro again, I guess. I'm interested in how to best mitigate mev if we can change the base layer consensus algorithm. And as well, I'm interested in working on recursive Snarks. That's how I do it as research outside of med stuff.
00:03:14.910 - 00:03:15.660, Speaker D: Cool.
00:03:17.310 - 00:04:32.034, Speaker B: Awesome. All right, so I have shared a bit of an agenda to guide our discussion. So this is FlashPass has been in existence for our research. Discussion has been going on for essentially three, four months, and we have started with our Flashposs research proposal process, FRP process. And the submission will be due next Sunday. So this call is our first research focused workshop that will go into discussing the FRPS that has been submitted according to the Flashbots Research Roadmap. For most of you who have attended our roast in the past, you will know that just go to Flashbot's Mev Research repo the README section, and the docs linked Hi dan will have everything that you need to know about how to contribute and be part of the Flashbas research in the FRP process.
00:04:32.034 - 00:05:14.660, Speaker B: Basically the deadline will be next Sunday and then the week after we will basically announce our grants that we will reward our MEB fellows who are the grant recipients who have submitted the FRPS. So, yeah, once again, everything is in the link that I just also shared with you is in our GitHub repo. That said, I think we just saw Dan Morose joining. Some of us here are already familiar with Dan's work. Dan is taking a sabbatical from Harvard. But Dan, do you want to do a quick intro, like one or two lines about your area of research?
00:05:16.630 - 00:06:17.974, Speaker H: Oh, sure. Hey guys, can you hear me? Yeah, okay, sure. So I'm a PhD student at Harvard with David Parks, and the group I'm in is called the Econcs Group. And typically they've studied mechanism design, but at a larger scale than what's studied in econ. So typically in econ, the know that they come up with that field originated in econ. And so there's a continuation of that in the computer science literature and there's like whole conferences essentially based on this, like EC and wine and so on. So I've kind of taken that approach and thought about cryptocurrencies in that light, so kind of cryptocurrency and the kind of game theoretic dynamics that occur like mining and mining pools and staking and so on.
00:06:17.974 - 00:06:34.620, Speaker H: And so I've had some papers where we talk about models of that and the kind of incentives of the different players and the equilibrium that result and the issues that we see in all this. So Mev is definitely up this alley. Very excited to be here.
00:06:38.020 - 00:07:05.210, Speaker B: Awesome. So I think just a couple quick updates as we go through the agenda. One is we have made a modification to the FRP template, minor modification that Alejo has submitted a PR and we have merged it. So Alejo, can you make a share screen and kind of just go through what has changed in the FRP process?
00:07:06.240 - 00:07:33.824, Speaker E: Sure. It's a very minor change, actually. So before there was actually no separate template, so I just essentially split the template and modified a little bit. Let me find my screen. There we go. Can you see my screen? Can you see my screen now?
00:07:33.942 - 00:07:34.610, Speaker C: Yes.
00:07:35.220 - 00:08:00.350, Speaker E: So this is the research repo. So before, this is just the introduction Tina was mentioning before. And then in the roadmap there was a section where they were some guidelines on what makes a successful FRP. Where is it now?
00:08:01.360 - 00:08:04.440, Speaker B: It's in FRP one or FRP.
00:08:04.600 - 00:08:19.260, Speaker E: Sorry. Yeah, it was inside the FRPS. In the FRP zero. Sorry about that. Here there was what belongs to a successful FRP. So it has more section with guidelines on how to build it. I thought it was useful to actually put this in a template.
00:08:19.260 - 00:08:59.810, Speaker E: And so I built a quick template. Okay, I got the wrong links. I have to fix that simple template that one can simply copy and fit in the different sections. This will work as this is a little table with information, summary of the project and then background and problem statement, plan and deliverables and a references section. Again, this is model I repeated after what was there. So no major changes. But I think it was useful to have like a separate file so people can simply copy that and build upon that.
00:08:59.810 - 00:09:02.690, Speaker E: I will fix that link.
00:09:04.900 - 00:10:12.612, Speaker B: Perfect. So that's the template that we will reference, I think it fits most of the research questions here. Second brief update is basically we have Nika, who is also an editor for EIP Process, raised a comment about our authorship that we originally abide by authorship, which requires submission of your credentials and et cetera. However, I think he made a good point about anonymous contributors being acceptable. So I think we should broaden the criteria to accept anonymous contributors rather than having to essentially quote unquote KYC research contributors. So that's just something that I think a slight update that I think would be beneficial for everyone here to know. But I think everyone who actually joined the call are happy to be not anonymous contributors here.
00:10:12.612 - 00:11:39.296, Speaker B: But anyways, that said, we'll continue. And third, I guess more or less administrative update is that we're finalizing our set of FRP editors. FRP editors will have the responsibility of actually be actively involved in reviewing and discuss with the research fellows and to help make sure that the FRPS can fit into the broader scope of the context and they're not contradicting each other too much in terms of methodologies, et cetera. So I think the current FRP editors that we're proposing is Alejo and Giorgios, who is not on this call at this moment, and Phil and Alex Abadia and myself will be assisting everyone in the coordination process. So that said, let's move on to the research questions and the FRPS that has been proposed. So if everyone here can go on the flashbox, GitHub or Alejo, you may share your screen in the Mev Research Repo. You will actually go to the paper one and paper two, the research questions.
00:11:39.296 - 00:12:46.040, Speaker B: What we have seen is that we have received two draft FRPS, one from Syria and one from author. They're still in draft, so they're not yet updated in the Flashbots repo. However, as we are going through these drafts with each team, respectively, we start to realize that we definitely, and this is actually also intentional, we left the research questions very vague and potentially have overlapping between the research questions. So we need to actually fine tune this a bit more in terms of our research questions. And so basically all the research questions that we have put forth is in the Mev Research Repo README. And perhaps, Alejo, you can discuss a bit about what you have observed in the current FRP submitted and then we can go into each of the FRPS.
00:12:47.340 - 00:13:08.924, Speaker E: Yeah, sure. So we worked with Surya this week. So FRP one was a bit of a blanket FRP. It had many things in there. So we worked in breaking that up in smaller, more manageable chunks. I don't know, surya, do you want to show that or do you want me to? That's still not in the oh, if.
00:13:08.962 - 00:13:12.312, Speaker C: You could just share your own screen, that'd be easier.
00:13:12.456 - 00:13:23.570, Speaker E: Yes. Okay, fine. So this is still in Surya's repo. Let me get that. Just a SEC.
00:13:31.780 - 00:13:45.670, Speaker C: Although I will add a caveat that from my call with Alejo on Monday. It's still in a very rough form, so it hasn't been updated just yet. But you can at least get the idea.
00:13:48.440 - 00:14:26.304, Speaker E: Just look at the title. So we essentially broke it down live in a call. So we haven't polished this after that. So before the FRP one, just for a little context, this was how can we build a good auction strategy, right? So it had like, questions of measuring mev and questions of designing the auction and had many different things. Bundling that. So this is the old title, how can we build a Good Auction Mechanism? So we broke it up in small chunks. I think this perhaps should be not sub FRPS, but FRPS on their own.
00:14:26.304 - 00:15:04.044, Speaker E: We can discuss that. So first one is actually building a taxonomy of extraction strategies, right? So right now we have liquidations, we have Arbitrage and so on and so forth. So one early step in the process is just like describing this taxonomy of strategies more properly. This will be very closely linked to what Mev Inspect does in crawling the blockchain and finding these opportunities. Second is measuring PGAs and other mev extraction strategies. Again. This is what mev inspect does.
00:15:04.044 - 00:15:48.300, Speaker E: We have to define what exactly we want to measure. And this will depend a little bit on what the taxonomy we define in this sub FRP. This was a big part of what was there in the FRP one. So that's something we need to refine better what things we want to measure and go ahead and measure them. This third one was separating layer one versus L2. This is related to Carl Frost post in It research, if any of you have seen that he was proposing perhaps doing the reordering of transactions as a L2 thing. So Surya was going to talk with Carl about this.
00:15:48.300 - 00:16:27.930, Speaker E: So this is something we also want to look into. FRP 114 or four or whatever we end up numbering. It is the meaning of good in the good auction mechanism. So first, there's good applying to different actors. So there's bidders, miners and external users that are perhaps impacted by, I don't know, gas prices going down. So this is one thing. We want to define what good is for each of the actors in the system and try to come up with a sharper, more measurable operational definition of good.
00:16:27.930 - 00:17:15.412, Speaker E: We've discussed before. This involves a notion of efficiency. And it probably involves other things, scale less geared towards good in an ethical sense that's more the focus of paper two, where I want to make sure we're doing something good for the ecosystem. This is more tied to how a notion of, again, efficiency, optimality and so on of the auction mechanism you want to incorporate in the system. So again, this is to be defined what this good means in operational terms and how this integrates that's good for differently good for each of the actors of the system. Next one is finding solutions to the objective functions. This FRP 13.
00:17:15.412 - 00:18:58.180, Speaker E: But because we renumber this should be FRP, once we have a notion of what's good, okay, what's the solution that optimizes that good? What's the actual auction mechanism that achieves this notion of good? Right, so this is again a mechanism design thing for P 116, sorry. And this is very much related to FRP. I think it was originally number six, that was that one Suryas was working on that. It's about surveying the literature, the auction literature, and see what actual auction mechanisms are already known, what are their properties, what can we possibly use for this? Finally for B 116 is where is our current POC proof of concept auction mechanism standing in terms of this ideal or this solution we find for this idea of good? So where are we standing in terms of that? We are now using a silvi first price auction for the Mev guest proof of concept. So how good is that? How bad is that? How it compares with more promising solutions? Eventually we don't know what the status is. So this is one thing we want to dig deeper into so that's the six sub FRPS that could potentially become FRPS, we are working into trying to pass this big, very ample question into some smaller, more tractable chunks. And again, these are sort of up for grabs.
00:18:58.180 - 00:19:10.190, Speaker E: We still have not assigned people to this. So that's also a good place where we can find people to contribute to any questions.
00:19:10.720 - 00:19:34.980, Speaker C: One thing I will also add to that Alejo, is that I think if we get some research fellows who are essentially a team of people, I think in that case a lot of those FRPS can become bind into a single one and a whole team, I think as well clip to handle them sort of in parallel.
00:19:41.640 - 00:20:57.664, Speaker B: Yeah. Thank you. Thank you for presenting essentially the breaking down of the research questions and so into the sum of our piece, but definitely we'll come up with a better numbering system. But I just want to hear before we go to the next FRP draft, that author and his team has put together questions on the way we are sectioning the research questions and dividing things up. I think there are a lot of questions and as we have discussed individually, one on ones with the researchers who have been joining the calls in the past. There are definitely questions on certain research questions deserve to be standalone paper where they're only like a page or two, would not be able to do justice, especially paper one, question three. And also the other comment that we have got a lot, which is the first paper really 80% above the meat of the paper in the first research question, which is that's why we're doing the breakdown of it.
00:20:57.664 - 00:21:17.750, Speaker B: And that's why we're having these research workshops to make sure that we are going to be able to select the research fellows who are interested in solving these questions collectively with us in a meaningful way. So that's why we're also adjusting our process to accommodate but that's the context. And.
00:21:28.450 - 00:21:39.460, Speaker D: Your audio is not the greatest, Tina, but I think we heard most of it. Maybe in a tropical storm, I think.
00:21:41.830 - 00:21:43.060, Speaker I: Sounds like it.
00:21:46.150 - 00:22:10.790, Speaker D: Have you considered not being in a tropical storm? I'm just kidding. That all sounds good to me. Did you find that there would be any tools or organization that would be helpful to your first FRP surya and Alejo, I guess while we wait for Tina to resume the program. I'm kind of curious about that.
00:22:12.920 - 00:22:19.850, Speaker C: So I think one thing I was interested in is I think Alejo brought this up in our call was.
00:22:23.420 - 00:22:23.736, Speaker D: How.
00:22:23.758 - 00:22:59.110, Speaker C: Is the sort of mev opportunities that frontrun me can find and report? How did they compare to mev inspect and further for mev inspect? Sort of how can we think about how much extractable mev that mev inspect reports in the sense that is it close to maybe a lower bound? Is it close to an upper bound? Like how many of the mev opportunities are being missed by mev inspect or what percent is being captured by it?
00:23:01.000 - 00:23:41.760, Speaker D: Yeah, so I think that's something we also set Stefan and Scott on the engineering side on a mission to try to quantify. So maybe it would be worth also chatting with them and seeing if they have any metrics run. Me. I can tell you real quick, was just like very specifically only atomic Dex trades that profited the arbitrager in ETH only on like five or six different DEXes that are mentioned in the paper. So that's like a very small subset. I expect the real upper bound is way higher and it also doesn't consider like reorderings or anything, it's just using bot profit as a proxy for mev. But really the miners could probably make more if they were actively reordering and things like that, which I think we might also want to capture in the dashboard.
00:23:42.340 - 00:23:48.912, Speaker C: Yeah, so it's fair to say that it's probably somewhere near a lower bound.
00:23:48.976 - 00:24:38.070, Speaker D: On yeah, it's definitely a lower bound, but it's a pretty bad lower bound because the miners could profit at least that much for sure. But it's pretty bad. And yeah, I think adding coverage is one of the main things we still need to do on that side. I also think that it's worth thinking about in general, how do we encourage sustainable research artifacts and maybe that's like packaging things up in a way that can be contributed to engineering and kicked over later and establishing a process where they actually do that. But I think that's one of the things we're really bad at as academics and frontrun me is an example where if it takes like 100 hours to update your thing to the newest industry trends or whatever, you're probably not going to be incentivized to do that.
00:24:40.200 - 00:25:06.110, Speaker C: And then on the topic of coverage, I wanted to also ask, is there kind of a running list of what mev extraction strategies are covered right now in mev inspect and sort of which ones you are trying to also cover or at least just some sort of enumeration of the main strategies you guys have come up with?
00:25:06.880 - 00:25:42.708, Speaker D: Yeah, I think it's worth chatting with them about that because I think they have something internal but it's probably not rigorous. So part of what I think it's good for the research side to do is if you find a question like this that people are working on on the engineering side, that's relevant. Just like guiding them towards giving you data that's more rigorous and can be used for a survey or some sort of more public kind of formal release rather than just like internal notes. Because I feel like we have most of the data but there's just some covered stuff that needs to happen that I'm sure you guys can help guide and also other people on this call can help guide.
00:25:42.804 - 00:25:43.224, Speaker I: Got you.
00:25:43.262 - 00:25:45.156, Speaker D: Sorry, I didn't want to derail your call Tina.
00:25:45.268 - 00:25:46.490, Speaker C: I'll hit them up.
00:25:47.180 - 00:25:48.810, Speaker D: Continue the agenda please.
00:25:49.760 - 00:26:24.100, Speaker A: I just have one remark to make. I need to hop off to another call. But it seems like all of the FRPS except FRP Eleven have the dependency on that FRP Eleven, which is establishing the taxonomy and notations around what we're building with MVP extraction strategies. So are we expecting this to be sequential given that there's dependency? Or are we expecting that all of these related topics will have different notations or how is that going to work? Is there going to be an interpacation mechanism?
00:26:25.000 - 00:27:04.112, Speaker E: Yeah, that's a great question. I think not necessarily. They don't mean necessarily sequential. So for instance, all the problem of what's good, how to define good in terms of in more operational terms and good for each of the actors, I think that can run in parallel to defining the taxonomy. The good thing is more dependent on the available. So there's defining good and then the survey of the auction mechanisms available and then finding the optimal. Those are sort of kind of related in a Blob and then there's the one on the taxonomy and then measuring and those two are certainly related.
00:27:04.112 - 00:27:17.956, Speaker E: So yeah, there's clearly some structure to those and some dependencies we can uncover. And that's a good point. We should make those explicit. But I do expect some things to be able to be run in parallel.
00:27:18.068 - 00:27:42.080, Speaker C: I would also say that I think at least trying to enumerate and classify mev, I think based on what Phil just said, I think talking to the engineering team and sort of getting access to their internal notes would go a long way in completing that FRP, just in terms of being able to then move forward without having it be a blocker.
00:27:42.900 - 00:28:17.896, Speaker E: Yeah, so far. So just from the code of MAV inspect, there is some sort of taxonomy. They're like operational taxonomy and it's more like bottoms up terms of, okay, compound. We know we have to look at compound and there's a compound inspector and there's, okay, ave. We need to look at ave and there's an ave. So it's more of like a spontaneously building taxonomy. So I think our job would be to try to organize that and try to make sense out of that and see if we can have something more hierarchical or to give some more structure there.
00:28:17.896 - 00:29:07.944, Speaker E: There was one comment talking with Scott, looking at the architecture. I think their inference mechanism is sort of there's an inference of like, okay, this is an mev extraction opportunity and I think that certainly could be improved. In particular, I think there's locations in which it might be detecting things that are not mev extractions just by the way it works. So I've detected one very corner case like where Zapper liquidity provision. So liquidity provision via Zapper is classified as an mev extraction event. Again, because of how this inference work. So I think that's super tricky because if we want to make strong claims about this being a lower bound, at some point we really have to look at that and be a bit more strict in how we tag things as maybe extraction events and so on.
00:29:07.944 - 00:29:15.070, Speaker E: I think, again, I agree with what Phil was saying, that there needs to be some interaction with the engineering team to define that.
00:29:15.600 - 00:29:19.916, Speaker A: Yeah, I think that's starting point. Sorry for going.
00:29:20.098 - 00:29:36.950, Speaker D: No problem. And feel free. I don't want to keep you too long if you have to get to your other call, but yeah, I think that's all sane. And I also think the engineering team has expressed that they very much want guidance on that front and systematizing. That I think is a very useful research objective in general.
00:29:39.720 - 00:30:13.090, Speaker I: Cool. I have a quick question for FRP twelve. So this is basically this inspector. So is the goal here to just be passive in the sense of detecting past mevs? Or would there be a goal of detecting the potential mevs that are out there? Right, because these are two different things. So for example, if you want to detect all the arbitrage mevs that are out there, then you basically need to detect all the arbitrage opportunities among all the DeFi platforms, which is a very different problem from just observing what do other people do and we want to measure what other people do.
00:30:14.820 - 00:31:35.928, Speaker D: Yeah, I think that's a good question. So I can give you my high level vision of what it was, and by no means is this necessarily what will happen. But just the way I was thinking about it was that at first we would kind of provide a portal to maximize transparency of what bots are doing, just because that's like a concrete, tangible thing that plays into all of our metrics of how much mev is there and how much gas is being wasted. Eventually I would also like to have almost like a contest style API where maybe you can submit mev solutions for a block or a range of blocks that's better than the order that was actually executed. And then we archivally validate the legitimacy of those kind of contest entries and kind of also talk about maximum pass mev for various interesting sequences and single blocks. And eventually, I think the whole flashbots infrastructure of if there's actual mev being extracted through this infrastructure should also automatically feed into that, where if it's extracted, it should feed into like okay, this is the best known solution. For this block, but also, potentially, when you're testing strategies, you can also submit to the public that, oh, actually, this would have been better for a past block, because also, as we mentioned, we expect mev, for even a fixed block, to be somewhat super linear in time.
00:31:35.928 - 00:31:59.136, Speaker D: Because the longer you have to solve the problem, probably the better instances you're going to find. So people probably will at some point if the game gets really crazy, be like oh, a year ago you really could have done this strategy and it would have been way more profitable. So I think that was at least the vision. But obviously there's a lot of work that needs to happen between there and now.
00:31:59.238 - 00:32:00.370, Speaker I: Yeah, makes sense.
00:32:04.580 - 00:32:05.136, Speaker B: Yeah.
00:32:05.238 - 00:32:18.680, Speaker D: The only reason being that starting from the point of we want to get all the mev in the past is very hard to do and this is like much lower hanging fruit and I think we can iteratively advance to the ultimate mev kind of dashboard, hopefully.
00:32:20.940 - 00:33:37.232, Speaker B: Yeah. So I think actually Shuji raised a really important point that I think has been a blocker from both of Flashbots engineering flashbot's inspect side in terms of what is a good taxonomy to in fact guide them in data collection. And also this is something that I think came up in our conversation, one on one conversation with authors team when they are drafting their FRP. They have posted an FRP on quantifying mev from impact on the protocol security and that is the paper two question. However, they picked a subset which is liquidation that is currently not being collected by the Flashbots engineering team from Med inspect for various reasons that have been shared in the app calls. However, it's worthwhile to bring it up here. So Arthur, would you like to share a bit of your yeah, of course.
00:33:37.366 - 00:34:12.220, Speaker I: Let me see. Should I share my screen? That might make things easier. I never use Google. Hang on 1 second. Sorry for that delay. Seems I have to kid and reopen to give granted permissions to the I will be back in a second.
00:34:13.630 - 00:34:14.700, Speaker D: Sounds good.
00:34:25.440 - 00:34:55.312, Speaker B: And while others rejoining, one thing I want to point out is also that we have also had this discussion with Sunny and Dave, who's also on this call from protocol designer perspective. And that essentially the taxonomy of MEB and also quantifying the empirical MEB extraction versus the theoretical limits. That is something that is potentially need to be addressed. Okay, cool.
00:34:55.466 - 00:35:04.600, Speaker I: Trying to share here a specific window. Can you see?
00:35:05.210 - 00:35:05.960, Speaker D: Yes.
00:35:07.050 - 00:35:08.710, Speaker I: FRP or is it too big?
00:35:08.780 - 00:35:10.360, Speaker D: Maybe zoom a little bit more.
00:35:16.500 - 00:35:17.810, Speaker I: Can you see it?
00:35:18.580 - 00:35:19.330, Speaker D: Yes.
00:35:50.510 - 00:35:52.106, Speaker I: It seems I'm struggling a bit with.
00:35:52.128 - 00:35:52.700, Speaker E: The.
00:36:02.820 - 00:36:04.770, Speaker I: Is it now clear?
00:36:07.700 - 00:36:13.600, Speaker D: Yep, still a little small. If you just zoom in, maybe the Google or the Control Plus anymore.
00:36:13.760 - 00:36:15.830, Speaker I: Let me check why that's the case.
00:36:16.200 - 00:36:19.816, Speaker D: If not, it's fine. I think we can read it.
00:36:19.918 - 00:36:21.144, Speaker G: Yeah, that's fine.
00:36:21.182 - 00:36:21.576, Speaker E: On my end.
00:36:21.598 - 00:36:27.496, Speaker I: I zoom in on my screen now. I hear you again, sorry about this. Can you hear me?
00:36:27.598 - 00:36:33.304, Speaker D: Yeah, I was just saying if you zoom in a little bit, it would be a little better. But it's okay if you can't.
00:36:33.432 - 00:36:35.084, Speaker I: Oh, of course. Like this?
00:36:35.122 - 00:36:36.460, Speaker D: Perfect. Yeah, that's perfect.
00:36:36.610 - 00:36:58.020, Speaker I: Awesome. So that's a very course draft, obviously. But the idea is to study in a first step liquidations. We have looked a bit into the liquidation platform. So there's Ave compound. UDX and probably Mecca. Dow I think collectively they represent roughly over 80% of the lending markets.
00:36:58.020 - 00:38:00.212, Speaker I: So by capturing them, we would basically capture about 80% of the lending markets. And because of the liquidation proceeds, they contribute quite massively to mine extractable value. The liquidation mechanisms in Aave compound and Dyx are not auction based, but they are based on a fixed spread liquidation. This means in RV, once the debt passes, the health factor, so goes below one of the health factor, then any liquidator can come in and liquidate parts of the collateral. Now, it depends a bit of how much they can liquidate. I think on Avian compound, the close factor, which is the percentage, the fraction of what they can liquidate is 50%, on Dwadx is even 100%. So this is quite lender or borrower, unfriendly, I would say, and liquidator friendly.
00:38:00.212 - 00:38:45.844, Speaker I: Right. If you can liquidate almost 100% of the collateral, although it might be sufficient to just liquidate 5% to secure the debt. We have seen recent price Oracle manipulations. Well, it's debatable whether these are benign or malicious manipulations, but there's basically a fact that liquidators yield significant profits right. Over all these three platforms. So, ideally, we want to systematically measure what's the current state in default liquidations and what's the current mechanism. There are already some works that have looked at compound, I think, but I don't think they're as deep as we want them to be.
00:38:45.844 - 00:40:34.404, Speaker I: So I think that this space is quite broad to be explored. And ultimately, it would be interesting to know whether we can recommend, for example, to the lending platforms a liquidation mechanism that is anti mev, right? If you can find a liquidation mechanism that is maybe friendlier for the borrowers, well, it would necessarily be a bit unfriendlier for liquidators, because in the end, it's a zero sum game. But ideally, we want to find some liquidation mechanisms that prevents mev in some way. So there are a few questions we want to engage in, like very simple engineering questions. At the beginning, what's the monthly accumulated liquidation profit for the different platforms? How competitive are these liquidations? Right? Basically, just analyzing the gas prices, plotting a nice distribution of the different methods over the whole spectrum of the whole time frame, what are the different liquidation mechanisms methods, and how do they differ with respect to mev? And yeah, as I said, which liquidation mechanisms avoid mev? If we quantify how sensitive current depths are to liquidation, then we know by how much an adversary would need to manipulate a price oracle in order to trigger liquidation, in order to trigger mev. So if a miner is an mev or miner, and he knows that there's, I don't know, 100 million of collateral that is about to be liquidated, if the price just drops by 5%, well, they might just push it over the edge, right? And then they can anticipate that there will be some mev. So sensitivity of collateral to liquidation might be relevant.
00:40:34.404 - 00:41:25.220, Speaker I: So there are a few related works. I'm sure we missed a few. That's why this is just a very early draft. And so we discussed with the Flashbots team before, because we wanted to also quantify how mev impacts on blockchain security. We think that we will separate this into a separate FRP, because it actually matters to all sources of mev. So the second FRP would be, how can we quantify, let's say there's an mev opportunity that arrives, there's an mev aware miner, but this mev aware miner somehow doesn't manage to mine this transaction. And let's say some other miner or some other trader manages to mine this mev.
00:41:25.220 - 00:42:38.130, Speaker I: Now, how big does this mev opportunity need to be for this mev where miner to start forking the chain? So is it enough if the mev opportunity surpasses like ten times the block reward? Does this already mean that the miner will start like a rational miner will start poking the chain, basically doing selfish mining, build a private chain that he doesn't publish, and at some point, when he's lucky enough, he overwrites the public chain. So this is a second FRP that we initially had in here, but after consultations with the team, never worries. Okay, cool. So obviously there are few plots and figures that should come out of this the systemization of different liquidation mechanisms, ideally, actually, what liquidation mechanisms are anti mev. Right. Some concrete recommendations on that end.
00:42:41.200 - 00:43:25.870, Speaker D: Yeah, that all sounds super interesting. I think those are all important questions. I also wonder, are there any inherent trade offs in anti mev liquidations? Do you need some mev to keep the system running efficiently? And how low and what are the trade offs when you approach that minimum point? I think would be interesting. I kind of think about it in a similar way as AMMS, where AMMS really only work because of mev. And even though they're pretty inefficient, people like the UX so much that they're willing to expose some mev, but they don't want it to be too much. So how do we think about the trade offs of reducing mev? And how does that change when it goes to the extreme of approaching zero? I think is interesting.
00:43:26.480 - 00:43:37.970, Speaker I: Yeah. We also don't want to give no money to the liquidators. Right. Otherwise they wouldn't secure the system if it needs to be secured. So it's quite a challenging game.
00:43:38.420 - 00:43:39.170, Speaker D: Yeah.
00:43:42.900 - 00:44:49.110, Speaker B: Well, thanks for sharing, Arthur. I think it will be actually very interesting. We're very interested to see how you split the two questions and how you develop this current FRP and how you split the research question into two FRPS. So yeah, would love to follow up on the update here. I think, once again, one of the perhaps the next step with regard to the liquidations for this study on liquidations is to goes back to the taxonomy question, goes back to kind of how do we systematically quantify mev? I think perhaps deserves a separate call with the Flashbots engineering team who is collecting a different data set that is not overlapping with your team's data collection, because I believe that author your team is planning to separately collect the data for this study. Correct?
00:44:49.480 - 00:45:05.480, Speaker I: Yeah, this was our initial idea because we have some experience with Geth and we have full archive node in Geth and so on. So we do have a base level of infrastructure that would help, but obviously, the more synergies we can create, the better for everyone.
00:45:05.550 - 00:45:05.784, Speaker E: Right.
00:45:05.822 - 00:45:07.770, Speaker I: So that's to be seen.
00:45:10.460 - 00:45:20.130, Speaker B: Cool. Well, Alejo, do you have any questions or suggestions on this matter, on this particular FRP and FRP that will branch out?
00:45:20.820 - 00:46:38.312, Speaker E: No. What we discussed the other day, I think it's great that you split this into two different things. Now, I think the challenge here is how this interacts with the taxonomy we will eventually build. And the question that was asked before, okay, is this dependent on the taxonomy we build? Should we look at liquidations on their own, or should we try to tackle measuring the mev across the taxonomy? So this is the main question to me if we tackle separately liquidations from other ways of extracting mev. I think the challenge there is coordinating everything in a way that all the deliverables are sort of aligned, that we're measuring the same thing essentially. Right? So one approach is to have separate teams measure each of these opportunities separately and then do a coordination effort to try to make sure that we're all measuring the same thing in the same way. Otherwise the other approach would be to have perhaps a larger team cover the entire taxonomy and measure all the things there.
00:46:38.312 - 00:46:47.580, Speaker E: But again, it's also dependent a little bit on when and how we define that taxonomy.
00:46:50.960 - 00:47:02.432, Speaker I: Cool. Yeah. I mean, happy to continue discussing. Right. As you said, this could also be like a small section or like a small part of this FRP one. I believe that does measure everything.
00:47:02.486 - 00:47:02.656, Speaker E: Right.
00:47:02.678 - 00:47:06.790, Speaker I: That would also be fine. I mean, whatever fits better. The group.
00:47:09.240 - 00:48:00.596, Speaker B: Sounds great. I think one thing to clarify is that the FRP process is meant to discover what is within limit. By defining the scope, we can come up with answerable questions that we will have owners for each of the answerable questions so that through this collective research process we can arrive at the general deliverables. But of course, each of these research questions deserved a lot more time and energy put into it. So a lot of them deserve to be a standalone paper, perhaps once we actually gone through the collective research process. And I'm sure Phil has a lot more to say on this. But I want to move on to the third question in paper, one which is currently under address.
00:48:00.596 - 00:48:24.990, Speaker B: And we have received questions and good questions on what the third question should be, which is on MEB on alternative architecture. So the question is not very well defined yet at this. Like, I don't know whether Sonny and Dave, you guys now have stable connections, can share a bit of your thoughts in this regard.
00:48:28.480 - 00:50:00.784, Speaker F: Yeah, what I was thinking about this question is I was also thinking that this seems a bit OD fit for this paper because this paper is mostly about the architecture of this design. But I feel like the way to go about showing, even thinking about what does this fit in other architectures is to start with the Dolph hypothesis that this design, like the auction design and everything works in other architectures. And then disprove that by designing architecture like chain architectures that this auction design doesn't work. Know, Dave and I are designed like we mentioned, dave and I were designing, are designing one chain architecture in a BFT case with threshold decryption and stuff that we think that this auction design doesn't work in. But then there's probably other ones that you can explore as well. Like Avalanche team claims that their leaderless consensus protocol also makes the auction design not work. And so I feel like before you can even start to answer what means how you would design this system in others chains.
00:50:00.784 - 00:50:34.084, Speaker F: I think the first thing would be to just keep exploring as many trying to design as many architectures as you can in which this auction design doesn't work. That's kind of what I'm thinking is if you wanted to answer that question, that's probably the way you'd go about doing it. And this feels a little bit out of a little bit different than the rest of the paper for that reason, because it's more of a design problem more than evaluation problem, almost.
00:50:34.282 - 00:51:09.970, Speaker G: It's also not that the auction mechanism doesn't work, it's more so that the auction mechanism is like suboptimal. And if you have a different base layer, you can do more optimal things like eg. If you do the auction with an SGX, you get some security properties, but SGX aren't optimal. But given constraints of being on ethereum, you can't really do that much better. But now if we examine other systems, e. G tenement style census where you have BFT with a fixed threshold for liveness, you get new solution types. If you do an avalanche, maybe get something new as well.
00:51:09.970 - 00:52:08.580, Speaker G: I actually understand avalanche well enough to have a cogent thing to say there, so I think the latter might be an interesting, like, suppose another base layer type, what can we do there? Or what's the optimal we can aim for there, or what's other security guarantees we can aim for. I'm not sure how much to what degree you're going to get any nice level of abstraction across different base layer types, though, at least when you have a beep consensus, the threshold for liveness. It feels among things I know at the moment it seems like threshold signatures are threshold encryption is the best, but doesn't seem like it's going to hold for proof of work chain or avalanche. So I don't know if there's any nice abstraction layer to get other than just a summary table.
00:52:12.920 - 00:52:38.100, Speaker B: I would love to hear Phil and Alejo's thoughts on this. Hi, David. Phil. So I guess this is a question directed to research question number three on paper one.
00:52:42.550 - 00:52:54.360, Speaker D: Sorry, what was the question again? I'm also working on a paper deadline and kind of zoning in and out. Not that I'm not listening, but I don't know the concrete question.
00:52:57.530 - 00:53:23.682, Speaker B: I think perhaps Sunny's question kind of summed it up pretty well in how do we frame research question number three? So it actually is meaningful to the paper one, which mostly focused on flashbots architecture. Or maybe, Alejo, you have a better way of framing Sonny and Dave's question?
00:53:23.736 - 00:54:06.970, Speaker D: Yeah, I think that point makes sense, that it is a little bit of its own thing. I think it does relate to paper one. And I don't necessarily think the papers have to be like a religious organizing metric and paper. One could just call out the fact that this is an issue, because I do think it's somewhat relevant to what our system will eventually do if we want to respond to these changes that people will probably make, especially in other chains. So I think it'll probably be relevant to mention in Paper One whether it's going to be like super under Paper One. I don't know. I think that will naturally evolve.
00:54:06.970 - 00:54:43.980, Speaker D: If you guys are interested in taking that and reorganizing it or someone else's, I think that's also sane. But I don't think we were going to do a super. At least my intention when I originally wrote that document was not to be super deep in Paper One and kind of leave it as a future work for a next paper, which I think is consistent with what you're suggesting is the best way to approach it. Is my understanding of that clear? Because I think I got all the concerns, but I just want to make sure that I'm actually addressing the question.
00:54:47.870 - 00:55:34.300, Speaker B: Yeah, I think that's a high level, definitely. I think we're trying to find a solution in terms of what is the depth that we go into in terms of alternative based labor and what is the worthwhile question that actually pertains to auction mechanism design. For me, auction, which is what Paper One is about, right? So essentially, I guess perhaps to throw a proposal out there. But once again, I want to hear more from Dan, from author, from everyone else on this call, from specifically perhaps a survey of alternative architecture and what.
00:55:35.550 - 00:55:39.450, Speaker D: Your audio is really bad again. Tina, slowly.
00:55:41.070 - 00:55:46.960, Speaker B: Well, maybe can someone else take over my vocals? I'll just type my question.
00:55:47.890 - 00:56:34.940, Speaker F: I guess one question I had was what level of detail of this answer would go in favor? What? We could just say, does the Flashbots design work on all chain architectures? And we could just try to answer that simply like that. Or we could take it a step further and say like, okay, well, provide an examples of architectures where it doesn't work. Okay, we could do that, or we could be even more detailed, explain why it doesn't work in those architectures. Okay. Or we can go even further than that, which is modify the Flashbotch architecture to work in these architectures. And so I guess my question is what level of detail do we want in Paper One?
00:56:35.710 - 00:57:11.210, Speaker D: Yeah, I think that's also up to you guys from my perspective. Because like you said, Paper One is kind of like first order engineering focused in some way, like it's describing the system. It's kind of like a white paper, et cetera. I think the most important thing to have in there is a things that are directly relevant to early days. So, for example, a lot of people will ask things like, doesn't ETH Two just get rid of this? Or sharding solves this. Or you just do optimism roll up and blah, blah, blah. So I think we'll need to answer those practical questions of the things people are actually doing in the very near future.
00:57:11.210 - 00:58:06.266, Speaker D: How does this affect, how does it change everything we're talking about? I think the longer term fundamental theory of what is the real difference between these systems and various chains and how do we think about this problem and designing systems that doesn't have to be in paper one from my perspective and can just be called out as like these are all unanswered questions in future work and then we work on it separately. But none of that is set in stone. So really from my perspective, I'm happy to include whatever, but I think the scope of paper one is going to be kind of defending a design and part of that is just like answering low hanging fruit questions about if the system changes a little bit or if we just add like a commit reveal to the protocol, whatever it might be. We kind of want to say that this is more fundamental than that, if that makes sense.
00:58:06.368 - 00:58:22.080, Speaker F: Okay, so it's basically describe the chain architect, the requirements of a chain architecture in which this Flashbotch design works and then maybe we can say that we know of architectures where it doesn't, but that's out of describing those is out of scope for this paper.
00:58:22.770 - 00:58:53.194, Speaker D: Yeah, pretty much got it. But again, it's very open ended. So if you feel like there's something you want to say that's out of not in that scope, that's also fine. I think we just kind of want to give some broad color to the community about why we think this is a good idea to build in Paper One. Are you back, Tina? We're also overtime, so maybe we should yes, I'm back.
00:58:53.392 - 00:59:47.850, Speaker B: I could hear you guys all pretty well. So sorry about my spotty vocal. So I think everything actually that's I think a lot more clear than where it started. So I guess the next step is that we have another research workshop next week. We haven't really dived into Paper Two, although authors separate FRP will be the bulk of it. Also one thing that's under addressed a little bit in the current paper, but I think Saraya is working on it right now is kind of the auction part and he's done the literature review for it or he's going to do the literature review. So I think what is the expectation there? Perhaps we want to address it a bit more if the FRP as well.
00:59:47.850 - 01:00:29.814, Speaker B: So I think overall let's leave it here for now perhaps what Ho and the Flashboss team, we will work on iterating and updating some of the research process for more clarity to address some of the concerns and questions raised here. And folks, who's on the call, who's already submitting FRP or is planning on submitting FRP, please go ahead and make updated changes and when you feel, you know, create a PRP for the flashbox repo and we'll follow up with you.
01:00:30.012 - 01:01:00.320, Speaker D: Yeah. And if you guys have any meta comments, everyone here and involved at this stage, I think is a relatively independent, senior level research, at least capable. So please send comments, especially to Tina, Alex and me, about how we can change this process or if there's any overhead that would help you to remove and things like that. We want it to be minimal and incur. As little overhead as possible for organizing things.
01:01:02.690 - 01:01:08.680, Speaker B: Exactly. Well, no more questions. Well, let's leave it here.
01:01:11.450 - 01:01:12.600, Speaker E: Thank you, guys.
01:01:13.290 - 01:01:14.360, Speaker D: See you guys.
01:01:15.130 - 01:01:15.926, Speaker G: See you.
01:01:16.028 - 01:01:18.690, Speaker D: Thanks for taking the time. Bye.

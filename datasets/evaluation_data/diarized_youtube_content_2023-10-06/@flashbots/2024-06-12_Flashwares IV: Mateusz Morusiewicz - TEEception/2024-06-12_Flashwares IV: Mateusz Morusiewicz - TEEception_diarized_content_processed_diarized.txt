00:00:06.400 - 00:00:26.528, Speaker A: All right, perfect. We are live. Welcome, everyone. This is the fourth flashbots flashware session. This session will be hosted by Mateusz. Information about the session, as well as previous and upcoming sessions can be found on the forum collective dot, flashbots.net dot.
00:00:26.528 - 00:00:29.520, Speaker A: And with that, I will hand it over to Mateusz.
00:00:33.380 - 00:01:27.326, Speaker B: All right, so, hello, everyone. I've prepared a very short presentation. Three slides, and then I would like us to go and try to make something actually work on a bare metal TDX. And hopefully I can follow the last at home. But also, just feel free to comment with what you would want to do next within the context of TDX and virtualization. All right, so I'll go ahead and talk for like, ten minutes. All right, so, yeah, the topic today is t ception.
00:01:27.326 - 00:02:06.210, Speaker B: So it's the idea of using TDX to run a tested hypervisor. So we are putting, you know, we are putting containers into our vms, and that's running in TDX. So, you know, why would that ever be a good idea? Right? So that's the risk. That's the idea of today's, you know, of this fast first session. And it's more like a jam and like a hack session. Rather than me explaining anything or me teaching you something, I would be wrong a lot of the times in this presentation, so feel free to correct. And hopefully, hopefully I can also learn something new.
00:02:07.710 - 00:02:13.220, Speaker A: Sorry, sorry. One quick comment. Only half the screen is shared right now.
00:02:13.680 - 00:02:21.140, Speaker B: All right, let's fix that. This should work.
00:02:22.400 - 00:02:28.140, Speaker C: No, still, I think you should turn off the share screen and turn it on again, probably.
00:02:29.000 - 00:02:52.458, Speaker B: Yeah, it's worked. Okay, stop sharing. Hopefully we can beat the share screen issues before we dive into solving all of crypto. Perfect. All right, does this work?
00:02:52.514 - 00:02:53.910, Speaker C: Much, much better.
00:02:55.010 - 00:02:56.590, Speaker B: Much better. Or like, perfect.
00:02:57.250 - 00:02:58.970, Speaker C: Perfect, perfect.
00:02:59.050 - 00:03:41.120, Speaker B: That's good. Perfect. Okay, so first, like, very quickly, visualization and containerization was the difference. I'm sure most people have at least heard of those terms, and at least some of us are, I'm sure, experts in the domain. So there's a couple of ways you can do virtualization. So why virtualization is nice is you're not running your applications with access to your hardware, so you can run something that you don't trust, don't fully trust, or just as a security precaution, think, for example, Firefox Windows. You don't want your firefox windows to have access to your ram and your disk, of course.
00:03:41.120 - 00:04:16.350, Speaker B: So that's one example where you do trust somewhat the application. But as a precaution, you don't want to be running that. So that's software, software containerization. And what we'll be doing here is harder virtualization, at least in part. So hardware virtualization is where the whole thing is running in a sandbox. So the whole os that you're running, rather than just a window, the whole thing is running without access to hardware, or at least direct access to hardware. And one example would be just full visualization.
00:04:16.350 - 00:05:22.890, Speaker B: Wherever your OS, this green box and your applications, they know they're in a sandbox, but they just can't do anything about it. And the only way for them to access hardware is through the hypervisor and through the host OS, where the host is whatever is running your application in your virtualized OS. And that's for virtualization. Some of the technologies that can do this, you see now it's like an old thing nowadays, mostly like Camo and KVM, you can use those to emulate basically the whole machine, right? There's no access to the hardware directly. Then we have something in the middle where you have this green box, this guest ice, but actually does have access to the hardware for some instructions, which makes it, for example, much faster because you don't actually have this emulation layer. This is called para virtualization. Sometimes there's things in the middle.
00:05:22.890 - 00:05:58.100, Speaker B: If you are using Camo and KVM, it's not true that it's in either of those. You are using basic KVM. The KVM is a kernel module for visualization. Kernel visualization module probably. And although I'm not sure that's the right abbreviation, and you're using that as a way to accelerate your application. So some of this actually is translated much faster and some of your workloads actually run on the hardware. So there's not a very even speed, but just things in the middle.
00:05:58.100 - 00:07:09.536, Speaker B: And then on the far left we have containerization, or sometimes also called Osliver virtualization, where you don't even run an OS, it's just your application running somewhere with a bunch of libraries, and then you have some kind of engine underneath that's going to serve your application basically OS calls. So here on the stripe side, whenever you want to go access hardware, you're going to exit out of your vm and go ask the hypervisor or the hostess or whatever to, you know, to give you access to hardware or to do something with hardware for you with containers. That's not so much, right? First you just request the OS, like with an OS call, and that goes into the container engine and gets translated into whatever instructions. So it's a bit high level. And you know, if you think about security, full virtualization is kind of, and the most secure because nothing ever really runs on the hardware. It could be the strongest sandbox. I'm not sure if it is, because there's still things that can go wrong.
00:07:09.536 - 00:08:02.110, Speaker B: And you can probably escape this green box of your sandbox. This green is the sandbox. And you can try to escape to your hostess by leveraging some kind of attacks against this virtualization that you're under. So with a container, the problem is that you have access basically to the host kernel. So if you think about it like your app goes and requests something from the OS, what happens there is it goes into the kernel, right? So if there is a bug in the kernel, or if there's a bug in the host OS, or there's a bug in the container engine, you basically immediately grant, get permission and get access to the hardware. So if you run, for example, if this blue box is, for example, previous docker container, it's kind of triggered to escape it because you have access to all the devices of the machine. So this is usually kind of easy to escape.
00:08:02.110 - 00:08:33.400, Speaker B: And there's some options of some container engines that just simply insecure. This para visualization is kind of a bit more interesting because there's, you know, there's, the attacks are maybe less obvious because there's no hostess to escape to. It's just the harder. Right. But I'll stop now. Are there any questions? Did I, did I get something wrong? By the way, please do correct me.
00:08:36.540 - 00:09:23.370, Speaker D: I do have a comment here. So I think when you mentioned the full virtualization with QMU and KVM is probably the most secure. There are people who say differently. I don't know if you've heard about the Kubes project, the Kubes OS project, and I can't remember the details right now, but they basically, they tried to ditch KVM and QEMU for Xenore. And the idea basically is they view hardware based isolation as the most secure of all. And then comes software based virtualization, which is what QEMU does. It's an emulator.
00:09:23.370 - 00:09:48.570, Speaker D: Obviously hardware based isolation is most likely more secure rather than any kind of software written code that might contain any kind of bugs or something like that. Of course we have hardware bugs as well, but they seem to be less common than software bugs. That's just my comment here.
00:09:50.150 - 00:10:40.950, Speaker B: Yeah, I think that's right. So this approach with parasite virtualization, where you don't even have this hostess to escape to it and there's no emulation that you want to try to find bugs in. Yeah, could be more secure. I could definitely see that being the case, but I didn't do as much. This is kind of intuitive where full visualization is for sure safer than containerization, although again with very good containerization, maybe it's secure enough. And yes, where you kind of have direct access to hardware so you can do some things, you can do something is if you're under parabetualization, you can, for example, try to abuse the resources and things like that where it's not an escape, but you can still mess things up.
00:10:42.930 - 00:11:18.772, Speaker C: But yeah, I have also here, that's all true, but it's also very use case specific because paravetalization, if I recall correctly, for scenarios where you are trying to virtualize a process for a different architecture, then it will not be your target. And then there will. There you only have the option of full virtualization in this case. Or maybe containerization where you can. Yeah, maybe specify a different target, but I don't think part of it realization will help you here.
00:11:18.956 - 00:11:47.156, Speaker B: Yeah, absolutely. Because you're running on top of hardware, you must, the target must be the right hardware. You can do a trick here, you can actually run this. You can run emulation here, right. So rather than treating the emulator, which is, you know, Camo is an emulator. Right. Rather than treating camo as a visualization, like for sandboxing, you can treat it for just emulation, run camo here and then whatever else you want on top of that.
00:11:47.348 - 00:11:54.950, Speaker C: Yes, that's true. But then you have to provide this manually because.
00:11:55.290 - 00:12:20.510, Speaker B: And then it's very slow. Right. Because camo with KVM is kind of fast here. If you are like, especially if you match the hardware, if the hardware is the same as the camo target as the chem guessed, it's very fast with acceleration here is going to be. Yeah, it's going to be slow by definition, because the guest OS is a different target than the hardware. So I have to have.
00:12:21.210 - 00:12:21.990, Speaker C: Correct.
00:12:22.530 - 00:12:44.310, Speaker B: Okay, let's get into, let's get into the myth, which is TDX. So why am I going on about this, about this visualization? Because TDX is, you know, is a virtualization thing. Right. It basically looks like this. Right. The trusted domains. Right.
00:12:44.310 - 00:13:15.242, Speaker B: I think of it as vm as probably correct. But yeah, that's roughly the idea. So I think that this is how it looks like, you know, my, this is like an artist. This on the right is my rendition, you know, artist rendition of the thing that Latino provides in their docs, where we basically have this addition of the CGX module. Right? That's, yeah, that's doing something that's linked basically on top of the hardware. Right. So how.
00:13:15.242 - 00:13:51.620, Speaker B: And this, I think is true, because the TDX module does access the hardware directly for some instructions at least. So Friedr, actually, feel free to correct me if you know, because I think that this TDX module goes and talks with the hardware directly. Rather, the hardware keeps track of the TDX module. All right. Yeah. So there is going to be some traffic domains running basically against OS. So this is a full vm.
00:13:51.620 - 00:14:15.340, Speaker B: It's not a container. It's actually running in os. It's like some asterisks. What kind of os is that? But it's going to be the OS. And on top of that, you have whatever you'd put on top of your os, whatever drivers you have, whatever applications you have. And. Yeah, and then that goes and talks to either the hypervisor or the TDX module, or the hardware for the TDX module.
00:14:15.340 - 00:14:35.030, Speaker B: Yeah. So that's kind of cool. Right? Like we have this box. I think that's roughly how we can, how you can interpret it when it comes to like in the index context of virtualization. And I'll stop here for a bit. I would love Friedrich's opinion about my rendition of this diagram.
00:14:39.050 - 00:16:01.280, Speaker D: I mean, I think the interesting thing about TDX here is that it's, and you can see this here in the picture very clearly. It's trying to not only wall off different vms being able to extract information from each other, but the actual host and platform itself. And it does so via the TDX module. So, and if we want to interpret this picture, of course, I'm not a TDX module expert, but it does provide some interface to the VMM and does take a lot of responsibilities that a normal VMM actually has. Like example, if you could look at the nested page tables or extended page tables, it's taking care of that. Although we've learned that it's not like if you look at, for example, migrating the vm to a different host, and there's some exceptions, and we're still not sure whether these are secure or not. But in essence, the idea is that the TDX module has access studio extended page tables, and they host VMN not.
00:16:01.280 - 00:16:52.748, Speaker D: And so, yeah, there's quite a lot of isolation happening. And this is good. And also good is that this TDX module is software, and it can easily be upgraded, even though you don't have to reboot your system, you can do it on a fly and then that will be part of the attestation as well. So, so far so good. What we've seen from intel, this makes sense. Unfortunately, if you go into the details about memory access and stuff like that, either things haven't been figured out yet by us, or there needs to be some additional work here. But it looks like that the TDX module is as it is software.
00:16:52.748 - 00:17:37.600, Speaker D: We can change it and we can provide suggestions how to change that and make it more secure to provide our needs. Where we want a TD VM running without ever getting interrupted and making this wall perfect that you see here, that's basically just running like it's running on a different cpu and the host really doesn't have any kind of access. And if it tries to access any kind of page table information, then yeah, whatever, like our application gets slashed or will stop, something like that.
00:17:41.260 - 00:18:24.490, Speaker B: All right. All right. There you have it. Yeah, this does look good. And this does look like an improvement from the user perspective, if you want to go and run this in a cloud, if you're a user and this is your os, you want to go and run your application, this does give you separation from the cloud, basically from the cloud hypervisor, and shields you from them accessing anything here, which is very nice. All right, cool. I can see.
00:18:24.490 - 00:19:13.842, Speaker B: Okay, so KVM stands for kernel based visual machine. Of course it does. And then can I talk about preferences about LXC and Docker? So to me, the level at which I'm kind of thinking about this is whether, what kind of virtualization we want. So to me, Docker and Alexei and pulmonary visor, whatever else, see, it's kind of in one buckets, and it kind of depends on which one fits your needs better for you. Specifically, what do you want of this? Do you want to be running untrusted code in that containers on behalf of people? Probably don't use Docker. Probably not use LXC either, actually. Right? Yeah.
00:19:13.842 - 00:19:53.540, Speaker B: And if you don't care, if you just prefer exceed and then go with that, right? Yeah. At that point, it's like whichever tool fits you best. But as far as the virtualization goes, as far as Tex goes too, it's actually kind of the same. Hopefully other answers. All right, so this is what TDX looks like, if you think about it as like a part of the visualization stack, basically, right. It's a module that's translating to the host VMM. I'm going to continue calling that the hypervisor, though it's not the hypervisor, but whatever.
00:19:53.540 - 00:20:24.930, Speaker B: And some of this too harder has the extended pages table. So there's some things residing here. Some things are delegated to the hypervisor. All right, sweet. So why I'm excited about this, so why I'm excited about this is that we can also run containerization here. We can nest this content because this runs just in regular Os. We can do another level of visualization.
00:20:24.930 - 00:21:40.092, Speaker B: And with a proper sandbox you can probably run untrusted code in those trust domains where whoever gave you the code can be convinced that they are not going to do anything to the code, and there's not much you can do with the hardware to trick them. As long as you control the sandbox and set up properly, it could be safe as well, depending on what type of virtualization you're doing. But I'm even more excited is that you can run containerization here inside this green box. So you have this TDX module that's acting as everything in this blue box can be attested. You can go and test everything here. And in particular, if you're doing, for example, on OS level visualization, like Docker or something as a guest, you can actually attest that you're doing this correctly or according to some rules, which I find an interesting topic and hence the deception. We're going to run some sort of continualization solution or virtualization as I guess, all the TDX module, and we'll see where that gets us.
00:21:40.092 - 00:22:17.290, Speaker B: For example, can you attest anything that runs as the guests? Let's try to find out. So, yes, that's roughly what I'm talking about. I think that TDX nested virtualization is something worth exploring, and it's definitely something that's worth hacking on. This is kind of simple to set up. You'll see that it takes maybe an hour to get up to speed on this and start using a stack like this. And. Yeah, so with a, with like an os visualization.
00:22:17.290 - 00:23:04.820, Speaker B: So like Docker, this would look like the string on the left where we have the TX module and the guest and the container engine, all attested. So this blue box is tested. The green box is not necessarily. Let's think. Let's talk about it later. Yeah, but you cannot test all the rules that are going on in this blue box. In particular, how you run the applications with the container engine, what kind of version of the containers are using? What's the firmware? What commands exactly are you using? How are you sandboxing? Are you running this privileged container or are you running user space containers or whatever on the right.
00:23:04.820 - 00:23:26.710, Speaker B: This would be full visualization where probably not full visualization with an asterisk, probably harder. Accelerated so that it's fast. And where instead of a container engine, we're running another hypervisor. We are running our own hypervisor. This hypervisor, I'm not sure if you can attest. I don't think so. I think this is trusted.
00:23:26.710 - 00:23:58.014, Speaker B: But we can attest this other hypervisor, which I think could be pretty neat. I would like us to explore if this gets anywhere and this useful at all. Questions. That's it for the presentation. Let's take any questions that people may have. Right, no questions. Everything is clear.
00:23:58.014 - 00:24:34.660, Speaker B: Let's go. So that's it for my presentation as promised. Very short and yeah, let's try to figure out what do we want to do as next step. So I have some proposals, I have some agenda. What I thought would be nice to do is just go and look at how this looks like. How do we actually run Docker inside kennel inside the TDX Vm? I don't think that's. It's kind of straightforward, but it's maybe counterintuitive.
00:24:34.660 - 00:25:21.398, Speaker B: It's good to see that actually works and that you can still access data stations in particular from this nested container. I can show you where I'm stuck with nested full visualization because I'm actually stuck with running camo in camo. For whatever reason, the KVM module is just not available. We have some very cool things from Mo, who has recently built a Yogto image with Podman. With Podman inside. So this would be like a reproducible image where you have a containerization solution inside. Inside the image that you can run as a part of the TDX VM.
00:25:21.398 - 00:25:55.430, Speaker B: I think it's pretty cool. Yeah, I think that's it. So Leo is asking, is Docker itself reproducibility built? I should have no idea. I'd be surprised if you couldn't get it to build reproducible, but I didn't check. And I think that if it's not built reproducibility, we could probably always use something else. That's a good question, actually. Don't know if anyone cares to check.
00:25:55.430 - 00:26:41.892, Speaker B: I also be very curious about the answer. All right. In the meanwhile, I'm going to set up my console and let's see if I can run it. Let's see if I can run the current cam again because I did try and live demos. Right. All right. I have to make it big, right? So I have access to a better metal instance.
00:26:41.892 - 00:27:34.760, Speaker B: So this is very nice. So this is not a TDX VM as you'd get from let's say azure. This is a bare metal server that is TDX enabled and that we've configured to work with attestations. So we'll be using, we have access to all the hardware and we have access to all of the, we have like TDX guest device and things like that. Okay, so I have found the guide from canonical to be an extremely useful resource. It's linked on the forum and under it's just TDX. I'm also going to paste it in the zoom if anyone wants to follow.
00:27:34.760 - 00:28:14.998, Speaker B: So let's just make sure that I've set up correctly. They ask me first to go and let's just look at what the script does. Right. Like how does setting up itd experimental host look like? So the first thing they ask you to do is to go here and run this setup tdXcript. Okay, let's go and see what it does. Okay. I have no idea what this does as some kind of boot options later on.
00:28:14.998 - 00:29:06.840, Speaker B: We have this Kabuk team which is building TDX index libraries and it's going to be actually very important. I have a bunch of other dependencies in particular. We are going to install camo kerm system X 86 is, there's various flavors of kernel. This is the target that you want to emulate basically. In this case it's just going to be native, right? Because we are on a X 86 server as well. And this TDX tools host, this is from the Cobop team and this is where most of the goodies come from. If you're interested in seeing the actual libraries and the actual tools, this is where you actually want to go.
00:29:06.840 - 00:29:53.290, Speaker B: All right, so we're switching the kernel here and that's it. Okay, so in grab. So this is like the boot options. The thing that we are doing is, is we're allowing the KVM Intel TDX. So this is like enabling the, I think this enables the TDX device inside the KVM module so that we can have access to TDX inside cam o vms. And this is actually very important. So this means that we'll be able to go and request quotes from inside the vm.
00:29:53.290 - 00:30:34.144, Speaker B: So here is just a bunch of dependencies. As you saw, this is not very complex. The most complex change is probably enabling the KVM module and then configuring it with TDX support. All right, so a couple next steps. The guide asks us to go and enable TDX in the hosts bios, which we have done already. I'm not going to show you that. And yeah, let's see if our host is TDX has TDX enabled and you can see that indities.
00:30:34.144 - 00:31:17.960, Speaker B: So if you're following account with your own machine, this is kind of what you want, what you're interested in. Once you put up after setting up the host, this TDX module should be enabled. So both in versus and then you should see the. Yeah, and you should see this KVM intel being enabled here with TDX as well. All right, next up is the guide is asking us to go and generate the vm image that you're supposed to run. So let's go see what this does. This is rather simple.
00:31:17.960 - 00:31:54.630, Speaker B: So we're going to use a official Ubuntu image, something like just like Ubuntu 23. And we are going to do a bunch of things to the image, making it like a TDX guest image ready to be run with Camo on our machine. So I'm not actually going to run this because this will take forever. This takes like an hour. I've run this earlier. So I already have the image. What this does basically goes and downloads the image.
00:31:54.630 - 00:32:26.250, Speaker B: It's not very interesting. And yeah, then it's going to go and install. So this is kind of interesting. It's going to install the. Got any data? It's going to install all of this, you know, as like metadata. It's just setting up a bunch of stuff. And here's how we define how, you know, the image defines the dependencies that it was installed.
00:32:26.250 - 00:32:56.650, Speaker B: And again, you're seeing that, you see that the packages are kind of fine. It's the same. There is this. So this is the important bit where we will mount the TDX device in this inner vm. Once it boots, it's going to go and mount this mode. If you need to, you can modify this could actually be part later on. You could make it a part of some group.
00:32:56.650 - 00:33:40.490, Speaker B: So it's mounts of non red group could be useful. So this is important. It's going to mount the TDX devices, in particular the device that you're using to get TDX quotes inside your VM. Again, thanks to the co team, as you see all the tools. And the last thing is it just sets the root password to one to three, profile six. I don't think there's anything more here. So let's go back and yeah, the next thing is going to do is just going to increase the size of the image.
00:33:40.490 - 00:34:18.160, Speaker B: So when you download the image is very small, but you want the disk of this VM to be bigger. And how you do that in camo is just add space to the file that you don't know that. Yeah. So this is how they do it. Yeah. Here they are copying the user data and they're doing some image magic because what you download is an ISO and okay, whatever this is, I don't think anything. I think the rest is kind of simple.
00:34:18.160 - 00:34:49.526, Speaker B: So one thing that's important that's left is this setup. TDX guest they're going to copy it into TMp of the VM and they're going to, and then they're going to run it. So this is kind of important. We should probably go take a look. And that's it. That's going to be the image. All right, let's go look at statutex guest so this is basically what makes the image.
00:34:49.526 - 00:35:35.570, Speaker B: I know, TDX, right. And it's very simple. All it does installs a bunch of dependencies, again from the kabuk team. Right. So they're adding the right repository and installing the Kabuk TDX guest package, which contains a bunch of stuff in particular contains like tools to get the quotes, to get the TDX codes. All right. So once you're on the image, what you'll get out is this TDX guest 1223 of this qcal two format, which is the cam format.
00:35:35.570 - 00:36:06.454, Speaker B: And let's see. And the next step is just to put it. So let's try, let me see if I actually have the image running anywhere. Yeah, I do. So let me kill it. Right? Let's run it. So the right command is like a var script.
00:36:06.454 - 00:36:34.320, Speaker B: And then I'm exporting the path to the navcreated image. And let's take a look quickly at the, at the command, at the script. So this site modified. I'm trying to make it in a run with versus visualization on with very success. Yes, the success is partial. It's just. Okay, let's see what it does.
00:36:34.320 - 00:37:18.460, Speaker B: So first the script checks that your user is in the KVM group because otherwise you cannot use the acceleration or in general the KVM module. So it's important that you do. Then that's basically nothing. It's just running the chemo system. This is the native one and you can see that it's native because we are passing in cpu host. In kernel terms, this means that the guest and the host is the same target and we are asking Camo to not emulate anything. There's a bunch of things here.
00:37:18.460 - 00:37:45.884, Speaker B: I didn't quite work out how the memory encryption is handled here. So if anyone knows, that would be nice to learn about basically saying, please encrypt my memory with TDX. And I have no idea how that sounds. Inside. Inside. I'd be very curious to learn. All right.
00:37:45.884 - 00:38:11.744, Speaker B: And then there's not much else really. Yeah. And just tells you that this is running. So let's go ahead and run it. All right. Usually needs a second to put up, but. All right.
00:38:11.744 - 00:38:26.016, Speaker B: And we are in. Okay. And I'm looking at the guides, what. What else they're asking to. Asking us to do. And. Yeah.
00:38:26.016 - 00:38:43.290, Speaker B: So now comes the verification part. So first they're asking us to run this comment. Right. Mask, pipe into grep, look for TDX. Right. So we are going to look through fruit mask. So this is like the kernel log or something like that.
00:38:43.290 - 00:39:19.180, Speaker B: Right. So first thing it does is it says that it's detected that it's a guest, which is very nice because it's also correct. And, yeah, saying that, you know, it has, like, memory encryption within the. Which is nice. So this looks very good. Of course, this is not something that you can trust because it's just a log. So we actually need a better way to confirm that we are indeed in TDX.
00:39:19.180 - 00:40:06.470, Speaker B: So next thing that they ask us to do is check if the TDX device is mounted. And this is where we go and request our quotes and. All right, I think that's it. So the guide goes into setting up attestations, which I'm not going to show because it's either very simple and you just follow the script or very complex. We have followed the guide with hopefully success. And. Okay, next thing that they ask us to do is to go and set up the guests at the stations.
00:40:06.470 - 00:40:33.076, Speaker B: So here again, Kabul team, the sleep. TDX hotels dev, I think this is from the Kabuk team, has a bunch of nice things in particular. I think this is. Yeah, this is the thing that they provide. Second example quote, um, which we're going to go and go and run. Um, so, yeah, let's run this. And what's going.
00:40:33.076 - 00:40:50.160, Speaker B: What's this gonna do is it's going to build this. This example that goes and requests a TDX quote. So generates like a TD report and. And request a quad. I never forget. I never remember the path. So.
00:40:50.160 - 00:41:12.500, Speaker B: Okay. And then we can go and run it and. All right, so we have some bytes, right? We have some. Some hacks and yeah. It's going to generate the report data. Here we have the full report. This includes all the fields that we are looking for.
00:41:12.500 - 00:41:35.906, Speaker B: Probably like what image was run and such. And yeah, we got the quote. So if we go and parse this, this should kind of convince us that we're indeed running into DX and everything is set up correctly. This should be signpoint or whatever. And. Yeah. So we got, we got like a camo VM running.
00:41:35.906 - 00:42:09.418, Speaker B: So that's the first step. Right. And I'll probably stop now for like a minute and see if there's any questions. The next part will be. I was going to run Docker inside and see if we can get the code to still work. Is cowork a canonical or intel team? I have no idea. Yeah.
00:42:09.418 - 00:42:41.144, Speaker B: Does anyone know the. I don't think they're part of canonical because they have a separate PPA. Right. This is not. It's not the usual colony coughings. So I'd be surprised if they were. Yeah.
00:42:41.144 - 00:43:05.070, Speaker B: I'm trying to look. Yeah. Hard to say. I don't know. I wouldn't be surprised either way. All right. I actually have a question here to Mo because Mo has actually went and parsed this.
00:43:05.070 - 00:43:14.390, Speaker B: This quote. And mo, could you maybe paste me or paste in the chat the parse data for this for this quote?
00:43:15.250 - 00:43:22.230, Speaker C: Yes, I can. 1 second. I need to parse it again but once. Give me 1 second.
00:43:30.860 - 00:43:31.800, Speaker B: Okay.
00:43:32.740 - 00:43:39.920, Speaker D: Andrew has written a cool script that does exactly that. I think it would be nice to show here.
00:43:42.660 - 00:43:51.692, Speaker B: Yeah. Mo, do we want to show the script or. We probably cut you over. So I don't want to make you all good.
00:43:51.756 - 00:43:54.430, Speaker C: Where should I post the. The quote?
00:43:57.610 - 00:43:59.950, Speaker B: You can dm me. Maybe I can just write here.
00:44:00.530 - 00:44:03.590, Speaker C: All right. I'll send it to you. 1 second.
00:44:04.090 - 00:44:10.030, Speaker B: Yeah. But we have a very nice parsing tool from Andrew. We should definitely go on the kit at least.
00:44:10.610 - 00:44:33.160, Speaker C: Yeah. The one from Andrew is Parser for the version four of the TD quote. So basically TDX 1.0. I think I've written two parsers in rust. Which one also v four and one for the v five in case we. Yeah, we utilize the newest quote. So we have two.
00:44:33.160 - 00:44:52.120, Speaker C: I can share with you the two repos. So this is the code pauser and rust. And I'll fetch you the one from Andrew shortly.
00:44:54.220 - 00:45:03.396, Speaker B: All right. Okay. So this is the parsed. The parsed quote. And. Yeah. It looks like, you know.
00:45:03.396 - 00:45:17.598, Speaker B: Looks like everything is here. Yeah. No, anymore it's kind of. Yeah. Intro I think dropped down there. Right.
00:45:17.774 - 00:45:18.142, Speaker C: Okay.
00:45:18.166 - 00:45:30.210, Speaker B: And we have the three most important measurements. Right. This is kind of what we care about. And user data is just zeros. Right. We didn't actually post, actually.
00:45:30.510 - 00:45:46.252, Speaker C: Sorry, I think I misled you here. The RTMR three is not necessary user data. It's like an empty field that can be extended with whatever later on. Because if you go up, you will see user data. There is a field for user data. Yeah.
00:45:46.436 - 00:45:47.480, Speaker B: So there's something.
00:45:47.940 - 00:45:56.844, Speaker D: It was my RTMR three could be used for the Bob private ssh key, for example.
00:45:57.012 - 00:45:57.388, Speaker B: Yes.
00:45:57.444 - 00:46:02.240, Speaker C: You can use it for anything you can't think of. Like it's a 64 byte, I think.
00:46:04.920 - 00:46:11.888, Speaker B: What do you mean by private key? So the public parts of the key or something like that?
00:46:12.024 - 00:46:12.740, Speaker C: Yes.
00:46:14.120 - 00:46:55.710, Speaker B: So if I want someone to, you know, if I want to convince someone that I'm running in SGX and, you know, and give them a way to give me data in a way that only I can get it, I should propose I should just put my public key, or like a hash of my public key inside this RTMR three. Right. And they can encrypt to that. And they can be reasonably sure that if they check that I'm actually generating the private key inside the enclave, right. Inside TDX, and they check the other three. So the image and the command line, whatever they would config, they can be sure that they can encrypt to that key. And only I can decrypt it inside TDX.
00:47:00.260 - 00:47:25.696, Speaker C: If I. Yeah, it's like you can think of it as a field where you can. You can export some data to the outside, attestably. Like basically you can make sure that this is really by this image and you can attest it like it's secure, like it's not being manipulated or. Yeah. Maliciously changed.
00:47:25.888 - 00:47:41.300, Speaker B: That's pretty cool. That's pretty cool actually, because that's the next step. Right. How do I get data in? How do I get convinced that I can get data in? Right. Yeah. And that would be one way. So that's interesting.
00:47:42.720 - 00:48:06.630, Speaker C: If you notice when you generated the TD quote, you got like three failures at the end which says like, could not extend those. RTmr two and three fail to extend. Yeah. Maybe we could look into this later on how we can extend these and add some data to it. But yeah, this is the main idea of the station here. You can add stuff.
00:48:08.410 - 00:48:20.250, Speaker B: I see. And with what would we extend this? Because as far as the guy goes, they're saying that this is fine. Yes. I'm not sure I trust. So what would happen here?
00:48:21.590 - 00:49:39.218, Speaker C: What would happen here if I understood correctly from the documentation that the TD module will inject those values plus their hashes and signs them and put them part of the session report. So this is mainly, as Frieder said, you can use it, for example, exposing your public key, and you can attest it then through the TD quote, and it will be part of the general hash value. And a very important part, if you show the parsing again, is the MRTD actually, which is how I interpreted it, is basically comparable to the Gx enclave. Mister enclave. So the measurement enclave, that's how I understood it, actually. So this here is basically measurement TD instead, instead of a measurement enclave. But I also noticed that your image that you created on this machine and the one that we created on Andrew's machine, on two different machines, they were generating the same measurement, which is actually correct, because if you think of it, you are both of them, like, you and Andrew generate the same image.
00:49:39.218 - 00:49:47.470, Speaker C: So like from the same base image, and you didn't do any changes. So I would expect also to have identical value.
00:49:47.930 - 00:49:54.510, Speaker B: But I did use different options for my Camus CMD.
00:49:55.490 - 00:50:50.440, Speaker D: I don't think this is the case. And if we can get a, a yocto at the station, we will likely see the same MRTD. And the reason for that is the MRTD only has, like, it's the initial measurement. Like if you look at a TPM measurement, PCR zero, the first value that being measured, that's only like the firmware and the boot UEFI, stuff like that. This is what's being measured. And then you have RTMR zero, which is probably the kernel. RTMR one might be the round disk, and RTMR two, kernel command line, but don't, like, I don't know which one of these, but that's basically what they're measuring afterwards, which you will find in PCR three.
00:50:50.440 - 00:51:19.132, Speaker D: Well, in the PCR values, so. But MRTD is PCR zero. So that's basically, that's why it's called MRTD, the measurement of the TD itself. So before any VM has happened, it's only the initial trusted domain that's being measured here with a firmware that's eventually going to boot the booty VMDez.
00:51:19.226 - 00:51:26.536, Speaker C: Yeah, makes sense as well. But the same time, I don't see, then, I don't see any usage for it, like at the moment for security wise.
00:51:26.568 - 00:51:41.820, Speaker D: So basically the most important, I mean, it's a firmware, it's a boot, it's the Ufe? You need to know what's being booted here. If you don't know what you're booting, you could easily sneak in a backdoor. So this is, of course, this is part of security.
00:51:42.240 - 00:51:50.680, Speaker C: Yes, but we don't have the access on this firmware. It's proprietary. So basically you kind of like just trusting this hash to be.
00:51:50.720 - 00:52:13.500, Speaker D: No, I think in this case here, we do have access. This is what actually what we give by the QEMU command is we provide an open source UEFI implementation. And I don't know what else is passed, but we do have access and we can actually try to do this MRCD measurement.
00:52:13.990 - 00:52:34.606, Speaker C: This would be an interesting. To verify this, actually. This is nice, but. Yeah, back to the RTMR zero, one and two. Yeah, you are correct about the. This is the unified kernel image hash. And I think the one was the CMD line, and the second is an advent disk.
00:52:34.606 - 00:52:54.370, Speaker C: But why do they say then that those three values cannot be generated without, like, booting the image? So these three values are runtime measurements that can be only generated during runtime and cannot be done at compile time, like at building time of the image.
00:52:54.830 - 00:53:26.942, Speaker D: So there's, there's a, there's a misunderstanding here. RTMR zero, one and two. These are, these are different depending on the VM image that you're booting. So it might as well be that you're going to boot an image that's not going to send this event of, I want to have a measurement right now. And then you don't have any rtmr zero. You don't even have an RtmR zero. Not even like a one and two.
00:53:26.942 - 00:53:58.050, Speaker D: Out of question. So it depends on whatever you're going to boot, which is then going to give you a measurement or not. It depends on the code that you like. This is a chain you put in measure something, you execute that, and then this something is going to execute something else, which is then being measured and so on. So depending on what you're going to start in the next phase, it's going to give you a measurement or nothing.
00:53:59.300 - 00:54:00.160, Speaker C: I see.
00:54:02.100 - 00:54:17.940, Speaker B: Yeah, I think that we actually can get this at build time. It's just complex and they didn't do it yet. But if you just captured all those events, I think that you can get this without access to TDX at least, right?
00:54:18.100 - 00:54:33.842, Speaker D: Definitely. If the MRTD is PCR Zero, which is what they're saying, then we just need to look at the TPM documentation and look how they're measuring the firmware and then we can reproduce the MRTD with MRTD.
00:54:33.866 - 00:54:36.910, Speaker B: Yes, but how about.
00:54:37.610 - 00:54:40.870, Speaker C: Yeah, how do you do them? That's the question.
00:54:41.450 - 00:54:53.910, Speaker B: But I think, I think it's the same for those. Right. I just have to emulate it. But there is no, like, those are not signed or anything like that. Right? This doesn't require access to TDX hardware. No.
00:54:54.410 - 00:54:59.990, Speaker D: For these measurements, we already have code that can measure these parts of the disk.
00:55:00.450 - 00:55:12.910, Speaker C: But are they comparable with the same values? This is the question. Are they generating the same values as these? You didn't verify this. We have to verify this, in my opinion.
00:55:13.770 - 00:55:18.642, Speaker D: Yeah, sure. We can verify that. We can just run the script on the image that we have here and.
00:55:18.706 - 00:55:26.570, Speaker C: Check whether, I tried this. It doesn't work out of the box. You have to do some kind of changes because the script does not accept this format.
00:55:29.470 - 00:55:30.102, Speaker B: What is it?
00:55:30.126 - 00:55:33.942, Speaker D: Is it the Kikao two format? Something like that?
00:55:34.086 - 00:55:35.550, Speaker C: Yes, it's Kikao two.
00:55:35.710 - 00:55:37.730, Speaker D: Okay. And that's the reason why it's failing.
00:55:38.630 - 00:55:47.450, Speaker C: It's failing. Yeah. It's failing. Not necessarily because of the format, but I assume it's because of the format. So I will try to change it to raw format and try again.
00:55:47.930 - 00:55:52.210, Speaker D: Okay. That I don't think this is like we can fix. This should be easy.
00:55:52.370 - 00:55:54.510, Speaker C: Yeah, yeah, definitely.
00:55:56.770 - 00:56:37.300, Speaker B: All right, amazing. So last thing, I'll show you how. I show you how you can, I don't know, access the DX codes inside Docker, which I think is pretty cool. I'm going to run a previous container because I have not yet figured out how to run this in user mode. The usual tricks with cgroups don't actually work. I'm sure this can be done. Just didn't have the time yet.
00:56:37.300 - 00:57:11.400, Speaker B: I'm also not sure if we want to use Docker. Not investing too much. Yeah. Let's see if I can get this work. And what we'll use is we'll use one of the tools from the people. Let me remember. Actually do this.
00:57:11.400 - 00:57:46.286, Speaker B: Oh, yeah. So installing the samples to then add. We are not pinning. I think that this actually. Okay. Is this. Yeah, trust.
00:57:46.286 - 00:58:07.152, Speaker B: Sorry. Okay. And then quot just like that. This is just zero, I think. All right. And we did, you know, get a call. Right.
00:58:07.152 - 00:58:34.520, Speaker B: So this is from inside Docker, which I think is pretty cool. It's running pre, it is running privileged, which is not cool. It's completely broken. But yeah, I can see that we do have a access to the device and it's generating quotes just fine. I'm actually not sure what this code has, what this code contains. I think it would be pretty cool to go find out. We should definitely go try and try and parse this.
00:58:34.520 - 00:58:48.600, Speaker B: Probably not right now. So if you want answers, you have to reproduce and then check the code. But in the meanwhile, we'll for sure try and parse this and see what this code has inside.
00:58:50.220 - 00:58:50.708, Speaker D: All right.
00:58:50.764 - 00:59:50.800, Speaker B: So, yeah, we are running Docker in a way that is attestable. If this initial VM was generated, reproducibility, and you could have tested, and it didn't include SSH access, it could actually be reasonably certain that the way that the containers are run is as you expect, which I think is interesting. There is not really anything severely broken, I think, about this approach, although I'm pretty sure that this, that the code that you're getting inside Docker doesn't actually give you any guarantees about the container running, rather about the initial VM, which could be actually useful in some way. So, yeah, I think that's it for me today. Do we have any last questions? Maybe questions from YouTube? If anyone is there, it's looking at the comments, I'll go check.
00:59:56.740 - 01:00:16.700, Speaker A: No questions from YouTube, but if you're watching this afterwards on YouTube, please go to the forum, ask your questions in the thread, it's linked in the description, and then any upcoming sessions will also be posted on the forum. Collective flashbots, Netanyahu, thank you so much.
01:00:18.200 - 01:00:24.120, Speaker B: Right. Thanks, everyone. And yeah, see you next time. Awesome.

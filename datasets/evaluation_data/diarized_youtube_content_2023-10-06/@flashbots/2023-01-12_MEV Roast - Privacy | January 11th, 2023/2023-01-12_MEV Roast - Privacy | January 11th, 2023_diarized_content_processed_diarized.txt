00:01:54.300 - 00:01:57.090, Speaker A: Wouldn't talk. Can you hear me?
00:02:00.020 - 00:02:02.560, Speaker B: Audio is good. You're good, Quentin.
00:03:29.580 - 00:03:32.650, Speaker A: Should I test sharing my screen?
00:05:16.330 - 00:05:17.080, Speaker C: Hello.
00:05:20.490 - 00:05:21.760, Speaker B: Hello. Hello.
00:05:49.510 - 00:05:52.562, Speaker A: My firefox crashed, and I tried to share my screen.
00:05:52.616 - 00:05:53.700, Speaker D: Let's try that again.
00:08:50.460 - 00:08:56.970, Speaker B: Hello. So I think we will give our first speaker a two minute grace period to figure out the audio, and then we'll get started.
00:09:27.630 - 00:09:30.060, Speaker A: Can you guys hear me and see my screen?
00:09:30.990 - 00:09:31.740, Speaker C: Yes.
00:09:33.070 - 00:09:34.298, Speaker A: Yes to both.
00:09:34.464 - 00:09:35.754, Speaker C: Yes to both.
00:09:35.952 - 00:09:50.590, Speaker A: OK, great. I can't see anything, and my camera is not working. But we all love Linux anyway, so do I have the green light to go? What's the story, Sarah?
00:09:51.170 - 00:10:10.310, Speaker B: Let's do a quick so. Hey, everyone, thanks for joining us. Delighted to bring back the flashbots tradition of the Mev roast. So today we are focusing on privacy, and our roast master will be Justin Drake. Justin, I don't know if you want to introduce the topics at all or if we should just go right into it. And our first speaker is Quintess.
00:10:12.970 - 00:10:26.940, Speaker C: No, I think we can just go into it. I think my role is to just ask hard and spicy questions, so I guess I also encourage questions from the audience, if there are any. I think we can get started with.
00:10:29.250 - 00:11:05.894, Speaker A: Okay, excellent. Please interrupt me if something goes wrong technically, and there is time allocated at the end for questions, so that should be good. Okay. With no further ado, I'll be motivating why we're having this roast in the first place. And my name is Quintess, and I'm from the flashpots research team. Right. So why do we want privacy in mev? When someone asks me this question, I kind of feel like there's two points to the answer to my answer.
00:11:05.894 - 00:11:42.402, Speaker A: At least one is cooperation. Right. In particular, we want cooperation between entities that don't trust each other and that might have conflicting incentives. And I think this is particularly difficult in mev, and I'll sort of expand on why privacy is important for that in a second. And the second reason why privacy is important in mev is because it affects user outcomes. Now, this is a very broad term, I realize, but I think it's broad intentionally because it's not exactly clear what the outcome should be. It depends on the application.
00:11:42.402 - 00:13:19.620, Speaker A: But an example you can keep in mind is like a uniswap swap. For example, the user's price is a measure of outcome, but then you might have some other outcomes, like, for example, a payment you receive via an order flow auction or something along those lines. Now, looking at cooperation first, what do I mean by cooperation? What are some examples of things we can think of? And really, if you think of the sort of the primitives the building blocks, no pun intended, that we see pun intended in the Mev supply chain is we see bundles, bundles of bundles and blocks. And really, what's happening here is we have some end output a block or an ordered list of transactions which represents some sort of utility to multiple agents that contributed the transactions that make up this ordering. And so if we think about it, we have a bunch of agents who want to submit transactions into a block and somehow they have to all get their transactions together into a single block. But in order to build this final block, they need to share this information, these transactions and some other information perhaps to actually have the transactions executed. But this is more difficult than it seems on the surface, in part because information is very valuable, right? What information am I talking about? I'm talking about transactions on one level.
00:13:19.620 - 00:15:01.342, Speaker A: So a basic example is someone is executing some complicated arbitrage with a transaction or a series of transactions and if someone else sees these transactions, they can just copy their strategy, which significantly reduces the profitability of the trader or the searcher or whatever you want to call them. But then there's also meta information that's important, right? So for example, bids, if the coordination mechanism you're using requires you to bid to pay someone for something, having someone know what you're bidding, especially when they're competing with you, is obviously a disadvantage because they can just bid epsilon more and suddenly you're down in the dumps. And so clearly privacy is important and one sort of mapping we can think of one sort of different use case that seems very similar, is high frequency trading. In traditional finance, these firms are known to be super secretive, to not even be willing to tell you how many members they have in teams and these kind of things because even that little bit of information can be alpha, it can be very profitable for someone else. And profit for someone else often means a loss of profit for these firms. But why do we care about cooperation? Right? Seems very nice, but can we be a bit more specific about what's nice about it? If we look at the mev supply chain, we can see in particular between the search and build and validator that a lot of this sensitive information is being passed around. But passing the sensitive information around means that there's a barrier to cooperation.
00:15:01.342 - 00:16:14.298, Speaker A: Or there can be, because there's a high degree of trust required if we don't have the proper mechanism for cooperation. And the risk here is that this barrier to cooperation means that the sort of most efficient outcome is just these entities being amalgamated into one large centralized entity. And this is not something we want. And I can give a couple of reasons why. So we want to avoid these centralized entities because we think often or they will likely be monopolistic or oligopolistic in the sense that there'll only be a handful of these ones of these centralized entities because the market can only support so many. Right? And the reason you want to avoid this is because we want to avoid rent seeking, for example, if there's not enough competition, then these entities can internalize a lot of the value that we might want to direct elsewhere. We want to avoid regulatory centralization, centralized entity is probably based in some sort of jurisdiction and we don't want a sort of credibly neutral blockchain to be subject to the whims of some government.
00:16:14.298 - 00:17:25.490, Speaker A: And then also we want to avoid undue or disproportionate influence over protocol incentives. Blocks are very valuable or can be, and they're also a very key component to blockchains, obviously. And so having one entity or one handful of entities controlling this process can be detrimental to the system. But where does privacy come in? Right. We've talked about cooperation, but what does privacy allow us to do? Well, like I hinted at earlier, privacy allows us to lower the barriers to cooperation, which means that the market can sustain, or rather I should say, in order for entities to work together, we don't need to build trusted relationships and we don't need to maybe sign legal agreements. We can have a permissionless system where entities can interact with each other, can coordinate without requiring this massive overhead or someone's permission. And what's nice about this is that permissionless systems mean that agents can join whenever it's profitable to do so, which hopefully means the system is more competitive.
00:17:25.490 - 00:18:24.030, Speaker A: And like I said earlier, this avoids rent seeking. It pushes value back into the chain, to the validators or perhaps back to the users. But it also hopefully allows more entities to participate in this system, making it more decentralized. What's also nice about cooperation is that it might unlock additional value. What do I mean by this? I think maybe the most basic example we can think of today is that many searches building a block together or aggregating many different bundles together into one block might see that block being more profitable than the block than that any individual searcher could produce. Right, and how is this being done at the moment? Well, some of the proposals or some of the implementations as far have just been trusted private channels. Mev geth was an example of this which allowed searchers and miners to cooperate without searcher bundles being stolen.
00:18:24.030 - 00:18:59.434, Speaker A: We had builder OPCs at the moment is another way for searchers to submit bundles privately without other searches seeing them. But obviously there are very heavy trust assumptions involved here. Similarly, commit reveal schemes like Mev Boost have been implemented. Right. Mev Boost allowing validators and builders to cooperate without the builder worrying that the validator will steal their block. So that's it for cooperation. What about user outcomes? It's like sort of very abstract term I referenced earlier.
00:18:59.434 - 00:19:40.190, Speaker A: What's an example of this? Well, a very easy one is sandwiches. I don't really have to explain this too much. We're all very familiar with sandwiches. And so maybe moving on to another example, we have generalized frontrunners. So a generalized front runner is one of the first forms of mev that was spoken about when mev became popularized in the Dark Forest post. If you accidentally leave some money available to the world in a smart contract and you try to get that out with the transaction through the mempool, you're probably not going to see that money again then. A slightly more intricate example than order flow auction.
00:19:40.190 - 00:21:15.066, Speaker A: So maybe leaving out the implementation details we can imagine some order flow auction or some black box called the order flow auction where users and searches both participate and the output is supposed to be some bundle which is beneficial to the user according to some rule. So the user's execution is good, their payment is good and we can imagine the output maybe being like a user being background by a searcher. But if we have the wrong privacy sort of environment in the Ofa and more information is exposed than we would like, a searcher could for example act outside of the order flow auction and outside of the rules that the order flow auction can enforce to effectively, for example, sandwich the user, which could end up with the user execution being much worse than anticipated and there actually having been a much better way to execute the user's transaction. Maybe just without the bundle, who knows? But the point is that it's very hard to reason about what's good for the user within the order flow auction if agents are also acting on the same information outside of it. Right? And why do we care? I guess why do we care about user outcomes? Should be a bit of a silly question. I think most of us probably agree that it's a very important thing to do but maybe just to motivate it a little bit, we can say that we want to make trustlessness appealing again a very general statement. But we believe in blockchain with cryptography and all the incentives and decentralization going into this.
00:21:15.066 - 00:22:43.830, Speaker A: We believe that the trust assumptions in the applications that we're building are better than the trust assumptions in the traditional world like a dex versus a sex for example. However, we don't want this trust to come at a very heavy cost to users in the form of worse prices or higher fees or these kinds of things. Similarly, one can argue that blockchains were invented to address mev and this is a bit like a bit more of a philosophical point. But really what I'm trying to say is that when Bitcoin was created we're trying to disintermediate remove this very powerful intermediary that can impose their objective function and extract value from users at the user's cost. Right? And if we think about what mev is, often this is basically the same thing because a validator or a miner, whoever is in a very powerful position and they sort of intermediate between all these other users who want their transactions executed, they're able to extract value often at the cost of users. And so addressing mev is in keeping with the sort of philosophical tradition of blockchains, which is arguably a good thing in itself, but also, I think, can teach us many lessons that hopefully can be applied outside of the very specific case of sandwiching or whatever it is. Maybe that was a bit too abstract, but I'll just say, bottom line, many people have this semi utopic vision of what blockchain can accomplish for people.
00:22:43.830 - 00:23:58.494, Speaker A: And in order for us to reach that, I think most people would agree that sort of in order to reach a world where users outcomes are improved, we need to improve user outcomes. Right? And then how has this been done, how people propose to do this? So again, trusted private channels, Protect RPC is an example of this where users can submit their transactions directly to Flashbots Builder, so it's not seen in the mempool. And then those transactions sort of end up in a block without anyone else seeing it until it's executed. There are many cryptographic proposals as well threshold encryption, mempools, commit, reveal schemes, trusted execution environments, and I'm sure we'll hear about all of these in the coming talks. There are also non private approaches, so decentralized sequencing, trusted marketplaces, et cetera. I should mention that all of them have their benefits, all of them have their drawbacks, and each of them merits its own talk. So I won't go into them individually, but maybe to motivate that this is a very interesting problem and that the most naive solution definitely isn't necessarily the best one.
00:23:58.494 - 00:25:18.742, Speaker A: I'll give this example, right? So why can't we just slap an encryption scheme on top of this to stop the validator to act on it? Or maybe why wouldn't we want to? Right? One reason is the specific challenges specific to the scheme. If you have a commit reveal scheme, how can you ensure a reveal after the commit was made? Or something along those lines. But I think another question that's maybe more interesting to me is that the outcomes in an encrypted environment, if the encryption is successful, is that the outcomes are blind in some sense, right? What does this mean? Well, if we assume that the outcome is blind, we assume that the transactions are ordered roughly randomly. But how does a random ordering compare to something which is like a buy sell, buy, sell with regard to swaps? Especially if the random ordering ends up seeing buy buy, sell, sell, where the second buy and the second sell revert because the prices aren't within their range. This is obviously not desirable. And now obviously we can go into the nitty gritty here. We can say, well, actually, the ordering wouldn't be random because people would be spamming the chain to try sort of compete for jockey for beneficial positioning and these kind of things.
00:25:18.742 - 00:26:29.310, Speaker A: But that's not the point I'm trying to get to. I'm really just trying to say that this is a hard problem and we can't just make mev private and then we've solved the problems. And so I'll introduce a buzzword before I close off, which many of you hopefully have heard of programmable privacy. And it's just basically this idea that privacy doesn't need to be binary, it doesn't need to be public or private, but rather there's this very large design space in between the two where users can choose maybe some components of the information is public and maybe only to some entities and maybe only under some conditions. And playing around with this is really something that we've been thinking about and that might solve a lot of the problems in mev and hopefully will. So before everyone goes into a very technical talk later on, I'll finish like a hand wavy, abstract conclusion. Which is to say that we can think of the Mev supply chain as a negotiation between these many different entities who are trying to go from these many different entities, some who can do the execution and some who want execution to be done according to their specification.
00:26:29.310 - 00:27:20.910, Speaker A: And what we've seen is an imbalance of power where some entities, for a variety of reasons, including the information they have, have been able to draw an advantage at the cost of other users. And so what we're trying to do is we're trying to provide the tools to users to enter this negotiation and get sort of the best possible outcomes for themselves. And these tools, we believe, are ways of expressing or choosing how the information is exposed so that they can get the best outcomes for themselves without other agents taking advantage of the information they've exposed. So I hope that made sense. I think it's Q and A now. I actually don't know if you guys have been listening to me for the last 20 minutes. I hope I haven't been speaking into nothingness.
00:27:22.870 - 00:27:56.010, Speaker C: Yeah, cool, thank you. Quintess. Yeah, we have been able to hear you. Anyone has a burning question? I'm mindful of the schedule. We only have two and a half hours, so we might only have time for one question. Yeah, go ahead. I can ask a question that's a bit spicy.
00:27:59.250 - 00:28:03.166, Speaker A: Has anyone looked into how would it.
00:28:03.188 - 00:28:05.520, Speaker C: Look like with privacy on and off?
00:28:06.770 - 00:28:55.146, Speaker A: Is this something that can be quantified in some way besides the general notion that we probably all understand that more privacy is better? I'd love for someone else to jump in here, but my understanding of this is that it's an open research problem and there are people working on actual implementations and so I guess we'll tell with experiments. But also one of the things we're working on internally and I think Phil will sort of touch on this in the next talk is how do we sort of theoretically understand the trade off between privacy or, like, the relationship between privacy and the sort of economic state of the outcome and also the trade offs?
00:28:55.178 - 00:28:57.440, Speaker C: Perhaps what you pay?
00:28:58.770 - 00:29:07.570, Speaker A: Yeah, I do think that there's a trade off, and I think that's what we'll hopefully touch on in the next talk. I mean, that's the title of the talk. Who knows?
00:29:10.790 - 00:29:16.840, Speaker C: OK, great. Fantastic. Thank you. Quintess, I guess. Phil, are you ready for your talk?
00:29:20.090 - 00:29:20.614, Speaker E: I am.
00:29:20.652 - 00:29:21.602, Speaker F: Can you see my slides?
00:29:21.666 - 00:29:23.606, Speaker C: Okay. Yep, we can.
00:29:23.788 - 00:29:38.938, Speaker G: All right. Amazing. So perfect segue. We're going to be talking about some open challenges and indeed trade offs in mev privacy. Hello, everyone. I am Phil. So all of this is let me minimize my little zoom here.
00:29:38.938 - 00:29:49.962, Speaker G: So all of this is kind of going to be in the backdrop of something you all may have heard of, which is something we announced recently at the last DevCon, which is the system we're building called Suave.
00:29:50.106 - 00:29:52.410, Speaker F: And this is kind of the next step for Flashbots.
00:29:52.490 - 00:29:55.186, Speaker G: So I'm going to talk for two minutes about Suave just to give you.
00:29:55.208 - 00:29:56.834, Speaker F: Some background in case you weren't present.
00:29:56.872 - 00:29:58.386, Speaker G: For that announcement, and then kind of.
00:29:58.408 - 00:30:00.450, Speaker F: Dive into privacy specifically.
00:30:00.870 - 00:30:43.390, Speaker G: So Swab is the next step for Flashbots. It stands for the single unifying auction for value expression. It's an Mevaware encrypted, aka private, with programmable privacy shout out Quintus mempool for users and wallets. It features progressive decentralization. So one of the goals here I'm going to be talking about is iterating towards decentralizing the current MEB boost market, as well as the Flashbots relay and other components kind of more than they are today. It can also provide a turnkey decentralized block builder for roll ups. So the aim is to kind of build the best mev ecosystem we can on ETH so that other domains and other chains can both interact with that, as well as kind of take some of the lessons for their own systems.
00:30:43.390 - 00:31:24.350, Speaker G: So to do this, we are creating kind of this fully decentralized block builder. This is the mission. We want to develop this in the open. So this is part of why the Roast series are kind of being restarted and pushed again, but not the only reason. And we want to be kind of 100% open and transparent about our R and D, where we're at today, where we're going, and have people come and comment and participate in the design, because there's a lot of questions we haven't answered yet. So this talk is going to be kind of about one of these big questions that I hope you all, as our community privacy aficionados and experts, can help us answer. The system is going to be ETH native.
00:31:24.350 - 00:32:11.266, Speaker G: It's going to have EVM kind of scripting that's going to be relevant in the rest of the talk. We're going to aim for optimal user execution, harnessing mev to give users kind of the cheapest possible price or the best outcome for any trades or other transactions they're doing. And this is again going to be one of the key goals. We're going to talk about privacy serving today. We're looking for kind of full compatibility with Flashbot's infra today so that searchers can continue searching and validators can continue validating with kind of a generalization, of course, to cross and MultiChain if needed. And this is really the key point of the design goal for this system, which is to maximize both the competition within the system and also the geographic diversity of the nodes in the system by creating a protocol that doesn't, let's say, overly advantage latency in mev extraction.
00:32:11.318 - 00:32:12.480, Speaker H: Or anything like that.
00:32:13.490 - 00:33:28.434, Speaker G: And the last two things are we want to enable open order flow. So this will be kind of a key part of privacy is how do you ensure open access to users transactions and kind of step away from the need to permission execution to certain searchers or protocols to get ideal mev outcomes. We want truly permissionless execution where people can send to any number of protocols and any number of actors can kind of optimize against these transactions in real time. And we want programmable privacy. So that's what I'm going to be talking about next. So these are some trillion dollar questions that I introduced at a talk I gave at a Columbia kind of event a few weeks ago. And we're going to be talking about here this first question, which is what is the privacy efficiency frontier in mev extraction? Basically, if you allow users to select much more rich decryption conditions and predicates at mev search time, which is as I'll describe what we mean when we say programmable privacy, how much info should they reveal? When should they reveal it? And what are the trade offs of their ability to internalize the value of this private information against the execution quality kind of of any options they participate in or anything like that? Other topics that may be relevant here include geographic diversity, censorship, resistance, how to escape SGX.
00:33:28.434 - 00:34:01.674, Speaker G: So we're going to be talking about one possible SGX solution, but of course we know the problems with SGX. Stay tuned for the spicy panel later, the feasibility of things like MPC and Fhe in these contexts, how this relates to the limits of minimizing mev and actually the act of minimizing mev itself. That's going to be kind of later in this talk and also meta mev on Swab. So how to use Swab mev to kind of drive the system itself. Okay, so that's all for Swab. Let's talk about privacy now, finally. So we're going to be talking about privacy in service of two concrete goals here separately.
00:34:01.674 - 00:34:33.450, Speaker G: The first concrete goal, as kind of Quintus talked about in the last presentation, is to continue to reduce the requirements for trust in the Flashbot system as it is today, to decentralize the role of Flashbots today and to remove kind of centralized choke points in the system and maintain the decentralized mev market we've built, prevent further centralization vertical integration, et cetera. The second thing we really want to use privacy for is to allow the user to internalize the value of their mev. So this is what Flashbots means when it says democratize.
00:34:34.910 - 00:34:35.942, Speaker F: Sorry, distribute.
00:34:36.006 - 00:34:37.318, Speaker G: I chose the wrong keyword.
00:34:37.414 - 00:34:37.962, Speaker F: My bad.
00:34:38.016 - 00:35:08.674, Speaker G: I was making these slides very early this morning. So this should be distribute, but we want users to be able to internalize the value of their MEB. And of course, there are other reasons you might want privacy alluding to some here, but I think we're going to kind of not talk about those in this specific presentation. Maybe we should have a separate roast on censorship, resistance, inclusion, robustness and things like that, if that's kind of of interest. All right, cool. We want privacy. We want programmable privacy.
00:35:08.674 - 00:36:22.160, Speaker G: What do we mean? What would be a useful abstraction for privacy? So this is a presentation I gave two years ago now about kind of the best privacy abstraction that we could use in decentralized building and what we want to build towards. So I'm going to give you kind of a thousand foot view, and then we'll zoom into the details of how this actually works in swap. So wouldn't it be great if we could create this thing I'm calling a proof of private transaction, which was basically an execution proof inside the EEP consensus rules that a certain mix of public and private transactions executed in a way that was consistent with a certain witness. Or here, I'm calling it a hatch of the proof. So what this would allow you to do is basically prove that executing some private and public transactions in a given state resulted in a certain outcome and kind of prove certain properties of this outcome without leaking what's in these private transactions. This is kind of a standard notion of basically programmable encryption. So then if we had this magical abstraction, what could we do? Well, instead of having a relay or a builder like we do today at Flashbots, we could have a whole network of nodes in between the validator here and the searcher trader user or whatever on the other end over here.
00:36:22.160 - 00:37:18.154, Speaker G: And the Flashbots relay, which currently kind of validates transactions for spam control and protects the privacy of bids and things like that in flight, as well as the rest of mev boost, would kind of almost cease to need to exist. The trust guarantees would be much more distributed, and we could build something more peer to peer than the Federated MEB boost system. You could imagine. Also multiple kind of private transaction proofs floating around this peer to peer network, as well as an ability to take two of these private transaction proofs and combine them into a new private transaction proof, which eventually kind of crystallizes into an ethereum block. So this would be the ideal way to use privacy to decentralize Flashbots today. Instead of sending the relay your bundle, you just create this proof about your bundle send it to this peer to peer network where it can be trustlessly permissionlessly without losing privacy combined with other bundles into eventually what becomes a block and this all kind of magically works. Hand wavy.
00:37:18.154 - 00:37:31.426, Speaker G: Hand wavy fully decentralized and we don't need the relayer builder today and we sidestep kind of a lot of the issues we're seeing in the mev boost market. So this is really what we want to build towards. This is the ideal abstraction, but how.
00:37:31.448 - 00:37:32.420, Speaker H: Do we get there?
00:37:33.990 - 00:38:10.814, Speaker G: So to get into that we kind of need to lay some technical groundwork to talk about Suave a little bit and this may be interesting to some people also who have kind of asked and been curious about Suave. This stuff is all going to kind of be part of a Swab spec that we're very actively developing and looking to roll out very soon. People were very angry at me for saying a timeline last time, so I won't say one but soon. TM so Swab is a stateful system, stateful distributed system. Essentially, you can consider basically Swab states as sequence of states through time. S. One s two s three.
00:38:10.814 - 00:38:51.174, Speaker G: And we can denote the current state by lowercase S and the set of all past valid Swab states as capital S. These are basically states that are confirmed by the Swab consensus algorithm. And transactions on this system are called bids. And bids basically represent preferences and preferences map future states of the world to utility functions to the bidder represented in basically computation. So what do these bids preferences transactions actually look like? Well, you basically have a program or smart contract on swap the same way kind of each transaction executes some code. This is the same idea. And it is also EVM.
00:38:51.174 - 00:40:02.894, Speaker G: As I said before, EVM compatible. Such that when you execute the bid in some future state s this should probably stay s prime to not be confusing, but this is a different s when you execute the bid in some future state, or in any state, really, you get this output where the bid or the program outputs kind of the value of that state in its model. So this B is kind of the value of reaching this state S or the amount that's going to be paid to the executor. And the bid also outputs an address where basically that address is the executor that executed the Swab transaction kind of computed dynamically gets a little tricky. So not expecting kind of this to be fully grasped right now all that really matters stateful system bids, EVM transactions, they're also Oracle contracts. So the way these bids are actually executed in the future if they do kind of come to fruition. So let's say I want to bid for an empty block in 1000 blocks, I can submit this bid and then by basically creating the transaction, but then the transaction will actually output a payment if the Oracle essentially tells it that the state of other domains.
00:40:02.894 - 00:40:33.390, Speaker G: Has transitions such that the payment should be made. So, here's some example. The Oracle can kind of be any flexible, smart contract Oracle. We've certainly seen a number of these on ETH and other systems. Any can be used here, but you'd have something like essentially, okay, block one on the chain. This is the block hash, here's a log hash, and here are the transaction hashes that are confirmed in this block body. And this actually having this Oracle plus this distributed system is already enough to decentralize flashbots bundling.
00:40:33.390 - 00:41:19.260, Speaker G: So, here are some example preferences you can state in this system. You can say, okay, if a transaction comes at position zero, so the top of a block pay the sender of position one some amount. So this assumes that if you have someone that can reliably kind of place transactions in blocks, they can kind of steganographically tag their doing so. And as long as your transaction here that you want zero X Cafe ends up being mined at position zero, that person gets to kind of trustlessly claim this three E bid against the Oracles. Another example is you can have kind of a list of transactions to come in a specific order. So this is what's known as a bundle. Now you can say Xerox Cafe must come before transaction zero x dead beef that must come before transaction zero X.
00:41:19.260 - 00:42:14.714, Speaker G: And let's say that represents a sandwich and that's where three eat to you. So that would be the B. You would pay essentially the following sender steganographically tagged again some amount for landing this sandwich for you. You can also use this to bid for empty blocks. You can use this to bid for certain execution logs. So you can just say, look, this is the state I want, create a log transition to the state I want, I'll pay you for it, and kind of fully generalize this to more bridge style transactions as well. So how do we decentralize flashbots using this? Well, we basically create this relay, which sorry, not create this relay, we create a swab this system where searchers can submit these bids to, and we allow other actors just on the network mev bots, other validators, whatever it might be, that we call executors, which may or may not be l one validators.
00:42:14.714 - 00:43:01.150, Speaker G: Certainly it's a more efficient optimization if l one validators natively plug in here, but also you could have PGO actors or other such actors kind of competing to fulfill this execution end of the MEB market. So this allows us again to kind of bypass the relay. I'm going to skip over some details here, essentially what this slide is saying. There's two cases you can have native plugins for this where validators directly listen to bids and kind of automatically switch over bids that they're able to parse and understand and control. And other actors kind of translate these bids into bids that validators can control. Or you can have validators that totally don't use Swab. And the actual execution happens over PGAs or some other kind of third party channel.
00:43:01.150 - 00:43:42.842, Speaker G: We've seen both in the mev market in practice. Great. So now let's switch gears a little bit and talk about really the meat of the privacy problem, which is not just to provide this proof of private transaction that allows us to decentralize the relay, that allows us to decentralize the builder into a peer to peer network, that there's more value to privacy that still hasn't been unlocked in the world yet. And that comes in in when you really kind of dissect the mev marketplace and the trends in the mev marketplace and where they're going in the future. So where is mev going? So mev market has two sides. There's the user and the validator. The user or trader, whatever else searchers even can fall in the middle or can fall on either side.
00:43:42.842 - 00:44:09.134, Speaker G: Here wants to make transactions. They want to purchase block space. They're a consumer of blockspace. Validators want to get paid as much as possible for providing this block space and engage in kind of a business doing so. And the crux of the mev market is essentially interfacing these two parties using mev as the utility optimization function. So users want to minimize the amount of mev they release. They want to minimize their payments.
00:44:09.134 - 00:44:46.938, Speaker G: Validators want to maximize the amount of mev they extract. They want to maximize their kind of received bids. So how do we allow the user to internalize the value of their mev or private information? And again, this should say distribute, not democratize. Well, there's two possibilities. The first one is we can use what we've seen before in various order flow auctions that have been proposed, that are executing various other kind of domains other than ETH are experimenting with these. You can use what's called basically permissioned execution. So you can auction off the right to execute your transaction to a specific protocol, to a specific searcher, to a specific set of parties.
00:44:46.938 - 00:45:29.478, Speaker G: You can sell futures on your protocol. That's essentially the same thing. I also call this an information auction. The advantage here is you kind of get a clear payment and a clear rebate up front. The disadvantage here is you're actually disincentivizing competition on executing your transaction, right? So like, you have to decide one party in advance, that party can't efficiently price your transaction. And in the real time mev optimization, you're losing the ability for other actors to economically provide input into what is your best execution, what is the best optimization of preferences. Here, on the other hand, you have programmable privacy, which basically lets users fine tune how and when they release their information to various parties and leverage that in negotiations for MEB.
00:45:29.478 - 00:46:14.618, Speaker G: So we strongly believe this is the better route of these two for scalability reasons, because it allows for more permissionless extraction, and because it doesn't lead to a PFOP style market, closed permissioned order flow or the need to kind of trust certain searchers or the need to kind of forfeit additional rent between when kind of the auction happens and the transaction is executed. So for many reasons, we believe this is the best option. Maybe we'll have a separate roast where we go deep into programmable privacy and why this is the best option. Here we have basically a more formal description of a bid in Swab, which is going to come from our documentation. So stay tuned for this. Please don't read this whole thing. Now you'll just get a little bit confused because we're kind of limited on time.
00:46:14.618 - 00:46:58.150, Speaker G: But what matters here is basically in this bid there's two things that users can provide an execution predicate this P of S, or three things, sorry, an encryption predicate Q of S and a set of peakers signal. So this is kind of the control knobs on our programmable privacy inside Swab itself. It allows a user to provide a set of transactions and say, okay, this is when this transaction will be decrypted. When this condition on the world state against all these oracles are met, this transaction can be decrypted. And this is when this transaction can be executed only if these conditions on state are met. So you maybe can say, okay, I only want my transaction to execute if it's first in a block, otherwise it should fail. You can say, okay, I want to reveal certain data, but only under certain world state transitions.
00:46:58.150 - 00:48:09.578, Speaker G: So what does this allow you to do? It allows you to partially decrypt transactions, to allow searchers to execute them, but also keep private various aspects of your economic preferences. Now this gets really powerful when you combine it with this concept that we call a fee escalator internally, which is basically signing transactions that increase mev subsidies over time. So you can think of this as like, let's say, users increasing a gas price over time, having a VDF based mev release function or anything like that. So in this world you can actually start with a negative mev subsidy where your transaction basically requires some searcher to fund your account in order to be executed. And you can slowly increase this mev subsidy over time to try to find kind of the optimal supply demand point where your transaction becomes profitable to mine. Now, if you do this and you keep this curve private, and you keep information about your transaction private, but you allow searchers to kind of brute force optimize this against other bundles. Using the type of merging we talked about in the proofs of private transactions earlier, you can actually back out the guarantee that a user gets optimal mev execution while having permissionless real time access to their order flow.
00:48:09.578 - 00:49:00.298, Speaker G: So without the need to permission, who is going to execute their transaction? And this is super powerful. It only relies on kind of a competitiveness assumption around the searchers and validators participating in this market. So this is what we consider the core of kind of programmable privacy and why we care about it. Okay, now, the last thing I'm going to talk about is kind of the trade off here, and this is the kind of trillion dollar mev question, how much information to leak when you make a transaction as a user. So there's the most extreme case of privacy, which is that searchers, Validators, et cetera, learn nothing until a block is signed and confirmed. You can only possibly reorder merge Encrypted Blobs, but maybe even not do that, and that you learn no information theoretic output on this data. Of course, in this most extreme world, it's very hard to mev optimize these transactions and get optimal execution for the user against mev.
00:49:00.298 - 00:49:28.638, Speaker G: Kind of find the right point on this curve. The least extreme is you send it to the mempool. You have no privacy. But there are lots of middle grounds here. So if you have a uniswap transaction, maybe you can reveal that this transaction uses the uniswap contract. You can reveal what pools are being traded. You can reveal the direction of a trade or something like that, which will help searchers, find, and computationally optimize your Mev without leaking the valuable trade data that's allowing you to find this optimal trade off point in our kind of analysis.
00:49:28.638 - 00:49:53.790, Speaker G: So this is the trillion dollar question here. We're between a rock and a hard place between inefficient mev with full privacy and mempool, which provides no leverage for users. So we really need to optimize this better and find a sane middle ground in the context of these programmable abstracts we've created. We look forward to your help here. Come join us on our forum and help us build this. I'm out of time. So sorry I had to rush through that a little, but hopefully it was interesting and illuminating.
00:49:53.790 - 00:49:57.140, Speaker G: Please reach out if you have any other questions. All right, thanks, everyone.
00:50:02.690 - 00:50:40.902, Speaker C: Thank you, Phil. In the next talk, which is my talk, I guess I'm going to push back a little bit on this trade off space. I think we can have our cake and eat it too. I guess the one kind of spicy question that I have I'm happy to open it up is on the S in SUAV, the single, is it necessary for Flashbots to want to take over the Encrypted mempool space? Can there be multiple competing mempools, or does it have to be like a single unified Encrypted mempool?
00:50:41.046 - 00:51:13.922, Speaker G: So I think there should be multiple mempools. I think the interesting question is, like, where to optimize the boundary. The S is a little bit of a troll, so I appreciate you for picking up on it. I think what it means more is the intent to kind of provide and maximally decentralize all possible features of an Encrypted mempool in the long term, not necessarily that there won't be computing systems. There definitely will be. In fact, it will be competing with the centralized systems that exist in the mev boost marketplace today on day one. So already on day one, it won't be the single auction and it'll need to kind of reason about how to interface with these systems.
00:51:13.922 - 00:52:07.798, Speaker G: So yes, I believe there's space for many encrypted mem pools. But we would like to try to hit the optimum trade off point in our opinion on what is the best option if you had to choose one. That being said, there are also some network effects and advantages of having one option, specifically when it comes to privacy. So the more you can get within privacy zones that can be optimized against each other for mev. So again, stepping down from this full privacy and having this mev optimizable privacy, I believe the better execution the user gets. So like, if I can also optimize my transaction without revealing its information against many other trades and liquidity provisions and arbitrages on uniswap, I should be able to get a better price than if that transaction is not optimized with an awareness of the semantics of mev in mind. So there's like a network effect of privacy that having more people in a single zone is better for those people.
00:52:07.798 - 00:52:15.226, Speaker G: And also same with crosschain mev, for validators cross chain. You get super linear rewards in the cross chain kind of buy in you.
00:52:15.248 - 00:52:16.614, Speaker F: Have to any single auction.
00:52:16.742 - 00:52:22.266, Speaker G: So for those reasons, there is kind of some pressure there. We also truly don't want to be.
00:52:22.288 - 00:52:24.026, Speaker F: The single system for obvious reasons, because.
00:52:24.048 - 00:52:30.926, Speaker G: Then if things break, everyone's all salty and stuff like that. Certainly we've seen that before. So it's a little bit more of.
00:52:30.948 - 00:52:32.794, Speaker F: A troll than like a serious product goal.
00:52:32.842 - 00:52:34.960, Speaker G: But hopefully that answers the question.
00:52:36.790 - 00:52:41.540, Speaker C: Thank you, Phil. Any other question for Phil? We have time for one more question.
00:52:52.090 - 00:52:53.800, Speaker H: All right, it was super clear.
00:52:56.410 - 00:54:19.390, Speaker C: Okay, great. So I guess we're happy to embark on part two, how do we provide privacy? And the next talk by me, we will be basically trying to give an overview of the design space for encrypted mempools. Okay, so the talk will be in three parts. First, I'll describe just the basics of what is an encrypted mempool and the design space. I'll talk about the motivation in part two and then kind of the fun part. Part three, the more technical part where we talk about metadata because it's all well and good to encrypt the payload of a transaction, but really all the metadata that comes with it also needs to be encrypted. Okay, so what is the simple framework of an encrypted mempool? Really, the key idea is that you want to encrypt your transaction off chain before it goes on chain, and you want to have some sort of commitment to the inclusion, to the ordering of that encrypted transaction before you decrypt.
00:54:19.390 - 00:55:21.250, Speaker C: So you have encrypt, commit, decrypt and then execute. And one of the questions you might ask is, does this kind of add latency to the whole user experience? And the answer is not necessarily. You can do all these three steps in one slot, all in one go, behind the scenes. So one of the important things that you need for the Encrypted mempool is some sort of encryption scheme that guarantees that the ciphertext will eventually be decrypted. Like commit reveal doesn't work as quintus alluded to. And there's basically five different families of encryption that I've identified with this property. So you can have basically private end to end encryption, where you have a centralized entity that's maintaining this encrypted mempool.
00:55:21.250 - 00:56:08.258, Speaker C: So that would be Flashbot protect. You can have enclaved based encryption where you're trusting the integrity of SGX. There's Threshold based encryption, which seems to be the most popular approach with Arbitrum, Shutter and various others. There's delay encryption that Starquare is looking into. And then there's witness encryption. Witness encryption, if you're not familiar with it, it's a very, very powerful primitive which allows you to have Arbitrarily complex and flexible decryption predicates. So you could say decrypt if something happens.
00:56:08.258 - 00:56:57.086, Speaker C: Like for example, you can have a snock of an arbitrary statement be a decryption. So one example could be if the chain has finalized, the chain that includes the encrypted transaction has finalized, then decrypt. And so you can think of witness encryption as being a generalization of all these other decryption mechanisms. Now, in terms of readiness, we already have things like Flashbot protect, and I believe that the technology is fundamentally ready. SGX is there to have things like enclave based encrypted mempools. And Threshold encryption is also pretty much there delay encryption. One of the hard bits there is that you need a VDF.
00:56:57.086 - 00:58:30.110, Speaker C: ASIC we actually, by we, I mean the firm foundation and Protocol Labs actually went through the effort of designing an ASIC. And we have samples, so we've manufactured samples, and they're going through the process of being packaged right now, and they'll be tested in a few weeks. And witness encryption is basically this moon map kind of piece of cryptography, which is not at all ready right now. Now, one of the important things that I want to highlight here, and this is where I kind of disagree a little bit with Phil and Quintus, is that you can have perfect encryption basically as a user, you can leak no information, but you can still be not blind to user outcomes. So basically, the encryption system itself can be aware of the transactions that it's manipulating and it doesn't have to randomly include these ciphertexts or blindly include them on chain. It can actually kind of look under the COVID of the encryption in such a way that the user doesn't have to leak any information. So that's called homomorphism, where basically you're given ciphertexts encryptions of messages m one and M two, and you can compute functions on these functions on these encryption ciphertexts and it's actually trivial to do homomorphisms in the trusted context.
00:58:30.110 - 00:59:59.274, Speaker C: Right? So if you have an encrypted mempool like Flashbot protect, they get to decrypt privately the transactions and they can run the functions on that. And it's the same thing for SGX, right? SGX, you have the in flight encryption between the user and the enclave, but then the enclave will have plaintext access to the message. But then as you become more and more sophisticated in your encryption mechanism, the homomorphisms become more and more complicated. Okay, so motivation on why do we want encrypted mempools? I think there's basically two reasons, one is front running and the other one is censorship. So front running is easy is this idea that if you can't see the payload of a transaction and you can't see the metadata, then you can't kind of meaningfully front run transactions. So for example a sandwich, if you want to sandwich a transaction, you need to know which pair is being hit, you need to know that it is a trade in the first place, you need to know the size of the transaction, et cetera, et cetera. But kind of a related aspect is centralization.
00:59:59.274 - 01:01:48.426, Speaker C: So one of the bad things of Mev is this centralization force and we can ask ourselves why is there centralization? And basically there's centralization because some sophisticated entities can have an edge in in producing blocks and being part of this Mev pipeline. And if we can remove sandwiches as an edge, then basically we reduce the surface area to be sophisticated and we reduce the surface area for centralization. So in this slide, basically I distinguish multiple types of mev. There's kind of the positive Mev which arbitrage and liquidations, basically things that the designers of the applications actually want Mev extraction to happen because it leads to outcomes for the decentralized application, like prices being arbitraged, but there's the bad stuff which is moving. So it's kind of a great coincidence that encryption kind of removes the bad stuff and keeps the good stuff and also helps with centralization. Now the other thing I want to highlight is around censorship. So one of the kind of counterarguments that you might have around encrypted mempools helping with censorship is you could say that some entities in this Mev pipeline will say I will just not include any encrypted transactions, or at least I won't include them unless you tell me that they don't touch certain addresses.
01:01:48.426 - 01:03:08.090, Speaker C: So you could imagine for example, a block builder saying I will only include your encrypted transaction if there's an accompanying SNOC saying that it's OFAC compliant. And one of the things that we want to try and do is basically make encryption the default in such a way that if you want to have this very naive strategy of saying I will not include a certain type of transactions, then you need to not include all the encrypted transactions. And the reason here is that if you include an encrypted transaction, you don't know whether or not it passes your filters. So you have to remove everything. And so you have a massive handicap as a sensoring builder. The only thing that you can see in the clear and you can really have an edge on is these arbitrage transactions. But you lose basically the tips for transactions.
01:03:08.090 - 01:04:15.550, Speaker C: Okay, so now the final part on the metadata. So one of the things to realize is that when you make a transaction, there's all sorts of metadata that is being leaked. So there's IP address of the sender, there's the size of the transaction, there's who the sender is, the tip, the amount that's being paid, there's the gas price for the tip, there's the gas limit, there's the nonce, there's the signature. And there's even more subtle things like the timestamp, the moment in time at which you post a transaction. And my claim, which is maybe a rather strong claim, is that you can prevent all leakage. You can basically have no privacy leakage whatsoever for any of these things. And really it's a matter of going through them one by one and for each trying to find an appropriate solution to not leak the piece of metadata.
01:04:15.550 - 01:05:05.758, Speaker C: So for IP address we have Tor. That's kind of an easy one for the signature. Well, one of the complications here is that usually signatures don't really leak information. There are some schemes that do leak information, but here it's more about transaction validity. So you want to somehow convince that your transaction is valid, your encrypted transaction is valid to the builder who will include it in the block. And one of the things that we can do here is basically use a snark. And a snark has several parts to it.
01:05:05.758 - 01:06:33.978, Speaker C: So it has a public input, it has a private witness and it has a statement that's being proved in zero knowledge. And so for the signature, what is the public input? Basically the user is saying here's my transaction ciphertext, that's part of the public input. And here is the state route of the Ethereum blockchain, which is also public. And then what the user wants to do is try and convince them that the encrypted ciphertext has a valid signature. And so what they'll do is that what does it mean to verify a signature? It means that you go fetch the associated pub key, you validate it against the state route with a merkel proof and then you prove in zero knowledge within your snark that your merkel proof is valid and that the signature is valid. And then basically you can do the same thing for every single piece of metadata. So for the gas payment, it's a very similar thing, right? Every account on Ethereum has a balance and you want to go authenticate this balance against the state route and prove that the merkel proof is valid and then what's specific to the balance is basically you want to prove an inequality.
01:06:33.978 - 01:07:49.830, Speaker C: You want to show that the sender balance is sufficient to pay for the gas cost, for example, the full gas limit given the base gas price. Again, same thing for the nonce, right? Like every account not only has a pub key associated and the balance, but it also has a nonce. Same story here and there's a little subtlety here around the replay tag. So one of the reasons that we have nonces is basically as an anti dos mechanism. We basically don't want one address to be spamming millions of transactions. We only want basically one address to be able to broadcast only one transaction. And the way we do that is with the nonce, we basically will only broadcast in the peer to peer network a single transaction for a given address and a given nonce per unit of time, for example.
01:07:49.830 - 01:08:55.514, Speaker C: So you can only increase your gas price, for example, once every second. And that provides an anti DDoS mechanism and you can get the exact same anti DDoS mechanism with a so called replay tag. And one way to do it is to basically have an encrypted nonce in a way where basically you hash the nonce and the private key. And so that's going to be a unique piece of information, a tag for your address and nonce tuple in such a way that if you were to try and spam the peer to peer network, then people would realize that the same replay tag is coming over and over again. Great. Now, one of the kind of the cool things is thinking about obfuscating the size of the transaction. So one idea here is to pad to the closest power of two.
01:08:55.514 - 01:09:41.270, Speaker C: You have transactions of various sizes and just by looking at the size you might think, okay, this is a unisoft transaction and this is a transfer, for example, because it's smaller. And so what if we just pad to the closest power of two? And I think this is a great solution that gets you 80% of the way there. But there's a couple kind of deficiencies of this solution. The first one is that you get imperfect packing. And the reason is that you have to pay for these padding bytes, these zero bytes that you have. You have to put them on chain and you have to pay for the data availability. So there's these little white squares that you have to pay for, which is a bit suboptimal.
01:09:41.270 - 01:10:51.150, Speaker C: And the other thing is that you have imperfect privacy because even though you're padding to the closest power of two, there's still going to be different transaction sizes. And so one of the suggested solutions is basically to use homomorphism, something which is trivial to do with SGX and harder to do with other types of encrypted MEMP pools. But let's see how homomorphism can help us. Well, basically what we're going to do is we're going to apply a function, which is the tight packing function. The function just takes the plain text and just packs them as close as possible and then outputs a full block of the maximum size. So if the maximum size of your block is, let's say, 100 KB, which corresponds to, I don't know, a gas limit of 30 minutes, well, you're just going to pack everything within that. And one of the nice things here is that you get both the optimal packing and the optimal privacy.
01:10:51.150 - 01:11:04.420, Speaker C: Now I don't have much time so I'm just going to skip ahead. But basically you can do the same thing when you're packing. You can also take into account.
01:11:06.390 - 01:11:06.658, Speaker A: The.
01:11:06.664 - 01:12:15.158, Speaker C: Gas price and you can do prioritization based on that or based on access lists. And I guess one of the things that I only realized recently is that we might actually be able to even hide something a little counterintuitive, which is the timestamp of the transaction. One might think that when you broadcast a transaction, it's kind of fundamental to leak the timestamp, but maybe it's not. And basically the idea here is that the peer to peer gossip network can handle a maximum number of transactions. Let's say it can handle 1000 transactions per second being gossiped around. And so what we can do is that if at any point in time we're under this maximum capacity for the peer to peer network, we can broadcast dummy transactions that look exactly like real transactions because they're encrypted. You can't distinguish them, but you have this kind of this magic homomorphic function that operates on the plain text that is able to filter out the dummy transactions.
01:12:15.158 - 01:12:41.060, Speaker C: So as an observer of the mempool, you're just observing a constantly saturated mempool that's processing 1000 transactions a second. But at the end of the day, when you produce a block, all these dummy transactions are filtered out so you don't have to leak information on when users are broadcasting their transactions. And that's it. Happy to take questions.
01:12:50.710 - 01:13:05.290, Speaker H: Hey, could I jump in and ask you to say more about the Homomorphic encryption plan you had in mind there? The main question I had is who is it that has the secret key for the homomorphic encryption in your setup?
01:13:05.790 - 01:13:48.710, Speaker C: Okay, great question. So here one thing you could do. For example, is you could give every validator and there's about half a million of those, but let's say there's a million validators, which I expect will happen. Each validator is allowed to make one dummy transaction every epoch, let's say. And so the validators would be observing the mempool and they would be signing with the validator private key and they would be able to set the flag, the dummy flag to true. And basically the Snark that they would publish along with the encrypted ciphertext would say, I'm a validator and so I'm allowed to produce these dummy transactions.
01:13:50.970 - 01:13:51.286, Speaker G: And.
01:13:51.308 - 01:14:15.310, Speaker C: I know that they will get filtered out because. The function that operates on the plain text can just read the flag, see that it's a dummy transaction, and then filter it out. So basically we're making use of the validator honest kind of majority. Like if we have sufficiently many honest validators producing these dummy transactions, then the mempool just looks like white noise.
01:14:15.750 - 01:14:44.940, Speaker H: Okay, so it's a threshold homomorphic encryption that you have in mind where the secret key for the encryption is like a quorum threshold thing held by the validator nodes. And then that means that the majority of the validator nodes have the ability to decrypt every transaction. But if they follow the rules, then they will only decrypt the added up homomorphic operation transaction after the fact. Is that the right way to think of it?
01:14:46.910 - 01:15:33.254, Speaker C: So, not quite. I guess there's two separate questions that you can ask. So I guess the question that you're really asking is what is the flavor of homomorphism? And it turns out the answer is that it doesn't matter. It could be anything. It could be enclave SGX based, it could be threshold based, it could be delay encryption, it could be witness. So each of these five flavors of encryption comes in the vanilla plane mode or it comes in the advanced kind of homomorphic mode. So you can think of it as a five by two matrix where you have well, this is exactly it a five by two matrix where basically some of these are ready and some of these are not ready for homophobic encryption.
01:15:33.254 - 01:16:21.634, Speaker C: So my claim, for example, is that let's say you have an SGX based solution you can trivially do these homomorphisms. Now, the question that I was answering previously was around kind of who's feeding these dummy transactions to the encrypted mempool? And here is the validators. But yeah, the validators don't have to participate in the decryption process at all. And if you take something like delay encryption, then really there's no party to trust. You're just trusting physics here. You're trusting intel with the enclave here. You're trusting flashbots, maybe for flashbots protect here, trusting a committee.
01:16:21.634 - 01:17:14.860, Speaker C: But here with delay encryption, you don't have to trust anyone. So just to make it a little bit more concrete, you have 1000 transactions a second that are coming in and they have the property that in 10 seconds they are all automatically decrypt. So that's the delay part. But they also have, in addition, a homomorphism property where you can take these transactions and kind of do operations on them in such a way that you go actually build the block while you're going through the process of decrypting them with the sequential computation. I think we need to move on, unless there's another kind of burning question.
01:17:19.150 - 01:18:02.300, Speaker B: Sorry, I raised my ask. I've been wanting to ask this since I saw your slides from the Columbia presentation. So on which dimension or which dimensions do you think are actually meaningful when we evaluate privacy solutions in the context of mev mitigation or MEB solutions. You labeled, I think, one of the axes as Sophistication and multiple other dimensions. But I guess can you sum it up for us? Technical properties economics? How do you think about this?
01:18:04.030 - 01:18:37.678, Speaker C: Right, I would take a Pragmatic approach and basically, exactly as you said, just follow the Sophistication frontier. So just do whatever we can do. Today. We've started with flashbot protect. I think it's an interesting start, but it has obvious downsides because it's controlled by one entity. I think the next obvious thing is actually SGX, and we have a whole panel to discuss that. I think SGX is ready to be deployed in production.
01:18:37.678 - 01:19:27.380, Speaker C: I think the next move after that is threshold encryption. Now, one of the reasons why I kind of put soon for homomorphic threshold encryption is because of basically Fhe. So you can take an Fhe scheme and you can just thresholdize it by splitting the private key, basically. Now one might say, okay, Fhe is just still years away, and that might be true, but it turns out that for very specific use cases, fhe might be perfectly fine. And the one thing that I'm especially kind of excited about is this idea of looking at access lists. So I have a little.
01:19:30.250 - 01:19:31.400, Speaker H: Where is it?
01:19:35.370 - 01:20:46.880, Speaker C: Yeah, so here I have this optional access list comment which basically says each transaction can come with an encrypted access list which will be readable in plain text by the homomorphic decryption mechanism. And what you can do is you can try and just pack your transactions in such a way that you have disjoint access lists. And it might turn out that this is kind of good enough in practice, you don't have to run the whole EVM within Fhe, you only have to compare access lists. And it turns out that comparing access lists is a so called low depth circuit. So when you're designing these circuits, a little bit like SNOX, you want to make sure that they're small. But for Fhe specifically, you want them to be low depth. And you can do that for access list comparison, which might mean that Fhe will be ready for the purpose of building optimal enough blocks sooner than people might expect.
01:20:46.880 - 01:21:37.920, Speaker C: And then if we talk about the long term, are we going to have an encrypted mempool within the layer one ethereum? And I think this will only happen if we have delay encryption, because that's the one thing that's really trustless. You're not relying on the committee. We've been trying to get rid of committees. Obviously the first two are not applicable for layer one ethereum because you're trusting companies. But yeah, delay encryption is the thing that could be enshrined in layer one. But I think that we're talking maybe half a decade away before things are fully mature. Andrew, I think you're next.
01:21:37.920 - 01:21:43.310, Speaker C: T smart contracts, pitfalls and best practices.
01:21:44.050 - 01:21:54.420, Speaker H: All right, sure. Let me turn on the share. Okay, all good?
01:21:55.510 - 01:21:57.300, Speaker C: Yeah, we can see you.
01:21:58.950 - 01:22:00.694, Speaker H: All right, let's go for it.
01:22:00.892 - 01:22:01.302, Speaker G: Cool.
01:22:01.356 - 01:22:39.774, Speaker H: Thank you for having me. This is a really cool discussion. I'm going to talk about Tea based smart contracts. My viewpoint here is a little bit different than I finally understand now what this point of suave was, how you're viewing Flashbots SGX as a way of having an encrypted mempool to do the mev. But this is still going to then produce bundles of blocks that get published on Ethereum in plain text when they're finally committed. The perspective I'm coming from is how to make privacy preserving smart contracts. So those who don't know me, I'm from IC Three and a researcher at UIUC, and I work with Zcash Foundation.
01:22:39.774 - 01:23:18.720, Speaker H: I'm also starting a new venture called Honey Badger Cooperation Labs. And something we're doing is building a zero knowledge credit network application on top of Te based smart contracts. I'm putting out that there just so that, you know, off the bat, you're not trying to guess where I end up at the end of this. I'm an SGX and Tee optimist, but you'll see the nuances and what it takes to get there. Even a little more background on the perspective that I come from. My research directions for the past decade have all been about privacy and functionality added to smart contract programming. Smart contract programming is what I care the most about.
01:23:18.720 - 01:23:54.330, Speaker H: But I've kind of followed this progression of doing everything we can with the simplest technologies, like just the plain text world just commit and reveal and then zero knowledge proofs. I viewed this as, like, progressing down a more and more complicated stack. And of course, what's been so interesting in the past few years, and it's still booming now, is just how pervasive zero knowledge proofs are through the developers Mindset zero knowledge proof tools. Everyone's working on it. All the big brains are doing zero knowledge work improvements. It's kind of diffused through the developer mindset. Smart contracts know that they're there.
01:23:54.330 - 01:24:38.614, Speaker H: What I've been working on, though, for the past several years, and I'm basically all focusing on now, are applications that need a more complicated platform for which the zero knowledge proofs and commitments stack are not enough. And for those you need some form of threshold assumption or multiparty computation. Those are the same thing to me. Or you need trusted hardware enclaves, or possibly both. And really my best frame of reference is the Akitan research paper from 2018. I had a small role on that. This was mainly the work of Fan and Raymond and a bunch of other authors, and this paper is the basis for the Oasis Project, although ideas from here relate to a whole bunch of the other projects too.
01:24:38.614 - 01:25:49.360, Speaker H: So I'll kind of make some references to that as well. I'll say just a little bit because this is kind of clear from some of the talks that have come before and I think Henry has a good way of explaining this I'll mention and maybe it'll come back later. So I want to get into the weeds a little bit about the details of SGX smart contracts, but I do think that there's a missing point to smart contract developers where maybe some people get this, some don't, but the line isn't so clear. When is zero knowledge proofs appropriate for your application versus when do you need to make the jump to either enclaves or this MPC threshold? The motivating example that I have for this is the issue of residual bids. I think you could call this something like rev it's like more than multiplock mev, but it is kind of of that flavor you can build with commit and reveal an auction where at the end of the auction you know what the winning price was. But there's a lot of people that didn't win the auction and whatever their bids are that basically is forecasting their unmet demand that might be a good predictor of their bidding strategies in the future. So maybe the minimal information disclosure from an auction is just the winning price.
01:25:49.360 - 01:26:56.482, Speaker H: If you build a commit and reveal auction, then you're also disclosing these bids that were not met and that is strategic information being leaked. And no way that you build a smart contract for fair ordering or anti mev techniques is going to touch this issue at all. Because it's not even about fair versus causal ordering, because later bids may have depended on the previous bids inherently, but still this unmet demand is leaking to someone like to a manager or an aggregator. If you use a zero knowledge proof based roll up to make this kind of application and hide this issue of residual bids, you have to build your application, your auction application using MPC or some threshold encryption or Tees. And in general, I have a bunch of other ways of making this point go to this one. So in general, I view this as like a framework where you maybe use the simplest tools that you can only move your way up to enclaves and multi party computation if you really need to. But from the viewpoint of prototyping, it's really the other way.
01:26:56.482 - 01:27:54.630, Speaker H: Once you get the idea of how you can do smart contract programming on Tes, it gives you so much more flexibility to define your privacy and disclosure policies that I can't even imagine going back to being stuck programming in the framework that doesn't provide that kind of a fine grained control. I think that this point kind of needs better explaining to where smart contract developers really see where that limit is. I think that the way that it's explained in the Penumbra protocol is pretty clear. I think I'll move on though. I have kind of like a spicy comparison table that places the Te based contracts what they're capable of, along with all of the other alternatives a couple of these are worth going into describing, but maybe only in the panel or if I get questions on it. I want to really move on to basically talking about where we're at with development of Te based smart contracts and the kind of really palpable thing is everyone's concerned about SGX attacks. We'll talk a little bit about that in a moment.
01:27:54.630 - 01:29:00.870, Speaker H: That's a legitimate concern, of course, but my view is that we have swung kind of the other way. It's like humorous how more people know that SGX is bad than they know any other details of it. And so even though this kind of like developer discourse that you see between consensus protocols, variants of proof of stake and all of that, and even now the zero knowledge proofs, really detailed technical discussions that are carried out throughout our developer ecosystem for SGX, it's not at all. Yet we're basically still just scratching the surface of even repeating mistakes that we already know how to deal with. From my perspective, a bunch of mitigations and good ideas were already presented in that 2018 Akitan paper and they just aren't yet even have made it to implementation. And even the onlookers who are trying to watch these projects aren't really spotting the critical features that are missing. So my hope is really to basically advance this developer discussion so we understand some of the details of what it means to have an SGX design, not just getting lost on kind of the high level trust model of SGX.
01:29:00.870 - 01:29:48.140, Speaker H: So to start with, I'm going to talk at the kind of high level view of what the Te based smart contracts are about. And this is meant to be kind of broad and vague such that it captures kind of all of know. It doesn't have exactly the details and there are differences in details from them. But this should give you the idea. In a nutshell, smart contract pee just means you take the contract execution and that takes place in these secure SGX enclaves. Practically what this means is that there's some secret key material that never leaves the enclaves, but there's a public key that you can use to send encrypted messages to the enclaves. So if you want to make a transaction in a Te based smart contract system, you send a transaction encrypted under the public key that corresponds to the secret key that only enclaves have.
01:29:48.140 - 01:30:19.640, Speaker H: Just the enclave kind of exists on the processor. It doesn't have that much memory available. So practically there's an untrusted storage that's sitting next to the enclave and the enclave interacts to get and set values to this untrusted database on the side. And so this untrusted database on the side. Well, the point of it is to be an encrypted database. So all the keys in the key value store are encrypted, all the values in the encrypted value store are encrypted. That's the basic idea.
01:30:19.640 - 01:31:00.126, Speaker H: Besides just sending encrypted transactions, you need some way to get some users are authorized to access their own account balance. For example, some outputs of contracts are published for everyone to see. So there's either events that get sent to you encrypted under your own address as an encryption public key, or you make a query directly with some interaction. Either way, what you get back is the response from that query that would also be encrypted under your address. That's the basic idea. I guess the last component that shows up at this high level is you also need some way of adding new nodes to the network and tolerating nodes that crash. So it can't just be there's one central enclave node.
01:31:00.126 - 01:31:49.890, Speaker H: You need a network of enclave nodes. They have to have some mechanism that the new enclaves nodes that join those enclaves can get access to the secret key by some mechanism. Okay, so that's the very high level view and that's really the only high level view of a diagram of this that we'll get to. But what I'll talk about kind of next on Pitfalls pokes a little bit below this and I'll come back and refer to this. Before getting to those, I'll just point out a couple of details about what it is that this is the blockchain platform interface described, but this is built on top of what the SGX primitives themselves give you. So understanding these two views is really what you need to have in mind in order to start picking apart issues. So there is the enclave.
01:31:49.890 - 01:32:28.290, Speaker H: The enclave has not the entire system memory available to it, but what it does is it can access more memory. The processor has like at most 100 megabytes of memory on chip. To do more than that you need to access Ram. SGX has like a Ram handling system, so it'll do virtual memory with pages, but all of the data on the pages are encrypted. There's also integrity checks that are sort of built in by SGX, so your enclave programs look like they have a big virtual address space. You interact with an enclave by making e calls. These go from the Untrusted operating system into the enclave and run some programs.
01:32:28.290 - 01:33:15.766, Speaker H: So for example, you might have an e call for processing a block of encrypted transactions. You typically will have to have an e call that starts up a new node by generating keys to communicate with just that node and begin on bootstrapping and getting access to other key material from the network as a whole. In order to e calls can't just generally be processed on their own. They need to request further services from the Untrusted operating system host to access a key value store, for example. So those are done through O calls, those are calls out to the Untrusted operating system. That's typically how you interface with the disk from an enclave. The last two concepts that it's useful to know are that the memory is lost if the process restarts.
01:33:15.766 - 01:34:10.990, Speaker H: Like, there's no way to load the memory from a prior process if the enclave process crashes. So for persistence, even just on one node restarting, you use a thing called sealed files. These have like CPU specific keys, and basically you can write to the file, store some secret data there, you can read it back, but only the CPU that wrote that file is the one that can read it. This gives you kind of a persistence ability. And then the last component that's essential to using these for Know to make it so that you don't have to trust the validators or you don't have to trust the Know flashbot operator is remote Attestation. So this is where one of your enclave E calls outputs a report. This report gets signed by intel, and then this signed report basically has output from your E call whatever it chose to put in the report data field and the hash of the program binary that generated it.
01:34:10.990 - 01:34:47.686, Speaker H: So this Attestation report is kind of where the magic happens. This is where you get a guarantee that this output was produced by some enclave running exactly this program. And that's basically the source of your root of trust. So I want to talk about some specific pitfalls and explain them in terms of the high level thing that I've set there. And these will follow along with some posts. You can read more data about these. So the first one is the issue of what it is that you do when an SGX vulnerability occurs.
01:34:47.686 - 01:35:48.986, Speaker H: So SGX vulnerabilities have occurred in the past over years, there's been dozens of them. They range in terms of how catastrophic they are to all of the intel chips or just some intel chips, and whether you can just get the Attestation keys out of a chip, that's like the worst case scenario or something more mild. What happened with Secret network and APIC leak was that so APIC leak was the absolute worst case scenario for an SGX vulnerability. This was publicly announced in August of last year, but it had been brewing for nine months. Like, the first disclosure from the people who found it to intel was like in January, earlier in 2022. So like a nine month period had occurred during which mainly like, motherboard developers, Lenovo's, HPS got kind of private advanced notice to be able to build patches against it. And cloud services were able to try to make their plan in advance for what to do when this disclosure would be announced.
01:35:48.986 - 01:36:47.102, Speaker H: When the disclosure is announced, it basically means, okay, anyone using a remote Attestation system is at risk of having fake nodes that aren't even enclaves, generate fake Attestations and show up. Really what's called TCB recovery is what intel calls what do you do when an SGX vulnerability is found and it involves releasing patches that you can patch to upgrade your own processor. The problem with remote Attestation is that your threat model are other people on the network who have not upgraded their processor. The best response for TCB recovery is something like shutting down all new node registrations. Until you can enforce that, everyone has updated their patched code in order not to be vulnerable to this. What happened with Secret network is that they had judged that none of the nodes that could join the secret network were specifically vulnerable to APIC leak. But this turned out not to be true.
01:36:47.102 - 01:37:32.858, Speaker H: So when we went to basically look into this, like two months later, it still hadn't been shut off. It was easy to join new vulnerable nodes to the network and then so we were able to get some secret data out of it. Another detail about this is that the Akitan paper had a bunch of concepts on it, one of which was compartmentalization and rotation. These are both hardening. At the time the Akitan paper was made, this had already been after the first handful of SGX attacks, so the need to prepare for a potential SGX vulnerability was already clear to us then. The basic idea of compartmentalization is that there's not just one master key that everyone has. Instead there's a small number of nodes that together share master keys.
01:37:32.858 - 01:38:52.460, Speaker H: Ideally, even those should only share them in a threshold multiparty computation, threshold encryption way, and then worker nodes maybe get contract specific keys on a need to know basis. The result of that would be that if there were this break, there would be a much smaller attack surface of nodes that could leak the master key, and perhaps a larger number of nodes that might have a portion of data threatened, but not the whole network. Secret chose not to have any compartmentalization for other trade off reasons, sure, but the result was that this attack enabled us to get the master key to the entire network. We're still showing on this SGX Fail site more details about how this works and like a demonstration, like we can still decrypt on their testnet transactions today. Part of the response is you want to rotate your keys when a vulnerability is announced, because you don't know for sure whether or not the prior data will tomorrow turn out to someone, could decrypt all of it and goes and publishes on the black market. So you should at least rotate your keys so that new people using the network ongoing transactions aren't vulnerable if the old key is compromised. So this is something that Secret but is developing as part of their rapid response to the disclosure that we made.
01:38:52.460 - 01:39:45.606, Speaker H: Oasis is still developing this too, and plans to launch their mainnet without that feature in there's more to say about this also Tom, my students, one of the authors of this, and there will be more presentations about SGX Fail, so I don't want to go more into that. I'm also running out of time, so I want to say a couple of other things, but there's a lot more detail on the SGX Fail website. I'll go really quick through this emmer signer because I want to make a couple of other points, but I've eaten up a lot of time. Here another thing that we had wrote about it, and you can read about it on this post on the IC Three site, but there's a centralized developer backdoor that's built into some of the code bases. That includes obscuro and Secret network at the time, although they're both fixing this and it relates to how the ceiling data works. So SGX nitty gritty details, there's two options. I mean, they're not that nitty gritty.
01:39:45.606 - 01:40:26.066, Speaker H: They show up on kind of the learn to use SGX 101 website. Sealing has two modes, enclave mode and signer mode. Enclave mode says that only the exact same program binary that generated the sealed file can read the sealed file. Mrsiner says that any program signed by the code developers can read the sealed file. So that means if you seal the data with mrsigner, which is what Secret did and what Obscure did, I mean, they haven't launched, but I looked in their code base and that's what they had when I looked at it. That means that the code signers the developers have a master decryption key themselves. They could just code sign a malicious program that dumps the consensus seed.
01:40:26.066 - 01:41:21.174, Speaker H: They have the key that they need to get it that way. So this is like a footgun cell phone kind of unnecessary mistake. Maybe I will end after this next one just because I want to say it briefly, but in this picture I mentioned that the enclave boundary sort of ends where the memory begins and the disk access through O calls begins. Well, this means that you need to be concerned about access pattern leakage. So the Secret developer documentation says that when you access the key value store from a smart contract, okay, it's a key value store, so the key is encrypted and the value is also encrypted. So that's great, but that doesn't reveal the contents of the key. But it'll still be apparent to the untrusted operating system if the same key is being accessed or not.
01:41:21.174 - 01:42:25.260, Speaker H: So if you write to an account balance, this is something that SNP 20 tokens have to do. What you want is that you can't tell which account is being written to, but what the interface gives you is that the access pattern is revealing that the same account is being used from one transaction to another or not. That's a problem. And the only solution to this problem, or the only solid solution to this problem, is to implement an oblivious Ram algorithm. This is something that could be added, but it's something that none of the different smart contract based systems currently feature at this point. In principle, you need to do this not just for your disk storage, but clearly for that you do need to do it for your disk based storage, but you also need to do it for your memory accesses, because the untrusted operating system gets to see which pages in memory are being accessed. So you could learn if smart contracts are stored in different spots in memory, and you're just using the virtual memory system that SGX offers, you're leaking an access pattern that very well may lead to the difference of telling which account just received a transaction or not.
01:42:25.260 - 01:43:18.042, Speaker H: What else did I want to say? I might cut it there so that I have five minutes for questions. I have a couple of other ideas that are about things that could even be let me just kind of do the summarize for this. Right? So I think that we're basically at the extremely early stage of kind of developers awareness and understanding of the details that go into SGX. I'm sure we'll talk about the panel, about the high level trust issues. You have to trust intel, you have to be aware of the potential for further attacks, but there's a lot of other kind of defenses and good ideas that could be built into this. I'm really a fan of this idea, but I won't be able to explain it in this talk. But that is that you should be able to have applications defend their privacy rules even against the code signers, and even the majority of Validators shouldn't be able to make a hard fork to change the rules.
01:43:18.042 - 01:43:39.480, Speaker H: Like the Dow hard fork was obviously the rule change in order to cause a change to the application functionality. With Tees you have the ability to make applications that can defend themselves even against the tyranny of the majority of the chain that they're running on hard forking. So yeah, I'll end it there and see if we have any questions.
01:43:43.610 - 01:44:30.946, Speaker C: Thank you Andrew. Very interesting technical deep dive into SGX. I mean, one thing that I've been wondering about SGX is why do remote assessations have to go through like why does intel have to sign the transcript, the report? Wouldn't it be so much easier if basically transcripts or reports are signed by the enclave key that's unique to this one CPU and then intel just tells you what the list of Valid pub keys are, those that are trusted basically at any given point in mean, that's.
01:44:30.978 - 01:45:19.460, Speaker H: Nearly how it mean. So a slight more detail about how remote Attestation works is it's split up into what's called a provisioning phase, which kind of necessarily involves intel, but you do that once per chip. You don't have to do it for the different applications that you run. Then there's the Attestation step which in the default setting, that Secret and Oasis currently I think that that's the case currently use every Attestation goes through intel again as well through the Intel Attestation service. There's an alternative called DCAP, where intel is still involved in the provisioning. Process, but someone else can do the second step of it. I think that that can be made in a decentralized way, but I don't know the details of DCAP so well.
01:45:19.460 - 01:45:50.750, Speaker H: The important thing is that you will have intel still be required as a kind of point of trust for at least the provisioning phase. But there's no reason why intel needs to be able to know, block some applications or block other application or not. And that's something that using the DCAP alternative almost certainly avoids the need for. So even with SGX today, you're not necessarily as reliant on intel as the current software projects make it seem.
01:45:53.250 - 01:45:59.570, Speaker C: Okay, great. Decentralized DCAP. Sounds interesting. Any other questions from the audience?
01:46:06.630 - 01:46:16.550, Speaker G: Do you have any opinion on the just recently released GDX system from intel, which is kind of like a separate but similar system to SGX?
01:46:17.610 - 01:46:55.282, Speaker H: Yeah, I've heard about it. I don't have any thoughts on it yet. My first question, so one thing that I've noticed is that there's a kind of huge gap between what I want from remote Attestation and Tees, what we want for these decentralized applications and what the kind of bread and butter use of SGX is. So the standard case is it's a two party versus three party thing. Like, the standard case is there's a developer and there's the cloud provider, and you don't trust the cloud provider, but you, the developer, are the one who puts the program there and gets the result, and that's it. There's just the two of you. So, very simple.
01:46:55.282 - 01:47:40.500, Speaker H: Remote Attestation can work for that, and I think that TDX is a good fit for that. What I care about is this three party disintermediation world where there's a service provider in the cloud, sure, but there's a developer as well, and the developer is also not trusted. There's clients who don't want to trust the developer. They only want to trust that the enclaves work, the remote Attestation that SGX provides fits that kind, because you don't have to be the developer, you get these portable signed reports that you can use to know that you're talking to an enclave on the network running the right program. I couldn't tell from my first look at TDX whether it supports that or not, but my sense was that it doesn't. If it does, then maybe that would be a good fit. I had a similar kind of concern in working with Sev.
01:47:40.500 - 01:48:04.220, Speaker H: I only know SGX as well, and even that only so well. So it may be that it's possible to use Sev to do this. But my understanding was that you could not get a Attestation report that's sufficient from Sev to provide the kind of guarantees that we want out of this for the smart contract setting. So that's my view now. But I'm not very knowledgeable about TDX or Sev, so that might be wrong.
01:48:13.120 - 01:48:14.732, Speaker A: There's a question in the chat maybe.
01:48:14.786 - 01:48:16.268, Speaker C: Jonathan, if you want to ask.
01:48:16.434 - 01:48:16.812, Speaker H: Sorry.
01:48:16.866 - 01:48:17.660, Speaker I: Justin?
01:48:19.280 - 01:48:20.024, Speaker A: Yeah, sorry.
01:48:20.082 - 01:48:22.476, Speaker E: I have the second oldest Mev Rose.
01:48:22.508 - 01:48:25.164, Speaker G: Participant here next to me, so apologies.
01:48:25.212 - 01:48:26.560, Speaker H: If someone is crying.
01:48:27.060 - 01:48:34.868, Speaker E: I was wondering about the diagram you showed in the beginning, Andrew, on using.
01:48:34.954 - 01:48:37.104, Speaker I: Tes for smart contract execution.
01:48:37.232 - 01:48:38.708, Speaker E: But do I have to send my.
01:48:38.794 - 01:48:40.852, Speaker H: Or encrypt my transaction with a public.
01:48:40.906 - 01:48:43.656, Speaker F: Key of a specific validator, or is.
01:48:43.678 - 01:48:53.732, Speaker E: It, say, the same secret key public key pair for all Tes in the validator network?
01:48:53.876 - 01:49:31.664, Speaker H: So it's a little more different than that, but only by a little. And there is a little bit of difference between the different systems. And I've just said these different systems, but I have on my mind, like, Secret Network already has launched their main net. Oasis Sapphire is an EVM based smart contract chain that I believe has not yet launched their main net. But you can use Oasis Sapphire on a public test network. And Obscuro also is meant to be an L two for Ethereum that has this weird policy where all privacy is canceled after one year. So it's only like a temporary privacy, just the policy that they have that also has a public test network.
01:49:31.664 - 01:50:18.848, Speaker H: And so that's running adjacent to Ethereum. So I kind of say like those as the whole industry of these. So with Secret Network, there's really only one master key that all of the enclaves share at a slightly lower level detail. There's, like, per contract derived keys, but you can derived all of them from the master public key. And so you send your encrypted transaction to the public key associated with that contract, but there's one master key for everything that everyone has. So it's kind of the same as this diagram, effectively. And then in Oasis, not only do you send your transactions to the key associated with the particular contract, but the worker node that is proposing the block or whatever carrying out the execution for that only gets the key from the key manager nodes.
01:50:18.848 - 01:50:34.680, Speaker H: The workers only get the key for the contract that they have to process at that point. So it kind of limits the attack surface and the amount of contracts that would be spoiled if one of the worker nodes is able to break inside its own enclave.
01:50:43.880 - 01:50:54.644, Speaker C: Okay. Thank you, Andrew. I think we need to move on to the next talk. Minimizing Mev on Penumbra by Henry Devan. Are you ready?
01:50:54.842 - 01:50:55.552, Speaker B: Yep.
01:50:55.696 - 01:50:56.390, Speaker C: Perfect.
01:50:56.760 - 01:50:58.250, Speaker D: I just need to.
01:51:01.260 - 01:52:03.740, Speaker E: Share the screen. Hopefully this works and everyone can see. All right. So I'm going to be talking about Minimizing Mev on Penumbra as a kind of like high level there we go. As like a kind of like a high level perspective of where we're coming from and where these sort of thoughts are coming from. Two kind of framing questions. The first is, like, what is mev about fundamentally? I think that this is a question or the whole field is fundamentally about how do the economics of an application interact with the consensus system that's being used to execute to replicate that application in some decentralized way so that you can execute it without a trusted party.
01:52:03.740 - 01:53:33.960, Speaker E: And a perspective that I have that comes out of that is that properly handling mev fundamentally is going to require vertical integration between the economics of a particular application, whether that's I say, app in a kind of big general sense. You could imagine that being, like, a single smart contract or you could imagine that being like a constellation of contracts that someone wants to interact with. But whatever that kind of high level application is somehow needs to have its economics integrated with the consensus mechanism that's actually executing it. And so my opinion, which people may or may not agree with, is that I think that app specific chains or roll ups are going to, in the medium to long term, outcompete general purpose attempts at sort of dealing with mev. Because ultimately the mev is linked with what is the actual application that you're doing. And so if you can integrate that with the consensus mechanism, you can be more powerful, you can do more things. And I think that at least for applications that are important enough for people to build some specific thing that'll kind of outcompete.
01:53:33.960 - 01:54:27.224, Speaker E: The second question is like, okay, well, where does mev occur? It's going to occur wherever the miner or proposer has actionable information about future execution. One term that I really don't agree with is rebranding med is like maximal extractable value. I think if you don't have a block proposer in a privileged position, then that's just arbitrage and we have a word for that already. Let's not sort of dilute. And so from that perspective, you can say, well, we can minimize mev basically in two words or in two ways corresponding to those two words. Either you've reduced the amount of information disclosure. You're probably not going to ever get sort of perfection on that front.
01:54:27.224 - 01:55:16.810, Speaker E: But then second, how do you do mechanism design so that the disclosed information that you do reveal, not actionable in a privileged way by the block producer? So all of the other talks here so far, as far as I know, are about general purpose solutions for arbitrary programmability, which is the case for Ethereum. The thing that I'm going to be talking about instead is, okay, well, what could we learn instead from building one single application? So I'm not going to claim that this is like a solution to all problems, but what I think is interesting about this approach is that.
01:55:19.360 - 01:55:20.008, Speaker H: Although you're.
01:55:20.024 - 01:56:57.860, Speaker E: Taking a very narrow scope of what the problem is, within that narrow scope, you can have a complete solution to the problem, right? So when people talk about, say, the mev supply chain, I actually would say instead that should just be considered like end to end protocol design, right? When you're designing a decentralized protocol, the design of that protocol should start from the actual end user and their key management, their custody solution, their client, all the way through that whole pipeline out to the ledger where the execution happens and then all the way back to where the client learns about it. And if you don't consider that, then you end up with sort of recentralization in all the places that you missed, like inferra so what are we building? We're building Penumbra. It's a private proof of stakeholder one. It does this interchange shielded pool with IBC and it has a private dex. So the motivation for building a private dex is that if you're going to pick one application that you're trying to zoom in on, this is a really interesting one because every market is a market also in information. And so we have this idea that privacy can unlock capital efficiency and maybe you can have a situation where a private alternative can outcompete transparent ones. So coming back to this idea of like, okay, mev is occurring where there's actionable information, let's sort of zoom in on those two pieces.
01:56:57.860 - 01:57:46.570, Speaker E: First, the information on Penumbra, we have base layer privacy. I personally think that you can't really hope to solve mev without having privacy at the base layer. And the reason is that privacy thought of as being control over information disclosure. You can't ever undisclose information at a higher level that you've already revealed at a lower level. And so if you have a transparent base system, you have all of these problems where paying fees, who's paying for the gas, there's all of these account. It's a lot harder to kind of retroactively layer on.
01:57:48.700 - 01:57:49.688, Speaker H: Sort of a fix.
01:57:49.774 - 01:58:25.140, Speaker E: To metadata that's revealed at a lower level. So what we've started with is a multi asset shielded pool that's similar to Zcash. And all of the value, unlike Zcash, is recorded privately in that shielded pool. So when you do like a cross chain transfer in, it just records that in the shielded pool. And this means that everything is happening in and out of that common private base layer. So you have no accounts, there's no other transaction metadata. The fees are all paid privately.
01:58:25.140 - 01:59:40.312, Speaker E: And the super powerful thing about building in privacy at the base layer is that it allows transactions to have precise disclosure for interaction with public state. So even if we just stopped here and said like, oh, and we're going to have a completely transparent deck state or whatever, there's still MUV problems that will come out of that. But from a privacy perspective, you've already achieved each individual transaction is only revealing the specific interaction with the public state and not all of this other metadata. Once you have that, you're in a good position because every useful blockchain revolves around having this public shared state, right? That's why people want to use these systems. And so the question really is about how do you allow people to have private interactions with that public shared state. So I think that there's two kind of like ways that that breaks down. One direction is to try to do splitting of flows, the other is to do batching.
01:59:40.312 - 02:00:24.830, Speaker E: So with splitting, let's say there's some action that someone wants to do. They want to affect some change, move some value around on the chain. If they split that value into randomized sub amounts and spread that over distinct transactions, then they can privately reassemble all of the output effects. But this is only actually possible if you have a shielded base layer, right? If you're doing this on a transparent chain, you just see where all the funds go and this is completely useless. The other approach is trying to do batching. What we've been thinking about is rather than trying to say, oh, well, we'll have threshold encryption where.
02:00:26.640 - 02:00:27.420, Speaker H: We'Re going to.
02:00:27.490 - 02:02:15.088, Speaker E: Treat this transaction as this totally opaque object, if what we're actually trying to conceal is like, what is this transaction's specific contribution to a particular kind of, like, round of public interactions, public state changes, then we don't actually want to be doing threshold encryption for the entire transaction because the entire transaction already is shielded. Because we have this shielded base layer. All we actually need is the ability to encrypt individual, individual contributions to the public state. And so what we do instead is have threshold encryption that works just on integer amounts and has additive homophism. So you can have the chain aggregate all of the encryptions in some interval and then have the validators jointly decrypt that batch total and do some public on chain computation. So that's sort of how we're thinking about the information side on the actionable piece of MEB, this is about sort of the mechanism design. So how do we make a mechanism design that minimizes the impact of a block? Proposer messing around with transactions? So again, we're focused on one very narrow use case, which is billing a dex on the market taker side of that.
02:02:15.088 - 02:03:37.704, Speaker E: We have sealed input batch swaps. So the idea is that some user wants to swap some amount, they have their private input amount, they encrypt that using flow encryption to a threshold controlled by the validators. And because this is going to be batched, they don't know what the output price is going to be, right? So you need to have some mechanism for doing late binding of the execution. To do that, they make a private swap NFT to themselves that commits to exactly what their private input was, what the trading pair was, what address they're going to claim funds to, and so on. What that means is that once the chain sort of gets this batch of swaps, whether that's in a block or a longer interval, they can aggregate decrypt only the batch total and then execute all of the swaps with a common clearing price. And once that data has been posted to the chain each user can consume their private swap NFT to privately mint their prorata share of the output. So that's kind of the market taker side.
02:03:37.704 - 02:05:04.020, Speaker E: But from that perspective, how you actually do that execution is sort of a black box on the market maker side. What is in that black box? We have a concentrated liquidity mechanism where effectively every position is its own little AMM, but it's an AMM of the simplest possible form, which is just a line. And this means that the optimal routing problem is easy because it's basically like the closest thing to an order book that you could have. So you can walk along this graph and because all of these positions are created out of this private base layer and returned back into it, any individual participant can privately approximate whatever trading function they want by creating various different liquidity positions. And although you have transparency of what the aggregate state of the market is, you don't know which positions correspond to which users to which accounts, because they can all be created through these distinct unlinkable transactions. So when you put these things together, the mechanism design basically is a frequent batch swap system. So there's multiple phases at the end of each block.
02:05:04.020 - 02:06:05.770, Speaker E: First you open all of the positions that someone has requested to open in some transaction in the block. Then you execute all the swaps ARB all of the positions into having consistent prices with each other and then close out all of the positions that were requested to be closed. This is pretty cool because you're only doing this execution once a block. You can afford to be considerably more computationally sophisticated because you're amortizing that execution cost over every transaction in the block. So you can do grouting on the whole liquidity graph. And because you have all of your liquidity and all these different little concentrated liquidity positions, you can have liquidity be sort of like active, passive or anywhere in between. Like if you want to simulate, say, like a univ two pool, you can just do that.
02:06:05.770 - 02:08:05.440, Speaker E: But all of that liquidity is kind of on a common footing and the chain is capturing all of the internal arbitrage of is this price consistent with this other price? So when you put these things together, kind of the implications are the batching means that there's no ordering effectively of transactions within a block, right? So if you actually look at the data structure, sure, there's like a list of transactions, but the actual execution is happening in a batch and so the ordering of transactions has no economic value, so there's no real sequencer. The proposer is only choosing whether or not to include or exclude transactions. And because of the way that the mechanism is designed, their decision of whether or not to include a transaction or not only has a marginal effect on the outcome because there isn't ordering. In order for a block proposer to prevent anyone from doing arbitrage on a specific trading pair, they'd have to censor many more transactions and sort of only have theirs be present. They can't just sort of play games with individual transactions. And even if you try to censor one specific trading pair because you're doing this kind of graph routing, the proposer's ability to block people from doing ARB is limited by the way that the ARB will sort of flow through the liquidity graph. It also means that the Dex is going to step between discrete sets of consistent prices.
02:08:05.440 - 02:09:56.500, Speaker E: When I say consistent, I mean internally consistent. But that means that you don't have to have a bunch of seekers who are competing to race in some kind of mechanical arbitrage. You just do the mechanical arbitrage relative to automatically as part of the protocol and the external ARB against reference markets ends up being shared pro rata among seekers. So there's a kind of interesting paper on this by the BaneCat Crypto research team that I have like a small part in helping with but it turns out that the game theory of this type of game is that the seekers just share prorata ARV against external reference markets. So I think there's a bunch of interesting pieces here. It's obviously a very application and use case specific for the moment, but I think there's some interesting design pieces or lessons that might be useful for either other application specific solutions or for building general purpose applications. And I think some of the pieces that we built in the longer term will end up being useful for more general kind of contract interactions.
02:09:56.500 - 02:10:04.550, Speaker E: Here's a bunch of links if you want to find out more and otherwise happy to just answer any questions that people have.
02:10:09.130 - 02:10:25.206, Speaker C: Thank you Henry. I guess one question I have is on the previous slide around the internal arbitrage profits being captured by the protocol, is there a reason to not give them back to the users?
02:10:25.238 - 02:11:01.494, Speaker E: I guess well I guess when I say capture I don't necessarily mean and this actually goes back to points that was made like a while ago in the chat, during a previous talk. I think it was yeah, it was Phil saying there's no free lunch, it's coming from somewhere. And what I would say is like yes, that's true, but if you capture it as part of the protocol, then the protocol can decide how to distribute that.
02:11:01.612 - 02:11:02.280, Speaker H: Right?
02:11:03.290 - 02:11:47.220, Speaker E: So one option which is I think like the simplest is to just do ARB burn mechanism but you could also try to direct it in various ways. You could try to rebate to users who swapped or to LPs. Actually doing that I think is kind of tricky because once you're redistributing that value now you need a way to you have to convince yourself that that mechanism itself is not going to be gamed. But yeah, when I say capture, I don't necessarily mean.
02:11:50.970 - 02:11:52.210, Speaker H: Sort of like permanently.
02:11:52.290 - 02:11:58.520, Speaker E: Held, but just captured and then like, okay, you know, now to do what with? Well, we'll figure it out.
02:12:03.470 - 02:12:11.260, Speaker C: Okay, so just to make sure I understand, is there some sort of global convex optimization going on?
02:12:12.030 - 02:13:03.180, Speaker E: Because that yes, but for a very specific special case of the problem. So the liquidity positions are made to have the simplest possible form so that the convex optimization problem is easy or easier. There's actually a bunch of interesting questions there that come from the fact that you're doing that routing in a batch. One thing that is more difficult about that is that you lose the ability to have precise accounting for resource use.
02:13:03.570 - 02:13:04.320, Speaker H: Right?
02:13:07.170 - 02:13:52.490, Speaker E: Like if somebody makes a bunch of sort of dust trading positions right. Like, how do you avoid that blowing up the complexity of the routing algorithm? Because you don't really have a way to impute that cost to a specific use. So the approach you have to take essentially is just like, get good and make it fast and have heuristics that bound the size of the optimization problem, even if you don't necessarily get like a perfectly optimal solution.
02:14:04.810 - 02:14:10.902, Speaker C: I think we're out of time. There is one more question in the chat for Andrews maybe to be answered.
02:14:10.966 - 02:14:55.720, Speaker E: Yeah, long range leakage attacks. Yeah, it's a problem. There's not really a great solution to that. On the other hand, if you look at sort of what role does the threshold encryption play in Penumbra relative to in some other protocol, even in the situation where you have no flow encryption at all? Well, exactly how much information are you leaking? Well, you're leaking just the amount that someone contributed to a batch and.
02:14:58.410 - 02:14:58.786, Speaker H: There'S.
02:14:58.818 - 02:15:21.438, Speaker E: No possibility to leak the account to correlate it with any other transaction history. And so I think that the consequences of that leakage are a lot less severe than if you were using that to kind of hide the private per user state.
02:15:21.524 - 02:15:21.726, Speaker H: Right.
02:15:21.748 - 02:15:37.700, Speaker E: Like on Penumbra, the private state for each individual user is known only to them forever, and the only thing that they're threshold encrypting is their contribution in a specific round of interaction with the Dex state.
02:15:40.490 - 02:15:43.542, Speaker H: Cool. Great.
02:15:43.596 - 02:17:03.360, Speaker C: Thank you, Henry. Next talk is by Robert from flashbots private searching on private transactions from COVID channels in SGX to MPC and back to SGX. Robert, the floor is I guess there'll be two more talks, including Robert and then the spicy SGX panel. I think we're just waiting for Robert to get set up. He just rejoined the room, so might need a couple seconds to share his screen.
02:17:04.610 - 02:17:06.398, Speaker D: Hey everyone, can you hear me?
02:17:06.564 - 02:17:07.280, Speaker C: Yes.
02:17:07.670 - 02:17:26.210, Speaker D: My browser just crashed. Can anyone enable that? I can share my screen. Says like I'm not allowed to share my screenplay.
02:17:52.690 - 02:18:02.900, Speaker C: I'm not sure I have the rights to make you a host. Sarah, can you help?
02:18:03.510 - 02:18:07.490, Speaker B: Yes. So Fred, I think, has the screen share abilities.
02:18:33.390 - 02:18:58.800, Speaker D: Robert, now see, it's working. Can you see my screen?
02:18:59.730 - 02:19:00.480, Speaker A: Yes.
02:19:01.410 - 02:19:01.822, Speaker H: Great.
02:19:01.876 - 02:20:02.122, Speaker D: Okay, so let's start. I'm going to talk about private searching on private transactions, this stuff I've been working on the recent weeks. So let's jump right into it. What do I mean by private searching on private transactions? I assume that users want to receive kickbacks on the mev they generate, but they still want to keep their transactions secret and at the same time searchers want to keep their intellectual property secret. Right? They don't want to reveal their searching strategies to competitors. So the question is, can we have both? Is this possible? Can searchers generate front running and or back running transactions under these conditions? Since we're in the area of private computing here, like an obvious first step is SGX. And when I say SGX here, I use it synonymously for trusted execution environment.
02:20:02.122 - 02:20:40.000, Speaker D: So I'm just using SGX. So very simple setting here. User the user's input is a transaction, the input to an enclave. The searcher inputs a program within the SJX enclave to run the program that takes the searcher program and executes it upon the transaction. And it outputs a signed transaction, signed background that is sent to the builder. So that sounds great, but there's a catch to that, right? The catch is like covert channels. I'm quickly explain what covert channels are because it's a very niche topic and hardly anyone knows about it.
02:20:40.000 - 02:21:25.114, Speaker D: So covert channels are ways to secretly convey information. Like in order to do that, they piggyback on so called overt channels. And if you're coming from telecommunications background, you can also think of COVID channels as a way to secretly modulate information on an existing carrier signal. It's a bit of abstract. Most people understand it when you compare covert channels to side channels because people are usually aware of what side channels are. It's just a difference in an attacker model. So with side channels, the attacker aims to extract information, but the attacker does that by observing, let's say, for example, from outside the system.
02:21:25.114 - 02:22:03.874, Speaker D: For example, there's an algorithm running and the attacker can observe the power consumption. I think that's a very classic example. But with COVID channels, the attacker has the same goal. So to extract the information, but it additionally has support from inside the system. So there's basically a colluder. You can also see why there's a stronger attack here. How does that relate to the SGX thing? Well, if I think about it, what are potential over channels here? Like the signed background, right? This is the output.
02:22:03.874 - 02:23:02.298, Speaker D: Can the searcher program manipulate the signed background? Well, obviously, yes. The program could be as simple as saying, well, take the user input and this is the output. So in order to protect against that, we could encrypt another over channel would be network communication. The searcher program could be as simple as saying, well, open a network connection to a host, take the user transaction and send it over to the network. So we need to filter that, but it gets tricky if you think over channels in terms of CPU and memory of the host system. I think Andrew Miller had a similar point here. So how can we ensure that the searcher program does not encode secret information in CPU or memory access or usage patterns? You can think of, let's say, encoding information in how much CPU is used.
02:23:02.298 - 02:23:32.818, Speaker D: Let's say you're using CPU for 1 second to encode a one, or for 2 seconds to code a zero and leak information that way. And that is very hard to protect against. So there's different ways on how to go about this. Well, this seems to be a trade off, right? Like how expressive should the searcher program be versus the existence of information leakage or covert channels? We can start with a fully expressive program, search a program, then check is there a covert channel?
02:23:32.904 - 02:23:33.298, Speaker C: Yes.
02:23:33.384 - 02:23:38.470, Speaker D: Restricted. Let's say we don't allow network communication. Is there still a covert channel?
02:23:38.540 - 02:23:38.822, Speaker H: Yes.
02:23:38.876 - 02:24:18.100, Speaker D: Okay, I don't know. We prevent for loops, let's say. But there's always the question, is there any leakage left? We could go the other way around. Say we start like a fully restrictive program and ask the question, is it useful? Right? So if the searcher program can't do anything, it's obviously useless. So we say, okay, let's allow additions, for example, is it useful? Well, probably not. Question is, at what point is it useful enough? It's also hard to say. Or we could start somewhere in the middle between in the expressiveness level.
02:24:18.100 - 02:25:15.670, Speaker D: The question is then where should we go from there? What we decided to do is to start with MPC, because MPC, interestingly, guarantees that the parties cannot learn anything but the output of the function. So there are no covert channels there. As a general statement, what is MPC? It allows multiple parties to jointly compute the public function while keeping their inputs secret. So this is a good start to explore the design space. Going back to the original question, like secrets searching on secret transactions, how would this look with MPC? So instead of using SGX, we now have like an MPC back running protocol. We don't know yet what this would look like, and again, we have the user inputted, transaction searcher input a program, and the output is a signed back running transaction. We just don't know.
02:25:15.670 - 02:25:32.780, Speaker D: The question is, what is the back running protocol, how does it work and what is the searcher program? And we started experimenting in the Mpspeeds framework. It's a general MPC framework. And I'm going to quickly present.
02:25:35.230 - 02:25:35.546, Speaker I: The.
02:25:35.568 - 02:26:04.286, Speaker D: Current state of the proof of concept. So first thing, what is the searcher program look like? It turns out like a searcher language can be pretty simple. So the searcher program can just consist of a list of constants, a list of computing instructions. And computing instructions are very simple. So it's addition, subtraction, multiplication, V square root. That's not super simple. But still it's relatively simple instruction.
02:26:04.286 - 02:26:41.550, Speaker D: But note that there are no loops and there is no branching. We cannot allow that. There's a couple of comparison instructions and a list of references for the populating the back running transaction. So what does the back running protocol here this middle thing. What does the back running protocol look like? Turns out this is simplified python like code. But it's just to highlight how it works on a high level. We have like a protocol internal storage.
02:26:41.550 - 02:27:26.538, Speaker D: If you think about what a transaction is, it's just RLP encoded data. So the first thing is to decode the data, make it and populate the storage with that. Second step is take the constants from the searcher, populate the storage with that. Next step, take the searcher's computations, execute the computations one by one on the storage, and then run the comparisons. So the searcher provides a couple of comparisons. And note here that there is a success variable and all of the comparisons must be true in order for the success variable to remain true. Then in the end, the back running transaction gets populated.
02:27:26.538 - 02:27:57.210, Speaker D: I think the interesting part here is that in the end, back running transaction is sent to the builder if and only if all of the comparisons were true. So this is a very abstract introduction of how the proof of concept works. We can walk through an example. I guess this makes it a bit easier to understand. So this is an example with a real world transaction from last month. A user sold 3.75 E for USDT on the uniswap v two pool.
02:27:57.210 - 02:28:53.578, Speaker D: So first step for the protocol would be to decode the transaction and populate the storage so you can see the non SCAS limit, whatever. So that's the entire transaction. In the second step, the protocol loads the constants from this provided by the searcher. There's a couple of I won't go into all the details, but constants for the comparison, for the back running amount and for the back running transaction. What is important to note here is that the searcher also provides on chain information. For example, here it's the number of we tokens in the pool at that point in time or the number of USDT tokens at that point in time. And I think it's a fair assumption because the searcher already knows for its strategy, like what on chain information is needed.
02:28:53.578 - 02:29:36.742, Speaker D: And we can expect the searcher to provide exactly that information. So there's no need for the back running protocol to query the EVM or the ethereum p to peer network for additional information. We can just assume the searcher to provide that information. But what is the strategy now for the searcher? Right, the searcher wants to backrun a uniswap trade. The searcher kind of knows that in this particular trade, a user sold ETH to the pool. So the size of the pool increased and took out USDT from the pool. So this slightly affected the price.
02:29:36.742 - 02:30:47.722, Speaker D: Obviously the searcher knows that. So the price of ETH went down slightly. So the question for the searcher is what is the amount I can put in in order to move the price up again to a certain target price. And you can use the formula like I'm not going to go into the details of the formula but it's important to note here it's just like a couple of simple computations. You have a couple of multiplications and additions like a division in the square root. And all the information is either provided by the searcher, so the fee of the uniswap market, the target price, the precision is like the number of decimals for the we token or it can be computed from the onchain information provided by the searcher and the user's transaction. For example, the y is the amount of ETH in the uniswap v two pool after the user's trade and then that can be computed by the amount of ETH in the pool before the trade plus the amount that the user put in minus the fee.
02:30:47.722 - 02:31:41.970, Speaker D: So all of this can be computed obviously very important for the searches. Also is the background profitable? So this is also part of the strategy. So this is like on a high level the strategy like we implemented in the proof of concept. How does this look like in this searcher language? So this is not nice to read and this is just a snippet only going to explain the first line here. So this is like 4229. So this reference is just the fourth item in the storage two references, a multiplication and 29 is the 29th item in the storage. So fourth item is the amount the value in the user transaction multiplied by the in this case searcher provided constant the fee and this is like step by step the backRunning protocol can execute the computations provided by the searcher.
02:31:41.970 - 02:32:51.318, Speaker D: Obviously it's important that the searcher wants to send the back running transaction if and only if the user transaction actually is selling e for USDT because the strategy the computations provided is really targeted for that and if the background is profitable. So there's a couple of comparisons like it works similar way if you look at the first line free 423 is third storage item. This is the two address of the user transaction. Four in this case is the equal operator and 23 is the uniswap v two router address that was provided by the searcher as a constant. Just a couple of comparisons probably the last line is also an important one is the background profit greater than zero. So if all those transactions, all those comparisons are true then the back running transactions is created. Creating the backRunning transaction is actually the simplest part of that.
02:32:51.318 - 02:33:16.830, Speaker D: It is just a list of references to storage. So let's say that it's 40. This is the FORTEST element in the storage. This is nons and you have the gas limit, gas price and so on. And these items are like the values are taken from storage RLP encoded. This is the back running transaction. So this is the proof of concept.
02:33:16.830 - 02:34:26.262, Speaker D: There's a couple of open questions with that. First of all, is the searcher language expressive enough to be useful? My gut feeling is yes, but I'm also not a searcher, so input on that is highly appreciated. You could also see the searcher language is very low level and this is very cumbersome and error prone to work with. So what should a high level language look like that compiles down to this low level language? And also, how can we make this practical? I mean, this proof of concept implemented in the MP speeds framework on a single transaction, a single searcher strategy takes in the strongest security model, takes like 40 hours to compute and a couple of hundred gigabytes of back and forth communication. So this is nowhere practical. How to make this practical? Right. I recall like, we started experimenting with MPC because we needed to restrict expressiveness of the searchers program.
02:34:26.262 - 02:34:41.850, Speaker D: And now we arrived at a design that is restricted and hopefully expressive enough. So can we use that and now implement it using SGX and create a practical solution?
02:34:43.230 - 02:34:43.690, Speaker H: Probably.
02:34:43.760 - 02:35:36.730, Speaker D: We also need to emulate some MPC like behavior, like execute all branches have constant time functions, but maybe that's a way forward. Another way would be to go for application specific NPC or with homomorphic encryption. Why is that? If you zoom out a bit and the proof of concept design basically has three phases, right? This extract the data from the user transaction. This could happen on the user machine. So this is easy. The user could use that and encrypt it, send it over to the searcher, then the searcher does a couple of computations on the extracted data and some constants that sounds exactly like homomorphic encryption. And if you think about it, we only need to support very limited operations.
02:35:36.730 - 02:36:22.490, Speaker D: So maybe partially homomorphic encryption is sufficient. And if it is, then we have partially homomorphic encryption schemes with reasonable performance that exist already today. For me, a big open question is we also need to enforce certain conditions under which the back running transaction is revealed. And I have no clue how to do that in a practical way. So if you have ideas, go ahead, share it. So that's it like the takeaways from this talk. If it's just the two takeaways, covert channels are afraid to SJX deployments and they should be considered.
02:36:22.490 - 02:36:25.450, Speaker D: And private searching on private transactions.
02:36:27.310 - 02:36:27.578, Speaker H: May.
02:36:27.584 - 02:36:35.360, Speaker D: Be possible, even though they are not obviously not practical at the moment. Any questions?
02:36:41.270 - 02:37:04.360, Speaker C: Wow. Thank you Robert, for this talk. Very interesting. For me, I didn't appreciate the covered channels for SGX. I guess I don't completely understand how COVID channels are addressed in the NPC case. Go ahead.
02:37:04.810 - 02:37:29.440, Speaker D: Yeah. For me, before I started with playing around with MPC I had same question. The fun thing is or for me the insight was they're just not an issue with NPC. They just don't occur. They're all already by their because by design you cannot leak information.
02:37:32.710 - 02:37:44.770, Speaker C: Well, a very simple MPC is just the constant function that returns all the inputs without doing any operation and that leaks everything, leaks the whole input.
02:37:47.210 - 02:37:51.270, Speaker D: Okay, sorry, it doesn't leak any information apart from the output.
02:37:54.170 - 02:37:54.920, Speaker C: Right.
02:37:58.570 - 02:38:36.326, Speaker H: When writing an MP speech program you still kind of have the problem that you have to do. If you have an array and you want to do an index into that array that depends on some data, like an input dependent lookup you're forced to either do a linear scan through the whole array, which costs a lot, or leak something by publishing which value in the index you want to do and doing some kind of interaction like that. So you either need to take this performance penalty or try to you could use an O Ram within an MPC. That's like one of the things that the cryptography theory relies on. Sometimes the same problem seems to show up anyway, right?
02:38:36.348 - 02:38:42.520, Speaker D: But this is how the proof of concept works. So it uses the storage is like an Orim and it works on that.
02:38:46.890 - 02:39:27.640, Speaker H: Could you also do any distinction between covert channel and a side channel? I think that they're different and to me the difference is kind of addressed by remote Attestation, at least in the SGX setting. Because if a covert channel would be built into the code, it should be visible to auditors looking at the source code to be able to check. And at least with remote Attestation, you have that option. And then if you check that the code only does linear scans in SGX, just like you would have to with MPC, you'd be getting the same guarantee that it's not leaking a channel, because it is doing a data independent access.
02:39:29.130 - 02:39:54.430, Speaker D: I think that the tricky question is can the input to your program that runs within SGX, can the input to the program change the program execution flow in such a way that it leaks information? And sure, if you analyze the program and you make sure that this is not the case I totally agree, I just think it's an analysis that's very hard to conduct.
02:40:12.230 - 02:40:52.820, Speaker C: I guess my question on the MPC was how can you guarantee that the program will output something which is expected? Let's say the program is a builder program which builds a block. What if instead of building a block, it just outputs just the input transactions? Or maybe in some cases, let's say in 99% of the case, it outputs a block like the expected output. But then if mev is over, let's say 1000 E, it just leaks all the transactions and then the attacker can just front run.
02:40:54.550 - 02:41:26.170, Speaker D: I guess that's an issue. Just maybe I should have clarified. Like, the scope for the proof of concept is just a user search interface, right? So the output is sent to the builder and the builder could see everything in clear text. And in this case, I don't bother with that. The builder is assumed to be trusted. So let's say the searcher leaks the user transaction, it can leak to the builder, and the builder is trusted in this setting. So I didn't go any further than beyond this user search interface.
02:41:26.170 - 02:41:50.050, Speaker D: So it's just like the user transaction remains private to the user and searcher, and the searcher strategy remains private among the user and searcher, but not among like the the output is then shared with the builder and the builder can see everything. Well, can see the output.
02:41:51.590 - 02:42:00.934, Speaker C: Okay. The searcher does not get access to the output, only the builder in the pink text. Yeah, I see.
02:42:01.132 - 02:42:02.306, Speaker D: But the builder is trusted.
02:42:02.338 - 02:42:02.486, Speaker H: Right.
02:42:02.508 - 02:42:04.486, Speaker D: The builder could act upon the information.
02:42:04.668 - 02:42:40.690, Speaker C: Okay, understood. Great. Thank you so much, Robert. We're already overtime for the whole event, but we do have one more talk and one more panel. So our last talk is the joys and challenges of adopting pets. Present and future applications of privacy enhancing tech at Flashbots by Jonathan from Flashbots.
02:42:48.220 - 02:42:50.410, Speaker I: Hello, everyone. Can you hear me well?
02:42:51.660 - 02:42:52.410, Speaker C: Yeah.
02:42:53.100 - 02:43:36.570, Speaker I: Perfect. All right, let's get started with that. I don't know, I kind of feel like it might have been better to have that talk earlier, but let's see, I hope I'm not too redundant with the other ones. It's going to be a bit high level. I'm not going to go into too much details. It's mostly about giving you a flavor of what's possible as of today. I think it's going to echo what Robert just showed you in terms of runtime and challenges to get things up and running and what we could expect, what we could do to improve the current situation.
02:43:36.570 - 02:44:54.130, Speaker I: So, first of all, pets, privacy, nancing, technologies. This representation is like something that we've agreed upon in the Pets community, basically splitting them into three different categories depending on what is their main feature. Do they protect the privacy of the input, the outputs, or are they more of a governance technology? And you see that some of them are kind of like overlapping. But what I think is important to understand from this representation is that we tend to mix sometimes the notion of privacy, confidentiality and all these kind of things. So in the world of Pets, we try to stick to using privacy for what we mean as like, output privacy. So technologies that guarantee that the results of an application remain private or at least do not disclose any information about the input. So that's kind of like the guarantees that differential privacy would give you, for example, which we're not going to address in this talk.
02:44:54.130 - 02:45:45.936, Speaker I: And similarly, you've got overlapping text, like I'm not going to address Norix because I think it's probably like the most familiar piece of technology you have in this community. So we're going to stick to the technologies that provide confidentiality. Mostly going to cover Tes, MPC and she for that matter. So in terms of the applications of privacy at Flashbots, I think a good reference to the use cases that are listed on the left. So mostly we're going to be working at applying privacy to these use cases. It's very high level. I think Robert's presentation was like one component within the other.
02:45:45.936 - 02:47:01.028, Speaker I: Flow auction, for example. Quintus's Talk could give you more details. And I think in general it's worth exploring the writings website as well as the forum to get a better understanding of each of these problems. But that's basically the context to which we want to apply these privacy texts and basically it's not about providing privacy. I think probably a lot of us are very keen on privacy as a right and those kind of things, but we need to see beyond that. We need to understand that privacy is actually a mean to unlock new use cases, but it's also a way to increase the decentralization of the services that Flashbots have been providing for a while and that the community has trusted Flashbots to provide. So by injecting privacy in these services, we're hoping to increase their resilience, increase their decentralization, but also to foster collaboration between actors that would normally not have the incentive to collaborate into performing a joint task together that might even be considered to be in competition when trying to perform a task.
02:47:01.028 - 02:48:01.550, Speaker I: Like, I'm thinking of block building, for example, where if we want to hope to have distributed block building, we need block builders to share information that it would not have any interest to share normally in terms of the requirements that we're expecting from these technologies, we want a lot of things actually. We want speed in order to not be too constrained by the flood transactions. We want to be able to scale to a large number of users. Of course, we want the maximal security guarantees for the minimal assumptions and especially we want well defined assumptions. That's going to be important in some of the text we're covering. We'll see it's not always extremely clear what is the threat model, maybe something we've not addressed too much today. When you start applying these kind of like technologies, MPC and FH in particular, you might lose some precision in the calculations you're making.
02:48:01.550 - 02:48:58.380, Speaker I: My take is that this might have an impact and we need to be extremely aware of that too. The one thing we don't need, and that's good because tends to be changing as well. Sometimes to provide is forward secrecy. So we know in the case of trying to implement an encrypted mempool for example, or private smart contracts like Andrew presented, everything that we are manipulating as like sensitive data is short lived in the sense that it doesn't remain sensitive forever. Once the computation is done and the information has been processed and the transaction lands on chain, it doesn't really matter if this competition can be disclosed afterwards. So at least I don't think we need forward secrecy. In terms of the roadmap itself, I think you've understood by now that in the short term we're pretty much focusing on Intel SGX.
02:48:58.380 - 02:50:10.336, Speaker I: Again, I want to make it very clear that we're not like SGX fanboys, we're just like taking the pragmatic stance of what is the most easy thing to deploy and the most ready thing to deploy today that can bring us closer to the end game. But definitely our goal is to phase out SGX and even maybe like hardware dependencies in general and you've just seen like a first attempt in doing so with Robert's presentation on the background by any means. That doesn't mean we committed to this path either. We're exploring multiple paths in parallel. You're more than welcome to join us in this journey. Without further ado, just diving into each of the so we've heard a lot about Te, so I think a great reference to that is of course endless presentations. SGX as a Te is by far like the most popular of the Tea as of today, which is good in a way because it's received a lot of scrutiny.
02:50:10.336 - 02:51:13.316, Speaker I: You've got lots of papers about it. So just to summarize what it is, technically it's just a set of CP instructions that allow you to create enclaves what we call like initially what was trusted portion of an application and that I've grown into sometimes being like whole applications containers, and maybe not even like whole virtual machines. And the idea is that you'll get full confidentiality of your data during the computation. So anything that happens within the same clave cannot be seen by any external party of the system, not even like the root administrator, the cloud operator, if you're in a cloud setting. So it's very much like this protected environment. And we know that SGX received a lot of bad press. It's been broken over and over again by various attacks, lots of academic papers in this direction.
02:51:13.316 - 02:52:48.040, Speaker I: So I guess the interesting question there is why? So we've started to touch upon it, as in it's received a lot of scrutiny because it's been one of the first Teas that was available and one of the easiest to get your hands on. It was just an SDK just extending like C plus plus, so it was relatively easy for people to start developing with it. My take on that is that the problems that we see repeatedly with SDX are mostly due to the way it's been designed. So it's been designed by intel on top of Intel CPUs, which means it's sharing various components like architectural and microarchitectural components like cache lines for example, that allows of the side channels effect that we've seen against SGX. But it's also sharing other components of the system like the memory address bus which make it pretty hard to defend thoroughly against some of the attacks. So the problem with that is that it was not maybe not like what intel wanted to see from these technologies that initially was not maybe meant to have this kind of application. So we've seen a move by intel recently, since the Ice Lake generation.
02:52:50.060 - 02:52:50.376, Speaker H: Of.
02:52:50.398 - 02:54:08.050, Speaker I: Intel CPUs that answered one request from the community to have larger enclaves. You might have caught from Andrew's presentation that the first generation of SGX enclaves could get as much as like 128 megs of memory. And intel decided to lift these constraints and they're like multiple hundreds of gigabytes of memory. The trade off for that is that we've lost the integrity in memory, so we don't really have the same security guarantees from this previous generation of SGX to the new one. And the way intel defended against that is that they repurposed SGX as a cloud only technology or a cloud first technology. So it's not meant to be massively deployed on desktops or laptops anymore, which of course hurts decentralization and maybe pushes us even further to try and find alternatives. And what could they be? Of course we're going to see the pure software crypto, but maybe in the meantime, before they get ready for the prime spot in production, we can also explore other Teas that might not have the same design flows as GX has.
02:54:08.050 - 02:55:03.010, Speaker I: So I'm thinking, for example, Keystone, which is very interesting project put together by Don Sung and the team. Maybe we might want to design a custom enclave if that would be even more challenging and resource demanding. I guess one notion that would be interesting as well in the context of decentralization is to try and see whether a heated regenerative network of tes would make sense, bearing in mind that the main challenge is that they do not have a common threat model. So it doesn't mean the same thing to have an enclave. We've kind of call it an enclave running in SGX or Sed, for example, let alone TDX and all the other alternatives. So that could be an interesting challenge to see if we could define this common threat model. Right.
02:55:03.010 - 02:55:40.940, Speaker I: Switching to software crypto. You've just seen a very interesting application of secure NPC with Robert, so I think you've understood the global ID. So you have input data. Here the five. And we're basically splitting into different shares. And due to the homomorphic properties of these shares, we're able to apply operations before recombining these shares to obtain the result you would expect. So that kind of works well until basically you need more complex operations.
02:55:40.940 - 02:56:38.892, Speaker I: So when you start from a general purpose secret sharing either like additive or Xiaomi secret sharing protocol, you can do these kind of things. Now if you want to get to better performances. Usually what happens is that you want to design custom protocols right as soon as you want to start to do custom functions. And the interesting thing when you start designing custom protocols is that if you look in the literature and in this presentation, most of the examples are drawn from the privacy preserving machine learning literature. There's two reasons for that. That's my background, so I've got a few papers and readings on that. And the second is that it tends to be like very large problems that requires a lot of computing time and memory.
02:56:38.892 - 02:58:09.550, Speaker I: So they tend to set like a higher bound, an upper bound of what you should expect from the behavior of these custom protocols as well. And in particular, what I like to note in these two tables that you've got on the right is that you can see that MPC has to be considered into different settings. We tend to just like in experiments, just report the things that we've done that we've run on our local infrastructure. But if we think into the context of Flashbots or any other decentralized application, we should be more interested in how NPC applications behave in one setting. So across the internet with longer latencies, the reason why is that the mainneck of MPC protocols is communication bandwidth. So basically the game in NPC to improve the performances is to try and address this communication bound problem. So either reduce the amount of communication that are required or redesign the protocols to make sure that they're generating less data or have less rounds of communications, for example.
02:58:09.550 - 02:59:43.052, Speaker I: Another hope with this regard is that in this PhD, you have a diagram on the right. You can see that with the right custom protocol, with a problem size growing, the author has been able to basically switch the natural problem of MPC from being communication bound to being computation bound. So it means that with the right designs, we can potentially go beyond this communication bound problem with MPC and then focus on accelerating the computation and kind of get the best of both worlds. That's kind of like what I was hinting at in the chat before when Robert was making this suggestion. There's quite a few protocols in NPC that also try to use homophic encryption natively within the protocol to reduce the amount of communication rounds that are required. So we'll see that it's pretty important to not see all of these technologies as standalone, but as like pieces of a bigger jigsaw, maybe switching to homophobic encryption. Okay, so same thing.
02:59:43.052 - 03:01:00.804, Speaker I: I'm not going to go into nitty gritty details about how Fhe works. We could do that another day maybe, because we're definitely going to go over time, way over time if we do that. What you get from Fhe, if you've not code that yet, is that you're able to perform alphabetic operations on ciphertext. And when you decrypt the ciphertext, if you've done things right, you basically obtain the same result you would have by performing the same operation or sequence of operations on plain texts. So you once again have these problems expressed as circuits, as we have in Snarks, and as we've seen in the EMTC context as well. What's interesting with homophobic encryption, what is it desirable, especially in our kind of fields, is that the security assumptions of most schemes are relying on lattice based cryptography, which is believed to be post quantum secure. So there's a lot of conversations about the state of cryptography and quantum computers coming and breaking everything.
03:01:00.804 - 03:01:48.260, Speaker I: At least we have stronger guarantees. In the world of homophobic encryption, we have different types of schemes that tend to manipulate different data underlying data. So schemes like focusing on manipulating binary data like just booleans others. Typically, like in the machine learning space, there's a strong appeal for schemes manipulating floating points, but also integers. They can be combined. So again, you can come up with more interesting protocols by doing these kind of things. There's two things that we need to pay attention to when dealing with holivic encryption.
03:01:48.260 - 03:02:54.676, Speaker I: I think Justin hinted at the fact that there is this notion of depth in the circuits we're building. So what's to be considered really is like what we call the multiplicative depth. So what is the maximum number of multiplications we need to go through in order to reach the output? Because in homophobic encryption, in order to protect the ciphertext from being revealed, basically we're adding noise to this ciphertext. And whenever you perform operations, the noise from the two ciphertext that you're adding or multiplying combined, when you perform additions, the combination of these noise is like relatively easy to keep under control. But when you perform multiplications, the noise grows exponentially. So that's why you want to make sure that the multiplicative depth of your circuit doesn't go too far. Otherwise you have to go through an operation called bootstrapping to reset the noise of your circuit.
03:02:54.676 - 03:03:48.856, Speaker I: But that introduces like, extra computational overhead. And the second point that we need to pay attention to that is often not evokes. We just tend to focus on the Runtime ciphertext tend to be big with homophobic encryption. In some schemes, the ciphertext to plain text ratio is like several orders of magnitude larger, which is called like, ciphertext expansion. So it's definitely an area that we want to pay attention to with Fhe in terms of what's possible of today. I've got two, again, examples drawn from the privacy preserving ML literature. So on the left you've got a pure software approach that's drawn from a company called Zama.
03:03:48.856 - 03:04:49.820, Speaker I: They are building an Fhe library called Concrete. And they've introduced a very nice trick when they're doing this bootstrapping operation that I was mentioning before. They make the most of it by, in a way, introducing lookup tables in there that allows them to encode very complex operations. And as you can see, by doing so, they came up with a scheme where even for relatively large. Number of operations in a neural network evaluation they only have a 100 x overhead, which is pretty impressive compared to what we were used to before for homophobic encryption. And on the right we've got the hardware version of that which is a program by DARPA called Deeprive whose goal was to reduce the overhead of homophobic encryption to just ten x. So just a single load of magnitude.
03:04:49.820 - 03:06:25.070, Speaker I: As far as I know, it's going pretty well. I was pretty pleased to see that as of yesterday or two days ago, a company called Duality was awarded a contract to enter phase two of the Deepry program. So that means that at the same time, we have innovation on the schemes and also innovation on the hardware side, which makes me pretty confident and make me want to take the same bet as Justin was saying before, that it's not crazy to think that app specific fhe is either within Rich or it will be soon. In a matter of, like, a few years, I think. And again, bearing in mind that these workloads are probably, like, way larger than what we'll see in the type of application that we've discussed today, except for maybe distributed block building, which might be in the same order of magnitude in terms of how much data it needs to manipulate and how many operations it needs to go through in order to get to results. Okay, so what's next in she? So as we've seen working on scheme level optimizations, either improvements like the Lookup tables by Zama or even brand new schemes that would ideally work on reducing the size of Stifetex. I think hardware acceleration is coming.
03:06:25.070 - 03:08:01.980, Speaker I: You've got this Deepry program by DARPA and something pretty interesting that I've seen recently, there's a demo of a fully homophobic chip like imagine like a CPU that is fully homomorphic, which could be interesting because we've had this discussion at Defcon around Sh EVMs, so maybe like some inspiration to draw from there. That reaches like 250 MHz, which is not too bad for those of us that was used to pension two S. And these older CPUs kind of goes to these kind of performances. And I'm sure that I think Sam is in the attendance and he could probably add to this conversation about what can be done in terms of hardware acceleration. Another thing that's pretty important tooling and especially compilers that will make all these drinks available to most developers and something that is very often discussed as well in the ZK community is how do you perform security audits when these tags tend to be more and more complex. I think there's a discussion, ongoing discussion on how do you edit like Zkevms and are we confident that this could work? Okay, so maybe a final remark is that you see this trend of compilers. I think it's getting pretty obvious that it's important to improve the UX for developers, but also to make sure we make the most of the hardware.
03:08:01.980 - 03:09:11.276, Speaker I: And what I like is that we see a similar trend in different privacy techs. You start to see compilers, people working on compilers and DSLs for ZK, but also for homeopic encryption. And in particular you've got like three, I think, very strong candidates in Microsoft Eva concrete from Zama that we discussed, and a transpiler jointly worked on by Google and duality transforming C into he circuits. Okay, just a final reminder that we shouldn't see these technologies as standalone components. If you remember these toys from Power Rangers, the small ones, they were very useless on their own, right? But if you put them together, they make the big robot on the right, whatever was his name, and it's very much the same thing here. If we consider pets on their own, we're not going to go too far. They're just like primitives, they're just like building bricks.
03:09:11.276 - 03:10:12.916, Speaker I: What's interesting is like the protocols that we can build to address their shortcomings. So for example, I didn't mention that, but homophobic encryption doesn't guarantee that the computation was done the way you intended. So it's pretty interesting to see how you can combine it with Snarks. But not in a naive way, where you would plug snarks maybe on top of she or the other way around, but maybe verifying that the data was encrypted decrypted correctly and combining that with other tools to make sure that you've got some kind of privacy in depth approach to this kind of stuff. Right? So as a summary, please bear in mind that these notions are different privacy, confidentiality, verifiability, and that it's mostly about collaboration. It's about using privacy to foster collaboration. That's pretty much the takeaway of this talk.
03:10:12.916 - 03:10:35.230, Speaker I: I think we need to combine these technologies. So yeah, that's the other takeaway, I think, like collaboration and putting them together to get to very interesting protocols and that can achieve our design goals. Thank you very much. I hope I didn't go too much of a time.
03:10:36.880 - 03:11:21.950, Speaker C: Thank you, Jonathan. Yeah. At this point, only the true enthusiasts remain. We've had 3 hours of content already. One thing that kind of I didn't completely appreciate is you were mentioning SGX kind of had 128 megabytes of memory and then that grew to hundreds of gigabytes of Ram and we lost something integrity. And that as a consequence meant that we could only really use SGX in the context of semi trusted cloud providers. What do you mean exactly when you say so?
03:11:22.800 - 03:12:15.100, Speaker I: The first version of SGX was kind of like very nice, primitive because it was giving you confidentiality of the inputs because of the Enclave guarantees. But what you were getting was that by combining the remote Attestation mechanism that Andrew talked about, when you do a remote Attestation, what you do is that you guarantee that the enclave, the program is like in the state you're expecting it to be when it starts. So you know, that you've loaded the right program that you were expecting to run. Now that doesn't mean that the execution of the program is not going to be tampered with by the underlying system. Because remember, in SGX we're not trusting the OS, we're not trusting the machine itself, we're just trusting the CPU.
03:12:18.240 - 03:12:18.556, Speaker H: And.
03:12:18.578 - 03:13:44.004, Speaker I: The intel would have trust. So what used to be the reason why they had this limitation of 128 megs is that they were using, I think, a Merkel tree under the hood to verify that whenever the memory pages were encrypted or decrypted in and out of the CPU registers, they were not modified from one use of the memory page to the other. So that's what I mean by memory integrity with this mechanism. What happens is that you start from this known initial state that is guaranteed by the remote attestation. And because you know that the execution cannot be tampered with, the memory cannot be modified by a malicious actor on the system, you know that you're going to go through all the way and obtain the result that you should obtain, regardless of where the application is running. So that kind of gives you similar feeling to what ZK proofs gives you, to what snark gives you this verifiability of the computation. But now that they've removed this memory integrity feature, because the key to unlock like larger enclaves was to remove the metal trees, which was like taking too much space, and maybe also introducing something other head, you can't really trust what's going on on the machine.
03:13:44.004 - 03:14:14.550, Speaker I: You don't know that, or at least I've not seen anything yet that says and maybe Andrew or Tom can chip in there if you've got more information than I do, but at least as far as I know, you can't really guarantee that the pages are not modified when they're not being processed by the CPU. So you've lost this memory integrity and by such you've lost the verifiable computation feature that the first version of SGX used to have.
03:14:16.600 - 03:15:11.300, Speaker C: Okay, understood. Well, maybe that's going to be the first question, the spicy SGX panel. Any other questions for Jonathan? Okay, it looks like we have no more further questions. Thank you so much Jonathan, for this thorough overview. And next we have the spicy SGX panel with Andrew. Jonathan, you're still with us and Phil. So I guess I'll just go ahead with the segue.
03:15:11.300 - 03:15:38.910, Speaker C: I guess the fact that we don't have this merkel tree kind of memory integrity with the new versions of SGX is that kind of a deal breaker almost for SUAV, whereby SUAV is meant to be reasonably decentralized and trustless. And now we're saying that the enclaves might need to be run in Google cloud or what is going on.
03:15:41.280 - 03:17:04.090, Speaker H: Mean, even if there's no integrity checks, it's possible to do mitigations from the applications that are using it, but that would require being very careful about it. And it's not really just integrity because if you could tamper with the memory while an enclave program is running, you could end up tampering with some access control things that it's doing. So it could affect privacy as well as integrity in that case too, but broadly that's something that can be mitigated. I mean your kind of line of defense would be to add your own integrity kind of checking from registers that don't get paged out. The kind of related question to this I kind of most was excited to respond to is about the kind of difference between the cloud use cases and the client use cases. So the client use cases are clearly being deprecated, no longer supported by, I mean the origin of SGX was like for Blu ray players and digital restrictions management anti user technology. So that was the first time when everyone began hating trusted platform modules richard Stallman would have huge rants about so like everyone hated trusted hardware know before then because of that really despicable use.
03:17:04.090 - 03:17:42.950, Speaker H: So I think good riddance to the client side SGX ones. The cloud services though are really getting a lot of use out of this and really want it. So I don't see that going away. Like Xeon processors are still going to be supporting SGX of some kind. They really need the integrity checks too. So that's not like a thing that's just not on their radar at all. And I think the real challenge is how the decentralized blockchain applications will be able to blend in with the cloud use cases and act like good customers and not do something that gets them cleft out from the kind of support that the cloud services get.
03:17:46.840 - 03:18:51.328, Speaker F: Yeah, I mean I do think in terms of like obviously any product change to intel SGX affects the plausible deployments. I will say Suave does not require perfect privacy or integrity necessarily the goal of using SGX and Suave is partially as defense in depth to iterate the status quo. It's not the same as, let's say using SGX for consensus or something like that, in that if you do manage to break SGX and perform any of these attacks you'll be able to kind of get an advantage in mev, which certainly might be profitable for a short term until people notice. But it's not really the same as having your secrets kind of permanently leaked to the world or your consensus protocol falling over and losing billions or something like that. I think this is part of the loss of subtlety in the SGX world is people love to have very binary views on SGX like either it's broken or not. Either it has integrity or it doesn't. Either you can use it or you can't, either it's applicable to blockchains or it isn't.
03:18:51.328 - 03:19:48.040, Speaker F: And to me there's a lot more subtlety in terms of what specifically are you using it for and does it kind of stand up to that use case. So a few things is like number one in terms of blockchains, I do think there are still blockchain use cases specifically in stopping a lot of these actors that maybe are a little bit stronger than honest but curious, like rational but curious actors from kind of having as much incentive to get an edge. And I think for that it actually could work really well. No matter even if the barrier is small, even if the Iterated game is messy, it still could work well and even if that kind of guarantee fails once in a while if a really kind of sophisticated attack gets pulled off. So that's my general answer for suave for all of this. Of course, as Jonathan said in his talk, we aren't like SGX maxis or anything. It's just part of defense in depth.
03:19:48.040 - 03:20:59.412, Speaker F: Would love to explore other tees, would also love to have know, although I think some separate spicy panel to be had there on the gap between kind of where we're at today and where we need to be to actually, in my opinion, be usable. So maybe I ranted too much, I guess. One more thing, andrew's question about how blockchain slips into the cloud, like I don't see why we wouldn't be able to do that. It seems like a lot of what people are looking at SGX for is like privacy preserving machine learning and things like that. There seems to be an analog in this real time financial optimization to cooperative AI, to privacy preserving AI, so you could possibly see all these use cases converging in some way. And also I think the nice thing about mev specifically is it's like a constant real time problem. So whereas a machine learning problem like Android keyswipes or signal contacts or whatever other machine learning problems you might have, you kind of do it once or do it a few times or once in a while here you have to be doing it constantly and the more computation you have, the more you're doing it.
03:20:59.412 - 03:21:10.570, Speaker F: So really intel should love that in my opinion, if their business is to sell hardware. So maybe that's how we slip in by just kind of making demand for their product real.
03:21:12.380 - 03:21:36.384, Speaker I: Yeah, that would be welcome, I guess, because I think one of the Pragmatic challenges as well is that it's pretty much only azure as of today that gives you all the flavors of it that you would like. So it's not great either for decentralization to just take it from the ends of intel to put in the hands.
03:21:36.422 - 03:21:37.010, Speaker H: Of.
03:21:39.540 - 03:21:42.156, Speaker F: Yeah, you did lag a little, Jonathan.
03:21:42.188 - 03:21:44.770, Speaker G: I don't know if it was just me, but I think.
03:21:46.740 - 03:21:48.660, Speaker F: I agree with the sentiment.
03:21:49.800 - 03:21:58.600, Speaker H: People are lazy and love clouds, but there's nothing stopping you from getting an Ikea rack and hosting your own Xeon processor. It's not like they're completely out of range.
03:22:00.620 - 03:22:59.060, Speaker F: Yeah, and if you're an Mev searcher and you want to do a lot of this local wide scale optimization. It seems reasonable to in the long term you're basically an infrastructure provider for crypto so having some server grade hardware seems reasonable to me. Again, not to say it's the ideal status quo where obviously we'd have magical encryption, but I think maybe this is another spicy take. It seems like all the alternatives to SGX introduce other gotchas for blockchains to me. So like MPC being the most practical example, MPC has scalability issues in the size of the committee. It has a really high bandwidth requirement and also it's much more efficient if you have low latency or if you can co locate. So all these to me seem to be equally bad to sometimes breaks if intel screws up and or someone spends like a few million on some really good PhDs.
03:22:59.060 - 03:23:01.690, Speaker F: But maybe I'm wrong, that's just my spicy take.
03:23:02.380 - 03:23:27.392, Speaker H: Robert covered a bunch of those in his talk. Some of those challenges with mean a lot of the most optimized ones. And this is kind of the thing that we found. We've been doing this Rattel project. There's a post about it that's like our MP speeds on uniswap kind of AMM. And it's an AMM because that's the most complicated thing. We can basically get to work that's practical with MP speeds, like a really simple operation.
03:23:27.392 - 03:24:06.400, Speaker H: And it was a challenge even to do that. And we wanted some notion of robustness, like availability. That's just what you expect with a blockchain system, but that's not the most desirable operating system. NPC people tend to prefer the maximum privacy and they'll have very systems that just topple over if any node fails. So all of the really hot interesting protocols where they're making the big speed improvements are mostly in the dishonest majority or N out of N sharing setting and then those just aren't applicable if you want something that kind of acts like a blockchain with its redundancy and fault tolerance.
03:24:07.300 - 03:24:35.800, Speaker C: On the topic of fault tolerance, I have a question for Phil about SUAV. Presumably there isn't like one master T that's running SUAV. There's some amount of redundancy and in that context if one of the tes is compromised and breaks privacy, how do you detect which and we observe front running happening, how do we narrow down who to kick out of the committee of te operators?
03:24:36.380 - 03:24:48.076, Speaker F: Yeah, so this is a great question and the truthful answer is we don't know yet. So we have kind of like the privacy abstraction for Suave and a few deployment scenarios with trade offs. I don't think we know exactly what.
03:24:48.098 - 03:24:48.764, Speaker G: We'Re going to go with.
03:24:48.802 - 03:25:33.768, Speaker F: So we'll probably have more kind of community conversations about what makes sense. There the trade off kind of being from more distribution but less attribution and wider attack surface to more centrality and or layering even reputation or committees that would in my opinion be bad, but we'll put it on the table. So these are the ranges of options you have on who to run it. Certainly one central party is not good, so we might as well just not. I mean, I guess it adds a little defense and depth to trusting Flash bots, but we definitely want more than one. And they should be like different economically kind of separate parties that provide competition and diversity. So that would be like the bare minimum.
03:25:33.768 - 03:25:48.976, Speaker F: Ideally we distribute it so everyone's phone runs a swap node and the whole thing is like this chaotic global process. Same with ETH, right? The dream is to have that phone validator and practically you probably land somewhere in the middle as you strive for.
03:25:48.998 - 03:25:50.480, Speaker G: That thing, I would imagine.
03:25:52.340 - 03:25:53.680, Speaker C: Okay, understood.
03:25:54.100 - 03:26:35.356, Speaker H: I really liked with Suave that Suave has this goal of using enclaves for this disintermediation goal. Like you really want to use it. You'll run this in order to prove to all the people that are using this system that you don't have the ability to tamper with it. I think that's really cool. That's kind of rare in the SGX, I think kind of application world. People seem to be really satisfied with just getting their own data results back and not trying to prove that they don't have these centralized controls left. It's just really cool to know that makes me think that the SGX based blockchains and you have that as a common goal and maybe some progress can get done.
03:26:35.356 - 03:27:19.608, Speaker H: I think no one's really done this kind of end to end job of looking at the entire chain of validation. You can't just say there is remote attestation. You have to have some process by which people in your community are actually looking at the remote Attestations for the sake of a spicy take here. The same issue is like with Arbitrum and other L two S. They're built around a very complicated audit protocol that handles the edge cases when something goes wrong and you need to process a fraud proof. But it's hard to go find visible examples of that and follow that process and see it working. That's something that's not unique to the SGX space, but that everyone should probably do a better job of validating their source code and publishing their transparency information where it's usable.
03:27:19.608 - 03:27:27.170, Speaker H: But it's especially needed for this use of SGX and maybe you'll solve these problems if you need them for Suave and everyone else can use them too.
03:27:28.580 - 03:27:59.780, Speaker F: I have a fun even spicier take, which is a little bit of a troll take, which is that luckily we have no on chain privacy in Ethereum. So you can also use funds flow to do a lot of your statistical analysis and stuff like that. That's how you back out. Centralized exchanges, cheating. So you would have these same tools in Mev land. Like if you were getting bad execution, you could see who sandwiched you on the chain or who was accessing. Perhaps in some cases it may be non Attributable and then you're really screwed.
03:27:59.780 - 03:28:06.380, Speaker F: But I don't know, in many cases you may be able to kind of divine misbehavior.
03:28:10.080 - 03:29:13.600, Speaker C: So my next question is around latency, and I have a personal story to share. So we recently launched the Ultrasound relay, which is this kind of non Censoring relay, and there's actually another non Censoring relay which was launched at the exact same time, the agnotic relay. And we basically have the same setup. We're running the flashbot code base and it turns out that for some reason that we're still investigating, we're simulating blocks roughly 200 milliseconds slower than Agnostic and these 200 milliseconds mean that we have roughly a two x penalty over Agnostic. So we're including on chain, we're winning the auction like half the time that we should be. And so my question is, if latency is just so important for MBV, how can SGX win? Because presumably there's some amount of performance overhead. Like maybe you can't do all the fancy overclocking and you can't get the latest and greatest CPUs and whatnot.
03:29:13.600 - 03:29:19.700, Speaker C: Yeah, I'm curious, how do you reconcile latency with SGX?
03:29:20.760 - 03:29:50.312, Speaker F: Yeah, that's a great question. Well, first of all, I'm very glad to have you in the relay game. So that's amazing. Thank you for running a relay. And I also think part of the challenge in the future is co designing the protocol parameters so you can do things that have somewhat of a latency penalty if they're considered qualitatively better. And maybe because of the way the timing is structured in the protocol or something, there's somewhat less of an impact. Obviously there will always be some edge to having higher latency.
03:29:50.312 - 03:30:53.728, Speaker F: That's not something we can just magic wand away completely. But yeah, so I would say number one, we should minimize the latency impact. Number two, we can lean on ways in which the decentralized tech is stronger to compensate for latency. So if you have this privacy kind of edge that allows you to optimize transactions better for users, and you can attract more economic activity, if you have ability to optimize cross domain, et cetera in a decentralized way, where people actually trust you to do this optimization, then maybe the latency penalty exists, but it's overcome by these other factors. So really look at what is the strengths of the decentralized thing and can we amplify those in enough of an edge to mitigate the latency penalty? Because the more decentralized you get also the more latency penalty. So SGX actually doesn't have that bad of a latency penalty, especially if you provide witnesses. You're basically just executing the EVM with really you can provide state witnesses, so.
03:30:53.734 - 03:30:54.416, Speaker G: You don't even need to do any.
03:30:54.438 - 03:31:47.750, Speaker F: Memory swaps in some cases. And that can have fairly low overhead. Like you said, you do lose overclocking and some other edge enhancements. I think that's within reason, there's already a lot of overhead in the building simulation process to kind of get this decentralization and get this merging of many different searchers from around the world with different edges into the most valuable block. So we're already kind of used to paying this latency for network effect penalty and I think SGX specifically is okay. I do worry as we push it more towards Fhe or something like that, or even if we want to do like we have some magic new NPC protocol with fairness that works and the latency penalty becomes bigger, we would still probably want to switch to that as a community. And how do we make sure that those systems stay competitive? I think that's like an L one design question also.
03:31:49.080 - 03:32:14.924, Speaker I: Yeah, I think there's two ways to see it as well. If ever one has to pay the same for peeling than creating like an edge to some of the users. So I think the most important thing is to make sure that if there is such a penalty, everyone should be in the same setting. And in the Esgx case, to answer.
03:32:14.962 - 03:32:15.790, Speaker E: Your question.
03:32:18.560 - 03:32:35.570, Speaker I: Things to be somehow again, as long as everyone is in the same setting, I think it's not such of an issue.
03:32:42.370 - 03:32:46.398, Speaker C: Yeah, Jonathan, your audio was a little shaky, but I guess what you yeah.
03:32:46.404 - 03:32:49.600, Speaker I: I'm sorry, my connection is like really bad.
03:32:49.970 - 03:33:36.670, Speaker C: No worries. But I guess what you're saying is that if everyone's paying this penalty, then everyone's kind of equal. But I guess what might happen is that we'll see maybe a centralized private mempool and then SUAV and then someone will do profit switching between the two and then the centralized one will just always win because it has not only maybe a lower latency penalty on SGX, but also it doesn't have to deal with the peer to peer gossip channels. Blah blah, blah. It's like straight end to end TCP connection from one point to another. But yeah, it will be. As you said, Phil, there's a trade off space and hopefully the forces lean towards decentralization.
03:33:37.490 - 03:33:58.486, Speaker F: I hope so. Side note, little known fact this is one of the reasons we run a centralized builder. So that A, we're forced to compete with ourselves and B, that if we do release something decentralized and we shut it down, it's kind of like a statement to the community on what we think the protocol should look like, even if there is a slight dip in.
03:33:58.508 - 03:34:00.120, Speaker G: Profitability for a while.
03:34:00.490 - 03:34:02.950, Speaker F: So that's one of the reasons.
03:34:06.350 - 03:34:20.670, Speaker C: So I guess my next question is around memes. SGX has this bad reputation which might be warranted or it might not be, but it's kind of there. Isn't that a tailwind for adoption?
03:34:22.450 - 03:34:24.014, Speaker H: Headwind. Sorry.
03:34:24.052 - 03:34:25.360, Speaker C: Headwind. Thank you.
03:34:29.290 - 03:34:31.046, Speaker F: Curious to hear Andrew's take on this.
03:34:31.068 - 03:35:20.440, Speaker H: And then I'll yeah, it is a it's it's weird. I mean, even in the research publication, it's a lot harder to get like a peer review paper accepted on SGX because there was a glut of papers that were really boring and just said, here's existing paper, we just forced it to run within SGX and didn't have so much else to say. So there's even just a headwind towards getting past that. I don't know, I mean it just seems weird to me. Clearly, it seems to me that there's more gut reaction like overvaluing the concerns about it, that it's far swung the other way. I hope it swings even more. I don't know if we're at the bottom of SGX negative sentiment, maybe we can go even further and catch the drop on the way.
03:35:20.440 - 03:35:48.000, Speaker H: Mean, my experience is that there's still just a ton of low hanging fruit of critical stuff to look at. So I get the sense that very few people are looking at this. I mean the ones who are get kind of diverted and turned off so quickly that they don't even get to the good bit. So you all are here. I'm glad to see that you all are working on it that way, so hopefully we can improve that all around. Yeah, it's absolutely like a negative sentiment but it's an opportunity too.
03:35:48.850 - 03:36:57.240, Speaker F: Yeah, I totally agree with that. And also Alex's points in the chat. I think the first crop of SGX companies were very much like OOH shiny new tech toy, let's just plaster this on to every single problem under the sun and try to raise money from our VCs which is like a common pattern in tech. It's like, okay, iPhone comes out with a new notification type, like what old UX patterns can we just plaster this onto and have a new fad? Basically it's like the same idea and I also think that turned a lot of people off, plus obviously there are some fundamental issues. It's the same thing as with crypto, right? There's a lot of people that think crypto is a scam and F, all this, it's just like all rug pulls and the tokens are not legit, they're all securities. Whatever other argument you might hear, they're all kind of true to an extent, right? Like all the arguments, they wouldn't be memes if they weren't at least a little true. The same way all the bad SGX takes and all those memes, they are a little true, but both things I think, lack nuance and so I'm glad that we're having this conversation and that there are people working on it because I think the next generation of companies is not like the shiny thing companies.
03:36:57.240 - 03:37:34.718, Speaker F: We have an actual need and we've gone down many paths and there's really no choice for this weird crypto intersection that's still better than something that's fully trusted. And I think in that niche there's actually a lot of practical gains to be made. Again, as a company, we're being very practical about this. We are an SGX company, our long term goal is to Sgxize the world. It's just like there's not really a choice. And yes, there's a major headwind that's also an opportunity because it. Means everyone else has the same headwind.
03:37:34.718 - 03:37:45.880, Speaker F: And if you're truly convinced that it's the right thing to do and you're correct and you pay the headwind, then that is what an opportunity is also. So I think it's both. Yeah, very excited about it.
03:37:47.210 - 03:38:31.206, Speaker H: I had a lot of fun talking with a bunch of people that you know when doing this kind of unsolicited audit of secret network. So, I mean, it was neat to talk to the Obscura folks. A bunch of projects are using enclaves that don't consider themselves smart contracts but middleware of some kind. So Falla is one of them. And it's a little confusing because even though they're middleware, they still are EVM compatible. That didn't make sense to me until Suave is like that, it's not to be a competing blockchain, but it is EVM and running in enclaves for something else. So they're doing something and the guy from Automata network, automata is another middleware one, but they aren't I don't think they have open source code, but maybe could be talked into it.
03:38:31.206 - 03:38:35.510, Speaker H: So yeah, maybe invite all of them to another roast.
03:38:37.930 - 03:38:52.620, Speaker I: It's probably the best way to go against the headwind is to keep on doing everything in the open. Transparent Edents making shelf position is well known and being the first critics of our own design choices, I think.
03:38:59.340 - 03:38:59.704, Speaker G: Your.
03:38:59.742 - 03:39:03.210, Speaker F: Audio is amazing now, by the way, Jonathan. So whatever you did worked.
03:39:05.980 - 03:39:30.930, Speaker C: So I guess my next question is just trying to assume the worst case, as Andrew put it, which is that what if there's a vulnerability that makes all the Attestation keys leak so that there's just no security guarantees anymore from SGX? What would be the plan for Surav? Is it that you fall back to the current model? I guess?
03:39:31.300 - 03:39:57.220, Speaker F: And does it mean that you kind of yeah, sorry. So yeah, I think there's a few options that are really practical from today. You kind of summarize them. There's like decentralized. That's what we have with Flashbots and Flashbots protect. Now then there's committee based, you could call this like the chain link ish trust assumption, something like that. You can layer on some staking and call it decentralized.
03:39:57.220 - 03:40:28.304, Speaker F: Also you can possibly reuse the ETH validator set these are all like ideas in that camp. And build some sort of committee where you have some protocol that aggregates multiple semi trusted kind of inputs into an oracle. You could also do privacy that way, certainly either trusting the kind of or of all the people you choose to trust and optimizing their intersection. That's very easy. Or you can use MPC to trust the and I don't know if I.
03:40:28.342 - 03:40:29.156, Speaker G: Reversed those or not.
03:40:29.178 - 03:41:22.036, Speaker F: I think it's right. So those are like kind of the levels and so yeah, we'll have to probably kind of go to one of those options. So probably ultimately the system will be some will be configured to allow you to fall back to this if SGX is broken. It would be sad, though I'm very bearish on committees and this is why I think SGX is the only choice, just for the reason that in mev, given that the breaks aren't falsifiable and the incentives are so high and there's a kind of positive incentive boost from being on this committee if you're also a searcher or a builder. That to me makes me very bearish on those trust assumptions actually holding, especially under stress. So that's why we think SGX can maybe patch over that like paper machete over that a little bit. And so I would be sad if.
03:41:22.058 - 03:41:24.310, Speaker G: We had to fall back to that, I guess.
03:41:24.920 - 03:42:43.970, Speaker I: I think that there's a very interesting assumption in what you've been saying, SIL, is that we are able to identify this new vulnerability and act accordingly. And I think that's what happened up until now in SGX, right, it's mostly been academic or white hat hackers like Andrew's papers that went through the process of disclosing the vulnerability to intel so that they could act accordingly, even though we can debate the update process afterwards. What's maybe more interesting, and I'm not saying I've got an answer to that, is that if the stake became so large that some people do not have the incentive anymore to go through this process, but on the other hand, to try and exploit these new vulnerabilities that they've discovered, then we could be in trouble. Because then you have this asymmetry again between users that exploit and users that pay the penalty, basically. And I think again to lean back to your paper, it's kind of like interesting to see and try to coast how much it would be to mount such attacks. I think that would be a very interesting line of research to try and estimate the cost of breaking this and this aspect of the technology.
03:42:46.900 - 03:43:04.564, Speaker F: Yeah, I've always said that that's what's like a few years ago, that that's what's missing from this whole SGX conversation. We don't understand the economics of all exploits. It really depends on the marginal cost to break additional chips like whether SGX can be secure at all. Is that zero for all exploits or no?
03:43:04.682 - 03:43:05.076, Speaker G: I don't know.
03:43:05.098 - 03:43:11.668, Speaker F: Maybe you know if anyone's done research in this, Andrew or Jonathan, but I'm not at least aware of any, it's.
03:43:11.684 - 03:44:14.556, Speaker H: Not really my area, but I'm a fanboy of all the people that do this vulnerability research at that level. Have you seen this on YouTube? From Linus tech tips on a tour of the intel debug lab. Debug Lab is like the spookiest phrase in the context of SGX because what Debug Lab means is they have a big laser thing that'll burn off the top of a production chip. It turns a production intel processor into an FPGA. They can rewire the logic of the chip by beaming it with powerful lasers in their Debug Lab and they gave this little tour of it to a famous YouTuber and it's nice to put like a picture of it to the myth, it must exist myth, but that's what it looks like. That doesn't answer the economics question. I've heard people say things like $100,000 is what it would cost to get access to that, or the one place in University of Florida that can do it, or something like that.
03:44:14.556 - 03:44:21.420, Speaker H: So I don't know the details should definitely we should be trying to find those because that would fit into this kind of analysis.
03:44:23.920 - 03:44:24.284, Speaker I: Yeah.
03:44:24.322 - 03:44:45.828, Speaker F: I will say our one leverage point here is a lot of this can be punted to intel. So they have PR skin in the game. Not that we should and we shouldn't answer these questions, but they also have skin in the game. And if someone does build a secret SGX lab to break mev and they succeed, intel's PR is on the line as well. So presumably, you know, we can I.
03:44:45.834 - 03:45:32.740, Speaker H: Think the relationship between the crypto community, including Y'all, and the blockchains that are doing this, I think should try to present like a united lobbying block to intel. So I mean, one of the lessons in the SGX fail paper which like Daniel and Christina and others have been kind of tracing down this for a much longer time it's a much broader point than just the blockchain setting, but no one understands TCB recovery that well. None of the relationships and things that you do afterwards, what it takes to get early notification or not, are so clear. So I don't know. My guess is that it's possible to do a better job negotiating and informing this relationship with intel by acting as a cohesive community rather than just one off startup projects.
03:45:36.610 - 03:45:53.090, Speaker C: One of the things that struck me when you guys gave answers is that you didn't mention AMD SUV as a potential replacement for SGX. If SGX is completely broken, does it mean that SUV is maybe not appropriate for SUAV.
03:45:54.790 - 03:46:49.160, Speaker I: If and Fret model? Well, first of all, I think that the TCB is much larger so that's like, regardless of the properties of the hardware itself, the question is whether you want to trust a relatively small application enclave size or whether you want to trust a whole virtual machine that there's absolutely no loopholes that could be exploited in there. And I guess maybe we should not address all of these technologies under the same name. I'm not very happy about everything falling under the Te name. I think a lot of these techs are now becoming just like confidential virtual machines and we should clearly make the distinction between them too. It doesn't mean that it's bad fundamentally, but it's like we should not expect the same behavior and security properties from two different technologies basically.
03:46:50.490 - 03:47:13.040, Speaker F: Yeah, I would say that being said, it could iterate into something useful like if they see a market demand and I'm not fully bearish on AMD or any other tees it would be great to have more diversity. If we had multiple solutions that worked for the threat model, maybe we could come up with a protocol that you need to break both to get anywhere, and that would be nice.
03:47:14.050 - 03:47:14.510, Speaker G: Certainly.
03:47:14.580 - 03:48:13.090, Speaker F: I think in the same vein as the ASIC for any delay encryption function that EF may do, like maybe one day the EF or other crypto companies together build a tee that's like open source. If this actually does end up becoming critical infrastructure that we can't replace and the other avenues don't pan out. So these are all like yes, they're all kind of like on the research radar, but I think, as Jonathan said today, less attractive for various reasons. Although we have talked to some people recently who are bullish on AMD, kind of eventually being enough for this use case. You could also maybe even jury rig like the iPhone Tees plus Apple's authenticity check. If you do a network that has enough attestations for your economic security, maybe you could get security out of that. I don't know, but yeah, things to think about, but I think less immediately, obviously applicable than SGX.
03:48:16.310 - 03:48:25.010, Speaker C: Guys, thank you so much for your time. I think we're an hour and ten minutes over, so it may be time to wrap up. Thank you so much to all this.
03:48:25.160 - 03:48:27.234, Speaker H: Thank you all. Yeah.
03:48:27.272 - 03:48:28.366, Speaker G: Thank you. Thank you, Justin.
03:48:28.398 - 03:48:28.754, Speaker I: Thanks everyone.
03:48:28.792 - 03:48:31.490, Speaker F: That was spicy moderation.
03:48:31.830 - 03:48:32.900, Speaker G: Thanks everyone.
03:48:33.590 - 03:48:34.900, Speaker E: That was really great.
03:48:36.030 - 03:48:39.740, Speaker B: Thank you, Justin, to our tireless roastmaster. That was awesome.
03:48:41.070 - 03:48:42.890, Speaker C: Thanks Sarah, for organizing.
03:48:44.910 - 03:48:46.058, Speaker G: Thank you both.
03:48:46.224 - 03:48:48.870, Speaker F: See everyone later, you guys. Bye.

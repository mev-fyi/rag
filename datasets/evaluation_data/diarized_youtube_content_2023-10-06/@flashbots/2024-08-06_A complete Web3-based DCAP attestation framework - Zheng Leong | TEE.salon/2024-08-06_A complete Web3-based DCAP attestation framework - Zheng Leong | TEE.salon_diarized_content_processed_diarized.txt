00:00:03.440 - 00:01:42.930, Speaker A: I don't think intel as Jensen was out there, but we were kind of like playing around with how can we actually have like trusted execution environments, like the social execution environment where you can run certain modules, we can integrity and confidentiality. So that's, that's like more than ten years ago. So basically today the presentation that I'm giving is how to share a little bit about our work on how we can have a web3 days. I think Andrew made a really good presentation just now on like what DCAP is about how right now all the way decap is voiced because intel provider asks all the tools when we get remove intel from the enterprise attestation workflow and in this presentation I will share how we program. So I think the first thing that we need, if we think about like attestation, there's actually two portion of it, right? One of it is the verifier and the other one is the verifier of course is the one that verifies the report cooked and produce a result. Whether genuine, is it trusted, and the other portion is actually the infrastructure that surrounds it. So the first thing, let's say, if you want to do verification of the decap attestation, say on the tube or any of the EVM chips, then we make a solidity based verified.
00:01:42.930 - 00:03:01.148, Speaker A: And so we actually wrote a on chain verify for automata. I know it's a very boring name, but I'm really bad at it. So this would have been good. So what it does is we implemented all the logic of report verification on chain. Of course, the assumption is that during the generation of the report, the collaterals are actually available to the users and any missing collateral actually have to be placed onto the contract itself. So what we have is actually, we have a structure like that where each individual project who wants to perform such an, actually choose to clone one of our, clone our raffle, deploy it on chain and provision certain configuration like the application hash, the MRN wave, the developer signkey, which is the Mr. Signer, and stuff like tcpinfo that Andrew mentioned about the collateral intermediary search, the person that is deploying the contract will have to actually perform all.
00:03:01.148 - 00:03:46.916, Speaker A: And if you think about it, there's actually like, there's no check because the owner is the one that is actually provisioning all these collect rooms. So this is actually what we have now. But we can quite realize that it's a bit problematic because the thing about Webtree is that it should be like open and then composed. And this isn't really very composed each time someone wants to do something new, upgrade the software, or I rely on something, they have to do. This whole process and the collateral aren't checked. So if I have a machine and I participate in like two different, I run two different enclaves on my machine, then I have to attach myself to two different contractors. This is not very useful.
00:03:46.916 - 00:04:48.630, Speaker A: So like, how can we make it better? Well, the thing is, we first need to understand like what we mean by verifying. There's actually two portions. The first, we can kind of like break it down into two portions where the first part is, we verify that the report itself is genuine and authentic. That means we can trust the content of the report. And subsequently, based on the content of the report, we can have certain so called business logic to determine what we want to do with the report. So for example, in terms of verifying the identity of the application, the NCAA application, we can say that, hey, we first ensure that this report indeed comes from a genuine intel SGX or TDX machine. Then once we have verified that this report is January, then we can do things like, let's check the hash of the enclave, let's check the TCB, so on and so on.
00:04:48.630 - 00:05:51.250, Speaker A: So if you kind of like think of it this way, then we can have a much simpler, instead of one single verified interface, where we written the, you can break it down into two interfaces. One of it is to actually verify the code. And once the code is verified, you expect like important information contact. And this content, this verified result would then be used by downstream processors to actually obtain the result of whether this is indeed the enclave that I want. So I mean, with that, you can come up with this like verify the test with a code. And what we have is actually, instead of having multiple contracts, we can have one single verifiable contract that is important on any chain that wants to support like VCAM verification. The code can then be sent on chain.
00:05:51.250 - 00:06:33.750, Speaker A: That single contract would collect all the different collectibles that we can find, like the TCefo and the certificates. And then the results of this contract will then be used by all the different downstream use. So for example, for automata, we have our one RPC endpoint that uses HX and flip. So we can say that there's this particular MRI flake that we are interested in, and it's going to verify it. And flashbots might have a zero, what's it called? MRNA. Similarly, they can do their own verification all. But we can share this single verifying then.
00:06:33.750 - 00:07:55.890, Speaker A: Yeah, that's great rating, right? But then like on trade verification is really expensive, but it actually may be cheaper. Like in order for us to verify a single code, it takes about 3 million. Yes, I mean that's, it's doable, but it's really expensive. So the thought of us is that can we actually make it cheaper by offloading the computation off chain compute platform? And then the computation is then verified using a succulent approach. So, and what do we know previously when we break out that verified Boolean? If we originally keep it as a symbol like verify and return Boolean, every time we have a new MRN tape we need to write a new signal. But since we have already separated out like the verification portion and the business logic, now we can actually have like kind of like a common interface where you can have verified as on chain if you want to perform everything on chain or if you want to make use of CPA. And the output of these two interface would be the same verified output that the downstream applications can use.
00:07:55.890 - 00:09:13.560, Speaker A: So kind of add into the overall architecture from the CKP and then, so Andrew actually mentioned something that is during the code generation process, the engine that you need to contact this software called pcCs. Now the thing is, the PCCs by default actually fetches the information from Intel's PCs, which is the kind of source of the information. But the thing is, not all collateral can actually be found on. If you are working with like cloud providers, like you're running Srecs or TBX or Azure for example, then the collector roles for those machines, you will actually find them on Intel's PCs. Rather you'll find them on Azure's own PCs servers. So depending on what kind of hardware and where you're running them, you actually need to go to different places to look for your collections. Can we do better? Of course we can.
00:09:13.560 - 00:10:38.104, Speaker A: Like what every measure can put it onto the blockchain. And this is exactly what we did. So what we did is we wrote code provider library. So when the enclave, when they actually wants to generate code, generate a report, what it does is you contact this library that's in stock as part of your SGX setup, and this code like you would be the one that's responsible to fetch it, to fetch the collateral from the pccs. So what we did was to actually write a decap code provider library that would fetch the corresponding collateral instead of PCs actually from a on chain contract, and on the on chain contract, we actually implemented the full schema for the pccs. So basically it's a one to one ranking of the PCCs schema so we have stuff like PCK Dao, TCP Dao, so on and so forth. And basically what we have there now is that we have a total attestation framework where on chain we have a database of all the different collaterals.
00:10:38.104 - 00:11:29.530, Speaker A: And when we want to upset a particular collateral, you will just perform the corresponding check that a standard tccs would do to ensure that the searching is being signed. Similarly for TCP info, and all this information is read by the, the, we can call it web3 plus. And the nicest part of it is that now our verifier don't have to maintain the collateral anymore. The verifier itself can actually read on chain from the on chain pccs, obtain the collaterals and then verify it. And this actually allows us to do more interesting things. Instead of including the collateral as part of the. Your code now can actually be generated offline without any Internet access.
00:11:29.530 - 00:12:15.834, Speaker A: So your offline, what's it called, enclave, can generate a code. We will take this code and then just directly verify it online. And because we have on chain qccs, the verifier is able to actually fetch the collaterals totally on chain without the need to access any like extrinsic external sources in Croatia. So finally, we have an architecture, something like this. We have a verifier that talks to the on chain tccs, that contains the collateral accepts like on chain verification, or off chain verification of the code and downstream kind of like applications can use of it. So. Oh, okay.
00:12:15.834 - 00:13:05.204, Speaker A: So basically that's the end. What we have done is currently the open source version of our station contract is actually for V three Intel SReC. We have actually implemented the version four of the code, which includes TBX verification also. And all of this is also kind of like combined with the ZK proof portion of it means you can actually verify the attestation of chain. And this is done via risk zero. And the on chain portion of it is actually pccs. Now the thing about the pccs is that we need help to actually kind of like populate the pccs.
00:13:05.204 - 00:14:01.840, Speaker A: It is a caching service. So the way how it works out is that if that is a code that has missing collaterals, we would actually push the collaterals on chip. But I actually opened this up to everyone in this room. I hope we can kind of have web3 banking pccs and you can keep that pccs service as updated as possible. And this way anyone who needs to use this pccs service can now just rely on this. And there's no need for us to like require our enclave or our operators to run like custom tccs servers, register with intel to get an API to find out whether we need to register again with Azure to have a separate like tcs from Azure or with GCP. So that's about it.
00:14:01.840 - 00:15:21.590, Speaker A: And then what we'll do is I'm continuing to reorder programming because I know that there's some interesting funding. Yeah, so quick question. In my fraction, the collateral would be very huge. For example, for every like batch of cpu they would have their own collateral. So I have the impression, but maybe I'm wrong. So basically for every like a few countries, a few thousand cpu, they're going to be their own classroom. So have you like measured how much it will be and if you put all of them on blockchain how much like storage it will occupy? So this is an interesting question.
00:15:21.590 - 00:16:06.754, Speaker A: We have actually measured it. Typically for most sub chain it will be about 1. Now the thing is actually a lot of the intermediate certificates are replicated. So you have a PC caser and then you have an intermediate cell that signs the PC caser. So the intermediate is actually the same for nearly all the different leaf pieces. But I don't think that would be a big problem, especially if we do it in a distributed manner. And then whenever we need it we will push the search information on ship.
00:16:06.754 - 00:16:29.290, Speaker A: So yeah, we are actually using it ourselves now for the verification of the machines that. So probably it will also be some kind of cash because the cash flows will also like fabricate over the time. Yes, correct. That's why there's a need to actually maintain this cash coke test.

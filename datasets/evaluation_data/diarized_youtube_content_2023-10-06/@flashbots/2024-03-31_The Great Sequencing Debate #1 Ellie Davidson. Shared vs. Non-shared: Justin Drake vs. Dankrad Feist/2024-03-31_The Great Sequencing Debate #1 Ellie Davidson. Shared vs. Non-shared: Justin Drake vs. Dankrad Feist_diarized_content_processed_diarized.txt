00:00:02.440 - 00:00:28.280, Speaker A: All right, so we're going to have two debates. The first one will be shared sequencing or not shared sequencing. The actual question is a little bit more nuanced than that. And then the second one is going to be based sequencing or non based sequencing. Okay, so I'm just going to give a frame of the first debate. So shared versus non shared sequencing. Okay, so a lot of this is kind of similar to the things I mentioned earlier in my talk and that were mentioned earlier in other talks.
00:00:28.280 - 00:00:54.672, Speaker A: So we have non shared sequencing. Each roll up has its own isolated protocol that determines the sequence of all the roll up transactions. This is the state of l two sequencing today. And then we have shared sequencing, which consists of two main parts. The first part is a proposer assignment mechanism. So this is what determines the set of proposers for the next roll of blocks. Usually this is just one proposer.
00:00:54.672 - 00:01:27.234, Speaker A: You think in the vanilla based sequencing, this proposer is the l one proposer. It's just one proposer that proposes for all rollups. But this could be some set of multiple proposers. But the point is that all the roll ups agree and they use the same proposal mechanism. The second property is some finality gadget. So this finality gadget would finalize all of the proposed roll up blocks, and it provides a confirmation to users that this is, in fact, finalized. So these two properties are completely separate.
00:01:27.234 - 00:02:12.794, Speaker A: You could, they're very separate, but there is a lot of benefit in sharing them. So, for example, if rollups use the same proposer assignment, but they have different finality gadgets, that's kind of hard then, to reason about your interoperability, because one is final under some set of conditions and another roll up is final under another set of conditions. So the finality gadget is the base. Finality gadget is always ethereum for all of the l one rollups. But you can imagine maybe another case where roll ups share kind of this layer 1.5, which is a fast finality gadget that can come to finality a lot faster than ethereum comes to finality. But then again, everything is eventually settled to ethereum.
00:02:12.794 - 00:03:17.412, Speaker A: So, uh, here's a few examples of what a shared proposer assignment is. So, as I said, um, you have, um, I'll start with the OG based sequencing, which is where your shared proposer is, the l one proposer. This is probably what's most familiar to most people. Um, you can also have a fixed shared proposer set, which is basically some set that you, you know, go through, round robin, et cetera. Um, and then you can have a dynamic auction, which is what I mentioned earlier, where you dynamically choose an electric the proposers. So the question for this debate, which is the more nuanced version, is, is it desirable to have a future where you have global shared sequencing, where ethereum, l one, and virtually all the roll up blocks are sequenced by the same entity within one slot? So the question is this a desirable future? And note that this question is separate from the question of is there value in sharing a finality gadget? So that's out of scope for this. Um, so this question was modified at the very last second.
00:03:17.412 - 00:03:54.168, Speaker A: So uh, here's some common arguments. They might not match up quite with the question, but I think that they're still useful for us to talk about. So, common arguments for sharing a proposer assignment. So one is that you optimize for cross domain user intents. Uh, if you have a shared proposer assignment, um, you can agree to have shared proposers and do these cross chain arbitrages, etcetera. Um, another argument is that if you combine it with real time proving, this enables trustless synchronous composability, which is very important. Um, you can actually get this without real time proving, uh, using something like polygons ag layer.
00:03:54.168 - 00:04:51.346, Speaker A: Um, but you know, if you have this shared proposer assignment, you can enable this like trustless synchronous composability. And then finally, um, you can say that, well, if you don't have shared sequencing, parties are going to try to be shared sequencers anyway, because there's value in sequencing for more than one roll up at a time. So, you know, you might argue that shared sequencing is kind of the inevitable end end goal. So some common arguments against a shared proposer assignment is that it's not optimized for front running protection. So if the shared proposer isn't trusted or, you know, they aren't randomly elected, or you don't have some sort of mechanism to prevent this, the shared proposer is going to have maximum rent seeking behavior. And maybe that's not what rollup rollups one, the second thing is that it might create bottlenecks that reduce performance on the l two. So yes, cross chain transactions are great, but you might say the amount of cross chain transactions are very small compared to just the individual roll up transactions.
00:04:51.346 - 00:05:35.174, Speaker A: And maybe having this shared proposer is going to create bottlenecks because you're trying to have all of these l two state combined when a lot of it actually does not need to be combined because it's completely logically separated. You could also argue that some roll ups simply don't benefit from it. Um, you could argue maybe some roll ups, maybe you have like some sort of a gaming chain that really, it doesn't have a lot of use for cross chain transactions. Um, and if it does have use for them, they really don't need to be atomically executed. That's also an argument. Um, and then finally you could argue that, you know, well, roll ups want to keep their mev, so if they have this like shared proposer assignment, they might lose their mev. Although this was addressed in my earlier talk.
00:05:35.174 - 00:06:19.364, Speaker A: Yeah. So that is, I'll go back to the question. So the question is, is it a desirable future to have global shared sequencing where you have one entity that is sequencing for both Ethereum and almost all of the roll up blocks within one slot? All right, I guess now it's time for the debate. So we're going to have Justin go first with his opening remarks in. Yeah, I guess in favor of this question. So I'll hand it over to Justin.
00:06:20.784 - 00:06:56.504, Speaker B: Okay, great. So I guess one point here is around understanding the benefits and the cost. Like in terms of the benefits, I see shared liquidity as being something that users will want. I also see shared preconfirmations as something users will want. Imagine that you have a complex application, for example, a marketplace which involves identity. It involves an escrow agent, an insurance mechanism, it involves reputation. And all of these things live in different execution environments.
00:06:56.504 - 00:07:32.994, Speaker B: Now if I want to make a complex transaction, I have to interface with all these different counterparties. And basically your UX falls to the weakest link, whoever is the slowest, to provide you a preconfirmation. That's going to be your pre conformation latency. If one of them rugs you, then now your whole transaction has to reverse because you want everything to go through or none of it to go through. So I think there's going to be market demand for this synchronous composability. And in some sense we can't avoid it. It's going to happen, whatever, in all futures.
00:07:32.994 - 00:08:41.391, Speaker B: Now, one of the things you can try and do is fight it, where you basically give sequencing and pre conformation rights to independent parties. But what I expect will happen there is actually even more complexity. And basically the sequencing, the shared sequencing layer will be built on top of it. So you can imagine off chain markets and very fancy, maybe suave based markets that aggregate and allow for each individual proposer to delegate their sequencing rights to this mega sequencer. And so in some sense, what shared sequencing is all about is minimizing the costs of shared sequencing, which is complexity and sophistication, all while still giving to users what they want, which is the synchronous composability. Now, talking to Dankrat just a few minutes ago, my understanding is that he wants to try and minimize the cost of builder centralization. And one of the things that he'd like to see is basically homogeneous virtual machines.
00:08:41.391 - 00:09:23.034, Speaker B: So if I want to build a shared sequencer, I basically need to specialize in one virtual machine, as opposed to 100 virtual machines. And I think there is merit to this, and I think we are going to see a parallel distribution of virtual machines. But I still think that we are going to see application specific virtual machines that specialize in gaming or auctions or dexs or liquidations or whatever it is. In some sense, if we want to see this long tail thrive, we don't want them to be isolated as islands, because if they're isolated, then, now they're not connected to the rest of the economy, and it's much harder for them to survive. And so in some sense, shared sequencing allows for a thriving and diverse long tail.
00:09:24.934 - 00:09:28.302, Speaker A: All right, the rebuttal, right.
00:09:28.398 - 00:10:41.434, Speaker C: So I think, like the potential ux advantages of shared sequencing do exist, I think there's a debate to be had about how big they are going to be, because right now a lot of crypto users are degen power users, defi traders, and so on, and they benefit a lot from atomic composability. I think with the roll up system, we will see an ecosystem emerge that will have a lot more applications. Applications will probably congregate around certain roll ups, and they will have most of what they need on one roll up, rather than being distributed across several different ones that have to be composed atomically. I think that's not a practical future, even in a highly shared sequencing world, because there will be large costs to it. I believe that that is actually what a roll up will ultimately aim for. Each roll up will develop its own ecosystem that has some independence of the general ethereum ecosystem. But there are undeniable UX advantages.
00:10:41.434 - 00:11:18.048, Speaker C: The problem with shared sequencing is I see it as potentially the biggest centralization risks that exists in ethereum if we act, especially if we actively try to work towards such a future. Centralization can come from many different layers. We know that by now. It can come from the staking layer, it can come from the builder layer, which we're seeing to some extent, relay layer. It can come from, I don't know. It can even come from the application layer. If one application takes over most of activity on Ethereum, it's also a centralization risk.
00:11:18.048 - 00:12:12.046, Speaker C: And I think the problem that I see with these shared sequences is we are through the back door building a component into Ethereum that comes with a very high concentration risk. And the concentration risk is because the cost of market entry is going to be very high. My problem is that someone has to build a piece of infrastructure that potentially interacts with hundreds of different roll ups, each with their own, not just virtual machine, but systems, different smart contracts and so on. This is going to be a highly sophisticated, not just piece of hardware. I think that part is almost trivial, but even that's going to cost millions, but it's going to be proprietary software, because once you build that, there's no interest in putting that into open source. And we don't control it like we cannot design for it because it happens organically. This just happens.
00:12:12.046 - 00:12:20.214, Speaker C: And so we're going to have a big problem that, like, there will be very few of these and they will essentially be in control of, like the Ethereum roll up ecosystem system.
00:12:21.794 - 00:12:24.534, Speaker A: All right, Justin, your rebuttal?
00:12:26.034 - 00:13:21.812, Speaker B: Right, so I guess one rebuttal is that if there's going to be a very long tail of virtual machines, we're going to see many builders specialized for each individual virtual machine, and that's basically going to be searchers. So what is a layer one searcher? Behind the scenes will be a L2 builder. So basically, builders today, you can think of them as being centralized, like Beaver is very scary. They have the blocks. But actually behind the scenes there's dozens of entities, which are called searches, that do provide some amount of decentralization and robustness there. And if you do want to compete as a smaller actor, well, just start as a searcher and specialize in that specific virtual machine. The other thing I'll say is that centralization in some sense is inevitable.
00:13:21.812 - 00:14:08.766, Speaker B: And the best you can do is segregate the validators from the sophistication. And we have proposed a builder separation, which is what it's all about. And we want to make sure that the builders, even if there's two or three builders that they can't censor, they can't cause liveness failures, they can't cause safety failures, they can't do front running, they can't do all of the bad things. And in some sense, once we've really cleanly separated things out, then the last thing that remains is mimetic downsides. It's just a bad look. If Citadel were to build 90% of the blocks, but fundamentally is maybe not so bad. And so what I would push for is a few things.
00:14:08.766 - 00:14:45.134, Speaker B: One is like really making PBS more robust. So that means like making the decoupling between the validators and the sequencing even stronger. And like the best design that we have here is called execution tickets, where as a validator, I'm no longer given sequencing rights. I only have two rights, attester rights and inclusion rights in the context of inclusion lists. So I still contribute to consensus and finality. I still contribute to censorship resistance with inclusions, but I don't have these sequencing rights and transaction ordering rights. Instead, that's given to a sophisticated entity.
00:14:45.134 - 00:15:11.954, Speaker B: And then the other thing we should do is take the l one sequencer or infrastructure and make it as robust as we can. So we have inclusion lists, we have encrypted mempools, and all of these things make it so that even in the worst case, and sometimes we need to think adversarially, like, let's just assume the worst case, let's assume there's one mega builder. Like even in that case, we want Ethereum to be world war three resistant.
00:15:15.134 - 00:15:18.234, Speaker A: You have about two and a half minutes left. Do you have anything you want to add?
00:15:18.814 - 00:15:19.714, Speaker B: Okay.
00:15:23.214 - 00:15:23.954, Speaker C: So.
00:15:26.494 - 00:16:14.250, Speaker B: One of the things that we were talking about bankrupt just a few minutes ago is, okay, it's less about a binary thing, like is shared sequencing good or bad? It's more about the subtleties and nuances of what is the barrier to entry, to become a builder. And one of the ideas that was put forward is homogeneity of the virtual machine. And I think this is something that we're going to move to eventually. So there's this idea of a native roll up, which used to be called an enshrined roll up. What is a native roll up? It's one that natively reuses the EVM. So today, if you're an EVM roll up, you're not native in the sense that you're trying your best to be EVM equivalent. But more likely than not, you're not.
00:16:14.250 - 00:17:08.236, Speaker B: You're going to have bugs, you're going to make trade offs for performance, you're going to have all sorts of things. And so one of the things that we're working on is basically exposing this ZKEVM precompile. That means that rollups can natively use the EVM, and if that precompile catches on, then we can expect homogeneity, and that's one way to think about it is execution sharding. But execution sharding, as designed a few years ago, was very opinionated. We had 64 shards, or 1024 shards, and they were each exactly the same, and they were each maximizing, enshrined and native. But with this precompile, we actually bring back the programmability of Ethereum in the sense that it's just a precompile. And if you want to have a wrapper around it, if you want to have tokenomics, if you want to have public goods funding, if you want to have governance around it, you can do that.
00:17:08.236 - 00:17:57.524, Speaker B: You can have your own brand, your own community, your own ecosystem, and still benefit from the perfect equivalence to the EVM. Because literally you're using the EVM natively, you don't have bugs, because bugs now are the responsibility of the l one and the l zero. And you also don't need governance for your virtual machine because you're in a position where every time the EVM changes rules, which is to say every time we have a hard fork at layer one, the opcode or the precompile kind of magically upgrades. And so we're the future, I think, will be very clean and more homogeneous. And we're in this temporary, awkward phase, puberty phase, I guess, but it's something that we need to go through in order to reach adulthood.
00:17:58.344 - 00:18:02.244, Speaker A: Awesome. Thank you. Dinkran. What about your rebuttal?
00:18:03.024 - 00:19:22.474, Speaker C: Yes, so I think I'm going to reply to three different points that were made. So I think the first one was the question of, oh, can we just, like, is it okay, like, are these builders actually that complex because they can outsource some of the process to searchers? So I think to me, the core argument that I feel Justin makes about shared sequencing is that it provides this global composability. I think if you want that, if that is what you believe it will provide, it effectively means there has to be at least someone out there who simulates this altogether. So even if you have individual searches somewhere, their software effectively will need to run in that big piece that simulates everything and figures out how it all fits together. Otherwise you're not going to get composability. So I don't think that this effectively, like, totally, it might happen if there's some very specialized thing, but as soon as that becomes interesting enough for the global composability, it will have to be run in the global sequencer with a global prover and so on. So I think, like, this concentration risk is not remedied by that.
00:19:22.474 - 00:20:04.256, Speaker C: In terms of how okay the central party is, I think like the argument that Justin is making here is that we can contain everything, like all the downside that this brings by adding more consensus gadgets, say for example inclusion lists and so on. And in the end it will be perfectly acceptable to have this. I do not believe that this is true. And the reason is this. Let's even assume that, let's say there's only one party, there's only a citadel doing it. They will still as a minimum have the power to stop their sequence. This is one thing that you cannot stop.
00:20:04.256 - 00:20:53.966, Speaker C: They can always turn it off. So this will give them some power. In the case where, say, they don't do this too often, they only do this once every few months or so, but exactly when it gives them a super beneficial trade. I think there's still a big problem here that that creates more centralization and that basically allows someone to exploit disadvantages. But I think they get even more power than that. They get the power to use this power that they have to switch it off to hold the rest of Ethereum hostage. They can now start making deals with validators about, well, I mean, if you do x, if you put this transaction in the inclusion list, then it's going to be switched off.
00:20:53.966 - 00:21:51.934, Speaker C: So they're going to be like secondary effects. If you have too much concentration, at some point you're going to get these effects where someone can hold the whole of Ethereum hostage for their benefits. And the only way to not have this, in my opinion, is to have, yes, I'm relatively okay with having some, some relatively large parties doing things, but there needs to be easy replaceability, like it needs to be possible on a relatively short timescale with a limited investment to replace all the centralized party that the protocol depends on. Because yes, the natural equilibrium for many of these is going to be to have something like three to five or something. I think that's an acceptable thing to have like three to five parties who are most of the time running sequencing. As long as once they start colluding, we can have someone else who stepping in and replaces them and there's not going to be a huge downside. And the damage they can do is very limited.
00:21:51.934 - 00:22:37.792, Speaker C: When you lose that ability. And that is my concern with shared sequencing, then you're running into big problems where people have too much power. And I had a third point, but right now I can't unlock my phone. Okay, last point is about native rollups. So I can see that you can potentially get to a sort of execution like sharding roadmap by adding construction. That basically adds an easy way to prove the EVM. I want to propose an alternative, which is this.
00:22:37.792 - 00:23:43.540, Speaker C: I think at the point where we are able to build sequences and provers large enough to run say 100 or 1000 times the current EVM scale, I think what we should actually naturally do is instead put these resources to scale our current l one. I think this is something we should definitely eventually do. I think we will with the next five years, arrive there, and I think it makes sense to start scaling the gas limit. Put an Zkev improver on L1, put it on the data availability layer and say yes, at some point we do need sequences, but if we do it this way, first we get totally for free global composability. Because it is actually the Ethereum L1, we get a lot of control. We'll know exactly how much it costs to sequence this, to run these transactions, and we get to build the infrastructure, we get to know that everyone can run a basic set of open source infrastructure. So I think this is a much better world.
00:23:43.540 - 00:24:22.974, Speaker C: And I think we will run into a world where within five years doing, say, 100 X EVM will be able at a sequencer cost of, say, less than $100,000. I'm pretty convinced of that. And I think if that's what we want, this is what we should be aiming for. And I totally think that should be Ethereum's long term strategy. And I also think that is not actually a threat to rollups, because ultimately rollups will build on their own ecosystems, they will have their own value provision, and they will be their own brand that provides users with a different experience that is good for certain applications that will continue to run on them.
00:24:23.634 - 00:24:36.934, Speaker A: Ok, so we were going to go into questions now, but I'm wondering if maybe we can go a little bit off book because I feel like Justin has a lot of responses. He would like to say to that. So maybe I can give Justin a minute or two to respond to that. I could see him squirming in his chair.
00:24:37.554 - 00:25:15.980, Speaker B: Ok, I guess one cool thing is that once we have this ZkvM precompile, in some sense we can remove the gas limit. Because what's the reason why we have a gas limit is because we want to prevent denial of service. But if verifying an EVM block is constant time, it takes one millisecond. You just have to verify the snark, then you no longer have this dynalog service. So you can stuff a trillion additions and multiplications and bit operations and it will all be kind of compressed into a single snock. And so in some sense I agree with Thankrad that we can basically just remove the gas limit. And maybe we do need a gas limit specifically for state bloat.
00:25:15.980 - 00:26:03.496, Speaker B: Right, right. To stay too much. But there is actually maybe an argument to be said that the limits on data availability also limit the state growth. Another thing that I agree with Thankrat, is around the need for a fallback. Just because we have sophisticated infrastructure doesn't mean that we shouldn't have unsophisticated infrastructure and act as a fallback. And so my mental model for many things actually is that we have this optimistic default path, which is hyper optimized and provides best outcome for users. But then in world war three situations where all citadel has been blown up, then we do need to have these unsophisticated builders and searchers kick in.
00:26:03.496 - 00:26:51.454, Speaker B: And one of the things that makes me very, very optimistic about this future being relatively straightforward is actually encryption. And the reason is that once all your mempools are just like encrypted white noise, then really the main thing that you can do is just concatenate encrypted transactions. Once you can't see, inspect inside, then for the vast majority of transactions you can just almost first come, first serve concatenate them. And even there's no sophistication there. You don't need capital, you don't need an army of phds, you don't need fancy algorithms and all of that stuff. So I am optimistic that yes, we can have more homogeneity on ethereum, we can have no more gas limit, and we can also have these fairly simple fallbacks that start kicking in.
00:26:52.154 - 00:26:54.882, Speaker A: All right, Dankra, do you have any, a quick response before we go?
00:26:54.938 - 00:27:00.494, Speaker C: I mean, I feel like everything he said was agreeing with my points. I don't know if there's a response here.
00:27:03.174 - 00:27:22.990, Speaker B: I guess my point is that all of these things, a fallback, increasing the number, these are not mutually exclusive. With shed sequencing, we can have both. Why not bother?
00:27:22.990 - 00:27:42.894, Speaker C: I think it will be interesting for you to sketch out design where you can actually have both in terms of the actual shared sequencing feature, where you have things like synchronous composability.
00:27:44.034 - 00:27:44.562, Speaker B: Right?
00:27:44.658 - 00:27:50.934, Speaker C: I think that is not convincing to me that there is a default fallback path on all of these.
00:27:54.254 - 00:28:19.998, Speaker B: Right? I mean, one very graceful way to fall back is just to disable the synchronous composability. Like it just fall back to the pure parallel, just concatenate encrypted transactions and don't worry about anything else. I mean, there's also this intermediate kind of level of sophistication, which is maybe suave, which is simultaneously you can think of it as an encrypted mempool, and it has the ability to have complex interactions within them.
00:28:20.126 - 00:28:49.214, Speaker C: As a minimum, the shared sequencer would still get the ability to arbitrarily switch off the synchronous composability, which means they can use this at a time and it's convenient for them. For example, if they can exploit something on a roll up that someone else cannot because they don't have enough capital and would require exploiting the synchronous composability.
00:28:52.074 - 00:29:40.914, Speaker B: Right. I mean, one thing that can be leveraged is actually providing cross roll up account abstraction and cross roll up bundles. And there's like for example, polygons aggregation layer ideas in that direction. And here, once you have that infrastructure, it's actually safe to use the inclusion list. So your slow path, your maximally simple and robust path, is actually still to an extent compatible with the synchronous composability. I think the main thing that you potentially lose is the pre conformations. So you lose this real time ux, you fall back to 12 seconds.
00:29:40.914 - 00:30:06.754, Speaker B: But one of the things that Vitalik noticed recently is that the Internet always, very often has these glitches. How many times a day do you have to wait a few seconds for things to reboot for your wifi to get back to normal? I think it's fine if sometimes we gracefully degrade and lose this instant ux.
00:30:08.534 - 00:30:16.950, Speaker C: So this seems wrong to me that you're claiming that you can get instantaneous composability just from inclusion lists.
00:30:17.022 - 00:30:18.534, Speaker B: It wouldn't be instantaneous.
00:30:18.654 - 00:30:20.394, Speaker C: Like you cannot get, like.
00:30:20.894 - 00:30:24.474, Speaker B: Yeah, so you lose the pre conformation, but you keep the composability.
00:30:26.294 - 00:30:27.954, Speaker C: That seems untrue to me.
00:30:29.054 - 00:30:51.108, Speaker B: Okay, so the way it would work is that you express your super transaction, your cross roller bundle, as something that you can include in the inclusion list, and then whatever builder ends up building a block. They have to respect this intent, this design.
00:30:51.156 - 00:31:01.838, Speaker C: But how can they respect it without being able to sequence on all the things that interact with each other? Like someone has to have a shared state of all the roll ups that interact with each other.
00:31:01.886 - 00:31:04.750, Speaker B: Yeah. So that would be the minimal fallback in case.
00:31:04.822 - 00:31:07.954, Speaker C: Okay, but that is a global shared sequencer.
00:31:11.094 - 00:31:37.594, Speaker B: Yes, but like this different notion of global shared, like there's one that's like maximally simple where if you zoom in, you know, you could have these searches that just do one thing and just concatenate transactions. Yeah, technically as an entity, logically it's one global sequencer, but that doesn't mean that there's one entity in the world that has a farm of servers that's doing all the sequencing.
00:31:39.934 - 00:31:46.114, Speaker C: I mean, at least you need all the state to know what exactly the transaction does, right? Otherwise you cannot have composability.
00:31:46.614 - 00:32:08.374, Speaker B: Well, let's say you have 1000 rollups and you want to compose between two rollups. Well, you only need to run a full node for these two rollups. And so like for 99.9 of the full nodes, you don't have to run them. And so you can have these like pairwise searches, I guess, that are more robust and much more simple than having a global view over everything.
00:32:10.794 - 00:32:14.570, Speaker C: I think a searcher is not enough. You need an actual builder who does both at the same time.
00:32:14.602 - 00:32:20.984, Speaker B: Yeah. So the layer one searcher is an l two builder. Like these are like different layers of abstraction.
00:32:22.564 - 00:32:38.704, Speaker A: All right, so maybe we go to questions for a couple of minutes. Okay, so I'll first give it to Dankrad. What are your opinions on things like hyperchains and super chains where there are communities that share a sequencer but they don't share a global shared sequencer.
00:32:40.524 - 00:33:12.966, Speaker C: Yeah, I mean, like, I think to me a super chain is in the end just one roll up. Like I would say it's just a different way of creating what I would call logically one roll up with just different partitions that are individually administered. But I think that doesn't make them separate roll ups. It's basically you could just have these different partitions just be their own smart contracts. So I think the global thing is logically one roll up.
00:33:13.070 - 00:33:25.794, Speaker A: Okay, yeah, makes sense. And then to Justin. So in your previous talk, you talked about execution tickets probably being several years away. What do you see as like, while we don't have execution tickets, how we should enable this shared sequencing?
00:33:26.494 - 00:34:05.958, Speaker B: Right. So the basic idea is delegation. So the sequencing rights would be given to an l one proposer. That l one proposer, if they choose to not be a preconfirmer, they can delegate their sequencing and preconfirmation rights to some other entity. And now you can ask yourself, ok, so I call it the gateway, so logically call it the gateway. Now we can ask ourselves what makes sense to who should be running the gateway? Well, the gateway needs to be mutually trusted by the proposal, of course. And they also need to be trusted by the users.
00:34:05.958 - 00:34:48.917, Speaker B: And one of the reasons is actually around the pricing of pre confirmation tips. And this is a really delicate balance. So every time a user makes a request for pre confirmation, they have to pay a corresponding tip for this service. And there's basically two outcomes that are bad. Outcome number one is that the tip that the users have to pay pay is actually too high, in which case the user won't be happy and they'll get ripped off. And outcome number two is the tip is too low, and the proposer kind of is not happy and feels that they've been ripped off. And so really, you want this neutral party, which is trusted to provide the pricing on both sides.
00:34:48.917 - 00:35:37.544, Speaker B: That is fair on both sides. And if I were to look at the existing ecosystem and try and map this gateway role to one of them, I think it would be the relay. And the reason is that the relay is already this kind of trusted brand, which is meant to be credibly neutral, that is already trusted by the builders and the proposers, and now they need to be trusted by a third type of entity, which is the user, and actually being trusted by the builders and having all the builder connections is useful. And the reason is that once we have preconfirmations, we modify pbs in such a way that the builders still have to build these MEv maximizing blocks, but with the constraint of having to satisfy the pre conformation. So really it's like this four way game, where we have users, proposers, builders, and then relays in the middle that are just neutral coordinators.
00:35:38.244 - 00:35:47.784, Speaker A: Okay, as a follow up question to that, how would you respond to people who say that we should not be adding more responsibilities to the relays, we should be removing relays from the system.
00:35:48.424 - 00:36:24.384, Speaker B: Right? So I've always been of the opinion that relays should be this temporary thing, and then they should just die. And like the previous kind of roadmap was enshrined PBS, and the promise there was, okay, we're going to remove the relays. Now, there's kind of good news and bad news. The bad news is that epbs looks way less attractive today than it looked a year or two ago. And so that as a roadmap, looks less feasible. But also it might take more time. But the good news is that we actually have an even better design idea, which is these execution tickets.
00:36:24.384 - 00:37:03.744, Speaker B: And so, sure, we might have to wait a little bit longer, and relays might have to live longer than expected, but ultimately we'll be in a better place. And I think this speaks to, like, ethereum's, I guess, philosophy, which is do things slow, but do things properly. We don't want to take too many shortcuts and we want to incorporate a lot of the research. And it just so happens that in some sense, with execution tickets, we made this quantum step in terms of our understanding of mev. And I think that is a much better design than entry and pbs in the short term.
00:37:04.684 - 00:37:23.894, Speaker A: Yeah. Thank you. So. And then a question to Dankrad. What do you feel about the argument that these builders, for particular roll ups, will end up centralizing anyway, because there's profit to be made by building for multiple roll ups, and that they'll just centralize themselves outside of the protocol and we'll just end up with a global shared sequencer anyway.
00:37:24.994 - 00:38:37.644, Speaker C: I think that is a good question for me, that's different from the normative question of do I think it's a desirable future? Well, right now I see it as a danger. I am currently not convinced that it is actually the natural future because I do believe that roll up ecosystems are developing independently and it does seem like they are doing their own thing. And I actually don't know if there is such massive value that the market concentration will be worth it for someone. It may be, but I'm not completely convinced that that is true right now. If it is true, then I would actually stand by my argument that if this is where we're heading, we're still better off saying, hey, let us put everything on scaling our base layer so that that is going to be the big shared sequencing layer that we can control and we can control centralization. And yes, roll ups either become their own independent ecosystems or maybe if in the worst case, we were actually to see this is inevitable, this is guaranteed to happen, maybe we would have to abandon the roll up centric roadmap. I don't believe this is the case.
00:38:39.464 - 00:38:46.164, Speaker A: Sounds good. Okay, so now we're going to go into the closing statements. I'll give Justin two minutes for his closing statements first.
00:38:47.544 - 00:39:22.054, Speaker B: So, I've known Dankrat for twelve years, and actually he's the one who got me into bitcoin in 2013. We were working on this FPGA project, and even back then we were arguing all the time. And he leans on the pessimist side of things. I lean on the optimist side of things. And usually truth is somewhere in between. I think we actually have so much more common ground than this debate would suggest. And so, yeah, I think I actually very much agree with Dankrate on many things.
00:39:22.054 - 00:40:21.494, Speaker B: I agree that we need to have this really robust infrastructure, so even if there's one mega builder, it can't do evil. I agree that we need to have these graceful fallbacks, but at the same time, I still think that. By the way, I also agree that it would be nice to have the ZKE EVM enshrine precompiles that don't have any gas limits. So we can really, really do as much as we can at layer one. But at the same time, I think that the short and medium term market forces, the network effects of synchronous composability, will lead to some amount of centralization. And that's something that we shouldn't necessarily be fearful of. It's something that we should be mindful of and try and design a future which is long term satisfactory.
00:40:21.494 - 00:40:44.464, Speaker B: As a researcher, we have this bias over the long term. And I also think ideologically, what are we trying to build here? We're trying to build infrastructure that will last decades and centuries. And sure, if the next five years are a little awkward, then so be it. I personally don't care. And so I think, yes, we need to be mindful of the next five years, but I remain optimistic about the long term future.
00:40:45.204 - 00:40:47.224, Speaker A: All right, wonderful. Don crag.
00:40:48.804 - 00:41:34.984, Speaker C: Yes. I mean, I think, like that's, that's a great sort of closing statement in terms of, like, generally, I think as before, like my, my point on this is not about what is going to naturally happen. I think that's like the second point. Like, what a good question to ask, where do the forces lead us? But I think my primary point is I want to know what is a good future? I think there are two different things here. There's the advantage from the UX point of view. There are disadvantages from the centralization point of view. And I think the natural thing is to ask the question, where do we want to be in five to ten years? And I think it's very good even for roll ups to ask themselves a question.
00:41:34.984 - 00:42:18.084, Speaker C: Should I, like, for example, share the sequencer? Is that the right thing to do right now? And I think there are good arguments to think about. Well, maybe this is not what you should aim for right now. It's a lot better for the roll up ecosystem to have a lot of diversity. And I think it's also ultimately better for roll ups in terms of their, the economics. Because rollups are building their own ecosystems. They do want to sort of build out, like something that is independent and will generate them some amount of revenue at least. And so I think, like, it's a.
00:42:18.084 - 00:42:29.834, Speaker C: It's a good question to ask. And I think, like, the normative answer for me is still, like, no, I'm not, like, willing to say, I want to build a global shared secret right now.
00:42:30.694 - 00:42:32.894, Speaker A: All right, thank you both. This was a really great discussion.

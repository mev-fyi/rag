00:00:00.330 - 00:00:00.880, Speaker A: You.
00:00:02.210 - 00:00:02.622, Speaker B: Hello.
00:00:02.676 - 00:00:48.220, Speaker C: Hello, everyone. Welcome to the 15th edition of Mev Roast PBS on Ethereum Roadmap. This is Tina from Flashbots. I would like to welcome our roastmaster hasu for the day and just a couple of things ahead of time about our roast meetup. If you have any questions, feel free to directly ask your questions in the site chat. And most of the time, our roast have had fun conversations in parallel in the site chat. If you would like to speak up, ask an interesting question and raise your hand.
00:00:48.220 - 00:01:24.150, Speaker C: Our roastmaster and our cohosts will do our best to bring you on stage. And lastly, if you would like to learn more about the agenda as well as read up on the slides ahead of time or relevant resources, please check out the agenda link. It is up to date and have all the material that will be relevant in today's MEB Roast. Without further ado, let's get started. KASU.
00:01:24.970 - 00:01:59.300, Speaker B: Hey, Tina. Thanks for the introduction. Hey, everyone. So feel free to interrupt the presentations at any time by asking questions, and if I think it's a good time to ask them, then I will act on it. So welcome, everyone. Today we are talking about PBS, which stands for proposal builder separation. I will share my screen in order to give you guys some more context because I think this is actually the first Mev Roast since more than six months.
00:01:59.300 - 00:02:45.730, Speaker B: So a lot has changed in mev land, and I will try to give you a little bit of context on what we are talking about. Let's see. How can I share just this? Does this work? Yeah, we can see your screen right now. Maybe you should like present. Yeah, I want to present oh, the button is here. No, where's the button? Where's the button to present? If you do, dear show, I don't know what language there it is. I see.
00:02:45.730 - 00:02:46.786, Speaker B: Got it. Thank you.
00:02:46.888 - 00:02:47.780, Speaker D: There we go.
00:02:49.510 - 00:03:51.874, Speaker B: Can you see this as well? No. Okay, so what are we talking about today? So PBS is proposal builder separation, and at least for me, the name was a bit confusing. So we need to get over this small hurdle in the beginning. So the P in PBS is the proposer, and that's basically the equivalent of a miner today or a validator in proof of stake. And the builder is someone who creates the content of the ordering of a block. So PBS is about separating these two functions, first creating the block content and then proposing it to the network. And as I understand, the name proposer comes from basically ethereum proof of stake terminology, where in the new consensus algorithm, we have this two part process of validators proposing blocks to the network.
00:03:51.874 - 00:04:37.670, Speaker B: And then we have these committees of other validators who give them weight via who basically vote on them and give them weight in the fork trace rule. So I think, as far as I understand, that is where the name comes from. However, it's also a bit misleading in the sense that block production is already separated today. So this is not inherently a new thing. So we have basically the same thing today, just in a slightly different form. So most miners, like 99, over 99% of miners tend to be workers in the mining pool. And the mining pool operator tends to be the one who creates the block template.
00:04:37.670 - 00:05:49.542, Speaker B: And then basically the other miners in the pool, they only lend their proof of work, their proof of works to this block. And the mining pool operators typically create the contents of the block with the help of a service like Flashbots. So I think Flashbots has around 70, 80% of hash power today. So that means the mining pool operators run the flashboards client in order to receive bundles from flashboards and then they use this client in order to create or construct the best block that they then publish to the network. So what's really new in PBS? Oh, I changed the order of the slides, let me go here. So what's really new in PBS? So PBS is primarily as far as I am concerned, is about scaling how the network works today. And we can only do that by sort of removing, identifying and removing the parts where a lot of trust is required.
00:05:49.542 - 00:06:48.080, Speaker B: So flashboards today is an integral part of creating block contents and that's probably not going to change. And so it makes sense to understand where the different participants in the system have to trust each other. And the way it works right now is that the users and searchers, they have to trust the flashboards relay and the miners in the system, not to unbundle their bundles and to front run their transactions. So it's effectively trusted system today. And the miners have to trust the relay, not to withhold any bundles from them and not to denial of service attack them. And after PBS. So this is sort of the goal and in this conversation, hopefully we will get a bit closer to what steps are necessary to get there.
00:06:48.080 - 00:08:03.590, Speaker B: After PBS the trust that is required by the participants in the system in each other will be greatly reduced. So users and searchers still have to trust, this is actually not for trust this PBS, this is for the step that comes right before it, but we will get to that. So users and searchers still have to trust a relay to some degree, but they no longer have to trust the miners. And this effectively removes the need to whitelist miners. Because in flashboards today, it's not because of the trust that is required in the miners not to unbundle any bundles and not to front run any transactions, it is effectively required that only miners beyond a certain size can participate because if flashboards had zero leverage over them, then the system wouldn't work. And for decentralization it is very important that all miners can participate in the system, but that means there cannot be any trust required in the miners. And so Justice PBS will be an important step in allowing all miners to have access to the best block.
00:08:05.850 - 00:08:08.070, Speaker E: Yeah, right.
00:08:08.140 - 00:09:05.226, Speaker B: And the miners also no longer need to trust relay. So that's something that we will talk about. And a couple days ago, Vitalik posted this update of the Ethereum Roadmap. So it just basically summarizes all the proposals that are going on in different directions and sort of neatly ties them together. The thing that we are talking about is on that roadmap, it is here at the bottom half. We will talk about short term mev mitigation and how it's basically a step on the road to having a first base specification for having in protocol PBS. We will also learn about how having or moving to PBS will change the censorship resistance of Ethereum and what can be done to maintain it.
00:09:05.226 - 00:10:15.010, Speaker B: And then we will talk about upgrades to PBS in the future, such as mev smoothing and all of the talks of our speakers today and the follow up discussions, they map very nicely to this roadmap by Vitalik. So we will start oh, I think actually we will start out with Vitalik's talk, where he sort of explains to us the reasons why PBS is so important and what is the motivation for designing it. And he will also share with us basically the predominant proposal right now for how PBS can be done in protocol. However, the proposal is very important. And so Flashbots has come up with a way to give us many of the same benefits before we can have PBS in protocol. So this is the topic of Stefan's talk. So he will talk about a Flashbots proposal called Mevboost that would basically create basically a similar function as PBS, but as a stepping stone to the In Protocol PBS.
00:10:15.010 - 00:10:48.940, Speaker B: And finally we will have a talk by Francesco of the Ethereum Foundation and he will address how PBS affects the censorship resistance of Ethereum. And many implementations actually make the censorship resistance worse. So it is very important that we are very careful about that and we design it in a way that the current censorship resistance can be at least maintained. Yeah. And having said that, without further ado, I would like to give the stage to Vitalik and the first talk of the day.
00:10:52.370 - 00:11:33.594, Speaker A: Okay, great. Thank you for the introduction, Haso. Okay, there we go. Does everyone see the slide? Yes. Okay, perfect. So I will start off with just general introduction to the problem, recapping why there is a problem, in what way PBS tries to mitigate the problem. What about it? It tries to mitigate and then go into some of the details of how the current design works and where some of the challenges and the research directions are.
00:11:33.594 - 00:12:31.370, Speaker A: So the core of the whole problem that I think this kind of subspace of crypto land is about is this concept of a hard to discover mev, right? Some examples of a hard to discover mev include internal uniswap arbitrage. So if for example, the previous block had some uniswap trades and the A to B price multiplied by the B to C price and the A to C price ended up being misaligned with each other, then you might be able to do some internal arbitrage. Basically do a triangle swap, a for B, B for C, C for A, and if the prices were misaligned, you would get more A out than you put in. And that would also, as a side effect, bring the three prices into equilibrium. Uniswap versus Sushi swap arbitrage. Another example. So A to B on uniswap and B to A on sushi swap.
00:12:31.370 - 00:13:19.302, Speaker A: Potentially this could even be between multiple DEXes. So A to B on uniswap, b to C on Sushi swap, and then C to A on whatever other newfangled swap people have come up with. I'm not even keeping track of all of the emms these days. Uniswap versus off chain exchange arbitrage. This is a fun, uh, I would argue a special case of something called cross domain arbitrage, which is something that we're going to be hearing more and more about in the years to come. But basically the idea would be that whatever the uniswap trades were that happened in the last block, since then the prices of those assets have moved within those last 12 seconds on other exchanges. So for example, on finance.
00:13:19.302 - 00:13:53.638, Speaker A: And so you can make the uniswap trades or the uniswap arbitrages that mirror the price movements that happened on Binance or happened on Poloniax or happened on whatever other exchange you're arbitraging against liquidations. So liquidating MakerDAO CDP is one example. Liquidating. CDPs. On rye. Just like any of these lending positions NFT purchases. So a lot of the time when people sell new NFTs, they release a limited quantity at a fixed price.
00:13:53.638 - 00:14:48.214, Speaker A: And I personally think this is a bad idea and I've written about better ways of doing this, but while this is happening, if they end up mispricing or miss selecting the quantity, then demand is higher than supply and there is this big race to just snap up all the NFTs quickly. And that's also a type of hard to discover mev. Right? This is all revenue that can be gathered by being in the position of choosing the contents of the next block where you need sophisticated algorithms in order to discover it. Right? So we're not just talking about kind of simple mev. People say like, oh, transaction fees are technically mev. We're talking about mev that actually requires these sophisticated algorithms to discover. Sometimes the mev is really huge even within a single block.
00:14:48.214 - 00:16:13.022, Speaker A: There is apparently this, as I understand, period of two minutes during which anyone could have sent a transaction that would have liquidated Justin's Son and cost him like over $100 million. But no one at that time managed to figure out how to do it because at the time, this was five months ago, the fee market really sucked had it happened recently in EIP 1559 land, actually, ironically enough, the greater efficiency of the chain probably would have meant that Justin Sun would have actually lost his money. But in general, snapping up these kinds of opportunities first can be a 100 million dollar big deal. So why is hard to discover mev a problem? Right? So hard to discover mev. Discovering it requires specialized software and that specialized software needs to be constantly updated, right? Like you're running specialized software to discover these arbitrages and then the exchanges where this stuff starts happening ends up changing. Sometimes you do your mev in ways where you end up being vulnerable and other people start parasitically like mev in your mev and then you have to change your algorithms. Sometimes you might want to change the location of your servers in order to grab up more opportunities.
00:16:13.022 - 00:17:46.330, Speaker A: You might want to surveil the network to see where the transactions are coming from and get more opportunities. Only specialized actors can effectively optimize mev revenue. There's just inherent economies of scale in figuring out these mev opportunities, right? Like if it costs $100,000 of just human effort to discover one of them, then that's only worth it if you also have say, at least $20 million of capital needed to exploit it. Large staking pools by default are the actors that are most capable of getting these mev teams. And so by default, this creates pressure for stakers to join large staking pools. So the solution to, or the mitigation to this kind of nasty pro centralization equilibrium that we've come up with is proposal builder separation, right? So the goal is to separate out the part of the whole task of being a staker that has strong centralization pressures, which is the selection of block contents. Because selection of block contents gives you this ability to take advantage of these hard to discover mev opportunities from the rest of the task of staking, which is block validation and making sure that you're building on the correct head, right? So you want to be able to outsource the ability to create block bodies without outsourcing the ability to choose the correct head.
00:17:46.330 - 00:18:56.930, Speaker A: Because if you outsource the ability to choose the correct head, then that becomes really exploitable to create 51% attacks and do all of the other nasty things. And also the ability to create invalid blocks also gives you opportunities to do all these nasty things. So the idea here is basically that instead of block proposers, so stakers that have been selected to choose the block at that particular time actually creating the block contents directly, block proposers sell the right to decide the contents of their block to the highest bidder. And this happens on chain or through this transparent marketplace that happens as part of the peer to peer network. So at this stage it's worth going through the current proposed VBS design. So this is something that can be improved over time but this is the design as it exists today. So basically the idea is that you have two classes of actors, you have the block proposers and the block proposers are chosen by the just standard Randall selector random validator mechanism and then you have the builders.
00:18:56.930 - 00:20:08.378, Speaker A: The job of the builders at this stage is to submit what I call execution block headers. An execution block header basically says hey, I have this header in mind and here's a commitments to the body of the header and here is the amount that I'm willing to bid in order to get this header included. And the amount that they would bid is realistically like the revenue that they would get from this header minus some small amounts of profit. And the reason why the profit is small is because you have a very competitive market of all these different actors that are all trying to create these execution headers. And so if one of them makes a bid that's not very high then there's going to be someone else that makes a bid that's higher. And so the amounts of profit that they make is going to get competed down to a very low number, right? So they all make these headers and then it is the block proposer's job to choose the header that has the highest bid. So the beacon block proposer chooses the header with the highest bid and they get paid the highest bid unconditionally.
00:20:08.378 - 00:20:46.170, Speaker A: So once the beacon block header chooses the execution header with the highest bid, the beacon proposer gets paid that amount unconditionally. So regardless of what happens after that point. And so what that means is that it is their incentive to just choose the execution header that pays the highest amount. So then there's the beacon block deadline and then after that you have the revealing game, right? So up until this point the builders only published the headers. They did not publish the body. There are two reasons why this happens. One reason why this happens is just like simple efficiency really.
00:20:46.170 - 00:21:54.214, Speaker A: You don't want 500 different copies of the body floating around the network because that would just overwhelm everyone else's p to p data bandwidth. And then the second and really important reason why you do not want to reveal the body is to prevent what we call mev stealing. So mev stealing basically means like let's say I'm a builder and I have some amazing strategy for extracting mev revenue. Then let's say I do publish my body. Then all of the other builders they're going to see my body and they might be able to run algorithms that inspect my body, inspect and discover which strategy I am using in order to get that body. And then they just take that strategy, they incorporate it into their blocks and then they add on their own strategies that they know about, that I don't know about and then they'll be able to outbid me. Right? So in order to prevent these kinds of stealing games which if stealing games became the equilibrium they would wreck the whole thing because they would just create an incentive to merge the builder with the proposer.
00:21:54.214 - 00:23:19.338, Speaker A: So instead of that we just say no revealing at step one and then the revealing game happens at step two. So how does the revealing game happen? So basically what happens is that first you have a round of attestations happen and the round of attestations basically commits to and solidifies the fact that this beacon block actually did win, right? So it solidifies it in the fork choice and so that prevents situations where a malicious proposer publishes at the deadline and so some people think they published on time, some people think they did not publish on time. Instead you just have a committee and that committee kind of tries to force the outcome to go in one direction or the other and then after you have the committee then you have the intermediate blocks. Right? So the way that the intermediate basically here what happens is that it's the builder that publishes the intermediate block. So the builder basically was selected based on the winning execution headers. It's the winner's job to basically aggregate this committee and then also the builder is going to reveal the body of the execution block and they're going to sign the whole thing. The body actually gets checked against the header and so the only thing that they can publish is the thing that they pre committed to.
00:23:19.338 - 00:24:31.554, Speaker A: Now if they publish a block then they already had to pay the fee in the header but then they get the revenue from the body, right? They get the mev from the body and they get the fees from the body. So theoretically even the coinbase opcode in the block should actually point to the builder address so that anyone who is trying to compensate the miner would actually end up compensating the builder. The job here is to actually concentrate all of the revenue into the builder. The builder figures out how to do the revenue maximizing and the proposer's only job is to just figure out which header is going to pay them the most. So if they reveal then they pay the bid and they get the mev and the fees and everything from the body. If they screw up and they do not reveal then they still have to pay the fee but they get no revenue. So it's a big loss for the builder so it's a bad idea for them not to publish and then it's the job of this next round of committees and the job of these committee to basically say whether or not the intermediate block was published on time or if it was not published on time.
00:24:31.554 - 00:26:01.280, Speaker A: So if the intermediate block was published on time, then they basically attest to the intermediate block and if it was not published on time, then they just end up attesting to a kind of virtual block that says that there was no intermediate block present at this particular time. And then the purpose of that is to solidify. What is the head of the fork choice? Like, is the head of the fork choice the post state that includes this block body or is it the same as it was before? And once that is solidified, that creates this kind of stable thing on top of which the next round of execution builders can actually build on, right? And that is one cycle of the entire process, right? So step one, they bid on headers because they know what the post date is. Step two, proposer chooses the winning header. Step three, winning builder reveals the body. Step three attesters solidify this header, then the builder reveals the winning body and then finally the Attesters select the winning body or they vote on whether or not the body is present or whether or not the body was absent and then you just go on to the next round of the exact same process. So that is the core idea of the current proposed design and we'll talk about what the benefits are and we'll talk about what the downsides are and so what is the room for improving it.
00:26:01.280 - 00:27:07.250, Speaker A: So security properties of the current design, right? One really important security property is that payment to the proposer is unconditional, right? So proposers do not have to trust builders. All proposers have to care about is basically which header has the highest bid, right? Because the returns of the proposer do not at all depend on whether or not the builder publishes. So this is important, right? Because if proposers do not need to trust builders, then one that makes the marketplace for being a builder much more open and accessible. Like there's no social credit score for builders that they have to navigate. That ends up being some kind of really exclusionary thing that benefits people with established reputations. And also really importantly, that means that the proposer does not have the social task of figuring out which builders are trustworthy. And so that makes the proposer side more decentralized because being a proposer just means you have to run a daemon and you don't have to go figure out and navigate the builder marketplaces.
00:27:07.250 - 00:28:15.206, Speaker A: So that's one really important property the builder has to reveal on time, right? So it's the builder's job to reveal on time. If the builder does not reveal on time, they pay their bill to the proposer but they do not collect the fees from the block. This does impose some amount of risk on the builder because basically if the network goes completely crazy or if there was a 51% attack, then they do have the ability to basically force the builder to lose one round of fees without gaining the revenue that they expected. So the builder does take on the risk of basically something really crazy happening at that exact slot. And so in order to mitigate the extent to which this actually is a problem, this is why we want to try to make the whole design as stable as possible. And ideally in the long run, as I've talked about in other places, I try to move toward things like single slot finality. So third, a security property, no risk of ABV stealing in the normal case because the builder should only reveal their body once the header actually has been solidified.
00:28:15.206 - 00:29:22.490, Speaker A: And then finally, censorship of a builder requires a 51% attack on the committee. Now, a lot of these properties, they do depend on the stability of the fork choice. And there is this entire separate strain of research in ethereum lands of trying to actually increase the safety of the fork choice rule. People like Aditya and Casper and Barnaby and other people and Johannoy and others have been doing some really wonderful work. But if you have that as a base then the security properties of this PBS kind of inherit naturally from whatever the security property is that the forkuist rule of LMD Ghost and Casper give you. Another important thing is that because of the way this thing is structured, it's basically structured as just like a two slot overlay on the existing system. And so the reasoning behind the fork choice rule does not really needs to change much because basically the thing that the attesters need to do can't be expressed in the language of them just voting on the fork choice the same way that they already vote on the fork choice today.
00:29:22.490 - 00:30:14.170, Speaker A: This is also really important. So those are security properties of the current design. So now finally we can also talk about some of the challenges of the current design. So the current design has the property that it involves multiple steps per slot, right? So it basically involves two virtual slots per every actual slot. And this requires increased block times, it requires stronger latency assumptions. So basically either you keep the length of a slot the same and you have like 24 seconds instead of 12 seconds per quote actual block. Or you have to reduce the timing of these slots to 6 seconds and then you keep your twelve second blocks but you have more risk.
00:30:14.170 - 00:31:18.838, Speaker A: Or you take a kind of middle approach and you say you're going to have eight second virtual slots and 16 2nd actual slots. Now we can try to kind of cheat a little bit and try to optimize things a little bit, right? So we can say instead of having Attestations and aggregations we're going to have attestation, one round of Attestations happen over here and then one round of Attestations happen over here and then we're going to try to have aggregation only happen over here. Or ideally we could even try to say we'll have one round of attestations here and then we're going to have N minus two committees happen somewhere in the middle and then the aggregation happens in parallel and so we can try to kind of squish things together and optimize it a little bit. So instead of being two x, it's like maybe 1.3 or 1.4 x. But this is one of the open research areas, right? Like trying to kind of parallelize and squish things together more so you don't have this trade off between either having less frequent blocks or having reliant, like much tighter reliance on aggregation and attestations being able to happen extremely quickly.
00:31:18.838 - 00:33:15.766, Speaker A: So that is one of the weaknesses. And then the other big challenge is basically if one of the builders ends up waiting consistently, then can they censor? Right? So the core idea behind PBS is basically that you have this concept of being a builder and you have this concept of being a validator, and we're going to protect validators from becoming centralized by taking the one piece of validating that has this really high economies of scale and splitting it off into a separate role, right? And so the question is, well, okay, so you have this concept of you have this kind of like centralization sponge, right? So if you think of economies of scale and centralization economic pressure as being this kind of water that seeps into everything and makes it wet, which we don't really want, and we want to keep the validators dry, then you have this kind of sponge that just soaks in all the water the validators can still be dry. But then the question is, well, isn't the sponge going to be extremely wet? Right? Like, isn't the builder market whose job it is to kind of suck in all of the centralization pressure from the validator ecosystem? Isn't their job going to become extremely concentrated to the point where you risk having very centralized block building? And then if that's the case, then doesn't that become a censorship factor, right? Imagine three builders creating all the blocks and then those three builders that just end up being in the same jurisdiction. And then doesn't that potentially create this big political centralization dystopia where if they end up colluding and deciding, like, hey, uniswap is bad, then are they going to be able to shut down uniswap or whatever? There are solutions to this. So I wrote a post about this. It was called State of Research, I think on PBS. It's on my Twitter.
00:33:15.766 - 00:34:28.820, Speaker A: If you just scroll down, you'll be able to find it. And so I talked about how the economics of PBS do naturally provide some pressure against censorship, basically because if you censor even one transaction, you're basically permanently putting yourself at an economic disadvantage, like every single slot. And if the set of transactions you have to censor gets bigger than the. Advantage of the best builders over whatever the open source builders or whatever the best kind of ideologically anti censorship builders are, then eventually, as a builder, you're going to either have to lose money every slot or the other builders are going to outcompete you and they're going to include all the transactions you were trying to censor. Right. But then the question is, well, is this economic argument actually enough? Right? And if the economic argument is not enough, then can we create kind of secondary lanes to try to allow people to bypass censorship the same way that optimistic roll ups have secondary lanes in case the sequencer is censoring? And this is the topic that the next speaker, Francesco, is going to talk a lot about.
00:34:31.590 - 00:34:56.262, Speaker B: That's right. Thanks, Vitalik. We got one question from the audience during your talk and the person asked, so what if a proposer accepts the payment, but then when the builder reveals, the block just chooses to not include it, would that be a concern? So the proposers do not need to trust the builders, but what about the builders trust in the proposers?
00:34:56.326 - 00:36:08.290, Speaker A: Okay, so this is exactly why, in the design that I outlined, what happens is that the builder for the salad N plus one, so the builder for the salad after the propose or for the virtual slot after the proposer actually is the builder. Right? So basically the job of proposer N is to include this header that chooses what you can think of as being the proposer for slot N plus one. So there is no proposer that has to approve the builder. Now, what does happen is that there is this committee of a testers, right? And it's the job of the committee of Attesters to basically decide whether or not the builder revealed on time. And if the builder did not reveal on time, it's the attester's job to make votes that vote for this virtual block that says that the attestors did that the builder did not show up. And so the next proposer builds on top of the same state. But that is a decentralized committee, right? So the builder does have to trust this committee and if there is basically a 51% attack or close to a 51% attack going on, then yes, a dishonest majority could grief the builder, but that's a much higher bar than one proposer being able to grieve the builder.
00:36:09.750 - 00:36:13.922, Speaker B: Got it. I have some questions for you prepared as well, if you have some more time.
00:36:13.976 - 00:36:16.440, Speaker A: Amazing. I do. I have lots of time.
00:36:16.810 - 00:36:42.350, Speaker B: Perfect. So flashboards has already gone from one bundle per block to several bundles and going to full block proposals is just another incremental step here in theory. So could you reiterate again what is the problem with just doing more of what we do today in terms of PBS via Flashbots compared to moving to an in protocol proposal?
00:36:43.010 - 00:38:27.198, Speaker A: Sure. So the version of Flashbots that exists today currently on mainnet is like, honestly, from a long term centralization perspective, pretty dystopian because basically it relies on the proposer to be trusted, right? Basically. And the reason is that the proposer does have the ability to see the contents of the bodies that are being proposed. And so the proposer has the ability to mev steal and potentially the proposer has the ability to do other things. Like if for example, your mev extraction relies on sending transactions that are vulnerable to sandwich attacks, then the proposer could end up sandwiching you or whatever. The reason why proposers needing to be trusted is such a problem is because it creates a centralization pressure, right? Like basically as a builder, you're going to whitelist Lido, you're going to whitelist Coinbase, you're going to whitelist Kraken, but you're not going to whitelist like random Joe with his 32 E off on his local Raspberry pi at home. And so that creates an ecosystem where basically you're just going to get staking pool dominance and even within staking pools, you're going to create a pressure in favor of the staking pools where the actors that are actually making the bodies within the staking pools are trusted, right? So it even risks favoring centralized staking pools over decentralized ones.
00:38:27.198 - 00:39:54.230, Speaker A: The Flashbots, the short term post merge architecture that I think Stefan has been doing a lot of hard work on, really improves on this. But it does this by basically adding this kind of class of actors in the middle called relayers or sorry, yes, called relayers, where basically the proposer only sees a header and then the proposer signs a header and then the body gets revealed. The purpose of the relayer is to attest to the proposer that basically that the body is valid and that the body actually exists. So in this case, if the relayer did not exist, then the proposer would still have to trust the builders. And that would not centralize the proposer market too much, but that would risk centralizing the builder market because if the proposers are decentralized, then they are going to be pretty slow to update their nodes and keep whitelisting more builders. And so instead we say we're going to have this set of actors in the middle called relayers. And relayers are going to be kind of fairly stable and proposers do have the responsibility to whitelist a bunch of them, but relayers would then be able to start talking to builders and they would even be able to start talking to completely new and untrusted builders.
00:39:54.230 - 00:40:48.460, Speaker A: So this is already an improvement, but it does depend on this class of actors in the middle called builders. And that's still annoying, right? It's still a trusted role, let's say, role that proposed. And so the task of choosing the relayers ends up not being fully trusted. There's the question of whether or not the relayer market ends up naturally centralizing over time. There's all these concerns. And so the idea of in protocol, PBS is basically saying, well, can we essentially take the relayer role and put it in protocol somehow? Right? So can we take away the need for proposers to even have to worry about is the body going to be published or not? Basically by creating this design where proposers really do only have to worry about is the header there and if the header is there to just take whichever one has the highest bid and then they're fine.
00:40:49.150 - 00:41:35.580, Speaker B: Yeah. So to summarize what you said, the proposers today need to be trusted because they can see the entire transaction flows, all the bundles that in theory ought to be private, right? And hence we need to trust the proposers and that creates a lot of centralization pressure among them. We can only allow basically the big and trusted ones into the system that we have some kind of social or economic leverage on. And in protocol PBS would eliminate that. So there would be no more need to trust the proposers. But at the same time the proposers themselves have to trust the relay today and that would also get eliminated, at least to a large degree. Let me ask you a bit of a cheeky question.
00:41:35.580 - 00:42:15.240, Speaker B: Is there even any point in protecting the solo stakers or is it not already like a lost cause? And I'm thinking primarily about two things. So as a solo staker you have discrete payouts compared to smoothed out ones like you have in a mining pool. So already it's extremely disadvantageous for you to be a solo staker. And this gets even worse with the rise of liquid staking systems like Lido that unlock a lot of capital efficiency for people who join the system. Aren't we fighting a losing battle here anyway?
00:42:16.490 - 00:43:55.350, Speaker A: I would say not necessarily for two reasons. One is that I think the staking protocol itself can change in ways that are more friendly both to solar stakers and to smaller pools. So like for example, single solid confirmation could enable something close to instant withdrawals. Once withdrawals exist at all, then a lot of the advantage is going to disappear. And then the other thing is that even if solar staking disappears and everyone is in pools, there's still this question of more centralized pools versus less centralized pools. Right? And the challenge there is basically the current setup does risk favoring more centralized pools there even more because you have to trust whoever is running the pool not to also be engaged in this mev stealing stuff, right? Even if everyone is like we switch to ethereum where pretty much everyone is stake pooling, there's still the question of what kind of pool is it? And there's better case scenarios where we have more distributed pools and then we have distributed validators. So like the thing that was formerly called SSV but then got renamed I guess is getting renamed to DV because SSV network is taking over the SSV.
00:43:55.350 - 00:44:31.970, Speaker A: But then the other option is like one piece of software run by Coinbase controls 16% of the network and one piece of software run by Kraken controls another 14% of the network and so forth. And requiring proposers in PBS markets to be trusted does create yet another pressure toward that world and away from the world where it's possible to experiment with more and different kinds of staking pool approaches.
00:44:33.830 - 00:45:17.170, Speaker B: I would also point out Justin Drake's message in the chat. So he says my rebuttal A in protocol, mev smoothing is definitely doable and I think we will hear about that from Francesco as well, at least a little bit. And B, it can be more profitable to solostate because you don't have to pay pool fees. Yeah, definitely. So, Vitalik, would you say we can sort of summarize your last point as a lot of these sort of amendments to staking that make staking more comfortable, better capital, efficient, more smooth, payout curve and so on, that we sort of tacked onto staking externally, that those can eventually become part of the protocol?
00:45:18.310 - 00:46:08.340, Speaker A: I think so, yeah. The protocol definitely can improve to be more I think in general the proof of stake research community definitely cares about making the improving the protocol over time to remove the centralization pressures whether that means enabling more outright solo stakers or whether that means enabling pools based on distributed validators as an alternative to pools where everything is controlled by one node. That's going to end up being up to the market. But there is a gradation and things can always get marginally better and things can always get marginally worse. And I think in protocol, PBS is one of the ways to make things marginally better.
00:46:09.830 - 00:46:27.954, Speaker B: So the reason why we want to make sure that all miners have access to the best block is that we don't get this centralization pressure in the network. Right? But doesn't it turn out that you can't remove the centralization, you can only really shift it to different parts of the state?
00:46:28.012 - 00:47:19.100, Speaker A: Totally. So that's like the point, right, that the builder market becomes more very centralized. But the power of a very centralized builder market to Censor is less than the power of a staker market to Censor, because in a staker market you only need 51% to Censor, whereas in a concentrated builder market, it's a one of N trust model. You just have to wait until you find a builder willing to include your transaction before it gets in. And then we have the ability to do all of these kind of secondary inclusion things and all of this stuff that Francesca will talk.
00:47:20.830 - 00:47:47.454, Speaker B: Yeah, okay. I think that's a very important point. So I wanted to tease it out again. I have sort of like a governance question for you, and this is a bit of a tricky one. So do you think Ethereum Governance should have a say in what software the miners run, even though it does not affect the consensus level. So with regards to, let's say, Mev.
00:47:47.502 - 00:47:52.162, Speaker A: Boost sir, can you just repeat the question again?
00:47:52.296 - 00:48:01.320, Speaker B: Yeah. Do you think that Ethereum Governance should have any say in what software the miners run, such as Mev Boost, even though it does not require any consensus changes?
00:48:03.370 - 00:48:14.460, Speaker A: I think ultimately it's a permissionless system and Ethereum Governance has no way of stopping people from running custom like, yeah, what can we do?
00:48:15.070 - 00:48:23.020, Speaker B: Can I ask for your opinion on the EGL thing? Have you seen this token, maybe to summarize for.
00:48:24.850 - 00:48:48.440, Speaker A: Basically you have a coin and that coin votes on basically bribing people to vote on gas limits in one direction or another. In general, I'm definitely a big skeptic of coin voting, and I've talked about why on lots of occasions and no one really wants to elaborate on it now.
00:48:50.730 - 00:48:58.358, Speaker B: Yeah, it wasn't really a question about coin voting, more so that somebody changes the right, okay. Outside.
00:48:58.524 - 00:49:55.306, Speaker A: Yeah. So I think what happens there, right, is that I think Ethereum uses this concept of minor voting as a way of choosing the gas limit. But that choice was not made because we believe that it's a long term good idea to have voting over the gas limit. That choice was made because we had no idea how to set the gas limit. And it was the sort of thing where we knew that we would want to upgrade the mechanism for choosing the gas limit over time. And especially in the short term, adaptability ended up basically what actually happened is that we originally wanted to do something similar to bitcoin style adjustable block size caps. And the auditors came back and said, like, hey guys, if you do this, then one third of the miners or whoever can exploit it and just force the value to whatever they want.
00:49:55.306 - 00:50:57.680, Speaker A: And so if you're interested in doing this, then why not just make it a voting scheme? Because voting scheme, whatever you do, can be exploited by 50% of miners wanting to push it in some direction. But then if it's a voting scheme, then you gain the flexibility of being able to adjust it without a hard fork. And so that's how we decided on the voting. And then the voting stuck. And then it turns out that miners have historically have done a decent job of reducing the gas limit in the case of, say, dos attacks or whatever. But I don't think there was ever any intent of saying whoever controls the consensus has a moral right to kind of govern the gas limit parameter. And so if people start voting wrong, then the Ethereum Governance is, I think, totally willing to remove the voting feature and just fix the limit to some particular amount.
00:50:58.930 - 00:51:26.646, Speaker B: Yeah, got it. One last question. How do you think about the connection of or the relationship between PBS and Flashbots and client diversity? Because it seems right now that all the miners who want to use Flashbots basically get locked into Go ethereum. So that may not be really compatible with the design goals of yeah, I know.
00:51:26.668 - 00:52:46.850, Speaker A: I personally have definitely been pushing the team implementing this stuff to basically implement it as a client or sorry, as a plugin instead of implementing it as a client. And in theory it should be possible too, right? Because from the validator point of view, basically validators just need the functionality of just signing a header that's provided from the outside and then they could just run a separate daemon that listens in for the headers verifies that they're signed by one of the relayers or whatever and then chooses the one that has the highest bid. That kind of architecture basically just make it be a separate daemon and then have the clients just have extra functionality that says, look to this source to tell me what header to include. I don't see any reason why that should not be possible or even why that should be technically harder than any other way of doing things. And then if you do it that way, then it is fully compatible with client diversity.
00:52:48.070 - 00:52:59.350, Speaker B: Yeah. Thank you very much. Does anybody else want to step on the stage and ask a question of Flashbots friends and contributors?
00:53:00.090 - 00:53:53.330, Speaker E: Unless I actually had a question basically about the two slot proposal and why we want to move from the original one, which was the one slot one, to this one. Just from my perspective. My understanding is that the point is that we want to protect builders more just by having this intermediate committee that votes and kind of gives them some assurances. But at least to some degree, we could still protect them in the one slot proposal by having the header publication deadline be before maybe having like one or 2 seconds a delay between the header publication deadline and the builder, like the body publication deadline, I guess. Is the extra complication worth it to just better protect builders? Why do we care so much about protecting builders?
00:53:53.490 - 00:54:42.920, Speaker A: Well, there is also one other argument for doing something too salot like, which is basically that it's not clear that enforcing these separate timeouts is actually game theoretically stable. What's the actual incentive to vote according to the timeouts instead of just voting along? Voting along with the majority. And the only way we know of to actually create some kind of incentive is to kind of put some one actor in the middle that would actually be able to include the committees and give rewards to them for submitting their attestations early. So if there's a solution to that, then it could definitely make a more priorized option work better too.
00:54:48.100 - 00:54:54.660, Speaker B: Okay, if there are no further questions, then francesco, do you want to stay on stage?
00:54:56.520 - 00:54:59.990, Speaker E: Sure, yeah, I'll share my screen.
00:55:01.580 - 00:55:10.970, Speaker B: Okay then. Yeah. For the audience. We're moving on to the next presentation. Francesco, can you give like a really short intro of yourself.
00:55:11.980 - 00:56:09.036, Speaker E: Yeah, I'm well, still a math student that started getting interested in theorem maybe, I don't know, eight months ago or something like not that long ago. And I did a sort of internship foundation focusing on MVP. And I'm still working there. And I've particularly been interested in at some point I was doing some research on MVP smoothing. And now the last maybe three weeks or something, I've been thinking a lot about PBS censorship resistance because it kind of seems to be like the biggest pain point. We definitely want to move to PBS, but we want to make sure that we preserve this property, that we this what I'm going to show is kind of the result of not a lot of it's really just a few weeks of thoughts. And a lot of it is from Vitalik, not from me.
00:56:09.058 - 00:56:09.724, Speaker B: But yeah.
00:56:09.762 - 00:57:34.120, Speaker E: So the point of this talk is really to kind of inspire people maybe to think about this stuff. I think I wanted to focus on design goals and what we need from a sensory resistance scheme for PBS because there's really a lot of kind of, I think a big design space for people to make small clever ideas that they can make a big difference to improve. So yeah, basically the first question is why do things get worse in PBS? Why are we so worried about censorship resistance? And the reason is mainly that it's really evident if we just look at how much does it cost to censor one transaction for some amount of time, let's say N blocks. And so in the status quo, even if we take not just, let's say, a completely naive validator that's running geth, but even someone that's running MVP geth, the cost is pretty high. Because basically if you want to censor for end blocks post 1559, you need to just completely fill all of the blocks. And so you have to essentially make up transactions which you have to pay the base fee for priority fees and rising base fee. And so it's really hard to do for even just a few blocks or really expensive.
00:57:34.120 - 00:58:14.176, Speaker E: Whereas in PBS, kind of in the worst case scenario, when there's maybe one dominant extractor, like one really good mev extractor that just wins all the blocks consistently, then it's really not nearly as expensive. It's just essentially the priority fee of the transaction times N. So just for each block you kind of have to give up the priority fee of this transaction. It's not immediately clear that that's what the cost is because you're not really giving it up. It's a bit more complicated than that. And I'll show it next, like what it is. This is from Vitalik.
00:58:14.176 - 00:58:58.624, Speaker E: Just don't want to take credit for other people's graphics. Basically, let's imagine that we have this dominant builder which is able to basically extract M plus A of mev. And let's say like every block, it's the same, and then the next best builder which is not interested in censoring, can extract M. So this A is essentially kind of the advantage that the dominant extractor has on the next best competitor. And basically this advantage is what we could think of as the profit. If the dominant extractor makes a really good bid, they would bid just a little bit more than M and they can profit this much. Sorry.
00:58:58.624 - 01:00:12.648, Speaker E: I should say, like M is without the victim transaction, whereas M plus B is if we consider the victim transaction to be available to still be around, and that everyone can include in their blocks. And so this P is how much the victim transaction basically the priority fee component of the victim's transaction. And so if the Dyna extractor sensors, they leave this transaction around for other people to use, and which means that everyone else can bid P more than they otherwise could. And so if you then want to still outbid them by just a little bit, you have to bid more than ample speed. So your profits essentially diminish by this amount, like P. And so that's why you don't just pay the opportunity cost once of not including P, but at every slot, everyone else can make a higher bid by P, and you kind of have to compensate for that in your bids. And this is a lot less than the status quo, essentially, except it's not really a lot more than the status quo if your model of censorship includes the possibility of bribes, because if you include the possibility of bribes, then actually we get essentially the same in PPS as we have now.
01:00:12.648 - 01:01:23.090, Speaker E: So the point is, if there's a transaction which pays a priority fee P, or like the total priority fee component is P, then you can just go to a proposer. And if they're a profit maximizing proposer, you can maybe just ask them to not include it and give them P plus one, and they won't include it if they're really profit maximizing. So if you're basically just treating proposals this way, then things don't really change that much. That's about what censorship cost. And if that's not the case, if you don't allow for the possibility of censorship sorry, of bribes, kind of explicit bribes, then even with PBS, proposers are still kind of have free will. They can participate in PBS if they want to, they don't have to take blocks from builders, they can always make their own, at least for now, and they can just detect censorship and stop it. So one might think, okay, then, is it really so bad? Does PBS make censorship actually really that much worse? And I think it really does.
01:01:23.090 - 01:02:16.000, Speaker E: We're not imagining the problem, it's really there. And I think one way to see it is just that censorship resistance behavior is really not the default in PBS. So the default is that everyone just gets the best block that they can from builder or chooses the best header more precisely. And if censorship resistance is needed, it's something that comes reactively. It's like someone has to detect censorship and then really have some kind of internal threshold or like some kind of alarm that goes off and tells them, okay, you should be altruistic, there's censorship going on. You should be the one to step up and stop censorship by making your own block and giving up profits. Because that would mean not taking the best block that you're given, essentially.
01:02:16.000 - 01:02:19.088, Speaker E: And I think there's difference between can.
01:02:19.094 - 01:02:38.440, Speaker B: I ask one question? So by stepping up and making their own block, you mean so we are talking about proposers validators and you want them to no longer select the most valuable block that includes the censorship, but make their own block which might be less profitable to them but be better for the system overall.
01:02:38.860 - 01:03:14.576, Speaker E: Yeah, exactly. So essentially just maybe have some kind of internal censorship sensor that goes off and tells them, okay, this transaction has gone for has been in my mempool for 20 minutes the whole time. It was includable, but no one has included it. There is censorship going on. I'm going to make my own block and include this transaction. And obviously if you're some random proposer, you won't make a very good block. That's the whole point of PBS that we don't want to ask proposers to be able to make good blocks in the sense of how much MVV they extract.
01:03:14.576 - 01:04:28.012, Speaker E: And so it means that kind of by default, by doing this, you will earn less than you would have otherwise. If this is how we think about censorship, we're really relying on some proposer to kind of, at some point just decide to be altruistic, and also that they have to be the one to be altruistic, that it's not going to be the next proposer or eventually someone will do it. But I'm going to sacrifice profits to stop censorship. And yeah, I think it's very different to have a censorship resistant model where the sensor needs to bribe all proposers to censor versus just the default is that you can censor and then someone has to decide to do something to stop you, essentially. But even if you don't agree with this, that's not the only problem here. It's also that even this reactive mechanism, this ability that proposers have to basically forego the PBS mechanism for one block or however long it's needed and just basically provide the censorship resistance that the network needs. This is probably not something that's here to stay and probably the main reason.
01:04:28.012 - 01:05:44.772, Speaker E: The second one, it's debatable, but I think the main one is definitely it's part of the ethereum roadmap and we really want proposers to be stateless to be able to not need to be able to make their own blocks, like at all. It's not just a matter of more or less sophisticated, it's really we don't want them to need to have the state and to be able to make blocks. So that this is kind of incompatible with this reactive mechanism because once a proposer detects censorship, we don't want them to go to someone else to get a block. You detect censorship and then you have to go ask some other sophisticated entity to give you a block because you cannot drink by yourself. That defeats the point you would have to go to some other trusted entity and let them provide censorship resistance and obviously it's not what we want. And another reason is that this might be debatable, maybe this is not what's going to happen, but it might be that proposers discretionality is really minimized even further to the point where not only they're normally getting blocks from builders but they really cannot choose to do otherwise. Their choice is really limited to a few good headers that builders have made based on how much these headers are paying.
01:05:44.772 - 01:06:44.772, Speaker E: And for example, this would be the case in mev smoothing. Like it's basically how the mechanism works and it's required for it. So if we did want to go down the mev smoothing route, then we would need to basically not have proposers able to even kind of start this reaction to censorship even if they detected it. And yeah, so far nothing good has come out. Can we still improve on the base PBS censorship resistance, which is not much, and at least go back to what we have today? So if we're not assuming Bribing, we still have this really high cost of censorship where essentially you need to fill all the blocks to censor something and yeah, it seemed very easy. You have all these proposals, you're assuming here again, we are assuming that they're not Bribable or a lot of proposals are not Bribable. So why don't we just let them add transactions.
01:06:44.772 - 01:07:42.532, Speaker E: They can have some a little power to add some transactions and then these transactions are what kind of keeps the model from today that gives the censorship resistance. And so for example, a naive solution would be the proposer just includes a bunch of transactions in the header before signing it. So maybe the builder creates a header but then the proposer, before signing it, can modify it and add some transaction and maybe they have a little gas allowance, like not too much and then the next block has to execute them. And so this basically amounts to the proposer having their own little dedicated block space that doesn't participate in PDF. So basically that they're not selling out to builders. This seems promising except, well, there's one really obvious problem that we're basically reintroducing the problem we had before. Now we're giving the proposers this power to control this little part of the block again even if they're participating in PBS.
01:07:42.532 - 01:08:35.752, Speaker E: And what should a proposer that wants to maximize profit do? They should either specialize so that they can use this. Power well, or they should go sell it to a dedicated market. So basically another round of PBS. And so obviously we don't want that. And then another problem that's a bit more subtle but turns out it's pretty annoying and hard to deal with in these kind of schemes is that we have to worry about what happens if these other transactions which are included are not valid anymore. Like maybe the proposer was acting honestly, they put valid transactions but then after executing the builder's payload they're not valid anymore because maybe the balance of the sender is not enough or something like that. And the question is should someone pay for them? Or what happens? They're in the block but they don't get executed and they don't pay anything.
01:08:35.752 - 01:09:19.672, Speaker E: And the problem is that if someone should pay for them, then it has to be the proposer because this transaction might literally not have a balance to pay with. And if no one has to pay for them and of course if the proposer has to pay for them then well, this obviously is not going to work. You can't ask proposers to kind of this is asking them to be even more altruistic than before. And if no one pays for them, then they get free data availability. They just can be essentially abused to introduce data for free into blocks which for example a roll up could do something with. And so yeah, we don't want to have these free resources lying around. So this kind of leads to some of the main design goals that we want to have.
01:09:19.672 - 01:10:14.360, Speaker E: If we're trying to design a sensor resistance scheme for PBS, which is the main one, and this is why it's on top, is that we really don't want to kind of sneak in Centralization by we kicked it out by tried to kick it out by introducing PBS, and we don't want to then modify PBS to introduce Centralization again. On the proposer side. And so that's probably the biggest, most obvious goal. Then again, no free data availability as I said before. And this is again really tricky and we want to be compatible with stateless proposers. So we don't want proposers to need to execute anything and we don't want to require a lot of altruism. If we do need to require some altruism, it shouldn't be expensive, it shouldn't be something that consistently makes you miss profits essentially.
01:10:14.360 - 01:10:58.212, Speaker E: And we want to require not a lot of extra bandwidth. So for example, even in the scheme before we might have extra things which end up in the block. They're redundant and they get gossiped twice. Like essentially the block becomes bigger but with no extra information. There's just maybe the same transaction twice and we don't want such things. And yeah, there's some other kind of maybe well yeah, I didn't put in there, they're not essential but also because they kind of don't fit the current scheme that I'm going to present is that it would be nice if it was compatible with MB smoothing just for long term. If we wanted to do MB Smoothing, it would be nice to have a scheme that works with that and with Ssle, which is a secret single leader election.
01:10:58.212 - 01:12:11.996, Speaker E: So we'd like something that doesn't kind of break or trying to do with secret single leader election, which is that the proposer isn't known to anyone until they actually do the kind of main proposing act. So in this case, we publish a header and yeah, we don't want more latency and there's probably a bunch of other things actually we maybe didn't think about maybe in the scheme that I'm going to talk about, there's some problems that come from this and so if you think of anything, just tell some of us. Yeah, IBRS is basically the scheme that comes from refining this naive solution by trying to kind of kick out all these problems and kind of stick into the design goals. And the idea is really simple. The point is that we want to go back to censorship being really expensive and precisely that to censor, you need to fill up blocks. Like if I want to censor transaction, the block in which it should have been included needs to be full and I need to pay to actually fill it because with 1559 that cannot happen indefinitely. And yeah, basically it looks a lot like just normal Pts, except first the proposer broadcasts a list of transactions.
01:12:11.996 - 01:13:01.612, Speaker E: So kind of like before. And yeah, we have this requirement that only one sender is in the list at once, that each sender is in the list at most once. And then the proposer also broadcasts basically a summary of the list which is essentially just a bunch of pairs that are like the sender and the gas limit of each transaction. And this is signed. And then the builder just takes this list summary. So not the actual list, just this smaller summary and puts it into the body and then needs to kind of respect this list that's been put in by having some validity conditions related to how they can construct the block and then everything else just Pts. So from basically three to five is just regular Pts.
01:13:01.612 - 01:13:58.636, Speaker E: Like the builder has made this block, they send the headers, the proposal, accept the best one and then it's published. And then there should be a six which is testers have to kind of check these validity conditions when attesting to something and yeah, this kind of secret ingredient to make it work is this validity condition which is essentially that for each of these pairs. So remember, each pair corresponds to a transaction. In this cr stands for censorship resistance. So it's just the list of things that the proposer is trying to give censorship resistance to, I guess you could put it. So for each of these pairs we have one of two conditions needing to hold. So either there is no space in the block for this transaction, so the gas used of the block that the builder made plus the gas limit of the transaction doesn't fit into the block.
01:13:58.636 - 01:15:16.584, Speaker E: So the builder really filled it up to the brink and then this transaction is too big to fit and that's fine. Basically, we don't consider this censorship, the builder filled the block, so either they paid to fill the block or there were enough transactions to include and so we don't think of this as censorship and otherwise the sender needs to already appear somewhere in the block. And basically the reason for that, I mean, for the first part I already said it, but for the second condition is that this has to do with this validity problem that we were talking about before. So the fact that something might not be valid even though it was valid at the beginning of the block, but this can only happen if there is already a transaction by the same sender in the block. So basically, if you send a transaction and it's valid at the beginning of a block, then after at the end of the block, it can only be invalid if your same address did something like there's another transaction from the same address which spent some gas or maybe the transaction is the same nonsense or something like that. And so basically, as long as at least one transaction from the same sender is in the block, then we don't have to worry about this. Or if there is no transaction from the same sender, then it is not possible that it is not invalid.
01:15:16.584 - 01:16:36.164, Speaker E: So it will be able to be included essentially, if there is a transaction from the same sender in the block, then essentially we don't care if you want censorship resistance for a transaction, then just send them one at a time, that's kind of the point. So no one really loses anything by making this simplification, essentially. And so yeah, with these related conditions we're guaranteeing that everything that could have been included in Cr list is included essentially in the block without having to put everything in the block. So there's no free data availability except for this pairs, but it's not much. And actually we can make this a bit more sophisticated and get rid of almost everything and really make it so that only things which are included, which are actually executed and valid are in the block or even have a little bit of data in the block about them. And yeah, now to think about, why does this disrespect our design goals? First of all, again, centralization is the key issue. So when no one is censoring, the proposer literally has no power because basically if there is no censorship, then builders wouldn't make a block which has space for transactions that the proposer included in Cr list.
01:16:36.164 - 01:17:22.992, Speaker E: Like either the transactions are already included basically if the transactions are valid that the proposer chose, then they will definitely be included by the builder, because there's no point in not including them unless you specifically want to censor them or the bot is full. But that's also okay. So basically the proposer is not able to constrain builders to do anything else than their normal behavior unless there's censorship going on. Then about data availability, as I said, only this sender guest limit is actually in the block and so it's pretty minimal and we can do fancier things to get rid of it. Yeah, bandwidth. Also the block doesn't require a lot of extra bandwidth. So basically the main thing is just the gossiping of Cr list.
01:17:22.992 - 01:18:12.708, Speaker E: So some transaction will be gossiped twice in the form of Cr list. And yeah, we don't require a lot of altruism or it's not very expensive. Everyone should be making this list consistently. But unless they're censorship, then it should never cost anything and neither effort nor missed profits. There's no problem with stateless proposals because proposals are not executing anything. And then there was these other two things which were smoothing compatibility to med smoothing and secret single leader election compatibility. And unfortunately this is not good in this scheme, we are not really compatible with these things.
01:18:12.708 - 01:19:15.232, Speaker E: In this basic version, we can do better. I'll go back maybe to show why, but for secret single legal election compatibility, the problem is that the proposer is broadcasting a list before or I mean, one of these two things, or both, before they act to publish the winning header. And so they have to do two actions and in this time someone could figure out who the proposer is and potentially doss them. Basically, I mean, they have to reveal themselves before they should. So there's this problem and this maybe we can get around it by having things happen over more than one block, but it's still to be kind of thought about more thoroughly. And the mev smoothing compatibility, it's a bit more complicated. The problem is that the proposer so one thing I didn't say is that one reason why this worked that I didn't mention is that the proposer could broadcast some complete nonsense.
01:19:15.232 - 01:19:47.280, Speaker E: Like they could broadcast the list of things which are not available, which are not even transactions, they could not broadcast anything. But the point is that builders will not accept this. Like if I'm a builder, I see something that doesn't make any sense, I just won't make a block. So for the proposer to broadcast nonsense, all it does is just kick out builders, like just prevent builders from making a block. And so essentially it's the same as the proposer just renouncing the right to participate in PBS. If they want to make a block, they have to make it by themselves. Essentially.
01:19:47.280 - 01:21:30.340, Speaker E: The problem with that is that as I said before, we don't want proposers to have this discretionality in MVV smoothing, it really relies on the fact that everyone can observe builders bids and then attesters can vote on it and they can kind of enforce that best one is chosen. And so yeah, the proposer here can just broadcast some nonsense and then essentially they become the only builder that can bid at that point. And so they can kind of get around the smoothing constraints essentially and not pay up pretty much. And this is actually a bit trickier to deal with. And yeah, at the moment not really sure how it can be done, but hopefully it can. But another question is can we do even better than now? If you remember this scheme, and if you think about it, it should make sense that this scheme essentially tries to give back to restore the censorship resistance guarantees that we have now today, if we're not assuming Bribing is going on. And so can we do something that is even better, that is purely economic in the sense that doesn't require any participation from proposers? Well, the minimal level participation of choosing bids in some auction, but not specifically, something like making this list or like before in the base PBS, something like stopping participation in PBS and making their own blocks, like not requiring this kind of activity from proposers, but really just requiring proposers just to choose bids.
01:21:30.340 - 01:22:45.016, Speaker E: And also just essentially something that is like bribe resistant and maybe we can this is something that really needs to be worked on. But another idea that was in this post from Vitalik, and it was basically this idea that the reason that we get this really high cost to exclude a transaction today can also be thought of as you need to beat the transaction in a lot of auctions. There's like, essentially a block sorry for the horrible picture, but there's a block, like partition allow slots, and you need to beat the transaction in an auction. That happens in every slot. So if I want to exclude a transaction, I have to exclude it from this slot, this slot, this lot and so on for all the slots in the block. This basically is the idea, just that if someone is naively choosing transactions like the normal guest kind of making a block, then you just have to have a fee that's higher than the sensor transaction in every slot. Let's say it would be nice if we can kind of restore this many auctions property, but with proper auctions.
01:22:45.016 - 01:23:09.796, Speaker E: So not auctions. First of all, these are not really auctions. But anyway, the general way that a block is constructed today is there's no privacy in the auction. And so bribes are possible. And also there's all these problems that come with not having privacy for these bids. And I mean, why we're moving to PBS and all that. So I'm not going to go back to that.
01:23:09.796 - 01:24:31.900, Speaker E: But yeah, it would be great. Essentially we can have the same property, but with these proper options with privacy, and so essentially have a block deconstructed by a lot of PBS style options. So with privacy but in parallel, and then the executable part of a block would be the result of combining all of these winning bids. And so the point of that is that essentially censoring, again, would require that every auction where there is a bid which contains the transaction that you want to censor, you need to win, and so you need to outbid in every slot. And yeah, another reason that we might want to move to something like this rather than something like hybrid PPS is that it might be a lot easier to adapt this to a world where we have account abstraction, essentially. And I don't want to go too much in detail of this also because I'm not sure how much time I have. But the rough idea of what's the problem with the account abstraction and IPS, or just in general, censorship resistance in an account abstracted world, is that basically the things whose censorship resistance we care about are some objects which are less than transactions.
01:24:31.900 - 01:25:41.730, Speaker E: So what we today think of as transactions might be bundles which have a bunch of these user objects, like, essentially things which might not be whose payment might not be clear. Like they might be things that pay in, ERC, 20 tokens. Or they pay in some obscure way that only the user and the bundler or the person that includes this object know. And so we don't really have kind of a clean way to treat these objects just like we do transactions today, but we want these things to have sensory resistance, we don't want the bundles to have sensory resistance. So we kind of want a more granular sensory resistance than the objects that we're actually able to, let's say, know about at a consensus level, or at least we know a lot less about them than today. We don't even know how they pay, for example. And so there's essentially this problem and this many auctions approach might be a lot more flexible and kind of be able to be completely agnostic to such issues.
01:25:41.730 - 01:26:37.990, Speaker E: How does it exactly work? How do you combine things? What about all these design goals, blah, blah, blah, and yeah, I don't know right now, maybe Vitalik does, I don't know. But maybe some of you who are listening will think about this and know eventually have a really good way to have this even better. I mean, we'll have a really good scheme for combining things and not kind of introducing all the problems that I talked about. So, yeah, just if you're interested in this stuff, start from the design goals and think about how can you apply these to this potentially better sensory resistance model with parallel options. Really? Like, small ideas can make a big difference because there's basically almost no previous work on. And that's it.
01:26:39.320 - 01:27:02.472, Speaker B: Yeah. Thank you very much for the presentation. So does anyone from the audience have a question? I think I saw at least one. I think I saw one from Kushal. So he says, question for Francesco. If I understand you correctly, in the hybrid PBS wouldn't validators again, have to specialize for proposing the censorship resistant list. I think that's not the hybrid PBS.
01:27:02.472 - 01:27:09.790, Speaker B: I think that's the other solution, right, where you add a list with, yes.
01:27:12.660 - 01:27:56.812, Speaker E: I guess, yes, this would be the case. And that's the problem. This would be this problem here, which is like, if I have this power, then probably I should use it maximally profitably. And so there's a pressure to specialize or to sell your power, just like today. And so we haven't solved anything. But in Ivpvs, the thing is that basically there's this line which is essentially that something needs to be in the transaction, needs to be in the block only if there is enough space for it. So what you should think about is essentially the builder makes the block that they like.
01:27:56.812 - 01:29:14.790, Speaker E: So the builder sees all whatever mempool transactions, they make a block, they maximize it, maybe everything good, but then somehow there's this transaction which still fits in the block. If this builder isn't censoring, then why is that the case? Like, why are they not including this transaction which is paying them? So essentially the only case that this would happen for the builder to kind of be forced to put this transaction in, that they got from this Cr list is if they actually were intending to censor to begin with. So if like 99% of the time there is no censorship, then 99% of the time it will make no difference what the proposer broadcasts in the sense that no matter what they broadcast either the builder was going to put it in anyway because they're not censoring and so they want to put all the things that they can find or the block was already full. And so it doesn't matter. Essentially the idea is cr list only matters if there is censorship already, where censorship is defined specifically, as in there is space in the block, but the builder is not using it. And yeah, that's it. Let me know if that didn't quite answer your question.
01:29:14.790 - 01:29:16.650, Speaker E: Can go back on it.
01:29:17.740 - 01:29:47.730, Speaker B: Yeah, it did for me. So if the person asking the question has any follow up, then please post it. So, let's see, would you be I think given that this was the most advanced presentation of the day, I think it would be good to recap some of the basics of it. So would you say that PBS actually makes the censorship resistance of ethereum in its naive form a lot worse than it is today?
01:29:49.620 - 01:30:47.860, Speaker E: I would say think first of all, if you don't have this model where it's easy for proposers to be bribed, so if someone wants to bribe, they're really not going to each proposer. So if I want to center something for N slots. I'm really not going to each proposer and telling them, please don't put it in, I'm going to give you more than the transaction is worth. Or anyway you think that this is hard to do because the proposer set is decentralized and so on. So if you don't have this model, then it's pretty clearly much worse because we really have this kind of much lower cost of censorship. Like you just have to pay the priority for the transaction for the number of blocks that you want to censor for, whereas here you really need to fill up all the blocks, make the base fee blow up, and even for one block, it can be really expensive. The block is almost empty.
01:30:47.860 - 01:31:33.484, Speaker E: So it's very different if you don't assume that it's easy to go to proposers and individually try to bribe them. But again, even if you do think that that's okay, that's feasible for some censor to do, you still have, I think, this problem, which is I think it's really different that to censor you need to go to all proposers and offer to bribe them and for them to accept the bribe rather than just, okay, I'm going to start censoring. And by the way, also another thing difference is that if you want to censor for one block and you're this dominant extractor, you can immediately do it. No one can stop you in advance. Kind of like you don't need to go convince anyone. You just do it. You don't put it in the block.
01:31:33.484 - 01:32:01.820, Speaker E: And maybe someone can look at the block and say, hey, why is this transaction not in? I saw it in the mempool and it was paying enough and there's enough space and all this stuff, but no one can actually force you to put it in because we have this private option. And so, yeah, you can start censoring and then you really are just hoping that no one is going to stop you. Which I think is really different than actively needing to go and bribe each proposer to censor.
01:32:02.960 - 01:32:57.970, Speaker B: Yeah, and I think maybe another way of framing the same thing would be that if you're the best miner today, even if you have substantial hash power, let's say you have 40% and you have the biggest margins, then you're still only going to mine 40% of blocks. Right. And if you want to censor a transaction, then yeah, to you, the cost of censoring that transaction is the opportunity cost of not including it. But 60% of blocks are going to be mined by other people, right, and they might include your transaction. Whereas if you are the best builder and have the highest margin, then I think there's a pretty high chance that you're just going to win every block. And so the market for building is actually going to be much more concentrated than the market for mining. So my question to you would be given that and given how sort of challenging the solutions are.
01:32:57.970 - 01:33:03.970, Speaker B: Are you even in favor of PBS? And if yes, why?
01:33:05.140 - 01:33:44.972, Speaker E: Yeah, I'm definitely in favor of PBS. I think Vitali did a very good job of explaining kind of why we want to move towards that. But yeah, I don't really see another I mean, I think PBS will happen no matter what. It's just a question of are we going to make it trustless? And in mean we even see it today? Flashpots exist, people run mev geth I don't really see why that wouldn't be the case. Even before in Protocol PBS, we're going to have mev boost and it's the kind of rational conclusion of the forces at play. So I think it's not something we can stop. We can only try to make it as good as we can.
01:33:44.972 - 01:34:26.750, Speaker E: And I think making it trustless is a step in that direction. But also another point is that I don't actually think the solutions are too bad. It's going to look very bad if you look at this presentation. I know I went through things very fast, but actually what's written here is quite simple. The last three parts are really just what happens in PPS today and then everything else is just the proposer has to broadcast it's. Basically the proposer chooses some stuff, broadcast it out, and then the builder does something with it and that's it. There's no interaction and there's really not like this validity condition is very simple.
01:34:26.750 - 01:34:58.016, Speaker E: This is not perfect. There's some issues with the Ssle, with smoothing, but for one thing, smoothing only comes with PPS anyway, so we wouldn't worry about smoothing if we didn't have PPS to begin with. But yeah, I actually think this is not so bad and this is stuff that's been thought about in the last month maybe not even. So hopefully we'll come up with much better schemes.
01:34:58.208 - 01:35:36.812, Speaker B: Yeah, I agree. I think the list approach looks quite good to me. And I think the big point that I think we would want the audience here to walk away with is that PBS, as it means sort of the division of labor between proposers and builders is happening. It's only like a matter of if you want to put it into a protocol or not. It has been happening for a long time. Flashbots is just a form of PBS, but it's happening outside the protocol. And to make it work there, as I tried to say in the very beginning in my intro talk, it requires a lot of trust in each other from the different participants.
01:35:36.812 - 01:36:30.656, Speaker B: And as a result of that trust, we create choke points for a system like Ethereum and we also become forced to exclude some of the less trustworthy, smaller participants. Right. So I think that again highlights why we want in Protocol PBS in spite of the challenges that it brings, because we have to compare to the challenges that already exist. And even though a system like flashboards is not getting exploited today by miners, it could well happen and there could well be pressure exerted on it from the outside. And I think this is all stuff that if we want to preserve ethereum's decentralization, then it's going to be very important. So, yeah, completely agree with you. Some questions about mev smoothing.
01:36:30.656 - 01:36:39.990, Speaker B: So you touched on this very briefly. So what is mev smoothing and why might we want it?
01:36:41.000 - 01:37:29.860, Speaker E: Yeah, so the mev smoothing is basically at a very high level, just trying to distribute mev rewards smoothly, like uniformly over the validator set. So let's say in a month there is I have no idea what the numbers actually look like, but let's say like 5 million of med. I don't know. We want each validator to get exactly or very rough, not exactly, but yeah, to get around their fraction of it. So if there is 300,000 validators, they should get 5 million divided by 300,000. So that kind of everyone gets their own fair share. I mean, fair is a loaded word, but okay, in this context we just mean like based on if you control ten validators, then you should get ten times more than someone that controls one validator.
01:37:29.860 - 01:38:54.944, Speaker E: And yeah, the reason to want that is there's a few. But I think the really key one that's very important is trying to protect or to have as much consensus stability as possible, to kind of protect consensus from the instability that comes with med. A lot of times people worry about mev in terms of what happens to users so that they can be front run, things like that and decentralizing effect. So basically what we talked about this whole time, like what we're trying to address with DTS and so on. But there's this other aspect, which is the consensus stability aspect, which is if blocks have very different rewards, like once you add up MVD to the rewards, blocks give their proposers very different amounts of money, then this can threaten the stability of consensus and they can create incentives for reorgs and all these kinds of things where basically someone is trying to take mev that didn't get to them. So my block has so much mev, the next proposer tries to reorg it out so that they can get it. And smoothing basically makes this pointless because it makes it so that no one can within reasonable bounds get more than other people.
01:38:54.944 - 01:38:57.010, Speaker E: Like everyone's going to get about the fair share.
01:39:00.980 - 01:39:03.090, Speaker B: Why is smoothing not possible today?
01:39:05.860 - 01:39:52.496, Speaker E: Well, the main thing that you need for smoothing is basically some kind of awareness. The builder's market, basically you need a way to measure MUV, right? Like you need to be able to know how much is or you need inconsensus to know roughly how much MUV did this block contain. But that's a very hard question. Like how do you measure even if you had all. The time in the world and wanted to go back through the history of Ethereum and measure how much mev there is in blocks. It's not that clear, because it might even be subjective, might be that someone would be willing to pay a lot more for a block because the reasons, they're not so clear to someone that's just analyzing the blocks afterwards. But what you can tell is what the builder's market is willing to pay for a block.
01:39:52.496 - 01:40:17.480, Speaker E: So if you have a bunch of bids in PBS, essentially basically you can take the highest bid as a decent proxy for me. And basically that's what we need. We need PBS, and then we need to essentially have some kind of inconsensess awareness of the various bids that have been proposed so that we can use that as our kind of proxy for mev.
01:40:18.160 - 01:40:32.000, Speaker B: Is it enough to prevent this if the block proposer has zero control over what they can include in their block, so there can be no grounds for any kind of off chain bribing?
01:40:34.340 - 01:40:48.564, Speaker E: So you mean like if we had no proposal and we just somehow had the validators, like a committee pick blocks? Yeah. I'm not sure what you mean, unless it's this.
01:40:48.682 - 01:41:01.080, Speaker B: No, it's fine. We can talk about it later. I think it goes too far. So, last question. How does MUV smoothing affect the censorship resistance of Ethereum?
01:41:02.140 - 01:42:02.024, Speaker E: Yeah, well, maybe from what I said so far, you might think, okay, it's only bad because it prevents us from I mean, if we want to do smoothing, then hybrid Pts doesn't work, and we have to come up with some other modification that works, but I think it actually can affect it quite positively. And the reason, basically, is that it makes altruism a lot cheaper. So we don't want to rely on altruism a lot, but even in Ibpvs, it's like really minimal altruism. But still we're asking proposers to do something that they don't have to do. And I kind of lost over this, but you could think, okay, broadcasting an empty list is optimal because you never exclude any builders. Like, it could be that you broadcast a list, but then some builders don't see some transaction, or maybe they only see the summary. They don't see the list, and somehow they miss some transactions, and then they're kind of excluded from the auction because they cannot make a valid block.
01:42:02.024 - 01:42:48.270, Speaker E: And basically so you take a little bit of risk if you're a proposer and you broadcast a list. Really not that much, but there is a little bit of risk. And maybe, okay, your expected value, if you really want to be strict, is actually a bit less than broadcasting an empty list. But with mev smoothing, whenever we're asking proposers to be a bit altruistic, this bit of altruism is so much less. And the reason is basically that let's say that I'm a sole staker and it's my turn to propose something. But the thing is, the income I get doesn't depend almost at all from what I do in this block. Even if I didn't propose at all, I would lose a little bit of proposal rewards or whatever it's called.
01:42:48.270 - 01:43:31.480, Speaker E: But the mev of this block is not going to me. Only like a super small fraction is going to me. If I'm a sole staker, I only get one out of it'll be like 6000 or something, depending on the committee size. And so I get so little of the blocks MEB that I don't have to hear that much. If altruism is a bit expensive, kind of globally, like maybe it reduces expected value just a bit, then for me it's almost irrelevant. And so I think this is one important part of like if we do have a censorship resistance scheme which does ask bid of proposed, which relies on proposers, then I think it's likely to be better under MEB smoothing.
01:43:32.940 - 01:44:15.178, Speaker B: Perfect. Do we have any further questions? Anyone wanting to join the stage? If not, then I would hand it off to Stefan of Flashbots who wants to talk about the Flashbots Mev Boost proposal, which would be basically a more trusted version, a stop gap on the way to the In Protocol PBS system that Vitalik talked about. Steph, are you here? Let's wait a second.
01:44:15.264 - 01:44:16.570, Speaker F: All right, I'm here.
01:44:16.640 - 01:44:17.018, Speaker B: Perfect.
01:44:17.104 - 01:44:17.718, Speaker E: Hear me?
01:44:17.824 - 01:44:19.120, Speaker B: Yeah. Take it away.
01:44:19.810 - 01:44:26.014, Speaker F: Perfect. Let's see here. Do I need to show my screen?
01:44:26.132 - 01:44:26.462, Speaker A: Yes.
01:44:26.516 - 01:44:28.000, Speaker B: Right, yes.
01:44:41.510 - 01:44:45.060, Speaker F: I might need to rejoin to do that, actually. Give me a second.
01:44:56.030 - 01:46:07.784, Speaker B: So, Tina, if you're listening, you may have to promote Stefan again after he rejoined or any other admin. Yeah, thank you. We can talk about some audience questions in the meantime. So Scott G asks no way to peek at bundles until the builder publishes the body. So I think you may have to specify your question. So in PBS, basically, yeah, Stefan asked to be admin, so maybe we take the question after. But basically there's two connections there, so one is between the users and the searchers and the builder.
01:46:07.784 - 01:46:41.540, Speaker B: So the searchers and users have to trust the builder and this is not going to change with PBS. But then on the other side, right now, there's trust required between the proposer and the builder and that is what is going to be affected by PBS. So In Protocol PBS is going to remove all the trust between the builder and the proposer via the commit revealed scheme. So, yes, the proposer does not see the contents of the block, they cannot peek at the block until it has landed on chain.
01:46:54.870 - 01:48:34.310, Speaker F: All right, I think we're all set. Hey everyone. So, yeah, I'm Stefan, I'm a founder and a steward at Flashbot and I'm going to be talking about mevboost or Mev Boost. We'll see which one sticks. Maybe I think the stage has already been set on what PBS is, what is sort of the long term objectives with PBS and what are the sort of unresolved questions with PBS in the long run? What I'm going to be talking about is what do we have between now and then? What are the tools, what are the systems that we can build in order to try to approximate as much as possible the properties that are provided by PBS in ethereum, sort of as it works today, as it works at the Merge and anytime after until we get PBS. I think probably a good way to introduce this topic is to take a look at a comparison of what are the properties that Mevboost will give us. So right now, the system that runs on top of proof of work ethereum called Mevgeth was launched in January of 2021 and it has provided sort of this block space auction that allows for the expression of preferences on ordering.
01:48:34.310 - 01:50:16.922, Speaker F: And in particular, it allows miners to outsource the task of searching for Mev to a network of searchers who submit these transactions. This has all kinds of positive properties that we've observed over the last year including taking a lot of the competition for opportunities out of the transaction pool, reducing the amount of failed transactions that land on chain because only successful transactions get mined, et cetera. But it has quite a few properties that it did not display. One of them is that so far it has been limited to the submission of bundles to miners, which bundles are just an array of transactions but that doesn't provide full capacity for including transactions or expressing preferences over the order of transactions. In order to do that you need to be able to submit basically full blocks, full block ordering, including having control over the parameters that are set in the block headers because those parameters can modify the execution path of the EVM when the block gets processed. So this is one thing that we want to move towards is sort of outsourcing the full block construction as opposed to just the partial block construction. Another property that Mevboost aims to provide is the ability for solo stakers to participate.
01:50:16.922 - 01:51:47.290, Speaker F: So on the Mev guest system today only large mining pools are able to run this and the main reason for that is that they receive all the bundles, all the transactions in clear text and they have the ability to do this Mev stealing behavior. And to prevent that, basically what Flashbots needs to do is monitor all the transactions get mined by miners and if it observes foul play then it no longer submits transaction to those miners in the future. This means that only sort of large mining pools who have some level of skin in the game and reputation are able to participate in this. But to get closer to the PBS design, we'd want to be able to enable anyone to just turn on their client in the proof of stake land as soon as they have a 32 E stake, then they'd be able to participate as a staker and receive the benefits from Mev without having to do Mev themselves. So that's the second component that Mvboost is designed to do. The third one is client diversity. So Mev Geth sort of has it in the name, it's only built on top of Geth.
01:51:47.290 - 01:53:12.570, Speaker F: And while it is a specification and any other execution client is able to implement the same mechanism, the fact of the matter is a lot of the mining pools have developed experience with customizing guest but not other clients. And so all the mining pools run the same software. With the transition to proof of stake, there's sort of an opportunity for this to change. And there's this wonderful ecosystem of client development teams who are building both consensus clients and execution clients, which we want to make sure that Mev doesn't prevent from obtaining adoption. So, on top of transitioning to full blocks, on top of adding solo staker participation, our goal is also to make the system client agnostic and sort of compatible with any client out of the box. Finally, I want to sort of list the two components which we are unable to fulfill completely without modifications to the core client. And so therefore, the reason why we need to have further research and development into in protocol PBS.
01:53:12.570 - 01:54:25.006, Speaker F: The first one is complete privacy. So, while Mvboost improves things by not sending the transaction contents to the miners, it is still reliant on sending transactions to relays and then trustlessness. So, because in Mvboost relays are sort of delegated the ability to construct a block, the validators need to trust the relays that they are connecting with to make sure that the blocks they are proposing are valid. So, a lot of sort of discussion of the different features here and their impact. But what does this actually look like? So, I've put together some graphics here that give an idea of the various actors in these three systems and how they interact with each other. So, in the current Mevgeth design, we mostly have three entities. We have users and searchers.
01:54:25.006 - 01:54:58.294, Speaker F: They send transactions to a relay. This relay then forwards those transactions to the Miner. And then the Miner produces a block and mines it. Now, in the Me boost proposal, we still have the same concept of users and searchers submitting their transactions. But now instead of sending it directly to a relay, they send it to a block builder. And this block builder is the one that's in charge of forming a full block. This block builder then submits their block in clear text to the relay.
01:54:58.294 - 01:56:01.770, Speaker F: This relay validates that the block is a valid one, that it's paying the validator a sufficient amount, does sort of the Dos protection, and then it only sends headers to the validators. So the relay sees the content of the block, but the validator does not. And then the validator is in task with returning the signed block header to the relay who then propagates it and then finally in the full PBS design we can get rid of the relay entirely. And so the functionality and the work that the relay is doing in MVV Boost is baked directly into the protocol consensus and is no longer needed. So it sort of increases the trustlessness of this design. It also makes it much easier to reason about fewer numbers of actors in the system. Okay, so this sort of presents things as being quite linear.
01:56:01.770 - 01:57:23.478, Speaker F: User sense one builder, one builder sends the one relay, one relay sense, one validator. But the sort of topology of the network that we're aiming to build is much more competitive than that. So in an ideal system we want each of these actors in the system to have a lot of competition. So we want there to be many different alternatives for where users can route their transactions, many different alternatives for where the builders route their payloads and many different relays for which the validators can connect to. And so the biggest question mark in this design and something that we want to encourage is for there to be many different builders and many different Relays who are able to provide this service and for which users can switch away from if a builder, a Relay, does not provide the right properties and guarantees that the user expects. Taking a closer look at how the system works on the validator side. So for people who have set up Beacon clients, they'll be familiar with validator client and beacon clients.
01:57:23.478 - 01:59:09.794, Speaker F: That's sort of how the Beacon chain operates today at the merge what we're going to do is introduce this Execution client and this is basically the current ETH one clients that are being brought into the beacon chain. And this proposal is to insert an additional middleware in between the Beacon client and Execution client that's able to communicate with these outsourced third party relays for receiving block constructions, do profit switching amongst the various different proposals that it received and include the most profitable block as the proposal to the Beacon client. So to get this done, we've done a few steps. Obviously the design and proposal of the system is sort of step one, making sure that we have something that achieves the properties that we want as much as possible. But we also need to make sure that it's designed in a way that works with the various different entities and stakeholders who are participating on Ethereum. So we've put together a working group here with various different actors that play some kind of role in this system. The reason why we think this is absolutely critical is that actually the setups that validators run is very different between different entities and probably each, every single one of these system operates slightly differently.
01:59:09.794 - 01:59:43.400, Speaker F: We have, we have custodians, we have just pure infrastructure providers, decentralized staking pools, centralized staking pools, solo Validators. And one way to think about the difference between all these entities is they'll all run different subsets of these clients and provide different services on top of them. In building a solution here, it's really important that it is compatible and works with all these different systems. This working group is something that.
01:59:45.370 - 01:59:45.686, Speaker A: We.
01:59:45.708 - 02:00:48.214, Speaker F: Are in the process of building and we want to encourage anyone who wants to participate in the design of medboost and development and testing of it to apply. To join this working group, I also want to mention a couple tooling that we want to provide grants for the community to build. One of them is a relay monitoring tool. So basically in the Mevboo system here, when Validators receive payloads from relays, they need a way to verify after they've produced a block that the relay was not acting maliciously and this sort of verification process might be somewhat burdensome to maintain. And so for Solo Validators, it'd be great to provide some tooling that allows them to outsource this monitoring to some third party. So we want to put together some grants and support for building that. And then another one is a one click validator setup.
02:00:48.214 - 02:01:10.100, Speaker F: So I think this is something that there's already a few teams out there building, but we think it's super important to make it as easy as possible for Solo Stakers to set up their Met Boost client and get up and running. So, yeah, that's what I have to present and happy to answer any questions.
02:01:10.790 - 02:01:47.950, Speaker B: Yeah, thank you very much, Steph. Let's see, do we have any I don't think I have seen any questions related to this in the chat, although there's very lively discussion going on and has been all day. So that's great to see. So I know you've answered this, but I think it's very important and so I want to discuss it again. So we asked in this Mev Boost proposal, we are stacking a lot of trust on the relay in order to remove it from the miner. Basically, how can we protect the proposers from a malicious relay?
02:01:52.610 - 02:03:16.170, Speaker F: So the guarantees that the system provides is a maximum of one block loss of revenue for the Validators. Now, there's a couple of different ways that you can operate the system and depending on the type of Validator, their risk tolerance, they can play around with these guarantees by configuring their Mev Boost client differently. But let's just sort of focus on talking about for Solo Stakers, Solo Validators who are operating it at home, which are sort of the target users that we're really aiming to design this for. How do they make sure they can trust the relay so when they receive a header, they don't see the content of the payload, they don't see the transactions, and so they don't really know if the payload that was submitted by the relay is a valid one. So they kind of sign blindly and have to trust the relay that is making a good claim, a valid claim, and then they propose that block to that network. The network then sees the full content of the block. They see the transaction and the Attestation set as part of the block proposal, gets to vote on if the block has been valid or not.
02:03:16.170 - 02:04:08.730, Speaker F: And if the block is invalid, then the validator gets to sort of see that the block that they propose was invalid. It doesn't cause them any loss of fund. They don't get slashed, but it does mean that they miss the proposal slot, so they don't get the revenues from it. And so what you want is a system that's essentially able to notice that there was some fault, some invalid block that was attempted to be proposed by a relay and able to switch away from using this relay. So there's multiple different ways in which the relay can sort of produce invalid blocks. And those are discussed in the E Three research post. But the Mitigation is making sure that Mev Boost on the client side.
02:04:08.730 - 02:04:14.590, Speaker F: So over here is able to monitor the reputation and performance of each relay.
02:04:16.930 - 02:04:25.650, Speaker B: We just received another question from the audience. How does Mev Boost address the problem of mev stealing?
02:04:28.790 - 02:05:37.350, Speaker F: So the main component of it is that the validators never see the content of the transactions until after they were accepted by the network. That being said, it does not prevent builders and relays from seeing the content of the transactions. And so both of these actors in the system still run in the same way as Flashbots does today, right? It relies on the fact that users won't send their transactions to builders who have a history of stealing transactions. Likewise, builders won't send transactions to relays that have a history of stealing transactions. But it does mean that relays can send blocks to any validator without having any risk of any stealing. And so decoupling away the block proposal, which is done on the validator side from the block construction, which is done by the builder and the relay, is sort of where you get this separation.
02:05:42.190 - 02:05:54.350, Speaker B: Okay, that's not relevant. Okay, so my next question, what are the challenges for Flashbots or any other builder in creating full blocks instead of bundles?
02:05:57.330 - 02:07:07.220, Speaker F: So it's a very different challenge when you are acting as a searcher. So we can go back here and look at how the system works today, right? Like, searchers tend to be highly specialized on specific strategies. So they'll only look at liquidations or they'll only look at atomic ARB, or they'll only look at statistical ARB, and they build sort of a moat on this vertical. What they don't have a moat on is figuring out what are all the other strategies that are available in the system. And so this means that there's an opportunity for another entity to come in and specialize on just aggregating the expertise of searchers and this is sort of what the block builder's role aims to be. So the block builders takes in bundles and transactions from varieties of different sources and combines them in whatever way is possible to produce the most profitable block and propose that through the rest of the system.
02:07:10.230 - 02:07:25.580, Speaker B: How has been the process of convincing miners to run this? I mean, given that you touched on stuff like full blocks, take a lot longer to propagate and so on, has it been a challenge or have you even talked to any miners and how they think about this?
02:07:27.230 - 02:07:28.970, Speaker F: Miners or validators.
02:07:32.510 - 02:07:36.478, Speaker B: This is only going live with the merge, right? So, yeah, I guess validators then.
02:07:36.644 - 02:08:16.586, Speaker F: Yeah, I guess I didn't touch on this. Yes. The big transition point that's in between these two is the merge. So Me Boost is a system that's designed to work on top of proof of stake ethereum, and so the parties are involved in running this are all Validator and staking providers. I think I saw a question in the chat about how far along we are. So we have a repository called Mevboost on the Flashpots GitHub repository, which you can keep track of. We currently have four milestones and we've completed the first one.
02:08:16.586 - 02:08:46.920, Speaker F: The first milestone is already compatible with the Kinsugi testnet that is launching in the next week or so. And so we already have sort of the core system running, and now it's all about working on integrations with the full range of consensus clients and providing the tooling for anyone to be able to run the system.
02:08:50.250 - 02:09:18.240, Speaker B: So we touched on that. Centralization can never really be curtailed. It can only be shifted to a different point in the system where maybe it produces fewer negative externalities and is better sort of siloed in some way that we can control it. What do you personally see as the risk of having one dominant builder and what can be done in order to prevent that?
02:09:21.330 - 02:10:39.000, Speaker F: So I think this is a topic that obviously Francesco has spent a lot of time researching and thinking about. I think from a market design perspective, which is sort of my role in this, the goal is to create a system in which there's as much competition as possible, the lowest possible barriers to entry for acting in any of these roles and the ability for new actors to come online and for the ability for users to switch away from actors that aren't behaving in a correct way. This, essentially, I think, is going to maximize the benefit that the users work. It maximizes security of the network and is what's worth designing for. In terms of what are the biggest risks of builders? I think the biggest risk is probably an economic one of having a sort of economic actor within the system that's able to extract sort of systematic rents at the cost of users, whereas with more competition, maybe there would be more user benefit in the long run.
02:10:41.230 - 02:10:47.370, Speaker B: What do you see as Flashbots role once we are in a permissionless PBS paradigm?
02:10:50.990 - 02:11:36.170, Speaker F: In a permissionless PBS paradigm, it's hard to say. It's not something that we've committed to in one way or another. Right now, if we look at the Mev Geth system, we operate a relay and we write the software that the miners run in the Mev Boost system, we're likely to be operating a builder and operating a relay and then be writing the software for validators. Likely that in a full PBS world, we'd sort of revert to only operating a builder, but because all of the sort of software development work for the validator side is baked directly into the clients and the relay doesn't exist anymore.
02:11:37.630 - 02:12:04.130, Speaker B: Great. Thank you. I have no further questions. I don't think there have been any questions related to your talk in the audience. So then I would say let's start the roundtable. The last part of this roast. Thanks a lot, Steph.
02:12:04.130 - 02:12:30.710, Speaker B: Yeah, it's not really a roast. The name is a bit misleading.
02:12:31.610 - 02:12:32.118, Speaker A: Yeah.
02:12:32.204 - 02:12:34.242, Speaker D: So what are we tabling for the roundtable?
02:12:34.386 - 02:12:39.850, Speaker B: Yeah, what are we doing? So who's in the roundtable? I think we are missing Phil.
02:12:44.110 - 02:12:49.402, Speaker D: I guess ultimately you can just start and anyone who's in the roundtable is in the roundtable, right?
02:12:49.456 - 02:13:33.610, Speaker B: Yeah, that's a good point. Let's just allow anyone to join. So this is the time for audience questions. So anything that hasn't been answered so far, or you thought you didn't get a satisfying answer, or we didn't see your question, or you have any more general question about mev and PBS, then now is the time to ask. In absence of any questions for now, let me just start with the first question so vitalik. How do we convince the public that a complex system like PBS actually works and can serve its goal and it's just not some extractive system that we put on top of ethereum?
02:13:36.430 - 02:14:02.340, Speaker D: Yeah, I think it's definitely a challenge. Like the fact that the economics of the system are basically becoming more complicated. And even if we have fancy arguments for why we believe that the equilibrium is still one that preserves all of the things that are good and true and beautiful about blockchains that.
02:14:04.950 - 02:14:05.574, Speaker A: It gets.
02:14:05.612 - 02:15:14.300, Speaker D: Harder for people to essentially tell that apart from techno babble, I guess the things that we can do on the margin are again, one is obviously just doing a better job of explaining the concepts and doing just a better job of communicating the fact that here, these are the goals that we are all working toward and that there is this large community of researchers that actually is interested in making sure all of these goals are satisfied and that there isn't some kind of conspiracy to centralize ethereum extraction or whatever.
02:15:15.790 - 02:15:16.540, Speaker A: Actually.
02:15:18.990 - 02:15:36.980, Speaker D: It is, I think, hard to get far beyond that point right now, especially because we're not quite yet at the stage where all of the experts even are convinced that there's some particular version of PBS that accomplishes everything that people are looking for?
02:15:42.630 - 02:15:43.620, Speaker A: I don't know.
02:15:44.710 - 02:15:54.120, Speaker D: I don't really have anything to say that's much wiser than just try harder at talking about it more and explaining everything that's going on in queer ways.
02:15:55.690 - 02:16:52.140, Speaker G: So I think one thing that will help a lot is the transparency that this new market provides, like the block market basically, so we'll be able to quantify, at least to an external observer, kind of how much mev there is. And I guess this transparency could get even better in the sense that we can even in the context of mev smoothing, make this an on chain oracle. But that's kind of a side note. And then what we can do is we can kind of try and see where all this mev goes. And I think to a large extent what will be extracted will just go to the validators. And the fact that it goes to the validators is ultimately a very good thing because it means that we're going to have more validators, more security for Ethereum and then that then leads to more economic utility for the whole platform.
02:16:53.790 - 02:17:35.000, Speaker H: Yeah, maybe. I'll also jump in and say that I think there's a few other tacks that we can take in addition to this data providing transparency that'll help the community a lot. One of them is extending this transparency work we've been doing on Ethan that we're talking about here to other chains and that's something that we're going to have more information about soon. Stay tuned on that. And another related research effort is coming up with a theory of L One design and mev informed L One design and how mev manifests on various L ones that's consistent with this data we're showing people. And I think if we do that, it'll really help people understand the design trade offs a lot better than they do now.
02:17:37.370 - 02:18:03.710, Speaker G: I think another aspect is also just reducing the extraction at the source. I mean, from the point of view of the public as a user right now people are really complaining about the high fees. If in the future they feel like they have very low fees and they're not getting front run every time they make a trade on uniswap, then maybe they don't need to know how it all works in the background because they can feel that that is the user. They're not getting exploited.
02:18:05.730 - 02:18:24.150, Speaker H: I agree. I think we need to have a concerted effort to educate users on fairness and the Mev was in some way intended to start that conversation. And I think the L ones can do a lot to educate people, but also the DAPs can do a lot to educate their users about their specific DAP and how their DAP is affected.
02:18:27.690 - 02:19:33.210, Speaker B: That's a good time for my next question. One of the best ways to prevent the centralization that's coming from mev. Extraction is to minimize the amount of mev that is actually there for the taking. Over the last six months, I would say a lot more people in this community and in this industry have become aware of the problem. Users have changed their behavior, whether it be using private relays or just using protocols that are more mev aware. And also depth designers are now thinking about mev basically from day zero and building mev protection into their protocols. How satisfied are you or how are you thinking about the progress being made there? Are you satisfied with the pace that we are going at? Do you think there are any low hanging fruits that applications and users are not thinking about? And yeah, what are your general thoughts on this? Anyone want to take a step?
02:19:36.640 - 02:20:22.810, Speaker H: I'm honestly pretty satisfied with the way all of that side is going. I think all of the large DApps that have mev have manifested kind of the relevant problems because of the amount of usage they've seen and have been thinking about this pretty critically. A lot of them are engaging with us, a lot of them are engaging publicly on Twitter. I expect the next one to three years will be a pretty big time for kind of DAP design and figuring out how to tackle mev and also how to educate users. But I do think it's kind of happening and enough catalyzing has basically gone off in this space that I think it's pretty much inevitable that they will kind of educate users and they will have to address these issues.
02:20:24.540 - 02:20:33.310, Speaker D: I think the mainstreaming of uniswap front running protection has definitely also done a lot of good in that regard.
02:20:38.960 - 02:21:36.290, Speaker G: I mean, if we take the long term and we zoom out, I guess the searchers are inherently decentralized. The users also the DApps as well. The main point of centralization will be the builders. And I think there's maybe somewhat advanced strategies out there to reduce the power that they have. So for example, if the bundles have some sort of access list which says, okay, I'm doing kind of uniswap arbitrage and another bundle does something else, then maybe they could be trustlessly packed into a block without necessarily having to trust an actual builder. So that could be done in the context of an NPC, for example, these very simple NPCs that just look at the access list and then build a block from that.
02:21:41.060 - 02:22:21.260, Speaker D: Yeah, especially if the best mev opportunities end up coming from these specialized searcher environments, then that by itself will just create pressure for builders to internally create these searcher like these SGX based or whatever based designs that basically protect the free trade privacy of the searchers. And if that happens, then we'll just get censorship resistance back in a different way because everything that's provided by searchers will be encrypted before it gets revealed.
02:22:24.640 - 02:23:09.980, Speaker G: And one thing that I'm a little bit worried about is this idea of deep packing of bundles, because the naive way of putting several bundles in a block is just to kind of concatenate them. But what if you have an even more sophisticated strategy where you inspect inside the bundles and then you kind of reorganize the transactions and insert things in such a way that you're really optimal. I mean, one simple thing you can do, for example, is that every transaction has this minimum gas cost of 21,000 gas. So if you can pack everything in one big transaction, then you're doing better. And then that starts to become very sophisticated and brings back centralization at the block builder stage.
02:23:11.600 - 02:23:50.008, Speaker B: Yeah, I think it's just I mean, as Vitalik said as well, I think it's inevitable that there will be centralization in some part of the stack. Right. Maybe it's better for it to be in the block builder. I mean, definitely. I think that's what also I was talking about with some people in the audience while the presentations were going on, but that being a block builder is not easy. There are a lot of unique challenges in doing a good job at that. And one of them is definitely getting all the bundles and getting all the transactions, but the second one is having a good algorithm and a good system for merging them together.
02:23:50.008 - 02:24:12.770, Speaker B: And then on top of that, having a good way to get them to miners in the shortest possible amount of time. And none of this is really stuff that searchers are doing right now. I think this is like a whole new class of a highly specialized actor in the system. And I think it's quite likely that we are going to see a very big amount of centralization in that area.
02:24:16.740 - 02:24:18.070, Speaker E: One other thing.
02:24:19.080 - 02:24:20.084, Speaker F: Go ahead.
02:24:20.282 - 02:24:32.152, Speaker D: We both wanted to bring up tangents, I guess. No, the tangents I wanted to bring up was what would mempools look like in this kind of world?
02:24:32.206 - 02:24:32.472, Speaker A: Right?
02:24:32.526 - 02:24:52.690, Speaker D: Because if users send their transactions so that they're only visible to some people and not others, then that could also be a source of winning builder advantage. So I wanted to get other people's opinions on how to, I guess, deal with that, mitigate that or handle it in whatever way.
02:24:55.220 - 02:25:25.560, Speaker B: Okay, I can take a step at it. I think that transactions, I think I'm going to predict the death of the public, mempool. So I think that the biggest ingredient actually for being a good block builder is having access to transactions that others don't have other builders. And so if we think this thought to its logical conclusion, then I think it's quite possible that builders are going to start paying users for their transactions.
02:25:31.280 - 02:25:32.750, Speaker A: I guess one.
02:25:34.960 - 02:26:32.190, Speaker D: Counterargument there is, let's say I want to send a transaction that is just obviously not mev vulnerable, right? So let's say, for example, I'm just using east to pay for a proverbial coffee. Then what is the it seems like it's in my interest to want to distribute that transaction to everyone. I think we want an outcome where that transaction gets distributed to everyone, right? Because if it doesn't, then it's just going to end up needlessly getting delayed. So what would my incentive be as a user to not broadcast that transaction through a system that gives it to everyone? And if the answer is the builder will pay for it, then what is the builder's incentive to pay for it?
02:26:33.520 - 02:26:51.860, Speaker B: Right. They wouldn't pay you any more for it than you would have to pay in a public mempool in this case. Yeah. So for transactions that are not mev relevant I totally agree. It's just for those where arguably there's not an efficient bidding process going on right now where users are overpaying.
02:26:56.220 - 02:26:57.290, Speaker A: Seems fair.
02:27:00.060 - 02:27:02.760, Speaker B: Any other takes on the future of mempools?
02:27:05.660 - 02:27:08.080, Speaker A: One thing that I'm kind of excited.
02:27:08.180 - 02:28:25.680, Speaker D: About PBS enabling is it allows off chain experimentation in alternative mempools. So probably the most famous example of an alternative MEMP pool now is ERC 4337. So like I can abstraction where basically you do it without requiring protocol changes by having users send user operation objects and those objects would get broadcasted around a dedicated mempool and then you would have builders gather up these objects and then package them up into a single transaction that wraps around all of them. But then that's only one example of what you can do with alternate mempools. Right, just to give a couple more examples, one really powerful one is BLS aggregation for validity. So let's say user operations would have BLS signatures and then those BLS signatures could get aggregated and instead of every single user operation having a separate one, the entire bundle would be able to have a one single 48 byte BLS aggregate.
02:28:25.760 - 02:28:27.316, Speaker A: And so you would save costs, but.
02:28:27.338 - 02:29:00.590, Speaker D: That would require another custom algorithm for actually aggregating them together. Another really interesting one that I think is going to be very important long term is Snark aggregation. Like basically recursive Snark aggregation for roll ups. So the use case here is like imagine you have five different ZK roll ups but they don't want to pay the 500,000 to 5 million gas overhead for submitting their proofs. Then you could imagine asepstama where there is one.
02:29:03.540 - 02:29:05.184, Speaker A: Single Snark that goes on.
02:29:05.222 - 02:29:59.890, Speaker D: Chain and that single Snark basically just proves over the narcs of all of the roll ups. And so we basically have this off chain process of making a proof of all the proofs and that proof goes on chain. And then the roll up contracts know to recognize that proof of a proof in place of a regular proof. And so you get to submit bundles for all the ZK roll ups paying the 500,000 gas NORC tax once instead of paying it many times. So there's a lot of these situations where you get benefits out of just different kinds of off chain aggregation. And one of the beautiful things of PBS is that the mem pools that do this off chain aggregation can get developed and refined just separately and over time without actually needing to have protocol hard forks for it.
02:30:03.380 - 02:31:05.700, Speaker G: So, on the topic of the death of the public mem pool for mev relevant transactions, I would agree in the medium term, but maybe not in the long term. And the reason is that there's kind of this cute trick where you can transform a private mev transaction into a public one and it involves like in the best case, you would use kind of something called witness encryption. And so the idea is that you have a message which you encrypt and it kind of automatically decrypts itself as soon as it's included on the chain. Now, there's kind of things which are not as powerful as witness encryption because that's a very strong cryptographic. Primitive things like threshold decryption or time lock encryption are kind of substitute for that which allows us to provide privacy for the mempool and then have public transactions once these transactions are on chain.
02:31:07.020 - 02:32:08.840, Speaker B: I would argue that this doesn't solve the problem for the user because the problem isn't just privacy, it's not just your transaction not getting involved, not getting included with pretrained privacy, but also you overpaying for the transaction. I think that's arguably the even bigger problem. This is not a problem that is solved by tree trade privacy, in my opinion. Because in theory, if a transaction has some mev value, let's say it's a trade that can be background in the protocol, and this transaction has a financial value that if you're encrypting it, you're giving the value away even though you don't have to. So if you allow someone, if you give it to someone in private and allow that person to bundle it with the background, then this would allow you to lower the price of your transaction or even make it negative. So that's what I meant by you can get builders to pay you for your transaction.
02:32:11.790 - 02:32:25.870, Speaker G: So basically are you saying that a user is making a suboptimal transaction and he could get paid for having his suboptimal transaction kind of corrected?
02:32:26.610 - 02:32:27.760, Speaker B: Yes, exactly.
02:32:29.010 - 02:32:39.038, Speaker G: I mean, isn't the solution just for that builder to just correct it himself or use a service that does that on his behalf?
02:32:39.214 - 02:32:47.170, Speaker B: That's what they are doing. Right? You could use a transaction.
02:32:48.330 - 02:33:06.010, Speaker G: Right, but I guess that's not mutually exclusive with a public mempool. You could find someone who will correct your transaction and then you concatenate these two transactions, the original and the correction. You encrypt it, put it in the mempool, and then it gets decrypted.
02:33:07.390 - 02:33:38.150, Speaker B: Yeah, possibly, I don't know. But in this case, the transaction has already been altered. So I think that's where the line blurs a little bit between private and public Memphis. So we don't have to go deeper than that. If we have no further thoughts on the mempools, I would have a question for the group again. Do you think that this PBS research that's happening right now has any implications for the layer two systems like roll ups?
02:33:42.490 - 02:34:39.750, Speaker H: I can take this briefly, I think. Yeah, definitely. I think ultimately every chain is going to need to handle the same mev problems. They're fundamental to designing these permissionless consensus protocols, especially if you want a relatively wide distribution amongst your validator set. And so that includes L two S, that includes side chains, that includes MultiChain chains, that includes any kind of distributed consensus abstraction that's handling value. And I expect one of the things I think PBS is trying to do on ETH is to iterate on sort of a community standard for how to tackle mev in these systems and start producing data on that standard. So I expect some L two S or other chains may adopt similar things or some of them may experiment with different trade offs, which is also useful because then we can gather data on these trade offs and use them to improve all systems.
02:34:44.660 - 02:35:43.600, Speaker G: So I guess my take is that layer two, such as roll up, basically extract the mev, as it were, take it away from layer one and give it to the sequences at layer two. And so in that sense, there's kind of a little bit of an incentive misalignment between the layer one and the layer two. And I think that's fine kind of in the medium term because these roll ups really are providing a very extremely valuable service. But I think in the very long run there is an opportunity to kind of enshrine the notion of a roll up in the shard. So basically, for example, providing execution on shards and kind of bringing back this mev and giving it to the validators as opposed to it leaving the system and thereby making Ethereum kind of stronger from an economic security standpoint.
02:35:49.040 - 02:36:28.330, Speaker B: So Optimism is one of the systems that has a rather unique approach to mev. So they want to auction off the right to run the centralized sequencer who can extract all the mev. And then I think the plan is to create a public goods funding mechanism so use the proceeds from that sale in order to funnel it back into the general OVM ecosystem. Do you think that this approach has any chance compared to a system where the money is returned to the user who cost it?
02:36:38.290 - 02:36:59.910, Speaker G: I mean, I guess it's not completely mutually exclusive, right? Because there's some types of mev which are triggered by users and they could get a refund, but there's some kind of mev which is just out there and latent and which is unavoidable. And then that could go to public funding or it could go back to the layer one and reinforce the economic security of Ethereum.
02:37:02.570 - 02:37:37.978, Speaker H: Yeah, I also have seen Optimism tweet that they've maybe considered redesigning that approach and allowing people to select different sequencing protocols possibly fair ordering protocols as well. So I'm not sure exactly what their latest plan is, I don't think they've put anything out there. But I do agree with the general sentiment that, yeah, there will be latent mevs on the roll ups, and they will need some approach for capturing it and distributing it either to their Validators, in which case you actually don't want it to be excessively large for security, or find some other way to capture.
02:37:37.994 - 02:37:39.102, Speaker A: It through the protocol.
02:37:39.246 - 02:38:32.900, Speaker H: And I think that's actually one of the interesting challenges. Maybe I don't know if we want to discuss it now, but just something that I thought about while I was listening to all the talks. One of the goals that's kind of been mentioned and that we've been talking about since the early flashbots roasts is mev smoothing. And I think it's an interesting idea but there's also a question of how to actually quantify mev and how to prevent kind of side channel based extraction or extraction outside the mechanism, especially in cases where there's potentially like a lot of value at stake black Swan events or other kind of long tails. So yeah, I think that's an open research question but it speaks to the same challenge those protocols will have in capturing mev is like how do you even know what mev is? And I think that is something we're doing active research on.
02:38:34.550 - 02:40:08.970, Speaker B: I would have another question to you guys about L two to stick with that. I think one of the most interesting things we have seen in the last couple of months in the layer two space is in ZK roll ups for users to give users the ability to decide within the same roll up where they want their data to be stored, right? Whether they want it to be stored on Ethereum, where they may have better data availability guarantees or stored on some other blockchain or even by some centralized provider. And users with different data availability guarantees can coexist in the same state. It was for me quite mind blowing to see that this is possible. So do you think that this kind of scheme could exist also in the sequencing space? So basically the idea here would be that you can opt into different sequencing approaches in the same blockchain. Maybe that question is a bit too far fetched.
02:40:11.310 - 02:40:18.650, Speaker G: I mean, maybe you can clarify what you mean by having the optionality to choose your sequencing.
02:40:19.470 - 02:40:31.440, Speaker B: I'm not sure myself, I just wanted to try to be creative and see if it gives you guys any ideas. I don't have anything concrete in mind that I wanted to talk about.
02:40:33.990 - 02:42:06.778, Speaker D: Just the general idea that layer two protocols get benefits by basically deciding their own, deciding by themselves how a transaction sequencing works instead of just depending on whatever Ethereum provides. I guess ultimately they do have incentives too, right? Because being able to decide sequencing does give you mev revenue and if you auction off mev revenue that can be directed toward things as a source of funding. If any of these projects have tokens, then that could be used to support the token and so forth. So there's incentives for projects to try to kind of grab up the sequencing power. There are also things that they can provide that are of value to users if they control sequencing. Right, because I think one of the things that I expect the ethereum layer one does not provide and that some of the more centralized chains do provide, and that I expect lawyer Twos are going to be trying to figure out how to close the gap in providing is 500 millisecond block times. And if you're a roll up, then you do have the ability to basically have a sequencer or some committee of sequencers give pre confirmations, which is definitely something that users are going to find useful.
02:42:06.778 - 02:42:10.590, Speaker D: It does also, ironically enough, reduce.
02:42:12.950 - 02:42:13.266, Speaker A: The.
02:42:13.288 - 02:42:34.200, Speaker D: Quantity of mev that you can extract. But even still sorry about my background brain, it is something that's different from just accepting ethereum default sequencing that a debt project would love to do.
02:42:38.570 - 02:44:01.940, Speaker H: Yeah, I agree with all that. I would maybe even take it further and say that from a pure UX standpoint, if we're just going from mainstream users and the end state of crypto is to be an under the hood primitive in a lot of applications, there probably are a lot of application specific advantages to choosing specific sequencing algorithms that are tailored to certain applications. And I think fast block times could be one on a more centralized kind of chain, but there could be other trade offs, certain exchange apps or certain liquidation apps or whatever else certain games want to make. I think that's kind of the direction Cosmos has been thinking about, at least the conversations I've had with them around mev, is that that could be one place for other chains and potentially L two S to also specialize. If you believe that you kind of want the best UX, it kind of seems natural that this general purpose sequencing algorithm won't be the best for all applications, especially because E as a base layer needs to have certain properties, right? And those properties are, for example, geographic distribution of nodes for resilience solo, validator ability for kind of decentralization criteria and things like that. And those requirements just might not be as strict or might not be there at all, and there may be different trade offs that are better for you.
02:44:15.610 - 02:44:32.960, Speaker B: Okay, I don't have any more questions for you guys, so unless there are any more audience questions coming in in the next minute, I think we can wrap up this event. I just heard, Phil, that you might have an announcement to make.
02:44:35.890 - 02:44:46.050, Speaker H: I guess, I don't know. Alex, are you there? Do you want to make the announcement? If you interrupt in the next 10 seconds, I would prefer you do it since you're the lead author, but otherwise I'll do it.
02:44:46.200 - 02:44:47.620, Speaker B: You said go ahead.
02:44:48.390 - 02:45:22.266, Speaker H: Oh no. Okay, great. So, yeah, very exciting news out of Flashbot's Research. We've been doing both internal in house and external research for a long time. As a lot of you guys know, we've put on many research events, had a lot of kind of interesting talks and whiteboard conversations that are available on our GitHub. We've also published several research roadmaps calls for funding and things like that. So one exciting thing I have to announce today is that Flashbots Research is releasing its first paper and it is, in my opinion, very much worth the read by everyone on this call.
02:45:22.266 - 02:46:12.074, Speaker H: It's a work in progress paper, so don't expect it to be kind of peer reviewed, academic kind of quality, but it is at the phase where we're excited to share it with the community and with all of you and see your thoughts and your feedback. The paper is about cross domain mev, so we take a look at formalizing mev in a MultiChain, multidomain world. This includes things like layer twos and centralized exchanges and we study kind of the implications and the formalization behind this new MEB game that's emerging. So we expect this research to inform the basis of a lot of our events and a lot of our decisions going forward. Mostly we just want to have conversations with people who are interested in the research. So the author emails are listed on the paper. If you want to access the paper right now.
02:46:12.074 - 02:46:47.740, Speaker H: Sorry, I skipped that part. There is a link in the agenda under, I believe, the extra credit heading. It's the first link there. Please wait to tweet about it. We're going to have a Twitter thread circulating momentarily with Alex kind of tweeting about this paper. So I encourage you guys to amplify that because I think it's really something that's important to discuss and that's going to be relevant to all DAPs, to all L ones, to all these kinds of systems going forward. And I'm really excited to kind of start the conversation as original work coming out of Flashbots research over the last six months to a year really, that we've been doing.
02:46:47.740 - 02:47:24.958, Speaker H: So that's all for that. Another announcement is I'm not sure whether we made the final call, but I believe also today we will be unveiling the Flashbots writings website. So stay tuned on Twitter for that. Either Alejo's Twitter or I'll amplify that as well. So we're going to be releasing a central hub for Flashbots writing pieces that's going to include our research. It's going to include comments on things like public proposals about PBS and other topics of this call. And we'll include things like simpler versions of the paper as well that can be circulated to a broader audience.
02:47:24.958 - 02:48:28.118, Speaker H: So we're really excited to start writing on the site. It's just a GitHub repo with markdown files. So if you'd like to contribute to flashbots research to flashbots writing we are an open source hacker collective style organization and we're happy to talk about all kinds of contributions, whether it's from Anans, whether it's kind of a consulting, part time engagement with the group, whether it's just open source, any medium. If you're interested in collaborating on open source mev research, please do reach out and please do check out those two resources as they come out. The cross domain paper and the Writings website. The Writings website is also going to have an inaugural post that's very exciting. That's going to talk about the mev definition itself and a lot of confusion recently about what is arbitrage, what is mev, what is the difference? Between these things that will also be on the website, as well as talking about the generalization of Mev into maximal extractable value and why the definition is still meaningful for reasoning about consensus systems and for formalizing these games that we're talking about.
02:48:28.118 - 02:48:59.442, Speaker H: So very excited to have more conversations on all of that. I think I'm going to hand it back to Hasu now. I see a bunch of messages in the chat I missed, so if there are any questions or anything like that, happy to address them. But yeah, please keep an eye out for those two things, the cross domain paper and the Writings website with its inaugural post about maximal extractable value. And thanks all for attending, it's been really good to have a roast. I know it's been a while. We've been very heads down, working on a lot of things that we're very excited to share with you and I'm very happy to have these community events again.
02:48:59.442 - 02:49:03.700, Speaker H: So thank you everyone for being here and for contributing positively to this.
02:49:04.970 - 02:49:33.230, Speaker B: Yeah, thanks a lot, Phil. Those are very exciting announcements and yeah, should all make sure to read the papers once they've been tweeted. So do we want to make any closing statements? Does anyone have anything more to say? So there are definitely no more questions from the audience? If not, then I would be happy to wrap it up.
02:49:37.610 - 02:49:39.240, Speaker D: No statements from me.
02:49:40.730 - 02:50:19.120, Speaker B: Okay? I hope this roast has sort of given you an idea of what PBS is and why it's very important to bring it into the protocol instead of allowing it to bloom outside the protocol where it would happen anyway, but with much more trust requirements from the participants. Having said that, thank you to all the speakers, thank you to Vitalik, Francesco and Steph, and thanks to Tina and Alex and Dan for organizing. And yeah, until next time.

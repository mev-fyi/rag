00:00:00.090 - 00:00:02.122, Speaker A: I was just like, why am I going to play games?
00:00:02.266 - 00:00:04.480, Speaker B: Do you all sing on this mic?
00:00:06.450 - 00:00:08.686, Speaker A: I could sing on this mic.
00:00:08.868 - 00:00:11.040, Speaker B: You want to take over this call?
00:00:11.890 - 00:00:13.790, Speaker A: Not with singing, I don't.
00:00:14.290 - 00:00:15.040, Speaker B: Okay.
00:00:17.330 - 00:00:19.360, Speaker C: What kind of input method do you have?
00:00:21.890 - 00:00:57.066, Speaker A: This is not a great system. I'm using a focus. Right, Scarlet? Let me look at it. I take this stuff kind of like I'm like a pro amateur. I want to use stuff that isn't horrible, but I also don't want to spend money on a real system that I'm never really going to fully utilize. But it's going into a Windows machine, and it turns out that the Focus Right drivers. So I had another Focus Right device, and its drivers for Windows Ten were hot trash.
00:00:57.066 - 00:01:08.340, Speaker A: So I bought another Focus Right device, and its drivers are also still hot trash. So it's a driver issue, but it's not a very good interface because of that.
00:01:08.950 - 00:01:09.860, Speaker D: I see.
00:01:11.350 - 00:01:12.914, Speaker C: Well, it sounds good.
00:01:12.952 - 00:01:15.250, Speaker E: Maybe the problem is that window is trash.
00:01:17.610 - 00:01:19.910, Speaker A: Well, yeah, that's what I meant.
00:01:23.610 - 00:02:11.830, Speaker F: All right, on that note, thanks for sharing the alpha leak on the latest. Yeah. Welcome, everyone, to our Mev research workshop, just like every other flashboss research workshop. Sorry for the late notice. It's going to be unfortunate, the nature of this, because we have so many great research questions to explore, and it's always hard to figure out which ones are the best one for this particular session. So for this one, we're going to dive deeper into auction mechanism design. And our Mev fellow from our first batch of Mev fellowship, seraya, please go ahead.
00:02:11.830 - 00:02:17.222, Speaker F: And I believe you have done some preparation. And feel free to screen.
00:02:17.276 - 00:03:57.106, Speaker B: I've got some slides I could talk about. But first I want to sort of introduce, I think, the overarching question that has come up as I think the driving force behind realizing what an Mev gets auction would look like. So one of the issues that I think Tina and Alex have really identified comes down to what do bot operators want to actually come on board and take part in such an auction? So, as we all know right now, a majority of these auctions take place in the Mempool in the form of PGAs, where all the information is public and where bot operators, over time, can adapt their strategies to how others are behaving. Now, the general Theorem Fortical Holy Grail of what most auctions end up end up being in the crypto space is second price sealed bid auctions. But it has become clear that really what bot operators want is to not be subject to the sort of truth telling and paying the most, paying really what other people value. What they want is more transparency in the auction, to actually be able to observe other people's bids, other people's strategies, and then bid according to that. So with that, I will share my slides, and hopefully this will lead to some good discussion.
00:03:57.218 - 00:03:57.754, Speaker G: Let's see.
00:03:57.792 - 00:04:07.100, Speaker B: I'm going to do this present. Okay, can you all see this?
00:04:09.890 - 00:04:10.640, Speaker C: Yes.
00:04:11.170 - 00:07:18.438, Speaker B: Okay, cool. So the first question really, that's on the screen now is exactly this, right? So do we care more about having a sealed bid second price auction where the incentive is truth telling and where we can at least attempt to maximize the revenue that an auctioneer, or in this case a minor, might receive? Or is it better to really use an alternative where sealed bids are not where bids are not sealed, where we release information about how people are bidding, perhaps in the form of rounds? And this sort of, I think, leads to the next more important question, really, is that a problem in this space really comes down to auctioneers can also be malicious, right? So if I'm a bot operator, my concern is going to be that if we're dealing with sealed bid, second price auctions, in reality, the auctioneer the miner in this case wants to, of course, earn as much as they can, can always inject their own second highest price bids and sort of influence how much everyone ends up paying. Right? So from the point of view of bots who are actually taking part in these auctions, there's a concern there that miners can arbitrarily influence the auction, they end up paying more. So the question really comes down to is, do we want a second price auction or do we want to perhaps sacrifice on minor revenue for the sake of having a first price auction, where such sort of a manipulation on behalf of the auctioneers is no longer is no longer possible. And under certain cases, the argument can be made that, for example, imagining that all the bidders and valuations are sort of drawn from a uniform distribution, one can say, okay, like an expectation both in first price and second price auctions, like an expectation, the miner will earn the same amount of money. Right? But of course that assumes that these valuations are independent and if they're not, then of course second price will yield slightly higher auctioneer profit. So from there, if we do think that first price auctions are the way to go, where bots can have a little bit more trust, more faith in the system, then the question moves to, okay, if we're going with first price auctions, should we consider a touch auctions? So the trade off there are quite simple actually.
00:07:18.438 - 00:09:17.802, Speaker B: I mean, in first price auction, auctioneers really don't have to do any work at all, right? They just have to wait and select the highest bid and they're happy. In a touch auction though, the miner has to do slightly some extra work in setting the highest price, the starting price of the auction to be high enough that it's more than the maximal extractable value of some transaction ordering opportunity but has to be not so high that these auctions take forever to actually yield some sort of a winner. And of course, as we know in practice, even though in theory the Dutch auction first price auctions have equivalent strategies, in practice, Dutch auctions actually yield higher revenue for miners. So with that, I think the main questions I want to drive the discussion from here is whether this concern of malicious miners is relevant, whether it is significant, and whether it's worth considering non second price auctions and taking the hit in terms of how much actual revenue miners are going to earn. This all sort of I think the high level question is we want to move as much of the auction behavior out of the mem pool and into the Mev guest auction. And so how do we encourage that adoption the most? And once we have adoption, of course we can update how the auction works. But at least at the start, these concerns are worth addressing for bot operators.
00:09:17.802 - 00:09:33.060, Speaker B: So I guess maybe we can start with is actually addressing this concern of transparency and whether malicious auctioneers are something worth considering and how do we work around that?
00:09:35.370 - 00:09:59.130, Speaker H: I would just have one context question because before we talk about what option strategy, I currently don't know exactly what we are auctioning off. So is it the right to produce one block that is oh, sure. In real time, or is it like a block next week or what exactly are we option?
00:09:59.200 - 00:10:15.682, Speaker B: Yeah, let me set up the problem then. So what we have here is imagine there's a block, some number of blocks in the future this can be yeah, it's exactly it's in blocks in the future. It can be at the scale of hours or maybe even days.
00:10:15.736 - 00:10:16.242, Speaker D: Right.
00:10:16.376 - 00:11:11.650, Speaker B: And so what we have is the imagine like an Oracle update is happening on the block, right? So what happens is a single bidder will say, here's a reference transaction that's going to be in the block and I want to submit and I want to submit a bundle of transactions in this order either before or after this reference transaction. And so the goal there is that bidder is trying to inject their own transaction right after or right before this reference transaction, and they are trying to extract some value out of it. So then so they will want to bid less than how much they value. But you can consider the game to be there's a single reference transaction and multiple bidders are trying to bid for their transaction either before or after this preference.
00:11:16.630 - 00:11:17.860, Speaker C: Yeah, sorry. Go.
00:11:20.710 - 00:11:23.666, Speaker A: Have oh, Martin's still going. I'm sorry. Go ahead, Martin.
00:11:23.778 - 00:12:00.834, Speaker H: Sorry, it's still not clear to me. In my view, there would be two options. So one would be miner could say, well, I'm expected to mine five blocks in the next hour, or something like that, and I auction off those future blocks. And you don't really know kind of what transactions will be there in the mempool. You don't really know. It's more like then it would be the average expected value of one block. That would be one option what you could auction off or you could auction off something kind of in real time where you see kind of right now with the given mempool, with the given state, with the given arbitrage opportunities, you could try to do this in real time.
00:12:00.834 - 00:12:04.562, Speaker H: So I'm still not sure what are those two options?
00:12:04.616 - 00:12:26.666, Speaker B: We are so in the current implementation, I guess this is more a question for Alex and maybe anyone else on the engineering side who's still here. Are the current mev, like in the current implementations, are these auctions live for the next upcoming block or are they for several blocks in the future?
00:12:26.768 - 00:12:27.034, Speaker H: Right.
00:12:27.072 - 00:12:29.930, Speaker D: So currently you have to resubmit for every block.
00:12:30.290 - 00:12:34.922, Speaker B: Okay. Live auction on the current upcoming block.
00:12:35.066 - 00:13:05.750, Speaker D: Exactly. It's a first price auction where every bundle that is submitted for that block is competing with one another and they are paying a tip to the miner in terms of using the block coinbase. So currently it is different bundles that participate in this first price auction and they price their preference with the tip that they give to miners. So it is competing opportunities and it'll be the one that pays the miner the highest that wins. Does that make sense, Martin?
00:13:07.290 - 00:13:56.520, Speaker H: Yes, I'm just saying there could of course be other ways. So you could say a miner could say, well, I have a track record of having so and so much hash power, so I will likely produce 20 blocks in the next hour. So I'm kind of auctioning off 20 blocks already and you can buy them already for the next hour. And then I don't know exactly whether I will deliver those 20 blocks, but maybe then it takes me not an hour, but an hour ten. And then kind of for those blocks and you don't know yet which those are. But then kind of this one bot operator has exclusively already the right to well, they already know they will get this block or well, I mean, they of course only know when it's mined, but they know if this miner mines block, then I will be able to build it.
00:13:57.370 - 00:14:43.314, Speaker C: Yeah, I think this kind of highlights the same question that I had, which is the need for maybe like a meta framework stating the various different problem approaches. So I think the first thing we talked about, which is the auction off clear future block X mev is similar to probably the layer two mev auctions we're going to have. So I'd imagine probably the optimism system is going to work like that. In terms of the layer one stuff, it is this more real time continuous thing right now. So I wonder, another question there is, how would the fungibility of the various kind of ARB transactions or the various bid transactions people want to place affect the auction?
00:14:43.362 - 00:14:43.574, Speaker G: Right.
00:14:43.612 - 00:15:25.346, Speaker C: Because you may be able to, for example, have two of these bids that are satisfied together in, let's say, the clearing of whatever auction you have. But it may be the case that bid A cannot go through. If bid B goes through, those two are mutually exclusive, et cetera. So you might have a very complex set of constraints on this real time system. So I wonder, I know the Gnosis team has thought about this, but there's obviously like a trade off there between computational clearing, cost and I guess fairness and the various constraints you can affect and how long the auction takes. These are all, I think, dimensions. So it might be good to articulate this.
00:15:25.346 - 00:15:40.422, Speaker C: And I think we do want to think about all these different types of auctions. I don't know whether the ideal solution is the same or different for these block future auctions versus the real time ones. Probably that's slightly different.
00:15:40.556 - 00:15:40.914, Speaker B: Yeah.
00:15:40.972 - 00:16:30.730, Speaker A: So that's very similar to what my questions were going to be, just so for clarity sake. Well, Phil just said it. I mean, we need to be clear on exactly which sets of problems we're trying to solve with which auction solutions. And then related to that and related to what Phil said and related to Gnosis, the miner has a benefit in trying to form a block from the previous lost auctions. It benefits everyone because the computing of the block is going to be actually very expensive and complicated for the miner. And so if they can cash that result and get more rewards, that's better for everyone. And that needs to be a parameter that's addressed in the bundle itself.
00:16:30.730 - 00:17:25.420, Speaker A: Like, does this bundle absolutely need to be in this block or can it be in the next block or something like that? Also, another thing that I thought was interesting in your presentation and thanks for giving it, is that we actually oh, this is a broader question about how folks see mev geth being deployed. If each individual mining pool, let's just call them pools for the sake of sanity, they should be the auctioneers that are competing directly with each other, right. So their honesty is going to be it's an open market. So we should assume that we're going to make one of these economic rationality assumptions, right, where they can sort of cheat, quote unquote, but we expect them to be able to compete on price as well.
00:17:29.630 - 00:18:07.240, Speaker D: One thing that maybe worth mentioning for that Dutch auction first price dutch auction example, if you're putting the computational weight on the miner in the sense where they have to propose a price, I fear that it might be beyond their capacity because it sounds like it's a very hard computational problem. Right. So asking the miner to suggest maybe they will do it naively at first, and then I guess the market gets more efficient as they find better ways to find a price. But what you're essentially asking them is finding all the potential mev and then that's the initial price or something like that.
00:18:07.770 - 00:19:30.926, Speaker B: Actually along that line. One thing I wanted to bring up was, I think in the conversation in the past, one possible outcome that we did foresee was that there would be these intermediaries who would run essentially auctions for smaller transaction bundles. And then these intermediaries are the ones who actually take part in the auction with the actual miners submitting these larger bundles that through their own auction, they've sort of created. And one concern there to me really, is that there is extra revenue there to be extracted, which I would wholeheartedly expect miners to try to capture as much of that revenue as possible. And does that mean that such intermediaries in the long term would eventually all just exit this system in favor of miners performing that task to maximize how much they can actually extract? So here's an example I kind of have, right? So imagine we have two intermediaries that run their own network of auctions, right, on small transaction bundles. Now imagine network one has two bids, right? One is a bid of, let's say, ten coins. The other is a bid, a bid of eight coins.
00:19:30.926 - 00:21:03.326, Speaker B: Now imagine network two that's being operated by somebody has a bid of five, right? So now each of these networks will report their own highest bid, right? Say ten and then five. And so now the top level auction, the miner will say, okay, if I'm going to run a second price auction, I'm going to say, okay, the winning bid is the network that submitted a bid of ten, but they pay only five. Now within their own network, right? The auction, let's say network one, that actually had the bids of ten and eight. Now they are paying only five coins, but they internally can charge their bidders their second highest price, which in this case is eight coins. I wonder if such opportunities for intermediaries to extract revenue exist and whether miners, I think, would value the trade off of doing extra work to essentially remove the need for any intermediaries and extract that revenue themselves. This thought I have is slightly little more vague than is slightly half baked at the moment. But that's actually something I just read this morning in a paper about intermediaries and how they work in ad auction.
00:21:03.326 - 00:21:07.906, Speaker B: So I thought it would be worth bringing this scenario up.
00:21:08.088 - 00:22:20.150, Speaker A: I don't think that in this model you can have any intermediary besides the mining pool for a couple of different reasons. One of the reasons is the simple alpha leak, right? The intermediary will be seeing your bundles, and so the intermediary will be able to, to your point, extract revenue before you even get to the minor. I think that that just from a privacy perspective is difficult. And also in a similar vein, from a sort of I don't know what the proper word for it is. But the contract between the bundle submitter and the Miner, you can't really add another agreement in there because then you lose that coupling. Right? And so I think what you're really getting at is that the nature of the mining software, the pool software, will have to change. And the argument is that the pool operators themselves will need to have more CPU and of a different type necessarily, than what they currently have to propose a block.
00:22:20.150 - 00:22:52.130, Speaker A: So right now a Miner can propose a block with like a laptop or something, right? It's very low CPU. But now in order for a Miner to maximize the revenue and the blocks that they're proposing, they're going to need some specific hardware configuration to be competitive. And so I think that that's actually fine because it's going to be a little weird. But I think that ultimately that's fine. And it's also interesting because that hardware can't be distributed.
00:22:53.830 - 00:22:54.578, Speaker C: Right?
00:22:54.744 - 00:22:59.446, Speaker A: Oh, yeah. I don't want to get started about 1559, whoever. I didn't see the name on that.
00:22:59.468 - 00:23:02.578, Speaker H: But yeah, let's pretend that 1559 doesn't.
00:23:02.594 - 00:23:18.170, Speaker A: Exist for the moment because that complicates things to a certain extent. And then I had one other comment with regards to I think well, I don't remember it, but yeah, that's.
00:23:20.830 - 00:24:19.226, Speaker C: Uh I guess I have two comments, or three. I guess one of them is towards Rick's point. It would be good to generally develop a framework as maybe part of this deliverable and add this to the FRP of how do the very low level ETH system details affect our choice of auction and do they require or impose any constraints, especially in the layer one versus layer two case? I think that would be a good thing to study. I think it would be cool in general because I know you've been reading a lot of ad papers. I would love some summaries or insights or pointers to cool papers once we finish this discussion. But that's probably a longer term kind of question. And I also wonder, how is ETH arbitrage unique economically? It seems like there are, for example, certain use cases and maybe we should enumerate in our mev taxonomy.
00:24:19.226 - 00:25:19.140, Speaker C: Maybe this relates to the taxonomy of mev, but let's say like hacks or something. What you have with hacks is like a very sparse distribution of a lot of value. So you very rarely get a very big kind of mev opportunity for something like a Dutch auction where you need to have some sort of price estimate maybe, let's say, rolled over from before or something. It seems like those kinds of shocks would interact with that mechanism. I think it would be good to also just enumerate in addition to the low level details, just like maybe plug into the mev taxonomy somehow and say, are there any specific details of these mev types that mean that we can't or must use certain auction types? I guess the only other comment I have is that I don't feel bad for bot operators who want to see like order types. I think we're going to have sort of privacy eventually anyway.
00:25:22.470 - 00:25:32.440, Speaker B: That's actually a good point. I should be taking some notes. Let me just write that down real quick. Oh, wait, no, this is all recorded right now. Yeah, I think we're fine.
00:25:33.530 - 00:26:04.830, Speaker H: Can I ask a more basic question again? What is currently the expectation that miners could just run the bot operator? Right. Basically use something like a generalized front runner and whatever submission they get. Fill the example you brought with the hack, where it's super juicy, where it's kind of 1000 times higher than what the auction is paying. What prevents miners from then just front running the front round?
00:26:07.030 - 00:26:52.942, Speaker C: Yeah, I mean, I think one of the things that we would like to build at Flashbots is I guess that privacy component. So last roast, we had some proposals for how to do that. None of them are fully fleshed out yet, but I think eventually we will have such a technique in the short to medium term, I guess it's like a trust relationship of which miners you choose and monitoring them over time, which is very suboptimal. So I think my guess is within the next year that tech piece should be done. It's not terribly complicated thing to do, I don't think at least to have a basic solution for that works well enough for this use case. But yeah, I don't know. It is a big problem.
00:26:52.942 - 00:27:23.690, Speaker C: You're right. I think my concern with auctions that are in the clear, like what the bot operators really want, more PGA style auctions, is just that there's all these weird politics around latency and who peers with who, and miners get lobbied to sell their order flow and weird things like that. And I just think that if we have privacy, we can probably have a more efficient marketplace without any of that. But that's just a hypothesis I would love to hear if people here disagree.
00:27:24.190 - 00:28:45.460, Speaker A: Yeah, while you were saying that, I was sort of working through and I'm jumping in sort of late, so maybe someone's already answered this, but it seems like once you're in the private network of the miner and you're submitting bundles, I don't know why a price time priority auction would be the wrong auction to have. So there's this interesting question about actually forming the block and the interference between the transactions, which is again a very complicated in the general case, an extremely complicated problem. But let's just say again, just so that we have a clear discussion topic, we'll have two competing bundles the miner needs to form the block as quickly as possible. That's still a requirement for them. So they say every 5 seconds I'm going to pick a winner and that's what's going in the block. And if you get in with the highest price, within that 5 seconds, you get in the block and there's not much else to really sort out. And those batch auctions need to be very fast in order for the miner to facilitate the gossip that it needs to facilitate to get its block until on the privacy side, again, I think practically speaking, there's just going to be phil is absolutely right about a blind bid or some other sort of system.
00:28:45.460 - 00:29:06.780, Speaker A: I think in the moment it will just be the sort of nasty well, the bots are peered with the miners and they trust the miner and know, I don't know, just go disparage them on Twitter or something if they guess, you know, I think that's about where we would be for a while.
00:29:11.090 - 00:30:05.520, Speaker D: Sorry. I want to bring up maybe, like, a practical point of feedback that we got from Flashbot users already, is that should two users submit two bundles that are non overlapping in any way, it's a shame that currently there's only one bundle that's including the block when both could have been included from the flashbot user perspective would be nicer for their bundle to be included. They're non overlapping and from the minor perspective, there's more profitability from taking two bundles in instead of one. Right. I understand that actually solving this in a general fashion would mean finding a way to find non overlapping state or something like this, but maybe there's like naive bundle merging solutions we can start with and then kind of iterate on that so that the auction is more efficient in the sense where the tide rises for everyone.
00:30:06.610 - 00:31:07.682, Speaker H: In my view, ideally, you would communicate with your bundle to some degree what parts of the state your bundle is touching. In many cases, you can pretty precisely say, okay, only those seven contracts or those seven contracts are read from or written to. And then if another bundle doesn't read or write to those contracts, they definitely are not but they definitely could be included. Both of them could be included. And I know that you can even do this with static analysis or Alexa knows much more about it, but you can just by looking at the transaction and looking at the opcodes of the contract they are calling, you can already get good knowledge about what state will be read from.
00:31:07.816 - 00:32:49.780, Speaker B: Yeah. So, I mean, like even in the current Flashpaths implementation or sorry, the mev guess implementation, I think an even more naive approach can just be in the upcoming block. There are essentially for any number of N, you know, any for any reference transaction, right? Like the auctions to submit a bundle around that reference transaction, as long as can be considered just completely distinct auctions altogether, right? Like if I have an Oracle update and people submit their bid, you know, my reference transaction is this Oracle update transaction, and I want to be in this location relative to that transaction and somebody else know saying, okay, this other transaction I want to be in this location relevant to this other reference transaction. So even a naive solution can be that for all the possible transactions that will be included in the block, treat each of them as sort of a reference transaction and that just becomes like an independent auction. So you can have essentially several auctions ongoing for different reference transactions. The problem there of course, is that you're going to run out of block space eventually, so the block producer doesn't need to at some point consider which ones can even be included. And so there it just becomes whichever of these reference transaction auctions yields the highest revenue for them.
00:32:49.780 - 00:33:35.380, Speaker B: One thing I do want to say, and go back to Rick's point, was that even with privacy, like you're saying that these bot operators can go on Twitter and complain that some minor is not acting as they should and basically rely on just trust in the miner. But my concern there is that with sort of high privacy in the auction, can such malicious minor behavior even be detected, let alone somebody going online to complain about it. And it can be something as simple as miners injecting their own bids into an auction in order to inflate the price.
00:33:39.170 - 00:34:50.760, Speaker G: I wanted to just suggest that obviously the problem of computing generally kind of what affects what, which transaction affects what is larger. I wouldn't say intractable, but it's very computationally intensive. So one thing which could be tried is to reduce the space of all transactions that are kind of accepted for the auctions. For example, to see whether this reduction will still bring the same value to the users. But this reduction may allow much more efficient computation. And so one specific reduction I would suggest first, unfortunately we haven't implemented this yet, is that essentially when you are looking at any transaction so you try to execute it in slightly modified version of EVM in which basically most things runs as they do, except that the S load and S store instructions work in different way. So S store essentially does pretty much nothing.
00:34:50.760 - 00:35:41.750, Speaker G: It blows up if the address value is undefined. So we're basically in the stack of EVM values could be either concrete or let's say undefined something like this. So the store, a store basically blows up if address is undefined, but otherwise it does nothing and just remembers that okay, this particular cell has been written which basically populates the right set. In the other hand, S Load also blows up if the address is undefined. But if it's defined, then it also does almost apart from putting this undefined value on the stack and remembering that this cell has been read. So this particular execution does not touch any state pretty much and can be processed pretty quickly in parallel. If you have enough CPU power, you don't have to have a state.
00:35:41.750 - 00:36:50.570, Speaker G: So I wonder the class of transactions that could be run like this without. Blowing up on those undefined addresses, probably quite rich. And then if you have transactions which are in this kind of class, you can pre run them in this particular modified EVM and you can figure out their reads and write sets, and you can figure out which ones are affecting the others. And then you can basically figure out which ones could be done in parallel, which ones could be preordered and stuff like this. But we don't know yet whether this reduction actually removes some usefulness for what people are actually doing with mev. So I don't know how these reductions they affect the mev, because if the auctioneer or somebody else or intermediary, if they wanted to have a more efficient system, they could offer to the users, okay, look guys, we only accept actions which could be run like this, but hopefully this is still good for you. But we can basically process them in much quicker.
00:36:58.520 - 00:36:59.824, Speaker B: Sorry. Go ahead, Alex.
00:36:59.952 - 00:37:04.550, Speaker E: No, I had an idea. Maybe it already works like that. I didn't know.
00:37:06.520 - 00:37:06.884, Speaker B: That.
00:37:06.922 - 00:37:54.950, Speaker E: Indeed, it's only one bundle that can be included in a block at the moment. But perhaps quite a trivial improvement can be that to keep some kind of a stack of the mev that the bundle extracts and order them in the order of how much mev does the bundle extract. And every time that you include a new one, replay the bundles and kick out if one of them suddenly returns zero maybe, or whatever, or returns a value low enough that it's not no longer profitable to include it. I'm not sure if that's how it already works or is it complicated to implement it like that?
00:37:57.560 - 00:38:46.340, Speaker G: I would say that if you do it sort of in a general, what you say quadratic complexity is that if you already have certain number of transactions in a bundle, let's say 100, and you try to test another one, you have to re execute all 100 again. And then the no transaction comes, you do another 100. In the approach of reduction that I just talked about, you don't have a quadratic. It probably would be linear and login because what you do is you already, for those 100 transactions that you have, you've already computed their read write sets, and all you need to do is to run a new one, figure out their read write sets and compare them. And so this effort is actually not going to be quadratic.
00:38:47.160 - 00:38:48.550, Speaker E: Yeah, that makes sense.
00:38:55.110 - 00:38:55.586, Speaker B: Go ahead.
00:38:55.608 - 00:39:01.620, Speaker G: And another thing is that it doesn't require access to the state, which is also not quite a big deal.
00:39:03.110 - 00:39:07.334, Speaker B: So you're going to talk I guess.
00:39:07.372 - 00:39:53.074, Speaker C: There'S a few things that come from so I agree that this merging is a big open question. I don't think only having one winner per block is the optimal auction. I think we can make that argument pretty easily. I wonder a few questions. Number one. Would it be better to have multiple auction types where, let's say one is like you just have one winner for each block and another one is you can have multiple winners, but they have to conform to this kind of static criteria where you provide the state upfront or like they're easily statically analyzable or whatever it might be. And then you kind of have these multiple auctions that form a meta auction that bid against each other, where maybe one block this transaction, which really has to happen by itself is just way more mev and that's fine.
00:39:53.074 - 00:40:09.580, Speaker C: But another one, these 30 Dex ARBs together kind of that don't conflict with each other override the one mega thing that screws up everyone's state. So I wonder how multiple option mechanisms together kind of interacts with this.
00:40:11.790 - 00:40:15.546, Speaker D: And your second question, I forgot it.
00:40:15.568 - 00:40:18.540, Speaker C: While I was saying my first one. I was hoping no one would remember.
00:40:21.490 - 00:41:44.662, Speaker G: I don't know the answer to this question, but I would suspect that is still kind of lucrative and profitable. Then I would suspect some kind of ecosystem springing up in here. Because, as you just said, Phil, that if there are different sort of reductions, if there are different constraints that you can place to make your stuff more efficient, and then you can announce these constraints to the users, and users will say, okay, what is the tightest constraint that my use case still works with? Because probably the tightest constraint would leave to the most efficient auctions and then I will go there. And so each user will choose whatever the tightest constraint that it can satisfy and go there. So for example, the super general one would be where everybody can fit, but it's going to be very inefficient and maybe they will only get a slot every like once every 100 blocks, but the ones which are super efficient, they might get a block pretty much immediately or something. Like if you win the auction, you get straight in, but you can run only very restricted types of transactions. But we cannot, I think, predict from the start what these all different types would be.
00:41:44.662 - 00:41:47.750, Speaker G: So I guess people have to figure out and compete about.
00:41:47.900 - 00:42:43.254, Speaker C: Yeah, so I think building a modular system and experimenting is definitely something we are trying to push for. So maybe that's a good also first approach is also figuring out what data we want to gather from experiments in this first round because we kind of have this system and we can deploy these multiple types. Plus we have auctions that are already running that we can get data from. So it might be worth just figuring out as another deliverable surya not to pile on, but I guess that's what these calls do is like what metrics do we want to measure and publish and have people exposed to researchers and things like that. And I remembered my other question. It's just like I wonder so in this adversarial environment we have, if we have this constraint based auction system that kind of Alexi and that we've all been talking about in the last few minutes. I think you'd also need to have some mechanism to enforce these constraints.
00:42:43.254 - 00:43:09.950, Speaker C: So you'd probably need a wrapper contract where if your transaction is mined but the constraints are violated, you don't end up paying anything so that the miner can't kind of steal your fee payment. I don't know. There's all sorts of concerns like that. And also that you don't lie about your constraints, right? So if you lie about your constraints, you should somehow be penalized for that too in this auction system because otherwise it's a dos vector.
00:43:10.030 - 00:43:12.420, Speaker G: Yeah, that's quite kind of interesting.
00:43:15.350 - 00:43:22.710, Speaker C: Yeah. I also wonder not to put you on the spot sorry, go ahead.
00:43:22.860 - 00:43:23.686, Speaker B: Yeah, I was just going to say.
00:43:23.708 - 00:43:35.180, Speaker C: Not to put you on the spot, Ben, but I know you guys are building an auction and I wonder if you've thought about these things or what your internal thinking is. You don't have to say anything if you don't want to.
00:43:36.270 - 00:44:33.994, Speaker I: It's all vibrant. Definitely everything you all are saying is vibing hard. It's interesting this whole notion of the static analysis and sort of multiple compatible bids being included in a single block. It's actually notable that this approach has implications for scalability too. So we're like doubly thinking about this because the same property that would allow you to have an access list checker that allows you to make sure that transactions don't intersect can actually allow block verification to happen in parallel too, even outside of this bidding gas strategy. So that's one comment. And another thing that is interesting that's been coming up here in discussion that I haven't considered in the context in which we're building, which is layer two, is this notion of the fact that we have miners individually running mev geth seria.
00:44:33.994 - 00:45:12.940, Speaker I: One of the questions that you started with was basically talking about the desirable properties of PGAs. Now this is an unknown hypothesis to me, but my suspicion is that one nice thing about PGAs is that they're a single marketplace and so we similarly have the ability to build a single marketplace for layer two. It strikes me as such interesting problem on layer one that to do all the miners running mev guests. Dan, you brought this up as well. Am I bidding to every single one of them? And if not, am I just losing out on whatever percent of the hash rate I'm not bidding towards?
00:45:14.110 - 00:45:41.700, Speaker C: Well, I think that is a problem you guys will probably have to deal with also because there may be multiple layer twos. And it might be the case that whoever is bidding in your layer two might also be biding in other layer twos. And they might be placing their bid based on how much they expect to be able to extract from cross layer two ARBs on multiple competing systems. So probably understanding you got me. Yeah. Be important.
00:45:43.430 - 00:46:23.940, Speaker I: That's an interesting point. Yeah, I guess. Do you think that would be specific to these strategies? Because one thing we were saying earlier is that it makes sense to have auctions that are sort of confined to particular strategy types. It makes sense that there's a front running style auction where you're just caring to get a transaction in before another one, versus the hack thing where you're like, maybe you're still trying to get in before, but it's just like this big opportunity that comes up. So I wonder if there are first order things that can prevent that problem, because front running is front running and it's on one chain and you're beating the liquidity at this one point in the state space.
00:46:27.690 - 00:46:35.122, Speaker C: Yeah, no, I think that's an open question. I don't know. That's an interesting thing to study.
00:46:35.276 - 00:46:36.220, Speaker B: Hold on.
00:46:39.390 - 00:47:50.206, Speaker I: The other the other thing the other thing that I will opportunity oh, yeah. Someone go use serious laptop while it's still logged in. The other thing, which I'll throw out just to share some of the layer two context that we at Optimism are coming from, we honestly have two considerations going on here. One of them is that we have a layer two system, and we have the ability to auction off, like on layer one, the ability to produce blocks. And the second one that we have is once someone has that ability to produce blocks, it still seems probable that the person who's best suited to producing blocks and doing those layer two things would still want to go. To frontrunner, like, you know, front runners and other bot operators and say, hey, can you help me choose this ordering in a profitable way? So we've published more on the former, which is like, have some sort of auction system that makes you become a minor, or at least what's a minor in the context that we've been talking about here. So I just thought that's worth throwing out.
00:47:50.206 - 00:47:57.170, Speaker I: We kind of have two layers of this. We have something that's replacing mining, and then we have the same problem that you guys are working on at the layer of mining.
00:47:57.590 - 00:49:08.358, Speaker A: Yeah. So I think that there's actually a different, slightly different problem for the L one. Optimism on L One is that you actually want to have a long term contract with a minor that guarantees that they will include your transactions. You want to be able to have some sort of proof that whichever operator submits the transaction that minor or some set of miners will guarantee the inclusion because that will stop a whole class of attacks. And that's, I think, a very different contract than what a PGA participant wants to the point where it's worth calling them out. And then my other comment was, oh, Phil was saying or don't actually, I'm not sure who was saying it. That one of the benefits of the existing PGAs is that it's one marketplace.
00:49:08.358 - 00:50:06.140, Speaker A: And I think that very literally what we're talking about in this conversation. The whole point of mev geth is an acknowledgment that that space is fracturing, that it's necessarily going to fracture. And that's essential to the discussion is that the different percentages of hash power are now basically claim we're converging to a world. And I will mention 1559 here, because I've thought about this. If you add 1559 and you add mevgeth people, there won't be any more transactions in the mempool, any transaction of any value. There'll be weird cheap BS in the mem pool. And anything of value is either going to go to go to some minor and so I don't know that everyone's really thought through.
00:50:06.140 - 00:50:19.840, Speaker A: Obviously this is a call where probably more than the general population, we've certainly thought through the implications of that, but that's the direction that we're going in and we just have to accept it, basically.
00:50:21.670 - 00:51:30.322, Speaker C: Yeah, I totally agree. I think the only reason that it's one marketplace is that that's just what the software does out of the box, but the incentives are definitely there to change it. And that is starting to happen, and it's been happening, and I expect it will continue to happen. So yeah, I think it's more about understanding the emergent properties of this already chaotic marketplace and understanding what happens if we can introduce privacy and how can we reason about these channels? And if we do introduce privacy, can we still somehow create a single marketplace out of these multiple smaller marketplaces? My hypothesis is maybe if you have kind of private bids that can be passed around the same way mempool messages can be. Now, I think your advantage as a large trader is to use a network like that to access more hash power. If you trust it to work, it's better than the mempool where anyone can front run you. I think that's yeah, but but we could also easily end up in a universe where it's just like a bunch of miners having their own fiefdoms.
00:51:30.322 - 00:51:35.320, Speaker C: And yeah, I would personally like to prevent that, but it's possible.
00:51:37.470 - 00:52:12.320, Speaker B: I think, with privacy in there. I think the hypothesis that I probably think is most likely is exactly that it becomes a single marketplace where you just distribute your bids over as much as power as you can, as you can, and then you can essentially simulate the mempool environment without front running. I think that's probably the more likely outcome than just having, like you said, minor fiefdoms that sort of split the market up.
00:52:12.730 - 00:52:15.558, Speaker C: Can I ask sorry, go ahead.
00:52:15.724 - 00:52:39.900, Speaker I: Can I ask maybe a slightly naive question from having missed conversations about how this privacy works? Is there a straw man for how you would implement this privacy? And why does introducing privacy not nullify the whole problem? Won't users use that privacy to keep themselves from being front run by these bots in the same way they're preventing each other from being front run.
00:52:43.770 - 00:53:36.498, Speaker C: Yeah, I think they will do that. There will still be space for bots to do things like there will still be bots that, for example, respond to market conditions and things like that, or otherwise have inferences on user order flow the same way you have. Them in the traditional market, where it's not the case that every bot on the stock market can see your order book before it hits the New York Stock Exchange or your orders, which is like kind of the ETH world of an open, mempool setting. But at the same time there's still opportunities to take advantage of asymmetries and other things kind of that don't directly come from just seeing the order before it's placed. That probably will still exist. So I'd imagine, yes, to some extent users will do that and part of the bundle combination and all this stuff we've mentioned will be part of that. But there will still also probably be some cases where there will inevitably be bots.
00:53:36.498 - 00:53:51.500, Speaker C: Like Liquidating is a good example of something that's on the network today that anyone can do it, but still only one person is going to end up profiting from that. So there has to be some mechanism there to make that happen.
00:53:56.030 - 00:53:56.394, Speaker D: Sorry.
00:53:56.432 - 00:53:57.158, Speaker C: Go ahead, Rick.
00:53:57.254 - 00:54:31.990, Speaker A: Oh, I was just going to say, are we considering some sort of ZKP based block formation in terms of the privacy stuff? Because I think I'm kind of with Ben, I'm having a difficult time imagining how this privacy stuff could work. And also isn't it sort of a base layer protocol change? It's great that we're all talking above the protocol layer and I am happy to stay there, but if we're talking about a privacy mempool, how do we achieve? And to Ben's point, I would assume it's not SGX actually. So I'm curious.
00:54:33.050 - 00:55:15.960, Speaker C: I think SGX is a good straw man. So we had a few different alternatives that we discussed in the last roast. I don't know which one of them are feasible. Like the ideal would kind of be like with the miner, possibly with a neutral arbiter who could ensure data was available. Basically the problem is the user wants to place a bid to the miner. They have to prove that their bid is valid and they have to prove how much the miner is going to get paid from their bid. And the miner wants to know that if they actually mine this hash that the block will not be useless, that a it will be valid and B the data will be revealed quickly so that they can profit from actually mining the block and they're not penalized on the know.
00:55:15.960 - 00:56:10.710, Speaker C: I encourage you guys to join these conversations, but I think SGX is pretty much the only solution that works without economic bonds and like crypto economic assumptions, honey Badger could work. You would have to run a whole ETH client in it. And the problem is that any penalty on the miners kind of latency is a penalty on their economics. And so the Mev would have to be really high for them to take that. I will say that I think you can design a network with SGX or trusted hardware such that if that piece breaks or is compromised, the only thing you will do is fall back to PGAs. So that would be the ideal that's the straw man assume it works. But I would love to have more conversations.
00:56:10.710 - 00:56:53.590, Speaker C: I don't want SGX in the network long term personally. And maybe a solution is like a more specialized smart contract language that is more natively suited to zero knowledge proofs of validity or some other static proofs of validity that maybe will come anyway from various scalability changes might make this easier. I don't know. Long term I think this is very much an open question, but I think one straw man is use SGX. You can do it, you can develop a private system that as long as SGX doesn't break, it works. And I think that will still probably be more efficient than the Mempool and then individual minor auctions. But I'd love to hear your thoughts.
00:56:53.590 - 00:57:19.830, Speaker C: And also I have a hard stop in nine minutes because I have to catch the last HAIRLIFT. So I really love these conversations. But just for the record, I'm not leaving because I don't love you guys. Thoughts, flames.
00:57:20.250 - 00:58:25.900, Speaker A: I have lots of thoughts. I'm muted with thoughts. I agree with your argument about SGX in the short term. I think that if we're going to add ZKPs at the protocol layer to make this sort of composability assertion that we're talking about, we might as well just fix the EVM. In some sense it's a backdoor into saying well, we need to fix the composability in the EVM, right? Because we're really talking about why is it that these transactions don't have to take semaphores in order to mutate the shared state, right? I can barely speak. I think that's a really deep question because essentially what we're acknowledging is that we're at a point now where we're like okay, the shared memory of the EVM is really broken to the point where it breaks everything. We have to go back in and fix it.
00:58:27.070 - 00:59:25.230, Speaker C: I think that might be a point that Sharding will maybe take us to anyway, because I also just don't see I think things get really weird with PGAs and dynamic memory accesses and our bots x like sharding X. Like possibly shard Gentrification X. Like whoever decides ordering of transactions between shards or which cross Shard transactions get priority. I think there's a lot of really ugly edge cases that will have to be looked at. So I think you're right that long term that might be the only solution is to think about composability more generally, which is, to be fair, what the Bitcoin maximalists said would happen. So maybe they deserve some credit for that, but I don't know exactly what the memory overhaul is that will be a solution. I don't think it's as simple as just go to the UTXO model because I think that there's a lot of trade offs there that need to be thought about.
00:59:25.230 - 00:59:30.426, Speaker C: But yeah, I think this deserves a much deeper, longer conversation also about the launch.
00:59:30.458 - 00:59:31.040, Speaker D: Yeah.
00:59:32.370 - 01:00:27.598, Speaker I: To prevent Rick from getting started at raging at the EVM any further and to catch you. Before you go, Phil, I do have one more question to loop back on an earlier comment you made when I asked about I definitely it definitely makes sense to me that there's lots of slow market arbitrage opportunities even in a very private mempool regime. But I guess my question then is to me it seems like the current Mev Guest implementation is very much not very well suited for slow market arbitrage strategies or preferences. So I do wonder how careful we have to be in trying to design for something, trying to design a system for privacy when if the system has privacy, it fundamentally changes the preferences of the participants.
01:00:27.774 - 01:00:43.880, Speaker D: How does it change the preferences of the participants, say, like using Mev Guest. Now when they submit their transactions, the miner can't see the content of their transaction before it's mined. How would that change the auction, for example?
01:00:45.930 - 01:01:12.642, Speaker I: Yeah, I guess the example that I'm thinking of, and definitely correct me if I'm off the mark, but an example I'm thinking of is just like, okay, let's say there's a private mempool. Now I can't front run a uniswap trade. So the way that I'm going to extract value from uniswap is I'm going to look at the price of off chain exchanges with lower latency and try to ARB against those off chain prices. I expect with where the off chain price seemed to be in the previous block when I could see it.
01:01:12.696 - 01:02:04.020, Speaker D: Right. So I think to some extent having a privacy system makes market a little bit less efficient where you're pushing the efficiency back to the next block. You still have different liquidity pools within DeFi and if you have like a price dislocation in a uniswap pool, then someone would argue between that. Soshi swap pool and uniswap pool, but instead of front running an order, sandwiching it or back running an order, you wait till that order and you before executing your transaction. That would still happen because you still need some kind of price efficiency and there would still be opportunities there for people to do so. But to some extent with a fully private system, to me it seems like you're pushing efficiency back to the next block in a way, if that makes sense.
01:02:07.580 - 01:02:21.020, Speaker I: Yeah, I think so. Okay, I'll have to think about that more. I think that's just like a generally open, fascinating question to me is in this private regime, what mev opportunities disappear? What ones appear and what ones remain.
01:02:21.680 - 01:02:24.270, Speaker D: Yeah, I think definitely you would have back running, right?
01:02:26.720 - 01:02:57.080, Speaker C: Yeah, I mean you might have dynamic back running where you spam transactions that check dynamic back running conditions kind of on the chain. But I think that is definitely like we need like a 4D matrix of mev types x auction mechanism, x layer one, layer two, x EVM internals and how do all these things kind of interact in each box. So I think that's definitely a clear deliverable is somewhat forming.
01:02:59.700 - 01:03:16.644, Speaker D: I totally agree. So I think you're going to see statistical art, right, where maybe there's patterns you can discover in price discrepancies or even Oracle updates and then you can submit those without having a view of the actual transactions in the mempool. So maybe there'll be strategies there.
01:03:16.842 - 01:03:48.370, Speaker C: Yeah, I imagine there will also be ARBs of the form. Like I send this bundle, I don't know how much money the bundle is going to make. It could make one E 1050, but I have some model for how much this will make on average. So I'm going to bid according to my model and kind of subsidize that so those kinds of bids could exist one day in more probabilistic like on chain logic style ARBs. I think that's worth considering in this taxonomy. Also.
01:03:50.740 - 01:05:00.018, Speaker D: I want to maybe bring up another question again, bringing it back to searcher feedback we got. So bringing it back to the current system that doesn't have privacy. And privacy is not something that seems that is implementable in the short term. I think if you're running a flashbot searcher and you're using a flashbault system, the main recurring question is like how do I set my tip right? Because a normal bot operator is used to looking at the Mempool, looking at other transactions and then reactively bidding and doing this kind of PGA activity that Phil described in Flashboys 2.0. In that system it's a first price seal bid auction and they don't necessarily have a way to determine their bid. My answer so far has been like, you can look at similar transactions historically and the successful flashback bunner and the tip that was given, and then you can maybe from that make an edge, but where they don't know if they could have bid lower or not, and they don't have a lot of information for them to understand that. I think.
01:05:00.018 - 01:05:10.180, Speaker D: So yeah, just bringing that up. See you Phil. By the way, enjoy the skiing. Thanks guys.
01:05:11.750 - 01:05:26.620, Speaker H: Do you have already some empirical data on the options that have been running so far? So I mean, is it like the average gas price or is it ten times the average gas price or 100 times or just very roughly what's going on?
01:05:27.790 - 01:05:57.330, Speaker D: We have some data. There's nothing that I can say conclusively. I don't know. Is Scott on this call? Scott, if you're here, show yourself. If Scott is not on this call, this is definitely something we can dig. The problem is I'm on the call, scott is here. Yeah, right now the number of searches we have isn't so large that I think that there's a lot of competition, especially for the same opportunities.
01:05:57.330 - 01:07:02.338, Speaker D: We've been really ensuring that we have a wider support for mev strategies than competition. So I don't think we have a full picture of that yet. They are taking mev opportunities that are available on chain and I think we could probably get some data about that because there is some information asymmetry for those that are participating in Flashpots that they still need to beat the vanilla ordered block. And so yeah, it might be interesting to get some of that data about how Flashbot users or even Tai chi users might be benefiting from this, seeing the bids of standard transactions while others can't see their haven't. We haven't looked into that yet. Right. So as Scott was saying naively, the minimum bid you would need to submit is enough so that the Flashbots block is more profitable than the vanilla block, than a minor wood mine.
01:07:02.338 - 01:07:19.200, Speaker D: Right, but then that's in the case where you're the only one submitting a bundle for that particular block. As soon as you have multiple bundle submitters, what do you bid? Do you just increase the bid and hope it works? Or if it doesn't work, do you just keep on increasing until it works? I'm not sure.
01:07:21.490 - 01:07:22.158, Speaker I: I'd like to have.
01:07:22.164 - 01:07:35.410, Speaker D: A better answer for bot operators and something that's also more helpful to them than just basically throw a dart in the dark and hope it lands.
01:07:37.190 - 01:08:09.610, Speaker B: I think that's just more to the point why current level mempool PGAs are sort of why they work, right? I mean, being able to observe others betting strategies seems to be something very important to bot operators, even to the point I would argue that without it, they would likely stick to mempool PGAs over some sort of mev gets auction.
01:08:12.690 - 01:09:12.160, Speaker A: So the interesting question there is the miners would, if the bots want to try to stay on that hash power, that's a fine option for them. But if more hash power moves towards privacy, it sort of happens regardless of what the bots want. And I think that there's certainly certain types of ARBs. I think that bots will end up paying maybe not the majority to their miner, but a significant amount. And there's probably some interesting game theory there given the distribution of hash power. So I think that ultimately, effectively what will happen is the mev supporting miners and the searchers will be colluding against the non cooperators to push them out of the market.
01:09:17.510 - 01:10:02.526, Speaker D: One thing I will add to that is something that we had fought for. Is it's definitely kind of to be expected that the tip for the, you know, as as the markets become more efficient and a strategy becomes more known or an ARB in particular, or a discrepancy becomes more widely. Known the tip will increase. Right. Because more people will compete for it and so they'll be willing to give more and more of their margin to the miner. But then what we imagine potentially happening as well is because miners select the most profitable bundle, you could bundle several opportunities within your bundle. For example, the one that's widely known, you give 100% of it and then you have another one in there that's less widely known where you give a smaller tip.
01:10:02.526 - 01:10:39.840, Speaker D: Right. So you might be included several opportunities within one bundle to just maximize the bundle profitability. And so you have these weird potential because a bundle still has a fixed size, right. It's still, I guess, limited by you can't submit a bundle that's larger than a block. So there's only so many strategies. Maybe there's like a churn or like a cycle in tip going from 100% to maybe less when there's other opportunities that are more profitable and then coming back in the bundle mixing, just putting it out there.
01:10:44.660 - 01:11:19.000, Speaker A: Yeah, I think there's also the question of to your point about that Oscillating price, that's also a reason why miners might offer a side deal to reveal the previous bundles to other bundle purchaser other bots. Right. I think that's something else that we have to put into the model is even if it is a commit reveal, you have to assume that the miners are going to turn around and sell that data to competing operators, competing bots.
01:11:21.660 - 01:12:01.728, Speaker B: It's actually a fantastic point. I think that's probably going to be that seems probably actually to be quite likely. I wanted to ask you, Rick, on a point you made, I think, two points ago about miners and bots sort of working together to push out non cooperating bots. Can you elaborate how exactly you define non cooperating bots? Are you saying only those who end up sticking to metamental PGAs versus actually adopting MVV guests and performing those auctions?
01:12:01.904 - 01:12:03.636, Speaker A: Yeah, that's exactly what I meant.
01:12:03.668 - 01:12:03.960, Speaker C: Yeah.
01:12:04.030 - 01:12:21.090, Speaker A: So if you're just in the PGA auction, you're going to be know there's this whole other group of people that are effectively, in this very OD way, cooperating against you and you're revealing data to them and they're not revealing data to you.
01:12:24.420 - 01:12:26.370, Speaker B: I get it. Okay, that makes sense. Yeah.
01:12:40.450 - 01:14:02.620, Speaker F: Cool. We are about a time. So I think we're going to summarize, I guess, some of the TLDRs from a lot of really cool brainstorming from today. But I would love to follow up with a lot of our new friends on the call, especially Alexi, Martin, Rick, and everyone, and Sam, everyone here for your comments. And actually, I think we would like to host another, more structured discussion on block space auction design at some point in the near future to kind of pick up a couple of the I would say more of the low hanging fruits and also do it in a more systematic way, maybe mapping out the 40 chess as a starting point before the call so that we could kind of dive into it and weigh the trade off within this design space. I wonder, how does everyone think about that idea to kind of in the next couple of weeks, find a time to dive deeper into this question so that we could actually come up with, I would say a more holistic view rather than just open ended questions.
01:14:06.850 - 01:14:35.160, Speaker G: I mean, I would definitely prefer the kind of the discussion about specific topics. The more narrow the topic the better, obviously. But yeah, I try not to have too many calls, but definitely I could spare 1 hour or something like that over next two weeks. But yes, basically I think it's fine for me.
01:14:36.570 - 01:15:31.820, Speaker F: Yeah, that'll be fantastic to have you guys. I think we will be able to we'll draft the agenda and share it with everyone before the call to see because I think everyone here on this call brings a very unique angle. And in particular, I think a lot of us are big fan of work by the Turbo Gas team as well as big fan of work from the open Ethereum Collective, et cetera. So I think a lot of we haven't really been able to dive deeper. We would love to kind of have more of that exchange from essentially the creators like builders who are actually providing these core instruments that the current block producers are using. So I think that's a very unique angle. Thank you guys for being on this call and we'll follow up with you.
01:15:31.820 - 01:15:57.170, Speaker F: If you guys are not in our discord group, we can share it afterwards or you can find any of us on Twitter and yeah, whatever is the best way if you're not already within our community. Cool. Okay, well, all right, Sarah, any closing thoughts?
01:15:59.670 - 01:17:37.630, Speaker B: My closing thoughts are actually I've been sort of trying to write them out in the chat as well. I think, two points to really take away and think about for I think maybe next week or the week after research workshop is one is what Lexi had brought up of these sort of smaller constrained auctions and using them to aggregate target as many bundles as we can into the block based on what sort of state space they touch. I think that's probably worth exploring for a future call and just sort of trying to flesh out that direction as best as we can. And also the 4D axis that Phil kind of tentified for classifying not only the auction mechanisms that will work out, but also how they're impacted by low level protocol EVM constraints. I think that I will probably talk to Phil more about after the call is over, after he's done skiing, and I'll try to maybe flesh out such an axes for our next research workshop that might sort of illuminate, you know, more precise design choices. But besides that, that's I think only closing thoughts I have. I think the smaller auctions constrained auctions is, like, in my guess, I think probably the most fruitful drop correction to at least explore.
01:17:38.130 - 01:17:38.880, Speaker D: Yeah.
01:17:45.020 - 01:17:45.504, Speaker C: All.
01:17:45.582 - 01:17:48.290, Speaker B: Anything else? That's about it.
01:17:50.660 - 01:17:56.112, Speaker D: Cool. Thank you all for joining. This was great.
01:17:56.246 - 01:17:57.570, Speaker B: Yeah. Thank you so much.
01:17:57.940 - 01:17:58.956, Speaker G: Thank you. Bye.
01:17:59.068 - 01:17:59.776, Speaker B: Thanks.
01:17:59.958 - 01:18:01.010, Speaker A: Really good time.
01:18:02.900 - 01:18:05.436, Speaker B: Thank you. Bye.

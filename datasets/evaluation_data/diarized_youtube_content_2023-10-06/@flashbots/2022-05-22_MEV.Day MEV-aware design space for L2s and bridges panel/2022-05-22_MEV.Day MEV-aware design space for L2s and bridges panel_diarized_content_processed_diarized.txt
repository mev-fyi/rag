00:00:09.210 - 00:01:06.078, Speaker A: Cool. I don't think that this these hello, I'm Angela. I am going to be moderating this panel, but I don't think any of our panelists needs an introduction. So I will just go forward with the central question that I have posed to our panelists. And the question is, how could mev specific to your layer of the stack positively or negatively impact mev on other layers and or the entire system in general? So I would like to hear first the panelists. We do have 40 minutes, so I would like to hear each of the panelists first, take some time to express their thoughts on this question, and then we can go from there. So maybe we should start at the end with John.
00:01:06.244 - 00:01:06.622, Speaker B: Sure.
00:01:06.676 - 00:01:08.450, Speaker A: I guess at the bottom of the stack.
00:01:08.790 - 00:01:19.526, Speaker B: Yeah. Since it's at the bottom of the stack, it kind of makes sense. And then we'll work our way up, right? Okay. So is this mic on? Okay. Yeah. Sorry. So hi everyone.
00:01:19.526 - 00:02:39.582, Speaker B: For those of you who happen to miss my talk earlier on modular blockchains and exploring MEB in a modular blockchain world, I guess I'll give a quick recap, which is that in a modular blockchain world, you have multiple layers that kind of have a dependence from top to bottom in a vertical way. So at the base, you would have a consensus and data availability layer. On top of that, you would have, optionally, a settlement layer. And then on top of that you would have an execution layer. And the execution layer can either settle to the settlement layer, in other words, verify its fraud or validity proof there, or it could actually essentially self settle similar to a layer one by posting its data directly to the data layer. But regardless of which choice you make, there's this kind of notion of verticality, and this is slightly different than what exists today, where you either have one single domain that's monolithic that does execution and data availability and consensus all at once, or you have multiple domains that are essentially siblings to each other. And this is what James and Arjun were talking about a lot, I think, with their cross domain and bridging talks, which is that traditionally we've had either one domain or multiple domains that are siblings to each other.
00:02:39.582 - 00:03:45.830, Speaker B: In the modular world, we're doing something slightly different, which is that we have our domains that don't do the same things, but they're vertically stacked and in this architecture, because it's not just one stack of things. Or you have one execution layer on top of one settlement layer on top of one data layer, but you might have like a tree of things where you have one data layer and five settlement layers and 100 execution layers connected to each of these settlement layers. It's very dangerous if the base data layer has something that will bleed upwards or if one of the upper layers has something that will bleed downwards. And then affect everything else. So in that context, mev is something that we have to be careful of because if someone constructs an execution or settlement layer that will bleed mev down to the base layer, then this can actually interfere and disrupt how other settlement layers and how other execution layers on top of that data layer actually operate.
00:03:46.890 - 00:04:06.102, Speaker A: So just to summarize, John, it seems like John, as the consensus and data availability layer, you wish that because you do see multiple execution layers happening, you do hope that they contain mev at the top layers of the stack. At the execution layer.
00:04:06.166 - 00:04:21.614, Speaker B: Yes. The ideal situation is something similar to what the E two researchers are doing with Proposer Builder Separation, where you essentially contain and compartmentalize mev into a particular layer and you don't allow it to bleed down or up.
00:04:21.812 - 00:04:32.500, Speaker A: So to the execution layers. Maybe. How do you feel about John pushing mev towards your layer? Maybe ed first.
00:04:35.610 - 00:05:34.998, Speaker C: I guess I don't conceptualize what we do as an execution layer to start with, but here's the way we think about mev in our system. First of all, we try to prevent in the design of our system extraction of mev from our users against their will. That is a cost that our users would experience if we don't try to stop. It raises the cost of using the system and it creates inefficient incentives for them to optimize for resisting mev extraction instead of optimizing for efficient resource use on our chain, which is what we want to incent them to do for everyone's good. So we think a lot about the incentives and what incentives it creates. Our system, like most roll ups, uses a sequencer. The main purpose of the sequencer is to give people certainty very quickly order of 1 second on what the ordering of their transactions will be.
00:05:34.998 - 00:06:16.046, Speaker C: And that also affects the opportunity for mev extraction that the sequencer might have, because whatever it does, it has to do it very quickly, rather than accumulating a big mem pool and then trying to optimize over it. Currently we run a centralized sequencer. And I think there are basically three ways you can do this. You can be centralized, which is what we currently are, and we ask our users to trust us and try to be transparent. That's obviously not the long term place we want to end up. The second thing we could do that we don't especially like is serial centralization, where parties take turns. They're elected to be the centralized party and they just take turns.
00:06:16.046 - 00:07:03.860, Speaker C: And you hope that things kind of average out over time. We don't like that approach because we think it leads to a lot of extraction of mev. Instead, the approach that we'll be moving to over time is a distributed sequencing model where we have a committee of sequencers and provided that K out of N of them are honest, then you're guaranteed a sort of formally specified, distributed, first come, first served policy. So the goal of this, again, is to minimize the amount of mev that gets extracted against the will of our users. We think that's a really important goal for systems. We don't think maximizing mev revenue extraction is the goal that we should be aiming for. Rather we'd like those funds to remain in the pockets of our.
00:07:08.080 - 00:07:08.492, Speaker B: Other.
00:07:08.546 - 00:07:41.496, Speaker D: Okay, well, let's tie it back to the execution layer question that we kind of started with. I agree. And Ed and I are building pretty similar protocols and a lot of that applies to optimism too, I think. I will say though, that I do agree with you, John. To go back to the original point that yes, it is the case, like when we posted about sequencing on Ether search, the thing that we were doing was saying we should move the sequencing out of l one and we have different terminologies now and data layers and execution layers. And it's funny, I think I would consider optimism Arbitrum an execution layer. Or maybe there's a different term there.
00:07:41.678 - 00:07:43.428, Speaker C: That you want to terminology.
00:07:43.524 - 00:08:13.604, Speaker D: Yeah, exactly. So it is the case that we move mev into the other layer and also I think I go backwards in the up and down of my layer two as everyone else. That's another one thing that always confuses me. I don't know, do you guys go up for layer two or down for layer two? Up. Oh, we got some downs back there. It's very contentious. I will say that we're introducing mev by creating a new Asynchronous domain, though.
00:08:13.604 - 00:08:33.690, Speaker D: I will say that so the existence of this other domain does introduce cross domain mev, which I do think is interesting. And whether it's the kind of panel topic is whether that's introducing mev at other places. It's hard to say if cross domain mev is a part of the chain that it is being going across or not, I don't know. But it definitely does introduce mev there.
00:08:34.160 - 00:09:11.556, Speaker A: Cool. So it sounds like the execution layers are aware that mev will kind of concentrate in your layers. I'm curious, like in your previous presentation you said that Arbitram's approach to Fair sequencing kind of moves the in a centralized sequencer. It's very obvious that the mez is in the centralized sequencer. Where does it bleed into in a more decentralized sequencer world for the execution layer is my question.
00:09:11.738 - 00:09:39.868, Speaker D: Yeah, I mean, I think basically what I said is that it will go to the edges. So if you have a model like many of these Fair sequencing protocols where there's a distributed set of parties and it's basically the sequence is a function of what they all submit, then the mev will move to manipulation around those layers, be the networking stack and trying to get your packets in first or doing other things. But that's definitely where it will live. I don't know if that is a different layer because it kind of is the layer of sequencing that you've built for the L two.
00:09:39.954 - 00:09:46.076, Speaker A: So by edges, do you mean it would move to, for example, the 20 it would just be split between the 20 sequencers.
00:09:46.268 - 00:09:53.670, Speaker D: Right, exactly. And then the mev searchers that are trying to do this would then be going to that part of the network. Right.
00:09:55.880 - 00:10:14.968, Speaker C: I think we need to be careful in thinking about this, not to pre assume that the amount of mev that gets extracted from users is independent of what kind of protocol you use. Right. One of the reasons why our protocol is designed the way it is is to try to reduce or minimize the amount of mev that's extracted from users.
00:10:15.064 - 00:10:15.324, Speaker E: Right.
00:10:15.362 - 00:10:46.848, Speaker C: And so you can ask where the opportunities for mev might live, but you should equally ask how much opportunity is there for mev extraction? Some designs tend to maximize the centralization, maximize the efficiency of mev extraction from users. Ours is designed to try to resist extraction of mev from users. Now, that can't be done perfectly. You can debate how best to do that, but I think that's the right goal in how to think about designing one of these protocols.
00:10:47.024 - 00:10:56.490, Speaker D: Right, totally, of course. And it is difficult to do that, especially when you're trying to build something like Google, which is a completely application, generic platform. So there's definitely challenges there too.
00:10:57.500 - 00:11:37.910, Speaker C: And I guess I would say that the one thing we would not want to do is come up with a protocol whose effect would be to put mev extraction power into the hand of the party who's most efficient at extracting it in a centralized way. I think that's the worst thing that we could do in terms of trying to reduce mev extraction. I think it's important to distribute it. I think it's important to distribute it administratively, but also geographically, because the network distance among parties also tends to act as a break on mev extraction. And I'm happy to dive deep on that with people afterward if you're wondering why that's the case.
00:11:39.080 - 00:11:49.624, Speaker A: Cool. So before we introduce bridges to the mix, john, as the consensus datability, do you have any thoughts you want to share?
00:11:49.822 - 00:11:50.184, Speaker D: No.
00:11:50.222 - 00:12:34.250, Speaker B: I mean, both of these execution layer teams or roll up teams if they don't want to be labeled as such, have brought up some good points, which is that just being a roll up doesn't inherently reduce the amount of mev. But by making systematic changes to how the leader selection process works and also within that leader selection process how blocks are built, then you can have reduction potentially in mev or mev extracted from users, which is definitely one. Of the benefits off this modularization approach because it allows us to experiment very quickly and iterate very quickly on these experiments in ways that just would not be possible in a single monolithic system.
00:12:35.740 - 00:12:50.700, Speaker A: Okay, so introducing a little bit the bridges so james here is working on the messaging part of the bridge, and on top of that is connect, which is the liquidity layer. And let's start with James.
00:12:51.280 - 00:13:49.432, Speaker F: Yeah. So I think the original question back at the beginning of the panel was how does mev on our layer affect the other? You know, the existence of bridges actually creates a kind of crazy, weird amount of mev on the base chains they're involved with. One of the reasons we don't see safety or liveness failures on base chains very often is because they're awfully hard to monetize. When you cause a reorg, a safety failure or a chain halt a liveness failure, it's difficult to extract value out of that chain you've just busted. Bridges change this equation. They make it so that just breaking the security model of some chain they're connected to is potentially very profitable on another chain. For these safety and liveness failures, the difficulty is getting your money out of a busted chain.
00:13:49.432 - 00:14:15.832, Speaker F: But the bridge solves that for you. You can't use coinbase to get your money out. You can't use, like, USDC to get your money out. They'll prevent it. You can't use an external short to get your money out because crypto prices are completely irrational. When Iota had a liveness failure, for example, the price went up that day. So bridges give you an opportunity to bust a chain, extract your money out to another chain, and go about your day with a lot more money.
00:14:15.832 - 00:15:52.500, Speaker F: So we're creating sometimes egregious amounts of mev on these base chains in ways that potentially interfere with their operation. One of the ones I think is going to be productionized in the next year or two is forced synchrony between proof of stake chains. Anytime you have validator sets, staker sets overlapping between two proof of stake chains, there is an opportunity for them to take actions for the shared validators or stakers to take actions on both chains simultaneously and enforce that those things happen atomically, and they are the only people capable of doing that. So, for example, for any two cosmos zones, if there is a staker with 10% on each zone every ten minutes, that staker gets a chance to set exactly what happens in both zones at the same time, extract all of the mev for both zones in a cross chain way that nobody else can replicate. So in this way, the existence of multiple domains and bridges between them creates an incentive to mess with the liveness of tendermint chains in order to extract value, to delay blocks so that your shared window comes around more often, or to cartelize the validators to create more of these MultiChain mev windows. So we're going to see, like, bridges start to interfere with the safety and liveness guarantees that the base chains provide, and it's going to be productionized within a couple of years easily.
00:15:54.700 - 00:16:53.924, Speaker E: Yeah, I guess following on that, I think one of the things that might have started to become clear to people over the course of that is that the higher you go in the stack, that's kind of where the source of mev comes. And when you get to the liquidity layer of bridges, we are the problem. Any mev that ends up bleeding out of our part of the stack is what everybody else on this panel has to deal with. And that's obviously quite difficult. I think a way to think about it is that each layer has a potential for how the extent to which transaction ordering could affect basically mev. But that potential isn't fully met unless you actually have mev bleeding out from the higher layers. And I think this is why John was saying that it's better to try to constrain mev to the higher layers in the stack because as it gets further and further down in the stack, it becomes more and more devastating.
00:16:53.924 - 00:17:52.460, Speaker E: And then also the possible ways that you have to try to mitigate it get constrained further and further. Now the flip side of this, of course, is that with bridges and especially the liquidity layer of bridges, which is really where you are extracting value, this is not always possible. It's just fundamental kind of distributed systems problems that you start to run into. And I kind of touched on this in my talk earlier, where I talked about what it looks like to build a cross chain decks and why that really, really sucks that you end up running into all these weird. Problems with synchrony assumptions and things like that, where it is just effectively impossible to stop from mev being extracted unless you find better ways to develop the applications in the first place. So I think one of the things that maybe I hope we end up talking about more on this panel is just like what are the ways to kind of build safeguards into each layer? Because really it's the connections between the layers where the problem of mev ends up compounding.
00:17:54.480 - 00:17:55.660, Speaker A: Go ahead, John.
00:17:55.810 - 00:18:19.220, Speaker B: So a lot of this talk around multiple layers, multiple domains, multiple things. It sounds a lot like the best approach to building a blockchain is in fact something like Solana, where you just have a single layer that does everything and you don't have to worry about cross domain anything. Do we think that the Solana approach is better than this multi layered and multi domain approach?
00:18:19.560 - 00:18:44.728, Speaker D: Criminally underrated, imo? I think in the Ethereum community we ignore a lot of the very legitimate stuff that Solana is doing. And John Deere credit Fuel does some of this too to make better execution where we can have larger synchronous environments. I don't think it's better to make this centralized thing, but I think we ignore the interesting thing Solana is doing because of their failure to meet the values that I feel believe in an Ethereum.
00:18:44.904 - 00:18:48.140, Speaker B: So basically Ben confirmed to have Solana bugs?
00:18:49.280 - 00:19:05.012, Speaker D: Never. I technically like some of the things that they do though it's true and it's easy for us to ignore that as a community, I think when we see five validators or whatever the hell it is because rightfully so, that's a reason not to get involved. Right, but there's interesting things going on there.
00:19:05.146 - 00:19:07.460, Speaker F: When are we going to see BPF canon?
00:19:07.880 - 00:19:09.750, Speaker D: Oh, you know, it is coming soon.
00:19:12.040 - 00:19:55.712, Speaker E: Actually. I really agree with that notion because I think there tends to be a lot of really interesting experiments that are happening around these kinds of things and other ecosystems that we as a community tend to kind of ignore because we have a lot of bagholder bias. Getting back to your original question, I think it's not to say that there's necessarily one better approach or worse. There are trade offs. And I think in this case the trade off may be that you're swapping out one demon for another. We're saying the kind of downside of this module approach is like more vectors for mev, but in the monolithic approach, your downside is like these fundamental problems to decentralization. And at a certain point, we're going to have to figure out the trade offs between those two and figure out how to balance them.
00:19:55.712 - 00:20:04.088, Speaker E: Because this is like effectively, this is one way to think about this on a macro scale is that this is a cost that users are paying or that the is paying as a tax for decentralization as well.
00:20:04.174 - 00:20:54.336, Speaker C: I think it's important when we're talking about monolithic versus layered to sort of separate two notions. One is, is the system structured in layers that interact. So when I see John's slides and he talks about the layers in the modular approach and I look at the design of Arbitrum, I recognize that we have within our system things that are reasonably well modularized from each other that play those roles. Although we used very different terminology. So it's not that the design is monolithic. The challenge really is to have layers and to think in a modular way. But at the same time to have a design where you are thinking and optimizing across layers for things like mev control and you need to get there somehow.
00:20:54.336 - 00:21:27.090, Speaker C: And I think you'll see a bunch of layers. Sometimes you'll see multiple layers inside the same product, sometimes you'll see them in different products. But I think from an engineering sort of how we think about design standpoint, you'll see similarities. I happen to think that the layers that we provide together and co design really do work well together. But from an engineering standpoint, I think there's a lot of similarity to what John's talking about and it's a really valuable way to think.
00:21:28.580 - 00:22:18.720, Speaker F: I agree. The whole modular narrative is like we've had this single blockchain ecosystem for so long, what if we just unbundle it a little? You know, to John's point, the response to that is well, what if we just rebundle it a little bit in a few more years. In normal tech development, bundling and unbundling is a cycle that people do every time they get frustrated with the current paradigm. We unbundle things so we can introduce specific optimizations without worrying about other parts of the stack, and then we go, hey, wait a second, why are we spending so much overhead on layers when we could just bundle everything and it'll be a lot more efficient at doing what? So, you know, maybe we'll see an unbundling period and then a rebundling period in a few years, and Solana might be a good choice for rebundling.
00:22:19.380 - 00:23:03.132, Speaker C: I think it's partly about standardization as well. If we're in a phase where there's still a lot of uncertainty about what is the best interface between layer A and layer B, then it makes sense for different people to experiment, try different things. And it will necessarily be the case that if I have a different idea of what the interface between two layers is than Ben does, that my layer A won't interoperate with his layer B, and vice versa, just because we have different ideas about how the layers should interact. And I kind of feel like that's where we are now, that there is not, I think, a clear idea, at least for some of the interfaces, as to what the division of responsibilities or contract should be between those layers. And so we're in this period of innovation.
00:23:03.276 - 00:23:47.612, Speaker F: Yeah, we had a good conversation about this at modular summit yesterday. Essentially five years ago, when it's more than five years ago. Six or seven years ago when Ethereum started, we could not build a modular blockchain because we had no idea how to build a blockchain in the first place. Just making it up as we went along, there was no prior art. We didn't know what layers were, where they were, what they should look like. And so really, the project of the modular blockchain stack is figuring out those layer boundaries, what's appropriate, what's useful, and trying to come to shared standards about them. So maybe you and Ben will always disagree, but I think we can get there on a lot of these layer boundaries, especially like cross chain things.
00:23:47.612 - 00:23:53.792, Speaker F: I think we can get there on just the cross chain communication channel versus cross chain app layer boundary. That one's easy to see.
00:23:53.846 - 00:23:55.744, Speaker C: These things always clarify over time.
00:23:55.862 - 00:24:01.220, Speaker F: Yeah, and when we started building Ethereum, they were completely unclear and we were all kind of dumb.
00:24:02.600 - 00:24:04.790, Speaker B: We still are, but we used to be too.
00:24:07.720 - 00:24:34.620, Speaker A: Cool. So just to get a little poll here so who on this panel thinks it's better to, in this current phase, let's say in the next two to three years, to unbundle further? So the two choices are to unbundle further or to bundle back into one thing. So who here thinks that we should keep unbundling?
00:24:36.960 - 00:24:43.424, Speaker B: Are we allowed to just hedge our bets and buy some soul and some ETH and then we're good regardless of what the outcome is.
00:24:43.542 - 00:24:46.370, Speaker A: All right, so it sounds like most of this.
00:24:47.540 - 00:25:14.200, Speaker C: Yeah, so I guess I would come down in the middle. I think there are some interfaces where it makes sense to bundle and others where it doesn't. I think for example, with respect to bridging, I would not want to try to bundle all of the bridging into what we're doing because I think innovation in bridges and having multiple bridges there is what serves our community the best because multiple bridges can coexist more naturally in designs like this.
00:25:14.350 - 00:25:17.400, Speaker F: Are we allowed to have nuanced opinions on stage?
00:25:18.380 - 00:25:59.610, Speaker E: No, sorry. Yeah. I actually think that this maps really well to how we think about bundling and unbundling bundling in web two as well with traditional tech startups. I mean, this is something that people have been talking about for a very long time as just like the way that the market evolves, usually the idea behind the whole unbundling and rebundling is like in the process of doing that, you actually optimize. This is like the meta process that we are following intrinsically, the epistemic process that we're following intrinsically to understand how do you actually optimize these systems. And to do that you have to break them into small pieces that kind of don't really work, figure out why they don't work, get rid of the stuff that doesn't work, and then put them back together again. And then break them again.
00:25:59.610 - 00:26:21.090, Speaker E: I agree that we are in the part of the cycle where we need to be unbundling for the next couple of years, because we've spent the last almost over a decade now with a single bundled monolithic blockchain. And now we need to figure out why we made those decisions in the first place. Or I guess why Satoshi made those decisions in the first.
00:26:23.940 - 00:27:08.990, Speaker A: Do. So I think that it's inevitable that there will be mev opportunities across the stack in between. So kind of for actors to be able to extract the mev opportunities that exist between you guys, there is a strong push towards centralization and bundling to be able to extract such opportunities. How can the five of you work together to keep to sort of steward towards this unbundling future that you guys all want?
00:27:10.000 - 00:27:40.890, Speaker E: I mentioned this in my talk, but I think this is actually the first time that there's ever been any formal conversation around crosschain mev and mev throughout the stack and how it actually fits together. I think a big part of fixing this problem is to keep having these conversations because I think over the course of this panel, I am already starting to build a better taxonomy internally about how we should be thinking about this and I'm sure everybody else here is as well. I think it's a topic that just really needs a lot more discussion and it hasn't existed yet. But thank you for putting it together.
00:27:41.420 - 00:28:11.052, Speaker D: Yeah. I think we also need to figure out better what our goals are. Quite frankly, it's not immediately obvious to me that all the types of cross chain mev are bad. Is making the price more efficient and the same across a bunch of different chains a bad thing? Maybe not, but it is cross domain mev. I think one question is maybe that we want to do it in a way that doesn't. Right. So actually, one thing that I didn't hear the bridge people talk about on the top of mev is that you guys are at least responsible for funding some of the cross chain mev.
00:28:11.052 - 00:28:43.272, Speaker D: Right. Like, the ability to move your funds back and forth between chains faster does allow you to have funds on two chains and execute a cross domain Arbitrage on them. Right. And I don't necessarily think it's even a bad thing that people are going to make the prices more efficient. I do think that if we do it in such a way that only the richest people will be able to do that, or they're at some kind of advantage, that would be a problem. So maybe your goal as a bridge is making that really democratized and not requiring a high budget. And so yeah, I agree that we haven't had a lot of conversations.
00:28:43.272 - 00:28:45.150, Speaker D: We don't even know what's right and wrong.
00:28:45.760 - 00:29:13.030, Speaker F: I reject the idea that you can make it not require a high budget. The nature of transactions is that the transaction fee will rise to the level of value that you can extract from transacting. You can't sell the $5 Arbitrage for a one dollars transaction fee. Can't be done. No scaling system will enable you to do this. No MultiChain system will enable you to do it. You can't sell $5 for one dollars.
00:29:13.030 - 00:29:30.110, Speaker F: I do think that minimizing the impact of mev on users trade prices across many domains is very important. We think about it a lot, and it's one of the reasons why Arjun and I both gave talks on why cross chain DEXes are such a bad.
00:29:30.960 - 00:29:31.710, Speaker D: Yeah.
00:29:32.240 - 00:29:36.680, Speaker E: Very, very unfortunate that we didn't coordinate beforehand. Two good perspectives.
00:29:36.760 - 00:29:39.120, Speaker F: I feel like my talk was a good introduction for yours.
00:29:41.380 - 00:30:29.280, Speaker C: I think it's important for each of the players, each of the components, to be really clear with the others about what it is that we provide and don't provide. And what are the mev extraction opportunities that would exist in our systems and who might be in a position to exploit them. In general, it's good to try to minimize or damp mev extraction opportunities, and we want to do that as much as we can. We certainly don't want to be in an architecture where we're maximizing mev extraction, but we should be really clear about where we are so that we don't get composability effects or composition effects across these systems that are really unexpected or unfortunate.
00:30:33.140 - 00:30:56.692, Speaker B: Yeah. So I think going forward. As was said before, one of the primary things that will probably help towards mitigating this mev is interpersonal collaboration. Inter team collaboration. Interproject collaboration. Because we're moving towards an era of modularism and not maximalism. You see, on the Bitcoin conferences nowadays, they're very much maximalists.
00:30:56.692 - 00:31:20.450, Speaker B: They refuse to collaborate or even talk to other projects that are also doing research in the blockchain space for whatever pure puritanical reasons or whatever. Right. So I think getting different teams, different projects that are working across the stack together on stage like this and also in the audience like this is critical to actually moving forward and mitigating these issues.
00:31:22.340 - 00:31:23.840, Speaker D: Kumbaya.
00:31:25.300 - 00:32:18.770, Speaker A: Awesome. So we have five minutes. I asked Phil Diane if there was a question I should ask that I could not ask each of them individually. Okay, do you guys want to hear the question? All right, the question is, what is your least favorite trust assumption that some other protocol on this stage makes?
00:32:21.800 - 00:32:23.910, Speaker D: Do we have to not make it, too?
00:32:28.840 - 00:32:33.700, Speaker A: We have five minutes. Answer quickly. Let's start with you then, Ben.
00:32:34.680 - 00:32:52.350, Speaker D: I mean, it's a love hate relationship. My least favorite is the fact that we have upgrade keys. We've done a lot of writing about how to get rid of them. It's not an easy path ahead, so we make this assumption too, but it's the one that I hate, and that scares me. A you know, that's what I would say. I'm actually less concerned about the mev assumptions than that one.
00:32:53.200 - 00:32:59.312, Speaker C: I guess I would give the same answer. Others do make this assumption. We make this assumption too, for now.
00:32:59.446 - 00:32:59.744, Speaker E: Right.
00:32:59.782 - 00:33:14.420, Speaker C: And we're all working to figure out how we can safely maintain the ability to respond to security incidents quickly and securely while still not holding too much centralized power ourselves.
00:33:17.480 - 00:34:28.620, Speaker F: Unlike roll ups, bridges have it even slightly worse is bridges require a trusted setup. And in the case of any events, like any issues with the bridge, they require the trusted setup to be redone, which means that the human held keys for upgrading or affecting the system are you can never get rid of them. There is no way to remove the admin or upgrade keys from any bridge. The only thing we can do is mitigate their impact on the running system and mitigate the potential damage they could do outside of my own protocol, because I think that was the question. My least favorite trust assumption is the relationship between roll ups and data availability. That there will be roll ups for users require the presence of some infura like trusted data availability provider. If that person doesn't exist, you're not able to use the roll up without running an ethereum node plus a roll up full node.
00:34:28.620 - 00:34:39.890, Speaker F: It just feels messy to me. It's not a bad trust assumption. It's just one that I taste bad. It's not very harmful, it just tastes bad.
00:34:40.900 - 00:35:36.290, Speaker B: Yeah, so I guess I generally agree with the upgrade keys assumption. I mean, it's a pretty standard one. This is where hopefully the notion of sovereign roll ups on top of a data layer directly will help because they retain the ability to harden soft fork through off chain governance while sharing security. But more specifically, other engineer repeating whatever else agrees was clearly upgrade keys. It's the notion of synchronous communication, which I think every protocol here probably makes. It's not that it's inherently bad assumption, but it makes analyzing the protocols very complicated. If we have to assume there's synchronous communication between honest parties, especially when one of those honest parties must be some layer, one blockchain that has very weird guarantees around the availability of its block space, so which is really hard to design around.
00:35:41.480 - 00:36:34.884, Speaker E: Yeah, I think I agree. Synchrony is definitely extremely uncomfortable, especially as you start to deal with different domains or different execution layers. Yeah, I think that I have two that I really still make me uncomfortable, and I know I have rational justification for both of them why I shouldn't be uncomfortable, but they still make me a little uncomfortable sometimes. The first is the way that we think about fraud proof windows over different domains and different execution layers. I think most of the fraud proof thinking has been done on Ethereum, and I still haven't gotten to the point where I fully am comfortable with it on other domains. I know James and I have had a ton of discussions about this, and he keeps being like, no, it's fine. And I'm like, is it? And then I think the other one, that this one might just be because I don't understand it well enough.
00:36:34.884 - 00:36:49.610, Speaker E: But I also have some concerns around the security of the data availability there, just as what additional trust assumptions are being introduced by the fact that you have an entirely separate separate potentially an entirely separate set of actors that are hosted data.
00:36:52.860 - 00:36:55.912, Speaker A: Right. We're just on time. Ed, did you want to give a.
00:36:55.966 - 00:37:03.556, Speaker C: Okay, I agreed with Ben. I think that's the right answer. Upgrade keys?
00:37:03.588 - 00:37:04.024, Speaker B: Yeah.
00:37:04.142 - 00:37:09.020, Speaker A: All right. Awesome. Thank you, everyone, for coming, and thank you all to the panelists.

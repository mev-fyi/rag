00:00:02.800 - 00:00:06.610, Speaker A: All right, each of you want to introduce yourself and what you work on.
00:00:07.550 - 00:00:44.850, Speaker B: Hi, I'm Davi. I'm working on a project called Project Technologies. We're trying to apply currency systems ideas to all the ideas of credit theory money. Basically working on credit, creating mutual credit protocols. Yeah, like, also our domain focus is on supply chain security of such a supply chain security and large overarching goal, I would say global data cancellation and redistribution of everything.
00:00:47.750 - 00:01:09.750, Speaker C: I'm Andrew. I work on smart contracts and privacy technologies, and especially in my trusted hardware era. So most of what I am interested, I'm really interested to talk about what trusted hardware can do in terms of information flow control. I think it changes a lot of what people's expectations, if they have any, are about what can be done with IFC. So, yeah.
00:01:11.690 - 00:01:39.160, Speaker D: Hey, my name is Henry. I'm the founder of Penumbra. It's a shielded Dex app chain so you can transfer funds in. And then there's dexdenne that you can do training with. So the idea is like trying to find one specific use case that you can use to exercise all of the end to end protocol flows. For a protocol that is both useful and has some notion of information control.
00:01:41.620 - 00:02:13.660, Speaker E: I'm Christopher, I work on Anvada. I may or may not be partially responsible for this panel, but I have no idea because we lost control of that information. But recently we've been reading a bunch of distributed systems literature because we're lazy and don't like being stuff, and came across this concept of information flow control, which of course doesn't mean one thing, like five variety of things. But it does seem useful for a lot of what we're trying to do in distributed systems, especially those which are intense using cryptography. That's my hero, I think.
00:02:14.680 - 00:03:08.184, Speaker A: All right, so the first kind of question that I want each of you to kind of think a little bit about is the goal of a lot of privacy preserving technologies for restricting information in blockchain settings are so that when you have an adversarial attack, it's much easier to reason about the strategy space of the adversarial. Restricted the strategy space. They can't do as much, or they kind of have some bound on, like how much they can do given a compute budget. So, you know, kind of classic example of this is go into rest or get look at the consensus node slashing rules and count the number of branches. A lot of those branches are because flashing events have to have a ton of censorship resistant properties. Right? Like someone could try to censor a slashing event to themselves if they're the composer. So there's all this like really ugly as fuck logic that goes into slashing events.
00:03:08.184 - 00:03:50.440, Speaker A: On the other hand, if you did the slashing event at Teddy, you only need a one event trust assumption because anyone who would get some incentive for executing slash doesn't know who the slash is for. So as long as one person is willing to execute it, it's easy. So your slashing rule code might go from 10,000 lines of code to 50. So in a lot of ways that's sort of the, this is just my interpretation of what information control flow controls mostly about. So in the things you're working on, where does that come up? Where are things where you're using cryptography to actually simplify implementations because you suddenly made the adversarial threat model a lot more easy to resolve?
00:03:56.980 - 00:04:41.720, Speaker D: Sorry, I was brainstorming. I feel like it's like a little off panel. But to me the example that most comes to mind with that description is not even about the software systems, but the distinction between like a conventional multisig and like a threshold NPC signing thing. If you are disclosing the information about like, what is the t of n and exactly which wallets are the signers on a multi state, that's like a much worse position to be in than if you're using some cryptography to like hide all of that, do it off chain and just like produce a signature that looks like any other signature.
00:04:45.340 - 00:04:46.560, Speaker A: And you use it.
00:04:47.020 - 00:04:52.160, Speaker D: Oh yeah, that's how the custody for Penumbra works. It's like threshold signing.
00:04:54.950 - 00:05:45.390, Speaker E: Yeah, I mean, it's also not exactly the question you ask, but it's related to me. Part of the advantage of thinking about things through the lens of information is to allow you to reason about sort of game theory and the strategy space at the right level of abstraction. Like at the level of abstraction which agents have which information instead of doing something that's very dependent on specific cryptography primitives. So like maybe you could craft an incentive model or strategy model based on certain information flow control assumptions and implement that with tes now and open yourself up the option to implement it with something else in the future with like certain different cryptographic assumptions but not needing to change. Can I take a step back? And can we all define information flow.
00:05:45.430 - 00:05:49.360, Speaker A: Control and what it means to, to us in our specific cases?
00:05:49.820 - 00:06:09.948, Speaker E: Chris goes first. I mean, I have been trying to use the word in a way that is sort of concordant with academic research discourse, which mostly comes from distributed systems in particular, there's a people called viaduct from Cornell that is working on distributed information for control.
00:06:10.004 - 00:06:10.172, Speaker D: Now.
00:06:10.196 - 00:07:05.904, Speaker E: They do it in the one shot compiler approach. So you write a program and the program describes different agents and what kind of trust assumptions you're willing to make of those agents, what information you're willing to reveal to those agents. And then the viaduct compiler takes that program and selects specific cryptography primitives to implement it, which preserve those information for select zero knowledge proofs or just some signatures, hash functions, public key encryption. Now they do it in this kind of one shot compilation model which doesn't really fit quite, doesn't quite fit the scenario we're operating in. The scenario we're operating in is much more like many people are writing many programs. Like the whole state of the system is constantly changing. And you want both, maybe as a programmer, as an application, and also as a user, to be able to reason about what information will or won't be revealed to whom as a result of your actions.
00:07:05.904 - 00:07:53.810, Speaker E: And as a developer, you want to be able to write programs a level of abstraction where you're talking about what information flow control properties you want, what you want to disclose to whom, and then you can use the compiler to spit out. Or is it similar at all to selective disclosure? Probably yes. The way you just described that, it sounded slightly similar. I mean, there are specific, like, I guess, theoretical frameworks, for example, that allow you to reason about information flow control through a program and then viaduct allow you to select specific cryptographic primitives which preserve certain identity and other information properties. So I don't know if that relates to selected disclosure, but intuitively I would say.
00:07:56.110 - 00:07:57.490, Speaker A: What does it mean to you?
00:08:01.400 - 00:08:34.412, Speaker C: Anything, that there are many notions of information flow control. My version, that mostly matches what Chris is talking about. So I think of this as a kind of formal methods. It is a way of indicating something that you want to your program so that your compiler can reject your program if you make a mistake by not doing it right. So one example, I'll try to walk through kind of the basic example of information flow control. I think I will get it right, but these are like the academic notion and kind of a simplified example. You often just say you have two labels, like high security.
00:08:34.412 - 00:08:54.436, Speaker C: You don't want to leak that low security, that's a public variable. You might have an access control structure in your code that says, well, anyone can read the low security variable. It's public. No one can read the high security variable. It's nothing. There's a kind of error. You can make when you're writing your program and put a bug in your program because you're not good at coding.
00:08:54.436 - 00:09:27.766, Speaker C: And that's you can take the value of the high security variable and write it into the public variable. And now when someone goes to read the public variable, they're learning the contents of the secure variable that they shouldn't, even though they weren't supposed to. And that was the intent. Now, there wasn't. How do you prevent against that? You just don't do that, right? That was a bug, and you should know better than to make that mistake. And hopefully your auditors, if you're basically doing the equivalent of this in a smart contract or something, then hopefully your auditors catch it. And what information flow control.
00:09:27.766 - 00:10:10.750, Speaker C: And this is the basics of the viaduct paper was like the most recent and most powerful version of this from Andrew Myers group at Cornell, but they did earlier versions of this through multiple decades prior. So that newest one kind of automatically enforces this for your MPC program. It helps you tell if you're about to make a wrong program because you wrote the wrong thing, because you labeled those variables that way. And it can detect that you've made this mistake and rejected at the requiring level. You don't necessarily need fancy technology to do that. It's like a way of avoiding a mistake that you could have avoided if you knew to think about it. But the logic helps structure how you would think about it, and it leads to a complete that can avoid this class of mistakes for you.
00:10:15.330 - 00:11:02.360, Speaker B: Well, I'm not the, like, 36th person. I can say maybe not. I can't explain what it is, but I can explain why I feel the, first of all, information from the world sounds a bit like top down. It can be, can lead to good things, it can lead to bad things. But, like, what I am personally, this direction is, I feel like it's a direction of design that can allow people to, like, horizontally organize. And it's a great system where you can take those. And this is the main, like, thing I'm interested in, I would say.
00:11:02.360 - 00:11:37.166, Speaker B: Yeah, like I think about, like last year I read a book called Circe about. Yes, about the nymph and the witch. And she was talking about, there was a mention of this greek concept of pharmacy, or pharmacy, which is like a plant with magical powers that even God cannot sort of reverse the effects of. And I feel like cryptography and these.
00:11:37.198 - 00:11:38.918, Speaker C: Kind of tools that can sort of.
00:11:39.054 - 00:11:47.850, Speaker B: Play the role where you can dictate rules in a way. But the thing is, you have to first, organize your tools. And this is like the most complex thing. So I don't know.
00:11:50.430 - 00:12:50.178, Speaker A: So Tina also made it clear that she didn't really want a determine about the cryptographic methods or like the sort of formal work, but also somehow talk about DeFi and confidential deFi, which is probably why I guess, she asked us to do this. So if I think about confidential deFi, generally there's sort of three classes of state that you want to have, right? You have fully public state, which is, I'm showing a user a price. No one is going to use your protocol if there's no public statement whatsoever. And I caveat that with meme, coins don't count as protocols in this, but no one is going to send money to an address and expect something to happen without some notion of public state. Then you have fully privacy. That's the idea of, I'm a searcher right now. I keep all of my current positions on binance completely private relative to the blockchain.
00:12:50.178 - 00:13:26.410, Speaker A: No one knows that. No one knows I'm hedging some particular position. No one knows my sex side position on sex x. Then I have semi private. And so semi private is when you're taking aggregations across many people's private data, or many people's or public and solely private data, and you are adding some noise to it, you are sort of kind of transforming it so that you can post the aggregated data, but it's hard to understand which. It's hard to identify individuals with high probability. So I call it sort of like statistically private state.
00:13:26.410 - 00:14:07.848, Speaker A: In defi, you have to think about building all three of these, right? You have to think about where this kind of, these revelations happen. As you're writing code, you have to think about, okay, to Andrew's point of like a yemenite, is this variable, what's its lifetime? Is lifetime going to be as perpetually private? Is lifetime statistically private? And when you transform between those boundary domains, you obviously have a lot of properties. So in the protocols you're working on, how do you think about this partitioning, and how you think about partitioning state versus execution, how you keep them separate? Obviously, I think t's versus very extreme, you're going to get different answers for how the state is partitioned.
00:14:07.864 - 00:14:10.248, Speaker C: So that's why the numbers started in between.
00:14:10.384 - 00:14:17.940, Speaker A: Yeah, well, you guys have the right orders. Not my vote. Right.
00:14:20.440 - 00:15:26.640, Speaker D: So branching off of the previous prompt or whatever, one case that as an example of like, flow control that makes things easier to reason about is for penumbra, the model we have is that all of the per user data is in the shield pool and that's private and all of the chain state is public and transparent. So all the positions on the decks are public and known to everyone. That's obviously a lot easier to implement. But when someone creates one of these positions, the order that they make is funded out of the shielded pool and it's not updatable. So they have to close it out and put those funds back into the shielded pool. And that makes the reasoning about it a lot simpler because there's no long term linkage of I see this position was created at this time and I can immediately infer that this is part of this person's complex like multi leg strategy. I just see someone has created this position and that is substantially easier to reason about because you're just seeing the individual pieces.
00:15:26.640 - 00:16:46.966, Speaker D: The second thought that I think is interesting is I personally am like quite bearish on pretty much any kind of protocol that requires user interaction. And for this reason I think that a split between private per user state and some public state that they can interact with is basically the middle ground that you have, unless you are using tes. Because anytime you have a system where users have to interact with each other directly, like I have to do an NPC with you in order to do a trade. Now from the sort of system developer perspective, it's very very challenging to get any kind of adoption for the system because you have to onboard users in pairs in very very tight time. Whereas if people are interacting in some public way with some public state, that on chain state can basically act to smooth out the user onboarding over time. This is why I think Uniswap worked really really well and atomic swaps were like the nerd thing for years that no one ever used. It's because in that case you get.
00:16:46.998 - 00:16:47.570, Speaker C: To.
00:16:49.470 - 00:17:10.730, Speaker D: You get to interact with the contract. And so as an individual person you can just choose to opt into doing it. Whereas if you have a cryptographic mechanism that requires you to be interacting with another party, now you can't just use the coordination technology to do stuff. You first have to pre coordinate to find the person that you're going to interact with.
00:17:18.079 - 00:17:55.946, Speaker C: So yeah, I want to go straight to how NPC's. This could be true of the number. I want to reject your framing a little bit of I do think that there's another kind of information category. So you went through public private and semi private, which you described as leaking some information they can and hash 30 aggregate sense about these. What I think we really have the opportunity to do, and I really want to draw attention to this, so it's tricky to categorize things beyond that. But I think we can. I care a lot about like the auction setting and the notion of failed bid privacy.
00:17:55.946 - 00:18:42.394, Speaker C: So one of the things I'm most am concerned about is if you contribute your bids into an auction, and it's the kind of auction where your bid can fail if it's not the winner at the auction. I really want to make sure that your failed bids are pivoting, the reason being that that's a good predictor of your unmet demand, that you're probably that reveals kind of what you're going to trade later on. So failed bid privacy is really important. But then that notion is a little bit different because there's a chance, and if you won the auction, it would be revealed. But if you didn't win the auction, then you reveal no information, not even an aggregate about it. This is certainly something you can express with an NPC auction. I think this is true of Zswap, except that I don't think you really have a notion of failed bids because you get whatever your amount was traded at that price without a.
00:18:42.394 - 00:18:45.110, Speaker C: It's not like you have a slippage limit. Well, we.
00:18:49.130 - 00:19:32.232, Speaker D: Yeah, well, what we ended up settling on actually is a mode where we don't attempt, at least in like the v one of the number. We just kind of like axed and whole, let's threshold encrypt all the stuff and do the encrypted batching because it was not really clear to us that the marginal increase in product value going from I can do a transparent interaction with a public position to I'm going to be private within my batch, but maybe the batch size is one because it's like a new protocol that nobody's using and shipping things is hard, but.
00:19:32.256 - 00:20:07.012, Speaker C: It makes sense, your reason for choosing that. But it's something you could do under the same threat model. Regardless of that, to provide that failed means privacy. But to me, the right way to think about what it's hard to pick what's a good name for another class of things that this falls into. It could be conditionally private, maybe. But I think the really key shift is that we normally think of access control as who can see what you're kind of limited to, that if you give someone information, you can't control what they do with it afterwards. You can have a contract, you can try to slash them if you determine that they've conclusively leaked something that's really hard to do.
00:20:07.012 - 00:20:24.200, Speaker C: But with MPC and trusted hardware, you cannot worry about who you're giving the information to, but how the information can be used. You can give information to a program, not to a specific set of people, and that seems to open up a whole lot else. I think that needs more categorization.
00:20:24.540 - 00:20:24.924, Speaker F: Yes.
00:20:24.972 - 00:20:29.692, Speaker A: For me, I was just trying to figure out, not have like ten categories.
00:20:29.796 - 00:20:37.720, Speaker E: Yes, well, I'm afraid that at least I'm going to play the bearer of bad news, because I think we have infinity categories.
00:20:38.500 - 00:20:39.760, Speaker A: And I would add.
00:20:43.910 - 00:20:44.558, Speaker F: I would add.
00:20:44.614 - 00:21:43.124, Speaker E: Two dimensions to your categorical scheme, which are identity and time. The first one is one we care about, particularly related to this problem of counterpart discovery, because we also want to support some kind of non interactive discovery where users don't have to find each other in Brussels trade. And in the context of supporting that, we think a lot about to whom specific tense are sentence. Because in the way of thinking about things, two phases of counterpart discovery, where you're trying to discover a mic that works at settlement, where you're trying to post your transaction somewhere. And privacy and settlement is much easier because once you know what the transaction is, you can just make a zero knowledge proof, at least for all the parts of the state changes that are known. Whereas privacy and counterpart discovery faces the fundamental trade off of, in order to discover the counterparties, you must reveal some information about what it is that you want. So we care in part about reasoning about to whom users are revealing that information.
00:21:43.124 - 00:21:45.972, Speaker E: How long did this user say they're supposed to store it?
00:21:46.116 - 00:22:14.750, Speaker A: All right, now it's time for a celebrity guest question, in that Hart thinks a lot about these types of solvers and getting them to show up to his protocol and make sure their users actually get their funds across, no pun intended. And how do you think about this kind of counterparty discovery in a private world? You have rebuilt your protocol, assuming you have intrusion.
00:22:16.530 - 00:22:41.650, Speaker G: Okay, so you guys like handle of super smart, big brain cryptographers. From a finance perspective, what do you care about? You care about no one arbitraging are screwing over your users. So you want to have the user reveal the minimum information about what they're trying to do in a way that gets them the best feel possible.
00:22:42.510 - 00:22:48.902, Speaker A: So how do you figure out, like, the value to the end user of using all these slow controls? How can they price them?
00:22:49.046 - 00:22:53.670, Speaker D: And I have a question, which is, what happens?
00:22:53.790 - 00:22:55.210, Speaker G: I'm not on panel, dude.
00:22:56.270 - 00:23:27.066, Speaker D: You're just doing the whole, like, okay, let me tell you the alternate perspective. So here's the question for that perspective is, what happens for a user when those two goals that you mentioned are actually intention, right? Like, if I am revealing the least amount of information possible, does that actually get me the best fill? Or if I reveal some information that says, like, I am a random metamask user and not citadel, like, maybe that gets me, you know, better pricing.
00:23:27.178 - 00:24:12.852, Speaker G: Yeah, I mean, I agree with that. Right. So it's like you can discriminate order flow to give, like uninformed retail flow, better pricing than informed flow. That's something that happens, generally speaking, and my mic feels really loud here, but generally speaking, my take would be, you want to use competition in like a cross chain bridge? Jo, I want to give the user the most funds possible on destination chain. And if you're trying to be sort of private sense, this is not something I thought a ton about, because this isn't my world. But you want to give, use an auction or some form of an auction to figure out who's going to pay the most. And I think then you do.
00:24:12.852 - 00:24:27.880, Speaker G: Where I think the information flow control stuff gets really interesting is running that auction in a verifiable and private way, like our friend Andrew here can build and get pretty cool effects that way. But I don't know if that's answering your question.
00:24:28.040 - 00:24:28.568, Speaker F: No, that's good.
00:24:28.584 - 00:24:31.780, Speaker A: I just needed some third party spice.
00:24:32.160 - 00:24:33.740, Speaker G: Marcus, you got anything to add?
00:24:35.760 - 00:24:36.500, Speaker E: Sure.
00:24:39.840 - 00:24:40.168, Speaker C: Yeah.
00:24:40.184 - 00:25:36.130, Speaker F: I think adding to what Hart said, it's important to realize from a practical sense that today most auctions are publishing information, and that's like the default that we have, which is easy, but also a bit naive. And I think you will most likely see changes being made to these public options, as we see, and are more aware of the costs that users are paying for having their information revealed. Like today, I don't think it's a stable equilibrium of having absolutely all information of intents, especially on larger swaps, public on public APIs, and rather we have to find ways to make that permission private somewhere along that scale of great to not have users be front run.
00:25:39.190 - 00:26:34.490, Speaker E: Yeah, I just wanted to know my other dimension, but it's related to this question, I think is, to me at least, information blow. Control is not just about whether state is private or not, it's also about when people can verify certain things. So credit, actually, this idea to Vitalik mentioned it on another panel we had about information flow control, which I was a meme, but for example, you could create a proof of something like either I know state such that x, like I know a piece of private state that I'm willing to swap for another piece of private state. Or I know the output of a BDF function, which I couldn't compute before a certain time. And now you've created a piece of data, a proof that before a certain time in the network, it provides like proof of something that's relevant to a steep transition. Right. It could be part of an intent, could be input or swap, but after a certain amount of time, it actually proves nothing because someone else could have made that proof just knowing the VDF effort.
00:26:34.490 - 00:26:42.526, Speaker E: So I think there's this like interesting temporal dimension that would often play into actual financial market structures. That could be something to consider.
00:26:42.678 - 00:26:43.414, Speaker A: Yeah, absolutely.
00:26:43.462 - 00:26:45.970, Speaker F: I think pre trade privacy is much more important.
00:26:48.030 - 00:26:48.382, Speaker B: Cool.
00:26:48.406 - 00:27:16.504, Speaker A: I know we're almost running out of time, so I'm just gonna go have you guys answer one final question, which is, what DeFi application do you think will use information flow control in practice, in production? At least $100 million in assets. First, what type of person should they name names? What? It might not be one that exists, might be something, but you have to be able to describe it. You can't just say not everything that exists.
00:27:16.592 - 00:27:17.580, Speaker B: It's kind of boring.
00:27:18.520 - 00:27:22.792, Speaker A: That's like being like the guy in Times Square with the, like, jesus is.
00:27:22.816 - 00:27:23.700, Speaker C: Coming today.
00:27:26.760 - 00:27:28.180, Speaker B: I'm gonna be this guy.
00:27:32.780 - 00:27:34.480, Speaker A: We gotta get your cardboard box.
00:27:36.540 - 00:27:57.230, Speaker B: I don't care about defy really is for me, it's casino. Like, you just. Casino is creates subculture. I mean, I see it like this, but like, you mean you pay within, you play within the system to get more chips to get them out of the system, and then you pay for stuff. Like this is the only thing defi can do right now.
00:27:58.410 - 00:27:59.322, Speaker E: Thank you.
00:27:59.426 - 00:28:00.110, Speaker F: Yes.
00:28:00.610 - 00:29:03.612, Speaker B: And so me, like, I care about how do we make tools for internal defi? Actually, the same time you can ignore it. So it did provided some background, like playground to explore some concepts like economics in economic field and like distributed systems. So like it led to some good outcomes in terms of, like, it gave like playground to explore cryptography, shooting systems, economics and stuff like that. But same time I feel like, yeah, I don't, like, try not to glorify it. Like, I don't take it seriously. Like, one thing is hard for me to think about is how do you bootstrap real economies? And so maybe defi can be used as a tool to do that. So in a sense, like you, so you have like order, like things that discuss recently with my friends.
00:29:03.612 - 00:29:06.200, Speaker B: Like, you have order books.
00:29:07.980 - 00:29:08.644, Speaker C: Dexs, and.
00:29:08.652 - 00:29:45.494, Speaker B: You can use them to provide liquid to like grant crossroads economics where you can have like movies that clears the dent and within the closet community that actually tattoo stuff we do. But then you can switch the tracks and you reverse it. So, like, if you have a, you have, if you're able to combine enough pool of people, like big enough community to actually have enough additional power to then dictate, just like their order books go like shallower and shallower. Shallow, they will shut down.
00:29:45.542 - 00:29:45.894, Speaker A: Okay.
00:29:45.942 - 00:29:46.646, Speaker B: Yeah.
00:29:46.838 - 00:29:47.730, Speaker A: Excellent.
00:29:50.150 - 00:29:52.822, Speaker D: But actually my short answer is penumbra.
00:29:52.926 - 00:29:54.610, Speaker A: Yeah, I know your answer.
00:29:55.670 - 00:29:56.650, Speaker B: Let's go.
00:29:58.110 - 00:30:34.920, Speaker C: I think I'm pretty excited about the mutual credit kind of direction. I think that in the near ish future, we will see a lot of different economic among people that looks a lot like lending money to family and friends, but it won't be in the way that you're used to, which is kind of unhealthy and bad because you won't have to know when the friends who you've offered credit lines to have taken you up on it. So you'll have a friendship bankruptcy protection mode of lending to friends and family that is protected through information better pure economics through information production.
00:30:37.340 - 00:31:08.516, Speaker E: Yeah, well, I kind of agree with that answer. To try and come up with something else that's different and interesting, I would say maybe we would have some kind of private, large scale upper goods funding using information to control certain things. Certain parties at different times can just create different incentives for people to like. Like to like when you want to issue certain evaluations in a way that.
00:31:08.548 - 00:31:09.948, Speaker D: You don't want other parties to always.
00:31:10.004 - 00:31:24.680, Speaker E: See who's saying what. I think this can be pretty helpful. You can create lots of interesting, like, structures for surfacing honest preference information when people know that the preferences that they're providing to the system aren't necessarily going to be used against them. Inquiry. So.
00:31:25.530 - 00:31:48.450, Speaker A: All right, well, hey, give a round of applause for our panelists. Learned a lot about information flow control, or we've done such a good job at conveying that we know the concept without revealing anything so confusing to understand that it worked.

00:00:09.530 - 00:00:44.022, Speaker A: Thank you. Hello. Thanks a lot for having me here. Very colorful and diverse audience, really great, really excited. Also, big thanks to the talks at the team that talked before us and really prologued in a great way, our talks and our work. I will talk about the dynamics of the EIP 1559 fee market. And this is work that I have done jointly with Barnabay here and Sam.
00:00:44.022 - 00:01:38.342, Speaker A: Big thanks to them for introducing us to these problems and of course, to this community. Yeah, I'm Stefanos, and also the work that I present is a joint work with my collaborators from Singapore University of Technology and Design, Daniel Reisbergen, Georgia, our inspiring advisor there and Stratis. So, yeah, all the things about AIP 1559 are already known. Very lucky to present at that point after these great speakers. So let me go right away to the dynamics that we are going to study here of the market. So at the center of EIP 15 nine is the base fee, as we heard before, which is dynamically adjusted between blocks. So have that the base fee of the next block is simply a scaled version of the base fee of the current block.
00:01:38.342 - 00:02:26.266, Speaker A: And the exact value depends on the term that we see on the right here. So the block size, how much gas was used and essentially a normalized term here that says how much more gas was used in comparison to the target that we have, which is right now to have half full blocks. And this depends on our fixed learning rate, which is currently the default now set at one over eight or 0.1 to five. All right, so that's exactly the update rule. And what we want to do in this talk and this work is to stress test this mechanism and what are the parameters that can change. In the formula above, there are precisely two things that we can see here.
00:02:26.266 - 00:02:56.898, Speaker A: So, okay, the target, we want to leave it at half full blocks for many reasons. This is nothing that we want to play with. So we can change, of course, the block size, which depends on exogenous factors like the demand that we have for use of the blockchain. And this is something that we want to study. We want to study how the mechanism reacts to different demand conditions. We can also change the learning rate, which is set at one over eight. And this is a parameter that we can decide and we can have different values for it.
00:02:56.898 - 00:03:38.340, Speaker A: And we want to see how different values of this parameter are going to change the mechanism. And the last thing that we can do is to go to the design space of possible mechanisms because it's just one mechanism to update the base fee. We can, of course, start from scratch and think of different mechanisms. And here, if we want to go that way, we have some constraints. For example, we want mechanisms that are simple for many reasons that I'm going to explain along the way. Of course, dynamic, because we have a very dynamic environment with blocks coming every few seconds. We want also the mechanism to be explainable and safe to understand what it's doing, so that users also understand what it's doing.
00:03:38.340 - 00:04:23.726, Speaker A: So if we want to study different rules, as we are going to do along the way, we want to keep these constraints in mind. So. Okay, our main task here is to take the EIP 1559 transaction fee market and study it from a dynamical systems perspective. See how it behaves in time and whether some oscillations that we have seen empirically, whether they are bound to the mechanism that we have selected or whether they are due to some other reasons also. Tim, very nicely explained before. So let's go to start with some stressed heads, maybe. Okay, a difficult figure to parse if you are not familiar with it.
00:04:23.726 - 00:04:59.898, Speaker A: So let me try to explain what we are looking at here. Let's start, for example, if you can see the hand here, let's start at the left of the x axis, where we see two kinds of block sizes, either empty blocks. So in the vertical axis we see the block size and we see either empty or full blocks. And this is something that we are familiar with. We see that, for example, we have quite a lot of demand. We see a lot large oscillations in the block. And what we change here in the horizontal axis is exactly the range of valuations that we have that the people that try to interact with the blockchain precisely have.
00:04:59.898 - 00:06:09.790, Speaker A: So if you think that if we are close to zero, it means that we have quite a lot of people that are coming and have the same valuation to transact with the blockchain. So essentially this means that a small change in the base fee would either price all of them in, all of them out. So what we have here with this mechanism, the EIP 15 nine, is that as the base fee changes goes up, for example, to account for very full blocks, it suddenly prices everyone out. This means when we are close to zero, it means that we have a lot of people that are at the same point, have the same valuation. Whereas if we go at the other extreme of the horizontal axis, around 25 here, if you can see it, where we see just one kind of blocks correct, exactly, I'm sorry, one kind of blocks being produced exactly half full, which is the target. Here we have valuations that are nicely spaced and the mechanism that we are studying, EIP 15 nine, can really predict the correct price, the correct posted price and really price half of them out and half of them in. In between we see a regime where we have this fancy shape, where we have chaotic behavior.
00:06:09.790 - 00:06:54.814, Speaker A: And this is one of the main findings of our work that the I 15 nine becomes chaotic and we have large oscillations for very compressed demand, too many people coming together, chaotic behavior in between and of course nice behavior as expected. But to have this we need to have a large distribution of valuations which of course is not always met in practice. Now we have a similar figure for the base feed dynamics. So what we saw before in the previous slide was the block sizes, the blocks that are produced. And here we see the base fee, how the base fee changes. So of course, again, if you go to the regime close to zero, you see that there exactly. We have two values, one large one and one small one.
00:06:54.814 - 00:07:27.046, Speaker A: The large one prices everyone out. That's why we had the empty blocks and the low one prices everybody in. So that's why you had the full blocks in between. We have again the chaotic regime regime and then we have conversions to the correct value that EIP 15 nine ideally could find and produce all the time half full blocks. Of course, as you see, this is a chaotic behavior. So here a technical note. We have used a normal distribution for the demand but our results of this behavior are robust to any kind of distribution.
00:07:27.046 - 00:08:18.586, Speaker A: That's a technical note. No need to worry about if you are not familiar with probability distributions. Essentially it says that any kind of demand that we are likely to experience in reality is likely to produce such results. So they are not specific to the technical assumptions that we have followed here, are quite robust across different assumptions. Of course, not everything is very bad here because as you see, although we have chaotic behavior, everything happens within some red lines that are maybe a little bit impossible to see. Yeah, but everything happens within a certain region. And the nice thing with the IP 15 nine is that if we take the average so horizontal, vertically, if we take the average of these very complicated attractors or shapes that we are looking, they are just right.
00:08:18.586 - 00:08:58.230, Speaker A: And that's where we are looking at the figure in the bottom. If you see here, this is exactly 0.5. So we see that if we modulo some noise, the blocks on average for every possible demand that we can experience are exactly equal to one half. This is a little bit bound to the simulation I write here. It can also slightly overshoot the target. And this is indeed what we see in other experiments that either we have exactly half full blocks on average or slightly larger than that. So 53% or 52%, but not very larger.
00:08:58.230 - 00:09:26.290, Speaker A: And above we see the base fee. The base fee is not entirely correct. The correct value would be on the red line, probably not visible. But this doesn't matter because it produces the correct block. So up to now we have seen quite wild behavior from block to block dynamics, but we see a very nice behavior, excluding some noise here it's a fourth decimal number. So even maybe this goes also away, but it doesn't matter. We see very good behavior exactly as we want if we take the average.
00:09:26.290 - 00:10:08.174, Speaker A: Now, in this case we did a stress test. So we tested different conditions, even adversarial ones, a whole range of different conditions regarding the demand that we can experience. Now I can go on and also produce similar shapes. I will not hire you more with such kind of shapes even if I change the learning rate. So this parameter D that is currently set at one over eight, again you see if I have a very small learning rate. Currently we are here at zero point 125 where we have some kind of chaotic behavior. If you remember also the previous paper we saw quite a lot of full blocks being produced by AP 15 nine and a distribution of blocks filling the whole space.
00:10:08.174 - 00:10:44.794, Speaker A: And this is exactly what this stress test produced. So one takeaway is that we are using here a mathematical tool and it has the ability to correctly predict what's happening in reality. Again, here what we are stressing, what we are trying are different values for this learning rate. Of course, smaller learning rates have very good behavior, lead to convergence, but this means that they are very slow and larger ones tend to create chaotic behavior. I will not argue more. So we can get again for the base fee quite wild behavior, but on average we have very nice performance. These are very similar to the previous ones.
00:10:44.794 - 00:11:10.722, Speaker A: So I'm going fast through the slides. Here we see the block sizes. For example, the current learning rate, they are slightly above 0.5, which is the ideal. They are at zero point 53. I think there are quite a few reasons why this happens here. We provide also a mathematical reason for having blocks that are more than half full, but not by much.
00:11:10.722 - 00:11:53.098, Speaker A: Okay, so we stressed as two parameters that I promised in the first slide. So the learning rate and the demand. And the only thing that remains to do now it's the third one to go to the design space. So what we have here let's recap. So we have that EIP 59 is simple and is quite a very important point because we don't want to have a very complicated mechanism that we don't understand because then we will need to stress test along a much larger space of conditions and really get lost and not know what to expect. When we have a simple system, we know where it can fail and even if it's not perfect, we know what to expect. Now when we go to the design space to study different mechanisms.
00:11:53.098 - 00:12:26.300, Speaker A: Maybe the mindset here is like the meme that we have. So we want to be perfect and the question is whether we can do better. So we have a simple mechanism that is working. It nails perfectly on average. Okay, sometimes it may be slow as we are going to see also later, but now we really adopt this perfectionist mindset and say okay, can we do better? You are on my list. Now we want to do better, we want to see if we can improve even in this case. So let's have some empirical data to see where to start from.
00:12:26.300 - 00:13:29.370, Speaker A: What we see here in this figure is precisely also described by the previous speakers, what happens when we have an NFT drop. So here we see with a blue line the gas price that is paid by the users and with the red line we see the base fee dynamics. And we see here what was presented also by the previous speakers that we have a gap between the actual average price paid by the users and the current base fee. So what happens here is that for some blocks the miners are really lucky because the base fee hasn't catched up and people are paying quite high prices and all this is getting to received by the miner. But here when the base fee catches up in the end, the miners that are producing these blocks are now having a much lower reward. So, okay, we heard that it's not a problem to have these oscillations and to have good performance on average. But actually we see here that we have an inter block variability and miners this may create some problems for miners for having very unequal rewards.
00:13:29.370 - 00:14:14.174, Speaker A: So in this case, something that would change this figure would be if we had a faster learning rate, a higher learning rate, so that the mechanism could adjust much faster. But this is during the NFT drop. If we don't have an NFT drop and we have normal conditions like here, so we have the same demand through the whole window that we are plotting here, we see that for example, people, okay, are paying sometimes different prices. The base fee, the red line here is fairly stable. It's oscillating in this howtic regime, but within some bounds this is not a problem. What is the problem is that the block sizes are quite erratic. So we have full blocks, empty blocks, and this is absolutely not necessary given that the demand is quite stable at that point.
00:14:14.174 - 00:15:15.898, Speaker A: Again, this creates a large variability in the rewards received by miners even of consecutive blocks. In that case, to avoid this, we would like to decrease the learning grade. So have a much lower D, this parameter D that we were set at one over eight, we want to have a smaller one that will lead to much smaller changes in the demand. So what to do? The question is whether we can combine now the best of both worlds and have both things have also a large learning rate, a small learning rate, and of course study different mechanism than currently EIP 1559 is implementing. So, how to have a variable learning rate. We want to have a high learning rate during demand peaks where we have aggressive adjustments and a low learning rate during stable demand. So, if you remember the formula in the first slide, we just had this D, this is exactly the railing rate of the mechanism and this is constant all the time.
00:15:15.898 - 00:16:21.990, Speaker A: And we want now going to the design space and trying to modify this mechanism. Of course we don't want to go very far because as I said in the beginning, if we go down that way we are going to introduce more complex mechanisms and this will going to create new threads and we will need then a more complex stress test analysis to reveal all the faults of the mechanism and that will be data. So here we're going to do a very minimal change inspired by internet congestion control, where we have additive increases and multiplicative decreases to control congestion. So, very briefly, without going into technicalities, what we will do, we are going to track not just the base fee, not just the block size of the last block, but let's say of the last five blocks or something like that, and if we have exactly the correct value. So if we are close to 0.5, meaning we have stable conditions, we want to dampen the changes in our base fee. So we are going to decrease the learning rate, not the base fee, the learning rate.
00:16:21.990 - 00:17:12.390, Speaker A: And this will create very similar base fees between consecutive blocks. On the other hand, if we have the average meaning, let's say we have four or five full consecutive full blocks, which is exactly what we observe when we have an NFT drop, then we want an aggressive change. We want to implement an aggressive change in the base fee. And to do that, we're going to increase exactly the railing rate. Of course, as I said also many times before, adding complexities is not a panachia because it's going to introduce new threads and we will need a more complex stress test to be sure that it's going to work on practice. All right, so let's see some simulations that we did now with both mechanisms. So, EIP 1559 and the additive increase multiplicative decrease AIMD.
00:17:12.390 - 00:18:08.030, Speaker A: So here we have what we saw before, AIP 1559 oscillating during a normal period with stable demand. And here AIMD looks much more stable and similarly in the demand peak, EIP 59 leaves this gap here, which creates unequal rewards for the miners to the very least, whereas AIMD catches up very quickly. Of course, the question is AIMD now has different parameters to implement these changes and this means a larger space. So there is a danger that when we have this figure here that shows that AIMD works well, that we are overfeeding the data that we have seen. So if EIP 1559 is simple, so works the same overall conditions and if it fails at some point, then this will be the same everywhere. Here we have the danger that we are performing well against some conditions that we saw. So NFT drop and stable demand.
00:18:08.030 - 00:18:44.782, Speaker A: But maybe overfeeding to these conditions means that we are going to do very bad in some kind of conditions that we haven't seen. So AIMD gives a promising direction, but one should be cautious and not say that it solves all the problems. Some more data here about the full data set performance of this mechanism. We have two performance metrics. So we see here in the figures the blocks produced block sizes produced by AIMD. During stable demand we see less oscillations, less full blocks and much less empty blocks. And also here during the demand peaked.
00:18:44.782 - 00:19:27.794, Speaker A: An interesting metric here in the performance is that we implemented the current EIP 15 nine. We implemented EIP 15 nine with a small step size and with a large learning rate or step size. In all these cases we had quite a large amount of very full blocks. So blocks more than 95% full. But with the AIMD we had a very low numbers of these kind of blocks and also on average, all of them did well. Maybe the AMD again did better. But as I said, introducing more parameters creates the danger of overfitting the data that we have and creates more possibilities for things going wrong.
00:19:27.794 - 00:20:15.362, Speaker A: Okay, so let me recap what our research has shown for EIP 59 is that now currently it is at the phenomenal advantage. So as very Eloquently Tim said before, these kind of mechanisms cannot be solved, problems cannot be solved by of the self solutions from economics. And doing something now right or better than everyone else, like EIP 15 nine is doing, puts this mechanism and of course the ethereum ecosystem at a phenomenal advantage. Of course it's not perfect, but it's as good as it gets for now and it's a very good starting point to improve in the future. As a very short takeaway, block sizes are achieved on average. Of course we have the interblock variability. It was argued before that it's not a big problem.
00:20:15.362 - 00:21:31.370, Speaker A: Also by Vitalik and the previous speakers and maybe just as a point here, as a side note, these oscillations create differences in mining rewards, which may be a source of concern for miners. Also it's worth studying, maybe alternative mechanisms under the constraints that I mentioned, keeping it simple and able to be studied. So with variable raining rate, also variations of EIP 59 or the automated market maker mechanism, quite interesting right now we are also producing results in these directions will be soon available and maybe some reference to the resources of the stock. So we have two papers on archive. You are welcome of course to have a look and also reach out if you have any questions. The last one was the transaction fees on honeymoon was very recently updated also with newest results. And you can also find on GitHub libraries for the simulations that we have in this paper and the agent based simulations here, or the simulations that I presented before by Daniel here, our collaborator.
00:21:31.370 - 00:21:41.660, Speaker A: Excellent repository here and excellent work. Yeah. So that's all for me. Thanks a lot and of course, contact us if you have any questions.
00:21:49.010 - 00:21:55.490, Speaker B: Thank you, stefanos, that was a great talk. Thank you. Is there any questions from the audience?
00:21:59.190 - 00:22:00.990, Speaker C: Hi, thank you very much for the presentation.
00:22:01.070 - 00:22:01.860, Speaker A: Very interesting.
00:22:02.310 - 00:22:05.566, Speaker C: You mentioned there briefly at the end, the inter block variability.
00:22:05.678 - 00:22:05.954, Speaker A: Yes.
00:22:05.992 - 00:22:27.420, Speaker C: And I'm curious if you have more thoughts around, like, let's say, this block time affecting the desirability of different update rules, for example, smaller granularities. Maybe, let's say one intuition I have is that maybe the chaotic part of it is less of a problem as you have shorter block times because the user experience will still be pretty. All right. And I'm curious around your thoughts around that, correct?
00:22:28.510 - 00:23:06.866, Speaker A: Yeah, exactly. The chaotic behavior is not really a problem. So you really have it and it's chaotic behavior within some bounds. As you said, the user experience is much more worried about the average performance. And since you have blocks coming very soon, close to each other, the result is pretty good. I think the main concern for the interbrok variability is the reward for miners and the topic for which there is quite a lot of discussion, the mev that it's going to be very different between miners of consecutive blocks. So for example, you mine a block, it's full and the very next block is empty.
00:23:06.866 - 00:23:41.790, Speaker A: And you kind of complain of getting nothing out of mining that block. So getting a very low amount of fees. The users do not experience that because just 10 seconds or something like that, but the miner has a large variance in their payoffs. So I think that's the main concern. Otherwise the chaotic behavior is indeed not really a concern. And I think it's also inherent to most mechanisms that are using this kind of update. So also the AIMD or also using different learning rate again creates chaotic regime.
00:23:41.790 - 00:24:05.498, Speaker A: But as you say correctly, it's not that bad for the user, only for the miner. I would say there is a problem. So that's the only source of concern. I don't know if this answers the question. Okay, thank you. Thanks for the presentation. Thank you.
00:24:05.498 - 00:25:10.254, Speaker A: This is based on proof of work. If we move to proof of stake, what's going to happen? Yeah, that's a very good question. So there we are going to have, of course, fixed intervals in the blocks and also know the minor. I think that from a pure dynamical perspective, as a dynamical system, I don't expect much to change in the behavior of the dynamics because you have again the transactions arriving in the pool. Some of them get into one block, some of them remain, but the big changes will be there, I think, for the miners and knowing which block they are going to mine. For example, an NFT drop is approaching and you know, you're not going to mine first, you're going to mine late in the drop or something like that, and you're going to get the blocks with the low payoffs and maybe then it creates very perverse incentives and very complicated threat models that we need to study. So that's actually a very good question and yeah, that would be a great direction to study before, of course, launching the proof of stake system, I think.
00:25:10.254 - 00:25:12.880, Speaker A: Yeah, that's totally at the point.
00:25:14.370 - 00:25:21.460, Speaker B: Yeah, this is something that you touched upon in his talk as well. The move to proof of stake will be really interesting. Yes.
00:25:24.310 - 00:25:25.300, Speaker A: Good question.
00:25:28.170 - 00:25:37.990, Speaker C: Do you have any lessons or recommendations about the implementation of such simulations? The actual simulation software?
00:25:40.990 - 00:26:08.260, Speaker A: Yeah, we are about to add the software to use to do the simulations. Yeah, I mean, just Python or things like that. We have used also for the agent based simulation and for the other one, or I think Daniel did the simulation. The last part is also in Java or JavaScript, not sure which of the two, but yeah, we haven't used something much more fancy than that to produce them. Also MATLAB works if you are old school.
00:26:11.510 - 00:26:43.680, Speaker B: Yeah, I can maybe even talk about it. The ABM simulations, that was part of that work. I think they work really well to study, let's say more theoretical patterns. But now we are trying to augment them with actual on chain data as well as transaction pool data to try and see how different mechanisms would work. And for instance, see what happens when you move to proof of stakes and you have fixed block times. So simulations are nice, but when you augment them with the data, they become even better and they're really useful as a predictive tool.
00:26:44.210 - 00:27:14.920, Speaker A: Also, maybe to add something here, also mentioned by the previous speakers that the Mempool is a quite interesting direction to go next. It's going to give quite a lot of information because all the simulations assume quite a lot of demand and okay, mathematically you do some assumptions that it's going away and coming again in the next block, which is not entirely realistic. It gives you the correct outcome, but maybe it's much more interesting to see and learn lessons from the Mempool. That would be very interesting.
00:27:16.570 - 00:27:18.114, Speaker B: Yep. Thank you again, Stefanos.
00:27:18.162 - 00:27:19.780, Speaker A: Thank you. Thanks a lot for having me. Thank you.

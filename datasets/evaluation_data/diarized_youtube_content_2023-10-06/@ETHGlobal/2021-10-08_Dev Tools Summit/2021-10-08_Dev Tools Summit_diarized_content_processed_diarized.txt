00:03:01.460 - 00:03:30.176, Speaker A: Good morning, good afternoon. Good evening, everybody. My name is Kartik, one of the co founders of ETHGlobal. I want to welcome all of you to our DevTools Summit. So all of you are watching this on ETHGlobal TV. Just a quick reminder for those of you who are joining this thing for the first time, this is what we're going to use for the rest of the day. So this is a live platform, so if you have any questions for our speakers, you can just sign into the chat and ask those questions there and we'll be able to relay those questions directly to our speakers today.
00:03:30.176 - 00:04:03.508, Speaker A: Also, for everybody that joins in, we will be giving a NFT POAP to all the participants. So sign in and say hi. And for those of you who are curious on what the timeline looks like for the Poaps, it's going to be right after ETH Online ends, which is next Friday. So this event is organized by ETH Global. And for those of you who don't know what ETH Global is, it's an organization with a very simple mission. Our goal is to onboard thousands of developers into the Web three ecosystem. And we do this by running hackathons and Summits.
00:04:03.508 - 00:04:46.388, Speaker A: So ETH Online is our biggest event of the year. ETH Online is a collection of a handful of Summits and a month long hackathon. For the hackathon, we have over 1100 people from 77 different countries participating from 19 different time zones. There's an incredible number of folks from so many diverse backgrounds and skills, and we can't wait to see what they build when we see all the project submissions next week. On top of that, we're doing six incredible Summits highlighting all the amazing things happening in this ecosystem. So our first Summit was about NFTs and creators on September 24. Then we did a Summit about the Ave Grants ecosystem on the 30th.
00:04:46.388 - 00:05:25.380, Speaker A: Last Friday was our Summit around governance and dows and everything that's happening in that sector. Yesterday was our Summit highlighting all the amazing things on the Compound Grants ecosystem. And today, of course, is our DevTools Summit. We're going to talk about all the things that you have access to as a developer and all the amazing tools that you can use into your existing workflows. So I can't wait to dig in. And next Friday will be our last Summit and also the hackathon finale, where we're going to showcase all the amazing projects from the hackathon, as well as talk about the future of Ethereum with Eats too. So let's get into today's Summit.
00:05:25.380 - 00:06:06.960, Speaker A: So we have an incredible lineup today. There's so many amazing people from the developer side that are going to come on and talk about what they've been working on. We're going to kick off the day with Austin, who's going to talk about how everything is structured under the hood for Scaffold ETH. Then we have Rick Moo talking about all the latest updates and features in Ethers JSV Six. Then Mark is going to talk about how to use use DAP and rapidly develop DApps. And then we'll have Franzi talk about sourceify and what you can do with sourceware verification and how you can do that a lot easier. Then we'll have Hari talk about all the new features in the latest version of Solidity.
00:06:06.960 - 00:06:56.924, Speaker A: Youssef is going to talk about how you can store off chain data easily and manage all of that with Web Three storage and NFT storage. Then we'll have Chris talk about Eat SDK and how you can make smart contract interactions a lot easier to debug and code. We're going to have an amazing panel discussion with Sam, Suzanne, Nikesh, Morillian and Rajiv around just security for your smart contracts. And then Daniel is going to talk about how you can decentralize front ends with tooling and home screen from the Skynet team. Patricio is going to talk about the future of Hard Hat, how it got started and where it's going, which I'm super excited about. And then we'll have Gilbert talk about how do you actually write smart contracts without Solidity. It's going to be a pretty big overview of how everything works internally on the EVM.
00:06:56.924 - 00:07:23.356, Speaker A: And then our last talk will be by Kelvin, who is going to talk about Smock showcasing everything you can do to do better testing for your code. So it's an amazing next 6 hours. So grab some coffee and something to eat and we'll quickly get started. So, without further ado, let's kick off with our first talk of the day. I want to welcome Austin, who's going to dig right into Scaffold. So Austin, welcome. Thanks for having me.
00:07:23.356 - 00:07:49.984, Speaker A: Kartik excited to do a whole day of DevTools. This is really neat. There's a lot of gigabrains you guys have amassed here together to talk about tools and Ethereum. Like you said, I will dive right in. I'm a builder on Ethereum and I work on this tool called Scaffold ETH with a great community of folks. But just to zoom out just a little bit, this is a great landing spot. Ethereum.org
00:07:49.984 - 00:08:27.372, Speaker A: is a great place to go for a big picture, learn the how and the why and if you get in here for developers, a lot of the tools that we're going to see today are here listed somewhere on this. So you can get started. And I'm going to be talking about scaffold ETH. But Scaffold ETH is just a collection of a lot of other tools like Hard Hat and Ethers. So we'll hear from them later today too. So let me jump into scaffold ETH. So scaffold ETH is a DAP template.
00:08:27.372 - 00:08:58.810, Speaker A: I found that creating my whole stack took a lot of time at every hackathon. So Scaffold ETH is a template where you have everything freestanding and working right out of the box and you can kind of tinker and learn and go from there and what I mean by that. Let's just go ahead and get it started here. So I've got my front end. Let's see. Let's Google scaffold ETH here. If you Google Scaffold ETH, it's going to drop you right into the repo here and you can follow this.
00:08:58.810 - 00:09:32.868, Speaker A: Basically you will need like Node and yarn and git. And that can take some time to set up. Make sure you get the right yarn. If you're on Linux, I go through that a lot with developers where it's just getting the environment right takes a little time. Then you'll clone down scaffold ETH yarn install and yarn chain, and yarn chain fires up hard hat. So it has a hard hat node on the back end that has a bunch of wallets for us that are loaded up with ETH. And then you'll Yarn start and that will bring up your dev server, your react server, your front end.
00:09:32.868 - 00:09:57.248, Speaker A: So we kind of have a back end and a front end. And then the last step is to yarn deploy. And what that's going to do is take this stock contract, this kind of like example contract for you and it's going to deploy it to the front end. If I bring this down, let's see, I don't even know what I'm doing here. Let's put that there. Then we get this interface. And this interface is the key piece to Scaffold ETH.
00:09:57.248 - 00:10:54.440, Speaker A: Being able to have your smart contract here and your front end here and be able to do things like let's grab this person's address and let's make an address public owner and set it equal to that and hit save. And then Yarn deploy. And you get in this iteration loop where you're testing your assumptions. You're building on your smart contract, you're learning solidity. And kind of this front end is kind of auto adapting to your changes as you write your contract and figure out kind of how that's going to work. And look, so one fun thing I like to do on a mentorship session is just set it up so maybe like the owner can edit this first so the owner can set the purpose first, right? So we're going to make sure that the what message sender has to equal, equal the owner, right? And if it's not, then we will say not the owner. Simple, solidity.
00:10:54.440 - 00:11:13.910, Speaker A: We're testing it out. We're trying it out. How do we go about testing this? Well, this leads us to how wallets work in Scaffold ETH. So if I bring up an incognito window, oh, not the luggies. If we go to local host, there we go. And not, I think it's 3000. There we go.
00:11:13.910 - 00:11:46.940, Speaker A: Got a lot of apps running here. Okay, so if you bring up an incognito window, see how we have this green account here. And then over here on my other window there's kind of like this purple account. And there's this big annoying button that helps you grab funds from the Faucet for any of these accounts kind of as they come up. But no, this is just like a burner wallet. Eventually you can connect your MetaMask or some other wallet and that's going to be there for you. But at first, just testing what you want to do is just kind of use a burner wallet and kind of just click and make these transactions quickly.
00:11:46.940 - 00:12:40.464, Speaker A: For example, if I wanted to send some funds from purple guy to green guy, I can kind of just copy this address. And then over here in the wallet, I can paste it in and I can see visually that we have the correct address and I could send $10 and notice how it's in USD, right? Like Scaffold ETH is doing a lot of stuff here with these components, so it makes a DAP just feel and work better, right? We can click back and forth between ETH, but for the user, they're like, yes, I just want to send the $10 and I just want it to go right. So notice no MetaMask prompt. We have notifications locally and that'll fill in with block native eventually when you go to a public network. But you can see that I can send money between those two wallets. So now these two wallets are interfacing with our smart contract. So if from this dude right here who is actually the owner, we can see if I say Hello World and I send that in, we get Hello World to change.
00:12:40.464 - 00:13:14.860, Speaker A: And if we do a read there, we see it and this should fail, right? I think if we did everything right, yes. Not the owner. Awesome. Okay, so it yells at us that it's not the owner. We kind of tested that line and made sure it works, but we also kind of learned how wallets work along the way, right? So let's see. The thing that I like to explain about Ethereum is that it's like this massive multiplayer game and that this is kind of centralized. What's more fun is if we think about our smart contract as like this vending machine, right, that we want to access.
00:13:14.860 - 00:13:57.432, Speaker A: And so I always do this payable example next, where instead of requiring that it's the owner, let's trigger off of the value. Let's make this thing from an Attestation smart contract into more of like a vending machine smart contract. And we make it payable, and we set the message and we double check that the message value is greater than or equal to like 0.1 Ether, right? Something like that. And we'll say not enough. And on the other side, we deploy that and we should see our smart contract load in. And now even the bad guy, if the bad guy wants to participate in our smart contract, can play along, right? This should work now, but it should cost me some money.
00:13:57.432 - 00:14:31.988, Speaker A: And let's send in just this. And here's another developer learning point. Here where you have to take this times ten to the 18, right? In my UI, I force the developer to go through that clunky process so they realize we're switching into way here as we're sending it to the smart contract. And once you do that, there we go. So it did work. And something interesting has happened here though, right? This contract now has some value, right? And what we would do is probably move on to build some kind of withdraw function or something that lets the developer pull those funds out of the contract. But I closed it up.
00:14:31.988 - 00:14:57.848, Speaker A: Let's dive into that's. Kind of like the TLDR of getting started with Scaffold ETH, right? You can pull that down from the repo. You can get in, you can start tinkering with your smart contract and your front end is going to auto reload. Let's dive in and just look a little bit more at Scaffold ETH. Kind of just look at how it's set up. So you'll have these major packages and it's hard for me to show here, but it's really small. But the packages that it comes with are Hard hat and React.
00:14:57.848 - 00:15:32.772, Speaker A: Those are the two major packages. And your React JSX is kind of like where you start to build your app. It's kind of what's displaying all this stuff. And it kind of sets up all your wallet stuff, it sets up all your providers. And then there's a bunch of handy hooks here, like Use Balance, right? You put in your provider and your address, and then you just have the balance of that address on that network kind of stored up in your state. And kind of digging in a little bit more to how we're working on Scaffold ETH. We're kind of working on kind of global context, like a single context for all the Web Three stuff.
00:15:32.772 - 00:16:15.552, Speaker A: So it's not as messy as this. So we are cleaning this up and working more and more on the repo. And to dive in that in a little bit more. I'd like to talk about ETH hooks for a second. So as we build out Scaffold ETH, we realized that there was all these hooks that we were using that were really useful and we wanted them to be their own library, basically, right? Like having them in Scaffold ETH is really handy because we can edit them live, but it's much better if we carve those out and kind of give them back to the ecosystem as a library that anybody can use in any project. And so that's ETH. Hooks So we took the hooks out of Scaffold ETH, wrote them in TypeScript, cleaned them up, put them up in their own NPM package.
00:16:15.552 - 00:17:06.212, Speaker A: And so now Scaffold ETH just brings that in. But you can use it as a dependency in your app too. And there's tons of handy hooks that you'll find when you get in and try to try to build a DAP and a Web Three app is going to just need a lot of this information, right? So just know the ETH hooks is there, and it kind of is carved out of Scaffold ETH. And we're trying to do that more and more. There's components here we'd like to carve out and then like ETH services, there's all these if you want to use Ethers to create 100 wallets and drop $5 to each one, that's a little service, right? Or even just like an SSL proxy in front of your DAP. So we'd like to have a services repo soon too, but diving in a little bit more to this front end. Things like network display, right? If I'm on the wrong network, I'd like for it to prompt me and let me have a little button, right? Your DAP needs all those things out of the box.
00:17:06.212 - 00:17:47.570, Speaker A: So that's why Scaffold ETH has that built in. So when you go to put your product out there, people get a warning about being on the wrong network, and they see their blocky previews, and there's an address input with a QR code scanner. So tons of handy hooks and components and services that we found that we needed as we built out Scaffold ETH that you, as the wonderful developer at home, can use to build your next decentralized app. So let's see. Grab funds from the faucet. So we have this nice faucet down here that kind of represents the hard hat accounts that are loaded up with cash and they can send some money out. You can even open up the wallet of that and send like a whole bunch, right? So we got our wallets there.
00:17:47.570 - 00:18:14.836, Speaker A: I want to show off this right here. So this component is the contract component. This is what's rendering this contract here. So you kind of have this solidity here. You have your contract here, then you're deploying it there. There's some hard hat config that you'll get into and you'll learn hard hat. And then over in the front end, it's kind of injecting it into this contract component, and it's doing that live every time you deploy your contract.
00:18:14.836 - 00:18:37.516, Speaker A: So it lets you really tinker with things right out of the gate. But then eventually you'll want to build an example UI, right? You'll want to set it up. So maybe let's see. Can I do that? You can hit a button and it will update that. Let's go back. So I just paid for that one, right? So I just clicked a button that went to the contract and called that function on the contract. And you can see that here in views.
00:18:37.516 - 00:19:05.480, Speaker A: If we go look at that, I just do a ton of examples, trying to show you all the different ways you could possibly do this. So here is that button right there that we just clicked, and basically it wraps it in a transaction so we get those notifications. And you can also send raw things to that transaction. But think of it more like a notifier. And then we reach out to your contract and we set the purpose. And you'll notice we throw this override in there where we send value along. And that's using ethers.
00:19:05.480 - 00:19:24.860, Speaker A: Rick Moo will talk more later, but we use that here in Scaffold ETH. So that knowledge will be transferable there. Okay, so let's see. So you've got your contract. You've got your app. You're able to tinker for a while. Then eventually, you go ahead and you build out some UI.
00:19:24.860 - 00:19:58.344, Speaker A: And then you've got, let's say, your app here. And it's kind of like ready to go, right? What's the next step to push this thing to production or to a live site? So what we'll do is we'll need to deploy this contract to a live network, right? And to do that, we can't use our Hard Hat. So I'm going to use a yarn. Or we can't use the there's, like, accounts that are loaded up with value on our Hard Hat chain. We can't have a free account that's loaded up with value on a public network. Right? So I'm going to yarn generate. Oh, I should make that bigger.
00:19:58.344 - 00:20:17.300, Speaker A: I'm going to yarn generate. And that's going to create a local mnemonic here within my Scaffold ETH directory. And then if I do Yarn account, I can see that account and see if it has any funds anywhere. Now I'm just going to go ahead and fund that on some testnet. Looks like we're already on Rinkabee. Let's go with it. So let's send this dude.
00:20:17.300 - 00:20:41.928, Speaker A: What point one? Rinkabee. Real quick. Hope this works. Let's go. All right, so now our deployer within 15 seconds should have some funds. And we should be set to do something like Yarn Deploy Network Rinkabee. And you can also get in and edit this Hard Hat file right here where your network is pointed.
00:20:41.928 - 00:21:04.544, Speaker A: But we're going to deploy with Network Rinkabee. And let's see if this goes please work. First try. This is using hard hat deploy from Wigawog. I think I'm saying his name right. It's a deploy plugin for hard hat. So a really cool ecosystem around Hard Hat there and a lot of cool plugins there.
00:21:04.544 - 00:21:36.872, Speaker A: And you'll have access to those as you build out with Scaffold, too. All right, let's get this contract deployed. Okay, so once we've got our contract deployed, we need to start talking about our front end. We've got our contract out there, and technically, our app is live. And people can talk to our app by just talking to the smart contract. But we'd like to build a front end around that, right? And so over in your app, JSX, at the top there is this little network selector, right? And what do we want to do? We want to switch our network over to Rinkavi. And if I hit save there, our app should hot reload.
00:21:36.872 - 00:21:55.244, Speaker A: And now it's pointed at Rinkavi, except for my contracts not getting deployed. Maybe I could call an audible and go to a little bit different. Oh, there we go. There it goes. There it is. Okay, so now we're out on Rinkabee, and now's the time. Like, maybe we don't want to use Burner wallets.
00:21:55.244 - 00:22:11.796, Speaker A: Maybe we want to connect in our MetaMask. And I can set the purpose to Hello World, and I can pay 0.1 ringerby. And of course, you wouldn't have your end user have to hit that little button. That's for developers. You'll build a better UI as you build it out. Man.
00:22:11.796 - 00:22:36.268, Speaker A: Should have cached those. All right, here we go. 0.1. Can I do it on rinkob? You'll notice now we get the MetaMask prompt, and I can confirm that we'll get a nice block native notify dialog down here in the bottom right? It'll track our public blockchain transaction. Right. That could have been a deployment to Mainnet if we wanted to. So it looks like it's all working.
00:22:36.268 - 00:23:07.636, Speaker A: I'm going to do a yarn build that's going to build up my local React app, and it's going to have this whole thing as a static app, and I'll be able to push that out to surge and use that app, give that app out to other folks. Now, there's a few things that you'll want to do before you go to production. There's some constants, like, inferior IDs that you'll probably want to update. Probably don't have those pointing to the stock one that will fall over really quickly in production. But that's zero to one with Scaffold. That's how you bring it up. That's how you tinker with solidity.
00:23:07.636 - 00:23:41.264, Speaker A: That's how you start learning. And once you have something, it's just a couple more commands, and you've got that as, like, a production app on a production network. So let me just dive into what you do with that tool. Basically, that tool starts you off. You have the license to learn at that point. So in the last five minutes here, I just want to cover where to go once you have the license to learn. And so the first place, of course, you'll look at your contract, you'll look at your front end, you'll work on your deploy script, but then check out the documentation.
00:23:41.264 - 00:24:17.824, Speaker A: There's really good documentation for scaffold ETH. Online video right at the top. Perfect, right? Happy bow tie Friday, by the way. So in here, you've got all the Scaffold ETH stack. It kind of explains a lot of what I'm explaining already, but does it in text form, and then it kind of gets you started with what's next. Right? So once you've got the app and everything figured out, you kind of want to go on this tour of duty is what we're calling it, where there's challenges and some other stuff. And let me just dive in.
00:24:17.824 - 00:24:48.504, Speaker A: Let's see. Okay, let's back up for a second. Make sure I cover the README sequentially. Learning Solidity. A great way to learn Solidity is just to have there's a lot of great apps out there too, but just have Solidity by example up and just go through these topics and kind of learn. And what I mean by that is like, okay, let's learn how a mapping works. Let's grab a mapping out of this mapping Smart contract example and let's paste it into our contract and let's Yarn deploy it and let's see what it looks like.
00:24:48.504 - 00:25:46.104, Speaker A: And then let's poke at it over here when we have that up. So diving into Solidity, that will get you up the Dunning Kruger, you feel like you can do anything, but then it's time to go on a tour of duty and learn kind of everything there is to learn about what works on Ethereum and what doesn't work. And all the weird gotchas right and so that kind of is here. And I have this thing that I shill called the Ethereum dev Speedrun. So if you are a Web two developer or, you know, web Two devs and they're thinking about getting into Ethereum, just tell them to go Speed run Ethereum. Hopefully when they type in Speedrun Ethereum or whatever I typed in there, they will get this Medium article that talks about what we just talked about, getting Scaffold ETH up and running, getting the syntax down, but then it jumps you into all these cool example branches. So something that has come out of having this template for building DApps is a ton of DApps and a ton of branches.
00:25:46.104 - 00:26:27.284, Speaker A: So there's 250 different branches here ranging from NFTs to different starter kits and different tutorials. There's the ZK thing there. We're seeing these lists. This composable NFT is awesome. I wish I had more time to talk about it, but getting into SVGs and NFTs and NFTs that go in NFTs and render their parents, that render the children it's really cool how it all hierarchically, renders an NFT all on chain in Solidity. But that's a whole different that's the side quest. As you get Scaffold ETH down, you can go to any of these branches and all the Smart contracts, all the front end, everything is going to be kind of the same language.
00:26:27.284 - 00:27:10.550, Speaker A: Everything's going to be kind of in the same place. So once you know one good branch of Scaffold ETH, you kind of know where everything is on all of them and you know how the wallets work and you know how to interface with a Smart Contract and you know kind of like what that context looks like. Okay, so from these branches, though, the Speed run, once you have the syntax, once you're ready to get in, I recommend doing the simple NFT example. And the simple NFT example I think I have right here will take you through the same setup we just went through. But then you'll edit this Mint script and let's see, what do I have a couple of minutes. Let's just go look at this localhost 3001. You'll do the same thing where you probably want to create.
00:27:10.550 - 00:27:39.120, Speaker A: Let's see, a yarn deploy. I have a yarn chain and a yarn deploy. Let's see if I can get it to work. Everything's in the same place, right? Guess what? Here's your smart contract right in that folder instead of your contract, it's called your collectible. And it's this super simple NFT example straight from OpenSea. And you can get in here and deploy that. And once you deploy it, you have a mint script and it says, grab your front end ID and paste it in here.
00:27:39.120 - 00:27:51.700, Speaker A: And when you run yarn mint, hopefully those NFTs show up here. There we go. Let's see if we can get an NFT to show up. All right. And then I'm going to grab whoops. I'm going to grab this address. There they are.
00:27:51.700 - 00:28:06.516, Speaker A: And I'm going to paste it in here. And I'm going to grab this dude's address and I'm going to send him this buffalo. Let's make sure that I don't have any gas. Got to go to the faucet first. There we go. Now send him this buffalo. Oh, I still don't have any gas.
00:28:06.516 - 00:28:27.120, Speaker A: What did I do wrong there? Oh, I sent that guy gas. That's funny. Now send him the buffalo. No, don't use my camera. Send him the buffalo. Isn't that nice that you have a QR code scanner, though, right, on all your address, right? Cool. So the simple NFT example is your first step to kind of get context and move on to how all these different branches work.
00:28:27.120 - 00:28:55.092, Speaker A: Then start taking on some challenges. Take on challenge one. You're going to be building a staking app where you have to get a bunch of jerks to coordinate. And if anything breaks down there, then they can all withdraw. You don't want jerks to be able to grief each other. But if they all do coordinate, then money moves on to another contract and your staking round kind of state machine moves on. Then challenge two is about a token vendor and building a contract.
00:28:55.092 - 00:29:24.944, Speaker A: You'll learn contract to contract. You'll learn, like, contracts, talking to contracts. You'll learn ERC, 20. You'll learn the approved pattern if you sell your tokens back. And then the third challenge is a little bit more open ended. Build the decks. And it's actually pretty easy using this article, but build a very MVP decentralized exchange and learn about reserves and then kind of move on to take the buyer mints and start branching out, right? Take some of these branches and take them to the next step or learn the thing that you want to learn next.
00:29:24.944 - 00:29:49.316, Speaker A: And there's a whole kind of like, funding mechanism with Build Guild where I'm funding developers that are building these tutorials. So there's kind of funding available for folks that are kind of building on top of this. Let's see if we can get right. Back to our app real quick and see if I do a yarn surge here. I think our app is built and ready to go. And what domain? It's like a rink purpose. So I'm just going to say our purpose.
00:29:49.316 - 00:30:12.524, Speaker A: P-U-R-P-O-S-E. Let's see if I can upload this DAP, go from kind of zero to one and have the DAP fully deployed. It will be at surge. Sh. No one like, front run me and get something on screen or anything. I think I'm open for questions now. We've got the app deployed.
00:30:12.524 - 00:30:23.684, Speaker A: Reach out to me. I'm Austin Griffith on Twitter. And hey, hey. This is our purpose, and I'm paying oh, I don't have a rinkabee. I need to connect. Here we go. Here we go.
00:30:23.684 - 00:30:56.584, Speaker A: Connect my app in and say hey and actually pay some rinkabee. Let's see if this works. Yes. There we go. So I went from zero to one. I took an app idea, brought up Scaffold ETH, built the contract out, deployed the contract. Then I deployed an app that talks to that contract out to a public network where anybody could go to that URL right now, and it'll probably fall over pretty quickly, but you can use that to interface with the smart contract.
00:30:56.584 - 00:31:14.544, Speaker A: And there we go. It's hey, hey. And so, yeah, again, check out the ethereum dev speed run. It'll take you through Scaffold ETH at first, but then it will move you. I've been missing the chat. I was supposed to be watching the looks like it looks like we're good, actually. You'll follow through a bunch of these branches.
00:31:14.544 - 00:31:40.536, Speaker A: A lot of these gotchas random numbers on chain and how DeFi and swapping and lending works and how signed messages work. There's lots of little gotchas that you'll learn. Build a multi SIG wallet and learn how that works. Good luck, everybody. Happy Bowtie Friday, Kartik. Thanks for having me. Any closing questions or anything I need to do on this? Think there we mean a lot of amazing comments from the chat.
00:31:40.536 - 00:32:21.300, Speaker A: I think the easiest thing would be maybe you can just log in on Eastcobble TV and answer some of those quick questions. Mostly It's people requesting you should have your own live stream. 24/7 call. Austin, you can just always showcase Scaffold ETH. One question I'll ask you is what's kind of getting you excited about things that you want to add to Scaffold ETH in the future? What are some of the things that matter? What's so cool about it is it's random things all the time? Right now, the thing that I'm most excited about is this SVG NFT library in Scaffold Beach. So there's DeFi and there's governance and there's coordination tools. There's all these different branches.
00:32:21.300 - 00:32:48.310, Speaker A: But really the one that I'm most excited about is, like, what I made lugie's with, which was just like a little SVG NFT. But it's like you get into the smart contract and you see, like, this is the building. It's crafting the JSON in the solidity and then it's crafting the SVG in the solidity. And we're doing something where you can send the NFT to another NFT. And then when it renders itself, it calls the render function of all the other ones. So then you see all the little NFTs inside of there, like moving around. Super fun stuff.
00:32:48.310 - 00:33:03.450, Speaker A: I don't know why that gets me so excited, but I am super excited for SVG NFTs. Awesome. Well, thank you for actually standardizing that then. In that case, cool. Someone else did it. I just made it easier to fork. That's what I'm here for.
00:33:03.450 - 00:33:22.824, Speaker A: Thank you, Karthik. Thanks, Austin. We are ready to move on to our next talk. So next up we have Rick Moo. And Rick's going to be talking about Ethers v six. So without further ado, I'd like to welcome hey, can you hear me? Yes, we can. Excellent.
00:33:22.824 - 00:33:42.150, Speaker A: Excellent. So I should just jump in then? Yes, sir. Excellent. So let me figure out how to go back to sharing screen. So, as some full disclosure, I kind of got confused as to what talk I was giving today and so I prepared the wrong one. So I spent the last hour throwing this together. So there might be typos and such.
00:33:42.150 - 00:34:01.320, Speaker A: Can you see this? Yep. Excellent. Excellent route. And do it live it's what, sorry? We'll do it live with the Bill O'Reilly route. Yes, exactly. So this has not been fully thought through, but here's my best thing. So I think probably a lot of people are familiar with Ethers.
00:34:01.320 - 00:34:37.892, Speaker A: So I just wanted to give a quick overview what V Six is going to be about. Right now, V Six only lives on my desktop as a local repository, but I'm hoping within the next two weeks to get a public beta out so people can start using it. I'm also hoping there's lots of questions that people have because I don't think this is going to take up the full half hour, but we will see. Also, awesome talk, Austin. It felt like the movies where the counter is counting down and you're trying to get this contract deployed in the last it's counting down 5432 and then you're done. You saved it. You got just in the neck of time.
00:34:37.892 - 00:35:12.770, Speaker A: So, anyways, back to ether's. V six. So one of the big things with Ether's V Six is it's ESM first. So there's no longer going to be any Es Three support. So if you're running Node Eight or Node Ten or you're using an Ie era browser, things probably will not work out well with V Six. I plan to keep V Five running for a little bit for people who really need kind of those old platform supports. But there's also some things I'm changing in V Six that'll make it easier to maybe use babel to get those Es Three like things working.
00:35:12.770 - 00:36:06.860, Speaker A: So also because everything's ESM, the build process is far more simple for those that aren't familiar, the build process for V five, because it builds es three and it builds ESM modules and also because TypeScript does not support multiple targets in that way. During the build process for composite packages, during the build process, it has to rewrite all the TS config files everywhere, all over disk, and then recompile it. This just leads to a really complicated build process, so this makes things much easier. Also, ESM has much better tool support. Like I said, between Babel and all the different bundlers, things just work. Also all the dependencies are ESM, which really helps the bundlers because the bundlers usually choke the second they hit elliptic or they hit BNJS or hash JS. These like traditional JavaScript libraries.
00:36:06.860 - 00:37:10.936, Speaker A: So basically, in a nutshell, ESM first is like a key part of V Six, and part of that is because now we can use modern Es features. For example, we can't even use Map or Weak Map or any of those really, especially Proxies, those really cool features that JavaScript has introduced in the last five or six years, just because V Five tried to stay compatible with a very large audience. So proxies are very cool. For those unfamiliar with Proxies, they're basically a JavaScript object that can trap when you're trying to do stuff with them. I've got a better slide next that kind of demonstrates that private members, a lot of the things in V Five, they were private just by virtue that they had an underscore in front of them. The problem with this is people kind of tinker with and break things they don't even realize they're breaking by interacting with these private members, especially other frameworks. I've definitely seen frameworks who are tinkering with private members, and then I get an issue because Ethers isn't working looking for them, but it's because it's been broken somewhere else along the way.
00:37:10.936 - 00:37:53.024, Speaker A: Again, much better bundler support. This is an important thing, I think, for most people. At the end of the day, everyone wants to make a react native app which needs Bundling, or as Austin was just showing with Scaffolding, you want this one thing all bundled up into one little concise package that can sit out on the web and be served from some CDN and your app should just work. Big int 20. Es 2020. Big Int is kind of like it's a weird point for me because on the one side, it's really recent. Es 2020 if you have a browser that's made in September 29 or even if you have a React native app that was made in September 29 of 2020, it's going to fail to work with this version of the library.
00:37:53.024 - 00:38:47.750, Speaker A: So for Es 2020 Big INTs, there's also an additional disk file which has got the Big Int stuff swapped out for the traditional big number libraries. So internally it'll be a bit slower, but it'll still work on older platforms. Backwards compatibility for those who don't know me is very important. I maintain a lot of really old projects, and it sucks when there's literally no paths forward to keep them alive, because I can't update this version of that thing without breaking this and vice versa. So, next slide contract proxies. So this is really where the proxies are going to shine. So right now if you use Ethers for a contract, if you've got a function called foo, if you've got multiple functions called foo, or in this case adder, it's hard for the system to know which one you mean.
00:38:47.750 - 00:39:36.752, Speaker A: If you have one that takes in an adder and a UN 256, and one that takes in an adder and a UN 128, there's literally no way that it can tell which one you actually intended, which is why you then have to specify the actual signature, which gets complicated. This might be too much detail for some people, I'm not sure, but those who've suffered this, they are very vocal about suffering this, and so they'll be the ones who appreciate this the most. And I'm hoping people going forward will appreciate this without realizing that they're appreciating it. But basically you can force a type. So in this case, we see that you've got a typed UN two six. You're casting this. So if there is for example, if there was a function called adder that took in an address, and a UN 256, and an adder and a UN 128, this is now non ambiguous.
00:39:36.752 - 00:40:29.304, Speaker A: The system now knows exactly which one you meant because that chain ID is enforced into a UN 256. The other big advantage of the proxies, though, is if you see the next three examples, they're all referring to the exact same method. This address that takes an address in U into 256, well, it will normalize them before you even get to the point. So the proxy actually gets this string and gets a chance to normalize it into a string to do a lookup in its own lookup table. So it doesn't matter how you specify this method, it'll be able to find the one you want, whether you have extra things in there, like the names or not the names, whether it's a view, public, all those extra stuff, it just throws it away. So that's the biggest advantage of having proxies is at runtime. I can decide what you probably meant now.
00:40:29.304 - 00:41:32.440, Speaker A: Ethers will still never guess if it's at all ambiguous, then you're going to get an error. The problem with EV five, though, is you start getting all these warnings in the console logs just by loading this abi. This at runtime can tell you you're wrong, go to jail, do not pass go, that sort of thing. So TypeScript, when I wrote V five, it was very much based on V four, and I had never used TypeScript before. And so as a result, there was a lot of decisions that were made that were I mean at the time TypeScript was still very young but there was a lot of decisions I made based on JavaScript developers. JavaScript is still very important. The nice thing is modern TypeScript takes into account a lot of things for JavaScript developers that it did not back then so it's been redesigned a lot with TypeScript as a first class citizen.
00:41:32.440 - 00:42:23.310, Speaker A: So TypeScript is like a fundamental part of the library now, not just kind of useful for people who use TypeScript. So all dependencies are fully typed TypeScript. There's no more weird little libraries lying around that have types that were made by hand and therefore maybe not quite right. It also again goes back to the bundler thing because all the dependencies are TypeScript and all the dependencies are ECMAScript. They kind of cohesively work together better without weird Foibles. There's also a lot more templating in V six and I'll give some examples of that next but even with the templating I don't think there's many places where you have to explicitly specify the templating. It will fall back onto meaningful defaults for you.
00:42:23.310 - 00:42:55.030, Speaker A: Strict error checking is in now, which is something I know a lot of people wanted in V five. Anything that returns something can always return something, or null. And this means that you miss out on a lot of type checking, because if you're not doing null checks, then you might get a null object back and you won't get any compile time error for that. And there's better separation between concrete classes and abstract interfaces there's. Moving around. More on that in a few slides, I think. Again, the slide deck is really new in my head.
00:42:55.030 - 00:43:36.592, Speaker A: Oh, those came first. Excellent. So concrete classes so I've moved some interfaces to concrete classes so interfaces are kind of good for things that you want the flexibility of just what they should look like whereas classes are nice because you can actually do things to them. So one of the big changes is networks. Networks are now an actual class there's actually another slide even later on about networks, so I'll go more into it then but it means that they can do much more things at Runtime based on the parameters you gave them. The other big one is transactions transactions for serializing and parsing. They've always been a hassle because people do weird things.
00:43:36.592 - 00:44:23.968, Speaker A: People specify a V as well as an Y parameter or they specify a Vs as well as an S. Like there's all these things that I had to check and make sure they all worked together. So now that transactions are a proper object, it's much easier to set all the things on it, especially these days with EIP 29, 30, EIP 20, 718, EIP 1559. We have all these weird things that go on with transactions, so this just helps bring them all together and much easier to either parse or serialize or pass them around. A transaction object is now a valid object, for example, to pass into a signer if you wanted to send it. And transaction responses, for example, inherit from transaction. So it's just like all those that's actually a slide I should have made.
00:44:23.968 - 00:45:05.308, Speaker A: I'll make a mental note of that. So basically the inheritance model makes more sense because you've got transaction requests, transaction responses, transaction objects, parse transactions, all these different types of things. Now that there's a proper hierarchy to how they all interact with each other, you can pass one thing in from one thing into another thing that should accept that thing. In V five right now, it does a lot of checking to make sure you're not shooting yourself in the foot, but sometimes that shooting yourself in the foot is almost desired. So this makes sure that when you shoot yourself in the foot, you're shooting yourself in the foot safely, if that makes sense. Also, there's a much more flexible Web API. It provides pre flight checks and advanced retry logic.
00:45:05.308 - 00:45:44.984, Speaker A: This is useful. AWS has added a lot of functionality for blockchain type things, but the way they interact with authenticated requests means that there's a lot of things that are very hard to do right now. So the new Web API I'm looking forward to sharing, I use it actually in other non ethereum, ethers based projects. So that's a bit on concrete classes. So abstract interfaces, I also moved to the other direction. Some things that used to be classes are now interfaces. So the signer and the provider used to be classes that you had to inherit, which meant if you want to do really custom things, you sometimes couldn't because you had to inherit from provider, you had to inherit from signer.
00:45:44.984 - 00:46:36.780, Speaker A: And now you're stuck because you might want to subclass something else that's more interesting, or you might not want to implement a thing that's in those abstract classes but that it needed that you don't want. Yeah, another big thing a lot of people ask for, so I'm just blowing through these, I'm hoping for questions to help clarify anything people. So please write down questions and bug Kartik for things that come up. I think he'll pass those along to me. So addressable, this is something that I know people really are frustrated with. There's weird errors because right now, if there's a function call for a contract or there's a method on a provider that takes in an address, it accepts addresses and accepts ENS names. A lot of people have bugs where they pass in a signer instead, and a signer is 100% reconcilable as an address.
00:46:36.780 - 00:47:21.944, Speaker A: It's just v five doesn't do that. So in V six you can pass in signers or accounts or anything that's meaningfully an address into something that expects an address. And so there's this whole address type that things can implement to ensure that the system knows that they're inadcessible and that they'll just work the new freezable API. So this is another thing that Ethers has always done and it's been a huge point of annoyance for a lot of people. Everything in ethers is immutable. This is really important for an asynchronous environment because you don't want to pass something into the provider, have it preparing to do something with it, and then you and another part of code start mutating that object. And now maybe the provider receives half of the mutated states and half the non mutated states.
00:47:21.944 - 00:47:57.300, Speaker A: So everything in Ethers has historically been immutable. So with the new freezable API, you can pass in immutable or immutable object. The first thing it's going to do is create an immutable copy of it internal to the provider. So you can go off and now do weird things to the thing you have and be assured it's not affecting anything else. There's also a lot of places in Ethers where it passes you an immutable copy. For example, a transaction. For example, you might hit a provider, ask for a transaction, want to change some things on that transaction and then send that transaction, maybe just update the nonce or something.
00:47:57.300 - 00:48:44.900, Speaker A: Well, you can't do that as it stands right now because those things are all coming back as immutable. So with this you would get back an immutable copy. But there's always on the freezable API you can do a clone get immutable copy which allows you to modify the things you want to pass. So it kind of like helps keep things safe by the things that need to be immutable or should be immutable are still. But when you need Immutable copy for doing something useful, you can the Air interface. I'll actually go into more as well in another slide, but it provides a type safety for the property access because Ethers provides a very complex I don't know if complex, right word a very useful but not the way that most people are used to handling with errors and yeah, I'll get to that in a second. Anyways.
00:48:44.900 - 00:49:04.164, Speaker A: Oh, actually, I'll get to it next Printly. So errors. So here's a great example. So if you have a modern TypeScript thing, errors come back as unknown. You don't know what the error is. So this actually uses a conditional type in TypeScript. So it knows that the transaction replaced is an enum.
00:49:04.164 - 00:49:34.256, Speaker A: And so once you're inside this is Air. I don't know if you can see my cursor, I'm wiggling over top of the Air replacement. Once you're inside this block for is Air. The typing system is now fully aware that the error object is of type, which is an interface, is the interface of a transaction replaced error. Sorry, I'm talking fast. Okay. So yes, once you're inside this block, it knows that's the type so it knows what properties exist.
00:49:34.256 - 00:50:26.852, Speaker A: It also knows what types of properties are. And so it also means that everywhere in the code that throws a transaction replaced error, it must provide all the properties associated with that. So it kind of helps on the coding side to make sure I'm not missing a property that you really want to exist, and to make sure that when you want to use a property that you can have the type checking in place to verify that property is the right thing. Don't know how much more I think I'm almost done this was talking about before. One of the biggest issues Ethers has right now issues, but requests I have from Ethers is people start having these weird chains. They have chains that no one's ever heard of, or they're chains that I've never heard of, at the very least, because I don't really follow a lot of these, like fringe or even some of the common ones chains. So the network now bundles a lot more stuff into it.
00:50:26.852 - 00:51:30.584, Speaker A: But as a result, the network is often enough to specify a chain. That's weird in a strange way. If it has a different address format, if it hashes things differently, if it needs to talk to L1s to do something, the network object is now more cohesive, more flexible. You can do a lot of those things. So, for example, right now for BSc and for Polygon and for Arbitrum, I don't know how to pronounce that one, but for those types of chains, they actually sometimes require a whole different package, which provides a new JSON RPC provider and therefore new static JSON RPC provider and a new Ether scan provider. All these extra things just because they changed something that's kind of fundamental to Ethereum, but for their chains, it made sense. So with the network object being pulled out, it means that you can now have just a BSc based network and things will just work.
00:51:30.584 - 00:51:57.752, Speaker A: The world's a happy place. All that extra work that needs to be done is done inside the network object instead of inside the provider. On that note, the plugins. The plugins are kind of part of that as well. It means that a network can use a plugin to describe a more complex behavior. One of the biggest issues with L2 S right now is that the ENS support is not obvious for how it should work. ENS on an L2 is somewhat complicated.
00:51:57.752 - 00:52:27.004, Speaker A: So with the new network object, we're now able to fully support L2 S. With ENS, basically they need an L One connection, but all that happens internal to the network and the provider object. So you can just start using ENS names on Polygon, for example, and also Durin. I'm not sure if people familiar with Durin. It's an awesome way for L two S to interact with anything. It basically means anything can become an L2. It's really awesome.
00:52:27.004 - 00:53:07.512, Speaker A: If you don't know about it, check it out. But there's built in support for it. One of the big advantages of using plugins is we can in a very backwards compatible way, add support or remove support for things like durin. So durin right now will be by default off, but we'll have a plugin that will turn it on in the future, we have it by default on and have a plugin that turns it off. Yeah, lots of awesome. Ah, excellent, I'm done. So I guess I will open up the floor to questions if anyone has anything to sorry, I blew through everything really fast, but I'm hoping to fill in the time with questions or the things I blew through too quickly or did not describe enough words to like, yes, it's a good rate, we're good here.
00:53:07.512 - 00:53:52.856, Speaker A: All right, so a few questions, few comments, and a lot of amazing comments. First of all, everybody's excited about TypeScript support, so that's great. That's not a question, that's just a lot of happiness. Obvious question, what is the timeline of the release? How are you thinking about that? And when can people try this out? Right, so I'm hoping for a public beta in maybe two, maybe three weeks. I have a minor bump I need to get out this week. I'm hoping that's going to be the last minor bump of V five. So hopefully in three weeks time, and maybe even earlier, I might not have a version up on NPM, but earlier I am hoping to even maybe have a GitHub repo up so people can kind of see the differences and if they're really ambitious, try it out from that without NPM support.
00:53:52.856 - 00:54:30.080, Speaker A: But it'll be on NPM hopefully within, I'm hoping two to three weeks. But this is Ethereum, so two weeks TM, give or take a month. This is great. Okay, so another kind of question and a theme is talking about you sort of touched on this, but talking about multiple networks, is the fallback provider the best approach still, or how do you think about supporting multiple networks more appropriately? And you kind of talked about some of them like optimism or arbitrary and a handful of those. Absolutely. So you should always still use the fallback provider if you have that opportunity. One of the cool things I'm doing with that is plugins.
00:54:30.080 - 00:55:21.940, Speaker A: So there's ancillary packages So, for example, if you pull in the ancillary package for polygon or for BSc, one of the things it can now do is that new package that you have that somebody else can even maintain, not Richard, someone else can maintain that package. It can actually call into the default provider and register itself as A. So basically you would include Ethers, then you would include the BSc package. But then when you do Ethers get default provider BSc. It's actually going to be the BSc package that's responding to that and populating the object as you need. That, for example, will automatically handle deciding how to connect to L1s so that you get ENS support. It'll figure out whether the network supports EIP 1559 or all those extra little things it needs to do.
00:55:21.940 - 00:55:57.804, Speaker A: So weird networks can do the weird things they need. And I don't use weird as a negative connotation. I use weird as in different it's behaving not as Ethereum does specifically, but it's ethereum enough to work. Yes. Cool. Another kind of question, which is we can kind of go as deep as you'd like here. What are some kind of extensions that you personally wish existed that still don't? And sort of like how does the V Six architecture sort of help enable some of those things from your own personal wish list in terms of extensions? I'm not quite sure what that means.
00:55:57.804 - 00:56:32.340, Speaker A: I'm going to guess maybe like ancillary packages. That's one of the things I'm focusing on in V five a lot is making more ancillary packages and I'm trying to move a lot of the things. So there's actually a lot of packages in V six that will not exist, that exist in V five. I'm merging some packages, but for example, Hardware Wallets is being moved out into its own Ancillary package. So the advantage of this is it makes the turnaround time faster because I don't want people mucking around with the core. The core is still something I want to make sure is secure and concise and adheres to all the things I want to adhere to. But the Ancillary packages are a little bit more open ended.
00:56:32.340 - 00:57:17.108, Speaker A: And so for example, what I'm hoping to at some point is to just give ledger the ability to have contributor rights to the Insurrection package for Hardware Waltz so that when they make an update, they can go in and make that change. It'd be nice if Trezor can also go in and make these changes as well. There's still going to be a gatekeeping thing. I still control publishing things to NPM, but I can at least let other people manage that sort of thing. So it's the same thing as well for other extensions, for maybe like diamonds. Maybe somebody wants a diamond API. I don't necessarily need that built right into Ethers, but if there's ancillary package for diamonds, the author of that EIP, I could even give him or her, I'm not sure, permission to modify or update that as necessary.
00:57:17.108 - 00:58:00.660, Speaker A: So that's part of V five ish but with V six I'm making a much stronger push towards moving more things out of the core and into ancillary packages. Awesome. Another question is around how you think Ethers will evolve to support more cutting edge stuff like building or testing or interacting with zero knowledge applications or just circuits. Do you kind of see that that's Ethersjs's role or what should somebody think about in this case? It would depend a lot, actually. I've not thought of it before, but I think it would make sense. So for example, there should be probably some sort of ZK you can imagine ZK sync could. Have like a ZK sync provider and again, this would be an ancillary package.
00:58:00.660 - 00:58:42.736, Speaker A: Anything that they need kind of bundled inside, I would totally be willing to add to Ethers. But a lot of that stuff can just be added kind of like as an extension library. If you don't need ZK snarks inside Ethers, I'd rather not have it directly in Ethers. But if there starts becoming a thing where all networks start using ZK roll ups for the specific thing, then it totally makes sense to put in there and possibly even wrap into a plugin for networks. And oh, that's another thing I forgot to mention as well. A big chunk of the redesigning for V Six is breaking things into a ridiculous number of files. So in V Five, everything was one file inside each package.
00:58:42.736 - 00:58:50.840, Speaker A: The problem is bundlers, and specifically tree shaking fail. Tragically, when you have one file.
00:58:53.340 - 00:58:53.608, Speaker B: It.
00:58:53.614 - 00:59:36.340, Speaker A: Has to be so pessimistic as to what is going to be possibly called that it includes stuff that is remotely completely impossible to be involved. So the nice thing is most tree shaking systems, they understand file boundaries. So if something requires something from their file, it's completely out of scope of what's going to be necessary. And so it drops. It going back to what we were talking about a second ago. It's actually possible, because of this splitting of files, to include ZK snark stuff in Ethers and because it'd be in its own file separate from everything else. If you're not including something that includes something that includes something that includes this, it'll automatically get ripped out by most bundlers.
00:59:36.340 - 01:00:10.610, Speaker A: Exactly. And I think in that world, even if something is part of the core Ethers library and not being used, you can still kind of make the argument that ZKS could be actually part of the core. That's one more quick point as well is the size of this library should be much smaller. I'm using Noble's sexy two, five six and a different big number library. And because of Es 2020 INTs, it's going to chop like a ridiculous amount of I feel like between ten and 20% of the size is going to get knocked off by this one library change. Amazing. Two more questions before we close off today.
01:00:10.610 - 01:00:54.472, Speaker A: How can people kind of contribute to the project? Do you need any help with certain things? What's kind of the process or things that you prioritize? Right, so this is one of the biggest reasons why I want to move to ancillary packages because everyone wants to help. I love the idea of people helping, but reviewing code is hard. And the other thing is any code people want little features added and once you add a feature, you may spend three days making the feature. But now I'm supporting it for life. So I'm looking forward to more ancillary packages so that I can actually just kind of give some of the ownership up if you really want this feature, then you can add it. It's kind of hard right now for me to kind of give pieces off to people to work on. Documentation is always appreciated.
01:00:54.472 - 01:01:22.088, Speaker A: I love it when people contribute to the documentation. I love tutorials, and once ancillary packages are more of a thing, I'm looking forward to having more people be able to just take that and run with it. So that will be coming soon. Again, TM and final question, which has been asked a couple of times, can you share the slides with our audience? So if you can, just send that link to me and I'll be able to send it to everybody in the chat. So whenever that absolutely. Yep, I'll send those out. Perfect.
01:01:22.088 - 01:01:38.060, Speaker A: Thank you so much, Rick. Awesome. Thanks, Kartik. Take care. All right, with that, we are ready for our next talk. So our next speaker is Marik. I want to invite him on stage to talk about used app, and I'll let him intro himself and talk about this amazing project.
01:01:38.060 - 01:01:49.392, Speaker A: So without further ado, welcome. Hey, Karik. Great to be here. Great to see you. Great to be here on this event and talking to you guys. One click disclaimer. I'm in a hotel in a public space.
01:01:49.392 - 01:02:26.796, Speaker A: That's the only place where there is a working WiFi. So there might be some distractions, but let's hope for the best. So today we're talking about used app. It's a framework for rapid development of DApps. And when I say DApps, I really mean the web component, the web part of it. We're not going to talk about smart contracts today, so it's going to greatly connect to the previous presentation of Richard that some of you might just seen on Etrschjs. So why doing a framework might be a question that many of you might be asking yourself.
01:02:26.796 - 01:02:56.944, Speaker A: And what could be possibly difficult about building front ends for JS? Right? It's a simple web application. It's a simple react application. Well, it turns out it's kind of hard, and we would know. We kind of tried it all. We tried React, we tried React with Redux, we tried Arxjs, we tried domain driven design. We tried everything for our last four years or so. We looked at what different people are doing, and we really didn't find an easy way to build T apps.
01:02:56.944 - 01:03:39.856, Speaker A: And I think there is no, like, any fundamental problem, not any major problem that makes it difficult. It just is little, small, little problems everywhere that makes it difficult. And I give you a few examples. My seven top picks. Right? So first of all, if you go to an application and obviously we want to make a good user experience, we want to build great UX for our applications, for our users. So, first of all, when the user goes to the app for the first time, they want to be able to browse the app without connecting. They want to be in this read only mode before they connect their MetaMask, before they connect their wallet of choice, right? So the app should support this read only mode.
01:03:39.856 - 01:04:29.604, Speaker A: And the other thing is, and that's not very hard, you just make a couple of leaves, make sure to connect to read only provider. Easy peasy, right? But now the problem is you always want to show the most recent state of the application every 15 seconds or so, depending on the network. Might be different times, but new block might arise. And when the new block arrives, some of the states might change. Some of the values that you display in your application might be different and you never know which one. It might have nothing to do with what user was doing. So what a lot of application developers do is they keep querying every time, every time, every few seconds they keep querying and see what is the status of this value over here, what is the status of this value over there.
01:04:29.604 - 01:05:14.604, Speaker A: Now that makes a lot of requests. Which brings us to the next problem, which is how do we keep amount of requests small? So that well, first of all, our infuriawalkemi bill is not that high. But second, that the UI is responsive and the user can see the kind side and there is no hundreds of requests in the background that one is waiting for the other. And then since we're talking about refreshing, there's a whole thing when we're switching wallets, right? So when we switch from one wallet to another, let's say I go to uniswap, I want to exchange from one currency to another. I set up the whole thing. I want to exchange A to B and this is the exchange rate. It all looks good, but I'm connected with the wrong wallet.
01:05:14.604 - 01:05:58.800, Speaker A: So I want to switch the wallet. I don't want to see the whole application reloading, right? And actually if you go to documentation of Ethereum, they say if you change the wallet or you change the network, you should refresh the whole application because it's so complex to figure out what needs to be refreshed on more not on the more, not with used up. Use up is handling that for you, as you're going to see. So switching wallet, switching networks is becoming a thing now because now we have more and more often we work with applications that have multiple net that support multiple networks. You're on layer one, you're on L2. You keep switching depending what you want to do. All kind of bridges are being built all the time.
01:05:58.800 - 01:06:27.064, Speaker A: It's not anything extraordinary anymore, anything weird, anything fringe, as Richard would say. And then there is the whole tracking of transactions. And I know it seems simple like you look for the transaction if it's pending, if it's successive, it fails. But then transactions tend to be slow. Users switch context. User wants to understand what happens. The transaction failed he's already on the other screen.
01:06:27.064 - 01:07:52.416, Speaker A: Maybe it was replaced, maybe something else happened. Right? So we want to give user support to give him information about the history or the notifications of the transaction, right? History, what was done, notification, what just happened and that's why we created Used Up. We created Used Up just earlier this year, I think it was March when we released kind of the first version and it's already used by close to 500 applications, I believe. So use that as a framework for rapid app development and it's built for Ethereum. But really any EVM compatible blockchain should be able to handle to you should be able to use that framework with any EVM based network and we didn't want to reinvent the wheel. So it's built on react, it builds on eaters that you might just seen Richard presentation that was just before mine. It's built on top of web3 react which was developed by guys in uniswap and became kind of standard thing for managing the connection state and for testing it uses Waffle which is popular framework which we also have developed for smart contract testing.
01:07:52.416 - 01:08:30.850, Speaker A: Now it's extended, you can use it for testing your UI as well. So without further ado, what are the features? We really have three major features connection management, reading, blockchain state and transactions. And we really don't want to make it much more than that. We just want to do those three things and do them really well. There will be some plugins, there are already some plugins. So there are other things that you can do with Used Up. But this is really the core stuff that we want to support, that we already supporting and that we think it should be done really well because that's what the apps are all about.
01:08:30.850 - 01:09:24.528, Speaker A: So what connection is doing? First of all, you have read only support out of the box. You have support for network switching and coming soon we want to be able you can now support multiple networks but we want to be able to support multiple networks in parallel so that you can display content from many networks easily. So here's an example code. This is really all the configuration you need to do. You need to specify very simple configuration object which tells you what's your default network in this case it's Ethereum, Mainet. What is going to be your address, your infuria Alchemy or whatever provider you want to use for your Ethereum, JSON RPC for your access to Ethereum. And then you wrap your application with the app provider and give the config as an argument and that's it, it's done.
01:09:24.528 - 01:09:49.396, Speaker A: Your application is ready. You can start developing your application without any further ado. And here is an example application. What it does, it allows you to connect to Ethereum and it shows your balance. So you connect with your MetaMask or your favorite wallet. There is a new hook. So Ethers is all about idiomatic react hooks.
01:09:49.396 - 01:10:54.190, Speaker A: So everything you do is a hook and it comes with all those great goodies that react hook comes with which is like you don't need to think about refresh, you don't need to think about state. It just gives you stuff and you can just use it. And in this case we're using Views features so again shout out to Richard and it gives you two things. One is account which is your current account can be null if the account is not connected and activate browser wallet which is a function then you can call to trigger connection to MetaMask. Then we ask for balance use ITER balance which is again hook which have one argument, give me the account you want balance for and the account in this case is just the account that we're connecting with. Again ITER balance might return null because we might be not connected or the balance was not yet retrieved. And then we have a simple piece of interface, the button to connect and we're just displaying eater balance and we format it with format eater which is again Ethers JS function.
01:10:54.190 - 01:11:16.068, Speaker A: So here's how it looks like. Here's a connect button. We click connect and boom, off we go. We can switch the accounts, we can switch the networks and everything working, everything is refreshing. This is like all done under the hood. You don't need to know anything about it. And if you see this example application you can see there is actually more than just the account.
01:11:16.068 - 01:12:03.296, Speaker A: There is more than just ITER balance. There's also the account and the value on Ether Staking contracts on Ether two Staking contracts. So here is the full code for the application without HTML and CSS. But this is basically the whole code except for the configuration, except for HTML and CSS that you need to have. So again we use use ITER balance in this case for Staking contract which is just a constant that contains the address of the Staking contract. We use account from use editors and we use user balance from well we just grab it from the hook and the hooks. Again they're going to take care of all the refreshment, whether it's different wallet, different network, whether we're not connected, whether we read only mode, whether we're not in the read only mode.
01:12:03.296 - 01:12:21.472, Speaker A: So that was pretty easy I hope. Let's see. Again pretty easy. We have this little notification at the bottom. I'm going to explain what it is a little bit later. Everything just works. Boom.
01:12:21.472 - 01:13:15.224, Speaker A: So that was just to show you connecting and very basic reading from the blockchain. Now we're going to dig deeper into other functions for reading from the blockchain. What is reading from the blockchain give you more than just eaters? Well, it gives you auto refresh on your block, it gives you auto refresh on wallet change. And here is a new thing combine multiple calls into a single multicol so everything that you see on the screen is aggregated into one collection and every few seconds there is a single call asking to your node, hey, is there a new block? No new block, nothing to do. Is there a new block? Oh, no, new block, nothing to do. Is there a new block? But there is a new block. And everything that is visible on the screen and nothing more going to be combined into a single multiple.
01:13:15.224 - 01:13:45.904, Speaker A: And a single request is going to retrieve all the data, get it back and distribute the data across the application, across the visible user interface. And it's all done by books, so you don't need to know anything about it. It just works. Right, so we've seen this example, I think we've seen this one example. Yeah. So here we're going to send money from one account to another. So we continue on the same example that we've seen a moment before, but this time we're waiting for pending transaction.
01:13:45.904 - 01:14:33.088, Speaker A: Just to show you that any moment now when the transaction is going to finish, you're going to see the Iterative balance going to change and boom, it just has changed to zero point 69. So again, nothing to do just works. So can we? Yeah. So here's an example because one question you might ask, okay, very nice about user balance, right? But what about if we want to read other things from smart contracts? So there's this convenient Use contract call which is again the hook which you can use to define your own hooks to query blockchain for really anything. So you have used token balance. So we're going to create a new hook. This particular usetock and balance hook is actually part of ride blurry.
01:14:33.088 - 01:15:25.296, Speaker A: But imagine you need to recreate it from scratch or you want to do whatever other call to smart contracts that you want. You use Use contract call that returns the value, that returns the same thing that smart contract is going to return. And it has four arguments. The first argument is ERC 20 interface. This is the same format that ETJs is using. It takes an address of the contract you want to call, it takes the name of the method and it takes an array of arguments for the function that it then needs to call. Again, there is a little bit with those extra ends and extra question marks because the values might turn out to be null if you're not connected, if the value is not yet retrieved.
01:15:25.296 - 01:15:49.272, Speaker A: But other than that, it's just a single function call. Good. So we talked about connecting to the blockchain and we talked about reading the state from the blockchain. Now we're going to talk a little bit more about making transactions. So here's an example. We're going to send a transaction. What we're going to use for that is we're going to use a hook surprise.
01:15:49.272 - 01:16:35.240, Speaker A: So Use Send transaction is a simple hook that allows you to send money that allows you to send Ether from one account to another and it returns well, three values. But for now we're going to focus on two values. One value is the send transaction and second is state and the send transaction is a function that takes as an argument ethereum transaction. So it has typical values like two value might be other things like nodes and whatnot or gas related fields. But for this example we're going to keep it simple. It just have two arguments, two and values. So we're sending some eater to a certain address and certain amount.
01:16:35.240 - 01:17:22.532, Speaker A: Again, we're using eater JS parse eater function and the nice thing about it is we have this additional variable that is state and state can be non mining success, failure and exception. So we might not yet send the transaction yet there is non mining means the transaction is pending success and fail transaction is mined successfully or not really successfully. An exception might be coming for example if user cancel in MetaMask or there is a button of code. So this is how it works. This is an example. If we go back to example, this is how it works. Just click send, opens your MetaMask and you have those really simple transactions being mined.
01:17:22.532 - 01:17:59.968, Speaker A: This is just a piece of HTML that you display depending on the state transaction successful, just a piece of HTML that you display depending on the state. And on the bottom you also have a notification. So we're going to talk about notifications in just two slides but for now we're going to go into more complex example. So that was Jeff sending an ether. Now we're going to actually call a function. We're actually going to issue a transaction that's going to execute a function on the blockchain. So for that we're going to use a very similar code that is called news contract function and it really has two arguments.
01:17:59.968 - 01:18:51.284, Speaker A: So the contract contract, again it's Ether's contract. So we already have information about abi and the address. And the second argument is the name of the function. Again it returns two variables, it returns state which can attract the state of the transaction and the send function that you can use to send to execute the transaction to call a function. Now with Send it's a little bit more tricky because send takes the list of arguments that is the same as a function as solidity and it might also take one extra parameter which is overwrite. So you might override some value of your transaction like value in eater or gas field. So in this case what we're going to do is we're going to wrap an unwrap eater.
01:18:51.284 - 01:19:40.432, Speaker A: So the first example from the top what it does, it simply unwraps the eater, right? So you're calling the withdrawal function on wrap eater contract and well, it sends just one argument which is the amount of wrap eater that you want to unwrap. The example from the bottom goes the other side. So it braps eater. So it takes your eater and deposit and you get brab ITER in return. In this case function has no arguments but you need to override the value, you need to override the amount of ITER that you want to send. And this is how it works in practice. And again, you see very nice state management, very nice notification over here and you just wait boom.
01:19:40.432 - 01:20:09.800, Speaker A: Transaction transaction is successful. Everything that needed to be related, the balances are now updated. Good. And you've seen those little notification at the bottom. To get those, all you need to do is the use notification hook. So it gives you the list of all the notifications. Notification include things like wallet, connected transaction, pending transaction, mine successfully transaction sale.
01:20:09.800 - 01:21:07.788, Speaker A: There was an exception running transaction and again, because it's hook and it takes care of all the updating, it's going to automatically make those notifications disappear after a certain amount of time that is configurable. And if you want to have just leave the history of all your transactions, of all the user transactions that you've done, you can use use transactions hook that gives you just persistent history and just think about the amount of work it takes to implement those hooks. They need to work on different networks, they need to work properly when you switch the network back and forth. They need to work when you close and reopen your browser. So there is significant amount of work to it that you don't just don't need to do if you're using use up. And there is one more extra thing there's. This use contract function returns one extra variable, that is events.
01:21:07.788 - 01:21:39.436, Speaker A: So we already have parsed events and you can just dig in and see what the events are. If anybody's done it in Etheres before, usually it takes a few hours to do it first time and then it always takes time to figure it out again how to parse those events. Boom, off you go out of the box. So what else is there? There's plenty of other stuff. So there's a lot of hooks related to many different things. There is use lookup address hook that relates to NS. There is Use gas price that gets you the gas price.
01:21:39.436 - 01:22:38.672, Speaker A: You can use Use block method that gives you the meta information about the current block. There's a lot of helper methods like get Explorer address link that generates the Explorer link that works even if you keep switching networks. So that is pretty convenient as well. Get the current chain name, shorten your address if you want to display just a part of it in the interface and so on and so forth. Currently we support all the Ethereum networks mainnet and all the testnets. We support Binance Xdite, Polygon, Teta, Moonriven and Mumbai which are the polkadot chains, Harmony, Palm, Phantom and if you want to do local development we support local chains, like for example, on Hardhat, if you're developing on Hardhat or Ganache, and it's a really short pull request if you need to make it work with anything else. It's a few things that needs to configure and we keep seeing more and more those pull requests coming.
01:22:38.672 - 01:23:12.864, Speaker A: So if your network is missing, I'm pretty sure there is an easy way to add it. And there is one nice bonus thing, which is a browser plugin. So we have a browser plugin and it's available for Firefox and Chrome and it tracks what's happening under the hood. So we can see it might be a little bit unintuitive at the beginning, what's going on under the hood. So it does that. It also manages your APIs and tags. So if you have specific accounts or specific contracts to interact with, you can make it very readable and understandable.
01:23:12.864 - 01:23:52.410, Speaker A: So, here's an example. You can see the history on the left. It was initialized calls updated means that there are new things displayed on the website that is now being tracked by the multicol. And every time you connect to a different network, mainet, Colban or anything else, you can see, right? Every time that happens, you're going to need to update calls again. Because you used to call on one network, now you're going to call on another network. Every time you switch screen, you change something in the interface, it's going to update calls, right? Every time there is a new block, it's going to check if it needs to update anything. If it does, it will let you know.
01:23:52.410 - 01:24:21.516, Speaker A: Calls updated, four states update. Sorry. Right. That's the browser plugin. What's next? Really? I was really enjoying I was watching Richard Moore's presentation about Etherjs because he talked a lot about the challenges coming with this new reality of multi chain. Layer one, L2, solutions. So this is what we think is going to be the most important next thing to implement in use dub.
01:24:21.516 - 01:25:12.864, Speaker A: So it's really great to see Richard is already working on that and going to take a lot of that work from our hands. But yeah, we want to be able for you to define your environment when you might have multiple networks connected in the parallel, those networks might slightly differ and everything just works. And also, as I said, we think this is pretty much feature complete, so we don't want to add more and more features. But we do see a lot of opportunity to add plugins or separate NPMS. And one example is CoinGecko Oracle. That is just very simple package that gives you the current price using CoinGecko API. And it's just so addictive when you start writing this Idiomatic react hoops in this style, in this API manner, it's just so easy.
01:25:12.864 - 01:25:47.176, Speaker A: So adding other things, they're just using the same Idioms, the same way of working and makes it so easy. Like if you want to display the list of what's on the user wallet and how much is it worth? You hook up the CoinGecko oracle, you hook up the standard Token API and then you just multiply one by the other. You don't need to worry about all those things. We're talking about refreshments wallets networks and yada yada. Yeah. So it's working. We have it in multi.
01:25:47.176 - 01:26:16.324, Speaker A: I think I mentioned it's like 500 application is using as of today. It's a very young network, very young framework. But we're using it on production in several different applications ourselves. Everything I show you today, the examples are available at example, used Up IO. So go check it. The code is available on the GitHub, check the documents, check our website, used up IO. And thank you very much for listening, guys.
01:26:16.324 - 01:26:54.896, Speaker A: Let me know if you have any questions. Mark, that was really mean. Everybody and myself got super excited by all the amazing kind of abstractions you have there. We have a couple of questions and a couple of comments and a couple of open ended things for you. I'll start off with something simple. Can you give us a framework of when somebody should think about using used app versus Scaffold ETH and kind of what are the differences? Absolutely. So, first of all, I want to say, and I'm not sure if it's on the main brand or not, but Scaffoldeth actually is using used app, at least in one of the versions, because I think Austin had many versions of that.
01:26:54.896 - 01:27:24.750, Speaker A: So I'm not sure which version exactly. Our philosophy is we want to do one thing and one thing really well. And I think Scaffolder is really good at being this boilerplate at place. Boom, off you go. And you can just start coding, right? And we don't try to compete with that. I think Austin is doing amazing work and we don't want to compete. We don't see there is a need to improve on that.
01:27:24.750 - 01:28:09.704, Speaker A: What we did see, the core problem is as we develop those applications for customers. So some of you might know me, I co founded E Force. Eworlds was recently acquired by Token, so but we're going to continue working on the open source. So don't worry, guys. But the point is, we work over and over solving the same problem and the code gets obfuscated, right? And we thought that we need a better abstraction layer on connecting, reading and writing to the blockchain. It's really those two things because that's what you do with blockchain. We want to be really good at that, right? We want to make it so it's super easy, super fast, super to.
01:28:09.704 - 01:29:17.470, Speaker A: We're super happy that Scaffold is using it and I hope it's going to use more of it. Awesome. Another question, is this production ready? And I think you kind of absolutely there is like with Tay, I don't remember, but I looked pulled together with Taylor, I've seen at least a few serious guys using it on. Production and we use that on I wouldn't be able to tell you from the top of my head, but there is several projects, production ready, like billion dollar total value locked and interfaces built in Utah at the top of that. Awesome. And then I'll do a final question, which is I think been brought up as a theme from a couple people, but for Darryl, any plans to support SVettel in the future? To support which one you have react. Okay, so maybe I'll type this in Chat, but the question I think directly got.
01:29:17.470 - 01:29:37.012, Speaker A: I see. Well, I didn't hear about this framework before, but I'll check it out and let you know. Guys, I know that there is an expert waiting to start, so thank you very much. Okay. Thank you so much, Merrick. And yeah, everybody check out Usap and we'll do it ourselves too. Thank you very much.
01:29:37.012 - 01:29:53.868, Speaker A: Bye bye. Next up, we have Renzi, and she's going to be talking about Sourceify. So a lot of you are interested in verifying your contracts and Sourceify makes that a lot easier. So without further ado, let's welcome Renzi on screen. Hey.
01:29:53.954 - 01:30:08.610, Speaker B: Hi, guys. Yeah, thank you for having me. I'm super excited to be here. Let's get it started. There we go.
01:30:10.500 - 01:30:10.912, Speaker A: Okay.
01:30:10.966 - 01:30:37.112, Speaker B: Looks as if I'm all good, right? Okay, cool. Yeah. So thank you for having me. Once more. Today I'm going to talk about next level source code verification. With Sourceify. My name is Francisca and I am part of the Solicitity team, and I am also part of this little side project called Sourceify and why Sourceify is next level source code verification and what you can do with this and why it's important.
01:30:37.112 - 01:31:18.230, Speaker B: All of this I'm going to share with you later. So, yeah, exactly what will I talk about today? First of all, I want to highlight again what's wrong with today's UX in Web Three. What is source verification and why is it important? What are metadata files and what's Netsmac? Why is Socify next level source verification? And last but not least, because this is a developer summit, you can learn how you can use Socify with the common dev tools or also manually. So let's get started. Yeah. First, I really want to remind us all what's wrong with today's UX in Web Three. I mean, many, many of you might have seen this before.
01:31:18.230 - 01:31:49.504, Speaker B: We have lots of trust issues and uninformed decisions. These decisions that we currently take when we interact in Web Three, they are based on hex data strings. We don't know what they mean and we don't know if this interaction we do is actually what we intend to do. And yeah, that process is also called Euro signing. And yeah, this really shows us nothing. We don't know what we are doing. And many, many questions might arise from this.
01:31:49.504 - 01:33:30.432, Speaker B: Some of them could be are the function arguments correct? Which contract am I interacting with here? Is this thing really doing what I wanted to do? What is the source code of this and has it been audited or is this the one that has been audited? Is this the right address that I'm interacting with? Did anybody check the legitimacy of this? Do I call the correct function? And last but not least, can I consider this safe to use based on this hex data string? You cannot answer any of these questions and yeah, if you are not sure what I'm talking about yet, I also brought a few little examples with me here. We have Uniswap where I am trying to swap some ease for Die and yeah, the information I get on which I can base my assumption or decision on is these beautiful 260 bytes of hex data. Same is here I'm trying to buy a super rare NFT and again I see maybe a bit of function type information and then again hex data but really nothing else which could prove that I am actually doing what I want to do. Yeah, a couple of more examples. The same here with ENS trying to prolong my ENS name and again I only get a hex data and a bit of a function type, in this case renew which could give me some indication maybe it's the correct thing I'm doing but it is not really approved. And lastly here I even needed to sign a message before I could even see any information on the website. And again, that is some data that is basically meaningless to me.
01:33:30.432 - 01:34:38.836, Speaker B: And even though this is a developer summit here today, I also want to remind you that our users are not necessarily developers and for them this is even more confusing than it is for us. So how can we improve the current status quo? Luckily, there are some ideas how we can even make this whole problem go away and achieve trust minimized Web three interactions. I'm just throwing a couple of words at you right now and I don't expect you to understand what all of these mean and no worries because we will go into more detail on all of these later on. But basically trust minimized web3 interactions can be achieved by a nice collaboration between several aspects which include source code transparency and availability, source verification metadata and net spec availability and lastly, Wallet and Block Explorer integrations. So with that in mind, I will go through some of the basics. Maybe some of you are new to the Web Three space and you don't know what the term source verification really means. That's not a problem at all because I'm going to explain it.
01:34:38.836 - 01:35:24.340, Speaker B: Source verification is what we refer to as basically or in other areas. This is known as binary reproducibility or bytecode reproducibility. And what it basically means is that the deployed bytecode that you deploy on chain equals the bytecode that is compiled from the source code. So let's say a project is open source and it claims that their source code can be found at location X. And then there is some bytecode and it's deployed on chain. And basically by recompiling the bytecode that is open source and verifying that this matches the deployed bytecode on chain, we have verified the source. And that's the process of source verification.
01:35:24.340 - 01:36:33.064, Speaker B: You might know this for example, through ESA scan because here, this is a very popular Block Explorer and via this Block Explorer you can do this verification process. So many of you might have seen this before and yeah, I will today show you turner for deferri, how you can also verify your source files. And we'll give a bit more context on why we think that the current verification, how it's been done for example by Ether scan is maybe not enough, it's already very good, but we can go much further than that. And throughout this talk I'm going to use the east to deposit contract to show you what I mean exactly using an example. So here you see the Ether scan website and we are on the page that shows the deposit contract. And if you scroll down and if you click on contract, you see this little green checkbox here and you can also see here contract source code verified. So that means somebody has done this verification process and the source code got recompiled and matches the bytecode that is deployed on chain.
01:36:33.064 - 01:37:36.160, Speaker B: Yay. Next up, what is a metadata file? Metadata files are actually a quite cool feature from Solidity, which got introduced many years ago, but unfortunately not many people are aware of them or are using them properly. So basically a metadata file is a JSON file that is generated by the Solidity compiler that contains a lot of crucial information about the compiled contract. At the very end of the compiled bytecode you see a hex data. And this hex data includes already a bit of information. It includes the used compiler version and a swarm or IPFS hash. And if you follow that hash to for example, IPFS, and the metadata has been published on IPFS, then you can find much more information, you can find the full compiler version, you can find the complete abi of the contract, developer documentation, user documentation, compiler settings to recompile the code to the bytecode.
01:37:36.160 - 01:38:39.456, Speaker B: So all of this is very important information, crucial. And some of this should in the best case, be displayed to the users directly. And let's have a look again what this means at the example of the deposit contract. Here we see the metadata JSON of the deposit contract, and here you see all the things that I've mentioned before, the used compiler version, the language here you could expand and see the entire API. Here currently expanded are the dev docs, so the developer documentation here are the user documentation and so on. So all the information that I've just mentioned okay, but what is netspec, which has also been already mentioned in the metadata file. Netspec is the Ethereum Natural Language specification format and that is basically a spec that helps you to provide rich documentations for functions, return variables and more in the form of comments.
01:38:39.456 - 01:39:40.656, Speaker B: So basically the developer documentation and the user documentation that we've seen before in the metadata file, they come from this comments that you put in the code using the net spec format. And yeah, so they are basically categorized in developer focused and end user focused messages. And there are also some other categories that you could use as well. All of this by the way, you can find in the solidity documentation in case you want to read more about it. And those end user focused messages that you can use to describe the public facing functions that you have in your code. They are really crucial to users since they basically translate into human understandable words what the contract interaction will entail so that they can decide on their own whether they want to do this contract interaction, whether that is what they intended to do or not. And so looking back at the deposit contract, we see that this deposit contract has been actually commented using this net spec format.
01:39:40.656 - 01:40:46.972, Speaker B: And here for example, we see at Def which is the tag that you would use for the developer documentation and here we also see at Notice which is the tag you would use for the user documentation. And I also want to show you again how this would look like in the metadata file itself. So all what we've seen in the source code you can find again in the metadata file. It's nicely structured here and it's basically all there just waiting to be displayed for the right person so they know what they are actually doing. So why is this important? That is especially important because the two things we just described, on the one hand the source verification and on the other hand the code commenting in form of Netspec comments. They together have the power to create greater transparency in contract interactions. But if we only have one of them, the equation is not complete.
01:40:46.972 - 01:41:45.970, Speaker B: So on the one hand, if we have a verified code that is open source but there are no Nets back comments or there's no code commenting been done, then the end user does not understand what is happening even though it has been verified. So that is bad. On the other hand, if the developer used Netspec and the end user can understand what they are doing because there is some sort of display of this Netspec happening for example in the wallet front end, but the code isn't verified, so then the description could be inaccurate or even worse, it could mean something entirely else. So that is also bad. But when the code is verified and open source and the end user can understand it because there is some meaningful information displayed to him in the Wallet user interface then that's awesome. So that is why we don't only need source verification and we don't only need code commenting, but we need both and we need it together.
01:41:47.780 - 01:41:48.240, Speaker A: Yeah.
01:41:48.310 - 01:42:57.990, Speaker B: So next question would be how do we bring all of these pieces together? Just lurking at the time there somewhere but I think I'm still good. Meet Sourceify sourceify is first and foremost an initiative to raise awareness about the importance of source verification and is also an initiative to try to raise the standards and the availability of the verified source files. Sourceify consists of several products that want to make it easier for devs to verify their sources. But first and foremost it's this decentralized metadata and source code repository which I'm going to show to you later. But we also see ourselves as bridge builders in the ecosystem and we really try to help make safer web3 interactions a reality. So what we do on a daily basis is basically talking to all the stakeholders in the ecosystem that need to be involved to make our vision come reality. What are our goals? On a high level we want to enable, trust, minimized informed web3 interactions and that also entails stuff like turning hex strings which we've seen in the beginning in Wallets into human readable information.
01:42:57.990 - 01:44:07.228, Speaker B: And on a technical level that means stuff like keeping the metadata and the source files available via IPFS that can otherwise be a big issue and also become an infrastructure or base layer which allows other tools to really build on top of it and to leverage what we are offering. So here's another little example of how this could look like if we would turn hex strings into human readable information. On the left hand we see what we've also seen in the beginning, contract interaction, how it looks at the moment. In Wallets we have a bunch of hex data and we have the function type contract interaction. But what we would like to see there would be a function type, would be arguments, but would also be a description that would display the net spec and then also showing the source and basically a little information whether this code has been verified somewhere or not. And then with the option to click on it, if you're a technical person to click on it and then basically see the source code for yourself. That looks like really a nice improvement to the UX we have today.
01:44:07.228 - 01:45:00.792, Speaker B: But what do we need to get there from our side? We think we need several components for this to make it work. On the one hand we need automated verifications or really, really easy verification processes that are not as cumbersome and as complex as the processes we have today. We need an open contract repository of all verified contracts that also includes the metadata files. Because I've mentioned before the verification alone without the metadata files does not bring us the translation part. So both of them are really needed together. We need verification interfaces and plugins that also contribute to the very easy verification process in case the automated verification process fails. And lastly, of course, we need integrations, integrations and more integrations because this is a very complex ecosystem.
01:45:00.792 - 01:45:58.416, Speaker B: And in order to basically bring this benefits that we then have on the infrastructure level to the users, we need to integrate with Block Explorers and with Wallets and maybe even with other stakeholders. First of all, I want to now describe you a little bit more how this automatic verification could work. So sourceify at the moment currently already automatically verifies new deployments. That's very awesome. And that only has really one condition. The metadata and the source files must be published to IPFS. So when you are a developer and you, let's say deploy a contract to Ethereum Mainet, then your next step must be to use auto publishing or to publish the metadata JSON and the source files to IPFS so that our sourceify monitoring service can actually pick it up.
01:45:58.416 - 01:47:08.212, Speaker B: So how does it work? Again, the deployer deploys a new contract to the blockchain and then our monitor listens to all the new blocks that are being created by the blockchain and basically looks in those new blocks for new deployments. Once the monitor finds new deployments, it checks in this bytecode that I've mentioned before, the very last bit, this hash, the IPFS hash and then checks at this address on IPFS whether it can find the metadata file. And if it finds the metadata file, and if it finds the source files, then it runs the Verifier. And after the Verifier has done its work, the stuff is being indexed and pinned and we make sure that the metadata files and the source files don't get lost on IPFS. So that would be the optimal automatic scenario. And in that automatic scenario, no manual verification from the developer is needed whatsoever. So this is really different to the verification process.
01:47:08.212 - 01:48:04.330, Speaker B: You might know, for example, from either scan at the moment, let's say you want to verify a contract that you deployed two years ago or you didn't publish it on time so the monitor couldn't find it on IPFS or some other scenarios where it needs manual input. That's also not a problem because we also have a manual verification interface, which I'm going to show you later. But this automatic verification we think is a crucial point in making it just easy and seamless for new deployments to be verified. So why is this next level source verification? I've touched on many of these points already. Firstly, we do no code flattening. That means the metadata in a Webery is verified as well. That does not mean that the content in the metadata, especially the content in the net spec files, is true.
01:48:04.330 - 01:48:47.140, Speaker B: We cannot judge whether what the dev translated to be happening in the contract is actually happening. But because everything is transparent and everything is open source, what you can do next is basically as a developer, go and see the source code, go and see the commons and see whether that reflects what is actually happening or not. As the next point, all contracts are independently verifiable. That means you have all the information you need to do the recompilation yourself. Anybody could do it. So that is not a one off verification. But anybody could at any point verify the integrity of this again and lastly, tackling the availability issue.
01:48:47.140 - 01:49:32.676, Speaker B: So making the storage of source files and the processes around verification more decentralized, independent and hence more resilient. That means especially we shouldn't just trust one third party to verify everything for us. And what happens if this third party goes down or the database is somehow corrupted or I don't know what can happen. So we are friends of open source and we are friends of decentralization. So we really try to make this process as decentralized and independent from one middleman as possible. Okay? And since this is a developer summit, let's now have a look at how you can use Solsify today to do this verification I've just mentioned. Yeah, in the best case, you don't need to do anything.
01:49:32.676 - 01:50:20.420, Speaker B: As I've explained with the automatic verification process, the only thing you need to do in that case is to publish your metadata files and source files on IPFS. Here's the example of remix, where you have a very handy button just right under the Compile button. You have a Publish On IPFS button, and all you need to do in the best case is click Publish On IPFS and you're done. Because our monitor will pick the stuff up and will verify it without any need for you to do anything. So I click Publish on IPFS and then I see here socify it's. That's how I called this project. Metadata has been published and I can see the addresses of those files that I've published to IPFS here.
01:50:20.420 - 01:51:31.176, Speaker B: So that would be an easy way how to do it with Remix. There's even also another way how you can verify your sources in Remix because there's also a sourceify Remix plugin which you can use as well. Secondly, if you're using Hardhead, there is a hardhead deploy plugin and that hardhead deploy plugin also includes the sourceify verification. So all you need to do if you want to verify on sourceify with hardhead is dot sourceify or whatever network you are on and then it will get verified as well. For Truffle, it's again a bit different. So in Truffle you find the metadata output in the artifact and in there you find the metadata as a string and not as a metadata JSON. So what you can do in the case if you use Truffle is you can go to our manual verification interface and just drop your source files and that artifact file in our manual interface and it will verify everything.
01:51:31.176 - 01:52:14.216, Speaker B: So no need for you to extract the metadata or to somehow transform it into its own JSON file. We do that in our verification interface. So you just have to dump this artifact file. And lastly, here is how our interface currently looks. I am sorry that this is a bit blurry, I know, but I tried to make GIF out of this. So let's see what is happening here. In the first instance you saw the Susiefi Dev website where I added let me play this from the beginning because this makes no sense for you guys or let's wait until it's over.
01:52:14.216 - 01:52:33.532, Speaker B: Basically what you're seeing here is already the repository, the contract repository with all information. But I want to see it from the start again. So let's see what's happening here. That's the metadata file. Great. I hope this will go back to what I wanted to show you. Yes.
01:52:33.532 - 01:53:34.370, Speaker B: So basically you enter which network you have been using and the contract address and then you dump the files, meaning the source file and the metadata file. And then you click verify. But because the deposit contract which I'm using for the examples has already been verified, I get the notification has been verified and it leads me to the contract repository where I can have a look at the source file as well as the metadata file. Here you see the source file of the deposit contract which is neatly stored in the contract repository. And then you can also go back and you can click on the metadata JSON which shows you all the net spec comments, but also the other information that is included in the metadata file. And yeah, all of this you can see when you go to Swissify Dev and enter the contract address. So also if you are interested in knowing whether a contract has been verified or not, you can just go there, dump the contract address there and it will show you whether this contract has been verified already or not.
01:53:34.370 - 01:54:24.284, Speaker B: Okay, so going back to the initial slide that I had in the beginning, how can we achieve trust, minimized web3 interactions? I now want to translate these into what you as a developer can do. So let's have a look. What you can do to help make this a reality is you have to open source your code and make it available via IPFS. You can use sourceify and verify your source and metadata files. You should use code commenting and comment your code using Netspec. And lastly, you should either build integrations or encourage others to do so. So what should you take home from this talk? No matter whether you are a developer or a user, please always verify your contracts or check if they have been verified.
01:54:24.284 - 01:55:04.980, Speaker B: And especially in the case that they have not been verified, demand verification and raise awareness for the safety risks that are there. If stuff has not been verified. And on the more technical side of things, because we want to become more decentralized, please help us pin the Socified content on IPFS, contribute code if you like, and generally all ideas are welcome, so please join in our chat. We are on Metrics and GitHub, so please join there and contribute ask questions. We also do user support there in case the verification should not work. We are on Twitter at sourceify ETH. We are in GitHub ethereum.
01:55:04.980 - 01:55:16.656, Speaker B: Sourceify. And for all the plugins, it's GitHub.com slash sourceify ETH. And our website is Sourceify dev. And in the DWeb. It's sourceify ETH. Yeah, wrapping up.
01:55:16.656 - 01:55:40.490, Speaker B: I want to say big thank you and credits to Chris, Eddie, Fabian, Yakov Ligy, and also welcome our two new maintainers, Khan and Johnson, because all the people I've mentioned, they are our developers and they are the brains behind this project. So I'm only the messenger here today and trying to be able to answer all your questions if you have any now. Thank you.
01:55:43.180 - 01:56:13.300, Speaker A: Thank you so much, Francie. This was awesome. There were a handful of questions which luckily Chris just already answered on the chat, but I'll still bring up some of these here. I think a common discussion that's going on is how do you think about integrations? And obviously there's multiple interpretations of what integrations are, whether it's about this plugging into existing developer environment, to adding more plugins or support for how this gets used outside of just a web interface. What are kind of plans for that and how does that look like?
01:56:13.450 - 01:56:27.656, Speaker B: Yeah, that's a good point. So in one of my other talks, I also had a slide on all the cool integrations we already have, but because the time was short and I wanted to this time highlight how to use it, I didn't include this, but actually in terms of so let's go.
01:56:27.678 - 01:56:29.336, Speaker A: Deep into whatever we can.
01:56:29.518 - 01:56:57.556, Speaker B: Okay, so in terms of developer tooling, there are already some integrations out there that I mentioned. So for hardhead. It's the hard deploy. For Truffle, I think there's no plugin yet, I hope I'm not mistaken. And for Remix, there is the Susify plugin already. So on the tooling side of things, we are quite good. Of course, on the wallet side of things, things could improve, but there are open conversations already with some of the wallets, which are great.
01:56:57.556 - 01:57:35.120, Speaker B: And then lastly, on the Block Explorer side, the AutoScan Block Explorer recently released a new version which actually includes sourceify support, which is very cool. So, yeah, there also needs to be some more work on the Block Explorer side of things, especially with the big Block Explorers. But yeah, we hope that this will happen soon and we are open to conversations and with most of the people, we already have an open conversation channel. But of course we also know there are so many priorities and so many things to work on at the same time that it's understandable that nobody can only prioritize sourceify.
01:57:36.900 - 01:57:57.430, Speaker A: Looks like other questions are coming in. Let's see. Other than everybody just being said about what's going on, do you have any specific small projects a hacker or a hackathon could build to benefit sourceify? Like small improvements, I think is probably the better interpretation here.
01:57:58.360 - 01:58:07.240, Speaker B: Yeah, that is a very good question. If I had more time, I would definitely come up with some stuff. Maybe Chris has some ideas if he's in the chat.
01:58:08.780 - 01:58:11.928, Speaker A: All right. Chris is OK. Great.
01:58:12.014 - 01:58:42.710, Speaker B: Yeah, no, because I think there's a couple of things that we can do. And as I also said, we are currently onboarding two new maintainers to the project, which is really exciting, and I think they would also have some ideas how you could help, for sure. But also on that side, I think we have some IPFS issues, for example, so if somebody is an IPFS expert or just pinning the repository but yeah, in terms of hackathon projects, there's probably some stuff that could be done.
01:58:43.560 - 01:58:56.760, Speaker A: Awesome. Well, if there are no more outstanding questions, we can end this. But this is obviously great. And congrats on making this a big initiative and better public utility.
01:58:57.420 - 01:58:59.208, Speaker B: Yeah, thank you so much for having me.
01:58:59.294 - 01:59:31.190, Speaker A: Yeah, so much. All right, so with that, we are ready to move on to our next talk. And our next speaker is Hari. And Hari is going to be talking about all the new features in the latest update for Solidity. So we'll just give it a second for everything to work out on the AV side. And Nari, whenever you're ready, turn on your camera and we'll get the slide started from our end. Here we go.
01:59:31.190 - 02:00:40.890, Speaker A: Hello? Can you hear me, Val? Yes, everything is good. I know we're doing the slides on our end, so just give me one more second to pull that up and we can sure make that workload. This one is on my end. I can go present it, but I'm trying to see if I can actually make it a presentation full screen mode, but let's see if that works. There we go. Okay, so just say Next whenever. Great.
02:00:40.890 - 02:01:27.160, Speaker A: Yeah. So I'll say next whenever I want to move. Okay, great. So my talk is about two important abstractions in Solidity. And as you might already know, the 80 version was a very important release for us because it introduced a major feature that is safe map by default. But since then, we have followed up with two other major features that we believe has a similar potential. I'm not going to say what the two features are right now, but rather I want to slowly introduce a problem and then try to convince you why we implemented this feature and how we can solve certain problems elegantly using our new features.
02:01:27.160 - 02:01:58.550, Speaker A: So next. So let's dive straight into our toy problem. Suppose you want to. Write a smart contract that sells some object. The object has a price and there is a limited quantity of the object available. And the problem is extremely simple. The problem is that a user wants to buy some quantity of the object and you want to compute the total price.
02:01:58.550 - 02:02:46.560, Speaker A: So next, the very first solution for this is the following. So you write a function which is total price, that takes two unsigned integers here, quantity and price. And then you multiply it. It's very simple and perfectly valid code. But what is the problem here? The problem is that you can notice that the price and quantity are supposed to be two different things. For example, you are not supposed to assign a price to a quantity or vice versa. But in our code we can because both of them are unsigned integers.
02:02:46.560 - 02:03:29.904, Speaker A: So from a type safety perspective we can do much better. So in our example, the type only represents the underlying data representation and not how the data should be interpreted. So to repeat, we would like to have two different types for quantity and price. But we already have a solution for this in the language. Let's look at another solution. So next, the solution number two is just using structs. So we have two structs here, quantity and price.
02:03:29.904 - 02:04:16.690, Speaker A: They both have a single element and now you can write the same function. But the arguments are now structs instead of elementary value type. So the code is much more type safe than the previous one and you can no longer assign quantity to price or vice versa. That would be a type error. But now this has some other problems. So stocks are a wonderful abstraction, but it comes with a cost. I will actually explain the cost in detail in a bit, but let's just say that it's not as efficient as the first example.
02:04:16.690 - 02:04:56.860, Speaker A: So note that a struct is a reference type. What this means is that it is a pointer towards a value in call, data memory or storage. So in this example it is in memory. So you can see it clearly because you have to explicitly specify it. You can see quantity memory Q and price memory P. So remember that I mentioned this is not as efficient. So let's forget about the problem for a bit and talk about something more fundamental.
02:04:56.860 - 02:05:55.116, Speaker A: So next, so we will briefly talk about the difference between stack and memory in the Ethereum Virtual machine. So a stack is simply a data structure. The Ethereum Virtual machine is a stack based machine, which means that you mainly do operations using a stack. Speaking of operations, the main operation in a stack is to push a value to the top of the stack and then there are a bunch of operations that allows you to rearrange the stack as well as doing various computations. So for example, if you have two elements on the stack, you can add them by using the add of code. And what that does is that the two elements will be removed and replaced by the result. And let's now talk about memory.
02:05:55.116 - 02:06:51.120, Speaker A: So, memory is a temporary location in the Ethereum virtual machine where you can store things and read them later. The main takeaway from this description should be that stack is much more fundamental than memory. So it's important because there is often this misconception that all values in Solidity are stored in memory. That is not true. In Solidity you have to explicitly say memory when you need to store or read something to and from memory. So for example, local variables are stored in stack and not memory because often they don't have a memory specifier. So if we go back to the first example, the values are actually stored in stack and in the second example the values are stored in memory.
02:06:51.120 - 02:07:38.080, Speaker A: But this still doesn't explain why one is more efficient than the other in terms of gas. Let's now try to see why that is true. Next. So as I said before, the most fundamental operation that you can do with the stack is putting a value in it. So you can do this with the push operation. The operations is very cheap and only costs three gas. So if you consume the value, for example, when you want to add it with something that is already in the stack, you don't need to pay anything extra for consuming it, you only pay for the addition.
02:07:38.080 - 02:08:26.050, Speaker A: So consuming doesn't have an extra cost as long as the element is at the right location. But if it's not at the right location in the stack, you can use some stack operations to move it to the right location before consuming it. And each of these stack operations would typically cost three gas. But in our best case scenario, the cost for putting something in stack is just three gas. And we hope that the value is at the right place so that we don't have to do any more operations to move it around. Now, let's see how to do the same things with memory. So, if you want to put a value in memory, you do it using the operation M store.
02:08:26.050 - 02:09:01.320, Speaker A: So M store of AB will store the value B at the location starting from A. So remember that all operations have to go through the stack. So to do M store of A comma B, you have to first put the values A and B in the stack. So you have to start with B and then A. So we have already discussed the cost for doing this. So to put b in stack it costs three gas. It is a push operation.
02:09:01.320 - 02:09:51.400, Speaker A: Similarly, to put A in stack, it cost three gas. And now the M store inspection has to cost three, which is fixed, and at least another three, which can vary depending on how big A gets. So the more memory you use, it can get more and more expensive after a certain point. So in total, you have to pay at least twelve gas for this operation. And similarly, if you want to read a value from memory, you do this using the operation M load M load of A. Again, you need to start by putting the value in stack, which costs three gas, and afterwards the M Lord inspection, which cost three gas. So that is a total of six gas.
02:09:51.400 - 02:10:40.330, Speaker A: So, as you can see here, just to write and read from memory, you need to spend at least 18 Gias, whereas this can be done with just three Gias in stack. So stack operations can be around six times cheaper than memory. So can you go back to slides? Great. Now I hope that answers my statement. Not efficient. Now let's go to the real solution. So, what if Solidity had a way to create an abstraction, but without having to pay an additional cost for it? Abstractions are amazing, but we don't want to pay more guess for it.
02:10:40.330 - 02:11:43.070, Speaker A: So let me introduce you to user defined value types. So it is what we call as a zero cost abstraction. It can be used starting from version 89, which was released exactly nine days before. So it allows you to create an alias type while having additional type safety. The syntax looks like type U is V, where U is the name of the new type and V is an elementary value type. That means V can be an address, an int, eight, et cetera. So how do we solve the same problem using User Defined value types? So, next, so here is an example on how to write a contract to solve the toy problem.
02:11:43.070 - 02:12:26.040, Speaker A: So here you define a new type quantity and price. You see the syntax? Type quantity is uint and type price is uint. Note that these types are distinct and therefore you cannot just assign one to another. That would be a type error. So this example also introduces how we allow conversions to and from the underlying type, which is by using the function Wrap and Unwrap. So quantity unwrap can be used to convert from quantity to uint and quantity Wrap can be used to convert from U into quantity. This can of course be generalized.
02:12:26.040 - 02:14:12.380, Speaker A: So if you replace U int to uint eight everywhere, then wrap and unwrap will correspondingly change. So next, a very important thing to note about this is that the types are fully backwards compatible. What does that even mean? So what this means is that even when you have to implement a contract that needs to follow a standard which was written a long time ago, you can still use the user Defined value types to interface with it or rewrite it. For example, the ERC 20 standard requires the type for the amount of token to be U into 56. But you can define a new type with the name decimal 18 which is a zero cost abstraction over U win 256 and you can replace U into 56 with decimal 80 wherever you think that's more appropriate and it would be completely backwards compatible. So here I have two examples of interfaces and they are supposed to represent some of the subset of the ERC 20 standard and both of them would work exactly the same. But in my opinion, the first one is much more clearer because it makes it clear that the value is supposed to actually represent a number with 18 decimals, which is the case for most tokens, whereas in the second case it's not obvious what value is supposed to represent in terms of decimals.
02:14:12.380 - 02:15:16.950, Speaker A: So effectively the feature allows you to write code that is much more clearer and easy to read. So, next, so there are of course some open questions about how we improve this feature and one of them is about defining operators. So user defined value types does not have any operators right now, but we would like to have them in the future. So as you can see in this example, which is again about a token, and how we have a type that represents a value in 18 decimals. So the type decimal 18. So we need a syntax to create the operator plus equal to because if you look at the function mint you have the line balance of user plus equal to value. But we don't have a plus equal to right now, but we would like to have them.
02:15:16.950 - 02:15:52.312, Speaker A: You can participate in the discussion where we propose this feature by going to the links. We would love to hear your opinion on this. I will leave a link to my slides later if you want to check out the links. So, now that we have solved our first problem, let's forget about it and talk about a completely new problem. So the new problem is also very simple. Next. So the new problem is the following.
02:15:52.312 - 02:17:01.856, Speaker A: So how can we tell a user why a transaction failed? So suppose you have a simple contract that can only be used by the owner. So it's typical to have a modifier that checks the sender and rewards if the sender is not the same as the owner. You can see the contract here where you have an immutable variable owner which would be set to the message center during the contract initialization. And then you have a modifier only owner which would check if the message or center is same as the owner which was saved during the constructor. And if it's not the same, the transaction would reward. For example, if you look at the withdraw function, it can only be called if the modifier only owner is true. So I have a comment here which I said don't do this, but this is very typical in Smart contracts and why did I say this? So that's mainly because this is a very large reward string.
02:17:01.856 - 02:17:49.350, Speaker A: It's 40 bytes, it's more than 40 bytes. And large revert string add to higher deploy costs for the contract as well as higher gas costs for reverting transactions. The deploy costs here can be especially important if your contract is getting near the contract size limit. But what if we had a way to create a high level error object next. And that is exactly what customers do. So it was introduced in the version 84 and syntax is very similar to how we define events. So you can see the error only honor and also notice how we use Natspec comments to describe it.
02:17:49.350 - 02:18:47.780, Speaker A: If you listen to the talk about source verification by Francis that happened just before, you will see some of our goals about how we want to use Natspec comments to improve the user experience for contract interactions. So instead of a required statement, you replace it by an if followed by revert only honor. Next. So here is a short summary of the before and after. In the first example, that's how you do it classically using a string. And in the second example we have a contract, we use customer S. And the second example is better because it has lower cost for rewarding transactions as well as cheaper contract deploy cost or smaller bytecode.
02:18:47.780 - 02:19:53.340, Speaker A: And next. So let's get to the next level of revert messages. Sometimes the revert reason, sometimes you want the reverse reason to have more information than a very simple static string. In the past, if you wanted to convey a structured message back to the user, you would have to do something like the following the context is that we have a token like contract and if we have a call to the transfer function and if there is insufficient balance, we want to revert and tell that to the user. Of course we can always reward with saying okay, insufficient balance, but we want to do more than that. So if you really want to have a proper error message, you could do something that looks like this. So what we have here is a function you went to STR that converts an integer to string and then you concatenate all these things on chain.
02:19:53.340 - 02:20:49.470, Speaker A: I think I have a bug here, but yeah, whatever, it doesn't matter. So first of all, this Uwin to string conversion is doing it on chain is paying more gas than you're supposed to do. I mean, it's just unfortunately expensive. So when I mean expensive, it's not as expensive as a storage read or storage write, but it's completely unnecessary in my opinion. Things don't really belong in smart contracts, so you should try to really minimize them. And the second reason is that whenever you have a function call in solidity, each argument has to be evaluated first. So if you have F of AB and if A and B are function call, you have to evaluate A and B before you evaluate f.
02:20:49.470 - 02:21:39.260, Speaker A: So in this case Abi encode pack is a function call and that means that even if the condition for require is true, the reward string has to be still evaluated. So this means that you are just wasting gas for every single call, even if the call is completely correct. So next. So let's see how to solve the same problem by using customer errors. So here is an example that combines multiple things from this talk. The first thing is the user defined value type decimal 18. So we have a token again and we have an error, insufficient balance.
02:21:39.260 - 02:22:39.730, Speaker A: So remember that I told you that customers are similar to events, you can have arguments. So here you have a revert with the address of the user, the current balance and how much is required for the transaction to succeed. It looks very similar to how you emit an event. So this is a much cheaper and much more idiomatic approach to having much more structured error than using strings. So, next. So customaries is a feature, it's a compiler feature, but it wouldn't be complete without tooling support. So several of the popular tools actually support customers and we are hoping to see better support.
02:22:39.730 - 02:23:21.870, Speaker A: So currently block explorers like either scan doesn't automatically decode customers and we hope this is something that would be supported in the near future. But all these tools do support it. So, next. So that's pretty much my talk. My name is Hari and I hope I was able to convince you why these two major features, that is user defined value types and customers are useful and also why we need them. I would love to see smart contracts using these features and I hope I was able to influence you. You can find my slides in the following link.
02:23:21.870 - 02:24:00.840, Speaker A: I can now answer some questions. You can also find my contact in the link if you want to follow up and if you want to reach out to the compiler team, you can find the details in the link. So, questions, that was a great talk, just kind of sourcing everybody. I'm just looking at all the chats to see if there are more questions. I think overall people are just excited about the gas efficiencies here. Of course, this is kind of the most obvious thing that you kind of highlighted along with those idiomatic abstractions. So if anybody has quite we're just getting comments that people are loving this.
02:24:00.840 - 02:25:12.320, Speaker A: So Richie, if you have any questions for RA, we can ask that too. Maybe just a more future forward looking question will be what are some of these other abstractions that you're thinking about in the back burner or possible Next releases? What does that look like? And sort of how are you thinking about the future of the language? Yeah, so something that we wanted to do was having some support for fixed point types and we think that user defined value types is like the first step towards it. So right now our thinking process is that we don't want proper fixed point types and Solidity because there is no single way to implement it. If you look at the implementation, there are like multiple implementation and each one has their own advantages and disadvantages. So if something lands in the compiler, it has to be somewhat the implementation, but there is no the implementation. So we think it's something that libraries should do and we think we want to better support it by using user defined value types. And that's why operators would like, be the next step in user defined value types improvements.
02:25:12.320 - 02:26:08.180, Speaker A: And I think that would unlock much more abstract code, that would let you write much more abstract code and also safer, also efficient code. Yeah, that's the number one priority right now. Got you. In terms of I mean, you kind of talked about some of the integrations that are still on track to be actually on there, from the libraries to Ether scan, what have you. What is it that they should keep in mind as they think about integrating it? Obviously, I feel like you addressed that there's no backwards incompatibility, sorry, there's no incompatibility here. As people think about it, it is equivalent, it's just a high level abstraction. But for developers on this side looking to just quickly switch over to these abstract types, do you have any advice or comments on what they should keep in mind? Not really.
02:26:08.180 - 02:26:55.328, Speaker A: I think it's fairly straightforward to switch and we purposefully designed it to keep it simple. And if you have comments, if you're using the feature and want to see some changes, we are always open for comments. So the way we implement features is by starting with a minimal version that will do most of the things and we would slowly add more features to make it stronger. So if you have comments, feel free to reach out to us. As a matter of fact, the feature user defined value types was greatly influenced by one of our user feedback. So your feedback really matters and it would influence the language. Awesome.
02:26:55.328 - 02:27:39.600, Speaker A: And the way people can get involved is it the GitHub or what is the official resource? So you can find all our information in Soliditylang.org, but you can also come to our GitHub chat, look at open issues in our GitHub channel or in the metrics channel as well. But the go to link is Soliditylang.org. Awesome. Well, a couple people were asking for a link to the slides. We just posted that, so that also has the link at the end of the presentation. So thank you so much, Hari, for that amazing intro for the demo of What's New and hope you have a great rest of the weekend.
02:27:39.600 - 02:28:06.010, Speaker A: Thanks, bye. All right, with that, we are ready for our next talk. So our next speaker is Yusuf and he will be talking about off chain data storage using web3 storage and NFT storage. So without further ado, let's see how we can make NFT storage. Welcome. Good to be here. Thanks.
02:28:06.010 - 02:28:39.728, Speaker A: Share my screen here. Cool. So, I am Yusuf. I work at Protocol labs where we make IPFS and filecoin. Those are two really interesting bits of technology that we think can help everybody in this decentralized app ecosystem take advantage of this vast network of storage that's now available. So let me sort of get into the mix here. This is kind of a mashup of two talks about web3 storage and NFT storage.
02:28:39.728 - 02:29:44.500, Speaker A: And these are both services that we've built to make using IPFS and Filecoin really easy and accessible, especially for Web Two developers or really anybody that wants sort of a low friction path into this storage network. So first I'm going to talk a little bit about NFTs. So we became really interested in NFTs. We have been for a while, but obviously this year they sort of take off in the public consciousness and that's when I personally started getting into them. I was loosely aware of them before that, but basically it was really encouraging for us to see that IPFS was being used to store lots of NFTs. And we think it's a really great fit for this kind of application because first of all, storing data on most blockchains is prohibitively expensive. And therefore to have an NFT that represents something outside of itself, which is the case for many, there needs to be a link between the NFT and data that lives off chain.
02:29:44.500 - 02:30:51.196, Speaker A: And IPFS has some really great properties for creating that kind of link. So we'll go into that in a little bit. But we started to realize that the developers that like OpenSea and foundation and Zora and so on, they care about users being able to access the data should they ever disappear. And this is sort of a common thread in these kind of circles, is that nobody wants to trust any individual party to stick around forever. But we combine, if we all play well together, we can hopefully design a system that outlives any of us individually. Right? It's good for us to kind of build systems with that in mind, even though hopefully, of course we'll be around for a while. But something that users care about, especially if they became aware, that the thing that they're I don't know, maybe people are already aware of this, but I think that people that are new to NFTs don't always understand what specifically lives on the blockchain and what lives elsewhere and what's that relationship.
02:30:51.196 - 02:31:26.856, Speaker A: So there's like an educational piece to that that we've been involved in trying to kind of clue people into. What is that link and what's the strong way to make that link. IPFS fits in. And if you're new to IPFS, it is the Interplanetary file system. It's been around for several years and the gist of it is basically that first you put your data onto an IPFS node and that node participates in this big peer to peer content sharing network where basically, if somebody wants a piece of content, they'll ask for it. And if I have it, I'll provide it. And everybody does this.
02:31:26.856 - 02:31:57.260, Speaker A: And it's actually a pretty efficient way to distribute data across a network in many ways. Anyway. First you put your data into the IPVs node and you get back this string, the Content ID. And it is a cryptographic hash. By default it's Sha 2256, but you can use lots of different hash functions and all the rest. It's a very customizable piece of software. But the fundamental point is that this CID will always identify one specific piece of content and any changes to the content would produce a different CID.
02:31:57.260 - 02:32:31.916, Speaker A: So given a CID, you can say, hey network, please give me this data. And when it comes back from anybody, you can always verify that it's correct because you can compare it against the CID that you use to retrieve it. So this means that you don't need to really care who is providing the data or where they come from or anything. You don't need to know anything about them. As long as the protocol works, as long as somebody has the data and they see your request, they can provide it and you'll get it. And it's a pretty cool feature for linking to things, which we'll get into in just a second. So here's the requesting process.
02:32:31.916 - 02:33:06.010, Speaker A: Somebody requests the data by the CID, the original node responds, and now they both have a copy. And if a third node comes along asking for it, both of them can respond in parallel and say, oh, I have it. Here's a few pieces, guy on the left gives a few pieces, guy on the right gives a few pieces. And now you get the file potentially faster than you could downloading the whole thing from one. But there's lots of variables there with respect to latency and so on. So it's really hard to make absolute claims about performance characteristics versus other systems. But in general, there's potential for efficiency there.
02:33:06.010 - 02:33:37.010, Speaker A: So yeah, now this third node has it and as a result, they can also participate in the providing process. And that's great. The original node can go away, but the content is still there. And so we've kind of gotten close to this dream of content outliving us and our organizational guidance and so on. The data is still retrievable from other nodes. And that's kind of the power of peer to peer networking. No individual peer is blessed or special.
02:33:37.010 - 02:34:10.620, Speaker A: But there's some caveats to this approach. With IPFS, if all the nodes that had the content disappeared from the network, then there's nobody there to provide it. It's like an active process where your node needs to be online in order to respond to requests. And if no node is online with that content, it's just not resolvable. Although I should mention that the same is basically true of Http. Servers like Facebook.com were suddenly to be unresolvable, then nobody could access it.
02:34:10.620 - 02:35:21.716, Speaker A: But with IPFS you have kind of an interesting property where if anybody later adds the same content to the network, provided they use the same hashing algorithm and everything, then they'll come up with the same CID and any links to that original content will be resolvable. I guess like a third party can sort of fix a broken link in a way that they can't with Http. So that's kind of neat. But the second caveat is that there is an automatic garbage collection process for these ephemeral copies that get made as content propagates throughout the network. Each node will keep a little copy for a minute, but eventually they might get disk pressure and we'll have to clean up and throw stuff away. So to prevent that, there's a thing called pinning which is just signaling to your IPFS node please keep this alive, don't garbage collect your stuff. And this has been one of the main ways for people to, practically speaking, get their data into IPFS and made accessible is to use a pinning service that will provide this data for you on your behalf so you don't have to run your own infrastructure and so on.
02:35:21.716 - 02:36:33.816, Speaker A: And as we were looking at the NFT space and thinking about what can we contribute, we saw well we can make this process a little easier for people by basically more or less becoming a pinning service, but doing so using some of our other technology, namely FileCOMING, which we'll talk about in just a SEC. So the way we present this is as NFT Storage. This is a website it is free to use. You log in, you get an API token and then you can upload your stuff through us and where we provide it on IPFS. And also for long term storage, it's all getting sent to Filecoin. So the way this works is, yeah, you take your NFT, it's a very simple upload interface, it's just an Http request, there's a few different variations on that depending on what your needs are, which endpoint you might want to use. But then anyway, we get your data through some request and then NFT Storage is going to store it on an IPFS cluster that we manage and then we also redundantly store it with a third party provider just for safekeeping.
02:36:33.816 - 02:37:49.908, Speaker A: And behind the scenes though, we are also negotiating deals with Filecoin storage providers to store data for the long term and they're actually getting paid by the network in the form of block rewards, which is kind of an interesting sort of economic angle that we can talk about in a second. But for now the advantage of Filecoin is that it fits this property of allowing members of the network to disappear, but still giving you some. Solid assurances about your data. So now if NFT Storage were to go away completely, and all the IPFS nodes that we manage or that other people run, lost all the content, the data is still just there on filecoin, being continually challenged by the protocol to prove its existence. Basically in the worst case scenario where we just fold up shop completely and can't pay the bills anymore. Everybody has this sort of public verifiable escape hatch, as it were. Or a seed vault, maybe, is another way to think of it, where the data is preserved and it's just right there.
02:37:49.908 - 02:38:27.184, Speaker A: And we provide all the information for retrieving. It in our API and stuff. So to use it, you go to NFT Storage, which is a top level domain now, so that's cool. And it's really simple and free. And check it out, it's really Http API. It's not very big. The main endpoint is this upload endpoint for storing things, but there's also stuff for retrieving status information about your upload to who is storing it on filecoin and IPFS and so on.
02:38:27.184 - 02:39:25.152, Speaker A: So you can kind of get that granular information if you need it. And if you're in JavaScript, we have this JavaScript client that makes things a little simpler and will help you format data according to ERC 1155 standards. So if you are building an ESC 1155 contract or one that can be compatible with one with that, use this client store method and it will do some nice stuff for you. Basically you can give it a file object and it will add the file to IPFS and create a hash link for you in your metadata JSON. And then also it wraps the whole thing up into this thing called a Dag Seabore Graph. It's not super important what Dag Seabor is, but it's basically just a compact binary JSON object. But it's a nice way of addressing hash link data that we like to play with.
02:39:25.152 - 02:40:14.080, Speaker A: It's part of the IPLD project if you're interested. So I'm going to quickly just show you guys how to use NFT Storage and then we can talk a little bit about our other storage service here's, the site itself. And you log in with GitHub or email, it'll send you a magic link to click on. If I log into my profile, you'll see a few things I've stored, mostly just testing things out and so on. And we can go here and poke at a bit and get an API token that we can authenticate with. I should also mention that my home Internet is very slow, so things that are slow for me may not be slow for you when you're using them, especially when I'm uploading things. It's kind of sad.
02:40:14.080 - 02:40:55.600, Speaker A: But anyway, so here we are at the API keys, and I made this one a few minutes ago. You can make and delete them here and there's my key for later. I'll probably come back here in a minute. I've got an empty project or just an empty folder here with some images that maybe we could store on NFT storage. And let's make an NPM project to write some code. So if I do NPM in it and I just going to accept all the defaults. Now I have a package JSON file and I can say NPM install NFT storage that gets me the JavaScript client library.
02:40:55.600 - 02:42:15.940, Speaker A: Yeah, I'm also going to pull in a couple of other libraries once this is done to make building a simple little example app easier. So minimist is for pulling out command line arguments kind of nice and then Mime types for figuring out what kind of file you've got because the store function kind of likes you to provide it with a Mime type. And this method that formats according to ERC 1155 expects it to be an image file type when you provide it the image field, well, you can actually give it an MP4 now for compatibility with platforms that use videos in the image field. So anyhow, we have now installed some dependencies and head over to an editor and make ourselves a file. I'll call this index MJS. Something that's relatively new in Nodeland is if you name your file with a MJS extension or if you put type module in your package JSON, you can use import syntax, import NFT storage from NFT storage. I'll also pull in the file object since the API uses the file object that you would see in a web browser context.
02:42:15.940 - 02:43:07.370, Speaker A: And then it provides an implementation for node if you're working on node JS. So I can import that here. And then in order to read the file from my local disk, I'll import nodes FS module. So import FS from FS promises so I can use the Async await and we'll pull in Minimist that we installed earlier and my pipes. So that's all the stuff we'll need in a second. And let's do a function for storing an NFT. So let's just call this Async function store NFT and it'll take an image file name and then maybe a name and description metadata that we'll tag our NFT with.
02:43:07.370 - 02:44:05.592, Speaker A: So to do this we're going to make an NFT storage client and for that we'll need a token which I'm going to be a naughty boy and hard code into my source code. Obviously this is actually area that we'll be improving upon very shortly. Right now the best practice for protecting your API token for NFT storage is probably to have it interact with NFT storage from a backend service and spundling it into a purely decentralized DAP. Front end would expose it to the client. But we're working on solutions for that which would involve direct authentication through a wallet and using a decentralized identity and also sort of user scope tokens so that you can manage authorization on your user's behalf. I am mentioning this because it's just a common issue that we are heads down working on. So stay tuned.
02:44:05.592 - 02:45:14.256, Speaker A: In the meantime, I'm going to grab a token from here and paste it in here. So I've got that and now I can make a client. So I'll say const client is new NFT storage and you give it a token argument and now I can do stuff with it. But first I will need to read my file in so I can say file data equals FS read file sorry, I need to await this. Let's say sync and image file name and type is going to be Mime lookup image file name because it just pulls the file type from the file extension, not super fancy. And then we're going to say, okay, I have the data and the file type. So now I can make a file file object that takes an array of Blob parts which is basically just things that can be turned into binary data.
02:45:14.256 - 02:45:46.750, Speaker A: So the stuff we slurped up from our image file name here will fit that just fine. Actually. Let me see. Let me quickly make this bigger so everybody can this is a little easier to read. There we go. So I'm making a new file and I'm giving it the file data, the file name. We'll trim that down to just be the last part of the file path import base name.
02:45:46.750 - 02:46:45.196, Speaker A: Now you can say this is image file name. Okay. And then the last part of the file constructor is the optional arguments where you can pass in the Mime type. So we looked that up earlier and now we can pass it in and now we have a file object that I'm going to call this image because that's what the store method expects, image. Now this is a proper file that we can hand off to the client. So now I'm going to say I'm just going to return client store image name, description and there's a few other you can add optional properties if you want. You can have properties with any key value stuff you want in there for custom use case, which if you are doing the ERC 1155.
02:46:45.196 - 02:47:24.200, Speaker A: We do recommend sticking custom properties in properties if you can just because it makes it easier. We're trying to beat the drum of standardization a little bit. Having been on the receiving end. We're also scraping ethereum chains and finding all kinds of NFTs in the wild to kind of see what people are doing. There's a lot of interesting metadata variations out there but at any rate, now we have this and we can say we can call it. So let's make up a main function name. And this is where we can grab our command line ARGs.
02:47:24.200 - 02:48:07.640, Speaker A: We don't need this complete getting even dirty. ARGs equals minimist and for this you pass in the process argument. So process argv pull off the first two for node reasons. And now minimist is kind of simple. It's just like it takes whatever arguments it gets and parses them out and gives you a dictionary or JS object rather. So now I'm going to just assert that you gave me the right stuff. So we want there to be an image, a name and description.
02:48:07.640 - 02:49:22.210, Speaker A: So if there's no image, complain. This may be a little fussy for live coding, but still, I mean, error handling is important. We'll let the description be optional, I guess. So then we'll say pull them out of this object and then pass them to the store NFT function. So image here's the image file name and we can just toss that over here and say metadata equals await store NFT and then give it the image file name, name and description. And now let's log it to the console and see what happens. All right, so now if I call main function, we should be able to call this thing as a node script and see what we see.
02:49:22.210 - 02:50:16.616, Speaker A: Here we go. If I do node index JS and then say image, I can give it images and we name. I probably should have added a little console log saying, hey, we're doing a thing now. But there it goes, it's already done. So what happens? The result you get back at this is you have an IPFS URL, which is in the IPFS format. If you want, you can pretty easily turn this into an Http gateway URL. So this part here is the CID, and then there's a file path.
02:50:16.616 - 02:51:37.930, Speaker A: So if I wanted to make a gateway URL out of this, I can say CID, sorry, copying things accidentally here CID IPFS DWeb link. There's lots of other gateways, but that's the one that sticks in my head and then add the file path at the end. So I'll show you what that looks like real quick. If I do CID IPFS D web link metadata JSON I spelled that wrong. The metadata, yeah, there's basically a little bundle, it makes a little graph structure for you and then you can traverse that graph using this pathing syntax. But basically it's just yeah, there's the metadata that we stored and you can see here, if it's big enough, that the image field has this same IPFS reference to the image itself. So make another gateway link and pull it out.
02:51:37.930 - 02:52:46.540, Speaker A: If you have brave installed it'll, follow these links automatically. But I for some reason didn't think to use it for this demo well link. So that will chase out the image itself. If you want a sort of machine readable or traversible form of this without having to parse links and so on, that wrapper object, like the root object of this graph, where if you just have the CID without the metadata JSON. It's actually that Dag Seabore thing I was talking about earlier, where you can fetch this object and then use our IPLD tooling to traverse into the metadata and find the image itself and sort of all bundled into this graph. Not sure why this is taking so long to resolve, but I blame my terrible internet. We'll see.
02:52:46.540 - 02:53:38.010, Speaker A: Anyway, let's maybe take a break from all this stuff and we'll talk about Web Three storage. We'll come back and hopefully it will have loaded by then. All right, there's something I want to mention before we get onto Web three storage, which is that we have this thing called there's a format called Car, which is a content archive. And you can send us content archives if you want to pre format your IPFS data, like if you have specific layout that you want, or also if you want to send big files over 100 megabytes. I should mention too that we're going to be doing this for you automatically soon. So may not have to do it yourself, but it's kind of nice to understand what's going on under the scene. So you have a mental model what's working.
02:53:38.010 - 02:54:26.060, Speaker A: So the advantage of using a car is that you can know the CID before you upload, so you're not waiting on our server to tell you what the Identifier is and you can verify that it's correct, that we're storing exactly what you're giving us. And like I said, it's Chunkable and you can split the cars into chunks here. So I have one big graph and I can split it into little graphs that all have the same route and our back end will piece them all together for you. And yeah, that's pretty cool. So I'll talk a little bit more about cars in a second because we have this other service and I'm quickly running low on time so I should get into the weeds of Web Three Storage. It works very much like NFT storage, especially under the hood. They are very similar.
02:54:26.060 - 02:55:28.458, Speaker A: If you remember this slide from before, it's the same thing but for non NFT data. Essentially any data that you have that you want to be stored on IPFS and filecoin, you can just upload through Web Three Storage and we will store it for you and it has the cars baked in. This will be coming to NFT Storage soon. But right now Web Three Storage has it already in the JavaScript client where essentially you give it a file of any size and it will create the Car file for you and do the chunking and send everything off and it gives you access to the root CID as soon as we compute it on the client. So you can display it in your UI and say, oh, here's the thing now in parallel, send it off to Web Three Storage and it'll get stored for you and you get progress callbacks and stuff like that. Very briefly here's kind of what the architecture looks. I'm not going to talk a bunch about it, but there's some cloud workers, we maintain some state in a database.
02:55:28.458 - 02:56:15.360, Speaker A: But then the interesting bit is the storage broker service. It will take your data and batch it up into, I think we usually do 32 gigabyte chunks and store those each with a filecoin provider since that's the most efficient format for getting data directly into a filecoin sort of pipeline. But parallel to that, we've already added it to our IPFS cluster and to a redundant pinata cluster. So it's available for retrieval pretty much as soon as you upload. But then there's maybe I think we're at like 18 hours now in terms of delay for getting it onto filecoin. I'm sorry, it might actually be eight, but I have to actually ask people what the real number is. Sorry, but it is a few hours because we have this aggregation process going on.
02:56:15.360 - 02:57:41.546, Speaker A: But as a result of this, by meeting the miners where they are, the storage providers as we're calling them, we are able to offer the service for free. So here's something that comes up a lot when we talk about the service is like how is this free? And it basically is because the primary economic driver for filecoin providers right now is block rewards. So they get rewarded first for committing capacity to the network. So if you bring drives online and to the network and prove that you've done so, then you get potential block rewards relative to your overall storage power, the capacity that you're adding. But if you are storing real data, boom, you get a ten x multiplier, basically. And the way that this works is that there's a system called Filecoin Plus in which a notary allocates this resource called Data Cap, and Data Cap essentially is sort of like a voucher that says we believe this is real data and not just some random garbage that somebody generated to pump up their numbers, I guess. So the idea is that by flowing your data through web3 storage and NFT storage, we have a reasonable assurance that you're a real person or that there's a real sort of social need behind the data.
02:57:41.546 - 02:58:32.234, Speaker A: That's kind of what we're getting at because fundamentally our mission is data preservation and all that. So anyway, verified data increases the chance of block rewards by ten x and so as a result it's the actual cost of storing the data and there's some collateral that the providers put up front to ensure that they're going to store it. That is all basically kind of negligible compared to the increased reward. So it works out for them to provide long term storage for free and so we're not charging users anything for storage as well. There's a minimal operational cost to us to keep the IPFS side of things running, but that's in the grand scheme not a big deal and we're super into providing it to make things easier for people. So that's what I got. Thanks very much.
02:58:32.234 - 02:59:20.118, Speaker A: And if anybody has questions, please let me know. So that was awesome. Also, nice recovery I feel like we're going to go over time, but this worked out. Yeah, totally. Fold it in, I think two kind of common questions, one actually already addressed, which was the nuance between Web Three and NFT Storage, just the formatting and the Car archive formats. A common question that I think we get, especially during the hackathon, is what are some best practices that you recommend? When people want to think about storing metadata or even updating it, how do we think about that? How does NFT storage of Kind come in handy for these types of things? And I want to question into what's next after this. Is this done? Is this a great service you're offering it? It works.
02:59:20.118 - 03:00:20.154, Speaker A: How do you actually improve this thing or what are future mean? So there are some reliability things that we want to bake in. Right now we're doing a database migration that should make everything faster and more solid. But feature wise, I think those two questions are kind of related. Where, right now? Especially Michael and Ghazala. I don't know if you guys have met them yet, but they are heads down trying to figure out a sort of a workable plan for extensible NFTs. Or not exactly mutating, but keeping track of assertions about an NFT over time. The way that we kind of see that happening now is using events to send out basically entity out value triples, where you would say like the entity is an identifier for the NFT itself and then an attribute is some assertion about it, like it has an alternate representation here or it was remixed into something.
03:00:20.154 - 03:01:20.334, Speaker A: You'd imagine lots of scenarios but then eventually you fold those into you basically compact a big log and then you have a view of the evolved NFT over time. But that's all kind of speculative right now. We're still trying to figure out how practical can we make this and also is this something that requires a lot of buy in from people up front or is there a way we can kind of apply this to NFTs that already exist? I think that there is, but there's a lot of details there. So I think that that's kind of where our focus is. NFT wise right now for NFT Storage is to try to figure I'm not sure if it'll actually come through NFT Storage directly, but I mean, we will port it there. But I think that that's kind of a broader effort of trying to figure out what the data model should look like in terms of the actual experience of using it. Right now we have two separate services and we're going to end up making NFT Storage a client of Web Three storage just for less stuff for us to manage and for the token management stuff is the big feature that's going to be coming to both platforms soon.
03:01:20.334 - 03:01:58.666, Speaker A: I think there'll be a way to have a sort of admin token that you can then create a user scope token and then users will be able to manage and delete their own stuff without having access to anybody else's. But then we're also going to have a fully decentralized path of using a decentralized Identifier document to assert ownership of a key. And then that gets you we just want to know that be able to identify you somehow. We don't have to know who exactly specifically you are. So we're building that out and should be coming. I mean, I can't promise timelines, but awesome. Well, the IDs do sound pretty incredible here.
03:01:58.666 - 03:02:18.062, Speaker A: That's great. Well, I think that's all the time we have today. Thank you so much for doing that presentation. And also yeah, thanks. That was great, but perfect. So with that, we are ready to move on to our next talk. And next up we have Chris, and Chris is going to talk about SDK and how to make development a lot more pleasurable.
03:02:18.062 - 03:02:52.094, Speaker A: So without further ado, welcome. Hello. Let me share my screen. Okay, I think it works now. So hello. Yes, my name is Chris Kachog and during the day I work as a software engineer for MakerDAO, working particularly on L2 stuff. And during the night I'm part of Dev Organization, where we're trying to make Ethereum developer experience better.
03:02:52.094 - 03:03:34.646, Speaker A: Today I want to talk about if SDK a new this is actually award premiere. So guys, free Alpha Incoming, a new tool that is a generator of lightweight and typesafe SDKs for Ethereum smart contracts. And I'm going to unpack this in a bit. Now let's talk a little bit about the Ethereum dev landscape and how it evolved. So if you were using Ethereum a few years ago, everyone was using web free JS and it was pretty raw. It didn't even support premises back then. These days iterative JS is a king.
03:03:34.646 - 03:04:14.550, Speaker A: Similar thing happened to Truffle and Hardhut. And I'd like to point out a more profound change, which is a change in language that we use. A couple of years ago, everyone was using JavaScript. Now more and more people use TypeScript. And not only blockchain community like, you can see this rise of TypeScript everywhere. And some time ago you could think about TypeScript as some kind of add on to JavaScript. These days, TypeScript is more popular than full fledged programming languages like Ruby.
03:04:14.550 - 03:05:17.370, Speaker A: Now these days a lot of libraries were rewritten in TypeScript. So for example, Ethersjs, it's written in TypeScript already. As Richard mentioned, it's going to be even better supporting TypeScript soon. But still, in some sense, web free JS with TypeScript is broken and it breaks exactly in the moment when you start interacting with smart contracts deployed on Ethereum. The problem is that to interact with a smart contract you need an API. And this is a piece of dynamic piece of JSON JavaScript that you basically inject into your blockchain access library and then you get some sort of object created during runtime that can talk with the smart contract. And the problem is that you cannot prepare typings to this in a usual way.
03:05:17.370 - 03:06:23.898, Speaker A: And I recognized all of these issues some time ago like the rising popularity of TypeScript and the problems related to webfree interface word and created a tool called Typechain. So Typechain takes your JSON APIs files and takes information about your target. So do you use traffic? Do you use Ethers maybe web3 JS and it generates TypeScript typings as a separate build step. So this way you have excellent ID support. You can just browse through the methods that are available on the smart contract. We support as well nut spec that was already mentioned during this dev summit. As I mentioned, it supports officially many different targets ethereus JS v four, v five, WebView JS truffle.
03:06:23.898 - 03:07:20.098, Speaker A: But recently we also added support for Hard Hat which is kind of great. Like if you use Hearthat you should totally give it a try. It's typing things like get contract add and so on. And I feel like does accomplished a lot like a lot of well known companies like Uniswap Maker. Obviously optimism uses it, but it makes interaction with Smart Contracts a breeze. But it doesn't solve all of the problems that web3 developer can encounter, especially during setting up the scene for Smart contract development, for smart contract interaction rather. So you can imagine that the typical day in the web free developer life looks more or less like this.
03:07:20.098 - 03:08:16.120, Speaker A: Imagine that you get a new assignment to write some kind of script that gathers data or reads some events from multiple smart contracts. Or maybe you're developing a front end or back end, it doesn't matter. First of all, what you probably do is you gather Smart Contract addresses and maybe use it scan for that. Maybe you browse and you just type in Etherscan search to find the addresses, maybe use GitHub or docs of a given project to find all the addresses. But then you need to find APIs. Maybe if you're lucky you can find the APIs somewhere on the GitHub. But then you need to wire APIs with the addresses in code like create Ethersjs Contract Wrappers or something similar.
03:08:16.120 - 03:09:36.686, Speaker A: Then you need to generate typings if you want to have good developer experience and type competition. And only then you can start actual work. So if SDK tries to make this ceremony much more easier and enable rapid Smart contract to enable rapid interaction with smart contracts so I like to think about it is a love child of Ethersjs typechain and talk is cheap. So let's go and try to use it in a Hard Hat demo. So here's a boilerplate code for Hard Hat example, and this is a very simple code that it's configured to fork Mainet from a particular block and we can start writing code. Note that there are no useful contracts here. We're going to interact with Mainet contracts and the only reason we use hardcut is for fork features and what we want to do here.
03:09:36.686 - 03:11:21.912, Speaker A: Imagine that it's I guess one week ago and compound hack just happened and you're a white hat or just person curious and you want to realize what happened. You don't know too much about compound smart contracts but you still have addresses of the contracts and you want to dive right into it and try to play with it, try to reproduce the original claim that caused like minting a lot of comp tokens and try to play with the whole setup. So usually now you would start dumping APIs in your code and so on and so on and it would take you some time. But now we can use If SDK and to do that we can go right to the GitHub and grab a command to install it it's to the dependencies and once it's installed we can use it right now. So first of all we need to create a config file so If SDK will read all contract information from contracts JSON config file. So in this file we define all of the contracts that we want to interact with and I already have this piece of code ready to copy so let me just dump it. Yeah.
03:11:21.912 - 03:12:39.296, Speaker A: So first we need to specify a network that we want to interact with. Here it's Mainet and then we can start writing arbitrary nested list of smart contracts. So we can have this namespaces like tokens but at the end of the day is name of a smart contract and address that it lives on the particular network and we do the same for other compound smart contracts like comptroller which is responsible for dealing out the rewards. It's a proxy so it has comptroller implementation and the treasury. So there's another interesting bit about this attack and that's why we need treasury now. It's the moment when we can actually run If SDK and see what happens. So now it read config file and it's getting APIs automatically and it's generating client and notice that client was generated directly to node modules and now we're good to go to start interacting with the smart contracts that we defined.
03:12:39.296 - 03:13:43.928, Speaker A: So let me import the SDK. So this is the If SDK client package and we have get Mainet SDK and this function is tailored based on the config that we just created. So here we're going to call it and we're going to pass signer and you can see that it matches the shape of this object matches exactly the shape of a config file. And if we go inside we see that there are a bunch of typings and in the runtime these are ITER JS contracts that are already configured to be used. So the interesting bit about the compound attack was that there was a treasury contract that could be used to drip even more compound tokens into treasury. So. Just to test that, let's actually test first the Drip function.
03:13:43.928 - 03:14:39.364, Speaker A: So we're going to add some logging here, let's say before Drip. And we're going to call some methods. So we're going to check the balance of comp token on the comptroller address. So if Drip function works correctly, we should see that the balance was increased. We need some formatting and we need to import this function. Okay, now we can call Drip function and notice that I'm not an expert in compound contracts, but thanks to type competition, I can write my code pretty quickly. And here again, I forgot to handle promise.
03:14:39.364 - 03:15:50.816, Speaker A: But since everything is typed correctly, I got immediately an error in my idea about this. So now we're calling Drip function and after Drip, this balance should increase if Drip works correctly. So here I have a script to execute the code that we just developed. And yes, we can see that Drip is causing a lot of new comp tokens available. Now we can try to replay what original, maybe not attacker, but the original claimer did. So we want to claim tokens and receive much more rewards than we should receive, right? So again, we're going to print out balance, but this time before claim and we're going to print out balance of the EOA that we're interested in. Now we can call.
03:15:50.816 - 03:16:50.500, Speaker A: So there's another thing that we need to actually initialize comptroller because it's just a proxy. So we need to take the implementation and attach it to the comptroller address. Okay, with this we can do claim and notice that there are a bunch of overloads. But this is the one that we're interested in. The holder is again, our EOA and C tokens is the list of citokens that the rogue claimer claimed. And finally we can print out the balance again of the EOA. So if things go well, we should see like this claim causing a lot of rewards to be sent to the UA.
03:16:50.500 - 03:17:42.962, Speaker A: Let me run it again. It's a little bit slow because it's fork mode. But yes, we can see that there was a bunch of comp reward sent to the user. I don't know, we can play a little bit with this code. But what I wanted to present here is that we were able to start interacting with a system that we know almost nothing about and write a script that does something meaningful very quickly. It's funny because if SDK wasn't ready really one week ago, as I told you, it's a word premiere and I was writing similar code and I made a typo while copying one of the addresses. And I was interacting using the wrong API to the wrong address.
03:17:42.962 - 03:18:35.110, Speaker A: And I spent like half of an hour trying to debug it. So with If SDK, it's all very simple to code. Now, continuing my presentation. So as you could see, if SDK generates this lightweight typesafe ready to use SDKs, it works for different networks. We care about the network config because we need to have a way to connect to Etherscan and get verified contracts for this particular network. So that's why we support Xpcd, at least of networks, but it's pretty long, including things like optimus mainnet. We generate SDKs directly to node modules.
03:18:35.110 - 03:20:05.886, Speaker A: So if you're familiar with Prisma, this is exactly the same approach. I think it's quite nice because the import paths are always the same and they are short. And as I said, it's perfect for writing any scripts, one time scripts or front ends or backends diving a little bit more into details. APIs that we gathered are stored in the if SDK APIs directory and this directory should be actually committed to the Git repository to avoid querying contracts again when you execute if SDK again. Another trick is that you could add executing if SDK as a post install script. So it's much easier to use because you always need to generate the client code. Client creation is a little bit complicated because first we generate TypeScript code, we generate typings, and only then we run TypeScript compiler to get JavaScript code that we can easily place in the node modules directory and Node Modules insertion I already mentioned.
03:20:05.886 - 03:21:09.758, Speaker A: So what are the future plans? So we would like to have a first class support for Hardcut. So right now you saw it's quite an opinionated tool. If it comes to what you're using, you could use it with whatever you want, but we can improve the integration for some of the frameworks. So for example, for Hardhat we could register the APIs so Hard hat knows more about them and can print meaningful error messages and so on. We would love to integrate if SDK with used app that Mark mentioned today and the bit that I didn't like during demo. You could notice that users are forced right now to reconnect proxy with implementation. So we could also automatically query proxies to get always the valid implementation.
03:21:09.758 - 03:22:07.746, Speaker A: So if we recognize that a given contract is a proxy, we can always query implementation and then query API for this implementation and then merge this API. So this would be, I think, a pretty nice feature for end users. Finally, we are planning on supporting alternative API sources. So sourceify was mentioned here today already and I think it's an excellent tool that we should integrate with because Etherscan is pretty great. But it's a closed source for profit company, so it's always nice to have a decentralized alternative. And then we're thinking about supporting dynamic addresses, for example for local network, when you can provide them by hand and just enjoy the typed shell and that's it more or less. You should join our discord.
03:22:07.746 - 03:22:48.798, Speaker A: So at Dev, we're focused on improving Ethereum developer experience. There's a couple of people involved in the organization here are social media, and I'm open to any questions right now. Thank you. Thanks so much, Chris. No this is really great. I think kind of a couple of questions. The first one is, just as a confirmation, are you getting the Abis from Etherscan or somewhere else? And how does that work? Yeah, so I think I answered it at the end, but yeah, right now we use Ether scan API.
03:22:48.798 - 03:23:54.454, Speaker A: There's actually a key hard coded somewhere deep in If SDK. So I hope you guys don't do and but yeah, the better idea would be to use Sourceify or at least have some multiple backends. But for now, Etherscan was a way to go. No, that makes a lot of sense. And I think one super cool part of this is that so many talks today, they're all interconnected and they're just helping basically modularize each other. So it's just great that I saw you step historic and everything here. I know you already touched on this thing, but what are some of the feature things that you're trying to integrate or add features for? And how do you think this will evolve over the next six to twelve months? Yeah, so I think a single biggest feature that we're looking at is integration with other libraries tools in the ecosystem, particularly the ones that you would use on front end.
03:23:54.454 - 03:24:46.902, Speaker A: So Magek was showing today, Used Up, and Used Up is great, but if you were paying attention, you would notice that smart contract interactions right now at Used Up is totally untyped. Right. I bet that the whole thing is written in TypeScript. But again, as I mentioned at the beginning, interacting with smart contracts is a little bit more difficult. So we would like to integrate with tools to provide this first class support for typed smart contracts. And it's not something that you do. The reason why we're doing is that because it saves you time in the longer term.
03:24:46.902 - 03:25:29.698, Speaker A: Right. Like now, these days, if I write some code without having type information and basically guessing, I need to go again to check the documentation or check the source code of the smart contract, to double check the arguments or whatever. Having all of this in the ID is just a game changer and it makes writing code so much faster and debugging. And that's just the best. Yeah. And this bit, like last thing, this bit that you could see that I forgot about Await in one place. And you could literally spot it right there and just say, hey, you forget Await.
03:25:29.698 - 03:26:32.650, Speaker A: This is exactly the thing that we are missing when coding just in JavaScript. Absolutely. And then just kind of lastly to close, are there some immediate things that people can help with in terms of contributing to the project directly or how is that structured and how can people get involved? Yeah, so I would encourage all of you to just jump on a discord channel. And it's a very fresh channel, so not so much going on there now, but this would be a perfect place to try to coordinate. And if SDK is in quite experimental stage right now, where we're just trying to figure out what's the best way, for example, to define the config or to define some other things, like, I don't know, the CLI interface on. So I would encourage anyone to just drop us some feedback and so on. Awesome.
03:26:32.650 - 03:26:56.100, Speaker A: Well, hopefully that was helpful for everybody, too. And it's a good reminder for everybody to join the discord and make it more lively. Chris, thank you so much for that amazing demo and presentation and can't wait to myself, use Ethsdk and have others try it out, too. Thank you. Amazing. All right, with that, we are ready for our next panel, which is something I'm super excited about. We're going to be just talking about smart contract security.
03:26:56.100 - 03:27:23.130, Speaker A: And for this panel, we have Sam Sazan, Nikesh, Rajiv, and Moralian on stage. And Marillian will be facilitating this discussion. So I'll let him ask all the panelists to introduce themselves instead of me doing the whole thing and making it more fun. So I'll hand this off to him and welcome everybody on stage. Hi, everyone. Yeah. Thanks, Karthik.
03:27:23.130 - 03:27:37.774, Speaker A: I'm Morelian. And let's do some intros. So, Nikesh, why don't you start us off and then Sam and Rajiv perfect. Yeah. Thanks. It's great to be here. Yeah.
03:27:37.774 - 03:28:12.170, Speaker A: So my background is in I actually did physics and computer science. At some point before the times before I joined the blockchain space, I was pottering around in a bit of cryptography, a little bit of reverse engineering, just general It security type things. But for the last two and a half years, I've been working at Openzeplan as a security researcher. So basically we do audits and research and trying to improve the security of the space, protect the open economy, as you say. I guess that's my broad outline. Thank you, Sam. Cool.
03:28:12.170 - 03:28:30.110, Speaker A: Hey, guys, I'm Sam. I'm a research partner at Paradigm, and I do, you know, finding bugs. Mostly just finding bugs. That's about it. That's basically all I do. Yeah. Rajiv.
03:28:30.110 - 03:29:01.900, Speaker A: Hey, everyone, I'm Rajiv. I'm the founder of Securium, which is a recent initiative to further improve the state of security of Ethereum applications. And Secureum is currently running the bootcamp on smart contract security auditing that's funded by an Ethereum Foundation grant and sponsor partnerships from Consensus Diligence, Sigma Prime and Taylor Pits. So here I am. Thanks. Great. Okay.
03:29:01.900 - 03:30:25.110, Speaker A: By way of introduction, I was one of the original members of Consensus Diligence and am now working at Optimism focusing on protocol development and security issues. And so I'm really excited to be doing this panel. So given that East Global, that this conference is really focused on Tooling, which I think is a really exciting topic, and this group is really security focused, I think it'd be great to kind of will move this conversation along. Kind of like balanced on the knife's edge between Tooling and security, of which there's a good amount of overlap. So, having done that, I think a good place to start would be just we can each provide a little bit of context about the way we approach tooling, where it fits in our day to day roles, what we're looking for when we're choosing what tools to include in our toolboxes, if you will. And if anything, maybe tools that you might have built in the past as well. Nikesh.
03:30:25.110 - 03:31:05.006, Speaker A: Fair enough. Yeah. So actually, as mentioned just before we started this, that my day to day work is pretty sparse with tools. So a lot of what I'm doing is just reading code and then trying to understand it deeply. I think we have a bit of a bias that way that we think a lot of the value we provide is just a security engineer taking the time to deeply understand code and then trying to match the knowledge to the particular task at hand. But I was saying I do think a lot of the tools that I find are useful are just things that avoid distractions. I have really good notetaking tools, for instance, to help me keep track of what I'm doing as I'm reviewing.
03:31:05.006 - 03:31:46.746, Speaker A: We can talk a bit some of those, if you're interested. Or the fact that I have in the past, if I needed to understand a line of solidity, I would launch Remix and then try and write it in there, which was a huge waste of time. But now I've got this solidity REPL which just connects to a local Ganache CLI in itself. The whole point of tool is just so that I can stop thinking about it. So I have a thought in my head, like, what does this line of solidity do? I quickly go and do that and then get back to what I was attempting to do before, which was just understanding the system. But I think a lot of it really depends on what you're attempting to do. Maybe just being a security auditor, there's a particular style that we follow which is just trying to understand contracts deeply.
03:31:46.746 - 03:32:18.214, Speaker A: But of course there are different approaches to security all over the space and I'm imagining there'll be several tools that will be useful in other places. I might leave it there for now. Pass it over to you. Yeah, I mean, I can jump in here. I think I mostly agree. When I'm doing audits reviews, I tend to actually stay away from a lot of the automated scanners. I find that I'm going to end up going through and reviewing the contracts anyways.
03:32:18.214 - 03:32:49.438, Speaker A: And so for me at least, there isn't really much benefit that those scatters bring. However, that being said, I do find value in tools elsewhere. Like for example, when I'm reviewing some contract on mainnet, sometimes I need to figure out what's in a particular storage slot or what happens if some function is called. In the past, I would pull up DevTools and Web three ETH gets storage at. And it worked. It was very ugly, but it worked. Nowadays I actually just use Seth for that from the Daptools package.
03:32:49.438 - 03:33:33.406, Speaker A: So here we go. We're three minutes in and already someone has showed Daptools. Let's see where else this goes. Yeah, it's funny, I kind of got off Twitter for a lot of the summer and then I came back and everyone's like talking about Daptools, which has been around forever. Where did that come from? What is it like? What flipped there that everybody wants to talk about Daptools all of a sudden? I actually think it might just be trans. Like you learn about a bunch of these things because they're happening on Twitter and then everybody else learns about them because they're happening on Twitter. And I think a lot of the security community is relatively small and a lot of the value is just like knowing what other people in the community are doing.
03:33:33.406 - 03:33:53.478, Speaker A: You hear that? I get to read a blog that Samsung's written and then I learned something new because of that fact. And I think it's just like access to the community. You'll end up doing whatever else they're doing. That's my instinct. But I don't know, I can't speak for why other people do what they mean. It's really cool. Martin and the team at Tools have been working so hard for so long.
03:33:53.478 - 03:34:30.542, Speaker A: It's nice to see them getting some traction like that, but please go. I mean, I might be the OD man out. I haven't used app tools, so please excuse me for that. I'm going to actually try to do that over the weekend. But yeah, from a Tooling perspective, I think the points made are valid. The way I see it, I do see tooling in the space of Ethereum security as maybe focused on developers and maybe a separate set of tools that are focused on auditors. And today I think there is a good overlap.
03:34:30.542 - 03:35:11.620, Speaker A: So a lot of the auditors, like Sam was saying, you just are in the space. You're looking at contracts and predominantly there's a lot of manual analysis. So the ROI that you would get from any of the automated tools is maybe not that much on a day to day basis. Maybe there are some special use cases for that. But for developers, I think there is a lot of value, be it any of the static analysis tools like Slither or the Mythx or any of those, there's a lot of value to that. So I do see that sort of dichotomy. Maybe that gets blurred sometimes.
03:35:11.620 - 03:35:52.942, Speaker A: But as for me, when I review contracts, I do fall back on magnet analysis. So the tool that I use there is usually the Serenity Visual Developer plugin, which really helps me navigate the code. Very cool. That stuff for Vs IDE score by my old friends at Diligence. Yeah, tinted web. So that's fantastic. And I do tend to use Slither now and then to just get me some good starting points, to just get some sanity checks going.
03:35:52.942 - 03:36:45.758, Speaker A: And in the past, I've actually contributed several detectors to the development of Slither. So that's my general perception on tooling. Yeah. The pattern I'm sensing here, I think, is as auditors, it's very different from developers. As a developer, you live in one code base and you are there all the time. And you joined this company or project and they gave you a couple of weeks to ramp up the amount of time that is kind of like the training period for someone at a new company is kind of like how long you have for an audit, I think. So what security researchers at ours are doing is just really trying to understand the code as quickly as possible.
03:36:45.758 - 03:38:13.770, Speaker A: And so I think that there seems like the pattern is that you're sort of like a bit more less of just point and shoot scanner approach and more of a marriage of, say, human and automation to get deeper understanding. And I think that's where you see the visualization tools, the graphing, those kinds of things becoming very popular for auditors. But so, I mean, you guys also see a lot of different code bases, I imagine. Do you see patterns of tools? And so you have opinions about teams and code bases and which ones are good and which ones you love less. And we don't have to talk about names, but do you see patterns of tools that the teams you think are on the right track are using in their development process? I guess my advice is whenever I see teams using the team that I have in mind at the moment, they do all of their pull requests out in the open, and then they answer their questions and they have security questions. Quite often I'll be reviewing code, and then I'll go look at the pull requests that they made or some of the commits, and I get to see all their comments and their thought process behind it. All of that stuff is really useful.
03:38:13.770 - 03:39:00.742, Speaker A: It seems to be correlated with a lot of the continuous integration tools that they use. Because I'm not a developer. I can't say exactly how related these things are, but I think there's probably some level of professionalism when you've reached the point where you take just development seriously, and then you make sure that there are two people reviewing every like all your there's always someone who reviews all your code and then you're going through the process correctly. That does seem to be at least correlated, in my mind, with people who take security seriously as well. And just maybe riffing a little bit on what Rajiv was saying. I think a lot of clients will actually use some of these tools before they reach an audit. And it's like a good way to find your own bugs first in your own code before you actually take the time and effort to go and get it audited.
03:39:00.742 - 03:39:56.394, Speaker A: So I guess that's my initial instinct. I'm not recommending a particular tool other than just noting the level of professionalism does seem to correlate somewhat with the level of security analysis, maybe you might say. So GitHub or git and the code collaboration tools in general that just enable people to ask each other hard questions about what they're trying to merge. Right. So I guess everybody is using GitHub, but then some of them are just like pushing to master directly and some people are making pull requests with reviews and that's the sort of way that I reviewing pull requests. Is a high bar or like an indicator or something maybe? I think it depends on the detail. I'm thinking I am speaking, sorry.
03:39:56.394 - 03:40:13.602, Speaker A: My point is that it's crazy that anybody's not doing that. I think it's just what I'm getting at. Okay. Yeah, I think my instinct is really more about how much effort they put into reviewing pull requests. There's obviously different degrees of how seriously you take that sort of thing. Certainly. Yeah.
03:40:13.602 - 03:41:29.658, Speaker A: Okay. I think maybe even if it's not the focus for anyone here, I'm curious what, if any impressions you have about the potential there is among the more advanced tooling. So, static analysis, I think running Slither is a really good just like it points out a lot of stuff, a lot of code smells. That's the static analysis tool. Then I think fuzing, there's a variety of good fuzzers out there that are maybe the next step to look at or all symbolic execution tools. Do you have a sense, do you have a feeling about where we are at with those? Have you seen sort of like output from them and found that useful? Or is it just usually just a list of findings that don't really give you joy? I mean, I can jump in, but I feel like I might be monopolizing this a little bit. So I'm anxious about that.
03:41:29.658 - 03:42:23.994, Speaker A: Certainly. Feel free to interrupt, Sam and well, you told us in Chat, but Sam, just tell us what you said about everything not in mean, I guess maybe I'm not connecting the dots here in Chat. I just said I'll pass on the question because when I'm reviewing code or a project, I basically ignore everything that's not in contracts. And I guess to even be more specific, I ignore everything that's inside tests as well. Because personally, unless the code is so confusing as to I'm not sure what the correct behavior is, there's really no point in me checking the test. I think it's just a waste of time. But actually on the topic of fuzzing, I once again will start Georgio's has been like one of the major drivers behind the Daptools Shilling, I think.
03:42:23.994 - 03:43:30.958, Speaker A: And now it's rubbed off onto me. So I will now Shill Daptools again because you did this presentation internally at Paradigm where you showed off the Fuzzing and property testing that you can do with DAP and it's actually kind of obviously you have Echidna and MetaCore and I think Mythx does Fuzzing too, right? Am I misremembering? Yeah. And you can do Fuzzing and property testing with them. You can go more advanced, I'm sure, but it's always felt sort of inaccessible, I feel like it's always seemed like this hurdle to overcome to figure out how to use these tools. And the interesting thing with Daptools is they've taken a very similar approach to how Go does it which is you just write a function in solidity like maybe right beside your actual code itself and you just put in as parameters to the function the things you want the fuzzer to explore and that's all you need to do. And the rest is just handled for you, just run the command. So I think that's actually really awesome.
03:43:30.958 - 03:44:33.574, Speaker A: And hopefully as more and more people find out about this through the nonstop shilling that happens everywhere, maybe we'll see more and more usage of Fuzzing and property testing. So to clarify, what I think I understand is it looks a lot like a typical test suite, but instead of saying transfer one token to Sam, I'd say transfer X tokens to somebody and that's all I do. I leave that open and the Fuzzer takes it from there. Yeah, pretty much. If you had a function that did some complex math to figure out the returns for some exchange, right. You could treat it as a black box. It takes some UN 256 as input and returns some UN 256 as output, and you could just tell the Fuzzer, I just care about this UN 256 input and then assert on the next line like the output is same, right? And the Fuzzer takes care of the rest.
03:44:33.574 - 03:45:40.650, Speaker A: It's just that magical. For anyone not really aware of what Fuzz testing is, it's basically that instead of writing one test at a time, it's tools that generate ideally millions of test cases and sometimes can be quite sophisticated about speaking from diligence for some reason. The Fuzer there is called Harvey. And that's not really like a product name, it's just the internal name. But Harvey, it tracks where it's been in the bytecode and when it bounces off a require statement or an if branch multiple times, it does solving to try and say, okay, I almost got this if else branch to flip so that I could get into that. And it tries to figure out the math so that I actually can trigger that, which is not an easy problem. And I think that that is.
03:45:40.650 - 03:47:10.406, Speaker A: I actually was just looking it was about a month ago that I think they've really shifted the focus from Mythx over to just Fuzzing and doing more Fuzzing as a service. And there's also like I'm really interested in what we were working on there, which is this tool called Scribble which allows you to write basically nat spec formatted comments which will then you recompile the solidity and it adds all these assert statements that allow you to describe specifically the failure cases. It was still coming along as far as sort of usability, but I think I'm due to check it out again. Go ahead, Rujief. Yeah, I think two critical points that were made, right? One of them is as maybe security researchers who are deeply into this space, we focus a lot on the effectiveness of tools, understandably so how accurate it is, false positives, all that make a big difference. We also focus a lot on the efficiency of tools. And the second part actually leads to the usability aspect of the tool itself that I believe oftentimes is not because if you're deep in the weeds, then if we are developing and if it's all open source, then we are using it.
03:47:10.406 - 03:48:48.162, Speaker A: So we really don't appreciate how deep we are. And if that same tool is actually expected to be used by the developers of protocols, like you said, may have like a week or two to actually look at this tool, then that barrier I think becomes a huge deal in terms of, well, let's take Slither for example, right? Take it, install it and you run it and it should just work right in the box, right? But for some of these other deeper tools like you said, right, be it fuzzing, be it symbolic checkers, there's just so much heavy lifting that needs to be done even before you can start using it, right? I mean, you need to understand how the tool works, the intricacies, the documentation of the tool itself. And then we need to write the rules, be it fuzzing or let's say property based testing, right? So there's just so much work that is involved there which I think hopefully over time will get much simpler so that the product or protocol teams themselves can actually start using these tools to a good extent. So I think that I think is something that maybe as a community we don't pay enough attention to. I agree, Mikesh. No, I was going to say so I haven't actually used Fuzzing since I've joined this space, but I used to do some fuzzing and stuff back in of VPN traffic and you just throw it a bunch of packets and see what breaks. At least at the time, a lot of what we were looking for was crashes.
03:48:48.162 - 03:49:33.278, Speaker A: Basically looking for places where the whole thing crashes and then seeing if you could instrument the system later and find where it broke. I was a little surprised to hear that logic applied to the smart contract space, just partly because you're not trying to crash the EVM in any sense. Maybe it's closer to smt or property based testing rather than what we'd call Fuzzing. Maybe I'm misunderstanding the term or I've. Got some bias that's forcing me to think in a particular way. Certainly your idea at the end of being able to nat spec a particular property, for instance, I've mentioned this example in the past. Sometimes I'm looking at code and I know that this value is meant to be a percentage, so it has to be less than one, for instance.
03:49:33.278 - 03:50:17.122, Speaker A: But it's not immediately obvious, just looking at the code that it always is. To the extent that it's possible to nat spec that and say this is supposed to be less than one, please make sure that's true. Throughout the whole code base, I think all that would be useful, but personally I haven't actually seen that happen. It sounds like you're telling me I just have to wait a couple of weeks and then maybe that'll be our thing. Well, I mean, in fairness, I think that that's how all of the fuzing related tools that we've talked about work is. You basically have to reason like you got to know your system and you got to know what's wrong. And if something is announced that only goes up, then the fuzzer can tell you if it goes down, but you have to write somewhere that it should only go up and it should never go down.
03:50:17.122 - 03:51:03.810, Speaker A: So there's various places you can write that. But yeah, it's not just like a general crash kind of situation. You have to be able to define your failure modes. Can I just clarify, is it doing this probabilistically or is it actually exhaustively checking the possible inputs? Exhaustively is a weird term when you enumerate through the whole space. But you could do it symbolically as well to check yeah, I know that the Mythx suite, they would measure how much of the code they'd visited. It still doesn't meet. Like you could hit 100% of the code and not necessarily have meet all the edge cases or explore all the kind of execution modes.
03:51:03.810 - 03:51:53.160, Speaker A: But that is the objective is to traverse the entire system. I will mention that Daptools does do symbolic execution as well. But also it's a good point that right now all these tools do require you to define. The weak part about unit tests is that you can only unit test what you can think of, right? And so often in hindsight, you'll look at something and go, damn, that would have been a really nice unit test. But the hard part wasn't writing the test, it was thinking the test in the first place. And with fuzzing and symbolic execution or property testing, you've alleviated some of the challenges with maybe defining exactly how to test. But you still do have to think of the thing to test for.
03:51:53.160 - 03:52:28.574, Speaker A: And in fact, we can take that one level higher with formal verification. We see that as one example that comes to mind. The miso bug that I found a couple weeks months ago. I don't know how time works anymore. That was formally verified. It was just that there was no case defined for both minting or sorry, both buying into the auction and using the batch contract. And so once the team went and added that case, the form of Verifier was like, yeah, there's a bug here.
03:52:28.574 - 03:52:59.100, Speaker A: But you had to think of that first. And so it might be interesting. I don't even know if this would be possible or not, but if there was some way to just similar to how traditional Fuzzers just look for crashes, if there's a way to just look for ways to send Ether out or ways to transfer tokens out, that might be way too computationally expensive. I'm not really sure. Maybe someone else here can comment on, like I think that Slither does that. Rajiv. Yeah.
03:52:59.100 - 03:53:38.610, Speaker A: I mean, to a certain extent, right? Whatever you can determine syntactically and semantically, like love Ether and so on, but yeah, please continue. Okay. Yeah. So I was going to say, I'm pretty sure Mythx did that. Does that. The thing is if you care enough about the security of your contracts, usually kind of well, no, this is not true. Obviously experience bears that out, but I think it's hard to detect the weird things and I think that the messages that you end up showing are like there's kind of like you call out here to unknown.
03:53:38.610 - 03:54:55.002, Speaker A: We're not sure what you're going to do, but like fuzz testing. So as soon as you call out to an unknown contract, what are you going to do? Like, generate all the possible contracts or symbolic execution as well? That just doesn't really make any sense, but I was hoping so formal verification, I'm just, like, overrated or underrated, let's phrase it that way. We'll go around and Rajiv, you got to go first because absolutely. So, yeah, I think, like with many things in the space and maybe in life, right. Formal verification is probably overrated in the near term in this space and probably underrated in the longer term. I get the impression maybe it's sort of the meme of the season or whatever, right? But there's just like, hey, let's go do formal verification. Right? I mean, I do believe that property based testing such as Scribble or Certulus Prover or KVM or Verex from chain security, all these do, will play a significant role.
03:54:55.002 - 03:55:41.886, Speaker A: Maybe it's just where we are in the maturity cycle of the tools. I mean, there are so many things that are moving, right? Solidity is changing every month. Ethereum itself is changing protocols, everything. So in that scheme of things, I think just sort of moderating our expectations from these tools, especially formal verification, that it's not a magic wand. And like Sam said, well, great, we do use a formal Verifier, but how do we know that the formal verification tool itself, somebody built it. How do we know that that doesn't have bugs? How do we know the properties that were written do not have omissions. Right.
03:55:41.886 - 03:56:20.294, Speaker A: So those things and this sort of goes back. I mean, none of this actually is new in the Web Three space. If you look back all the way to who was it? Ken Thompson's Turing Award lecture on reflections on trusting trust. Right. So he talked about, well, all these layers that we seem to rely upon as something very, you know, perfect, but that's not the case. And that applies even to formal verification tools. So no wonder, right? I mean, if you have a checkbox saying, well, this protocol was formally verified, it's not a magic one, but that is not a problem with the tool or the approach.
03:56:20.294 - 03:57:01.362, Speaker A: It's just a problem with our mismatch expectations, if you will. So what you're saying is you should write a GD spec. You should write a what, sorry, a spec. So that you can identify those things, I guess. Right. I mean, that would be, again, a mismatched expectation at this point. Having looked at several code bases, I would be happy for a typical project for something more than one screen README file, right? Something we can start with, that we can go to better documentation.
03:57:01.362 - 03:57:25.502, Speaker A: I mean, if we have a list of all the contracts and the interactions, a spec would be fantastic. Absolutely. Yeah. Spec is a powerful tool. English language. Underrated Nikesh overrated or underrated formal verification, I think it's probably useful. But as Rajiv is pointing out, there's probably a mismatch between what it can do and what people think it can do.
03:57:25.502 - 03:58:26.366, Speaker A: Even a spec, I don't think helps as much as you might expect. At least my instinct from that is based on the fact that people have been talking about formally verifying VPNs forever and there is a spec, there's an RFC, and it's existed for a long time. And it seems theoretically, that you should be able to just implement that spec in a formal verification tool, but still, OpenSSL has the market, and it's like spaghetti code completely. And partly that's just because they got there first. And also, if you want to add this new protocol, you want to use Divi Helman instead, or you do something slightly different, then that spins out a whole six month, eight month project to specify that part of the test. I think particularly in the blockchain space, it's moving so quickly that by the time we have like a spec of, ERC, 20 people already doing flash loans and stuff, so then you'll lose the ability to at least keep up to date with what people are doing, I suppose. I do think it probably would be useful to have formally verify some repeatable components.
03:58:26.366 - 03:59:20.258, Speaker A: Like if you get I might just throw open Zack component contracts in here. If you can formally verify something that's been used in lots of different projects and is relatively well defined, I think that might be useful. But at the moment, I think it's just going to be lagging behind for a long time. Yeah. So I think sam, anything to add? I think know short term, long term answer is just so effortlessly wise that it's hard to add a whole lot. But I mean, anecdotally I will say that usually when I see that Sartora has formally verified a repo, I'm like, okay, that's probably know again. But I think that speaks of eco volumes to both the technique itself and also their team's ability to actually reason out what your code is supposed to do for you.
03:59:20.258 - 04:00:34.250, Speaker A: Because that is what they do is they sell you the service and they sell you well, they sell you the technology, and then they sell you the service to use that technology. Yeah. So one thing I think is interesting there is one of my favorite auditing techniques was like, making diagrams. And I think that's something like that's a form of spec. And so a lot of tools do this too, in that they informal verification as well, in that they force you to reason through they just put you through an exercise in which you sit down and you're like, what does it do? What does it actually do? And converting solidity to a picture or words, I think is an effective way of or like, or properties, and maybe properties is a higher value output because you can reuse them. But I think for a lot of tools, my sense is that is a lot of the value is that it forces you to interact with the system more deeply. Yeah, I think I totally I was just going to do the same.
04:00:34.250 - 04:01:41.810, Speaker A: Absolutely agree with what was said. I think to sort of go back to one of the first questions that was posed. If there were two tools that I would love to see right from, again, separating out the auditing from a developer perspective, from a development perspective, if there were two tools, I think those would be at two ends of the spectrum. One of them would be something like slither, something that's very fast static analysis that catches all the code smells, that catches all the basic pitfalls, shows you what the best practices are. So that, I think, would give the best bang for the buck for the development team right away. And the other one would be the other extreme, which would be the property based tests, because that would force the dev team to think about, well, one, do I have a spec? Right? And you might call it spec, documentation, whatever. But it forces you to think of, well, what is the requirement? What is the expected behavior? And it makes you document that formally in the context of this tool.
04:01:41.810 - 04:02:34.154, Speaker A: So those, I think, would be the two sort of top on my wish list. So I have an instinct. It's not very well formalized, so I'm kind of shooting from the hip here. But I think Marillian's point was excellent about the fact that it forces you through this process in itself is useful, even if the output of what the tool says might not be that readable. But I have a sense that we might be mixing layers because at least in my experience, the real value of a lot of these things is being able to transfer the knowledge in the developer's head into someone else's head. So into an auditor for instance, or just into another developer, so they have some threat model in mind and they know that they wrote the code in this particular way because they're trying to avoid some particular style of attack. And then an auditor comes in and thinks, well have you thought of this style of an attack? And maybe they have, maybe they haven't.
04:02:34.154 - 04:03:15.646, Speaker A: But then there's a huge ramping up period and then it's also quite unfortunate. You get to the end of an audit and now you're an expert in a system and then the that wanes until the next audit shows up. I think there are a lot of processes that are potentially in place to maybe shorten that time period so that we're not doing it in batches. So obviously it'll be useful to try and maintain more of a continuous sort of relationship that way. But I think we then make a mistake potentially when you then try and specify it in the code. Because at the high level I haven't said anything about this particular contracts or if statements or anything. I'm thinking really just about have you thought about replay attacks, have you thought about access control issues and that sort of thing.
04:03:15.646 - 04:03:54.822, Speaker A: And I guess a lot of times your threat model goes out of date after a while you wrote your code assuming some sort of threat model and then it turns out the ecosystem changes. Flashlands become a thing. Or for instance, now you can do reentrancy because the gas limit has changed or something like that has gone wrong. And you don't go back and revisit the code because you thought the code was self sufficient, whereas what we really need is just a way to transfer knowledge. I think a lot of the value comes from just the existence of the security community that has seen all of these things before. You can go through previous audit reports and stuff. We have repositories of where these things exist.
04:03:54.822 - 04:04:28.694, Speaker A: So like you could say I'm building a tool, like I'm building a voting tool, let me look at all the places. These are the checks that I need to worry about, these are the things that are broken. I think a lot of that is useful well before you actually get to the code level. And to the extent that we can have tools that just spread security knowledge around the space, I think that's going to be at least it seems like an underserved market. That's my own instinct, but it isn't particularly formalized yet. So we're kind of just shooting a little from the hip here. Fair enough.
04:04:28.694 - 04:04:52.430, Speaker A: I think a good example of that, like the threat model changing, I think is maybe like developing a Dex. Oh, this will use a bunch of ERC 20 tokens. And then somebody's like, oh, but I have a token that will do callbacks to whoever you want when you transfer it. And you just don't think about that. Right. You're like, it's just an ERC 20 token. It does nothing fancy.
04:04:52.430 - 04:05:34.214, Speaker A: So maybe just to keep moving along and I don't know, this is probably a little bit out of everybody's wheelhouse, but do you have thoughts about what you should be doing when the code is running on chain? It's out there. Is there a magical way to detect and prevent attacks in real time? I think Nikesh, this is kind of softballing for you. So go. This I sort of have to mention at this point. So we suddenly open Zeppelin. We have this tool defender. It's got audit tasks.
04:05:34.214 - 04:06:14.066, Speaker A: You can suddenly write up your security properties or things that you want to check. You can say like, if this balance changes or if some property holds on the blockchain, then please run this task or at least give me an alert. We're also developing a new tool called FORDA, which is like a Web Three Native cybersecurity thing, which is basically like an alert monitoring system. There'll be details to come soon. But the important thing, the thing that's particularly interesting about this is it's Web Three Native. So it's not like an external tool that you're running and then you try and pipe it into the blockchain. It's actually running directly on the chain so you'll be able to hook it into all of your apps.
04:06:14.066 - 04:06:49.042, Speaker A: It's like developable sorry, it's decentralized and directly integratable in the same way and composable in the same way the rest of the blockchain is. So that's my pitch. But is it going to save you or is it just going to make sure that you know right away that your system is totally owned? True, that's a good point. So it's like agent detection. So it's detecting things that have changed. It's not necessarily preventing it. But certainly we do have things like autotask that say if this happens, then run this command so you could pause a contract at the moment that something changes.
04:06:49.042 - 04:07:46.680, Speaker A: So you can take sort of automated actions. That way if the attacker doesn't bother to use Flashbots, I guess. Right, right, yeah. So of it'll shorten the time period it takes to react. Maybe that's a good way to are there other things out there? Or Sam or Rajiv? Do you have a thought about not even tooling, but just like running these systems safely? That was an okay answer too. Just okay. I've seen quite a few attempts at building these sort of things now where you try to alert on transactions in the limpo, of course, as Nikesh said now that Flashpots is more and more thing, that becomes kind of hard.
04:07:46.680 - 04:08:39.320, Speaker A: The only time I've really seen you know what, I don't really know where I was going with this. The point I was trying to get to is like I tried building one of these at one point and it was meant to alert on past transactions. So like things that were already mined and just just to see if anything interesting was going on. Try to automatically detect if a transaction was anomalous it was somewhat okay. It was very noisy though, so I sort of escape upon it. But that would be I don't know if anyone's built that or made a public version of that, but that would be cool to see. Just like a live automated threat intel feed almost, yeah.
04:08:39.320 - 04:10:55.474, Speaker A: I don't have much to add in this space, but maybe I have more questions in this space, right? And I've discussed this with some of you in the past, is if you look at the Web Two world, you have a long list of security products in the last 30, 40 years, all the way from ABS, Firewalls, intrusion detection systems and all the different names of that intrusion prevention systems, all these things, right? So there's no reason except taking into account some of the big changes in the Web Three space, maybe culturally as well as technologically, that these systems could not theoretically be implementable in the Web Three space. Right? So if you're able to see a transaction in space as it is flowing through the mempools or whatever layers you're in, theoretically one should be able to simulate that for your main net with whatever tooling be able to simulate this transaction and be able well, you obviously need better and faster resources than the attackers themselves, but you should be able to do that and then put in a transaction that actually takes over or goes ahead of the attackers transaction and somehow fixes the code or makes the tackles transaction invalid. So theoretically I think it should be possible. I don't know, I mean maybe Nikesh and others have more practical experience in this place with Defender and other tools, but that was just a thought and I hopefully will see some research or maybe even products or techniques in this space to just make sure I understand that claim. So the idea is you see something in the mempool and then you're essentially trying to replace that transaction. So obviously front running as a concept is existing and people are doing it for non security related reasons, like just for Arbitrage generally. And that's been developed quite extensively to the point where people are running gas suctions and things whenever something new happens.
04:10:55.474 - 04:11:39.038, Speaker A: And of course, Flashbots now is alleviating some of that. I understand you're perhaps approaching it from the security angle, but maybe I haven't seen why it's a different concept. It still seems similar to seeing something that you don't want to happen or something that you want to prevent first and then getting your transaction first, unless the contract itself is designed in such a way that it has a delay. Sorry, I'm thinking out loud at this point, and I might be misleading here. Sam, why don't you jump in here? I think you've been quiet for a little bit. I mean, put me on the spot, I guess. I don't know.
04:11:39.038 - 04:11:49.300, Speaker A: I've been quiet because I didn't really have much to add. You were unmuted. I took that as a signal. Sorry. Yeah, I read too much. That's my bad. Okay.
04:11:49.300 - 04:12:27.210, Speaker A: I kind of think you're right. Nikesh well, basically, I guess you're going to get into this is, like, outside wheelhouse, but you're going to get into reorgs, right? Because you got Flashbots, you got private transactions. I'm a brilliant black hat hacker. I know how to I found an exploit. I submit it through Flashbots. Nobody can see that, and it's going to execute. I'm going to own your contract.
04:12:27.210 - 04:13:17.038, Speaker A: The only way to get back to restore that is to reorg the chain and outbid. And I kind of lost track of that conversation that was happening over the summer, but that's where that goes to me. As far as I can tell. It still sounds like it might be in the same bucket in the sense that now I'm definitely speaking outside. I don't know anything about how useful it is to reorg or how plausible it is to do that. Hopefully people are thinking about that to make that difficult. But I would still guess that if that tool is available, if that technique is available, it'll be used first to win trades, uniswap trades or something, to arbitrage some.
04:13:17.038 - 04:13:47.946, Speaker A: As long as there's, like, direct money on the line, that'll be the use case originally. And people will be doing arbitrage with that tool before the security level catches up. That's my instinct. I guess we got, like, a minute and a half left. A question I kind of, like, I just remembered I really wanted to ask is what tool needs to exist or be way better than it currently is that you would like to see in your life? So let's like 15 seconds. What does it do? Nikesh you're already unmuted. Go ahead.
04:13:47.946 - 04:14:23.238, Speaker A: Fair enough. I have this grand plan of making a threat modeling tool that I think that works. Same concept, saying, working at the high level of understanding threats rather than understanding code. That's my 15 2nd pitch. Cool. Rajiv so I have a slightly different wish, right? I think all tools have their place, but my wish is they get used sooner than waiting for the auditors to run them. So I'm thinking and I'm getting really big on the shift left that has been such a big thing in the web two space.
04:14:23.238 - 04:14:57.374, Speaker A: I think web3 space needs a lot of that. I have a really big insane idea and, like, a smaller dual idea. The big one is I want this integrated all in one platform where I can view contracts, decompile them, analyze transactions, inspect storage slots, look up four byte hashes, the works. Everything I need to do ever is a tab away convert from Hex to ASCII or whatever. Right. All that stuff. That is like, a lot of work.
04:14:57.374 - 04:15:29.740, Speaker A: Also, I suck at UI design, so I'm not doing it myself. The more doable one is like some tool in my IDE that lets me annotate specific variables or blocks or whatever with things that I don't have to remember. Variable is always going to be even, or this variable is always going to be less than 100 or something like that. And then that way when I click through three functions and I look at the variable again, I don't have to remember that. I can just hover over it and it's like, hey, by the way, you said this is going to be less than 100. So just for reference. Yeah, okay, that's great.
04:15:29.740 - 04:15:55.270, Speaker A: I think we're at time. Yeah, that was an awesome discussion. We'll do two quick things and anybody can pick. We don't have to do everybody. But the first kind of question is for people who are trying to enter the space as auditors. Do you have any tips or advice for them? And what do you kind of recommend they do if they want to be on the auditing side? Join the secure boot camp. Sorry.
04:15:55.270 - 04:16:49.220, Speaker A: No, you should shill first, maybe, just to give more context to people. What is the bootcamp and how can they find out more? Yeah, I mentioned this in the beginning, but Secureum Bootcamp is a three month bootcamp that has just started in October. It's funded by an EF grant, and the sponsor partners are some of the top auditing firms in the space. The idea is to be extremely open to people from different contexts. So there is a two month learn phase where people are going to learn about Ethereum 101, solidity 101, 201 audit techniques, audit findings, all the rich content that we already have curated in this space. And the final month is going to be where the rubber really hits the road. They're going to be taking a look at some real world projects where they actually evaluate them for audit readiness and hopefully have a good chance of becoming auditors.
04:16:49.220 - 04:17:24.656, Speaker A: Awesome. May I kind of blend this on the other side of that? I feel like I might want to answer that question just because, first of all, I certainly agree with Rajiv that the securing bootcamp seems excellent. But of course, I feel like I have to point out if you're going to ask me that question, OpenZeppelin has a bunch of videos that we put out. Like Tincho, one of our best security researchers, puts these things out. We have like, the Ethernet, and these sorts of techniques are useful and we're always hiring. So if you actually resonate with that question, then come hit us up. All right, one quick one.
04:17:24.656 - 04:18:04.670, Speaker A: And others can kind of mix and match the last one too. Just for people who are trying to now replay apps to production or contracts to production, any tips for how should they think about auditing or insurance or anything else around that? And what are some things to keep in mind for newcomers? Very open ended. Anything qualifies? I think I have maybe the same instinct, like try and get plugged into the security ecosystem. There's lots of people who will guide you through the process, but it's hard to answer that in 1 second. But try and get plugged into the ecosystem is my main suggestion. Book. Your audits are early, the lead times are long.
04:18:04.670 - 04:18:24.240, Speaker A: Perfect. Well, we'll end that there. Thank you so much. Sam rajeev Nkesh and Orlean. This was an awesome discussion, and for any other questions, we'll relay them to you over email. So with that, we are ready for our next talk. So without further ado, thank you very much, Daniel.
04:18:24.240 - 04:19:02.930, Speaker A: Daniel is going to be talking about how to decentralize frontends with Skynet and home screen. So, Daniel, welcome and I'll let you kick it from here. Thank you so much for the introduction. Let me go ahead and get my screen sharing going and I assume everything can be seen now, so yeah, thanks Kartik, for the introduction. I also just want to, before I get into things, say thank you so much to ETH Global for inviting me to speak. The hackathon and summits have been a lot of fun so far. Always good to learn from all the smartest people around.
04:19:02.930 - 04:20:08.864, Speaker A: Yeah. So the talk name it is decentralized Frontends, better tooling with Skynet and Home Screen. I'm Daniel Helm, I'm the developer evangelist at Skynet Labs. And in lieu of doing kind of a personal bio, I figured I'd kick off this session with a question. Should we? Decentralize front ends in the web3 space? So I work day in and day out in decentralized storage. So I'm going to emphatically say yes. But this is the question that developers have to make a decision about, right? And I think maybe it's better to reframe this question if we really want to get to the bottom of it and ask, are we really building permissionless systems if they're centralized at the point of entry? So phrased another way, are we really building open protocols if we're only letting our users access them or 99% of our users access them using AWS Netlify Versaille, DigitalOcean? So these are kind of how I'm framing my talks.
04:20:08.864 - 04:20:28.792, Speaker A: If some of these terms are new to you, don't worry, I'm going to do some backfilling. But I just want to kind of set these out at the very front. So if you're unfamiliar with decentralized storage, we can kind of start there. Maybe you missed. Yusef's. Great talk earlier today, introducing some. Of the ideas of decentralized storage.
04:20:28.792 - 04:21:20.216, Speaker A: But we're talking about a core piece of web3 infrastructure where files, web apps, NFTs, basically anything not stored on chain can be accessed without relying on a single trusted authority. At their best, they're trustless, permissionless and censorship resistant. And they're really good ways to potentially wrangle control of data storage away from the Amazons and the Googles of the world. There are a lot of folks building in this space. So we're talking about projects like Skynet or IPFS or Rweave. And most of them take a similar approach, at least to this kind of base data that you're going to upload. So you upload a file and what you get back is a unique identifier, this cryptographic hash or merkel root that looks all crazy.
04:21:20.216 - 04:21:38.976, Speaker A: But what it says is that this is the contents of this file. And if this file changes, my URL is going to change. So here I'm actually showing a skylink. It's what we use inside of the Skynet ecosystem. And it can be used to know that once a file is uploaded, you can share that URL. And no one's going to change it. You're not going to change it.
04:21:38.976 - 04:22:11.800, Speaker A: The portal is not going to change it. No host will be able to change that data. That data is immutable. It's not going to change. And what this lets us do is take that and stick it on the end of a portal URL. And so again, everyone in the ecosystem has portals or gateways ways of accessing this data through a web browser. And so here we see the Skylink stuck on the end of Sciasky net, which is the portal that we run, or you can stick it on the end of a community portal like SkyPortal XYZ.
04:22:11.800 - 04:22:49.076, Speaker A: All right, so if this is new to you, this might seem a little bit abstract. So real quickly, I just want to show what it looks like to upload something to Skynet we can jump over. And I'm actually going to upload a web app because we're talking about website front ends. And look, I've already forked and Yarn installed and Yarn Build, the uniswap interface. And so we have a build folder here. And I'm going to open it up in Explorer, find my build folder, and drag and drop it to the Skynet uploader. And so what happens when I do this is that file goes onto Skynet.
04:22:49.076 - 04:23:38.440, Speaker A: It gets broken up into a bunch of pieces and stored on the SIA blockchain. And at the end of it, what I'm going to get back is one of those URLs, right? So I have this folder that has the index HTML file, and I get back a URL that I can open. And I've got uniswap here. And once that file is uploaded and on the Skynet network that is available everywhere, so we have a URL, Sciasky net, I can change this again to SkyPortal XYZ. Click Enter and I'm able to pull up the exact same content. So this is kind of the base idea of decentralized storage. We're able to have lots of access points to this data that's not stored in a single location.
04:23:38.440 - 04:24:58.880, Speaker A: Okay, great. Let's see what this looks like though, from the perspective of running a web app, because I think a lot of developers say to themselves like, hey, it's just a web app. These are kind of overblown requirements, we don't need all of this to be immutable. But the stakes are real and they're getting realer every day in the Web Three space. And so we're seeing developers and Web Three users get placed in really tight spots and they're having to kind of address questions like what do teams do if they're hosting a site that makes them liable for user actions? Or what if their hosting providers don't like the way that the wind is blowing with regulations or local social pressures. And for users right now, you're totally unaware when the code of a front end changes, which kind of puts you at the whim of the security and product decisions that the dev team is making as they push out these changes to their website. So these aren't paranoid hypotheticals like we see this play out in the news, right? Uniswap had to removed assets from their front end in order to protect the developer team and users during a time of regulatory uncertainty.
04:24:58.880 - 04:25:56.630, Speaker A: We had Sushi's miso attack that put over $3 million at risk, not because of a smart contract bug or some of the security issues we saw before, but malicious code that was introduced into the front end. And one of my favorite things I've seen recently is one inch's new feature that I don't even know if it's live anymore. But briefly, you had to sign with your wallet a little message saying I am not a citizen of the United States. And they also did some geofencing where if you then still tried to use their web app while being located in the US. It would say, no, you're not in the US. So make sure you disable your VPN, which is telling us that you're in the US. And so if we're seeing all these issues, developers can be asked why not decentralize? And it's because there's lots of challenges and concerns that developers have.
04:25:56.630 - 04:26:55.160, Speaker A: Not all web two patterns translate well to web3. If you've always used a back end to handle server side things like storing user sessions or doing database queries, sometimes the new Web Three frameworks can just feel weird, just like writing smart contracts can feel weird. Similarly, in the Web Three space with this decentralized architecture, we have limited framework support compared to traditional web serving. So if you're only serving static assets because these things are immutable, then your frameworks are going to be limited. And most protocols don't even allow for writing custom routing rules which are usually available in on traditional web servers. And the final kind of thing that I think developers have concerns about is performance. And so I think this can take many shapes, both in terms of things like time to first byte for users, you want your website to load really fast and feel snappy.
04:26:55.160 - 04:28:24.230, Speaker A: But there's also performance concerns about is the long term scalability proven for projects that are going to be like storing all their files on the blockchain? Or is data availability that's a performance concern? Who can we rely on to keep data available and online? So these are real challenges. And to these developers, I shill, why not decentralize with Skynet? So it's true that not all web Two patterns translate, but the tooling is being built for really performant mutable data APIs, including one of my favorites is one that we've developed called MySky, which is a cross ecosystem, decentralized user identity. Additionally, there is limited framework support. So some kind of classic, both backend front end paired frameworks aren't going to work. But at this point, you've got full support for things like gatsby and react router and other dynamically routed client side frameworks. And lastly, with regards to performance concerns, it's probably a little bit out of scope to get deep into the architecture of Skynet or saya here, but try it out. I think you'll see that our speeds are already comparable to the experience of web Two and what web Two users expect.
04:28:24.230 - 04:29:18.448, Speaker A: And this level accessibility for our users is our primary concern. We're always working to really reduce our time to first byte and what that looks like. So with Skynet, all of these things are possible for users and developers without having to install a wallet or special software or really touch any sort of cryptocurrency. Okay, so at the end of the day, yeah, this is our goal. Any developer can build a web Three app that anyone can use. All right, so I talked about some of the kind of, like, fundamental ideas there. But if our web app is immutable, if we have this folder of files that we stick on to our Wevip IPFS Skynet, how do users keep up to date? Right, we have this crazy URL that is not very readable.
04:29:18.448 - 04:29:48.972, Speaker A: Well, let's take a look at an example. Here we have our friendly user, and that user really likes this website that has daily builds, and they use the decentralized web. They're good. And so when they release Tuesday's Build, it has a Skylink like that. And our user grabs that Skylink and is happy using Tuesday's Build. They've been using it all the time. But tomorrow rolls around and the developers roll out Wednesday's Build.
04:29:48.972 - 04:30:25.290, Speaker A: They shipped their dark mode update, and our user doesn't have any way of knowing what that new Skylink is or is going to be. It's a cryptographic thing. It's unpredictable everything else. And so we have to introduce ways to fix this issue. And for Skynet. This looks like Resolver Skylinks. In IPFS they have IPNs, but what this does is let you have a mutable constant URL that you can just then point and make those updates when you sign some sort of certain proof that you are the owner of this piece.
04:30:25.290 - 04:31:21.150, Speaker A: And so what this looks like on Tuesday is that our user has the Resolver Skylink and is getting Tuesday's build. And what this looks like on Wednesday is the user still accessing the build through the exact same URL this Resolver Skylink and never had to worry about the immutability of the core underlying data. And then in actuality, this is kind of ugly and terrible, right? This is not very usable. And so what most developers will do is add in a human readable name. And so this is going to use DNS, like traditional DNS ENS or HNS to give us something like Dailybuilds.com, Dailybuilds ETH. Those will have records pointing to the Resolver Skylink and then know the Resolver Skylink probably is part of like a GitHub action when a new build gets created and deployed will automatically update to point to the latest build.
04:31:21.150 - 04:32:12.136, Speaker A: All right, and again, I'm using Skynet here, but all the other ecosystems, I think, have kind of comparable things. All right, so this is how easy it is to get a decentralized front end. But then the next question is, is decentralized hosting enough here? If a user is still just going to like app Uniswap.org, which is hosted on IPFS, that's great for censorship resistance, it's great that it's decentralized and hosted that way, but that still doesn't answer that question of the front end attack. And I want to kind of look at that a little bit in our diagram here. So returning to the diagram, let's assume Thursday comes along and a bad build makes it through. The developers have gone rogue, there's malware everywhere.
04:32:12.136 - 04:33:09.068, Speaker A: Worst of all, Dark Mode has been removed from the application. What we have is a situation where our automated deployment is still just going to go ahead and automatically point to that and our user, when going to Dailybuilds.com is going to still in a decentralized way access this malicious build. And unfortunately, because the user is so accustomed to accessing the website through the ETH domains, they have no history or recollection of the underlying immutable data that's still available, but they just don't know how to access it. And so for this reason, we've really started seeing a problem where it seems like we need to not only decentralize our front ends, but also our upgrades for users need to be voluntary and a version history kind of needs to be accessible. And Home Screen has entered the chat. This is the project that we've been working on.
04:33:09.068 - 04:33:51.592, Speaker A: We released Home Screen at the beginning of this hackathon and what it is, is a decentralized application where users are able to log in with fully decentralized identity and access their favorite decentralized apps. These are versioned builds of web apps. They're fully controlled by the user. And when they pin these to their own personal cloud, it gets all of the assets, all of the code and stores it there so that they always have access to these apps. And then they can also upgrade downgrade, share the apps with friends at any time. So I just want to quickly show a little bit of what it's like to interact with home screen here. I can go to homescreen HNS sciasky.
04:33:51.592 - 04:34:27.464, Speaker A: Net and it tells me that web3 needs decentralized front ends. Great. I'm going to go ahead and authenticate with MySky and this is what I was talking about earlier, our decentralized identity. And we can sign up. I'll get a new passphrase. This is never communicated to any server or anything, but I'm able to use that passphrase across device anywhere to access my personal cloud. And so we're sitting here interacting with the mutable data layer of Skynet, and I can add apps whenever I want.
04:34:27.464 - 04:34:48.460, Speaker A: So let's say I want to go and add Uniswap ETH. I told you earlier, this is hosted on IPFS. We have IPFS support here. Oh my God, the live demo gets me. Okay, let's try app Uniswap.org. Let's see if that one will work. All right, cool.
04:34:48.460 - 04:35:30.840, Speaker A: Also hosted on IPFS, it finds the IPFS link uploads that to Skynet. And now I'm able to pin that DAP to Skynet and have it always accessible for. Okay, so and we can also kind of look at the details, know it's going to pull down our name, our description, and some other details. And now when I go to click on uniswap, I have a build of Uniswap here. Okay, I talked to you earlier about Resolver Skylinks and how those things can update. And I don't have updates available for Uniswap because they host on Ipffs. But we do have updates available for Skysend.
04:35:30.840 - 04:35:51.248, Speaker A: And so I love Skysend. I'm using it. I want to check for updates I can do. So here it'll go. It'll find that we now have a new Skylink, a new immutable file. The resolver skylink is pointing somewhere else. The dev team has signed off on this version and I can then pin it.
04:35:51.248 - 04:36:51.030, Speaker A: It's then stored on Skynet and then I will add it to my personal metadata here. And I can access this new version of Skysend instantaneously. If I don't like this new version, I'm also always free to go view the details, come in and I can say better version and downgrade to my older Skylink that I had before. And that way that will always be my default when I come and click this here. Okay, so if you've worked with decentralized storage before, maybe some of this isn't new, but also just like pay attention to how fast this is going. We are interacting with mutable data and it's performance. Yeah, it feels good if you're a developer and this is interesting to you, I really encourage you to look at what it takes to integrate with home Screen.
04:36:51.030 - 04:37:28.240, Speaker A: Let's get this full screen. Again, so for integrating with homescreen, there's kind of three main steps. You're going to have to get an app that deploys on Skynet. You'll want to set up automated deployments using something like our GitHub action, which I can show a little bit of later. And you'll want to add a home screen button and a reference to that app's, Resolver Skylink, so that users can easily find this and add it to their home screen. So you can follow along any of this at docs scienceguy. Net integrationshomescreen.
04:37:28.240 - 04:38:43.332, Speaker A: And you'll also find a link there to the video that I did earlier for ETH Online that I actually do this as live code in about 20 minutes to set up a home screen integration. So we already deployed an app to Skynet. Obviously, when you're building code, you're not going to want to go drag and drop a file every single time, but just to kind of, again, say, any directory with an index HTML file is going to be supported as a web app. And then if you use kind of our deployment tooling, you have additional gatsby and react router support that you can get working in terms of automating those deployments. Like I had mentioned, we have a GitHub action which lets us build and upload our build directories straight to Skynet whenever we push a new PR. And we can also set a secret in there so that we can sign that code and update that resolver Skylink every single time one of those new builds deploys. And the Resolver Skylink is very nice because then we can also point ENS names or HNS names or traditional domain names at that resolver Skylink.
04:38:43.332 - 04:40:04.580, Speaker A: And we know that we have this kind of, like, fully automated deployment system, and at no point do we ever really have to interact with a traditional hosting provider. And then again, step three here is going to be adding the Add to home screen button and our Resolver Skylink. And so, like I kind of showed before, when we're interacting with home screen, you can go ahead and actually type in things like we're still tweaking the UX for the user side of things, but you can also find repos where an Add to home screen button has been added. I've worked with some kind of, like, unofficial builds here where I've made a repo for, say, Balancer, and it now has an Add to home screen button that has the Resolver Skylink that gets built every time something gets pushed to main. So I have a GitHub action that deploys to Skynet. And when that happens, there's a step here that you can copy and paste from our documentation to get things automatically deploying to Skynet. So when I click on this Add to home screen button, I'm able to be taken to home screen instantly asked if I want to add this app to my home screen and we can see all the metadata that the developers provided including the Resolver Skylink where it's going to be updated.
04:40:04.580 - 04:40:59.748, Speaker A: And of course I can open up balancer here on the next tab and get going with decentralized storage and decentralized trading. Okay, so yeah, one last little shill here. There's a 10,000 Psyacoin prize pool, 2000 Psycoin for the best hack using home screen and so look into it if you are a last minute hacker still having to figure out how to get your front end live and on the internet, we have a lot of Skynet resources. If you want to learn more support Sciasky net is kind of our intro guide but we also have developer guides available at docs. Sciasguy. Net along with SDK stuff for JavaScript and SDKs available in quite a handful of languages. If you're interested in joining the Skynet community, it's a good one.
04:40:59.748 - 04:41:43.852, Speaker A: We have a discord at Discord GG Skynet Labs and it is full of developers that have built with Skynet and are super generous with their knowledge. So come say hello, tell us what you're interested in building and I'm sure some folks will help you get started. Thanks again for hearing my appeal for the web3 needing decentralized front ends and I'd love to answer some questions from the chat. Thanks, Daniel. This was great. I think we have a couple of minutes. I think the set of questions or follow ups here are maybe just understanding what does this evolve to like? Hosting static content is great, but code is a lot more complex.
04:41:43.852 - 04:42:53.210, Speaker A: Use cases of front end applications. How are you going to think about the evolution of home screen or just kinded? And if you can share some things that will be possible in the future or in the works right now? Yeah. And so I kind of glossed over all of our mutable data structures. We have a good handful and MySky is a big one that we're kind of aggressively developing on the back end where users have totally user provisioned storage space that when they log in with MySky and different applications, those applications can request permissions to other application storage. So you can build a social graph on application A and just import it natively into application B as though it were an API, even though it's a piece of storage that you locally own. And beyond that, probably a few more months out. We are working towards monetization and so if you have content that you've put up as part of your MySky identity and people want to help support you or consume that content, we want to have a more equitable way for content creators to get paid for their data.
04:42:53.210 - 04:43:31.504, Speaker A: Amazing. And I know the answer, but I'll ask this for the sake of others also knowing this is kind of free. Yes and no. So free to use it's freemium, similar to Web three storage. If you use Sciasky net, you get, I think, 10GB. If you don't give us your email if you give us an email address or later on, just sign up with MySky, you'll get 100GB and then you can pay in Fiat beyond that at this point. But the whole storage stack or the whole portal stack is totally open source.
04:43:31.504 - 04:44:11.650, Speaker A: So if you don't trust us, you don't like us, please run a community portal. We love community portals, and you don't have to rely on us at all. And just so we have some clarity on the limitations, when you say ten or 100 gigs, is that storage or bandwidth? And how does bandwidth work if it's not? That is storage. Bandwidth is actually kind of like on the consumer, not on the original uploader or provider. So once something's kind of on Skynet, anyone can pin that. And so there's no single owner anymore. And so right now, the bandwidth is just kind of like part of the system and the portals eat that cost.
04:44:11.650 - 04:44:41.352, Speaker A: Maybe other portals will need to throttle that or something else, but we have kind of some of those things in place, but nothing that, if you're not on a very impressive connection, you'll probably ever notice. Well, hopefully, Victor, that was good enough for your question to be answered. And Daniel, want to thank you again for doing this amazing presentation and making a live demo work. Thanks so much. It was a lot of fun. And with that, we are ready for our next talk. And up next is Patricio.
04:44:41.352 - 04:45:05.488, Speaker A: And Patricia is going to be talking about Hard Hats present and future. Super excited to see what he has to share and announce today. Welcome. Hey, thanks Karthik, for the introduction. So let me just set this up. Okay. Can you see my screen? Yep.
04:45:05.488 - 04:45:47.680, Speaker A: Right. Okay, thanks everyone to be somewhere watching at this presentation. So I'm Patricio, co founder and CTO of Nomic Labs, and you probably know us from our product, our development tool called Harhat. In this presentation, I'm going to talk about how Harhat works internally and its future. So first, a quick recap about what Harkat is. Harkat is an ethereum development environment which is composed by two major components. One is Hardhat Runner and the other one is hardhat network.
04:45:47.680 - 04:46:48.580, Speaker A: Hardhat Runner is a task runner that lets you automate all the common tasks that you have to do while developing ethereum applications. There are similar tools to Hardhat Runner in every development ecosystem or platform. For example, Webpack and Parcel are some of the most common ones when doing web development, or Gradle when doing Android development. And actually, Hardhat Runner has been heavily inspired by this. By default, Hardhat Runner comes with a set of predefined tasks that let you do things like compiling your contracts, testing them, deploying them, things like that. But there's also a rich ecosystem of plugins that let you integrate other tools, add features or new tasks to Hardhat Runner or customize the existing ones. Hardhat network is our development ethereum network.
04:46:48.580 - 04:48:04.270, Speaker A: And what this means is that it simulates an Ethereum network just like Maine, Robstene or Coban where it's totally local. Instead of having many nodes communicating with each other. You can think of Hasha network as a single node ephemeral Ethereum network. When you run Harka Runner, like running your tests, a new instance of Harka network gets initialized. Your smart contracts are run within Harka network and then after your test passed or failed, this instance of Harka network gets destroyed. And in this presentation we are going to focus on how Harka network works, the challenges of building and maintaining it, and how it's going to evolve in the future. So first, how does hardhat network work? Hard Network is a node JS module that it's embedded into Hardhat Runner and exposes the same JSON RPC interface that a real Ethereum node does.
04:48:04.270 - 04:49:09.456, Speaker A: This means that we kind of lie to the different libraries and applications that integrate with Harka network and pretend to be a real node but instead do everything locally within node JS. So for example, when you connect MetaMask or other wallet to Harhat network, it doesn't need to know that it's dealing with Hardhat. Instead, it just acts as if it were working with Ethereum Mainet. The same happens with Web Three or Ethers or any other library or application. This gave us the advantage of being able to integrate with everything quite easily. So instead of communicating things to a network, hacker network resolves everything locally. And what this means is that if you send a transaction, we don't forward it to a network of different nodes but just create a local block in our own blockchain and keep it for us.
04:49:09.456 - 04:50:14.084, Speaker A: We don't forward those blocks either and not communicate with anyone else. To do this we use Ethereum Jsbm, which is a TypeScript EVM implementation and it lets us execute everything locally. But what makes Hackath network different or special is not being able to simulate a network, but rather that we always look or try to provide as much context and information about what's going on with your smart contracts. Because that's what let developers debug and test their smart contracts and be more effective on building them. And this is where automation challenges appear. And the way this works is by relying on runtime observation. And this is because in Ethereum, as we all know, you have to pay for gas when you try to execute something.
04:50:14.084 - 04:51:40.396, Speaker A: And in particular the person paying for that gas is the final user. So keeping the amount of gas that you pay to a minimum is super important because it makes your application more or less competitive. And this leads to many things, but in particular, one of them is Salt C generating a minimal amount of bytecode when compiling your smart contracts. Instead of embedding functionality to help you debug your smart contracts or head tools do that it has to offer a very minimal bytecode without any kind of runtime support so that the amount of gas that the final users are going to pay when running that smart contract is lower. So things like for example generating stack prices are not part of the program but rather left to the tooling. In contrast, in other development platforms this will be embedded within the actual binary which makes things easier because the compiler has the whole controller information to be able to do this effectively. The way we approach this is instead by, as I mentioned, random observation.
04:51:40.396 - 04:53:22.168, Speaker A: But what does that mean? It means that when we execute anything within Harka network we trace this execution and by tracing here I mean collecting information or the history of what went through when executing the contract at the EVM. And these traits you can think of it as a sequence of EVM opcodes or operations that have been run during the execution of a given smart contract. And while this is very useful at that level, it isn't very approachable because you have to be very deep into the AVM to be able to understand things at that level. But instead what we do is take that EVM and very low level representation of the execution of your contract and try to recreate more friendly information for the user. For example, this is how we implement console log. When we take a trace of the EVM we recognize certain patterns that mean that someone tried to call to the console log library or function and when we detect that we decode the call arguments and print them to the console or to the terminal of the user. And this is in general the approach that you have to take if you are willing to build advanced tooling for ethereum.
04:53:22.168 - 04:54:51.116, Speaker A: Another thing that we do is generating stack traces and in this case it's similar. Like we take the trace NVM trace but also fetch the compiler sample that has a lot of information about your contract and combine those to recreate a call stack in Solidity. Which means that we know when a function was called or a return from a function was executed. But this is not always complete or perfect because there are certain ways that a contact can fail or certain paths of execution which are not actually reflected or come from your code, but rather from internal Solidity functionality or autogenerated code. That information is not very useful for the final user or developer and this is particularly true for all the versions of Solidity. So what we do is rely on a set of heuristics that we bid through time to improve this information and give richer things to the user like auto generated error messages. For example, when you send a transaction to a contract and the function that you are trying to invoke doesn't exist.
04:54:51.116 - 04:56:08.520, Speaker A: In that contract we can detect that and give a clear error message explaining what it did while depending on the version of Solidity and your settings. Without this set of heuristics, all you would have got is a revert without reason therefore message. And this is in fact a ton of work to read and has some limitations that I'm going to explore next. The first one is that relying on Heuristics is extremely fragile. They are built super ad hoc for every version of Solidity. In fact the way that we build them is by looking at hundreds of EVM traces and after some time you start to recognize patterns between them and then encoding those patterns within hard network. So we can kind of translate our intuitive pattern matching that we do when looking at Dcbn traces and encode it as JavaScript code within Hatham network.
04:56:08.520 - 04:57:47.960, Speaker A: But the problem is that as they are super ad hoc they are fragile because whenever a new version of Solidity comes out they can break because maybe Solidity changed something that broke our pattern, it doesn't repeat anymore and the change may make sense. It's not their responsibility for our heuristics to be stable through time. But the problem with that is that nothing guarantees us that we will be able to fix them or that we will be able to create new ones if we need them for a particular feature. Another problem with them is that they are not always accurate because these are heuristics and for the ones in the audience that don't know what that means, you can think of them as fussy matching things. In this context at least, they are like pattern recognition logic, but not very precise. And the reason that they are not very precise is because they can't be too precise or we are going to have a lot of voice negatives and they can be too loose because otherwise we are going to have voice positives but we'll never be able to be 100% accurate because the compiler doesn't give us the precise information to do that. Another problem with this approach is that the tooling that does this is always getting more and more complex.
04:57:47.960 - 04:58:50.812, Speaker A: The reason for this is that Solidity versions tend to stick forever within the ecosystem. Let's suppose that you build the contract now you probably are going to use Solidity zero eight four or zero 85 something along those lines and tomorrow zero point and you finish your contact, you deploy it and tomorrow 0.9 comes out and has some cool features that let us tool developers improve your development experience. The chances of you rebuilding, I mean porting rebuilding and redeploying your contract just to get better tooling are very low because that's going to cost a lot of money, at least for audits. And also it's going to take a huge coordination effort and while the advantages for you may be huge, it's not great for the community. They won't get a lot of advantages. So that's not going to happen.
04:58:50.812 - 04:59:53.340, Speaker A: But even if you are building with the latest version of Solidity, chances are that you are interacting with a contract that was deployed using another version of Solidity and you still want to understand what and why things go wrong while you are testing your context or debugging them. So that means that we still need to support every version of Solidity probably forever. Another disadvantage is that creating these tools is very expensive and complex. And this leads to two things. The first one is that there are fewer tools than maybe there would be if these were cheaper. And the other disadvantage is that you get very inconsistent features across the different tools. For example, if you want to use console log today, there's only a few tools that support it, like Hardhat.
04:59:53.340 - 05:00:44.240, Speaker A: If you want a step debugger, there is just a few that have it, that have them. If you want to use a good integrated fasting system, there is just a few of them. And the problem with this is not that we want to have every feature that everyone has, but that these are very basic features that in other development platforms are a given. And they should be a given for every tool in Ethereum. But they are not. And that's something that we are aiming to improve. Instead, I think tooling should be different, tools should be differentiating themselves with more specific functionality instead of the basics.
05:00:44.240 - 05:02:07.284, Speaker A: And the way that we are planning to tackle these problems is with two new projects that for now we call Slang and ResNet. Slang is a new Solidity compiler that is going to be built specially for tooling. And ResNet is a library that provides a development network with all this rich functionality that Hardhat has. So as I just mentioned, ResNet is going to be a library for other tools to build on top. ResNet won't be a replacement for Hardhat network within Hard hat, but instead it's going to be its new core and the interface of Hardhat network will still be the same. It's being built as a platform, as a runtime observation engine that will let Kakat network be more stable, faster and mature, but also will let other tools get the same functionality for free. It's written in Rust so it can be run everywhere and distribute just as a normal library, like a C library.
05:02:07.284 - 05:03:49.644, Speaker A: And also it's going to be compileable to Wasum so that it can be used in the browser and things like Premix or Ethereum Studio can get all these features for free. It's going to provide all the functionality that hacksA network has out of the box. And instead of relying in Heuristics, it's going to depend on Slang's output to have an accurate understanding of Solidity, of what's going on everywhere. So we are going to be able to be precise on all the things that we do, but we'll also be able to do more stuff because we are going to have the information to do those things. And once the basic functionality is mature and we have the common base for a development network, we are going to work on more advanced tools, more advanced features that has network doesn't provide today like a step debugger, a gas profiler, code coverage analysis and more. Slang is a solidity compiler as I mentioned that it's going to be focused on developer tools. This means that we won't be competing with soil C but instead we will be focusing on development time of your smart contracts but like orienting the compiler to be able to integrate with other tools and provide all the information that those need.
05:03:49.644 - 05:05:34.030, Speaker A: But building a compiler is a huge challenge and we think that Susie does a good job on building a compiler, that it's good for running your smart context on Mainet and we pretend to keep using it for that so hardhat. And other tools that want to use Slang will build both with Slang and Solt C and use each of those builds for different things and of course deploying with the Solc build. Slang is also going to have an integrated language server which is a service that lets text editors and ides integrate with the compiler to gather features that advanced editors have to support the language for free. Things like shampoo definition, refactors, some to references, things like that kind of require a compiler to be built or at least part of the compiler. And we think that having them integrated within the compiler is a way to have them, to build them reliably and keeping them up to date with the evolution of the language. So we are also providing that out of the box. It's also going to have APIs for different tools to be built on top like exposing the parser or the type check system and those things are going to allow things like reliable, fast and up to date linters formatters and other things.
05:05:34.030 - 05:07:29.568, Speaker A: One of the key things of Slang as I mentioned is that it's going to generate all the metadata that ResNet requires, not only to be able to avoid relying on Heuristics, but also to let us iterate breathnet faster. So if we want to do anything that is not possible with bresnet we can just tweak Slang a bit and generate more metadata. And the cool thing here is that as we are not going to be deploying these bytecodes generated by compiling these smart contracts, we can tweak what we generate so that we can enable everything we want within ResNet. But maybe some of you are wondering on how reliable are things going to be if we compile with one compiler during development and with another one when deploying. And that would be a great question because if we use different compilers for these things this wouldn't be as reliable as just using Susie. But one of the cool things about Ethereum is that it's a completely deterministic and isolated platform or execution environment that lets us do pretty cool things. If you have two builds of the same smart contract that were built with different compilers but both of them did a good job like translating solidity to EBM bytecode, they should execute and give the same result.
05:07:29.568 - 05:08:57.944, Speaker A: There's of course going to be small differences in gas costs and stuff like that, but in general the modifications to the Ethereum state should be the same. If I execute a near C 20 transfer built in a smart contract built with Slang or built with Soil C, the end result should be the same. So we are going to take advantage of this and build ResNet in a way that can execute both versions of a smart contract at the same time. So instead of relying just on slang during development, we are going to be building with both and executing with both slang and soil C. We are going to trace both of them, compare the results and use slang to gather rich metadata of the execution and soil C to commit the changes that that smart contact execution made to the ethereum state. And in general this should work great. And let us have the best of both of both worlds reliable test results because they are the results that the Salt C version of the contract generated and that's going to be the same ones that this contract would generate on mainnet.
05:08:57.944 - 05:10:07.856, Speaker A: And at the same time we are also going to have as much metadata about the execution as we need. There's of course, a chance that these results don't match and this would probably be because some bug or immature aspect of slang. But that wouldn't be terrible either. Because at worst, what would happen is that the development experience would degrade a bit on a certain transaction or smart contract, but we'll still be able to rely on our test results, so we won't be compromising on correctness or security of our smart contracts. So the current status of these projects is different for each of them. RedNet is already under development, it's being built from the inside out of Carcan network. We are going to replace one module at a time and ship them as part of Karthan network.
05:10:07.856 - 05:11:11.480, Speaker A: Probably we'll ship both at the same time initially and do something similar to what I already mentioned of executing two things side by side and comparing results to ensure the correctness of ResNet before shipping it to production. And Slang is not being developed yet. We are building a team of compiler experts and doing some research and planning around it. But both should ship within the next year and will be shipped initially as part of Carhat. And as they mature, they will be exported as libraries and independent tools for other libraries and tools to be able to rely on them and get all this functionality for free. And finally, our goal here, both for reinhardt restnet and Slang, is for them to become the building blocks of the Tooling of Ethereum. Like all the major tooling.
05:11:11.480 - 05:12:36.820, Speaker A: And our objective is to lower the cost that I mentioned of building new tools and maintaining the existing ones so that this leads to new and more mature tools for eventually for all of its users and protocols that build on top of it. And finally, if anything of this looks interesting to you, we are hiding both for Breathnet and Slang, also for Hardhat and other projects that I didn't mention here. So feel free to go to this link, nomiclabs IO hiring and take a look at our shop listings there and if you have any question you can join our discord which is in our website, hardcat.org. And that's all awesome. Patricia, that was a greater view and I mean that's such a massive overtaking that you're going to go into over the next few years. You talked a lot of this is still in the works and especially for Slang. My only kind of question is how do you think about that? Especially when Solidity itself is also evolving in parallel.
05:12:36.820 - 05:13:58.670, Speaker A: What are some kind of things that you are thinking that should be kept in mind and how do you kind of match the direction and the speed of the VDM ecosystem evolving? Yes, I think that's a good question, especially about Solidity still evolving. I think that's a common fact for every language. It's going to evolve fast and tools are going to struggle to keep up with it and we are already struggling to keep up with it and these projects were made massive, are going to make keeping up with it much easier for us and other tools. But also as the ecosystem matures and gets bigger and has more tools and more stakeholders depending on Solidity, I guess the natural progression is for the evolution of the language to split apart from the evolution of the compiler and have some kind of governance over the language but that's still to be defined in the future. Absolutely. Obviously finding this out in real time with everybody else is a challenge. Anybody to know what this look like? But this is great.
05:13:58.670 - 05:14:17.940, Speaker A: I think you already talked about how people can get involved so check out Hardat.org and if you're interested in being part of this. So thanks again, Patricio, this is great. Thank you. I wish you all the best and can't wait to use playing in RedNet. Awesome. Thank you Karthik.
05:14:17.940 - 05:14:46.570, Speaker A: Bye, see you. And next up we have Gilbert and this is a very interesting talk that I'm super excited about. Gilbert is going to be talking about how do you actually write smart contracts without solidity. We're going to go into some internals about how all of this works under the hood. And without further ado, let's welcome Gilbert. I'll ask you to turn your camera on and we're good to go. Thanks a lot.
05:14:46.570 - 05:15:21.112, Speaker A: Let me share my screen real quick. All right. Hello everyone. My name is Gilbert. I am a smart contract auditor and instructor at Optilistic. At Optilistic, we do smart contract audits and we also train people how to write smart contracts and then place them. But enough about me.
05:15:21.112 - 05:16:04.752, Speaker A: Let's talk about smart contracts without Solidity. So we're going to go over several things in this talk. First, we're going to go over why should you learn EVN Opcodes as a smart contract developer. We're going to go over how to deploy a smart contract, or in other words, how to write Opcodes for deploying a smart contract without Solidity. We're going to take a quick look at a little new language called Trim. And then we're going to implement a full smart contract using these Opcodes. So first.
05:16:04.752 - 05:16:51.780, Speaker A: Why learn EVM opcodes? Well, essentially, you want to become a better Solidity engineer. What does that mean? If you know Opcodes, then you are better prepared for low level hacks and issues. Solidity's compiler has had problems in the past. If you understand Opcodes, you'll better understand why those things happened. Second, you want to have a deeper understanding of common design patterns, especially related to Proxies. Proxies use Opcodes all the time that are not available normally in Solidity. And it's great to have an internalized understanding of how smart contracts actually run when you're making transactions to these contracts.
05:16:51.780 - 05:17:29.760, Speaker A: Okay, so to start, we're going to look at what I call BASM, which is bear assembly. And basically what this is, is we want to be able to write these Opcodes without writing the raw bytecode. So on the left you have the bytecode, on the right we have BASM. So we definitely want to write what's on the right so that we don't have to. Well, I mean, it's pretty straightforward. You don't want to write what's on the left. And yeah, this is pretty much all it is.
05:17:29.760 - 05:18:04.216, Speaker A: There's pretty much no features in this language. All it does is that it takes your Opcodes and then converts it into its respective bytecodes and puts it all together. So let's use this to actually write some code. So for the first contract that we're going to look at, we are going to deploy a contract and it's going to be a very simple contract. There's not going to be any functions in this contract. All it's going to do is whatever transaction that's made to this contract, it's just going to return the number nine. Just blindly.
05:18:04.216 - 05:18:59.390, Speaker A: It doesn't even care, doesn't care about what function you're trying to call, doesn't care about your arguments. It'll just return the number nine. So as you probably know, when you deploy a smart contract, you deploy the code of that smart contract, but also some additional initialization bytecode. So here we have some init bytecode. And the way that it works is that the bytecode that you use to deploy needs to return the runtime bytecode. So in other words, in this example, the init bytecode, we have here the goal of this init bytecode. It can do other stuff, but ultimately it needs to return the data that represents the bytecode down there.
05:18:59.390 - 05:19:51.810, Speaker A: So when we make a deploy transaction, the runtime bytecode is not going to run at all. Only the initial bytecode runs just because of the way we wrote it, and then it will return it. So let's look a little bit at the details of how this works. So first we have a code copy, and this copies into memory a piece of the entire bytecode that you're running in your Create Smart contract transaction. So the first argument here, what I have here is EVM is a stack based language. So all this code that you see on the left is pushing onto a stack. And then when you run code copy, it just pops off the top three items in the stack to do whatever it needs to do.
05:19:51.810 - 05:20:44.672, Speaker A: So on the right hand side, we just have a syntax that's a little bit more readable for those who are not that familiar with Opcodes. So this code copy takes three arguments, and the first one is where you're going to copy to when you do code copy, you are copying your bytecode data into memory. So zero just says stick it into this flap. And as you can see, this is going to copy some code and we're going to see exactly which code it's copying. The second argument is the offset of your contract by code. So this we hard code zero x, zero C because it's 13 bytes before getting to that point. So that second half is our runtime code.
05:20:44.672 - 05:21:24.700, Speaker A: We want to start there when we do the copy. Then lastly, we tell it how many bytes to copy. So last over here, we have ten bytes because our runtime code is ten bytes. So that will copy ten bytes into our memory slot, which is at zero x zero. Now that it's in memory, we can use the return bytecode or the return opcode to return it. And return takes two parameters. First one is the memory offset we just wrote to zero x zero.
05:21:24.700 - 05:22:14.312, Speaker A: So we want to start returning data from that point. And then secondly, the length, which is again ten, because there's ten bytes of memory that we need to return. And that's pretty much it. So this memory or this data that we're returning, the green box, this is the code that the EVM will take and store at your new contract address. Now, whenever anyone makes any sort of transaction to your contract address, it's going to be running that specific bytecode, which again is the green box. So this works, but there's a problem. We are hard coding some bytes.
05:22:14.312 - 05:23:00.060, Speaker A: And when you're writing code, you definitely do not want to be manually counting bytes so that you can just get it to run. Adding one line of code will cause these values to be wrong and that's really bad. So that is the motivation behind the language Trim. So Trim is a little language that I wrote in a few days. And the idea is just to have a mostly purely syntax transformation so that you can write your code in a little nicer manner. You're still dealing with Opcodes. With Trim, there's not any fancy function calls or stacks or memory management.
05:23:00.060 - 05:23:48.380, Speaker A: It's almost purely syntactical. So instead of writing what you see on the left, which is the code we just saw, you can optionally write the thing on the right. Basically, the rule is anytime you have apprentices now, you're in S expression land and you can reverse the order of your arguments and it'll just translate it back to the left. So that's pretty straightforward if you don't have parentheses and you're still in Opcode land. For example, the stop on the right, that is just a plain Opcode feature. Number two is labels. Labels is how we solve the problem of manually counting bytes.
05:23:48.380 - 05:24:36.896, Speaker A: So on the left we have zero C and zero A. These are hard coded values based on the length of our code. Now on the right, we can write this hashtag runtime, and that just represents a location in your code. So the last runtime on the right, that is the actual label. And then when you reference runtime within an S expression, it will fill in that location for you. So this is a way to get around manually counting bytes. The first line, we subtract the total code size with the position of runtime and that'll give us our runtime code size and we dupe it so that we can use twice.
05:24:36.896 - 05:25:25.604, Speaker A: And then we code copy from zero to the runtime position with that length and return the length. So that's pretty handy. And last feature with Trim is instead of manually putting in strings, you can just write the string and it will translate it to that push statement for you. So again, these features are mostly syntactical. It's not going to manage memory for you. You're still writing up goods. Okay, so lastly, we want to look at an example of writing a full contract.
05:25:25.604 - 05:26:02.340, Speaker A: So here we are going to Emulate, or we're going to implement a version of this in Opcodes. So here's the solidity code. This is a little bit different from the standard greeter contract that you get from generating a new hard hat project. The main difference is it uses bytes 32 instead of string. And the reason for that is, just for teaching purposes, string is a lot more complicated than bytes 32. So I avoided that by just using bytes 32 directly. The other thing to note about this code is it has initialization.
05:26:02.340 - 05:26:39.490, Speaker A: So our bytes 32 greeting variable is initialized with Hello EVM. So that's something else that we're going to have to implement as well. So let's do it. All right, so on the left, we have our initialization code, and it's pretty much the same as what we just saw in two slides ago. The only addition we have is the S store. We are storing in stored slot zero, our string hello EVM. And that's pretty much it.
05:26:39.490 - 05:27:12.440, Speaker A: That's all you need. You just need these three opcodes. One opcode for S store, one opcode for push zero, and another opcode for pushing the string value. And then that's your initialization. Because it's initialization code, it's not going to make it into your runtime code, which is good. Now, on the right hand side, we have a reference for API encoded function cults greet. This is a function ID for greet.
05:27:12.440 - 05:27:58.488, Speaker A: And then on set greeting, that does have an argument. So you have the function ID plus the value of that bytes 32. And that's what that looks like. We're going to be using that or referencing it when we write the code to access that. All right, so we just omit the init code for the slideshow to make more room. The first thing we want to do is copy the function ID onto the stack, and this is the transaction data. So on the right, this reference, I didn't mention, it's the data that you send with the transaction.
05:27:58.488 - 05:28:36.010, Speaker A: So if you're making a transaction to our contract, most of the time you're going to be encoding your data using API. And that's what we see on the right hand side. So if they're calling Greet, then it's going to look like that. I can use my mouse, can I? If they're calling greet, then it's going to look like this right here. If they're calling set greeting with this parameter, it's going to look like that. In either case, we need to handle different functions in our contract. And the conventional way to do that is by using an API encoded function ID.
05:28:36.010 - 05:29:20.550, Speaker A: So we need to see if the first four bytes of our transaction data or our call data is either this here or if it's this here. And based on that, we're going to run different code. So that's what this first one does. Call data copy will read data from your call data. And the offset four is the length that you're reading. Zero is the starting point and one C here. This is the position in memory that you're writing to or you're copying to.
05:29:20.550 - 05:30:06.100, Speaker A: So zero, we want to start at the beginning, obviously, because the function ID is the first part of your call data. Four, we want to read four bytes. Four bytes is eight Hex characters so that we read the function ID and nothing else. And then this is actually 28, because this just makes it easier to deal with call data copy. We want to write it as A-U-N 256, which is 32 bytes. But we're only writing four bytes. We're just doing this so that we can slot it into a very specific spot in memory to make things easier.
05:30:06.100 - 05:31:01.722, Speaker A: And then here we are loading from memory position zero and m load will load 32 bytes. So it will catch the data that we just wrote. After that, we want to see if it matches a no function ID. And the reason we do that is because we're using trim. Now we're going to have two different labels. One label for our greet code and one label for our SEC greeting code. So this here, this is pushing a known function ID onto the stack and then it's duplicating the input function ID.
05:31:01.722 - 05:31:43.270, Speaker A: And if they match, then it's going to jump to that label. So EQ will take the top two items of the stack and if it's true, it'll push a one, if it's false, it'll push a zero and jump. I will only jump if the top of a stack is not zero. So in other words, if this matches the call data's function ID, then it's going to jump to Greet and we're going to do the same thing for SEC reading. So if this does not match, then jump ID or sorry, then jump. I will not jump. And then we'll move on to the next one.
05:31:43.270 - 05:32:17.010, Speaker A: And then we're going to check. Well, does our input match this function ID? And if it does, then we jump to set greeting. Otherwise we revert. But this logic here, this is how Solidity gets compiled down. Obviously Solidity compiles into more bytecode than this with some extra features. But this is essentially how it works. It's basically a case statement.
05:32:17.010 - 05:33:19.000, Speaker A: Does the function ID match this go here? Does it match this go here? And that's it. So now let's get into writing the actual code for these functions. It's a convention to have a jump destination opcode for places you expect to be jumped to. It actually doesn't do anything, but I guess it makes the code a little nicer to read. And for Greet, the only thing we need to do for Greet is we need to load the current greeting. So first we load the storage at position zero and then we store that into memory because we need to return from memory and then we return it. So in other words, we're loading from storage into memory the current greeting and then we are returning that value.
05:33:19.000 - 05:33:58.290, Speaker A: And that's the entirety of our Greet function set greeting is pretty similar. In fact, it's even simpler. Call data Load will load again 32 bytes from your call data and here four is the offset. So we are skipping four bytes because we want to skip the function ID. And then the next 32 bytes we know is our parameter. So we load that onto the stack. That comma shouldn't be there, that's a typo.
05:33:58.290 - 05:34:49.650, Speaker A: But we load the string onto the stack and we store that into storage slot zero and that updates the storage. That's the entirety. Of the secreting function, then here we have a stop, because just in case later we want to add more functions. We don't want to accidentally run over the normal problem with which statements you just kind of go over your case. So that's what stop is done. That's what stop is doing there. So, yeah, that's the entirety of the contract.
05:34:49.650 - 05:35:42.674, Speaker A: But how did we do so if you compile this in Solidity, you end up with 404 bytes, and the code that we just wrote is only 76 bytes. So that's pretty cool. Of course, this is not without its trade offs. We are not checking call data length, for example. Solidity checks call data length by default. That avoids, for example, accidentally setting an owner address to zero without providing a zero without providing an address, and some other stuff. Solidity also makes sure that all your functions are not payable by default, which means that it generates spike code to revert if the transaction has ether value in it.
05:35:42.674 - 05:36:26.290, Speaker A: It does that for all functions, unless you specify payable. So there's trade offs there, but it's pretty cool. We can write some Opcodes and we can be how many times is this? Like four times smaller than the default Solidity bytecode generation. But yeah. So hopefully that gives you a good taste of how to write smart contracts without Solidity. With plain old Opcodes. We use Trim as a language just to make things a little bit easier to read and write, but ultimately it's still just Opcodes.
05:36:26.290 - 05:37:13.840, Speaker A: So learning this stuff will make you a better engineer. It will help you internalize how things work at the lowest level of the EVM. And Opcodes are just good to know in general, because things like Proxies and Static calls, those are all using Opcodes that are not available in normal Solidity code. And lastly, we teach smart contract engineering and security at Optilistic. So if you or anyone else is interested in becoming a smart contract engineer, we take mostly senior engineers. We only make exceptions for special cases. But yeah, if you're interested, then visit our website and contact us.
05:37:13.840 - 05:37:53.942, Speaker A: Awesome. Thank you. Gilbert, a couple quick questions. Where can people learn about Trim? And could you talk a little bit more about some resources to sort of play with it or debug things and just how people should think about trying it out when they're doing an October directly? Yes. So preparing for this was a little bit rushed, I'll be honest. Trim is not published yet, but it will be soon. And we also have a really cool in browser tool for kind of writing Trim.
05:37:53.942 - 05:38:26.198, Speaker A: And it just automatically runs your code as you type it, and it shows you the results, it shows you your memory, it shows you your stack usage, your gas usage, and all of that. Yeah, if you're interested in knowing when it does get released, just shoot us an email and Optilistic and I'll put you on a list. Awesome. Wonderful. Well, thank you so much for that amazing demo and presentation and can't wait to see how to play with trim. Thank you very much. Great.
05:38:26.198 - 05:39:01.400, Speaker A: And with that, we are ready for our last talk of the day. Up next, we have kelvin. And kelvin's going to be talking about smock. And I'll let kelvin introduce what smock is, but I'm already excited about the talk title, and I'm also glad that kelvin used a 2007 plus version of microsoft word instead of the original 2003. So without further ado, let's welcome kelvin. Here we go. Let's give you turn video on, and you can get started, kelvin.
05:39:01.400 - 05:39:20.140, Speaker A: All right, cool. Fantastic. So let me share my screen. Where is this? Okay, sharing. Perfect. Let me make sure I can see the comments just in case. Great.
05:39:20.140 - 05:39:58.730, Speaker A: All right, so hello. Hello. I'm kelvin. And today I'm going to present to you smock. Smock is a tool that well, it's the solidity mocking library, and it's a tool that we originally built over at optimism last year to sort of simplify our smart contract development process. And today we've evolved and we've created a v two in collaboration with DFI wonderland. And we would like to present it to you and hopefully see if you can get something out of it.
05:39:58.730 - 05:40:29.380, Speaker A: Let me make sure these are actually showing up. Where are we? There we go. Got the twitter handle for optimism, got the twitter handle for DeFi wonderland, and you've got my twitter handle. So first things first, I want to set the scene I want to set the scene for you and for why you need smock in your life. This is you. You are a smart contract developer. You are a very smart, smart contract developer.
05:40:29.380 - 05:41:11.712, Speaker A: You are a big brain, gigantic brain smart contract developer. And as such, you sit on your very expensive, very powerful 2013 MacBook pro, and you spit out smart contracts into the ether. Now, spitting out smart contracts into the ether is a very dangerous activity. You need to be very careful when you do this. But you are a big brain smart contract developer, and you know that what you need is you need well tested smart contracts. So let's talk about testing. How do people usually test their smart contracts? Well, they might do a little bit of this.
05:41:11.712 - 05:41:54.284, Speaker A: They do some JavaScript, and they might do some calls and some assertions. They might do a little bit of this and some calls and some assertions. And then they sit there and they put a little checkbox on their contract, and they say, it's safe, it's perfect, it's beautiful. But as you can see, this is a single, small brain smart contract. But you, as the legitimate DeFi developer, you don't build these small, smart contracts. You build real smart contracts. You are a big brain DeFi developer, and you only build the biggest of brain contracts, right? So when your smart contract systems start to get bigger and start to get a little more complicated.
05:41:54.284 - 05:42:42.876, Speaker A: It gets harder to effectively test your contracts. So you need to evolve with it and you need to become a big brain DeFi contract, smart contract tester. So how does this work? How does Smock make your life easier? Well, let's first talk about what Smock is through an example. I'm going to talk about a very specific example of how Smock functions and why it might be useful and sort of get you to sort of bring back dark memories from your past about difficulties that you might have had while trying to test smart contracts. Because I've definitely had these dark memories blocks deep in my brain. Smock is the solidity mocking library. The solidity mocking library.
05:42:42.876 - 05:43:01.936, Speaker A: There is no better. It allows you to write better tests. That is a key feature of smart. Why do you need it? Let's talk examples. This is you. This is you, big brain testing creature. And you're going to write some smart contracts.
05:43:01.936 - 05:43:31.736, Speaker A: You're going to start with writing a small smart contract and then you might write a big smart contract and you want to test how these things work. You want to test them individually. You want to test how they work together. You throw out words like unit testing and smoke testing and integration testing and whatever, all these different testing things. But ultimately you want to make sure that your system works or people might lose money, which is a big problem. So let's throw an example on this specifically. Let's talk about something reasonably complicated.
05:43:31.736 - 05:44:39.124, Speaker A: We're going to talk about a Merkel AirDrop. Do you know what a Merkel AirDrop is? It doesn't make a difference. The point is something reasonably complicated that people can kind of comprehend, right? So let's say we have a Merkel AirDrop and then we have a recipient of a Merkel AirDrop, right? So how would you go about testing the Merkel AirDrop contract? Well, you might do some stuff like you're going to have to create a Merkel tree and you're going to have to hash a bunch of stuff and you're going to have to deploy the contract. And then you're going to have to publish the Merkel root and you're going to have to test if you have a balance and all this, right? So it's a ton of effort, but you need to do that in order to effectively unit test your smart contract. But how are you going to test another contract that interacts with your Merkel AirDrop contract? How are you going to do that? Because you want this, right? This is the ideal end result. The ideal end result is that your recipients get their money and they can go off and do stuff and they can spend it on yams or whatever they want to spend it on. And you don't want this, right? You don't want their drop to just fall on the floor because no one can get their money and you just whatever.
05:44:39.124 - 05:45:21.292, Speaker A: It's a whole headache, right? How are you going to test this? Well, let's talk about this other character, right? This other AirDrop recipient. Think about how you might test this AirDrop recipient. Well, there's the AirDrop recipient. The answer to this question is basically for most people, if you think about it, you'd have to basically perform the entire testing process that you already performed for the first contract, right? In order to test if this person is going to get a balance, you have to go and you have to create this merkel AirDrop contract. And you got to go and set it up. You got to do this. You got to load the whole contract.
05:45:21.292 - 05:45:47.160, Speaker A: You got to deploy it. You got to do all this setup, right? This is a huge headache. So how do developers actually do this in practice? How have they been doing this? They've been writing these fixtures, right? All these fixtures. And then you get fixtures inside of your fixtures. And then you get fixtures inside of those fixtures. And it keeps going until at the very bottom, there's a Bose Einstein condensate of fixtures. And all matter is just fixtures.
05:45:47.160 - 05:46:16.072, Speaker A: This is bad. What you really want is you want smock. So how does smock fix your problem? Smock means you don't need to load anything. Smock means you don't have to do all of this junk setup that you on, all this fixture code that just completely pollutes the code base. And you can just get straight to the AirDrop. Straight to the AirDrop. And how you do that? Through the power of mocking.
05:46:16.072 - 05:46:33.364, Speaker A: We love mocking. Mocking is a beautiful thing. So let's talk about it. Let's talk about how this tool actually works. Now, you have a scenario. You want to test a contract that interacts with a much more complex contract. But you don't want to set up the entire complex contract because that's a huge headache.
05:46:33.364 - 05:47:17.296, Speaker A: So how does this actually work? How are we going to make this happen? Well, Smock gives you two primary tools, gives you fakes and it gives you mocks. So first we're going to talk about fakes. This is what it looks like to create a fake with Smock. So you can see here, hopefully people can see my little mouse. If you can't, you can see here that we are going to import Smock from DeFi Wonderland is where we're hosting the NPM package, where we're hosting this. You get it? And then it's really straightforward. This is a hard hat plugin.
05:47:17.296 - 05:47:56.432, Speaker A: So you get this beautiful syntax where I can just say smock, fake, and then the name of the contract. And now I have a fully fledged fake version of my contract. That contract doesn't have any real code, but it has a real address. And if you make calls to that contract address, you are actually going to get back real results. So, for instance, I can make. Let's say this fake has a function called Bark and I tell Bark to return woof. If my smart contract calls that fake contract, it says, you know, fedcontract Bark or know contract Bark, it's actually going to return woof when you run the tests in the EVM.
05:47:56.432 - 05:48:33.808, Speaker A: So it hooks in to the EVM in hard hat. The hard hat EVM at a low level. And so it really simulates that there is a smart contract there and you can make it do whatever you want. You can even do these beautiful assertions, this nice syntax. If you use these Smock matchers, you can get this nice syntax and even make assertions that your mock was called with a specific input data. This basically just removes all of the need to do all this setup, right? I don't need to set up my Merkel AirDrop anymore. I just create a fake version of the Merkel AirDrop and I just give myself a balance in it.
05:48:33.808 - 05:49:06.250, Speaker A: I just say the balance of me returns however much I want. What crazy. So the docs are at Smock readthedocs IO, and inside those docs you're going to find some really cool things as to what you can do with these fakes. So, pretty straightforward. One thing you can just do is have it return default values. Default values, it's all zeros. So if the function is called Get address and it returns an address and you just return like this, it's going to return the zero address.
05:49:06.250 - 05:49:44.068, Speaker A: You can also make it return fixed values. You can make it return a given address, a specific address, or you can make it return a number depending on what the function expects to return. You can also make the function revert. This is really useful if you want to test cases where, okay, this one thing went wrong and I want to make sure that my contract behaves properly. But think about it. You have to do all this weird modification to your other smart contract to be able to get it to revert and to get into that specific state where it's going to trigger that one specific revert. No, get rid of all of that.
05:49:44.068 - 05:50:00.730, Speaker A: It's just going to return the revert message that you expect. And you can test the behavior of your contract. Fantastic. You can make a revert with a string. You can make a revert with bytes. You can make a revert with whatever you want. But here's where it gets more interesting.
05:50:00.730 - 05:50:25.376, Speaker A: You can also make it return more complex structures, right? So we have support for Structs. You can make it return Structs. You can make it return arrays. So these are really interesting data structures beyond just the basic ones. You can even make it return dynamic values. You can stick a function inside of the return and this function can return whatever you want. And it can look at this.
05:50:25.376 - 05:50:51.310, Speaker A: So it could randomly return one value or the other value. I wouldn't recommend doing this in practice, but you could definitely have a more complex piece of logic inside of this return function. This return function could even be asynchronous you can go call. You can make an Http request inside of a smart contract, which is a little insane, but only during testing. Don't try to do this in production. It won't do anything because that doesn't make any sense. But in testing, you do whatever you want.
05:50:51.310 - 05:51:36.970, Speaker A: Fantastic. And you can even use the arguments that were provided to the function inside of the function that you are triggering. So for instance, if I had a function that took a UN as an input and I wanted to return whatever the input is times ten, I can do that. I can just have it take the input to the function and multiply it by ten. And I'm going to get my output value and it's just going to return what I expect, essentially. And I have these beautiful things written in JavaScript that can do whatever you could possibly imagine to make your testing life easier. You no longer need to set up your contracts to be in this very specific state.
05:51:36.970 - 05:52:00.960, Speaker A: Fantastic. So fakes already get you really far. Fakes are a beautiful thing, but I have to tell you, there is something beyond fakes. There's something even more beautiful than fakes. And that of course is mocks. Mocks are fantastic. And let me tell you a little bit about mocks inside of Smock.
05:52:00.960 - 05:53:01.220, Speaker A: Smock mocks are like fakes, but they're backed by a real smart contract. So this means that you deploy your smart contract and you essentially have the ability to manipulate your smart contract after it's been deployed, which can be very useful. So a basic feature that you have with this mocking ability is call through, right? By default, when you call your contract, it's a normal contract. It's a standard solidity smart contract. It's going to behave just like the solidity code that you wrote, but you can also manipulate it. So let's say by default I have an add function and I call Count and it's going to return ten whatever, right? And this is because there's actually solidity code running, but then I'm going to say, okay, but for now I actually want to make Count return one. And now Count returns one.
05:53:01.220 - 05:53:29.432, Speaker A: Easy, right? Beautiful. But there's more. And now let's see if this works because I animated this by hand in PowerPoint drumroll. There we go. You can set the value of a variable. This is where the game changes with MOX. You can completely manipulate what's happening inside of your smart contract.
05:53:29.432 - 05:53:54.976, Speaker A: You can set the value of any variable to whatever you want. Look at this. My variable name is being set to 1234. I can set the owner of my contract so I don't have to do all this. What if there's a bunch of complex logic that I want to test that's based on an internal variable being something. Well, I don't want to do all the complex logic to get the internal variable to be equal to that value, right? There's a huge amount of effort that goes into this. You don't need to do that anymore.
05:53:54.976 - 05:54:36.928, Speaker A: You just say, okay, well, I'm going to test the case where this internal variable is equal to 1234, and I want to see how my contract works when the internal variable is equal to 1234. But there's more. You can even set the value of a struct or a mapping. You can set the value of whatever you want. You can set a value of a nested mapping. You can change literally anything inside of your smart contract and make it possible to test every tiny little interaction without mountains of boilerplate fixture code that somebody's going to have to maintain for the rest of time. This is how you should be writing your smart contracts.
05:54:36.928 - 05:55:06.344, Speaker A: And if you're not writing your smart contract tests this way, you are missing out on a deep and satisfying tool. Tell you that this is you after learning about Smock. This is the entire universe after learning about Smock. And this is Smock. So there you go. Smock is all there is. The entire world is now just Smock.
05:55:06.344 - 05:55:18.636, Speaker A: So how do you get started? Well, it's pretty straightforward. D five wonderland smock on NPM. The code is available. GitHub.com d Five Wonderland smock. And the docs are at Smock. Readthocs IO.
05:55:18.636 - 05:55:42.856, Speaker A: It's quite intuitive. The docs are good. The code is pretty straightforward. It's got a really nice API. Shout out to the DeFi Wonderland team for really cleaning up the API, and I really recommend that you check it out. You try to write a few tests, especially for your more complicated smart contracts, and get a feeling for just how easy it is to build great tests when you're using Smart. And of course, I'm going to throw this in there.
05:55:42.856 - 05:56:17.750, Speaker A: Optimism is hiring if you're bored of your Web two job and you want to work on cool stuff like this. And there's the Jobs link lever jobs lever, co, optimism. And that's my talk. Pretty straightforward, pretty short, but I hope you enjoyed it and very excited to see all the new people who are now going to use mock forever and always. Thank you. Thank you so much. Kevin, I'm still just laughing through all the incredible stuff that you got in this.
05:56:17.750 - 05:56:55.216, Speaker A: The drum rolls kill me. It's really good. One final plug for everybody. For the sake of everybody following up, what is the URL? To learn more about Smock, the website, the GitHub, all these things in one off slides, but tell us where people can go to use it immediately. Yes, I would recommend starting with looking at the GitHub. It's got instructions on how to get started and it's got links to everything you'll need to know. So GitHub.com,
05:56:55.216 - 05:57:58.036, Speaker A: Dfiwunderland, Smock will have everything you need to get started. Awesome. And one last question before we close today is obviously you've been working on this thing for a year, and there are a lot of people that are using this, but what does the future of the library look like? What are some features or additions or things it's not good at that you want to do? Just talk to us a bit more about that. So the thing that I'm most excited for is we're planning a rewrite of the core internal stuff. Smock was originally uses a very hacky method to do what it does. It uses the fact that the ethereum JS VM emits things in events, and it turns out that emits objects by reference, and you can listen to the event and then manipulate the thing that you receive in the event, and it will have an impact on the VM, which is really terrible. So what we are planning to do is a more comprehensive rewrite, which essentially involves a fork of the underlying VM instead.
05:57:58.036 - 05:58:43.964, Speaker A: And the feature that I'm most excited for is the ability to directly test libraries. If you've ever tried to test libraries, you know that the standard pattern is you create these mock libraries that wrap those libraries and expose all the functions. You can actually test them. And so in the planned sort of Smock V three, it'll be possible to directly test libraries with one of these contracts. So you don't need to keep writing this boilerplate mock code for your libraries. And you'll also be able to manipulate internal functions so you can, you know, my internal function is going to return whatever I want instead of just these external public functions. Oh, that is incredible.
05:58:43.964 - 05:59:00.250, Speaker A: It's like God mode for EVM. God mode for EVM. Cool. Well, thank you so much for that incredible presentation. We got to get you back on just so we can see what the next one would look like. Now you have to top yourself, if not at least meet the same expectations. But this was great.
05:59:00.250 - 05:59:30.572, Speaker A: Thank you. Wonderful close to today's devtool summit. Thank you for hundreds of you for sticking all the way to the end. It's been six incredible hours of just back to back devtool showcases and talks. So I can't wait for the next version of the summit ourselves. All right, so in conclusion, I got two quick things for everybody. First of all, for all of you who are hackers watching the summit, that submission deadline for your projects is this Sunday.
05:59:30.572 - 05:59:54.708, Speaker A: So be sure to make sure that you do everything before 03:00 P.m. Eastern this 03:00 P.m. Pacific. So 06:00 P.m Eastern. This summit. If you have any questions, you have any last minute things that you're stuck on, you can ask all of that, or you can ask us for help on the discord for Deep Global and just make sure that you're ready for the submission deadline.
05:59:54.708 - 06:00:32.640, Speaker A: And before we close today, I want to just remind everybody that our next hackathon will be unicode. We are proud to announce that we're doing this event for the uniswap grants ecosystem and this is going to take place at the end of this month. So if you're interested in hacking on more DeFi stuff and building on top of uniswap protocol, check out Unicode ethgoba.com and sign up to hack for the next hackathon. So with that, I want to sign off today and hope all of you have a great weekend and we'll see you all next Friday for the Ethanline finale. Take care everybody. Good evening.

00:00:07.210 - 00:00:27.480, Speaker A: Awesome. Thank you so much. And this is going to segue perfectly so you can hang on here. We're going to have a panel now on mephconomic security in liquid and restaking protocols. So it'll be myself moderating and we're going to have Turam and then we're going to be bringing on Tarun, Ben and Hathu. This one. How's it going, everyone?
00:00:27.850 - 00:00:30.710, Speaker B: Hi yo.
00:00:33.450 - 00:01:30.890, Speaker A: All right, sounds all working. So your last slide actually segues perfectly into the thing that I wanted to ask for the first question, and it is around that centralization risk which exists for both for both restaking and liquid staking with both of the topics here. Liquid staking so far has been somewhat limited in the amount of operators that are generally actually working under their hood of some of these liquid staking protocols. So there's going to be a challenge there. Lido has talked about in their V two things like the staking router, starting to use DBT to try to decentralize under the hood. And then similarly for restaking, there is that centralization risk of ideally we would like to have these super horizontally scalable things like IDA that are easy for nez to run, but someone could also show up and put solana on restaking. And now there is effectively a massive incentive out there to be a really sophisticated restaker.
00:01:30.890 - 00:01:46.320, Speaker A: So where it's supposed to take advantage of staker heterogeneity? Does it just then incentivize that kind of lower bound to actually just move up? So I'll turn it over to Yushram to kind of continue where you left off on the last one to start?
00:01:46.770 - 00:02:55.278, Speaker C: Yeah, no, I think if you look at aspects of decentralized trust, there are two distinct aspects of decentralized trust. One is just coming from the amount of economics and the other one is it comes from a certain amount of decentralization or collusion resistance. And I think different services rely on different kinds of security. Like for example, if all you want is for example, for certifying that a certain execution condition is valid and you want somebody to underwrite this risk, as long as there is a significant amount of economics underpinning it, it is enough. Like if you had $1 billion restaked on a validity condition, which is checkable on chain and slashable, then it doesn't really matter whether that $1 billion comes from one node or it comes from thousands of nodes. I'm talking about this from the point of view of services building on top of ICLR. And for those services we would expect basically there is a significant benefit to centralization.
00:02:55.278 - 00:04:17.882, Speaker C: So there is like a small centralized committee or just like Coinbase or some few nodes which can just opt in and provide these services which are primarily just economic in nature. And there is another set of services which simply does not suffice to have economic security, you need decentralization based security. And some, some examples there are you want to have an ordering layer which has censorship resistance. You want to have secure multiparty computation where you're splitting up some secret and information into different nodes and the core assumption is that these different nodes don't collude with each other. There are other examples like the threshold cryptography we saw earlier, where you need to split up a key into secret shares, even things like data availability, reliance to some extent on honest majority or like an honest certain fraction assumption. And these examples all demand a decentralized quorum. So what we expect to happen is on more expressive restaking platforms like Eigen Layer, people will specify that they only want a decentralized quorum for certain tasks and this can promote an additional yield to accrue onto the decentralized quorum.
00:04:17.882 - 00:04:32.210, Speaker C: And basically, instead of all of us just talking about the ideology of decentralization, there is an actual value of decentralization and if the users can just pay up for it, that's really the best way to promote decentralization.
00:04:37.460 - 00:05:09.150, Speaker A: And Hasu, I wanted to turn to you on the kind of first half of that question, curious for your take on the liquid staking tokens and kind of the underlying operators of those, particularly because it's unlikely that we're going to have a million different types of liquid staking tokens. So it is important if we want a decentralized validator set, most likely that kind of the underlying components of Lido, rocket pool, et cetera, that they are able to more sufficiently decentralize that validator set underneath and kind of how you see that landscape and how do you see that playing out going forward?
00:05:10.000 - 00:06:57.650, Speaker D: Yeah, great question, John. I think that first of all, I agree it's super important that the liquid staking providers decentralize because there is a lot of centralizing pressure on them because of the network effect of the underlying token. And we have seen a range of different designs from completely centralized providers like Coinbase on the one end, to arguably very decentralized providers, but less scalable like rocket pool on the far end and then Lido maybe to the slight left of rocket pool making another trade off, more scalability but less decentralization. And so it comes down to a trade off and the question is will those trade offs remain or can we have the best of all worlds, right? Can we have scalability and decentralization? And I think the answer is mostly yes. So there might always be the need for some amount of governance that cannot be removed. So my favorite mental model for thinking about this is basically thinking of a staking pool as another variant of a lending market where you take money from stakers and you basically give it to node operators, right? And there's different types of lending. There's one that's secured by reputation and then you don't need a lot of collateral or anybody basically can borrow and then you do need more collateral to secure it.
00:06:57.650 - 00:08:09.264, Speaker D: I think whenever you want to have scalability, you basically can't have over collateralized lending only. And so you need some way of dealing with this reputation challenge. And I think it would be interesting to see how well we can bring these kind of attestations to someone's reputation. How well we can make that trustless, how well we can bring that on chain entirely. For example, through the use of inspecting performance debts, building reputation over time, but also minimizing the harm that a faulty note operator can do through techniques such as DDT. And then in the center I see something like the staking router that you alluded to in Lido V two. That is basically the central hub where anybody can, where anybody can add new modules, new combinations of node operators and collateral and reputation and whatnot.
00:08:09.264 - 00:08:43.730, Speaker D: And then there's some central mechanism to allocate those and to allocate the eve that comes in to those modules. And I would be very interested to hear Tarun's talk because I think what Tarun thinks about this because he's one of the leading experts on lending markets and parameterizing. parameterizing? parameterizing, yeah, basically the relationship between the collateral and the borrowers and so on.
00:08:49.830 - 00:09:32.014, Speaker B: Yeah, I kind of think the Lido model is the end game. The router model is sort of the end game for this. It's funny you mentioned, hey, you could implement salana on top of a restaking mechanism. Well, I don't think running layer two sequencers is that much less difficult than keeping up a Salana node. If we're going to be completely honest. If you look at all the Arbitrum posts, if you look at all the optimist, it's not that different. And I think in the roll up world, sequencers and providers to roll ups are going to have to do a lot of operational, have a lot of operational overhead.
00:09:32.014 - 00:10:39.590, Speaker B: So I think the centralization aspect of like, oh, I don't know how to correctly restake or allocate my assets is a problem you will have generically in a decentralized sequencer roll up world, those users are going to have to be just as sophisticated. So I guess I see it as less of a concern from the perspective of like, we're already moving to this kind of extremely complex ecosystem of chains and in that world you're inevitably going to have to solve these allocation problems no matter what participant you are. And based on that, I think figuring out what the collateralization looks like will change over time, especially if a lot of Lido node operators are restaking to also provide sequencing services for particular roll ups. And I think of course, Ben has wrote a nice post about kind of opinions on that and how to think through how the strategic decisions when you're in a decentralized.
00:10:43.770 - 00:11:30.600, Speaker E: I just one thing to add about the question about? What if a protocol like Solana, which favors centralization, were to run on Idolater? Whether that favors centralization of ETH staking I think it really depends on the relative fraction of value that's accruing to staking ETH from participating in ethereum itself versus another protocol. So it would only really become an issue for centralization if the value of value coming from Solana was much greater than the value or equal to or greater than the value coming from participating in Ethereum itself. Yeah, that's just a very important part to take into account.
00:11:33.370 - 00:11:41.898, Speaker C: Ben, do you want to say something about how lightweight decentralized sequencing can be? I think basically decentralized sequencing will be.
00:11:41.984 - 00:12:21.430, Speaker E: From the perspective yeah, I think that it's anyways a deciderata of decentralizing sequencers to make it lightweight so that it can be fully decentralized. I think there's a bit of a different question from the concern that something like Salonic could also come onto E Three Staking platforms. But yes, you can definitely try to make decentralized sequencing as lightweight as possible. And that's what the E Three stakers would be participating in. Like, E Three stakers would not be participating in complex roles like proving they would be participating in the sequencing. You don't need to have Ether stakers participating in proving if they are participating in the sequencing.
00:12:22.090 - 00:12:31.450, Speaker C: Yeah, I think even more specifically, I think the idea that you don't even need to hold the state of the roll up right. You don't even need to participate in execution.
00:12:31.790 - 00:12:33.402, Speaker E: Just ordering and data.
00:12:33.456 - 00:12:48.670, Speaker C: Just ordering and ordering is a stateless operator, so you just order a bunch of transactions and as long as you're collecting the fee for ordering the transactions, those transactions are kind of like forced to be included. So that's how you can scale sequencing.
00:12:49.650 - 00:13:32.778, Speaker B: The reason I would slightly push back on this is looking at, say, the Arbitrum example of the sheer amount of network bandwidth that the sequencer had to handle. It very much reminds me of the Salana DDoS level bandwidth. Like, you're talking about people sending like 100 gigabits a second to a single entity. So we still haven't gotten to that point where I would say I believe that they're that different to a Node operator. I'm sure Hetzner probably can, which is like a big data center operator. I'm sure they have the exact statistics on how much bandwidth Arbitrum has had to deal with versus Solana and uptime statistics. And I bet you that's not that crazily different, especially after the Airdrop.
00:13:32.778 - 00:13:39.978, Speaker B: I think they're not so different in terms of operational overhead. That's sort of my main point right now.
00:13:40.084 - 00:14:04.460, Speaker C: No, I think that there may be one thing to it, but I want to just say that the problem of not having mev auctions is what has contributed to that. And to segue into your next talk, and as well as the decentralized sequencing system has reasonable mev management, which Ben has doubt a lot about, I think you would not have a problem like that.
00:14:05.310 - 00:14:49.350, Speaker E: I also wonder how much that needs to correlate with the value of Staking. You could also have, as a public good, an infrastructure or server that's doing a lot of a lot of work in terms of routing messages. But in order to participate and stake in the protocol you just need to do lightweight operations. And so in some sense that public service is just a public service that's being subsidized by everyone participating and it's not so that by staking more you can then run that service and therefore profit more. So I think it depends on the relationship between staking and participating in different roles.
00:14:53.290 - 00:14:53.702, Speaker C: Yeah.
00:14:53.756 - 00:15:52.940, Speaker A: John I was going to say the one point I would push back on a little bit from earlier is in regards to how much the rewards actually need to be for something like this to create a centralizing force where it should be equivalent to or possibly greater than the type of rewards you would get on Ethereum. I would say that doesn't have to be the case. I mean, this is exactly what we see with Mev boost and you can kind of think of any additional restaking revenue to be viewed as a form of mev to any kind of potential Restaker. And we see that with Mev boost where hey, if I could earn 4% or 5% of my own, but I can earn 6% with MAV boost. 95% of people are going to run that thing and they don't even necessarily need to create that value, particularly if this restaked solana if they say they have an inflationary token that they're giving to the Restakers and that subsidizes like a high yield. So that risk still does still exist somewhat in my mind. I don't think there is a perfect answer to it.
00:15:52.940 - 00:16:10.000, Speaker A: One of the interesting things Anna sure and we've talked about before is actively incentivizing decentralized committees with higher rewards as opposed to centralized ones, such that there's actually an explicit advantage which is a very difficult problem to do but theoretically could be done and it's a very.
00:16:10.370 - 00:16:14.562, Speaker D: Rama I would have a follow up question to that.
00:16:14.616 - 00:16:15.220, Speaker B: So.
00:16:17.510 - 00:16:21.506, Speaker D: How do you identify decentralized committees?
00:16:21.698 - 00:17:25.634, Speaker C: Reliably yeah, I think this is going to be whole fun. Another service which would basically do it and just to clear our perspective on this is Eigen layer wants to be one of the paradigms that we lean heavily into is intersubjectivity. intersubjectivity is that most subjective decisions are made at the edges, not at the platform. So we don't want to make a judgment saying somebody is more decentralized and somebody else is less decentralized and each service needs to consider its own requirements when making these decisions and these could be supported by decentralization oracles which then steer people in those directions and for the particular needs of each of the services. Like a secret sharing is an example. If you send this n shares of the secret to the same person you basically end up getting no guarantee even if those set of people are geographically distributed. There are other use cases where for censorship, resistance or legal and other purposes.
00:17:25.634 - 00:17:54.610, Speaker C: You want people from different jurisdictions to participate. That's a different kind of like a requirement. So each service will have its own requirements and they will lean on a new ecosystem of oracles which just try to do this thing. And then it's hard to identify decentralized nodes. It's easy to identify the centralized nodes. We will know what the exchange wallets are, we'll know what some of the biggest operators are and so on. And just excluding them just still gives us a long tail of nodes to work with.
00:17:54.610 - 00:18:04.820, Speaker C: So there are all kinds of ways that services can do this and there's no one universal correct, good answer. And it's going to depend very much on the service.
00:18:05.770 - 00:18:58.194, Speaker B: So actually, one thing I've kind of wondered as sort of a research direction towards this that I don't think we can do right now, but maybe in a couple of years we'll be at the place to do this is there's this line of research on doing secret leader election in proof of stake with threshold homomorphic encryption? And there's a question that I've always wondered of can you do private elections of committees, not just single leaders for this type of thing? If you had say, threshold Fag and would that be sufficient for the type of thing you're talking about? Because I actually think you could generalize their method to multiple participants, but no one's done that yet and I think that would be the full proof. Obviously, relying on Fhe for anything is always scary.
00:18:58.242 - 00:19:20.906, Speaker C: But there's two aspects to this. If you start with a centralized taking pool and just choose like even many leaders randomly, still not going to do any benefit because all leaders are basically the same person. So that is a kind of baseline of decentralization that you absolutely sure, top of which you need like multiple secret leader election pro to make it even more protective.
00:19:21.018 - 00:19:43.510, Speaker B: Yeah, sorry, I agree. Definitely you need to kind of have the state distribution be more uniform over unique identities, not just addresses. But I guess there's a lot of this other stuff that I think has been lying in the shadows around this type of stuff that maybe we'll see live in one to two years, hopefully.
00:19:47.610 - 00:20:53.020, Speaker A: Turning directions a little bit. I just got a rather spicy question someone sent me just a few minutes ago during the talk it relates to. So I know, Shirom, you've spoken in the past how Eigen layer could particularly later on be viewed and restaking broadly as some kind of like free market upgrade to Ethereum, where particularly as it gets more difficult to upgrade Ethereum, validators can effectively opt into it as a free market and do it themselves. The inverse side of that I wanted to ask everyone's takes on is does this give kind of additional unearned governance power to validators? Where for example, if Ethereum developers in the community, there's some upgrade that they view as rather risky this is not something that we should be doing, but the Restakers say hey, I can make a bunch of money from this thing and we're all going to opt into this. Where do you kind of see that kind of tension between that governance power which we may not want them to have versus also that flexibility, the positive thing of being able to kind of free market upgrade over time?
00:20:53.470 - 00:22:12.654, Speaker C: I think the real answer to this lies in the full nodes, okay? So as we all know, there is a power in the full node which is not fully specified in just the internal nodes, which is that if there was an invalid state transition, the full nodes can reject it. And imagine now there is an upgrade on top of which comes from something like Eigen layer which everybody opts in and all the validators are doing it, but at the full node level. So buying opt in, for example, at the full node level gives you like a significantly boosted security beyond the economic security that you can get by the stakers opting in. And it is at that threshold that really the buy in from the rest of the community is needed. And I have some ideas, untested ideas on how a new service for example, might be able to do it. For example, a service may commit to burn eat if all the light nodes upgrade or full nodes upgrade to when receiving the fees. Fees is not just distributed to the stakers, some fraction of the fees just burned as a compensation for the externality to the full nodes which then need to upgrade to not only check the validity condition on the core protocol, but also on this protocol extension.
00:22:12.654 - 00:22:40.590, Speaker C: So there are all kinds of interesting things that can be done. But also the flip side is for example, if there is a censorship market built on restaking where you just say that hey, I'm going to pay to censor somebody's liquidation transaction so that I can earn the money. I think this can only be dealt with socially by whatever social slashing these stakers and so on. So it does become more complicated.
00:22:41.730 - 00:23:22.650, Speaker B: One thing I guess I would say is in what world have if we view sort of restaking as sort of bridging the gap between like clients full nodes and archive nodes each of those levels had different governance rights. In some sense, in almost every network, all you're doing is you're taking these discrete node types and making a continuous spectrum out of it. And in some sense light nodes never really had governance rights before, right? They sort of were just forced to eat whatever shit merkel tree is shoved at them. And I think all you're doing is just widening that spectra from these three delta functions.
00:23:25.570 - 00:23:59.560, Speaker E: Would also note that validators do already have the agency to run another protocol, e three Staking is subsidizing that agency, right? It's saying you already have estaked. So now it's less costly for you to run this additional protocol, but they already have the agency to run another protocol. And it's also not clear that by running another protocol this necessarily is equivalent to an upgrade because it would only be if they were running that to the exclusion of running Ethereum itself.
00:24:00.810 - 00:24:32.740, Speaker C: So it's a protocol add on. You could think of like if everybody's running it, you could think of it as a protocol add on and that's where I was going with. But full nodes don't check for the validity of this protocol add on and so you could ask them to check for it by doing this fee burn. There are some fans of 1559 and fee birth here. So that's basically a compensation for the externality to the full nodes for having to check that they're continuing to do that.
00:24:36.700 - 00:25:35.788, Speaker A: Great. Another question I know that a lot of people have kind of had trying to get their head around is this idea of leverage, quote unquote in staking and race staking, noting the clear difference in that obviously you take on a leveraged trade or something like that, you might get liquidated on that due to just market conditions. If you're restaking and you're honest, you shouldn't be slashed assuming everything operates correctly. But you are increasing the leverage in the sense that you potentially have a very high ratio of value secured relative to the amount of stake actually securing that thing, which is moving in this direction of bold security. And that works primarily under the assumption where this increases the value of something like ETH with the value that it's securing because more value goes to it. But the other side of it is something like restaking. One of the interesting benefits is you could do dual staking tokens with it where there's some other kind of token that captures value.
00:25:35.788 - 00:25:53.760, Speaker A: So do those things kind of become at ODS with each other at a certain point where now ETH isn't necessarily capturing that value, which accurately compensates it for the additional risk that it's taking on economically, where some of that value starts going to the second token more and more and they want to kind of move in that direction.
00:25:54.340 - 00:26:49.964, Speaker C: Okay, so I think there are really different, like you said, from the staker point of view, if they're honest and if the protocol code is correct, they'll never get slashed. So let's keep the staker out of the picture. From the service point of view, are you increasing additional profit from corruption by adding new services on top? I think that's the high level question and I think there is a lot more nuanced question and I don't think we'll get to this thing here. The idea is if you look at Ethereum, it's securing 400 $500 billion of value with $25 billion of stake. And first we have to get to the bottom of why is it okay to do this. It's okay to do this because the total value secured is not what is protected by what is staked. The total value transferable out of the system within a short period of time, within the attack duration, is what is being protected by staking.
00:26:49.964 - 00:27:04.520, Speaker C: And by having this mental, this crypto economic model correctly programmed across various services, you can actually get very strong, probably correct guarantees on what the crypto economic conditions are for safety.
00:27:08.380 - 00:28:27.840, Speaker E: John, I think another way of looking at that issue that you described as leverage, so just from a different angle is that because an E three staker is now participating in many different sources of revenue, right? For an individual chain that it's securing, the value that being generated by that chain is low relative to the value of the ETH overall being restaked because it has many other sources of revenue. And so this becomes an issue of the fact that if the relative value of this one chain that it's securing is low relative to all the other chains it's securing, then the marginal utility is too small for it to care that much about that one chain. So in essence, from the perspective of the chain, the risk arises and dual staking can lower the leverage of the E three stakers. Right. And it then ships the security onto another source, what whoever is what the other token is. And so that is helpful for the chain itself. I think it's the same issue as being over leveraged, but just from a different angle.
00:28:28.580 - 00:29:17.200, Speaker B: Yeah, I would just add I like thinking of it as even though I'm sure by mentioning this word, people will suddenly get scared. But I like viewing it as this sort of like tranche style insurance where the second token is taking the equity style losses beyond a certain point and the ETH is not, which is that's sort of this over leveraged piece. There's not going to be some huge restaked ETH liquidation versus some fraction of that gets absorbed by this other token. Now the question is, can the other token ever get to a market cap close enough for it to be meaningful relative to ETH? And that's a different question. Will there be enough liquidity for it to actually be this sort of loss asset? But in theory that's sort of what you're kind of hoping for is kind of this split.
00:29:19.720 - 00:30:19.860, Speaker D: I would also point out that you can't really prevent validators from taking on additional leverage. So for example, we've seen the rise of liquid staking tokens and those liquid staking tokens are now the primary form of collateral used in ethereum lending markets in order to borrow anything. So we already have an implicit amount of leverage in the system today. And so people are blaming liquid staking tokens for that which is, I mean, it's just inevitable. But so to those people, I would say even before that in proof of work, there was already a lot of leverage in staking, in mining, that is because all of the big mining farms were all deeply, deeply leveraged. So they were buying all of their machines actually on credit. They were borrowing against their machines and they were using their machines to collateralize as well as their future cash flows to buy more machines.
00:30:19.860 - 00:31:10.584, Speaker D: And so this is something that all protocol designers have to keep in mind, that you just can't control what people do outside of your protocol. And that's why you have to operate with big margins of safety. Like Sriram was saying, the ethereum protocol does not secure all of the money that is sort of part of the ethereum state somewhere. It's not even all of the money that is currently being transacted, it's only that which can be controlled by the ordering, basically, because not even 100% malicious validators could force an invalid state transition. So yeah, that's why I think the gist is basically leverage is always possible, there's no way to prevent it and you just have to design around it.
00:31:10.782 - 00:31:38.640, Speaker A: Curious, quick follow on for anyone, and I would agree on this, that something like liquid staking tokens were inevitable. In hindsight, are liquid restaking tokens inevitable? Looking forward where you have a position saying that, yeah, I have my ETH staked, but I'm also restaking to these four other things and this gives me the right to the associated cash flows of those. And there's all these different liquid restaking tokens with an additional layer.
00:31:40.020 - 00:32:07.960, Speaker C: I think it's much more likely that liquid staking protocols will integrate some of the services under the hood, which means existing liquid staking tokens kind of eat the additional reward by just integrating under the hood for that certain services which are highly yield bearing rather than you having to go and create a whole new liquid staking token for restaking.
00:32:08.860 - 00:32:55.610, Speaker B: So I guess I sort of think of it as like if restaking is successful in the sense that it has hundreds of applications using it, there will inevitably be some notion of Etfization where people want different classes of ETH. There'll be like the most high grade ETH yield, but it's just pure staking. There's like the slightly riskier ETH yield which is like maybe staking plus submitting Oracle updates. Then there's maybe the slightly higher risky version like data availability plus Oracle updates. This all depends on what the slashing rates are. The relative ordering is not perfect, but I could imagine people basically fractionalizing what level of ETH risk do you want?
00:32:57.020 - 00:33:38.710, Speaker D: Yeah, I would agree with both of those. I think that the liquid staking protocols will internalize restaking if it turns out to be profitable and useful. And I think also down the line, maybe in a few years those same liquid staking protocols will come out with different tranches of eve that give different levels of risk and seniority to investors. I think that's one of the main things that remains in the design space for. These protocols after stuff like the liquid staking router and DVT has been figured out, I think.
00:33:42.670 - 00:34:35.100, Speaker A: Great. So one of the applications that you guys are very familiar with that will be secured potentially with resaking and has been talked about a lot in some of the previous talks, is something like a shared sequencer layer, something like Espresso has talked about in the past week, even in simple forms of a shared sequencer, aka. Effectively based roll ups, where you're using the L one as a shared sequencer. One of the interesting points in the value flow of mev, as Justin was speaking a lot about earlier, is that in the simplest case, that value now effectively goes to the L one itself. So in base roll ups it would go to ETH. In a shared sequencer, the value from the roll ups mev that they would normally get from their own sequencers, in the simplest case, would go to the shared sequencer layer itself. And so the question then becomes kind of around the incentives for roll ups to use those things if they want to keep that kind of value for themselves.
00:34:35.100 - 00:35:09.110, Speaker A: And more value should be created in this system because I know sure amount of some great tweets about this the other day is like kind of the baseline is what they would have already had as mev and now you should have an additional mev that's opened up by the interoperability between all of them. So in theory of more value created, but that kind of incentive alignment issue of like how do we return that value to roll ups in some form such that they're incentivized to opt into this thing. And it's not just nobody wants to opt into the thing that will optimize everyone because I want to keep most of the value myself. Like how we kind of think about those trade offs and value flows.
00:35:14.120 - 00:36:08.020, Speaker E: I could take a stab at this to go first. I think there's a lot of analogies here too. Like you have a music festival and you have all the bands showing up to the music festival and the music festival is selling tickets, right? And how do you allocate, how do you pay the bands to show up? And it's also not a one shot music festival, it's a repeated game. So eventually if the bands realize, oh, the music festival organizer is taking all the profit, we're just going to run our own music festival. So I think that before we can talk about the economics of shared sequencing and how and to whom the value accrues, it's important to identify who are the players. Right? I think Barnabay has a very nice post on this for roll ups, which distinguishes three parties like users, a roll up operator, the base player. And here with shared sequencing, we have another party, we have the shared sequencer and the nodes operating it.
00:36:08.020 - 00:37:01.270, Speaker E: But I think we should also separate at the roll up operator level between the provers who are actually incurring the operating costs and the governance of the roll up that has the power to decide two things. How do you define the VM right? And which sequencing layer is the roll up going to run on? And importantly, not only do they have the power to decide that initially, the governance has the power to decide to move away from the sequencing layer. And that gives the governance of the roll up leverage. That governance could be encapsulated. Well, it could be a central company or it could be encapsulated in some token. Let's just call out the governance. So base fees covering the operating costs like proving plus some epsilon profit that can be easily directly programmed into the VM and they need to do that because they need to get provers to run.
00:37:01.270 - 00:38:06.660, Speaker E: But obviously that base fee doesn't capture mev. And so then there's negotiation between the roll up Governance and the sequencer. The roll up Governance wants to know am I going to make more running on this shared sequencer than I would make running my own sequencing layer, right? And obviously there's a cost to building your own one time capital cost to building your own sequencing layer, but ultimately you want to know that you'll be making more going to the festival rather than running your own show. And so I think it comes down to a negotiation and that can manifest in many different ways. One way is if the average mev that the roll up would make on its own can somehow be estimated or simulated, or it can be adjusted dynamically based on historical average, then that can be hard coded into the base fee of the roll up VM. But I think that's quite hard. And that base fee would not be covered by users be subsidized by the sequencer nodes.
00:38:06.660 - 00:39:01.688, Speaker E: Maybe they go into a deficit sometimes, but on average they would be able to cover the cost and take the surplus that comes from shared sequencing. Another way would be probably the ideal option, but maybe challenging to perfectly achieve is if the allocation algorithm, the mechanism that the sequencer is running, is transparent. In other words, if there's transparency in the mev auction or the block building process, and if it can calculate and verifiably report, what is the marginal contribution of each roll up to the total mev and it distributes that. Proportionally to each roll up, taking a cut for itself then that would foster the strongest trust and incentive alignment between the roll up governances and the shared sequencer. But I think that's an important research question and that I think is like the ideal option. But it may be hard to achieve.
00:39:01.784 - 00:39:40.970, Speaker C: I think it's there is some inspiration from the atom world on decent security here, which is basically doing dropouts, like randomly dropping out one of the chains and then calculating what the average builder value is. And then you can use that to calculate or estimate what the looking at the chat here estimate what the marginal value is for the different ones. Another way is having actually like coordinatorial auctions and then now I have to segregate platform.
00:39:44.700 - 00:39:49.550, Speaker B: That sounds very expensive for the participants, but yes, that's possible.
00:39:51.440 - 00:40:44.990, Speaker D: So I think there's one option that we haven't discussed yet, which is just allowing roll ups, not enshrining a single sequencer layer, but just having the ability to profit switch between different ones. And it's a funny thought how sequencing layers could kind of be destroyed and be created on like a poor per block basis. So I don't know if that's viable or not, but I think definitely in the future of multiple sequencing layers, nothing speaks against these sequencing layers competing on a per block basis for the mev and just bidding up the value paid to the proposer or to the governance as it would be in that I think. I think that's another option.
00:40:48.060 - 00:41:44.860, Speaker A: Probably get in trouble for asking one more question because we're running late, but I want to ask it. I'm curious for thoughts regarding it's something that I talked a bit about earlier as well and Barnby has discussed and asked of his idea of PEPC the idea of protocol being able to enforce different proposal commitments. And the first part of that abstraction that he's talking about is this kind of idea of an in protocol Eigen layer, where you can make the protocol aware of these commitments such that you don't end up with this. Problem where the protocol is not aware that, hey, maybe this person is slashed and it's not really aware of what's going on with its own security at that point. So I'm curious as to any of your thoughts on is it helpful to kind of build these things in more to a greater extent, to be able to just give the protocol more awareness of what's actually going on with its own security? Or are there other externalities that think about in there where that may not be attractive?
00:41:45.600 - 00:42:33.804, Speaker C: Yeah, I think the first part to that is how to make ethereum aware of a slashing event on something like Iden layer. I think the answer to that is actually simple and thankfully coming up in an upgrade called smart contract triggered withdrawals. Right now withdrawals are validator triggered, not withdrawal, credential triggered. And once you change that, the awareness can be kind of instantaneous. As soon as the contract is aware that there is a slashing, it immediately goes and triggers the thing from Ethereum. So that's the answer to the first part. But there is a second part of the benefit which I think you accrue by having it be enshrined as opposed to being on a kind of like secondary layer like Eigen layer is.
00:42:33.804 - 00:43:08.340, Speaker C: The benefit is that suppose somebody makes a proposal commitment that I will only include the decrypted version of these encrypted transactions in the block. But they actually don't. They actually don't include the decryption on Eigen layer. All that we can do is to slash them for 32 eat. So the maximum liability is like bounded by 30 to eat in eigleair. Whereas if you make it in protocol I think this was mainly Barnaby's idea. The idea is that if you make it in protocol it can be part of the validity condition of the block itself.
00:43:08.340 - 00:44:03.720, Speaker C: That the proposal met. The condition or not, this is just a much higher path. There are ways to I think therefore if and when such a thing is possible, it's actually beneficial. But the problem is that if somebody writes a bad opt in condition which had some smart contract bug could lead to mass slashing events and things like that and the only protection we have right now is based on Eigen layer, is based on a subjective slashing veto. And I don't think Ethereum would want to internalize such kind of subjective committees. So the evolution that I imagine is going to be that initially people play with a lot of these models on an opt in layer like Eigen layer and once that is much more robust and stable, some aspects of it can be basically just enshrined default into Ethereum.
00:44:09.690 - 00:44:23.820, Speaker A: There we go. Awesome. We will cut it there. Thank you everyone for this. This was a lot of fun. And again we will perfectly transition. We've got Tarun, who will be staying on for the next one, who in his own words is going to be talking about how who kill fair order.

00:00:07.610 - 00:00:20.400, Speaker A: Hello, everyone, and welcome to the Hackfs Consensus Lab workshop. Introducing Interplanetary Consensus IPC. Joining us today is Alfonso de la Rocha, who will be taking us through this session. And with that, I'll pass it over to Alfonso to get the session started.
00:00:21.170 - 00:01:07.662, Speaker B: Thank you much, Rory. Thank you for having me here. So today, hopefully will do a high level overview of IPC so that you get a sense of what is this framework, how you can use it. And finally, I will do a quick demo where I will deploy a smart contract in one subnet, a subnet that I have running. But in any case, I will point to all of the instructions and the getting started guides, docs and so on, so that you can tinker with it your own. Okay? So I don't know if we all agree, but I guess that everyone is aware of how consensus algorithms in blockchains are a bottleneck. So if we want massive adoption in Web Three, being blockchain one of the key models of Web Three, we really need to scale the consensus algorithm of our blockchain networks.
00:01:07.662 - 00:02:01.886, Speaker B: And if we see at what the two most used networks, which are bitcoin and ethereum there, we see that the throughput is around the dozen of transactions per second. And in order to scale them different layer, two solutions are coming into these ecosystems. But if we look at more like next generation, if we can call it like that, blockchain technologies, we see that all of the technologies that try to scale vertically, they are limited by the validator spec. So in the end, the consensus algorithm, we are limited, the throughput is limited by the specifications of the validators that are running that consensus. So we see that we can have whatever transaction hope. But in the end, the sequentializing stage of the consensus is limiting the amount of throughput that we can get in our blockchain networks. After these realizations with IPC, what we are trying to do is to horizontally scale blockchains.
00:02:01.886 - 00:03:19.930, Speaker B: So seeing that we have this limit of vertical scaling where there's a maximum transaction throughput that we can get at a consensus layer with IPC, what we want to propose is a framework that allows us to horizontally scale the same way that we horizontally scale right now in cloud infrastructure. And these are the kind of targets, like when we were designing IPC, and as we are deploying and we are developing IPC, these are the kind of targets and the kind of features that we are targeting as goals. First of all, as I said, if we really want massive adoption of Web Three, we should be able to tackle and to adopt with our substrate, with our infrastructure, web Two scale throughput. And this is not the case right now. I mean, there are some attempts to deploy social networks, to deploy other high throughput applications, but so far, the moment we go through the blockchain, we have a scalability limit there. But then there are other interesting features that currently we don't see in blockchains and that by horizontally scaling we could achieve like for instance secure global finality, fast optimistic local finality. Which means that depending on our use case we may want really fast local finality and then slower and more secure finality in other levels according to the use case.
00:03:19.930 - 00:04:20.554, Speaker B: And right now we don't have a way of fine tuning the substrate and fine tuning the consensus and the finality of our blockchain network in order to fit the needs of our application blockchains. Generally they are not partition tolerance. So if we are running a use case on a blockchain and part of our network or the network where we are interacting with loses connections with the rest of the network. So there's a partition in the blockchain network, there's no way to make progress, make the use case like our application to run and potentially keep catch up in the future. So the idea is that with IPC we're going to build subnets that will be partition tolerant. So we're building an isolated instance of a network where we can run our application and we will be able to interact with the rest of the networks in this ecosystem. Meaning that even if for some reason our network is running locally and loses connection to the rest of the HerKey, we would still be able to operate locally and eventually settle our changes to the rest of the network.
00:04:20.554 - 00:05:12.622, Speaker B: And finally, like what I was mentioning, it would be great if we can have horizontal scalability the same way that we have it in cloud infrastructure these days. And it would be great if this can be demand based. So instead of the protocol enforcing like in Sharding or any other horizontal scaling proposals out there where partitioning is explicit and like the storage is partitioned explicitly, it would be great if users could play with the substrate, play with the infrastructure to fine tune it to their needs. And this is basically what we are aiming with IPC. So in IPC, in the end, what we have is an on demand horizontal scalability framework in order to horizontally scale initially filecoin. So obviously we are focusing on filecoin initially, but the design is general enough to allow us in the future to port the solution to other networks. And how IPC works is in the following way.
00:05:12.622 - 00:06:34.742, Speaker B: We start from the Falcon mainnet and whenever a user sees that for some reason, like for instance in Falcon we have 32nd block times and for their use case this is not good enough, they will be able to deploy a new subnet. So deploy a new network instance that has still by design connectivity, by design interoperability. So the ability to interact with the Falcon mainnet from this isolated network that it spawns and it will also anchor its security to that of the upper layers of the heroic. So in this way, whenever a user needs and I'm going to show a figure in a minute to illustrate this, but whenever a user deploys a new instantiation of a network in a new layer, it will still be able to interact with the rest of the network and anchor its security to upper layers of the hierarchy. That potentially will be more secure than the subnet. And right now these subnets, they run BFT consensus. So it's a BFT based consensus, kind of a BFT with weighted consensus where the voting power is weighted by the stake and the collateral that a validator has in a subnet.
00:06:34.742 - 00:07:49.794, Speaker B: And another interesting property that these subnets have is that they enforce. So IPC enforces a firewall property, which means that whatever happens in a subnet, so if something wrong goes in a subnet because there's an attack, because there's a misconfiguration or whatever, the impact that this has over the upper layers on the rest of the networks in the hierarchy, it is limited. And as I said initially, the subnets, they all run a single consensus, that is a BST like consensus. But in the future we are trying to make this as modular and as configurable as possible to enable other kind of consensus algorithms. And how is this implemented? Like in the end, all of the operations and the logic of IPC are implemented through a set of on chain FEDM contracts in each of these networks that we run. So in the Falcon main net and from there in the different subnets. So to illustrate a bit how IPC works, let's imagine that here in the root, this is our Falcon main net, we have a 32nd block times we deploy our super cool DFI application and it doesn't have the kind of finality or the features that we need.
00:07:49.794 - 00:09:03.862, Speaker B: Users will be able from the Falcon mainnet with IPC to deploy their own subnets in this way so they will be able to spawn in a new level. And each of these subnets, they are independent networks in itself and they are all running so validating transactions in parallel subnet will be running this BFT like consensus. They each will have their own state and they will be able to run independently with the caveat that through IPC, each of these networks they will still be able to interact with other subnets in the herer key. So root t zero one will be able to interact with root t zero two. And also we have a periodic checkpointing from subnets to the upper layers of the hierarchy so that we can keep some pieces of the state of the subnet in the upper layers in case something goes wrong, so that we can build fraud proofs or we can build any other kind of security enforcement protocol. So the idea is that right now the UX, as you'll see in a moment, it's a bit rough, but the idea is that we want to expose all of these interfaces to users so that they can fine tune the substrate to their own needs. And this is recursive.
00:09:03.862 - 00:10:10.490, Speaker B: So meaning that the same way that from Falcon mainnet, a set of users were able to deploy their own subnet and start operating over there and interacting with the rest of the hierarchy. If at some point we see that there's a subnet, that it's reaching capacity, or it doesn't have the kind of substrate of features that we need, they can also deploy a new level of subnets from a child subnet. So we could have layer three and so on. And in this way, building an IPC, builds a hierarchy, recursive hierarchy of different subnets that interact with each other and run the APC protocol throughout the hierarchy and going back, moving into more of the implementation of the protocol. How does this look like from a system perspective? So, let's imagine that we have this root debt and these two child subnets. What we have is a set of on chain contracts, specifically, and mainly the gateway actor and the subnet actor. The gateway actor is the main, like the common actor that all subnets have and that implement the core logic of IPC.
00:10:10.490 - 00:11:06.702, Speaker B: And then the subnet actor, which is a user defined actor that subnet operators can deploy with the specification of all of the policy for their subnets. So the collateral, the kind of requirements in order to join as a validator in the subnet. So all the policies that you can think of and that you want to implement in your subnet, this subnet actor. Right now we have a reference implementation, but in the future we are looking into all users to come up with their own subnet actors, deploy their own subnet actors, and in this way have an ecosystem of subnet operators and subnet developers. So we have these actors that are all around in the different subnets and that implemented the on chain logic for the protocol. And then we have the APC agent, which in the end, we can think of this as an orchestrator. So a process that we run locally in order to interact.
00:11:06.702 - 00:11:56.286, Speaker B: So it abstracts from all of the interactions that need to be done for IPC with the different networks. And finally, we have the last piece of the puzzle, which is the peer implementation for these subnets. So in the end, we have like these subnets, what they're running is the same exact at this point, it's running the same exact stack as the Falcon network, because what we have, like subnets, they run modified a fork of lotus that we call ETCo. That has been modified to run a different consensus algorithm. And this consensus algorithm is the high throughput BFT protocol that I've been talking about that is sorry, that it's called the mere transfer consensus. Yeah. And the IPC agent, in the end, it's your entry point for IPC.
00:11:56.286 - 00:12:48.740, Speaker B: So in the end, if you want to run an application that interacts with Filecoin Mainet for some storage stuff. Then you have some application in a layer two subnet and then a layer three subnet, and you want your application to be able to interact with all of these subnets. Usually you don't interact with each of these subnets individually, especially when you want to do IPC specific features, but you use the IPC agent, which is the same instance, and interacts with all of these networks. And it's abstract for you all of the low level interactions that need to be done IPC wise in order for your application to be able to use IPC. And finally to wrap up this high level overview. Okay, IPC is really cool, but I don't know when to use it. Here I share a few questions that you can ask yourself to see if IPC fits your use case or not.
00:12:48.740 - 00:13:50.770, Speaker B: You can think of IPC as a let's call it cheap and lightweight way of deploying a full blockchain stack. So whenever you have to agree and share information between different parties, and you want to have Fast Consensus with Fast Finality, it may be a good option to deploy an IPC subnet if you are used to interacting with Fevm Smart contracts. But the Falcon mainnet may not have the highest throughput and faster finality that you need, but you still want to be able to interact with storage that lives in the Falcon main net. This may be a good case. As I said, it is an easy way of deploying a full fledged blockchain. You have some features to interact with other blockchain like other subnets in the hierarchy, but you don't need to use it. You just spawn your lotus with these Fast Consensus invite a bunch of validators and you will be able to run this blockchain with all of the RPCs and the semantics that you're used to from the Falcon ecosystem and the Falcon stack.
00:13:50.770 - 00:15:05.450, Speaker B: And of course, if you have an application that needs an incentive mechanism, but you don't want to figure out all of the blockchain, all of the crypto token and so on, it may be a good option. And also for verifiable computation, right now we have the amount of features that we have. Of course it's limited, but we're growing in the number of features and we want to be able to switch runtimes to configure the cascos. So in the future you will be able to do more stuff and configure and fine tune the substrate of these subnets to fit better the needs of your applications. And moving to more practical matters, if you want to start tinkering with IPC, here I share a few and I can share at the end the slide so that you can navigate all of these links. But we have already a testnet where you can interact with IPC and that runs the I mean, this subnet is called SpaceNet, and if you go to SpaceNet IPC space you will be able to get some test file for the SpaceNet network. All of the instructions of how to connect to SpaceNet and how to use SpaceNet can be found in this repo.
00:15:05.450 - 00:16:16.558, Speaker B: And then if you want to learn more about IPC, what is the Mirandra protocol, what is Mir, how IPC works and so on, I highly recommend going into this IPC space link where hopefully you will have references to all the basic knowledge that you need and the basic reference to start using IPC. Then for the technical implementation, all of IPC runs on four different code bases. So actually three different code bases, but one is replicated because subnets right now run through a set of FVM contracts that are native actors. So they are bundled with the built in actors. This has historical reasons, but yeah, the reference implementation is written in Rust and it's bundled in in the built in actors when you deploy a subnet. But we are working on an implementation of the IPC contracts for solidity so that they can be deployed in calibrationnet, in even the filecoin mainnet. So in that way we are able to deploy subnets from these networks.
00:16:16.558 - 00:17:18.760, Speaker B: And finally, that's why I said that there are three main code bases. This could be one like the on chain logic implemented through a solidity contracts and a set of native actors. And then we have Udco, which is our Fork of Lotus, with the modified Consensus and other IPC related features, and the IPC agent, which is the central point, and the subtraction that you can run in order to orchestrate all of the low level interactions with the different subnets and what your application will potentially use to interact with. Finally before I move into the demo, so if you want to know more about Consensus Lab and what we're doing. So IPC is one of the projects that we're doing, but we are also figuring out ways of scaling filecoin through the Consensus algorithm. So on, I leave you here a bunch of links if you want to learn more about what our team does. And finally, if you have questions, if you have even suggestions, bug fixes, if you want to interact with the team.
00:17:18.760 - 00:18:32.654, Speaker B: We live in Slack and in the Falcon Slack, and these are some of the interesting channels where you can interact with us. The Consensus for more of general consensus algorithm related or scalability related topics, the IPC specific channels and finally the SpaceNet specific channel for those of you that are interacting with SpaceNet. And you have questions, bugs, suggestions, any other thing that may come, like what I would recommend. There's a lot of information here, and it may be hard to grasp initially, but my recommendation would be to initially just go to the IPC space website that I mentioned and then reading a bit the IPC agent documentation. In the IPC agent repo that I just shared and the SpaceNet like skimming through the SpaceNet repo. And it would give you a sense of what is the state of the technology and how you can start interacting using IPC and building applications on top of the SpaceNet and IPC testnet. And finally, let's start with the demo.
00:18:32.654 - 00:19:34.020, Speaker B: So what I'm going to do for this demo, I already deployed a subnet, I'm going to show you briefly how to deploy a subnet, but whatever works. So I'm going to show you how to deploy a contract in a subnet. And it's not as exciting as it sounds because in the end the fact that we're using Lotus means that everything that you see in the file conducts and that's why I link it here. Regarding smart contracts, not storage specific features, but all of the smart contracts, interaction with FEDM, all of the CLI commands and RPC endpoints that we have learned to love, all of them are exposed for subnets because we are a fork of Lotus. So in the end, anything that you want to do in a subnet ideally should work from scratch. So you just have to follow the pipeline docs, just that the blockchain step that you're interacting with is different. I mentioned this because if you see that there's something that is not supported or you follow the pipeline docs and something fails, come to the pipeline, slack start ranting about it so that we are aware that this is the case.
00:19:34.020 - 00:20:36.662, Speaker B: And with this I'm going to start sharing briefly my terminal to show you something and then I'm going to come back to my browser. All right, so I guess that hope everyone can see now my terminal. Right now what I'm showing is just to show you what is a subnet running. So in the top screen you can see my IPC agent connected to the different subnets that I'm running. And then in the bottom screen you see one of my subnets running. I'm just showing you how it's generating blocks every second because we are running these flash consensus. So I'm going to show you briefly like the IPC agent CLI to show you some of the commands that we support.
00:20:36.662 - 00:21:34.374, Speaker B: So you see that you can run the demon. There's a bunch of subnet specific operations, config operations, wallet, cross messages, checkpoints, so there are a bunch of operations there that allow you to interact with and use IPC through the subnets. And the most interesting ones of course are the IPC agent subnet. That gives us all of the things that we can do related to subnets. Right now you can see here in subnet list that I'm running, just one subnet that is this root T 1002 that is running with a collateral of two file coin and that it has this 192 circulating supply inside. So this is the amount of filecoin that has gone from the root net. So from SpaceNet, from the SpaceNet root net to the subnet so that it can be used there if we want to deploy a subnet.
00:21:34.374 - 00:22:18.338, Speaker B: It's quite straightforward. So the steps are the following. First, we deploy our subnet actor that is going to govern the is going to govern the policies for our subnet that this leaves in the pan. So let's do this subnet create. So I'm saying I'm going to create a subnet from the root. I put some random name and I say the minimum number of validators checkpoint and period and so on, potentially once you read the documentation, all of this because we don't have a lot of time, all of these flags will make sense. But what we do with this is that we deploy a subnet actor that is going to be the one that governs the policy of our subnet.
00:22:18.338 - 00:23:10.362, Speaker B: So we see that here we created subnet actor with ID t 1003. If we list the subnets now, we see that the subnet, the new subnet is not there yet because no one has joined. And now we're going to join the subnet so that we register and we can start. I'm joining the wrong one. So I was joining this one. I want to join the three with let's put three password so that you see a different number. And then again, like the flags will make sense once you read the documentation and you see that with this we were able to deploy a new subnet and with free fibers of collateral and no circulating supply because there hasn't been any kind of interaction with that subnet yet.
00:23:10.362 - 00:24:12.942, Speaker B: And from here you will be able to deploy your validator, deploy your subnet and start running this independent network that I was mentioning with this. This is just to give you a brief overview of the end to end of operating a subnet. And now I'm going to move into the running a subnet, like being a user of a subnet side of things. And for this I'm going to do this subnet RPC to make easy fetching all of the data to interact with a subnet. We have this command line that gives us if we are running, like now I'm running the IPC agent is interacting locally with the nodes that are running the subnet. But you could be running the subnet in some remote endpoint. And with this command, that where we're getting all of the information that we need in order to connect to this subnet because the chain ID will change according to the subnet ID.
00:24:12.942 - 00:25:00.070, Speaker B: And then we may be interacting with the subnet either through glee or through other endpoints. That is not necessarily our local peer. In our case it's the local peer. But that way we don't have to even remember how to connect and how to interact with the subnet. So this is the endpoint of the peer running the subnet and the ten ID. And now what I'm going to do is configure my MetaMask and deploy an EVM smart contract over this subnet to show you that the interaction is exactly the same, but it goes way faster due to the consensus algorithm that we have. So I'm going to change again what I'm sharing here.
00:25:00.070 - 00:25:37.126, Speaker B: So I'm just copying yeah, here I'm just connected to my IPC root net. And what we're going to do is add in MetaMask, the network, the new networks that the subnet that we want to interact with. This is the chain ID. Hopefully I know it by heart. If not, I will have to look at I will have to look to the signal. So sorry about that. Again, we copy here our IPC address.
00:25:37.126 - 00:26:14.398, Speaker B: The symbol is T file, all of the instructions. Again, I'm doing those instructions that you can find in the filecoin docs to show you how you can interact with a subnet using the same kind of tools that you are already using to interact with any of the testnets that run Fcvm or Falcon mainnet. So now we switch to root T 01002. In this case, you see that I already have some fucking there because I was doing some testing, but I'm going to send a bit. Yeah, actually you don't see my terminal, so that makes no sense. And we are three minutes almost on the top of the hour. So I'm just going to show you how to deploy a subnet.
00:26:14.398 - 00:27:04.420, Speaker B: Like, you see that MetaMask is integrated directly to the Tao subnet and we're able to deploy a contract with Renix or any of the tools you're used to. And you'll see that this is going to be really fast because the fact that we have 1 second block times makes it really fast to interact with these child subnets. So we're going to compile these simple, stress solid contract and let's get the injected provider. And now if we deploy, I mean, you don't see the prompt from MetaMask asking to pay for the transaction and saying the transaction, but you'll see that it should appear here almost immediately, the deployment of the contract. Yeah. So I hope this has been useful. I don't know if there are questions, sorry.
00:27:04.420 - 00:27:17.640, Speaker B: I would have loved to get a full hour to explain you all of the nitty gritty details of IPC, but happy to answer any questions, secrets, or help you with anything. Thank you very much.
00:27:18.970 - 00:28:03.080, Speaker A: Yeah, if you have any questions, please feel free to type them in the chat or take yourself off mute and ask Alfonso. Currently there are no questions in the chat, but yeah, if there are none, then please don't hesitate to reach out via Discord or the partner channels or any other method and check out the partner prizes and the partner pages on the hiker dashboard as well. But yeah, if there are no questions, Meek asks, what is this useful for? Again?
00:28:04.650 - 00:28:31.470, Speaker B: So if you face some kind of congestion or limitation in this case, parkland, but eventually other blockchains where for instance, you have 32nd block times and it goes too slow. It is a good way of deploying a new instance of subnet and getting the kind of throughput that you need for your application. So it's a way of scaling proposal to scale horizontally blotching networks.
00:28:36.130 - 00:28:56.390, Speaker A: Cheers. Thank you. And yeah, if there are no other questions, thank you Alfonso for the presentation today. And thank you all the participants for attending. And we have a few more workshops later today. And yeah, if you have any questions, please don't hesitate to reach out to the partners on the discord channels. So, thank you everybody.
00:28:56.390 - 00:28:57.414, Speaker A: Have a good rest of the day.
00:28:57.452 - 00:28:58.210, Speaker B: Thank you. Cheers.

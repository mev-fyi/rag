00:00:00.730 - 00:00:12.080, Speaker A: Thanks Eddie. Bye. I don't really have a preference. Happy to start the second part, I guess.
00:00:14.290 - 00:00:14.894, Speaker B: Sure.
00:00:15.012 - 00:00:17.434, Speaker C: Let's start the second part and then have a panel.
00:00:17.482 - 00:00:30.520, Speaker A: Actually, people in the chat are saying panel, panel. So let's do the panel. All right, so we have three panelists vitalik, Phil and myself.
00:00:36.490 - 00:00:37.240, Speaker B: Hello.
00:00:38.970 - 00:01:28.780, Speaker A: Hi everyone. So I guess I was asked to prepare a couple questions for the panel. So maybe I'll just go through those quickly and then we can kick off the discussion. So the topic is mev and scaling. And I guess my first question is kind of qualitative and my second question is quantitative. So the qualitative question is, is optimal mev extraction in the context of scaling a centralization force? Right? Because we have these block proposers in order to do optimal mev extraction they need to be aware of all shards, all blockchains, all roll ups. So they basically need to be a super super node with lots and lots of computational power.
00:01:28.780 - 00:02:58.600, Speaker A: They potentially need a team of analysts, a team of PhDs, whatever. And if you zoom out, I know how to kind of decentralize everything except this block proposing. And this is kind of one of the last unknown. So that's my first question. Second question is quantitative and it's like what will happen to the fee market when we scale? For example, one of the questions I'm interested in in the context of ultrasound money is do base fees completely disappear right when we have lots and lots of scaling or will there be some sort of dip but then it will go back up? Or what are other considerations around scaling? Is it possible that maybe because we have lots of scaling, lots of shards, there's going to be many, many more fees? And so this is even going to make the centralization problem even worse in the sense that not only do we have these centralized actors, but they're going to be incentivized to be super, super large because of all the economic activity. If ethereum becomes the financial hub for the whole internet and the whole world, that's kind of scary. So anyone want to take question one or question two?
00:03:00.970 - 00:03:22.640, Speaker B: I think question two is easy. Base fees are never going to zero because there is always demand for all sorts of uses of the blockchain. If prices go low enough. Like at some point some miner is going to spin up a service where the blockchains just get used as a store to back up people's cat pictures. So we don't know what that floor is going to be. But no, it's there.
00:03:24.530 - 00:03:33.470, Speaker A: Right, but do you expect we'll be in this deflationary mode after, for example, sharding?
00:03:35.490 - 00:04:04.826, Speaker C: I would think on net if anything like the fees would be more, they might be less individually, but I think at least anecdotally we've seen every time capacity gets increased there's a dip for a little while as level of activity is now too little but then pretty quickly there's a return to the mean at some point. And on net I think there's usually more profit for miners after each one of these cycles. So I would at least personally expect the same thing to happen.
00:04:04.848 - 00:04:14.880, Speaker A: But it's hard to say, I guess, right. And this is definitely what we've experienced kind of historically. Like the total amount of fees just goes up only.
00:04:17.250 - 00:05:20.302, Speaker C: Yeah. As for the first question, I think it's interesting and it's super concerning. I agree that mev is a centralization force. I think there's a question of how much of a centralization force it is and how much of an advantage to centralizing is there going to be and how much of that can we mitigate through either incentivizing explicit decentralization or minimizing the centralization incentive in the current form? It's very strong of a centralization incentive, I think. So, for example, let's say without a network like Flashbots, which has this searcher miner separation, it's a huge centralization incentive because you have the miners that each have their own infrastructure and unless you can reach the barrier to pay that engineering cost, you won't be competitive. And that's like what we were seeing with pools like Ethermind kind of having their own mev infrastructure. I think adding in this more decentralized infrastructure where anyone can participate in either receiving profit or sending bundles is like a step towards making it more decentralized.
00:05:20.302 - 00:06:07.106, Speaker C: If that infrastructure is decentralized, which today it's pretty much not, but let's say it is right, then that's a little bit more decentralized. But there's still, I think, somewhat of an advantage from participating at more layers of the stack. As much as we try to flatten this reward function into being linear on the validation power, where with 20% you have 20% profit, there still probably will be some economy of scale to size related around your ability to build network infrastructure or have business partnerships with entities or whatever it might be. I still expect that curve to be a little bit above the linear curve. I expect size to continue being an advantage. So I think the only thing we can do is try to squash that down as much as possible. But I still see it as being there and being a huge issue.
00:06:07.106 - 00:06:10.340, Speaker C: But yeah, I'd be curious to hear what Vitalik thinks of this also.
00:06:11.430 - 00:07:51.060, Speaker B: Yeah, I guess I generally view these mev efforts as being about if centralization has to exist, like concentrating it in a particular type of actor so that all the other types of actors can still be basically just plug into that and continue to have economies of scale that are as linear as they were before. It's obviously an open question, the extent to which that will succeed. And then the other open question is even if centralization at some particular layer happens, to what extent does that turn into a risk for actual underlying goals? So like censorship, resistance, for example, if there is, say, one professional trading company of some kind that starts producing 80% of all block orderings, then what practical ability would that company have to say, stop me from sending my transactions onto the Ethereum blockchain? If it decides that it doesn't want those transactions included for whatever reason, would I still be able to get my transactions included by paying an extra fee? And then the extra fees of everyone who gets excluded will kind of add up to be enough to let some other aggregator get more reward. Will there be some alternative mechanism where I'll be able to get included with a one slot delay? Will there be something else? I don't know.
00:07:53.030 - 00:08:26.560, Speaker C: Here's a related question is like, what are the goals of Ethereum with regards to decentralization? I know this is a very broad question, but I'm sure you've thought about it, because to take that previous line of thinking to the logical extreme, there's like EOS and Algorand on the other end, and clearly we as a community want to be more decentralized than that. But how do we set a target and benchmark progress towards that and design for that goal? Or how do we even start to think about quantifying that or promoting it?
00:08:27.490 - 00:10:13.102, Speaker B: Yeah, I think one thing that we definitely needs to get better at is actually kind of expressing our thinking about the ultimate goals behind decentralization. Right? So are we concerned about els because they don't do the right rituals and pray to the right gods? Or are we concerned about EOS for very practical reasons? And my concern about decentralized platforms is definitely for very practical reasons, right? Like, if you take either EOS or even one of the recent EOS like platforms that have managed to get themselves into a position of higher respectability than EOS, the question is if the elites of that community get together and decide to force, through some protocol change that the community finds unacceptable. So this could be some kind of censorship, this could be like forking in some kind of issuance to say themselves and claiming that they deserve it because they're the core developers. Something would be like preferential treatment for KYC participants or something, whatever, right? Would they be able to do this even if the community just really strongly opposes this and in these centralized platforms, I think the answer is yes. Right? Because there isn't a culture of running validating nodes and there isn't a culture of that many people running nodes at all. And so if the elites get together, they can schedule a hard fork and they can even schedule it like 6 hours in advance. And then even by the then 6 hours later, the users by default detect nothing.
00:10:13.102 - 00:10:56.890, Speaker B: And then maybe 12 hours later, the users start detecting things. And by then the hard forks already happened and the users don't really have a way of quickly making a user activated soft fork. The users don't really have a good way of coordinating a rebellion. And so they've just basically successfully pushed it through. And what are you going to do? Are you going to revert billions of dollars of economic activity in the last 6 hours and try to coordinate all of the block explorers and pools that disagree before there's even more activity like you can't? Right. Whereas on Bitcoin or Ethereum, that sort of thing would very easily fail. Right? Because first of all, the number of elites you have to coordinate is larger.
00:10:56.890 - 00:12:03.380, Speaker B: You have more client developers, more core developers. Second, there's all these users running nodes and then there's all these users that are actually verifying everything. And those users would have to be convinced to download the software would definitely take longer than 6 hours just because of sheer numbers. And so your ability to pull off that kind of forced protocol rule change in Ethereum where Bitcoin is significantly lower. Right. So the question I guess would or one way of looking at the problem would be, would a single dominant mev extractor change this calculus and make it easier to pull off this kind of social attack? Now, clearly the mev extractor would not be able to force through transactions that are invalid, but they would be able to censor. Right? And so the practical question is just exactly how much ability to censor what they actually have? And is that something that users would be able to find some way around quickly enough?
00:12:05.450 - 00:12:30.730, Speaker C: So I guess what I'm hearing is that the fundamental role of decentralization, in your view, at least in this perspective, is to maintain this power balance between the privileged actors in the system and everyone else, such that everyone else can check the power of these actors and stop them from pushing through unpopular changes unilaterally.
00:12:32.290 - 00:12:50.660, Speaker B: Right? I think that's definitely a way of describing a large part of what the value of decentralization is there to do. Probably not 100%. I think there's other reasons to like and want decentralization too, but I think it's definitely a significant piece.
00:12:53.830 - 00:13:49.474, Speaker A: One of the things that we've tried to do in the design of EV Two is minimize the power of these privileged actors as much as we can. And I guess maybe one way to tackle mev is to basically constrain the block, proposers as much as we can. And I'm just thinking out loud here, but maybe there's an opportunity to somehow constrain the strategies that they have for block creation. So they have to commit ahead of time saying this is going to be my search algorithm and I'm going to adhere to it. And if I don't adhere to it, I can't create blocks or I'll get penalized. And then maybe there could be some sort of yarnstell open sourcing of strategies so anyone can submit strategies. These strategies kind of get run maybe in a distributed fashion.
00:13:49.474 - 00:14:16.750, Speaker A: And then the winning strategies, a portion of the, the income goes to those who wrote the strategies and then maybe there could be some sort of social pressure to push for at least the decentralized entities like the pools to adhere to basically constraining themselves artificially in the context of block production.
00:14:18.130 - 00:15:09.390, Speaker C: So I think that broad marketplace is kind of what Flashbots is trying to build in a way. But I think there's still a lot of the variability and a lot of the power of these entities comes also from their infrastructure. So like the network infrastructure, like how do you police whether they heard a message or not or whose message they heard first? I still think that is kind of the fundamental source of why they need to provide this input into the system. And I guess there's a question there of how much of this P to P networking attribution side is like does ETH kind of view as core infrastructure versus kind of designed to be changed and customized and if so, what are the desired properties of that layer?
00:15:11.490 - 00:15:44.890, Speaker A: Right, so I guess it's kind of the classic separation of data availability and execution. I mean, we can completely remove the unfairness in execution but there would be potential unfairness in the data availability. And I guess one thing we could potentially do is look at these off chain data availability committees and that might be a way to go from purely centralized as in there's one single actor to some sort of committee which might be more acceptable, more palatable long term.
00:15:48.430 - 00:16:26.294, Speaker C: Yeah, so I think basically that's the chain Link Fair sequencing protocol is trying to bootstrap that from a committee. I guess the question is just like what inherent trade offs are there and where does it fall in the L One? L2 DAP responsibility funnel distinction because obviously as you go down that the design needs to be more general and work for a broader class of people. Like L One needs to be the trade off space that's most optimal for a huge number of people and then L2 can be more specialized and adapt can be super specialized. So where do we fit that in I guess is a good open question. Do you think L One is the best place?
00:16:26.412 - 00:17:04.850, Speaker A: I'd say definitely not. L1. And the reason is in order to do that data availability and sequencing, you need to have a really good internet connection because you're basically connected to all these mempools and whatnot. So it would have to be semi centralized. But I guess the good news is that at the very least we can get this federated security. There's kind of a lower bound on the security we could get because when we select a committee at random at layer one, we're assuming that these are raspberry pi's running on a home connection so they can't really do like the high bandwidth data availability.
00:17:11.240 - 00:17:34.290, Speaker C: It yeah, interesting. So there is going to be like a natural specialization vector there. I guess. And as you said, it comes from both the data availability issue and I think also the network asynchrony aspect of like, we want people all over the world to participate and we need this network asynchronous like a fundamental part of how we're going to coordinate them.
00:17:35.220 - 00:18:03.640, Speaker A: So yeah, right, okay. So if we have a bit of time not sure we do, Tina. Interrupt me if we don't. But my last question, I guess is kind of a meta question is what are things you're most worried about? Like what are maybe some of the known unknowns or maybe unknowns unknowns for which you have some intuitions? What are these scaling things that you're worried about in the context of mev?
00:18:08.460 - 00:18:09.996, Speaker C: I would love vitalik to take this.
00:18:10.018 - 00:19:51.700, Speaker B: One first because I think I think this cross chain mev extraction issue that you mentioned is definitely one of them. Yeah, aside from that, will just like will demand for low block times lead to centralization issues? Like pretty much no matter how we satisfy that demand, even if we satisfy it with fancy L2 schemes. And then also there's just like centralization risks on the, like staking liquidity side. Like basically would staking in ways that open up centralization vectors, just have fundamentally better capital efficiency properties by enough to encourage people to stake in pools that are, I guess I want to say like, custodial. But the reality is there is going to be a spectrum and the question is where on the spectrum would it be most capital efficient to stake in pools where basically the custody properties of that ETH become such that they open up opportunities for attackers to grab up and control a large portion of the stake power? But that's less of an mev issue and more of a DeFi capital efficiency issue.
00:19:55.190 - 00:20:47.140, Speaker A: Go ahead, Phil. No, go. Mean, one thing that just came to mind is the question whether mev is objective or subjective in the sense that we're kind of assuming that mev is an objective thing and we can minimize it. But actually, maybe there's some privileged actor not in the blockchain world, but in the real world. So let's imagine that you're a government, you're a privileged actor there and so you can do things that others can't do and maybe we're going to have perfect equality on the blockchain, but because these other actors have privileges, we're going to have this subjectivity of mev. Like one transaction might be worth zero to most people, but to a government it could be worth a ton of money.
00:20:48.870 - 00:21:42.180, Speaker C: Yeah, I think that's super interesting. Like thinking about the full space of manipulation people will do because you see it in the financial markets where people will use some weird obscure power they have and also do some trade over there and these two things line up really nicely for them and they make a bunch of money and something happens and people don't know. So yeah, I expect there's going to be a lot of shenanigans in terms of things I'm most worried about. I think it's the same as it's always been with mev, which is that Goldman Sachs starts the mev division and they're just fantastically good at it and everyone buys the license to have Goldman Sachs tell them what order to mine transactions in because that's the best way and there's not a network there. It's just like very top down. So basically ETH turning into Robinhood in an order flow sense. That's kind of what I worry about.
00:21:42.180 - 00:22:07.766, Speaker C: And also how this interacts with large exchanges in POS like Binance and Coinbase and how that also plays with the correlated slashing and the correlated failure incentives. Are those incentives kind of enough to prevent centralization? Is the meme enough of their existence? Will they kick in at the right time and kind of have the right effects? I think those are all open questions.
00:22:07.868 - 00:22:09.470, Speaker A: I have on scaling.

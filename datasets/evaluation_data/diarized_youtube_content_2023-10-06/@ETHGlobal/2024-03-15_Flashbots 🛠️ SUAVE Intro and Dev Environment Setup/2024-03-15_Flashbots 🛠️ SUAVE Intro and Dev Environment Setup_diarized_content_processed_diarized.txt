00:00:00.650 - 00:01:08.820, Speaker A: Welcome to the Swab workshop for ETH London. Extremely happy that you are watching this video. And yeah, let's get into some background on swab and we'll also have an explainer of how to set up your first swap and deploy it, as well as we have another explainer on how to set up a local testing environment which includes everything from a swath node and the mevum node to al one chain node to mock as well as MeV boost and validators to mock the entire MeV boost pipeline in case you may be trying to experiment with building blocks. Awesome. So at a very high level, our goal with suave is to be an open marketplace for MEV applications, which we call swaps. That stands for swab applications. Some example of existing MEV applications or swaps are private RPCs, order flow auctions like MEV share block builders, relays, shared sequencers and more.
00:01:08.820 - 00:01:45.450, Speaker A: If you're looking for ideas here, check out the what to build on our docs. I'll show that at the end and then additionally feel free to hit up anyone on the team. We have tons of ideas and our forum also has many unbuilt ideas that are great candidates for the hackathon. So swap. What is it? At the highest level, it's a programmable mem pool with three key features. One, advanced privacy primitives. So from our experience in running MeV share, not all applications have the same privacy requirements.
00:01:45.450 - 00:02:15.174, Speaker A: But we do think that for many applications, privacy is probably one of your top concerns. Although there are definitely some applications which need no privacy. A great example is trading on uniswap. If you are to send your uniswap transaction to an order flow auction that allows a network of searchers to backrun it, you may have different privacy needs based on the application, based on the pool you touch.
00:02:15.292 - 00:02:16.360, Speaker B: Excuse me.
00:02:17.050 - 00:03:08.806, Speaker A: So one example is ETH USDC. If you're swapping ETH USDC, you could actually probably reveal much less information. This is because the pool is extremely liquid, so you probably don't need to reveal as much detail about the size. You could maybe get away with order of magnitude. And as well, you don't need to reveal the direction because a searcher can send in both direction the background for both directions, but a very illiquid pool. It will become crucial for you to reveal the amount and depending on the pool, the direction may or may not be needed. Anyways, this is just to highlight that there's a vast design space around revealing intents and preferences in your order flow auction.
00:03:08.806 - 00:04:03.580, Speaker A: Next we have credible compute capabilities. Most of the MEV infrastructure that exists today is off chain as well. There's not a lot of observability in the MEV boost pipeline. We have created the ability to see bids and from which block builders, thanks to relay, is publishing a relay API bid standard. But aside from that, you essentially get no guarantees into what the program that the infrastructure you are interacting with is running. So credible compute allows you to do this. One of the key ways we do this is by allowing a network of SGX nodes to fulfill your compute, and upon joining the network they attest to the code hash that they are running and are continuously checked against that as well.
00:04:03.580 - 00:05:20.290, Speaker A: This allows you to have guarantees that they are running the correct version of the mevum, of which you can deploy applications to, and be sure that the node is running that compute associated with your contract on top of the mevum. And lastly, low latency messaging passing. This is important because many applications in the MEV infrastructure space benefit from lower latency, and additionally we see many actors pushing things like submitting blocks and transactions as late as possible to the network so that they can incorporate as many signals from off chain domains as possible. So what does it mean to build your application on swap? So at the highest level, it's a place to define your off chain application logic. This can include things from protocol rules to data storage. Say you're running an order flow auction. Then you need to first have the ability to store encrypted intents, and second, you need to define the logic for how you are actually auctioning off intents.
00:05:20.290 - 00:06:15.490, Speaker A: And the second point mentioned here is consensus. So when your application is ready to move past a single node infrastructure, you can actually define consensus and have it run across multiple nodes. This gives you replication and removes a single point of failure. On the right, you can think of this ball as representing all protocol data and logic. Next, swap is a place to pay a network of TE coprocessors to run your application, similar to the paradigm of smart contracts on Ethereum today, where you can simply submit your program and it just runs autonomously. A network of TE coprocessors allows you to do this as well. In this diagram, you can see that the coprocessors aggregate around specific protocol data and logic in order to perform your computation.
00:06:15.490 - 00:07:05.250, Speaker A: So an application on Swab is a cluster of TE coprocessors. We call these kettles, acting as a singular protocol defined by the developer, some potential food for thought. Swab is a place to create mesh order flow networks. These are order flow layers that are defined between various coprocessors. Right now we only offer tee based coprocessors processors, but in the future you can imagine MPC or perhaps even distributed key generated coprocessors which live on your phone. So what else is swap? It's a place to define multi domain off chain applications. In our previous example we had seen how there was protocol data and consensus and storage that are defined as well as rules.
00:07:05.250 - 00:08:08.982, Speaker A: But one thing we didn't mention is that you can actually closely link this to a specific node on a specific chain. So in this example we can see that perhaps there are a few coprocessors which are running your application and they are all situated near optimism nodes. And then we can also see other coprocessors which are situated near ethereum nodes, and one coprocessor, or potentially many in the future which which are performing compute for applications on both clusters. This would allow you to accept a crosschain intent on one, propagate it to another network, and receive your token on the other chain. So the suave programmable mempool stack consists of a few things. First, we have a chain abstraction SDK. This allows you to craft transactions for different chains, as well as even store a private key that is generated by the tEe, and you can fund that and use that to sign transactions on other chains.
00:08:08.982 - 00:09:01.062, Speaker A: Of course, we do not recommend aggregating extremely large amounts of funds to a private key stored on the TE, and we also have various measures for how you can ensure safety in the event that there is a network outage across these TEs. You can think of it as these TE based private keys are really good for sort of session management. Next, we have a confidential storage API. This is how you can put encrypted data onto the TE and have it propagate across multiple TEs as well. We have a builder API, and the builder here refers to block building. So if you receive a transaction using the builder API, you can actually simulate that transaction on an L one or l two node. You can even build an entire block.
00:09:01.062 - 00:09:55.610, Speaker A: You can even simulate a transaction and then inspect the state of the chain after simulation if you want to check the results of the pool and much more. Next, native intents. So swab supports EIP 712 messages, and eventually this will actually be the native transaction format on suave. And lastly is the mevum, which we won't get into details too much today, but it is a slightly modified evM. And when I say slightly, I mean that you can still compile regular ordinary solidity into swaps. But the key difference is that all of these nodes are running a modified interpreter. So when they see specific precompiles that are required to make like a network call, for example, then the tees will interpret this differently than a L one node and perform that network call.
00:09:55.610 - 00:10:27.710, Speaker A: They will then attest to the results and propagate that to the other nodes. And this is how we enable network calls. So swab is a programmable mempool layer. Using these fundamental tools, you can build a searcher or market maker on top of it. You could build an order flow auction, you could build any type of trading protocol. Many Dexs these days have large off chain components, and so you can think of encapsulating those components on swab and improving the trust guarantees. You can build block building protocols.
00:10:27.710 - 00:11:30.598, Speaker A: And if you want to get even more fancy, we even have AI and web two capabilities. A small secret for those that are listening this far, we actually have LLMs running on Tes today. Let me know if you'd like to use those. So with this in mind, you can see how this programmable mempool layer can have multiple actors interacting with each of these different components. And because they're all defined in solidity, and if these applications live on similar nodes, then you can actually compose them, something which is completely impossible in present day off chain infrastructure. And at the top, you can see they all coalesce into a block building protocol, which can put out a coherent block to a validator. So based on this, swab turns the existing MeV supply chain, which is the user wallet searcher builder validator paradigm, into a network of decentralized nodes that are doing the computation for each of these actors.
00:11:30.598 - 00:12:26.934, Speaker A: This massively improves the scenario we have today, where many of these actors we see in the traditional MEV supply chain are just a single AWS server running somewhere that you're not even sure of. But now we bring more transparency visibility into the supply chain, as well as we reduce single points of failure. So I'll quickly run through some of the swap design goals. The first is that we hope to be censorship resistant. This is of course a never ending battle, but one of the key ways we achieve this is by allowing encrypted intents into the network and then propagated. This blocks the node from being able to filter transactions based on their contents. One key area of research though, is that nodes would still be able to set up a filter at their network level in front of their node.
00:12:26.934 - 00:13:27.562, Speaker A: That could potentially filter out based on IP addresses. But this is quite a hard problem and we're actively developing it and hope to have a solution by Mainnet. Next, geographic decentralization. We hope to enable these nodes to run in a variety of geographies so that we avoid regulatory capture of a node running in a single data center in some area. Next, low latency. So we have worked on optimizing the hot path from receiving your intents to processing it via your specified program, and as well reducing the latency between message passing between kettles. Last programmable privacy as I mentioned, we hope to enable users and all applications the ability to define their privacy rules as opposed to sticking with just a single predefined privacy primitive defined by your chain multidomain.
00:13:27.562 - 00:13:44.020, Speaker A: These nodes are set up to run as many domains as possible, and we view this as the most scalable infrastructure and architecture possible. And oh whoops. You weren't supposed to see that. Awesome. Now let's see an example.
00:13:45.610 - 00:14:33.166, Speaker B: Hello everyone. In this video I'm giving a walkthrough on how to build your first swab application. First of all, a small TLDR on the architecture of Suav that you can sort of fill in and get more detailed information from our documentation. Suab has two main components. You have on one side the swab chain, which is a consensus chain that receives normal traditional Ethereum transactions. And on the other side you have the kettles, which are the off chain components. Users can use the kettles to execute solidity functions from their smart contracts completely off chain with privacy, since those kettles run on SGX.
00:14:33.166 - 00:15:21.594, Speaker B: And once those kettles finish this on chain heavy computation, a transaction for the swap chain is created as some sort of callback or receipt, so that off chain computation produces an onchain computation. And that's what we are going to do now. So let's start. First we're going to create a repo and we're going to use forge as the template for the project. So we're going to use the forge template as a template. Now this is the contract that comes by default. Let's create a swap.
00:15:21.594 - 00:16:23.026, Speaker B: Here it okay, so now, as I said, there are these two components, the on chain component and the off chain component, and the off chain component executes as a result on chain component. So let's write that down. We create two functions, really simple and basic functions. First the onchain function, then the off chain function. But what the onchain function returns always. So let's assume here that the off chain function has some heavy lifting logic to perform here. But what the off chain function returns is a function selector.
00:16:23.026 - 00:17:16.710, Speaker B: It's a function selector to another function inside the swap. This other function will be executed on chain. Okay, so if we follow the explanation that I gave before, any user can use a kettle to call this off chain transaction. The kettle will perform this logic and once the kettle is done, we'll take this function selector, we'll wrap a swap transaction and send that execution on chain. And eventually that swap transaction will execute this on chain component. So now we are going to deploy our first swap and execute the off chain transaction, everything in a local network. So let's start a DmAX session.
00:17:16.710 - 00:17:58.006, Speaker B: We're going to use swap geth. Swap get is the official currently maintained client for the swap chain. It implements both the swap chain and the kettle component. So you can download the swab geth client with this cordless command. This command is in the getting started documentation that we have online. Now we have installed swapgath. You can even check the current installed version in your system.
00:17:58.006 - 00:18:42.100, Speaker B: That means that everything is correct to have gets installed. We are going to run it. So we use swap dev flag and this creates the, as I mentioned, the swap chain plus the kettle running in development mode. So by default this exposes some really predefined private key, funded private key that we can use. So first we're going to compile the examples with Forge. So suave is fully compatible with us. So we have to rename, let's remove the test for now.
00:18:42.100 - 00:19:19.134, Speaker B: So swab is fully compatible with Forge. You can compile any swab that you have with Forge. Now once it's compiled, let's deploy it. So to deploy it, we are going to use helper utility that comes built in inside Suab Geth that facilitates deploying and sending confidential requests for the dev chain. So let's use it. The tool is called spell. So you can see here the two commands that it has.
00:19:19.134 - 00:20:13.278, Speaker B: So we're going to do deploy and then the name of the smart contract. So in this case the first swap, that's all two points, my first swap. Okay, so this automatically checks the artifacts folder generated by forge, finds the contract and deploys it. So you can hear that the transaction was sent, the on chain transaction was sent and the contract was deployed at this address. Perfect. Now we're going to use the spell command to send the, to send a request to this off chain function. So spell confidential request.
00:20:13.278 - 00:21:07.634, Speaker B: We put the address of the contract and the function signature that we want to call off chain. Okay, so here you see that we are sending an off chain confidential request to this specific kettle, which is the same as the swab client here. And this generated this suave transaction right here that eventually was mined. Now, I'm going to showcase how to emit logs inside your off chain computation. So let's assume you have an event called off chain event right here. This is an event that gets only emitted in the off chain context. Let's say we want to emit it.
00:21:07.672 - 00:21:08.260, Speaker A: Here.
00:21:10.950 - 00:22:12.358, Speaker B: Right here, even twice we want to emit this event. Okay, so if we were to deploy this again, sorry, we have to build first we were to deploy this and then execute the off chain call again. We'll see that this doesn't show that any logs were emitted. In order to emit logs from your off chain context, you have to modify your on chain function. So in this case, we're going to use Swav STD. Swab StD is this utility that we wrote that includes helper libraries and functions to help building swaps. So it's easy to install.
00:22:12.358 - 00:23:00.150, Speaker B: Just do swab install. Sorry, forge, install flash swab std. We have to commit. Okay, yeah. So now suave TD has been installed. Now we're going to use this utility from swabstd called the swap. So, swap is a contract that comes with a modifier called emit option locks.
00:23:02.730 - 00:23:03.142, Speaker A: Okay?
00:23:03.196 - 00:24:34.480, Speaker B: So what this modifier does is that when the onchain function gets called, all the events emitted from the off chain function are going to be emitted on chain. So again, we're going to build with Forge, we're going to do the same, we're going to deploy again, we're going to take the address, we're going to run the example again. It and now you see that as part of the on chain execution, not the off chain execution, but as part of the on chain execution, two log events were emitted, two off chain event logs were emitted, and these are the field or values of the events. So you can do not only this, but many, many more things using the suave std library. We have support for multiple protocols like Chgpt or the Flashbot Mapsture bundle types, flashbot relay bundle types. You have functions to call the JSON RPC endpoint, and like utilities to use transactions, encode them in RLP and code them in JSon. So there's a lot of utilities that it can help you build your own swap.
00:24:38.440 - 00:26:07.052, Speaker C: Hi everyone. This is a small video to show you how you could use cortoisis and docker to run your local devnet for swap development TLDR is you need this repository checked out on your machine. So swap example from flashbot organization, Docker and kurtosis installed and then you run make devnet up command and then wait until it will do all the magic. What happens right now we run this script from this make file and this script spins up cortosis stack and after that it will launch the Docker compose with the sidecars to the stack which are basically swap Mevm node and explorer that relates to it. The Ethereum Stack Ethereum devnet that will be running on your machine now is configured via this file cortosis Yaml file. You can find the information about this stack on ethereum.org website with some details.
00:26:07.052 - 00:27:11.510, Speaker C: And then there is a GitHub repository where everything is outlined. There is a very good documentation there that explains you how you can tweak your local devnet to suit your needs. Essentially our setup right now is very minimalistic. The main idea here is just to do the demonstration, show how you could do that. Obviously if you need more, if you need different clients, if you need some stuff running inside the ethereum chain, you might want to use this cortosis Yaml file to configure what you need. Otherwise you can use this docker compose file where we run sidecars to the ethereum stack. In this file you can see that it is using same docker network as cortosis will spin up.
00:27:11.510 - 00:28:15.850, Speaker C: And then in the same network we will run medium node with parameters that point it to one of the cortoises stack, Ethereum el nodes and then blockscout which is essentially an explorer to swap chain while the explorer to Ethereum chain will be taken care of by cortosis. When the script finishes you will see this long output of everything that is running right now in your machine. So there is block scout for Ethereum. There is geth nodes, three of them. There is one combination of builder plus lighthouse. Then there will be MeV boost, sidecars, MeV flat relay and so on and so forth. Quite a long step.
00:28:15.850 - 00:29:33.120, Speaker C: And here is the things that our docker compose has created by default out of the box. You will get very basic things, very basic ports exposed to you for your use at predefined ports via this Nginx configuration file. Reason why we need that is that cortosis, when it spins things up, it will expose every single port of your application of all the ports that it will be running at random local host ports on your machine, which is very hard to predict and it's not very convenient when you need, for example your application to know where to find the RPC, which is why we need this nginx file. Also, same Nginx file takes care of the explorers, so let's have a look at them. This one is the Ethereum chain explorer. This one will be swav chain explorer. Nothing happens.
00:29:33.120 - 00:30:49.000, Speaker C: Right now it's two completely clean fresh chains. These transactions are a result of MeV flat because initially cortoisis would spin it up, but we would stop it just to stop the noise that it will generate. If you need it, you can remove this line in your experiments, but otherwise it's two completely clean slate chains. So quite useful for for example scripts where you need to know exactly what happens and when and how deterministic basically. Now when those chains are running, let's try to do some example in this repository. There is a number of examples. The most interesting for our purposes is this one of a private which essentially creates a bundle with a background and sends it to the relay.
00:30:49.000 - 00:31:59.950, Speaker C: And it does it not via direct call to the Ethereum RPC, but via SwaF. So it sends contract call to Swaf and Swaf node will contact the Ethereum node and do all the work to run it. It will need two things taken care of. It will need to be told where to find the RPC endpoint of the Ethereum stack. So builder RPC endpoint in the Ethereum stack we just created, in our case it will be el four because first three will be just plain gets and not builders. And it needs to be told also which account to use by default. This example uses hard coded account which is different from the one that is founded in cortosis.
00:31:59.950 - 00:33:00.870, Speaker C: This key comes from cortosis. You can actually find it somewhere in the documentation where there is a list of keys. That cortosis stack will make sure that they have enough. With this we are good to go, we can run it and this is the command that will run. And to see that it's working, let's do it like this. This example will first fund two accounts and then create a bundle where one account sends some ETH to another account. So these two transactions were created by the example, but these four are already the result of the bundle being landed.
00:33:00.870 - 00:34:37.134, Speaker C: You can see it on this med boost relay. Also something that's spun up by cortosis. You can see here is this bundle. So that's how it all works. One small thing though, it will start working after block 128. Before that it needs some time to get everything into up to speed state so this particular example if you've been faster than me so probably talking less than I then you would probably have everything ready and running at block number 70 or 60 then this example wouldn't work but after 128 it's pretty stable and predictable that yes that's the moment when it will work and now when you are done when you don't need it any longer same command, make diff net down will clean everything up from your machine it will stop the containers, it will remove the volumes, it will stop the corteosis engine so that your docker locally is completely empty and clean. And next time you do the Devnet app it will be again very clear and empty chains on both sides.
00:34:37.134 - 00:35:08.780, Speaker C: This is it. So thank you very much for your attention. If you have questions you can ask us in all the channels that we maintain in GitHub issues in forum or on discord channels or if you see this video at the conference if London then there are guys that are there you can ask them questions as well. Thank you very much. Thank.

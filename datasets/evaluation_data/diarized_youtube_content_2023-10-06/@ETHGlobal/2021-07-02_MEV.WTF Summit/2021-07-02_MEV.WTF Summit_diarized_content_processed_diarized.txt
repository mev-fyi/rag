00:00:02.650 - 00:04:28.170, Speaker A: Yeah. No talking. Hello, everyone. Welcome to the Mev WTF virtual Summit east Global hacked Money hackathon edition. This is Tina from the Flashbass Mev fellowship. If you are watching today's summit from V and would like to interact directly, ask your questions to the speakers and panelists of today's conference, please feel free to please make sure to log into chat here and ask your questions. We will make sure to relay your questions to the Zoom link where the speakers and panelists present and discuss.
00:04:28.170 - 00:05:15.660, Speaker A: The WTF Summits are where we go deep on interdisciplinary research subjects. Today we have four parts over 7 hours of content, over 40 speakers and panelists joining us. So this is the agenda for today. Part one is the evolution of Mev. Two, framing the mev problems. Three, protocol level response to mev divided into minimization democratization and minimization versus democratization. Part four is application level response to mev.
00:05:15.660 - 00:06:13.220, Speaker A: All of these latest agenda can be found on Mev WTF. It is the link that will redirect you to the agenda itself. And lastly, our WTF man will be kindly reminding all of our speakers and panelists, as your time is up, that your time is up. Without further ado, my time is up. First part, we have our first speaker, Charlie Doy from Paradigm, giving us a talk on WTF is MEB. Charlie, feel free to directly share screen now. We're working on it.
00:06:13.220 - 00:06:40.810, Speaker A: Here we go. Just a kind reminder for all speakers. We can see all of your screen. Here we go. All right, we good to go here, Tina. Perfect. All right.
00:06:40.810 - 00:06:49.774, Speaker A: Hell yeah. Here we go. All right. Minor technical difficulties aside. Tina. Thank you so much. Hello.
00:06:49.774 - 00:07:56.610, Speaker A: My name is Charlie Noyes. I'm an investment partner at Paradigm crypto focused investment firm. I have been interested in Mev for a long time, and I have had the opportunity and pleasure of getting to work with Tina and the rest of the Flashpots team for the last, like, six or eight months or so now. So my talk is on WTF as MEB. I'm not sure how much more I will have to say about MEB or how interesting this will be relative to the rest of the agenda, but we will try to give the intro. Mev is present in any system which cannot demonstrate its own consistency. It is a theoretical quantity which we can only approach asymptotically fundamentalist of permissionless, blockchains and a measure of the profit a miner or validator sequencer, et cetera, can make through their ability to arbitrarily include, exclude or reorder transactions within the blocks they produce.
00:07:56.610 - 00:09:56.410, Speaker A: Realistically, I would suggest reading these descriptions of mev or explanations of mev, like, given the depth of the conference track today, the first of which here I'd written and the second filled more recently. But yeah, if you want to understand what these profit opportunities generally look like and where they're actually generated, I would suggest going to read some of this stuff and the conference track will probably make a lot more sense. That being said, a brief history, I actually didn't know this, but up McGuin, sorry if I mispronounce your name back in 2014, saw pretty far into the future and asked a very interesting question on Reddit what is to stop front running by a minor in any marketplace implementation by Ethereum? This was really quite ahead of its time here. So we asked the question and we didn't see much more of it for a while. Flash forward to 2019 and Phil published the foundational Mev paper Flash Voice 2.0, showing that specifically in the context of DEXes, high fees paid for priority transaction ordering poses a systemic risk to consensus layer security synonymous with there was a lot of front running happening and priority gas auctions were starting to heat up. And they also said that such fees are just one form of a general phenomenon indexes and beyond what we call minor extractable value and what we would now define as the profit opportunities, the general profit opportunities that a block producer has access to by virtue of their ability to arbitrarily order transactions within the blocks they produce.
00:09:56.410 - 00:10:50.090, Speaker A: Well, this was the paper. Flash forward to 2020 and Flashbots was formed a research and development organization formed to mitigate the negative externalities and risks posed by MAB, to smart contract blockchains by Phil, Tina, Alex and a number of other folks. And in 2021 plus, I would say that we are now in the era of Mev. It's getting quite exciting. We have mev geth, we have private transaction relays, we have poison sandwiches and a lot of other stuff. So what do we mean by the era of mev? Earlier this year I had said that I thought the dam is probably burst on mev, that miners will venture further into the frontier exploring more exotic forms of mev and collusion. And I would say that this has happened empirically.
00:10:50.090 - 00:11:42.058, Speaker A: The percent of Ethereum blocks with Flash bodge bundles included has increased from nearest, I mean rounding to zero to more than half in just that period of time. And Mev revenue relative to transaction fees on an average basis looks pretty similar. So the short version is this is real and it's actually happening. But what is the AR of Mev? I have a couple of hypotheses. The first is that miners will collude to their heart's content and really that the hypothesis that they will run stock gas out of Altruism is false. I think that we've just come to accept that now. I think that there are a lot of good guesses that can be made about what this period of time will look like.
00:11:42.058 - 00:12:22.630, Speaker A: Applications will start to design around MEB, like as a core design principle. A lot of systems will fail, hopefully not too catastrophically. Anime icons on Twitter will make a lot of money, a lot of thought experiments will not stay theoretical. And the last bullet point here is the only prediction I will be making in this talk. So I think the best way actually to think about where we are with mev is just with a couple of anecdotes. The first is from mev intern in the flashbots discord. We have observed front running bots keeping bids down by naming and shaming those that bid above them.
00:12:22.630 - 00:12:54.820, Speaker A: So for those who have heard of the groom trigger strategy game, theoretically in practice what we are seeing is that every day or two they post some address like zero x, dead beef. We are all bidding 70%, you are biding 95%, you moron. And this actually works. It's honestly really funny. Everyone should go check it out. Otherwise we will simply outbid you until you make nothing. Some other anecdotes sort of like exotic forms of mev that we've seen.
00:12:54.820 - 00:13:42.340, Speaker A: One of my favorites is a heist that took place across blocks, across multiple blocks. I think this was the first that was really documented. And what's interesting about this is that most MEB is intrablock, especially given sort of that it began with PGAs and we didn't have access to flashbox bundles. It's a big deal because when you submit a bundle to flashbots, you need it to be private. You don't want a miner to be able to steal the profit opportunities that you've identified or for other search groups to be able to. So it needs to remain private. And it appeared that someone had managed to break that model.
00:13:42.340 - 00:14:57.030, Speaker A: That's not actually what happened, though. What happened is that there was like a two block reorg and a searcher was smart enough to essentially pull the profit opportunity out of the block that was uncled and take advantage of it in the newly canonical main chain. So for those of you who have heard of time bandit attacks, the idea that you could reorg intentionally to extract mev, although we cannot say or we can say that this one did not appear to be intentional, I would say that it is definitionally a time bandit. And the distraught searcher who was certain that their bundle had been leaked realized that in fact, yes, it was included in an uncle blocked in an uncle block and someone else was smart enough to selectively extract it. That would be the one prediction I will make. Short term, one to four block reorg frequency may increase over the next year, but that's pretty much all I have to say for now. I think most importantly, being in the era of mev means that a large group of very, very smart people cares about understanding the nature of mev, minimizing its social harm and helping us to design better systems.
00:14:57.030 - 00:15:37.110, Speaker A: I would not bet against them and I was going to include all of their profile pictures, but we didn't have time. So instead, here's Phil, who I will now turn it over to. Thank you very much. All right, thank you, everyone. Thank you, Charlie, for the concise presentation. Next up we have phil. Please feel free to share screen and we'll take questions because we're running a bit late at the end before the panel.
00:15:37.110 - 00:17:39.712, Speaker A: So are you able to share your screen? So can you check your mic? So can you check your mic? We cannot seem to hear you. Can you hear me now? Yes, you can take it away. Amazing. Can you see my screen at all? For some reason it won't let me kind of expand. There we go. Yes, we can see your screen, but you may want to adjust it a bit. Okay, can you see the limits of crypto economics? The whole phil, click Presents, then go to the bottom.
00:17:39.712 - 00:18:15.420, Speaker A: So your taskbar comes up, click zoom, click Share screen and then select the fully sized. Yeah, Charlie, the problem is I got a new laptop and it's got wayland and I didn't set zoom to the X Eleven fallback mode that is required to reroute Linux's display thing. So that's not going to fix it, but I think maybe tina, can you just share the slides? Would that let me let's do it. Thanks so much. Sorry about that, guys. Like I said, new tech stack, new problems. And also don't use Windows, even if it's easier.
00:18:15.420 - 00:18:48.228, Speaker A: All right, I am waiting on my slides. All right, I guess I'll start talking. So today we are going to talk about the limits of crypto economics and how to build antifragile MEB based systems. Next slide. All right, so kind of a brief intro of this talk. This is not going to be kind of my usual, very kind of in depth researchy deep dives. Instead, I kind of want to be a little bit more provocative for this event because we have a lot of panels and a lot of discussions.
00:18:48.228 - 00:19:25.780, Speaker A: I think we have a real chance to kind of influence the future of how we build systems and marketplaces for mev extraction. So this morning I was driving to kind of a piece of land I'm trying to build a home on to fight with the government over permits. Here's a picture of me and my truck. And honestly, I had no idea what I was going to talk about in this talk beyond some vague stuff about SGX and the title. So that's kind of the backstory. Hope you're not expecting too much, but please be prepared to kind of open your mind and challenge your preconceptions and have some discussion because that's what I would really love to happen. Next slide.
00:19:25.780 - 00:20:20.900, Speaker A: Great. So first things first, because this is going to be kind of a very specific talk. I'm specifically going to be talking about SGX and crypto economics and the interplay between the two and kind of the synergy between the two. If you want a more general talk, if you want a more high level talk about what we do about mev in general, and you haven't attended scaling ethereum, specifically the mev roast session that happened last May, May 6. I highly recommend you just pause this talk and spend the rest of my time here watching the mev what do talk, which is much more kind of prescriptive and higher level here. We're kind of going to focus on a more specific question. Assuming mev is present and assuming that it can't be reduced to zero, how can we build the best systems and the best marketplaces around it? So what's the problem? So the first thing is that we want to avoid the centralization of mev at Flashbots.
00:20:20.900 - 00:21:15.924, Speaker A: We want to avoid a case where miners and exchanges and large validators are kind of centralizing mev to themselves. And we feel that the only way to do this is through a fair, real time marketplace. What do we mean by fair? Well, we consider a few different properties, kind of key to keeping mev decentralized, lowering barriers to entry, and making sure that anyone can kind of engage in the mev ecosystem to get data, to run bots to participate or to see what's going on if they're an app developer or a user. So in order to have such a marketplace here's, a few of the properties that we kind of think are fundamental. One of them is pretrade privacy. So the idea that as a bot or a submitter to this marketplace, your trade stays private until it's unrevertible by miners, this is to stop things like payment for order, flow of the bundles. Otherwise we kind of enter a very Wall Street style hierarchical situation.
00:21:15.924 - 00:21:57.628, Speaker A: We also need spam resistance. This is to prevent miners from getting dos and taken off the network, which would threaten overall system stability. And we also want to maintain the stability of the overall protocol as well as alignment with the incentives of all its actors. So where do we stand today? flashbox alpha has two properties which are currently pretty suboptimal. The first one is that pretrade privacy relies on trust in both miners and Flashbots. So both of these entities right now in the alpha are able to kind of see bundle flow and front run it, mess with it, and otherwise manipulate it. So we do kind of actively monitor for behavior like this in the ecosystem, and we do stay on top of the motorcycle.
00:21:57.628 - 00:22:29.980, Speaker A: We do stay on top of this kind of thing. However, that's a lot of trust in us as a centralized entity, and we don't think that's a long term solution. Also, spam resistance currently relies on trust in Flashbots. So miners have to trust that Flashbots won't spam them, dos their endpoints, or otherwise expose sensitive infrastructure, which is suboptimal for miners as well. Next slide. Great. So how do we upgrade this? How do we get out of this world into a better world? So to move forward, the first thing we have to do is remove all these elements of miners and Flashbots trust in the system.
00:22:29.980 - 00:23:20.664, Speaker A: So it's obvious that we need decentralized and secure spam resistance and privacy. But what is good enough decentralization for us and what is good enough fairness? Well, there are a few properties that are obviously additional on top of this that we also need to be suitable for use in ETH and in a kind of financial context. The first one is that the marketplace has to be robust to system shocks. What do we mean by this? We mean things like large price events, attacks on the network, downtime of large, validators and other kind of unexpected events in the system and in the world. Also, if we're not building a system that's robust to system shocks, system shocks are going to pose a massive vulnerability and we want it to be robust for miners, bots and users. So we don't want system shocks to advantage any of these one parties over the other. We also want a system that's suitable for byzantine operation up to a threshold.
00:23:20.664 - 00:23:57.960, Speaker A: So up to a certain percentage of the actors in the system can be blatantly malicious without the system falling over as high of a threshold as we can achieve. And we also want a system that's suitable for rational operation up to a higher threshold. So we don't want the rational action to be attacking the system up to a pretty high threshold of hash power and validation to achieve our kind of goals of decentralization. Great. So how do we get there? Next slide. So again, to get there, our task is to remove all elements of minor and Flashbots trust in the system. Otherwise I would personally consider that Flashbots and mev has failed.
00:23:57.960 - 00:25:20.820, Speaker A: Why is that? Why is this such a failure point? Well, if we're not robust to system shocks, we risk a trust collapse or a spiral and that could erode trust in all blockchains and all the financial ecosystems we're building. There's also a cat and mouse game, so a lot of the attacks on bundle flow or payment for order flow may not be visible, you may not be able to tell if a miner is front running bundles to insert their own transactions if they don't directly alter bundles. And there's a wide class of behavior in the system that's not detectable or falsifiable or policable, and that creates a cat and mouse game where flashboss has to constantly monitor and try to stay a step ahead of people who are trying to kind of take personally advantaged actions in this marketplace, providing kind of a constant need for data and policing. Also it creates major centralization in the ETH stack. So we don't want a case where we're actually responsible for kind of policing all these functions because that puts us in a centralized position and makes us a kind of risk and a point of failure for all of Ethereum, which would be absolutely terrible. We also don't want vampire tokens, so what do I mean by this? Well, there's a risk that in a world of centralized mev, you'll get tokens that come up that kind of claim to handle mev that are not actually aligned with ethereum itself and with the broader ecosystem, which is also a major centralization risk. All right, next slide.
00:25:20.820 - 00:26:12.848, Speaker A: All right, so what can we do about this? So one proposal, and this is a proposal by Vitalik and also kind of very similar to several kind of internal areas of research that we've been engaging in at Flashpots is to use economics to solve this problem. So to decentralize us using economic incentives that kind of secure spam resistance and also privacy. So I encourage I'm not going to dive too deep in these ideas. I'm more going to talk about the high level kind of content here. But I do encourage you to check out this e three search, post and comment and kind of bring your feedback and your comments. What these proposals all have in common is there's some economic incentive to behave honestly. So either you want to behave honestly to maximize your revenue or because you'll lose revenue otherwise, or there are some slashing conditions that force you to behave honestly.
00:26:12.848 - 00:26:54.864, Speaker A: That's kind of a common theme in crypto economics. Next slide. Okay, so what else can we do other than crypto economics? Kind of exploring the trade off space. So I called this slide Voldemort, and this is kind of the more provocative part. I wanted to kind of talk today about why we're working on SGX based solutions at Flashbots and why we think economic solutions alone aren't enough to build the robustness of the marketplace that we really need to handle mev. So on the left kind of shows you my mental model of how to think about mev in various distributed protocols. So on the top, you have some code that's running of the distributed protocol.
00:26:54.864 - 00:28:11.928, Speaker A: It might be an ETH validator, a Cosmos validator. It might be a, I don't know, centralized exchange service, whatever kind of distributed system or cryptographic system that's ultimately being exposed to the public. And the system has a bunch of outputs that it sends as messages across the Internet. Here it's labeled out one, out two, out three. And there are users and observers and auditors who look at these outputs and try to define what is the code that's running? Is it the right code, and is it kind of doing what it says on Pin? So in this kind of picture, there's something I call the wiggle room, which is kind of how I think about approaching protocols at first blush, which is like looking at the code that the validators run and the outputs it produces and seeing what other outputs can be produced by code kind of other than the prescribed protocol. So what other messages can validators send, and what does that mean about the state of the world that's inferred by these kind of people at the bottom, are they able to detect that the validators have kind of changed the code? And what are they able to detect about that? So without SGX in the ideal world, this wiggle room consists of the code plus the network input and output. And with SGX the code is removed because you can attest that you're running a particular code base.
00:28:11.928 - 00:28:50.464, Speaker A: So the wiggle room is kind of limited to the network. So if code is not in the wiggle room, that actually simplifies the analysis. A lot of security. You don't need to define these economic slashing conditions like we saw before of inferring. What is the code security property from these messages we see on the internet? These conditions are also prone to introduce additional assumptions, right? So you might need to assume that a certain number of validators are honest to see the truth and figure out who's actually taking liberty in this wiggle room. And these conditions kind of also introduce fragility into the system. So what I'm going to propose is defense in depth, which is adding an ideal SGX construction to the stack.
00:28:50.464 - 00:29:17.628, Speaker A: It doesn't mean we don't have the economic incentives, it means we also have these other systems. Next slide. So I think these are complementary for mev. And this table is kind of the one takeaway I want everyone to have from this talk. Why? Well, let's look at both. So first of all, how much capital is required to break the security model of these two systems? With SGX, it's hard to say. It's hard to say how expensive it would be to attack and break SGX for a miner, so I've put that as an unknown.
00:29:17.628 - 00:30:02.056, Speaker A: With economics, the capital requirements are likely pretty high if you design the slashing conditions properly. However, the security outside of the design, so outside of these assumptions you've chosen in economics is zero because you haven't really analyzed the space outside of these assumptions. Whereas with SGX, the fact that you have some guarantee that the correct code is running may give you some assurances, even if you kind of look outside the specific code paths you've reasoned about. So what I mean by that is it just removes the wiggle room. It removes enough wiggle room that it just fundamentally simplifies the analysis of how much capital is required outside your design space. The next column is the engineering expertise required. So this is a big barrier to people actually pulling off attacks.
00:30:02.056 - 00:30:57.020, Speaker A: It's like getting the engineers together in the room and doing the attack. So with SGX, to get together kind of ten engineers to do this attack, you'd need a pretty high kind of level of engineering expertise. You'd need people who are familiar with either kind of extracting keys from secured memory through kind of molecular level analysis, or specific side channels, or kind of very specialized technical attacks. So that's a pretty high level of skill. With economics, violating the economic assumption requires capital usually, and not much coding ability, you can usually violate the assumptions pretty easily. That also brings me to this next row, which is how many people do you need to get together? Right? Generally larger conspiracies are more likely to fail. So my personal heuristic is like you probably need at least ten people together in a room to break SGX with at least one month of lead time, whereas the coding level to kind of code a malicious ETH validator is almost trivial when you're modifying stock software.
00:30:57.020 - 00:31:47.724, Speaker A: So the point here is that these approaches are complementary and not mutually exclusive, that SGX adds barriers that economics misses and economics imposes capital requirements that SGX may not have. So using these together is kind of our proposal here at Flashbots. Next slide. And another reason for that is because of these system shocks we're talking about. So here are some Flashbots bundles that are the most profitable bundles ever. You can see some bundles that pay as much as ten different ETH blocks, 30 different ETH blocks, 50 different ETH blocks of reward. So in these moments, and we expect these to continue increasing, it's much easier to kind of defect from the crypto economic system because of that lower barrier to defection than from this kind of more technical cryptographic equilibrium, even imperfect cryptographic equilibrium.
00:31:47.724 - 00:32:32.610, Speaker A: Next slide. All right, so this is the last slide that I think is kind of important. So you might be thinking like SGX is poned, it's not secure. And this is the slide I kind of want you to look at and internalize, if that's your opinion. So here I have two different worlds and I'm not sure which world we're in, but I want to raise the top and bottom world as two possible worlds. And what these graphs are showing is how much does it cost to attack SGX, how much does it cost to attack one chip and break it, and then how much does it cost to generalize that attack to two chips, to three chips, to four chips, to five chips? What is the economic marginal cost of attack? So in that top world, it's expensive to have a specific attack. Maybe it requires a lot of research, but cheap to kind of reproduce it.
00:32:32.610 - 00:33:14.460, Speaker A: Sorry. The labels on these emojis should be switched, that should be nontrivial or low marginal costs. Basically, in that world we're screwed, right? Because miners can simply pay this $3 sign, which is probably going to be less than the total available mev, and scale their attack to infinity. However, if instead we live in the bottom world, where there is a marginal cost at equilibrium to attack each chip after the first one has been pwned, we can leverage that to build secure crypto economic systems by only entrusting each chip with the amount of value that is kind of much lower than that estimated marginal cost. So that is where the security of SGX comes from. And why SGX is still secure even in the face of attacks. Next slide.
00:33:14.460 - 00:34:09.800, Speaker A: The last slide here that I'm going to talk about, and I'm overtime, so I'm not going to finish the slideshow. Most of it is the rest of it is just fluff, but I really want to get through this. What about when SGX breaks? So this is a key way to think about SGX in your protocol. What happens when protocol security properties break? First of all, can the public tell? If it can't tell, then maybe SGX can still provide some defense in depth, where if it's working, it gives you additional properties, but if it's not, we don't really rely on those. That's what's known as defense in depth and like layered defense to make attacks more expensive. If the public can tell, on the other hand, if it produces objective evidence, or if it produces evidence at all, you can build protocols that are either subjectively or objectively secure without relying on intel and without relying on SGX or trust, because you have this kind of additional falsifiability when it fails. So anyway, that's all I wanted to say at Flashbots, we're building both protocols.
00:34:09.800 - 00:34:48.200, Speaker A: I would love to talk to you guys about where SGX fits in this ecosystem and where it doesn't, and let's chat more about it. Sorry for the technical issues earlier. I'm going to go dig into my Linux configs and make sure doesn't happen during the rest of the day. Thanks everyone for listening. And probably no time for questions, but feel free to ask them on Twitter, I think. Great, thank you. So there seems to be a lively discussion on the Eastglobal TV live chats, so if any of the speakers here have time, can also hop onto Eastglobal TV to interact with our global audience.
00:34:48.200 - 00:35:31.476, Speaker A: Next up we have Alejo. Alejo, would you mind directly sharing screen? Perfect. Yes. Can you see my presentation now? Yes. Awesome, thank you. All right, so I'm going to talk about near future, which is 1559 upcoming. This is joint work with Christophe from Nethermind.
00:35:31.476 - 00:36:27.150, Speaker A: And let me also say that this is very much a work in progress. Hopefully we'll have a write up of this soon. So perhaps some of you already thought out the question of MEB in 1559 and the first conclusion one might arrive to, there's nothing new under the sun here, we're going to burn the base fee, but there's no new mev extraction opportunity that's raining on us. So it's nothing really strange, but still we think there's some. So this is perhaps correct at order zero, but we still think there's some interesting things to be said about one and mev. So hopefully this serves to spark some further thought on this. So I only have 15 minutes and I already spend my talk index time, so it's going to be three surprise topics coming.
00:36:27.150 - 00:37:16.984, Speaker A: First one is on minor economics, so naturally there's the question of okay, now that. They will have less revenue after 1559? Will they be incentivized to extract more mev in particular in nefarious way like Charlie pointed out before, is there going to be more reorgs and time bandits and so so, okay, this is an interesting question. First we realize we need some better understanding of minor economics actually. So the first question we ask ourselves is will miners switch lanes? Meaning will they be incentivized to switch to other blockchains after the reward cut? So we built a super simple model. I'm going to run through it to try to assess this question. This is an equation for profit. So the profit is just reward minus cost.
00:37:16.984 - 00:38:16.872, Speaker A: There are some equations for hash rate. There's a total hash rate that's distributed between ethereum and x other GPU based blockchains after one five nine. This looks again distributed between post one five nine ethereum and some other blockchains. Assuming the total hash rate stays the same and there's a revenue drop due to the burning of fees in 1559 parameterized by some parameter gamma, then we state some equilibrium here. We say like the profit per hash rate is the same in ethereum and in other blockchains. Otherwise it would be a non equilibrium situation where miners would be switching and another equilibrium holds after the London fork. So we plug in some algebra here, we do some rearranging and we can find an expression for the actual fraction of hash rate that stays in ethereum after the London fork.
00:38:16.872 - 00:39:07.576, Speaker A: Let me say that this is of course a very naive model. It doesn't consider in particular the cost of switching or the fact that the revenues are denominated in different currencies and miners might have more or less trust in the different currencies. So again, this is a very coarse first approach to this question. But we can do some nice colored graphs here. You see the fraction of miners staying in ethereum after the forecast function of the revenue drop after 1559. And we have another parameter which is again the size of these other blockchains in terms of revenue for miners in proportion to ethereum. So we can plug in some numbers here with actual data from the different revenues, the sizes of other blockchains.
00:39:07.576 - 00:39:30.064, Speaker A: And we actually find that we're in the red cross there in the graph. It looks like most miners will stay in ethereum. According to this prediction it's zero point 98. So 98% of miners would stay. The equilibrium would be at 98% of miners staying. Of course these numbers are super tricky. They change by orders of magnitude.
00:39:30.064 - 00:40:17.220, Speaker A: So you're all aware of how gas prices change. So take this with a grain of salt. So okay, this is for again the minor economics and switching to other chains. How does mev play a part here? So first question that comes to mind is how much extra mev miners will have to extract to match profits before 1559. And this is a whooping 150% more. So they would have to go through a lot of effort to try to increase their extraction widely to actually compensate for the drop in minor revenue. But of course this might be like prohibitive or it wouldn't be easy, of course, to try to come up with strategies to do that.
00:40:17.220 - 00:41:15.256, Speaker A: So the next question is try to integrate the two things and compare the extraction with the switching so we can ask how much extra mev would need to be extracted to match their revenue hike from switching chains. Okay, so to achieve this equilibrium, in achieving this equilibrium, they would increase their profits a little bit. What would that be compared to if instead of switching, they would extract more mev, and this is a more reasonable number of 22%. Of course, these numbers don't tell us what miners will actually do. It's not enough to think about these numbers in terms and try to come to conclusions, but it gives us a framework to compare the two different things that are switching to other chains and extracting more mev. So we think it's a first steps to work. Next step would be incorporating costs more quantitatively and try to model that and perhaps agent based modeling and so on.
00:41:15.256 - 00:42:05.424, Speaker A: So again, this is a first approach. Take it as a working process. I think it illuminates a little bit the different ways of these two factors of the equation switching chains and the MEB one. Okay, the second topic I wanted to talk about is the fact that there's actually many auctions going on in Ethereum, despite the picture we have of running one auction for inclusion. So 1559 was designed and mostly analyzed in a pre mev world. Charlie already gave timeline for how mev developed, and although the mev idea was there earlier, the extraction was much less and was a fringe activity. Now we're in a world where this is commonplace.
00:42:05.424 - 00:43:18.456, Speaker A: We have like flashback suction all the time. But what happens here is that this design assumed there was an auction, that the Ethereum auction was for transaction inclusion in blocks. While in reality we know that users bid for much more than that, they also bid for ordering of transactions, they bid for privacy and so on. So how does this change things? So in particular, I'm going to focus on Tim RAF Gardner's analysis of 1559. So he posits three things that are desirable from a transaction fee mechanism. The first is the myopic minor incentive compatibility, saying that miners are incentivized according to the mechanism in the first place in the short scale, one block. Second is user incentive compatibility, meaning they'd achieve the desired UX improvement of users expressing their true preferences for inclusion without needing to strategically speculate on what other users are doing and off chain agreement proofness, meaning that users and miners cannot outgate the system by making agreements outside of the chain.
00:43:18.456 - 00:44:37.064, Speaker A: So he shows that MMiC and OCA proof are satisfied by 1559, but the UX improvement is only achieved outside periods of high demand. In that same paper, he posits another alternative possible mechanism, which is the tipless mechanism, which he shows to be myopic minor incentive compatible user incentive compatible, and only OCA proof outside periods of high demand. Right? So here we're left wondering, okay, right now we know that Ocas are commonplace these days via flashboards, for instance, for ordering of transactions. So perhaps having a tipless mechanism would have been a better idea, like where users are all the time guaranteed that they don't have to speculate on other users price setting when they only care about inclusion and separate the auction for ordering. Right? So, again, this leads us to think, okay, there's this many auctions going on. Perhaps we could think of the inclusion one as optimized for user experience and have the ordering one be done elsewhere. In particular, we have already mentioned this.
00:44:37.064 - 00:45:20.432, Speaker A: We have the inclusion auction privacy, the ordering one, all handled at different levels, if you will. We're, in fact, at Flash starting to discuss tiers. Okay, some searchers care about ordering, but perhaps regular users only care that their trades are not front run, so they only care about privacy. So should we treat this separately? And in fact, if you look at traditional finance, they run different markets for different instruments. There's one for stocks and one for options. And these are all separate places, so they can be more efficient. And if you look at our auction, it looks like it's perhaps more attuned to arps than liquidations.
00:45:20.432 - 00:46:12.230, Speaker A: And due to our pricing formula and this is all open and you can look at this formula in our documentation, there's discussions in the GitHub. So this leads us to the greater question of can we efficiently encompass all preferences with a single auction? And here, the key word is efficiently. Again, this is many things going on at once. Can we make it in a way that it's efficient for all the interest there, for all the users? This is one of our key research problems. So if you're interested in that, please come talk to us. And yeah, now that Mev is commonplace, more generally, we need earlier involvement with the EIP process. I'm happy to say that we're thinking a lot about East Two and how mev will interplay with East Two.
00:46:12.230 - 00:46:46.544, Speaker A: All right, final topic of my session, it's on flashboard ethics. So ethics is something that was on our research agenda from the very beginning. It's really critical for us to be transparent. And in particular, right now, 85% of the ethereum's hash rate is running our software. So it's a new shelling point. And by this, I'm thinking out a situation where miners could passively collude by just adopting Flashpots default. This is not different from the situation before where geth was this shelling point.
00:46:46.544 - 00:47:26.296, Speaker A: But now that we have that responsibility, we will be open about it and think about implications of that. And here I'm thinking about within protocol collusion. So nothing like 51% attacks or something like that. But instead, to give you a concrete example, we have in mevgue a parameter that's the max merge bundles. So it's a parameter that says how many maximum bundles can be merged in a block. And so could we. Flash codes lead to having only bundle blocks, so no vanilla transactions by playing with these parameters and feeding something to the miner.
00:47:26.296 - 00:48:34.528, Speaker A: So this is clearly not feasible because there's opportunity cost eventually of leaving transactions out. So this comes back to the first slide there, where there's really nothing new here. But this brings yet another question. So, doesn't seem like Flashbots is more powerful after EAP 1559, but can Flashbots defeat 1559? And to wrap up my talk, I'm going to show you some ideas along these lines, or one idea along these lines rather, which is, what if Flashbots by default, decided to fill blocks only up to size slightly smaller than the target block size S zero? Right? So we can actually simulate this again, assuming 85% of the hash rate is doing this, instead of what's meant to be filling up to S zero. And this is what we find. This is the base fee as a function of the time for different values of this epsilon parameter for some demand dynamics. This is based on notebooks by the robust incentive groups at the robust incentive group at the Fume Foundation.
00:48:34.528 - 00:49:34.748, Speaker A: So you see here that for some value of this parameter, if all miners run this modification to the software, they would be able to drive the base fee to zero. Of course, the question is, is this tenable economically? Right? They would be forfeiting a profit, immediate profit. In the long run, this would be good because there would be no burn fees, so it would be all tips thing they can get revenue out of, but it will be in the short term unprofitable because it would be leaving transactions out. So what is the critical number of underfilled blocks for this to turn a profit for miners? Okay, and this is the part where it's a work in progress. This is unfinished work. So hopefully we'll have an answer for this question soon. Again, it's important to think about this question for how 1559 will ultimately have an impact on the network.
00:49:34.748 - 00:49:53.630, Speaker A: So stay tuned for an upcoming post on this. Again. This is joint work with Christophe and gasso. And thank you all the people that contributed to this conversation. Bernard Emmanuel and the Ros Incentives Group. Tim Baker, Leo Zhang and of course, the entire Flashports Group. All right, thank you all for tuning in.
00:49:53.630 - 00:51:05.040, Speaker A: All right, thank you, Alejo, and you made it perfectly in time. Yes. So, do we have any questions from Eastglobal TV live stream for the speakers? If not, I suggest the speakers who just finished speaking can sign in to ETHGlobal TV, where you can directly interact with our audience on the live stream. Next up, we have our first panel of the day, mev and interoperability in across l two and cross chain world. So the moderator of this panel is james. James. And a note to all panelists, please turn on your camera if you would like the east global live stream folks to actually see you when you speak.
00:51:05.040 - 00:52:09.998, Speaker A: If you just have an avatar, people can only hear your voice. All right, so let's get started. James, are you here? Can we unmute the panelists based on those pictures? I feel like I could sub in for James, but I'm not him, I swear. We can recognize your voice, ben okay. I was able to unmute myself. Yeah. Hello, Zaki.
00:52:09.998 - 00:52:36.880, Speaker A: How's it going? Can you hear me? Yes. Yes, we can hear you. There you go. Finally figured out how to use zoom. All right, let's see. Cool. So I'm assuming that I'm not going to see myself show up on the zoom call here because I don't know how this works.
00:52:36.880 - 00:53:02.040, Speaker A: We can just dive into the panel because it looks like we have most of the panelists here. I think the only person I haven't heard from yet is John Adler. Do we know if he's on the call? I'm here. Oh, perfect. And I can even see you. Cool. So this panel is about mev in the coming cross chain world.
00:53:02.040 - 00:53:36.020, Speaker A: We only have about 30 minutes for it, and we have five people. So I'm going to try to get through the introduction really quickly so we can just dive into questions. I'm James Preswich. I'm going to be moderating the panel today. I'm lucky enough to have with me five people who work on layer twos, roll ups and cross chain environments like Cosmos and Celestia. Throughout the panel, I'm going to be trying to say cross domain. Some of these things are not strictly speaking chains, although a lot of the semantics for connecting them are just the same.
00:53:36.020 - 00:54:22.690, Speaker A: So whenever I say cross domain communication, just think cross chain. I'm just trying to be a little more technically accurate. So I know that each of the panelists has a lot of opinions on the subject. I'm going to give each of them just a minute upfront to talk about themselves, their project, and give a brief introduction. Could we start with Zaki? Cool. So I wear many hats. I think in this particular domain, I'm wearing the cosmos IBC hat, representing sort of the live Internet blockchain, like communicating light client system of inter blockchain communication.
00:54:22.690 - 00:54:45.670, Speaker A: Great. John, do you want to go next? Sure. Hello, everyone. I'm John Adler. I'm with Celestia labs, where I do protocol, specification and research. And I guess I also wear several hats. And in this case, I guess I have been brought on to talk about things like shared security models when it comes to cross domain communication.
00:54:45.670 - 00:55:15.490, Speaker A: Ed hi, everybody. I'm ed Felton. I'm co founder and chief scientist at Off Chain Labs. And we make Arbitrum, which is a layer two scaling solution for ethereum. Ellie? Ellie. Ben Sasson, co founder and president of Starkware. We use ZK Starks, which I co invented with some of my co founders to solve scalability on StarkNet and Ben.
00:55:15.490 - 00:55:54.190, Speaker A: Hey, folks, I'm Ben, co founder at Optimism. We're building optimistic ethereum and I will similarly take less than my minute a lot of time. Well done, panelists. We're moving through things quickly. I think it's interesting that we have a split of Know, John and Zucky who are working on multi chain environments and other non ethereum things. And we have primarily ethereum based roll ups which are split between the optimistic with Ben and Ed and the ZK with Ellie. So I kind of want to start off by talking about the technology a little bit for each of you.
00:55:54.190 - 00:56:45.294, Speaker A: How does your system handle cross domain communication for the rollups? How do you communicate with the layer one? And for the cosmos and Celestia What does that even mean in your environment? And let's go in reverse order. Can we start with Ben? You can indeed, yeah. So in layer twos, right, where we have this L One running the show, where the data is coming into and disputes are going to be handled if necessary. Basically, the L One is that source of truth. The cross domain messaging is sort of based in that L One. So we have two kind of levels of cross domain communication in our system. The first is a lower level one where basic, but the interfaces are very similar and it's about the properties that these two bridges give you.
00:56:45.294 - 00:57:46.302, Speaker A: So at the lower level, you basically have any smart contract or account on layer One can send in a message which specifies a target, some data and a gas limit and that will eventually be included as a call in the L2 chain or domain, I should say. So that's what it is. And then you have an opcode in the L2 VM that lets you access who on L One sent that call. So there's one tricky part with L2 S, which is that you can be out of gas and you kind of can't know about it on L One. Right? Because you have to impose a gas limit on L2. And because the whole point is that L2 is a separate environment, l One can't know about it. So basically we add an additional layer of messaging which is like, really what's exposed to devs, which has the same properties, but basically wraps everything in a system that enforces atomicity.
00:57:46.302 - 00:58:13.834, Speaker A: So it might be the case with that lower level message sending that a smart contract might send a message in. But on L2, that basically times out or can't be run because you're out of gas. The chain is too congested at the moment. So we add in another layer of messaging that gives you atomicity, where if you pass the message in, it's guaranteed to be received at some point in the future. Some point in the future, some point, that's right. So that's kind of the two levels of cross domain messaging that we have. Cool.
00:58:13.834 - 00:59:14.474, Speaker A: And let's go to Ellie. How does the Stark based roll ups handle cross domain communication? So, currently we have a few different systems that are alive in production. And the way that there's cross chain communication right now is basically through layer one and the way you would imagine it, that you pull something out and you take it in from the other side. And I like to speak more about what we actually have and about what might be in the future. I'll just stop here. We'll have better cross chain communication directly between things, but when it's ready, we'll be able to discuss it. But yeah, that's the way we do it right now for people who might not be aware.
00:59:14.474 - 00:59:51.260, Speaker A: How many different production systems is Starkware running right now? Currently we're running three production systems. Spot trading, it's diversified. dYdX does margin trading or perpetuals, and just 1 second. And I'm at home with my kids and Immutable X does Minting and trading of NFTs, also third party. So they have a whole ecosystem running there. And very soon, Sorre is going to go live, which is going to be another NFT based thing. So three right now, in a few weeks, four.
00:59:51.260 - 01:00:48.374, Speaker A: Very cool. Ed, same question. How is Arbitrum handling communication with the L one? Sure. So some people will use specialized cross domain functionalities, like cross chain atomic swaps and so on. That would work pretty much across any pair of chains. But the general purpose cross domain communication and call mechanism we use is basically one that allows a contract that's running on one chain to send a call to the other chain so that's call data, call value and a destination. And because the L one and L two run asynchronously from each other, what you get is that you can know synchronously that your call has been in queued for the other chain, but it does run asynchronously, which means you know it will run, but you don't get to see the result within your own transaction.
01:00:48.374 - 01:01:36.602, Speaker A: And this is true in both directions. A contract on either chain can make a general call to any contract on the other chain by this mechanism. And then there's other functionalities built on top of that, such as Token bridging. Isn't that generally true of all cross domain communication, that everything will run asynchronously? Pretty much. I think when you're talking about a roll up type of approach, asynchrony seems to be necessary, at least without if you were to lockstep things together more, it would have side effects that you wouldn't want. Okay, and John, I think you're up next. Celestia, what is the concept of a domain and how do you communicate between them? Sure.
01:01:36.602 - 01:02:28.150, Speaker A: Thanks. So for those unfamiliar, I'm going to do like a five second spiel of what Celestia is doing, because otherwise my answer will make no sense. Essentially, it's the first and currently only general purpose data availability chain. It's a chain that's specifically built just for data availability throughput it doesn't execute any transactions. And before Dancrad crucifies me for saying general purpose, we can also call it overhead minimized. And because it doesn't execute any transactions, it doesn't actually have any notion of bridges with anything else enforced inside its VM, because it has no VM, essentially. So what this means is you can build applications on top of Celestia that leverage it for shared security, and those applications can define their own mechanisms for crushed domain communication.
01:02:28.150 - 01:03:16.490, Speaker A: And Celestia does not enforce anything. So to give an analogy, it'll be like asking ethereum, how does it handle a cross roll up communication? Well, it doesn't because it's a credibly neutral layer that you can build applications on top of. Similarly, Celestia doesn't enforce anything around cross application communication. However, it does provide certain interesting things when you're dealing with cross domain communication. Namely, it allows shared security. And what that means, it's a shared time snapping server. So imagine if you had like a BTC relay or some sort of Bitcoin relay where you would still have to do fraud proofs or blockhead or validity or transaction validity and stuff, but you just straight up didn't have to deal with Bitcoin reorgs.
01:03:16.490 - 01:04:05.146, Speaker A: You just completely remove reorgs out of the equation. And both chains can proceed in lockstep that if you try to reorg one chain, you would also, as a consequence, reorg the other chain. That kind of stuff can really help cross domain communication, and it allows general purpose chains to leverage the same nice token and smart contract call bridges that systems like Starkware and Optimism and Arbitrum have been doing. You can leverage those kinds of mechanisms between more general purpose chains so long as you have the shared timestamping server. So in a lot of ways, it's similar to a framework for roll ups and for communicating between roll ups. You could say that, yes. Okay, and Zucky, let's finish off this round of questions with you.
01:04:05.146 - 01:05:11.920, Speaker A: So IBC, which is Cosmos's flagship inter blockchain communication protocol, is an asynchronous packet based system between blockchains that have sort of fast finality between them and primarily exists between tendermint ecosystem blockchains. Let's see, what are the other sort like right now? I think one of the coolest things about IBC is its general tolerance for failures of any sort of intermediaries. So the chain that you're communicating may have lost liveness the chain you're communicating, there may not be a live relayer between them. And we have reasonable failure recovery paths between all of these things, which I think is relatively cool and unique and is running in production right now. And people are sending like, tens of thousands of IBC packets every day, which is kind of cool. Very cool. So this is more of an open question for the group.
01:05:11.920 - 01:06:58.100, Speaker A: Are there any specific apps that we're seeing use cross domain communication? I think a lot of us have talked about token bridges is how do we get assets from one domain to another? Are there any other applications that we think are going to use this and anyone can just jump in here? Yeah, I'll jump in. So in addition to token bridges, a common design pattern that we're seeing is applications that want to exist on multiple chains, say on L One and on Arbitrum, using one of two patterns. Either they're sort of homed on one of the chains and open up a sort of branch office contract on the other one, where the home is the ultimate source of truth, but they allow people on the other chain to have whatever functionality their application provides. And we're also seeing some that are genuinely dual homed where you have a contract on each chain and those communicate with each other through a combination of out of band mediated communication and also the on chain supported cross chain functionalities, and they're jointly providing functionality. So we're seeing people, especially in the DeFi space, building a lot of interesting things in this design pattern. Do you have an example of the second pattern? An example of this? I don't want to name specific names, but we are seeing people who have token based systems, for example, that can do Minting and Minting and redemption type of activities on both chains. So it's not the case that you have to transfer your tokens to either particular chain in order to do those things, whether you can only Mint on one.
01:06:58.100 - 01:08:00.294, Speaker A: So that's a simple example. Interesting, I can offer another example with respect to or a class of things that could come either from L One or from other L2 S going towards StarkNet. So I think the main advantage of something like StarkNet is that you can really compress both computation and the nondeterministic witnesses that are needed in other things. Both l one and other l Two S. So you could sort of have a situation where you want basically to relay or ask from l one or from some other L two StarkNet to run this computation, let's say a VDF or an auction or something that has compute something an average based on many, many Oracle price feeds and things like that. And if you would have done it either optimistically or on l One, you would have paid either for the computation or for the computation and the transmission, depending if it's on l One or some roll up that needs to put all the data. And so I could see those kinds of bridges as well.
01:08:00.294 - 01:08:41.330, Speaker A: And so these are non token bridges. These are basically bridges or the communication where you want to rely on the ability to compress computation and call data on something like STARTnet. They don't exist right now, but they exist implicitly. Like dYdX relies on multiple computations of price oracles, and all of the signatures are abstracted away. But I could see use cases where there's demand from it from L One. So kind of the general thing there is that you're using the cross domain communication to communicate about the validity of some computation. Right, right.
01:08:41.330 - 01:09:27.300, Speaker A: And nondeterministic witnesses that maybe you don't want to verify on chain. Right. Things like large batches of signatures you can just drop from the message entirely. Got it. Very interesting. Any other examples of cross chain applications that we're seeing? One of the things that the Cosmos ecosystem is most excited about is what we call interchain accounts, which is basically taking the idea of, like, a smart contract account or smart contract like wallet, and extending it to the idea of an entire blockchain. Can be represented as an account on another blockchain and has all the powers of all the capabilities of the native blockchain on the other blockchain system.
01:09:27.300 - 01:10:08.266, Speaker A: It's probably less abstract than the other examples that people have been giving, but I think it's like the level of excitement about it shows the demand for things beyond token transfers generally. So the idea there is basically that this other domain has an account and can call contracts or perform any normal blockchain action. Yes. Very interesting. I wanted to add James, another specific example of the kind I said is just voting. So you have a bunch of stakes, let's say some ERC or governance token. You want to collect votes.
01:10:08.266 - 01:11:15.890, Speaker A: If you do it on L One, it's going to be very expensive. You could ask StarkNet to do that for you. So you could take something like Snapshot and turn it into Stark based proof that the vote occurred. Okay, very cool. So we've identified a few cross chain applications, things like attesting to validity, allowing a blockchain to control an account in another blockchain, DeFi apps that are homed on multiple chains and can perform all of their functions. There are there specific ways that mev in this application differs from mev within a single domain. I'm willing to go first and say something obvious, which is that even like in the conventional financial world, apparently a lot of the Arbitrage and high frequency trading is connected to having different systems or exchanges or markets where things are happening, sort of connecting the dots and acting on them.
01:11:15.890 - 01:11:57.682, Speaker A: I think mev has this aspect to it, which is that you even can manipulate or do things. The more places that you have where things could sort of be manipulated, then of course it just raises the possibilities. But this is just a general state. So, like, if you could influence both the sequencing at one place or the transactions or the mem pool in one L two and then in another side chain, then of. Course, you could have even more arbitrage opportunities. But this is, again, I think we'll see it in the future, probably this kind of ties into what Ed said earlier about computations running asynchronously in all these environments. Sure.
01:11:57.682 - 01:13:04.402, Speaker A: And, yeah, let me jump in. I think Ellie was talking about the sort of combinatorial explosion of different mev strategies and levers that happen when you have more than, say, two chains or domains. In the case of two, I think, like the L2 S, I think the roll ups probably are similar to what we see, which is there is a mechanism which determines the order of transactions or incoming inputs to our roll up chain. And that really is the mechanism that establishes order and where the mev and fairness questions are going to be dealt with. And that's because if it's an L One to L2 call, then you have an L one contract that wants to put an event into the inbox of the L two contract. And that essentially goes through that ordering mechanism. And if it's something that happens at L2, well, L2 transactions are ultimately triggered by inputs that come in and also go through that ordering mechanism.
01:13:04.402 - 01:13:59.180, Speaker A: So there's that single ordering mechanism. I think that would be true of other roll ups as well. And so the question is, how do you handle that? Because that's what determines ordering and mev and fairness consideration. So we've devoted a lot of attention to how we do that in a way that reduces the amount of value that gets extracted from users, and that is as fair and transparent as we can make it as we evolve over time. So the problem here, if I can restate, is that messages between domains and messages to a specific domain can be interleaved. Arbitrum has a shared ordering mechanism for these, but other cross domain systems might not. So, given the example of IBC, there is probably no global ordering of IBC messages between domains, right? Zaki no, there could not be.
01:13:59.180 - 01:15:02.250, Speaker A: And for optimism, for example, does optimism maintain a separate mem pool that is ordered separately from incoming L one messages? Yeah, we do. It's an interesting question and a great discussion. I think one of the interesting I will call out one difference between cross domain messages and other, just like within the transactions within the L two. Ed's definitely right that at the end of the day, the L two's ordering is determined by some mechanism which is on L2. One interesting thing, though, is that that mechanism is also required to follow the L one ordering. So one interesting thing that we see is that if you have a transaction which is just a piece of data that is like an L2 transaction, it's like a user transaction with a signature, then you can attempt to order that optimistically before it goes on chain and know the outcome. But this is not the case for the finality of deposits.
01:15:02.250 - 01:16:28.682, Speaker A: Because if a smart contract calls into the chain that is dependent on the l One's finality. So if you have an l one reorg, you might observe that a different message ends up coming into the chain because let's say the l one reorg moved some money away and now the deposit can't actually be deposited. So I think this is worth calling out that cross domain messages are going to be more restricted in how quickly we can get them in and choose an ordering for them because what they are doing is required to depend on the l one state. Can I respond to that briefly? I think there's actually different ways of handling that use. Case question is, do you need to evaluate the correctness of this thing at l One before you can establish it in order? Do you need to determine whether it will succeed at l One before you assign it a spot in the order, or do you assign it a spot in the order and then the result of it may be dependent on l one reorgs? And there's some design choices there which do affect what outcome you get. So do you think we're likely to see well, let me rephrase that. I think that we're seeing a wide spectrum of choices here from a more tight ordering to something like Celestia where there is no guarantee that any specific message will succeed or do anything.
01:16:28.682 - 01:17:18.050, Speaker A: Is that right, John? Not exactly. So for people, I guess not familiar, but solutions like Arbitrum, for instance, uses correct me if I'm wrong, Ed, but they use this inbox style system where anyone can submit a transaction for the roll up and they can submit it into an inbox contract on the L One. Is that correct? Yeah, that's part of the story. We also have a sequencer which has limited power to reorder transactions in order to make faster guarantees. Yeah, so you have those two components. So I think what James is alluding to is he's saying that Celestia would only have that first scheme of anyone can submit a transaction and then they come in any order for the L2. But that's not exactly correct because you can also do batches of transactions and in fact, you can have entire blocks on top of celestial.
01:17:18.050 - 01:18:05.718, Speaker A: Application can be blockchain based and they can have blocks and you can decide your own sequencer aggregator or however you call it. And for example, they can be the only ones that have the right to produce blocks with application. And everyone else, you just ignore the messages that they post. So you can get essentially the same thing that you get out of rollups on top of Celestial. You don't have to worry about this kind of anyone can just post anything at any time. But I did want to mention one thing relevant to your question, if that's okay, which is that I like to invoke what I call the law of conservation of mev when it comes to layers, which is basically that mev can't be created or destroyed. Well, it can be created, it can't be destroyed, it can only be moved from one layer to another, which is completely not scientific law or anything.
01:18:05.718 - 01:19:02.378, Speaker A: It's just an observation, which is basically saying that if you have a roll up, you're not going to have less mev, you're just going to move the mev from the best you can do is move the mev from the main chain to the roll up, which isn't inherently bad, especially if you use only batch submission style systems and no inbox. Then the layer one doesn't see the mev, it just doesn't see it because the only people who can submit blocks are these layer two sequencers that comes with its own set of trade offs. But you can move the mev to a layer two, but you can't eliminate it'll, still be there in terms of quantity. So the mev of the total cross domain system is always increasing at the very least? Yes, it never decreases. Interesting. I don't know that that's true in general, actually. There are degrees of freedom in design that you have in an L two system that don't exist in the fixed architecture that exists sort of on Ethereum L one.
01:19:02.378 - 01:19:50.294, Speaker A: And so you do have opportunities for design that Ethereum doesn't have because Ethereum already exists and has baked in a certain approach. So I don't think it's at all Ethereum that you can't reduce mev. It's not easy. And if you're just careless about it, you probably will maintain or maybe even increase the extractable value. But you can do better if you're willing to innovate in design. So I should clarify that when I'm talking sorry, very quickly, if you don't mind, I should clarify that the observation I'm saying is mostly about if your layer two functions the most naive way and exactly the same as the layer one, then you're not removing mev. Of course, just like how you could change layer one to reduce mev, you could also apply those changes and experiment with new techniques for sequencing, aggregation, mev reduction on the layer two.
01:19:50.294 - 01:20:59.614, Speaker A: But that's orthogonal to the fact that it's a layer two. Like you could do those same things on Ethereum if it wasn't for the fact that needed to maintain backwards compatibility. Okay, so this kind of segues nicely into the last thing that I wanted to talk about before we wrap up the panel, which is whose job is it to reduce mev? Should it be the job of the system developer or the job of the application developer? And when we get into these cross domain systems, who has to do all of the work to minimize mev and communication between want to because we're wrapping up. I'd love to do this last one kind of round robin. Give everyone a chance to speak again. And let's start with I mean, it's a great question, James, and it's the philosophical one that I think will get thrown out on every single know, flashpots talk from now to the end of time. I think the responsibility is on both parties and I think that there's a trade off between doing it within the system in terms of how universal you think those fairness properties are.
01:20:59.614 - 01:22:00.574, Speaker A: So I think that the tricky thing is that we don't yet have a result that says that any particular system can have general applications that are mev resistant in some way by nature of the system. It's not obvious at all that for any system that is non trivial, that actually can have economic activity, that there's not some application that you can put on that system that introduces mev. So fundamentally, that seems to put a lot of attention onto the application developer. If we don't know yet if it's even possible for a generalized mev resistant application, there are obviously things that we can do that are very useful heuristics and that feel very fair. It may be different between who thinks what, but fundamentally some of it has to go on the application, I think, because of the nature of that systemic unknown. Interesting. Ed, do you want to go next? I would agree with Ben that it has to be everyone's job because it's a hard problem and there are hard trade offs.
01:22:00.574 - 01:23:05.558, Speaker A: Right? So system design should be trying to reduce or mitigate mev as much as possible, but then there'll be some part of the job that will fall onto applications. But it's also important for the system designers to create affordances that are useful to application designers so that they can fight the particular mev or front running issues that afflict their applications. So it's not just sort of fighting it separately in each layer, it's also about what can the base layer do to help the application developer have the tools they need. Ellie so I take my inspiration from what happens in the conventional markets. There you are under the assumption that if there is a flaw, someone will use it and try to front run or do whatever wash trading or things that are illegal. And then it's the sort of at the system level you ban it by law and regulation. The analogy to that is that I think it is of course it's objectionable to front run do things like that and operators and whatnot shouldn't be doing it.
01:23:05.558 - 01:24:09.606, Speaker A: But I think you would like in a decentralized protocol based system, you would like to put maximal effort in getting the protocol to eliminate reduce to the maximal extent the ability to extract value from these things. Because especially in this anonymized permissionless world, it's going to be very hard to assume that DAP developers are going to be moral. It's not the case. So you really need the protocol to solve it. John sure, I would say, and mirroring what Ed said, that the protocol development developers, under the assumption here that the protocol is some sort of credibly neutral public good, probably have responsibility to at least build tools so that application developers can minimize the mev that the applications they build have. I think it should provide appropriate tools for this. And so it is at least partially the responsibility of the protocol developers.
01:24:09.606 - 01:24:44.440, Speaker A: I'm not really sure if the application developers have any responsibility. I guess it depends if you're talking about if it's like an ethical responsibility or a financial one. And it depends if the application is a public good or if it's just some financial application. Application developers. And I think the Ethereum protocol developers had to learn this the hard way with things like refunds. The application developers have responsibility. Assuming the application is not a public good, the application developers have one responsibility, and that's to make money for themselves and to a certain extent, for the users, inasmuch as that makes themselves money.
01:24:44.440 - 01:25:09.486, Speaker A: And in that regard, mev doesn't matter as long as you can make money. And that's why you see things like gas token happen. So if the application is a public good, yeah, they should probably strive to reduce MAV. If it's not, we shouldn't assume that they have any such responsibility, in my opinion. Interesting. And let's wrap up with Zucky. So, two things.
01:25:09.486 - 01:26:21.400, Speaker A: What we found is practically attempting to reduce mev propagates dependencies up and down the stack. So the demand to reduce mev is like changing APIs within how tendermint interfaces with the application, which is this idea called ABCI Plus Plus that is sort of propagating mev related ideas all the way down into how Tendermint works. And on the other hand, yes, mev is very application dependent and very much the idea of Cosmos is that people could coevolve all layers of the stack to provide the optimal user experience and to go to a little bit of why would someone want to do this? Why do people care? People care because mev reduces takes value away from their users and sends it to other parties. And you will probably be more successful in acquiring users if that doesn't happen. All right, thanks for your time, everyone. Always a pleasure to see each of you. I think Sunny is up next.
01:26:21.400 - 01:26:56.110, Speaker A: Yes, thank you for all the panelists, and we shall proceed to the next section. Wait, now you guys can hear me? Okay. Hey, guys. My name is Sunny. I am one of the co founders of a project called Osmosis. It's a Dex built on the Cosmos ecosystem. And one of our main things that we've been focused on is how to decrease front running in new L ones.
01:26:56.110 - 01:27:39.694, Speaker A: And yeah, so I've been thinking about mev for a long time. I think initially started thinking about it with the Flashbots team last summer. And so part of what I've been doing is thinking about how to classify mev and how to approach different. I feel like this mev terminology is very broad and covers a whole swath of different kinds of things. And so I wanted to kind of dive deep into figuring out how to classify it, and then with each sort of category of mev, what kind of solutions are possible, and then just come up with a model for how to think about solutions. So to start off, I just want to get one thing out of the know. Mev stands for minor extractable value, but really it's proposer extractable value.
01:27:39.694 - 01:28:29.882, Speaker A: Thank you Phil. For end of time we're always going to have to start every single presentation with this caveat. But yeah, so as systems switch towards proof of stake, we don't have miners anymore, but we have proposers. But really it's the same sort of thing. It's whoever is the block proposer has some ability. How are we defining mev? I like to think of it in terms of proposer powers. So what unique powers does a block proposer have that they can single handedly execute? So obviously it depends a little bit on the protocol, right? Like different protocols, block producers have different powers, but we can talk a little bit just about some of the generalized ones that are pretty common throughout most protocols.
01:28:29.882 - 01:29:27.614, Speaker A: Obviously some protocols will have more, some will have less, but some of the most common ones, one of them that comes up often is the mess with the timestamps in their block proposal. So in many protocols, so including Bitcoin and Ethereum and many protocols in a distributed system, you often need some form of decentralized clock and we often use the block proposers as a sort of oracle into wall clock and because they're being used as oracles, there's very little that they can do here. And so a lot of flexibility that they have and very little ability to slash them. Both Bitcoin and Ethereum have models of constraining their ability. Bitcoin does the whole has to be greater than the median of the last twelve and whatnot. But with this you can pull off a lot of different sort of attacks. There's randomness manipulation.
01:29:27.614 - 01:30:25.730, Speaker A: So if you remember back in Ethereum a couple of years ago when everyone tried to started using timestamps as sources of randomness and that was just like a terrible idea. But the fact that a miner could mess with the timestamp and win a lottery or something, that is a form of mev because it is a type of power that the block proposer had single handedly. There's also attacks like timejacking where if you mess with the timestamps you could screw around with the consensus protocol a bit and how you can solve this. One way of doing it, this is something that we do with tendermint is we use some, you know this well, there's the application layer solution which is like you stop using time as a randomness source, but then there's also protocol layer solutions. And this is what we do in Tendermint. It's called BFT time. So the idea is basically you have every validator, because Tendermint is this BFT system where every validator contributes votes, you can have every validator give like, hey, this is what I think the time is.
01:30:25.730 - 01:32:15.574, Speaker A: And so, even if you have the block proposer, who has some weird time that completely out of band with everyone else, as long as you take the weighted median of all the votes, you'll end up with a BFT time that is more accurate than just depending on the block proposal themselves. So what is something else block proposals can single handedly do? You can do consensus vote censorship, right? So I would consider selfish mining and all the things that come from it, feather, forking, all these kind of things as types of mev, because the ability to censor other validators votes and not build on top of them is still a power that a single block proposer can have. What else can block proposers? Do? They have the ability to read transactions from the mempool. So normally, everyone has the ability to read transactions from the mempool, but thank you to Flashbot, only the block proposals now have the ability to read transactions from the mempool, because now there's a system where Flashbot provides a way for users to send transactions directly to the miners, and so it's not visible in the public mempool. So now this has become sort of a power of the proposer that is not available widely, which is good in a lot of ways, because now, instead of anyone being able to front run you, only a select few can front run you. Then they have the ability to control inclusion of transactions in their block proposal, so they get to choose which transactions to include in their block, and they get to choose the order of transactions in their block proposal. So I think what's interesting is you notice these latter three all contain this transactions as a core piece of what they're trying to do.
01:32:15.574 - 01:32:58.322, Speaker A: And so I think we can put this into a category called transaction based manipulations. So within transaction based manipulations, I think there's further subcategories, there's censorship, manipulation and ordering manipulation. Censorship could include you're just trying to censor people from a block. Maybe they have to close a payment channel or something, and you're trying to censor them. If you could do that successfully, that would be a form of mev, because there might be a way to profit off of that as well. But ordering manipulation, I think there's a couple of different ways we need to think about it. So we'll build it into this sort of quadrant.
01:32:58.322 - 01:33:27.226, Speaker A: So we'll start with things that are based on other transaction data. So you have relative ordering. So this is what normal front running is, where you see someone else's transaction and you do something with it. So in traditional finance, front running would be. You see someone's trying to place an order for a large amount of shares and you put your order right in front of them and then sell right after them. And you can profit off of this. This is called a sandwich attack in a blockchain.
01:33:27.226 - 01:34:08.534, Speaker A: It's very similar where there's a bunch of transactions in the Mempool. And then the block proposer can say, hey, I can read Alice's transaction and I want to do something with it. So I'm going to go ahead and add my transaction to the Mempool. And then make sure my transaction comes in front of Alice's because I wanted to do something off of that. Yeah, and then there's also what I'd call absolute ordering, where it's dark force pack style things. This is know, it was written by Dan and Giorgios, a couple almost a year guess. Um, and you know, the way this forms is know, you can assume that you can simplify it and say, hey, here's a reward for the first person that can show a solution to a puzzle on chain.
01:34:08.534 - 01:34:55.734, Speaker A: And that puzzle could know it's vague, it could be an exploit, that's possible. Or it could know there's many different things that it could be. But what would happen is Alice figures out the solution, she goes ahead and submits the solution to the Mempool. Which is a block proposer can now go ahead and read the transaction, add their own solution, and then make sure their solution comes first. The difference between why I categorize these as two different things about relative ordering versus absolute ordering. Relative ordering has to do with positioning relative to another transaction. So in that case, the block proposal, their goal is to be right before Alice's transaction or right after Alice's transaction in absolute ordering.
01:34:55.734 - 01:35:34.514, Speaker A: They don't really care about where in the block, they care about the position in the block. They don't care where they are relative to Alice's transaction. So why that's important is they could just go ahead and remove Alice's transaction altogether. And if they don't include Alice's transaction, but they still go ahead and put their transaction as the first one in the block, they still have successfully executed the dark forest attack, which is why I think it's worth separating these two. One requires inclusion of Alice's transaction while the other one does not. And so you'll notice that this is based off of reading other people's data. And both of these attacks come from the ability to read transactions from the Mempool.
01:35:34.514 - 01:36:10.546, Speaker A: And so the solution to this or one solution to this is you have encrypted transaction in the Mempool. So at a high level, what would happen is Alice would go ahead and submit a encrypted transaction. All the transactions in the Mempool would be encrypted. The block proposal will create a block. All the validators will commit and finalize on a block. And then some sort of private magic will happen and the transactions will get decrypted and executed. And at this point, it is too late to do anything about it because they've already been committed and they must be executed in that order.
01:36:10.546 - 01:37:12.690, Speaker A: There's many ways of doing this encryption which is not sort of I actually gave a talk at a previous Mev roast about sort of comparing the trade offs of all of these. But I'd say the three main ones that I'm aware of right now are trusted hardware, time lock encryption, and threshold encryption. This is sort of the end result of that talk I gave last time, which is, here's the trade off summaries. I'm a little bit biased because our project, we're focused on threshold encryption because we think it makes the least trade offs. Assuming if you use any of these solutions, if you're able to remove the ability to read transactions from the Mempool, you've solved sort of both of these sort of attacks. But there is like another type of ordering manipulation where it's not really based on anyone else's transaction data. And so what I mean by that is, what if the puzzle was so simple that sickai didn't need to copy anyone else, we just knew the solution ourselves.
01:37:12.690 - 01:37:50.098, Speaker A: So it's like $5 to the first person that can answer two plus two. And there could be all these solutions in the Mempool that are all encrypted, and the block proposer doesn't need to be able to read these solutions because we're not that dumb. We know the answer is four. And we can always guarantee because of our ability to choose ordering in a block, we can always guarantee that we will be the first one in the block. And so it doesn't have to always be like the two plus two equals four. It could be, for example, a liquidation, right? That's something that I don't need to copy someone else's transactions to know how to do it. It's a very simple thing.
01:37:50.098 - 01:38:41.570, Speaker A: Everyone can do it pretty easily. And so I don't have a good term for this right now. I'm calling it blind front running, but I don't really like the term. So if people can come up with a better one, that would be great. A relative ordering for something not based on another transaction doesn't make any sense because how can you be relative to nothing but absolute but not based on something else? We'll call that blindfront running. How do you prevent this? You can try to block off these powers that enable it. So the fact that the block proposer can choose the order of transactions, well, one solution you could do is some sort of order randomization, right? You could say, okay, once you decrypt the transactions, there's a second step where you use some sort of decentralized randomness in order to mix up the transactions and just tornado them around and so they get into some random ordering.
01:38:41.570 - 01:40:13.098, Speaker A: Does that solve this blind front running, though? It doesn't, because even if we go ahead and randomize the order of the transactions. You still have a situation where sika, because the block hostor doesn't only have the control of the ordering of transactions, they also control the inclusion of transactions. And so if they create a block where they are the only transaction in the block, you can randomize it as much as you want, it will still be the one that will win, right? And so you still have to solve this other one, which is the control inclusion of transactions in a block proposal. And I think this is sort of what a lot of these fair ordering protocols like Equitas and things try to aim to do, where you want to make sure that it's not just one person involved with making a block, choosing which transaction to go in a proposal. And I'm kind of dubbing all of these in this idea called joint proposals, where you say hey, instead of just the proposal including the transactions, everyone has a little bit of a say of which transactions get included and they can have overlaps, which is fine. But once you have the votes from the previous block, the next proposer has all of by having the votes which needed to commit, they by definition have to have the information of at least a bunch of other transactions. Even if they choose to do a little bit of censorship, they'll still have other people's, other votes that they have to include.
01:40:13.098 - 01:41:06.254, Speaker A: And their block proposal will only be valid if they include all of those transactions. And so this basically makes it so the proposer is not single handedly choosing inclusion, all validators have some input into the inclusion process. Obviously this helps you solve this sort of blind front running problem. So to zoom out from what is this sort of taxonomy that we have designed so far? So we have this large category of MEB manipulations. I want to avoid the word attacks because I feel that provides a certain connotation which might not always be correct. Because you want someone to be doing liquidations, that's a good thing, right? So I'll call them manipulations. We have things that are like oracle based because oftentimes block proposals are used as oracles in many protocols.
01:41:06.254 - 01:41:54.714, Speaker A: So timestamp manipulation would be categorized as a type of oracle based manipulation. There could be other ones, right? Because many protocols rely on block proposals for other sorts of things. So as an example, gas pricing, right? Or in EIP 1559, the block proposal has some amount of say in the minimum fee. And if there's a ways to exploit that for gain, that would also fall under Oracle based manipulations. Next would be consensus based, where block proposals are obviously a very important piece of the consensus protocol. And so this is where the vote censorship and the selfish mining kind of stuff would fall under that category. And then we have the transaction based manipulations in which we have the censorship category.
01:41:54.714 - 01:42:37.694, Speaker A: Which we talked about. And then we have the ordering based and there's probably other types of transaction based censorship that I'm not sure of right now, but I'm sure people can come up with more. Within ordering based, you have the type that is based on other transactions, so this requires the ability to read other people's transactions and then you have the type that's not based on other people's transactions. And then finally within the based on other transactions, we split it up into absolute ordering versus relative ordering. So the relative ordering would be what we term front running. Absolute ordering would be what we term dark forest. And then when you're not trying to be based on someone else's thing, it's called blindfront running.
01:42:37.694 - 01:43:36.354, Speaker A: And within the blindfront running, I'm sure there's a whole swath of things to talk about. Are we talking about liquidations, are we talking about there's all these different things that fall into blindfront running. So I think that's going to, if you zoom into there, there's an entire subtree of categorizations that can be done that will probably be interesting for someone else to dive into further. My project, we're focused mostly on preventing the adding mempool privacy, so we're trying to really focus on solving everything that's under that base on other transactions tree. But I think a lot of the stuff that has to do with auctions and mev auctions and things like that are really trying to solve a lot of the problems that happen in that blind front running category. And then I just want to provide a little bit of categorization to some of the different solutions that people have come up with. For mev mitigations, I'm just going to put them into three main buckets, but there's probably more.
01:43:36.354 - 01:44:35.762, Speaker A: One is cryptographic, the second is threshold based, which makes a little bit of sense because blockchains are crypto distributed systems. So obviously it makes sense that your solutions will usually be cryptographic or distributed in some based. And then there's also like application specific ones. So from the examples that we went over in today's presentation, some examples of cryptographic mitigations would include things like randomness, right? For the order randomization, you have some sort of randomness, whether it's from a VDF or some sort of threshold key, which I guess if it's from a threshold, it's somewhere in between cryptographic and threshold based. But yeah, that would be a cryptographic solution. Time lock encryption is a type of cryptographic solution to the mempool privacy. And then I'm sure if you want to get really into it, you can design very brand new types of state machines that are used Snarks and MPC.
01:44:35.762 - 01:45:23.458, Speaker A: That mitigate MEB in a way that's very different than the state machines that we're currently used to. Anyways, then you have the Threshold base, and within that, we have examples like the BFT time where you're saying, hey, the proposer doesn't get to choose. All validators get to choose. You have threshold encryption where you say, hey, all the validators have to contribute to decrypting these transactions. You have the joint proposals, right? Which is like the way of allowing for inclusion. And this is really interesting because I think, like I said, it's kind of my own definition. I posited at the beginning where Mev refers to the types of manipulations that a block proposer can single handedly do.
01:45:23.458 - 01:46:16.222, Speaker A: And if you take that as the definition, the idea of these threshold based solutions are you say, try to take these powers that only the block producer has and try to decentralize them across your entire validator set. And so you're basically trying to move these powers to have the same security model as your consensus system as itself. So with threshold encryption, only two thirds of your validators have to come together to decrypt a propose to decrypt the transactions. And so you make that follow the same security model of your proof of stake chain itself. And obviously what you need to do is now figure out how to add slashing conditions for each of these. For threshold encryption, we've come up with a lot of different slashing conditions that seem to work well. The tenderman core team has come up with a lot of slashing conditions for BFT.
01:46:16.222 - 01:46:57.934, Speaker A: Time to make it work pretty well. I'm sure a lot of the people who are working on fair ordering systems have come up with things for joint proposals. But I think that's one of my main issues with a lot of the fair ordering protocols is I don't understand how the slashing conditions work. And so I think that's something that's important to be figured out. And then finally we have this last category of application specific solutions. So this is where if you know the application you have in mind, you can design very specific solutions. Which is why so an example would be things like slippage tolerance, right? The fact that AMMS and many DEXes have slippage tolerance is sort of in and of itself an Mev mitigation.
01:46:57.934 - 01:48:05.506, Speaker A: If you didn't have the slippage tolerance, someone could front run you and just cause you to buy things at an incorrect price. So the idea is that that is a type of application specific mitigation that's already very widely adopted. You have batch execution, right? Batch execution is a form of how do you do DEXes and you provide more fair pricing for everyone that should say liquidity stability pool. So the liquidity protocol, one of the cool things that they did in their thing was they said, hey, in MakerDAO, the liquidation auctions are way too weird and too subject to mev. And so what they did was they said, hey, we're going to build into our protocol a stability pool that provides fair access to liquidation revenues for everyone who helps deposit into it. And so that's also another example of an application specific mitigation. And then just like tips and tricks like don't use bad randomness like timestamp manipulate like timestamp as a randomness source.
01:48:05.506 - 01:48:41.170, Speaker A: Right. That would also be a type of application specific mitigation where you're telling the application developers, hey, avoid this thing. So, yeah, that's the end of my talk. I hope it was pretty fast and lightning ground, but I hope that helps give some clarification of like, okay, these are different ways to start thinking about mev. And then once you really start to understand mev in terms of the powers of proposers, then you can start to work on solutions to start striking away at the different powers that proposers single handedly have. Thank you. All right, thanks.
01:48:41.170 - 01:48:54.200, Speaker A: Sunny. Hasu, you're up next. Please feel free to directly share screen. Great talk. And Sunny, you are seven minutes over time. Thanks, Sunny. Great talk.
01:48:54.200 - 01:49:27.006, Speaker A: Let's see. Okay, I think this should do it. Can you see my screen? Yes. Perfect. Okay. Yeah. My presentation is called Mapping the Mev Solution Space, mostly for dex trading because I feel like that's what most people care about and also because it makes up for huge amount of activity on Ethereum.
01:49:27.006 - 01:50:26.786, Speaker A: Right now, as we will get to I'm Hasu, you might know me as the co host of the Uncommon Core podcast, collaborate on Research with Paradigm, and I'm also the general editor of Derivative Insights. So what is mev? This is the slide that we will get in every single presentation today. Mev is permissionless incentives in blockchains, and it's usually extractable on a first come basis. In some cases, this is very good. It's purely additive to the ecosystem. For example, if you think about liquidations without all lending markets, whether it's compound or maker or Aave, they all rely on the assumption that for a sufficient incentive, there's someone available who will recapitalize positions that are close to being underwater and put sort of the lending protocol solvency at risk. And the same goes for Arbitrage.
01:50:26.786 - 01:51:14.478, Speaker A: So the most popular AMMS today, they don't rebalance their reserves automatically. They never change their price unless someone trades against the pool. So if you have a price on, say, uniswap, and in the same market, the price on binance moves up, then you need someone to also trade against the market on uniswap to create a common price that market participants can rely on. However, users can also unintentionally create mev, often without knowing. And this then leads to front running and sandwich attacks. And those are purely harmful to users. So we can summarize mev has risks.
01:51:14.478 - 01:51:54.794, Speaker A: The biggest one, I'd say, being financial loss to users. It can also lead to consensus instability. We have heard about that in Charlie's presentation, I think it was the first of the day and can lead to BP Centralization. I think that goes into what Phil said in his presentation, and we will also talk about the latter one in more detail later. But mev also has great benefits. So as we just said, it makes up some of the core functionality of DFI that many protocols need in order to function. And it also adds to a blockchain security budget in the context of ethereum.
01:51:54.794 - 01:52:48.322, Speaker A: For example, ERP One Five five line has allowed us to basically lower the inflation that was paid by holders safely because miners now make so much money from mev, and this share of their block reward was basically zero only two years ago, and now it's bigger than the block subsidy. In this presentation, we will focus on the financial loss and the BP Centralization. So, financial loss, because 70% of gas used on ethereum today is used for dex trades. Now, that's a huge amount. So this affects a whole lot of people. And many, many of these trades unintentionally create mev. They do this in the form of creating back running opportunities or sample text.
01:52:48.322 - 01:53:27.760, Speaker A: So what's going on in the chat hasu you may want to share your full screen to hide your okay, yeah, I can do that. And see how did I do that? We can also see fine. So it's all good. Do you still see my screen then? It's not anymore now. Okay, yeah. Then I'll just leave it at that. It's not there's nothing to see there anyway.
01:53:27.760 - 01:54:06.870, Speaker A: So to continue back running, imagine there are three markets uniswap, Sushi and Binance. And Alice only buys from uniswap. And this is very typical behavior for the average sort of retail DeFi user. So what ends up happening is she pushes up the price on Uniswap, but not on any of the other two markets. And if she does that enough, then it can create a backRunning opportunity for Arbitrage. So Arbitragers come in and sort of run it back to the fair market price. And this is just money that comes straight out of Alice's pocket for sandwich attacks.
01:54:06.870 - 01:54:54.730, Speaker A: I have this great diagram here by Will Warren. So what this shows sort of where a user is expected to be filled in the absence of mev bots and Mev cognizant miners. This is sort of the green line. So you can see they would be filled very close to the quoted price. But if there are mev bots present or miners who know about mev, then what will almost always happen is that the trader will instead get filled at the worst acceptable price that they defined in their slippage tolerance parameter. So based on that, we can state two goals. We want to minimize mev as much as possible.
01:54:54.730 - 01:55:42.742, Speaker A: So the harmful kind of mev that we talked about and what we can't minimize, we want to democratize in order to satisfy our second goal of preventing BP Centralization. So I have small categorization here. So generally I would separate sort of the solutions to mev into three categories on the consensus layer, the peer to peer layer, and the application layer. On the consensus layer, we will later on hear a lot about fair ordering and about privacy. And I'm greatly looking forward to these talks. So in this presentation, we focus on the peer to peer layer and the application layer. And the first concept from the peer to peer layer is gasless transactions.
01:55:42.742 - 01:56:37.782, Speaker A: So conceptually, what it means is you have a transaction where the payment to the miner is conditional on the success of the transaction. So in the context of uniswap, for example, a uniswap transaction would only be included if the trade also gets filled. So it cannot get filled, for example, because there's insufficient liquidity in the market, right? Or because your slippage tolerance wasn't met. And this is a big deal because it allows traders to sort of use the tools that are already given to them by uniswap. So users can already set zero slippage tolerance on uniswap. But what then happens is that around half of the time in markets with a lot of trading, that transaction will simply fail. And fail transactions in Ethereum also cost gas.
01:56:37.782 - 01:57:38.160, Speaker A: So this can be costly for the user, especially for smaller trades. But gas's transactions sort of completely solve that because there's a party who knows if a transaction will succeed or not. And that's the miner. So if you give the miner the right incentive to only include the transaction when it succeeds, then they will do just that. And I have this in its own category because sort of gas systems only require support from maybe the wallet and the block producer client. What this means is in the past it was not possible to make a zero fee paying transaction that pays the miner in a separate transfer of tokens and not in sort of the native fee, in the native fee field. And this changed due to Flashbots, right? So Flashbots gave miners the ability to also recognize when a user wants to pay them with a token transfer.
01:57:38.160 - 01:58:23.134, Speaker A: And that's very helpful. And so the wallet is necessary because crafting these transactions is a bit more complicated. Second category, and that's arguably the biggest one that has the most impact is mempool segregation. So here's Alice and she wants to make a transaction. And what happened sort of in the past and even still to a large degree today, alice just sends her transaction to the public mempool and sort of gives it away for free and says, you can all have it. And anyone who follows traditional finance at least a little bit knows that Alice's order flow has a monetary value. And if she just gives it away, then she loses that value.
01:58:23.134 - 01:59:32.078, Speaker A: She just donates it to the miners, basically. But if Alice segregates the mempool basically by sending the transaction to one miner and not other miners or one group of miners and not other miners, then she can add conditions to that transfer of basically her order flow. And in this case, she can say, okay, you can have my order flow exclusively and none of the other miners, but please don't front run me and this is getting more and more common. Now, another great way to prevent mev especially from back running opportunities is by using a dex aggregator. And dex aggregator buys from all markets at the same time and thereby minimizing the price impact on all of them. So this is double useful sort of because the profitability of a sandwich attack depends on the price impact of the transaction. So the price impact is lower, it's less vulnerable to being sandwich attacked.
01:59:32.078 - 02:00:28.658, Speaker A: But also if you buy from all exchanges equally, then you don't create a backRunning opportunity, right? And that's why sort of dex aggregators are actually the unsung heroes of mev minimization. Nobody really talks about them as greatly minimizing the mev that's created by traders, but they do. And I would recommend anyone who trades more frequently to always use dex aggregator for that reason. Lately we have seen another concept come up with, I think it's called backgroundme.com and swapswap. And what they do is sort of they bundle your trades on a single exchange with sort of another transaction that backgrounds that trade and closes the arbitrage opportunity that you created. But this is not really a product because it already relies on sort of the user making a mistake by not using an aggregator, as we said on the previous slide.
02:00:28.658 - 02:01:16.070, Speaker A: But it can be a feature. There will always be retail users who won't use an aggregator who will interact directly with uniswap, for example. And for those it makes sense for uniswap who owns the user to implement this and give them a better price and not sort of bleed the money to arbitragers. Even if unisop doesn't pay the money back to the user, which I'm sure they will, but even if they didn't, then it still makes sense for them to integrate it and keep the profit for themselves. And then now we get to the sort of off chain ordering. And this is very similar to how fair sequencing would work on a layer one. So users submit transactions to an off chain oracle.
02:01:16.070 - 02:02:13.106, Speaker A: The oracle applies some fair ordering and then the trades are filled in that. So to categorize that on the peer to peer layer we have the gasless transactions. So this is enabled by flashboards and the first exchange that really supports it is Mist exchange and the mempool segregation. There you have a lot of competition, right? You have flashboards, you have Tai Chi, zero X Keeper blocksroute and Archer dao. These are all networks that the user can send their flow to exclusively and they gain some kind of benefit in return. This is very important because if there was only one network then there wouldn't be this competition between the different providers and it would lead to worse conditions for the trader. And then on the app layer, the dex aggregators, the three big ones, the back running services and off chain ordering.
02:02:13.106 - 02:03:26.446, Speaker A: And I actually have sort of chainlink and cowswap here in the same category. Because if you think about it, cowswap is also just an off chain oracle, right? They also order the transactions in a particular way, except that their condition is that all transactions, all trades in a block in the same market must have the same clearing price, but it's really no different otherwise. And finally, we can also expect some general improvements. So for example, more concentrated liquidity would lead to lower price impact and that again leads to less mev created. So straight up we could say if there was only a single exchange on Ethereum, there would be far, far less mev. So from that standpoint, it would be quite good if some of the exchanges would consolidate into one or markets would get more liquid. And then another idea, and maybe don't know if we ever see that, but sort of an AMM pool that auctions off the first look in every block and let sort of the exchange owner give them the right to arbitrage the pool and this would solve both impermanent loss and mev at the same time.
02:03:26.446 - 02:04:36.770, Speaker A: So impermanent loss and mev is really one and the same when it comes to arbitrage. And yeah, this basically gets us to the limit of what we can minimize. And we already said sort of some of the stuff we can't minimize because it's crucial for a DeFi to function, liquidations, some amount of arbitrage at least. And what we can't minimize we should try to democratize. And what democratize means is that it should be very easy for miners or stakers to find competitive transaction bundles or even entire block templates that can compete with even more advanced firms. So basically what we don't want is that extremely large financial firms from Wall Street merge with miners because this is the only way that they can extract the most mev. Like in theory we want this block production, like the block templates to be traded on an open and permissionless market that's not centrally controlled.
02:04:36.770 - 02:05:25.670, Speaker A: Yeah, and the takeaways are sort of mev. Minimization and democratization are not an either or and they are both very important. So we should try to minimize as much mev as possible. And in fact we are already seeing that, right? So we said that mev is a permissionless incentive and everyone just came to the conclusion, well, the miners are going to get everything in the long run, but it's simply not true. We have seen so many examples today of ways that we can prevent mev from going to minus. Like we can capture it on the peer to peer layer, we can capture it on the application layer and in some cases also on the protocol layer and then it doesn't get to the minus at all. Some of it will always go to miners because it's essential and others because it's very hard to prevent and that we should seek to democratize.
02:05:25.670 - 02:06:22.062, Speaker A: And yeah, because of this permissionless incentive. We see, like, huge free market competition right now in order to take back the mev that sort of miners were getting and give it back to the user and also claim it sort of or, like, claim it as a project and share it with the user. So, yeah, thanks for watching. Thank you, Hasu, for an amazing podcast and next lakshman. Please feel free to directly share screen and give the talk on is mev a problem to be solved or a reality to live with? Will you be able to share screen? If you have trouble, I can share it for you. Sorry. 1 second.
02:06:22.062 - 02:06:47.980, Speaker A: Yeah, I should have tested this earlier, but having some accessibility issues. 1 second. Cool. Do you guys see my screen? Yes. Excellent. You may want to yeah, perfect. All right, so hi, everyone.
02:06:47.980 - 02:08:08.706, Speaker A: My talk is is mev a problem to be solved or reality to be lived with? I think it's pretty clear that this is a rhetorical question. The answer is sort of both. The truth is more nuanced, as Hasu pointed out at the end of his presentation just before. In some sense, we need to be working to both democratize mev extraction and mitigate within protocol and application where it makes sense. And so really, I guess my talk is sort of a further argument that this is the case, that there is nuance here, as well as a few thoughts around how I'm thinking about how the future here will play out. Because it is also interesting to think about where will naturally mev mitigation come into play? Like what types of chains and where will democratization be inevitable? So, by way of quick introduction, I work as a researcher with the Ethereum Foundation on a bunch of different stuff. I think if I had to classify what research questions I end up involved with, it's stuff at the kind of boundaries of our protocols and where things are changing.
02:08:08.706 - 02:09:14.762, Speaker A: So things like layer twos, mev, e, two staking pools, and other things as well. And so this is kind of like, I guess, the why of the talk. I think mev is an old topic in the sense that it's been on people's radar since the early days of Ethereum, but it's newly something that everyone kind of cares about. And as a result of that, I think there's naturally been this sort of bipartisan split in talking about it. And as an American, I can kind of speak to the fact that that sometimes leads to an aversion of truth. And it feels like both of these two parties that have been propped up in these two sets of beliefs that I've sort of put up here are sort of missing the nuance, or at least some nuance will get missed if you just read what these two groups are kind of putting out as truth. And so kind of what I see the evidence that the future will be more nuanced, I think there are three things that really come to mind.
02:09:14.762 - 02:10:47.786, Speaker A: So one is, and this has been talked about elsewhere, but there's sort of a limit to scalability on a single synchronous block space. Actually, Vitalik wrote a good blog post about this that maybe I should have linked and as a result, if we're thinking about what the world looks like when all finance or some superset of finance exists on chain, we're going to have to have synchronous block spaces communicating asynchronously. So we're going to have a MultiChain world, there's going to be difference in choices in different places and there's going to be mev to be captured between domains. Additionally, it's interesting that to observe that chains that exist today that seem to be serving the same sort of market and big quotes here are making different choices. With respect to mev, I think the example a lot of people think about is optimism kind of like really championing mev options and arbitram kind of pursuing fair sequencing, fair ordering. So maybe that's evidence that seems like pretty direct evidence that we're going to have multiple choices out in the wild. And then finally I think this is an area that needs more research and more formalism and I'll suggest some thoughts on this a little later but intersynchronous block space mev is quite different from intra synchronous block space mev in terms of what is possible and how kind of big it is.
02:10:47.786 - 02:12:00.622, Speaker A: And there are a bunch of different ramifications of that that I think we'll figure out in the years to come. Two factors I kind of think about when I'm thinking about what is the future of how chains organize with respect to mev. As I mentioned earlier, I think the inter versus intra chain mev question is really interesting and sort of underexplored and then finally there's a bunch of trade offs, engineering and security wise when it comes to many of the mitigation techniques people are exploring. And so it's reasonable to think that different chains will make different choices there. This is a kind of interesting topic. First of all, interchange MEB, it's worth sort of talking about what that is. So let's say you run there's a few different regimes there's, say a couple of L, two S and maybe like side chains and you are running the proposer or validator whatever.
02:12:00.622 - 02:13:13.640, Speaker A: The thing is that has sort of a monopoly on transaction sequencing on multiple of these chains. Then you might be able to capture kind of opportunities that exist between these chains. But one thing that's very different about asynchronous block space and things across synchronous block spaces is there's always some time delay between two blocks occurring in two different systems. And as a result of that there always is some period of time where an outside party with a large amount of money can observe you putting something in a block in chain A and intervene in chain B. This is not true for intra chain mev. And I feel like this means that intra chain mev is considerably scarier, like, intra synchronous block space mev. It seems like there are much deeper things that can happen there, but it's also kind of, like, reassuring, because as I'll get to later within a single chain, it feels like many things can be mitigated if the chain chooses to do so.
02:13:13.640 - 02:14:22.560, Speaker A: And then, yeah, I think Phil's talked about this at length, but basically, between many different chains, it's inevitable that there will be kind of these mevd opportunities between different chains because there's no universal notion of fairness. As I'll also talk about later with regards to sort of like, the cryptographic and privacy oriented mitigation techniques, there are trade offs there that make me believe that not every chain will choose to adopt, say, the best technique there. Cool. Yeah. The other piece of this puzle is that all of the mitigation techniques seem to introduce trade offs that it's not obvious that every single regime will want to choose. And this is sort of evidenced by my point about optimism and arbitram earlier. But yeah, anything involving time lock encryption introduces some type of latency into the use of your system.
02:14:22.560 - 02:15:23.860, Speaker A: Anything using some kind of fair sequencing or, like, a threshold encryption thing adds some security assumption to how the chain works. And so it's just not obvious to me that there's, like, a universal best solution here, or it's even possible that there will be one. Yeah. And so if there is a conclusion of this talk, this is sort of like what what I think is true, and it's it's sort of self evident, but it's worth restating over and over until it's kind of common. Like Scott, if it's true and it's that interchange mev is inevitable. It's probably not as bad as intrachain, but it's something that we should work to, kind of, like, democratize intrachain is going to exist, but mev mitigation research will mitigate some of this. I doubt it'll mitigate all of it.
02:15:23.860 - 02:16:16.740, Speaker A: There's heterogeneous choices that we made that's that's the conclusion mitigate where we can and mocketize elsewhere, hasu made this point as well, and I will echo it. And that's all I got. Perfect. All right, so thank you for the three presenters for helping us framing the mev problem. And that concludes our part two. Let's move on to part three, where we explore protocol level response to mev. First, we start with mev minimization techniques, and we shall start with Mahimna talk on the Fair order.
02:16:16.740 - 02:17:06.670, Speaker A: Hello. Hey, Mahimna. I think Tina cut. If you can share your screen, we can go ahead with your can you see my slides? Not at the moment. Could you share your slides with me if you haven't shared them already? Let me see. Let me try to do this again. Oh, wait.
02:17:06.670 - 02:17:14.942, Speaker A: Sorry. I can see your slide now. Okay. Are we good? Yes. Okay, cool. Awesome. So hi, everyone.
02:17:14.942 - 02:18:00.522, Speaker A: I'm going. To talk a little bit about the fair ordering design space today. So just to briefly get started, I wanted to just introduce who I am because I haven't sort of interacted with this community quite a bit. So I'm a PhD student at Cornell, and the reason I'm giving this talk is I'm the lead author on the papers that developed the first protocols on fair transaction ordering. This started with Iquitos protocol, which was published at Crypto last year, and the extension in the permissionless setting which is available in Eprint. And feel free to reach out to me with email. In this talk, I'm going to be mainly focusing on a design space and understanding the nuances of fair ordering rather than focus on the specific protocols that I've designed.
02:18:00.522 - 02:18:46.138, Speaker A: So let's begin. Basically, Ethereum is decentralized as people think it is, but it's not because miners have complete control over the transaction inclusion and ordering in the blocks that they propose. This is what we call like an Ephemeral centralization for ordering. And this is sort of the Achilles heel in my opinion, that stops Ethereum from being truly decentralized, or any blockchain for that matter. So I'll talk a little bit about mev, but I'm sure everyone here has talked before me. But I will make one axiom for this talk in particular. So, almost all of the quote unquote bad mev will come from adversarial manipulation of transaction ordering.
02:18:46.138 - 02:19:51.902, Speaker A: For example, something like censorships or insertions of malicious transactions or reordering user transactions. And this is exactly what fair ordering protocols try to prevent, trying to prevent this adversarial manipulation of transaction ordering. So what exactly is fair ordering at a high level? Fair ordering tries to say if there's some property of transactions in the input ordering, then you want to guarantee some other property in the output ordering. So fair ordering, of course, tries to set definitions on how would you take the input ordering of transactions and in some fair way create an output ordering of transactions. So, just to give one example, this is one we had in our paper for Icutas protocol is if most nodes, or if all of the nodes receive a transaction m before M prime, then M is output before M prime. So sort of a first in, first out notion. So fair ordering at its core is sort of decentralization.
02:19:51.902 - 02:21:02.234, Speaker A: By democratizing ordering, you're taking into account everyone's proposals instead of a single minor or a single block proposal. And fair ordering protocols provide a quote unquote fair way to combine different proposals from these protocol nodes or miners. And I'll talk a little bit about what this fairness means in a while, but essentially, this is the diagram in, say, a permissionless setting. Instead of having one minor add on to the next block in the blockchain, you can think about choosing a random assortment of miners and somehow creating a joint proposal from which the final transaction ordering can be extracted. So it's this multilateral decision making that makes fair ordering more decentralized than just standard consensus. So why should we study fair ordering? Fairness, as fair ordering defines it is in terms of being beneficial to the ordinary users of the system and improving user experience. It's independent of application design, so it targets mainly the protocol layer but it can also be accommodated for application design.
02:21:02.234 - 02:22:18.610, Speaker A: But here's the hot take mev solutions, especially like minimization ones. I would say fair ordering is even more general than other mev minimization solutions because it targets the whole broad spectrum of attacks that can be done by reordering transactions or insertions. Any form of adversarial manipulation as opposed to privacy techniques, let's say that defend against attacks based on transaction data themselves or random ordering that can be susceptible to a flooding attacks. But the cool part is that fair ordering can be combined with these above techniques so they are orthogonal and you can use them in tandem with each other. I will make one point though, in comparison of fair ordering with other approaches like democratization as something that's done by flashbots or mev auctions in general is that selling to the highest bidder is not in the true spirit of decentralization. It's basically centralization with extra steps. And I want to illustrate this with another sort of controversial or hot take is there was this notion of mev minimization and democratization or opposing views, which is something that I also thought about for a while.
02:22:18.610 - 02:23:00.910, Speaker A: And there's been a couple of speakers today that talked on. Maybe they're not so at opposed at ODS with each other. Right. You can have mev minimization approach and a democratization approach and they can sort of work together. But here's sort of my claim is mev minimization is the true democratization, selling to the highest bidder is not the definition of democratization. The true definition of democratization is coming up with a fair notion based on the joint proposals of the miners, basically. So minimizing mev is actually the democratization.
02:23:00.910 - 02:23:57.522, Speaker A: Mev auctions are just fake democratization. With that kind of in point I would like to move to defining what I mean by fair ordering. So let's take a step back and try to look at what fairness would mean in an ideal world, a world full of sunshines and rainbows. So I'll argue that if we had trusted user clocks and a synchronous network, then the unequivocally correct ordering should be based on the transaction send time. So whenever a user sends a transaction, it's locally timestamped at that time and that's the ordering that gets put on chain in the final ordering. And of course we're assuming trusted user clocks here, synchronous network here, but this should be unequivocally the correct ordering because it leaves zero room for mev. Obviously this is a strong assumption and not at all practical in the slightest sense.
02:23:57.522 - 02:25:22.860, Speaker A: So what can we actually do? So what's a good definition for fairness that we should use in practice. So number one is that it should come as close to send ordering as possible, possibly only up to network latency in a non adversarial network. And even in an adversarial network it should be sufficiently close enough. It should also provide a good trade off between the strength of the mev minimization that the definition can provide and of course the efficiency and practicality of the protocols that can be constructed. So just to lay out all the designs on this line here you can look at the leftmost side of send ordering which prevents the most attacks but also has the strongest assumptions, the most unrealistic assumptions. In my work we proposed two definitions of receive order fairness and batch order fairness which prevent most mev and they have slightly weaker assumptions than send ordering but still not as efficient as we would like them to be but definitely provide resistance to more mev attacks. And then you can look at other end of the spectrum where you're designing for simpler assumptions or more efficient protocols which other concurrent works have also done, which Klaus will talk about in the next talk as well.
02:25:22.860 - 02:26:16.842, Speaker A: I want to talk a little bit about a bunch of nuances surrounding fair ordering that I'll get to in the next couple of slides. So the first one is permission versus permissionless mev. So permission versus permissionless fair ordering. So in permission or L2 fair ordering you could technically have some sort of subtle censorship if the nodes that are running this permissioned l Two system try to go against you. So if not done correctly then censorship could actually be a problem. Whereas permissionless fair ordering you can actually achieve true decentralization, but possibly less efficient protocols in L2. You can also be more application specific so you can interact with different definitions of fairness for different protocols and possibly be easier to incorporate into existing systems.
02:26:16.842 - 02:27:39.400, Speaker A: Bus permissionless is more fundamental but harder to change the actual designer's protocols. One more thing I'd like to point out is you should be careful with any kind of mev minimization in L2 because let's say for example roll ups or sequencing services essentially transfer the ordering power from the minor to the roll up sequencer or the fairness sequencer, right? So the sequencer, you don't want it to have the ability to arbitrarily manipulate ordering. Otherwise this will essentially move the mev from L One to L2. The other thing with L One and L2 fair ordering protocols jointly existing is that if we have only l Two protocols that are fair and the underlying consensus layer still has unfair ordering, then you could imagine this composition between the two layers posing threats to mev. But what might work out in the end is you can have stronger fairness guarantees in the Altu network and some kind of weaker guarantees in the permissionless network because they're harder to implement. And that should probably be okay. Let me end with some open research directions and invite anyone who wants to join to come collaborate on fair ordering related research.
02:27:39.400 - 02:28:50.890, Speaker A: So one thing I would like to talk about is interoperability of different blockchains or different L two L one layers, as Phil has mentioned in his blog post and also repeatedly to me is no one true definition of fairness can exist. But here's my conjecture, which I think is probably true, that kind of answers. This is the mev from composition of two good fair ordering protocols. So good in the sense as I talked previously on, the definition is probably way smaller than mev, just as a general composition of two protocols. And the idea for this is that the distance between the two fair ordering protocols is small, as both of these are close to send ordering. So if we had a system where there's different fair ordering definitions coexisting at the same time, even on an intra chain level and an intra chain level, still the mev that results of their composition can be small enough. So I would like to argue that fair ordering can be used to minimize both intrachain mev and interchange mev.
02:28:50.890 - 02:29:43.950, Speaker A: And this is of course an open research problem. The other thing I'd like to talk about a little bit is rational designs. So all the fairness protocols that we know of currently require some kind of honest majority or supermajority assumptions of the nodes or miners that they're interacting with. So the real question is can we handle all or most nodes being rational rather than just honest? So this is, I would like to highlight, currently an open problem, but it is an unrealistic expectation. For example, like proof of work and proof of stake is not completely resistant to rationality either. For example, it's like rational to mount a 51% attack on the blockchain while shorting the system externally. And even though this is technically rational, we don't see that happening in practice because people don't want to destroy the system.
02:29:43.950 - 02:30:43.086, Speaker A: And you can use similar incentives for fair ordering protocols to get enough rational resistance in practice. So I don't think this is really a caveat for fair ordering protocols either. The other cool thing is the fair ordering protocols are already resistant to non colluding honest users. So non colluding rational users. So as long as the honest users are not colluding, even if they are completely rational and want to work in their own interests, it's still fine. So for example, if there was a bunch of users that wanted to front run a bunch of miners that wanted to front run a user transaction and choose to front run a different transaction ahead of the user's one, the honest user's transaction will still get sequenced first in a fair ordering protocol. So as long as the rational miners are not colliding with each other up to some threshold, fair ordering protocols should still be resistant.
02:30:43.086 - 02:31:09.740, Speaker A: Obviously there's more research to be done here, but I would say that the lines are promising. And that's pretty much it for my talk. If you want to reach out, that's my email address there. And I would love to chat with you about Fair ordering protocols in general. Thank you. Thank you, mahinda. Next up, we have Professor Eradhu from Chain Link Lab.
02:31:09.740 - 02:32:10.346, Speaker A: And so please feel free to directly share screen. Okay, is this perfect? Are you able to see my slides? Yes. Okay, great. Let me start then. I'm going to talk today about Fair Sequencing Services system we're building at Chainlink, turning into a product. I should emphasize that I'm speaking in my industry role, in other words, as chief scientist of Chainlink Labs rather than my academic role. But you've already heard about the work that's gone in my academic gone on in my academic group from Phil and Mahimna who've talked about Flashboys 20 and Iquitos and so on and so forth.
02:32:10.346 - 02:33:01.678, Speaker A: And I'll allude to that work, but that's not the focus of this presentation. My own view of mev is that there are many different forms of mev. Some, very roughly speaking, are good, and some, very roughly speaking, are bad. For example, there are certain forms of arbitrage that one can argue on Wall Street or in blockchain systems are beneficial in a sense. They're beneficial in that they communicate valuable price information across markets, for instance, and therefore make those markets more efficient. I would contrast this with many forms of front running. Front running in general communicates essentially only the fact that users can be shafted in systems as they're designed today.
02:33:01.678 - 02:33:52.014, Speaker A: I would allege now this distinction between good and bad is an open research problem, as is the formulation of good metrics to measure whether or not a form of mev is good or bad and even the extent of mev. And there are different metrics used in different places in the economics literature. For instance, there's study of the impact of various forms of arbitrage, like latency arbitrage, on the cost of trading to investors. And I think this is a good metric. Others today have spoken about or will talk about other metrics. Mahimna talked about the metric underlying Iquitos, and P. McGuin has an interesting take on metrics for measuring whether or not we have a fair system as well.
02:33:52.014 - 02:34:46.170, Speaker A: But to be fair, this is an open prop. I would say that however we define bad mev, we probably can't eliminate it in its entirety. So what we can only hope to do is to build tools that help enact fairer policies for users. And by fairer I mean fair in the sense, for instance, that behemna discussed, or fair in terms of the fees incurred by users when they trade. And this is the goal of Fair Sequencing services. The current model of transaction ordering we've reviewed over the course of the day. Very simply, transactions enter the mem pool in an L One system in some order and a miner or a validator picks them up and decides unilaterally how they're going to be sequenced in the block that the miner mines.
02:34:46.170 - 02:35:37.490, Speaker A: Now, the miner may decide this on the basis of gas price. It may decide it on the basis of an mev auction. But the point is that this decision is being made exclusively by the miner that mines the winning authoritative block. And this is clearly a form of centralization. And its harms have been well documented in an older setting where mev was mostly extracted directly by bots in the flashboys 20 paper. New models, of course, are emerging and an important impending model is one in which transactions go not to the mem pool but instead to an L two system like a roll up. And the important thing to observe here is that the L two system now is ordering transactions unilaterally.
02:35:37.490 - 02:36:22.346, Speaker A: Now, I won't say that this is a destructive or harmful form of centralization. It could be. It depends on how these systems are designed. And for instance, Arbitrum is looking to sequence transactions in a fair way that comports with the notions of fairness that I mentioned earlier. So it's not inevitable that we see the same degree of centralization that exists in today's world with miners. The idea in fair sequencing services very simply is to decentralize the process of ordering transactions to leave it not in the hands of a single entity but instead to invest a committee with the power to order transactions. A decentralized committee.
02:36:22.346 - 02:37:54.490, Speaker A: So the committee collectively decides how transactions are ordered on chain and this decision takes place off chain. Users can send their transactions through the mempool and nodes in the committee can just observe the mempool. That's one possible design option. A better, more practical one has users sending their transactions directly to committee members and then they decide in the aggregate how those transactions get ordered. Now, natural question to ask of course the first question one would ask is where are these committee members going to come from? How are we going to compose this committee? What we've observed at Chainlink is that existing decentralized Oracle networks are already good, ready made committees with many of the trust properties that users are looking for. To begin with, these networks are already serving price feeds, for instance across a range of DeFi products and staking and various exogenous crypto economic guarantees of type that for instance, Mahim mentioned before can help provide the assurances that users are looking for in this setting. Another interesting observation is that ordering transactions is actually a very natural operation for an Oracle network.
02:37:54.490 - 02:38:29.238, Speaker A: What do Oracle networks do today? They observe off chain behavior and they collectively decide on some value to convey on chain. So for instance, a collection of nodes may observe the price of some token. They may observe it from multiple sources. They get together and they reach consensus on an authoritative price and then they relay it on chain. What's happening in Fair sequencing services. Well, Oracle nodes are observing an off chain activity namely the transmission of transactions. They're observing in particular the order in which transactions come in.
02:38:29.238 - 02:39:17.030, Speaker A: They're taking this data. They're collectively agreeing on an authoritative ordering an authoritative observation of the events that they've seen in the real world and conveying that on chain. So as I said, very natural extension of what Oracle networks are already doing today. In the first phase of our design of FSS we're going to use a notion of fairness called secure causal ordering or secure causal atomic broadcast to be a little bit more precise. This is the idea of encryption essentially. But the intuition here is that no node sees a transaction payload before the transaction is ordered. Or to put it another way transactions get ordered or sequenced before anyone observes the transaction payloads.
02:39:17.030 - 02:40:12.220, Speaker A: This idea is actually about three decades old devised by Mike Reiter I think in his thesis PhD thesis at Cornell and adapted to the public key setting by Christian Cashan and others including Klaus who'll be speaking shortly. The way this is implemented is relatively simple conceptually straightforward. Transactions are transmitted to the committee in encrypted form encrypted under public key belonging to the committee with a corresponding private key that is shared in a threshold way among committee members. The committee orders these encrypted transactions and after they've been ordered authoritatively then decrypts them. That's the idea. That's the way this notion is implemented. This works very well because it's hard to front run something that you can't see.
02:40:12.220 - 02:40:41.810, Speaker A: But it does have some limitations. And I point to two limitations in particular. One is that metadata are still visible in this setting. You know, for instance from what account a transaction originated. And that can in some circumstances leak significant information about the content of the transaction even if it's encrypted. The other problem is what I would call blind front running. Best defined perhaps by example.
02:40:41.810 - 02:41:22.302, Speaker A: Suppose there's an ICO and one of the nodes in the committee wants its transaction sequenced in this ICO first she wants to buy all of the tokens. Secure causal ordering is not going to prevent this from happening. At least not definitionally. But there's an interesting observation we can make here which is that secure causal ordering doesn't actually specify the ordering of transactions. It says that once transactions are ordered then they can be decrypted. But it doesn't specify exactly how transactions have to be ordered. Transactions can be ordered as they were received as I show here.
02:41:22.302 - 02:42:10.330, Speaker A: Or they could be ordered in some other way. And that would be consistent with the definition here. This observation leads to the refinement we're planning for the second phase of development which is the addition of Aiquatas. These are the protocols alluded to in the previous talk. This family of protocols developed by Mahinda Kelkar and some others in my group was proposed first in 2020 in a paper that's theoretical in nature, uses consensus protocols in a black box way and therefore isn't terribly efficient. But a more efficient version should come out in a month or so, maybe a little bit more than a month. So these protocols can be practical.
02:42:10.330 - 02:42:56.826, Speaker A: The intuition here is that transactions essentially are ordered according to the time that they're received by a supermajority of nodes. And how the supermajority, how large the supermajority has to be is a parameterizable feature of the protocol. Family things are a little bit more complicated than this, but this is the basic intuition. How do we compose these two? Well, this is fairly straightforward. When transactions are sent to the committee in encrypted form, the committee orders them exactly as I showed before. But now it uses Iquatos in particular to order the transactions. Once the transactions have been ordered, then they can be decrypted.
02:42:56.826 - 02:43:41.754, Speaker A: And in this way you get causal ordering in addition to the features of Iquitos. Now, Iclitos in and of itself actually prevents the attacks that I described previously, or at least mitigates them. It prevents things like metadata based attacks because it's ordering transactions according to the time that they were received. So it's potentially stronger than secure causal ordering. In the right setting it will be, but it's somewhat sensitive to network adversaries. If an adversary, for instance, in the limit controls the Internet, the adversary can decide how transactions are ordered. And there's not much you can do about that.
02:43:41.754 - 02:44:09.410, Speaker A: Iquitos isn't going to help. Secure causal ordering will actually help in that setting. Iquitos is also a little bit more complicated to implement than secure causal ordering. But the two nicely complement one another. They act as hedges for the other protocol. And this is the reason why we're interested in composing them. FSS can be used in any of a variety of settings.
02:44:09.410 - 02:44:53.250, Speaker A: It can work, for instance, as a preprocessing stage for L one functionalities specific smart contracts can be FSS enabled. And this doesn't require terribly much of a developer. It's not much more than would be required, for instance, to integrate roll ups into a contract. But of course, as we know, we're living in a world in which ordering is increasingly taking place off chain. For instance, at layer two in roll ups, flash bots and so on and so forth. It's worth pointing out that FSS can work equally well in those settings. If we're talking about a roll up, for instance, you can use FSS to sequence transactions that then go into the roll up and the composition again is fairly natural.
02:44:53.250 - 02:45:36.560, Speaker A: And this may well be the first place in which we see FSS used. That's it for my talk. If you're interested in learning more, I would direct you to the academic paper on Iquatas and those on secure causal ordering classic papers. Now, if you're interested in FSS in particular, you can read a bit about it in the chainlink 20 white paper at the URL given here. Thank you. Thank you, Ari. Next up we have Claude from Vega to present on Wendy adding order policies to the consensus level.
02:45:36.560 - 02:46:36.390, Speaker A: Klaus, please feel free to directly share screen. Now you see my screen. Now we can see your entire screen and you want to present with you see those slides now? Yes. Perfect. Thank you. So thanks for having me in here and I think this talk is now the proof that I should really sit together more with the Cornell guys because we are pretty much going in the same direction here. So I'm talking about Wendy, which is another fair ordering approach.
02:46:36.390 - 02:47:31.690, Speaker A: It came out of a slightly different use case. So in Vega we are building a derivative trading system on a dedicated chain, which is tendermint. And our main goal is we need to convince traders from a centralized exchange that decentralized is an alternative. And that especially means if any flash traders steal more money or get more money out of them than they do on a centralized exchange, they're not coming. So we need to pretty much minimize mev as much as possible. And in this use case, democratizing isn't really an option because if we democratize rewards, the traders still stay at a centralized exchange because they make money, more money there. And the problem we are having here is that the price of decentralization is that we have a much larger attack surface.
02:47:31.690 - 02:48:27.610, Speaker A: So currently if we don't put in protection then flash traders have actually an easier game on a DFI system than they have against a centralized exchange. And we have spent 30 years plus work in doing consistency, but much, much less work on what's a good order in the last time. And only now has the problem been big enough that people really care about that other thing we want to do is we want to have minimal latency impact. So we need a practical protocol and if we waste a lot of time, then we are too slow compared to a centralized exchange and again the traders will go away. There's another issue which is sort of turning around the economic arguments. So for other reasons, we want economic control over our validators. So we want to set economic encouragement for things like diversity and performance.
02:48:27.610 - 02:49:11.320, Speaker A: If they make most of their money by mev and not by validator fees that the network can control, then trying to do this is a little bit like trying to control smugglers by tax breaks. It just doesn't work because this is not where they make the money. So that's another reason why mev minimization is important for us, because we want network control on what validators get and we want them to get the fair share. So there's no doubt there. But we want to link policies to economy. Our goal is a little bit different than from what Ari described. We want to integrate the protocol into the consensus layer as a modular add on.
02:49:11.320 - 02:49:49.334, Speaker A: So we don't want to mess with the consensus code, but we also don't want to run an oracle. We want this to be part of the consensus code. A little bit like cusper is for ethereum to add finality, we want an add on that adds fairness. And our original chain is a BFT style protocols we built on tendermint. I have one slide on how this would hold for Ethereum in the end. And our goal is a tool set for kind of everyone. So we heard this argument before, there's no point in being selfish and trying to have one chain that handles front running because we all suffer if this is a real or perceived problem.
02:49:49.334 - 02:50:29.102, Speaker A: So as many solutions as possible, as many tools as possible is helpful. State of the defense. So there is a little bit of protocol archaeology there argue already mentioned causality. There also are leaderless protocols which solve a lot of the problems by just not having one validator or miner setting the whole order, but having a group already baked into the protocol. That's also the work I did back then in my PhD thesis. Honey Badger is doing that now, but they never really took off. So the BFT style got more into fashion.
02:50:29.102 - 02:51:03.294, Speaker A: So now most implementations are stuck with leaders and we need to handle. Yeah, and then we have the block order fairnesses. And what I'm talking about now is the evolution of Wendy, which is a fairness framework which also includes causality in there. And I have a couple of links to most of the papers I mentioned. So for further reading you can see that on that slide. So we already saw some fairness definitions. So I have the luxury of being able to go over this very fast.
02:51:03.294 - 02:51:53.446, Speaker A: The one thing to add here is we have a bunch of impossibility results. So the standard thing if everybody saw or if all honest validators saw A before B, then A has to come before B isn't always decidable because there's loops. So that led to block order fairness. So if you have a loop, put the whole loop into one block and let the application sort it out. But that too runs into a problem that we need potentially unlimited block size since these loops can be arbitrary size even in a synchronous system. And then we have a backup definition that is timing based based on local clocks. So it doesn't add as much fairness, but it doesn't lead to a paradox.
02:51:53.446 - 02:52:29.634, Speaker A: And our first approach in Wendy was we go for the block order fairness when we can and if we see we are now growing a too big block, we are running into trouble. We switch back to the weaker definition of fairness, resolve a deadlock and then move back to the original protocol. Once we had that, the next idea was actor was to expand this to an actual framework. But. First set up and model. So we need a known set of validators. So I wouldn't call this a permission network, but we are not registrationless.
02:52:29.634 - 02:53:16.662, Speaker A: Validators need to say here I am and they need to know of each other. We assume an existing consensus layer and we're trying to be as flexible as possible where we fit in. And we assume a multi use chain. So we assume that we have a blockchain that does different things, in our case different markets, if it's ethereum, different smart contracts. And not all transactions need fairness, and some transactions may need a different kind of fairness. So if you have different definitions of fairness, different markets, different smart contracts may actually have a different perception of what fairness they want. So we have a framework protocol that then can encompass different definitions of fairness both between different applications and switch for one application.
02:53:16.662 - 02:53:49.726, Speaker A: Like I said, for the block order, if things go wrong, we can switch the definition. First phase is a dissemination phase. That's a one round protocol that just makes sure that every potential block creator gets all the information they need to make an order. That can be timestamps. If you have trusted time, we would throw trusted time in there. For block order, everybody just throws in the order in which they source things and sends this to the potential block creators. Then we compute blocking sets.
02:53:49.726 - 02:54:34.670, Speaker A: So this is the transactions that need to be delayed because it cannot be fairly used right now. And the new thing is we also now have a reveal thing. So the nice thing, if you have an ordering protocol, if we link the ordering with the commit and reveal, we can actually reveal at an earlier point than we could for normal commit and reveal protocol. So normally I can only reveal once the order is set. So once a transaction cannot be reordered anymore. Now I can reveal as soon as I know by the fairness rules I cannot be front run anymore. And one of the problems of commit and reveal, especially in non finalizing chains, is that it can take some time until I'm allowed to reveal.
02:54:34.670 - 02:55:18.634, Speaker A: This combination makes it actually very nice that I can start revealing earlier. So the two techniques are not competing, they're actually working very nicely together. And then the more practical things, blockchain interaction and post processing, that's getting the whole thing actually to run on an actual blockchain, which is then the less exciting but very important and very tedious work. So the blocking and revealing rules, and this is where the whole fairness definition comes in. So everybody can, every market or every smart contract can have their own fairness definition through these rules. And there's essentially three and a half important rules. So a transaction is blocked.
02:55:18.634 - 02:55:58.054, Speaker A: If given what I know now, there can be a transaction that I haven't seen yet that may have been scheduled earlier. If this happens, I cannot put this transaction into the next block, it needs to wait. Then we have transaction dependencies. So given what I currently know, a transaction I know about but haven't executed yet, has to come before my transaction. I can then either put them in the same block or if one of them is blocked, both of them need to wait. And then we have revealability. Given the current knowledge I have, a transaction now has precedence over all newly generated transactions.
02:55:58.054 - 02:56:30.040, Speaker A: So this is where I can open the commit and reveal. And weekly revealable is not as strong and I haven't found a very nice definition of it. It just means now you need an insane amount of network control to still front ran me. And for all practical purposes, this is just not going to happen. Now, policies, examples fair block order was mentioned already. So if all honest parties see T one before T two, then T one must be in the same on earlier block. And then the post processing will sort this out.
02:56:30.040 - 02:57:03.150, Speaker A: And this is then the rules for when it's blocked, what the dependencies is, and I'm not reading the rules for you can look at the slide maybe later. So this implements fair block ordering by just defining those four rules. Okay, slide. I forgot policy requirements. So there's a couple of things I need to think about. If I build a policy, what I want to do has to be measurable. So we heard it also before.
02:57:03.150 - 02:57:34.860, Speaker A: If I need a trusted signed clock or if I want to have sender time, then I need a trusted signed clock. If I cannot measure sender time, I cannot put this into a policy requirement. Ideally loop free. Ideally we should be efficiently terminating so that no transaction blocks forever. And ideally, once a transaction is unblocked, it should stay unblocked and not go back. Now, as in all requirements in the Byzantine world, there's usually workarounds. So the fair block order already violates two of them.
02:57:34.860 - 02:58:07.842, Speaker A: So we have a couple of things. Measurability is sort of unavoidable. Loop freeness is solved by putting stuff in the same block and then let the application settle. Things efficient terminating can be solved by detecting if you're not terminating and then switching the policy and monotony. We can tolerate a non monotonous protocol if we don't want to do commit and reveal. If we want to do commit and reveal, then this is getting difficult. Timed fairness.
02:58:07.842 - 02:59:13.020, Speaker A: The other one I mentioned is just a different set of rules. And just to show that we can get completely different capitalistic plus Social Security, that's essentially the Ethereum model with an add on that if you wait long enough, you didn't need to pay that much. So the transactions your blockbare transaction that either paid more or is already waiting for a very long time. So we can actually be relatively creative on what examples we want as long as we can formulate them in these three properties and then the protocol will support them. Now, performance measurements. We did two implementations, one to be the real implementation, which is still being integrated since mempool integration here is a bit complicated and a simulator to see how the performance are. So in terms of latency add, which is our biggest worry, the protocol runs completely parallel to the host blockchain so it doesn't delay anything in that sense.
02:59:13.020 - 03:00:15.338, Speaker A: But some transactions are blocked and then end up in a block that would be later than they otherwise would be. In our experiments, number of this transaction depends on this ratio of block time versus message delivery time. So if I have a very fast protocol so if I use tendermint, that's sort of 10% of all transactions. If I use a slower protocol like Ethereum, you won't even notice that this is happening. Transactions that don't need fairness are passed through right away and suffer no delay. And the waiting I mentioned above is actually the dominant factor. Transactions blocking each other was in our experience pretty much negligible the assumptions we have and that's where integration gets interesting is so we assume that the blockchain does not change the order of events that we propose.
03:00:15.338 - 03:01:04.246, Speaker A: We can work against the blockchain here but having a mem pool where we can give the mempool an order or priority makes things much more efficient. If the blockchain needs ability to drop messages due to overload, we need to coordinate this. And if we have another ordering mechanism, that's of course a conflict. So since most people here care mostly about Ethereum and this is where the whole mev problem was biggest. So we can implement or use Wendy with Ethereum. So it would be an add on like cusper also having its own sort of validator set like cusper that know of each other and can run a protocol where everybody needs to talk to each other efficiently. So the good things you can make commit and reveal much more efficient.
03:01:04.246 - 03:02:00.160, Speaker A: As we solve the non findability issue, every smart contract can choose their own fairness definition and just use it and there's a lower performance impact. What we need is to or what we would need is a defined set of fairness validators. We need a hook into block and transaction validity verification so Wendy can say this transactions is now invalid. And the biggest issue, but there's certainly solutions to this that can be discussed is we need a mechanism to resolve a conflict between the native ordering mechanism which is gas fees and the Wendy policy. So we want to avoid a setting where I have a transaction that by Wendy fairness rule need to be executed next. But it didn't pay any gas so everybody else is blocked by a transaction that just refused to pay gas and needs to pay for them or find something else. And with this I'm at my end.
03:02:00.160 - 03:03:03.090, Speaker A: So I guess we don't have time for questions anymore, right? Yes, unfortunately. However, I think we should continue the discussion offline and we'll continue to collect these questions. Next up, we have our guest, PMC Guhan. I'm sorry for butchering your name, but feel free to directly share screen. Can you unmute yourself? Okay. Can you hear me now? Yes. Great.
03:03:03.090 - 03:03:34.094, Speaker A: Can you see my presentation at all? We cannot see it. Right, hang on. Let's see. I spent ages preparing this and obviously it didn't work. I logged in ages ago, but I still failed. So where do I go if I just go back into it? That's probably not a good idea, is so if I just share screen hang on, you can share the screen for me? Okay. Yes.
03:03:34.094 - 03:03:42.334, Speaker A: I can do it for you. Easier for you. Yeah, do that, Tina. Brilliant. And then I can just maximize it here, can't I? Yeah. Brilliant. Yes.
03:03:42.334 - 03:04:10.650, Speaker A: Can you just give me a second? Let me set it up. Sorry, I haven't used Google meet before. You can introduce yourself a bit while I open up the sure. Okay, brilliant. Well, I'm so excited to be on, guys. Thank you very much to the organizers for thinking of me and for organizing such a great event with such kind of diversity of views. It's such an important topic.
03:04:10.650 - 03:04:41.854, Speaker A: So, yeah, I was very chuffed with Charlie for having very sweetly put me at the beginning of the mev timeline there in 2014. I'd really like to be at the end of the mev timeline in 2022. Let's be optimistic. So that's where I'd like to go with this talk. Are you any closer to sharing there, Tina? I believe I'm currently sharing. Can everyone see screen? Yeah. You'll see my slide? Brilliant.
03:04:41.854 - 03:05:07.318, Speaker A: OK, fantastic. I'll crack on then. So I'm going to start with a very quick definition of mev. Mev is a profit to be made by Reordering and Censoring transactions. So I'm sort of using this original definition, as I call it. I'm not including block rewards or gas fees or just any way that miners make money. I'm also not including latency arbitrage and actually probably includes cross chain latency arbitrage.
03:05:07.318 - 03:05:34.638, Speaker A: And I'll come back to that. Reordering and Censoring transactions is data corruption. Transactions are data, so reordering them is data corruption. And you might be thinking, well, what do you mean by that? Because transactions seem fine to me. They're atomic and they're digitally signed and they're validated by thousands of nodes. Well, the reason is that data order is as important as data content. So I'm going to give you an example of a picture file.
03:05:34.638 - 03:06:08.990, Speaker A: There's a beautiful picture file. So what would that look like if I took every pixel in the file and I reordered them? So I'm keeping the same content, but I'm reordering it, so it might look something like that. So I think we'd all agree that's a pretty corrupt looking file. So the bad news is that this is actually on the left here. Each one of these pixels represents a transaction in the Ethereum network. So on the left, they're ordered by arrival time. I've taken this data from infura, and on the right, they're ordered by inclusion time.
03:06:08.990 - 03:07:01.114, Speaker A: So that's the time that those transactions are actually included on the Ethereum blockchain. So what you're looking at on the right is the data corruption created by mev extraction, gas price auctions and mev auctions colluding to create this data corruption in the network. So that's real data corruption from the last few days. So what we're doing here is we're selling the right to corrupt transaction data in this way. So I guess what I'm getting at is you can't be surprised if you sell the right to corrupt transaction data, that your data ends up being corrupt and you get these mev effects. It's kind of literally what we're doing. So what I'm trying to make the point here is that mev is equivalent, which actually is I defined it as reordering and censoring transactions.
03:07:01.114 - 03:07:20.134, Speaker A: And that that is equivalent to data corruption because we can see what happens when we do that. So I've done a sort of triangle here, just because it's pretty. But actually, honestly, this is the best way of thinking about it. They're just directly equivalent. And this is why it's only preventable in the base layer. That's why I'm interested in the base layer. Only a base layer fix is going to work.
03:07:20.134 - 03:07:47.680, Speaker A: I mean, obviously, every l two above it needs to be doing it as well. But the base layer needs to do it, too. So in terms of sort of a statistical analysis rather than my not so pretty pictures, the average inclusion time for a transaction going through the mempool seems to be around two minutes, 30 seconds. On average. That's twelve blocks. It's pretty high. Right? The standard deviation of inclusion time is 20 minutes.
03:07:47.680 - 03:08:12.322, Speaker A: Right. That is some serious variance. So time order is corrupt in Ethereum. Now, that means latency arbitrage is not possible because latency is a measure of time. And this is what our time axis looks like. Looks like this. So we can't talk in a meaningful way about latency arbitrage and good forms of arbitrage, and even in some senses, cross chain arbitrage.
03:08:12.322 - 03:08:34.670, Speaker A: In those terms, it's all bad. So what we need is some transactional order integrity. Now, Mahema has touched on this. What do we mean by fair? So this concerns some people. Well, by what measure? Fair for who? And who gets to decide? But it's very simple. It's send time order. That's our ideal.
03:08:34.670 - 03:08:56.070, Speaker A: If Alice sent her transaction before Bob's, this should be included first. If Bob sent his transaction before Alice, then his should be included first. So I'm not saying this is easy. I mean, I'm really not. But I am saying it's objectively fair. All right? This is really important. And the reason it's objectively fair is it models reality.
03:08:56.070 - 03:09:28.640, Speaker A: And this is what any transaction processing system actually needs to do it's trying to audit and log and record reality. And this is reality. They either did or they didn't send their transactions before each other. Now, remember, mev is a profit to be made by reordering and censoring transactions. If you get sentime order, you don't have mev anymore. It's gone. So now we've got a measure of order integrity, and we can measure it very simply and define it simply as minimal divergence from time.
03:09:28.640 - 03:10:03.110, Speaker A: But there's actually an equally important measure, I would say, which is symmetrical divergence from some time. So Asymmetry would, for example, be Citadel, always having zero milliseconds latency access to the markets. And Wall Street Bets traders always having 300 milliseconds plus, I think, 300 low. So that's an obvious asymmetry. So what I'm showing here is we've got the kind of worst to best on TPS, essentially. So, Ethereum, where we are now, I've got to say, sorry to say, but we're at the bottom of the heat. We've got high Asymmetrical send time error.
03:10:03.110 - 03:10:41.378, Speaker A: Transaction order is very corrupt, wealthiest, best, resource benefit Nasdaq, I've just sort of dealt with. We've got these Asymmetries, but the actual transaction order is broadly okay, but the Asymmetries are nasty. What we're going to do is we're just going to leapfrog Nasdaq all the way over here, and we're just going to end up here, over here at the best, right, Ethereum. Soon we're going to have a low symmetrical send time error, where transaction order approximates send time. All participants are treated equally. Now, the point I want to make about this is centralized exchanges can't do this because they're centralized. They can only do arrival time we're distributed.
03:10:41.378 - 03:11:22.654, Speaker A: So we can aggregate arrival times and get something that approximates Suntime orders is a massive advantage. So our current sort of woes come from us being decentralized in one sense, but it's going to be our superpower. So that sounds good. How do we get there? So I'm proposing a class of solutions with many potential implementations, but three broad characteristics. So first thing, we need to do decentralized content creation. So we've touched on this before, but why are we letting miners order transactions if it causes all these problems? It's because we can't stop them because content is centralized. So we've got this decentralized application layer of many computers.
03:11:22.654 - 03:11:58.106, Speaker A: We got this decentralized blockchain structure, but the miners just like, hidden in there at the very crucial moment when a block's created, one single computer has total tyrannical control over what transactions go into it. So the solution should be no surprise to anybody at this conference. It's the way Satoshi solved double spending. It's how we'll solve mev. We decentralize. Many nodes will decide the content of one block. So the next big problem we've got is the structure of the mempool, by which I really mean that there is no structure to the mempool.
03:11:58.106 - 03:12:27.458, Speaker A: It's an unstructured mess. It's essentially a graveyard for send time order. We've got hundreds and thousands of transactions sloshing around. Probably about 150,000 right now, I'd guess. Now this increased choice of transactions leads directly to increased mev opportunities, all right? Because you've got more transactions for a minor that your tyranical miner to exploit. Massive range. So what we could do is we could chunk up the mempool at low latency.
03:12:27.458 - 03:12:52.990, Speaker A: So I'm talking about maybe one to every 3 seconds. And we can do this quickly because there's no need to execute these transactions. We're doing basic validation on them. We're not updating state and broadcasting blocks to everybody and attesting them. So the idea is that if you're doing it in three second chunks, you will have about 70 transactions to exploit per chunk. 70, not 100,000. So less mev.
03:12:52.990 - 03:13:15.110, Speaker A: The other thing about this, so this is what I'm sort of building here is the most basic version of a content layer. It's called plain alex. And it does very, very little. It just does what I've talked about there. It doesn't try fair ordering or anything like that other than the innate amount that comes from chunking up the mempool. So for this to work, it's got to be non optional. All right? So this is why it's a base layer solution.
03:13:15.110 - 03:13:42.974, Speaker A: So the content layer creates chunks. The validators must write these chunks in order. If they don't, they will fail attestation. And the idea of this is that corrupting transaction order will require the same resources you basically have to mount a 51% attack. Rather than just being the miner and choosing them, you need to escalate all the way up to that level. That's what we're trying to do. So let's look at the advantages of doing that.
03:13:42.974 - 03:14:11.930, Speaker A: I've done some research. This is based on real data. So by mev type, as far as I could tell with the flashbots bundles, I've done some analysis. We're getting about 43% of what is uncontroversially exploitative. I would say to my mind, it always up here. Can you look at the zoom screen? Because I'm scrolling for you, but I'm not exactly sure which oh, you're scrolling for me? Sorry. Oh no, I didn't realize.
03:14:11.930 - 03:14:54.390, Speaker A: I thought I was doing all the scrolling. Yeah. So you want to be on the pie chart. Sorry. Okay, so that's right, we're on the pie chart here. So what we've got is 43% of the most exploitative mev sandwich attacks and backruns make up 43% of the mev that we're getting through flashbots bundles. So what I'm talking about doing, if you chunk up content chunks at 12 seconds, right, every 12 seconds, and this is based on real data, you could get a potential reduction of 40%.
03:14:54.390 - 03:15:21.926, Speaker A: Well, actually, sorry, the reduction you would have got in that data set was 40%. And that is just by reducing the number of transactions that there are available to attack with. So I'm not trying to do it every 12 seconds. I'm trying to do it every one to 3 seconds. So the mev reduction could be greater than 40% potentially. There we go. So I'll go on to the next advantages.
03:15:21.926 - 03:15:57.686, Speaker A: Tina, next slide. Thank you. So I'm not sure how long I've got actually. Have I got long enough to go through these? I will quickly, very quickly. So other advantages we've done the 40% reduction, lower user costs overall when you count mev extracted and big costs, better data integrity, some user experience improvements, remaining mev is more democratized, which I know some people are a fan of. So you've only got 70 transactions to mine, not 100,000. So you don't need a massive mining rig, bandwidth reduction potentially because you've got fewer transaction messages once they're chunked.
03:15:57.686 - 03:16:34.790, Speaker A: So there's ways you can do that. I'm not going to go into the last one, but it's quite good roadmap. So how could you possibly do this getting from reducing mev to solving mev. So I'll put some dates in for fun. That plane annex that I've just described is really pretty simple as far as these things go. I would suggest relatively quick to implement relatively you get that immediate significant mev reduction, but the fun really starts when you start doing other things with the content there. So in Dark Alex for example, you could have users encrypting transactions, sending them to the mempool.
03:16:34.790 - 03:17:40.502, Speaker A: If you can get this running at a frequency of every 3 seconds, say, then you can use time lock encryption timed at 5 seconds, for example, you don't get any block delays, you encrypt your transactions, order them and then decrypt them within maybe several times within the space of one block. So you're not slowing down the structural there. You don't have to use timelock, you could use threshold encryption. I quite like the idea of a reputation market for key split holders and then you kind of solved mev at that point. I would go further after that and go on to the fair ordering because I want to get to send time and be the best that I talked about earlier. So when you do that, you could have pickers that I've described in the diagram earlier of the content layer that choose these transactions actually seem to map quite closely to equitas replicas. What I like about encrypting beforehand is that in that instance you have protected yourself against collusion because bad actors are minimally incentivized to order encrypted transactions fairly.
03:17:40.502 - 03:18:26.714, Speaker A: All right, even bad actors, good actors are going to do it fairly anyway. Bad actors are minimally incentivized because the easiest thing to do, the least work, the least overhead is just to pop a transaction on a list in arrival time. It's the cheapest thing to do CPU wise and there's no advantage to doing anything else. So I would say though you could go straight from plain Alex to fair Alex, you don't have to do Dark Alex. I just wanted to get the ideas down so at that point, I'm going to boldly claim that Mev has solved you have objectively, fair, distributed systems for all. Best transaction system on the planet. The thing we always wanted for Ethereum, the thing I wanted for Ethereum when I first noticed this issue in 2014, I've written Yay there to remind me to say, yay, we've done.
03:18:26.714 - 03:19:08.040, Speaker A: It perhaps worth looking at. Anyway, on that note, thank you for your presentation and we should move on to the next speaker, Rick Dudley. Thanks, guys. Thank you, Rick. Please feel free to directly share screen hi, folks. Can you hear me okay? Yep. All right, great.
03:19:08.040 - 03:19:34.416, Speaker A: So not going to really describe myself at all, but this is not my domain of expertise. Mev. I mean, it's interesting. Me and Phil talked about it many years ago now, which is sad because we're all aging and dying, but mean, this is not really my area of expertise. A lot of the talks here have been really good, really interesting. So I don't want to pretend to be I'm an expert. All right.
03:19:34.416 - 03:19:58.090, Speaker A: I'm already accidentally clicking things. All right, great. So transaction level hinting is considered helpful. Yeah, it'll be a while before I actually get to what that actually means. So take some time, relax. We're going to go down memory lane a little bit here. Ethereum has an identity problem, and it's sort of come up in some of these discussions, and I'm glad I made a slide about it.
03:19:58.090 - 03:21:00.604, Speaker A: A lot of people in this space make their living and make quite a good living because Ethereum is a casino. And then there are some of us who are foolish and believe that maybe we should be making a system for verifiable cryptographic attestations of simple and safe computations. Which doesn't sound much like a casino, right? I mean, it sounds like they're kind of opposites, but that is kind of like a lot of the people in the space is one or the other. And then of course, there's people who think it's alien communication or whatever, right? Really? Why isn't it both? I mean, we can do both, so we probably should do both given where we are in the space. And so here's the thing about Mev. If you think Ethereum is like the house of a casino, like, it's like operating a set of casino games for people to gamble, then you may think that exploiting mev is breaking the rules. Like, you're the house and you're supposed to be fair, and you're not really being fair.
03:21:00.604 - 03:22:17.108, Speaker A: You're letting some people cheat, and that's not cool. But if you think Ethereum should be safe, then you must also want it to be predictable. And what I mean by predictable is just very briefly, a secure in my definition means that other people can't tamper with it. Safe means that it does what you expect it to do and that it has predictable behavior. And so the problem that we really have well, mev is contentious because it forces us to recognize that Ethereum has problems on both of these axes, right? So what we're going to get into here is some of these broken Zany models, with all due respect to Gavin Wood and the other people who were instrumental in the development of the system and the time crunch and the economic crunch and what have you, that being said, let's still go through some of the weirdness of the model. Right? So one of the weirdest things hit that button again. One of the weirdest things about Ethereum is that by default, which is very unsafe and very unusual in any sort of computer system and with all of the respected computer scientists that have spoken before me, I'm a little confused as to why people don't bring this up more often.
03:22:17.108 - 03:22:50.304, Speaker A: But we have transaction contention as the default. So in pretty much any toy system where you have multiple users, they can't just muck around with each other's state information. They can't just muck around with each other's memory. Windows 31 didn't have this problem. Right? Well, whatever. So then we have this other thing that's related to this, which is just broadly speaking, Ethereum is a state machine, right? We use this term all the time. We talk about it all the time.
03:22:50.304 - 03:23:53.060, Speaker A: When we talk about Ethereum as a world computer, what we're talking about is we're talking about globally shared state. And that is actually where Mev in my opinion, there's a lot of different types of mev. Obviously, people have given a lot of different definitions. But ultimately the thing that we're trying to minimize are the problems that are created by users being able to muck around with each other's state when they shouldn't or when they don't expect to. So maybe they're actually playing a game where part of the game is who can flip this bit first. But then there's times where there's other games that people are playing and they don't realize that another player can come in and flip the bit out from underneath them. And so there are a lot of problems in Ethereum come from the way that we handle this merklized data structure, which is kind of what I struggle with and wrestle with as a large part of my day job, is dealing with these stated difficulties and these will actually come into play later.
03:23:53.060 - 03:24:21.848, Speaker A: So keep them in mind because anytime that you're trying to verify a block or generate a new block, you're going to run into all of these stated difficulties. So it's very difficult to read the data out of the Merkel tree. That's going to be very difficult. It's also very difficult to write data for similar reasons. It's impossible to prefetch because all of your keys are random, right? So there's no way that you can cache data at all. Totally random. Extremely frustrating.
03:24:21.848 - 03:25:13.180, Speaker A: Your caching is like, okay, just throw like 120 gigs of data into Ram. That's not really awesome. The caching that does exist in the existing clients is almost entirely focused on consensus, not on proof generation or general retrieval. And so again, if we're using Ethereum, we're using it because of proof, right? We're using it because consensus provides us a type of proof. So if we're not leveraging that proof generation, then why are we even using Ethereum in the first place? Why don't we just use a centralized database, as people love to say? And I think that's a totally valid concern. And the other thing that's pretty obvious is we can't scale storage forever, right? So we have all this state, we have all these weird things that are going on in state that are these weird side effects. And at some point we're going to run out of disk space.
03:25:13.180 - 03:26:03.036, Speaker A: We have to have a way of truncating the chain. And so when we talk about state rent and whatever it's called now and regenesis and there's a whole bunch of things in the Ethereum research community around how do we prune state. And this is going to be very relevant to the activity of block building and block production. Right now we have a reality where if you use Ethereum, you can't get the summary. If you're using uniswap info, you're relying on the graph to provide you the summary of the Ethereum state that you use to transact with. So, like, if you're making investment decisions based on uniswap info, you're actually trusting the graph to tell you what the state of Ethereum is. And there's no way for you to verify that.
03:26:03.036 - 03:26:43.092, Speaker A: And ideally, that graph entity, the graph indexer or what have you, would be an entity within the Ethereum consensus model. There are people that you could slash within Ethereum natively. It would be a native part of the protocol. And right now there's really no way to do that. So if you want to keep it running, you have to address some of these broken models. Right? So the stated difficulties, the issues with Ethereum state, I think absolutely are super high priority. That's actually why I started working on 1559, which is a weird historic aside.
03:26:43.092 - 03:27:11.156, Speaker A: But we have to start addressing these state issues anyway, and we have to address these mev issues anyway, so we're going to address them together. So these are a list of EIPS that are starting to get at the mechanisms that I'm describing. So the first one, most important one transaction envelopes. We can make new transaction types. This is insanely important. This is like a superpower for Ethereum. I'll just put a little plug here.
03:27:11.156 - 03:27:49.816, Speaker A: Cosmos SDKs obviously supported this for a very long time, but to have transaction types in Ethereum is a significant improvement. Obviously, no new transaction types, no 1550, 915, 59 will have a huge impact on the mem pool, which no one else has brought up yet. And that will in turn have a huge impact on mev as an aside for anyone who may happen to know and can send me a message somewhere. I don't know how we actually have multiple. We're putting each new feature in a new transaction and I don't know how we unify those so that we have one transaction type. I don't know if anyone's actually described that yet. Optional access lists.
03:27:49.816 - 03:28:50.560, Speaker A: So this is a list of addresses and storage keys that the transaction plans to accesses outside the list are possible but become more expensive. So this is basically a way of hinting the block builder, which is currently the block producer, and giving them some clue about what the memory access pattern needs to be when they see the transaction in the mempool. So they can start preloading some information before they actually have to go build the block. Again, this is because there's some runtime brutality in the ethereum system that's unavoidable, right? So because of how state works, we have to start giving these hints because we're not going to be able to build blocks otherwise, period. And then a block access list just takes those access lists of the transactions and puts them all into the block and makes a little field for them in the block. And then hashes that just like you have transactions and then the transaction hash or you have receipts, and the receipts hash. And again, this is for the purposes of facilitating Statelessness.
03:28:50.560 - 03:29:33.696, Speaker A: So this is absolutely there's a similarity here. There's a relationship between statelessness and the reduction of mev. And so my suggestion here is know, because Tina sort of again, this isn't really my area of expertise and Tina asked me to give a talk and I'm happy to give. So I kind of just threw this thing together just sort of based on some conversations I've been having with people, frankly, over the years. And so my basic suggestion is a new transaction type which adds two predicates, very simple predicates. Only apply this transaction against these merkel leaves. So you reference the ethereum state as merkel leaves that you want this transaction applied against.
03:29:33.696 - 03:30:20.130, Speaker A: That's the first one. And the second one is only include the transaction if this set of merkel leaves has these values. I'm sorry, there's some lines missing at the end of the block, right? So basically, if this transaction results in me having a bunch of money at the end, run it. If it doesn't, don't run it. These are very simple. This is very much like this is not a steal a man argument, right? This is just to sort of get our foot in the door and sort of start to understand the power of some of these concepts. These are pretty tricky predicates to use, but they're sort of like a generalized solution to slippage in uniswap, right? It's like, well, can we actually get all transactions to just sort of have that property? And this is a way that we can do that.
03:30:20.130 - 03:31:05.230, Speaker A: These are pretty easy to implement, but they're pretty difficult to use. We could make more complex comparators, sort of more traditional ones that actually somehow inspect the value and know the value. That's theoretically possible with something like a homomorphic encryption or some sort of weird mercury to homomorphic hashing where you can assert that a greater value has a greater hash or some zany thing. But that's way out of my field of expertise. I'm sure it's theoretically possible, but I have no idea how you would start to do that. And we're already mucking around a lot with Merkalization that's also another one of my hats is messing around with mercury on the Cosmos SDK side. I think that there's a lot of opportunities there.
03:31:05.230 - 03:31:53.550, Speaker A: So we probably could do this. So the benefits of this system is now block producers, builders and other transactors know which transactions will be contentious without needing to execute them. If you trust the statement in there. But you can even do a light verification with ETH call that will verify the hint that was provided with the transaction. And that's very powerful, right? Because you may know, because you can't just look at the to and the from of a transaction and know if it's going to mutate the state that you care about. That's the important piece that's sort of missing from this slide. You need these hints because of the way that internal transactions, quote unquote work.
03:31:53.550 - 03:32:54.370, Speaker A: And ultimately the goal of these types of additions to ethereum is to just remove, get us out of a contentious first mentality. And I could go on and rant about this forever. When we were working on super early ETH two, like super early me, Vlad Vitalik and Greg Meredith, and occasionally guest stars would show up. But we were always talking about removing having asynchronous transactions on the chain, right? It's this synchronicity that's a problem which has also been talked about during this conference as well as the shared memory. And the two of them together is just like a lethal combination. And so we can work towards removing those things by adding new transaction types over time that move us closer. Iteratively move us closer to the correct solution and do so in a relatively quick pace without necessarily having to make l two changes or things of this sort.
03:32:54.370 - 03:34:07.684, Speaker A: And so I've kind of already hinted at this. So Phil mentioned this blog post or this thread in his talk. It's from Vitalik. He's basically explaining how we can separate block proposers from block builders. The highlighted part is sort of the important thing. The idea is that we have an outside market of actors that we call block builders produce bundles, which is basically like an mev bundler consisting of complete block contents and a fee for the proposer, right? So we're basically saying, well, let's generalize how Flashbots works today. And what I'm suggesting is let's actually offload some of that computation in the block building to the users themselves, ultimately with the goal of, well, if this new transaction type is used, block builders should charge less for these transactions to be included, which is an interesting aside, right? Because the users are doing computation on behalf of the block builder, somehow, they should get a rebate for that, and that's a significant discount to the actual block producer.
03:34:07.684 - 03:34:54.600, Speaker A: So they should get a rebate for that as well. Okay, I will wrap it up in two minutes. All right. The perfect block creation has these properties pipeline, data access, constant time construction, and verification in relation to bytes included. This is important because it actually provides it solves some pricing problems that we have that are theoretical, that I won't have time to get into. And then the goal is that we want to achieve, like, Bitcoin level mev, right? Like Bitcoin has mev, but no one really talks about it because it's an application specific chain. So we should be able to achieve that by actually reducing the amount of state computation that block producers need to do.
03:34:54.600 - 03:35:59.596, Speaker A: Also, like many Ethereum killers, separate transaction ordering from execution, and they do that for scaling purposes, but we're doing it for a similar reason, and we'll also achieve a scaling benefit as well. Also worth noting, there's some new clients on Ethereum that by again, sort of addressing how mercurialization is done, they can greatly expand the amount of gas that can fit into a block. And so it's all related, right? All these things have some intersection, have some relation. All right, so next steps, someone write an EIP, someone implement it. That's easier said than done. It should be really easy to get this on the main net because it's a new transaction type, it doesn't have to really interfere with things. Some of the features we may want to add to the system is we may want to modify ETH call to generate the hints that we need, and we may want to build services that make it easier to extract state from the existing chain, which is something that I'm already working on.
03:35:59.596 - 03:36:18.370, Speaker A: And there's a link provided in the slide, and that's it. I'd like to give thanks to the pirate ship tina phil. Edgar. Lev et. And over the years, I've talked about this idea to a lot of different people, and I can't really name them all and thank them all. But thanks those people for listening to me as well. And thank you.
03:36:18.370 - 03:37:27.546, Speaker A: Thank you, Rick. And thanks for the shout out at the end. Well, this concludes our previous session on MEB minimization technique, the fair ordering part. And next, we'll move on to the domain of privacy solutions as part of the Mev minimization technique. And Makira from Hashclook, please feel free to start sharing screen and give your talk on the survey of privacy solutions to Mev Mitigations. Okay, hello everyone. I'm Akira, and today I'll be going over a few solutions that are mainly like privacy focused or cryptography focused for minimizing mev.
03:37:27.546 - 03:38:14.670, Speaker A: This is a current work in progress that we're doing as part of a flashbots grant. So if you have any feedback, any questions, you can always just reach out to us. And also, this kicks off the whole privacy part of the talk today, so we also have a panel afterwards, so you can ask your questions during that time as well. So I guess a quick recap of what was discussed over the day over the other talks. So mev is a very multifaceted problem, manifests itself in different ways, and as such, we have different ways to solve it. And keeping that in mind, we know that not all MAV is bad. In fact, some of it is just going to be as part of building financial applications.
03:38:14.670 - 03:39:14.370, Speaker A: And the goal of this talk is mainly to discuss how to use cryptography in order to solve mev. And we'll look at ways in which people can try to use these solutions today in their applications or whether or not make sense. Just have this as like a layer one solution, and then later on in the panel, we'll dive more into that aspect as well. In addition, we'll briefly go over some directions that we're pursuing as part of this research as well. That's way more experimental. I'm not sure if we'll have time for that. So in the context of mev, what exactly do we mean by privacy? So there's a few considerations that you might want to think about when thinking about privacy in this context.
03:39:14.370 - 03:40:35.450, Speaker A: So this is a concept of pretrade privacy, which is, if you're sorry, which is the context of trade. So you send a trade to be spent. Um, but oh, no precinct. Okay, so fill trade privacy is if you're sending a bid and it's a losing bid, then you don't want the mempool to see that. The concept of pre trade privacy, which is slightly subtle, is that you don't want a filled transaction to be seen in the mempool. So the subtle between these two, the differences between these two are very subtle, which is why I kind of pose up there. And then the concept of complete privacy, which is the most desirable one, which is probably what most people think is when everything is hidden from the mempool until it's time to execute the transaction.
03:40:35.450 - 03:41:45.860, Speaker A: And the focus of today's talk is effectively on complete privacy solutions. I guess a very short overview of the design space for just solving mev. In general, there is the side of using more like math and economics for solving this problem. And I think later on in the talk and earlier in the day, people discussed those kinds of solutions and then today we'll be focused mainly on the cryptography side of things. So there's quite a few different solutions that people have come up with over the past years to solve front running and mev and ethereum we'll briefly go over each solution and I guess as part of this being an ongoing work, if you have any more suggestions or ways to combine these, just reach out. So first we'll go into Commitments. Cryptographic commitments are a really easy tool to use for trying to solve firm running for your application.
03:41:45.860 - 03:42:52.434, Speaker A: So briefly you can commit to a message and then later on you reveal it whenever you want. And so in a specific context what you do is you would commit to a transaction and then once it's added to a block, you can reveal the transaction later and then have it execute. The main issue with doing this is that you need an extra block delay because now you need to execute your transaction which is not the best in terms of user experience for the users of the application implementing this. But a good side of using this is that there's typically libraries that allow you to just do this as a drop in replacement. However, due to this one block delay it's really deployed in practice. So from Commitments you can use ZKPs and I guess most people here are familiar with ZKPs. Very briefly, it allows you to prove statements without revealing important details about that statement.
03:42:52.434 - 03:44:16.242, Speaker A: So in this case you might want to prove something about a transaction such that the gas price is within a specific range and that it's a valid transaction but you don't want to reveal the transaction on chain because we're trying to make it such that people can't arbitrage some kinds of transactions. And the nice thing about ZKPs is that they're quite flexible so you can sort of aggregate many transactions together and prove them in Azkp. And typically we've seen this applied at both the protocol layers in layer one blockchains and at application layers in the forms of different L two S. And they tend to not have as significant of a delay as the commitments that we just looked at. And there's also a lot of tools for using CKPS as well. So the next one is timelock encryption which is also just an application of using commitment schemes. So in the vanilla commitment schemes what you do is you commit to a message and then you refill it whenever you want.
03:44:16.242 - 03:45:52.610, Speaker A: But with time lock encryption there's like a set date by which you have to reveal the message or a set time specifically. And using timelock encryption you can build these time capsules in such a way that you needed to solve a puzzle and the puzzle will reveal the commitments and this allows you to effectively prevent front running in your application. And this hasn't seen widespread deployments but it does work at both like layer one and at the protocol layers and it has like the similar issues as commitments in terms of the delay provides to users. And the tooling for this isn't as ready compared to like CKPS. Then there's Threshold Decryption which I think was brought up earlier today in a separate talk. So in Threshold Decryption you have quorums of Miners or validators that each have a share of a private key for decrypting messages that users encrypt. And depending on whether you're an approval worker proof stake system, there is sort of delays on when you can decrypt these transactions.
03:45:52.610 - 03:47:11.222, Speaker A: Most schemes I've seen usually have at least a one block delay on executing the transaction because you have to decrypt the transaction. And as such, usually this is done at l One. But as you'll see later, there's an attempt at doing this at the application layer so that it's a drop in replacement or drop in addition to your DAP while you're building. So then there is SGX, which is also another way that's been proposed to solve mev. And SGX is technology by intel in which you can store data in these secure enclaves and the data can't leave these enclaves. So all the computation and accessing the data has to be done within these enclaves and it's isolated from the rest of the OS. So pretty much what you need to do is find a way to sort of split up the encryption key for accessing the enclaves and that's how you would do your computation.
03:47:11.222 - 03:48:45.558, Speaker A: So practically how this is used for solving mev is that you can verify all sorts of complex statements like the ability of transactions and blocks and stuff like that. So what do you do is you would split up this primary key that we use to sign messages to the enclave and then the SGX can ascertain the validity of the transactions. And then depending on whether you're in a proof of work or proof of stake system, you either get the unencrypted transaction data or a proof that your transactions are valid, and then you can use that as part of consensus. And depending on how it's instantiated, you might get just as good as latency as the current flashpots setup. One of the downsides though is that you do need to rely on intel for being an honest manufacturer, although there are some attempts at making some open source versions of this kind of tech. And lastly there's MPC which is you can kind of consider as a software only version of SGX which allows you to compute arbitrary functions without knowing the inputs. In a sense, Threshold Decryption is an instance of MPC and more famously I guess MPC is known for being inefficient but depending on the constraints of the system it might not be as inefficient as one might think.
03:48:45.558 - 03:49:57.630, Speaker A: However, it does introduce more trust assumptions on node behavior that might not be desirable depending on your use case. So I guess we're nearing the end of the talk. Some current work that we're looking into in addition to those other solutions is the use of Malleable cryptography. So very briefly, Malleable cryptography lets you do transformations on encrypted data. So the idea here would be to use something like some homomorphic encryption that will allow you to morph encrypted transaction so that you can probably still do some execution on it if it's possible within an efficient amount of time. And then the other primitive we've been looking at is called order revealing encryption, which mainly has been applied in the database search domain for providing searching functions over encrypted databases. And we think this might be a promising way for providing similar functionality for encrypted transactions.
03:49:57.630 - 03:50:39.610, Speaker A: It does kind of reduce so far from our work, it does kind of reduce to the threshold decryption case. So we're not sure if it's particularly useful. But we do have a write up that I can share more widely if you're interested. And something else that we're working on is we're trying to look at using NPC for providing complete privacy and Flashpots. So in the same way that Mev SGX provides complete privacy using SGX and Flashpots, we're looking at using some off the shelf MPC frameworks towards that goal as well. So I guess that's the end of the talk. And so it's time for the panel.
03:50:39.610 - 03:51:51.330, Speaker A: Thank you, Mikhail, for giving a great and thorough survey. Next up, we have the panel that you are hosting, privacy all the way down, tackling MEB at different layers using cryptography. And we have Christopher Ghost from Anoma, Daligong from Automata, ken from secret network, Janic from Charter network and Dave from Osmosis and Barry from Ethereum Foundation. If everyone's here, let's start. Here are the four questions that Mikira has posted and it's also updated on the agenda. So I would ask everyone who is currently speakers and panelists waiting in a zoom chat to turn off your camera and the panelists and our moderator to turn on your camera. If you would like to be seen on stage by the East Global audience who are streaming from East Global TV, thank you, and the stage is all yours, Mikira.
03:51:51.330 - 03:52:56.680, Speaker A: Okay. Hello again. So I guess, yeah, today the goal of this panel is to just discuss these different privacy techniques that I just went through in more depth from people who are actually building out the solutions. And it's just to look at the different kinds of trade offs one needs to consider when using these kinds of techniques for solving mev. So the first question I'll ask today is to all the panelists is what are you working on and what kind of techniques in terms of cryptography or privacy are you using to minimize mev? Well, I suppose we could start in alphabetical order. We are working on a system for distributed key generation and threshold decryption called Fervio, which is a collaboration with Sikh. So Dave could probably speak as to any parts that I miss or perhaps parts that I don't even know about yet.
03:52:56.680 - 03:54:09.642, Speaker A: One it sounds like you've already covered, as you referenced in the slide, social decryption. I'll just note that the way we integrate closely into the consensus algorithm, in this case tendermint. Although the approach should generalize to any sort of like multi phase BFT consensus allows us to more or less avoid the one block delay. I mean there's still latency insofar as the validator set, which is the same as this set, which has to provide threshold decryption shares in our case has to compute the shares and combine them, but because we can just put the threshold decryption shares for each transaction in the pre commits and tendermint. So in the last phase of the BFT Consensus round, we can execute the transactions in the same block. Decryption execute the transactions in the same block even though the proposer who has to propose before the pre vote round, which happens before the pre commit round, has to commit to an ordering of encrypted transactions by the time we get to pre commits. If a block is finalized, because we have the same set for two thirds of the quorum requirement to finalize a block and two thirds of the share requirement to decrypt transactions, those two coincide.
03:54:09.642 - 03:55:04.886, Speaker A: And so we can decrypt and execute the transactions in the same block in which they were committed. Maybe I can take the next one. Hi everyone, this is Stelli, I'm the co founder of Automata Network. So, for those of you who heard about us for the first time, we are building privacy middlewares for DApps across multiple chains using SGX and Oram. So our team has several researchers who has been doing SGX research since 2014 and some of us were previously working at a security research lab in US National University of Singapore. And just to let you know, before Automan Network, this research lab already had a few successful sipping of crypto projects such as Kyber Network and Zelika. So under this context of mev, we are actually developing decentralized privacy middleware called conveyor to help DEXes to minimize mev.
03:55:04.886 - 03:56:12.358, Speaker A: And also if you happen to know that we actually also released a small free tool called Mev Tax for people to inspect if they have been sandwiched attacked previously. So our approach is we are using trusted hardware te or Intel SCX, whatever you think the term is, to try to just hype the transaction temporarily and determine the transaction orderings before it's published and to preserve the maximum compatibility with existing blockchains. It will review the transaction only after the ordering is locked, decided and locked. So that means layer one block producer and also layer two sequentials. We just process it as normal transactions, but they don't have the ability to change the order anymore. So this would allow us to directly work with Dexis on many chains and to protect existing users with a non intrusive integration with them and maybe a little more details about it. So the ordering we are providing here is actually particular to it's, very application specific.
03:56:12.358 - 03:57:12.490, Speaker A: So we can even just provide a lot order only for a particular trading pair, and we will have multiple trading pairs running in powerlife. So it's kind of just a scalable way for us to support DEXs. And the other technique we are using is called Oblivious Wan, which directly enhances the privacy of trusted hardware. And it also raises the bar of breaking dee through side channel attacks. So we know trusted hardware can provide these safe rooms or enclaves but it actually doesn't solve all issues. For example, the traces left by these enclaves when interacting with the outside world could leak information even your data is encrypted. Before leaving this enclave the access pattern that it reviews could be collected and learned by malicious node operators and then used to infer the computation inside your enclave.
03:57:12.490 - 03:58:43.750, Speaker A: There have been papers that successfully apply these sidechain attacks and also extracted private keys from tee so it's pretty dangerous in some sense and this kind of attack involves many rounds of profiling, probing and analyzing and the sensitive information is actually reconstructed sometimes bit by bit based on the access pattern that were exposed. Maybe I can give an example of this. So if something looks like a duck and swims like a duck and quacks like a duck, then it probably is a duck. So if some observations of the access pattern could be associated with certain computation with very high probability then the observer would know what you are doing even you are using traffic hardware. So Oram is trying to change the access pattern so that even the traces are observed, it will be useless because the access pattern will not make sense anymore to those observers. And this line of research actually has been there for several decades and the idea is just to providing just to kind of shuffle the access pattern, just doing more useless work, but it ended up just doesn't allow the observer to get any useful information from that. That's kind of the technologies we are using to try to safeguard the privacy of the transaction orderings.
03:58:43.750 - 03:59:53.594, Speaker A: Okay, cool, who's next? I think I can go next. This is John from Secret network. Secret network is a Cosmos SDK based layer one chain where every validator runs an SGX. And as a result, as every validator runs an SGX, what happens is we can ensure that all contracts on the network are private, preserving contracts. And the way this works is there's one private key that's shared across all the validators that's generated within the SGX or the trusted execution environment. And when a user is interacting with the network, they create a symmetric key by using their private key. And the network key and encrypted inputs are stored in the mempool.
03:59:53.594 - 04:01:00.114, Speaker A: That's why no one can really see what's going on as to what the inputs are, and then validators take those encrypted inputs, they can decrypt them inside their enclaves because they have the network key. The computation takes place inside each validator's enclave, and then validators share hashes. Of the computation results on chain and form consensus based on those hashes and assuming there's consensus the state updates. The state is also always encrypted and stored on chain. So that's how Secret Network deals with front running attacks. And we've had secret contracts live on our main net since September of 2020 and we have a functioning AMM that is front running resistant since February of 2021. Okay, cool.
04:01:00.114 - 04:01:27.318, Speaker A: I guess throughout the panel you'll probably have the time to go into detail about how you default from automata number. So let's see who's next. Dave? Yeah. Hello. I'm Dave. So we work on project called Osmosis, and one of the things we're doing to front running, as Chris mentioned, it's like working very closely with them is to use threshold decryption. So Chris kind of summarized this earlier.
04:01:27.318 - 04:02:33.870, Speaker A: So I think what I'll talk about instead as a brief overview is how we want to handle fair ordering, which I think is also an important question. So with threshold decryption on its own, a proposer can still try to get their transaction as the first transaction or the last one. So on top of that, we kind of imagine our take on fair ordering is not the same as kind of the Wendy or Equidast take it's instead, which is like this kind of time, this take on when something arrives in imagined global mempool across all nodes. And instead we're trying to take that everything in a block should ideally be treated as though it came at the same time. So the way you can imagine this for something like trades is then you could imagine you had a random permutation of the trades. You take the average across the random permutation for how your trade would have been executed in sort of a batch environment. And then for things where you can't really whitebox like that, where it's not clear, like transaction sends for instance, then you take a random permutation.
04:02:33.870 - 04:03:31.826, Speaker A: So the idea is then I summarize for orderings and take for things you can whitebox, like analyze, do some white box analysis as though everything came at the same exact time, or you have random permutation of them all, which you can't which applies for trades on uniswap, for instance. And then for things you can't take a random permutation based off of decrypted contents and then do some other techniques to ensure that there's some decrypted content, there's some transaction content in there that the validator who's proposing the block doesn't control. Yeah, that's like we do for fair ordering on top of special description things. Interesting. Yeah, I guess I'll have more time to go into details. Who's next? Barry, can you hear me? Yeah. Hey everybody.
04:03:31.826 - 04:04:21.282, Speaker A: Yeah. So my take on mev prevention is that there's two kind of approaches. The first approach is where you limit the amount of the group who are able to take advantage of minor extractable value. And that's where you see solutions like encryption and threshold decryption. And the second approach is where you make it kind of impossible for you kind of randomly order transactions based upon you just randomly order them so that even if someone is kind of front running, you're not able to get as much value out of it. But there is a certain class of mev that we're not really able to prevent with either mechanism. Like for example, if someone is getting their collateral slashed, there's going to be mev there.
04:04:21.282 - 04:04:54.606, Speaker A: And even if you order the transactions randomly, someone is going to get that. And this will actually produce this kind of weird incentive game where people are creating thousands and thousands of transactions because they just want to be the first one ordered by the block. So there's these weird kind of incentives that appear. So that's my take and maybe there's some interesting things to discuss about that. Okay, cool. So Christopher went. Okay, so, Yannick, I guess I'm the last one.
04:04:54.606 - 04:05:26.210, Speaker A: Can you hear me? Yeah. Cool. So, yeah, I'm from Shutter and we are one of these projects that use threshold encryption to prevent front running. It's very similar to, for example, Sicker Desk. I think the general principle is very similar. The main difference is that we don't see this as a new layer one blockchain, but we try to interpret this as a more general technique that can use and apply at different layers. And the first layer that we applied it on is very close to the application layer.
04:05:26.210 - 04:06:45.300, Speaker A: So we implemented this as a kind of a smart contract system on top of Ethereum so that users can send encrypted transactions to Ethereum wrapped, of course, in a normal Ethereum transaction. And then those would be at some point decrypted and passed on to another smart contract, which would then be front running protected basically as long as they only accept transactions through this mechanism. Yeah, that's the main idea of Shutter at the moment. Okay, I think that is everyone, I guess from the introductions, everybody's working on different solutions and they're meant to be deployed in different ways. So some are working on layer one solutions and then others are working on drop in solutions for app developers as sort of a plugin. And so the main point of this question is sort of what are the pros and cons of using your respective technique at these different layers, at layer one or at layer two, an application layer, however you'd like to answer that question. Yeah, I'll leave it up to you guys to choose your order.
04:06:45.300 - 04:08:25.650, Speaker A: Maybe. Can I start first? Our solution is actually so the pros about the solution is fully compatible with any kinds of layer one and layer two, because we are really just trying to provide this solution as a plugin to the existing system so that we can help the users and also the DEXes. And most important thing is we are not modifying any layer one layer two protocols and also at the application layer we are able to offer kind of different variants of implementations that balances between easier integration, better gas efficiency or even higher fault tolerance. For example, if you just need a very quick patch to get rid of mev so you could just build off a single trusted relayer that does a very simple FIFO ordering that will just kind of solve that, but for sure that introduces single point of failure. So maybe a more decentralized relayer network that runs a little bit consensus algorithm to ensure the ordering is better. And in terms of the integration, actually since we are directly working with Dexis at the application layer so they could just adopt this approach very easily as it only needs to kind of acknowledge the ordering coming out from the trusted relayers. And also this kind of metatransaction approach also brings another quite interesting design point where we can actually make the transaction gasless and user won't need to pay in the native tokens for the gas fees.
04:08:25.650 - 04:09:34.180, Speaker A: And also since we have this great flexibility, our design also make it possible to work with other MEB solutions as well. For example, we can work with flashboard in order to just ensure the order transactions are delivered without being kind of censorship by the miners talking about the cons. I think it's really about when you build this kind of relayer network, it really takes time to fully decentralize your entire system. But actually, since we are using trusted hardware, each individual node in the system has a slightly different trust model than just a random node that hosted by anyone. So we sort of have a slightly better confidence on this te node. So in that sense, even we're starting with a smaller number of nodes, the system overall is also secure. Yeah, I guess that's my take on this.
04:09:34.180 - 04:10:58.110, Speaker A: I guess I can go next for us. When you have smart contract privacy on layer one, the things that you can address with that is much more than mev. You could have NFTs where the content is encrypted and you could get into more subscription and content access or content monetization like use cases in the Web three, which to me is very exciting. And also building things are easier but then the problem is then you have to build a new ecosystem and have new people build applications on this new layer one rather than plugging into another network. To me that's the big trade off. And I think one thing that we are doing more and more is to explore some sort of an operator model whereas in order to target someone who's on ethereum and just like a simple use case say want to do a mix. One thing that we are working towards is how to allow the user to do that just with the MetaMask transaction rather than getting into the whole cosmos ecosystem, wallets and tooling.
04:10:58.110 - 04:12:35.866, Speaker A: And I believe that will be something that will allow us to target more people where we can have the user get a key from the secret network to the help of an operator and then when they're making their Ethereum deposit transaction, they can also create an address where they want to get their funds back. That address can be decrypted in secret network. I guess that's similar to what you have been mentioning Delhi and then sent back to Ethereum to make a new mean. That may not be as exciting in the mev index cases because it does add some latency. We're also building noma is also building a layer one and I would agree with the primary disadvantage of simply adoption from zero or building an ecosystem up from scratch, although I think some of that can be mitigated with good interoperability protocols. The other point I would note specifically with relation to MAV is that it seems to me like for some of the protocols involved which use randomization or which use threshold decryption in ways which are where there are like a bunch of transactions being grouped together and somehow combined, as Dave was mentioning, or being randomly reordered. There's a little bit of a sort of network effect or like, the larger the set is, the better the guarantees or the better the kind of unpredictability individual transactions have.
04:12:35.866 - 04:13:57.666, Speaker A: And it seems to me that's easier to achieve in practice when you can make it the default in a system as we can much more easily do at a layer one than perhaps in kind of an add on. Solution just because the whole system can be architected to integrate it as like the default pipeline for submitting transactions and we can change tendering concerns of surrounds like I mentioned. So it's very easy to achieve a kind of holistic integration such that end users can really use threshold decryption without knowing it, and such that it's so easy that even transactions which don't need it and probably aren't going to want to pay additional costs, either in gas fees or in user experience to get it, can get it for free and thus contribute to the public good of more transactions being randomly reordered or whatever. I can go next, I think Chris summarizes pretty well. I do want to say on the point of mev resistance tactics, I don't think there's actually a meaningful difference in pros and cons between L one and L two. Really what you're doing is you control your own chain, your own consensus and L two or really roll ups really just means that you have some data that needs to be posted to ETH or whatever base chain and some priority for getting transactions from ETH onto your chain. That's not really like an mev concern.
04:13:57.666 - 04:14:51.794, Speaker A: That's like a fund transfer thing which didn't really have coach mev, that really had like latency and sensor resistance concerns. So I think the key questions to ask is just your own chain like L one. L two is one category versus the app layer. And then for something like Threshold Decryption, the guarantees actually differ a lot here, actually, really for all the mempool privacy techniques except SGX. So I guess mempool of Encryption and Threshold Encryption sorry, Time Block Encryption and Threshold Encryption, the guarantees differ a decent amount because you're doing in the app layer. To get these strong guarantees, you kind of have to make your own subsets of the chain that's only taking in transactions from this encrypted layer. Otherwise you get these issues where since the decryptors can never guarantee their transactions going to get like when it's going to get included, they could broadcast the decryption.
04:14:51.794 - 04:15:45.900, Speaker A: And then if there was a path for someone who's not using decryptions to get the transaction in, first they'd do is they'd see the decryption being broadcasted over the PP layer here and then they'd front run that before the decryption gets posted on chain, then defeating the point. When you're in the app layer, it's actually pretty hard. You have to kind of make your own subsystem, which is not going to be interoperable with the rest of the ecosystem. So I think that's a key difficulty you have with really these member privacy techniques when you're on Apple Air versus your own chain. Yeah, sorry to interrupt you deb. Yeah, I completely agree with what you're saying. That was the point that I was planning to make and maybe to drive the point home just to drag it out a little bit more.
04:15:45.900 - 04:16:50.366, Speaker A: So the example here is that, okay, if you take uniswap and you say, we want to make a mev resistant version of uniswap, there's always going to be a place where the mev resistant version goes to the smart contract to tell it. These are the orders to place, and at that point you're able to front run. And this is the concern that you end up just building everything in a silo where you have like front run resistant uniswap, and then you have uniswap and then you have front run resistant compound, and then you have compound. They can't really be interoperable between each other and this is a big concern. I guess I definitely agree with these concerns. That's also the main issue that we see, that this application layer, front rank protection breaks composability in some sense. The reason why we still started there is that it's just much easier to implement and you can just focus on this particular problem of front running protection and you don't have to worry about all the other stuff.
04:16:50.366 - 04:18:12.010, Speaker A: I mean, building a new blockchain is very hard. Building a new layer two is very hard. It takes a long time. So this is one reason why I think it makes sense to start there. And the other reason is I think it has already been mentioned that the problem exists at the moment on layer one for many applications, and it doesn't really help them if there's an mev or front running resistant layer one or layer two somewhere else if the application is on that layer that is not protected against this. So that's the two reasons I see for in pro of application layer I guess to build upon this is depending on the application, you might be willing to take some amount of, I guess latency. So I guess asking you guys for your respective techniques, do you think some categories of applications are better suited for your technique or is there another technique that's probably better or maybe you think installation is good for all techniques sorry, for all applications.
04:18:12.010 - 04:19:55.158, Speaker A: Any thoughts? I think a lot of difference is based on the security assumption you're willing to take. I've been working on tendermint things for years now where in tendermint this proof stake algorithm where you say I trust that over that two thirds of this validator set is honest, but then I can detect their faults and then if they commit some fault, slash them. And if you're willing to take that assumption, then I think the threshold decryption security works for all the kind of really all applications I can think of which are kind of siloed to one chain, then you do have some cross chain concerns, but these are really inherent to all of the techniques. And so I think the reason I think SGX comes interesting for when you want more than just MEMP level encryption, but you then take the cost of what happens when SGX breaks time lock is I think interesting if you're willing to make hardware assumptions, but not these multi party assumptions that you typically do stake. So I think it's really around the security assumption for timelock versus threshold. And then for SGX it's like well, okay, we're taking the lower security because it's cost to break on SGX and we're instead pivoting to well here, what else can we do on top. I think my argument on that point is that it's a different trust assumption if you're trusting the majority of the chain to not do something that can potentially get them slashed.
04:19:55.158 - 04:20:39.474, Speaker A: It's very different from trusting the majority of a chain to do something that they can never be sashed for. You can never prove that they did this. So there's no punishment for the validators if they kind of front run people. There's no way to even know that. Well, you can kind of know, but not really, but yeah, that's my thoughts, sorry. Definitely agreed. I spent a while trying to think about this to what extent is this slashable? And I feel like the best way to get slashing abilities is to have the decryptor shares or the decryptors do the decryption work in an SGX, so that way they're still forced to be behaving the protocol correctly.
04:20:39.474 - 04:21:06.510, Speaker A: But everyone only needs a cryptographic assumption to know that the protocol was done correctly. But then as a defense in depth. So it's like, okay, well now you need to trust enclave and break cryptography and break this two thirds assumption. Yeah, agreed. This is definitely hard. There's no solution to that problem. Yeah.
04:21:06.510 - 04:21:50.560, Speaker A: If there's an offline collusion attack, there's no way you can know it. Well, what you need is you want to be able to have a defector report. So in Proof of stake, the reason we can do double sign protection is that a light client at the end of the day needs to get the double sign a different signature than the rest of the world and this can be reported. So if Farm running, the problem is that only the validators actually got these decryption shares. So to get a similar guarantee you'd need that any member of the Validator set can defect and prove that, hey, look, this cabal tried to decrypt something when they shouldn't have. Okay, I understand. Yeah.
04:21:50.560 - 04:22:33.050, Speaker A: I don't know how to actually do this without more assumptions. Interesting point, but I don't want to take all the time. But let's discuss another time. I think there's about five minutes left. So yeah, if you want to answer this question or we can quickly go on to the next question. We can quickly go over to the next question. So yes, the last question is we're all dealing with either hardware assumptions like SGX failing or trust assumptions such as some quorum of nodes being honest or at least incentivized.
04:22:33.050 - 04:24:11.178, Speaker A: So how do you guys handle failure scenarios for your technique? How does it affect the user? How can they recover? So as already has been mentioned, it's very hard to prevent these key shareholders to collude with each other. And therefore I think it's very important to make sure that they are well incentivized to not do this, mainly by having a lot of them. Because if there's a lot of shareholders it's much harder to collude and it's easier for a single person to defect and notify the world about this. The other way I think this should happen is that they are selected in a good way, so not just randomly and not just the spots shouldn't be sold to the highest bidder. Or that's at least what we're trying. Not to do, but instead select them from different organizations, from different sets of people to make sure that they're not all not a single person. And lastly to give to them very long term incentives so that they have a financial incentive for the system, for keeping the system honest and keeping users trusting the system, kind of.
04:24:11.178 - 04:25:22.738, Speaker A: And to do that we probably want to have a kind of Dow that does the selection process because it's very subjective and you can't really write a cryptographic or economic protocol to do this. Well, I would quote with that a little bit. I mean, I think in the case of proof of stake systems you have already a naturally incentive aligned group of participants in the validator set who are because they're staked aligned in some sense with the long term success of the protocol and who potentially have sort of out of band or chain external reputation on the line. Plus they have the ability, if they are able to coordinate and collude in large enough groups to commit more serious faults potentially than extracting mev. So it seems to me like that's a case where there's a group that already exists and you wouldn't need a separate selection process. I think on that point I kind of think about the kind of validator set as this economic group and this is a group that are selected based upon whoever is able to make the most profit from what they're doing. And I see exploiting this kind of minor extractable value opportunities is just like another potential revenue stream for them.
04:25:22.738 - 04:26:30.070, Speaker A: Like you've seen this on Ethereum when the Ethereum miners started en masse to use splash bots or front running methods to increase their rewards. And I'm also super worried about the stakers on Ethereum doing this. When we move to proof of stake it seems like just such a natural thing for them to do. I agree that having these mechanisms in place, some of these mechanisms will reduce the amount of money they're able to extract, but I feel like they will get more and more sophisticated because that's just how they make their most money. That feels like the natural place for them to do to be for us. Because of the hardware guarantees. This is assuming the validate, I mean, side channel attacks are going to be expensive because you have to pay gas and then actual physical way to hack the tes is assuming most of these run on data centers is not very, I think, practical.
04:26:30.070 - 04:27:06.498, Speaker A: So that's how we think about it. But worse comes to worst, you end up with exactly in the normal blockchain kind of scenario. Okay, cool. So I think that ends this panel. I'd like to thank everybody for taking the time to answer these questions and for going through the trade offs on your respective techniques. I guess Tina can take the floor. All right, so up next we move on to our next section in part three.
04:27:06.498 - 04:27:46.314, Speaker A: Protocol level response to Mev 3.2 is mev democratization approaches and the first talk will be given by Vitalik on in protocol block space auctions in Ethereum. Sharding. Vitalik, can you share a screen now and start your talk? Yes, I would share the screen right now. 1 second share. Okie doke. Do you see my hello? Yes.
04:27:46.314 - 04:28:38.110, Speaker A: Okay, great. So I'm going to talk about this proposal that I think Phil mentioned earlier on today, which is basically block space auctions and an integrated market that kind of separates the function of block builders that come together, that actually package and come up with proposals from blocks from the consensus function of block proposing. And our proposal to add that into the Ethereum sharding design. So a quick summary of the ethereum sharding design. So there's a beacon chain, there's a bunch of shard chains currently 64, but that amount is likely to increase over time. And the shard chains just have data. So they're just data availability space.
04:28:38.110 - 04:30:02.074, Speaker A: And the reason why these shard chains exist is basically to provide space for roll ups to publish their data and have it be guaranteed by consensus through data availability sampling that this data actually is available, right? So projects that are currently roll ups with data on mainnet could instead be roll ups with their data on chart chains and this would increase their scalability by something like a factor of 100. Now the question is what actually is the fee market for putting data into these shards going to look like? Right? So basically the challenge here is that we're looking at these data blobs and it will mostly be roll up projects providing these large data blobs. But conceivably there could be multiple roll ups that provide multiple blobs that get included into the same shard block. And the job is to just make it easy for block proposers to choose what data to include and get paid for it. So this is the proposal for a market for choosing block proposals. So there's a few steps but I'll go through it step by step. So we have a class of actor called block builders and the block builders propose block bodies and think of the block body as being just a lump of data.
04:30:02.074 - 04:30:48.730, Speaker A: So it has no meaning within the protocol itself, but roll ups can refer to it. Roll ups will be able to make proofs that show that, hey, this particular piece of data actually is available because it actually was published in a shard block at some previous point in time. So the block body, you can compute a polynomial commitment and that can go into a header. And so there is this concept of a block body header. A header contains the commitments of the block body and it also contains a signature from the block builder that produced it together with a number that represents what fee the block builder is willing to pay. So we have a bunch of block builders, they create a bunch of bodies and from those bodies you can create the headers. So the header is going to be at most like maybe 100 bytes, maybe a little more altogether.
04:30:48.730 - 04:31:56.618, Speaker A: And this all gets published into a special peer to peer network that we call the proposal header subnet. So then there is the block proposer, right? So block proposers are these actors that are actually the ones that are supposed to have kind of ultimate choice about what gets included. And block proposers are going to look at all of these headers and they are going to take the one that has the highest fee and oh, this is a mistake, this should be zero point 15 instead of zero point 13. They're going to take the header that has the fee, that the highest fee, not the lowest and they're going to sign it and they're going to republish the signed header into the proposal header subnet and the block builder that actually created the winning header is going to see this. So step one, block builders create bodies, submit headers with fees, block proposer chooses the high C that they find, they sign it. And step three the block builder sees this and at that point it's up to the block builder to publish the body. Once the block proposer has submitted the header, the block proposer does not needs to do anything more.
04:31:56.618 - 04:32:50.946, Speaker A: They have no further choice about what happens. So notice that at the time that the blog proposer makes their only decision they do not see the body. Right? So this makes the fee market very efficient for the blog proposer. They don't have to do any kind of complex math, all they have to do is see a bunch of headers and choose the one with the highest fee and they have no ability to censor because they have no ability to see contents. This gets published back to the network and then the block builder is the one that publishes the block body. They have to publish a block body where if you calculate the commitment that actually matches up with the header. And so the block builder does not have a choice of what to publish, they have to actually publish the original block body that they started with and then they publish this into the main chart subnet and then you have the attesters who are basically the same attesters that are currently participating in east 2.0
04:32:50.946 - 04:33:20.646, Speaker A: consensus. And instead of voting on basically either there being a new block or there not being a new block, they end up voting on one of three choices. One choice is that the body is available so everything is available. The second is that the header is available but the body is not available. And the third is that the header is unavailable. So if the header is unavailable that basically means that well this basically means the signed header is unavailable. Right? So that means that the proposer kind of neglected their duties.
04:33:20.646 - 04:34:07.898, Speaker A: The proposer was offline, if the header is available but the body is unavailable then that means that the block builder neglected their duties. So in this case what happens is that the fee from the block builder to the proposer still goes through but the body is counted as not being included. And then if the body is available then the body is counted as being included. So the goal is to basically replicate this kind of fee market design sort of similar to what Flashbots does with a single bundle with this nice privacy property but do it all in protocol in a way that's kind of very efficient, has very light. Trust assumptions. So properties, right? So block proposer does not know any contents during step one. By the time the block proposer assigns the header, which is step two.
04:34:07.898 - 04:34:37.086, Speaker A: After they do this and after they publish, they cannot prevent publication of the block body. And the final actor in publication actually is the block builder, but they have no choice of what to publish. I made an ETH research post about this. It may have been linked somewhere, but you can easily find it. It's like block builder proposer separation. Just search for those words that you research and you'll find it. And it talks about the rationale of kind of all of these design decisions.
04:34:37.086 - 04:35:52.742, Speaker A: But the goal is to basically allow block builders to be this specialized actor that can understand kind of where to grab different pieces from roll up projects and other projects to come up with a block body. And then the function of block builders is fairly specialized and the function of block proposer is this very easy function that's very amenable to decentralization, which is they just see a bunch of headers and they pick the one with the highest price. So this potentially even allows the block proposer to be MPC for example, which could be useful for staking pools. And it actually provides an advantage for decentralized staking pools because decentralized staking pools are the only ones that can credibly not be kind of siphoning off mev to themselves by side channels because they could have multiple participants that are running this algorithm and they would have to all agree on which of these headers has the highest fee. So this can be combined together with Flashbots. So Phil also talked about the possibility of combining together the SGX based approach with the economic approach. What I talk about here is purely economic, right? There's the fee.
04:35:52.742 - 04:36:50.986, Speaker A: And the incentive for the block builder to publish is that if they don't publish, they have to pay the fee, but they don't get the benefit of their block body being included. And the incentive against censorship here is basically that if there is some underlying lump of data that pays a fee, then if the block builders try to censor it, they'll just get outbid by block builders who don't censor it. And if the censoring block builders suggest start pushing their bids higher, then they'll have to basically pay higher bids than what they can actually get in revenue. And so they'll have to keep losing money very quickly. They lose money once every block forever, until eventually they have to stop censoring. Right? But these are all economic arguments. But what you can also have is you can have this market going from searchers to relayers, right? So block builders, in this case we could call them relayers, this would be the central actor and then they themselves would be listening to a flashblood style market where you have a lot of different searchers.
04:36:50.986 - 04:37:45.946, Speaker A: Searchers can specialize, they can focus on individual roll ups, for example. And so searchers are this function where you can do something useful even if you're very small, even if you're an individual hacker, for example. And then Relayers would be responsible for just doing all this aggregating between the searchers. And you can kind of slot this into Flashbots and even kind of Flashbots with me VSGX. Almost as it exists today, except instead of the contents of a body being unlocked when the miner gets the proof of work, the contents of the body would be unlocked when the relayer gets back. The header signed by a proposer. So there's this nice kind of opportunity to create this three layer market that basically Kimball has a kind of very decentralized market of searchers doing all sorts of things to a fairly small but still competitive group of these more professionalized three layers and then going to block proposers.
04:37:45.946 - 04:38:09.782, Speaker A: So that's it for me, and hope you enjoyed the presentation. Hope you go read these research posts. Well, thank you for staying on time. Vitalik, for your talk. We have three minutes for questions. Oh, I was actually hoping to kind of help the event get back on track. So three minutes.
04:38:09.782 - 04:38:30.506, Speaker A: Can you go to the next guy? All right, in that case, Ben from Optimism, you're up next. Please directly share screen. All right, sounds good. I'll just take Vitalik's three minutes back. Go. 18 minutes. JK JK.
04:38:30.506 - 04:38:40.082, Speaker A: I won't do that to you. Oh, sorry. I got to do a system preface. Share. My bad. Give me 1 second. Hello? Hello.
04:38:40.082 - 04:38:57.080, Speaker A: How's everyone doing? Am I coming in? I guess I should be asking that. Eh? We're not seeing your screen yet. We're only seeing your flowing hair. That's great. Okay, I have to quit a darn zoom update. Reset my permissions. Give me a second.
04:38:57.080 - 04:39:42.292, Speaker A: For everyone who's watching the live stream, we were running 30 minutes late compared to the posted schedule on Mev WTF. But thanks to Vitalik, we won back eight minutes. But we are losing two right now, so do the math in your head, Ben. Feel free to be back in action. Awesome. All right, stage is all yours. Cool.
04:39:42.292 - 04:39:50.056, Speaker A: Thanks, guys. All right. Hoping y'all can see that. Sure looks like you can. Sweet. All right. Hello, everyone.
04:39:50.056 - 04:40:41.572, Speaker A: I am Ben, and I am a co founder of Optimism. We're building optimistic ethereum layer two scaling solution for making your EVM more beautiful and fun and fast and cheap. So today I'm going to be talking about some old things and some new things and their intersection. So we have this enticing title searching for EVM parallelism. But where I want to start is just talking a little bit about mev and how we're thinking about it on L2, and especially how it's been in the last year. Because about a year ago oh, I guess a year and a half ago now, we put out this post called Mev Auction, which basically talked about how in protocols generally not just on L2, although L2 is particularly suited for implementing it. We really can separate out the role of transaction inclusion and transaction ordering and break those into two separate rules.
04:40:41.572 - 04:41:26.280, Speaker A: And there's some fun stuff we can do with that, especially if we auction off the right to ordering those transactions and we call these mev auctions. So I just want to reflect for a minute on where we're at with that. A year and a half in and there's an elephant in the room that relates to this, which is Flash bots. So I think this chart is way out of date. We're way above 60% hash rate now running Flashbots. If I'm not right, if I'm not wrong, and this is a question that comes up a lot, people look at that post that we put out and say, okay, that's an auction for mev. How does that compare? Does it relate? Does it contrast? Does it complement with Flashbot's auction? Because now we have 60% plus of the hash rate running mev guests and basically running auctions for mev.
04:41:26.280 - 04:42:12.180, Speaker A: So that's a really great question. And the cool thing about it is that they are totally complementary. So I just want to talk a little bit about that to set the stage cool. So the mev auctions that we were talking about and this Flashbot auctions are not the same thing, and they're actually complementary. So the analogous property that these mev auctions where you're in the protocol, selling off the rights to ordering within the protocol is actually similar to leader selection or like proof of work or proof of stake. And you can think about the sequencer that is being a position. Auctioned off in mev auctions is actually the equivalent to the proof of work or the proof of stake that's determining the block proposer for the protocol.
04:42:12.180 - 04:43:00.150, Speaker A: So this is an important note. Obviously, we have mev auctions in some effect taking place with Flashbots right now, but this did not require a fork of the L One, it didn't require a change of protocol. We still have miners that are finalizing and assembling these blocks and continuing the chain, and yet we still somehow have these auctions going on as well. So what does that mean? Why is that? And really the answer is that we're just further separating concerns. So whereas before in L One, we had miners and the pools that were both progressing the consensus of the protocol and determining the ordering, we actually still have that ordering being upheld by the miners. But where Flashbots comes into play is that we now have a secondary market for reselling that ordering. And that's really what Flashbots is doing.
04:43:00.150 - 04:43:34.210, Speaker A: And I think this is an important note because it's a separation of concerns where now we have miners that are able to do their specific thing that they're good at, which is compete on providing network security, and they're able to outsource the searching for the Mev extraction. And what is the correct order to make to external parties? And Flashbots is there providing that auction that sits in the middle. And of course, right, this is an order. So a market. So, in fact, there's a bunch of people that are participating in this market, not just one big yellow circle. So I added some more yellow circles. Oh, yeah.
04:43:34.210 - 04:44:18.988, Speaker A: So what do we expect this to look like on L2? Right? Is it a matter of these Mev auctions replacing one part of this or something else? The answer is something else. What we can imagine on layer Two is that we have L One that is determining the inclusion of transactions. We have an in protocol on L One, effectively a sale of who is allowed to order transactions through an Mev auction. But there's no reason. And in fact, now that we see the popularity of Flashbots, we actually think it's very, very likely that we will still see resale of ordering rights on layer two. So we still can expect to see a secondary market for ordering. And it actually is complementary to these two things.
04:44:18.988 - 04:44:38.310, Speaker A: They both come into play. So it's not a matter of whoops. It's not a matter of replacing some part of this. It's putting something in the middle and extending it. Okay. So that's why I want to say oh, and then also by selling it off within the protocol, we can redirect those funds to all sorts of lovely projects and research and development. That's for another talk.
04:44:38.310 - 04:45:08.808, Speaker A: Okay, let me do a time check. Oh, we're doing great on time. Good. Okay. That's a bit of an aside, an update on our thinking about mev on L2. Now I want to talk a little bit about some new stuff on how we're realizing we can use this, given the fact that it seems very, very possible that we'll have both of these markets layered on top of each other. Okay, so we're going to start with a digression into a very old problem now, I guess old for the crypto space, which is parallelizability.
04:45:08.808 - 04:45:37.844, Speaker A: I guess the problem statement really is the EVM is darn slow. And one of the reasons it's so slow is because you have to run it in serial. You can only run it on a single thread. So we have here from Vitalik, an EIP that's, wow, fully four years old at this point, talking about maybe we can parallelize these things. And by things, I mean transactions. And spoiler alert, that is still an open PR. So we're not there yet, although we are getting closer.
04:45:37.844 - 04:46:18.244, Speaker A: Right. So one of our recent forks, we had access lists which could set the stage for parallelism, but hasn't quite done that yet because they're optional. But it's worth noting. Okay, so why are we four years in and not having parallelized EDM yet? The answer is basically about state access and what happens when you say that transactions can or can't be parallelized. So to very quickly summarize, if we have two transactions and they do not touch the same state, then they are parallelizable. If they do touch the same state, then they are not parallelizable. Okay? So this is pretty obvious.
04:46:18.244 - 04:47:29.672, Speaker A: If they touch the same state, then you're required to know what modification the first made to the state before you can know the result of the second. Okay? So that's a very simple definition of parallelism. And the reason that we haven't seen these things is because in the current EVM design, any smart contract at any time can talk to any other of these money Legos, right? This is like a huge feature of the EVM is that we can just jump around and call any contract and everything's very interoperable and lovely. But it does come with a problem for parallelism because it means that you can't know if two transactions are parallelizable until you have run them both because it could be the last, very last thing that one transaction does is to call out to another piece of state that intersects with the access list for a previous transaction. Okay, so just to maybe state this in an even more simple way, there's more complex things you can do with gas metering, but we could just try to parallelize the EVM right now. We could say, okay, consider a block. We're going to introduce a new block validity rule, which is that no transactions can touch the same state within the same block.
04:47:29.672 - 04:48:33.036, Speaker A: This is maybe not, maybe not the best way to do it, but it's very simple to imagine, right? If there are TXi and Txj such that they're not parallelizable, meaning their state intersects, then the block is invalid. So why haven't we done this yet? If we have such a simple construction that will let us increase the throughput of our EDM, can we do this? The answer is we could sort of, but it's not so clear. And in particular there's two separate things and one is okay and the other is not from the perspective of a verifier. So someone who is taking the chain and checking that it's valid, there's no problem with this condition. This is a very simple condition to check and just as a part of your processing, you output, you look at the result, you say, did these things intersect? Yes, they did. Therefore it's not parallelizable and it's an invalid block. The problem comes from block production because block producers don't know whether or not two transactions are going to intersect without running them and they have to choose them somehow.
04:48:33.036 - 04:49:04.312, Speaker A: So how do the block producers choose a valid block? It's often been considered a Dos vector. So I want to quickly call out Jeff Coleman. I think this presentation is public. If not, I'll link it after for a great little thread on this. But just a quick chunk of this is that you can really think of there being a first run of a transaction and a second run. And the first run is what happens when you're producing the block, and the second run is what happens when someone is verifying an already produced block. And these two things are different.
04:49:04.312 - 04:50:08.716, Speaker A: Okay, so this problem of how does the miner, how does the block producer figure out whether or not it can put these two transactions, will they be parallel? This is the problem that we have right now. Okay, but I now have a question for you, and especially if you're in the flashbots community. Does this problem statement sound familiar to you? The problem that you don't know whether a transaction is valid until you've run it? Well, I will tell you that this should be a problem that you're familiar with because it is exactly what we see in Flashbots. So I took this from some of the docs on flashbots, right? Flashbots what is fundamentally doing. It's letting you pay the miners at the end of a transaction. So literally, I mean, at any point in time, but literally, in the example that is like the first one I found on GitHub, the very last thing that happens in this flashbots execution is the transfer to the coinbase. So this is the exact same problem statement that we have for valid bundles in flashbots and valid blocks in a parallel block validity condition.
04:50:08.716 - 04:50:42.532, Speaker A: It is impossible to know beforehand, but you can know after, and then that part is no problem. So I'm running a little short on time. So maybe we'll have some more time back for you too, Tina. But the thing that I just want to conclude with is that this is awesome because we are not yet seeing flashbox collapse due to dos. I think there's concerns, but what's very exciting is that y'all are working on it. So this is a message to all of the folks that are out there working on Flashbots and keeping this alive. You are actually going to increase the throughput of our chain more than you even realized.
04:50:42.532 - 04:51:24.840, Speaker A: And that is incredibly exciting. So that is my 15 minutes talk. Thanks, you all. All right. Thanks, Ben, for a very optimistic presentation and the shout out. So up next, we have our medic panel hosted by Hasu, and it is on the state and future of mev. And we have here our panelists, vitalik, Phil, Mahimna, Giorgios and Dan.
04:51:24.840 - 04:51:55.360, Speaker A: So, Hasu, anytime, when you're ready, the stage is yours. Yep. Thanks, Tina. Yeah, I'm super excited to moderate this very stacked panel with you guys. Why don't you start by introducing sorry, start my video. Okay. Why don't you start by introducing yourselves with, like, one sentence, starting with you, Vitalik.
04:51:55.360 - 04:52:13.636, Speaker A: Yeah, hello. I don't know. I'm Vitalik. I make posts on youth research from time to time. Dan. I'm dan. I'm a research partner at Paradigm, and I have to mention that both for me and Georgios, it's an investment firm, but none of what we say is investment advice.
04:52:13.636 - 04:52:31.980, Speaker A: And these are our own views that we're representing, not those of the fund. Mahimna. Hi, everyone. I'm Mahimna. I'm a PhD student at Cornell and a lot of my research has been focused on share ordering protocols. Okay. Phil hi, everyone, I'm Phil.
04:52:31.980 - 04:52:51.340, Speaker A: I'm a PhD student at Cornell also and co founder of Flashbots and coined the term MEB. Great. And finally, Georgios. Hey, everyone, I'm Georgios. I also work at Firedm. I'm a research partner. I do a lot of engineering and research work on Mev and have worked with Flashbots since the very beginning.
04:52:51.340 - 04:53:23.964, Speaker A: I'm very excited for this discussion. Thank you. Just in terms of structure, please. I'd like this to be a fluent conversation, so just feel free to interrupt each other and follow up on each other's points. That would be great. I start with maybe a controversial thesis. So Charlie Noise has argued in his first talk, one of our friends from Paradigm, that we have entered the era of mev and it's basically only going to go up from here.
04:53:23.964 - 04:54:13.230, Speaker A: But with all the amazing innovations that have already been showcased today and some more that we will see in the next block, could the mev era end much sooner than we expect? And just feel free to take it. I don't have any phil no, go ahead. I was just going to say that would be amazing. I'd be so happy if that happened and Flashbots can pivot to building the fairest markets out there. But yeah, that is the goal. I think it's one that will take a long time to truly achieve, but it's definitely my goal. I think there is definitely important types of mev that are not going away no matter how hard we try.
04:54:13.230 - 04:55:11.490, Speaker A: One simple example is just uniswap price arbitrage, right? Like in between one block N and block n plus one, there's 12 seconds of market movement on any exchange that's not on the ethereum blockchain itself. And so you can make uniswap trades off of that. You can make trades on every decks on top of that. And so I don't really see how something like that can even conceivably be removed entirely. I do expect that any deal will be reduced just because there's a fairly big incentive to reduce it. But there's also other types that seem to be harder to reduce. And I do think that gains from specialization in being a block builder is something that's going to continue to exist in the long term future to enough of an extent that we need to worry about it and design around it.
04:55:11.490 - 04:56:01.200, Speaker A: I agree with that. And I think not only are there kinds of mev that can't be eliminated, but attempts to eliminate them or naive attempts to do so often cause greater problems. And so, yeah, first rate of a block, first rate after a price movement. The way that this is resolved in traditional markets is just whoever gets their order executed first. And while that seems like the goal of a lot of sort of anti mev research or a possible goal, what that means is that there's a massive market in Colocation and in these arms races to communicate at as close as possible to the speed of light and have minimized distance as much as possible, which is just totally wasted. And so that's where the mev in traditional markets goes, is basically toward research into fiber optic cables and colocation fees. New York, Manhattan real estate.
04:56:01.200 - 04:56:46.700, Speaker A: Yeah, I think that's exactly right. I fundamentally do agree with you, Dan. And as much as I'm excited about reducing mev, I think that was my original research agenda. However, I think for a large amount of structural opportunities and a large amount of market design issues, it is necessary and it is kind of fundamental in my opinion. I have a blog post about this. People disagree, but I think for that kind of remaining mev that we do need democratizing, it is really the key one. Interesting anecdote here was back from 2017, back when the very first kind of gas market shenanigans started happening with ICOs.
04:56:46.700 - 04:57:25.752, Speaker A: At the beginning people were trying to get in front of everyone else by raising their gas prices. But then some projects really naively bans that by just banning gas prices above 50 GWe. And what that led to is like instead of trying to get ahead of everyone by sending one transaction with 1000 GWe, people just got ahead of everyone by sending 20 transactions with 50 GWe to increase the chance one of them would get in first. And so you ended up replacing competition with competition that has even more negative externalities. So it's definitely a good idea to try to avoid that. Yeah, and I told them that that would happen when they asked at one of the DevCons whether that was a solution. And I was like, no, people are just going to spam and then it happens.
04:57:25.752 - 04:58:06.868, Speaker A: So it was really funny. And I think that's a good analogy to also other protocols where people are like, oh look, there's no leader, everything's probabilistic, there's no mev here. But oftentimes just because you've made something probabilistic doesn't mean it's still not worth playing. I think I feel like there's some kind of mev that will exist in the system always, and that can be some kind of good mev like Arbitrage. But I do believe that most of the other mev that comes from ordering manipulation can be removed and to the point, or at least to the point where it's not worth it to go after that mev. And I think that's the goal that we should try to go for. I'd like to get your view, vitalik.
04:58:06.868 - 04:59:15.060, Speaker A: And also, Dan's, on an earlier point that you made about sort of Arbitrage dex arbitrage never disappearing from ethereum. So I kind of see two counterarguments to that. So for one, the share of RFQ orders among all Dex orders seems to be only going up. And this is a sort of decentralized exchange approach that does not generate any on chain mev, as far as I know. So first, what do you think about that? And second, couldn't you, in theory, design a decentralized exchange that gives the exchange operator sort of a first look in every block? So the exchange operator has an onchain cemented right to be the one who performs the Arbitrage, and only after that everyone else can trade? I guess my answer to that would be number one, yes, that's true. And that might reduce mev somewhat, but it's not going to reduce it by anywhere close to 100%. And my answer to two was like, yes, you can, and that's great, but that's not mev minimization.
04:59:15.060 - 05:00:09.588, Speaker A: That is mev extraction. And then it could be democratization depending on where the revenue for sort of auctioning off the first DIVS ends up going to. But that's not something that's in the minimization camp that's just kind of shoveling the mev around. Yeah, I think one example of that is IDEX. So when I first gave the Flash boys talk, a lot of people asked me what to do, and I said, I think my favorite design right now is like just having a centralized sequencer. And yes, all the mev is still there, but if you're legally obligated or business incentivized or whatever not to extract it, that's probably practically the best design for users where they get the least exploited, but it's also the least decentralized because in some ways you're centralizing that trust. So there's also, like, in my opinion, a fundamental trade off between mev and trust assumptions that's kind of in the efficiency.
05:00:09.588 - 05:01:25.050, Speaker A: Also, if you want to add sort of mev mitigation measures in your system, you reduce overhead. So if you wanted to lock, let's say, the first transaction to a certain person, you introduce an extra load operation, an extra state load operation on every transaction for every user, which is not ideal if you're trying to mitigate some certain component or exploit in your system. Okay, yeah, moving on. Another point that Charlie made in the same presentation was he argued that Time Bandit attacks, the fabled Time Bandits attacks from your paper will finally become real and quote unquote, short term, meaning wonderful block reorg frequency may increase. What does this group think about that? I think so far, every time I've underestimated how sophisticated mev would get an mev extraction tools. This is well before we invested in Flashbots, but every time I underestimated and Charlie would say like, no, they're going to do this crazy Sci-Fi thing, and then they started doing the crazy Sci-Fi thing. So I think in this I think I think multi block mev is only a matter of time.
05:01:25.050 - 05:02:35.480, Speaker A: I'm kind of surprised or skeptical if it isn't happening already. I think this is a question that we as flashbots should probably answer for the space in terms of our data efforts. But we've seen uncle banded attacks, we've seen inadvertent uncles and the way they affect bots and kind of block producers and arbitragers. So since we've seen these and they're benign and people are okay with them, who's to say that a few of the benign ones weren't actually intentional? There's also a post e two world where there's a small change in the protocol where instead of having the block producers being randomly elected now you know all the block producers for the next, let's say twelve minutes, which means that potentially collusion will be more likely there. Or as a validator maybe I get pseudo randomly assigned two or three or many continuous slots and that would make the extraction easier. Vitalk I think, may have some thoughts here. In particular, the example use case I have on my mind is just manipulating Uniswap Oracles.
05:02:35.480 - 05:03:21.016, Speaker A: You insert the last transaction in the block and then you insert the first transaction in the block and you do this for many blocks and you manipulate the T walk. I see it again. I guess that particular attack would be possible and maybe Uniswap would have to redesign their oracle. I guess, I don't know, I haven't thought about the details of that. There are other things that the completed switch to proof of stake will do though. One of them is that it'll make short reorgs basically impossible, right? Because unlike the current proof of work design where the fork choice basically has like one actor per block, the proof of stake fork choice has hundreds of actors that contribute to the fork choice in parallel. And so unless you control close to a majority there just isn't a way that you can revert someone else's block.
05:03:21.016 - 05:04:23.932, Speaker A: So that's one way in which proof of stake will improve things. Of course predictability of proposing is definitely an issue now. Of course we are going to add a single secret leader election at some point and that will probably come with penalties for revealing ahead of time when you're going to be the proposer. But if that happens then collusion will get harder but it'll still be possible for individual proposers to detect when they're going to have two or three blocks in a row and there is going to be things that I guess are possible as a result. But at the same time there is the question of like well how much is possible? That just isn't possible in the status quo world where I know sometimes you do just have one single block for a span of 45 seconds. I don't know. So I think even with single secret leader election you might be able to collude off band and prove to someone that you are chosen.
05:04:23.932 - 05:05:13.776, Speaker A: Yeah you can, right? Yeah you can. So this is why I suggested adding this. What I call an anti pre revelation game, which is like if the people who are colluding really trust each other, that's not going to solve it, but that'll still reduce the risk. Like basically if someone else tells you when they're going to create a block, then you can sort of anonymously predict that. And if you predict correctly that you can penalize them. I think still it will be possible, especially for kind of single pools, to do mev extraction off of a couple of blocks in a row that definitely will exist. So Phil, I don't think it's possible today for a searcher and Flashbots to propose to a miner to perform a reorg attack.
05:05:13.776 - 05:06:04.640, Speaker A: What would it take for this to become possible? And where do you stand on sort of allowing or disallowing the proposal of such blocks? I don't know. I think hop on the next roast and let's talk about it. I don't want to claim to speak for Flashpots here, since Flashbots is kind of a collective and we have to exercise the collective in making any decisions. That being said, we have no current plans to support anything like multi block reorgs. It is an incentive in the system, however, and our general philosophy as an organization is that in order to build systems that are robust, we should kind of either mitigate or work around any incentives that might have negative consequences to the system. So that is one of them. So a few approaches that could be possible.
05:06:04.640 - 05:07:06.148, Speaker A: One could be just letting it burn, trying to incentivize reorgs as much as possible and gaining robustness from statistical evidence that the incentive isn't strong enough for the reorg to happen. I think the big risk there is, especially around Black Swan events, reorgs become much more attractive. Another option could be a more active kind of economic kind of meta game design in which you create a system in which reorgang and attacking the system is less profitable than doing the right thing. And I think that's more the direction that we've been thinking in. But yes, definitely want to consider it in our security model and build tools around it because it is a real possibility. You once mentioned to me that you will allow miners or stakers to express preferences for the sort of bundles or block templates that they can buy. Would this be one of those preferences? Possibly, it's hard to say.
05:07:06.148 - 05:07:55.444, Speaker A: So I think the mission of Flashbots is to allow anyone to express any programmatic preference that is ethical to do so in a sustainable way. So the question is, can we allow that preference to be expressed ethically? I think if we have broader mitigations and we're using that in a principled way as part of a broader system, I don't see anything wrong with adding that feature. I think just adding it like willy nilly probably will destabilize the system needlessly and break social norms. So we don't really want to do that either. I see. And I have a last question for you about Flashbots. So could you briefly walk us to where you see Flashbots in two years and what are the biggest hurdles to getting there? It's really hard to say.
05:07:55.444 - 05:08:39.620, Speaker A: Like I said, Flashbots is very much like a research collective. So we're trying to answer in this next phase, we're kind of transitioning from phase zero, which was proving the concept, proving that there is a need to solve these questions and a strong market need. And I think we've done that very kind of well. And now we're transitioning into a phase where we're thinking, okay, now Flashbots looks like it's going to be around for a long time. What is its role in the ecosystem? What does the organization kind of look like? So I think those are all questions that are still being answered. We welcome people to participate. My personal vision is like, I would like to build kind of a Turing complete market for any kind of bot style preference and kind of an associated game around that much in the way we've been doing on top of ETH today.
05:08:39.620 - 05:09:22.400, Speaker A: So very much want to keep that momentum going and keep building community and also keep doing fundamental research and community events like this. I see. Thank you. So what was really interesting to me in the last block was the entire section on fair ordering. So Mahimna, you earlier defined sort of quote unquote sent ordering as ordering transactions in the order that they were sent. And you described this as fair. In your opinion, why does this not just succumb to the high frequency trading that you know? And this sort of picks up from what Dan said earlier, but I think it's a very interesting angle to explore.
05:09:22.400 - 05:10:27.844, Speaker A: So I was thinking about send ordering in sort of an ideal world where you have user trusted timestamps at the user side and you have some kind of synchronous network. So for send order in particular, there's no impact of the actual network delay. So it doesn't actually become high frequency trading. What you might be referring to probably is like receive order fairness, where you're thinking about sending the transaction and you're timestamping it at the time in which each node is receiving the transaction, which technically has the potential to be similar to high frequency trading if not done correctly. So in our paper, we distinguish between two different networks, like an external network and an internal network. So the external network is this network between the users and the protocol nodes. And if you can basically control this entire network, so you're this global adversary that can control the access for all users to that protocol nodes, then you can still arbitrarily reorder how muchEVER you want.
05:10:27.844 - 05:11:51.276, Speaker A: But in practice, this should not be the case. The other point I tried to make is other sort of networking layer solutions can be used for that layer in particular fair ordering, more so deals with once the transactions have been received. How do you classify fairness in terms of the ordering that were received? In and other sort of network layer solutions can be used for the first stage of sending the transactions from the users to the protocol nodes. So you can use things like hiding the transaction data so you can't front run based on it in that layer or other orthogonal techniques. Any follow up on that guys? How do you feel about fair ordering? Basically requiring that you corrupt the set that creates the ordering rather than just having one party? In a way, it does not seem to me that you're solving the problem, rather you're increasing the cost to attack by a constant. So it's not actually a constant because you're not corrupting the set. So let's say if you are in an l Two permission network, right, so you're taking the proposals from most of the nodes in the network.
05:11:51.276 - 05:12:43.152, Speaker A: So not like a constant, but if you have N nodes and you're taking them from two thirds of the nodes, so you do require a substantial more amount of corruption power. So it's not just a constant number that you're corrupting, it's basically almost all nodes that you need to corrupt. It seems to me that even if you have perfect send ordering, you're just incentivizing an arms race and essentially like processing and responding to news, right? There's still some kind of race where this value ends up going to whoever runs the fastest one of that. And that seems like a wasteful use of resources, right? So send order, as I said, doesn't actually be affected by the network latency. So it's not like not the network latency literally your transaction sending latency like something happens in the world and you react to it. Your reaction speed, your reflexes are what determines it. Right? Right.
05:12:43.152 - 05:13:30.620, Speaker A: I mean that you can argue provides some kind of unfairness, but I would say it's an open problem to whether that can even be solved. And that's something that even exists in any solution that you can find. I think I have one thesis which is that applications shouldn't try to have a heartbeat that is faster than the heartbeat of ethereum itself. So the twelve second block time. And so one consequence of that would be that you should use sort of batched auctions, for example, in a decks. Wouldn't this be just fundamentally even more fair than even the fairest ordering solution? Yes, that's a good question. I'd like to talk a little bit about batch auctions.
05:13:30.620 - 05:14:02.132, Speaker A: So when you're talking about batch auctions what you're saying is there's some l. One ordering service. And any transactions that are posted to this contract or smart contract that does this AMM it will take the transactions from the l. One. And the transactions that are relevant to it it'll batch them according to how they're posted on L. One. But that still hides the fact that the person ordering on L One can take advantage of their power on L One, so they can exclude transactions.
05:14:02.132 - 05:15:26.020, Speaker A: They can reorder even arbitrarily far right? So batch auctions, when you're considering it like a smart contract setting, is not really batch auctions because of the fact that or it's not really fair because of the fact that whoever controls the L One ordering can control the quote unquote batches in layer two. Now, I would like to draw this comparison between batch auctions and fair ordering, where you can think of batch auctions in a centralized fashion. So suppose there's only like one server for the exchange, and you send it to that server. Now, you can consider a batch auction based on transactions that were received by that server in that batch time, right? And what fair ordering tries to do is tries to distribute this over a network of servers. So now you don't have just one server that's receiving transactions, but you have end servers that's receiving transactions, or potentially like a large global network. Now, the question is, how do you do batches? Which is not obvious, right? You need to change the L One protocol, which is exactly what fair ordering does. How do you see the trade off between having mempool privacy and fair ordering? So when you say mempool privacy, does it mean hiding particular transactions in the mempool so you know they exist, but you don't know what they are or the entire mempool is dark? I guess that's a good question.
05:15:26.020 - 05:16:12.020, Speaker A: And as I understand it, is there even a way to make the entire mempool dark? Right? Because the miner can always see their own transaction. I don't know. So in the case of when you're adding privacy to the mempool, I think there's still a problem. Suppose you encrypt transactions that are in a mempool and you choose some random ordering within the mempool. That still leads to a problem of a flooding attack where you can just send thousands of transaction, and because the block space is limited, you can have a higher probability of your transaction being selected in the block. Right. On the other hand, with fair ordering, what we're trying to do is have a definitive way of ordering transactions that get processed into the network.
05:16:12.020 - 05:17:22.408, Speaker A: So basically, in order to, you can't do the same kind of flooding attack in a fair ordering protocol because you would still need to send those transactions at the same time. Like in a random ordering protocol, you can send those much later than a user transaction you're trying to front run. And if you send thousands of them with high probability, at least one of them will be sequenced before in a random ordering. I see. I have one for Georgios and then Vitalik. So why do you think that fair ordering protocols are often presented as sort of the diametrical opposite to what Flashbots is trying to do? Firstly, I don't think anything is a solution that solves everything. So basically I think that instead of having them as diametric opposites, we should have them as more like as you did in your talk, as more synergistic approaches, we use one to minimize the surface where possible, and where whatever remains, we try to auction it off in another way compared to the normal one.
05:17:22.408 - 05:18:10.584, Speaker A: So honestly, that narrative seems a bit misplaced to me, and I would prefer that it was more synergistic than not. I would agree with that. I think there's a lot of mischaracterization of the Flashbots narrative, which is possibly expected because I think Mevgeth was a relatively opinionated software release and it had a relatively widespread effect on the ecosystem and it's a very accelerationist piece of software. That being said, Flashbots does not start and end at Mevgeth. Like has a number of other research streams, activities, projects that I encourage you to take a look at and get involved with. And Fair Ordering has been there since day one, so we're definitely interested. If anyone wants to work on Fair Ordering, please reach out.
05:18:10.584 - 05:19:15.260, Speaker A: We're happy to fund that or help you do it in whatever way we can. Because I think I personally see it exactly the way Georgios does, where if it can be minimized and you get the same effect, why not do that? That's like a no brainer. That being said, I do still think it's somewhat fundamental, which is an open question, an open research question as well. And just to add on that, Phil, minimizing does not mean that the total number will not be large. The Mev surface is so large that I don't think that any minimization, let's say, techniques would get us to a point where searchers are not making money or miners are not making enough money from flashboards bundles. Yeah, I think that's true because fundamentally, searchers provide a service to the network. They're the ones that liquidate transactions and do the ARBs, and every single Flashbots transaction is doing some service for adapt, otherwise there wouldn't be any money in it except the ones that are hacking or doing other kind of unexpected things, but like the vast, vast majority of them.
05:19:15.260 - 05:20:05.630, Speaker A: And yeah, I think that the bots need to get paid enough to survive because that's like an existential thing for those applications. They need those bots. So in the long term equilibrium, I do agree with Georgios that there will be some very tight and efficient, but still kind of profitable marketplace. Dan, from you, I'd like to hear a bit about your experience in building unisop. So how much did you think about mev when designing unisop v three or even prior versions for unisop v three specifically? I think that a little obviously about how it affects the Oracle. The big discussion was about this weird sandwich attack that becomes more feasible in v. Three than v two, and that we've actually started to see now the strange variant on a sandwich attack.
05:20:05.630 - 05:21:02.988, Speaker A: Yeah, this was going to be my next question, so maybe to give the listeners some context. So, over the last weeks we have seen a new type of sandwich attack that doesn't target traders anymore, but LPs. And the way this works is the front runner deploys tens or even hundreds of millions of liquidity to Unisor pool just in time to front run an incoming trade and then capture the fee and then withdraw their liquidity right after. And as a result, they capture the fee without any of them permanent loss. So what are your thoughts on that? And does it mean that market makers and miners are actually converging right now? So we thought about that a lot. I think there are some ways that you could prevent it by charging a fee on depositing, liquidity or withdrawing, but all those have trade offs and hurt other things. I think ultimately what this is, is helping the user.
05:21:02.988 - 05:21:48.940, Speaker A: You're improving the price that the trader gets when they trade. And this is only profitable to do when the user is getting a worse trade than some centralized market maker would be able to give them. So, yes, you are sort of allowing someone to essentially use uniswap in the sort of hackish way, use it to provide price improvement to users and therefore intercept some of the fees yourself. This was always possible in uniswap, I think in V three makes it easier because it requires less capital. Ultimately it's an inefficient way to do this. And so if it's actually because you don't do two transactions and you got to buy the mev if you're going to do this, I think that means there must be like a big opportunity. And so ultimately I think those are going to be competed away anyway.
05:21:48.940 - 05:22:14.232, Speaker A: So I think right now it's probably better that it happened within uniswap than outside of it. And if you don't allow it like this, then a big opportunity like that certainly is going to get seized somehow by Dex aggregator, by someone else. So ultimately I didn't think it was a big problem. We'll see though experimentally we'll find out whether it's a big problem. Yeah. And I'd also maybe point out that concentrated liquidity does a lot to mitigate mev, actually. Right.
05:22:14.232 - 05:22:47.280, Speaker A: So I covered this in my own presentation earlier, but sandwich attacks are a function of price impact that you cause with your trade. Back running opportunities are a function of price impact that you cause with your trade and the lower the price impact of your trade is going to be. Hence the less mev you generate. So I think even so, PC does more than meets the eye in that regard. That's right. Yeah. So if we have no further comments on the Dex section, then I'd move on to the last block.
05:22:47.280 - 05:23:49.444, Speaker A: Vitalik, if you had the chance to completely redesign Ethereum, and I guess you do a little bit with these two with mev in mind, then what would you change? I would definitely just look into some of these ideas that allow you to separate block building from block proposing more. Aside from that, it's not super clear how much can actually be done. Add protocol layer, just find ways to design the protocol around the, around the expectation that kind of transaction selection and mempool logic is going to become more specialized. If you're going to accept that, there's a lot of other gains that you can get right. Like for example, you can make account abstraction much easier. So I guess think about and do some of all of those things. Yeah.
05:23:49.444 - 05:25:18.290, Speaker A: So I think roll ups are a great place to experiment with some of the protocol layer approaches to mev that have been discussed today. Are there any that you're particularly looking forward to? Well, I think some of the kind of thought leadership that optimism has been doing around this idea of like, hey, let's auction off sequencer rights and then take that revenue and use that revenue to fund public goods. So I guess they've been talking about for at least over a year now and is potentially really interesting. I kind of like this idea that basically ethereum can do some of these things at layer two, and so you can preserve the economic simplicity of the base layer. But then if you have public goods funding at layer two, and then you can kind of get back some of the benefits of these platforms that have on chain treasuries of different kinds, but you get those benefits without actually interfering with the monetary properties of the base layer itself. So that's interesting, but the one thing that I think would still needs to be done is you don't just want democratized extraction. You do also, I think, want at least some minimization and basically ways to kind of detect sequencers that are doing a bad job and potentially voting them out or something like that.
05:25:18.290 - 05:26:45.630, Speaker A: Basically, I do think that there's an opportunity to be sort of a little bit more governance activist there because the costs of governance breaking are lower than if those costs were at layer one, because ultimately you still have your fallbacks, you're still guaranteed safety, you're still guaranteed censorship, resistance after a delay and so forth. The other interesting thing that roll ups potentially could do is they could add some notion of transaction preselection and transaction. Or this was the OMG proposal back then. I'm not sure how much of this OMG is actually implemented right, but they wanted to have some kind of more centralized delegated proof of stake style consensus that would make off chain agreements on transactions, and then they would give users fast reconfirmations and then they would submit badges to chain once every couple of minutes. We could also do that with it too, I guess, providing pre confirmation because, you know, the validator ahead of time. I also think that Solana does a variant of that where if each block, let's say, takes 400 milliseconds to get produced, you can anchor your transaction into, let's say, sub slot times. So we could try doing something like that to improve latency on our system.
05:26:45.630 - 05:27:33.180, Speaker A: Yeah, I think that stuff's interesting too. The other thing that ethereum sharding is considering is staggering the publication of the Shards. So there's always going to be one shard that publishes something within 1 second. And so if you want to get data in quickly, you can just select the shard that does that. And then theory would be that roll ups would have a way of kind of building around that. But I guess we'll see how that goes. Because making experienced block times faster is itself a type of mev minimization, right? Because if you have two N transactions, then the amounts of reorderings is like two N in brackets factorial, but then if you split them in half, then you have N factorial squared and that's strictly smaller.
05:27:33.180 - 05:28:34.512, Speaker A: There's also the argument, though, that shorter block times make it easier to mask short reorgs, which would be very possible. Well, I guess in this particular case, one of the benefits of the Ethereum sharding is that there's just lots of different actors involved, there's lots of different block proposers, there's these large committees of attesters, so it is hard to do any of that stuff until you get fairly close to the 50% mark. But so far this is all conjecture, so we'll see how it goes. What we haven't really seen so far, but I'm sure we will see a lot of in the future, is cross chain mev. George, could you maybe give an example of how that could look like in practice? Maybe we have chain A and chain B. Let's say one is optimism, the other is Arbitrum, or maybe two are optimism chains. Doesn't really matter.
05:28:34.512 - 05:29:57.580, Speaker A: If you want to send a message from one chain to another, you need to somehow relay the message after you've committed to it on the sending chain and relay to the receiving chain. And if there's many messages and there's no way to commit on the ordering on the sending side, firstly the relayer could just reorder the messages as they relay them on the receiving chain. Or they could simply, if ordering is committed, maybe they can simply choose to delay and just not publish a message on the receiving chain. And an example would be if you're doing a cross chain arbitrage where your transaction needs to get somewhere within some time, because that's the window when it's economically profitable, but maybe the relay takes too long to relate and as a result it doesn't work. So probably what will happen with crosschain transactions will be that we'll have some form of liquidity providers and channels to make transaction latency lower or some other protocol like cello's optics by James firstwich which would be some alternative to having lower latency message passing while preserving some notion of ordering. Hey, thank you. That makes sense.
05:29:57.580 - 05:31:15.644, Speaker A: And also maybe like in the cosmo somewhere where that thesis will be stress tested, I think will be probably the Cosmos ecosystem with IBC. I would like to argue, actually, and this is a point I made in my talk as well, that if you have two sort of cross chains that each have some kind of fair ordering protocol running on it, the cross chain mev might not be actually large as you would expect, because even if they're different definitions of fairness, their orderings might actually not be that different. This is just a conjecture, but I think it's an interesting open problem. Yeah, I'm actually out of questions since we skipped a few. So if we don't have any questions from the audience, we can check the chat, the zoom chat. I have one while we wait without knowing anything, in two years from now, you guys need to make a massive trade. Are you going to go on the fair sequence roll up, or are you going to go on the mev auction roll up? Why not both? Because okay, both at the same time.
05:31:15.644 - 05:31:42.544, Speaker A: You'll do half your trade on each one. See, here's the thing, Phil. Dollar cost average. Georgios, is that what you do? You. Here's the thing, Phil. Everyone here except me has vested financial interest in one of these solutions. I literally have no vested interest in chainlink, no vested interest in Arbitrum, no vested interest in you know, follow the money and you'll reach your answers.
05:31:42.544 - 05:32:19.696, Speaker A: Everyone. I don't think Flashbots has a business plan. So other than Dan and Know burning their VC money under our sorry, sorry, LP paradigm, in some know, Flashbots is funded by paradigm. Yeah, I mean, obviously we do want to be sustainable, but I think at least my goal is not to make money. My goal is for cryptocurrency to succeed. And yeah, I think my track record on that front kind of speaks for itself. I would trade it on the Fairer sequencing chain.
05:32:19.696 - 05:33:03.520, Speaker A: I don't know why you wouldn't. I think the argument that mev is inevitable is different from the argument that you should just walk right into an mev wall if you have another choice. Yeah, I'm actually with Dan here, like, as a user, why shouldn't I prefer, in that case, the ordering chain, right? It's fine that the operator or some public funding source gets the mev that's extracted on that chain, but doesn't mean that I get it. That is true, but I also didn't say the liquidity or usage is equal. So I think your assumption that you'll get better execution is what I would call into question, making the personal decision myself. But I see your point and totally reasonable decision. I don't disagree necessarily.
05:33:03.520 - 05:33:21.790, Speaker A: I just wanted to troll a little. Yeah, certainly successful. So you would argue that basically the mev chain would get more adoption and more liquidity. That makes it better. I don't know. I think optimism versus Arbitrum is the first round of this testing, this hypothesis. So I'm open to whatever happens.
05:33:21.790 - 05:34:09.300, Speaker A: Either universe is, I think, fine. I mean, I would argue how many users would actually use selling to the highest bidder if they knew the true cost. So just to kind of give a very weird example, like Robinhood, right, it offers free trades, but users actually don't know the cost of the free trades that they're giving. There was this filing from the SEC last December that users, if they just used some other brokerage that didn't offer free trades, they would have made like $34 million more even if they paid for those brokerage trading fees than they would just make, like using Robin Hood. Yeah, but that's a terrible argument. It sells order flow and actually users get a worse price. They would have made way more money even if they just paid for transaction fees in another brokerage.
05:34:09.300 - 05:34:43.956, Speaker A: I agree with you, although I think doing that study without thinking about the market impact of the order flow activity is probably how it was done and is like a little bit of a flawed methodology, but on that I agree with you. But my counterargument is that payment for order flow is like the number one model right now as is same as ad revenue on the Internet. Right. They're both very suboptimal models, but very clearly what the market wants. And every single brokerage is moving towards it because they don't have a choice because people don't want to pay for trades anymore because they're just not used to it. No, it's because they realize they can make more money that way. The brokerage can make more money that way.
05:34:43.956 - 05:35:22.690, Speaker A: Like Robin Hood made $300 million of they make more money because people want to trade there and pay the higher implicit fee versus the higher explicit fee. Right? Like, if they charge $20 a trade and people wanted to pay that know the real cost of what their transactions are actually costing them, would they want to do something like that? Would they actually want free trades? Who knows? I think it's an open question. Like, would users want to pay for Facebook to not have their data sold? I think is another version of the same. Yeah, yeah. As much as I wish the answer was different in both cases, to me, the market has very clearly spoken in both. So? Yeah. I don't know.
05:35:22.690 - 05:35:55.848, Speaker A: Okay, great, guys, who wouldn't have guessed that the last six minutes after I ran out of question would be the most entertaining one? So thanks Vitalik, Dan, Georgia, Mahina, and Phil for joining this panel. And thanks everyone for listening. Have a great night. Thanks, everyone. Thanks, everyone. Perfect timing. This perfectly rounded up our part three, which is protocol level response to mev.
05:35:55.848 - 05:36:41.820, Speaker A: Up next, we have. An entire section on application level responses to mev, starting with Mev and DeFi, a very exciting talk to be given by Tom Schmidt how to redesign your DeFi protocol around mev. It is the new frontier for DeFi design. Tom, whenever you're ready, the stage is yours. Please feel free to share screen now. All right, cool one. Can everyone see my screen? Yes.
05:36:41.820 - 05:36:59.164, Speaker A: Cool. This look good. All right, great. Hi, everyone. I'm Tom Schmant. I'm a partner at Dragonfly Capital. We're a crypto venture fund, and this is fantastic extractable value and Where to not Find it, which may be a little different than the title that was given, just to be totally self contained.
05:36:59.164 - 05:37:38.776, Speaker A: I'm going to give a very brief overview of Mev. Generally speaking, smart contract platforms or blockchains, they specify transaction, correctness? But they don't really ordering. So there's sort of an assumption that, hey, within a block, transactions should be ordered by gas price, right? They should be ordered by people who want to pay the most to people who want to pay the least. It's an auction, but it's not actually mandatory, it's not specified. And even within there, it's difficult to know, hey, if two people want to do the same transaction, and how do we know which transaction was broadcast first? The Mempool is sort of global. It's really hard to know. How should transaction ordering be done? Fairly and normally.
05:37:38.776 - 05:39:03.064, Speaker A: This isn't really a big deal, right, with something like Bitcoin? If I were just sending money back and forth, I don't really care that much if you send your Bitcoin before I send my Bitcoin for most purposes. But on a smart contract platform, these transactions have economic value where maybe there's a really good trade opportunity and I want to get it before you do, or maybe there's an arbitrage, or maybe there's a liquidation, and I want to get it before you can get access to it. And so there's actually really large amounts of value being held in the ability to sort of arbitrarily reorder or exclude transactions from a block. And so Mev sort of refers to this idea, which is there's value in transaction ordering, specifically when there's economic activity occurring. And so a lot of the problem space that we explore, sort of discusses around, well, how do you minimize mev? How do you redistribute mev? Who should actually get access to that value? Because it continues to grow, the more so economic activity actually occurs on these platforms. So a couple of different, very more specific flavors of what that looks like when we talk about liquidations. Most lending platforms today compound Ave Maker when a loan becomes under collateralized or sort of under the required LTV threshold, anybody can step in and basically recapitalize a loan and penalize the initial borrower with a small penalty so I can come in and basically top up your underwater loan and get money for it.
05:39:03.064 - 05:39:45.652, Speaker A: And for most designs right now, it's a first come first serve scheme where the first person to actually go in and recapitalize a loan gets that 5% bonus or 13% bonus or whatever it happens to be. And so there's this massive race to actually win that money. And we sort of see this in the chart on the right, which is Duetti X liquidations over time, which slowly and slowly get more competitive. This is every new color is a new address and you can see they're all sort of competing with each other to design new strategies and be the first one to get that very limited set of opportunities. So liquidations are only a very small percentage of the total mev space, but they're very competitive. Another sort of segment and chunk that we talked about is sort of around decentralized exchange. And there are a couple of different flavors again within here.
05:39:45.652 - 05:40:21.200, Speaker A: Front running again, pretty straightforward. If you see someone who's about to get a good trade deal, their transactions are sort of floating in the mempool. Maybe you should go and get it before them, and you can sort of get a really cheap asset before somebody else has a chance to buy it back. Running is similar, but a little bit different. Where with an AMM, if I make a trade and maybe I introduce too much slippage. So the mid price of the AMM moves dramatically off of market. An ARB opportunity pops up where someone else can come in and basically sell that really overpriced asset back to the LPs, back to the AMM and lock in a nice profit that way.
05:40:21.200 - 05:41:14.092, Speaker A: Sandwiching is sort of a combination of the two where if I see you about to go and make a large trade, I can buy that asset before you. So sort of move up the price that your trade is going to get executed at, you're now going to buy at a higher price and get a worse execution and then I'm going to then come back and sell that really marked up asset back to the LPs. And so I'm sort of profiting both ways. So there's even more flavors like that within the deck space, but at a high level. Overview these give you maybe some more concrete ideas of what does mev mean when it comes to being in DeFi and why are we even talking about this? This sounds kind of esoteric. Well, it's actually a pretty big deal. Millions of dollars a day get made by reordering transactions and extracting this mev by winning these liquidations, winning these Arbitrages.
05:41:14.092 - 05:42:53.740, Speaker A: And there doesn't really seem to be any sign that it's slowing down. It just continually grow day over day, month over month. And I think a kind of bigger point beyond just the monetary angle is mev doesn't exist in a vacuum. When mev gets really large, it can really degrade the user experience. People really want clean, deterministic experiences when they use a blockchain, they don't want their transaction to fail when they want to make a trade because someone's front running them people want good executions, right? People don't want to get their faces totally ripped off and so if experience of using a blockchain or using something like ethereum can use to degrade that can be really bad and sort of stop us from achieving the vision and the mission that we have. Additionally mev kind of must be extracted for chain security which is a point Phil made in his blog post which I tend to agree with which is basically you want everybody to be making as much money as possible if they're a miner because if you don't you have sort of adverse selection right? The people who can make more money mining are going to mine more often and that might centralize control of the chain within their purview right? If I have really cheap electricity I might be able to mine more than someone that's inexpensive electricity and the same thing happens with mev where if I'm able to make more money per unit by extracting this mev I'm going to be mining more than you will and that obviously affects chain security. We've sort of seen mev is a big thing it's important for reasons beyond sort of the clear monetary reasons I think the analogy I sort of think of is when there's high gas prices devs start to optimize for low gas usages, right? They start to gas golf their contracts to drop down the actual gas price of executing.
05:42:53.740 - 05:43:25.480, Speaker A: They look at other chains, they look at roll ups. They try to do things to minimize gas usage. I think right now we're in sort of a high any view environment. So what are Devs doing basically in response to sort of this change in the ecosystem? And I think sort of one way to think about it is it's sort of like any ecosystem where when there's outside pressure there's outside influence it's going to change. Things are not static. So this is the Tawny owl. It's an owl in sort of northern Scandinavia generally comes in sort of one or two colors.
05:43:25.480 - 05:44:01.576, Speaker A: Sort of this brown color on the left, which obviously blends in better. With the woods and then the sort of gray white color on the right which blends in better with the snow. And basically, as a result of climate change winters are getting warmer, there's less snow. And so basically this brown variant of the owl has sort of been outcompeting and winning out over this white version of the owl and I think of mev and sort of as a similar sort of evolutionary pressure where you have this new predator. You have this new thing that's entering the ecosystem and you have to figure out what you're going to do. You have to basically adapt or die. And I think that's sort of the most interesting area of exploration for me right now.
05:44:01.576 - 05:45:10.188, Speaker A: Within DeFi, specifically, what do if you're a developer? Well, one option is you can just sort of roll over and die. And so this is just some random block that I pulled off of the polygon explorer, but it's pretty endemic. And I think most people who use polygon on a regular basis will sort of relate to this in some way. Where getting a sales transaction, getting front run, having someone else scoop in front of your trade, it's a pretty common feature. And so I think if you don't do anything, of course profit motivated individuals will go and find ways to go extract nev and that could really ruin the user experience if you're a protocol dev or if you're an application dev. Another sort of thing teams are doing is basically embracing it and saying, hey, mev is going to happen, but we should at least benefit from it, right? Like someone's going to get screwed either way, so let's find some way to actually like capture some of that for ourselves. And as was sort of discussed in the past few panels, a lot of L two s are looking this way where they're like, hey, we should actually be able to get some of the mev that's going to occur in our roll up because we don't want to give that away.
05:45:10.188 - 05:46:27.392, Speaker A: It's a potential business source and I'd rather have it be internal than have it be sort of externalized and given away to some random bot. And I think there's maybe even a path forward where maybe DApps take their own mev and they give it a token holder so they hold it in the treasury. To a certain extent, all users are equal, but maybe some users are more equal than others and maybe some people deserve the mev more so than some random bot or some random miner somewhere. I think the third option is kind of the most interesting and more likely, most likely, which is you can prevent it by adapting. And so when I think about what's the problem here? What are sort of the constraints that we can play with? The main issue basically, or the main sort of problem, is that transactions on Ethereum, they can most of the time be made by any arbitrary address and the transactions are all the information within the transaction is public and while the transaction is waiting to get mined, it's sitting in a public mempool. So anyone can come in, they can see exactly what you're doing and they can see your actual transaction while it's waiting in that public mem pool. So you're just sort of a sitting goose or sitting duck while you're, while you're just waiting there waiting for your transaction to get mined.
05:46:27.392 - 05:47:10.400, Speaker A: So we sort of have this RBOT deployer on the right just absolutely copying this random user, trying to make a nice little trade. So I think when we think about the design space, it's like, well, how can we change some of these assumptions, right? How can we make it so maybe it's not any arbitrary address. How can we make it so it's not a public mempool? How can we make it so it's a public mempool. But maybe the transaction contents aren't public and that's sort of the place that I would say most devs are sort of sort of playing with. So you want to prevent mev, what do you do? Well, one option is just hide it. And with hiding it, again, takes a couple of different forms. One of the more popular forms, especially for application devs, is to get rid of that public mempool that we just talked about and instead just send the transaction right to a minor.
05:47:10.400 - 05:47:50.944, Speaker A: The mempool is not required. I can just pay a minor directly to mine my transaction and then I avoid the whole mev issue entirely. So 1inchh has this integrated archer swap has this integrated where I can check a box and they will send my transaction not to a mempool, but they'll send it directly to Flashpots or Tai Chi network and then a miner will just mine it. It's great because my transaction is not going to fail and I'm not going to get front run. And so we see more and more devs moving this way and I suspect that this will also be an increasingly popular option as it becomes more easy to integrate. So again, you just sort of get rid of this public mempool issue. Unfortunately, you also do have to trust the person that you're working with in order to do it right.
05:47:50.944 - 05:48:24.136, Speaker A: You could send this to Tai chi network and then they could go and frontrun you. So probably not an optimal long term solution, but certainly it's feasible. Right now, another option is sort of playing with like a semi private or semi public mempool. So it's not quite the same as the private transaction, but it sort of achieves the same effect with no trust. So Keeperdao's Hiding book is sort of like this where it's only really accessible to whitelisted bots so people can see it but they can't really get access to it. So I can submit a transaction and you can submit a transaction. It's sort of hiding in this sort of pseudo public mem pool.
05:48:24.136 - 05:49:17.624, Speaker A: These whitelisted bots can come along, see our transactions, mine them for us, and then they can send that mev back to users. So it's kind of a public transaction but it's kind of not a public transaction. But in any scenario, that mev is still sent back to us at the end of the day. And then the last sort of solution here is again, these are public transactions in the public mem pool, but the contents of the transaction are not public. So one of the again, sort of throwback one of the popular ways people used to do this and I think Micro actually covered a lot of this in her talk is using Lisa Marine or submarine sends, which is a commit reveal scheme where users basically send transactions, send first transaction that has the content of their transaction and sort of the value that they want to send. But it's obviously all encrypted. And then in a later transaction, maybe even in a later block, then they send the reveal which actually executes the transaction.
05:49:17.624 - 05:50:03.224, Speaker A: And so, obviously, there's a lot of UX overhead and it's not ideal for all scenarios, but you're still going through a public mem pool and you're still sort of having a minor mine. You but because the actual transaction contents are encrypted until a later date. You're kind of safe, for the most part, from flash bot coming in and totally ripping your face off and sandwiching you. Or Arbitraging, whatever it might actually be. So there's a couple of different scenarios people use to hide mev either by sort of isolating themselves from the mem pool or sort of encrypting the transaction contents. But another sort of scenario or another sort of solution that some people are employing is to just unionize. So instead of hiding the nev, let's at least take it for ourselves.
05:50:03.224 - 05:51:02.888, Speaker A: Instead of just letting anybody else, like let a minor let a bot take it. So B protocol is an example of this where B protocol holds onto users compound positions and then co invests. So in reality, your liquidation buffer is actually a little bit better than it would normally be because they sort of co deposit alongside you. And so that means that if you fall below that new liquidation buffer from what B protocol is invested alongside you, you're not actually liquidatable on compound because you still have the buffer on compound itself, but you're liquidatable on B protocol, right? They say, hey, actually you're below our liquidation buffer, but you're not below the liquidation buffer on compound. And that means that whitelisted addresses within B protocol can liquidate you and sort of recolateralize the system, but those profits are then redistributed back to yourself. So hey, maybe you get liquidated but you get account of that fee. And so in reality it's a little bit better than just sort of being raw and being exposed on something like compound and going back to an earlier slide keeper.
05:51:02.888 - 05:52:06.524, Speaker A: Dao and the hiding game It's sort of a generalized version of this, but they have a very directly applicable version with K compound sort of the exact same idea where, hey, let's create our own little sort of like pseudo little network or pseudo ecosystem within something like compound or within something like Maker. And then it's only accessible to whitelisted addresses. And then when people do those liquidations, we distribute the fees amongst all the users as opposed to having some random compound bot come in and sort of knife you with the liquidation. But these are all sort of co op model, right, where it's, you know, some of these go back to a Dow Treasury or some of these go back to token holders. But this is also possible on an individual level. So Blockstrap has made this service called Backrun Me, where if you're going to make a trade on an A M such as Uniswap or SushiSwap, they will then see if you're introducing a backRunning opportunity, basically an arbitrage like are you moving the mid market price too much? And they will come in and they will basically create a bundle. They will backrun you on your behalf and give you a cut back of the arbitrage that you introduce.
05:52:06.524 - 05:52:56.130, Speaker A: So instead of having it be sort of co op know, you sort of have this handshake agreement with Blocksroute where they just give you back a cut of the arbitrage of the slippage that you're, you know it's again, sort of unionized, but not in sort of this token holder dow style way. It's just someone's providing a really nice service for you. DeFi Savers are doing the same thing with Be protocol as well where DeFi Saver will just go and sort of save your position for you but they won't actually sort of distribute it to some sort of Dow or something like that. And so ultimately there's maybe a little bit of a risk here. You don't want the pinkerton miners to come in and bust the faces off of a bunch of DeFi Dgen traders. There's definitely risk to unionizing. And so maybe the answer is instead of unionizing, maybe we should just evolve, maybe we seem to change.
05:52:56.130 - 05:53:46.260, Speaker A: And I think this is definitely a possibility where some protocols might just be too mevable to be salvaged. It's like trying to make a faster course. And you see this a little bit with a lot of the on chain order books in the early days like Oasis or arguably Kyber was sort of their reserve model where it's like, okay, maybe even earlier early version of Synthetics where it's just like there's just too much back running, there's too much front running. It's just too easy to get mev'd. And so this maybe isn't really a feasible model for the stage of ethereum that it's at today. And so maybe we just need something to do, something different. And I would argue that sort of the rise of RFQs in the last few months or so are sort of representative of this where this graph on the right is one inch volumes by protocol and excluding dodo which I think had sort of a weird sort of fluke or sort of spike over the past month or so.
05:53:46.260 - 05:54:22.524, Speaker A: RFQs, when you look at this one is native RFQ, zero x, cash flow. All those RFQs combined. Now they're second largest source of liquidity, second largest source of volume behind Uniswap E three. So they're larger than Curve, larger than Univ two, larger than Sushi because these RFQ models don't have mev. When you make a model with RFQ, when you make an order, you specify a specific taker address. So again, you don't have this arbitrary address issue where some random bot can come in and sort of fill your order. Your order is made for you, specifically made for your address, and so it can only be filled by you.
05:54:22.524 - 05:55:25.556, Speaker A: And if it's not, then no one else can come in and take it. And so it's actually like a sort of novel approach to sort of old school, but sort of a novel approach to how to get around mev and get around some of these gas issues. And I think maybe Phil was mentioning this earlier, but again, this is all maybe even a little bit of throwback to sort of centralized coordinators matching engines on some of the early order book DEXes like Paradex or dYdX, where we all can sort of sign our intents to trade. We have one trustworthy entity that actually does all the executions, so there's no arbitrary address, no one else can come in and fill. And it's in their business interest to fill correctly, right? Like if you're the matching engine on FTX or on dYdX, you don't want to be ripping off your users because if you are, they will see it and they'll move and they'll go somewhere else. And so you want to be as fair as possible when it comes to actually doing execution. Cowswap is, I would say, sort of the closest analog today where they hear sort of a decentralized network of participants that basically act as a matching engine where different people sign their intents to trade again, sort of like a bid out.
05:55:25.556 - 05:56:22.772, Speaker A: Order and ask order and then when they overlap, they have their sort of decentralized group of bots actually do the matching. So when you limit the number of addresses that can actually interact and you sort of delegate it to them, you can actually get rid of a lot of any of that that exists. And sometimes you don't even actually have to modify the protocol that much. Maker is a great example where Maker liquidations V One, where again, we're sort of in this classic style of lending liquidations, where it's first come, first serve massive bonus to whoever could come in and recapitalize the protocol. But in reality, sometimes that was way too punitive when Volatility was low. Maybe it was not punitive enough when Volatility was super high. And so Maker has moved to using Dutch auctions in V Two where basically people can enter and do the liquidation at the price that they think is fair, as opposed to having one fixed price and having everybody sort of rush to enter.
05:56:22.772 - 05:57:23.268, Speaker A: And so Euler is working on sort of a similar thing where basically the liquidation penalty increases by the amount that the loan is underwater. And so having these sort of scalar compensation systems as opposed to having some one fixed compensation and having everybody sort of rush in the door to sort of fit in is sort of a way to get around mev. Because everyone sort of choose the price can choose the price that they think is fair, as opposed to having one fixed price and having everyone sort of try to outbid each other. So a couple of different options you have as a developer right now but what is this thing going to look like? The space is evolving so quickly it's kind of incredible. Where do we think the future is going to go? One possible scenario is everyone just constantly getting their face ripped off forever and it just kind of sucks to use ethereum but you got to use it. But I think maybe another potential scenario is sort of more dowification where maybe you have to be part of a particular dow and a dow can take many different forms. It can be holding a token, it can be holding an NFT or whatever.
05:57:23.268 - 05:58:39.980, Speaker A: Maybe you have to be part of this dow in order to trade on a particular AMM or use a particular protocol call if you're a bad actor or you're sandwiching people, you're a bot, then you get kicked out and you don't get access to this thing. Or maybe use products like Archx or Know your farmer to look at people's past on chain activity as sort of a civil resistance mechanism. So hey, if you haven't traded on Uniswap in the past six months maybe you're a bot and if you try to trade on our exchange we're going to ban you. And so again you're sort of getting around this sort of arbitrary address issue and certainly you could say hey, maybe this is exclusionary but it's only exclusionary to sort of bots and people who would maybe civil attack by spinning up a bunch of addresses. If you're a normal human there's plenty of ways to get access to these things. So maybe that's sort of what the future looks like is we don't allow just any random address to interact but we have some sort of minimum bar that people have to get over in order to use these know, I'm assuming applications also even experiment with running their own application specific roll up right? Like, if I'm uniswap or if I'm compound, why do I want my mev going to spark pool or coinbase or random bots that should be going back to uniswap and the treasury and uni token holders? So maybe I run my own chain. I extract that mev and then that goes back to uni token holders or uni treasury.
05:58:39.980 - 05:59:27.392, Speaker A: So again it's sort of going back to that sort of unionized co op model but taking even a step further where we're sort of circling the wagons. I also think just the mev space continues to get more competitive compressing margins on mev bots, mev clearinghouses and miners mining dao being a great example of this where they sort of take what Flashbots is doing it but doing it sort of all on chain. And so again the more transparent, the more accessible you make these things. As Flashbots is obviously done with Mev overall sort of the more you just compress margins because you have more players with more information. Additionally, mining right now is sort of very specialized and inaccessible. The vast majority of people don't mind. But what happens when anybody can be a miner with POS, right? There's going to be way more people running nodes or using a node mining service maybe.
05:59:27.392 - 06:00:19.520, Speaker A: In that case extracting mev is a lot more palatable or a lot more accessible, right? Like maybe the stakefishes and the stakes and the lidos of the world. Maybe they end up offering generalized threat running as a service and they have to sort of offer that to users because the overlap between Ethereum users and miners becomes a lot tighter than it is today. And maybe this is just a sort of temporary blip in the history of Ethereum. I think the jury still out when it comes to what happens in a proof of stake world. I suspect a lot of large mining pools or a lot of large staking pools such as Coinbase or Binance or Lido might refuse to participate in mev just simply due to the negative optics, right? If I'm Coinbase, I'm a public company, I'm not going to be known for ripping users'faces off by participating in mev. I'm just going to allow the PGA to happen or whatever. I'm not going to actually participate in it.
06:00:19.520 - 06:01:12.872, Speaker A: Or maybe I introduce some sort of other fair ordering mechanism. But I think a lot of these people are not necessarily maximally profit motivated and so they might have a lot of issues with actually extracting any V. And I think generalized again roll ups might just take any present for themselves which sort of excludes searchers. So optimism just does it themselves and searchers sort of get excluded or maybe protocols sort of enforce using verifiable delay functions in order to randomize transaction ordering. And so again, all these are sort of potential ways that we might see sort of the mev market space sort of decline over time where people refuse to play ball, people refuse to participate in this transaction ordering game or it just becomes not even feasible to participate at all. So thank you. These are all sort of just thoughts and ideas that I've had but I think mebase space is obviously super interesting and very much evolving.
06:01:12.872 - 06:01:57.196, Speaker A: So I look forward to continue investing and researching with you all. Thank you Tom, our frequent guest on WTF. Another stellar overview presentation on a really tough topic in a really new emergent area. So up next we have a few sections. We have 4.2 section 4.2 mev mitigations and we have well sorry your time is not up and mev redistribution.
06:01:57.196 - 06:02:27.216, Speaker A: And lastly, hybrid model for mev minimization and democratization. So first off we start out with four lightning talks. The first one being by Felix from Cowswap. And Gnosis on batch auctions and off chain ordering. So Felix, feel free to share screen now. You have ten minutes. Cool.
06:02:27.216 - 06:03:31.830, Speaker A: Yeah. Thank you very much. I'm very excited to talk about Cowswap to you guys today. Cowswap is kind of the first application, the first trading interface that we have built on top of Gnosis Protocol version two, which is the underlying trading mechanism. And Gnosis Protocol is trying to prevent mev by employing batch auctions and uniform clearing prices as a kind of separate trading mechanism compared to what we know from Ethereum today. So let's take a look at you can basically take any random block on Ethereum today and you're very likely to going to find a couple of trades on the same token pair potentially even on the same protocol, different indices, which will have sometimes slightly but sometimes also significantly different prices. And this just comes from the fact how the underlying protocols work, that they basically give a price time priority and the ordering at which transactions are executed even within a block matter.
06:03:31.830 - 06:04:32.296, Speaker A: And this kind of concept makes sense in traditional finance where we have continuous markets and where we can actually execute trades kind of all the time. And we want to incentivize traders to act as fast as possible and kind of incorporate new information as fast as possible into the market price so that the market is very efficient and kind of resembles all the real world information that is out there as efficiently as possible. And even in the traditional space, there's people arguing that kind of this arm's race nanoseconds milliseconds to incorporate new information might not be actually best useful compared to the externalities that it costs and are even advertising for batch auction in kind of that sense. But then that is kind of this continuous market, traditional finance. If we go back to the Ethereum space, we really only get new information every 12 seconds when a new block is mined. And then we get a bunch of new information in the form of multiple transactions. But if you look at these transactions, they are all really just mined at the exact same time.
06:04:32.296 - 06:05:31.660, Speaker A: So kind of this notion of employing a price time priority within a single block to us is not really meaningful. And I mean, frankly, this is the reason why Mev exists in the first place and why we are here. And so in Gnosis Protocol version two, but also Innosis protocol version one, kind of our vision is that at least within a single block, trades that happen on the same token pair should, regardless of their index, regardless of their ordering, all receive the same uniform clearing price. There shouldn't be a difference if you're first or second or third. Everyone, every trade that happens in one block or for the matter of batch auctions in one batch receives the same uniform clearing price. So how do we get there? There's two main ideas that we need to incorporate. The first thing is we need to stop people from giving their trade execution in form of raw Ethereum transactions directly to the miners.
06:05:31.660 - 06:06:41.120, Speaker A: Because we've seen miners are not acting in your best interest if you don't use technologies like MEB guest, they're just going to take your transaction and trying to extract as much value from it as they possibly can. So they're not acting in our best interest. What we should do instead. And what nosis protocol does is instead of signing a directly executable transaction, the user just signs kind of Intent to trade, basically saying, I'm willing to buy Token A for Token B at a certain limit price, maybe with a certain deadline, and it then hands off this abstract intent to trade to a third party, which maybe in the traditional sense would have been called relayer. In Gnosis Protocol V two, this party is called Solver and that is basically it's a professional player which can execute the transaction of the user much better than the average MetaMask user would be able to. The solver can employ kind of professional price estimation for what gas price to pick. It can even use tools like flashboards mev gas to make sure that it is in itself mev resistant.
06:06:41.120 - 06:07:29.360, Speaker A: It can look on chain for the best path at execution time. If this path is no longer available because there's race conditions, it can reroute the trade. And so overall, this kind of professional party can just do trade execution much better than the average user can. Now, you might ask why would the solver have an interest to actually act on behalf of the user in their best interest? The first answer is kind of, well, there's a longer lasting relationship between the user and kind of this network of solvers. But also, at least in Protocol V two, each solver is bonded financially inside the protocol. And if it extracts value from a user which is most often provable after the fact. The protocol can penalize the solver and could actually refund the user from the penalty that is taken.
06:07:29.360 - 06:08:38.040, Speaker A: So we have bonded solvers which can do trade execution much better than the user. Another aspect of kind of this extra layer of indirection is that now not only can we settle each intent to trade individually, we can also start aggregating multiple trade intents together and settle them all in a single on chain transaction. And that allows us to actually be even more efficient than if every user was going to settle their trade individually. Because if we batch five or six trades into a single Ethereum transaction, that costs less gas than settling these five or six trades as individual transactions on chain. The other cool thing that comes from this aggregation is that the solver can now apply certain rules to the settlement. So for example, the solver can make sure that if two trades are happening on the same token pair, both of these trades get executed at the exact same clearing price. So the solver can employ kind of uniform clearing prices to a settlement for all the orders that it settles in one batch.
06:08:38.040 - 06:09:36.084, Speaker A: And this brings us to kind of the second core idea of Gnosis protocol or cowswap also where the name comes from, which is coincidences of wants. And coincidences of wants. Well, the general idea is that we want to reduce the amount of volume that we trade against external market makers because those charge a fee for their service. And if we kind of minimize the amount of volume that we have to match against these, we can actually get a better price for users. And so coincidence of wants is basically the phenomenon where somebody wants to sell a token for another token and another person wants to buy the token that the first party is selling exactly for the token that the first party is buying. And so today on Ethereum, what would happen, let's take Uniswap as an example. If you had one party selling $2,000 for ETH and another person that would be willing to buy one ETH for US dollar, they would both hit the uniswap pool, they would both pay the liquidity provider a fee.
06:09:36.084 - 06:10:08.656, Speaker A: It might be 0.5% now, but it is kind of a significant fee. And at the end of the block, the uniswap pool would actually be in exactly the same state. It would have not provided a real change or value other than kind of just being a sponge to within that block. Kind of absorb the liquidity temporarily on Gnosis protocol. Because we have these solvers that are batching trades together. They can first perform kind of a peer to peer matching within all the orders that are in a block or in one of those nosis protocol batches.
06:10:08.656 - 06:11:16.804, Speaker A: And then they only have to match whatever they cannot settle peer to peer with external on chain liquidity. And so in this specific example where we have a perfect coincidence of wants, we actually don't need any external liquidity at all. We can match the two traders directly, peer to peer. Now of course, more often than not one order will be larger than the other, in which case we could still match the small order completely via a coincidence of want and only have to take the access and try to find the best on chain opportunity to settle that extra part. And for every dollar that we don't settle against external market makers, we save fee and we can pass that on to the user to get a better price. And now you might say well, but how often does it really happen that two people really want to trade the exact opposite? Tokens markets are directional and so either tokens are going up or down, but it's not like you have a lot of times that people are trying to buy the exact opposites. But that's also not really necessary because if you look at the trades that happen within a block today, you really need to dissect kind of what are the individual hops that are happening on the underlying protocols.
06:11:16.804 - 06:12:22.624, Speaker A: And so, for example, if you're buying a project token like curve for US dollar today, what would happen most often is that you actually do a two hop trade on Uniswap, where you first convert your curve into WETH and then you make a weth against USDC trade. And kind of similarly, if you were to buy GNO with US dollar, you would first convert your US dollar into WETH and then trade that WETH against GNO. And you might see that there is now actually a coincidence of want in this WETH USDC part. And so even though there's not a perfect coincidence of wants, there's still some aspect of these trades that can be matched peer to peer and where we can reduce the amount that we have to trade with external market makers that are charging a fee. So, to summarize, kind of the mev protection that Gnosis protocol or Cowswap specifically offers is basically twofold. The first part is everything that we can match peer to peer via coincidence of wants is fully mev protected. It's somewhat similar to the RFQ system that we've seen in the talk before.
06:12:22.624 - 06:13:06.328, Speaker A: The prices are agreed to off chain, only the Gnosis protocol settlement contract is allowed to execute this trade. And it doesn't matter in which position within the block the actual settlement transaction is mined, because the only entity that can actually do this trade is Gnosis protocol settlement contract itself. So the coincidence of ones are fully MEB protected. They are maximal gas efficient because they just trade tokens, kind of transfer tokens back and forth, and they save the LP free from external market makers. Then we have the part that is kind of the excess that cannot be matched peer to peer directly. For this part, we have to hit kind of the best available on chain liquidity source. And so that part theoretically is prone to mev.
06:13:06.328 - 06:13:42.250, Speaker A: But here kind of the mev protection comes from the fact that we have a professional solver executing transactions for us. And so they can set extremely tight slippage bounds, basically zero slippage for any external liquidity source they tap into. They can use mev gas or flashbots to even bribe the miner to make sure they get the best price available. They can watch the mem pool to avoid race conditions. And just generally, they can protect the user from mev much better than the average MetaMask user could. And so, yeah, that's the overview. Thank you very much.
06:13:42.250 - 06:14:19.290, Speaker A: Thank you for a great presentation. Up next we have Amir from Xerox. Amir, feel free to share screen now and take the stage. You have ten minutes. All right, can everyone see my screen? Yes. Cool. Perfect.
06:14:19.290 - 06:15:19.460, Speaker A: Cool. So today I'm going to share Xerox's RFQ model, one of the trading models that is 100% mev proof and also has several other really nice properties. If you were listening to Tom's presentation, he did drop some spoilers and I think this might be one of the few presentations today that will actually be under time. All right, so first of all, what is RFQ? This is a concept that exists in traditional finance. It's not specific to blockchains at all, but has some really nice properties that work really well with blockchains, I would say. So at a high level, you could think of RFQ as programmatic peer to peer OTC trades. So you have a trader, let's say they want to sell 200 Ether.
06:15:19.460 - 06:16:13.580, Speaker A: They say, how much can I get for this 200 Ether? A market maker will be on the other side. Actually, one or more market makers will be on the other side and they will respond with the best prices they're willing to quote. So in this case, market maker says, hey, I'm willing to pay $500,000 for this Ether. And then the trader at that point can decide to agree to the trade or pass on the trade. And at that point the trade is sent to the blockchain and settled. So some of the high level properties of RFQ are well, first of all, it can offer really competitive pricing. And while it does have complete protection against mev, that was not necessarily an explicit design goal.
06:16:13.580 - 06:17:08.140, Speaker A: This model was designed first and foremost to offer the most competitive pricing. And I think it's just a little bit different framing than a lot of the other solutions that we've seen or we're going to see today. All communication happens off chain until these trades are actually settled, which makes the system extremely gas efficient for liquidity providers. They could be quoting all day, hundreds of times a minute, or a second, or whatever, and they're not going to spend any gas on that. And in addition to that, orders pretty rarely need to be canceled, I would say so very rarely actually spending gas as a market maker at all. Trades are completely impossible to front run or sandwich. And we'll get into how that works in the next couple of slides.
06:17:08.140 - 06:18:19.712, Speaker A: Trades have zero slippage, zero fees aside from gas, and they're settled at a predetermined price. The price of the trade does not change if the transaction is mined in a different order or anything like that. These trades are highly capital efficient for market makers, so they are trading directly out of their own wallet and can theoretically offer trades as large as the balance in their wallet. And RFQ liquidity is also composable, so other DApps can consume this liquidity. Smart contracts can consume this liquidity, can be used with more complex systems. So how does it work? Well, if you're familiar with Zero X, the underlying concept is pretty similar to how Zerox has worked since the beginning. So Xerox uses off chain orders with on chain settlement, an order just describes the properties of a trade.
06:18:19.712 - 06:19:25.400, Speaker A: So the tokens that are involved in that trade, the price of the trade, the time at which that trade expires, and several other fields. The market maker will hash all of the order properties together and sign the hash with their private key. And at that point the order becomes executable and can be sent to the Smart contract for settlement. You could check out the entire order field and documentation in this link. So I want to focus in on this one field in the order TX origin. This is actually the main field that prevents these trades from ever being front run or sandwiched. So the TX origin field enforces, who is actually allowed to fill this order, who can send this trade to the blockchain, only that field is allowed to fill the trade.
06:19:25.400 - 06:20:10.504, Speaker A: If anyone else attempts to submit the same order, the trade will just revert. So, literally impossible for any other bot, any miner to come in and try to fill the same order. And in addition to that, since the price is predefined in the order, the trade must be settled at that exact price. And this is how zero slippage is accomplished. It's totally agnostic to how market makers are pricing their orders or how they are hedging behind the scenes. There's no price curve involved, no magic pricing formula baked into the system. The user really doesn't know any of that.
06:20:10.504 - 06:21:20.678, Speaker A: They just know that this is the price the market maker is willing to give them and they either accept that or they don't. So what are some of the constraints of RFQ? Well, I would say, first of all, this is not really for your average liquidity provider that's depositing their tokens on, not a market maker uniswap or SushiSwap. It does require a pretty high degree of sophistication to be a market maker on the system. You are trading completely programmatically. There is a good amount of off chain infrastructure. You're not just depositing your funds and you need to be able to hedge out your risk in a pretty sophisticated way overall. And because of that, market makers typically aren't going to be experimenting that much with brand new tokens or tokens that are difficult to hedge or maybe tokens that have questionable legal status.
06:21:20.678 - 06:22:06.426, Speaker A: Right. So they tend to participate in already established markets that have a lot of trading volume. So you're going to see really good coverage in the main markets that involve ETH, WBTC, Stablecoins, any of the DeFi blue chips. But if you're trying to market by a million dollars of some dog coin that launched an hour ago, you're just going to get sandwiched. There's no way around it. However, yeah, I would say for consumers of liquidity, there really aren't any downsides to trading against RFQ. You're going to get all the advantages of that.
06:22:06.426 - 06:23:22.370, Speaker A: Consumers don't really need to care about where that liquidity is coming from otherwise. So I would say overall, the trade offs are pretty minimal and there's really good coverage in general. Tom showed a chart in his presentation about how large of a percentage RFQ volume makes up in the overall deck space. Yeah, it's probably somewhere around 40% these days, I would think, and probably somewhere between ten and 20 professional market makers who are using these systems, from my experience. So how can you go and actually use this in practice? Well, we have a liquidity aggregation API called Xerox API, where Xerox RFQ is one of the major sources of liquidity taps into several professional market makers behind the scenes. If a trade is routed 100% through zero X, it will be protected from mev and slippage. And you can easily set that in the API parameters or can also just let your trade be aggregated.
06:23:22.370 - 06:24:23.206, Speaker A: There will be cases where there are mispricings and automated mark makers are offering better prices for whatever reason, you don't really need to worry about it. But if you're doing a very large trade, could be worth considering, even if you are offered a slightly worse price. In some cases, you can think of it as insurance, essentially because it guarantees you're not going to get front run. So yeah, give it a shot at Matcha XYZ, which is our user facing Dex aggregator, or one of several Xerox API. Integrators zapper MetaMask DeFi saver coinbase wallet forgetting a bunch. And if you're using Matcha and you do want that insurance, you are making a really large trade. There is this OTC tab you could check out and that'll just be trading 100% with this RFK system.
06:24:23.206 - 06:25:10.318, Speaker A: So it's not even going to bother looking at the other liquidity sources in this case. That is all. I guess my closing comment is it's a super simple system which I think is desirable. It's really hard to reason about a lot of these solutions, but with RFQ, I think it's actually like really black and white and hope you enjoy the presentation. Thank you, Amir, for another crystal clear presentation. Up next we have sorry, that was a little out of order, these slides. Up next we have Kai Hua and Li.
06:25:10.318 - 06:25:48.620, Speaker A: Please feel free to share. Screen. Hi, can everyone see my screen? Yeah. Cool. All right, so thanks for the introduction, Tina. So today we are going to talk about a to Mm, which is an application layer solution we propose to Mitigate mev. This is a joint work with Kai Hua and ASA.
06:25:48.620 - 06:26:37.304, Speaker A: So to start, I want to discuss why maximizing mev, even in a decentralized way, might be problematic sometimes. So let's consider a simple scenario where we have two miners. One is honest and the other one is malicious. So both of the miners are trying to append to block B one, and they both observe some mev opportunity on the network layer and they are trying to extract them. So let's assume that the honest miner succeeds in mining the mev opportunity. Once the malicious miner receives block B two from the network layer, it will need to decide whether to forfeit the mev opportunity or not. So there are two cases.
06:26:37.304 - 06:28:00.696, Speaker A: In the first case, the malicious miner forfeits the mev opportunity, so it jumps onto B two, just like following the standard ethereum protocol to mine on the longest block blockchain. However, mining on the longest chain might not be the optimal strategy because the miner can choose to keep mining on block C two in an attempt to fork the blockchain. If the malicious miner is lucky, then the forked chain can catch up to B two. And then this forking behavior is actually quite dangerous because it's going to waste the computational power of the honest miner and it's also going to increase the stable up rate, which makes the game easier for the adversary to do double spending attacks and selfish mining attacks. So how does the malicious miner decide whether to fork or not? So, there are many factors he needs to consider. What's the average block reward, what's the mev reward, what's the hashing power he controls? And how long does it take to switch from mining the old block to the new block. So, in order to quantify this problem, we have modeled the entire thing as a Markov decision process.
06:28:00.696 - 06:29:05.100, Speaker A: So, based our finding in this paper, we find that if the adverse rail miner owns 10% of the hashing power, the rational behavior is to fork the blockchain if the mev is four times larger than the average block reward, but four times is nothing. We have observed mev opportunities exceeding 874 x of the average block reward. This is actually the BDX attack in the past. So here is the critical takeaway message. When the mev is big, even small miners would fork the blockchain in order to steal the mev opportunity from the other miners. So, although we have not seen substantial efforts indicating such behavior at moment, according to our quantifications, this is actually the optimal strategy to do so. Why the miners are not doing it at the moment? Remember, one year ago, miners are not extracting mev.
06:29:05.100 - 06:30:13.010, Speaker A: So I believe this is basically because miners do not have the setup at the moment to help them fork the blockchain. I really hope I do not see this kind of forking behavior in the future because this is definitely going to be a disaster. And I hope Flashbots can also be aware of this risk and try to mitigate the problem. Is there any simple way to reduce the mev to kind of mitigate the risk? So, when I think about this problem, I always ask myself the following two questions. So who is the creator of the mev? And if the creator can close the mev itself? So this is very similar to what Tom said about the unionized idea which implemented by the B protocol. So I will give a different example here. So let's think about an arbitrage opportunity.
06:30:13.010 - 06:31:25.160, Speaker A: Let's say a user makes a trade on uniswap in this transaction here. This will cause an arbitrage opportunity between uniswap and SushiSwap. So what we observed previously was mev searchers will try to background this opportunity with the background in arbitrage transaction. So if the mev is not extracted just in time within the same block, then the searchers will try to front run in the next block with the arbitrage transaction. So here comes the core idea of a to Mm. So instead of leaving the money on the table, why don't the trader, the blank trader here in Orange, why doesn't the trader atomically close mev themselves by performing the arbitrage atomically in one single transaction? So what's the pro and cons of a to Mm? A to Mm will minimize MEB. It is backward compatible, so it doesn't require any changes to the Ethereum implementation.
06:31:25.160 - 06:32:08.020, Speaker A: And it's a decentralized solution. It doesn't require any additional trust assumptions which is different from other. Like for example, background me services where they rely on private communication channels with the miners. A two M also have some financial benefits, but it also has some cons. So Ethereum has this block gas limit. So sometimes it's impossible to extract old mevs in a single transaction. Which means some mevs will be left for the next block and searchers will do front running in the next block.
06:32:08.020 - 06:33:08.372, Speaker A: It's not trivial to determine optimality on chain sometimes. So especially if the underlying pricing formula is complex. For example, it's quite hard to determine the optimal parameters for arbitrage between uniswap and curve. Also, a two Mm only mitigates some types of mev, not everything. So here I give one example of one type of mev that cannot be mitigated by hmmmm this is actually inspired by Retaliat's comment on our Medium article. So in a sense, there is a contract which rewards any caller after a certain block number. So the creator of the MEB opportunity actually wants the opportunity to appear in a future block in a way that it doesn't want anyone to close the MEB opportunity atomically.
06:33:08.372 - 06:33:50.120, Speaker A: Therefore, a to Mm will not be able to mitigate this mev. This is something different from A to Mm. But I also want to mention in our previous paper we have actually proposed a simple application layer solution for Sandwich attacks. So here we show a concrete example. This is Uniswap version one easter to side market at block number nine minute. So on the x axis we have the Easter transacted by the victim and on the y axis we have the Easter transacted by the adversary. The color here indicates how much revenue the adversary can gain.
06:33:50.120 - 06:34:47.210, Speaker A: What's interesting here is there is this threshold which we call it the minimum profitable victim input. If the victim transacts an amount that's below this threshold, then no matter how much the adversary trades for the Sandwich transactions, it's always not going to be profitable. So there's no incentive for the attacker to attack. So yeah, so basically there is application layer solution for sandwich attacks. And I hope in the future we can see some AMM protocols implementing this solution. So, to summarize, let's minimize mev to reduce the risk of poking. Thanks, that's it.
06:34:47.210 - 06:35:15.936, Speaker A: All right. Perfect timing. Combining research and DeFi design together. Thank you for the presentation. Up next, we have Jennick from Shutter network. You can start sharing screen now. Can you see my screen? Yes.
06:35:15.936 - 06:35:54.896, Speaker A: Perfect. So hi, I'm Janigan, work for BrainBot at a project called Shutter. We try to prevent front running using Threshold encryption. And we've heard about this a couple of times today already, but I still want to talk about the problem a little bit to set the scene. So if you send a transaction to pretty much any blockchain today, it will not get included into the chain immediately. It will first have to travel through this dark forest, the peer to peer network, where everyone can see it. And also the miner can then try to include it only later, wait a little bit and decide to include it.
06:35:54.896 - 06:36:39.390, Speaker A: Not at all, maybe. So, all in all, there's some time that passes between the transaction being sent and the transaction being included. And during this time, the transaction can be overtaken by some other transaction, by a front runner. And the front runner can see what transaction you sent and depending on using that information of your transaction, change the transaction that they sent, and by using the knowledge that your transaction will come later, extract some value from you. And people don't usually like this because it reduces the or they lose money, basically. And therefore we try to prevent it. And the simple way we do this is simply by encrypting it.
06:36:39.390 - 06:37:28.332, Speaker A: If it's encrypted, it can still be front run. There's still time that passes between sending and inclusion, but there's no information visible for anyone. So the front runner can't extract any information or any value from your transaction. Unfortunately, if we now end up with an encrypted transaction, the blockchain doesn't help us very much because in order to execute it, we need it in plain text. So therefore, at a later point in time, we provide the decryption key, then everything is fine. The chain can decrypt it and execute the transaction. Of course, here I only showed a single transaction, but in practice, there will be many transactions encrypted using the same key for the same key, and then this process will repeat all the time.
06:37:28.332 - 06:38:18.536, Speaker A: So after one batch of transaction is encrypted and executed, or decrypted and executed, another batch will come next. Where does the decryption key come from? It can't be the user. Unfortunately, that would be the easiest solution, but it doesn't work because it would prevent front running, but it would allow the user to decide to not decrypt or not release the key. And using that technique, they would. Have a free option and that would create some problems in some applications. So we need some way to make sure that this decryption key is provided in any case, whatever happens. And therefore we use threshold cryptography.
06:38:18.536 - 06:39:15.232, Speaker A: So we have a set of nodes, which we call keepers because their job is to provide keys. And as long as the majority of the set is honest and not malicious or offline, then these keys will be generated. And also they will be generated at the right point in time and not too early. Because if they would do it too early, they could read the transaction and front run again. Now ideally the set is very large, the larger the better because the larger the harder it is to attack the protocol. And this has to be repeated many many times for every round. We call these rounds epochs they have to generate a new key and unfortunately these protocols get very inefficient if there's many people or if you have to run many times.
06:39:15.232 - 06:40:23.076, Speaker A: So therefore we collaborated with some cryptographers and together with them we developed kind of a new protocol to make this more efficient, this key generation process by having a kind of a setup phase first. So we have first traditional DKG distributed key generation phase that provides what we call the Eon public key and the Eon secret key shares. Eon is like this very long geological scale. Ideally this would be we can just say it will only be run once and it will output a public key and a secret key share, one secret key share for every keeper that they will keep private and the Eon public key will of course be published. And then in the next phase we will derive from these keys epoch keys. So for every repetition of the protocol we get a new key pair. The epoch public key can simply be derived from the Eon public key.
06:40:23.076 - 06:41:09.568, Speaker A: Every user can do that on their own machine. No additional communication is necessary. And for the epoch secret key shares each epoch secret key share is derived from the keeper's eon secret key share. So this one for this and so on and once we have published enough and once we've got enough epoch secret key share we can combine them to receive the epoch secret key. So this sounds maybe a little bit complicated but it's actually quite easy. For the Eon public key we don't need any additional communication so it's very efficient. For the secret key we only need a single message per keeper.
06:41:09.568 - 06:41:56.756, Speaker A: So for every round the protocol is very efficient. Only the Eon DKG process takes some time but this is fine because it has to run only very seldomly. Now, this is a very general technique that I just described in the whole process and it can be applied in many different domains. We think the most obvious one is a blockchain and in particular at the base layer of this blockchain. So this encryption and decryption process can be part of the block production mechanism itself. And this is basically the ideal system. But there's other applications too.
06:41:56.756 - 06:43:01.784, Speaker A: For example, centralized institutions might also be interested in something like this because they suffer from front running too. And that's what we built so far. We can even apply it on top of an existing blockchain. So even if the blockchain itself does not use this process, we can protect transactions from being front run. We call this on chain shutter because that shutter that runs on ethereum on a blockchain. And it's basically a set of contracts, smart contracts running on this chain where people can deposit their transactions in encrypted form and then at a later point in time, they will be decrypted and sent to the target contract they specify. And if this target contract is careful and only accept transactions that came through this mechanism, then they're protected from being front run.
06:43:01.784 - 06:43:38.356, Speaker A: And it's running at the moment on Gurley. You can try it out. We host the keepers for now and we deployed a very simple example application so you can try it out. It's a very simple message billboard, so you can simply publish messages for other people to read in a front rank protected way. Kind of. That's all I have. I was probably relatively fast, so maybe I saved some time.
06:43:38.356 - 06:44:13.330, Speaker A: Thanks for listening. Thank you for saving us a bit time. So I believe we just wrapped up our Section 4.2 and now we're going heading into Section 4.3, which is Mev redistribution and it's a panel. Tom, do you want to the stage is yours. And I ask all panelists and moderator to turn on your camera while everyone else turn off your camera.
06:44:13.330 - 06:44:46.542, Speaker A: Cool. The questions for the panels have been shared in the MEB WTF agenda. Great, I think we're all here. Do you want to do like a round of intros to start? Maybe? Yvonne if you want to start. Hi, I'm Yvonne. I've been doing mev research for a while and particularly front running, and then I'm advising Dragonfly Capital and Building Mining Dao, which I think Tom mentioned in one of his previous slides. I guess I'll take it from here.
06:44:46.542 - 06:45:33.786, Speaker A: Hi everyone, I'm Uri Klarman, CEO and co founder of Blocksroute. We've been working on the network layer of blockchains, which has a lot to do with DeFi and front running and pretty much get your transaction faster to pools. Also with my hat off backrun me, which Tom mentioned earlier. And it's super cool to be here, kind of like here with Tom and Ivan and Joey. This is kind of like, oh, all the friends stand together and kind of go, let's do a panel together. Jaron I know less, but this is an opportunity. Joey hi everyone, I'm Joey Zachrol and I'm a founder at Keeperdow, where we provide infrastructure for capturing and distributing mev to users and keepers and a variety of others as well with the goal of making DeFi more secure and profitable.
06:45:33.786 - 06:46:22.940, Speaker A: And my background includes trading, market making, automation engineering, decentralized exchanges and cybersecurity. Hi, my name is Anton, I'm co founder of 1inchh. I'm also interested in discussing different blockchain related things like consensuses of different projects, tokenomics and of course minor extraction value. I'm sorry, I don't know how to pronounce your hi. Yeah. So I'm Iron, founder of B Protocol. We shift profit to the users in learning.
06:46:22.940 - 06:47:00.646, Speaker A: Previously was CTO of Kyber network. We are doing a lot of on chain market making and previously one of the founders of Smart Pool which was the first decentralized mining pool on Ethereum. Awesome. I'm glad everyone could get together. This is really like a stacked panel. So I'm glad you guys are all here. I guess we've sort of been talking a lot, I think at the event about where does mev come from, who's taking it, what do you do as a protocol? And these are kind of around like mev mitigation techniques and things like that.
06:47:00.646 - 06:48:00.234, Speaker A: But I think at a certain point, to an extent, mev is always going to exist. And so I think the question is almost like is there a fair distribution of mev in your mind? Which actors do you think sort of deserve some amount of mev and how do you actually go about achieving something like that? I can try to volunteer on this one. I guess the way I think about mev is kind of after you've accounted for everything, mev is what remains. It's kind of this weird thing at the edge of a protocol. And so I would say kind of fairness is a second order thing. It's much more important to minimize it and kind of by the time you defined what it is and what fairness is, you might as well fix it. And there are specific examples of that where at least like half of all mevs like front running, uniswap and even Flashbots, which kind of started on the idea of making it fair.
06:48:00.234 - 06:49:05.002, Speaker A: Right now it's kind of this backdoor way of solving it where you could now send transactions privately on 85% hash rate or you could do use background me. And so kind of if you can do kind of the ten x step and avoid front running kind of why would you work on kind of redistributing it fairly? It doesn't super matter whether it goes to a kid doing up the bot. It's kind of worse if it goes to a pool, but still fine. I'd like to start maybe by saying what is a really unfair distribution or a bad distribution. And I think the situation and this I think goes kind of like against the idea of Flashbots here, which is something I want to push against. Is that the idea? If we really optimize and maximize so you have like searchers trying to get as much mev as possible and then they try to outbid one another and almost all that value goes to the pools. And pools being competitive with one another would probably be forced to pass these revenues to their miners.
06:49:05.002 - 06:50:13.730, Speaker A: So they'll keep just a tiny thing and that goes back to the miners making mining more competitive. Therefore more miners join and we spend more electricity on mining and start to go we took all that money, we passed it along, leaving very small crumbs along the way and eventually paid it all to electricity companies. So that would be an unfair way. So I think I'd kind of like want to point out that when thinking about fairness, it's not like, well, the user should have it, it's about how much the miner should have. I think it's important maybe not to optimize it to a race to the bottom. Maybe try to think about it as can we have some reasonable like X goes to the miner, Y goes to the user, but not to make it an optimization race, which at the end of the day, might be worse off. Even if it's, like, economically optimized and you're essentially taking something that has some negative connotation to it and kind of spinning it and making it healthy and livable and help it make the system grow and distribute to various other people involved.
06:50:13.730 - 06:51:42.382, Speaker A: And so the way that we like to look at the various parties, there's users, there's keepers or searchers, you could even consider liquidity providers, there's DeFi products and then there could even be a market maker which could be like an automated user or automated liquidity provider. Trying to kind of make this mev something more healthy and less unhealthy and distributed around makes a lot more sense, especially when you focus on the users who historically were kind of, I guess abused and sandwiched and front run and tailgated, yet they receive zero of it. A lot of times they're actually the ones who are responsible for making the profit opportunity to have existed in the first place by some action that they performed. Maybe it was a lending position, maybe it was a trade that they made. And so as mentioned earlier, if these kind of leftovers as a result of people interacting with these protocols, generating these mevs opportunities, you may as well distribute them. That's maybe a good segue to the second question, which is it seems like a year ago or two years ago really the answer was sort of like it's some sort of split between miners and bots and people sort of participating in PGA. And now everything that we're talking about is sort of shifting this mev to DAOs or to individuals directly.
06:51:42.382 - 06:52:53.270, Speaker A: Sort of like with background me. For example, which of these do you think is kind of more likely to prevail in the long run or maybe in the next few years? Is it sort of individuals basically get to reap their own mev maybe you could argue RFQ is something like that or Background is something like that or like a DeFi saver or something like that. Or do you think it's going to be sort of more dow fied where the liquidations and the ARBs go back into some sort of pool on chain and we all sort of sort of benefit from it. Okay, so maybe to answer the first question first, I think, in my opinion, fairness in mev is eventually the point where traders and users don't need to have some kind of specialized personal connections or business connections with the players in the ecosystem. For example, miners, et cetera, which eventually they must have some in order to become profitable. And eventually this just keep players out of the game. Very similar to how now you cannot be a serious algo trader if you have unfair benefits in centralized exchange arenas.
06:52:53.270 - 06:53:53.946, Speaker A: So me as an average trader will not go into BitMax because I have no fair chance there. So I think same should be applicable also for DeFi. And right now if you have to have some connections with miners or have some specialized knowledge to use the flash loan boats, et cetera. So in my example, this is also some kind of unfairness in mev. Yeah, that's like I guess that's sort of the Flashbot's idea, right? Which is like, okay, we can do it, but make it kind of auction and transparent so everyone gets access to it instead of having some special hookup with a miner. And Tom, to your question, I think maybe me and Joey are kind of like on the two ends of the spectrum, kind of like between and I'm not sure me and Joey feel very bad about it. I think both options are kind of okay and both are livable with right.
06:53:53.946 - 06:54:24.310, Speaker A: You could do something like Keeper in which the platform itself has all these actors. So it's a dao, it's a protocol or whatnot. And users can come into that knowing, oh, what are the pros and cons. And so maybe they know what they're getting into and if it's not competitive they'll go somewhere else. And therefore just like if uniswap takes 0.3% and that's fine. So maybe Keeper taking the mev and if that's comparable then that's also fine.
06:54:24.310 - 06:55:18.594, Speaker A: And so there is a question that's one I think okay, solution. Our end on our end, we know who mentioned it earlier was it hasu that I think so that providing the order book is actually providing value. If I'm kind of like the transaction stream, me as the user has the power, I can make this trade here or there. Like I could choose to do it on CFI or DeFi or which protocol specifically. So I'm going to want a piece of the profit if you want my transactions. And so the user will hold some of it, I assume a bunch of it will go to again, whether searcher or miners or whatever, but definitely the user holding a significant piece and I think maybe that kind of defines a spectrum. Yeah, this wasn't intended to be sort of like what you think is right or which you think is ethical.
06:55:18.594 - 06:55:59.666, Speaker A: It's more like what you think is more likely. I think the other question is, is there a third option I kind of see people on? So I was going to just say since Uri and Joey offered kind of the two opposing options, I'm going to do a third one. And I think this is kind of like a more long term hypothesis, but curious what you think. So if you think, okay, who really owns mev? It's like is it kind of the anime avatars on Twitter? Like, do they own the information that the user is trading on uniswap? The answer is of course no. They were just like the first to figure out you could extract value that way. And so now that there's a lot of anime avatars on Twitter, 90% of that goes to the miners in terms of fees. But if you ask, okay, do the miners own that? The answer is still no.
06:55:59.666 - 06:56:47.714, Speaker A: The miners are entitled to be paid for block space, but not for the full value of the transaction. If somebody is trading a billion dollars, they're not entitled to extract all of it. And that's the core of the mev cris. But there's private transactions and so on. And so if you really kind of unroll that game into the future and try to think who actually owns the interactions, I think the answer is wallets because there's nowhere up the stack to go and kind of wallets are the ones that really do the user interaction. And so I think kind of the long term outcome is kind of that value accruing to MetaMask or maybe nosis Safe because it's like that's where the big transactions are or like fireblocks and so on. And by the like, if you guys read Money Stuff by Matt Levine, which is fantastic, if you don't, you totally should.
06:56:47.714 - 06:57:32.754, Speaker A: He keeps saying know, crypto rediscovers traditional finance kind of step by step and stumbles in all the same places. And so I would say maybe now is the time to rediscover the Robinhood plus Citadel type sort of payment forward or flow situation where there's like the wallet that owns the user and some Arbitrator Azure that sort of does the back running but not the front running, kind of like the way background me does that. And so I would hypothesize that to be the long term equilibrium. So that's a really good interesting point. And so first of all, say don't say bad things about like anima on Twitter. Zero x two would come for you. I'm not saying second, that's an interesting like, I love this thesis here.
06:57:32.754 - 06:58:13.226, Speaker A: This is like, oh, you think it could go up to the wallets and wallets would be happy about it. Because up until MetaMask started to make money, I think like a year ago or something like that, there was a huge question of how wallets are actually going to kind of monetize all their users and it wasn't that easy for them. But then I'm not sure I agree that's the last step. Like if you have MetaMask and MetaMask is making tons of money in comes, I don't know, competitor number one and says, you know what, I'm going to give you exactly the same experience and I'm going to give you part of that. And so it goes back to, I think the user. The user is standing on top of the wallet. Maybe the wallet will take a chunk.
06:58:13.226 - 06:58:49.642, Speaker A: There's a question of network effect and which one would use what, but I'm not sure I agree with you that well. It has to stop there. I would argue that a user can totally choose to use a different wallet if the wallet passes a big chunk of these balance both agree and disagree. So first off, definitely love the fact that there's a way to monetize wallets. They've been sort of sitting on, they've been doing useful things for years and years. But then second, I think kind of wallets are this scary thing to replace with your seed that could get stolen. So I think there's definitely kind of a baseline where if I'm getting paid like a cent, I'm just not going to do this.
06:58:49.642 - 06:59:45.638, Speaker A: And then finally, kind of the other part of that equation is once you're trading on one inch on uniswap, there's no back runs and there should be no front runs in the first place. So I definitely agree with you that sort of mev as a percentage of the ecosystem tends down to zero. But as the ecosystem explodes, wallets are still in a pretty good position to capture kind of a small percentage of it. I think back to the comparison of individuals versus dows. I think that line is a little bit blurred too, because dows really are made up of individuals, and dows tend to cater towards the individual and kind of try to empower them as a group. And then even if you want to think about it from the searcher or the keeper's perspective, you could have a keeper. I actually know someone, and I'm one too, as well, who essentially would use this tool and that tool they may use background me, and they may use keeperdao and they may also use flashbots and anything else as well.
06:59:45.638 - 07:00:50.974, Speaker A: So I think the line is a little bit blurry there. I don't necessarily think that just individuals or just dows or just some of third option has to win. Yeah, guys, let me add I'm pretty sure everyone attached what happened to flashbots. After flashbots was launched, some of the DApps started to exploit flashbots to hide from flashboard active users. So even like in one inch we have flash transactions. It's not working with MetaMask, but would work with your ledger because MetaMask will send it to Mempool. It's not possible to prevent it, but you can put your transaction into flashboards and it will be mined without disclosure before it will be included into blockchain or in case of reordering reorganization, it could happen that it will be shared.
07:00:50.974 - 07:02:21.070, Speaker A: But what I actually think that Mev belongs to users and we need some kind of layer one protection, like blockchain layer protection from front running and from abusing users. Because right now I believe that miners and all these Arbitrage traders, they are handling all these issues, but they are trying to earn things which not belongs to them. And there are a number of projects who are working right now on general prevention of front running, but not back running for sure. I heard of Metrolabs and Stackware. So in a perfect world we would see maybe BDF based solution to prevent phone running. Back running is not that much a problem for user because it usually happens because of inefficient trades. If user shifts the market significantly and this creates arbitrage opportunity, anyone can background this transaction to earn this inequality on different prices.
07:02:21.070 - 07:03:25.970, Speaker A: As far as Mev belonging to users, and you mentioned Flashbots as well, so do you think basically Flashbots plus one inch solve Mev? Or at least not the liquidations, but at least on the sort of buying and selling side, like there's no front runs, there's no back runs. No, I think actually it's abusing of Flashbots functionality. And next step, Flashbots should share these bundles with everyone who would like to listen. Like if any service would like to use Flashbots to just send transactions, flashbots should share these bundles with anyone, to allow anyone to replace these bundles, rub these bundles to do anything with these bundles. Because I agree it is abusing. But it's a good thing, right? They've built this thing and now you could use it sort of for the user and as they transition to SGX, there would be a way to do this without even relying on honesty. Like it doesn't matter sort of how we ended up here, right? It seems like a solution.
07:03:25.970 - 07:03:47.654, Speaker A: I believe it will work only on short term. In next version, Flashbots would just share these pending bundles with everyone. I hope not. I wonder if Tina wants to find on this. I don't know, but I want to be contrary again for a second. There is a very big difference between front running and mev. And we're all kind of like focusing.
07:03:47.654 - 07:04:25.846, Speaker A: Well, back running is solvable. If you just route it around to everybody, raise the entire market. And it's not entirely true because you'll raise the entire market. But what about CFI? Right? So you can do DeFi CFI, ARB and you can't do that from within DeFi, but maybe unless you're moving giant chunks of money, I think maybe it's good enough. But mev is about minor extractable value, right? If you're the miner, you're about to create a block and all of a sudden price crashes on coinbase. You see that and you're the miner and you can put a transaction you're not front running anybody. I think Sonny called it the blind front running or something like that.
07:04:25.846 - 07:04:58.130, Speaker A: The idea of the miner has value which it can capture because it organized. A transaction is something which I think is inherent and we're not going to solve that easily. So maybe we can solve front running. But I'm not sure that's the current thing. I'm not even sure it's the big thing. I'm not sure if you'll be thinking about DeFi CFI ARB whether that might not be a bigger opportunity than the front running individual transactions of people on DeFi. I don't know but I think so.
07:04:58.130 - 07:06:25.446, Speaker A: Or it's at least a mean your note on sort of like CFI DeFi Arab and I think sort of like a lot of the complicated strategy that we're seeing now is maybe a good segue. I'm kind of curious what you guys are seeing maybe specifically Joey and Yvonne as sort of like the frontier of the bot space. I think generalized front running seeing some of these generalized front running bots operating the Mempool has been pretty surprising to me and I think a lot of other folks. But are you seeing other novel technologies that people are employing or what do you sort of see as the end game for sort of bots in DeFi right now? I can take a yeah, so far all the pending transactions have been public and so my understanding is most of generalized front running bots have essentially been copy bots. The idea is like oh, can I send the same transaction but from my address and make that money? And then it becomes like a cat and mouse game where if you kind of invented a strategy yourself, you want to sort of complicate this so that people are not able to steal it and then you sort of try to decomplicate that and so on. I think Flashbots is a major change in that landscape because again, all the strategies you could submit privately and so these copy bots would no longer work at all and I don't think they do anymore. Even right now at 85% hash rate there is just no point.
07:06:25.446 - 07:07:24.542, Speaker A: And so I would say that now these generalized I don't even know if it's like the most money to make or whatever, but at least kind of the technological frontier and sort of the frontier of what's interesting would be the bots that just take the new block and try to figure out, okay, what the hell are the new opportunities that came up in that block? And I think the first approximation to this is Mithrail. If you guys have seen this tool, it's like a security analysis tool that just magically transforms the VM into this symbolic execution and tries to find pathways to make more money. And it already has all the tooling for that. And I think the author Bernard Miller even built this into a tool that's called, like, a Scrooge Mac Deal face or something where he literally tries to do that thing and sort of extract the money. I looked into it. I haven't had such a great experience. If somebody manages to use it even to birth a CryptoKitty, send me an email.
07:07:24.542 - 07:08:05.790, Speaker A: I'd be impressed. There's definitely a lot to work on, but oh, screws Mac Ether face. Yeah, I think kind of that's at least kind of the way to think about it. In the way we build deep blue and AlphaGo, we may as well build something like this. Yes, I see a lot of separate ecosystems forming and even coexisting similar to how, say, our oceans consist of unique marine life ecosystems all within the same planet. So we have a variety of strategies that historically would thrive on public mempool. Nowadays, we also have strategies that thrive using tools like Flashbots.
07:08:05.790 - 07:08:44.982, Speaker A: But then there's also even more specific task oriented automation projects, say, like Numer, AI or Gelato. These are maybe less related to mev, but still very much related to botting. But then I say generalized front running does kind of seem to be an end game for some ecosystems. But then private mem pool kind of changes the rules and economics. So, for example, we're building a keeper coordinator that essentially enables users and keepers to kind of coordinate together. It prevents things like gas auction, scrim triggers. So it's essentially a walled garden, right? But the idea here is you focus less on competition and front running and more on just efficiency.
07:08:44.982 - 07:09:27.222, Speaker A: But in this type of environment, you really want to cater towards the coordinator's algorithm, right? So the algorithm is essentially designed to maintain a healthy ecosystem, so it changes the strategy. Right. But again, back to the separate ecosystems, I think you may ultimately see generalized front running kind of just solve certain ecosystems, but then private mem pool is kind of totally separated. There could be tools and technologies and skill sets from generalized front running applied to even private mem pools. But at the same time, you're kind of more catering to whatever the coordinator is, whoever's setting the rules in that ecosystem. In the walled garden. Tom.
07:09:27.222 - 07:09:58.960, Speaker A: We kind of, like, jumped question three, which I really want. I do want to go to. I just thought we were talking about bots, so I kind of want to go into but, yeah, if you guys are down. We can sort of jump to question three or question four now, I guess, which is good, basically about sort of the shift to proof of stake, which is sort of rapidly approaching. I'm curious how you guys sort of view maybe the second order effects of the move to proof of stake with respect to mev. What are some things. That maybe we're not thinking about or not seeing right now.
07:09:58.960 - 07:11:12.378, Speaker A: So I thought of it a bit and I have my own opinion, which seems to be, again, not a lot of people think that way. And I would really like to definitely joey and Avon and Yaron, I know you left on that, but really, maybe get some pushback on this. But my perspective is that we saw that mev, he was what, $700 million in the past 18 months or something like that, and we all talk, well, 700 million, that's tons of money. But then when I'm thinking about the move to POS and it's kind of like I'm thinking, okay, we're going to have validators run by really large organizations. Coinbase is going to be a big validator, binance is going to be a big validator, a bunch of others are going to run the validators. And when you think about the large stakeholders, just think whether they are centralized or decentralized. If ETH is worth $200 billion or so, and if DFI Tokens on top of it is another $50 billion and just Coinbase is another $50 billion, we're talking about a total value of businesses and tokens and economies on top of ETH, which are worth in the order of 400 $500 billion.
07:11:12.378 - 07:12:01.378, Speaker A: So $700 million per year is nothing. I would argue that those who are betting big on ETH and stuff built on ETH are better off running vanilla nodes, not capturing mev because the value it generates is larger than capturing mev. If you think about the legal risk for Coinbase to doing these kind of things, instead of I just take guess I run it or not guess because like prism or whatever and I really don't want to screw anybody over because the legal around it is a nightmare. I'm not going to risk it for my share of $700 million per year. Ask for pushback and you're not going to get any from me. I think I agree 100%. And people, there's this phrase that cryptocurrency works better in practice than in theory.
07:12:01.378 - 07:13:19.300, Speaker A: I think it's one of those cases where kind of honesty assumptions become even more believable as we transition to proof of Stake. And so Anton worried that what if one of the Flashbots participants ends up kind of trying to screw the system? I think it's kind of even less likely in the proof of Stake shift. And so you could just run Flash bots on the Coinbase nodes or back on me or sort of any kind of private mempool, and that might just be the simplest end game. But why do you expect regulation concerns or legal concerns where these days regulated exchanges in the real world do give different priority classes to different users? Yeah, I think that is true. If it were we were talking about something like a uniswap or something. But this is like Nasdaq Exchange giving different priority classes to different players. So why Coinbase can't I mean, I'm pretty sure that Coinbase centralized exchange give different classes of service right now, right? So it's not really something that is unheard of in the real traditional world, even in the regulated space.
07:13:19.300 - 07:14:10.130, Speaker A: I also think that you don't want to assume the value of mev in the future just because it changes dramatically. One thing to keep in mind is that every time ethereum scales you get more users, more protocols, more products, more exchanges. And history shows that every time that happens, you're multiplying mev opportunities and which then further emphasizes the need to capture and distribute to me. But an example would be kind of thinking back to the days of the first few DEXes popping online and the first big mev opportunities. It was great. And then all of a sudden the third and the fourth and the fifth came online and it was like lightning striking and just kind of just rejuvenated everything. The bots were going wild and more bots were coming online and everyone was reverse engineering other people's bots.
07:14:10.130 - 07:15:18.358, Speaker A: And then add in the fact that Stake is fundamentally more liquid than hash power so someone could very easily double down on their stake. But with mining hardware you can't very easily do that, right? So if suddenly mev just multiplies and multiplies and multiplies and all of a sudden maybe you have people kind of doubling down on their stake and trying to grow their pool. Maybe they are now incentivized to use that ability to just instantly increase their pool size, use that to somehow capture mev with some of these tools that are available that could be very tempting for a lot of folks, even like a coinbase. So to your last point, you talk about hash power being less liquid, but there's a giant difference between mining pools who are capturing this value and miners. And so miners make what, $10 billion per year. So even for them it's nice. 7% increase is nice, but it's not that big for mining pools who capture just 1% out of that.
07:15:18.358 - 07:16:17.420, Speaker A: That's a whole lot of money. And so that's a bit of that. And to Yarn's point about well, Coinbase is already and Nasdaq are giving like priority. I think there's a big difference between giving priority and colocation and access to flow compared to, oh, accepting bundles of sandwiching just from a legal perspective or I think there is a difference. Maybe I'm wrong, but I'm not sold on the fact that the value of mev is great enough in order to push really big stake like people who are betting billions of dollars on ETH and protocols on top of it. But what if these tools like say, Flashbots or mining dow have nice privacy features where all of this stuff is just kind of wrapped in and they're just mining, they're just kind of running their software and everything's built right in. They're not intentionally doing anything, it's just kind of happening.
07:16:17.420 - 07:16:53.080, Speaker A: It's a good question. I don't know the answer, but I'm not sold on that. The obvious answer is of course mev. Like as we see it right now will be in POS the same way. That's kind of like my point. Yeah, it's certainly going to change. Mev is only hundreds of millions where east will be trillions but is trillions because there is some expectation that most of the future financial transactions will be on Ethereum and then also mev will be orders of magnitude higher.
07:16:53.080 - 07:17:47.894, Speaker A: I agree and correct me if you think differently. I think that mev is subtracting from the value of Ethereum. The fact that you can't just transact on uniswap but you have to do all sorts like oh, I have to make sure that you route my transaction for back running and I have to use services to avoid front running and all these kind of things. And even then if value is extracted, it's extracted from somebody. So my argument is that ETH would become more valuable and the protocols on top of it if mev is mitigated minimized and not happening. So that's kind of like my argument that they're betting more on east and the value there rather than benefiting from capturing mev value. Does that make sense? What better time to talk about fixing things when you're adding new features and adding upgrades, right, that perfect.
07:17:47.894 - 07:19:06.770, Speaker A: Time to introduce something new to fix something. When you're say transitioning to e two proof of stake, let me add a little bit. Yeah, I agree that Ethereum will became more variable with all these protocols working on top of it. But I believe also that miners no matter proof of work or proof of stake but yeah, let's talk about proof of work, they will never be properly aligned with the network interest and inspiration because we also can see this on this old topic of block gas limit. You want to talk about Eagle? Let's not dive deep into it because it's holy wire. And I'm also not sure that right now Flashbots works not to hide that mev is happening. But I believe if this would affect someone's reputation then some system will appear that would allow to hide that this mev is happening.
07:19:06.770 - 07:21:14.300, Speaker A: It will not be easy to prove that Miner is doing this mev, it will look like someone is front running someone I'm not sure if Miner is involved in this right now. Flashbots were not trying to hide this, you know what I mean? But if this would affect reputation, they would find a technical solution to prevent tracking of minor and also switching from proof of work to proof of stake. I believe that proof of work guys, they are not properly aligned and I believe they will never be aligned with the interests of hold the ecosystem because they don't care if this just transfers of either transfers of tokens or really complex DeFi transactions. But proof of stake guys, they are more likely be aligned. But this is also a matter of network upgrades because right now everyone is waiting, like next hard fork and this Ethereum improvement proposal 1559. But there is also a case that miners will not like this improvement proposal and will upgrade to any other hard fork, excluding this EEP because right now they're forced to get this hard fork with all these Ethereum improvement proposals just because of this time bomb of proof of work. And at some point in future they will be able to exclude some Ethereum improvement proposals, possibly, and everyone who are Ethereum developers, they will not be happy about it.
07:21:14.300 - 07:21:54.306, Speaker A: I think that's a fair question. I think that's a fair point to end on. We have, I guess, one sort of point or question from YouTube. Lawrence says med is going to be more pervasive in proof of stake. As selected, Validators will be able to reorder transactions over several blocks instead of one. I'm curious what you guys think about that. Isn't it harder to reorder on proof of stake? That would be my impression, but I don't see the logic in it being easy on multiple blocks.
07:21:54.306 - 07:22:39.238, Speaker A: It's going to be easier in terms, you know, your turn is in three blocks from now, so it does open an angle which isn't open right now. On the other hand, right now with proof of work and the probability around it, if you're one of the top three, you know, you have like, well, 10% or so of like, if you're right now Ether mine, right? With the change of hash power moving away from China, that's 25% of the hash power. So in 12.5% of the cases, they mine like two blocks consecutively. So I'm not sure it's going to be more pervasive there that you're going to mine. Like, it's hard to say at this point how decentralized the Validator landscape is going to be. Nobody knows, I think, and it's definitely opening an angle, but I'm not sure.
07:22:39.238 - 07:23:18.106, Speaker A: Yeah, reorgs are honestly pretty implausible. But now that Uri mentioned it, you could have like a multi hope agreement, right? Because you not only know your turn, other people know their turn. So if you want to do like a ten block sensory, you could have a service that's like opt in and once kind of people doing the next ten blocks opted in, I think that could be an avenue for me. You can pretend to be multiple, right? You're running ten different validators. Sometimes they will be consecutive. You'll know, it coming ahead of time. That much is the same as mining, right? It's like, okay, you run a bunch of them, but the probability is like, you'll be stacked.
07:23:18.106 - 07:23:46.970, Speaker A: Like all of your Validators are going to get stacked is very low. On the flip side, if you can sort of scour the whole world for people who also want to opt in and find the next guy after you and then the next. That could be an attack. That's not a happy thought. Well, we're not here to hit think happy thoughts, guys. Sorry. I came up to idea it's related to what you was just discussing.
07:23:46.970 - 07:24:42.378, Speaker A: Let's imagine that Mev appeared with 1 billion of US dollars, how many network reorganizations we would see in next 24 hours possibly that every miner would try to remind this block. And that's why Mev is dangerous, right? Originally I wasn't in favor of Mev, but that's definitely one of the top two reasons for something like Flashbots. The other being Flashbots did an amazing job removing the whole gas biding, like where I am in the block. And now we're all enjoying really low fees because of yeah, but actually reordering is one thing that is solved by proof of stake, right, true. Good point. And Anton, like more on your example. I think if we actually think through this, I'm not sure if it's that bad, right.
07:24:42.378 - 07:25:21.862, Speaker A: If there's at least a few honest miners, it's like they mine on top of one of the blocks just by being naive. And then you have a bit of an advantage and then the others are at a disadvantage. So that's one defense and then the second defense, if literally everyone is remining, I think the miners quickly realize that I'm not winning this, no one's winning this. And then they could do a thing where they sort of shift the Mev onto future blocks that are like, hey, I'm going to take, let's say 30% of this and then 70% goes to the people who mine after Me. And then that 70% is also split. It's like, okay, I'll mine on top of you. I'll take the 30%, you get the rest.
07:25:21.862 - 07:26:06.678, Speaker A: And then it's kind of this you thought about it a lot. That's why I'm on this panel. But yeah, that's where we got all the killers. Should this be also implemented inside node? This kind of logic and also tested, I think proof of state kind of like solves it anyway because people are not going to be reminding this. And I think Flashbots were also thinking about this a while ago. They had the idea that was then scuttled to route everything through a smart contract. And part of the things you could build there is kind of you programmatically enforced in a smart contract that you stake something or give something to the future.
07:26:06.678 - 07:26:50.630, Speaker A: And I think kind of another way that came out in practice was when finance got hacked for 50 million and people were also debating it's like, oh, but what if they sort of instead of just taking the loss, they essentially offer the private key as a bribe to the miners. But then the miners would fight, but then they would pay a little bit to the next blocks. And so kind of that debate came up and kind of people thought of that solution and I guess it's doable in theory at least, I think that's a happy thought to end on the billion dollar mev. Thanks, everyone, for joining. This is a really great panel, really great team. And yeah, I guess we'll see everyone on Twitter. Thanks, Tom.
07:26:50.630 - 07:27:20.160, Speaker A: Bye, guys. Thank you, everyone. See yep. Bye bye. All right. Thank you, Tom, for this panel. And we're now down to our last panel of the day, moderated by Dan.
07:27:20.160 - 07:28:04.060, Speaker A: I guess I'll stop sharing my screen so that we can see all your faces, guys, I was just showing the questions real quick. Dan, I'll let you take the stage. All right, well, thanks for having us. This has been an incredible day of talks, and I feel like we're very privileged to get to wrap this up and really focus on impacts for protocol developers and for users of those protocols. So thanks. I know the schedule said we were having somebody from 1inchh join us, and I don't think we are until we've got Benji Richards from Future Swap is added to the agenda. And so welcome, Benji, Joseph, Scott, and Jerome.
07:28:04.060 - 07:29:57.090, Speaker A: So actually, just maybe you want to take the first shot at know we've had a lot of quantitative approaches to mev today and trying to quantify how much mev it is, how bad it is from what you've seen interacting with the Sushi swap community. How much of a problem do you view mev as today for the users and potentially for the development team? As, like basically every trade that's like five digits or more is, in USD terms, right in the tens of thousands of dollars is getting sandwich attacked if your slippage bounds are not tight enough or if there's, like, a profitable sandwich attack there. Do you assess that users are aware of this, or is it just kind of, like, happening? I just talked to somebody just the other day who's, like, a large trader. They're trading in seven and eight figures, and they said they went back and once somebody had showed them kind of like a site that would highlight mev that had happened to them, just selected by their wallet, and they said, every single trade I've made this year has been hit with mev. It's like, damn. But I'd say quantity wise, capital wise, it's bad, but I'd say quantity wise, most users aren't trading in that range or they're trading in ranges that are just unprofitable for me. If we're not having a gas crisis, that makes sense.
07:29:57.090 - 07:30:32.216, Speaker A: Scott, you've had a pretty broad view across the Ethereum ecosystem, and you've been part of the flashbots community since the beginning. Does that sound similar to what you're seeing across other projects of, like it's just a fact. It's there. People don't really think about it that much, but it's just ever present. Yeah. I think that slippage has started to become instead of an amount that you'd be willing to accept. I've seen some users start to recognize that this is the amount that I will be accepting.
07:30:32.216 - 07:31:49.620, Speaker A: And if that isn't the case, it's like it was your lucky day. And so I think that with this change that there are some users who are more aware of just how much that they are leaking here and trying to set their own slippages tighter and work with protocols that maybe don't have slippage in them, such as these RFQs. And I think that there is been some awareness there, but I think we could do a better job of promoting this information, especially from the wallet. That makes sense. So while users seems like they're accepting it just because they have to, from the protocol developer side, I'm curious, how much is this coming up in conversations within your teams or talking to developers and other teams? Is this something people are designing around or just it's there and we have to deal with it or if it's going to get solved, it's going to get solved at the protocol layer. Yeah, it's kind of fun in this way because Flashbots has both kind of created the crisis, but then it also has the Band Aid, which is well, just privately relay your transactions. So it's a bit of two sides of the same coin here.
07:31:49.620 - 07:33:23.052, Speaker A: I do think that relying exclusively on private relay is a little bit of a Band Aid to get us through, I think, what's going to be some real fundamental changes in protocols and UX that are going to, I think, ultimately mitigate this to a level that I think that users will find more acceptable. Mostly it's projects that come around and say like, hey, we want a private relay because we actually haven't solved this problem. So also sorry, Luciano is here, just not on video from Urine. Luciano, I'm curious, within the Urine developer community, as you're looking at different vault strategies and different pieces here, how much does mev factor into discussions for what you do and don't do or how you implement it? Yeah, hey guys, mev is actually a big part of what I develop for these days or this past month, I think. So for strategies and for strategies, sorry. And for most protocols or forks that usually use the same kind of code base as we do, kind of the most critical part is kind of the harvest method. So whenever the strategy kind of claims their rewards and also blindly swaps them, so we usually have 100% slippage tolerance on those methods.
07:33:23.052 - 07:34:39.900, Speaker A: So they are extremely juicy and extremely tonable and sandwichable by whoever, basically. But the thing is, we haven't seen any attacks at least on wire until a month ago whenever this first happened, right there. So we were using Keeper network jobs to do that. So a Keeper got sandwiched and we lost, I think around nine k on a trade. So we stopped all the jobs and we've been doing kind of this harvest manually through Tai Chi and we've been as well developing a lot of contracts to kind of force or incentivize keepers that are like the bots running the jobs to use either Flashwatch or a private mempool. So it's kind of been a pain in the ass to having to deal with mev but we already kind of knew that it was going to happen. We're just like waiting and hoping to have a bit more days to able to develop but also it helps us grow in a more robust and kind of reliable solution.
07:34:39.900 - 07:36:03.510, Speaker A: So when you're using these relays that keeper networks, is that just kind of like a standardized repeatable solution you can just apply across most situations or do you have to do a lot of tuning for specific implementations? No, yeah, it actually is kind of a generic solution we come up with. So we have a set of contracts called the Stealth Bout and the Stealth Relayer that let's say they have a few checks both for only EOA transactions or accounts and for kind of a slashing mechanism that it will happen if the transaction gets either publicly available or there is another issue or collision with EVB. So the keeper will get splashed and the protocol can at least get some refund out of it if the penalty is high enough. But yeah, the thing we develop obviously is right now we are starting to test this. I think we deployed yesterday actually on wiren but then when it's kind of battle tested, at least for us, anyone can use this. So we hope it helps a little bit on the ecosystem. So this will be something that anybody in the ecosystem can just start using this once you guys have got it to a place where you feel good about it.
07:36:03.510 - 07:37:01.850, Speaker A: I don't think I'm here, sorry, go ahead. Obviously it has a little bit of gas cost for the user. But let's say for example for us, the keepers running jobs on keeper network usually kind of have an implicit cost for reverted transactions since they are always raising each other. The first one that gets the job done is the one that gets paid all the other transactions if they don't get canceled or even if they get canceled, incurring a cost of the cancellation of the cancel of a transaction. So by forcing them to use flashboards, we are actually making them save money so we can also lower the cost of the jobs that we work. So this is kind of a good win win situation for both of us. That does sound pretty good.
07:37:01.850 - 07:37:54.612, Speaker A: Sounds like you guys have got some good solutions there. We heard that it sounds like generally people are accepting this. It's kind of like an ever present thing. Are there any features or things that any of you have looked at implementing and then discarded and just said like we can't do that because just the mev problems are too great? Not sure our problem is pretty small one and it's pretty easy to tackle. So our vulnerable method, quote unquote, is not like user facing. So the end users are not the ones that are kind of taking the slippage. So it's easy for us kind of to mask or to move this vulnerable swap into more protected systems.
07:37:54.612 - 07:38:46.344, Speaker A: But in the case of a Dex or a CDP where you need this to be publicly available, it gets more complicated. And we didn't even thought about a solution for those kind of issues. It seems like maybe more relevant to the Sushi or Future Swap projects because you guys do a lot of trading. Have there been any things you guys have tried to do where you're just like can't do it? Mev is going to be too much of a problem. Yeah, right. Like our harvester, we take all our fees and LPs and then we have to unwrap and harvest those and we have a service that helps us with vulnerabilities and about once a week we have like a vulnerability. Reporter it's like people can sandwich attack when they press the harvest methods.
07:38:46.344 - 07:39:30.004, Speaker A: Right? It's just something that we have to deal with or we either have to privatize that and put tighter bounds on it. Yeah, I know. At Future Swap we were looking for our V three to use polygon and essentially the miners or I guess stakers can trigger block reorbs in certain situations. So you would actually have like a two and a half minute window to go back and insert one of your transactions. And that's definitely something where we had to scrap our plans and kind of go back to the drawing board and rework that. And so you guys were going to launch on polygon, didn't because of that. What are you doing instead? Yeah, so we're launching on Arbitrum.
07:39:30.004 - 07:40:27.710, Speaker A: We've been chatting with the team and essentially their sequencer solves that problem. It's a trusted entity where you're trusting Arbitrum right now to run that. So it's essentially you're trusting them not to wreck the brand name. Okay, so I don't know if everyone was online earlier for Tom Schmidt's talk about kind of protocol approaches to mev or sorry, I guess more application level approaches mev. So one of the things that he mentioned was ways to internalize some of that mev into the protocol itself. Is that something that any of you have explored as potential solution? Or if not, are there other things you've looked at to kind of turn this on its head rather than just being like we'll try to minimize it, but it is what it is for us. We have looked into that.
07:40:27.710 - 07:41:38.690, Speaker A: The issue that we come around with is to solve mev. Every single solution relies on Asynchronous and we just have this lovely synchronous composable network right now. And introduction of Asynchrony is problematic for if you're an application that you want other people to compose with you. So it's like where do you put the Asynchrony do you put it in the protocol level? Do you put it in pre consensus like with Flash bots? Do you put it at the L one? Because there are great solutions if the assumption is that what is fair is natural ordering, right? Like first derived, first executed, there are good solutions out there, like threshold signatures, et cetera, that work. But it's just like are we going to remain synchronous? I think is the real question. And we're probably going to have to give it up in E two anyway. Anyone else have thoughts on that? Some of the designs that I've heard floated around, revolve around trying to get the number of participants that can extract this mev very low, sometimes even down to one.
07:41:38.690 - 07:42:25.600, Speaker A: One of the proposals was to have some sort of a token that has a supply of one that if you are the owner of this token, you are the exclusive executor of any of these MEB operations. But you need to pay to hold onto this token and that payment can go to the project operators, usually via some sort of like a harbinger tax. Yeah, exactly. This came from Austin Williams. I think you right. Yeah, it did. I think that's probably one of the solutions that I think of the most when I try to find a way to reduce that contention around who's competing and who's sharing so much that profit with the miners.
07:42:25.600 - 07:43:33.044, Speaker A: Cool. So when we think about different places where you can potentially have solutions, we talked about things you can do potentially at the protocol level, at the DeFi application level, but how about at the DAP level? This is one thing that I've thought about when I'm getting sandwiched on the daily. Is this something that the wallet should handle for me or is this something that the web app should have some solution and approach for this? Do you guys have any strong opinions on where some of this responsibility most easily sits? I think the easiest one would be the application, as Joseph mentioned, just having really tight bounds. For example, future swap. We have an adjustable bound, but I think the limit is defaults to 0.1, which is relatively small, 0.1%. So applications can definitely do that.
07:43:33.044 - 07:44:18.636, Speaker A: But beyond that, it would be amazing if Wallets started doing that. But pretty much any problem, everyone's always like MetaMask should do this for the users and I'm sure the hands are very full. Go ahead. I was going to add to that one of the things that I've always felt that wallets should participate more in is updating your slippage as blocks progress. I think that the UX around signing a transaction is so burdensome that people choose much larger slippage limits that are necessary because they don't know if a transaction is going to land in three or seven blocks where if your wallet and DAP could work together to keep your slippage really tight. Based on the current situation. As opposed to just firing once and hoping it lands in a couple of blocks.
07:44:18.636 - 07:45:22.550, Speaker A: I think you could prevent that single block mev from growing, especially when prices move kind of in your favor. That feels like significant complexity to add. Yeah, absolutely. No, it's definitely not simple. I think it's really sad that I'm going to ship this with 2% slippage because I don't know what's going to happen because I'm not a computer that can react. I have some thoughts around this with the mev. Do we think that mev is like a tax that we're willing to pay? Right? This all comes from just like, pre consensus, right? This idea that I can't validate that a message arrived, this is all included in the Byzantine general's paper.
07:45:22.550 - 07:46:16.824, Speaker A: I can't validate when a message arrived. And so a lot of our network just relies on this pre consensus, kind of like whisper and gossip altruistic network. And our public mem pool is going to suffer pretty soon if we start kind of like, going down this road of like, okay, well, I don't want to get robbed, so I'm going to be blackmailed more regularly. Right. It just doesn't make sense to me yet. Yeah, it feels like we need some I know that when I am doing certain trades that I know are likely to get sandwiched, I just flip over to Tai chi and MetaMask, and that's like the easiest solution for me. But it feels dirty.
07:46:16.824 - 07:47:53.484, Speaker A: Like, why am I sending it just to one mining pool that doesn't feel like the decentralized future we were promised? Well, so one of the more extreme things that we talked about here and Joseph, you actually addressed this a little bit in one of your earlier answers is the idea of where composability becomes a trade off. Here one thing that I've seen, at least discussed more, and I think we're starting to see outside of the ethereum ecosystem a bit, is the idea of application specific chains where you can have more, I guess, fine tuned trade offs to your own application and potentially manage fair ordering in some way. But the trade off is you lose a lot of composability. Is that an approach that you think will become more common or necessary? Or what would it take for the extent that you're working with the protocol, what would it take to get you to say, okay, yeah, we need to go and do this just to create a better experience for our users? I think it will become more common. I think part of the reasoning is people in search of a solution to MAV, but it's not really a good solution, in my opinion. To say that you're going to do fair ordering is like, okay, well, I hope, right, you're going to pinky promise each of your nodes that you're going to do fair ordering of the transactions. That's what optimism is saying.
07:47:53.484 - 07:48:26.964, Speaker A: They're saying, oh, we're going to do natural ordering of the transactions. Okay, how long does that last? Right. When you move to these application specific chains, you don't really have any control. Well, you can say that you're going to do it a specific way and you may or may not. That's not what we rely on. We rely on programmatic guarantees. Well, but do we need to rely on programmatic guarantees or can we think more kind of like economic guarantees? Like, I always go back to crypto economic guarantees.
07:48:26.964 - 07:48:57.840, Speaker A: Yeah, sure. Even some softer ones. Right? Like thinking to say, like the Auger security model, using rep as what you're bonding rather than just bonding ETH. Right. You can cheat it, but if you cheat it, you're going to destroy the value in something that you've been holding. It's more of a problem rather than using a completely separate platform asset as the thing that you're putting at stake. So by moving it to a single obligation chain, if you've got a native governance token and you're putting that at stake, it kind of aligns interest more for you to play fair.
07:48:57.840 - 07:49:46.080, Speaker A: Because if you try to cheat there, people are going to stop using the application and you've cost yourself all of your future cash flows as well. Yeah. Threshold signatures so far to me seems like the best solution. Flash bots are probably like the second best solution as like a patch. But I definitely think the solution has to come at the protocol level and I don't think starting a new chain for a specific application is going to alleviate that at all. But they will be very popular, no doubt, because people think it's a pretty light undertaking, but it definitely isn't. You could almost consider that as like what Duidx did with yeah.
07:49:46.080 - 07:50:29.964, Speaker A: So I know Benji. That future swap. When you guys did your Alpha launch a while back, one of the reasons that you guys ended it early was realizing that there were some meaningful mev problems related to doing Oracles on l One, especially once you've added on a significant amount of leverage. Can you share a little bit more about what that looked like and how you may have tried to address that in future versions? Yeah, definitely. So we launched Future Swap V One when mev really wasn't a common term. This was like April 2020 and essentially what you saw was exactly what everyone now knows. Mev is front running and back running.
07:50:29.964 - 07:51:22.320, Speaker A: We had the front running handled of at least the Oracles, but the back running was definitely a problem. So we went back to the drawing board and no l Two was even close to ready. This was last summer, and a solution that we came up with was, what if we have somewhat trusted entities, these off chain Oracles that are in charge of sequencing the transactions. So the user would actually sign the transaction and then it would get broadcasted to the we call it the Oracle Relayer Network. And then they would be in charge of putting it on. And again, there's a whole complexity about how do you trust them, what are the repercussions if they're dishonest and how do you prove that? Which is a whole nother can of worms, but essentially in the last version, future Swap V, two traders would just sign a message and then their trade would be pretty much executed because it would be broadcasted to the off chain Oracles. They would sign it and then they would be with the ones putting it on chain.
07:51:22.320 - 07:52:00.780, Speaker A: So just kind of all then went on chain through that network. Exactly. And since they already had the price labeled off chain in that order, it really didn't matter if you got in front of them or behind them when it mined on chain. That's interesting. I didn't know that about your platform. That sounds very similar to how preconceisus happens on Flow. The Dapper Labs blockchain, they use a sequencer so you kind of get block ordering from the jump and then they do their execution and block creation afterwards.
07:52:00.780 - 07:52:53.254, Speaker A: That's interesting. I have to check it out. We now are going down the model of saying Arbitrum, like trusting that entity is good enough for now. I know that Ed Felton has a paper on actually how to prove sequencing. I haven't dove into it that's way above my head, but hopefully they actually implement that. So it's not a trusted is this is this like one of the more, I guess, practical solutions right now? It sounds like going to a smaller number of people who can take actions or trusting some party in some capacity to be ordering. Is this the path that we're likely to go down over the next, I don't know, six to twelve months where we're just going to rely on some more trusted or centralized solutions? It sure looks like it is.
07:52:53.254 - 07:53:42.674, Speaker A: Like everyone's ready to launch on Arbitrum and while they can only reorder and manipulate it that way, they can't actually do anything fully dishonest. It seems like that's a consensus. Everyone's perfectly fine with that. Anyone disagree? Yeah, just a little bit. I think with the technology we have today, we can minimize mev a lot. So basically a similar thing, let's say. Okay, yeah, you can basically just reduce slippage to a minimum percentage amount as a user, obviously, because you can off chain calculate the price you're going to get doing this on chain.
07:53:42.674 - 07:54:42.220, Speaker A: Obviously it's way more expensive. You only kind of have the risk of the price moving and having your transaction reverted. So basically losing money or losing an opportunity, you can obviously use, as I said, like flashboard bundles to kind of avoid your transaction getting reverted. You can also kind of send your transaction through a relayer that only executes the transaction on a certain block. So you can actually kind of avoid having the ankle bandit attack on your transaction if it gets included in an ankle block. But I think just by having users kind of opting in into, okay, yeah, I want to pay a little bit more, but my transaction and obviously having to sign a bunch of transactions until it gets included into the block. This is kind of the bad UX you will have.
07:54:42.220 - 07:55:55.250, Speaker A: But it won't cost as much as whenever there's a bank run or whatever. There are a bunch of failed transactions. I think Vitalik was the one that kind of had to use Archer Dow to kind of drop all the tokens, like a few months back. But let's say the reverted transaction cost for last month were like 150 ether, so like around $330,000 just on reverted transactions that did nothing. So let's say hypothetically, if you could send a transaction to the protocol and it costs the same as a regular transaction, but you send it with a flag, that okay, if this reverts, don't include me, that will be like a huge improvement on the protocol because you can just circumvent this cool feature that Flashbot gives you. But I think with only that, obviously it kind of ruins a bit the user experience. But I think those are kind of the 99% cases where users get a bad experience out of the network because of mev.
07:55:55.250 - 07:57:23.580, Speaker A: So it sounds like is that like your kind of top near term wish to see an ecosystem for improving the mev situation would be better, I guess transaction management from wallets is that what yeah, exactly. This obviously can be done at application level, so in the UI, but the wallets are the one that should implement this as a more general approach. I'm curious, the rest of the panelists, we've heard from the foremost experts in the world on the topic of MEB today. They've proposed a lot of different paths for research, different solutions. You've all got your hands full kind of working on very specific projects right now for the broader research community. Are there asks or things that you would say like, hey, this is the thing that for our protocol, for our users would make the biggest difference for them realistically, over the next six to twelve months. Flash bots, that's the direction we're going for these private mem pools.
07:57:23.580 - 07:58:33.652, Speaker A: We have integration with Archer Dow. I think that's already released. Maybe it's not, maybe it'll be released this week, but integration with Archer Dao y Cabal and a bunch of these other mev pools. Benji Scott yeah, I mentioned earlier, I'd love to see smarter wallets that are able to kind of take advantage of some of either the private relay to protect users or cancellation when things don't work anymore. I think to the point that was brought up earlier about how much is wasted on these rover transactions, we have the capability to do these things, and I think it would improve a lot of things, improve negative externalities and how much money users are spending on these things. I think I also want to make sure that when we talk about mev, we don't try to overcorrect and reduce mev so much that some protocols become unstable. With the Black Monday thing from a year ago, there was a pretty massive problem that occurred, I think, because mev was reduced too much in that system.
07:58:33.652 - 07:59:13.360, Speaker A: And I think some mev is a good thing. And we shouldn't try to drive it all out. We should try to leverage it into a system that can react appropriately when necessary. What if we take this to a logical conclusion, right? If you want the wallets to help manage this, we don't want to waste gas on failed transactions. Shouldn't wallets then by default just submit everything as a zero way transaction through Flashbots? But then what are the bigger consequences of that? Right. That solves that problem. But it presumably creates a nuance.
07:59:13.360 - 08:00:00.690, Speaker A: Yeah, I think it creates a lot of probably load on the system, especially a system we're still trying to decentralize. The point made earlier about who do we trust? Flashbots is a system that's also working towards this more decentralized architecture. I think that there is probably not that much negative aspect of it so long as these back channels and private relays and these executions can keep up with that load. I can't think of a lot of negative externalities to these transactions appearing directly in my blocks. Actually. Maybe gas wars. Right? You're going to get back to gas wars because people who want to take these mev are going to try to outbid each other on the next block as opposed to doing it in the current one.
08:00:00.690 - 08:00:51.328, Speaker A: I wonder if there could be some reverting to the old top of the block warring again. Right? I guess the miners will be happy about yeah. Benji, any wish list for you? Yeah, I wish that the wallets would natively handle this for users because using MetaMask is already complicated enough for the average person that's just using Robin Hood or something like that and then trying to explain to someone what mev is. There's zero chance it's actually going to happen. And there's the site, and you can see like $750,000,000 or something in mev if you look at it's, not like a linear graph. It's growing almost exponentially. So this year we could easily see it break $2 billion.
08:00:51.328 - 08:01:54.266, Speaker A: And so the quicker we address this, I think the easier it'll be on the end user. All right, well, we're about up on time here, so I want to thank you guys all for joining and participating in this. And thank you to the audience and the organizers for having us. Well, yeah, thank you. This will mark us exactly, I would say, well five minutes short of 8 hours marathon on mev, and this panel has wrapped up our part four, which is application level response to mev. Thank you for a great panel. And it's very rare for us actually here that some of the biggest developers in DeFi sharing their expectations on how future of the DeFi stack is going to evolve.
08:01:54.266 - 08:02:28.890, Speaker A: So we hope to discuss more of these with you guys to bridge the researchers and the builders together so that we can get a much more coherent and coordinated view on what is ahead of us in tackling MEB. Yeah. So here we go. Our time is up and I would like to see you all on the next Mev Roast. Thank you, everyone, for joining. Have a good evening. Thank you, guys.
08:02:28.890 - 08:02:29.990, Speaker A: See you all.

00:00:06.250 - 00:00:22.670, Speaker A: Okay. Welcome to our do workshop for ethf. Sorry. For some reason, my computer just decided that it wants to be in the night mode and it wants to sleep. So we're gonna just go with us today. So my name is Jackie. I work as wizard relations.
00:00:22.670 - 00:00:49.766, Speaker A: So, basically, developer relations for Do Dune. I go by Agape online. And then I guess a little bit about my background. I used to be a developer for banking and then decided I want to do more data stuff for traditional finance. And then I found out about crypto, and I'm just like, oh my God, I need to be in this field. And then I just started doing like when you do Web Three data, you cannot help but run into Dune, basically. So that's how I found out about Dune.
00:00:49.766 - 00:01:23.840, Speaker A: And then here I am working for Dune. So today we're going to go on a journey about how to build the frontier of Web Three data analytics. Okay, so if you want to follow along, there's like links and stuff. This is the link for the slides itself. So I put some reference docs links there. I'll leave it on for like, a few more seconds for you guys to scan. Put this a little lower.
00:01:23.840 - 00:01:51.414, Speaker A: Okay, cool. Looks like we are getting there. Okay, cool. Okay. Data, right? So up till now, the data in the old world where, like, the Web two world where Harold lives thing, right? It's like, proprietary. You have to pay for the access, and it's very slow. So think about, like, I don't like JPMorgan, these big banks, everything for them is super close.
00:01:51.414 - 00:02:18.938, Speaker A: They want to make sure that they have the best competitive advantage. So everything is proprietary for them. Close. And then you need to pay like Bloomberg. It's very expensive, right? Like, if you have a Bloomberg machine for your analytics, and then if you think about, oh, there's always talks about earnings, seasons, right? Like, you have quarterly reports, so you don't really have real time data about your firm, like the industry per se. So as a result of that, you're doing a lot of repeated work. So that could be like, data scientists from two different big banks.
00:02:18.938 - 00:02:53.286, Speaker A: They might be working on the same project, but they're not really collaborating with each other and learning from each other. And because it's so expensive, you don't really have access to good, good data. So it's like high barrier to entry. And as a result of all of this, it's just like less innovation for humans, for people who are interested in Web Three data in general. Crypto, though, on the other hand, we have a shared public back end, right? And then we are able to have a live view of the chain. So it's like real time. You can see what exactly is happening with all the transactions.
00:02:53.286 - 00:03:46.086, Speaker A: Anyone can analyze it. Real time, flexible, and it's super collaborative. We're all building toward the same goal. So as a result of this, a result of a super open system, a collaborative system, and everyone's building on top of each other, right, real time, I would argue we would argue that the Anon crypto Pepe actually has better access to data about their system than, say, Jamie Dimon from JPMorgan, right? Because of the crypto ethos and the way data is set. So for me personally, that was one of the big reasons I got into Web Three data. It's just like for me, for the first time in history, I see because before it would be like, kaggle, if you're a data scientist, it'll be just like, okay, Kaggle, we have free data, then we can train models. But now it's like we have real data about Blockchain, it's free and it's real time, and we can just like everyone's building toward the same goal.
00:03:46.086 - 00:04:41.438, Speaker A: And that just really excited me. Okay, so how does Dune fit in with the whole Web Three data thing that we're just kind of talking about? So, Doom is a leading community powered crypto data platform, and then our mission is to make crypto data accessible to everyone. So kind of assuming if you're here, you're interested about Blockchain and you hear about how Blockchain is open and everyone has access, but if you actually look at it from a node to when you can actually produce analytics, the journey is quite a lot, right? You have to first harvest the data and then you have to preprocess it to be the format you want. And if you do analytics, it's just like quite a lot of work in between actual data and then the data that's being produced from Blockchain. So what Dune can provide for you is that basically in aligning with the Web Three Ethos, it's open to everyone. It's composable. So you can building Lego style, you can build on each other's work.
00:04:41.438 - 00:05:14.582, Speaker A: I can show a little bit more later and then it's very community driven. So everyone is here to build with everyone else, and we're all here to help each other. So that is dune together with the web3 ethos. And a bit more specifically, the way I think about Dune is like two component. So you've got the data component, which has the role tables, the decoded tables in the spell book we call them, they're like abstractions that are built on top of the role tables and decoded tables. I'll give you some examples, like later on, right after this. So that's like the data side and there's the community side.
00:05:14.582 - 00:06:08.086, Speaker A: So we call our community members wizards because they're just like making magic to the data. So they're like an essential part because if think about it, when GitHub become really popular, you got these open source coding that's happening. So everyone's like open source software, right? And that's how we got to the space to be where we are today. And we're so early in the open source data field, right? So it's like tens of thousands of people. Eventually, hopefully millions of people are just like here and building the data analytics, right? So before this, people don't really think about engineering. We're building data analytics, but we can because we have the same shared back end and why not? Okay, so for the rest of the talk, just going to kind of explain how you can use Dune to build the frontier of web3 data through kind of like three different ways. They're not independent, they actually feed into each other.
00:06:08.086 - 00:06:45.702, Speaker A: But just categorically speaking, these are the three ways. And then we're going to kind of go into the angle from NFT Marketplace analysis. So we're going to try to look at NFT Marketplace. Okay, so data. So just kind of like level setting data is produced by on chain activities, right? So here we're just going to use a super simple example because we're talking about NFT Marketplace. So we're talking about NFT trading. So simply put, person A just like get person B some money, and person B just transfers the NFT back to person A, right? Like in a very simple life format, that's like what happens.
00:06:45.702 - 00:07:27.294, Speaker A: So when this transfer event happens, kind of like the lifecycle of it, it's like an externally owned wallet has to sign this transaction, right? And then the signed transaction would call certain functions, right? Let's say like a transfer function. And then also it should also emit an event. Not all of them do, but let's just say it complied with the standard and emit events. So after this. So from the functions in terms of how it generates data, so the call functions will generate call data along with the send transaction. And the data will get reflected in one of the raw tables called the transactions table, right? If you're familiar with the Ethereum architecture. So that's how the data gets mapped to the action.
00:07:27.294 - 00:08:20.386, Speaker A: And then also the surface level transactions will trigger some internal transactions, right? So those data in turn goes into the traces table that we have another role table. And then for the emitted events, those are logged in the locks table. So we can kind of walk through an example. So here I have an example of just like on OpenSea, somebody wanted to buy this KPR token NFD. And this is like the transaction hash for it. And then so in turn, if I want to look at kind of like the transaction data associated with it, what I can do is I would grab the transaction hash from it, right, and then I can make this bigger so you can actually see. Okay, so here, remember I was kind of talking about the three types of data.
00:08:20.386 - 00:08:48.762, Speaker A: Actually, let me minimize it one more time. So on the left hand side, you can see that we have the role table, right? The decoded projects and the spells. So the role tables are just like transactions, traces and locks. Those raw data that's being emitted by the chain, like broadcasted by the chain. The decoded projects come from. Let's say you have uniswap and you have smart contracts and those produce data. But instead of just going straight up to the transactions, like the role tables, you can actually go to the decoded project to get better data.
00:08:48.762 - 00:09:38.138, Speaker A: And it's really powerful if you know what you're looking for. And then the spells are just like abstractions built on top of both raw and decoded projects. And let's say if you want to analyze all the trades in the NFT sector and then you might not know. So as a person who might not have deep backgrounds about how is a trade being constituted, how can you read the trade data basically from the solidity code level, right? You can go to this is like all community gathered data. So we have these NFT trades table. And then from here, you can already see there's like, the amount that's being traded, right? You can also see like, the buyer, the seller of it. So, like, if you start from like the top, we actually have table like this, like spell book table that you can start.
00:09:38.138 - 00:10:08.806, Speaker A: But those are kind of like diversion from what we're talking here. So those are three types of table that we have. So kind of coming back to the role table example we're talking about. So we can query from Ethereum transactions table, and then we just filter for the specific hash. We're looking at putting the block number just to optimize the performance a little bit. And then we can simply see, oh, from this person to this person. This is the transactions that's been triggered, and then this is the data associated with it.
00:10:08.806 - 00:10:38.762, Speaker A: But as you can see, it's very gibberish. You can't really read it. It's just like, blah, blah, blah, blah, blah. So you need to do more work about this. But yeah, so that's the transactions table and then I guess quickly show literally the same logic about the traces table. You just query the Ethereum traces, put the transaction hash, and then you get all the internal transactions that were triggered by this top level transactions. But again, the problem here is just like, it's still not very human readable.
00:10:38.762 - 00:11:09.258, Speaker A: It requires you to have a lot of skills to be able to parse the data. Here you can, because in order to get the higher level tables that we talk about, someone has to be equipped with this knowledge. But that's like the beauty of the space. Only one person needs to find that, and then everyone else can benefit from you. So to me, that's the beauty of open source data. Okay, I'm going to skip the locks table. You kind of get the idea these are like the real tables and then just decode a table just to give you an idea.
00:11:09.258 - 00:11:46.034, Speaker A: So with OpenSea they release their support contracts and stuff. So you can directly query for the OpenSea support contract, this particular event order fulfilled. But again, this requires you to have some skills. You have to know how to parse these data tables. However, if you just go to spell book so NFT trades table that I was just showing you guys, literally, like here, it's like super clean. You can just select the seller, the buyer amount, original currency, symbol, and then you get a really clean results. I don't know.
00:11:46.034 - 00:12:28.894, Speaker A: So when I started looking at I used to flip NFTs, and then when I was looking at the data to support what NFT arbitrage opportunities I should look at, it was like so much to just look at the contract level data. But then once we have this NFT trade table, it's just so beautiful. You're able to just do analytics so quickly. And then it almost like I feel like in a way, it's like the community itself is democratizing the community itself, right? Everyone's building toward a higher level table, and then we're just going to get better and better as an ecosystem. But yeah, so those are the data tables. And then just like quickly, a word. The way you get from some base level tables from transactions traces to NFT trades.
00:12:28.894 - 00:12:58.774, Speaker A: We use this thing called DBT for data transformation. You can read more. I'm going to skip this part. I just want to show you guys there's a quite nice lineage trace from this abstraction table. How do you get from the lower level to abstraction table? There's like a lineage graph that you can go look at. But yeah, I'm going to skip this for today. And if you want to know more about how to contribute to our spell book, you can check this link out.
00:12:58.774 - 00:13:37.238, Speaker A: There's like three different guides depending on your style. You can go digest and do it. Yeah, that's how you can contribute to open source data from the data perspective. The second perspective is the dashboard, which actually is tightly coupled with the first one, because without data, you can't actually do dashboards. But just going to show you guys an example. So here we're talking about how do we do NFT marketplace metrics, right? So this goes back to the spell book that I was talking about. So with the NFT trades table, we have data for OpenSea on Ethereum and Solana magic Eden looksra.
00:13:37.238 - 00:14:20.598, Speaker A: I'm not going to read all of them, but literally someone. So one person can go contribute to OpenSea on Ethereum and someone else can do OpenSea on Solana. And together we get this more complete system view of all the NFT marketplaces, and they're just beautiful. Amazing, right? So then with this table, what you can do is just like, okay, we want to see the total volume in USD term or in transaction count. You can just do that. The way you do that is super simple. If you know, SQL, you see like two lines of code, select, count, distinct, unique, trick ID from NFT Trades, right? So this really simplifies the process.
00:14:20.598 - 00:15:13.080, Speaker A: When we think about Aggregating total value locked in a protocol, it's just like such an insurmountable task, really, right, because you have to know what protocols are out there, you have to aggregate it, blah, blah, blah. But with a table like NFT Trades, it's like everyone is trying to reach that complete picture for NFT marketplaces, right? And then as a result, the people who come after we're all benefiting from the people before us. So we can just write a simple query like this. But obviously the caveat is you have to understand what data you're querying. So you have to understand the data you're querying only includes these marketplaces that are listed. But yeah, as long as you know what data story you're telling from, I guess that's like the trade off you're doing. You have more flexibility, but you also have more responsibility because you got to know what data story you're telling from.
00:15:13.080 - 00:15:54.600, Speaker A: But yeah, so with this data set, you can also just do some visualizations about the market share from different marketplaces. You can rank them by their total volume. And all this is done by just like writing some simple SQL. And then once you have the SQL ready, let me open one of these. So let's see with this pie chart, right? So you write some SQL, and then once you finish writing that SQL, you can generate a visualization from the results table and then you can just add it to your dashboards. I'm flying through all these. Just feel free to stop by our booth if you have any questions because there's just quite a lot to cover for our platform.
00:15:54.600 - 00:16:42.278, Speaker A: But yeah, so another thing I quite often do, feeding into learning from each other, building in public. So I go to this Discover page for Doom, and then I just look at what's trending. And I recently was really doing a deep dive on Uniswap, but I want to see what other people already did for Uniswap. So I just came here and I just did, oh, uniswap. And then I just searched for it, and then I see, oh my God, a lot of people already did similar things and I can go click into each of them, right? And then I just see what other people have done and then I just click into that query and I learn from it. So in this way, I feel like we're also building the frontier of web3 data through the dashboards. You're learning from each other, you're sharing it's like all in the public and they're just like, you're also having fun together.
00:16:42.278 - 00:17:24.930, Speaker A: How nice is that? Okay, so lastly, also kind of like feeding into the data side, you can also build a frontier of web3 data through just apps, right, through APIs. Okay, so we are still in the beta testing stage of API. But if you want it, come by our booth and we'll give you an API key to test it out. I'm just going to quickly show you a demo of how we can do this. Let me just pick something. Let's see, what did I pick over here? Okay, so we're going to just pull data for this one. So we're pulling data for the 24 hours volume on all the NFC marketplaces that we have on Doom.
00:17:24.930 - 00:17:49.834, Speaker A: And it's just like a number. So the way you can use API to pull Doom data is you get this query ID, right? So the first chunk of number after queries. So you copy the query ID and then going to come back here. I'm going to paste it here. Okay, I already did. Okay, so let's see. So nothing really hard.
00:17:49.834 - 00:18:21.474, Speaker A: I'm going to just import the packages that are needed. And then I just wrote like a quick function, kind of like calling our endpoints to get the data. I can walk through that in a little bit, but pretty much like just standard call to get the data. Okay. So first I'm loading my environment to make sure I can have my Dung API key. Cool, I do and make sure, okay, this is like the query that I want to query for. And then cool, I'm just like running this function.
00:18:21.474 - 00:19:11.250, Speaker A: So all it does is just like first, okay, authentication and then calling our API Dune endpoint and putting the query ID and then say, okay, let's execute. Right? Once it execute, it's going to get the execution ID for this particular query ID. So you grab that and after you grab that execution ID, because it hits our back end, it's like literally running the query live in our engine. So you need to wait till the query finishes. So here I just have a simple while loop just waiting for the query to finish executing. And once the query finished executing, then I basically call another endpoint to get the results for this particular execution ID. And then I just do some simple parsing to get like a Pandas data frame.
00:19:11.250 - 00:20:03.460, Speaker A: But yeah, we only have one number here, so it's pretty easy. We just got TADA like 24, 25.923. But yeah, like a very simple example, but you get the idea. So the way you can pull data from Dune is just like, you write a query about whatever you want to analyze and then after that you grab the query ID and then with the Dune API key, you just get the result and then you can feed into whatever application that you want to build. So going back to here and then this is like the link to API docs if you want to actually dive into a little bit more. So today or this weekend, we are giving five times 2000 bounties to just kind of like for epic integration with our dune API. Read more details online about this, obviously.
00:20:03.460 - 00:20:32.406, Speaker A: And then you can fill out this form. If you want an API key, this is the QR code for the form. But yeah. So lastly, just want to leave with some inspiration ideas, right? Because in a hackathon, I think sometimes unless you came with an idea, it's quite hard to know what you're building. So with Dune API in the past, what people have done, they built like sector specific market intelligence. So, like the Moonblocks, they did like NFT sector market intelligence. So they were just like pulling data from Dune.
00:20:32.406 - 00:21:05.080, Speaker A: Like basically the NFT trades table that I was showing you guys and then they feed that into their own app. Or someone else did like a no code interface. So they basically use Dune API to integrate with Google Sheet functions. That's something you can also do. Or there's like data transparency tool. Tornado cache was just like such a hot topic. So somebody a team implemented where you can put in your address and it will tell you how much closer you are to being kind of like doxed by the government.
00:21:05.080 - 00:21:34.060, Speaker A: But yeah, so some other things you can do. You can build trading automation because you can get trading data live from Dune. You can think about how to transform Webtooth things into Web Three. So, like the same funnel that Web Two analytics often do, you can do the same thing in Web Three just in the same stack. But yeah, so the data must flow. And happy hacking this weekend. Thank you.

00:00:00.090 - 00:00:04.000, Speaker A: Without further ado, I'd like to kick us off with Alex's Talk.
00:00:04.690 - 00:01:11.090, Speaker B: Welcome to the talk about Zkavm, the technology that will extend ZK roll ups from application specific functionality to generic programmability. This has been considered a very difficult task and it was in fact impossible up till this year and many people thought that arrive up till a few years from now. But I'm CEO and co founder of Metal Labs, the company behind the ZK Sync protocol and I can attest that Zkvm is coming to Ethereum this may on the testnet and in summer hopefully to production. And in this talk I'm going to go into the history of the ideas behind generic computational zero knowledge proofs and we'll demonstrate why it was not possible, what changed, what breakthroughs actually make it available for us today. And hopefully I'll be able to give you a good intuitive understanding of its design. I will assume that you have some basic zero knowledge proofs understanding. If not, please watch other videos.
00:01:11.090 - 00:02:08.198, Speaker B: We don't have time in this 20 minutes talk. Let's start by recapping quickly how ZK roll ups work. We have a state of our blockchain or a roll up with some accounts, they have some balances, some data, they are packed in the merkel tree. We have a root hash of this merkle tree serving as cryptographic commitment to the state. And whenever the state changes, because we apply one or more transactions to it, the root hash will also change and we can define the transition with a so called state transition function. So whenever we have a block, the new root hash will be result of the state transition function from the previous root hash. The transactions data that are involved in this block, the accounts that are modified by those transactions and the merkle proofs for this account.
00:02:08.198 - 00:03:12.438, Speaker B: And this is all information we need to construct a new root hash. This is in fact what you would place in a stateless client to verify a block. So if we only could implement the state transition function as a zero knowledge proof, this would allow us to implement any type of ZK roll up and we actually have this. So, ZK Sync is live on Mainet since June. It's been used for payments very actively and we have the very efficient provers, very efficient arithmeticization techniques that is frameworks that convert the algorithms in the state transition function into the form which is digestible for zero knowledge proofs. We have all the server infrastructure around it, the smart contracts. So all we need to do in order to support generic compatibility is to make sure that the generic smart contracts can be efficiently arithmetized.
00:03:12.438 - 00:03:54.274, Speaker B: And this is a big challenge. The Arithmetization is a process of converting the function into what we call an arithmetic circuit. It's a directed Acyclic graph where the inputs of your function are the initial nodes and then you go through a sequence or through a network of gates. Each of the gates represents an operation of addition or multiplication in a finite tilt. And eventually you keep accumulating your results and you get to the final output. And you can imagine it can be really complex if you have a big algorithm. So something like simple arithmetic operations are very cheap.
00:03:54.274 - 00:04:26.690, Speaker B: You can do them with one gate. Logical operations will take more gates. Hash such as shutter, five, six or even Ketchup will take a lot more of those gates. But that would be doable. The problem we have, or the challenge we have, is how to make it generic. Why is this a challenge? If you're familiar with your knowledge proofs, you know that the Verifier, which in our case is a smart contract on ethereum, must know in advance the circuit. So the circuit must be fixed.
00:04:26.690 - 00:05:45.786, Speaker B: You can't change it on the go, you define it once, then you make some computations to generate a verification key, and then you use this verification key to check the proofs. Now, with generic smart contracts, we want the users to be able to define the contracts and deploy them on this chain permissionlessly, which means we cannot rely on a single static rigid arithmetization of one fixed state transition function. So we need to find a way how to have multiple contracts coexist. So let's go through the history of ideas that were tried in this area. We will start with an approach called tiny Ram, which is already eight years old. And this is a really fantastic idea. It solves the problem by saying let's create a circuit which verifies not an execution of a single algorithm, but let's make a circuit that can verify any algorithm by verifying the execution trace of the program.
00:05:45.786 - 00:06:42.160, Speaker B: The way we do it is we assume that we will have N steps of execution. You can think of them as the cycles in the processor. And at each of these steps, what we're going to do is we will read the inputs and the opcode from the program counter and we will do all of our operations. And then we will select the result of only the one operation which actually is supposed to be executed at this step. So this gives us a quadratic complexity or like number of steps multiplied by the number of operations. And the number of operations must be relatively small. So we would go for something like risk architecture with a small number of opcodes, which must be relatively equal in cost, and we could then prove anything.
00:06:42.160 - 00:07:21.382, Speaker B: How It Works to give you a better, more intuitive understanding, I made this model in a spreadsheet. Let me show it. Imagine that I want to write a program. So I want to turn this spreadsheet into a universal interpreter of a program. I will provide my program here in the yellow columns with the type of operation at each step and the operand. And I want this program to be executed every time sequentially. So each step must be applied to the result of the previous computation.
00:07:21.382 - 00:08:21.870, Speaker B: We will start with accumulator, with a value zero, for example. And then I'm going to add 13, subtract five, multiply this by three, and so on. So we're going to support three operations add, sub and move. And as you can see, when I change something here, all of the computation changes starting from this step. And finally, in this cell, we will have the result of our computation, of the application of all of this program. So the interesting thing is I can modify the program and I can modify the inputs, but the spreadsheets itself, the formulas, or essentially the circuit which I use to produce this final outcome remains the same. And if you look at how I constructed this circuit, at each step, I do a simple computation.
00:08:21.870 - 00:09:21.610, Speaker B: It's the same computation for all of them. And it's just a simple formula which does the execution of all three of our operations, addition, subtraction and multiplication. And I use this simple naive approach to select just one of them. So if the operator is add, then I will just take this result, because I will multiply it by one and not by zero. If the operation is sub, I will take this result, mal this result, and I just add all of them and I get only one outcome. So this is how tiny Ram works. So in this example, we have here only static problem, without jumps, without comparisons, without memory access, but all of them are possible to implement.
00:09:21.610 - 00:10:15.986, Speaker B: We have some very efficient models that could be used for Tiny Ram. The problem is that it's going to be pretty expensive. If you compare a program written like handwritten as a circuit to a program which runs in a tiny Ram circuit, the tiny Ram must be approximately 1000 times larger in terms of the number of gates in order to accommodate this program. And for some simpler cases, just for simple computations, this will work. And even for some, actually, even for simple hashes, it will be already too expensive. But for hashes that are required for EVM, that would be prohibitively expensive. We won't be able to support it.
00:10:15.986 - 00:11:02.110, Speaker B: The cost will blow up immensely. So this doesn't work. It's been there for eight years, but it remained a very theoretic approach until recently because not usable. So we looked at this two years ago and we thought, okay, what if we use the recursive aggregation? So it's possible with zero knowledge proofs, to construct a circuit which verifies a proof of a different circuit. And we can dynamically load the verification key so we can verify circuits of different types. And there were approaches to this. The main problem was the cost of constructing such a circuit, which was solvable by using cycles of elliptic curves.
00:11:02.110 - 00:12:08.760, Speaker B: So we could have like each user will define their own circuit, or like each each developer of a smart contract will define their own circuit, publish it on the roll up, and then the users will take the circuit, provide the proofs, and then the aggregator will take all of them in the block and produce the proofs of intermediate results. It can be nested many times in a tree like structure until we get to the final proof of the entire execution of the block. The problem was that cycles of elliptic curves were not available for efficient computation on Ethereum because we lacked the pre compiles. We only have a pre compile of BN two five six on Ethereum. This is the name of a curve we use. And BLS is coming soon, but nothing that supports the cycles of curves. So our first solution to this was two years ago to come up with EAP 1962.
00:12:08.760 - 00:13:12.822, Speaker B: We implemented it at MetaLabs. We produced two different independent implementations, one in Rust, one in C, plus plus. We made a lot of testing, fuzzy testing, a lot of discussions with core devs. But eventually the community deemed this to be too risky back then and too big a pre compiled to include and it never got adopted. And I can understand that for a project like Ethereum, being more on the conservative side with regard to what's going on on the main net is perfectly justifiable so okay, we thought, what can we do else? And last year the Aztec team came up with a number of interesting ideas on how you can structure elliptic curve arithmetics in a Plunk circuit in a more efficient way. We looked at that and we thought, this is the perfect candidate for us. So we went ahead and implemented the first recursive snark on Ethereum using Plonk.
00:13:12.822 - 00:14:30.340, Speaker B: We submitted it last summer, in August for the Reddit Skating Challenge and we actually implemented it in production and launched it in January this year for our Ziki sync roll up for payments, which made this roll up indefinitely scalable. So we are now only limited by Ethereum block size for data availability, but not by the zero knowledge proof computations because we can construct this tree with as many blocks, like smaller blocks of roll up as we need to submit on Ethereum and verify in one single check. The problem with this solution is it's not Turing complete. It required us to implement a new programming language. We called it zinc. It was rust based and you would need to rewrite your programs in a certain way. You would need to avoid unbounded loops, avoid recursion, and also think about how you structure your branching because if you have too many nested branches, all of them would have to be executed and it could blow up the complexity a lot.
00:14:30.340 - 00:15:10.190, Speaker B: We thought, okay, for most DeFi applications, this is probably not going to be a problem. They are not as complex. They do not require that many computations. A lot of programs are written in Viper, which is also a non Turing complete language. But then we realized that people actually really want Turing completeness. People wanted to have EVM. We got this market signals that people really wanted to take existing programs written in solidity, reuse the tooling they have reuse, the audits they already invested heavily into and just not need to learn a new language and rewrite stuff.
00:15:10.190 - 00:17:04.450, Speaker B: So we thought, okay, can we embrace this challenge and actually implement it? So we looked at the third approach, which would be what if we could optimize tiny Ram to make it more efficient for this specific use case? And what brought us to this idea is this observation. If you write a smart contract in Zinc, like manually handwrite a circuit for it, then the smart contract logic itself would take a very small fraction of the prover cost structure and the bulk of the prover costs will go towards access to memory, access to storage signatures, hashes, other heavy operations. So if we could apply tiny Ram to this small fraction to the actual contractual logic, then even 1000 times overhead would not be a problem because overall it will not make a big impact on the prover costs for this transaction. Maybe it will just increase it twice or maybe by 30% by 50%. And the heavy operations, we could write specialized circuits for them. And what we could do is take our tiny Ram circuit and split it in parts and have one part for actually tiny Ram with execution of arbitrary trace of opcodes and then have signatures and hashes done as separate parts of the circuit which can be addressed by these operations. Now, the problem with this approach is you can't really have too many of these specialized operations.
00:17:04.450 - 00:18:20.822, Speaker B: Maybe you need to pick one or two because otherwise it's an impossible optimization problem to pick what fraction of the circuit should be reserved for each of the operations. Because if you just reserve equal number of gates for storage access and for Kchak hash and for shadow F six, then it would be very inefficient if some block does not utilize all of it because the blocks and transactions are very heterogeneous. One transaction might require a lot of storage accesses, another transaction does a lot of EdDSA signature checks, so you need a lot of Kchak hashes. And yet another transaction uses shutter five six for some reason, so it's not clear how to dispose it. And this is why it's not suitable for Zkavm, it is suitable for generic programmability. So you could write a separate language and force developers to think about it and make certain trade offs and only have hashes, for example, and build everything on top of cryptographic hashes like not Kchak, not Sha two five six, not Ethereum compatible. And I think this is the only approach which you can do with Starks.
00:18:20.822 - 00:19:11.722, Speaker B: And this is very efficient with Starks for the reasons of how Starks are structured. But it doesn't allow us to make Zkvm. And this was the goal, so we could not go for this. And this brings us to the final approach, which we actually implement in ZkSync 2.0, which is a combination of Dynam optimized circuits for specific heavy operations and the recursive aggregation of all of it. And the way it looks like is this we have transactions, like users submit transactions in form of or smart contracts in form of bytecodes. We have separate circuits of different length structured by powers of two for the execution of the tiny Ram part of those contracts.
00:19:11.722 - 00:20:04.762, Speaker B: And then we delegate all the heavy operations to specialized circuits which are then aggregated recursively along with all the proofs for the transactions. If we need more of Ketchup hashes, then we just add more of these circuits to the mix. If we need more storage, we just add more storage. If we need more EdDSA signatures, we add more of those circuits and we can efficiently aggregate any number of them the way I described before, to get the proof of the execution of the entire block. And we also heavily optimized the specialized parts over the course of the last year. So we added specific things for two, five, six bits. Arithmetics, we have very efficient Snark friendly hashes.
00:20:04.762 - 00:21:15.620, Speaker B: We have pretty efficient non Snark friendly hashes as well, because we take advantage of the Plunks custom gates and lookup tables. And this gives us a boost of ten X, or even more in some cases, so we can do it very efficiently. The way things work with Zkvm is you take your code written in solidity, for example, like the language, you know, you compile it with your normal compiler into U, and from there we have an LLVM based compiler using a lot of optimizations from LLVM. It's a great platform for compilers to produce the Zkvm bytecode, which you can then permissionlessly deploy on the ZK roll up and execute. And we actually have done a simulation. We took the transactions from L One for some frequent DFI use cases. We fetched the execution trace and we looked at what the prover cost will be in this case for us, like with overall costs, with recursion, with the heavy operations, with the tiny Ram part of it.
00:21:15.620 - 00:22:00.426, Speaker B: And we came to the proverb cost of like one to $0.02 for any transaction we analyzed, which is very doable. And on top of that, you will have to pay the cost of data availability, which depends on the gas price if you use ZK roll up, if you use something like ZK Porter, our alternative approach to data availability, that's going to be a lot less. So you will overall pay only like two $0.03 for a transaction on a ZK Porter. But this is your base cost and yeah, this scales a lot. So, as I said, this is coming to testnet in May and hopefully to production in summer.
00:22:00.426 - 00:22:04.880, Speaker B: And we have a few minutes left. I'm happy to answer any questions. Thank you.
00:22:19.530 - 00:23:01.830, Speaker A: Minor technical difficulties. Alex, that was an awesome talk. I was really impressed with how visually explainable everything was in terms of how you went through tiny Ram. And thanks also for sharing the actual spreadsheet on the chat. So this is awesome. I think we're getting a couple of questions in and the one kind of question which I feel like may have been slightly answered later on in the talk, but I'll ask it again in general is this is from Maurice. And the question is, when you were talking about the size of the circuit, why was Ketchax so much worse than shot 2256? And is that a difference in interpretation or what's kind of the background on that?
00:23:01.980 - 00:23:07.026, Speaker B: It's a different algorithm. It uses broader state with more bits.
00:23:07.058 - 00:23:10.838, Speaker C: And it has more rotations, more manipulations of those bits.
00:23:11.014 - 00:23:23.502, Speaker B: I'm not the best person, by the way, to answer the deep topics in the crypto implementation side. We have a big separate team for that, but I'll just do my best to explain.
00:23:23.556 - 00:23:25.146, Speaker C: Yeah, so it's just a different algorithm.
00:23:25.178 - 00:23:28.378, Speaker B: Which is less snack friendly than shot.
00:23:28.394 - 00:23:30.974, Speaker C: Two five six, and both are way.
00:23:31.012 - 00:23:34.850, Speaker B: Less friendly than algebraic hashes.
00:23:35.590 - 00:23:44.850, Speaker A: Hopefully that answered your question. Morris, a couple more questions coming in. The first one would be, are there any opcodes that are not supported by Zkvm?
00:23:46.390 - 00:24:05.930, Speaker B: We transpile the ethereum opcodes into Zkvm, so we need to support not only the opcodes but also the pre compiles. And we will definitely not support all the pre compiles from the beginning. So there will be some limitations, but they will be very rare. I think most contracts should work without difficulties.
00:24:07.150 - 00:24:17.150, Speaker A: Got it. Another question is Tinyram can handle data dependent control flow, or can Tinyram handle data dependent control flow, or do you still execute all branches?
00:24:18.210 - 00:24:32.386, Speaker B: It's fully handling the data control flow because you have a program counter and you read the next comment from the program counter, which is controlled by the program itself.
00:24:32.488 - 00:24:33.906, Speaker C: So you can make jumps, you can.
00:24:33.928 - 00:24:42.790, Speaker B: Make conditional jumps, and you only execute one step at a time, and your cost is the total length of the execution trace.
00:24:44.570 - 00:24:45.094, Speaker C: Got it.
00:24:45.132 - 00:25:27.746, Speaker A: Hopefully that question was also clear. And if there's any follow ups from Uli, I'm happy to answer that as well. I think this is more of like a slightly technical one. It's referencing a particular slide. So I'll repeat that. And the question is for the slide that refers to the mixing of heterogeneous circuits, are all the functions in the Pi function there different or are they part of the same circuit? Yeah, I think this is referring to the slide that you had at the end where you talked about you're mixing the storage one and you're mixing the tiny Ram all in the same circuit. And maybe this will help you better if you were to see that on the chat.
00:25:27.746 - 00:25:29.320, Speaker A: Are you able to look at.
00:25:30.570 - 00:25:37.190, Speaker C: I remember this slide. I don't quite get the question. So all the functions.
00:25:40.430 - 00:25:42.166, Speaker B: Well, tiny Ram.
00:25:42.198 - 00:26:22.200, Speaker C: Is the same circuit. So we have multiple tiny Ram circuits for different length. They are there structured by powers of two. So we have a circuit of length, let's say 1000, then 2004 thousand and so on, and we pick each of them depending on what the execution trace for a particular contract call is. Now, the circuits for heavy operations, they also have different sizes and we pick them, we just use as many of them as necessary. Yeah, not sure I understand the question.
00:26:23.290 - 00:26:33.260, Speaker A: Yeah, in case we get a clarification on that question, we'll ask that. But if not, that's great. I guess my only other question would be actually we got a new question, which is where does the recursion actually happen?
00:26:36.030 - 00:26:55.650, Speaker C: In the intermediate circuits? So we have special circuits that aggregate other circuits. Actually their sole purpose is to take multiple proofs and produce an aggregate proof of those and to connect the inputs in a proper way. So it's a separate circuit dedicated for recursion.
00:26:57.670 - 00:27:29.126, Speaker A: Awesome. And I think there's another question that I got from the other chats. We have a handful of places where people are watching this aggregate all that maybe one last kind of question will be from our end is just generally kind of seems like you've talked about that this is actually fully Turing complete and EVM compatible. Is there any other gotcha at all involved here or kind of what's the level of completeness to what we understand on the EVM right now that can be mapped onto Zkvm?
00:27:29.318 - 00:28:14.634, Speaker C: Well, it's not going to be 100% exactly bitwise compatible with the bytecode. What we mean when we say it's EVM compatible is you can take your existing contracts written in solidity, for example, and transcompile them to this thing. You might require some minor modifications. We expect that for most DeFi protocols, for example, you don't have to change anything for some contracts. Make some assumptions about the specifics of EVM. So for example, you might depend on the specific costs of gas consumption in a transaction, which will of course be different. In L two, the gas matter is differently than in L one.
00:28:14.634 - 00:28:29.806, Speaker C: You actually only pay for storage access. Right. So such things necessarily will change. And this affects all layer two protocols. Probably if they try to simulate it at some great costs, maybe some of.
00:28:29.828 - 00:28:33.114, Speaker B: Them will, but it will not reflect.
00:28:33.162 - 00:28:37.730, Speaker C: The actual cost structure. So you will be just wasting some gas in such cases.
00:28:39.430 - 00:28:53.990, Speaker A: More small questions coming in. Let's just repeat them for the video. So we got a clarification on the slide question again, which is are all the functions labeled Pi the same? And it appears that they are different circuits but in the same form or are they different sizes?
00:29:10.370 - 00:29:50.430, Speaker C: It I'm still not sure. Well, you can recursively combine different circuits, if that's the question. So you will have completely different circuits in the circuit itself. You can load the verification key either from some set of predefined constants or maybe even from storage, and then you can verify the proof against these verification keys. So the proofs can be of different types and different length. The circuits which were verified will be of different types of different lengths. I hope this answers the question, otherwise I'm happy to jump on the chat.
00:29:50.610 - 00:30:07.466, Speaker A: I feel like you can clarify that at the end and we'll just do two quick questions before we wrap it up. And the second last question is what is the block latency for sdkvm here? And I'll ask the last one as well, which is what are the curves that you're using for your circuits?
00:30:07.578 - 00:31:01.520, Speaker C: We're using BN two five six for now, which is the only curve we have on Ethereum currently with pre compiles. And the latency depends on the hardware you use. Our provers are very well parallelizable, especially with this recursive nested aggregation. We also have hardware accelerator based in FPGA and we can produce a proof for a single transaction, like a single layer of recursion, I think within a second, like maybe 3 seconds. I'm not sure about the latest numbers. So you can imagine that if you want to aggregate 1000 transactions, you have like ten layers oh no, sorry, not ten, because we can aggregate up to, I think, 20 or 40 circuits in a single block. Again, I'm not sure which number, let's say 20.
00:31:01.520 - 00:31:30.230, Speaker C: So that means you only need three or four layers, four layers of recursion. So the block could be produced within 1215 seconds maximum. So if we use the FPGA accelerator, if we use CPUs, then it depends on how many CPUs we have running instance and so on. The more we add, the faster.
00:31:31.050 - 00:31:45.818, Speaker A: Awesome. Well, thanks again for clarifying that. And I think now there's a bit more discussion on the other question about the slide. So hopefully you're able to hop on and answer those slides. But thanks again for making this work with Live coming on here live. And thanks for the presentation.
00:31:45.994 - 00:31:48.620, Speaker C: Thanks everyone for watching. So.

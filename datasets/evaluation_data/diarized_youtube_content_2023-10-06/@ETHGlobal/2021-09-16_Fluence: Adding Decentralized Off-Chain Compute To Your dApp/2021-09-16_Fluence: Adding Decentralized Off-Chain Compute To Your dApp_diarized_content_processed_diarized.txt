00:00:17.290 - 00:00:18.720, Speaker A: All right, stream is up.
00:00:19.650 - 00:00:53.542, Speaker B: Perfect. So welcome, everyone, to the adding decentralized off chain compute to your DAP workshop. Here we have Bernard from Fluence who's going to be leading it. So, yeah, if you guys have any questions, feel free to drop them into the chat and he will get to them as soon as possible. But if you guys are not able to get your questions answered, or if you have any questions after the workshop, feel free to contact him and the Fluence Team through the sponsor Fluence Discord Channel. All right, Bernard. All yours.
00:00:53.686 - 00:01:25.054, Speaker C: All right, thank you very much. All right, as it's been pointed out, my name is Bernard, I'm part of the Fluence Team and thanks for being here and thanks for having me and thanks for being interested in the hackathon. It's going to be awesome time today I want to do a workshopy kind of thing. Program, decentralized compute and IPFS with Aqua. And the next ten slides are so basically all about unpacking that headline. So let's dive into it. Fluence.
00:01:25.054 - 00:02:37.926, Speaker C: What is fluence? Fluence is an open, permissionless peer to peer protocol that's focused on compute. Aside from the protocol, we provide a network and a vast open source tooling repository that allows you to, in our opinion, really take on distributed and particular peer to peer programming at a level of ergonomics and convenience you probably haven't experienced before. And we'll get to that. The way things work, sort of roughly bird's eye view, is we use WebAssembly interface types as our highly portable compute modules. They execute on what's called the Marine runtime, which is a general purpose WebAssembly runtime built on Wasma, which we have on each network peer. And then from these modules you create services. So WebAssembly modules themselves share nothing and how we build services which are logical constructs, we do them by linking those WebAssembly modules to a JSON file, which establishes the dependencies.
00:02:37.926 - 00:03:49.106, Speaker C: And now you end up with very powerful service constructs that allow you to execute external effects, including download, upload, modify and replicate and interact with other networks or participants of other networks as well. And if you look at the right there, get to peer to peer network, the greenish things are sort of, I don't know, could be clients, could be browsers, any kind of client IoT. And then we got a couple of services here and as you can see, you can write adapters essentially to interact with the outside of the Fluence peer to peer network basically bring in your traditional web two APIs microservices or actually web three networks like IPFS. And this is where we're really going to focus sort of throughout the workshop. And now if you look at this, so you got this peer to peer network, you got a bunch of peers, you get a client and you got services that are hosted on nodes. So, yes, there's a way to deploy those WebAssembly modules with the configuration onto these nodes. So now you're looking at it.
00:03:49.106 - 00:04:48.242, Speaker C: It's like so how do you actually program this? For most of you, not most of you, but for those of you who have experience with blockchains, which is probably the biggest peer to peer consumer these days, you interacted through JSON RPC or even rest endpoints influence. This is not the case. And the reason this is not the case is because it's a general purpose environment where pre specifying JSON RPC endpoints is impossible because you as the developer create those services. So the question now is how do you actually harness those services? How do you compose them into an application? And this is where a special purpose language Fluence created. It's totally open source. Everything's MIT, Apache, two or both to program distributed networks and services. Now, the interesting part is it doesn't just apply to the Fluence network.
00:04:48.242 - 00:05:32.114, Speaker C: You can actually use Aqua to compute and compose services. Not compute, just compose services that include networks, outside networks and outside applications. And that's actually really powerful. And we'll see this how you can use custom services in conjunction with IPFS through Aqua, which it's a ten line. You'll see it, it's going to be awesome. And we believe the ergonomics of Aqua are such that it's really going to commoditize peer to peer programming in it by itself. So what does it look like? So it was a lot of talk, a lot of how wonderful it is.
00:05:32.114 - 00:06:15.054, Speaker C: Let's put the pedal to the metal here, the rubber to the road, go right to the bottom. This is a very simple example of a Hello World service. So the assumption here is we have a service already deployed on a node and that service is a greeting service with the function greeting. So basically that greeting function which we would have written in Rust and compiled to Wazi 32 takes two parameters a string and a boolean. The string is the name and the boolean is basically whether or not we greet the caller. So a boolean of true and a string of Joe or online for example, would be high ETH online and false on the boolean would be a by ethanoline. So fancy.
00:06:15.054 - 00:06:59.600, Speaker C: Hello World. So lines one through two basically show you how to create the interface within Aqua. This is literal Aqua code and how we can map that to the deployed service through this WebAssembly modules through what's called the service ID. The service ID is unique as you create a service from those modules. You can literally create ten services from the same modules if you want to, on the same node and you get ten different service IDs, which has advantages if you want to do this. And then lines four through eight are the actual Aqua function. This is the composition, if you will, of that greeting service.
00:06:59.600 - 00:08:11.720, Speaker C: And that gives us a result at the end, basically the hello or the Hi or by whatever the name is and in addition to the name and boolean, the name and the greet, the string and the boolean we saw in the Greeting service signature, we also have a node and Greeting service ID parameter. The node is the peer ID of the node or the peer on which the service has been deployed. And the Greeting service ID is the unique ID associated with that service which is comprised of reusable WebAssembly modules. So what we're doing now is we're basically saying on this node, on this peer specified follow my cursor here, we bind this interface, this Aqua interface, to the actual WebAssembly interface. We then use that binding and call the function Greeting, which is part of that interface with the provided parameters of greet and name. And then we return the result. And then that's it.
00:08:11.720 - 00:09:07.750, Speaker C: You just basically harnessed a distributed peer to peer service in basically eight lines. And if we go back and look at it from a diagram perspective so what you basically did is let's just say you're in a browser and for a browser you need a relay. For those of us little newer to peer to peer networks, a relay is a publicly accessible peer because not all peers, because of net requirements may be publicly accessible but they might be accessible through a peer. Browsers are not directly accessible. So they have to go through a relay at all times. And so basically what we would have done is we would have called from this peer on the relay and then on the relay it would have determined, okay, let's just say this is our service, our hello service. We call this service, we execute it there and then we bring back the result which could have gone to the client we initiated with or some other client.
00:09:07.750 - 00:10:14.366, Speaker C: And if you look at it, this basically on the little sequence diagram there. So basically we initiate this Greeting, we call it, we execute it on that node and then we return the results by the relay back to the client peer. If you expand that model you'll very quickly realize this leads to a very different request response model than you usually see in your traditional client server environment. Your response model is request response back to the client, request with that response back to the client and on and on it goes. So if you wanted to do, say, a credit card authorization and I don't know, let's just say you want to use Stripe for that and then you want to send your customer a SMS of the outcome of that credit card authorization, you basically in a typical client server environment you call Stripe. Then you get the response back. Then you call your SMS service tool I O and you notify the customer and that is it.
00:10:14.366 - 00:11:10.922, Speaker C: So request response, request response. But in a commonly designed peer to peer application workflow like we're looking at, you don't necessarily have that at all. What you can do is you basically can forward your response to the next service. So if we look here and let's say we want to do this very example I just said and I don't know, out here you have Stripe and Twill IO. So the first service would call Stripe, get the response, then feed it directly into the next service, which, I don't know, here Micro, somewhere over there is Twillio. And then you get back your OK or whatever to your browser. You make this a large number of hops in a request response model and all of a sudden what you realize is you have a very thin client.
00:11:10.922 - 00:12:08.946, Speaker C: Everything happens on the network and that's extremely powerful because it allows you to minimize the client requirements. And I mean, I'm sitting here with a pretty damn nice laptop and a pretty fancy phone, but the majority of the 8 billion people out there are not running this big network, this big laptops or desktops. They're Chrome OS type situations and same on phones. So thin clients. And then if you add edge devices, various It devices are going to be a huge volume and they'll extremely benefit from having this redistribution of the workload to the network. And that's one of the things we're super excited about. The other part of course is why do we do what we do? Well, first of all, again, if you look at it, if you look at that workflow, you stay in control of your data.
00:12:08.946 - 00:13:11.140, Speaker C: And to us this is a really huge Web Three benefit and you also don't have any centralized brokers, which means you're not tying into various cloud environments necessarily. And also you get very censorship resistant. It's not censorship proof, but it's definitely censorship resistance. And there's a lot you can do in terms of deploying multiple services on multiple nodes and different geographies that really, really strengthen the resilience to censorship. Okay, so this was Aqua in a nutshell and we'll look at all this in much more detail. However, if you go back so we have hang on, one more time. If we go back here and we have Aqua, so now we know that we have this location addressability of a service through Aqua in the network, through the node ID and the service ID.
00:13:11.140 - 00:13:53.442, Speaker C: And now you ask and then I told you that we have a request response model that actually forward chains responses without having to go back to the client at any given time, unless you literally need the result to update a browser page or whatever, nothing has to go back to the client. So the question now is how do you do it? And there's one more foundation component you should know. We call it the particle. You can also think of it as a smart packet. Basically, particles are conflict replication data structures. They combine the data and the execution sequence and a whole bunch of metadata. Let's ignore the metadata for the time being.
00:13:53.442 - 00:14:35.742, Speaker C: Let's look at the data and execution sequence. The execution sequence literally is the compiled Aqua that script those eight lines you saw. It gets compiled into what we call Air, which is the Aqua intermediate representation, which is a low level machine readable output. It's not bytecode, but you can think of it as bytecode. It's at the same level of abstraction at least. And what happens is when you compile this Aquascript, you create, let's just say in the browser, a TypeScript client, which actually automatically is generated for you through the Aqua compiler. And then you create this particle.
00:14:35.742 - 00:15:22.458, Speaker C: So if our name was East Global and our boolean was true, then we create this particle with the data name and string, and we literally fling it out on the network onto the first relay we can get to from the browser. Then at that relay we have Aquavm. It starts checking where is the service, which node is it on? This node? Is it on a different node? And if it's on a different node, it forwards that particle to that node. The Aqua gram there now starts checking. Okay, we got this greeting service here. We execute it, we get the high ETH global output, and then it checks where it's going, and in our case, it's going back to the client. And this is super powerful.
00:15:22.458 - 00:16:18.900, Speaker C: It's basically a push data model instead of a pull data model. And it really adds a lot of attributes and capabilities that I'm not entirely going through today. But security in particular about data ingress data or particle ingress, and egress from a VM, from a processing perspective plays a really big role in these smart packets. Okay, anybody have any questions at this point? I know I'm going fast, so if I need to down, tell me. Okay, hang on, let me look at the chat here. No? Okay, all right, that's cool. All right, no questions.
00:16:18.900 - 00:16:52.874, Speaker C: So what we're going to do now is we're going to look at Fluence at IPFS. So I told you at the beginning that Fluence is a compute protocol. And basically it sort of, to a certain extent, requires developers to bring their own store within Fluence. We have adapters for file services on a node, SQLite and few other things. And one of the few other things is IPFS. IPFS itself being a Web Three optimized protocol. It's peer to peer.
00:16:52.874 - 00:17:38.780, Speaker C: So it's a perfect complement to the Fluence compute. And what we've done is we basically build Fluence nodes with IPFS sidecar. That is, an IPFS node is deployed on their Fluence node. So let's switch here and let me go to the demo real quick. Let me show you what we're doing here. Okay, come on. Okay, so let me overlap that with code as well, otherwise it doesn't make much sense.
00:17:38.780 - 00:18:32.742, Speaker C: What we want to do is the following. We want to create a service that does something and then deploy that service to the Fluence network and then use that service as a storage. For that service we want to use IPFS, not necessarily your local network. Yeah, your local storage. So let's start with the service. Okay, so the service we want to build basically is a service we want to build basically calculates the size of a file. Okay, that's all there's to it.
00:18:32.742 - 00:19:02.342, Speaker C: This is in Rust. It gets compiled to WebAssembly. It's pretty straightforward. It's only literally the simple part of Rust not to complicate it. There are no lifetimes, there are no generics, none of that. Because in WebAssembly we pass everything by value. And with this little macro here, with this little keyword, we actually provide the compiler instructions to use the appropriate types and the compilation into Wazi 32.
00:19:02.342 - 00:19:38.210, Speaker C: So basically the rest is just pretty standard. You read from the file and you calculate the file size. Very simple. So what we first would need to do is we are in the service directory here, and what we want to do is we want to build that Rust code into our compile target, which is YZ 32. Now of course, I've already done this, I think. Yes, I have. And what we're doing is I'll show you this in the build script.
00:19:38.210 - 00:20:37.162, Speaker C: Basically there's a bunch of noise in there, but what really matters is this marine, which is our compiler extension to Rust, basically builds and builds this WebAssembly module. And then we just copy that module in a more favorable location, which we call artifacts. And here, this is, this is it. This is our file size compute WebAssembly module. And if we want to use it, we need to deploy it to a node on the Fluence network. And there's different ways of doing it and one of them is to do it with IPFS. And I'm going to be very hang on that's suboptimal.
00:20:37.162 - 00:21:03.866, Speaker C: Hang on. I'm looking, I'm looking. I'm looking. Something disappeared. Okay, so I'm going to use the IPFS desktop. Now. I told you we don't want to just use any old node IPFS node.
00:21:03.866 - 00:21:47.810, Speaker C: In this case, we want to one that we control through not control, but that's associated with a fluence node. So what we're doing is now we're in the web interface on how to nice. Not nice. Okay, this is not good. Dang it. It's just working. MMM, that's embarrassing.
00:21:47.810 - 00:22:51.620, Speaker C: Let me try one more. But we're going to get the same thing probably. Ah, let me try language one more time. Okay, so this is no good.
00:22:53.110 - 00:22:56.840, Speaker A: So might be a node error. Node is not running.
00:22:57.690 - 00:22:59.000, Speaker C: Sorry. That's what.
00:23:04.490 - 00:23:10.540, Speaker A: I'm saying. There is a node. The request it's sending is that node is not running. Maybe.
00:23:12.190 - 00:23:17.686, Speaker C: Okay, it should be running, but it's.
00:23:17.718 - 00:23:21.834, Speaker A: Not IPFS node or maybe a fluence.
00:23:21.882 - 00:24:17.220, Speaker C: Node, some of them. All right, okay, let me regroup here. Okay. Always fun when something works and then it doesn't. Of course it never does. It when you're not live. Okay? What we wanted to do was we wanted to take that service, put it on IPFS and then deploy it with IPFS onto the Fluence network.
00:24:17.220 - 00:25:20.250, Speaker C: And in order to do that we use Aqua. Aqua, as mentioned before, is the distributed language. We have to handle those things and this is what Aqua looks like. So basically we have some services and this is the deployment aspect of it. So basically this little function here tells Fluence Compute to go to IPFS and add a module. It does this by creating a blueprint on the node. And hang on, Alexe is working on it and hang on, we might be able to do this live after all.
00:25:20.250 - 00:25:57.968, Speaker C: He was just there in Chat. Oh, if I succeed, I screen Share. Okay, all right. And we create a service for that module. Okay? So now follow me. Mentally, it would have been much nicer graphically, but we created Rust code to calculate a file size. We compiled that Rust code into WebAssembly Waze 32 and for that we have now a WebAssembly module.
00:25:57.968 - 00:26:59.976, Speaker C: We take this module and we copy it onto an IPFS node which I wanted to do with the desktop. In order to do that we want to know the IPFS sidecar to use. That is we need the multi address of that node which I wanted to get from the browser. And now we have that file sitting on IPFS and you can deploy it, you can access it. As long as you have the CID, you can do just about anything you want. One way of us wanting to do is we wanted to do this with Aqua and these are the functions we need to call in Aqua in order to take the module from IPFS and deploy it to a node of our preference. And it starts with deployed service and we can just basically go through it.
00:26:59.976 - 00:27:47.960, Speaker C: So the return of the deployed service is your service ID. And the service ID, as I said before, is the unique Identifier for the service on a particular node, on a particular peer. So the location addressability comes from the peer ID service ID tuple, which we briefly touched on before. So what we're doing now is we're going to find a relay and now we want to get from IPFS with the CID and the multi address. This is IPFS. It's the multi address which we provided early on. And then we just go through building the service from the actual module.
00:27:47.960 - 00:28:23.140, Speaker C: Because as I said before, you can build multiple services from the same modules. You can different services from reconfiguring your modules. And basically the way it works is you basically take the module and then you just compute the hash of it. You then create what's called the blueprint from the hash which basically entails all your dependencies and you get a blueprint ID. And from that blueprint ID we can now create the unique service ID. So everything up to service ID is totally reusable. And then the service ID is unique.
00:28:23.140 - 00:28:43.150, Speaker C: Unless, of course, it doesn't work. Then you get an error. Which, by the way okay, I see in Chat. Okay, all right. Let me switch to Alexa to do the share. Let me stop right here. Alex, a, are you ready?
00:28:44.080 - 00:29:13.540, Speaker A: Hello. I was watching YouTube instead of zoom, so I was a bit late. Sorry for. Okay, let me close few of wrong, so I'm sharing. I don't know why, but also the local host stopped working, so I had to use this. It's a local host, but in a different subnetwork. Anyway, hello, everyone.
00:29:13.540 - 00:29:44.852, Speaker A: I'm Alexei. I'm developer at Fluence. And I saw that it wasn't working for Bernard, so I came here to help. So, as Bernard was describing, we have IPFS demo that allows us to connect to some node in the Fluence network. So here we connected. It automatically retrieved the IPFS address from the Fluence node. Because each Fluence node is sidecarred with IPFS nodes.
00:29:44.852 - 00:30:08.804, Speaker A: So they run together. And every Fluence node is connected to IPFS Node through WebAssembly Fluence adapter. Through WebAssembly IPFS adapter deployed on Fluence Node. And it knows address of IPFS Node. So it reports here. And we can connect there through IPFS desktop. Let me restart it.
00:30:08.804 - 00:30:39.680, Speaker A: I hope it won't connect automatically. So it asks us for IPFS Node address. That's awesome. Let's connect there. So we have connected to the IPFS node running along this limits Node. Now we have to click twice here and now. Since what we want to do is to deploy WebAssembly service, we need to upload it to IPFS Node.
00:30:42.180 - 00:30:48.692, Speaker C: Bots. Okay.
00:30:48.746 - 00:31:14.904, Speaker A: Anyway, we have this IPFS Node you see here. It shows that it failed to upload. I wonder why. Never seen that before. But anyway, I hope it will work. So what I did is I have this IPS desktop connected to IPS Node, and it shows me that IPFS Node has this WASM file. I know that it's a WASM file for service written in Rust and compiled to WASM.
00:31:14.904 - 00:32:07.256, Speaker A: So I copied CID. I pasted it here and pressed Deploy, and it deployed a new service by this CID like IPFS file hash a deployed service. And it's available to be called through this service ID. Awesome. So now when I copy this CID once again, what this service does, it allows me to calculate to download a file from IPFS another file, and calculate its size. So here, for example, I paste the same WebAssembly file CID press Get size, and it reports the size of this file, of this Wasn't file. Also, it uploaded this file size to IPFS Node.
00:32:07.256 - 00:32:28.672, Speaker A: And the uploaded file size, like a TXT file with this number inside, is uploaded to IPFS under this hash. So I paste it here. It should be a very small file. So yeah, it's just six bytes. Let's try another file. We have config Tomal here. Just a random file.
00:32:28.672 - 00:32:53.450, Speaker A: It's 116 bytes. I paste CID here and we have this size. So it goes to IPFS through Aqua, downloads file to one of the frames nodes, applies a function in the WASM service to this file, calculates its size and uploads result back to IPFS. I'm done.
00:33:02.690 - 00:33:54.074, Speaker C: Okay. All right, let me get back to screen sharing here. Take that back. All right, while we're diddling around here, anybody have any questions? Really? All right, so we saw the code. I'm a little bit stranded, so it's going to take me just a minute to get my train of thought back lined up here. So we saw the Rust code that turned into the WebAssembly module. We put the WebAssembly module on IPFS, basically permanent storage, distributed storage, permanent web, three storage.
00:33:54.074 - 00:34:57.090, Speaker C: So you can use it from anywhere, anytime, which is in my opinion, at least in my case, a lot more reliable than saving something locally. And we've seen that we can deploy the service with Aqua in just a few steps. So the important part here is not just that you can do it with Aqua, but the important part is that you can interact seamlessly with the fluence, compute with the fluence node and IPFS. There is no separation. There are some backend services Alexa implemented that allow you to do that. And that's really the aside from it being cool that he can employ this blah blah blah, that's really the takeaway message is that you can use Aqua seamlessly across different protocols, distributed compute protocols and store protocols and that is really powerful. And then things like removing a service, obviously Scaffolding is always more expensive than destroying things.
00:34:57.090 - 00:35:34.666, Speaker C: It's always like build a house, then tear it down and destroying is always fun. This is at the bottom, it's just you remove service in Aqua. This is how you remove a service in basically three lines. And again, it's the location addressability of the service that allows Aqua and the underlying network, marine and Aquavm to take care of a lot of the headaches you would usually get. And one of the things it's important to know is that in peer to peer networks, especially, peers come and go. It's not an exception, it's almost an expectation. It's in flux.
00:35:34.666 - 00:36:32.206, Speaker C: It's a network in flux and being able to work on this location addressability and then there are ways of implementing failover which are a little bit beyond the workshop. You'll see how truly powerful this is, especially compared to if you had to manually code that stuff. In addition, this was the actual file size calculator, which is very similar to what we had before. So the actual binding is the process file blah blah blah blah blah, which we had here. So these are the interfaces you use for that Rust service I showed you earlier. One was the size result, one was the right result. And then this is the actual service that provides you the bindings to the file size and the right file size functions.
00:36:32.206 - 00:38:26.710, Speaker C: And one neat little thing is actually it's very convenience because I really dislike copy and paste or leave alone retyping. What we have is we have a REPL that allows you to interact with the WebAssembly modules locally and oh look, big surprise, those are exactly the interfaces we were looking at before. So if I had a file path with the string then I could actually utilize that right here and you would do something like this and then put your file path in and it would process and that's how you can interact locally with the services. So if you want to test things out or if you want to test your bindings, if you want to reconfigure services, this is a really cool way of doing it. And of course through Marine, which was the compiler we saw before, we can hang on, I need to know where I'm going. We can export those interfaces. I think it was process righteous, it process files.
00:38:26.710 - 00:40:31.200, Speaker C: Nothing is going as fully planned. Okay, so you can export those interfaces and if you wanted, you could just pipe them straight into whatever file you want to and then you end up with a file like this. Okay, so this is sort of a quick start on how to set up your service, your module, your service deployment, and then your aqua coding using the necessary bindings or interfaces from your services. And when we start looking in the actual components, the application logic now if you integrate it with the browser code is here. And one thing I wanted to show you is these are the actual acrophiles, the way you saw them before. We've seen this in Vs code and if you compile it, you all right, there are some dependencies it doesn't work if you compile it. You end up with where are we.
00:40:41.760 - 00:40:43.630, Speaker A: In build folder, I think.
00:40:45.200 - 00:41:00.610, Speaker C: Alexey, do you know where the aqua output, the compiled aqua output files went? They used to be in here. God, where did they go?
00:41:02.500 - 00:41:04.080, Speaker A: Well, maybe they're.
00:41:06.920 - 00:41:55.216, Speaker C: Okay, they get moved to a different directory. Okay, so basically what happens is if you compile it, you can compile it in a way that it wraps your output aquacode directly into a reusable TypeScript wrapper. So let's just have a look if we can find one that we used before. So get from, for example, that's what we looked at. So this is how you do the get from and how the compiler prepares it for you. So you can just call that function straight from your client. And this stuff in here, this is actually Air and this is the machine level code.
00:41:55.216 - 00:42:27.500, Speaker C: And believe me, it's not fun to write by hand, but it's extremely powerful. And what the compiler does, it basically wraps that. And this is the part, this is the part when we said the execution script is part of a. Particle. That is the execution script. This is part of the execution script, and this is what gets executed on the Acrobm. And sorry for this ending up fairly disjointed.
00:42:27.500 - 00:43:04.170, Speaker C: So if you have any questions on that, hit me up or hit us up in discord. And now let me go back to the presentation because I do want to go over the bounties. That should be fine. And if you have any questions, please shoot. Okay, prizes. So we get actually, let me make that smaller. That's not what we wanted.
00:43:04.170 - 00:43:52.388, Speaker C: God, there's like nothing working today. Nothing. I really apologize. It we get multiple prizes. So we have a really simple bounty, $150 for the first ten submissions. That basically extends our quick start. If you look in our examples, it's in Fluence dev in the examples there's in the documentation, that's Quick Start section.
00:43:52.388 - 00:44:46.170, Speaker C: And we would like you to extend this and basically add a service just like we showed you that counts words of a message. That's it. And I think even in this disjointed presentation, you should have gotten everything you needed to do it. Now, you don't necessarily have to use IPFS to do the deployment. There are other command lines that are outlined in the Quickstart, but that's a real easy way to stick your toes in the water and play with some concepts, make a little bit of money and see if you want to go on with the hackathon, which we really hope you want to. And the next bounty is $2,500. Best use of Fluence compute for your decentralized application.
00:44:46.170 - 00:45:38.250, Speaker C: I give you a few examples here. For example, NFT creation. With the marketplaces, the way they're going, it doesn't really matter anymore where NFTs get created. There are examples of people using Fluence already to create NFTs, and there are some pretty interesting ways of creating metadata around NFTs that also work with Fluence. For example, you can do Mutable metadata for an immutable NFT using Ceramic, for example, or generally. Or if you just want to do an IPFS by yourself, that's fine as well. So using something around NFT creation, maybe based on gas arbitrage across different EVMs, for example, that's something that'd be super interested.
00:45:38.250 - 00:46:47.570, Speaker C: Price Oracles, particularly Price Oracles that go straight to the decks. Reusing already an aggregator. That's kind of lame, but if you go straight to the source and start pulling from DEXes, particularly if you start bringing liquidity information with it, that's also super interesting to us and we would love to see that. And then another example would be, for example, to arbitrage contract use across different EVMs, whether it's layer one or layer two. If you have say, a given contract that's deployed on multiple EVMs, obviously when do you use which one? And it's actually not that different than how to do order routing to DEXs, right? So you can start checking on gas prices on the different EVMs and then start using the contract for whatever execution you wanted to use on those different EVMs. And then we have another price. It's $2,500 for best tooling or pattern for other developers to use.
00:46:47.570 - 00:48:03.240, Speaker C: And things in there are really about porting existing libraries or library functions to Fluence, whether it be a Web Three library, for example, or just a signature signing verification service where verification is interesting as a network solution. If you have domain knowledge in decentralized identities to verify credentials, we'd be interesting to see what you can do with that. In particular about linked data and resolving linked data. If you use BBS Plus, it would be really cool because that is really where everybody's settling on right now in verifiable credentials. And we have one more, which is basically if you're into front end development, decentralized Network Explorer of our network, and we have some examples that are listed on the bottom here. And then lastly, we have a $1,500 best use of Fluence with another event Sponsor Bounty. And basically just use Fluence, integrate it with one of the other event sponsors, and wherever it comes up with the best use of it, $1,500 are yours.
00:48:03.240 - 00:48:31.744, Speaker C: Going back here. Just one more on resources. So there's a variety of resources. We have a discord channel we have a discord channel in Heath Global. We have a fluence YouTube channel. We are available in Discord. But if need be, you definitely can book some time with one of us and we'll answer all your questions and help you sift through what needs to be sifted through.
00:48:31.744 - 00:48:46.550, Speaker C: And lastly, if you're interested in peer to peer, we're hiring, have a look at our website. And that's it. That's all I got. Sorry for whatever that was.
00:48:47.480 - 00:49:17.084, Speaker B: No problems. Thank you so much, Bernard, for this workshop. And thank you to Fluence for sponsoring ETH Online this year. Just like what he said. I really want you guys to continue this conversation in the Fluent Sponsor Discord Channel. So, yeah, you could find Bernard there and ask him any questions, if you guys have any that pop up while you're using Fluence during duration of the hackathon. But yeah, everybody have a really great day and I'll see you at the next workshop.
00:49:17.084 - 00:49:17.500, Speaker B: Bye.

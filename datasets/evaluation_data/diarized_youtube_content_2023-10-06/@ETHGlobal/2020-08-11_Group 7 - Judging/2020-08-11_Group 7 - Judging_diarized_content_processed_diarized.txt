00:00:56.730 - 00:00:57.280, Speaker A: It.
00:01:37.380 - 00:02:36.216, Speaker B: All right, we're going to get started everybody. My name is Kartik, one of the co founders of ETH Global, and welcome to Hack FS. For those of you who don't know, Hack FS is a month long hackathon that ETH Global and Protocol Labs have done. And today is our day four of judging where we'll be going through a lot of the projects that we've seen come out of this event. So over the past month, we've had 470 hackers from 50 different countries and working across 19 different time zones come together to experiment and play with what is possible with the world of Ethereum and Filecoin. And we've had a lot of these teams spent the last few weeks learning about what is available to them, to understanding the basics of a lot of these protocols and blockchains and worked on a project that they submitted over last Thursday to us. And we're taking this entire week to demo what everybody's done and showcasing them to the rest of the world.
00:02:36.216 - 00:03:20.068, Speaker B: So we're super excited to announce that we've had 132 projects that have come out of this event and we're showcasing them in groups every day for the rest of this week. And today makes day four for these demos. So before we go into these demos directly, I want to quickly walk through the logistics of how this call is going to be set up. We're going to have about 13 teams that are going to be presenting today. And each team will have four minutes for their demos and four minutes for a Q and A. And to minimize any AV issues, we've asked all of our teams to pre record their videos and we'll be playing with them, playing them and we'll have the teams come on for the live Q A part. So, quick overview of how the event itself was set up.
00:03:20.068 - 00:04:05.350, Speaker B: Each team could have up to five team members, but they were also allowed and it was okay to work on your projects individually. And all code you're going to see today was written at the hackathon. So everything we are going to see was done over the past four weeks. And the only criteria for them to be eligible for submitting and presenting here was that their project should incorporate the tools and technologies from the Protocol Labs and Ethereum Ecosystem. And that's great for us because we're seeing a lot of creative mashups of what's possible between decentralized storage and smart contracts. So our judges will be looking at our projects from these few categories. Every project will be rated on how technical, original, practical, and usable it is.
00:04:05.350 - 00:04:43.472, Speaker B: And we understand that this may not be a full criteria for a lot of these teams. So we also like to have a category that we kind of call a catch all call the wow factor for us to help understand and make sure that we haven't missed anything. So before we kind of go into our very first demo. I want to really emphasize that this is not a competition. The hackers are very much here to learn and they're here to share the excitement and show you what they've been able to accomplish over the past four weeks. And our judges are here to primarily give feedback for these projects and actually help them understand and comment on what they can do to take it to the next level. And not everybody is trying to become a business here.
00:04:43.472 - 00:05:30.944, Speaker B: So a lot of this thing, a lot of the demos today and a lot of our projects are very much the outcomes of the real creativity experimentation that we encouraged all participants to go on with. So with all that said, the schedule for today is as follows. We'll have these teams come on and present to us one by one. And doing the hard job are our three judges. I want to welcome Harrison Hines from Fleek, molly and Kinley from Protocol Labs, and Monty Prakash from Consensus, who will be with us for the next 2 hours looking at and giving feedback to all of our projects. So, all that said, I want to kick off with our very first demo for today, and that is Team Libriscore, and we'll be playing their video on their behalf. And with that, I'd like to kick off the first demo for day four.
00:05:30.944 - 00:05:33.650, Speaker B: So we'll get started.
00:05:42.980 - 00:07:45.360, Speaker A: Okay, just loading up the video now. It double check. Can you give us a shot? Yes. Let's go. Al.
00:07:50.230 - 00:07:57.940, Speaker B: I'll copy this thing on my end. Apologies for this types of thing.
00:08:00.570 - 00:08:01.670, Speaker A: Submit.
00:08:06.090 - 00:08:11.900, Speaker C: Image is rendered by WebAssembly. You can play it.
00:08:20.750 - 00:08:52.920, Speaker A: Download MSA, download Midi, download PDF, screen index of shapes in text dialdb, refresh it's shown on the home page.
00:09:05.390 - 00:09:19.280, Speaker B: That was a super quick demo, but you're here on this call. Would you mind just kind of going over a little bit, telling us a little bit about what you wanted to do and just kind of describing to our judges how it works?
00:09:20.530 - 00:09:38.440, Speaker A: Okay, it.
00:09:42.090 - 00:10:15.200, Speaker B: Maybe a question from our side is how easy did you find it to work with all the libraries that you use for storing the data? Yeah. So you said you used a lot of libraries like Textile and you also used Infira for storing the information on the blockchain. How easy was it to use?
00:10:20.150 - 00:10:25.220, Speaker A: Let us submit and so on the list.
00:10:34.090 - 00:10:45.260, Speaker B: Got it. Maybe another question from our side is if you had more time, what would you do to this? After.
00:10:53.330 - 00:11:00.990, Speaker A: Multiple database integration such as Shipbox and Obdb.
00:11:09.590 - 00:11:45.390, Speaker D: I really liked how the song could kind of play forward as you were viewing it within the page. I noticed when trying to view the live demo that it wanted to install some sort of extension in the site. I'm curious kind of how you were connecting, how you configured that so that you could do the playback of the song at the same time I use.
00:11:45.460 - 00:11:49.630, Speaker A: WebAssembly to integrate.
00:11:54.050 - 00:11:56.910, Speaker C: The Mulescore library.
00:12:01.520 - 00:12:02.910, Speaker D: Got you. Thank you.
00:12:09.750 - 00:12:27.230, Speaker B: Awesome. So I think what we'll do is we'll kick off to our next demo and would like to invite Foin pricing mechanism team up on and share their video. Hi.
00:12:27.300 - 00:12:52.100, Speaker A: Thank you. So that's I'm afraid I have to share again because I think I forgot to share my audio. Let me do it again. It okay. Should be okay now. Shall I play it now?
00:12:52.470 - 00:12:53.570, Speaker B: Yes, that'll be great.
00:12:53.640 - 00:15:18.258, Speaker A: Okay. Scam SA. Okay, so now there is going to be a second part of the video, which is a short demo of the of the system we have developed. So at the beginning we initiate our private blockchain. So in Gas, just some scripts, we have some preceded accounts. We have developed a simple CLI interface so we don't have time for something more fancy. So basically here we list all the accounts available at the node.
00:15:18.258 - 00:15:50.958, Speaker A: We deploy our smart contract using one of the accounts that has some money, and then we can start interacting with the smart contract. So the smart contract is the platform running the auctions. So here users can just submit the items so storage nodes they have with the characteristics they want. So here we are submitting 20GB nodes. We are offering 30 days of storage without any minimum price. The same happens if you want to bid. So when we need storage.
00:15:50.958 - 00:16:42.610, Speaker A: So again, here we specify our requirements. So, yeah, I've added just two items from the CLI and now this JavaScript to make it a bit more interesting and submit more items and more bits automatically. And then any node can use the information submitted on the blockchain, solve the auction and submit a solution, which is an optimal assignment between the nodes and the bidders. And then smart contract doesn't verify it, but anyone can do it. So here you can see that the client downloaded the solution, verified it, it's perfectly correct. But now if you submit a fake solution, it's the same procedure. And then if we verify it, the verification will fail.
00:16:42.610 - 00:17:00.120, Speaker A: So now can just simply submit a proof of misbehavior, which allows the smart contract to delete the solution that was invalid. I think that's my four minutes.
00:17:07.000 - 00:17:09.012, Speaker D: Super cool. Thank you so much for sharing.
00:17:09.156 - 00:17:09.576, Speaker A: Thank you.
00:17:09.598 - 00:17:22.510, Speaker D: I really like how you guys found a really useful kind of way of connecting people from a marketplace perspective. I'm curious how you guys came up with or decided on this project in particular.
00:17:24.400 - 00:17:59.312, Speaker A: So we had a mathematician in the group and so he was working with auctions. So I think it's kind of we have people from Cybersecurity and some mathematicians and as you could see, no one from user interface. So, yeah, I think we're discussing. So we are also researchers, so that was a problem we were discussing before multiple times. So I think auctions was something that we said, okay, this would be great, because you can have this optimal assignment between nodes. You don't have to worry about anything. The price will be optimal.
00:17:59.312 - 00:18:27.200, Speaker A: You will get the best node that is most suitable for you. It's great. But then it's very difficult to run it on top of the smart contracts because then every single mine has to repeat it's too heavy. So then we say, okay, how we can do it differently. So we found this way with outsourcing. So at the beginning, the initial version, the smart contract was verifying its solution, but it was also pretty heavy and costly. So that's why we came up with those proofs of misbehavior.
00:18:27.200 - 00:19:05.260, Speaker A: And then from the cybersecurity perspective, we said, okay, so now actually in Falcon can be problematic if you're a company. If you rent some storage and it's publicly available, this storage node can become actually a target because if everyone knows you're storing some data on a specific node, well, that's a target for a potential breach. So that's why we also wanted to add this privacy preserving layer to prevent this kind of attacks. So in our system, you don't know who actually it's not disclosed publicly, who made a deal with whom?
00:19:10.080 - 00:19:15.970, Speaker D: Yeah. Thanks so much for sharing. This is a really interesting project. I'm curious, what do you think is next for you guys as a team?
00:19:18.580 - 00:19:22.000, Speaker A: What is, for now? First of all, user interface.
00:19:25.080 - 00:19:25.540, Speaker C: Okay.
00:19:25.610 - 00:19:52.830, Speaker A: Yeah. So, first of all, I think user interface. So from the security perspective, we've integrated BLS signatures, but I think we need one more mixer that would be kind of automatic for the users to make it really usable. And then we are researchers, so actually we would like to write a paper about it. I think it can be interesting. So, yeah, that's the plan. I guess.
00:19:52.830 - 00:20:53.170, Speaker A: I had a question. Does the smart contract handle the payments and file tokens? Well, it could, but for now it doesn't. So we didn't really know how to implement file coin payments because then we'll have to the users for this privacy preserving layer, they submit money to the deposit and then they get some crypto material saying, okay, you've paid this amount that they can randomize and make privacy preserving. So then we can pay like the smart contract could potentially pay it from this deposit directly the node after submitting the proof of timespace from filecoin. But then we'll need to add verifying the proofs of timespace from filecoin onto our smart contract so it could be done, but at this version, it doesn't do it. Gotcha. Very cool.
00:20:53.170 - 00:21:24.020, Speaker A: Thank you. And did you use powergate to build this from textile or no, we didn't. No. Okay. So we were considering a lot of technologies because we also were considering powergate and then fleek to deploy it and then just lack of time. Gotcha. We ended up with CLI.
00:21:24.020 - 00:22:18.156, Speaker A: OK, awesome. Thanks, Team FPM. Thank you. All right, up next we've got Team Umwelt with rafael, feel free to share your screen and tick that share sound buttons over the video. Because it only has adio. It's a decentralized application to make semantic carries. It has a stack.
00:22:18.156 - 00:23:37.660, Speaker A: It was built with IPFS type of client. And you upload books and media and it will tag it into Linked Data model which is web ontology language, and you can make carries out of it. And it is a public ontology. So you can make this sort of carries not only in this platform, but you can download this information and also search for it depending on your interest. It is an idea to decentralize the search engines. That's a sample of how to upload it. It will get a hash on IPFS and it will retrieve from the ontology file.
00:23:37.660 - 00:24:48.610, Speaker A: Every time you upload a file, it will update this ontology and you can follow the blocks, for example, of these updates also, that's a sample of this. The ontology is also hosted on IPFS and the idea was to experiment with different web3 technologies. I also got really interested during this rakuten over Filecoin to try to also upload these files and other medias there and also had some interest over centralized identities over this ragaton. It was a really interesting experience.
00:24:53.460 - 00:25:21.390, Speaker D: Thank you. Nice background music. I was curious if there were any parts in the kind of IPFS technology stack that you guys used in order to store the data here. Were you just directly using like a Goips node or did you use textile or fleek or any of these things to store the data?
00:25:33.420 - 00:27:12.334, Speaker A: Hey, Rafael, I think you're muted sorry, when I lost the screen, yes, I was using an IPFS node and with the client, I would connect with it and insert the the raw bytes of the file and retrieve the hash from IPFS. And then I would create a JSON and this JSON would also have a hash and I would insert them on the ontology. But it is a stack with the idea is to decentralize keep decentralizing it. I guess the stack running IPFS know this. I don't know. This architecture tends to change, I think with more experimentation, like only with JS clients or something like that. What would you add to it next if you were to continue building it? I probably think I would go to try to experiment integration with Filecoin and some other medias also like videos and audios to it.
00:27:12.334 - 00:27:34.150, Speaker A: In this example, I was using only books, but I don't know. You can add many sort of media formats like scientific papers, also SS feeds. And the idea is to feed this data structure.
00:27:37.290 - 00:27:49.340, Speaker D: Yeah. Thanks so much for sharing. This was a really cool demo. I really liked learning more about it. I'm curious, do you think that there are any sort of features that are missing right now? Just piggybacking off of what Harrison asked.
00:27:53.250 - 00:29:00.066, Speaker A: Yes, I think that it would be interesting to be live on the web. It's something that I'm trying to experiment. And with this feeding of data, I think it would be an interesting platform to be around. I think that also some identity questions would be interesting to implement, for people to have more to integrate with other to make it possible this interoperability with other chains. And to think of these questions, I think identities are a good point, but thank you for letting me take part of and learn about those features of the ecosystem. It was an interesting experience. Awesome.
00:29:00.066 - 00:29:36.680, Speaker A: Thanks for creating something great. Thanks so much, Rafael. Up next we're going to have team filecoin 123. One, two, three. I think Roger is going to take it away. Feel free to share your screen. Roger.
00:29:54.430 - 00:30:31.774, Speaker E: The coin one, two, three website is divided into homepage basic information, blockchain details and nodemap. It provides for kinds of information query. The homepage displays regular basic information, including the latest block height, network, computing power network, account number, etc. The interface is refreshed every 30 seconds. The latest block table is implemented by first obtaining all blocks within a specified height range and then listing the miners within that range. Refresh every 30 seconds. The height range is the block height generated within the last 30 minutes, and the miners list fluctuates based on the number of blocks per height.
00:30:31.774 - 00:31:07.034, Speaker E: Next is the latest news section. Get the latest packed block, get the list of messages inside the data, and then the miners ranking table. A key field to explain the effective calculation. Occupation Field every 30 minutes to go through the list of all miners, update the effective force data for all minor lists from the Lotus OPI. The formula of 24 H mining efficiency field is 20 for H mining efficiency is equal to 20 for H mining efficiency. In 24 hours, miners accumulated block rewards miners effective calculation. And finally, the field of Attribution team personalized Definition node.
00:31:07.034 - 00:31:25.220, Speaker E: Attribution team easy for users to view. Let's look at the block details page which lists all the block, hash values and so on, and see the single block details. List all the information. Click on the message tab to view all messages. Click on the account tab to view all account information. Let's try the query function.
00:31:46.390 - 00:32:14.280, Speaker A: Hey, Roger, it looks like you ended your stream there. Maybe that was on purpose. You're muted if you are trying to reach to us, that's all the presentation. Okay, great. Awesome. So I'll turn it over to questions.
00:32:27.450 - 00:32:40.090, Speaker D: Yeah, I can go. So thanks so much for sharing this. This is really great. I'm curious, what do you think is next for you guys? Like, what else do you want to build? Or what features do you want to add to this sort of dashboard?
00:32:42.350 - 00:32:44.410, Speaker A: Shida shida.
00:32:49.390 - 00:33:30.790, Speaker E: Shi manda tika ti shi lang pan based on the filecoin link data, this paper provides the filecoin link data API service for community developers optimizes the data collection strategy and database table design makes the data service more efficient, carries on the high order link data analysis and gives the valuable data analysis results.
00:33:35.910 - 00:33:55.160, Speaker A: Very cool. What was the biggest challenge you guys faced in building this? Were there any unique challenges to scraping the data from filecoin? Sorry, pardon?
00:33:59.200 - 00:34:01.150, Speaker D: I think he wants you to repeat your question.
00:34:01.520 - 00:34:16.370, Speaker A: Oh, sorry. I was just saying, what was the biggest challenge you guys ran into? Or were there any unique learnings from scraping data from the filecoin network to build this?
00:34:25.730 - 00:35:08.800, Speaker E: Difficulty and solution cannot get block rewards for a block from the data interface. For Lotus, block rewards are sent to the Lotus VM as an implicit message solution by calculating the reward state in each tip set, compare the change in the reward balance between the previous tipSet and the next tip set, and then select a reward for each block win. Count the average block per block produced by the block reward the whole network. Minor data calculation is huge. Need to seek efficient strategy. Reason according to the performance of Lotus test network, two later miners data more solution. Take a sample every 30 minutes from the miners data in the chain and take a snapshot of the miners data with arithmetic power is more than zero.
00:35:15.730 - 00:35:28.818, Speaker D: Awesome. This is super cool. I was curious, if you guys spent more time on it, what would be the next thing that you would do or add to it? What area would you explore more?
00:35:28.984 - 00:36:11.610, Speaker E: Welcome to the Shiji. What do you do or what you do based on the filecoin link data? This paper provides the Filecoin Link Data API service for community developers, optimizes the data collection, strategy and database table design makes the data service more efficient, carries on the high order link data analysis, and gives the valuable data analysis results.
00:36:22.290 - 00:36:23.300, Speaker D: Thank you.
00:36:25.830 - 00:36:45.000, Speaker A: Awesome. Thank you. Team Filecoin. One, two, three. Up next, we have Team Open Polk Assembly, and I think a note for the judges. You may need to refresh your judging sheets just for this team to show up.
00:36:46.810 - 00:36:52.090, Speaker D: Is it if we have, like, partially input data, is that going to stay there if we re refresh?
00:36:53.070 - 00:37:14.556, Speaker A: Good question. I think it should, yeah. I think it auto saves. Cool. All the judges got it on your sheet. All right. Sweet.
00:37:14.556 - 00:37:36.712, Speaker A: Okay, Tibo, feel free to take it away. Hi, everyone. I'm tibo Sardon. I've been working on pocassembly and openpocassembly. So open. Pocassembly is actually an extension to make pork assembly trustlet. So first of all, I'm going to tell you what Pork Assembly is the centralized platform that I've been working on in the past.
00:37:36.712 - 00:37:59.600, Speaker A: So it's like a forum where people can create new pods and comments. So it has existing users. It's already. Live on kusama pocassembly IO, for instance. And you can see know posting things and commenting. You can also see the on chain proposals for polka dot, for instance. And people can discuss and vote on them.
00:37:59.600 - 00:38:24.900, Speaker A: So this is all nice, but it's a Web Two stack and this is what we want to solve with open Pocassembly. We want to make it the same, but trustless and censorship resistant. So how does it look like? Well, exactly like Pocassembly. And this is the whole point. I really want the UX to be the same and Web Three should be as easy and performant as Web Two. So here you go. This is a test discussion overview.
00:38:24.900 - 00:39:24.440, Speaker A: There's already a new post here, but I'm going to create one and I'm going to have some content in there. And so what I do here, I'm already logged in and when I create a new post, there's this little dot here that tells me the content on this page matches with this one stored on IPFS and you can click on this little button to refresh it. So what happens is actually when I created this post, I'm creating on threaddb a post that is similar and I'm checking between what's on my centralized DB and what's on IPFS. So here I can comment as well. And you're going to see here this little dot is going to change and it's been checking basically the update I can also edit. For instance, if I save here, it's actually turning red. There's a little glitch, I need to refresh it, but then in the end it tells me it's green or good.
00:39:24.440 - 00:40:19.556, Speaker A: My comments and my post, everything is matching with what is on IPFS. Now, let's say I'm a malicious actor, I have access to the DB. So here I can see the comments, for instance, and I spot this one, I can comment, I can edit, which I just wrote, and I'm going to hack this directly from the DB. So I hacked you, for instance, I'm going to save this and go back to my fleek and just refresh and see what happens. So here it's checking on IPFS and it's going to turn green or red, depending on the outcome. The go, it's turning red and it says the comments do not match between this page and what is stored on APFS. So we should not trust and you can update that's the same, you can refresh it if you have a look at the console.
00:40:19.556 - 00:40:57.112, Speaker A: Actually, I'm logging some more things. So I'm just saying iHack you is different than what I'm expecting, which is I can comment, I can edit. So this is all about Hawk assembly. It looks super simple, yet it's a bit complex in the back, but that's the idea so that the users don't have to trust and can see it right away, while benefiting from the super high performance of a Web Two platform. So how it's built? Using Textile HDB, as I said, to store posts and comments. It's hosted on IPFS for the front end using Flick and it's been pinned on Pinata and Archive on filecoin. Thanks a lot.
00:40:57.112 - 00:41:08.132, Speaker A: For your time and see you around. Awesome.
00:41:08.186 - 00:41:32.920, Speaker D: Thank you so much for building this. It's super cool. I'm curious, you're talking a little bit in your description about wanting to add better authentication onto threadsdb. I'm curious about kind of what your next steps were there and kind of what the hack is, if you will, on the current behavior.
00:41:33.600 - 00:42:35.292, Speaker A: Thanks for the question. That's actually what frustrated me the most when I started in this hackathon to get to know Textile DB, and I wanted also to maybe play with three box and stuff like this. And it turns out that the DB doesn't have any ICL, so basically anyone that can read something can write on it. So it's fine if you're playing with your own checklist and stuff like this. You can add stuff and remove and you don't want to share this, but what if you want to share the read thing but not allow anyone to write on it? Well, you can't today, so it's not really a hack. It's just something that you cannot do in a decentralized manner today with Freddy DB, the same way the authentication is not awesome. I would have loved to use three box, but to be honest, actually my server is actually exactly working the way three box is doing.
00:42:35.292 - 00:43:07.960, Speaker A: So there is a centralized server today that matches an ID with an Ethereum address. And this is what my server is doing. My server is open source, but so I can hack it if I want. So I know that I don't know if I haven't been in this call for long, so I don't know if there is anyone from $3 there, but I know they are building Ceramic, which is intending to do this. It's okay for Ethereum, but it's not yet there for Polkadot. And I know they're working on it. I'm talking with them actually in private, but it's not there.
00:43:07.960 - 00:43:33.250, Speaker A: So I know what I have to do and I know where I can make it better and really decentralized. It's not totally yet there, but it's at least a bit censorship resistant. And if we have ACL from Freddb, then we're at least okay to move a Web Two to a censorship Web Two Web Three platform, which is I think, pretty cool.
00:43:37.480 - 00:43:42.410, Speaker D: Cool. Thanks so much for sharing this. I'm curious what is next for you guys as a team?
00:43:43.740 - 00:44:37.512, Speaker A: So the team is myself, and the next part is playing with Ceramic to make this. So what I mentioned to make the authentication like, truly decentralized without any authentication server in the middle. I've been chatting a lot with the textile people during this hack, and they've actually kicked off a big refactoring of their API to basically be able to tackle this ACL liability. I was in the shoes today of someone, okay, I have a Web Two stack. I have users. I cannot just rebuild it all in Web Three. I want to just see if I can be step by step, a bit better or more decentralized, at least today, to be totally honest.
00:44:37.512 - 00:45:11.878, Speaker A: It's just not possible. You cannot think, okay, I'm going to take this decentralized DB and just do whatever I was doing on my Web two stack and do it with the web3. And this is what I wanted to check. I'm pretty sure in the next six months we can make this evolve. But for me, I'm just going to work with the teams from textile and from ceramic to just make this happen. How long it's going to take? Probably more than six months to be totally transparent. Very cool.
00:45:11.878 - 00:46:28.478, Speaker A: My question is, in regards since you had already built a version of this on a Web two stack, what was your experience then, taking that and switching it to a Web Three stack? Was it a difficult process, any learning? Yes, very good question. Actually, it was the hardest part to figure out what you can do, actually with these web3 things, because I've been in the ethereum world for like two and a half, three years now, building things. And I've touched IPF and everything, but not really building with it. And the hardest part was to actually train, to understand, okay, this API has been built for other people and you want to do something else with that. So the API I've been using were actually used for you own your data and you do whatever you want with your data, but you're not actually sharing your data. So today if you want to build, say, a Facebook like thing where you're going to write things and show specific things to some people and actually allow some people maybe to write to you, but not everyone, again, it's not really possible. And it's just because it hasn't been thought through and maybe just because it's super early.
00:46:28.478 - 00:47:34.560, Speaker A: So the harder start and what I've learned is actually that while the documentation is also a bit lacking and I've actually offered my help to make this better because often when you're in web3 mindset, you're like, okay, this is the kind of user I'm going to have for my API. And actually when you open it to hack FS, people that come up with like, I mean, my idea wasn't crazy, but it sounded crazy, obviously, because it wasn't made for it. I guess it's super good for the people to just realize, okay, actually this API should be turned this and this and maybe a bit more generic so that it can cater for other use cases. So, yeah, the hardest part was to turn this into my own use case and make it work with my own use case. Thank you. TiVo team one of one on open Poke assembly. Awesome work.
00:47:34.560 - 00:47:49.730, Speaker A: Great. Up next we have Team Graffiti. So, Michael, Sammy, Stephanie, feel free to share your screen with the sound button ticked on, turn on your cameras and welcome to. The judge ceremony.
00:47:56.810 - 00:48:34.734, Speaker F: This is called graffiti. And it is called that because we're going to be drawing what looks like graffiti. And the data structure for these objects are going to be directed to cyclic graphs. And this will help us gossip about, gossip about user generated content and also a way to crowdsource the funding of the pinning costs needed by the person who created the wall or the post. In this case, this demo was just created just to give an idea of this could have been reddit, this could have been messages, images or whatnot. But just think, more visual here is just drawings, right? So in this case here, I'll just have some drawings done here on this side. And you see they get gossiped immediately.
00:48:34.734 - 00:49:25.874, Speaker F: Over each individual line is its own message, but it also references two or three of the previous lines that it's drawing on top of. That way, not only does it maintain order locally, but when this client receives it, it'll also append references of where it's seen that line drawn on its own canvas, which may or may not be the same ones. But most of the time it is in this case because things sync so fast, and then it will gossip that information back across the network. So all the clients will be aware not only where they drew something in reference to the lines that they see, but also where other clients have seen things being drawn on top of. And the idea here is that the more gossip there is and the more clients that are, the tighter this Dag will be and the more consistent or the ordering will be in the long term. And then once a client connects to the network, they will immediately find nearby clients. In this case, he connected to this one here.
00:49:25.874 - 00:50:06.238, Speaker F: First pull the data, and then if I hit syncing on here, then he'll pull data from here too. This syncing is not done via gossip. It's done directly. You find a peer, you see if they speak the correct protocol, and then you start exchanging information with them to pull the remaining data. There's a lot of content here. This might be expensive. So the better thing that we do also is allow individual clients to post checkpoints of the Dag to IPFS such that they can gossip that those CIDs around a new client can come on board, find one of the CIDs, pull the information from IPFS directly, and then just have to worry about syncing the differences with the updates.
00:50:06.238 - 00:50:50.474, Speaker F: So again, we have gossiping about the data as well as gossiping about CIDs containing checkpoints of the data. And then additionally, I touched on the concept of creating a wall. So you can create your own wall. And as the creator of a wall, you can be expected to pin things to IPFS if they gain traction. And by gaining traction, what we mean is that every single one of these lines here contains an additional payload of assigned Ethereum payload. So these payloads pretty much are intended to give tip to the creator of the wall. And once enough of these lines, therefore enough of these payloads have been accumulated, the person who created the wall can post in batch all of these payloads on the Ethereum blockchain.
00:50:50.474 - 00:51:45.906, Speaker F: Will they be verified against the signatures of those payloads as well to see if they meet a threshold of interaction or a threshold of tip. And then all of that coin will be transferred. ERC 20 tokens will be transferred from the individual tippers to the tippy. And then you have to rely on someone here on good faith that the person who created the Wall will use those tips in order to pin the content. Once we get to a filecoin VM, this can be puppied not only atomically, but trustlessly. So you can have filecoin smart contract not only verify all those payloads, but also use them directly to pay for the pinning of some content that they've all agreed upon. So that's the overall idea here is just gossiping about content, gossiping about where everybody else saw that content, pinning IPFS for checkpointing data and then crowdfunding for pinning that data so more eyeballs can see it.
00:51:45.906 - 00:52:05.160, Speaker F: And then if more eyeballs see it, you can have these runaway social media posts or content that we can expect from things like Reddit and Facebook. When enough likes come on then enough more people see it and it goes away. Anyway, thanks for taking a look at this demo.
00:52:07.930 - 00:52:08.710, Speaker A: Yep.
00:52:09.230 - 00:52:11.980, Speaker F: Sorry we're not having maximized the screen there.
00:52:15.710 - 00:52:18.390, Speaker D: This is super cool. Thanks for sharing.
00:52:18.550 - 00:52:19.420, Speaker F: Thank you.
00:52:19.950 - 00:52:47.842, Speaker D: I'm really curious about the part around tipping using my understanding of this is based on the lines that were drawn, you look at all of the different parties that drew lines and then tip the creator of the wall according to the people who drew lines. I'm curious a little bit how you kind of came up with that concept and then in order to draw then each one of those is an Ethereum transaction every time you additional line.
00:52:47.896 - 00:53:46.626, Speaker F: Yeah, I'll explain it. So basically the idea here was users are generating this content, but really you can't have everybody individually paying for the pinning of content. So how do you accumulate that coin? So the way it works is every single line I'll give an example of, there's a smart contract in the Ethereum blockchain here where you can post in batch an array of signatures and an array of tipping intents. So instead of it having to be individual transactions on the blockchain for each micro tip, you can post all of those as delegate calls. So that way this checks the threshold. So if you have 50 lines, you will have had 50 tips that were gossiped around that say if you find a way to collect enough tip, the contract will allow you to verify true and then go ahead and send you all those coins, the 50 different coins or the 50 different transactions. And if the post doesn't get enough traction, then when you try to validate, even if the signatures are all good, the amount of tip that's been accumulated is not sufficient and then the contract will fail.
00:53:46.626 - 00:53:52.730, Speaker F: So it's just every line not only contains the payload, but it also contains a signed intent that is broadcastable as a batch.
00:53:53.230 - 00:53:54.522, Speaker D: Super cool. Thank you.
00:53:54.576 - 00:53:55.420, Speaker A: No problem.
00:53:57.150 - 00:54:01.018, Speaker D: Yeah. This is a really unique idea. I'm curious, how did you guys come up with it?
00:54:01.184 - 00:54:32.294, Speaker F: Yeah, so the idea is we wanted to make like a decentralized reddit and we didn't think that Lorem Ipsum text would have been a visual enough or quick enough demo. And also having lines and drawings is a good visualization for what a Dag would be useful for in terms of having lines on top of each other. It's very easy to visualize if your line that you draw is behind on top of something. So the idea is, okay, well, how do we make something decentralized and that uses the Dag that's visual and specifically here, user generated content is quite ephemeral and it's promotion based.
00:54:32.332 - 00:54:32.486, Speaker A: Right.
00:54:32.508 - 00:55:05.290, Speaker F: So you don't expect it to exist for that long. When you post on something on reddit or you comment, you don't go back seven days later and check it, so you don't expect it to be there forever. And it's also promotion based. Right. So as content gets more and more liked, it should be seen by more and more people. And this was very conducive with the idea of, okay, well, we have really hot storage which is keeping it locally and then gossiping it, you have a little bit more colder storage where you start putting things in IPFS and they might get deleted or might not because it's free. And then finally pinning data which is where enough people have said this is worth everybody seeing it's got 1000 likes or whatnot.
00:55:05.290 - 00:55:10.180, Speaker F: So the two ideas can conducive. And we want to take a look at decentralized user content.
00:55:17.790 - 00:55:30.686, Speaker A: If you were to continue working on it, your plan would be to integrate it to filecoin so maybe those tips could be used to store it. Is that the idea?
00:55:30.788 - 00:56:05.978, Speaker F: Yeah. So of the array of things we want to do next, one of them is definitely yes. Right now you have to rely on good faith that the person is going to use the coin. They got an Ethereum to pay for the content and if they don't, then you kind of like blacklist that wall creator and you never tip them again. But it's not really enforceable. But yes, once you get Alcoin VM, if you can do that same smart contract, then there's no if, ands or buts about how the tip is being used apart from spam protection. We have some ideas on using Hub and spoke state channels to prevent people from, like, to enforce people to not only tip the creator to wall, but give a little bit of tip to the person who drew the last line.
00:56:05.978 - 00:56:18.080, Speaker F: So if you think about it down the road, that actually helps with good faith content in that no one wants to have the last word, and therefore you only want to draw something. If it's worth drawing, I can get into it, but it's long.
00:56:19.010 - 00:56:30.114, Speaker A: Yeah. Awesome. Thank you, Michael, for your demo and everybody else on the Team awesome project.
00:56:30.232 - 00:56:31.620, Speaker F: Thanks a lot for having us.
00:56:32.870 - 00:56:44.390, Speaker A: Great. Up next, we have Cindy from Team Cadencia. So, Cindy, feel free to share your screen. The sound ticked and turn on your camera if you're willing.
00:56:50.810 - 00:56:54.440, Speaker D: Just to let everybody know there's no audio on this demo.
00:57:01.330 - 00:58:48.896, Speaker A: Ram. SA. It also might be helpful if you guys do a quick little explanation of what you built there, too. I know it's good to see the UI, but quick little high level explanation would be helpful, too. Yeah, absolutely. So Cadencia aggregates data from decentralized sources. The goal was to create, like, an interaction of data sets on one interface.
00:58:48.896 - 00:59:33.920, Speaker A: And we wanted to do that because we thought that by having them all on one interface, we could make insights into that data more accessible. And we thought that would be important because accessing that data, while it is public in nature, is very difficult for nontechnical users. So we wanted to make those insights accessible for people who aren't developers or data scientists. And beyond that, we wanted to foster a community of people who cared about high quality data and also use that data. And, yeah, those are kind of the core features of Cadencia.
00:59:40.300 - 01:00:54.170, Speaker D: Well, you mentioned in your description that you had difficulty syncing to the FalcoIn network, but that you were still able to get the visualization, and the nodes on your globe do look relatively accurate to where I'd expect them to be. So what was your workaround there? We were using mock data. We were unable to sync for testnet just because we didn't have enough Ram on our computers. But that didn't stop us from looking at the grafana and checking it out and saying, maybe we can make it look as realistic as possible to anticipate that real time data when it's ready. Yeah. Thanks so much for sharing this. I'm curious, what were some of the unique challenges that you guys had when working on this project? One of the challenges that I've had while we were building this was we're pulling data from subgraphs right now from the graph, and we're using their GraphQL endpoints, and making one Apollo server consume multiple Apollo clients from multiple GraphQL endpoints is kind of difficult.
01:00:54.170 - 01:01:23.440, Speaker D: Also, another major difficulty is the lack of standardization of data. So each API is written, decided by each organization, and also, especially with DeFi data, a lot of the data is denominated in the base token currency of whatever that chain is using. So that makes it difficult to compare, but likely down the road. I would like to publish an NPM package or a module that would standardize the data to make it more comparable.
01:01:28.830 - 01:01:36.094, Speaker A: Is the idea to also get data from sources outside the graph in the future?
01:01:36.292 - 01:01:52.420, Speaker D: Yes, absolutely. So when we're anticipating data sets that are stored on Filecoin as well as Oracles, it would just ensure the high qualityness of the data because we can cross check them to look for consensus amongst them.
01:01:53.910 - 01:02:27.550, Speaker A: So to verify if the data is accurate versus not, the plan would be to use Oracles and judge it based on the sources of where that data is coming from. Yeah, so we would kind of be cross checking that data from those sources. And I guess we would just kind of be creating another layer of verification on that data. And most of that data does come from those reputable sources like Oracles or subgraphs that are already synced.
01:02:28.610 - 01:02:43.460, Speaker D: Well, they do have different mechanisms of verifying the data as well, so there would be more investigation needed to see how we're going to create consensus when all these verification mechanisms across Filecoin Oracles are so different.
01:02:44.150 - 01:03:33.974, Speaker A: Got you. Very cool. And we also just thought that there was some kind of natural verifier properties in the project, so that in that filecoin dash. That's why we visualized how much of the network is verified or not. That's all mock data, but we just kind of wanted to show that as a tool that we could kind of also provide that service. Awesome. Well, thank you so much, Team Cadencia.
01:03:33.974 - 01:03:35.678, Speaker A: It's a great team name as well.
01:03:35.844 - 01:03:36.334, Speaker D: Thank you.
01:03:36.372 - 01:03:58.340, Speaker A: Very unique. Awesome. Great. So up next, we have another team that judges you may need to refresh your sheet for team is crowdstore. Looks like they're all coming in and great. Whoever on your team is in charge of the screen share, feel free to do so and share the sound. And there we go.
01:04:01.350 - 01:04:55.542, Speaker C: Good afternoon. Or evening, or morning, depending on where you're located. We are extremely appreciative of your time and we're looking forward to showing you what we've been working on for the last month and to getting some feedback. So we are Crowdstore and we are interested in an exploration into incentivized information propagation. The long term goal of our exploration is to enable digital organizations such as messaging applications, forums, or organizations yet to be conceived with a means to spread their information through incentivized crowd mechanisms. With that being said, based on our experience level, we wanted to limit our scope to building a proof of concept that mints a non fungible token for a filecoin storage deal. On top of this, we also had the goal of learning as much as possible.
01:04:55.542 - 01:05:35.250, Speaker C: This is our first time working with IPFS and Filecoin, and we also have very minimal solidity experience with that introduction. Out of the way. Let's get into the demo. As many of you may be aware, the quote original hackers of the had such an extensive list of Jargon that they would actually post a Jargon file weekly so that they could understand each other. In this spirit and the spirit of hacking, we created a forum for them to incentivize the spreading of the Jargon file. As you can see here, we have a user associated by his ETH address and he has zero seed NFTs for spreading the Jargon file. We will click here to begin spreading the Jargon.
01:05:35.250 - 01:06:08.526, Speaker C: This is the seed page where individuals in the organization can go to upload their file. We designed the seed page to be separate from the main application so that organizations can deploy this page to IPFS and then build their application or use case to work in tandem. Once the user's verified this info, they can go to the next step. Here the user can associate his ETH and File coin address so that once he makes the storage deal, he will get paid his NFT. Once those have been associated, they can go to the next step, add a.
01:06:08.548 - 01:06:09.230, Speaker A: File.
01:06:12.870 - 01:07:00.030, Speaker C: Make the storage deal and boom. From there they can go to the next step and view the transaction hash for the token that was minted. Then the user can go back to the forum and see that they have one seed NFT for helping to spread the Jargon file. So how exactly does our application work? From the front end, the user associates the address using MetaMask. From there, a storage deal is made through Powergate. After that, the deal ID is sent to our backend which verifies the deal through the Lotus API. And then from there the token is minted onto the Ethereum address where our front end pulls to update the balance.
01:07:00.030 - 01:07:58.958, Speaker C: The two biggest flaws in our design are one, that we assume the user already has the file on their drive and two, that the backend is a single point of failure. If it were to go down, then no new NFTs would be minted. The inspiration behind our application, besides filecoin and Ethereum of course is Discord. For those of you unfamiliar, discord has the inverse model of Slack where users can boost the server to have it gain benefits and in return they gain perks and privileges within the server. In this light, we envision organizations creating customizable reward structures for users to redeem their NFTs for. While we've had fun, there is still a lot we hope to do. Mainly, we hope to add a mechanism to accept wrapped filecoin, resolve our single point of failure, develop reward strategies and then build a prototype P to P chat application using Libad P to P to run trials and tests.
01:07:58.958 - 01:08:01.670, Speaker C: Thank you. We'd love any questions or feedback.
01:08:06.410 - 01:08:17.500, Speaker D: Thanks so much for sharing this. I'm really curious how was it your first time building something that was like Web Three native? What was that experience like and what was good about it, what was challenging about it?
01:08:18.590 - 01:09:24.640, Speaker C: Yeah, definitely was a large learning process, I would say. Well, I mean, one of the biggest things was, I guess just getting, like, MetaMask our local FNET as well as Powergate with the multiple instances as it runs all working together. That probably took us half the hackathon just to kind of get those just to verify we were actually talking to the right endpoints and such. And then yeah, so from there, it was just kind of working on integrating those two well, specifically information from the two different blockchains. That was probably the biggest that was probably the biggest takeaway I had was that there's a good amount of work that needs to be put into just to verify that a storage deal was actually made and then communicate that information to the ethereum blockchain in a manner that's secure, I guess.
01:09:28.210 - 01:09:53.594, Speaker D: I saw in your kind of architecture that you guys are using Powergate. This seemed to be mostly like storage oriented, but was there also kind of a fetch side of being able to then fetch this more decentralized version of the Jargon file from the IPFS network or kind of how did that aspect work?
01:09:53.712 - 01:09:54.182, Speaker A: Totally.
01:09:54.246 - 01:10:01.340, Speaker C: Yeah. Unfortunately, we did not get there, but that was kind of what one of our next steps was.
01:10:01.710 - 01:10:20.000, Speaker A: Yeah. Besides that next step, what else were you thinking to build into the project if you could keep going or if you do keep going.
01:10:20.850 - 01:11:09.726, Speaker C: Yeah, so first thing would definitely be to incorporate. I saw there was another project that did, like, wrapped file coins, so I think it would be cool to be able to just contribute F as well. But then after that, mainly focusing on how do we kind of remove the back end, because I think it kind of in some use cases, it defeats the purpose to have the organization host a back end when they're not even trying to host their own file. I guess we're playing around a bunch of options, like assume every storage deal was good and then have possibly the users vote on which actual storage deals.
01:11:09.758 - 01:11:31.216, Speaker A: Were legit, things like that's. We have time for one more question if anybody has anything burning, I guess.
01:11:31.238 - 01:11:33.890, Speaker D: What inspired you guys to take on this project?
01:11:37.780 - 01:12:01.050, Speaker C: I don't know. I guess it's a good I mean, I like Discord's model, and I just saw all the pieces are kind of there for a decentralized version. It's just like how you put them together, I guess. Yeah. I always feel like a greater sense of community kind of in Discord forums than most other places I go, so yeah.
01:12:04.160 - 01:12:19.410, Speaker A: Thank you. Awesome. Thank you, team crowdstore. Awesome. And then up next, we have our last but not least, Team Drazel contacts. So it looks like Josh is here, ready to go. He's got the right background and everything.
01:12:24.400 - 01:12:29.744, Speaker G: Hello. So I'm sharing my screen in 1 second. Is everyone able to see?
01:12:29.862 - 01:12:31.632, Speaker A: Yep, looks great. Cool.
01:12:31.686 - 01:13:22.092, Speaker G: So Drazel. Contacts is a Contacts app. It's meant to provide a way to keep your address book or contacts always updated by the people who have that contact information. So you would enter in your phone number, address, all that stuff, and it would automatically update everyone else's information on their phone. So the problem is that traditional contacts apps are outdated always. I can't count how many times my friends or family have tried to reach out to me, but I've updated my email or contact information and they have to find some way to get the new information. And so the problem is that you own their information, you have a copy of their information that you're in control of and having to keep updated.
01:13:22.092 - 01:14:15.424, Speaker G: But wouldn't it be great if they were able to do that? Razel Contacts is a decentralized contacts app that allows you to request subscriptions to other people's contact information. And whenever those people update that contact information, that contact information gets updated in your address book. I'll log in with the first user here and the second user in a mobile screen, a mobile size screen over here, except the three box connectivity pop up. So we're using MetaMask and three box. Everything is running on fleek. Underneath three box, there's Orbitdb and other technology and of course IPFS. So the first thing you see whenever you log in is your contacts list.
01:14:15.424 - 01:14:45.904, Speaker G: Both of these users are brand new to this app, so they don't have any contacts. We'll go through creating one in this demo. They also have access in the second tab to profile information. So this is where the users will add their profiles that they can allow other people to subscribe to. So I'll quickly add a user here. It'll be a work profile and I'll just select that. So now we have a work profile.
01:14:45.904 - 01:15:30.056, Speaker G: When I hit Save that went through and added it to a three box store for this user. It's private, so only that user has access to it. For now, we'll do the same thing for this user. We'll go to the Ur info page, we'll add in a profile, we'll say Lane and we'll give him first name and we'll just give him an email address of lane@email.com. So now they both have a profile. And then the next thing that we'll look at is request to access that profile. So this user on the left will hit add contact.
01:15:30.056 - 01:16:28.028, Speaker G: And if you remember, this user had an email of lane@email.com. So we'll add in lane@email.com and then since all of the application instances are connected to a thread, they will be able to see the messages that are meant for that user and send that user a message. So on the mobile view we see that a user named Joshua Purcell, which is the same information that was in our default profile, our only profile over here is requesting access to our information. And this user only has one profile, so that's the one that's showing up here. And then we're able to choose to either accept or reject that subscription request. So we'll accept it, and then it'll eventually pop up for this other user in their Contacts app.
01:16:28.028 - 01:16:38.510, Speaker G: And so we see the user's name and the email. And so now whenever this user updates their information, it'll automatically get updated for this.
01:16:49.280 - 01:16:54.252, Speaker A: Oh, Josh doesn't see oh, sorry, I was on mute.
01:16:54.316 - 01:17:13.610, Speaker G: I was just talking about this is quickly a diagram of the different spaces and the threads that we're using and whether they're private or public and shared between people. We can talk about this a little bit more if you have questions as well as upcoming plans, but I'll open it up to questions and we can go from there.
01:17:22.140 - 01:17:58.672, Speaker D: This is super cool. Oh, sorry. Harrison, thanks so much for sharing this. I was curious on kind of the last piece you were showing around, kind of the schema that you guys had used and kind of how you were exchanging this information between people, how you kept these things in sync. I'm curious if there were any challenges or hacks you had to kind of put in to make sure that people were getting kind of the updated contact info. Especially you mentioned a little bit in how it's made, like the challenge of when one person's online and another person's offline to kind of have a delayed propagation.
01:17:58.816 - 01:19:20.850, Speaker G: Yeah. For future plans, we plan on having a server probably so that we're able to offload that from the client and make sure that we have some type of mechanism to maybe retry or something like that. But for now, we have this thread. So if you look here at the top notifications thread, that is a thread that's shared across all of the application instances, and a notification will go out from if one person decides to request a subscription to a profile, then a notification will go out there and then the instances will look at that message and decide, is it for me? They filter through those, and if so, then they add that notification to the My notifications thread, which is a private thread, and that's what shows up in the Activity page. And then that allows the user to act upon that, delete it. And then there's a timestamp that makes sure that whenever the application comes back online, it looks at the timestamp that's stored in this Drazel Activity space to make sure that when it's going back and subscribing to notifications, it doesn't get any old notifications, only new ones.
01:19:25.780 - 01:19:47.736, Speaker A: I I saw in the project description you mentioned you had a lot of issues with mobile and connectivity, and long term it would be your goal to make it work as a mobile app. Can you just talk through specifically what issues you ran into or any learnings you found in that regard.
01:19:47.918 - 01:20:35.160, Speaker G: Yeah. So three box doesn't run in mobile. So I didn't try to create a mobile app because of time constraints. I wanted to just focus on a web app because that's what I'm most familiar with. But I know that some of the dependencies would have a problem running, like in Node or like a mobile app, for instance. But I have a plan for I think identity wallet may be a good replacement for some things, or it may make it possible to have a mobile app. But then also, if we were to offload some of the functionality that's in the client on the mobile app to a server, then we wouldn't need to have so many dependencies on the mobile app.
01:20:35.160 - 01:20:38.008, Speaker G: And it would also take into account.
01:20:38.094 - 01:20:38.730, Speaker A: Better.
01:20:40.700 - 01:20:55.260, Speaker G: A mobile device going down and losing connectivity and performance issues. But I kind of sidestepped those problems and didn't really try to tackle those problems for the hackathon.
01:21:01.140 - 01:21:09.296, Speaker D: Thanks so much for sharing this. What are sort of your next steps or what are you planning to do after this?
01:21:09.478 - 01:21:49.840, Speaker G: Yeah, looking into identity index and ceramic. Those are awesome things I'm most excited about. I want to see how I can integrate with that. And then also, like I was saying, mobile app and maybe offloading some of the functionality to falling back to a server implementation. Those are my biggest things. But I have other ideas for the same type of user facing tools like calendar sharing or different ideas that I would use this as a platform to focus on other use cases for end users. My goal is to create tools for end users.
01:21:55.470 - 01:22:23.410, Speaker A: Awesome. Thank you so much, Josh. And a big thank you to all the nine teams that demoed here today. That concludes this group seven judging session. Massive thank you to our judges, who of course, now have to go back and do the hard work of deliberating it's a big thanks to Molly, Monsie and Harrison for dedicating some time to us and for walking through all these presentations with everybody. We're really excited. So much more judging still to come.
01:22:23.410 - 01:22:33.380, Speaker A: Another kind of three days, actually, of judging. So keep a lookout for those. And with that being said, we'll leave that here. And thanks so much for everybody coming out.
01:22:36.630 - 01:22:38.580, Speaker D: Thanks so much for having us. This is awesome.
01:22:39.390 - 01:22:41.002, Speaker A: Of course. Thank you.
01:22:41.056 - 01:22:42.954, Speaker D: All right, thank you.
01:22:43.152 - 01:22:51.594, Speaker A: And just to be clear, is this the halfway point or we're done as judges? Yeah, we're out. I'll send you a note on Slack real quick. Okay, cool.
01:22:51.712 - 01:22:53.338, Speaker D: Okay. All right, thank you.
01:22:53.424 - 01:22:53.880, Speaker A: Take care, everybody.

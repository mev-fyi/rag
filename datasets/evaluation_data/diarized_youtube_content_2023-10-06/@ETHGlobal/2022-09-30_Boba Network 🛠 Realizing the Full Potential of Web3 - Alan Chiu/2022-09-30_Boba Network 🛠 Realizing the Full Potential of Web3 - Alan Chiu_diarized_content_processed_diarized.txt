00:00:06.250 - 00:00:57.084, Speaker A: All right, good morning. Thanks for coming to this workshop about realizing the full potential of Web Three. It's really about how why we build Boba Boba network and what Turing Hybrid Compute, which is only available on Boba, would help developers build more engaging, more more interesting, more compelling Web Three applications. So let's go back in time a little bit, right, to the original creation of Ethereum. And a fundamental premise of Ethereum is that while Bitcoin, which is a ledger, is good, if you can actually program it's even better computers. And our hypothesis is that let's take it one step further. A more connected computer will lead to a more creative and powerful decentralized system.
00:00:57.084 - 00:01:36.680, Speaker A: Just to give you an analogy, right? We all have a phone and imagine creating mobile apps without the cloud, right? You're limited to what you can do on the device itself, and that's it. You can still build apps that run on the phone, but it's not nearly as interesting, right? And that's what we do here. So we started with Bitcoin, bitcoin script, minimal stack based programming language. It's really designed, it's very transactional oriented. It's not terrain complete. And then Ethereum came along. Breakthrough innovation.
00:01:36.680 - 00:02:17.264, Speaker A: However, it is slow, as we all know, and there's a good reason for that. Ethereum wasn't designed to maximize, to optimize for raw compute performance. It's designed to be a decentralized system with thousands of uncoordinated nodes that could somehow come to agreement on something. And that's really hard. And in order to achieve that, there has to be a lot of limitations imposed on the kinds of computations that you can do, that we can do. And, for example, you can only do integer operations. Reason is if you allow folding point operations.
00:02:17.264 - 00:03:16.436, Speaker A: What if two computers are running on different CPUs and they come back, has slightly different answers they won't be able to come to? So that's why Ethereum is slow and the computational complexity is very limited. We can only do pretty basic computations, can't even take the square root of a number and get a reasonably precise answer. But then l two S layer two S came along. But the original motivation for creating layer twos is to address the most obvious challenges of Ethereum, which is speed throughput and cost. Right? There's actually an additional major benefit, and that's enabling more complex computations. And that might seem a little bit counterintuitive. People don't think of layer twos as delivery deck kind of benefit, right? Most people think of layer two, oh, faster, cheaper.
00:03:16.436 - 00:04:12.380, Speaker A: Oh, that's awesome. Let's just move our transactions to layer twos. Well, the key difference what is a layer two? A layer two, really is we're decomposing this monolithic layer called Ethereum that combines execution, settlement and data availability all into one layer. We're taking the execution layer, separating that into its own layer. And we're calling that layer two. And the key difference between layer two and layer one is that a layer two doesn't run its own consensus protocol, right? The whole point is that we rely on layer one for consensus so that we don't need to do our separating these two. Now suddenly because of that, we don't need to worry about what it takes to ensure thousands or tens thousands of computers would arrive at the same answer because layers are only responsible for execution.
00:04:12.380 - 00:05:07.032, Speaker A: And what does that mean? Right. It means we don't need to impose the same kinds of constraints on the kinds of computations you can do as you would need to on the layer one. And that changes everything. So on layer twos, there's only a single sequencer that produces a block. It executes a transaction. And therefore, we thought, well, maybe we could use this to our advantage, to develop this advantage to interact with the outside world, to call external APIs. And after a year's worth of work, we're able to overcome EVM's restrictions by modifying gas.
00:05:07.032 - 00:05:34.048, Speaker A: So we have a customized version of Get running on Boba network. It's called LTT for turing. LTT Geth with atomic support for generating random numbers and making any external API call that you specify, that you trust. And it's super simple to use. Very easy. These are one line calls. What you see on the screen is the pseudocode.
00:05:34.048 - 00:06:04.104, Speaker A: But, like, look at the first example. Turing get random. That's all you need to do to get a random number. On the second example, specify the RPC endpoint that you want to call to, let's say, get the current vault for BTC USD pair. Boom. Like, one call and you're done. Now, how does it work? So let's look behind the scenes a little bit.
00:06:04.104 - 00:07:10.940, Speaker A: So our LTT gap is the one that actually makes the external API call on behalf of your smart contract. So it will intercept certain calls that has Turing calls embedded in them and then call the auction API or brands to generate a random number. And when the results come back, our guest would replace the original call data with modified call data that includes the responses that come back from the off chain call. And this is important because we need to ensure that these transactions can be verified afterwards by the fraud proofers. We need to make sure that whatever we've done is fully compatible with the rest of the optimistic role of architecture. And so we'll write both the original transaction and the modified call data that includes the offchain API responses into ethereum layer one. And from that point on, everything is treated just as if it were a normal guest transaction.
00:07:10.940 - 00:07:58.212, Speaker A: And the key is only the sequencer would call the API, no one else. Because if you let other independent nodes call same API, you might not get the same results back, right? So it's important that only the sequencer makes the calls. And then once the layer two block is written back on layer one and Verifiers and the replicas will use the stored responses from the API call from the block to do their job. So here's a diagram that outlines how that works. So, step one, LTT guest would intercept the RPC. You would make an RPC call to the Gap. And our guest would be like, okay, this is a Turing call.
00:07:58.212 - 00:08:42.020, Speaker A: It is. It calls the endpoint that you have specified waits for the response to come back. If the response doesn't come back as soon as timeout, we've set the timeout currently at 1200 milliseconds. So when you're writing around this, you want to have a graceful fallback default value in case the external API doesn't come back voltage too long. So the response comes back. Our get would replace the original call data with updated input that includes the response that comes back from the option call, creates a new block, and submits that to layer one. And then new block is indexed.
00:08:42.020 - 00:09:26.252, Speaker A: Replicators has worked. Verify this work. Everything else just works. It's taking us a while to roll this out on a main net because there's a lot of work that needs to happen under the hood. These are some of the changes that we need to make. So we modify EVM go and modify the Ethereum block format to include the responses from the off chain APIs. And all of the data from off chain APIs are written back to Ethereum, layer one.
00:09:26.252 - 00:09:29.736, Speaker A: So as a result, we put a limit on the size of the response.
00:09:29.768 - 00:09:30.988, Speaker B: String that comes back.
00:09:31.154 - 00:10:18.878, Speaker A: Otherwise these calls could become really expensive. And then we also added the ability for GEF to replay these compute requests based on the data that's written to Ethereum. We also modified a bunch of internal data types and finalized an assemble and other parts of L two gas, minor worker go. We also needed to modify of services that pass data from layer two to layer one. How you index layer one, how you inject layer one data into the layer two gas. And then we tested and tested and tested. Finally, roll out Turing on Rinkob during East Denver, and then a month later made it live on mainland.
00:10:18.878 - 00:11:09.646, Speaker A: And by now, developers have started building on Boba using Turing. And I'll give you some example use cases. For example, you can build DeFi protocols based on blockchain assets such as real estate or some sort of bonds denominated in fiat and trap by world. You can now start pulling these fiat world real world assets into DeFi world. There's a team on building on Boba, creating an NFT lending protocol that uses an off chain machine learning based valuation model to put a valuation on these NFTs so that they can figure out how much to lend against these collaterals. Imagine doing trying to do that all on chain. It's just impossible.
00:11:09.646 - 00:12:00.770, Speaker A: Too expensive, too slow. But now you get the best of both worlds. You might also want to decide to incentivize your community members to do certain things on social media, for example, to retweet. And you can use Turing to make to call Twitter to verify that, to see if someone has actually retweeted something. And after the verification, you can then automatically release or AirDrop some rewards to these community members. And since it's all happening on layer two, these transactions are much cheaper, much more affordable than layer one. There are also Dow memberships that would dows that want to connect their members identity with the off chain real world identities.
00:12:00.770 - 00:13:23.146, Speaker A: Now, to some of the Web Three natives, this might seems like a little weird, but if you think about how web three is growing and looping in more and more mainstream organizations into the movement, you start realizing there will be actually more and more demand to integrate what's happening on chain with what already exists off chain. For example, there are college alumni associations out there thinking about, oh, how do we create NFTs that represent memberships in our alumni association and identify them as verified members in a metaverse that they created. So in that case, they're not really trying to create NFTs that can be flipped or traded. They're trying to use NFTs to represent an identity that exists in the real world that needs to be verified. You don't want someone to fake themselves as a Harvard Aluminum. So Turing also enables that you can create NFTs that could be connected to the school's official alumni directory and verify the real world identity of that metaverse character. You can also create a Twitter activity based token fountain.
00:13:23.146 - 00:14:05.680, Speaker A: We've created this. We've created a Boba fountain on a rink and beat. And you can also use our atomic random number generator for your NFT. And bottom line is, if we're able to connect this decentralized computer with the rest of the world, with other network computers, you can now create a lot more interesting applications. And this here the list here is we're just scratching the surface. Some of these ideas actually came from developers that started trying not touring. So we've got a detailed write up at this link bitly.
00:14:05.680 - 00:14:52.952, Speaker A: Getturing the capital T. It's really easy to use. It's just one line call. And what really sets us apart at Boba here is we're enabling developers to build smarter applications on Ethereum. We're not just scaling it in a traditional sense or making it faster and cheaper. We are augmenting Ethereum by enabling you to build applications that can include algorithms that are much more complex than what you can execute on Ethereum layer itself. All right, so that's our hybrid compute story.
00:14:52.952 - 00:15:27.670, Speaker A: It's live on mainnet, really encourage you to try it and see what you can build with it. A lot of developers are finding that this completely changes how they think about what they can build. It really expands the design space available to you. And yeah, I can't wait to see what comes out of this weekend's hackathon. Thank you. Questions yes.
00:15:28.600 - 00:15:59.970, Speaker B: Just got a quick question about sort of a quick question about I don't know if it's working, but security. So you said that there was a time limit on requests coming back and having a valid response. Well, do you think it's possible that someone might want to overload the network with requests that might take too long and that might slow down block times or transactions because of that? Is that something that's possible?
00:16:02.820 - 00:16:38.840, Speaker A: It is possible, which is why we put a time limit on it. Of course, we have no control over how quickly the external API comes back. It's a 1200 millisecond timeout. Fortunately, you get to control which APS you call. And our hypothesis here is that the developers are only going to call you're only going to call APS that you trust. So these are either going to be your own RPC endpoints if you're, let's say that NFT lending model, you're running your own off chain valuation model. It's your own RPC endpoint.
00:16:38.840 - 00:17:20.890, Speaker A: If it doesn't come back but it's too slow, you have full control on how you want to fix that. And in the case of calling Twitter or whatever that is, a much more established and trusted API. So that's less of an issue. Now it is possible for a nefarious developer that really intentionally wanted to deploy a smart contract that calls some random API that just never comes back? That is possible. But fortunately, we do control guests in this case where the trusted party operates a single sequencer. So if that's the case, we can filter that out.
00:17:21.740 - 00:17:47.890, Speaker B: That sounds good. What other sort of functions do you see potentially being created in the future as well? You've got random number and API. Do you see stuff like maybe doing knowledge proofs as well? Possibly ways of having arbitrary sort of code get run separately and then having it proved later down the line that this has been run and it's valid as well? Is that something you're thinking about?
00:17:50.340 - 00:17:52.068, Speaker A: Could you frame that question again?
00:17:52.154 - 00:18:17.724, Speaker B: Sure. Are you thinking about other sort of arbitrary sort of functions that maybe developers want to create as well, and having those arbitrary functions run on the network and then maybe having like a proof function, something like ZKP, where you can prove that those functions have been run correctly, the output is correct as well. Is that something that you think about with Boba as well?
00:18:17.762 - 00:18:25.180, Speaker A: Potentially, yeah, definitely. That's something that we're looking into. Related.
00:18:29.760 - 00:18:51.220, Speaker C: Quick question. As you've said, because of the API Turing feature, there can only be one sequencer. The problem that I see is if the sequencer gets attacked, goes rogue, goes offline, right, this would destroy the whole roll up, correct?
00:18:51.370 - 00:19:41.380, Speaker A: Yeah. That's a more general challenge with today's rollouts in general not specific to rollout Turing. So we've already begun our work on distributing the sequencer to address this availability issue. And in terms of rope sequencers, all of the rollouts are going to have to deal with this challenge as soon as we start letting other parties run these sequences. Now, we are not, of course, going to operate a role sequence ourselves, because that will be shooting ourselves in the foot. We have enough skin in the game to not do that. So the idea would be to extend the same, to ensure that other sequencer operators will have enough skin in the game through staking other mechanisms that if they do go rogue, there will be severe management.
00:19:42.200 - 00:19:59.980, Speaker C: But this API feature makes it harder. Right. So if your Ebi equivalent, like optimism, arbitrary, for example, to decentralize the sequencer is easier without the API feature. Right, because how would you come to consensus?
00:20:00.640 - 00:20:13.970, Speaker A: Yeah, so we won't we won't be running our own consensus protocol amounts of sequencers. We'll be rotating the role of making Turing calls multiple sequences. So at any one time, there's only one that's been there.
00:20:17.380 - 00:20:29.712, Speaker C: Another really quick question. You pointed out the example of the Twitter API. Right. So I imagine you have a smart contract. You do the actual API call inside the smart contract.
00:20:29.776 - 00:20:30.390, Speaker A: Right.
00:20:30.920 - 00:20:40.970, Speaker C: You have to put the Twitter API key somewhere. Right? And if it's in the smart contract, anyone can see that. How do you handle this stuff?
00:20:47.570 - 00:21:07.126, Speaker A: We do handle it because we have already implemented a faucet on Rinkbeat that requires a user to go through captcha. And how do we handle the API key? I'll need to get back to you on that to look at how we implement it.
00:21:07.308 - 00:21:07.750, Speaker C: Thanks.
00:21:07.820 - 00:21:09.560, Speaker A: Yeah. Thank you.
00:21:19.310 - 00:21:20.300, Speaker C: One more question.
00:21:23.470 - 00:21:39.242, Speaker A: Any other questions? Yes. Tell them you look very nice today. I did. Thank you. Cool. Will you manage through the hackathon so you get enough sleep?
00:21:39.306 - 00:21:41.930, Speaker C: You're okay? You're excited for the rest of the hackathon?
00:21:42.010 - 00:21:56.254, Speaker A: Super excited. Thank you. That's the spirit. Thank you. All right, well, thank you for coming to this workshop. Please go to Bitlygettouring, check out desktop. Really look forward to seeing you build amazing things on touring and on both of us.
00:21:56.254 - 00:21:56.580, Speaker A: Thank you.

00:00:06.090 - 00:00:07.646, Speaker A: So we are going to move on.
00:00:07.668 - 00:00:09.790, Speaker B: Now to our final panel.
00:00:10.370 - 00:00:16.014, Speaker A: We've got a stacked panel for the last one. We've got Eric Bootish, Tyrone, Phil and.
00:00:16.052 - 00:00:17.646, Speaker B: The other Michael Jordan who will be.
00:00:17.668 - 00:00:36.486, Speaker A: Talking about late to this one. Thanks, John. Hey, everybody, I'm Michael Jordan. No relation. No relation to the Berkeley professor, basketball player or actor. So my parents just have a 6th sense of humor. We're lucky to have three awesome people on this panel today.
00:00:36.486 - 00:01:10.034, Speaker A: Trin phil and Eric Buddhish. I think Trin and Phil have spoken to if you have a context, but I don't know if people know, but Eric is kind of the Michael Jordan of HFT latency and market design. Wrote an incredible paper that I highly recommend and we will crib a lot of this out of. But I wanted to start on this concept of eliminating the latency wars. Eric, I'd love to hear the intuition of how you started thinking about this problem that the latency wars is not in the execution, it's not in the trade team. It's actually hidden. And that the first step is understanding it, is seeing it.
00:01:10.034 - 00:01:12.180, Speaker A: So I wanted to start there.
00:01:12.950 - 00:02:20.774, Speaker C: Great. And no one's ever called me Michael Jordan of anything before, so I'll take it. I think what got me started on this intellectual journey was almost 15 years ago at this point, but was reading about some of the very early investments in speed, technology and fast connections from one geography to another. Geography like the Chicago, New York high speed fiber optic cable that's become kind of famous and genuinely not understanding how such a small amount of time could be worth so much money. We're talking fractions of the time it takes to blink your eye. What gave my collaborators and I the idea for the paper you're referencing that used message data and this is the work with the UK Financial Conduct Authority or with researchers. There was, once I figured out that earlier work, how to think about why milliseconds or really millions of seconds or finer are valuable in modern financial markets.
00:02:20.774 - 00:03:54.946, Speaker C: You realize a lot of the value is around race based arbitrage, is around arbitrages that are sometimes very simple to the naked eye, but the complexity is capturing them quickly and then realizing that, well, geez, traditional financial market data doesn't actually let you see races. That's part of why it took some theory to uncover this issue is you can't actually see that Phil, Tarun, Eric and Michael Jordan are all racing for the same arbitrage opportunity within a sub thousandth of a second of each other. So what we got in that England study, in that UK Financial Conduct Authority study, was the full back and forth message traffic between market participants and the exchange, in this case the London Stock Exchange. So this is just very cool kind of data that no one had ever studied before that lets you see in all its glory just trading races. So you kind of count them up, how frequent are they? How much money is at stake? So it was just a multi year project, and I'm starting to be a little rambly. But the thing that was most striking to me in that study, I had a prior that a lot of races would be for small amounts of money, and they were actually smaller than I would have guessed. But the volume of races was just astonishing.
00:03:54.946 - 00:04:36.942, Speaker C: It was like 20% of all trading volume. And this is in the UK. Equities market was trading races, the modal race. The difference in time between Phil and Tarun would be five millionths of a second in crypto trading. I don't have the data. I'd love to speculate with this group what kind of data you'd find, but my prior is it could be even higher just because the shenanigans you can do with reordering time in crypto markets. Phil and I are going to get philosophical about time that's promised it's even more stark than in traditional finance.
00:04:36.942 - 00:04:40.726, Speaker C: So it's a long winded answer to a great question. Let me stop there.
00:04:40.828 - 00:05:14.670, Speaker A: Yeah, well, I wanted to maybe let Tarun take a stab at translating between the message and execution tape of a market to what we see in crypto, what's lit and what's like, where are we seeing evidence of the burden that these latency games exist and where they stress the systems? I think recently we saw this with Arbitram Sequencer was a place that I think they had to flag that this was happening, but no one was really aware of it other than people running the infrastructure. So I'd love to hear take a stab at translating Eric's message analogy into the crypto.
00:05:17.170 - 00:06:30.042, Speaker D: Think. Obviously, I think the Solana world probably is where we saw the most latency games. Obviously they made particular choices and how their protocol works such that it prioritized low block times and kind of effectively forcing all the validators to be in hetsner or some very high end data center. I think the on chain stuff is still less than lit US exchanges or Urex by like maybe three to four orders of magnitude in terms of message volume, but I think it definitely can get there. The centralized crypto exchanges are a little bit more interesting because most of them are actually cloud hosted. They're not actually hosted on prem, like on a fixed data center. And so you have all these games of people, like starting 500 nodes at a particular AWS zone, pinging the matching engine endpoint, seeing which node had the fastest relay time, and then submitting your transaction, which is very similar to what happened in the arbitrary case.
00:06:30.096 - 00:06:30.700, Speaker B: But.
00:06:34.110 - 00:07:12.774, Speaker D: This type of cloud based endpoint is actually, ironically, the way the normal market is working. So most exchanges are actually moving away from on prem hosted data centers, except like CME, because basically futures trading is much more latency sensitive in the US equities trading people already internalize all the order flow. So it's sort of like this very weird, not as latency sensitive. It started very latency sensitive and then once wholesalers bought all the order flow, it became way less latency. So the long story short is, I think on chain stuff is still a bit far.
00:07:12.892 - 00:07:14.086, Speaker B: I mean, you can do a lot.
00:07:14.108 - 00:07:33.846, Speaker D: More things, but it's less about pure latency games. It's a little more like online ad auctions where, yes, there's like a pretty frequent auction frequency, like tens of milliseconds, but the dimensionality of the objects you're bidding on is very high relative to other games.
00:07:34.038 - 00:08:00.630, Speaker A: Yeah, Phil, I'll let you respond to either anything that Eric or Trin said, but I would like to add a question, which is you're designing a lot of these systems, and I know a founding tenant of Flashbot is eliminating such that we can understand what's actually happening. And so how do you kind of think about elimination when you're designing some of these ideas? Like the fact that what pieces of data do you need to be able to see and what pieces of data do you not want to be able to see such that we understand really where these games are being played?
00:08:02.570 - 00:08:55.462, Speaker B: Yeah, no, great question. So maybe I want to riff a few things that have been said which are just kind of random trolling, high level fuel on the fire here agree with a lot of the points that have been made so far. I think the interesting thing to me, one point that hasn't been made is like latency games can kind of be roughly divided into two categories. One that are kind of winner takes all kind of race style Arbitrage games where you have a market structure that incentivizes along a certain axis of economic activity, low latency, and then kind of determines outcomes of kind of rent gains based on this axis. So this is kind of the most extreme form of latency game. It's what we see in TradFi and it's what Eric's paper talks about mostly. There are a lot of other more subtle kind of latency games and interactions even in kind of the solutions that are proposed to the latency games, like batch options.
00:08:55.462 - 00:09:52.634, Speaker B: So in Eric's paper there's kind of like an analysis and a discussion of the latency games that happen at the end of the interval for each batch which still exist. The argument being that the economic value of those latency games at the end of the interval is much less than this extreme kind of winner takes all form of game. So I think when we're in crypto, it's really important to think about specifically what type of latency gain and what type of latency activity are you optimizing for? I think the winner takes all race model is by far the most centralizing because it means like physical infrastructure participants that have microwave towers, like take all the ARBs and we've seen in TradFi and we know the market dynamics of that market are super centralized. So riffing then onto where this shows up in crypto. I think the case that this shows up the most in crypto is two places today. Number one is if you have a first come first serve sequencer. So if you have a first come first serve sequencer, there are kind of two options.
00:09:52.634 - 00:10:34.710, Speaker B: Either you have low fees or you have high fees. So if you have super low fees, like it's basically free to make a transaction, then your zero sum Arbitrage game moves into spam. Basically at that point latency is not actually profitable because if you just spam, you'll always beat someone who sends like an actual latency sensitive transaction because you've sent an uninformed packet like a minute ago and that spam will just be like ahead of them in the queue. So what that does is it pushes more ARB logic on chain and pushes the actual economic auction into the spam externality bucket. On the other hand, if the fees are high, doing the spam is just unprofitable. So you'll never actually do it. And that's when you see these latency participants have the ARB edge from reacting first.
00:10:34.710 - 00:11:13.906, Speaker B: And this is what you see in sequencers, like Arbitrum for example, which have relatively high fees compared to something like Polygon I believe it was, where we saw more of a spam attack or Avalanche, which also had very low fees. We saw spam attacks and then raised their fees and saw latency games. So this is like kind of the trade off landscape, higher low fees, spam or latency. But I do think it's important to also make that zero sum distinction. We don't see it a lot in ETH because of the size of the batch, because ETH has been kind of intentionally designed to allow for this global slow mev auction underlying its block. That being said, there's still an edge game. So in the relays are a latency game article or whatever.
00:11:13.906 - 00:11:52.154, Speaker B: It really quantifies this edge game, which is again important to note, very different from like a winner takes all game that you see in TradFi. So that's my full rant and that's where we see them. Oh, one more thing. So that's one place, which is FCFS sequencers, the second place is Sexes, which has already been mentioned by Tarun. I think there's a fun corollary here which is in the cross domain MEB work. And what that work says is basically like the bad drives out the good in these markets. So if you have super latency sensitive systems that are very centralizing, they actually also impose centralizing pressure on decentralized systems because they add latency edges to whatever latency game is there through cross domain mev.
00:11:52.154 - 00:12:28.694, Speaker B: Fun fact, we already see this with centralized exchanges. So there are certain entities that have very efficient routing between centralized exchanges and already play that latency game. And because of for example, where our infrastructure is on like a cloud service provider having some overlap there. We're already seeing even in our decentralized systems or permissionless mev markets like this, latency competitive pressure from existing TradFi routes. So it's not like a theoretical issue. It does kind of creep into decentralized systems. How do we think about illuminating it, do research, do data, have conversations and keep kind of putting out philosophical pieces.
00:12:28.694 - 00:12:44.814, Speaker B: So I have one on geographic decentralization I really want to plug. I think that's like an important piece of the latency discussion and kind of trying to come up with definitions and data around that as we speak. So sorry, that was a very long ramble, but all the fuel I have to add to that fire.
00:12:44.932 - 00:13:27.886, Speaker A: The funny thing is the common thread of all three rambles was this non agreement on the nature of time. We have discrete time, continuous time. We have a relative time, we have absolute time. And Eric has this incredible point about the challenge of discrete time is that you always have a relative edge or continuous time trading. And so I wanted to start there. When it comes to time, Eric, I'll let you start on what you observed in traditional markets between continuous and discrete time. And then also feel free to comment on what we see in these systems that are designed without the kind of concept of relative time, which is actually the underlying latency games across different data centers and other things we see.
00:13:27.988 - 00:14:17.374, Speaker C: Yeah, great. Let me answer that question. And also I want to respond to something Phil said that I think is really terrific that I want to riff on. So in a continuous time market, if there are arbitrage opportunities in a continuous time market that will very naturally incentivize competition on speeds, that's a very relativistic kind of competition. Competition to be faster than the next guy. In this empirical study with the FCA researchers quantified it on the order of millions of seconds of time difference between winners and losers. Actually, in a chunk of races, about 4% of races, this Phil will get a kick out of this.
00:14:17.374 - 00:15:03.630, Speaker C: The difference in time between the winner and loser of the race was negative because it's like you show up at two different chips and my chip happens to process a little bit faster than yours. So I win the race even though I kind of got to the finish line after you. So there's a tendency towards relative competition, relative time rather than absolute time being important. So we're fighting over tinier and tinier and tinier slivers of time. I like Phil's point that that can have a tendency towards winner take all competition. We do find that in the empirical study, the top three firms in our data, I don't know the identities of the firms. To be clear, that's anonymous.
00:15:03.630 - 00:16:18.606, Speaker C: But we can link firms over the data and the top three firms win over 50% of races. The top six firms win about 85% of races. So you're relatively centralized, to use the terminology here. So the idea of frequent batch auctions that I've advocated for in the context of traditional financial markets like cowswap, that I advise is working on in DeFi the idea there is to make time discrete, and then that enables re engineering the nature of the competition to be competition in a more productive dimension. So competition on, in the case of an auction, competition on price instead of competition on speed, and that you can kind of go through the economic chain of why that leads to a more liquid market of less. wastable rent seeking activity. The thing I wanted to riff off in Phil's comment that I thought was very interesting was this idea of some kinds of latency games might be winner take all, whereas other kinds of latency games might not be different parties might discover tiny corners, tiny little arbitrage quarters.
00:16:18.606 - 00:17:13.734, Speaker C: And that, for whatever reason, reminded me of the real estate industry. So the real estate industry is another industry with tons of rent seeking. The fact that it's 5% or 6% of your house value to sell a house from one person to another is a ridiculous rent seeking activity. The way that plays out economically is you have lots of small real estate brokers each fighting for their little scrap. But there is a centralizing tendency in that market, which is the real estate lobbies. And the real estate lobbies help preserve the kind of flawed economic arrangement of needing a broker on the buyer and the seller side and all the little subtle stuff that kind of keeps us stuck at 5% fees. That was just one that struck me as like, yeah, we do see some winner take all rent seeking, which naturally creates a concentrated, dispersed dynamic in the Mansour Olsen sense.
00:17:13.734 - 00:17:24.970, Speaker C: But even in these cases where we see very dispersed rent seeking, like in real estate, sometimes the dispersed rent seekers find a way to band together nonetheless.
00:17:27.790 - 00:17:52.830, Speaker A: Is there a good place to look at research on the consolidation? It started as a broader, more competitive market and then once we had discrete changes in the rules, the technology stacks, whatever, it meant that it was returned to. Sophistication return to capital. Different types of forces of consolidation forces as Turin Phil think about kind of the design space. It's good to understand what type of technical shifts drive consolidation and centralization.
00:17:52.990 - 00:18:46.870, Speaker C: Yeah, the best scholarly work is by Donald McKenzie, who's a sociologist based in Edinburgh, and he's over decades, made a mark studying the sociology of finance. So he did this amazing study on the Chicago Mercantile Exchange and he put out a book, I think a year or two ago at this point, called Trading at the Speed of Light. So that's the best scholarly work. And the best line is in Flashboys by Michael Lewis, where he said, I used to know, about a thousand guys making a million dollars a year, and now I worry about one guy making a billion dollars a year. And I can't remember there was some stereotype baked into that quote that I don't remember and won't try to recall, but that was sort of the best anecdotal nugget on that tendency just described.
00:18:47.370 - 00:19:04.090, Speaker A: And trin Phil, as you've seen the block kind of production supply chain get much more sophisticated. How have you seen the number of actors, whether they've grown or consolidated? And how do you think that's related to whether it's latency or any other type of technical sophistication edge?
00:19:08.690 - 00:19:53.360, Speaker B: Happy to take a bat on this first. I think I have this troll theory of markets, which is like any competitive market will land in some degree of oligopoly. And it's about managing the externalities of this. And this is my troll. I've never seen a counterexample as many times as I've trolled economists with this. But we do see that to an extent in mev. I think the dangerous thing, at least the way I reason about it, is how much consolidation pressure are we talking about and how many counter forces are there for actually maintaining the meta properties that allow this thing to exist? So like geographic diversity, decentralization of capital, whatever, not like a plutocratic staking set, things like that.
00:19:53.360 - 00:20:38.150, Speaker B: I don't think we can ever remove these centralization pressures entirely. That being said, I think mev market is super interesting. So there are certainly a few large firms and entities that do very well on specific mev verticals, especially when you look at certain types of Dex designs like AMMS, there's a few kind of centralizing or consolidation pressures we see there a big one. And I think the most powerful in today's market is the ability to take risk. And this kind of looks like traditional market making activities in TradFi because a lot of it relates to sex dex arbitrage. That's like one of the number one fire hoses right now. People want to make trades on a Dex, but the liquidity on DEXes inherently updates slowly.
00:20:38.150 - 00:21:34.114, Speaker B: So how do you bridge the gap between this sex liquidity that's gated by KYC and regulation and custom custody rules that people may not trust to this interface that people actually want to trade on? That's just where we've seen the most activity and the most maturity, just because of the volumes. It's not inherent mev or anything. It's just what people use ethereum for today. And there you see this ability to take risk as for sure, like a powerful centralizing pressure. Before that, we saw gas golfing as another fun one. So the early generation of the flashbots auction intentionally kind of gave you a huge boost if you were able to be more gas efficient than other bidders to try to drive down kind of the network externalities of the auction in terms of how much block space was being used by the auction. And this led to people kind of really looking into super arcane tricks to save a little bit of gas because the gas game kind of became almost a winner take all style.
00:21:34.114 - 00:22:19.558, Speaker B: But instead of competing on latency, they were competing on gas used in the system. So that was another example early on, although I say that one has kind of faded away with maturity of the market. And now we're looking at much more things like ability to warehouse risk. Another category is latency for sure, especially in sex. Sex Arbitrage, complex sex, sex dex, Arbitrage or Arving against domains that are latency sensitive like Solana or Arbitrum. We've seen that one less, I would say just anecdotally my intuitions in the market so far, just because a lot of the mev today is on less latency sensitive markets like ETH. But we're starting to see that kind of creeping at the edges and also compound with the risk pressure and together form a centralizing force.
00:22:19.558 - 00:22:25.694, Speaker B: So for us at Flashbots is a question of how do we kind of minimize the impact of those on the decentralized system.
00:22:25.892 - 00:22:55.442, Speaker A: Yeah, so you wrote up a good point, which is about the adaptive nature of the network. Eric, I looked through some of your prior research and showed up in the lot of the benefit of tighter spreads and stuff came through just general electronification and now we're at this petabys of war. How have you seen markets evolve? Where they go from this big step function and then the competition gets very tight because we get smaller and smaller and that becomes a bit of a centralizing factor.
00:22:55.586 - 00:24:09.726, Speaker C: I think that's an important just fact to understand about the evolution of traditional financial markets, let me just make sure the fact is clear and then we can flop it and we can discuss it, which is that there is this transition that played out. And again, I'll point to Donald Mackenzie's work as kind of the scholarly work to look at. There's this transition that played out from the 90s into the early 2000s when a lot of financial markets still had a large role for human participants. So think pit traders in Chicago. This is the thousand people making a million dollars a year that Michael Lewis was joking about were specialists on the New York Stock Exchange for running so humans facilitating trades, running a market, running a limit order book the same way that a limit order book, in a way, was run since the 18th century under the Buttonwood Tree, aided by computers, but fundamentally a big role for humans. And then there was a transition and in the US stock market it was really facilitated by regulation national market system. Grab a copy of Big.
00:24:09.726 - 00:25:22.438, Speaker C: I got a copy of my office. But that facilitated the transition to electronic markets. In the fully electronic trading in the US stock market, it's pretty clear if you look at the historical data that the transition from human based trading to electronic trading meaningfully improved liquidity and efficiency. There's a famous study of this by Hendershot Jones and Menkfeld that's very widely cited but my read of the data and I have a lot of references to this in my work is that you can see this kind of step change as we went from humans to computers. Computers are a good idea, but then all of this additional relativistic competition on speed has moved the needle precisely zero on the market's cost of liquidity. So if you look over like the last 1517 years of financial market data it's hard to see there were big gains in the transition from humans to computers and that kind of flatlined what that implies for crypto markets. I honestly don't have a confident view.
00:25:22.438 - 00:25:28.230, Speaker C: It's a newer domain but that's what we saw in traditional finance.
00:25:28.650 - 00:26:08.040, Speaker A: Yeah turn you always talk about how Reagan, Ms and NBBO really changed equity market structure and how whether it's order rules, those are regulations but we have things like regulations which are there's a new AMM launches with very specific rules or curves and we see that those things really change market structure. So I think it'd be interesting to comment on what Eric just said around the actual material performance layer in this added co, evolving nature of the regulatory landscape and kind of bring it over to Crypto where we're seeing we went from this very naive, unsophisticated world to things like SCP went to much more sophisticated on chain people. And it's just really changing the market.
00:26:09.850 - 00:27:46.642, Speaker D: Yeah, I think the weirder part about crypto maybe versus traditional markets is like traditional markets actually had a contraction in number of venues since RegNMS because a lot of venues basically couldn't beg the economics work given their volume like places like Philadelphia Stock Exchange which you'll still have to connect to but basically doesn't do anything. Crypto actually has the exact opposite problem where there's constantly new venues of different types and there's new venues because there's new chains so there's new roll ups. So it's creating more cross domain arbitrage. Centralized exchanges obviously have had huge calamitous changes in the last six months which have created a bunch of arbitrage opportunities certain things that were collateral that was not expected to move out of a particular range in terms of its value in numerator terms you have things happen like that. So there's sort of a very different dynamic in the sense that there's this kind of proliferation of venues in crypto that were versus the contraction in venues that you had in the normal world. That does change the dynamics a little bit. And this is one of the reasons I would say the last year of crypto has basically made me more convinced that this actually looks a lot is going to end up in a different state than traditional lit exchanges where you kind of had the reg NMS happen.
00:27:46.642 - 00:28:21.566, Speaker D: Then the financial cris happened and so a lot of algo trading firms did. Well then. And then you had the kind of like boom up to 2012. Then after 2012 it got extremely competitive and people realized buying order flow was better than becoming faster alone. And so then you kind of had this like the number of competitors decrease after that point. I think crypto is actually kind of weird because the number of products is growing really fast, like the number of different places you can trade the same product. Just think about every new roll up.
00:28:21.566 - 00:29:14.914, Speaker D: Think about the arbitram launch, right? Like when the coin came out that just basically dossed a bunch of venues. And so there's sort of this interesting thing where this is the reason I make more of a comparison to an ad auction in that you have on the X axis a number of different assets that are growing. On the Y axis, the number of venues that the assets traded at, and then sort of between the two of those, those are actually growing. Like the density of those is growing at the same time. And it means sort of that the dimensionality of the products is higher. It really does mean that trading ARB on Arbitrum versus trading ARB on ETH versus trading ARB on Op, they're actually kind of not fungible products because the amount of leverage you can get on each chain is different. The amount of security you're willing to take when you go across the bridge is different.
00:29:14.914 - 00:29:49.930, Speaker D: And the mev auctions are different in terms of how much you have to bid. The gas rules and that sort of high dimensionality for products that are sort of fungible creates a huge sort of arbitrage opportunity where people hold portfolios of what's supposed to be the same asset, but then they're doing this weird risk warehousing, statistical arbitrage type of stuff. And, yeah, that's where I see the crypto markets actually deviating quite a bit from traditional lit markets and it's going to be kind of interesting to see that evolution.
00:29:51.810 - 00:30:47.722, Speaker C: Yeah, sorry, in response I think that's fascinating and it sort of relates to what I was initially so confused about 1013 years ago or so at this point, which is from a distance. Think of arbitrageures and quant trading firms as doing something really fancy and sophisticated because we have, as economists or finance researchers think that there shouldn't be technical inefficiencies in financial markets. You've all heard of the efficient market hypothesis. To beat the market you have to know something the rest of the market doesn't know. Economists are very dismissive of technical trading opportunities. But then you just look at what arbitrariors are actually doing, a lot of it is like the same shit trades on lots of different venues are when the prices get out of whack. And it's actually like grandma could notice the pricing, could notice the pricing discrepancy.
00:30:47.722 - 00:31:02.766, Speaker C: All the complexity is just in technologically exploiting. The thing. So then if tarun, if you if you're right, there's this just proliferation of venues and very closely related ways of trading the same risk exposure. That's an arbitrageure feast.
00:31:02.958 - 00:31:11.174, Speaker D: Yeah. And it seems to only be growing because token issuance is sort of still growing even in the bear market, I think.
00:31:11.212 - 00:31:34.858, Speaker B: Yes and no. I don't think it's an arbitrature feast in the same way you think about like HFT Sniping or something like that. To me this looks much more like market making and competition on risk which is actually what you probably want in these ARP markets. So it is a very different nature. I think there's two interesting effects here. I also want to point out that do kind of aggregate add to this and make it very different from TradFi. Number one is like the way you can interact with these venues.
00:31:34.858 - 00:32:25.950, Speaker B: So in TradFi, execution relies on trust and it's kind of like a human based or a technologization of a human based process. Right. So if I want to place an order that's like a combinatorial order of I either want these three orders to execute on the New York Stock Exchange or take this other one to this other venue or et cetera. It's kind of very hard to do those orders where on a blockchain you have more programmatic ways to express more complex preferences and something like using two different venues at the same time is not mutually exclusive if you can structure the right aggregation or metatransaction cowswap is like in some ways an attempt to do this. So that is, I think, one difference. And the other difference, I think is the profiles of the people taking the risk. So assuming this is true, what I said, and we have competition on risk and we want that.
00:32:25.950 - 00:33:00.226, Speaker B: I was having an interesting conversation recently about the stablecoin Dpegs kind of last week during all the bank failures and things like that. It turns out during these stablecoin Dpegs, all the sophisticated actors and the active liquidity, even though there was a ton of money to be made and so many ARBs across these combinatorial venues, basically a lot of them sat a lot of these opportunities out. If you look at the chain and if you look at where the mev distribution actually went, passive LPs in these protocols made a lot of money because the active LPs disappeared and this was like the backstop.
00:33:00.258 - 00:33:00.598, Speaker C: Right.
00:33:00.684 - 00:33:26.100, Speaker B: And who are these passive LPs? They're like Dgens who are taking like they have their own risk profile. It's highly bespoke. It maybe isn't even rational to a market making participant which is why those participants did the rational thing and backed off. But it kind of does add this robust liquidity backstop because you have a risk segmented rather than a zero sum game that makes the system more robust in downturns. So anyway, that's my rant about how maybe things are different.
00:33:27.030 - 00:33:51.290, Speaker A: Yeah. Eric, do you have any comments or thoughts on that kind of resiliency and robustness question. I know in the US we've had volmageddon and some other things where there's different causations but a lot of what happens is too much of liquidity has the same kind of profile and same type of structure and strategy. They're running stat ARP mean reversion. When it gets two sigma they just turn off whatever that thing is, it can cause market fragility. So any thoughts there?
00:33:51.360 - 00:35:15.510, Speaker C: I think that's a big topic to some extent when I see a flash crash, I think prices change to some extent. I think markets could be more robust markets could be more robust if designed differently. So I worry let me kind of walk back something I just said because I think it was a little bit imprecise. The thing I kind of worry about I use the phrase fast and thin crowding out smart and deep or slow and deep is probably a better way of putting it. So I worry that if you have a market that in good times or in relatively stable times is very profitable, if you're technologically sophisticated picking up nickels and that that in a way crowds out deeper liquidity but that is less technologically sophisticated. This probably makes the most sense thinking about the treasury market. If you have some firms that are very sophisticated technologically at proprietary trading and they're faster and that crowds out some deeper pocketed slightly less technologically sophisticated investment banks.
00:35:15.510 - 00:35:25.718, Speaker C: But if when the shit goes down pardon me, I shouldn't keep cursing, I'm a professor. But if when there's when was the.
00:35:25.724 - 00:35:29.306, Speaker D: Role professors aren't allowed to curse me, just check.
00:35:29.488 - 00:36:15.160, Speaker C: I try to be dignified right? But I worry that is the deeper but slightly less technologically sophisticated liquidity there in a crisis. I have made the argument that discrete time batch auctions, slightly slower market design, level playing field, that those kinds of properties could have a robustness benefit. It's honestly very hard to model in a way that's convincing to skeptical just it's a hard nut to crack. And my guess is someone will figure out a way to study it using a diverse set of tools. I think it's a good sympathetic to the hypothesis. I haven't figured out how to prove it.
00:36:15.610 - 00:36:18.646, Speaker A: Eric, it seems like you have a good question for Turin before he has to go.
00:36:18.668 - 00:37:50.440, Speaker C: I know question kind of for Phil prefaces every question with this is a trolley question. So I think this is troll which is at some level if you read Nakamoto, the problem it's solving is a timestamping problem. Compare Nakamoto to Haber Stornetta in the 90s doing a blockchain like data structure where they were using hashes to link data over time and ensure that data hasn't been tampered with. Part of what Nakamoto was solving relative to what Haber and Stornetta did is creating in effect a decentralized timestamper. But suppose you had I kind of wonder if a lot of mev manifests in the trading of crypto financial assets. If there was a trusted timestamper and there was a decentralized exchange that made reference to credible trusted timestamps, I think that might be that's the trolley premise of the question, could you solve a lot of mev problems? You can't rearrange transactions because we know what it means to rearrange transactions. It's to fuck with the timestamps and you got to process transactions in order.
00:37:50.440 - 00:38:03.420, Speaker C: And then you could talk about what do we batch process, do we make time discreet, blah, blah, blah. But the fact that you can rearrange the sequence is what's so appalling to me as a scholar of financial market.
00:38:03.870 - 00:38:06.234, Speaker B: I guess I'll give you the sort.
00:38:06.272 - 00:38:15.294, Speaker D: Of economics version of this, which is the decentralized thing doesn't work because of the errors and possibility theorems of the world.
00:38:15.332 - 00:38:15.534, Speaker B: Right.
00:38:15.572 - 00:38:54.860, Speaker D: I have many validators having to pick an ordering and agree on it. And obviously the only sort of social choice function that works in all cases ends up being dictator. And so these kind of very weird social choice things around, like if we do really want to be decentralized, then you run into these kind of problems that come from just the nature of the symmetric group, though those are very kind of you can't get around them. But in the centralized case, of course, it doesn't matter. The Arrows impossibility theorem says there's a dictator, so all you're doing is picking the dictator in some sense.
00:38:56.750 - 00:38:59.050, Speaker C: So with timestamping alone.
00:39:00.930 - 00:39:26.622, Speaker D: I don't think it would remove everything for the record because it's not just timestamping. It's also like adding and removing around particular transactions, which is akin to the adding a ton of cancels in front of a big order that's going to run you over. So there's still some of the adding and removing part that I think it still probably is an issue, not just the ordering.
00:39:26.766 - 00:39:57.790, Speaker A: And are you assuming that time is a zero bound that you can't do any speculative transactions? I know in the European markets there's a thing called speculative triggering that they actually start firing orders off of messages so fast that they're just starting to see the first bit string. They're sending out messages on the other side before they've even confirmed that this is in strategy. And they start canceling them, creates this insane amount of load on the centralized server, and they've actually banned the issue of speculative triggering, meaning that they're sending pre confirmed transactions. It's insane.
00:39:58.930 - 00:40:08.270, Speaker B: Oh, man, I have so much trolling to do here. I want to let Tarun hop into his train if he had to, but I'm going to line up the baseball bat and let her rip.
00:40:08.430 - 00:40:09.300, Speaker A: All right.
00:40:09.990 - 00:40:11.102, Speaker D: Thanks, Aaron.
00:40:11.246 - 00:40:13.650, Speaker B: Amazing. Thank you so much, Tarin. That was super fun.
00:40:13.720 - 00:40:17.122, Speaker C: I'm glad you look so happy.
00:40:17.256 - 00:40:18.886, Speaker B: I'm so happy. I'm so happy.
00:40:18.988 - 00:40:23.640, Speaker C: We met on a panel. You asked me towards the end if we could get philosophical about times.
00:40:24.490 - 00:41:41.374, Speaker B: I know we need, like, hours, though. We need hours. But anyway, so I will say a few things that are trolley responses to your trolley question. First of all, I think let's assume you had the world's most perfect timestamp system in the universe, and it had no problems that I could possibly complain about. There's still, like, the fundamental physical limit of the special theory of relativity. So in the early 19 hundreds, there was this idea that if two things happen at the same time, the observation of a third observer of the order in which these two things happen depends on the reference frame of the observer, right? So even if we had a perfect timestamp system, the best we can possibly do is approximate FCFS, which, as we've said, either creates, like a spam this is what Michael Jordan was just talking about. These preload transactions is like some form of spam or a latency race, right? But then who wins this latency race? Who wins this winner take all game depends on the third party observer, which here, in theory, is like a decentralized protocol that's supposed to be fair and universal, right? So if these two people legitimately send their transaction their ARP at the same time, and they're not in the same place in physical space, the network still has to sequence that.
00:41:41.374 - 00:42:22.234, Speaker B: And one of those two people is going to be feeling left unfair, right, because, oh, we sent it at the same time. And because of the network's reference frame, this person's transaction got in before mine. So that's like, even if you had a perfectly synchronized, like, to the absolute physical limit set of clocks, you wouldn't achieve fairness. The best you can do is approximate FCFS against some reference frame. For TradFi, they kind of wave around this by saying, okay, our reference frame is like this address in New Jersey, and the game is like, build a cable there. But that doesn't really work as a reference frame for a distributed permissionless network. So one more thing I had to say.
00:42:22.234 - 00:43:06.058, Speaker B: This is like a trolley idea that I had many, many years ago when I first started studying mev that I've talked about to a bunch of people. But I feel like it might be worth mentioning publicly in the context of this. This was one of my first intuitions when I came into Mev was like, wouldn't clock synchronization just solve this? Okay, how do we build decentralized clock synchronization? Okay, let's assume we have SGX. Let's give ourselves as much ammo as we can. Can we still build something useful here? So I actually had this idea of a dex that works based on this SGX nuclear football. So you can imagine basically a portable, like, in a briefcase SGX machine that has, like, a long standing key that can't be rotated. So this machine has to stay up for the exchange to kind of work.
00:43:06.058 - 00:43:53.094, Speaker B: Then you travel from place to place around the world to all the participants in your market. Maybe once a month you synchronize their local SGX with the football, right? So like if you put the football physically right next to their SGX, you can get tighter clock synchronization balance because the latency between this trusted football clock and your local chip is like super low. Then you're kind of approximating as close as you can within real physical constraints. This timestamping thing still doesn't solve fairness. Still doesn't solve mev. What does it actually give you? It gives you basically a shorter block time, right? It lets you have this uncertainty in the same way that kind of fair ordering protocols do with a smaller window, which in your batch model is the same as shortening the batch, essentially. So all a trusted timestamp would allow you to do in a decentralized context.
00:43:53.094 - 00:44:27.870, Speaker B: Is shorten the batch. Is shortening the batch desirable now? It depends on the meta argument of the rent extraction against the batch. How meaningful was the end of the batch, how much does latency matter, what's the actual participant distribution, et cetera. So TLDR, is it useful? I think it's interesting. Certainly you can tweak some parameters and building this SGX football thing I think is kind of fun. Maybe if I had infinite time I wouldn't be against just yolo and trying it and seeing what properties we get at the same time. Solving mev, to me mev is intentionally unsolvable, so it's very hard to solve.
00:44:27.870 - 00:44:50.438, Speaker B: And maybe I'm wrong about this. This is like an open hypothesis. It's like why? One of the reasons that I like that other people are studying this because maybe there is a best design. But my intuition is this is not a solve because someone's still going to be left feeling the unfairness. And whether or not that's decentralizing depends on the power dynamics of your system, basically. So sorry for the long troll.
00:44:50.614 - 00:45:40.220, Speaker C: Can I answer? It just an open question, which I think so I think of the solving mev as something you could try to do at call at the application layer or at the protocol layer, and at the application layer I think frequent batch auctions, properly implemented, solve mev. We can debate that and let's take that offline. I think the really cool open question is whether you can quote solve mev at the protocol layer. Is there some tweak to blockchain design? My intuition is it comes from just not being able to rearrange stuff. But then that raised between the two of you. You invoked Arrow and Einstein, so I got to think a little bit harder about it.
00:45:41.630 - 00:45:44.110, Speaker B: I alternate question is like who gets the rent?
00:45:44.530 - 00:45:47.966, Speaker C: I'll eliminate the rent. That's why I mentioned the real estate agents. Why?
00:45:47.988 - 00:45:48.746, Speaker B: Who gets the rent?
00:45:48.778 - 00:45:50.506, Speaker C: Why not shrink the rent?
00:45:50.698 - 00:46:41.854, Speaker B: No, I think shrinking the rent is great and I think that is where frequent batch auctions are super useful. But I don't think they eliminate it because they're still kind of how do these batch auctions interface with the rest of the world, which is the part that's really hard to model, especially if there are a lot of continuous venues. I think this is where a lot of the crypto research in the global solve needs to go. Specifically, for example, I don't think frequent batch auctions solve mev even for DEXes for one very simple reason, and I say this as someone who was in 2018 like uniswap guys, frequent batch auctions solves mev for DEXes. Why are you not using this? I think people do, actually. Some people want things that can only come with reordering. So many people want the ability to do complex dynamic transactions that depend on the specific state a transaction is being executed on and are conditioned by.
00:46:41.854 - 00:47:27.514, Speaker B: This one example might be like a protocol that wants to liquidate tokens on uniswap and then do something else in the same call frame atomically. And maybe this gives them some security property they otherwise wouldn't have or something like that. So as long as you have these people, they can't use the batch because their requirements are simply incompatible with waiting for it. And I think that solving mev for that class of users looks very different as solving mev for the people who can wait 2 seconds or something where I agree a batch is totally fine and a great way to reduce. So I think all these plug away at ways to reduce mev. But the reason they can't happen at the protocol is because of rap wrangling with all these fundamental limits. My last piece of trolling is, I think the flashbotch auction.
00:47:27.514 - 00:47:44.260, Speaker B: I remember I said this last time we had a panel and I got so much pushback, but I'm going to say it again because I think it's true, is actually a frequent bash auction solve of mev at the protocol layer, assuming a lot of timing things about the ETH network. It's at least kind of looks like that if you squint hard enough.
00:47:46.170 - 00:48:11.770, Speaker A: Is that not an important assumption? The assumption because you wrote about the importance of geographic diversity. Geographic diversity is that antagonistic to fairness because you're just increasing the actual amount of time for the network to coordinate literally. Like if we're all in one box in NY four, then our coordination time is very different than if we're designing a system such that the replication is happening across physically large areas.
00:48:12.190 - 00:48:45.080, Speaker B: Yeah, this is why I hate fairness as a word because everyone has their own pet fairness definition. For some people I have to wait a second longer because some guy in Australia wants to trade with me. That's super unfair. It's like, man, if I just cut that guy out, I don't care about his economic activity. It would be way better for everyone I care about if we could just trade instantly and not care about that guy from Australia. Whereas if you had that the guy from Australia would be like, this is super unfair. There's like, this cartel that I just can't access without submitting myself to the, you know, hedge of money or whatever.
00:48:45.080 - 00:49:31.566, Speaker B: So, yeah, I agree with you that there is a tension there with fairness, which is why I think geographic diversity is like I'm not implying it's more or less fair for exactly that reason. I don't know whether people will agree with that. My argument for why that's good is much simpler. It's like if we don't have that, we will just be subject to a very single specific set of regulations and the rent game will look exactly like trap by. That's my two cent, but yeah, no, I agree. Even parameterizing this time, right? Like, do we do 9 seconds or 10 seconds? Do we do ten or 15? There are fairness arguments there that various people make because the impact is on the actual distribution of the rents, which is where people actually feel the fairness. Right.
00:49:31.566 - 00:49:37.480, Speaker B: Ultimately, fairness to me is like, are the rents sanely distributed? And there's no clear way to define that, really.
00:49:38.890 - 00:50:08.414, Speaker A: Derek, did you do any work on conditional orders? In HFT, there's a concept called ISO orders, which is you can sweep across multiple venues with one order, and you're able because you do have to trade within the bid ask spread illegally. If you trade outside of it, you get fined. That actually moves across venues. Now, the venues may all physically be in the same place in crypto. Our venues are just kind of a very different concept from what we're describing. But I know your LLC work was done just on the LC. Have you done any of this kind of cross venue latency considerations?
00:50:08.542 - 00:51:04.806, Speaker C: It's a great question. The closest I've done is in this work with Robin Lee and John Shim where we pulled together a bunch of empirical facts on competition in the US. Equities. Market. And the way I think about the use of ISO orders, this intermarket sweep order is most of the time if you're trading not in a race in response to some Algo signal, but because you happen to yourself just want to trade some stock, but you don't want to leave an Algo signal for others to exploit. You want to trade across multiple venues all at once so that responders to your trade. Trade after you and ISOs are one way, so sweeping the market is one way to do that.
00:51:04.806 - 00:51:55.010, Speaker C: There's also a reg NMS compliance issue which is super in the regulatory weeds, which is a reason why some firms use ISOs. So that's the closest I've gotten. I think the conditionality is very interesting. I kind of take Phil's point that at the application layer for certain kinds of trading needs, frequent batch auctions eliminates mev. But the more conditional trading needs, which intrinsically need to rearrange stuff or condition, I do A only if B and C happen. That strikes me as more of an open question. So let me kind of put two open questions out to the audience, which is what can you solve at the application layer and what, if anything, can you solve at the protocol layer?
00:51:56.790 - 00:51:57.298, Speaker A: Different.
00:51:57.384 - 00:53:32.946, Speaker B: I think we're also seeing this super interesting effect in this direction, which is a lot of so there's two theses in crypto. One is like the general or at least in smart contract chains, and I'm being very high level here, but do you have a general purpose chain which tries to optimize for anything anyone might ever want to do and have some reasonable compromise for the consensus across all these use cases? Or do you couple your consensus much more closely with the actual economic activity that's happening on the chain and then make more activist design decisions in the consensus itself? I think this is kind of a version of that same question. So in the chain world, you could have like a batch auction chain, which only purely allowed for batch transactions, and then there would be very clean abstraction boundary to reason about the rest of the world. You'd still have to reason about it, and you still, in my opinion, need to do some reasoning to fully solve mev, because there's still some mev that's introduced by Arbigu across other venues. But there's like a very clear boundary that the Dex itself can control. Whereas when you look at something like ETH, something like cowswap trying to do these DAP kind of interventions on a more general purpose chain, that boundary becomes like the flashbots auction, basically, which is like trying to stuff everything but the kitchen sink into the block production. And then it's a question of how do you align your thing with this block production algorithm so that you still get the properties you want? I think which approach makes more sense is like a religious question, as Turin put it a few months ago, which I really enjoyed, but there's certainly a lot of experimentation to happen on both.
00:53:32.946 - 00:54:01.206, Speaker B: And my rough trolling is like, I consider batch options and the general purpose ETH model almost like a cartel. And I say this not in a negative way. To me, cartel is not always negative, but it's like a union. It's like a union of users that are like, we will kind of execute together and throw our full economic weight behind this system that works a certain way and define a boundary to the rest of your option. So that the same way we would normally define one against the rest of the world by having a bench.
00:54:01.238 - 00:54:07.002, Speaker C: It's like a cartel with the sign flipped. It's people getting together saying, let's collectively not get screwed.
00:54:07.146 - 00:54:36.054, Speaker B: Collective bargaining. Yeah, that's what I'm saying. I don't say cartel is like a negative thing. My whole pitch for flat spots for the first two months was like, let's make a cartel of people who work in mev who aren't profiteering assholes, so it doesn't all go to crap. But then I realized maybe I shouldn't pitch a company I'm making using the word cartel because certain people have very strong reactions to that. But yeah, union, I think, is a better framing for sure.
00:54:36.252 - 00:55:18.774, Speaker A: You have cartels. Bill, how do you think about the fact that the more complex application and kind of protocol logic, we want kind of the more exotic and expensive hardware we might need? And so there's a lot of different things of centralization causes of hardware. And in the HFT world we have FPGAs that can do some 50 nanosecond full trigger to target type loops and that's very expensive and complicated to design. And so if we want to do some of this more rich and interesting state transformations, we might create a cartel that's the hardware developer, and they might be able to create some type of thing. And so how do you think about the hardware layer when you're making these decisions either?
00:55:18.812 - 00:56:01.300, Speaker B: Eric, this is one of the trillion dollar questions of the next ten years of crypto finance. I think it goes very deep. I think you're totally right in that in some ways, just the complexity and the dimensionality that Tarin mentioned is already enough, even without throwing more fuel on the fire, that this effect exists. Especially if you push the latency, it makes it way worse. Right? Like if you look at Solana, for example, you need to use an FPGA on Solana to extract mev, which most people don't even understand, but it's true. And the strategies you can do are much simpler and there's a huge hardware edge. If you have a slightly better FPGA, you can do more complex strategies, include more transactions, and directly kind of winner takes all the Mev game.
00:56:01.300 - 00:56:42.880, Speaker B: I think it's a very complex space, so I won't give any prescription. I think there's a few things that we need to be mindful of. Number one is make sure the hardware is doing something that is actually valuable and indispensable in a way. So if the FPGA centralization force is just there because some protocol parameter kind of induces it, is it really needed? Is this hardware edge for these manufacturers really needed to make the system work? Probably not. That being said, for some mev systems, maybe there's like a fundamental trade off of like, the state space is just really complex. The more decentralized we make it, the more complex it gets. There's a hardware edge here.
00:56:42.880 - 00:58:07.660, Speaker B: If that's the case, then how can we decentralize this? I think that's what we're thinking about with Suave. It's like, in some ways a decentralized computation network for MEB where we're going to try to distribute this as much geographically as possible. I think this is like an activist thing, though, and it's very much an open question, right? So if you play out one obvious roadmap of Suave, it could be that intel suddenly is the mev company and intel wakes up and they're like shit, why are we making processors that are for general purpose? If we just use all these nice fabs to make better mev hardware we'll be like a trillion dollar company rather than 100 billion dollar company or whatever. So yeah, that's a risk and I think the crypto community needs to be really careful and probably actively invest in distributing hardware, supporting alternatives, making protocol choices that make sure one hardware mafia isn't principled over or privileged over another. I don't think there's like an easy fix there other than be super mindful, make sure the hardware is doing something actually useful and then try to actually decentralize that if it does need to be there and there's no other way. But yeah, it is risky and I have this troll, this super troll which is that mev turns any proof of stake system into proof of work which is very depressing but noodle on that for a second which is kind of a corollary to your question. Proof of work was the most extreme version of this world.
00:58:08.670 - 00:58:12.526, Speaker C: I'm not fast enough to figure out that fortune cookie but I do want.
00:58:12.548 - 00:59:12.560, Speaker B: To add because you need to optimize this combinatorial problem in real time. It's very computationally complex and if users want to push the latency bound lower it gives edges to people who have hardware that optimizes this better and they need to be doing a lot of also not useless. It's less useless I think it's like more proof of useful work because it's actually doing something useful but it's still like a grind. You still need to grind all these uncertain orderings and run these combinatorial algos and shit and there's hardware externalities there and when we saw this in proof of work, like proof of work, the ASIC manufacturers were such a political force they basically dominated the politics. So there is a risk in the future that mev asics exist and mev ASIC companies are a super politically important force in MEB. I think we can mitigate a lot of that with sane parameterization but yeah, the fundamental force is there and there's no clear answer to say like that won't matter or that's not going to happen right now.
00:59:13.590 - 01:00:13.634, Speaker C: I wanted to just echo your point about useful versus non useful competition. I think profits incentivize all kinds of innovative behavior. I always have emphasized and deeply believe that should try to align private profit incentives with what's socially useful for for markets, for society. So that my criticism of latency arbitrage is it's kind of socially wasteful or neutral to negative and then there's a lot of private incentive to capture it. But hardware innovation isn't per se positive or negative it's in service of what. So if it's in service of rent seeking or socially negative activity, that's one thing. If it's in service of curing diseases or making the world a better place that's quite a different thing.
01:00:13.634 - 01:00:29.990, Speaker C: So. I like to focus on what is the source of the innovative incentive and making sure that that's a positive, not zero to negative force. So the alignment of private and social is kind of an economist rift.
01:00:30.650 - 01:01:14.658, Speaker B: I think we can also achieve that with mev. So the ideal system in my mind under this model is like living in fantasy world. It's like one where you get paid to deploy hardware into places that aren't already hardware rich and that deployment directly benefits the user, like commensurate with the amount of money you're spending. So it's not like an adversarial situation where you're spending it and they're getting exponentially screwed the more you spend it's, more like spending it and you're relatively aligned with their outcomes. And maybe you make more rent from the protocol because you're optimizing user outcomes better. There's a fee for you that's sane. And this is all aligned with the actual social welfare function we're trying to optimize.
01:01:14.658 - 01:02:11.930, Speaker B: How do we get there? I actually think batch options are a fun key to this. So if you take the framing of unions that we had earlier, I do think we need to build protocols that support the ability of various geographies to unionize and the protocol still works and is in fact more effective when this happens rather than less effective. This is like my geographic decentralization trolling and push because the worst case is we centralized like the US or Europe or something like know. But the best case is there actually should be computation in New Zealand, right? Like if there are users making transactions there and the system doesn't predatorily advantage those transactions being optimized in New York, then why not do the computation where the transaction is actually happening? So I think this is where the care has to be taken. Make sure the system doesn't push those unions to the central place and instead allows them to exist in their natural local geographies.
01:02:12.670 - 01:02:47.970, Speaker A: Yeah, Eric, I think it'd be interesting to use that as a comment on what happened with fiber. I think a lot of people became aware of Egypt's investment when they started to see physical places coming between Chicago and Secakas or wherever the amount of fiber that was laid. And then we went to the more advanced stuff that even I know that bird droppings had issues in the Mackenzie book, he comments that but the world does need fiber. So it'd be interesting to hear what your thoughts on how was that useful at all? Was the fiber late for this or was it literally just for latency? Edge.
01:02:50.470 - 01:03:54.650, Speaker C: I'm open minded that there can be unanticipated benefits, that the innovation incentivized by high frequency trading activities might have some spillover benefit, but I haven't seen any specific reason to see. I have this time lapse data that it's a very dedicated research assistance build where you could see called it the latency Arbitrage triangles you could see using Federal Communication Commission applications for microwave licenses. You could see the line from Chicago to the New Jersey equity markets and also from both of those locations to Washington DC. Get straighter and straighter and straighter. So DC because I see your eyes raising. It's the government data that moves financial markets. It's released in a data center on street where all the lobbyists are just by coincidence.
01:03:54.650 - 01:04:27.990, Speaker C: So there's this latency Arbitrage triangle that you can see in the microwave applications data and straightening the thing by a few extra fee. It doesn't cost that much money so I don't want to get up in arms about it. But also to find social value in that I think is nuts. The fiber, transatlantic fiber or transoceanic fiber, that seems useful. I don't know what the delta is if there weren't an incentive from latency Arbitrage.
01:04:30.090 - 01:04:49.270, Speaker A: It does come maybe to this idea of the social welfare function being reflective of the fact that speed in this world was so relative. If Phil has a four second connection and Eric has a three second connection, you'll pay infinite dollars for that 1 second edge. And so there is no socialization of the welfare function. It goes all to that one spurt.
01:04:49.350 - 01:05:05.742, Speaker C: Yeah, very relative. And then so the social value is probably based on the absolute getting from five microseconds to four microseconds. It's hard to see a ton of social value in that. But again, it's not like I have a proof, it's just a strong economic intuition.
01:05:05.806 - 01:05:44.700, Speaker B: I feel the same way. I would check it at like 5% benefit versus 95% burned for zero sum. My guess is had you emulated the latency game in a simulation universe where they could all invest this money and get the same edge, there would be little difference actually. And again this is just like a gut feeling. I do think there's some utility to speed. I think the tricky thing is the types of links they're incentivized to build don't have high throughput and they're not usable by the public. So that's where the winner takes all thing comes from.
01:05:44.700 - 01:06:49.010, Speaker B: I see a little bit of social utility and certainly there's externalities of like if you get a better routing technique, maybe that propagates to other switches and Google's data centers or you know, very hard to throw the full baby out with the bathwater when you have thousands of engineers working on any pursuit. That being said, I don't know if it's super aligned with the actual outcome of efficient markets which is like that's I think where the zero something really takes it from being much more aligned to much less aligned. If there was a way for us all to improve the latency of markets together and we actually each were able to express our individual welfare on that in a mechanism that then optimized the social welfare, I think you'd get to a better social welfare with less investment. So I see it as like a coordination failure basically. That a lot of that money was burned. But that's just my own political opinion and again, this gets highly controversial with HFT people. I've certainly had face turning blue in conversations about this before, so you kind of have to make your own judgment there.
01:06:49.010 - 01:07:31.470, Speaker B: I think the relevance to crypto to me is just like not even asking the value question. It's just like do we want a global system or not and how do we want the rents to be distributed in this system? Let's just come up with something that we don't put value judgments on is like a much easier place to go than oh, this thing is bad, so therefore let's moralize it. I think we also see a lot of that in mev. The truth is usually a little more subtle. There are trade offs we should actually engage with the subtlety of how much money is going where and why. That to me is the question that a lot of these things sweep under the rug by popping to these different layers of abstraction where you lose the core thing of where's the money actually going.
01:07:31.620 - 01:07:41.106, Speaker C: Follow the money is a good general purpose instinct. So where's the mev money going? That's what I want to I mean.
01:07:41.128 - 01:08:25.470, Speaker B: We have data on this. The mev money is going largely to validators right now. Certainly there's some going back to users in the form of transactions being mined because of mev that otherwise wouldn't have been. I would expect that to increase as users get more sophisticated and kind of leave less on the table in the transactions they're making to be extracted by the searchers and the validators. We're seeing trends in all sorts of text designs for that. Some of it is going to the searchers, but on net I would guess the searchers and this is not data, so this is just my gut feeling. It may even be a negative sum game where most searchers are losing money and the new entrants are subsidizing the profits of the few that are making some edge.
01:08:25.470 - 01:08:58.220, Speaker B: Which is not great. But it's not like the searchers are raking home bags full of cash, unless they have a substantial edge on sexes, in which case they'd probably be raking the same bags of cash regardless. So that's kind of where the mev money is going today. A lot to validators, some to searchers, some to users. The middlemen, like Flashbots, some of them take some rents today we don't. So it's a pretty race to the bottom y market and I don't think anyone's really making a killing there or like extracting huge rent or anything.
01:08:58.910 - 01:09:26.578, Speaker A: Eric, that's a great thing to end on Follow the Money. I think if we had to say something about today's incredible summit, follow the Money I know that Ethereum Rate Group is focused on some of this stuff and I think that's going to be some really cool stuff to come out of that. So hopefully next time we talk, we can do that. This is the last talk of the day, everybody. Eric thank you so much. Really appreciate it. That was awesome.
01:09:26.578 - 01:09:33.120, Speaker A: Phil good to see you. Everybody, these are going to be recorded, chopped up and put on the Internet. And we'll see you soon.

00:00:05.370 - 00:00:35.030, Speaker A: With that, we are ready for our next panel. This is something I'm super excited about. We're going to be just talking about smart contract security. And for this panel we have Sam CZ son Nikesh Rajiv and Moralian on stage. And Morelian will be facilitating this discussion. So I'll let him ask all the panelists to introduce themselves instead of me doing the whole thing and making it more fun. So I'll hand this off to him and welcome everybody on stage.
00:00:36.010 - 00:00:49.690, Speaker B: Hi, everyone. Yeah. Thanks, Kartik. I'm Morelian. And let's do some intros. So, Nikesh, why don't you start us off and then Sam and Rajiv perfect.
00:00:49.760 - 00:00:51.920, Speaker C: Yeah. Thanks. It's great to be here.
00:00:53.250 - 00:00:53.614, Speaker D: Yeah.
00:00:53.652 - 00:01:21.430, Speaker C: So my background is in I actually did physics and computer science. At some point before the times before I joined the blockchain space, I was pottering around in a bit of cryptography, a little bit of reverse engineering, just general It security type things. But for the last two and a half years, I've been working at Opensupplyn as a security researcher. So basically, we do audits and research and trying to improve the security of the space, protect the open economy, as we say. I guess that's my broad outline.
00:01:25.130 - 00:01:28.038, Speaker B: Thank you. Sam cool.
00:01:28.124 - 00:01:40.460, Speaker D: Hey, guys. I'm Sam. I'm a research partner at Paradigm, and I do security. So finding bugs, mostly just finding bugs. That's about it. That's basically all I do. Yeah.
00:01:45.010 - 00:01:45.950, Speaker B: Rajiv.
00:01:47.890 - 00:02:15.080, Speaker E: Hey, everyone, I'm Rajiv. I'm the founder of Securium, which is a recent initiative to further improve the state of security of Ethereum applications. And Secureium is currently running a bootcamp on smart contract security auditing that's funded by an Ethereum Foundation grant and sponsor partnerships from Consensus Diligence, Sigma Prime and Taylor Pits. So here. Thanks.
00:02:16.250 - 00:02:16.902, Speaker D: Great.
00:02:17.036 - 00:03:36.740, Speaker B: Okay. By way of introduction, I was one of the original members of Consensus Diligence and am now working at Optimism focusing on protocol development and security issues. And so I'm really excited to be doing this panel. So given that East Global, that this conference is really focused on Tooling, which I think is a really exciting topic, and this group is really security focused, I think it'd be great to kind of will move this conversation along. Kind of like balanced on the knife's edge between Tooling and security, of which there's a good amount of overlap. So, having done that, I think a good place to start would be just we can each provide a little bit of context about the way we approach tooling, where it fits in our day to day roles, what we're looking for when we're choosing what tools to include in our toolboxes, if you will. And if anything, maybe tools that you might have built in the past as well.
00:03:39.830 - 00:04:20.826, Speaker C: Nikesh fair enough. Yeah. So, actually, I was mentioning just before we started this that my day to day work is pretty sparse with tools. So a lot of what I'm doing is just reading code and then trying to understand it deeply. I think we have a bit of a bias that way that we think a lot of the value we provide is just a security engineer taking the time to deeply understand code and then trying to match the knowledge to the particular task at hand. But I was saying, I do think a lot of the tools that I find are useful are just things that avoid distractions. I have really good notetaking tools, for instance, to help me keep track of what I'm doing as I'm reviewing.
00:04:20.826 - 00:05:02.566, Speaker C: We can talk a bit some of those if you're interested. Or the fact that I have like in the past, if I needed to understand a line of solidity, I would launch Remix and then try and write it in there, which was a huge waste of time. But now I've got this solidity REPL which just connects to a local Ganache CLI in itself. The whole point of that tool is just so that I can stop thinking about it. So I have a thought in my head, like, what does this line of solidity do? I quickly go and do that and then get back to what I was attempting to do before, which was just understanding the system. But I think a lot of it really depends on what you're attempting to do. Maybe just being a security auditor, there's a particular style that we follow which is just trying to understand contracts deeply.
00:05:02.566 - 00:05:13.060, Speaker C: But of course there are different approaches to security all over the space and I'm imagining there'll be several tools that will be useful in other places. I might leave it there for now. I'll pass it over to you.
00:05:15.830 - 00:05:53.502, Speaker D: Yeah, I mean, I can jump in here. I think I mostly agree. When I'm doing audits for reviews, I tend to actually stay away from a lot of the automated scanners. I find that I'm going to end up going through and reviewing the contracts anyways. And so for me at least, there isn't really much benefit that those scanners bring. However, that being said, I do find value in tools elsewhere. Like for example, when I'm reviewing some contract on main net, sometimes I need to figure out what's in a particular storage slot or what happens if some function is called.
00:05:53.502 - 00:06:12.420, Speaker D: In the past, I would pull up DevTools and web3 E, get storage at and it worked. It was very ugly, but it worked. Nowadays I actually just use Seth for that from the Daptools package. So here we go. We're three minutes in and already someone has showed Daptools. We'll see where else this goes.
00:06:13.430 - 00:06:31.270, Speaker B: Yeah, it's funny, I kind of got off Twitter for a lot of the summer and then I came back and everyone's like talking about Daptools, which has been around forever. Where did that come from? What is it like? What flipped there that everybody wants to talk about DAP tools all of a sudden?
00:06:33.230 - 00:06:59.694, Speaker C: I actually think it might just be trans. Like you learn about a bunch of these things because they're happening on Twitter and then everybody else learns about them because they're happening on Twitter. And I think a lot of the security community is relatively small and a lot of the value is just like knowing what other people in the community are doing. You hear that I get to read a blog that Samsung's written and then I learn something new because of that fact. And I think it's just like access to the community. You'll end up doing whatever else they're doing. That's my instinct.
00:06:59.694 - 00:07:04.066, Speaker C: But I don't know, I can't speak for why other people do what they mean.
00:07:04.088 - 00:07:13.400, Speaker B: It's really cool. Martin and the team at DevTools have been working so hard for so long. It's nice to see them getting some traction like that. But please go.
00:07:16.490 - 00:07:51.202, Speaker E: I mean, I might be the OD man out. I haven't used app tools, so please excuse me for that. I'm going to actually try to do that over the weekend. But yeah, from a tooling perspective, I think the points made are valid. The way I see it, I do see tooling in the space of Ethereum Security as maybe focused on developers and maybe a separate set of tools that are focused on auditors. And today I think there is a good overlap. So a lot of the auditors, like Sam was saying, you just are in the space.
00:07:51.202 - 00:08:44.594, Speaker E: You're looking at contracts and predominantly there's a lot of manual analysis. So the ROI that you would get from any of the automated tools is maybe not that much on a day to day basis, maybe there are some special use cases for that. But for developers, I think there is a lot of value, be it any of the static analysis tools like Slither or the MythX or any of those, there's a lot of value to that. So I do see that sort of dichotomy. Maybe that gets blurred sometimes. But as for me, when I review contracts, I do fall back on magnet analysis. So the tool that I use there is usually the Serenity Visual Developer plugin, which really helps me navigate the code.
00:08:44.594 - 00:08:49.540, Speaker E: Very cool. That stuff for Vs code IDE.
00:08:51.770 - 00:08:54.230, Speaker B: By my old friends at Diligence.
00:08:55.290 - 00:09:18.350, Speaker E: Yes, tinted web. So that's fantastic. And I do tend to use Slither now and then to just get me some good starting points to just get some sanity checks going. And in the past I've actually contributed several detectors to the development of Slither. So that's my general perception on tooling.
00:09:19.970 - 00:10:37.750, Speaker B: Yeah, the pattern I'm sensing here, I think is as auditors, it's very different from developers. As a developer, you live in one code base and you are there all the time. And you joined this company or project and they gave you a couple of weeks to ramp up the amount of time that is kind of like the training period for someone at a new company is kind of like how long you have for an audit, I think. So what security researchers at ours are doing is just really trying to understand the code as quickly as possible. And so I think that there seems like the pattern is that you're sort of like a bit more less of just point and shoot scanner approach and more of a marriage of, say, human and automation to get deeper understanding. And I think that's where you see the visualization tools, the graphing, those kinds of things becoming very popular for auditors. But so, I mean, you guys also see a lot of different code bases, I imagine.
00:10:37.750 - 00:11:04.320, Speaker B: Do you see patterns of tools? And so you have opinions about teams and code bases and which ones are good and which ones you love less. And we don't have to talk about names, but do you see patterns of tools that the teams you think are on the right track are using in their development process?
00:11:07.730 - 00:12:01.554, Speaker C: I guess my advice is whenever I see teams using the team that I have in mind at the moment, they do all of their pull requests out in the open, and then they answer their questions and they have security questions. Quite often I'll be reviewing code and then I'll go look at the pull requests that they made or some of the commits, and I get to see all their comments and their thought process behind it. All of that stuff is really useful. It seems to be correlated with a lot of the continuous integration tools that they use. Because I'm not a developer. I can't say exactly how related these things are, but I think there's probably some level of professionalism when you've reached the point where you take just development seriously, and then you make sure that there are two people reviewing every like all your there's always someone who reviews all your code and then you're going through the process correctly. That does seem to be at least correlated in my mind with people who take security seriously as well.
00:12:01.554 - 00:12:27.980, Speaker C: And just maybe riffing a little bit on what Rajiv was saying. I think a lot of clients will actually use some of these tools before they reach an audit. And it's like a good way to find your own bugs first in your own code before you actually take the time and effort to go and get it audited. So I guess that's my initial instinct. I'm not recommending a particular tool, other than just noting the level of professionalism, does seem to correlate somewhat with the level of security analysis, maybe.
00:12:30.530 - 00:12:45.070, Speaker B: You might say. So GitHub or git and the code collaboration tools in general that just enable people to ask each other hard questions about what they're trying to merge.
00:12:45.890 - 00:12:53.300, Speaker C: Right, so I guess everybody is using GitHub, but then some of them are just like pushing to master directly and some people are making pull requests with.
00:12:54.070 - 00:13:04.520, Speaker B: That'S the sort of way that like reviewing pull requests is a high bar or like an indicator or something.
00:13:07.210 - 00:13:12.234, Speaker C: Maybe? I think it depends on the detail. I'm thinking I am speaking, sorry.
00:13:12.272 - 00:13:16.794, Speaker B: My point is that it's crazy that anybody's not doing that. I think it's just what I'm getting at.
00:13:16.832 - 00:13:28.094, Speaker C: But okay, yeah, I think my instinct is really more about how much effort they put into reviewing pull requests. There's obviously different degrees of how seriously you take that sort of thing.
00:13:28.212 - 00:14:04.138, Speaker B: Certainly. Yeah. Okay. I think maybe even if it's not the focus for anyone here, I'm curious what, if any impressions you have about the potential there is among the more advanced tooling. So, static analysis. I think running Slither is a really good just like it points out a lot of stuff, a lot of code smells. That's the static analysis tool.
00:14:04.138 - 00:14:34.850, Speaker B: Then I think fuzing, there's a variety of good fuzzers out there that are maybe the next step to look at or all symbolic execution tools. Do you have a sense do you have a feeling about where we are at with those? Have you seen sort of like output from them and found that useful? Or is it just usually just a list of findings that don't really give you joy?
00:14:39.610 - 00:14:46.902, Speaker C: I can jump in if but I feel like I might be monopolizing this a little bit. So I'm anxious about that. Certainly. Feel free to interrupt me.
00:14:46.956 - 00:14:57.100, Speaker B: Well, I mean, I'll just like Sam and well, you told us in Chat, but Sam, just tell us what you said about everything not in.
00:14:59.950 - 00:15:41.046, Speaker D: Mean, I guess maybe I'm not connecting the dots here in Chat. I just said I'll pass on the question because when I'm reviewing code or a project, I basically ignore everything that's not in Contracts. And I guess to even be more specific, I ignore everything that's inside tests as well. Because personally, unless the code is so confusing as to I'm not sure what the correct behavior is, there's really no point in me checking the test. I think it's just a waste of time. But actually on the topic of fuzzing, I once again will start Georgio's has been like one of the major drivers behind the Daptools shilling, I think. And now it's rubbed off onto me.
00:15:41.046 - 00:16:27.080, Speaker D: So I will now shill Daptools again because you did this presentation internally at Paradigm where you showed off the fuzzing and property testing that you can do with DAP. And it's actually kind of obviously you have Echidna and MetaCore and I think MythX does fuzzing too, right? Am I misremembering? Yeah. And you can do fuzzing and property testing with them. You can go more advanced, I'm sure. But it's always felt sort of inaccessible, I feel like. It's always seemed like this hurdle to overcome to figure out how to use these tools. And the interesting thing with Daptools is they've taken a very similar approach to how Go does it which is.
00:16:28.990 - 00:16:29.306, Speaker E: You.
00:16:29.328 - 00:16:56.690, Speaker D: Just write a function in solidity like maybe right beside your actual code itself and you just put in as parameters to the function the things you want the fuzzer to explore and that's all you need to do. And the rest is just handled for you, just run the command. So I think that's actually really awesome. And hopefully as more and more people find out about this through the nonstop shilling that happens everywhere, maybe we'll see more and more usage of Fuzzing and property testing.
00:16:57.190 - 00:17:16.120, Speaker B: So, to clarify, what I think I understand is it looks a lot like a typical test suite, but instead of saying transfer one token to Sam, I'd say transfer x tokens to somebody and that's all I do. I leave that open and the Fuzzer takes it from there.
00:17:16.970 - 00:17:50.850, Speaker D: Yeah, pretty much. If you had a function that did some complex math to figure out the returns for some exchange, right, you could treat it as a black box. It takes some UN 256 as input and returns some UN 256 as output, and you can just tell the Fuzzer, I just care about this UN 256 input and then assert on the next line like the output is same, right? And the Fuzzer takes care of the rest. It's just that magical.
00:17:53.750 - 00:19:39.000, Speaker B: For anyone not really aware of what Fuzz testing is, it's basically that instead of writing one test at a time, it's tools that generate ideally millions of test cases and sometimes can be quite sophisticated about speaking from diligence for some reason. The Fuzer there is called Harvey and that's not really like a product name, it's just the internal name. But like it tracks where it's been in the bytecode and when it bounces off a require statement or an if branch multiple times, it does solving to try and say okay, I almost got this if else branch to flip so that I could get into that. And it tries to figure out the math so that I actually can trigger that, which is not an easy problem. And I think that that is I actually was just looking, it was about a month ago that I think they've really shifted the focus from MythX over to just like Fuzzing and doing more Fuzzing as a service. And there's also like I'm really interested in what we were working on there, which is this tool called Scribble which allows you to write basically Nat spec formatted comments which will then you recompile the solidity and it adds all these assert statements that allow you to describe specifically the failure cases. It was still coming along as far as sort of usability, but I think I'm due to check it out again.
00:19:39.000 - 00:19:40.710, Speaker B: Go ahead, Rajiv.
00:19:42.090 - 00:21:36.006, Speaker E: Yeah, I think two critical points that were made, right? One of them is as maybe security researchers who are deeply into the space, we focus a lot on the effectiveness of tools, understandably so, how accurate it is false positives, all that make a big difference. We also focus a lot on the efficiency of tools and the second part actually leads to the usability aspect of the tool itself that I believe oftentimes is not because if you're deep in the weeds, then if we are developing and if it's all open source, then we are using it. So we really don't appreciate how deep we are. And if that same tool is actually expected to be used by the developers of protocols, like you said, may have like a week or two to actually look at this tool, then that barrier, I think, becomes a huge deal in terms of well, let's take Slither, for example, right? Take it, install it and you run it and it should just work right out of the box. But for some of these other deeper tools like you said, right, be it Fuzzing, be it symbolic checkers, there's just so much heavy lifting that needs to be done even before you can start using it. Right? I mean you need to understand how that tool works, the intricacies, the documentation of the tool itself. And then we need to write the rules, be it Fuzzing or let's say property based testing, right? So there's just so much work that is involved there which I think hopefully over time will get much simpler so that the product or protocol teams themselves can actually start using these tools to a good extent.
00:21:36.006 - 00:21:43.180, Speaker E: So I think that I think is something that maybe as a community we don't pay enough attention to.
00:21:44.990 - 00:21:49.246, Speaker B: I agree. Makesh no, I was going to say.
00:21:49.268 - 00:22:49.118, Speaker C: So I haven't actually used Fuzzing since I've joined this space, but I used to do some Fuzzing stuff back in a VPN traffic and you just throw it a bunch of packets and see what breaks. At least at the time, a lot of what we were looking for was crashes. Basically looking for places where the whole thing crashes and then seeing if you could instrument the system later and find where it broke. I was a little surprised to hear that logic applied to the smart contract space, just partly because you're not trying to crash the EVM in any sense. Maybe it's closer to smt or property based testing rather than what we'd call Fuzzing. Maybe I'm misunderstanding the term or I've got some bias that's forcing me to think in a particular way. Certainly your idea at the end of being able to nat spec a particular property, for instance, I've mentioned this example in the past, sometimes I'm looking at code and then I know that this value is meant to be a percentage, so it has to be less than one, for instance.
00:22:49.118 - 00:23:08.630, Speaker C: But it's not immediately obvious, just looking at the code that it always is. To the extent that it's possible to nat spec that and say this is supposed to be less than one, please make sure that's true. Throughout the whole code base. I think all that that would be useful, but personally, I haven't actually seen that happen. It sounds like you're telling me I just have to wait a couple of weeks and then maybe that'll be us.
00:23:08.780 - 00:23:44.770, Speaker B: Well, I mean, in fairness, I think that that's how all of the fuzzing related tools that we've talked about work is. You basically have to reason like you got to know your system and you got to know what's wrong. And if something is announced that only goes up, then the fuzzer can tell you if it goes down, but you have to write somewhere that it should only go up and it should never go down. So there's various places you can write that. But yeah, it's not just like a general crash kind of situation. You have to be able to define your failure modes.
00:23:45.450 - 00:24:00.698, Speaker C: Can I just clarify, is it doing this probabilistically or is it actually exhaustively? Checking the possible inputs is a weird term when you enumerate through the whole space, but you could do it symbolically as well to check.
00:24:00.784 - 00:24:24.720, Speaker B: Yeah, I know that the MythX suite, they would measure how much of the code they'd visited. It still doesn't meet. Like you could hit 100% of the code and not necessarily have meet all the edge cases or explore all the kind of execution modes. But that is the objective is to traverse the entire system.
00:24:28.390 - 00:25:14.350, Speaker D: I will mention that Daptools does do symbolic execution as well. But also it's a good point that right now all these tools do require you to define. The weak part about unit tests is that you can only unit test what you can think of, right? And so often in hindsight, you'll look at something and go, damn, that would have been a really nice unit test. But the hard part wasn't writing the test, it was thinking of the test in the first place. And with fuzzing and symbolic execution or property testing, you've alleviated some of the challenges with maybe defining exactly how to test. But you still do have to think of the thing to test for. And in fact, we can take that one level higher with formal verification.
00:25:14.350 - 00:25:48.720, Speaker D: We see that as one example that comes to mind. The miso bug that I found a couple weeks months ago, I don't know how time works anymore. That was formally verified. It was just that there was no case defined for both minting or sorry, both buying into the auction and using the batch contract. And so once the team went and added that case, the form of Verifier was like, yeah, there's a bug here. But you had to think of that first. And so it might be interesting.
00:25:48.720 - 00:26:09.606, Speaker D: I don't even know if this would be possible or not, but if there was some way to just similar to how traditional fuzzers just look for crashes, if there's a way to just look for ways to send ether out or ways to transfer tokens out that might be way too computationally expensive. I'm not really sure. Maybe someone else here can comment on.
00:26:09.788 - 00:26:15.000, Speaker B: Like I think that Slither does that. Rajiv yeah.
00:26:16.810 - 00:26:26.220, Speaker E: I mean, to a certain extent, right? Whatever you can determine syntactically and semantically, like love ether and so on, but yeah, please continue.
00:26:26.750 - 00:27:20.974, Speaker B: Okay, yeah. So I was going to say, I'm pretty sure MythX did that. Does that. The thing is, if you care enough about the security of your contracts, usually kind of well, no, this is not true. Obviously, experience bears that out, but I think it's hard to detect the weird things. And I think that the messages that you end up showing are like there's kind of like you call out here to unknown we're not sure what you're going to do, but like, fuzz testing. So as soon as you call out to an unknown contract, what are you going to do? Like, generate all the possible contracts or symbolic execution as well? That just doesn't really make any sense, but I was hoping so formal verification, I'm just, like, overrated or underrated, let's phrase it that way.
00:27:20.974 - 00:27:26.400, Speaker B: We'll go around and Rajiv, you got to go first because absolutely.
00:27:26.930 - 00:28:24.162, Speaker E: So, yeah, I think, like with many things in the space and maybe in life, right. Formal verification is probably overrated in the near term in the space, and probably underrated in the longer term. I get the impression maybe it's sort of the meme of the season or whatever, right. But there's just like, hey, let's go do formal verification. Right? I mean, I do believe that property based testing such as Scribble or Sirtola Spoover or KVM or Verex from chain security, all these do, will play a significant role, maybe just where we are in the maturity cycle of the tools. I mean, there are so many things that are moving, right? Solidity is changing every month. Ethereum itself is changing protocols, everything.
00:28:24.162 - 00:29:23.842, Speaker E: So in that scheme of things, I think just sort of moderating our expectations from these tools, especially formal verification, that it's not a magic wand. And like Sam said, well, great, we do use a formal verifier. But how do we know that the formal verification tool itself, somebody built it? How do we know that that doesn't help bugs? How do we know the properties that were written do not have omissions? Right? So those things and this sort of goes back. I mean, none of this actually is new in the Web Three space. If you look back all the way to who was it? Ken Thompson's Turing Award lecture on reflections on trusting trust. Right. So he talked about, well, all these layers that we seem to rely upon as something very canonical, something perfect, but that's not the case.
00:29:23.842 - 00:29:41.180, Speaker E: And that applies even to formal verification tools. So no wonder, right? I mean, if you have a checkbox saying, well, this protocol was formally verified, it's not a magic one. But that is not a problem with the tool or the approach. It's just a problem with our mismatch expectations, if you will.
00:29:42.590 - 00:29:46.860, Speaker B: So what you're saying is you should write a GD spec.
00:29:50.270 - 00:29:52.342, Speaker E: You should write a what, sorry, a spec.
00:29:52.416 - 00:29:58.350, Speaker B: A spec. So that you can identify those things, I guess.
00:29:58.500 - 00:30:23.480, Speaker E: Right? I mean, that would be, again, a mismatched expectation at this point. Having looked at several code bases, I would be happy for a typical project for something more than one screen README file, right. Something we can start with that we can go back to better documentation. I mean, if you have a list of all the contracts and the interactions, a spec would be fantastic. Absolutely.
00:30:24.010 - 00:30:36.694, Speaker B: Yeah. Spec is a powerful tool. English language underrated Nikesh overrated or underrated formal verification, I think it's probably useful.
00:30:36.742 - 00:31:42.670, Speaker C: But as Rajiv is pointing out, there's probably a mismatch between what it can do and what people think it can do. Even the spec, I don't think helps as much as you might expect. At least my instinct from that is based on the fact that people have been talking about formally verifying VPNs forever and there is a spec, there's an RFC, and it's existed for a long time. And it seems theoretically that you should be able to just implement that spec in a form of verification tool, but still OpenSSL has the market and it's like spaghetti code completely. And partly that's just because they got there first. And also, if you want to open a new you want to add this new protocol, or you want to use Divi Helman instead, or you do something slightly different, then that spins out a whole six month, eight month project to specify that part of the test, particularly in the blockchain space, it's moving so quickly that by the time we have like a spec of ERC 20 people already doing flash loans and stuff so then you'll lose the ability to at least keep up to date with what people are doing, I suppose. I do think it probably would be useful to have formally verify some repeatable components.
00:31:42.670 - 00:31:59.400, Speaker C: I might just throw open Z component contracts in here. If you can formally verify something that's been used in lots of different projects and is relatively well defined, I think that might be useful. But at the moment, I think it's just going to be lagging behind for a long time.
00:32:00.330 - 00:32:12.860, Speaker B: Yeah. So I think sam, anything to add? I think know short term, long term answer is just so effortlessly wise that it's hard to add a whole lot.
00:32:14.590 - 00:32:42.740, Speaker D: Anecdotally. I will say that usually when I see that Satora has formally verified a repo, I'm like, okay, that's probably safe again. But I think that speaks of eco volumes to both the technique itself and also their team's ability to actually reason out what your code is supposed to do for you, because that is what they do is they sell. You the service and they sell you well, they sell you the technology and then they sell you the service to use that technology.
00:32:43.910 - 00:33:41.030, Speaker B: Yeah. So one thing I think is interesting there is one of my favorite auditing techniques was like making diagrams. And I think that's something like that's a form of spec. A lot of tools do this too, in that informal verification as well, in that they force you to reason through they just put you through an exercise in which you sit down and you're like, what does it do? What does it actually do? And converting solidity to a picture or words, I think is an effective way, or properties, and maybe properties is a higher value output because you can reuse them. But I think for a lot of tools, my sense is that that is a lot of the value is that it forces you to interact with the system more deeply.
00:33:42.810 - 00:33:44.150, Speaker C: Yeah, I think I totally.
00:33:48.430 - 00:34:47.578, Speaker E: I was just going to do the same. Absolutely agree with what was said. I think to sort of go back to one of the first questions that was posed. If there were two tools that I would love to see right from, again, separating out the auditing from a developer perspective, from a development perspective, if there were two tools, I think those would be at two ends of the spectrum. One of them would be something like slither, something that's very fast, static analysis that catches all the code smells, that catches all the basic pitfalls, shows you what the best practices are. So that I think, would give the best bang for the buck for the development team right away. And the other one would be the other extreme, which would be the property based test because that would force the dev team to think about, well, one, do I have a spec? Right? And we might call it spec, documentation, whatever.
00:34:47.578 - 00:35:03.460, Speaker E: But it forces you to think of, well, what is the requirement, what is the expected behavior? And it makes you document that formally in the context of this tool. So those, I think, would be the two sort of top on my wish list.
00:35:06.070 - 00:35:54.554, Speaker C: So I have an instinct. It's not very well formalized, so I'm kind of shooting from the hip here. But I think Marillian's point was excellent about the fact that it forces you through this process in itself is useful, even if the output of what the tool says might not be that readable. But I have a sense that we might be mixing layers because at least in my experience, the real value of a lot of these things is being able to transfer the knowledge in the developer's head into someone else's head. So into an auditor, for instance, or just into another developer. So they have some threat model in mind and they know that they wrote the code in this particular way because they're trying to avoid some particular style of attack and then an auditor comes in and thinks, well, have you thought of this style of an attack? And maybe they have, maybe they haven't. But then there's a huge ramping up period and then it's also quite unfortunate.
00:35:54.554 - 00:36:34.942, Speaker C: You get to the end of an audit and now you're an expert in a system and then that wanes until the next audit shows up. I think there are a lot of processes that are potentially in place to maybe shorten that time period so that we're not doing it in batches. So obviously it'll be useful to try and maintain more of a continuous sort of relationship that way. But I think we then make a mistake potentially when you then try and specify it in the code. Because at the high level, I haven't said anything about this particular contracts or if statements or anything. I'm thinking really just about have you thought about replay attacks? Have you thought about access control issues and that sort of thing. And I guess a lot of times your threat model goes out of date.
00:36:34.942 - 00:37:15.034, Speaker C: After a while, you wrote your code assuming some sort of threat model, and then it turns out the ecosystem changes, flash loans become a thing. Or, for instance, now you can do reentrancy because the gas limit has changed or something like that has gone wrong. And you don't go back and revisit the code because you thought the code was self sufficient, whereas what we really need is just a way to transfer knowledge. I think a lot of the value comes from just the existence of the security community that has seen all of these things before. You can go through previous audit reports and stuff. We have repositories of where these things exist. So you could say, I'm building a tool, like I'm building a voting tool.
00:37:15.034 - 00:37:42.500, Speaker C: Let me look at all the places. These are the checks that I need to worry about, these are the things that are broken. I think a lot of that is useful well before you actually get to the code level. And to the extent that we can have tools that just spread security knowledge around the space, I think that's going to be at least it seems like an underserved market. That's my own instinct, but it isn't particularly formally formalized yet, so we're kind of just shooting a little from the hip here.
00:37:43.910 - 00:38:42.600, Speaker B: Fair enough. I think a good example of that, like the threat model changing, I think, is maybe like developing a dex, oh, this will use a bunch of, ERC, 20 tokens and then somebody's like, oh, but I have a token that will do. Callbacks to whoever you want when you transfer it and you just don't think about that, right? You're like, it's just an ERC, 20 token. It does nothing fancy, so maybe just to keep moving along and I don't know, this is probably a little bit out of everybody's wheelhouse, but do you have thoughts about what you should be doing when the code is running on chain it's out there. Is there a magical way to detect and prevent attacks in real time? I think, Nikesh, this is kind of softballing for you. So go.
00:38:43.370 - 00:39:12.782, Speaker C: This I sort of have to mention at this point. So we certainly open zeppelin. We have this tool defender. It's got audit tasks. You can certainly write up your security properties or things that you want to check. You can say, like, if this balance changes or if some property holds on the blockchain, then please run this task or at least give me an alert. We're also developing a new tool called FORDA, which is like a Web Three Native cybersecurity thing, which is basically like an alert monitoring system.
00:39:12.782 - 00:39:39.330, Speaker C: There'll be details to come soon. But the important thing, the thing that's particularly interesting about this is it's Web Three Native, so it's not like an external tool that you're running and then you try and pipe it into the blockchain. It's actually running directly on the chain, so you'll be able to hook it into all of your apps. It's decentralized and directly integratable in the same way and composable in the same way the rest of the blockchain is. So that's my pitch.
00:39:39.410 - 00:39:46.650, Speaker B: But is it going to save you or is it just going to make sure that you know right away that your system is totally owned?
00:39:47.070 - 00:40:08.420, Speaker C: True, that's a good point. So it's like agent detection. So it's detecting things that have changed. It's not necessarily preventing it. But certainly we do have things like Autotask that say if this happens, then run this command so you could pause a contract at the moment that something changes. So you can take sort of automated actions that way.
00:40:10.390 - 00:40:15.634, Speaker B: If the attacker doesn't bother to use Flash bots, I guess. Right, right.
00:40:15.672 - 00:40:15.874, Speaker E: Yeah.
00:40:15.912 - 00:40:21.586, Speaker C: So of course it'll shorten the time period it takes to react.
00:40:21.618 - 00:40:41.760, Speaker B: Maybe that's a good way of doing that. Are there other things out there? Or Sam or Rajiv? Do you have a thought about not even tooling, but just like, running these systems safely? No is an okay answer.
00:40:46.130 - 00:41:45.554, Speaker D: I mean, I've seen quite a few attempts at building these sort of things now where you try to alert on transactions in the mempo, of course, as Nikesh said, now that Flashpots is more and more thing, that becomes kind of hard. The only time I've really seen you know what? I don't really know where I was going with this. The point I was trying to get to is, like, I tried building one of these at one point, and it was meant to alert on past transactions. So like things that were already mined and just to see if anything interesting was going on, try to automatically detect if a transaction was anomalous. It was somewhat okay. It was very noisy, though, so I sort of just gave up on it. But that would be I don't know if anyone's built that or made a public version of that, but that would be cool to see.
00:41:45.554 - 00:41:49.300, Speaker D: Just like a live automated threat intel feed almost.
00:41:54.390 - 00:43:11.200, Speaker E: Yeah. I don't have much to add in this space, but maybe I have more questions in this space, right. And I've discussed this with some of you in the past, is if you look at the Web Two world, you have a long list of security products in the last 30, 40 years, all the way from ABS, firewalls, intrusion detection systems and all the different names of that intrusion prevention systems, all these things, right? So there's no reason except taking into account some of the big changes in the Web Three space, maybe culturally as well as technologically, that these systems could not theoretically be implementable in the Web Three space. Right? So if you're able to see a transaction in space as it is flowing through the mempools or whatever layers you're in, theoretically one should be able to simulate that for your main net with whatever tooling be able to simulate this transaction and be able well, you obviously need better and faster resources than the attackers themselves, but you should be able to do that and then.
00:43:14.610 - 00:43:15.086, Speaker D: Put in.
00:43:15.108 - 00:43:43.880, Speaker E: A transaction that actually takes over or goes ahead of the tackles transaction and somehow fixes the code or makes the tackles transaction invalid. So theoretically I think it should be possible. I don't know, I mean maybe Nikesh and others have more practical experience in this place with Defender and other tools, but that was just a thought and I hopefully will see some research or maybe even products or techniques in this space.
00:43:46.410 - 00:44:30.120, Speaker C: Just make sure I understand that claim. So the idea is you see something in the mempool and then you're essentially trying to replace that transaction. So obviously front running as a concept is existing and people are doing it for non security related reasons, like just for Arbitrage generally. And that's been developed quite extensively to the point where people are running gas suctions and things whenever something new happens. And of course flashbots now is alleviating some of that. I understand you're perhaps approaching it from the security angle, but maybe I haven't seen why it's a different concept. It still seems similar to seeing something that you don't want to happen or something that you want to prevent first and then getting your transaction first.
00:44:30.120 - 00:44:42.920, Speaker C: Unless the contract itself is designed in such a way that it has a delay. Sorry, I'm thinking out loud at this point and I might be misleading here.
00:44:44.990 - 00:44:48.140, Speaker B: Why don't you jump in here? I think you've been quiet for a little bit.
00:44:52.190 - 00:44:56.880, Speaker D: I mean, put me on the spot, I guess. I don't know. I've been quiet because I didn't really have much to add.
00:44:58.530 - 00:45:02.526, Speaker B: You were unmuted. I took that as a signal. Sorry, I read too much.
00:45:02.548 - 00:45:03.360, Speaker D: That's my bad.
00:45:04.390 - 00:45:41.754, Speaker B: Okay. I kind of think you're right. Nikesh well, basically, I guess you're going to get into this is, like, outside our wheelhouse, but you're going to get into reorgs, right? Because you got Flashbots, you got private transactions. I'm a brilliant black hat hacker. I know how to I found an exploit. I submit it through Flashbots. Nobody can see that, and it's going to execute.
00:45:41.754 - 00:46:06.306, Speaker B: I'm going to own your contract. The only way to get back to restore that is to reorg the chain and outbid. And I kind of lost track of that conversation that was happening over the summer, but that's where that goes to me. As far as I can tell, it.
00:46:06.328 - 00:46:45.630, Speaker C: Still sounds like it might be in the same bucket in the sense that now I'm definitely speaking outside. I don't know anything about how useful it is to reorg or how plausible it is to do that. Hopefully people are thinking about that to make that difficult. But I would still guess that if that tool is available, if that technique is available, it'll be used first to win trades, uniswap trades or something, to arbitrage some. As long as there's, like, direct money on the line, that'll be the use case originally. And people will be doing arbitrage with that tool before the security level catches up. That's my instinct.
00:46:46.610 - 00:47:03.846, Speaker B: I guess we got, like, a minute and a half left. A question I kind of like, I just remembered I really wanted to ask is, like, what tool needs to exist or be way better than it currently is that you would like to see in your life? So let's like 15 seconds. What does it do? Nikesh, you're already unmuted. Go ahead.
00:47:04.028 - 00:47:17.318, Speaker C: Fair enough. I have this grand plan of making a threat modeling tool that I think that works. Same concept saying, working at the high level of understanding threats rather than understanding code. That's my 15 2nd pitch.
00:47:17.414 - 00:47:18.970, Speaker B: Cool. Rajiv.
00:47:22.110 - 00:47:42.580, Speaker E: So I have a slightly different wish, right? I think all tools have their place, but my wish is they get used sooner than waiting for the auditors to run them. So I'm thinking and I'm getting really big on the shift left that has been such a big thing in the web two space. I think web3 space needs a lot of that.
00:47:46.370 - 00:48:13.186, Speaker D: I have a really big insane idea and like, a smaller do buy idea. The big one is I want this integrated all in one platform where I can view contracts, decompile them, analyze transactions, inspect storage slots, look up four byte hashes, like the works. Right. Everything I need to do ever is like a tab away, like convert from Hex to ASCII or whatever. Right. All that stuff. That is, like, a lot of work.
00:48:13.186 - 00:48:41.890, Speaker D: Also, I suck at UI design, so I'm not doing it myself. The more doable one is like, some tool in my IDE that lets me annotate specific variables or blocks or whatever with things that I don't have to remember, like this variable is always going to be even, or this variable is always going to be less than 100 or something like that. And then that way when I click through three functions and I look at the variable again, I don't have to remember that I can just hover over and it's like, hey, by the way, you said this is going to be less than 100. So just for reference.
00:48:43.030 - 00:48:47.410, Speaker B: Yeah, okay, that's great. I think we're at time.
00:48:47.560 - 00:49:04.140, Speaker A: Yeah, that was an awesome discussion. We'll do two quick things and anybody can pick. We don't have to do everybody. But the first kind of question is for people who are trying to enter the space as auditors, do you have any tips or advice for them? And what do you kind of recommend they do if they want to be on the auditing side?
00:49:08.400 - 00:49:11.150, Speaker E: Join the secure boot camp. Sorry.
00:49:12.640 - 00:49:15.996, Speaker B: No, you should shill first, maybe just.
00:49:16.018 - 00:49:19.970, Speaker A: To give more context to people. What is the boot camp and how can they find out more?
00:49:21.220 - 00:50:07.004, Speaker E: Yeah, I mentioned this in the beginning, but Secure Bootcamp is a three month boot camp that has just started in October. It's funded by an EF grant, and the sponsor Partners are some of the top auditing firms in this space. The idea is to be extremely open to people from different contexts. So there is a two month learn phase where people are going to learn about Ethereum 101, solidity 101, 201 audit techniques, audit findings, all the rich content that we already have curated in the space. And the final month is going to be where the rubber really hits the road. They're going to be taking a look at some real world projects where they actually evaluate them for audit readiness and hopefully have a good chance of becoming auditors. Awesome.
00:50:07.202 - 00:50:09.864, Speaker A: May I kind of blend this on the other side of that?
00:50:09.922 - 00:50:36.490, Speaker C: I feel like I might want to answer that question just because, first of all, I certainly agree with Rajiv that the securing bootcamp seems excellent. But of course, I feel like I have to point out if you can ask me that question, OpenZeppelin has a bunch of videos that we put out like Tincho, one of our security researchers puts these things out. We have, like, the Ethernet, and these sorts of techniques are useful and we're always hiring. So if you actually resonate with that question, then come hit us up.
00:50:38.060 - 00:50:54.636, Speaker A: All right, one quick one. And others can kind of mix and match that last one, too. Just for people who are trying to now replay apps to production or contracts to production. Explain that. Any tips for how should they think about auditing or insurance or anything else around that?
00:50:54.658 - 00:50:56.096, Speaker E: And what are some things to keep.
00:50:56.118 - 00:51:02.800, Speaker A: In mind for newcomers? Very open ended. Anything qualifies?
00:51:04.660 - 00:51:17.200, Speaker C: I think I have maybe the same instinct, like try and get plugged into the security ecosystem. There's lots of people who will guide you through the process, but it's hard to answer that in 1 second. But try and get plugged into the ecosystem is my main suggestion.
00:51:18.260 - 00:51:20.530, Speaker D: Book your audits early. The lead times are long.
00:51:22.700 - 00:51:23.208, Speaker E: Perfect.
00:51:23.294 - 00:51:33.990, Speaker A: Well, we'll end that there. Thank you so much, Sam, Rajeev and Orlean. This was an awesome discussion, and for any other questions, we'll relay them to you over email. So with that, we are ready for our next talk.

00:00:33.170 - 00:17:31.424, Speaker A: Sam. Sam. It it's for me. Sam. Sam SA it's. Sam should be like, hello, I have not connected yet. It all right.
00:17:31.424 - 00:17:47.030, Speaker A: Cool. Hey, everyone. My name is Juan. I'm here to talk to you about regen crypto economics for good. And could I get a quick show of hands? Who is familiar with a regen crypto movement? A few people. A lot of people. That's great.
00:17:47.030 - 00:18:32.848, Speaker A: How would you gauge raise your hand by degree of familiarity with it. You're like a region, maybe not a maximalist but super into the Green Pill region movement kind of halfway like you kind of know something about it but not a ton like, hey, you're not very not familiar. Great. Awesome. So this talk is for all of you but that just calibrates how much I should explain different things and how much I should not bore you. Great. So one of the claims of this talk is that if regen wagme else NGMI so if we can achieve regenerative crypto economics to achieve private utopia, then we're all going to make it and if we don't, then we're pretty screwed.
00:18:32.848 - 00:19:15.952, Speaker A: So there we go. So the talk is going to go through these set of things. I'm going to intro region cryptoecon. I'm going to talk about what pirate utopia is and how to achieve it. I'm going to walk through two examples that are both massive and break them down into smaller chunks so we can think of how to scale it up and how to cause an incentive structure build up towards fixing that problem. Then I'm going to give you a whole bunch of region ideas that people are talking about right now and I'm going to end with how to get involved and how to take your region ideas forward, how to join the movement and how to improve the world. Great.
00:19:15.952 - 00:20:04.050, Speaker A: So I'm going to use the mimetics of Green Pilled which is a movement that the gitcoin folks and especially Kevin Awawe and a whole other folks have been producing. The memes are awesome. So I'm going to rely on the great illustrations of the book. Should definitely get this book and check out the podcast. So take the Green Pill anon the basics of the Green Pill movement in a sense and region cryptoecon is that first the whole planet is filled with coordination failures. We'll talk more about that in a moment. We understand that and we understand the problem space and we also understand a set of solution possibilities and so we reject the numerism and we are going to try and build a much better future.
00:20:04.050 - 00:21:30.732, Speaker A: Web three is a big moment of presents a ton of opportunities and it's a big shelling point in a sense of people that want to cause this kind of action and this kind of change. The tools that we're going to use are mechanism design and tools around using game theory and crypto networks and so on. Leaning into all the crypto blockchains that we've built and with that we aim to generate a massively generative and regenerative crypto economy that is going to kind of eclipse all of the other kind of degen more dystopian perspectives of the future. And we're going to get there by both talking about all these ideas and creating spaces for implementing those ideas, creating spaces for showcasing those things and once we find things that work, pour tons of energy and resources into scaling those to cause massive change. The basics of all this is that everything is about coordination. So humans are social animals. Humans have been building many different kinds of institutions over millennia that are basically about different ways of coordinating parties to achieve various goals from early hunter gatherer tribes or even before that PACs and families and so on all the way to modern nation states and modern crypto networks and so on.
00:21:30.732 - 00:22:40.080, Speaker A: There's many different ways of coordinating across many layers of the stack and you can even go into biology and think about coordination in terms of an integrated system that is a body and an integrated system that is one of the major organ systems or the organs themselves or the cells and so on. So everything is about how to coordinate different kinds of pieces of a large system to get to certain objectives. The cool thing is that crypto econ gives us massive levers to coordinate the planet. So what is crypto economics? It's a field of study that involves many different tangential disciplines. So things like economics itself, things like cryptography, things like game theory, mechanism design, optimization, control theory, all of these kinds of things blend together into crypto economic systems. Mechanism design is really useful. The way to kind of think about it is that game theory is the study and theories behind studying some incentive structure and understanding what the strategy landscape looks like for a set of agents in a game.
00:22:40.080 - 00:23:47.032, Speaker A: Mechanism is game theory in reverse, where you set a goal and you're trying to create mechanism and analyze landscape to figure out how you need to warp the incentive field to achieve that outcome. So it's kind of like applied game theory with specific sets of goals. Now with crypto we can lean into building systems like that that have all kinds of malicious parties and coordination failures and so on to sort of get there. So what is regen cryptoecon? Regen cryptocon is about building systems that are not just kind of that are certainly not extractive and are not just resilient and sustainable but they're also regenerative. They have all kinds of positive externalities to the systems around it and you try to minimize the negative externalities to try and sort of create these holons that are just kind of emitting value and emitting energy. And if you can create systems like that then you can scale them up over time coordinate between systems like that and over time lift massive problems. So let's talk about coordination failures for a moment.
00:23:47.032 - 00:24:55.196, Speaker A: Coordination failures are kind of at the core of many of the problems that we have today. So everything from something as large as nation states fighting over resources and fighting about the nuclear arms race and the build up, there was a massive coordination failure between the two largest macro coordination systems that we had. We have much more, much smaller examples like maintenance of software, maintenance of infrastructure, taxing systems where the tax money actually goes and so on. So the world is rife with coordination failures and often a lot of it comes from lack of knowledge. Often a lot of it comes from lack of mechanisms that arrive at a good incentive structure for all parties in the system. So there's a set of memes around Moloch which I think came from Slate Star Codex's Meditations with Moloch, which is an essay that kind of talks about all of these terrible coordination failures that are really at the core of all major problems in the world and sort of try to imagine some demon god of coordination failure. And that's what moloch is.
00:24:55.196 - 00:24:58.748, Speaker A: So if you've heard of Moloch, Dao and Slaying Moloch and so on, that's.
00:24:58.764 - 00:24:59.216, Speaker B: What it is about.
00:24:59.238 - 00:26:25.192, Speaker A: It's about like, hey, humans tend to respond better by visualizing an enemy and trying to fight it. So let's name that coordination failure, god, Molok and so on. And the Web Three movement is kind of like leaning into those medics and saying, great, we're going to use Web Three and all of these amazing mechanisms to Slay Molok and so that's where all that comes from. And the Green Pill movement has this really nice pipeline of taking the super fast growing and super capable and super amazing crypto community and go from the early incentives that bring a lot of people into crypto that are kind of like exiting or trying to improve on other financial systems come into crypto because of that. And then over time they sort of realize the potential of the potential of crypto and the potential to become region and that's kind of like how things flow. At the end of the day, what we're trying to break coordination failures for is to kind of build a drastically better potential future usually mediated by all kinds of public goods that we need to generate to help humanity flourish, help other species flourish and achieve a good long term progress. So let's kind of look at game theory and public goods for a moment.
00:26:25.192 - 00:26:56.790, Speaker A: So who here knows what a public good is fully well and doesn't need a definition? Great, most people. So the idea is most goods that you buy and you pay some money for, some currency for and you purchase and you can use is a private good. These are tend to be excludable or rival risks, usually excludable and rival risks. Excludable means that when you use it, somebody else can't use it. So software is not like this ideas are not like this. You can have an idea, you can tell it to me. Now we can both have that idea.
00:26:56.790 - 00:27:37.772, Speaker A: Rivalry means that I think it's when you use it you get to yeah, sorry that's rival risk excludable is that you can, you can or cannot toll it. So for example yeah, mistake. Let me rewind definition. So when I consume it and when when you consume it that's rival risk excludable is whether or not we can kind of like cordon off the good and toll people into it. So for example, the air is not really excludable. A public pool that you can build a fence around is excludable. So you can create a toll booth for people coming through and you can exclude the participation.
00:27:37.772 - 00:28:23.372, Speaker A: And so that's kind of public goods are kind of all of these large scale infrastructure pieces that are not excludable. So you can't toll them and you can't kind of build them with tolling and they're also non rival risks. Now the public goods notion is like kind of messy because what public are we talking about? Certainly access to specific good is not universal. Not everyone has access to the same good at the same level. So I like to think of network goods in reality which are goods specific to a network of parties that agree on some set of things. So think of like the ethereum blockchain, is a network good in a sense and so on. So with crypto, econ and web3 we can kind of lean on the fact that we know how to create incentives.
00:28:23.372 - 00:29:03.068, Speaker A: We know how to create incentive structures and deploy them into the network and start using programmable money to build these kinds of infrastructure that is going to fund many major kind of public goods. We've already built a bunch of crypto networks that are these public goods. We've already built a bunch of Dows that are causing some impact in the world. We can scale that up and cause many larger scales of impact. So great. So let's go into coordination games for a moment. When you kind of study some incentive structure in a coordination game, you end up with this is kind of like a traditional game theory style analysis of a game where you can think through the different parties, you can think of their payoffs and so on.
00:29:03.068 - 00:30:01.520, Speaker A: And there are classic games that show coordination failures. Very famously kind of the Prisoners Dilemma has this classic kind of like defect, defect equilibrium where all parties tend to defect even though all parties would be better off if they coordinated. All this study of these kinds of games enables us to turn zero sum games where you have fixed resources into positive sum games where you can tweak the incentive structure. You can use mechanisms to orient people towards coordination, towards growing the pie as opposed to fighting for the pie. So in general for most of the universal resources. You can generally either encounter some conflict and fight for splitting some set of resources or you can focus on growing the pie and growing the resources. And we'll get a little bit more into that in a moment with prioritopia.
00:30:01.520 - 00:30:57.312, Speaker A: Once you start constructing simple incentive structures and you start scaling them and composing them and building larger systems, you start building incentive fields. And you can think of these as large scale surfaces that you allow parties to dynamically optimize through. So for example, you can coordinate larger and larger groups of people by building these open ended permissionless incentive structures that all parties can see and can engage with and so on. And you can coordinate large action by creating a different equilibrium. Most of the time when you are frustrated about some problem in the world and you kind of start thinking about it, start analyzing it and usually you'll end up finding some broken equilibrium. And usually it'll be people are just stuck in some basin. And usually a lot of people in that basin know that it's very possible to arrive at a different basin that is much better for everybody.
00:30:57.312 - 00:31:42.210, Speaker A: But people can't coordinate their way out of it. It's very difficult for individual parties to kind of get out of it. There's a great book called Inadequate Equilibrium that goes deeply into this and kind of why those basins form and why it's very difficult to get out of it. And the gist of it is you end up in a structure where there are multiple different parties that have different strategies and if one of them starts taking a different, more pro social attitude, it's easy for the other parties to kind of take advantage of that. And so it's difficult to coordinate everyone out of that basin at the same time. But with cryptoecon, by creating mechanisms you can start warping that surface and maybe moving, destroying the mountain in between those two basins to enable everyone to flow out. So that's kind of the major promise of the whole thing.
00:31:42.210 - 00:32:52.736, Speaker A: There's many kinds of great economic theories that we can rely on. The Eleanor Ostrom's principles for managing a commons is a great example, being able to kind of reason about how parties can use a commons and so on. And this is a great example of building robust incentive structures for managing the commons and for funding the commons and maintaining the commons, which was before Ostrom, a kind of kind of open problem and intractable problem to solve. So where a lot of this is headed, at least right now in the web3 space, is that many times major problems have many people that know how to solve the problem and know how to create solutions, but they're lacking the time and resources to implement those solutions. So a lot of times today in 21st century, what many of those groups need is funding and funding at larger scales. So funding is one of the easy ways to solve a lot of these problems, finding structures that can fund those groups. Now you have to make sure to understand what the impact of that funding is and whether or not that's incentive aligned.
00:32:52.736 - 00:34:26.244, Speaker A: And so you have to create funding structures that can measure impact and then cascade that. But at the end of the day, you'll see a lot of the ideas right now in the last few years and probably in the next few years will relate to how do you fund larger and larger impact groups at various different kinds of scales. And so a lot of a study right now is around different kinds of distribution models for funding that how do you get funding to the groups that have the best ideas for how to solve problems, the best or the most effectively, fastest and most distributed around the world and so on. And then there's a whole set of study around as you're scaling funding to groups, how does that perform, what is that impact, could you do better? And so on. So you have a capital deployment and maybe assessment of how the capital is being deployed but you now need to kind of create a feedback mechanism to be able to generate more and more capital to fund at larger and larger scales. So this is where things like the sort of value generation of crypto networks in general can be hooked into these mechanisms, right? So if you have a system that is funding public goods and we all know that when we have these goods we can get more capital for other reasons. For example, the fact that these blockchains exist enable us to build monetary systems and make it enable businesses that enable cash flows and so on and money generation, then you can feed some fraction of that into funding the public goods themselves, right? So in a sense this is kind of what nation states do.
00:34:26.244 - 00:35:22.340, Speaker A: Nation states do that kind of feeding they tax societies and take some fraction of that tax and feed it into funding of public goods like science and so on. And that's kind of like from an enlightened perspective of saying great, we know these public goods are really valuable long term, let's take some of the proceeds of the society and fund these larger public goods. The problem is that the funding structures in these groups are not that great and they're not scaling with the capital generation elsewhere. We'll see that in a moment of how the science funding has not kept pace with the GDP growth of the world and there are major problems in between. How do you go from science into technology and broad diffusion? So there's all kinds of mechanisms that people are exploring. So everything from quadratic voting and conviction voting, staking bonding curves and so on. I'll kind of like flash a few of these right now for you to explore.
00:35:22.340 - 00:36:09.424, Speaker A: A bunch of these ideas have been many of them have been proposed many decades ago, in some cases centuries. Some of them are very new. But what's really cool about blockchains is that you can now have a software system that enables you to broadcast all of these kinds of mechanisms and deploy them into the network at scale, right? So you're no longer rate limited. Before, crypto economists would have to come up with a mechanism, write a bunch of papers, and then start to try and convince large scale governments or large scale institutions to build that kind of mechanism and that kind of incentive field. And that's an extremely slow process in the crypto world. You can dream up a new incentive structure, deploy into the network, see what happens, study it, and then from there, scale it. Now that's also dangerous.
00:36:09.424 - 00:37:21.356, Speaker A: You can definitely deploy bad incentive structures so be careful but it gives you this very very powerful tool that you can use to understand the world, try to solve some problem and as an individual or a small group actually deploy a solution and if it's working then you'll get scale will follow. There's all kinds of problems and potential opportunities. I highly encourage you to check out the book. It goes into a bunch of these possibilities, and the book kind of finishes with a good notion of impact dows and kind of starts painting the future of potential dows formed around creating impact on some specific vertical kind of case. And the whole movement in general is kind of very oriented around this kind of, again, regenerative economics that are trying to orient and align incentives towards kind of maximal flourishing. Great. So I will now switch gears to so that's kind of the Greenville movement and region crypto and kind of the underlying technical foundations but also kind of the social and memetic structure around it.
00:37:21.356 - 00:38:23.052, Speaker A: Check out the book for more and get involved with the broader movement. Now that we have those strong foundations and we have a sense of the general goal let's kick it up a notch and now talk about pirate utopia. So at the end of the day I think we live in an extremely critical century and I'll convince you why. We've had tremendous global improvement over millennia and maybe tens of thousands of years and certainly in the last few hundred years we've seen by most indicators that we have about human well being and the well being of groups and so on. The world has been getting dramatically better life expectancy, poverty rates, health and so on. By most measures the world is getting dramatically better. It doesn't feel that way because our media and other systems are kind of co opted by interest groups that push all kinds of conflict memes to try and achieve outcomes.
00:38:23.052 - 00:39:14.156, Speaker A: But in general most groups that take this longer view and longer view of study can point to just the world getting dramatically better over time. However, we're also faced with extremely large challenges this century can I think I missed a this one first we're faced with x risks, which are these existential risks that might wipe out the species. So for example, there are these major nation states with nuclear weapons there's. One of them is like in a war right now. And for a while there, it looked really scary, still scary for a lot of people, and this still could escalate. We also have a massive disaster around climate change. We have potential problems around biotech, potential problems around AGI.
00:39:14.156 - 00:40:36.270, Speaker A: So all of these are major technological improvements that because they enhance our capability, enhance our capabilities, it has great positive potential and also great negative potential. So that this creates the possibility of coordination failures that get us into a really bad state. So this is why we need to create very strong coordination structures to achieve really good outcomes. And so the reason this century is extremely critical is that while other x risks which are natural so things like supervolcanoes or asteroid impacts or supernova and so on, the scale and timing of those is so large that we'll likely kind of colonize the planets and go out to potentially other stars before one of those things happens. However, in this entry, there are major, major x risks that we have to make it through. And one of those is the kind of computing phase transition. If you kind of look at the history of computing and you think of the last 80 years and how decade over decade, computing infrastructure has improved human life, and you sort of start projecting that 80 years in the future, a lot of the tech that we've known about and we've dreamed about for the last few decades will likely come to pass.
00:40:36.270 - 00:41:28.840, Speaker A: Computing is one of these kind of interesting things that is so fundamentally powerful and it's such a tremendous physical process that once we've been able to harness it, it's going to rewire what we are. Computing is not like about digital computers on its own life. Living systems are a computing system. Neural and memetic systems are a computing system. Digital computers are a computing system. All of these things have the three kind of like major events in the planet in the last 4 billion years, are different layers of computing stacks. So this transition is super dangerous because if we get it right, this could be phenomenally great for the whole species and it can lock in this amazing open ended progress.
00:41:28.840 - 00:42:35.264, Speaker A: However, we screw it up if we build things like brain computer interfaces, things like AGI and so on, are extremely powerful technologies that if we misalign them or don't broadly diffuse them and so on, they could spell catastrophic outcomes for the species. So there's an extremely critical century. And one of the weird things here is that early on in computing's history, we got the implications of building computing machines and computing machines that can think and so on, sort of generated a ton of Sci-Fi that kind of helped us view potential futures. And so we've gotten this very rich cultural set of memes that can paint various possible pictures of what the future might look like and force us to contend with implications. Unfortunately, the Sci-Fi perspective has like, because it's science fiction, the world finds it really easy to just dismiss all of those ideas as just purely fiction. And yet we're just marching decade over decade straight into this brain. Computer interfaces are not that far away.
00:42:35.264 - 00:43:37.750, Speaker A: They're probably on the order of like ten to 20 years out from being able to actuate most computers directly from your brain or later on connecting brains together and so on. AGI is very unclear. The building of AGI has been predictive for many, many decades and those timelines were always over optimistic. But now most of the experts have radically shrunk their timelines. In the last 1015 years, we've gone from most experts thinking somewhere between 53 hundred years down to somewhere between ten to 30 years. And that timeline shrink is alarming because if we don't get this right, could be bad. So with all of these things so like an enormous global improvement, very scary x risks that we have to avert that are stemming from coordination failures and this really important computing phase translation that we're engaging in.
00:43:37.750 - 00:44:18.736, Speaker A: Unfortunately, our current macro systems are not very adequate to help us solve these major problems. These were really great for getting us here and getting us to this point and driving a lot of the improvement, but they're not able to contend with these cancel coordination failures and they're not able to contend with something like a phase transition like what computing is causing. So hopefully the picture is clear. This is a very, very critical century. Now what are we going to do about it? The good news on all of this is that just in time, we have figured out extremely powerful coordination tooling. All of these potential failures stem from coordination problems. These are macro scale coordination problems.
00:44:18.736 - 00:45:20.624, Speaker A: But you can usually break down macro scale coordination problems into smaller and smaller pieces that you can then meaningfully contribute to and meaningfully solve. So let me introduce you to a kind of concept called paradotopia and then kind of give you a tool set for how you can achieve large scale improvement by kind of breaking down those problems. There's a great talk called pirate topia and goal alignment from Drexler, who's one of the kind of inventors of a lot of the crypto stuff that we use today. Drexler and Eric Drexler and Mark Miller kind of in the wrote the Agoric papers which kind of described computing with markets and currencies and the ability to kind of like trade resources and having digital money and so on. And it just took a very long time for those ideas to percolate and make it into our global systems. And now get scaled. And so part of what they talked about was that there was this concept of paradotopia and it's really useful to kind of visualize that picture.
00:45:20.624 - 00:45:58.816, Speaker A: So imagine kind of a very simple resource sharing structure. So you can think of two agents, a and B and you can think of just one resource. Like there's just the uniform notion of all resources. And this is the picture of a serial sum game where they're kind of like trading off resources perfectly. Let's kind of plot it on a log scale so that bulges it out. That takes that straight line and bulges it out, which is useful to kind of visualize growth in a moment. And then most people kind of now, in the last 150 years have recognized like, hey, actually most resource growth is not most resource taking.
00:45:58.816 - 00:47:02.020, Speaker A: Creation is not a serious game and in reality, instead of conflicting with each other, we can coordinate and we can arrive at kind of broad resource growth. We can grow the pie instead of kind of compete for the pie. And so you end up with this really nice kind of pareto frontier is like that line of the potential kind of choices that people might make and they can coordinate to try and grow the resources. But most kind of systems and governments and so on are built upon this kind of picture where growth is kind of a small fraction of what you have now. You're kind of like growing at 5% a year or 10% a year, 50% a year. But when you zoom out, the reality is that we're growing at in terms of many orders of magnitude. When you think of something like as pivotal as Germ theory and the ability to kind of have sanitation and understand microorganisms and them as a cause for disease and then kicking off all kinds of health innovation systems, that creates a massive scale of improvement.
00:47:02.020 - 00:48:13.630, Speaker A: Same thing with communication technology, being able to kind of go from a world where you had to send letters to each other to suddenly having the telegraph and then the telephone and then radio and then the internet, that kind of growth creates orders of magnitude, more resources and so on. We don't see this in most of our measures like GDP and so on, because those measures tend to just look at what people are willing to pay currently, which create this structure, where once you create a lot of value that is broadly diffused. It's sort of like nobody will pay anything for it because it's just so cheap that GDP doesn't capture this kind of growth. So if you were capturing this kind of growth, GDP would be like many orders of magnitude of growth every century or something like that. So this is kind of like the fundamental idea here, which is that if we coordinate to scale our resources to do the kind of deep science work and deep technology. Translation work and deep product diffusion work to get all that tech out there. We can get into this much faster pathway to growing the well being and resources for the species and for many other species for all of life and so on.
00:48:13.630 - 00:49:03.784, Speaker A: So that kind of perspective here is what prior topia is about. One critical thing here is the difference between parties, once you put it in these terms, the difference between parties taking more or less or whatever is kind of like negligible compared to sharing and so on. So it really is kind of like this forcing influence to get everybody to kind of agree to just coordinate as opposed to taking more and so on. And it's also worth pointing out that when people get into conflict, they destroy a lot of resources and they hold each other back and they prevent progress or they could wipe out the species. And that risk profile in reality is much more pronounced than this. That red line should really be kind of like going from zero bulging out all the way out and back. It's kind of like a scarier picture of the diagram.
00:49:03.784 - 00:49:49.048, Speaker A: So the question is, how do we get there? How do we go from where we are today to that paradotopian potential crypto econ? That's how we get there. The crypto economic stuff that we were talking about is extremely powerful. So the crypto community in general thinks of this as really powerful and so on. We know kind of how cool programmable money is and how cool incentive structures are and so on. But in reality, it's way deeper than that. At the end of the day, all of these systems, from nation states to tribes to families and so on, they're just coordination structures. And what we have now is a way to marry the digital computing platform that we have that is broadly diffused in the world with programmable incentive structures and programmable coordination structures.
00:49:49.048 - 00:50:24.490, Speaker A: And so that is just super, super powerful. It can rewrite all of our economic systems, it can rewrite all our government systems, it can rewrite all ways in which humans coordinate. And so we're going to be seeing this kind of major improvement diffuse into major different parts of our life, into different verticals and so on over time. So this is an extremely powerful stuff. This is a massive lever by which to kind of move mountains. This is a major tool by how we can solve those large scale problems. And just to kind of put it into very clear perspective, just think of the Bitcoin hash rate.
00:50:24.490 - 00:51:17.784, Speaker A: Before Bitcoin started, there was no Bitcoin network. When Bitcoin started, it had a few computers chugging away and burning a lot of hashes and so on. And the incentive structure did two things like the block reward incentive structure did two major things. One is it got a lot of people interested in this currency and gave them a little bit of the currency and it broadly diffused. That emission rate enabled the currency to be distributed to a lot of people and it created an incentive structure for paying the people to maintain the currency itself and paying the people for adding security to the network and so on. It also helped broadly diffuse the currency to a lot more people. But it had this kind of unintended consequence because that incentive structure was so powerful and the computing power that had to go into kind of mining each block is just kind of it absorbs any amount of power you throw at it.
00:51:17.784 - 00:52:00.724, Speaker A: It created this runoff equilibrium for consuming as many resources as possible to secure the ledger. And so this is just kind of mediated by the price of Bitcoin. If the price of Bitcoin goes higher, more energy goes into securing the ledger. And so in a few short years, we've gone from like a tiny little network with maybe initially 110 and so computers to now one of the largest energy consuming processes on the planet. And in that timescale it also had to kind of create the notion of virtual currencies and cryptocurrencies and so on. It had to create the entire crypto movement in its wake and so on. So that process was slowed down.
00:52:00.724 - 00:52:35.360, Speaker A: You could redo something like this much faster now and I would guess in two to five years you can get something of this scale. And that just gives you a sense of how powerful this open and permissionless incentive structure is. We've gotten a taste of it with the Falco network. In a year and a half. We went from no storage in the network to 1516 exabytes, which is an enormous amount of storage capacity. So you go from bytes to kilobytes to megabytes gigabytes terabytes petabytes and then exabytes, which is an enormous scale increase. I might have missed one.
00:52:35.360 - 00:53:38.310, Speaker A: I think I got it right. But the point is an enormous network appeared because of that incentive structure. So it just gives you a sense of the scale of change that you can have on the world by designing a good incentive structure and deploying it into the network. One important thing here is, is this the sort of scale that now this is at the scale of major computing platforms like Google Cloud and Azure and so on, it's within like one or 2 hours of magnitude, which is totally super close. And that's where you can get with a year and a year and a half and a super powerful incentive structure that is just coordinating that kind of network. So the optimistic view on this is like you can use these incentive structures to cause coordination at that scale and solve major problems in the world. So let's go back to this kind of like mechanism design view of hey, you have some complex surface area.
00:53:38.310 - 00:55:11.540, Speaker A: I wanted you to kind of use this tool set of whenever you're encountering some large scale problem, break it down into trying to visualize the incentive field and trying to think of what basin are people stuck in, what other basin could be better? And how do you get people from the basin they're stuck in into that better basin and use the magic of cryptocurrency to kind of warp the incentive structure to enable the people stuck in the higher basin to flow into the lower basin. So kind of like one way to think about this is you have your crypto economic toolkit which is represented here by like a tunnel boring machine and you're going to bore a hole from one of the basins into the other and kind of create the potential for all of that energy to flow. So with a large problem you can break it down into smaller things and keep making it basin to basin to basin to basin, create incentive structures along the way and that way it solves macro scale problems. And so this is how we can get to this private sopien vision. This is how we can solve these major scale problems by coordinating humans at grander and grander scales. We don't have to convince everyone in the world, we don't have to convince nation states, we don't have to convince various governments, we can create incentive structures that are well designed and that way kind of cause action at various different scales of the network. So think of like a picture like this, this is how we get to prior to topia so it's extremely critical century.
00:55:11.540 - 00:56:18.932, Speaker A: This is how we can solve those major problems, coordinate out of those x risks and make sure this computing patient station goes well. So now I'll break down a couple of examples with you to kind of give you a sense of how to apply this thinking and then we'll talk through some ideas and we'll end with how to get involved. So think of a massive problem like how do we get the planet to go green and start being carbon negative and start fixing a ton of carbon on the planet? Well, you can get there by first creating a green industry. So if most of the industry in the world becomes green, then we can get pretty close to a green planet. You can do that if you have one industry that you can point to that is being phenomenally green, not just carbon neutral but carbon negative. That is like actively fixing carbon in the ground at great rates. If we can cause that to happen in the world, that industry will be looked at by many other industries as a strong competitor and they'll be kind of forced to adapt to what that industry can do or those industries will wane because people will select these other processes to go to the much greener potential.
00:56:18.932 - 00:57:23.192, Speaker A: So how do we turn crypto into a fully green industry? Today we have things like the bitcoin process, we have many other proof of work networks and so on that are not green and are consuming massive amounts of resources and carbonizing the planet. So the way we can get all of green crypto is if we get a few crypto networks to become fully green and start decarbonizing themselves and becoming carbon negative and create incentive structures for the other crypto networks to follow suit, to adapt themselves to do the same thing that these other crypto networks that are much better are doing. So great, let's do that with one. This is what we're doing in the filecoin project. We're making a green file coin so that we can be the greenest possible blockchain to then kind of help drag all of the other blockchains along with us. And so how do we get there? Well, we start first by thinking about the source providers which are the main parties that consume a lot of energy. There are many other groups as well, like let's start there and enable source providers to be fully green and get to the point where all storage providers in the network are not only carbon neutral but carbon negative.
00:57:23.192 - 00:58:01.880, Speaker A: If we can get that going, then we can get the entire filecoin network to be green. If we can get that to happen, then we can get other blockchains to become green. If we can get all of crypto to be carbon negative strongly, then we can shift the entire industry world into that. And then if we can do that, then we can get to decarbonize the planet. And this is the kind of thing that if you can think of each one of these circles as achieving that on like a two to three year timescale, you could get out of this in ten to 15 years. You can get to sort of become heavily carbon negative. Might take longer, but if a lot of us kind of work on these pieces, we can get there.
00:58:01.880 - 00:58:33.700, Speaker A: And you can think of using collaborative competition at each layer of the stack here to cause that kind of incentive cascade. So let's kind of break that down, be super practical. How do you do that? How do you take a crypto network and make it carbon neutral? So let's use crypto incentives. You can do things like measure the energy use, estimate the energy use of a particular source provider. You can create a lower bound and upper bound. You don't have to measure it perfectly. We'll get to measure it perfectly once we kind of add some devices and so on.
00:58:33.700 - 00:59:38.872, Speaker A: But right now we can just estimate it and just take the upper bound and say let's just assume that we're like in the worst possible case and then after that, if we're doing better than that, we can adjust. And then once you have that measure, you can then offset all of that or get renewable energy to be produced at exactly the same moment in time as you're pulling it out. Of the grid. So the energy grid is this really cool system where all of the plants are pumping the energy into the grid at the same time, and all of the users are pulling energy out of it. So it makes it really difficult to trace who you're getting your energy from. But if you, as a consumer of energy buy renewable energy credits from specific plants at specifically the times that you're drawing the energy out, you can make a very credible, verifiable argument that as you're pulling the energy out, you're paying for renewable energy to be put into the grid precisely at the exact moment in time in which you're pulling it out. Now, if you do that, then you have a very strong verifiable claim that your entire operation is operating on renewable energy and it is a green process.
00:59:38.872 - 01:00:47.490, Speaker A: Now, instead of just paying for that amount, you pay for like five times the amount of energy or ten times the amount of energy, you now have a multiple you now have a way of saying when I pull energy out of the grid, I am paying for five times the amount of renewable energy to go into the grid. So it gives you a facility to become not only carbon neutral, but carbon negative. And so if you can look at all the storage providers on the Falcon network and one by one figure out which grid they're in, and one by one start a rec buying process in that area, you can make all of the SPS in the Falco network become not just carbon neutral, but carbon negative. And then we are done with the first and part of the second circle, and then from there you can scale it up to other parts of the network and kind of treat each increasing circle. We're kind of in part of this process, so it'll take a while. Yeah, this is a pretty interesting problem. And there's all kinds of areas where crypto tooling and verifiable claims and zero knowledge computation and so on can come in to help this entire structure get much more verifiable, much more verifiable green.
01:00:47.490 - 01:01:32.332, Speaker A: And then you can use programmable money to cause all kinds of action. I'm going to maybe fast forward through to get to the science one because I want to cover that one for a little bit. And yeah, if you want to get in, you can check out all the dashboards. You can get involved with this project. A big part of causing this sort of change is that not only do you have to have a technical solution, you have to create a large scale social movement that enables a lot of other parties to participate, to come up with more ideas, to improve the system and to then scale it, to copy it to other places and to scale it. So think of all of this as generating public goods that many parties in the world can learn from and can use and so on. Cool.
01:01:32.332 - 01:02:36.624, Speaker A: So let's go into accelerating progress. So a lot of this global improvement that we talked about at the end of the day has been a consequence of the science and technology process. So science is the process that humans use to expand our knowledge, to get to know more about the universe. And the technology buildout is about building tools and systems to leverage that knowledge to increase our capabilities on the planet. So these are kind of two sides of the same coin. And part of the reason the Internet has been so impactful is that at the end of the day, what it really is, is a way of doing this process much faster and kind of letting it feed back on itself at a greater degree. So if we want to kind of accelerate global progress and accelerate the rate at which we're solving tons of problems, one thing you can do, one high leverage thing you can do is you can think of the entire pipeline from basic science to fundamental development to designing devices that put those ideas into kind of early notions of technology and then get all the way into products and diffuse that into that technology, into the world.
01:02:36.624 - 01:03:25.104, Speaker A: And you can think of that entire pipeline and create incentive structures to fund it at better scales, to create this regenerative crypto econ loop. That where you're taking kind of outputs at the end of the pipeline when you're able to kind of create a lot of cash flow and then feed it back through the entire process at every point in the way to accelerate the diffusion of basic science all the way through that pipeline to the end. Today, the funding scales for basic research and basic fundamental development are not great. We'll see them in a moment. And especially in the middle, in this research development part, there's a huge chasm. So there's a missing set of coordination structures that enable this technology. Translation and many times many of us can imagine many problems that we are frustrated by in the world.
01:03:25.104 - 01:04:05.768, Speaker A: And we know that there are communities out there that know really good solutions and have like you can find tons of papers and you can find tons of solutions discussed and yet those solutions haven't made it into technology, haven't made it into products, haven't been broadly diffused. Something has happened along the way where some of those efforts just got stuck somewhere. They didn't make it all the way. Sometimes some ideas don't make sense or they're not as effective as others, but many times what's going on is some idea is getting roadblocked and there's no funding to enable the people that want to get it to completion to actually do that. Or there was some funding, but that team failed. And you need a much more robust approach where you're funding many teams at the same time or in sequence to make that technology transition. Happen.
01:04:05.768 - 01:04:50.060, Speaker A: So this problem exists because there's no good way of creating profit structures in the middle here. The incentive fields here are broken so we can use region cryptoecon to fund this. So you can think of the whole science funding structure and funding scale and this kind of what I mentioned about hates big but it's not that big and that has roughly remained similar decade over decade. It has increased a bit but not dramatically. This is just the US and this is one of the biggest circles on the planet. China is now really big, it didn't used to be that big so it's a good sample of the amount of funding in the world that is going towards R D. You can use crypto to scale this.
01:04:50.060 - 01:06:08.164, Speaker A: So crypto is not that big yet to be able to kind of fund this year over year but if crypto gets one or twoers made to larger we're basically there crypto is going to be able to fund R D at the scale of nation states and that is massive. That kind of shift could be transformative for the world. If suddenly, as a scientist or an R D person and so on, you can get funding not just from the NSF, NIH or the equivalent agencies in other countries but you can now get funded by crypto networks at this massive scale that could just ripple through the entire system to solve major planetary problems. And if you kind of don't just stop at the early beginning the way that the modern nation states do, but you kind of create incentive structures throughout this pipeline to help push things along. That entire chasm to make. Sure that there's a really solid incentive field through this whole thing, then we can really scale up the technology translation pipeline and at that point get a lot of the big solutions that we need in the world actually implemented and scaled and way to kind of visualize these things. That's helpful is like think of large scale projects as again breaking down into smaller things and you can get a lot of action to happen if you have a reliable way to kind of start small and scale up.
01:06:08.164 - 01:06:49.612, Speaker A: If you have ways of starting small projects, prove them out and scale them, then you can be in a really good place. And part of the reason we have so many scaled up startups and products that have for the last 20 years had these super fast growth rates is because we have a phenomenally good capital structure in private funding where you can do this kind of scaling at every step of the way. So it's very easy for groups that are very close to a product to get funding at larger and larger scales to be able to achieve this outcome. But this is not the same for public goods. Public goods has a pretty broken funding structure where in the smaller scales it's massive. There's just tons of money flowing into charities. A lot of that funding is lost.
01:06:49.612 - 01:07:27.250, Speaker A: A lot of that funding is even negative. There's like bad accounting of the impact of that funding. And then once you start getting into larger scales, there's fewer and fewer and fewer funders and you get to certain scales where there's just no funding available. This is why we have this concept of fusion never where fusion never got the funding it needed to actually get done and research in time. We're finally breaking that, but it took like 40 years more than we needed. And so if you can create a funding staircase for public goods similar to this one at similar scales, then we can be in a much better place. The scale here is massive and this is all a decentralized system.
01:07:27.250 - 01:08:17.388, Speaker A: The private venture capital system is all pretty decentralized with many different actors that are part of this incentive structure, incentive field that enable them to kind of collaborately, compete to fund startups in better ways and so on, and larger scales. Can we create a similar kind of structure for a funding staircase for public goods? I think one of the highest leveraged ways to impact the major problems in the world is to do this. And you can do it with crypto econ. You can do things like create new funding structures, new grant programs. You can take things like what Getcoin is doing and scale it up. Like go from the quadratic funding type structures that work really well for the small crypto projects and scale it up to build out entire crypto networks. Or scale it up to do science research and scale it up to do full technology translation.
01:08:17.388 - 01:09:00.968, Speaker A: You can come up with better mechanisms to pair the funding proposal structure with the impact and so on. And so you can use the cryptoecon tooling to greatly improve the structure. You can even think of things like patreon and so on as like examples of doing this. So there's a whole field of potential design here and there's a bunch of groups now starting to actively pursue these kinds of things. So I greatly encourage you to get involved. We're now at time, so quick question, is there another speaker that is about to jump in? Great. So I'm going to pause here and maybe conclude with hopefully I've given you a bunch of different region ideas.
01:09:00.968 - 01:09:35.450, Speaker A: I'll be out there and we can talk more if you want to explore more. And the last thing is get involved by going to the conferences and communities that are talking about these region ideas. Go listen to the Green Pill podcast, go watch the videos from Shelley Point that happened two days ago, go to the next one and come to Funding the Commons, which is happening in June. Great. So let's all make it by aligning ourselves towards the paratopian outcome and solve the large scale planetary problems with crypto. Thanks.
01:12:13.070 - 01:12:20.320, Speaker C: All right, can we start? Yeah.
01:12:22.450 - 01:12:23.200, Speaker A: Okay.
01:12:23.990 - 01:13:40.490, Speaker C: Hi, so my name is JOA Vice, I'm from the Ethereum Foundation and I want to talk today about account obstruction and ELC four, three seven. So first, what is account obstruction? Account obstruction means that instead of using an externally owned account, which means an account that's directly associated with the private key, you're using a contract wallet. And this contract wallet can be controlled by a key or multiple keys, but it could also be controlled by an arbitrarily complex mechanism that is encoded in the contract. So this enables use cases such as social recovery, which means that if you lose your keys, you lose access to your wallet. Your friends can sign a special message with their keys to help you recover it. Or you could use complex access controls such as multisig in the context of your wallet. It also allows you to switch even to different signature schemes such as moving to BLS or to quantum resistant signatures in the future, which is quite useful for Ethereum.
01:13:40.490 - 01:14:40.106, Speaker C: And it allows you to do things such as batching, such as batching multiple operations. So for example, let's say you want to trade an ERC 20 on uniswap. When trading, you don't need to approve and then to do a transfer from you can bundle both of them together in one core. So account obstruction can be quite useful. It can also do things like gas abstraction. So gas obstruction means that a decentralized application can pay for its user's gas it can sponsor so that the user can be onboarded without buying ETH. This can be useful in various scenarios, and it also makes it possible for the user to, for example, pay for the gas with some tokens instead of having ETH.
01:14:40.106 - 01:15:43.940, Speaker C: And behind the scene, the contract will change the token to ETH in order to pay for the transaction. So the user doesn't need to know anything about ETH if he has tokens. And let's say you have a gaming application, you have a blockchain game, something non financial, and the user doesn't own any crypto you want to onboard the users that are not crypto people. So they can pay a service provider by credit card just for sponsoring their gas. But this centralized service doesn't control the transactions. It can't say anything about what the content of the transaction should be, it can censor it, it can only pay for the gas. And it enables some more complex use cases, such as private withdrawals from ZK roll ups and from zero knowledge mixer such as Tornado Cash.
01:15:43.940 - 01:17:03.050, Speaker C: Currently, if you want to withdraw money from something like Tornado Cash, you need to have ETH in the withdrawal address in order to send a withdrawal call. And this could de anonymize you because it associates an address that already has ETH with the address that's performing the withdrawal. And right now there are centralized solutions like a centralized relay that helps you perform the withdrawal, but then the relay knows about you. So with account obstruction, this becomes decentralized and doesn't de anonymize you, because the withdrawal operation can pay for itself. You can have a paymaster that looks at the withdrawal, that looks at the withdrawal, it sees that it's going to be successful, so it will perform it it will perform the withdrawal for you, take the cost of the deduct, the cost of the withdrawal, and give you the rest. Which means that you end up withdrawing to an address without associating it with anything else. It makes some interesting use cases that are very popular these days, such as cross chain operations, because it means that you could do things like cross chain trades without having to hold the native currency of both chains.
01:17:03.050 - 01:18:11.150, Speaker C: So now that we see what account obstruction can give us, why now? Why again? Ethereum already had its fair share of account abstraction attempts. There were many attempts to figure this problem out and the problem is that it's very complex. It's very complex and it's hard to agree because all of these attempts require changing the consensus or changing the protocol. So what's different about this is that it's an ERC, there's no protocol change, which means that it can be immediately used on any EVM chain, no need to wait for a hard fork. And this allows us to start experimenting with account obstruction without committing to a protocol change. So we can start experimenting and iterating until we see that we have something that everybody likes that satisfies all the requirements and there are no problems. So the end goal is to reach a situation where we can drop EOA altogether.
01:18:11.150 - 01:18:47.194, Speaker C: We no longer need externally owned accounts and everything is account obstruction. But in order to take the first steps in that direction, we need a way to experiment. And, ERC, four, three, seven is the way to start these experiments. So this is our first step. So how does it work? Instead of using normal transactions, we created a new abstraction level above that which we call user operations. And these user operations live in a separate mempool. They live in a separate mempool.
01:18:47.194 - 01:19:54.786, Speaker C: And there are bundlers that mine this mempool. They take user operations, they check that these operations are going to be paid for and then they send the bundlers, put it on chain through a global contract called Entry Point, which delivers it to the contract wallet and the bundler gets paid for it. Now, this is permissionless. Anyone can be a bundler, including the I mean, the user can be its own bundler or anyone else can be, but the natural fit is that it will be miners or post merge. It's going to be block proposers or validators. So the miners will probably participate in this additional mempool and will mine user operations. As we can see here, users just sign and assign user operations and put them in this user operation mempool, where bundlers take it from.
01:19:54.786 - 01:20:39.374, Speaker C: There and put it on chain as long as they see that they're going to get paid for it. So I'm going to go through the flow of such bundle from the moment it's sent by a bundler until the operations actually happen. I'm starting with the simpler flow where there's no gas abstraction. So the bundler built a bundle of one or more op. So let's say it puts some user operations inside a bundle transaction. It ran a simulation locally, it saw that the bundle is going to be successful. So it puts it on chain, sending it to the entry point.
01:20:39.374 - 01:21:23.150, Speaker C: Now, the entry point contract, this is a single tone, there is one on the entire chain. And this entry point starts by calling the validation function of each wallet. So each wallet needs to implement a validation function and this function performs several actions. First of all, it does the access control, which normally means checking a signature. So it will verify the signature of the operation, seeing that it is really signed by the user. Then it also checks for replay protection, which in the current model means checking and non and incrementing it. And finally, it pays the maximum cost of the operation.
01:21:23.150 - 01:22:02.250, Speaker C: Just like it works for current transactions. You first pay for the entire, you pay the maximum cost and then you get refunded for the unused part. So the validate function verifies everything. Then it pays for the operation. And then Entry Point calls the wallets to actually perform the operations. So the wallets now get to perform the user operations to act upon the user's request. And after that and after each operation, the entry point also refunds the unused gas payment.
01:22:02.250 - 01:22:39.282, Speaker C: The part that wasn't consumed by the operation gets refunded to the wallet, just like with the current transactions. Now let's switch gear and look at what happens if there's a paymaster involved, which means there is gas abstraction. So now the wallet doesn't pay. It starts the same way. Entry Point calls the validation function and the validation function checks the signature. It increments the nons, but it doesn't pay. It is not asked to pay because there's a paymaster.
01:22:39.282 - 01:23:42.198, Speaker C: Instead, the Entry point now checks if the paymaster is valid and staked. And I'm going to elaborate on that in a bit, but let's assume it sees that the paymaster is valid and staked. So now it also calls a validation function in the paymaster contract and the paymaster gets to look at the operation and decide whether it wants to pay for it. If it wants to pay for it, it approves it. And now Entry Point performs the actual operation, tells the wallet, it gives the wallet an opportunity to perform the operation and the paymaster is charged for the amount. And now there's another optional step here because the paymaster might want to do something after it knows how much it paid on behalf of that user. For example, if it's a token paymaster where the user is paying with tokens.
01:23:42.198 - 01:24:53.220, Speaker C: So now the Paymaster wants to charge the user to transfer tokens from the user to charge for the operation. So the Paymaster could ask for a post op and in that case after the operation the Paymaster's post op function is called. So now the Paymaster gets to do its internal bookkeeping or to charge the user or anything else that it wants to do as this information. So in order to perform all of these duties, the entry point contract needs to have a few interfaces, it needs to have interfaces to serve the three different entities in the system. It serves the bundlers, so the bundler creates the bundle and it needs to locally call a simulate validation function which is how it checks that the operations are valid. And then it calls on chain the handle ops operation which performs the flow that we just seen. And the Paymaster paymasters have a stake as I mentioned.
01:24:53.220 - 01:25:39.010, Speaker C: So they need to manage the stake, they need a way to lock the stake, to unlock it and to withdraw it. So there's this interface and finally there's a deposit that is used to pay for gas. The deposit is owned by wallets or by Paymasters. So they also need a way to check their deposit and to check the deposit to deposit more into it or to withdraw it. So these are the interfaces that Enterpoint provides and if you want to build a wallet or a Paymaster, you need to implement certain interfaces as well. So the wallet implements a very simple interface. It has just one function, it's the validate user op function.
01:25:39.010 - 01:26:45.830, Speaker C: This is the function that gets called during validation. It performed this signature check or whatever access control it has. It performs the non increment or any method of replay protection and it optionally pays for the transaction. Now the Paymaster has a similar interface with a validate function as I explained earlier and it could optionally have another function called postop where it charges the user or perform bookkeeping. So the entry point is a highly trusted component because it's actually trusted by all the wallets to perform. It actually tells the wallet what the user wants it to do. So the wallets must be really sure that they will only get something that really came from the user and it's trusted by the Paymasters to only charge them, to only charge them for operations that they really agreed to pay for and by the bundlers to compensate them properly for the bundle.
01:26:45.830 - 01:27:46.246, Speaker C: So there are a lot of security requirements. I'm not going to go through all of them right now, but we just finished a security audit with OpenZeppelin so the contract has been audited and I'm happy to talk about its security later if anyone wants. Another important security consideration that also affects the way you use the system is denial of service. Is the risk of denial of service against bundlers. So user operation relies. The validity of user operation depends on EVM state and that makes a pretty big attack surface against bundlers. For example, if someone can submit a large number of ops and then invalidate all of them at once, it means that there's going to be a lot of unpaid work performed by the bundlers.
01:27:46.246 - 01:28:16.766, Speaker C: They need to simulate all of these ops. Each of these ops is going to fail simulation and get dropped off chain. But nobody is paying for all of this extra work. We need to protect against this. And it can be even worse if there's a bad paymaster because a single paymaster can affect a large number of different ops from different wallets. So we put many mitigations in place. The first one is a limit on validation gas.
01:28:16.766 - 01:29:28.282, Speaker C: So validation gas represents the risk of unpaid work for bundlers and for nodes because this is the work that's being done for the validation before knowing that the operation is going to be paid. So each user operation has to specify how much validation gas it's going to need. And if this number is set too high then bundlers are likely not to accept this yobu's user operation and not even try to simulate it because it has too much risk. Another thing we needed to take care of is to make sure that the environment is consistent because otherwise user operations could be invalidated in large numbers without any action. For example, let's say we allowed during validation to check the block number. So someone could send a very large number of ops that depend on the current block number and they're all going to be successful when added to the mempool. But then the block number changes and by the time a bundler tries to bundle them, the block number is no longer the expected one.
01:29:28.282 - 01:30:03.382, Speaker C: So now all of these operations need to be dropped and that's going to be a lot of work. So we needed to ban any environment operations. So all of the ones listed here are not allowed. So an operation is not going to be accepted if it uses them during validation. Of course it can use them during the operation itself, just not in the validate function. And we also needed to restrict a couple of opcodes. So for example, the gas left call, it can only be used in the context of a call.
01:30:03.382 - 01:30:55.430, Speaker C: When setting the gas for a call, you cannot use gas left to read the number and act upon it and make decisions on the gas. In practice, this shouldn't really be a limitation. There isn't a lot that you need to do with it other than making calls. And one last thing that we do to ensure consistency is we make a list of any account of the code of any account that is accessed during this during validation. And if the code change between getting into the mempool and creating the bundle, then the operation is dropped without simulation. Normally, this shouldn't happen. It means that someone either created or self destructed one of the contracts related to the operation.
01:30:55.430 - 01:31:41.526, Speaker C: So this is how we make sure that everything stays consistent, which leaves us with just storage access. So we also need to make sure that a single storage change cannot invalidate a large number of ops, because then someone could set a flag that kills all of the ops in the mempool. So we limited the wallet. The wallet can only access its own storage. It cannot access the storage of other contracts. And this is complemented by another requirement that each wallet can have only one user operation in mempool at a time. It can replace it by fee, it could even replace it with a batched operation that perform multiple actions, but it can only have one.
01:31:41.526 - 01:32:36.040, Speaker C: So these two rules together mean that a wallet that a state change can only invalidate one op. It cannot invalidate a large number of ops. So we have a similar rule for paymasters, but for paymasters, this is not enough, because you actually could have multiple paymasters. You could have multiple ops that use the same paymaster. So we also needed a reputation system, where each bundler maintains a reputation for each paymaster it sees, and it needs a way to know if this paymaster is causing a lot of unpaid work. So what it does is it checks how many operations with this paymaster failed simulation in a sliding window. And if it sees that the paymaster is causing too much unpaid work, then it's going to throttle and eventually ban it for a while.
01:32:36.040 - 01:33:56.458, Speaker C: And this is where the stake comes in, because we needed a civil resistance mechanism so that it's not cost effective for an attacker to spin up a large number of paymasters that misbehave. So each paymaster has to lock a stake and if it wants to unstake, it needs to wait for a while, which means that if someone wants to perform such attack, they need to spend a lot of ETH on deploying these paymasters. And each of the paymasters is going to cause a very small amount of extra work before it gets itself banned. So when can you use this? We started building this eight months ago. It was co authored with Vitalik and since then the Nethermind team and the Opengsn team have been working on building it and we kept iterating with Vitalik on the design until we're satisfied with it. And now, last week, OpenZeppelin completed a security audit for it, which allows us to put it on Mainet. So today it's available on Ethereum, Mainet, and on testnet.
01:33:56.458 - 01:35:02.440, Speaker C: It's also available on Gnosis chain, formerly XDI, and soon it should be available on more layer one and layer two networks. And now is your part. Now we would like you to start building and experimenting. We want the community to start building, ERC, four, three, seven wallets and also experiment with different gas abstraction models by implementing Paymasters. So if anyone wants to start experimenting with it, this hackathon is a great opportunity because the Opengsn team is sitting right here and could help you get started. Or you could join our discord, where we can also help with such integrations. And finally, if you are building a cool project that uses ERC four three seven, you should consider applying for a grant from the Ethereum Foundation because we would love to see the community start experimenting with this.
01:35:02.440 - 01:36:01.720, Speaker C: Right. So I'm going to post a couple of links for the EIP itself and everything associated with it. And now I would like to invite Draw from Opengsn to walk through the code of the so I'd like to invite Draw to walk through the code and show what a wallet looks like, what a Paymaster looks like. Right. GSM still affiliated with Open. These buttons no, not with OpenZeppelin. It's maintained by Opengsn, but.
01:36:03.530 - 01:36:04.258, Speaker D: It'S active.
01:36:04.274 - 01:36:20.540, Speaker C: And actually a new version is coming out now. Sorry, you were asking? Yeah, because OpenZeppelin was working on GSN right before in the first version. We worked on it together, but we've been maintaining it since.
01:36:29.050 - 01:36:53.406, Speaker D: Okay, just a second. Okay, I'm drawa. I'm from the opengsn team. I worked on this project. Now, after the overview of Joav, I'll try to dive into the two contracts in the system that interest you as developers. I can overview the entry point, but we don't have time for that. It's the contract that we all trust and love and OpenZeppelin Verified.
01:36:53.406 - 01:37:36.510, Speaker D: I'd love to go in person if you like, but the two components that applications will want to customize and create are a wallet and a Paymaster. So, first of all, what is a wallet? This is the interface that you have talked about. A wallet is an account. It holds your account. It has an execute function, but we don't mandate its format, so the interface doesn't require it at all. And in order for you to easily create a wallet, we created the base wallet implementation. It exposes nons.
01:37:36.510 - 01:38:25.550, Speaker D: Of course, it has to have the entry point it supports at any given point. There is exactly one, and it implements a validate user op. So we provide you with the default implementation, which verifies it calls only from an entry point. We have to provide a validate signature. Now, this base doesn't implement it. We'll see in a minute how it is, and it perform a prefund, which means it sends back to the entry point. That called it the value, the cost of this transaction if we go down into a specific the sample wallet we created.
01:38:25.550 - 01:38:40.560, Speaker D: Now, sorry, it's simple. This is a very simple wallet, and for one thing, I want to zoom in.
01:38:42.930 - 01:38:43.680, Speaker A: Great.
01:38:45.410 - 01:39:20.320, Speaker D: This is a simple wallet contract. It's a base. It provides anons it has an owner, and it accepts signature only by its owner. It implemented the Verified signature by using the verified signature. It validates the signature using the standard EC recover. If you like, we can have any different signature scheme we're not enforcing we don't require any signature scheme, not even a length. This one uses EC recover.
01:39:20.320 - 01:40:13.148, Speaker D: It uses the very, very simplistic nonce mechanism which is increment by one. Again, it's very good for a start. And it provides an exec from entry point, which is of course, how you receive requests from the entry point. It requires that it is called from the entry point to execute on behalf of this wallet, which to create the request. One thing it doesn't do, and of course, a wallet probably will do it is not a proxy. It works very well, except that the deployment will cost you quite a lot because the entire contract is deployed each time you use it. A better implementation, of course, will only deploy a simple proxy so that this contract can exist once on chain.
01:40:13.148 - 01:40:48.524, Speaker D: It also exemplifies how it uses a batch. As you have said, we can have only a single transaction per wallet in the Mempool. But if you want more, you probably would use a batch. So we added a sample batch into this simple wallet. And another example of something it can do is it can transfer it can transfer ETH from its own balance to other contracts and of course, to execute code in any other contract. Let me see. Okay.
01:40:48.524 - 01:41:46.320, Speaker D: And it provides the basic help function for elac. It has an admin to modify its entry point. This is the edge case where an entry point has to be upgraded, so of course the owner can perform the switch. This sample contract is also acts as a standalone proxy account and it accepts requests directly from its owner. That is, you can either call it just like you would call any other contract object from your owner account or through an account abstraction where the entry point executed as long as the entry point pays and as long as you are using Ethereum. As it is today, there is no real difference. As we said, the difference comes when you use features like the paymaster.
01:41:46.320 - 01:42:46.120, Speaker D: So again, if you look what it takes to be a paymaster this is the interface you have described earlier. There is the verify paymaster. A paymaster receives a request just before it gets accepted, and if it appears in the request, it has to accept it and then has a chance to run a post operation code to do it. Again, we create a base paymaster to implement this interface. It provides a convenient way to initialize the entry point. And to support this entry point, validate paymaster itself is exposed as it is, because it's a view function. There is no added value we can do in the base class, but the post operation is required to be called from the entry point to enforced it in this base paymaster.
01:42:46.120 - 01:43:52.976, Speaker D: Now, let's look at an example which is very interesting but a bit more complex of a Paymaster. This is a token paymaster. It is a token and it is a Paymaster and if you have tokens you will pay for the request using it so the main function is the validation. Let's see what it does. This is the validate userboard it's a view function that a Paymaster expose and it should revert if it doesn't agree to pay and should accept if it agrees to pay for this request. So this is an abstract method, a conversion from it knows how much this operation will cost so it knows how many token it needs to request from the account it okay. It performs some validation that the verification guards in the request is big enough.
01:43:52.976 - 01:44:55.668, Speaker D: This security issue, I'll not dive into it right now. Now we need to check if the wallet will agree to pay for the request. What it does, it checks that there is a balance that the token balance. Again, this Paymaster is a token it verifies that the balance of this wallet is high enough in this token Paymaster and if this balance is enough and it reverts if it doesn't balance is enough. What you see here, it's return value. The return value of the verification is what we call a context it's something we pass after the request is complete to the post operation. This is a signal from the paymaster to the system that it has some post operation to be done.
01:44:55.668 - 01:44:58.260, Speaker D: Don't forget me after the execution.
01:45:00.120 - 01:45:00.436, Speaker A: I.
01:45:00.458 - 01:45:47.264, Speaker D: Need to complete the balancing of the user. If you go into this post operation, it extracts this context, which is the it saves the address of the user and the post operation, it gets the actual cost. So now it knows how much tokens it needs to get from the user. So what it does, it forms a low level transfer. Again, this is a token so it can do it by itself from the user's account to itself. So this way the user paid in token. We made sure that in advance that the user has enough tokens for the maximum possible price in token and post operation.
01:45:47.264 - 01:46:58.164, Speaker D: After the user completed the operation we perform the actual charge. Now, if you are thinking maliciously as a user, okay, I will start a transaction and then the operation I will create is empty my token balance because if I empty my token balance after the operation I don't have any tokens and I will not have to pay anything. The Paymaster will not be able to charge me so we need to mitigate that. Now, it's a bit difficult to see from this Paymaster code how it is done. So it is written somewhat in comments and you have skipped it in the first part. When a Paymaster runs its post op post operation, if this method reverts, the entry point performs a very neat trick, in that it reverts the user operation completely, along with the postop, of course, and then calls again the postop of the Paymaster. Now, if you think about it, the code that the user create executed was completely reverted.
01:46:58.164 - 01:48:18.500, Speaker D: It's not on chain. So if you look at the state of the chain, the pre operation, the verification, the user has a balance, was executed, we did some operation and reverted it and now we call the post operation, which means the user has a balance. So if the user will perform this trick and try to empty its own balance, the post op will revert, the entry point, will call this post operation again, by the way, with updated actual cost, which is higher, it has to cover for this revert and the transfer will succeed. So this code, it's not that complicated, but this is a paymaster that works with a token. There are several other paymasters we have in the sample code. I don't have much time, but I don't have any I don't think we have okay, if you like you can talk with us. There is one paymaster we added is the ability to kind of an oracle, to trust an external address so that this paymaster can trust a signature created outside of the system, outside of the net off chain and the paymaster will validate it and will pay based on this signature.
01:48:18.500 - 01:48:25.448, Speaker D: So we also think it's a cool paymaster to use and to integrate. Okay, thank you.
01:48:25.534 - 01:48:35.930, Speaker C: If you have any questions any questions? Yeah, if anyone has questions, we can go outside because there's already.
01:48:38.700 - 01:48:39.496, Speaker D: Available.
01:48:39.678 - 01:48:45.310, Speaker C: Oh yeah, I will publish it on our discord and I'll make it available.
01:48:46.080 - 01:48:47.470, Speaker D: Okay, thank you.
01:49:57.290 - 01:49:58.294, Speaker B: Hello. Does it work?
01:49:58.332 - 01:49:58.534, Speaker C: Yeah.
01:49:58.572 - 01:51:42.728, Speaker B: So just going to wait a few minutes maybe some people are going in or out and then we start in like one or two minutes. Well, I think since the talk is a little bit short, we just jump in and if people stream in later then we should still be ready for the code examples and the technical details. So let's say hello, I'm Chris from Flashbots and here's my colleague Mateosh and we are happy to give an introduction for developers in what we do and how you can actually play with it and with our infrastructure. So I guess I would like to know who is already familiar with Flashbots here. All right. Have you used a Flashbot protect already too? Send a bundle ever manually. All right.
01:51:42.728 - 01:52:38.452, Speaker B: Okay, that's good. Then we have a little bit of context, then we dive into more of the technical details. So if anybody's interested, the slides, they are online and it's linked again at the end. So the talk is titled Flashbots for Solar Park supercoders and it's because we share the democratization values and openness and permissionlessness and maximizing the social good ideals at Flashbots. So we really try to contribute to an open permissionless system where much of the value is available to the community that is very important. Like we really strive towards open, supporting also the future of Ethereum. In this talk, it's just a little bit about us Flashbots, which APIs and services we have and then common libraries to interact with us.
01:52:38.452 - 01:54:00.784, Speaker B: And then I show you a couple of code examples. And there is an example project that you can clone. I'm not sure if you're familiar with the background with PHA Wars and miners searchers, trying to extract value from the public mempool and miners doing their own things like front running and back running transactions. And this was having a very centralizing force. And flashboards came up with some research as basically a research collective that focused on illuminating the dark forest, which means making what is happening and what is going on more transparent in form of writing, of videos, of data. We have a bunch of dashboards that quantify the amount of mev that is extracted and also about how to tap into that, how to become a participant in the whole network, to democratize it, so that not only a very small group of privileged players have access to this, but that this is a decentralized nature where people where everybody if you have ideas, you can just tap in and become a participant in the network. This is a very important thing because the centralizing effects they just also compound and the distribution of the mev benefit.
01:54:00.784 - 01:54:31.656, Speaker B: So our goal is to maximize social goods as well. There's some writings like you can easily find on writingsplashbots net or on Docsflashbots net. There's a lot of background and context that you can find. There things we do. Let's get into the more practical side. We have the Flashbots relay, flashbots Protect, we have Mev inspect. So the relay which basically is the central entry point for the bundles and simulations that forwards the bundles to the miners.
01:54:31.656 - 01:55:10.932, Speaker B: So you can use this API. The API is a little bit tricky to use because you need to sign the requests. There's a couple of robbers that you can use in libraries for Python go JavaScript TypeScript. Rust and I will dive into them later. Flashbot Protect is a user facing service where you can set your wallet endpoints to RPC Flashbots net and it will route valuable transactions through Flashbots so your transactions will not get front run. And you also have a reverb protection with that. You can actually disable the reverb protection by using Protect with fast mode which routes direct the transactions without simulation to the miners.
01:55:10.932 - 01:55:52.808, Speaker B: So if you just visit RPC flashbots. Net then you will have a table with the advantages of both approaches. But it's usually a very simple way to protect your transactions from being front run by bots from the public MEMP pool without needing to do any signing or anything. It's like just a MetaMask endpoint or whatever. Movect is a Python tooling that automatically inspects the new blocks and the blockchain. Also historically to quantify mev opportunities, be it front running, back running, Arbitrage and other things. We have a pretty wide range of things that are quantified there and the data is shared on Dashboard and explore flashboards net.
01:55:52.808 - 01:56:41.540, Speaker B: So visit that if you want to have some charts that give you insights into how the trends are developing over time. Most of this is also open source software, so we appreciate contributions. It's pretty easy to jump in, it's very easy to participate on open issues or PRS or get most of these things even running locally for yourself. Of course we have MAV GEF, which is a Go ethereum implementation that has a couple of additional features. So you can do transaction simulations there where you can send it a bunch of transactions, a bunch of bundles, and it will simulate those against the state that you specify. And then it returns you the value difference for, what is it? Warfare minor. And you get a couple of additional informations about individual transactions.
01:56:41.540 - 01:57:31.320, Speaker B: And it's very useful for quickly working locally with the flashboards release tech. We do a lot of research and collaborations. There is a lot of open research, we writings and specification work in collaboration with a bunch of teams and the EF and wide ranging collaborations and also always are opportunities to contribute. We are hiring as well. So if you're interested, look at Flashbot's jobs. There is a bunch of open opportunities, especially for engineers, plus points if you have a Go experience, it's a very collaborative environment. I would definitely encourage you to take a look at that if you are interested in opportunities.
01:57:31.320 - 01:58:06.872, Speaker B: And also check out our GitHub repository, it's GitHub.com slash Flashbots. I touched on this briefly. Using the Flashbots infrastructure gives you a couple of advantages like privacy, front running, protection, river protection, block priority. So the bundles, they are added on the top of the block and it lifts also certain transaction size constraints. So if you have like large data that you want to send through, gaff won't let you do that through normal transactions. I think it's like 500 size limit.
01:58:06.872 - 01:58:57.040, Speaker B: So you need to do something very interesting to actually go over this limit. But there is a bunch of use cases and this transaction size limit is also not applied through bundles. Quick overview how it really works. Users send transactions to the Mempool, goes to the miners. Then there is the searchers that look at your transactions in the Mempool and slip in a transaction right in front of it that does whatever they can do to maximize their value based on the impact your transaction has. Of course there is like very quick growing segment within a few weeks. It was like ten bots that competed against each other and this leads to a lot of transactions by bots that are in mined into blocks.
01:58:57.040 - 01:59:52.150, Speaker B: So here we have the solution. Here is Flashbots with mevgaf and the flashboard three where searchers. Do not send their transactions back to the Mempool, but they send it to the flashboard relay. There they get simulated and sent to the miners and the miners will only include those if they do not revert in the end. So basically it's also for searchers advantages because they can send and resend better and better bundles but do not get penalized by having a bad bundle actually mined and losing the transaction fees. Flashbots Protect is currently completely excluding searches aborts their transactions get routed directly from users to Flashbots to the miners. There is thinking about how to involve searchers in a non front running way that's coming later.
01:59:52.150 - 02:01:08.780, Speaker B: And we also have mev boost. I don't know, are you guys familiar interested in Mev Boost? It's basically an approach to proposal builder separation for Ethereum Two that is currently very also collaborative project. We have a big part of the community and we try to think through all the challenges and get the approach that it's possible that a consensus client, besides talking to the execution client, can also get additional private transaction flow. So there is relays that send basically blocks to MVV Boost which runs as part of the validator consensus client node or instance and the consensus client can then choose which block to use. If it's coming from MVP Boost, then the transactions are not revealed, only the header and the validator signs the header and only after he signed the header he receives the block payload which guarantees transaction privacy here. So this is a very interesting project. I encourage you like the specification is all on GitHub as you see here flashboards Mevboost or if you search Me Boost on Google, you will find this very easily.
02:01:08.780 - 02:02:01.580, Speaker B: All right then let's dive a little bit into the technical details. This is the APIs that we have if Call bundle and If Send bundle is our classical most widely used APIs. Call bundle allows you to simulate bundles so a list of transactions and you get the information whether they have rewarded, how much value they provided and so on. And with Send bundle you can actually send it to the relay where it will be simulated internally again. And if the simulation succeeds, it will probably go to the minor except of a time of very high load where there is some rate limiting. If Send. Private Transaction is a relatively new API that we have which does not require the payload signing.
02:02:01.580 - 02:03:16.132, Speaker B: No, it requires a payload signing, but you can use a similar API to flashboards Protect too. So Send Private Transaction, you send one single transaction and it will internally get sent as either bundles to the relay because the bundles, they are only for one specific block. So it's kind of a little bit of hit and miss if you get included. If there's like a lot of competing transactions and Send Private Transaction abstracts this that it will send it automatically for up to 25 blocks until your transaction is included. So if you're developing and you want to just an easy way to send transactions privately but don't have all the issues of resending and checking, if it's included, you can just send it to Eve send private transaction and of course, you can also use the RPC endpoint where you can use Send raw transaction that will either route non valuable transactions to the public mempool or if it's a valuable transaction through the flashboards relay through Send private transaction again. So if you send it to the RPC, it will use Send private Transaction internally. The RPC endpoint is also open source software written in Go so you can take a look at that.
02:03:16.132 - 02:04:16.068, Speaker B: Also you can run it locally very easily. And we also are always happy about contributions, issues, pull, request feedback, whatever. If you run into anything, we encourage you to open and get in touch. And here is maybe the more interesting thing for hackathon, like exactly how would developers what's the easiest way to interact with the flashboards APIs depending on your programming language? In Go, it's this flashboards RPC library. Maybe in Python, it's the web free Pi PY flashboard provider. If you use JavaScript TypeScript, it's the Ethers provider and we also have one, there is also a community built one for rust and I wanted to show just a few code examples how to approach that. And I decided to use JavaScript TypeScript because for a hackathon it's usually very accessible and you can maybe reuse the same code across backend and front end with Node JS and the browsers.
02:04:16.068 - 02:05:12.620, Speaker B: So I will jump into that and show life with the Flashbots Ethers provider. So the repository, if any one of you is interested and I'm sure we can somehow publish the slides later, it's GitHub.com Metacrist, this is my username and then it's a flashboard Ethers example. So if you just go on GitHub Metacrist you should find it on the repositories. So I will show you now some live coding here. So basically what I did was Git clone the repository, it's in the README, it's built on some TypeScript boilerplate project that does the right dependencies and that you can bundle the code as a Node JS executable or for the browser with es build. So it's a little bit outdated maybe, but it is something that gets you started very quickly and that you can just install right now.
02:05:12.620 - 02:06:08.316, Speaker B: So it's probably easily transferable to other things, but I'm familiar with that, so I use that. How it works is you clone the repository, you install the dependencies with Yarn and that's basically all the setup you need. Here in the source directory there is four different main TS typescripts with increasing complexity and this is included from CLI TS. It's basically just include the run method and run it or from browser. So is it large enough? Should I make it a little bit larger like this? So the first example is a very simple setup of Ethers. This has a hard coded girly API key for infura. So I will deactivate this in a day or so but feel free today to play with that too.
02:06:08.316 - 02:06:40.040, Speaker B: It's in the configuration here. This is just some randomly created private keys because it's a little bit tricky how to handle them if you build for both the backend and for the browser because for the back end usually you would use a process environment variable but for the browser this is not existent. You can use es build to replace these variables in the build process. That's very easy. But yeah, it's up to you how you handle this. So for the sake of simplicity, I just hard coded these values but you really should not check them into code. So don't do what I did here.
02:06:40.040 - 02:07:22.244, Speaker B: This is really for just for example, it has no values chain 85 and some helpers and is the girly relay endpoint. So in the first example it sets up a e first infuria provider, gets a block number and then gets the block for this number. It's kind of a very simple example and let's just run this a little bit smaller. So you can run this in the CLI mode with yarn CLI. This is also written in the README. So here it fetches the block, the block number first and then the block. That's it.
02:07:22.244 - 02:07:47.884, Speaker B: And in the README we also have the information what else you can do. So you can build it for the browser with yarn ESB browser and you can add colon watch. So on every change in the code it automatically rebuilds. There is no hot reloading. So in the browser you still need to manually reload the code but it will automatically build it if you change anything. So it's waiting for changes. It's all fine.
02:07:47.884 - 02:08:25.764, Speaker B: You open the browser test. How do I do that? I think like this and here it's doing exactly the thing. Let's reload to see it better. So it's getting the block number and then it's getting the block and then here you have the block details and it all runs in the browser. Maybe if you target the browser instead of an infura provider you do like a I think it's called default web free provider that connects to your MetaMask. So MetaMask can then sign your transactions and then broadcast them. So you don't need infura.
02:08:25.764 - 02:09:29.260, Speaker B: But this is up to you. But this shows you it's really kind of simple to reuse the same code with some constraints in both the backend in node JS as well as in the browser. In the second example, in the second example we create a transaction and in the third example we simulate it. In the fourth example we send it to Flashbots and get some statistics. So it's the same code as before, it's just that we create a wallet and here we get the maximum base fee for the future block. And then we create a wallet with two, the wallet address and a bunch of parameters and basically that's it. So to use that you would for instance, go in in CLI, choose main two and then you can run Yarn CLI and then here you can see the transaction.
02:09:29.260 - 02:10:25.062, Speaker B: So in the next step it's exactly the same code, except that here we also add a simulating part. So basically you have to choose a target block which is the latest block plus one in this case. And then we simulate it, which means it sends to the flashboards relay with Call bundle, the call bundle API. The request is properly signed and then it returns you the simulation result. Let's see what this does. So I again go to CLI and just import this from mainfree and run yarn CLI again. So what do you think will happen with dummy keys? Exactly? Simulation is successful in the sense that it was simulated and a response has been received, but it was of course invalid because in this empty wallet there is insufficient gas to send the transaction.
02:10:25.062 - 02:11:18.494, Speaker B: So this is a simulation result that the transaction itself had an error. So success. Basically it's really up to you how you want to craft the transactions or where you get them from. And here, finally, in the fourth example after simulation, if it's not an error, if it's not an error, we submit it to the relay with Send Raw Bundle there's send Bundle and Send Raw Bundle in this provider, send Raw Bundle means the transaction is already signed and because it's here, it's signed. And if you do Send Bundle, it will sign it internally. So it submits the bundle. But it won't happen here because the simulation has an error.
02:11:18.494 - 02:11:27.940, Speaker B: But we can comment this out and still send it anyway. Let's see what happens. I need to import main four.
02:11:45.740 - 02:11:46.490, Speaker A: It.
02:11:48.460 - 02:12:43.000, Speaker B: But where is that? 72 oh yeah, simulation. Yeah, exactly. So this is here, it's just a compiler error basically that there's additional APIs that this does for you. And because I commented out the simulation error response, you cannot actually get the result. But there is two more additional APIs that's called bundle stats and user stats where you can query the flashboard relay. Like how did this bundle do? What happened with this bundle? Did it have a reputation? Impact and user stats for seeing the reputation and some data about your signing key. Because we create basically we have two private keys here, one private key for your wallet and one private key for signing the requests that go to the flashbacks relay.
02:12:43.000 - 02:13:08.800, Speaker B: And this signing key is impacting, whether you will end up in a high or in a low priority queue in times of high congestion. When we have a lot of traffic, the high priority signing keys will get simulated faster than those with the standard low priority. And it's pretty easy to get into high priority. You just need some successful bundles. So let's try this again. And I hope I saved. I probably not.
02:13:08.800 - 02:13:10.210, Speaker B: I need to save.
02:13:18.960 - 02:13:21.090, Speaker A: It's not like this.
02:13:28.320 - 02:14:11.688, Speaker B: So the bundle here was submitted, but that it tells you here that the block that you sent it for has passed without the bundle being included. So kind of what we expect here, but it shows you if you want to interact with the flashboards really from JavaScript, like, this is all that you need to do. And then you can do some additional user experience with error handling and so on. But this is a very simple way to get started, in my opinion. Personally, I think for backends, the Go code is even a little bit simpler and more straightforward, but I think that's probably not true either. Okay, just going to wrap it up. If you're interested.
02:14:11.688 - 02:15:15.644, Speaker B: Again, take a look at GitHub metacristexample. And here you have the full code of the examples. But also if you're building applications, are infrastructure services, user facing apps, be mindful of mev, like Mev exists. It's exploitable very often and it's not a great approach to just don't think and don't care about it too much. It's really important, like if you're a developer, that you have some thoughts about how does your code, your application, your infrastructure impact users and emit Mev? Because it is going to be exploited and this can be disadvantages to users or lead to centralizing effects. So if you have questions like there is a flashboard Discord where there's very active discussions and it's very easy to get in touch. So if you want to get feedback also on your applications about possible Mev, it's definitely relatively easy to get in touch.
02:15:15.644 - 02:16:08.510, Speaker B: Also, Mateosh is here, so he is one of our Mev experts, and he will also be able to answer a lot of questions. And I'm available after the talk too. So that's it. I think we rushed a little bit through it, but if you want to collaborate easy, just join Discord, read the docs, join GitHub, and if you want to build something, I hope you have a lot of fun. Thank you. So maybe you have a few minutes for some questions. Any, what is on your mind? You all right then.
02:16:08.510 - 02:16:12.150, Speaker B: I hope you enjoy the hackathon and happy hacking.
02:16:35.790 - 02:17:40.930, Speaker A: Sam. Sam.

00:00:08.550 - 00:02:28.676, Speaker A: Stream is good. Thanks. It's a good way to start it off. It it all right. Welcome, everybody. My name is Kartik. I'm one of the co founders of Epglobal.
00:02:28.676 - 00:03:33.508, Speaker A: And welcome to Hack FS judging So for those of you who don't know, hack FS was a month long hackathon that we did in partnership with Protocol Labs as Ethg Global, and we're taking this entire week for showcasing the projects that came out of this event. So as a quick summary for people watching this on video, the past four weeks, we've had 470 hackers from 50 different countries are working across 19 different time zones. And we had a whole mix of people who are beginners and intermediate and advanced in their skill sets on the understanding of the ethereum and the protocol last alcohol ecosystem. And they spent the last four weeks working on projects that use and show creative uses of both of these technologies. And as of last Thursday, we're super excited to say that we have had 132 projects that came out of this event, and we're kicking off a whole week of showcasing these amazing projects. And today is day four of our demos. So I'm going to quickly walk through the logistics of how this call is going to work for everybody watching this.
00:03:33.508 - 00:04:17.884, Speaker A: In recording, there's going to be 13 teams that are going to go on today. Each team will have four minutes for a demo and four minutes for a Q and A. And to minimize any logistical and AV issues, we've asked all the teams to pre record their demos so we can quickly walk through and adjust if something is not working according to expectations. And as a quick overview of how the event itself was structured, each team had a maximum of five members they could work with. A lot of the projects are in groups, but we also have a lot of individuals who are going to be demoing. And as a general rule, all code that you're going to see today was written over the course of this event. So everything was done as the event itself began.
00:04:17.884 - 00:05:13.552, Speaker A: And the only criteria for being eligible to demo and be part of this event is that they must incorporate the tools and technologies from the protocol as an ethereum ecosystem. So we're seeing a lot of really interesting and creative mashups of what you can do with decentralized storage and smart contracts. And the way we're going to think about judging these teams today is going to be on these five different categories. So each team will be rated on how technical, original, and practical their idea is and how easy it is to use for their intended audience. And because we recognize that these four categories may not be enough for everything, we also have a general category that we like to call the wow factor that helps us sort of do a catch all for anything that we may have missed. And before I go into our demos, I want to emphasize that this is not a competition. The hackers are very much here to learn, they're here to share their excitement.
00:05:13.552 - 00:05:49.760, Speaker A: And the judges are here in particular to give feedback on what they see as their projects and how they can take it to the next level, whether it's improving things or using a whole different technology that might be available. Now that abstracts a lot of their work. But it's very much a session for us to celebrate what everybody's been able to accomplish over the past month. And I just kind of want to point this out again. Not everybody is here to become a business. So the goal is again experimentation and education. And we're showcasing what everybody is learning to play with these technologies.
00:05:49.760 - 00:06:59.318, Speaker A: So with that, the schedule for today is going to be that these teams are presenting to our judges. And doing the hard job are our three judges. We have Mintier from Consensus labs, we have Raul protocol labs, and we have Danny Zachman from Ceramic network. And they'll be with us for the next 2 hours looking at it and commenting on the amazing projects that we're going to see today. And with that, I'd like to call up on our very first day and I'll let the Parcel team take it away and showcase what they did for this hackathon. Jeroon, I think we're not getting the audio. If this is playing, you may want to just quickly check off the audio flag on the screen share and then we'll be able to get our file.
00:06:59.318 - 00:08:14.720, Speaker A: Coin and Bread is the front end debit pass. We're using deterministic signatures for the hello and welcome to the sorry guys, just one secondary. We're still not getting the audio. So what we can do is if josh, you're on our smart contract development. Tarun handles integration. Hello and welcome to the Parcel demo. Parcel is a service to manage crypto payroll seamlessly with end to end encryption using IPFS and Filecoin.
00:08:14.720 - 00:08:51.720, Speaker A: We're a team of three. I am Anubhav and I handle smart contract development. Tarun handles integration with IPFS and Filecoin and Brennan is the frontend debit parcel. We're using deterministic signatures with Ethereum private keys and storing all the confidential data or documents on IPFS and Filecoin in an encrypted form. We're also enabling money streaming and through money streaming to employees in one click. Our aim is to enable employees to be paid in real time, which leads to making Payday loans obsolete. We're also enabling mass payouts in one click, irrespective of tokens held by employer or employees.
00:08:51.720 - 00:09:20.484, Speaker A: The idea of mass payouts was inspired by my previous hack at Hack Money with the same name. And with this, I'd like to call in Tarunu for the demo. Hi. Let's try to create an organization we can set the name for now, Amazon. One, two, three. It is asking for the MetaMask pop up. So it is saying sign your address to create the encryption key.
00:09:20.484 - 00:10:00.512, Speaker A: And this encryption key will be used to encrypt data on IPFS and filecoin. So we can just sign it now. Now it'll ask for the signatures for creating an organization. So now let's create an organization on the smart contract and the ID is submitted. Let's wait for the confirmation so our transaction is confirmed and we are redirected to our dashboard. So we can go to payroll section and add some department here. For now we can say we have marketing department, we have engineering department and we can just create it.
00:10:00.512 - 00:10:37.180, Speaker A: So now we'll first calculate the encrypted data hash from IPFS and then submit it to Smart contract with mapping with the sum index. And once the transaction is confirmed, we'll just can see here the departments. So now we have marketing and engineering department here. Let's go back to the people section and try to add some employees. So now we can submit the request. You can see the employees are added successfully. Now let's try to run the mass payroll for these employees.
00:10:37.180 - 00:11:06.710, Speaker A: So now let's try to run the mass payroll. So in the mass payroll section as you can clearly see, we have three employees with the salary of ten die and ten USDC. And we have two options. One is stream and other is Pay. Let's try to run through Pay first. So what does pay means? Pay simply means we are doing transaction batching under the hood. So in single transaction we'll be batching up the transactions for all the addresses and let's try to run the payroll via Pay button.
00:11:06.710 - 00:11:36.972, Speaker A: I guess we can run the streaming for the same employees. So we have already selected. So let's try to run the stream. And now I want to run the stream for all my employees for let's say another 1 hour. And I can press stream. So, as you can clearly see, the stream has been started for all the employees and we can clearly see that 1% of the streaming has been done. And we have one more section here which is documents.
00:11:36.972 - 00:12:40.602, Speaker A: And here you can add your company's confidential documents. So for now we can add any document, let's say baselift. It all starts with generating encryption keys by signing a deterministic string using Ethereum private keys and then encrypting the data with that generated key. Then we send the data to IPFS and file Quinn and store the returned hash in a smart contract wallet owned by the organization and to fetch all the required information by retrieving the hash from the smart contract and decrypting the corresponding data locally to run mass payouts on money streaming. Future work includes role management of data and therefore enabling encrypted file sharing within or outside the organization. We're looking to expand our horizon to a full fledged agile management suit to manage health records, W Nine S, et cetera. We're also exploring layer two solutions to offer efficient mass payouts and money streaming.
00:12:40.602 - 00:13:08.822, Speaker A: Since gas on layer one is a concerning issue, especially these days, and layer two solutions, like weakest things, offer a relatively better prospect for us. We're also looking forward to making the code stable, bug free, get the contacts audited, and go to Mainnet as soon as possible. We're live on fleek as well. Our demo is hosted on fleek. And thank you. Awesome. Thank you, Parcel.
00:13:08.822 - 00:13:49.670, Speaker A: So we'll turn over the judges for comments, feedback, suggestions. I didn't catch the part in the demo where you added people. Can you just talk me through that flow and what were the Identifiers for the people and how do they get added to the organization? Sure. The architecture that we decided for this works like this. Let's say if you want to add some people in the organization, we store all the information of the data on IPFS and filecoin and we get a corresponding hash. Right. So we store that hash in the smart contract, and that's how the transaction works.
00:13:49.670 - 00:14:31.526, Speaker A: So that's actually encrypted by the ethereum private key. So that is deterministically encrypted. Yeah. So just to elaborate on that question, just for me to understand, what you're doing is sort of like deriving or calculating an object that represents the entire organization with the employment structure and so on. And this object, as it gets modified, it gets changed, and you store that object in IPFS and you always keep the smart contract updated with the latest hash. Right? Exactly. Just to be specific on the architecture, we have a mapping on a smart contract, which is so we have index based mapping.
00:14:31.526 - 00:14:47.854, Speaker A: So let's say the zero th index is for documents. The first index is for, let's say, employees. That way we have one hash that we need to change all the time. And so there are corresponding hashes that we only change in the IPFS directory. Yeah. So you have multiple top level objects. Got it.
00:14:47.854 - 00:15:57.062, Speaker A: Yeah. I think this is an idea that I've personally thought about, because if you look at how the world operates today, employees are trusting their employers to pay them at the end of the month. And one of the ideals of blockchain in general is to operate a trustless architecture which can operate the world in an automated fashion in some way. Right. So it does make sense. Regarding the streaming option or the streaming function that you demoed, is there a possibility to keep the stream real time going and flowing as long as the employee is still working with you? Or do you have to manually look forward and book streams in a looking forward basis? Yeah, so actually, at this point of time, you have to store all the information on the IPFS and then when you call the function right, so we look at the information on IPFS, but even then, while the stream is running, we're planning to have notification subscriptions. Right.
00:15:57.062 - 00:16:33.146, Speaker A: So you can actually subscribe to notifications. So there's a protocol called EPNS, which is basically decentralized notifications. So we're trying to integrate with EPNS and trying to think of a way to notify employers and employees regarding what all changes that have done. So in future, they might just need to update us with a tap and then we'll know what happens then, and then act accordingly in the smart contract level as well. Great. That's the time we've got for Q A. Thank you, Team Parcel.
00:16:33.146 - 00:17:07.060, Speaker A: We're going to move on to the next team today. Who are Veronabeam? Veronabeam, I think you're already on the call. If you want to share your screen and play your video, we can get started. Hello everyone. We are Boroni Bean, and this is our presentation for Hackface, a hackathon run by ETH Global. Boroni Bean is a decentralized content delivery network based on IPFS for Internet service providers. This is our team, Veronica and David, myself.
00:17:07.060 - 00:17:56.740, Speaker A: Let's take a look at how the current model works. Content creators such as Lisa, they need to rely on expensive CDN companies to make sure that the creations are available everywhere. In the meantime, CDN companies force Internet service providers to install expensive third party hardware such as their point of presence servers to make sure that all traffic stay local. Let's take a look how we propose that the model should work. In this model, CDN companies aren't necessary anymore. Content creators take advantage of BBN and IPFS to publish all the content to the Internet service providers right away. In addition, Internet service providers, they take advantage of the BBN protocol to run catching servers that will be pinning all the content that's been demanded by the customers.
00:17:56.740 - 00:18:48.494, Speaker A: All of this while nothing has changed for the customers, they can keep using the Internet as they've been doing it before. So how does it work? Bibin has two key pieces the Pimpap and the gateway. The Pimpap is a service run by creators or publishers that they use to announce and update the list of data objects that they have published to keep track of the Bibin gateways which they serve the content and to handle the customer's http request. The gateway is a service run by the ISPs and it subscribes to the Bin bin Pimp apps. Let's take a look to a live demo. We're going to start looking at the backend. On the left, we're going to be starting the Pimpap, as you can say, has subscribed to a topic.
00:18:48.494 - 00:19:16.390, Speaker A: On the right, we're going to start the gateway. Let's take a look at the configuration files for the Pimpap. Each topic has a source directory that it knows where the content is going to be coming. And as well, it has the different gateways that it should be serving the content. For the gateway, it only has the subscriptions for the proper topics. As we said, there's a source directory that has been added. Let's see what happens when we make a modification to this directory when we look at it.
00:19:16.390 - 00:19:52.150, Speaker A: Once that modification has been done, the new Content Identifier has been updated and the gateway which has been listening to the publisher updates and pins the new content. So let's look at the front end. In this case, we have a publisher like Bill Shakespeare. He has his latest content. For the demo purposes. We have a trace link so we can see what happens when we click on it. Based on the CID request, it's been handled and it's been forward to the proper gateway, depending on the Content Identifier.
00:19:52.150 - 00:20:22.066, Speaker A: If we look for the user, we just have to click on the proper link and it gets the content. As we can see, Bibin is the best of two approaches. It's compatible with IPFS and untaps the power of fully decentralized content addressable networking. It's an effortless decision for developers. A master's degree is not required to debug it. It also adds the best of the CTM model. Police maintain full control of the content.
00:20:22.066 - 00:21:13.214, Speaker A: In addition, it's important to note that it's in the best interest of Internet Service providers to use VBN servers of a city and companies for the future. We are very excited about this idea. We wish we have a little bit more of time to work on it, but we hope that with more work in the future, this can become something very interesting. If you guys are interested, please feel free to join us and thank you very much. Awesome. Thanks, Bruno B. And again, we'll turn over the judges for questions, comments, feedback so that was really cool.
00:21:13.214 - 00:22:32.876, Speaker A: I have a question regarding to how you associate, as you mentioned in the presentation, that you associate particular Content IDs to particular content providers or particular gateways. How do you do? Maybe I misunderstood that part, but if you could elaborate a bit further how from a given client, the request lands on this appropriate gateway server that you believe to already have cached that content locally. So how it works each gateway server has a configuration JSON file that has been subscribing to each pimp up, depending on the publishers. And the publishers have the chance to choice to choose which gateway is going to be serving the content. For example, if it's based on latency or if the publishers realize that some gateways is not working properly, they can always redirect to the proper gateway and make sure that the customers is getting the content right away. But everything works through JSON configuration files. Are there certain types of content or use cases that you think are least well served now by the current CDN model, especially for ISPs that you think this is particularly good for? Well, especially for large files.
00:22:32.876 - 00:23:26.560, Speaker A: If we go to the example of Netflix, for example, it's a streaming service and we have duplicates of the same video all over the network, we believe that there is a waste, especially for CDNS that they use such a very high electric consumption. So we believe that we can remove the amount of duplicates with the help of IPFS. And instead of having to start a CDN for each Internet service provider, like a point of question for each service provider, we believe that with IPS and Boronibian, it's possible to completely remove the number of duplicates. Thanks so much for your submission. This is really cool. So is this something that you plan on continuing on? What's next for you guys? Are you planning on supporting it as an open source project? As of right now, yes. Our plan is to continue with it and continue as an open source.
00:23:26.560 - 00:23:59.896, Speaker A: Maybe in the future if things take off and things go well, we could explore making it a company. But as of right now, we believe that it's best to continue as an open source, to have something to get as many people as possible to help us. Can you tell us a little bit more about the team? I think you're working with somebody else. Yes. Unfortunately, Veronica wasn't able to be here. She's working full time as well, so she couldn't get the day off from work. So myself, I'm a student at the University of Waterloo in Toronto.
00:23:59.896 - 00:24:18.644, Speaker A: I study systems engineering. And Veronica. She's an engineer at Huawei. Great. Okay, thank you, team. Drona. Beam, thank you very much.
00:24:18.644 - 00:25:04.330, Speaker A: Excited to see people present from Waterloo. I hope you come to ETH Waterloo someday in the future when we can run them again. Okay, thank you, team. Ronabeam. We're going to call up the next team, which is Zero Swap. I believe you're on the call now, so if you want to share your screen, play your video, we can get started. Hi, welcome to Zero Swap, a decentralized platform that enables collateralized loans for filecoin and ethereum via Oracle timeswap burn algorithm.
00:25:04.330 - 00:26:01.850, Speaker A: This also has a decentralized chart feature. The team consists of Jay, Rickson, Nandit and Brahma. We have used $3 Filecoin, IPFS, slate and Flick to develop the product. Here is the front end to the application. We have the timeswap bond protocol. As a user, you can borrow, stake or lend the money or any denomination. You can choose a die, you can choose Ethereum, you can put a specify redemption date and you can put a collateral.
00:26:01.850 - 00:27:03.866, Speaker A: The collateral could be any denomination and it could be a wrapped file coin. Once you hit OK, it goes through the authorization, through your MetaMask and once the transaction is complete, you can see your transaction in the dashboard. Like I said, you can borrow, stake and lend. And here is another example of lending. In the lending situation, the collateral is a requirement and there is multiple variations to this. And let me show you also the administrative interface where one can log in and to the bond interface to review the transactions. There is also a chat component, the decentralized chat component that would be showed.
00:27:03.866 - 00:27:50.778, Speaker A: So this is the chat system of our application. This has multiple chat rooms that can allow users to either communicate about the collateralized loan on timeswap or about different DeFi protocols as well. Let me type in a message. So these chat systems are created by three box ghost threads which are peer to peer. So these data are not stored on any centralized server. And the beauty of this is that at least one of the PA needs to be online so that other pas can fetch the messages from it. If all go offline, the messages disappear.
00:27:50.778 - 00:28:30.794, Speaker A: We have an inbuilt wallet connected to your wallet provider like MetaMask. Then we have this screen where we are sharing hot news and topics that users can chat about in the chat room. Then this is the page where user can manage their decentralized profile powered by three box. Yeah. So that's pretty much it about our chat system as well. Thank you. Great, thanks.
00:28:30.794 - 00:29:32.320, Speaker A: Zero swap and we'll pass over to judges. This is great, thank you for your submission. Could you talk a little bit about how you intend on sort of pooling initial liquidity incentivizing people deposit their fill into your liquidity pool. Yeah, so for that we have the staking feature. We have all those functions in our smart contract, time swap smart contract that we have created on our own. So the stakers will be there, who will be providing liquidity the pool and they will earn dividends on a specified date to provide the liquidity for a specific, ERC, 20 token. So this time swap protocol that we have created, this is Oracle less like others that you will see in the market.
00:29:32.320 - 00:30:28.214, Speaker A: They take data from somewhere else. But this is getting all the market interest rates by itself only by seeing how much okay, the lenders are willing to lend, how much borrowers are willing to borrow. So that is the price of interest rate is being decided by the market only, not by any external protocol as is done by others. And you can lend your file coin tokens in here. We are still working on the bridging part, but right now we have demonstrated it for wrapped file coin, which is an ERC 20 token. So right now you can lend and borrow or stake any kind of ERC, 20 token pairs on our platform. Yeah, got it.
00:30:28.214 - 00:31:36.530, Speaker A: In terms of the protocol and sort of like the mechanics, the market mechanics. Are you planning to do kind of like a detailed analysis of the game theoretics behind how that Oracle s market would go ahead? Yeah, Brahma, you can go forward. No, I was just saying that this is where we have not included any game theory aspects of it. Right now. It's basically hinged on the stake that you put. Basically suppose you want to lend, then you have an insurance if you're lending and then if you're borrowing sorry, if we're lending, you want to have a collateral, and then if you're borrowing, you want to have an insurance. So that way if the borrower cannot pay, then we will sell that insurance and depending on how much insurance you take, that would determine the Apr.
00:31:36.530 - 00:32:06.730, Speaker A: We can also add the game theory in further versions as well. Rick, who is our other teammate, he had a full time job. He's not here right now. He has published the White Papers first version for the time swap as so yeah, our actual coder is not available for the bond protocol. He's the one who developed the whole thing, so he's not available today. Okay, got it. Thanks for that answer.
00:32:06.730 - 00:32:58.442, Speaker A: What I was looking for was the Acknowledgment that there is a lot more work to do in terms of designing the mechanics of the protocol itself because it can lend itself to a lot of manipulation potentially. So definitely if you intend to productize this, you really want to dig into that. But yeah, this was a really cool submission. Thanks. This is just also for the chat feature, we plan that in further versions, you can directly interact with the protocols via our chat system. Like, if you type in, I want to lend 100 file coins for 200 die at, let's say, 5% of the interest, or is it decided? The interest is decided by the protocol, so you will be able to do that via our chat system. We are working to build some AI models so that it makes up like a chatbot system that is still work in progress.
00:32:58.442 - 00:33:15.440, Speaker A: Thank you. Okay, thank you, team. Zero swap. So we're going to move on to the next team, which is Ethquad. I think we've got you on here already. I'm going to play your video for you. So let me just get that set up and we'll get started.
00:33:15.440 - 00:35:00.998, Speaker A: Sorry, Luke, should there be audio on here? No, there's no audio. Okay. Just want to make sure I wasn't sorry, I'll just let it go then. Yeah, I think the wrong screen is playing. Is it possible? Oh, Josh, I think you're sharing your screen. I'm sorry, there's no video showing. Hey, yeah, nothing was playing there.
00:35:00.998 - 00:35:38.062, Speaker A: Sorry, guys. Okay, do you see a video now? Okay, sorry about that, everybody. If you can start from about one and a half minutes into it. Sure, I'll jump in there. Yeah, thanks. So this was truly a hack. I was trying out filecoin and all the different tools.
00:35:38.062 - 00:36:23.700, Speaker A: So basically I got the latest filecoin running, got the docker containers all running. That was all there for me, just what I needed. And then I basically integrated that into a front end react with a back end node JS exprs back end. Just because the idea was that I wanted to integrate E 2.0 and I wanted to protect the keys for that. So that was basically why I had a separate back end. So what you can see there is all I'm really doing in this demo is going through the slate guide, which was actually part of the workshops that I went through.
00:36:23.700 - 00:38:02.740, Speaker A: But yeah, I guess some of the things that I was happy with was going through with the integrating the unstoppable domains with Pinata. That was pretty interesting seeing how that all worked because I hadn't actually done any of that before. So basically writing a script and discovering other people who got involved in that before as well, and then going through redirecting it from say, a traditional Heroku application through to an IPFS and then redirecting that again to the unstoppable domains website or an IPFS hash. Yeah. So what's happening now in that video? So you can see I've created a redirection there that was necessary to go through the IPFS hash. And then if you scroll down the screen, it basically shows it's just showing the quick API query to the backend. So that was pretty much, in a nutshell, what I managed to put together in the time frame.
00:38:02.740 - 00:39:40.650, Speaker A: And there I'm just basically showing through showing the different steps or scripts that I put together. And that was just a screenshot. So I've got a few different pins there. I've got a production and a development pin on Pinata and it basically unpins the ones that I don't need using the script. And it was taking a while to redirect to the site from that Heroku app for some reason. Yes, it eventually takes us to a redirection page and then that redirection page takes us to the IPFS hash and then the idea there is the web pages varying the latest. Okay, so we'll pass it over the judges.
00:39:40.650 - 00:40:53.030, Speaker A: I'm glad that you got to experiment with a bunch of things and sort of mix and mash a bunch of ecosystem projects together. It's really cool to see people experimenting and having their juices flowing and throwing out things to see what they managed to do. This was pretty cool. I was curious if you could maybe talk us through some of the AHA moments that you had when you were navigating all these technologies and linking them together and so on. What were the things that actually made it all fit together in your head? Well, I think when I discovered the script, I can't recall who put it together. It might have been textile, but there was a docker container which basically spun up the power gate, it spun up the Lotus filecoin and basically all the different what else was there? It also spun up basically spun up all four docker containers that all interacted together. And that was basically all I had to query to use the front end slate interface.
00:40:53.030 - 00:42:21.606, Speaker A: Whereas I guess if I had to do that manually myself, it probably would have taken me a lot longer. So I don't know if that's necessarily an AHA moment, but that was quite interesting just to go through and see how that was. Done and also just understand the pinning process. So I went through and basically pinning and unpinning and realizing that basically I was building the website in development and then I'd have to deploy that to production and having a separate IPFS address for each one for my workflow. So that was, I guess, an AHA moment that I actually needed a separate development and production environment and a separate IPFS just to preview what it would actually be like in production as opposed to that was basically part of the workflow issues that I had. And it was also interesting looking through unstoppable domains and actually looking at through how that was, just discovering the transaction on Ethereum and seeing where that was, looking at the smart contract and seeing how I could do that manually, like the transactions manually and all that kind of stuff. And just chatting in the forum and seeing how other people were tackling similar issues as well.
00:42:21.606 - 00:42:47.998, Speaker A: That was quite interesting. That's really cool. It would be awesome if you could contribute back to the community your learnings in the form of code or even blog posts on kind of like the story of how you integrated these things. I think it would be super valuable. But yeah, thanks for this. Yeah, I think that was really handy. I basically created a check list and I actually felt that was really handy for myself as well.
00:42:47.998 - 00:43:16.214, Speaker A: So anyone who goes to my repository, they can sort of see where it got up to and if they wanted to sort of take it further or borrow it and just use it for their own, that was, I guess the key and see what's next. So I guess it'd be nice to actually work on the quadratic sort of governments that's down the pipeline as well. So great. Okay. Thank you Ethquad. Thank you, Luke. Sorry again for the video screw up there.
00:43:16.214 - 00:43:56.580, Speaker A: We're going to move on to the next team now, which is Hyben, so I'm going to play the video again, but I'll get it right this time. And we've also got Ken on the line with us as well who's going to translate for the Q A portion. So let me get this set up and then we'll get started. Okay, thank you. Okay, everyone can see that, right? Great. Hello everyone. It's my honor to introduce our team and our project.
00:43:56.580 - 00:45:23.470, Speaker A: We are students from China Normal University as the Beijing Forestry University representing Haven Network technology company to participate in this hayson. Most of the members of our team are undergraduates and graduate students who are studying the direction of the blockchain. This is our team and this is all sparnington Company Hibn Technology. Our project is the Iterm Traceability system based on the Ipfi science, the accelerator. When we build this project during the COVID-19 epidemic, the traceability of the item is becoming more and more important. Although some people have made a blockchain based Iterm traceability system it is either based on the Consultium chain or the problem of the preserving of the larger mode of the data has not been reserved. This project is based on Ipfis.
00:45:23.470 - 00:46:36.710, Speaker A: It spreads the company information and the item information to ensure that the large amount of information is storing on Ipfis. Our project serves the large number of the data storage problem. The projector wide smart contracts to ensure the complete save the execution of the date. Excise then finds the information of the item in IPF and then uses recusive algorithm to recuse the parent atom of the problem. Atom from the Instilled and Ipfis and finally from the Dag. This is the all work flow chart. And first, we found the IPF drives through the instrument.
00:46:36.710 - 00:47:27.698, Speaker A: And then we get a specific date by accessing the IPF files from the parent product ID. And third, according to this, ID interact with Insulator again to query the comparison IPFS drives. Finally, we'll go back to the first step. This is the our demo, which is the atom. Yeah. We see the list atom ID. We know the chart.
00:47:27.698 - 00:48:02.500, Speaker A: And when we move the mouse to the specific atom, the parents and the children's, not a select atom, a highlight. Okay. And if we are a company, you can also add the production information of the item. Now we select the date. Yeah. And we select the company. Okay.
00:48:02.500 - 00:48:46.976, Speaker A: We select the material ID who is the father of this product. Okay. We subsides, and the technology we use is the Ipfis. Thank you very much. Thank you. Okay. Thank you, Team Hyben.
00:48:46.976 - 00:49:03.290, Speaker A: So, yeah, we'll open it up to the judges for any questions, comments, feedback. Okay. I need Interpreters. Thank you. Yeah, I think we've got Ken on the line from the Ethereum Foundation. Hey, Ken. Yes, I'm here.
00:49:03.290 - 00:50:16.070, Speaker A: Do we have any questions? Sorry. Yeah, sure. I'm going to give my Mandarin a shot, actually. Dubai what is Dongwan tiangapuhao ruko ninjantu shi tian yoshaman nehrong ni hui tia tia chi zaka yang moon zhong holiday shanghai joshua SHO xiang Baniga yama woman shi chin mimashi yanjo shu aho Yamaji shamu yodinji woman joe so Mahui jarunika mimi mashi shanghuanda is. Yeah. Um bishop shopping. Zhou rahul kanka nominal Jaroni nigga shin shi the chapin chapin say yung proven.
00:50:16.070 - 00:51:19.114, Speaker A: Proven saying different. Okay. Rahul shiba teacher mantaja the Gosheni it's possible that I might ask the same question, because I didn't actually catch much of what you said. Sorry. I asked, if they had more time, what else would they have added to the project in terms of features? And they mentioned sort of identification, verification, amongst other things. Yeah, thanks for that. My question, Kenneth, is about whether they've estimated the cost of storing and changing this data and the references to the data on the Ethereum blockchain.
00:51:19.114 - 00:52:55.630, Speaker A: Like, given a particular tracing history of a particular item, say, if it has, like, 30 entries or 40 entries, how much would it cost to continue sending transactions to Ethereum in terms of the transaction cost, the gas fee, and the storage cost itself, which percolates as gas. I don't know if I can do that. I think Min her Chinese is much better than mine. Okay, so how many Rugo, Ethereum, Bijao Toy, then? It transaction cost hubahoy. What is it if we do 30 to 40 transactions? So an item with maybe 30 or 40 tracing entries, like, what would be the cumulative cost of tracking the history of that item? It okay, so Sanjay Dao says there's a transactions hoy ji kwe shama tai shua Yanchu Yanchu Harasha madonshi Yanchi. I don't know what that is. Transaction.
00:52:55.630 - 00:53:27.560, Speaker A: What was the transactions? What are we doing? You say tracing calls. Tracing calls. I don't know how to say tracing calls. Let's try this. Tracing. I don't think this is right either. Google Translate says that's not right.
00:53:27.560 - 00:53:59.150, Speaker A: I don't know how to translate that one. That's hard. Actually, I might be able to figure it out by looking at the source code. Something that transaction. Joy shima. Okay, sorry. Nakawan t shu naka tong tu huafe.
00:53:59.150 - 00:54:25.810, Speaker A: Beginning to end. Sutu shao nigga. Time kim time huafema time spent. This is tian. Tian huafe. Oh, Tian Huafe. Yeah, I forgot.
00:54:25.810 - 00:55:01.486, Speaker A: Sorry. I think I've upset a lot of people with that question. Chinese you. Thank you so much, Team Hybin, for bearing with us here. And thank you, Ken. Ken's going to stay on for the next one as well, where we're also going to have a translator. So up next, we've got Team TJ wallet, light.
00:55:01.486 - 00:55:27.190, Speaker A: So I will play your video for you. I understand that there's no audio for the video, and so we'll play that, we'll view it, and then we'll have Q A afterwards. All right, give me a moment to get this set up, and then we'll be rolling. Okay. We are the team. TG wallet light from China Then I will. Oh, yeah.
00:55:27.190 - 00:56:07.490, Speaker A: It's a video. Great. So I'll play this, and then we can do a Q and A. Okay, thank you. Maybe I can. You the TG Village Light. I find the video is no sound.
00:56:07.490 - 00:56:42.970, Speaker A: Sorry. Do you want to speak over the video? That's fine if you want to, but I'll just keep it playing. Bao chiang kin. Hello. Kino Hungary. Video? Yep. In Kong Yippin Leon legal video case, a high phone has a wabi.
00:56:42.970 - 00:57:07.474, Speaker A: Joe Jojo got him. Bower yong nigga yong. Fine. Kong on. So he's just showing the video and showing how this how it works. How do you want him to do this? You want him to talk through it? I just want to play the video. If they want to speak over the video while it plays, that's fine.
00:57:07.474 - 00:59:55.626, Speaker A: Or we can just watch the video. You can just watch over video first. Great. Okay. All it's new performing what I should michelle and Tush. Great. Thank you.
00:59:55.626 - 01:00:43.822, Speaker A: TJ wallet. So, yeah, we'll pass it over to the judges and ken can help transit as before. Good guys. Hello. Come. They call it jojo called fine kongbao yung nanginbao Moxin okay, so this is their custom made file coin wallet. And it includes we have the blockchain wallet before and now we just made a funkon wallet just for you guys.
01:00:43.822 - 01:01:31.340, Speaker A: And this is how to say that customized. And also we have the hardware wallet. This is the first 2nd you can see we have a lot of information like fine coins on other blockchain information inside. And this all the information the data and we have to say that save this data on the IPFS. Just we use the IPFS technology to make this void. This is second and the third. And you can see we have a lot of DApps over 3000 inside.
01:01:31.340 - 01:02:58.770, Speaker A: And so we build develop tools SDK to connect DAP and to find coin. I think there is a lot of app or webs games or other how to say that other programs want to join finecom but didn't how to get in. So we build a state SDK to let them assess and then they can work with us together. Nice. That's very cool. Any questions? Yeah, presentation was a bit blurry for me, but the UI looked pretty cool. Are you planning to allow people to do transactions, wallet transactions as well? And if you do, you have an idea on how to make the UI model the payment channels that Filecoin has? So filecoin has this concept of payment channels and you can send vouchers and you can settle a payment channel and so on.
01:02:58.770 - 01:05:01.358, Speaker A: So I don't know if you've thought about the UX flow of how that would work payment channels, transactions so come on uxim bigger user, high team fatsang ed transactions jungle young hama hama kuman gao beijong hoi Joe so my dumb dumb and Lumber. Yeah, but okay, he says the transaction flow is actually already there and it looks like a normal transaction. So he has a high quality video. I guess it just didn't load well. We have faucets to get file right? The file con right? And in our wallet we also do that. We can let them people how to say that sao kun dim gong Saokun Kuri download fine con wallet fine kong like fine kong yong for Saokun. Okay, so Saokun, could you approve? Could they approve? Go faucet hi.
01:05:01.358 - 01:06:00.002, Speaker A: Okay, so he said the faucet is already baked in the wallet. I guess it pings your server. You guys have to approve the faucet and then it goes to their wallets and they're able to transact directly through their wallet. Hi. In the future we will help the fine coin user to approve faucet approved their account to how to say that to send transactions or prove the app to get information that they want to give them. Also, all this is already in our SDK. They have it, but the video is not very clear.
01:06:00.002 - 01:06:18.630, Speaker A: So we didn't see it. And if you can download our APK, you can see it already. Great. Okay, thank you so much. So I think you have seen the chat. We're going to take a five minute break now, so a chance to use the washroom. Judges, take some notes.
01:06:18.630 - 01:06:32.030, Speaker A: Thanks again. TJ wallet and yeah. See you all back in a few minutes. Okay. Thank you. Thank you. Thanks, Kenneth.
01:06:32.030 - 01:06:56.180, Speaker A: I tried. Good job. You got a free Mandarin encanto lesson. Thanks for having me. Thanks for considering me. Sorry to put you in the top spot, like, a few times I volunteered for this. I wish I was better.
01:06:56.180 - 01:11:25.980, Speaker A: Not a shame. All right, I'm going to hop off, but good luck to judging. Have fun. I'll see you all soon. It okay. Hello, everyone. We can get back now.
01:11:25.980 - 01:12:07.720, Speaker A: Judges, let me know when you are back on the video. All right, we got Min, we got Danny. So I'm here, but my video seems to be blocked for some reason. Okay, well, we'll see if we can get it working, but you can't start your video because it says you can't start your video because the host has stopped it. Interesting. I don't believe that I did that, but let me see if I can all right. I did that.
01:12:07.720 - 01:12:30.654, Speaker A: Sorry about that. Thanks. My audio is also way quieter. Is that just me or did that happen to you guys, too? Just me. Okay. Sounds okay for me, but by the way, Josh, I don't know if it happened to everybody, but the screencast was a bit blurry in the last two presentations or three presentations. Okay.
01:12:30.654 - 01:13:09.178, Speaker A: I don't know if it's like a bandwidth problem on my end or your end or something. Yeah, I'm not sure. I've got a lot of stuff going on because we have multiple videos loading all at once, so it may just be an unavoidable bandwidth issue. Unfortunately, these videos are available on the showcase and I can say the links afterwards. And anyone that's watching this that wants to see the higher quality videos, if you go to the Hack FS showcase, there's all the video links, all the repos, everything there. Okay, so next up, we have Upala digital identity. I think that I'm going to play this video again for you, Peter.
01:13:09.178 - 01:13:51.790, Speaker A: So I'll get that set up and then we'll get started. Greetings, humans. We are upala an anti civil system for the apps and the decentralized identity of the future. Today, there is no reliable way to tell humans apart from bots on Ethereum. Neither there is on the traditional web. And in Opala, we believe that over 1 billion people without aid is a part of the same innate human problem. Existing solutions out there measure the probability of personhood in percents.
01:13:51.790 - 01:14:12.182, Speaker A: We don't do that in Apala. Instead, our count score represents how much it would cost to forge this account. We have dollars instead of percent. Let's see how it works. The first concept is a group. Users join a group, they put their deposits in a group pole and the group assigns scores to all of its users. Notice that the score is higher than the deposit.
01:14:12.182 - 01:14:43.330, Speaker A: This is where the second concept comes in exposure Bots protocol. It ensures that anyone can delete their ID at any time and grab an amount of money corresponding to their score. Here, a malicious user is able to get $10 from the pool. Sure enough, other members will feel betrayed and they will not let this person in again. The third concept is stacking. The same way users join groups, groups gather into hierarchies. Superior groups may require deposits from east subgroups and in turn add extra scores to their users.
01:14:43.330 - 01:15:22.462, Speaker A: But the same scores will be paid as a reward to an exploding attacker. Group at the top may acquire large audiences this way and they may then charge the apps for providing user scores. Or they may earn interest on their huge pools. And the last concept is pass. Both an attacker or reviewed user need a membership path for the group hierarchy to prove their scores. These four concepts incentivize groups to gather large low explosion risk audiences. And users are incentivized to get the highest scores for the lowest investment of money for reputation, the market, similar to insurance, emerges.
01:15:22.462 - 01:16:01.198, Speaker A: But instead of trading coverage for premium in Opala, scores are traded for deposits. The user scores then roughly represent the efforts needed to acquire such a score or the price of forgery. And it is a very reliable metrics for the apps to assess human indigenous growth. Opala is a protocol. A variety of identity systems can be built with it, like the one based on friendship or on Dow membership. It can even wrap over multiple identity systems and communities, enabling scores that type higher than a black market cost of a state ID. So it has a potential to become a substitute for that.
01:16:01.198 - 01:16:28.200, Speaker A: And yep, that's our goal. But for now, we made this minimal viable anti civil system. The top group is the playwright. The other groups are entertast that auto assign scores to members of existing DAOs. An Aragon based Dao can change the scores and decide to add groups with other entry conditions. Let's see how it works. So first we register an ID.
01:16:28.200 - 01:17:03.614, Speaker A: Then we join a group. We are a member of Medifertel, so this group lets us in, no problem. So if we join and now Blade Runner assigns us a score of 15 die. Let's change the score. 20 die score. Now, notice the Blade Runner balance and our ID. So we're going to explode.
01:17:03.614 - 01:17:22.780, Speaker A: Now, that means delete our ID forever. Now let's register new ID, an empty one. We don't have anything. We cannot join any groups. And we can see that the playground balance is decreased. So this is how it works. Thank you very much.
01:17:22.780 - 01:17:42.654, Speaker A: Great. Okay, pass over the judges for feedback and comments. Hey. Hello, everyone. Hey, Peter. This is awesome. We literally were just having a conversation a few weeks ago about how someone needs to try something like this.
01:17:42.654 - 01:18:45.090, Speaker A: So very excited to see this project. So a couple of questions. The first one, are you guys using Ethereum keys as the identity or is there an abstraction away from that that lets you use it across different networks beyond just like the Ethereum network, we use Ethereum keys to access your ID. So an ID has a owner which is represented by an Ethereum key, but I think that upala could be blockchain agnostic, so we can use any blockchain for that. And so you said the ID has an owner. Where is that stored currently? It's stored in the smart contract in the Protocol Pala Protocol. It assigns a permanent user ID to users and to groups.
01:18:45.090 - 01:19:50.280, Speaker A: Got it. And have you thought about as you start to if you use a smart contract and are linking to Ethereum keys and then have users a part of multiple groups, are there privacy concerns about what users have to be disclosing publicly in order to get this kind of coverage? Sure, great question. Yeah, we are concerned with that a lot. Well, basically I'm not sure yet how to handle it, but I think it's possible in the future with probably some ZK snarks magic. But currently we are focused to deliver the MVP, so this is out of our focus right now. So I think that staking on identity and group identity is a really cool idea. It's very original.
01:19:50.280 - 01:20:36.604, Speaker A: Kudos on that. Exploding is one way to exit the group and it's kind of like the rage quit, I guess. Or kind of like, hey, I'm going to take the lucky pot or whatever. How would you deal with organic with natural rotation in that group? So if a particular member really does leave a group that represents a collective identity and this is genuine, how would you deal with that? Yeah. There are two different ways that you can leave a group. You can either explode or you can leave peacefully without explosion. So explosion means that you are stealing from the pool.
01:20:36.604 - 01:21:10.660, Speaker A: And as opposed to that, just simple leaving. You are leaving either taking your deposit or nothing at all. The group will decide what leaving peacefully conditions are. Okay. If there's no other questions or constantly judging panel, we'll move on to the next team. Thank you, Team Paula. Thank you, Peter.
01:21:10.660 - 01:21:37.198, Speaker A: Really awesome to see this project. Okay, thank you. Speak. Archivator, you are up. I see you in the chat. So unlike the last four, this time you're going to play the video, so I'll let you take it away. I don't hear any audio.
01:21:37.198 - 01:22:23.910, Speaker A: Robert. You can hear the audio? No, we don't hear the audio at all. You might have to stop the share and then restart the share and click the button in the bottom left corner of that dialog box. Let me try it again. All right, so we are the team speech archivator, and this is what we have built for the HFS hackathon. My name is Robert and I build this project with my friend Tian, and we build a program that uploads videos that contain a specific person to IPFS. And we build this because of the problems that are emerging from deepfake technology.
01:22:23.910 - 01:23:19.830, Speaker A: Deepfakes are videos or images that look exactly like real ones, but they are artificially generated. So, for example, you can have a video of some presidents talking about starting a war, but you have no idea if this video is real or if it's artificially generated. So for that reason, we came with an idea to record speeches of influential people and save them to IPFS so that we have a record of what the person said in history and how it works. It uses artificial neural networks to perform face detection in the videos. When we find the faces, we cut out video segments that contain the specified face, and then we can upload these video chunks to IPFS. And now it's demo time. All right, so on the right side is the project, and on the left side is the video in which we want to find Donald Trump speaking.
01:23:19.830 - 01:24:00.640, Speaker A: It's a video from the Telegraph about Donald Trump and the Coronavirus. You see that at the beginning, there is some background footage, which is not very interesting for us. But about 20 seconds later, donald Trump starts his speech about Coronavirus. And our goal is to cut out this part where Donald Trump is talking about Coronavirus and get rid of the beginning where no action is going on. So let me run the script to process the video. This is the part where face recognition algorithms are trying to find the Donald Trump's face in the video and cut out the interesting segments. And this takes about a few minutes.
01:24:00.640 - 01:24:55.836, Speaker A: It depends on the size of the video. All right, the video was processed, and if I play the process all right, the video was processed, and if I play the processed video, which is download transport now, we can upload this file to IPFS. So let me run the script to upload files IPFS. I'm running IPFS server in the background. Before. Since video files can be very big files, it's a good idea to split the video into smaller chunks. So that's what's going on right now.
01:24:55.836 - 01:25:46.620, Speaker A: I will split this video into three smaller videos and then upload it's. Okay, so we split the video into three parts and then upload it. Here's the IPFS web user interface. And if I refresh it, I see there are three files now, and these are the three video chunks I just uploaded a few seconds ago. And if you want to retrieve the video back, we can use this hash, which is basically hash of the video content. Yes, this was our project speech archivator and thank you for your attention. Great, thank you.
01:25:46.620 - 01:27:30.716, Speaker A: So yeah, open up the judges for comments and feedback. That was pretty cool. I think you definitely use a very controversial person that says a bunch of things and we probably want to as humanity want to archive some of those bits for posterity and for accountability and for traceability in the future. I could see a lot of such cases. Are you thinking about automating in some way? I guess this is kind of like the start of a project. But what are your thoughts on making this a fully automated bot or system that would spider streams on YouTube or whatever and detect the faces that you're interested in and pipe them onto IPFS and maybe use IPNs to sort of things like pub, subsystems and so on, to advertise whenever a new video has been uploaded for a specific person that users are interested in. Like what are your thoughts on automating? The whole process for now we are tracking YouTube channels of some famous magazines like CNBC, BBC and this kind of stuff and what we want to do is to look for live videos and get the interesting faces like some famous politicians from it.
01:27:30.716 - 01:28:43.860, Speaker A: So that's our goal. We are still having some problems with it. So for now we have a script which checks periodically for new videos on some YouTube channel and then process it. But our goal for now is to make it work life with the live videos, not just upload it, but the live ones. So that's our goal for the future. And then of course make some better front end for the users which can pick up the pairs that they are interested in and some time period or this kind of stuff or some events like promotion speech of President of Presidents in the United States between years 2010 and 2015 or something like that. This is super cool and thank you for your submission and how do you sort of ensure that on the counterpoint to this that it's not used for any sort of surveillance or any sort of unintended consequence? It doesn't sort of contravene any privacy concerns.
01:28:43.860 - 01:29:37.060, Speaker A: Yes, this is a thing to be solved. Actually there might be some privacy concerns like about the people tracked. We want to use it not for personal use but really for the US presidents and this kind of stuff and they are already on the tip on television in these days. So I don't think it would be such a big problem for these very famous people who are used to be on the tip on camera. But there has to be some proof that this really is like what they said and it's not modified in any way. This has to be solved, definitely. It would be cool if there was some camera which you could use it like camera connected with blockchain cryptography.
01:29:37.060 - 01:30:03.810, Speaker A: What was filmed on that camera is really like the truth. Okay. Thank you, Robert. Thank you. Speech archiviter, we're going to call up the next team now for their presentation which is Secured Finance. I believe you're on the call now. So if you want to share your screen, play your video, we'll get started and remember to click that audio share button.
01:30:03.810 - 01:30:29.140, Speaker A: Hi everyone. We will talk about a DeFi project called Secured Finance. Secured Finance is a financial transaction platform with automatic margin call system. So what are financial transactions? It's simply a collection of future cash flows. Please remember this shape. I'll go over four examples loans are basic form of all complex transactions. You borrow money and you have to pay coupons and return the money at the end.
01:30:29.140 - 01:31:01.084, Speaker A: If we flip the arrow, a loan becomes a deposit interestingly, if you combine a loan and deposit, you can make a swap transaction. It is a cross currency swap option is even simpler. It's just a conditional swap. If we can do loan, we can do others too. So our main focus is filecoin loan. Our target user would be miners, investors, hedgers and arbitragers why we made this project? Since IBM and the World Bank did the first cross currency swap, we have accumulated knowledge for almost 40 years. So we already have bottle tested protocol for finance.
01:31:01.084 - 01:31:33.700, Speaker A: And if you use the same protocol, all the traditional financial institutions can join us quite easily. OTC derivatives is peer to peer and has $600 trillion of size. We made the interbank market system open to public. We aim to gain 1% of market share but more conservatively, we are aiming to bring $1 trillion into Crypto economy. What's missing in the current DeFi is clear volume and new liquidity. We can't sell 10 million ether through an exchange. Also, we are missing time access because we don't have yield curve, we can't manage the future cash flow and that's why large corporates are slow.
01:31:33.700 - 01:31:59.264, Speaker A: So we are making a new market and opportunities. We also have liquidity provider with incentive mechanism to keep the bid offer spread tight and ensure liquidity. Our mission is to connect institutions and provide open finance. Our clients can provide secondary layer services to their clients. As an example, if a bank wants field deposit but a client deposits ether, they can do a cross currency swap. Let's talk about how we built it. Key components are built using smart contracts.
01:31:59.264 - 01:32:26.252, Speaker A: So we created these three smart contracts and designed at state machines. Here's a sequence diagram stored in our Git repository for margin call. Our contract calculate discount factors and get PV to avoid margin call, borrowers need to keep 150% coverage. Here's our UI components, we don't need to log in. Lastly, here's pros and cons of our service. We provide zero credit risk transaction because we have yield curve, clients can control the future value of cash flows. Thank you very much.
01:32:26.252 - 01:33:06.040, Speaker A: And here's our demo secured Finance crypto is a decentralized app. Deployed on IPFS using Flick. Here we have money market swap, FX, book history and Pipecoin page. First we will go to Book in order to set FX and Loan. After filling out all these input fields, let us set FX. Let's confirm. Let's now set loan book confirm.
01:33:06.040 - 01:34:12.104, Speaker A: When we head back to Money Market, we can see the values we set on Borrowers and Lenders tables to Lend. We select a row from Borrowers, click Lend and enter Amount and confirm it. Next we will go to History to see the list of loans and borrows we made. Here we can search, sort and filter our entire loan book. We can also pin our table to IPFS with Pinata cloud and the last one to see is Five coin Page where we generate token, create Five coin address and send it and this will complete state of our loan. Thank you very much. Thank you.
01:34:12.104 - 01:34:47.620, Speaker A: Secured Finance. We'll turn over the judges for feedback and comments. This is really cool. Go ahead. Sure. I love the UI as well and it's great that you guys built that during the duration. Could you talk to explain a little bit what you're using for price feeds and how you're sort of managing any sort of price volatility or fill as well? Sure.
01:34:47.620 - 01:35:51.576, Speaker A: So, speaking about the Oracle problem so in terms of Oracles, we thought about using outside price sources from Coinbase or Kraken at the beginning. However, their price is not executable because lacking of liquidity. So we decided to build suitable market for large size transactions and made ourselves as price Oracle so we don't need to rely on external sources and also for filecoin balance. Currently it is manual and the transaction hash and confirmation basis but we are building Lib P, two P based filecoin Oracle to automate this process. So let our teammate back to speak about this. Yeah, one of the main problems between Filecoin and Ethereum is how do we handle interoperability. In order to solve this problem, we actually created a peer to peer based peer to peer Oracle network which is kindly working as a way, as you might think about chain link.
01:35:51.576 - 01:37:11.240, Speaker A: Instead of using a chain link scheme where one node has its own set of smart contexts on Ethereum chain, we have peer to peer nodes which is messaging to each other using pubsap and then the layer of a consensus layer. Right now we're using Rocks Consensus but we're planning to migrate to practical BSc consensus, going to commit to the Ethereum blockchain as the state forms a file coin and that's how we are achieving the interoperability between two networks. Speaking about the motivation. Actually the original idea came from 100 hackathon idea by one and actually I drafted the sketch and talked with him and he liked it and then decided to join this hackathon and try to help Filecoin ecosystem. Because we are very much worried about Filecoin price fluctuation. That's because there's no place to trade large amount of currency. So we make the block trade platform to make the price much more stable and help to grow, helps the economy.
01:37:11.240 - 01:40:24.120, Speaker A: Okay, if there's no other questions from the judges or comments, thank you, team. And we'll bring up the next one for the presentation. So, next up, we've got access underscore Denied, and I understand that I'm going to play your video for you, so let me just get that set up and we'll get started. It's Sam. Sam. Sam. Sam Ram.
01:40:24.120 - 01:41:10.236, Speaker A: Okay, thank you. Access to naive. We'll pass it over to the judges for feedback, questions, comments? I really like the music of that presentation. It was really upbeat. Thanks for that. Thank you. Yeah, it's pretty cool to create tools to create marketplaces so that folks can connect with one another and sort of improve their skills and also earn prices.
01:41:10.236 - 01:41:55.600, Speaker A: That's pretty cool. It would be interesting to see kind of like the whole workflow where potentially when Adapt is let it pass for a second. Sorry for that. Imagine Adapt is approved. It would be really cool to be able to deploy to production immediately by deploying the smart contracts that are associated right. And potentially deploying the website on fleek, which goes to IPFS and so on. I don't know if you guys have thought about what comes after the approval of Adapt.
01:41:55.600 - 01:42:44.060, Speaker A: Yeah, we have actually thought of deploying it in the unstoppable domain so that it can go live right away. That's the main motive. But right now, we are also thinking of making it further improvements, including staking, so that there will be decent behavior in our platform. So that's the main motive. And also to make it production ready. That's the key endpoint. And also we could show a small demo if you want, because the whole demo, we tried to put it in the video and turned out to be out of 25 minutes, so we had to cut short on the video timing.
01:42:44.060 - 01:43:15.240, Speaker A: Yeah, that actually be really cool. I don't know. Josh, what do you think? Yeah, we've got a couple of you know, if it's just a minute or so, that's no problem. We got about two and a we can just show the profiles present in our platform. My teammate Monalica will present the screen. Yeah. So can you see my screen? Am I audible? Clearly.
01:43:15.240 - 01:43:42.800, Speaker A: Yes. Both things all good? Yeah. Okay, so this is the like, I have logged in as a solver so I can see the solve button. So this is the profile. Like, I can see the questions that have been uploaded. If I click on Solve, I'll get the dialogue for uploading my smart contact and giving the README file. And now I can show you the publisher profile.
01:43:42.800 - 01:44:13.992, Speaker A: I'm logged in as a publisher. Yeah. So this is the publisher profile where you can upload a question. There are two options. He can either upload for a smart contract or for a DAP plus smart contract, he has a reward that he can select for the smart contract and DAP. And there is a time limit and these are the questions that he has uploaded for now. This is the DAP.
01:44:13.992 - 01:44:56.760, Speaker A: Only one solution is being uploaded for that question. So he gets this and if clicks on approve, this is an escrow contract that we have initiated for this question, this was completed. So like the publisher will first initiate the escrow so he can chat with the DAP person who has uploaded the solution. And then after the DAP person, he clicks on ownership transfer. Like he transfers the ownership, the publisher will come to know about that and he can confirm the payment. That is reward distribution to the DAP. So this is how the stages are after commission of a solution and for voting.
01:44:56.760 - 01:45:40.836, Speaker A: So as I'm a voter, this voting part is only for the smart contracts, but for the DAP. The publisher has the right to choose which DAP he wants to approve, as I showed you in the previous page to the escrow. So if I click on vote, there are no solutions uploaded. So if there are solutions, there will be like like and dislike button. So a voter can like or dislike a solution. Yeah. And this is the get roles portion where anyone can get a role publisher solver DAP or a voter.
01:45:40.836 - 01:46:20.288, Speaker A: Because if he doesn't has any role, he can just see the questions. He'll not get any interactive buttons on our platform. So this was the quick demo of our platform. And for the DAP profile, we also have a DAP profile. This is the DAP Login. There's a DAP profile where you can see the DAP that the solver has uploaded. If he clicks on view, there's an escrow contract.
01:46:20.288 - 01:46:49.660, Speaker A: This initiate button can only be done by the publisher because he'll select which DAP he wants to approve. Ownership transfer is done by this DAP person and the confirmed payment will be done by the publisher. So these buttons are placed according to that. We're a little over time now, Monalicia, so I'll probably have to stop you there. But thank you for the demo and thank you team. Access denied. So we're going to move on to the next team up.
01:46:49.660 - 01:47:22.666, Speaker A: That is censorship resistant web annotations. I believe you're on the call already and I'll let you play your video and we'll get started. Okay, I'll play the video now. Hello everyone. This is our demo of the public annotations network. We build this because social media websites can censor data. They can delete or mutate content.
01:47:22.666 - 01:47:50.210, Speaker A: People can block you. There are tons of ways that you can be censored today. And every day society becomes more dependent on these centrally controlled platforms. Web annotations are a nice way to promote discourse by enhancing web pages. And they are also a W three C recommendation. So using web annotations on top of IBFS and Ethereum, we can reduce the censorship attack vector. So let's now go to a quick demo and then we can explain how all of this works.
01:47:50.210 - 01:48:45.458, Speaker A: So here I am on Twitter and I already have the Pen web extension installed, which is signaled by this yellow pen here. So I can come here to the suite page and I can write something and I can say, whoa, this looks super cool. And then I can comment that when I do so, I essentially take my Ethereum wallet and I sign the message which proves that I was the one making this annotation. This web annotation is then wrapped into a verifiable credential which is what contains the signature and allows for anyone to verify it. So at this point, my comments has been published and if I go back, I can see it here. Now I can go again and I can do another one. If we come into another browser and we open the exact same page so this exact same tweet just reloading so everyone sees that this is fresh.
01:48:45.458 - 01:49:23.650, Speaker A: We can open the annotation here the extension, I mean, and both of them are here, which is super cool. Okay, so how does this work? The web extension allows for an easy user interaction. Then we have a publishing service which broadcasts and caches annotations. And then we use a subgraph from the graph for easy data access and integration between IPFS and Ethereum. So someone submits an annotation, the publisher takes it, stores it on IPFS. Then. Manipatchi's fool makes an ethereum transaction.
01:49:23.650 - 01:49:58.510, Speaker A: And then the graph captures that Ethereum transaction data and sends it either back to the publisher or directly back to the extension. So, back to some questions now. Why do we need a publishing service? It is very important for the system to keep track of the canonical order of all public annotations. It's the only way to make sure that none of them disappear and are censored. So we store annotation logs on Ethereum. However, doing one transaction per annotation would be extremely expensive. Just imagine having to pay for every single tweet or comment that you make.
01:49:58.510 - 01:50:36.970, Speaker A: So we came up with this optimization. It's a publishing service that can aggregate transactions and allows just one transaction to record any number of annotations. It could be one, it could be 10,000. It really just depends on how long you want to wait for the transaction to be processed. This service is not a single point of failure because anyone can run their own. They just need to take the server code and run their own. So what's next? Well, the first thing naturally is to deploy to mainnet and then implement native interactions with IPFS and Ethereum so that anyone who wants to be totally decentralized can be totally decentralized.
01:50:36.970 - 01:51:02.820, Speaker A: Then we could work on creating a network of publishers. So having several entities running their own publishing services and those entities could then figure out incentive mechanisms to support the infrastructure and transaction costs. We can just imagine that with Ethereum too. This would be insanely cheaper. That's all we have for you. We hope you enjoyed the demo and check out the GitHub repos, install the extension, play around with it and let us know what you think. Thank you.
01:51:02.820 - 01:51:35.346, Speaker A: Awesome. Thank you. Thank you. Pan over to the judges. This was very cool. It looks like a great project. Is the intention that this would always be public annotations or did you also think about private? Or for example, like team annotations for web pages? So we didn't really think about it.
01:51:35.346 - 01:52:10.458, Speaker A: I'm guessing for private annotations you'd have somehow to encrypt the content and share some key for other people to be able to see it. Yeah, I think it can be done, we just don't have it. Right. Like an answer to you right now on how we could do that. But that's my answer. Yeah, it makes sense to start with public comments, for sure. We did implement or actually we have a design, I'm not sure the code is there a mechanism for whitelisting so that you are only exposed to the ones that you want because that's a way to prevent spam.
01:52:10.458 - 01:53:00.060, Speaker A: Because if this becomes super cheap, then everyone's going to use it and then you just become spammed by everyone, which is not desirable, obviously. That's cool. That's super awesome. I was wondering if you guys thought about how to make the solution work. Even if the URL to which you're attaching content to changes over, like, how would you canonicalize A? Yeah, that's a very good question. So right now we built this one for Twitter because we wanted to get something done fast and Twitter is just the most popular thing. So the way we are identifying the way we figure out how to show the comments based on the tweets is based on the username and the tweet ID.
01:53:00.060 - 01:53:38.294, Speaker A: So if the tweets URL changed tomorrow, as long as we had some clue to who the user is and what the tweet ID is, we could still do it. But then you can think of other things. Maybe what we could do would be take the data of the tweet, take the content of the tweet itself, hash all of that. That becomes the ID that we use to point to the thing. Right? Yeah. Then just becomes like how do you fingerprint that content? Because it'd also be pretty cool to be able to show it on the Twitter feed right. Which is not right now because on the Twitter feed it's always the same URL, but you have tons of tweets, so we cannot simply just grab the idea of each one of them.
01:53:38.294 - 01:54:13.860, Speaker A: But yeah, we thought about all of that. Just super complex stuff to get done very fast. I'm also thinking about deleted tweets. Right. Which is also a you would you could leverage IPFS and take a screenshot of the tweet and publish it to IPFS. And then when you visit the profile of that particular user, you could display a badge if you've detected deleted tweets or something like that and recover those from IPFS along with a comment thread. If that happens, you can also think about a decentralized Internet Archive to use this type of stuff.
01:54:13.860 - 01:55:01.700, Speaker A: And you can also include the tweet inside of the web extension. I think part of the web extension spec is that you can actually include the original content. So we could also do that and it will all be encapsulated in the same standardized data format, which is awesome because then other applications that implement the spec, it would just work with everyone, right? Yeah, this is super cool. And as a follow up to that, I saw you also built a subgraph. Are there any sort of applications that you imagine being built on top of the network or any sort of integrations with other sort of similar tangential products? Yes. So the good thing about this is that it's super agnostic. It works on Twitter today, but with minimal modifications, can work on any website for any content that you want.
01:55:01.700 - 01:55:40.960, Speaker A: So we could very easily change it to work on something else. It's just really a matter of, like we discussed first, how do we identify content, how from that content you decide what to and thinking about more services. You could actually think about the publishing network, which is this set of parties that take your annotations and actually issue them to IPFS and Ethereum. You can think of a lot of business models to support that. You can think donation based models for things that are really important that the community cares about. You can also think of a model where you pay a subscription and then you are allowed to do X comments per month or per year. So yeah, tons of interesting stuff that we can do around this.
01:55:40.960 - 01:55:59.126, Speaker A: Awesome. Okay, thank you. We're out of time for this one, so we're going to move on to the next but awesome presentation. Thanks so much for being part of Hackafs. So the next project is our last one for today. This project is IPFS Recovery. And I understand that.
01:55:59.126 - 01:56:57.852, Speaker A: I'm going to play your video as before and then we'll move into Q A. So let me get that set up. This video is our submission for Hackfs 2020 IPFS recovery. Coming into this hackathon I had some experience working with erasure codes in the context of distributed systems and I thought this was a very natural solution for IPFS, which faces some problems that we'll fusion shortly. Some of these problems are data corruption, which can be caused by things like coffee pouring on your laptop, or a lightning storm taking out the power grid of an entire city, which can cause losses and potentially vital information. Another problem is node churn, which is when nodes just drop off for whatever reason, for example, their power could drop off, or the person just closed your IPFS client. Permanent availability of content is not guaranteed in the face of censorship.
01:56:57.852 - 01:57:37.656, Speaker A: This is a pivotal problem that IPFS purports to solve, and has been doing so for the last few years. Attackers can go to any extent to try to get content off the network, and it is our prerogative to ensure that data persists at all costs. Finally, availability of resources is hindered by transient connectivity. When a node is downloading information from another, it could fail to download the information properly due to a faulty internet connection. The solution to these problems is erasure coding. Erasure coding is a method of data protection in which data is broken into fragments, expanded and encoded with redundant data pieces and stored across a set of different locations or storage media. What this actually means is data that is erasure coded becomes a sort of hydra where you chop off some of the heads.
01:57:37.656 - 01:58:26.360, Speaker A: They can be regenerated, and it's impossible to get rid of it unless you destroy most or all of the data chunks. It's actually worth consuming some extra storage to obtain this better data resiliency and even routing performance, as perhaps redundant chunks could be a fewer hops away than data chunks. What we actually built is an abstract erasure coding module that operates over IPLD merkel Dag. There is an elegant integration with Goipfs, along with CLI utilities that you'll see shortly in our demo. How this works is that the root node of a content dag is passed into the encode function, which operates on the entire Dag according to the instructions specified by the erasure coding scheme that implements our module. We created two set schemes. One is the industry standard retalement code, which is used by a lot of big companies such as Facebook and Amazon to protect their data centers.
01:58:26.360 - 01:59:11.070, Speaker A: We also implemented a novel alpha entanglement code which features a simple self healing parity lattice. This is bleeding edge erasure code technology, which is being actively investigated by distributed systems researchers, notably for Ethereum's Form. We also wrote some test plans using testground for simulating network interactions and seeing how network holds up. So now we're going to see the CLI client in action. First the client is initialized and a folder filled with files is uploaded onto the network. Then the folder is encoded. Following this, the refs are displayed so we can see what the contents of the folder are, and randomly selected blocks of data are deleted.
01:59:11.070 - 01:59:58.022, Speaker A: And finally we can see that the recover function still works. So why does IPFS need recovery? Data distribution in the limitless manner that is in the core of IPFS requires strong data integrity. We want to ensure content persists on the network at all costs, and further recovery is a long requested feature for IPFS on various layers. There's an open issue from 2016 on GitHub that proposes retalme and erasure coding there are currently no existing solutions, especially ones that natively work with the IPLD merkel bag, which is why we thought it would be awesome to integrate something directly with the core. Finally, it's a modular interface for any pluggable erasure scheme. So in the future, if there is something much better than anything that we have ever seen before, we could just plug that right into our module. We have quite a few plans for the future.
01:59:58.022 - 02:00:29.842, Speaker A: Namely, we want to upgrade to the more complex offense anglement parity latice. This will allow us to create self healing networks which can tolerate a lot of faults. And further, we want to take this down to the DHT overlay network level so that we can actually have low level routing performance increase as well as resilience. We want to create some specs for formalization through active discussions in the community. We also want to create JavaScript Go and other language implementations in the future. Finally, we want to battle Test, the network empowered by erasure coding resilience. This is the awesome team that brought you this hack.
02:00:29.842 - 02:01:14.846, Speaker A: Thank you very much. Awesome. Thank you. So, yeah, we'll pass it up to judges. I think you're hitting the nail on the head with this idea. As you duly noted in the presentation, it has been a long standing request and definitely it can be applied at many layers. And the fact that you picked the IPLD layer makes it almost like generalizable to everything else, which is really awesome because you pick kind of like the foundation of the way that data is encoded across the stack.
02:01:14.846 - 02:02:08.766, Speaker A: So that's pretty cool. I really like the fact that you use Testground spoke very near and dear to me. Pretty cool to see that in action. I was wondering a couple of things. Can you tell us more about the team that built this? How did you get the idea? What are your future plans? Are you planning to contribute this to IPFS or spin it off into a business or something else, or loan standing project or something else? And yeah, how was your experience with Testground? So I'll answer the first couple of questions. So I have been working with erasure codes for about a year ish for a company I started a couple of years ago. It does erasure coding.
02:02:08.766 - 02:02:42.800, Speaker A: I worked with someone else who was like a patented erasure code. So I learned a lot about the field and I learned about some stuff that's happening in this space, the ethereum ecosystem and so on. In fact, I was in touch with some of the researchers who developed alpha entanglements and they gave me a lot of resources on how to implement this and thought, you know, this would just be great. I ended up meeting Cleeb and Sarah during the hackathon and both of them are extremely well experienced Go coders. So yeah, that was really great. As for the future, yes, I do think we want to add this into the IPFS project. As I mentioned, we want to discuss with you guys, see what you guys want.
02:02:42.800 - 02:03:30.558, Speaker A: Because I'm sure you guys have some ideas on how you want this implemented. So collaborate and figure out how to move forward. And if the others have anything to add to that, I'm suggesting you to look at source codes, how it's implemented, like how we did actual, how we put it into the IPLD layer. Because in the first version, even zero version. Because I know that there is incoming version go APPLD prime and we haven't had enough time to dive deeper in that. But we have actually working recovery for garmin IPFS. Also, I think you haven't seen anything in the demo because it was blurred.
02:03:30.558 - 02:04:09.266, Speaker A: But I can do a live demo if you're interested, or you can try it yourself on our GitHub. There is an explanation on step by step how you can try out. We have a forked version of IPFS with the new CLI that integrates this. Also there is a description how it's all integrated. So if you're interested, just go ahead and look at this. Josh, do we have time for a quick demo? Do other judges have more mean? This is the last team, so I think it's not a big deal if we go a bit over time. As long as the judges have a moment for it, certainly no objection for me.
02:04:09.266 - 02:04:43.660, Speaker A: Let's go for it. Yeah, demo would be great. Okay, let's start. Share my screen. So can you see my terminal? Let's start from the scratch. I'll remove IPFS. Then I'll do IPFS init empty one.
02:04:43.660 - 02:05:15.380, Speaker A: Then what I'll do is IPFS add. I'll do this. There is a directory that has bunch of different photos. You'll see them next. Also I'll use a CD version one. So nothing special here. Just logos filtered by the protocol apps, ethereum foundation, consensus, like all this stuff.
02:05:15.380 - 02:06:09.698, Speaker A: This is not important. Then what we can do is IPFS encode recovery encode. I'll use the suggestion so we can see that hashes here match recovery encode. What this does, then it produce hash of the encoded version for this hash. Also I think we should add it's quite easy to add a new option for IPFS app that will just do the same thing as chunker where you can specify the algorithm and maybe some there is a recoverability option that can like I'll discover it later if you're interested. So we have this encoded hash. Then what we do is IPFS refs on that hash.
02:06:09.698 - 02:06:51.190, Speaker A: Also recursive. This way we can see all the blocks. This root CB is pointing to like whole deck. Then what I'll do is I'll just remove bunch of them randomly. It doesn't matter through block REM just any of them. This one and maybe this one, this one. So those are deleted then IPFS.
02:06:51.190 - 02:08:01.050, Speaker A: Then what we can do is actually use plain IPFS get to retrieve this hash and it onto K and we will still be able to get it as well as on the other side, like meaning on the network that is connected to our node and it sees that we serve this hash. So let me first doesn't matter. Okay, pfscad so I'll do this offline for you to see that you won't fetch it somewhere else. And as you seen, this is plain IPFS without any data. So we see those error message, those are not important. This is just a small hacking implementation. But actually we were able to get the content even we removed those blocks so they were not existing.
02:08:01.050 - 02:08:45.722, Speaker A: I'm not sure if it's enough proof for you that it works as it works, but I totally trust that it works. I was interested in seeing it in action. This is pretty cool. I could see that the size of the recovered blob is obviously a few magnitudes larger than the original directory was packed, which makes a lot of sense. It would be pretty cool to see this integrated with Bitswap and potentially graphsync going forward. I think there's a lot of stuff that we can do at the graph sync level to be able to convey metadata about the erasure coding policy that has been attached to a particular blob or a particular IPLD node. There's a lot of stuff that we can do there.
02:08:45.722 - 02:09:34.780, Speaker A: I think you've built some pretty interesting plumbing for this that then needs to be percolated such that we can represent the erasure coding policy at different layers. So that when you go out and fetch a particular blob, a particular IPLD node of which several leaves have disappeared from the network, you will backtrack and realize that you can actually recover those leaves using the data that you already have. So yeah, it's pretty awesome. This definitely got my juices blowing. Pretty cool. I want to say that this is implemented on a dark service layer, meaning that it actually works on top of Bitswap. So Bitswap doesn't know about all the magic happening here.
02:09:34.780 - 02:11:15.062, Speaker A: There is one issue before making it fully working on the network, like where you can do one multiple nodes on the network, one node adds the file, deletes some blocks and other node just tries to get it. It actually can get the blocks, get the file, the content, but it should wait for till the node understand that it can find those blocks on DHT. So we need to add just kind of like there is an issue on a GitHub with several solutions for that. So from the user standpoint, it's hard to understand where's the moment where we should recover the blocks because the doc service waits for blocks and it can wait till the context is canceled or other stuff. And if we just do recovery by default, it will recover once we get enough amount of files where it can just start a timer, wait for some time like. Start a timer when it understand that we have enough blocks to recover missing one, then wait for some time out and to do actual recovery, we could totally share some ideas in an offline discussion. One potential way is to I'm thinking about if Recovery running the recovery function on the partial set of blobs that you've already retrieved is not too costly.
02:11:15.062 - 02:11:48.580, Speaker A: You could run this on a loop, essentially, or for every blob that you receive, or maybe with some debouncing there to make sure that you're not running it too frequently. Yeah, but it's pretty cool. Yeah, I'll have to jump in there because I got to steal these judges away for a bit. Thank you. IPFS Recovery. Thank you to all the teams who presented today. It is so exciting to see what got built over these several weeks of seeing you all work so hard from a distance in the slack channel, but it's amazing to see the final product.
02:11:48.580 - 02:12:07.030, Speaker A: So thank you again. Hope you can tune in for some other judging sessions, and we'll see you with the closing ceremonies, which will be next Tuesday. Judges, if you can stick around, I'll send you another call link. We'll do a quick debrief, and then we'll be done. Okay, thanks, everybody. Bye.

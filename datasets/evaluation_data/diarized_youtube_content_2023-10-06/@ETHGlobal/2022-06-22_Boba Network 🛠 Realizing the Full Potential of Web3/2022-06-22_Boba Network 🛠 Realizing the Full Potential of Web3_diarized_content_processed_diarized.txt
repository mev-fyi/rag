00:00:06.250 - 00:00:56.950, Speaker A: All right, good morning. Thanks for coming to this workshop about realizing the full potential of Web Three. It's really about how why we build Boba Boba network, and what Turing Hybrid Compute, which is only available on Boba, would help developers build more engaging, more more interesting, more compelling Web Three applications. So let's go back in time a little bit, right, to the original creation of Ethereum. And a fundamental premise of Ethereum is that while Bitcoin, which is a ledger, is good, if you can actually program it, it's even better computers better. And our hypothesis is that let's take it one step further. A more connected computer will lead to a more creative and powerful decentralized system.
00:00:56.950 - 00:01:36.640, Speaker A: Just to give you an analogy, right, we all have a phone and imagine creating mobile apps without the cloud, right? You're limited to what you can do on the device itself, and that's it. You can still build apps that run on the phone, but it's not nearly as interesting, right? And that's what we do here. So we started with Bitcoin, bitcoin script, minimal stack based programming language. It's really designed, it's very transactional oriented. It's not terrain complete. And then Ethereum came along. Breakthrough innovation.
00:01:36.640 - 00:02:17.224, Speaker A: However, it is slow, as we all know, and there's a good reason for that. Ethereum wasn't designed to maximize to optimize for raw compute performance. It's designed to be a decentralized system with thousands of uncoordinated nodes that could somehow come to agreement on something. And that's really hard. And in order to achieve that, there has to be a lot of limitations imposed on the kinds of computations that you can do, that we can do. And for example, you can only do integer operations. Reason is if you allow folding point operations.
00:02:17.224 - 00:03:10.232, Speaker A: What if two computers are running on different CPUs and they come at arrive, has slightly different answers? They won't be able to come to consensus. That's why Ethereum is slow and the computational complexity is very limited. We can only do pretty basic computations, can't even take the square root of a number and get a reasonably precise answer. But then L two s layer twos came along. And the original motivation for creating layer twos is to address the most obvious challenges of Ethereum, which is speed throughput and cost. There's actually an additional major benefit, and that's enabling more complex computations. And that might seem a little bit counterintuitive.
00:03:10.232 - 00:04:12.320, Speaker A: People don't think of layer twos as a little bit deck kind of benefit, right? Most people think of layer two, oh, faster, cheaper. Oh, that's awesome. Let's just move our transactions to layer twos. Well, the key difference what is a layer two? A layer two really is we're decomposing this monolithic layer called Ethereum that combines execution sentiment and data availability all into one layer. We're taking the execution layer, separating that into its own layer, and we're calling that layer two. And the key difference between layer two and layer one is that the layer two doesn't run its own consensus protocol, right? The whole point is that we rely on layer one for consensus so that we don't need to do our own separating these two. Now suddenly because of that, we don't need to worry about what it takes to ensure thousands or tens thousands of computers would arrive at the same answer because layer twos are only responsible for execution.
00:04:12.320 - 00:05:07.052, Speaker A: And what does that mean? Right. It means we don't need to impose the same kinds of constraints on the kinds of computations. You can do as you would need to on the layer one and that changes everything. So on layer twos there's only a single sequencer that produces a block. It executes the transactions. And therefore we thought, well, maybe we could use this to our advantage, to developers advantage to interact with the outside world to call external API. And after a year's worth of work, we're able to overcome EVM's restrictions by modifying Gas.
00:05:07.052 - 00:05:37.680, Speaker A: So we have a customized version of Gas running on Boba network. It's called LTT for Turing LTT guest with atomic support for generating random numbers and making any external API call that you specify that you should. And it's super simple to use, very easy. These are one line calls. What you see on the screen is pseudocode. But like, look at the first example. Turing get random.
00:05:37.680 - 00:06:22.650, Speaker A: That's all you need to do to get a random number. On the second example, specify the RPC endpoint that you want to call to, let's say, get the current vault for BTC USD pair. Boom. Like one call and you're done. Now, how does it work? So let's look behind the scenes a little bit. So our LTT gap is the one that actually makes the external API call on behalf of your smart contract. So it will intercept certain calls that has Turing calls embedded in them and then call the option API or brands to generate a random number.
00:06:22.650 - 00:07:24.552, Speaker A: And when the results come back, our guest would replace the original call data with modified call data that includes the responses that come back from the off chain call. And this is important because we need to ensure that these transactions can be verified afterwards by the fraud provers. We need to make sure that whatever we've done is fully compatible with the rest of the optimistic roller architecture. And so we'll write both the original transaction and the modified call data that includes the offchain API responses into ethereum layer one. And from that point on, everything is treated just as if it were a normal guest transaction. And the key is only the sequencer would call the API, no one else. Because if you let other independent nodes call same API, you might not get the same results back, right? So it's important that only the sequencer makes the calls.
00:07:24.552 - 00:07:58.920, Speaker A: And then once the layer two block is written back on layer one and the verifiers and the Replicas will use the stored responses from the API call from the block to do their job. So here's a diagram that outlines how that works. So, step one, LTT. GAAP would intercept the RPC. You would make an RPC call to the gap. And our gap would be like, okay, this is a Turing call. It is.
00:07:58.920 - 00:08:39.270, Speaker A: It calls the endpoint that you have specified waits for the response to come back. If the response doesn't come back, it's going to time out. We've set the timeout currently at 1200 milliseconds. So when you're writing around this, you want to have a graceful fallback default value in case the external API doesn't come back or takes too long. So the response comes back. Our get would replace the original call data with updated input. That includes the response that comes back from the option call, creates a new block and submits that to layer one.
00:08:39.270 - 00:09:21.698, Speaker A: And then new block gets indexed. Replica does this work. Verify does work. Everything else just worked. It's taken us a while to roll this out on a Mainet because there's a lot of work that needed to happen under the hood. These are some of the changes that we needed to make. So we modified EVM go and modify the Ethereum block format to include the responses from the off chain APIs.
00:09:21.698 - 00:10:03.138, Speaker A: And all of the data from off chain APIs are written back to Ethereum, layer one. So as a result, we put a limit on the size of the response string that comes back. Otherwise these calls could become really expensive. And then we also added the ability for Guest to replay these compute requests based on the data that's written to Ethereum. We also modified a bunch of internal data types and finalized an Assemble and other parts of L two gas, minor worker go. We also needed to modify of services that pass data from layer two to layer one. How you index layer one.
00:10:03.138 - 00:10:46.610, Speaker A: How you inject layer one data into the layer two gas. And then we tested and tested and tested. Finally rolled out Turing on Rinkobe during East Denver and then a month later made it live on maintenance. And by now, developers have started building on Boba using Turing. And I'll give you some example use cases. For example, you can build DeFi protocols based on blockchain assets such as real estate or some sort of bonds denominated in fiat and traffic world. You can now start pulling these fiat world real world assets into DeFi protocol.
00:10:46.610 - 00:11:33.790, Speaker A: There's a team on building on Boba, creating an NFT lending protocol that uses an off chain machine learning based valuation model to put evaluation on these NFTs so that they can figure out how much to lend against these collaterals. Imagine doing trying to do that all on chain. It's just impossible. You're too expensive, too slow. But now you get the best book. You might also want to decide to incentivize your community members to do certain things on social media, for example, to retweet. And you can use Turing to make to call Twitter to verify that, to see if someone has actually retweeted something.
00:11:33.790 - 00:12:57.322, Speaker A: And after the verification, you can then automatically release or AirDrop some rewards. And since it's all happening on layer two, these transactions are much cheaper, much more affordable than if you do it right on layer one. There are also Dow memberships that would Dows that want to connect their members identities, the off chain real world identities. Now, to some of the Web Three natives, this kind of seems like a little weird. But if you think about how Web three is growing and looping in more and more mainstream organizations into the movement, you start realizing there will be actually more and more demand to integrate what's happening on chain with what already exists off chain. For example, there are college alumni associations out there thinking about, oh, how do we create NFT memberships in our alumni association and identify them as verified members in a metaverse that they've created? So, in that case, they're not really trying to create NFTs that can be flipped or traded. Try to use NFTs to represent an identity that exists in the real world that needs to be verified.
00:12:57.322 - 00:13:32.140, Speaker A: You don't want someone to fake themselves as the Harvard Aluminum. Really not. So Turing also enables that we can create NFTs that could be connected to the school's official alumni directory and verify the real world identity of that metaverse character. You can also create a Twitter activity based token fountain. We've created this. We've created a Boba fountain on a ring. And you can also use our atomic random number check.
00:13:32.140 - 00:14:27.254, Speaker A: And bottom line is, if we're able to connect this decentralized computer with the rest of the world, with other network computers, you can now create a lot more intricate. And the list here is we're just scratching the surface. Some of these ideas actually came from developers that started trying out Turing. So we've got a detailed write up at this link bitly getturing with a capital T. It's really easy to use. It's just one line call. And what really sets us apart at Boba here is we're enabling developers to build smarter applications on Ethereum.
00:14:27.254 - 00:15:16.740, Speaker A: We're not just scaling it in a traditional sense or making it faster and cheaper. We are augmenting Ethereum by enabling you to build applications that can include algorithms that are much more complex than what you can execute on Ethereum layer one itself. All right, so that's our hybrid compute story. It's live on mainnets, really encourage you to try it and see what you can build with it. A lot of developers are finding that this completely changes how they think about what they can build. It really expands the design space available to you. And, yeah, I can't wait to see what comes out of this weekend's hackathon.
00:15:16.740 - 00:15:27.610, Speaker A: Thank you. Questions? Yes.
00:15:28.620 - 00:15:59.970, Speaker B: Just got a quick question about sort of a quick question about I don't know if it's working, but security. So you said that there was a time limit on requests coming back and having a valid response as well. Do you think it's possible that someone might want to overload the network with requests that might take too long and that might slow down block times or transactions because of that? Is that something that's possible?
00:16:02.760 - 00:16:38.860, Speaker A: It is possible, which is why we put a time limit on it. Of course, we have no control over how quickly the external API comes back. It's a 1200 millisecond timeout. Fortunately, you get to control which APS you call. And our hypothesis here is that the developers are only going to call you're only going to call APS that you trust. So these are either going to be your own RPC endpoints if you're, let's say in that NFT lending model, you're running your own off chain valuation model. It's your own RPC endpoint.
00:16:38.860 - 00:17:20.910, Speaker A: If it doesn't come back but it's too slow, you have full control on how you want to fix that. And in the case of calling Twitter or whatever that is, a much more established and trusted API. So that's less of an issue. Now it is possible for a nefarious developer that really intentionally wanted to deploy a smart contract that calls some random API that just never comes back? That is possible. But fortunately, we do control gas in this case where the trusted parties operates a single sequencer. So if that's the case, we can filter that out.
00:17:21.760 - 00:17:47.910, Speaker B: That sounds good. What other sort of functions do you see potentially being created in the future as well? You've got random number and API. Do you see stuff like maybe doing knowledge proofs as well? Possibly ways of having arbitrary sort of code get run separately and then having it proved later down the line that this has been run and it's valid as well? Is that something you're thinking about?
00:17:50.310 - 00:17:52.820, Speaker A: Could you frame that question again? Sure.
00:17:55.110 - 00:18:17.754, Speaker B: Are you thinking about other sort of arbitrary sort of functions that maybe developers want to create as well and having those arbitrary functions run on the network and then maybe having like a proof function, something like ZKP, where you can prove that those functions have been run correctly, the output is correct as well. Is that something that you think about with Voga as well?
00:18:17.792 - 00:18:21.360, Speaker A: Potentially, yeah, definitely. That's something that we're looking into.
00:18:29.730 - 00:18:51.270, Speaker C: Quick question. As you've said, because of the API Turing feature, there can only be one sequencer. The problem that I see is if the sequencer gets attacked, goes rogue, goes offline, right, this would destroy the whole roll up, correct?
00:18:51.420 - 00:19:41.430, Speaker A: Yeah. That's a more general challenge with today's rollouts in general not specific to robot Turing. So we've already begun our work on distributing the sequencers to address this availability issue. And in terms of role sequencers, all of the roll ups are going to have to deal with this challenge as soon as we start letting other parties run these sequencers. Now, we are not, of course, going to operate a role sequence ourselves, because that would be shooting something in the foot. We have enough skin in the game to not do that. So the idea would be to extend the same, to ensure that other sequencer operators will have enough skin in the game through staking other mechanisms that if they do go rogue, there will be severe punishment.
00:19:42.250 - 00:20:00.010, Speaker C: But this API feature makes it harder. Right. So if your EBM equivalent, like optimism, arbitrage, for example, to decentralize the sequencer is easier without the API feature, right, because how would you come to consensus?
00:20:00.670 - 00:20:15.550, Speaker A: Yeah, so we won't be running our own consensus protocol amongst our sequencers. We'll be rotating the role of making Turing calls, multiple sequences. So at any one time, there's only one that's making that call, but there's still be multiple instances.
00:20:17.430 - 00:20:35.670, Speaker C: Another really quick question. You pointed out the example of the Twitter API, right. So I imagine you have a smart contract. You do the actual API call inside the smart contract. Right. You have to put the Twitter API key somewhere. Right.
00:20:35.670 - 00:20:40.760, Speaker C: And if it's in the smart contract, anyone can see that. How do you handle this?
00:20:47.610 - 00:21:07.146, Speaker A: We do handle it because we have already implemented a faucet on Rinkby that requires a user to go through captcha. And how do we handle the API key? I'll need to get back to you on that to look at how we implement it.
00:21:07.328 - 00:21:08.458, Speaker C: Thanks. Yeah.
00:21:08.624 - 00:21:34.180, Speaker A: Thank you. Any other questions? Yes, you look very nice today. I did, thank you. Cool.
00:21:34.630 - 00:21:41.958, Speaker C: Will you manage through the hackathon down so you get enough sleep? You're okay? You're excited for the rest of the hackathon?
00:21:42.054 - 00:21:56.118, Speaker A: Super excited. Thank you. That's a spirit. Thank you. All right, well, thank you for coming to this workshop. Please go to Bitly, gettouring, check out Devdoff. Really look forward to seeing you build amazing things on touring and onboard.
00:21:56.118 - 00:21:56.600, Speaker A: Thank you.

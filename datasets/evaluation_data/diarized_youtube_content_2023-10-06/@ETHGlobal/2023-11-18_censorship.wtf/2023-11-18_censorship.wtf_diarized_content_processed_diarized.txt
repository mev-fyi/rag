00:00:08.970 - 00:02:28.230, Speaker A: Give me a sign, take my hand, we'll be fine. Promise I won't let you down. Just know that you don't have to do this alone. Own promise I'll never let you down because I know I can treat you better than he can. And any girl like you deserves that. Gentleman, tell me, why are we wasting time on all your wasted ground when you should be with me instead? I know I can treat you better danny can better up a stranger things. Stranger things every stranger things used to run around the scoastown always thinking out how we're gonna get out get heaven over all that you really want only get it.
00:02:28.230 - 00:11:30.400, Speaker A: I've been thinking about everything that you won't father tell me we get what we discover you oh we get what we miss and we're down we go down we go nowhere down we go way down we fall whoa you let your feet run thomas come as we all go down ever do you dare look all right in the eyes? Oh good day we run you down down to the dark Sunday we run you down now see all and they will run you down after you go you can't grow no more and where down we're down we go down we go you down I'll see your car all the way down we'll bab down nowhere down way down I am so different. I am so different love I am so different than love. Can I be love? Could I ever really be love? If you ever find me I wonder will you try me? So different than the boy love the kind that I dream of will it start right here inside of me, love? If you ever find me I wonder will you try me? So different than before, love I am so different than before so different smokey rooms I hear you singing to me, love take you and the song we make way so different than before oh, yes, my love if you ever find me? Then I ask you, try me. I'm so different. Love. I am so different. So different.
00:11:30.400 - 00:11:56.508, Speaker A: So different. The wood is out. The diamond gum begin again. I reinvent my love. Make it strong with us, So. Long. It's stretching out to everyone and nothing replaces lived out space.
00:11:56.508 - 00:17:13.178, Speaker A: This what I wanted. This is what I made. Every little thing will not be all right one day. This time you won't mistake me. I'm ready, love, for you to take me with you. Love if you ever find me I wonder will you try me? Oh, yes, my love I know when you found me or wrap yourself all around me so different than before oh yes, my life different than before I am so different friend so slow it it's SA sam by my side so we can be free strange things do happen here. It's the time to leave if we met at midnight the willow tree are you are you coming in with me? To run by my side so we can be free strange things you happen here it's the time to leave if we met at midnight the willow tree are you are you coming here with me? To run by my side so we can be free.
00:17:13.178 - 00:20:28.880, Speaker A: Strange things to happen here. It's the time to leave. If we met a midnight we me change into free jam when you can just reach out. No, I'll be there. I'll help you with together. Nothing ever felt like home. No.
00:20:28.880 - 01:11:42.172, Speaker A: I'll be there. You will never be alone. All I need is your love tonight all I need is your love tonight all I need is your love all I need is your love all I need your love close it. It my tight so far but in the end it doesn't even matter I had to fall to sit on in the end it doesn't even matter I tried so far but in the end it doesn't even matter I had to fall in the end it doesn't even matter. It sam sat and got so far but in the end it doesn't even matter I had to lose it all in the end it doesn't even matter I tried so far but in the end it doesn't matter I had to fall in the end it doesn't even ma it. It test. We are testing the mic test test test test varasdwa testing test test test varaswa test restriction between you yeah some other people it yeah doing the test in the guide of the main way yeah yeah and but yeah because people like we do have shows engagement email you summer days passing by my love eternal summer it up eternal summer sweat I'm dreaming of some brand forever I'm open you open up your mind open up your mind open up your mind um open summer days passing by my love eternal time is what I'm dreaming of shall it sound ram sunny by forever everything coming up on I'm feeling this is what I'm running away from solid hundred sunny mine forever I would try and drop a try I don't think you wanna be I've been trying to think you wanna get I've been trying to try I don't think you wanna be shut I've been trying I've been trying to try I don't think you wanna I've been trying prepared but I'm not asleep what's left of my old dreaming paradise GM.
01:11:42.172 - 01:12:09.770, Speaker A: GM. Hello everyone. Sorry for being fashionably late. Despite standing next to the stage, just like many of you were probably grabbing coffee and many more are still grabbing coffee. I know that feeling. But today, buckle up. We have 8 hours of content.
01:12:09.770 - 01:12:49.024, Speaker A: Not sure how you feel about that. We will have some light snacks. One ask is for everyone here in the Istanbul stage. Please be respectful of our hackers food. This is an ask from our co organizer Eastglobal that said well welcome to Censorship WTF. It's yet another new episode in the series of WTF Conference Unconference. But today we're doing something experimental.
01:12:49.024 - 01:13:55.240, Speaker A: It may or may not work. We are here being part of this Tale of Two cities. So right now I'm standing here on the Istanbul stage. And joining me in Prague, and you will see him shortly, is my co host Tim Bakel and many more dialing in from around the world on ETHGlobal TV. This is the chat box. If you log into ETHGlobal TV, you will see this is going to be the main interface for us all to ask questions, discuss with each other or with a speaker, whether they're on stage or off the stage. So today here we'll have a technical discussion about censorship resistance.
01:13:55.240 - 01:14:52.190, Speaker A: This is a fundamental concept to the space that we live and breathe in, but something we kind of take for granted. And oftentimes we have drastically different interpretations. We thought we're talking about the same thing. We somehow ended up arguing and shouting at each other because we aren't talking about the same thing. So this WTF is put together specifically to provide the spectrum of interpretation, at least on a technical and social and economic scale. So in the next 8 hours, we'll go on a journey from you can see on the left side, right side of the screen or your left side. We start with an overview, a birdside view of the problem space.
01:14:52.190 - 01:15:54.880, Speaker A: And then we dive into our first chapter, which is deconstructing the ethereum l One PR problem. And next we will explore some alternatives in the application infrastructure space. And next we will take a look, sample the alternatives and the approaches from the l Two perspective. And finally we'll bring it all back together, back to reality and how we can impact the real world by weaving theories into practice. Here on the Istanbul stage, we also have a breakout room. So across from this main stage are two workshop rooms. There we will have three impromptu workshops.
01:15:54.880 - 01:16:51.644, Speaker A: First one is about what if we do want to censor. And the second one is going to be about PBS or pretty bad situation or promising but slow. Yet another definition. And finally we'll have a confession from the largest node operator of Mastodon about the paradox of decentralized social network. It will happen in parallel to the main stage talk in the afternoon. So pick your battle. Anyways, without further ado, I would like to welcome 1 Second.
01:16:51.644 - 01:17:19.566, Speaker A: 1 second. Okay, Grace. Cool. Thank you. Great. All right, cool. How's everyone going? Good.
01:17:19.566 - 01:18:16.370, Speaker A: Want to talk about a lot of censorship persistence? All right, so what I'm going to talk about today and to kind of warm up the day and get us going is I'm going to talk about how to prevent digital totalitarian states. I'm going to talk about how these might rise, what the current powers might be and what we should be solving for it is not a given that we're going to land in these kinds of things. It would be great to avoid it, but it is a definite possibility and a lot of technologies are empowering these kinds of structures. So thinking about this kind of thing, I like always going back to 1984 because it has a very good memetic power in terms of in people's minds, what a society with huge amounts of power and control over society, how that society behaves. If you go back and read the book, it is super tame. Like, technology plays almost no role. It is primarily social.
01:18:16.370 - 01:19:36.570, Speaker A: And so when you reason about 1984, like the technologies at Play are maybe like, hey, the TV in your room is owned and can look at you and maybe there's some amount of surveillance in CCTV and it's just like the prediction relative to where we are now. Or not necessarily prediction, but that model is just so, so tame with what's possible today. So if we were to write George or Will's 2024 hours, 2024, what would that look like? And so I'm going to take us through that in a bit just to give you to have a little bit of a claim to why I know what I'm talking about. I've spent the better most of the last ten years working on a set of technologies to prevent these kinds of systems, these kinds of problems, IPFS and Lipidop, which are tools designed for a much better internet infrastructure that can give us a certain level of safety and human rights. So human rights is a huge focus of our work and we try to create structures that protect civil rights globally or give people the tools to protect civil rights globally. It's not a given that distributed technologies actually do that and help you. It just empowers the people locally to make better decisions and it gives an asymmetric advantage.
01:19:36.570 - 01:20:48.050, Speaker A: I think everyone here working on web three initially got inspired by that kind of vision, initially got inspired by bringing in those kinds of rights. And I think that web three has an enormous amount of potential in achieving this sort of thing. Some of the tech that we've built was we're so no strangers to censorship that we were involved in many, many events. Our technologies got involved in many, many events relating to censorship. So what are modern or William states, what could be built? Then we'll talk about how to prevent them. Then after that we'll talk that's something a lot of people were worried about before the internet and now post the internet and the ability to generate a lot of data that might become a problem. Again, I probably don't have to convince most people here that totalitarianism is bad, but to put things in perspective, think of completely locking down some society and preventing any kind of shift out of totalitarianism, but also just kind of when you weigh it by the horrible deaths involved, you just kind of end up in a just terrible outlook.
01:20:48.050 - 01:21:36.530, Speaker A: Now what's new in 2024? So first off, telecommunications globally have drastically improved since 1984. We have now the internet for most of our interactions. We have about 7 billion smartphones deployed. We have CCTV basically in most cities, in certainly most places of transit. Any kind of hubs for moving around are full CCTV. We have satellite imagery globally you have very good resolution in those pretty quick updates. We have a fully digital economy that could enforce policies and rules which if you suddenly are disliked by your local system and prevented from moving around, taking some public transportation, buying food, water, whatever, this could get a little hairy.
01:21:36.530 - 01:22:01.100, Speaker A: And of course AI is going to make all of this kind of stuff way harder. Think of levels of all of that. Massive surveillance needs to be analyzed by somebody. Humans are not exactly the best at this. Computers are extremely good at it. So think of all that object recognition stuff that we looked at. Now deploy it at massive scale, being able to then guide behavior and policy.
01:22:01.100 - 01:22:57.820, Speaker A: You can build and deploy automated systems of control. You can have behavioral ML models. We're going to talk a little bit more about AI because since I give you the first version of the stock earlier this year, there's been a set of improvements worth including I mentioned, surveillance. But just to put things into perspective, we have lots of evidence that many organizations around the world are monitoring all traffic metadata and the content, phones, GPS positions, audio, video, communications data, health data, all of that kind of stuff. If you're like me and you really like tracking your biometrics, you have one of these devices and you take all of your data and you give it to the cloud in the clear. And so probably several corporations that right now have a full biometric model of me and can predict how I move and so on. Other corporations have full models of what I say online and can predict what I'm likely to say.
01:22:57.820 - 01:23:44.506, Speaker A: Not a good position, not a good outlook. Then beyond that, we have all of our communications and social media. Just all of this is mediated through currently still corporations and subject to a lot of local policies. We've had evidence of a bunch of propaganda problems, control of news, publications and so on, disinformation. And if you think about modern computing and the ability to generate content today and kind of coordinate, and if you have a system that is producing content, optimizing for some goal, and is measuring the reactions of people that can run off in a pretty terrible way. You should pay attention to what happens in the next US election. That'll be a really interesting testbed for a lot of this kind of stuff.
01:23:44.506 - 01:24:22.198, Speaker A: Hopefully nothing really bad happens. Hopefully good will prevail and a lot of this won't come to pass. But it'll be an interesting place because people are certainly going to try. Then we have things like if you have all of these computing systems and you can control a lot of robots and so on in computers, you can also do the same thing with humans. You can measure their behavior, you can create some incentives and you can couple the surveillance system with a control system. We're starting to see the beginnings of this kind of thing being deployed. We have the social credit systems in a few places in the world.
01:24:22.198 - 01:24:45.198, Speaker A: These are like super tamed right now. They haven't been really weaponized. And one of the things that I think is crucial to enabling this kind of control to happen is that these things get implemented and then just make everything better. If these systems come in contact with the country, they make everything better. For years, everyone learns to love these things. They're like, oh man, the world just got so much better. After these social credit systems, more and more and more societies will just grant control to these things.
01:24:45.198 - 01:25:27.078, Speaker A: Over time, a decade or a couple of decades in the administration's transition, somebody starts rewriting the rules in the algorithms and boom. Now you have a really bad situation. One of the key things here is most administrations in the world today tend to want to protect people, tend to be pretty well intentioned. We have had a relative level of peace compared to other parts of history. And so usually those administrations are trying to be defensive and implementing extremely bad systems that are going to be taken advantage of by successors. Like, this is classic history. Just go back and read about the histories of the worst kind of police systems got, usually implemented with very good intentions.
01:25:27.078 - 01:25:50.318, Speaker A: Then we have things like automated enforcement of situations, right? So not just incentives. We have robot storms coming, right? Like this stuff is going to get nasty. But this is about censorship so we won't dive too deep into this promised AI. AI. Edition. So a lot of stuff has changed. We have, again, massive surveillance and data analysis.
01:25:50.318 - 01:26:19.494, Speaker A: We can generate an enormous amount of media. LLMs are just tremendously powerful. Just try playing around with them. It's amazing. You can generate and summarize all kinds of content. We have enough computing power to just observe and write for all humans, right? So the computing power available to major corporations and to nation states is sufficient to just generate, to observe all streams of communication coming out of a human and write back to the human. That's insane.
01:26:19.494 - 01:26:51.942, Speaker A: How do you even fight that? We have to bake in protective systems, by the way, this is like first part of the talk. We're going to be very optimistic towards the end, don't worry. And then think of new things. We will have new economic structures, new control structures. We will have preventative control models for like are you likely to dislike the state in a year. Should we prevent you cut that early and this isn't even touching. AGI right, that's way out of scope for this talk in that people predict it's going to come in like the next two to five years.
01:26:51.942 - 01:27:11.690, Speaker A: So very out of scope for today. But if you want to wrap your head around this, think of anything a human can do at a clock speed, a thousand times faster, fully connected to the internet. Think of that. That's sufficient. Of course these systems are going to get better. So problems. So we've talked about the capabilities.
01:27:11.690 - 01:28:06.606, Speaker A: How could the totalitarian systems rise? Usually there are a few different ways, but usually they tend to rise in the name of public safety, whether it's from dictatorships, after some upheaval or democracies where something bad is happening. And so groups tend to vote in all kinds of safety measures. The Patriot Act in the US. Is a very good example of this. Eventually, even though those administrations could be super well intentioned and trying to do what's best for everyone by creating infrastructure with that level of power, eventually someone bad is going to look at that level of power, plot how to take over, do it, and then implement a really terrible system. You just have to pick up a history book to see lots of examples. Now practically what this means is implementing pieces of these systems, demonstrate that they're really good for everybody, get everyone to love them and want them to spread and increase that distribution over time.
01:28:06.606 - 01:28:29.730, Speaker A: You keep up ratcheting power and control and eventually someone will come along and take over. So great. We've talked about the problem. How do we prevent these terrible things? So there's a lot of different ways. You need a full combination of approaches. Primarily, you need a super well educated public that understands the potential that has reliable media. This is where censorship persistence is really critical.
01:28:29.730 - 01:29:10.130, Speaker A: You need schools and learning and you need humans to be very well aware of what's possible here. You need extremely good policies in government. You need balanced government structures, very strong institutions that can prevent this kind of takeover, very strong institutions that are like red teaming problems and trying to nip things in the bud before they become an issue. We also need extremely strong technological powers. We need extremely secure communications. This means, again, censorship, resistance to enable all of us to coordinate, but also privacy reader writer privacy. Being able to coordinate requires the ability to coordinate in private so that you can't be taken out by some would be totalitarian controller.
01:29:10.130 - 01:29:47.834, Speaker A: And this usually gets forgotten. The economic loop here is extremely crucial. You need a very strong economy to prevent these massive upheavals that tend to give instability to governments. But more importantly, from my perspective, you need a very strong economy to stay ahead of the curve in the technological stream to be able to implement all these technologies with human rights at the forefront instead of lagging behind others and then letting others kind of implement their control structures on you. I won't go super deep into this because it's a little bit of out of scope for today. But the world has hundreds of democracies. There's very strong institutions.
01:29:47.834 - 01:30:29.974, Speaker A: Most of them really want to prevent this. Most of them really, really are aware of these kinds of problems and want to prevent them. But there is this big debate in all of them about between security and privacy. There are very real short term, practical problems with security, and that usually gets used by the would be implementers of these kinds of apparatus. So the world has used, thankfully, the Cambridge analytica problem gave us a very good example to use now to talk about these problems, to implement safeguards. So this is no matter what government you're in and so on, bring this kind of thing up and fight for this kind of stuff. Now, I want to mention that privacy is not a great brand.
01:30:29.974 - 01:30:51.842, Speaker A: It tends to be dismissed as optional. It does not convey the real problem. We as a community of builders going back to the so on, missed up here, it's not about privacy. It's not about keeping what you're doing secret from other people. That's not at all what is going on. We're trying to establish security. Secure communications is what we're talking about.
01:30:51.842 - 01:31:26.030, Speaker A: Being able to coordinate securely as a people, that's what we are orienting for. And so really, whenever you kind of think about privacy and so on, really strongly mention security. Because at the end of the day, it's about two forms of security, short term security in terms of current problems or long term security in terms of how your civilization is able to prevent these kinds of problems. There's a lot of good progress to highlight. There were the original crypto wars, strong encryption standards. They always come up for people, always try to get rid of them. But we have so far been pretty successful.
01:31:26.030 - 01:32:06.522, Speaker A: There are really good proposals against AI biased systems. We need to go hard on this, stay ahead of the curve here. And I think in general, we just have lots and lots of groups fighting super hard to prevent these kind of problems. Huge kudos to tons of people around the world that have worked super hard to enable this great so this technology conference. So let's get back to that. I'll dive very deep into secure communications in a moment. I just think about it in terms of like, we need secure communications, talking and writing to each other in order to properly coordinate so that we can take significant actions and prevent these kinds of problems.
01:32:06.522 - 01:32:39.942, Speaker A: And so the basic foundation that I want everybody here to walk away with is that we need global secure communications. Censorship, resistance, reader, writer, privacy. Any human in the world should have the right to communicate with any other human in the world securely and privately and in groups. So again, I talked about the economy. I won't dive super deep into that, but just the economy is what lets you coordinate large groups of people. It lets you build the technologies that you need and it lets you take actions. Cool.
01:32:39.942 - 01:33:04.000, Speaker A: So let's dive into secure communications. I'm going to give a view into the internet infrastructure, lots of applications and hardware and so on. And I'll kind of hint at a roadmap of what we need to do so at the very bottom. So this is not typical in the blockchain space. We tend to operate kind of like on top of the internet. And the internet is this big black box that we don't think about oh yeah, just send packets to each other, right? It'll just work out. Absolutely not.
01:33:04.000 - 01:33:38.290, Speaker A: Censorship happens at a lower layer. We need to improve the entire IP stack. We need to bring censorship in the blockchains but sink it all the way down into the basic building blocks of the internet. We need proper communication protocols that are able to have censorship resistance directly in the routers in how your computer connects to the internet and so on. We need to make this a human right. Like it's not going to be easy to implement this globally. We need the UN and other groups behind these kinds of policies.
01:33:38.290 - 01:34:18.418, Speaker A: We need things like secure systems like Tor ITP and the new mixnets like NIM and so on. I want to call those out as really good efforts. But we need something that's going to scale to the billions and tens of billions or hundreds of billions of devices that we're going to have. A lot of these systems are really good for small use cases and they're really good to give us something to work with and scale. But what we need to be targeting is something that's going to work for tens of billions to hundreds of billions of devices communicating a lot. So when you think about protocols, really target that. Because if you're going to spend three to five years designing a protocol and implementing it and five years in you're like, hey great, you got 100 million things to communicate privately.
01:34:18.418 - 01:34:44.186, Speaker A: Awesome. That's a really great progress. But there's a huge gap there. Then if we manage to getting censorship, persistence and privacy at this layer is extremely difficult. It's going to be hard to start here. We need to make progress on this, but it's an area that is difficult to get to. One thing I would recommend folks here is create large scale incentivized routing systems.
01:34:44.186 - 01:35:23.530, Speaker A: So use blockchains to build large scale incentivized routing systems in the clear at first and get them to work and get them to scale. Then you can bring in the sensor persistence and the privacy reader writer privacy later. But just showing that you can build a massive scale routing system that works globally internet wide would be a great plus. And then cell networks and other kinds of routing and satellite and whatnot would be really useful. Be great to have a decentralized starlink type of thing that would be super valuable, that would enable us to really communicate with a lot of people around the world. Cool. So DNS is one really strong Achilles heel in some of the things that I mentioned before.
01:35:23.530 - 01:36:01.990, Speaker A: This was usually a lot of states tend to attack DNS because if you can't find the contents and you don't know where to go, tough luck. Even though you could theoretically communicate to the right computer, you can't find it. So DNS is like this place Achilles heel that you can cut in terms of how people find things. This is where things like blockchain naming are really useful. Things like ENS and so on are extremely valuable in terms of ratcheting this up. But most of those systems still use the traditional routing infrastructure. We need the naming system, especially for really sensitive names, to be able to be spread out and distribute to lots of devices so you can load things locally without having to depend on some registry later that could be blocked.
01:36:01.990 - 01:36:24.234, Speaker A: We need to radically improve the internet, sorry, the CA system. So in blockchains we thankfully use much better cryptographic systems, but most of the internet and most of the places where we get our software are still using the CA system. So great. You have a great blockchain. Awesome. Kudos. If you can't get the right software and the software that you can get is owned by somebody attacking the CA system, tough luck.
01:36:24.234 - 01:37:06.998, Speaker A: You now have a vulnerability and you won't be able to do what you wanted anyway. So we really need to take the magical crypto systems that we have and rewrite and improve how our browsers get content in the first place. We need a way better web that has censorship persistence baked in. This is stuff that a lot of us have been working on and we've made enormous amount of progress. Still a ton to go. We need this stuff to work on every native browser and we need it to work at scale for all kinds of applications. Right now it works really well for static content and so on, lightly dynamic content, but it doesn't yet scale to something like a social network that though you could do it in practice, it doesn't work well enough to really spread.
01:37:06.998 - 01:37:49.766, Speaker A: That's a major area of focus for these projects. We really need browsers to be very strong privacy oriented. We need hooks for routing systems, for naming systems, for certificate authorities, for other loading, systems that load other content, systems that load applications, all of that kind of stuff. The browsers and the operating systems are these key entry points where if you can hook in there, then you can distribute much better, much better infrastructure. App stores are a huge problem right. Now because Android is a little bit better than Apple, but these are basically super locked in environments where you can't distribute whatever you want onto these things. They're super controlled in terms of geopolitical structures.
01:37:49.766 - 01:38:20.622, Speaker A: And so we need some way of having the control over the mobile phones, networking systems directly from decentralized App Store type of environments. Not sure if Android enables this right now. It might because Android has like a much healthier open source orientation. But I know certainly Apple does not let you install anything you want. You can only install what Apple wants. And I'm a use Apple device all the time, but this is a huge problem and they should improve, they should know better. Then you want to think about the different modes of communication.
01:38:20.622 - 01:39:13.426, Speaker A: And for each of these modes, make sure that you have a really good, awesome product that everyone loves, that is secure by default, that has censorship, persistence, that has reader writer privacy, one to one communications, one to many, many to one, many to many kinds of things you can imagine. Although think of any application that you use for communicating with other people, telegram, signal, email, text messages, forums, whatever, you should have an alternative that works really well, that is beautiful and wonderful to use, that has censorship, persistence and privacy. Rear writer privacy baked in. I would encourage starting with very simple things. So the fact that we have signal and being able to do one to one or small group communications already is a huge plus. The metadata is still observable by attackers. You can correlate who's messaging who and so on.
01:39:13.426 - 01:39:54.946, Speaker A: If you're observing the links, that needs to get way better. And then on top of all this, think of much more complex applications. Once you have economies and organizations and whatnot you want to enable those things to write on top of these kinds of systems, eventually it would be great to get the secure communications hardware. The problem here is that there's very few vendors that can produce the really high quality stuff. This means an enormous amount of lock in. The good news there is that there's a strong orientation towards democracies and civil rights, which is awesome. We need to work towards getting more vendors and getting these systems to open up so that you can run whatever you want in them.
01:39:54.946 - 01:40:35.166, Speaker A: And I'll give a plug here for research and development in general. So one of the things I love about the crypto community is that we read all the amazing cryptography papers and we're like, oh my God, this is amazing. Why don't we have this deployed? And old cryptographers were like, when you deploy new cryptography, it's bound to break and never works. And that led to this massive slowdown in cryptography. So new things weren't getting deployed and developed. We're like, hey, let's take these magical tools, deploy them at scale, and if they break, we'll fix them and let's use them to generate an enormous amount of wealth that we then will loop back into the R and D cycle to make even more cryptography and even more systems. And that has been amazing.
01:40:35.166 - 01:41:20.922, Speaker A: So from a perspective of what is the thing that has happened in the last 1520 years that has been the most promising for secure communications? It's the rise of the crypto community. Like the cryptocurrency community is feeding the entire cryptography community and accelerating the research into zero knowledge proofs, into fully homomorphic encryption, into just secure communications in general, distributed systems and so on. So we need to double down on this. It'd be great if blockchains in general started devoting a huge fraction of their significant fraction of their wealth directly to this kind of R and D like funnel emission of tokens directly into funding R and D of this kind of stuff. You'll hear me talk a lot about that over the next coming years. There's really great new tech frontiers. A lot of the speakers here are going to talk about this stuff.
01:41:20.922 - 01:41:37.586, Speaker A: Cronolledge proofs is all the rage right now. Awesome. Not good enough for certain kinds of things. I think things like fully homophobic encryption are going to be critical. These are going to become much more widely deployed and important in the next five years. So keep an eye out for that. There's a lot of work to do there.
01:41:37.586 - 01:42:20.000, Speaker A: I think that these things can be used for routing, for all communications, for all messages, for all kind of like normal human communications. So it sounds crazy, but when you think about the number of thoughts and messages that a human can output, within 1020 years we'll have enough computing power to run all of that in secure communications fully with perfect cryptography. So don't worry too much about things being way too slow. That's just wrong. Just wait a few years, it'll get way better. And like I mentioned, the innovation cycle. We need successful projects to scale to generate a lot of wealth so we can feed that back into R and D.
01:42:20.000 - 01:43:07.562, Speaker A: And I just want to kind of end with a huge congratulations to the entire ecosystem, because overall, we've made an enormous amount of progress in the last few decades, especially from my perspective, in the last decade. We did that on the shoulders of lots of giants that fought the crypto wars, gave us basic cryptography, highlighted all these problems. But I want to kind of remind everyone that we need both production grade infrastructure and software for lots of different use cases. And you want to find things that are going to be really important and you want to make sure that you have a beautiful, wonderful product that everyone wants to use. A lot of us use and love Telegram because it's just so nice and really useful. But I don't think the whole thing is open source. And without knowing that the whole thing is open source, and secure and so on with really good cryptography.
01:43:07.562 - 01:43:42.714, Speaker A: I can't trust it. And instead Signal is like a little bit of a ratchet better, but not dramatically better still, because I think you can't run all of your own instances. I think some of the again, it still relies on the app stores, which kind of suck, and you have to go through the app stores, but you should offer alternative ways of communicating and the metadata is kind of in the clear. But again, super great that we have those things. And all of these things need to get better. And we have a really good innovation cycle. It's really special that the cryptocurrency community has this entire thing going.
01:43:42.714 - 01:44:06.898, Speaker A: We need to scale it. But just as you head into the conversations today, know that this is a long road, it's a long fight here. We have a long way to go to we're fully orwellian proof and digital totalitarianism proof. We've had an enormous amount of successful progress. We need to double down on it and scale it. We're in a dramatically better place today than we were five years ago or ten years ago. We have magical internet money.
01:44:06.898 - 01:44:55.850, Speaker A: We have much more secure names. We have much more secure ways of communicating our applications and our web pages and so on. We have pretty good censorship persistence relative to where we were ten years ago. But we have so much more to do. And so I really hope that the people in the room are going to sign up to come build these human right protecting technologies and help us all live in a much, much safer and much, much better future. Thank you very much. Thank you for such a strong start.
01:44:55.850 - 01:46:23.672, Speaker A: So unfortunately, we're not going to have QA or the mutual Q A, but my ask is for our first two speakers, one and Vitalik, who will go next to commit to sharing your slides with everyone and to answer everyone's question in the site chat so we can be inclusive. Thank you. Okay? So I thought that what I would do is take some of this discussion around censorship in a broader context, which is absolutely super important, and bring it kind of I wanted to say down to Earth, but like, ether is sort of up in the sky. So bring it down to the sky and think about some issues that affect the ethereum ecosystem specifically. So hardening the ethereum ecosystem, going all the way across the stack. There you go. So the interface layer, right? This is one of the big frontiers of practical ethereum ecosystem censorship resistance that I think is often not appreciated enough.
01:46:23.672 - 01:47:44.188, Speaker A: And actually when I was on a panel a couple of days ago with the different layer two companies, and I asked them what is a decentralization and standardization issue that is more at the application layer that they were concerned with? Interfaces were actually brought up as one of the basically the number one issue. So who here actually knows which interface this is? Uniswap. Great, okay, glad to hear people here have used Uniswap but this is an interface and you can use this interface for converting coins into converting other coins. One of my own addresses has actually been banned from this interface because I used Tornado cash at some point a couple of years ago. And so this is an issue that affects me personally to some extent. But basically there are lots of DApps and a DAP on chain is fundamentally just a contract and it's a piece of solidity code or sometimes Viper code, sometimes handwritten EVM code. But for most people in order to practically interact with these DApps needs to go through some kind of interface.
01:47:44.188 - 01:49:34.980, Speaker A: Now in some cases the interface is fairly simple and the interface is basically just a nice and pretty wrapper around putting the right numbers into a function that goes straight into a contract. And in those cases the interface matters a little bit less because if you're really being censored then you can go on Word and you can figure out what fields to type in if you go to Etherscan IO and you go into the right Contracts tab. But unfortunately those situations are also the situations in which writing alternate UIs is the easiest. The more challenging situations are situations where either your application is not just a contract or applications where the contract functions are so complex that you just have to provide messages from the outside in some way to interact with the application. Right? So here all that we're doing is swapping tokens. So this is on the easy side but increasingly we have applications that interact with layer two s applications that interact with all kinds of custom layer twos applications that require you to sign off chain messages. And how do you even start signing off chain messages? What do you do if you're a smart contract wallet and you need to be ERC 1271 compatible? And so this is like one of those areas where if you don't have the official interface then it's kind of hard, right? And it's especially harder if your application depends on centralized APIs, right? If your interface depends on centralized APIs, then you can't fork the interface, you can't even just do control, view and view source and copy paste the source because even then it talks to specific things and you're not really able to untangle the application from those things.
01:49:34.980 - 01:51:09.824, Speaker A: So a major frontier in increasing censorship resistance of the ecosystem and I think especially for really critical functions like being able to move tokens across different layer twos is actually having protocols that are more open as much as possible and for every protocol that exists, ideally having an open source alternative interface actually exist for it, right? So I think ideally this would be something that the ecosystem tries to adopt as a yes standard. I think one of the best tools that we have for this is social pressure, basically, along with pushing applications to support, for example, things like ERC 1271 so they can be actually friendly to smart contract wallets. Also push for at least one alternate UI to actually exist. So that's the interface layer. Now, centralized node providers are one of these other really important bottlenecks, right? Basically most users interact with the ethereum blockchain through DApps and those DApps generally interact with the blockchain either through a centralized provider that is maintained by the DAP itself, or through a centralized provider that is maintained by the user's wallet. And both of these are again censorship vectors. And this is an area that is a challenge and it's an area that is also, I think, much worse for L two S than for L ones.
01:51:09.824 - 01:52:22.500, Speaker A: One of the things that is important, I think, to realize is that the ethereum ecosystem is going through a rapid transition from everything happening on L One to everything happening on l two S. And one of the things that's super important for us to be cognizant about is that as we go through this transition, there are certain fundamental values that we need to fight really hard to avoid going backwards on. Right. Like there's a big change and the default direction in a lot of these changes actually really goes backwards on a lot of key questions, right? Centralized sequencing, one simple example, even if you look at how ENS works, right, if you want ENS to be usable on layer two, we have the CCIP protocol that allows you to have a domain inside of a contract and then all subdomains of that domain can be issued, transferred, whatever, inside of a layer two. And the correct way to do this is that the CCIP contract actually checks merkle branches of the state inside of that layer two, so it's actually trustless. But the lazy way to do it that unfortunately most people are doing today is to just rely on centralized providers with signatures. And we need to really make sure that we're not doing things like that because every single one of those trust vectors is also a censorship vector.
01:52:22.500 - 01:53:30.808, Speaker A: And furthermore, every one of those trust vectors makes it hard, much harder to have an ecosystem with lots of independent providers because we don't just have to care about whether or not the provider exists, we have to care about whether or not they're trustworthy. And that just naturally tends toward more of an oligopoly, which creates more of a censorship risk for layer twos. Node providers today are even more centralized. And so this is, again one of those things that I think is a big challenge to the ecosystem. Now, what can we do about centralized node providers? So I think there's a couple of different directions that we can take. The more moderate direction is basically to add armoring to the existing centralized providers and encourage users to connect to lots of them at the same time. If you do this then you have a one of entrust model, right? So we have light client protocols so there's something called Helios created by a 16 Z which basically is a light client that verifies the sync committee which allows you to stay up to date with the Ethereum proof of stake chain.
01:53:30.808 - 01:54:24.450, Speaker A: This is good but if all that you have is headers then that's not enough right? Most DApps don't just need headers. They need actual state. So if you want to verify actual specific things that are happening in ethereum, you need headers, but you also need providers to give you merkel branches, and then those merkel branches can actually be verified against the headers and the transaction and state routes that you have. And then you can actually have this kind of fully verified pipeline where you have a pretty high guarantee that the thing that the server is feeding you is actually correct. So this is one part of the puzzle, right? The part of the puzzle is basically increasing the security that you get of the answers from a server. The second part of the answer is moving from talking to one server to talking to end servers. This is, I think, a major theme in censorship resistance which is increasing openness and increasing security.
01:54:24.450 - 01:54:57.284, Speaker A: If you do them technologically, then they are actually mutually supporting. Right. And the reason is that if you increase security then you decrease the trust requirements on anyone providing you information and that allows you to be more open on that side. Right. So openness versus security is a trade off frontier. But if you can improve on one or the other independently then you're actually pushing that entire frontier forward, which improves on both. Ideal long term solution, better decentralized protocols.
01:54:57.284 - 01:55:42.100, Speaker A: Ideally, we would not even have to name specific IPS. Right. And ideally, as much of this as possible would be done through things like the portal network layer two sequencers. So again, layer two protocols ethereum ecosystem is going through a rapid transition from being layer one dominated to being layer two dominated for the sake of security. But the problem is that it's very challenging to make sure that we actually maintain these fundamental values that we really care about. So layer two sequencers in a lot of cases are centralized. And this is a problem because it's an extra censorship vector and it's also potentially a take away your money vector.
01:55:42.100 - 01:56:29.160, Speaker A: Right. One of the things that's important to remember in the context of DeFi specifically, is that a censorship attack can often turn into a takeaway your money attack because people's positions in financial systems are so time dependent. Right. If you can lock up someone's money for some amount of time then often you basically get a free option against them which means that probabilistically you're taking away their money so strategy one force inclusion protocols, right, protocols where if you are being censored inside of the layer. Two, you can go and get around that, and you can publish a transaction straight on chain, and the protocol forces the L two to just go and include that transaction in the next block. This is great. Who here, if you got censored, would know how the hell you're supposed to do a force inclusion procedure.
01:56:29.160 - 01:57:26.712, Speaker A: Okay, cool. Two, hands up. That's amazing. Okay, you two, can you just, after this, do a breakout session and teach everyone else? And we have to scale this to the entire world. So can you two just do a course, $199 an hour, have a Scammy website, or go and teach people how to do force and collusions? Okay, this is one way of doing it, but the other way of doing it is we need force inclusions to also to have good UIs, right? Any anti censorship strategy, for it to be practical, needs to actually have a good UI. One historical analogy for this is who here is familiar with OTR messaging? This is off the record messaging protocol from about 20 years ago. One of the co authors of it, Ian Goldberg, just actually happens to totally randomly be at the university I stayed at for eight months before I dropped out to do bitcoining, so ended up randomly learning a bit about that.
01:57:26.712 - 01:58:44.976, Speaker A: But one of the really important things that he impressed on me is that OTR has this property called deniability, which basically says that if you make a message, you cannot prove that the other side made a particular message or you cannot prove to someone else that you made a particular message. And this is an important privacy property because it means that even if you get coerced, you cannot reveal what the other side is saying. Now, how do you do deniability? The way that you do deniability is basically by creating a protocol where it is easy for the other side to forge messages, right? So you make a protocol where if I have the ability to sign to make a message, you have the ability to also make a message using that exact same procedure. The big thing that OTR made sure to do is they did not just have that as a thing in theory, but they also actually had a UI. Like, if you want to forge a message, you could go and forge it. So this is, I think, an example of where if you want a capability to exist for the purpose of some censorship resistance related goal, you need to actually have the UI for that exist. Right? So we need UIs to exist for force inclusions, and ideally, these UIs would be created by independent organizations, right? So ideally, you'd have the roll up police, and maybe L Two Beat wants to be the roll up police.
01:58:44.976 - 01:59:18.776, Speaker A: Maybe someone else does. Maybe we need to do the anarcho capitalist thing and have five competing roll up polices and that'll actually work here. But we need to have independent organizations creating interfaces for these, making sure that they actually work. Strategy two, decentralized sequencing basically actually create an open sequencing system where lots of people can come in and participate. Crosswayer two bridging. So crossway or two bridging becomes really important. You have coins on optimism today, but you want to have coins on Arbitrum because of the application that you just discovered.
01:59:18.776 - 01:59:44.976, Speaker A: And you want to go trade in. You want to move from one to the other within 30 seconds. Well, it's lots of options today, but they're either centralized or they are needlessly governance heavy. And this is something that requires more open standards. So this is a diagram from a project called Uniswap X. So they're actually working on something like this. Basically what we really need is not really these centralized wire two bridging protocols.
01:59:44.976 - 02:00:53.752, Speaker A: What we need is essentially an open marketplace for cross chain friendly limit orders, right? And as Twitter told me, limit orders are basically 99% of what's useful about the whole concept of intents. So maybe we should go do limit orders, the peer to peer layer. So relatively little attention to peer to peer networks compared to other layers. And one of the reasons why I really appreciate Juan is just because he consistently actually cares about this stuff, right? And his various umbrella of fancy organizations actually contributes to stuff like Lib P to P, and Ethereum is actually using Lib P to P. And thinking about the P to P is really valuable. Because even if you have a fancy theory that says that you need to pay $5 billion to 51% attack this thing, realistically, you can totally pone the peer to peer network for less than 5 million, probably even 500,000, right? And so a strong adversary can easily become more than 90% of Ethereum nodes. The network is probably quite vulnerable to Internet censorship at multiple layers.
02:00:53.752 - 02:01:27.840, Speaker A: So this is something that could be it needs to be addressed at multiple layers, stronger antidenial of service. So one of the ideas that we could do is so this is something called the RLN protocol. It's a zero knowledge civil resistance protocol. It's in the same line as ideas that I've published around. Like, let's take the original HashCash, which was a proof of work antispam protocol that then inspired proof of work consensus. You have proof of work hash cash, which inspired proof of work consensus. Proof of work consensus inspired proof of stake consensus.
02:01:27.840 - 02:02:42.304, Speaker A: And now let's have proof of stake consensus inspire proof of stake hash cash, right? And so you have coins, you prove that you have coins and then that anonymously gives you the right to send some limited number of messages for a period of time. And we're going to do a fancy math, aka two points make align stuff that you hopefully learned in 9th grade to actually make it possible to send a limited number of messages, but keep a limit on how many messages can be sent. And then we can have a design where if you have a peer to peer network and stuff starts going wrong, we can identify who the validators are and prioritize them so that at least Ethereum continues to be safe and sane. The social layer. Who here remembers the whole bitcoin? Thermos small block censorship situation? Basically one guy was the moderator of a forum and started basically censoring the hell out of anyone who did not agree with his opinions on the way the bitcoin block size war should go. And he basically started just like banning everyone who said things that did not agree with his views. And he even said these famous lines if 90% of our Bitcoin users find these policies to be intolerable, then I want these 90% of our bitcoin users to leave.
02:02:42.304 - 02:03:58.456, Speaker A: So Quan talks about digital totalitarianism. We have digital totalitarianism. One of the questions is like, can we make the Ethereum social layer more robust against attacks, right? If Ethereum becomes a big deal, then one of the ways in which people might try to attack Ethereum is by attacking the social. And attacks against the social layer totally are possible, right? So the way that it will work is not through someone trying to do weird manipulations to force Ethereum to adopt a particular policy. What's going to work is probably the same thing that generally works better in these social media manipulations against democracies, which is you don't try to push one side of an issue, you instead basically empower the worst people on both sides and you just kind of generally create chaos, right? There have been literally confirmed reports that I think at one point the Kreblin supported both sides of BLM rally. They intentionally do this sort of stuff, right, and they basically try to not optimize for an objective, but just optimize for the high conflict parts of both sides of any particular issue. This is something that bitcoin and Ethereum ecosystems could totally be subjected to.
02:03:58.456 - 02:05:28.416, Speaker A: So I think in terms of what do we want to identify which platforms we're worried about and we want to identify the threat model and particularly we want to think about internal risk versus external risk. And this is not necessarily very sharp divide because external threat actors can easily try to create internal risk because internal attacks just can more easily create damage. But as one simple approximation, if you look at Twitter, twitter is a platform that is not controlled by the community at all, right? And so Twitter is probably not going to pull a thermos on the bitcoin or the Ethereum ecosystem, but there is external attack risk, right? Like maybe Elon decides that. Elon has opinions about ethereum. He did have opinions about Dogecoin now on Community hosted bitcoin forums such as the Ethereum Foundation hosted Ether Research. There's much less external attack risk, but there is more inside the community risk, right? So better understand specific threat models. And another thing I think that's like one very specific to do is better forms of signaling, right? The biggest risk to a blockchain from the social layer is basically a risk of a 50 50 split hard fork as a result of disagreement over some decision that realistically, probably doesn't warrant a community split over, right? And one of the ways of mitigating that is to have better forms of signaling ahead of time so that people are aware of which way the wind is blowing in terms of consensus.
02:05:28.416 - 02:05:55.880, Speaker A: Back when the Dow Fork and other controversial stuff like EFP Nine Nine Nine, a failed attempt at rescuing the money stuck in the parity wallet and some issuance reductions were happening. There was a tool called carbon vote that was developed that allowed people to basically vote with their ETH. And you could see which positions were more popular. It's a non binding voting mechanism. It's still a voting mechanism. So we could do Carbon vote. We can also extend that to do forms of signaling that are not just ETH dependent.
02:05:55.880 - 02:06:28.740, Speaker A: So back then we had ETH and we had GitHub and Reddit voting. Now we have popes, we have zoo stamps. You could use Zoo Pass with defconnect tickets. You could use any kind of Pope. You can use any kind of proof that you have any NS name. You can do some kind of zero knowledge score over all of them. Actually use this zero knowledge, identity and reputation stuff to try to create better forms of signaling to identify who actually is a member of the Ethereum community with stand dig to participate in a particular poll.
02:06:28.740 - 02:08:03.100, Speaker A: So, conclusion, ethereum stack has lots of layers. A front door 51% attack is by far not the cheapest way to make Ethereum break or to censor Ethereum, right? Like, who here seriously thinks that if the US government or any other government wanted to censor Ethereum, they would literally go and buy up 18 million ETH and they would grab up the validators? Who here thinks that if they wanted to do that, they would buy up 60% of the lido tokens and make lido sensor? See, that second thing is way cheaper than the first thing. But they would not even do that, right? You just go through all of these other things that are much weaker that we don't even think about. And so it's worth moving forward to better harden all of the layers and really think about all of the different layers, technological, infrastructure, social in order to make Ethereum as hardened as possible. Yes. All right, well, Vitalik, please keep in mind the name of the game is to answer the questions in the side chat. So if you have any questions for Juan and Vitalik, shoe them away.
02:08:03.100 - 02:08:29.940, Speaker A: And next we have SHRIM, who arrived just in time. If he is two more minutes late, I was going to appoint. A representative from the audience to do slides karaoke. But he walked in the door just in time and then took a picture of the stage. I was like, wow. All right. Awesome.
02:08:29.940 - 02:09:04.222, Speaker A: Good morning, everybody. Hi, I'm Sriram. I was formerly a professor at the University of Washington, Seattle, and founder of the IconAir Project. Today I'm going to talk about revere. It's the name of our gadget. We are proposing for censorship observability in Ethereum. Why is censorship important? Right.
02:09:04.222 - 02:09:48.620, Speaker A: I think we all know this, but I'm just going to take a couple of minutes to say this. So censorship is about you want to get transactions included in the blockchain, and you want to be protected against all kinds of economic attacks. For example, you are running a liquidation protocol. You may get liquidated if your transactions get censored. So there is economic reasons to worry about censorship resistance. There is credible neutrality. You want your protocol to not depend on jurisdictional considerations.
02:09:48.620 - 02:10:51.412, Speaker A: Different participants may have to adhere to the jurisdictional constraints, but together the protocol should not have to take a dependence on one geographic region. You also want this property I call meta censorship resistance. What is this? Normally we talk about censorship resistance as though it's a property to only users of the platform. But I think smart contract platforms like Ethereum have a more generic sense of censorship resistance, which is even more important, maybe, which is that developers building on top of this platform cannot be censored. So imagine somebody is running a social network and one of the big features of blockchains is immutable open API access to other builders to build composable open innovation on top. And what if the roll up developer or somebody or the blockchain nodes all censor any new deployments, new smart contract deployments on top? Or calls to these new contracts, new smart contract deployments on top so as to make it unusable for any other developer to build new features. So this is another important property that we need to worry about.
02:10:51.412 - 02:11:55.050, Speaker A: So when we're talking about censorship resistance, we think of it as though it's some kind of a binary thing. Is the system censorship resistance or not? But really there is a nuance to this, which is what we call time to censorship resistance, which is what is the timescale at which the system expresses the censorship resistance property. I send an honest transaction into the system which is paid enough base fee, then am I going to get included in the blockchain? How long is it going to take to get included in the blockchain? Imagine you have things like short term expiring options or like a fraud proof period which gets over within that short period. Then even though my transaction gets in afterwards, I don't get any benefit. So there is a time to censorship resistance, which is what we need to be thinking about. Another reason which one of the things we know from blockchains is when you convert these philosophical things to more measurable economic metrics, there is a lot of incentive for different people to optimize it. One of the important things is, for example, when you think about economic efficiency of, let's say, like an optimistic roll up.
02:11:55.050 - 02:12:40.916, Speaker A: In an optimistic roll up, there is a settlement lag, maybe a seven days or whatever. And inside the settlement lag, people have to front the capital in order to do any kind of faster transactions. So the capital efficiency of the optimistic roll up system is determined fundamentally by the fraud proof window, and the fraud proof window is determined by the censorship resistance time. So censorship resistance has consequences all across the spectrum to permissionless innovation, to usability, to credible neutrality, to capital efficiency. Imagine you're running a stablecoin protocol. What is the overcollateralization factor that you need to keep for the protocol? It's dependent on the time to liquidation the volatility during the time to liquidation. The time to liquidation is dependent on the time to censorship resistance.
02:12:40.916 - 02:13:17.696, Speaker A: So there is this temporal aspect of censorship resistance I think we should all think more about. Okay, so the goal of Ethereum is to be resilient beyond majority trust. Vitalik just gave a talk explaining where majority trust may break. In the normal model many blockchains are built on you just trust that the majority of validators will be honest. But in a pseudonymous world, it's not robust to assume that a majority of these nodes will be honest because who knows who they are. So the goal is to build systems that are resilient to the majority of validators not being honest. Okay, so there are really two aspects.
02:13:17.696 - 02:14:19.796, Speaker A: When you're building a system in a blockchain or any distributed system, there is safety, which is that if something gets confirmed, it should not get deconfirmed or reorg. So it's very easy. So Ethereum is built on this principle of slashing, which is that if a majority of validators collude to attack the protocol, you can actually attribute them and slash them. So if there is a safety violation, then they sign two conflicting blocks with the same block number and it's easily attributable and we can actually slash these nodes. However, when you think about slashing for censorship, it's much more difficult and intricate. So imagine a majority of the validators collude and make sure that transactions are not getting included. How is the protocol going to know in a rigid way that this was actually happened? Because there may be users that claim that, yeah, I submitted my transaction and the blockchain validators may say I didn't receive the transaction.
02:14:19.796 - 02:15:09.796, Speaker A: So there's a he said, she said kind of a thing which is not there in safety violations. So censorship is difficult to attribute and slash on chain. Okay, so given this context, what are the types of censorship that can actually happen? There are two fundamental types of censorship that we can categorize into. Number one is proposer censorship you're a block proposer and you fail to include transactions that are valid and perfectly good for whatever reasons, for legal reasons, for economic reasons, you took a bribe and you want to censor somebody, whatever the reason may be. So proposer censorship is one kind of censorship. Another kind of censorship is attester censorship a tester. Censorship means somebody has proposed a block with certain transaction, and I as an attestor.
02:15:09.796 - 02:16:06.008, Speaker A: So in Ethereum, you have this kind of a protocol where there is a chain of blocks being proposed and then attestors attest to these blocks. And what you can do is attesters can all kind of collude together and not certify any blocks that contain certain transactions. So if you want to compare these two types of censorship, it's much easier to solve for proposal censorship. Why is that? It's because proposer censorship can be mitigated by having even a small fraction of honest proposals. Okay? Imagine that the network has 5% of honest proposals. They will just follow the protocol, include whatever transactions, satisfy basic validity conditions, and include them. That is actually enough to solve for proposal censorship because if you have 5% of honest proposals, you will get one in 20 blocks, be built by them, and the transactions go through.
02:16:06.008 - 02:17:17.868, Speaker A: That is a reduction in the throughput of censorship resistant transactions because only one in 20 blocks can comprise of censorship resistant transactions. But still, the fundamental fact and the time to censorship resistant resistance can be controlled quite significantly even by having a small fraction of honest proposals. This is one of the important reasons why in the Ethereum community there is an emphasis on home stakers, solo stakers, even if they are not in the majority, small percentage still makes a big difference because proposal censorship can be solved using a small number, a small fraction of honest validators. Okay? But a test of censorship is actually much more difficult to solve. Why is this? Let's say if 33% of the stake is adversarial, 66% is actually honest, okay? But the 33% of the adversarial stakers are not just failing to include transactions from others. They actually will not build on a block in which those transactions are included. Why are they doing this? Maybe they're doing this for legal reasons.
02:17:17.868 - 02:18:00.984, Speaker A: Maybe they're doing this for economic reasons. Somebody gave them a bribe to say that, hey, I don't want this guy to refuel his collateral before liquidation occurs. You guys all go and make sure that that transaction never gets included. So this is a significant problem in censorship. Okay? So an example of an attestive censorship is when blocks are being built, there is a block, this uncle block that you're seeing here in dotted lines, and nobody builds on top of it and starts attesting only alternative blocks. So now what has happened is there was a proposal which included the transaction. It just never gets into the main chain.
02:18:00.984 - 02:19:02.796, Speaker A: And therefore it is as though it didn't exist at all. So this is a big issue. Okay, so what can we do about this? Can we try to enhance the observability of uncle blocks? How do we do this? So the first thing is if there is a certain fraction of Adversarial stakers and they're actually censoring these blocks, then what happens is if you are using any standard Byzantine fault tolerant protocol, a protocol which just finalizes each block as it comes. What will happen is this block will get proposed and will not get enough certificate and therefore there is not even a block in regular BFT protocols. Ethereum actually has a little bit of a different kind of a protocol called Gasper. In the consensus layer, which basically has a layer of liveness, blocks keep getting proposed, they just don't get attested and finalized. It turns out this actually performs a vital function of observability.
02:19:02.796 - 02:20:00.256, Speaker A: Okay, so this is one of the kind of core designs behind the Ethereum consensus protocol is that there is a layer of liveness and a layer of safety built on top of it. And so you can start seeing that there is a pattern of blocks. There's a bunch of blocks and then you can see this proposed block which is not on the main chain and people have not voted it. So actually this is already very useful. However, there is a problem. The problem is if you see a pattern like this where there is a bunch of blocks and then there is a forked block, you cannot attribute whether it is because of network latency that this block didn't get included or it is because of intentional sensoring, because both of them look alike. If this block came in and the nodes basically didn't observe the block and then they continued building, or it might be that this block was intentionally censored.
02:20:00.256 - 02:20:45.148, Speaker A: How do you disambiguate between the two when you see a pattern like this? So that's what the rest of the talk is going to be about. Okay, so what we propose is this gadget called revere, which is a mechanism to solve for a tester censorship. So the first point here is a slight change in the inclusion rule. It may already be what most of the consensus notes use. The transaction inclusion rule is when a proposer proposes a block, it must include transactions from recent uncle blocks whose transactions have not been included in the fork. So you see a transaction and if you're proposing a later block, you must include these transactions. That's a rule.
02:20:45.148 - 02:21:38.576, Speaker A: Okay? And you can set some threshold. You say like the fork transaction should have at least paid significantly over the base fee or something like that. So that you don't have to force include every transaction, but somebody who's trying to get their transaction in, we need to give them a certain quality of service that actually they'll get included. So this is a transaction inclusion rule, okay? If you're running a client you have to follow this if you're using PBS you have to make sure that the relays will have to make sure that this is actually the case for the proposed blocks. Okay? So now something powerful starts happening. If you see a pattern like this and you see this transaction and then eventually in the chain that transaction gets included, you're like okay, these guys are not intentionally censoring because this transaction was eventually included. They used the proposed inclusion rule and eventually you can see that the transaction is included.
02:21:38.576 - 02:22:59.266, Speaker A: So you can infer or assume that it's because of network latency that this block didn't get included in the main chain. However, if you see this pattern where you see a transaction as an uncle block and then other blocks keep getting proposed and this transaction is never included anywhere in the future, then you can infer that the cost is a tester censorship. Okay? So that's the basic idea. You have this mempool rule which is that take extract the transactions which are paid beyond a certain fee from reason blocks and then you have to include them in your block if you're a proposer. And this rule basically enforces a social consensus where by looking at the structure of the blockchain you can infer socially whether attested censorship is happening or not. Okay, so now how do we propagate this information? So who is observing this and how do we propagate this information? So one of the problems with any of these methods is we need a lot of nodes to be observing the blockchain to see for these patterns in order to establish social consensus that censorship is actually happening. And one way to do it is you can start building sophisticated light clients which can enhance observability.
02:22:59.266 - 02:23:49.826, Speaker A: So what is the idea here? A slight variant of this light client rule is basically that you download and do sampling, which is just to ensure that the block was available. You download block headers, it should say download headers. You download the block headers and sample blocks, not only blocks that are well attested, but also blocks that are proposed by valid, proposers but not attested. You do this. So now what's happening is everybody who's running a light client actually is seeing the pattern of headers. This structure from the previous slide is transparent to anybody who is actually observing the blocks. Even though they won't see into the blocks and see the transactions, they definitely know the structure of the block headers and at what times these block headers are released.
02:23:49.826 - 02:25:03.326, Speaker A: So this actually creates a very significant incentive for not doing a tester censorship because now light clients can bear testimony to whether censorship is happening or not. So instead of light nodes only being checking validity for their own selfish purpose, which is one way of using light clients here what we're doing is using the light client as a technology to enforce and monitor the Commons, the Ethereum Commons and make sure that validators are behaving according to the covenants that they signed up for. So once you have light nodes, bad testimony to a tester censorship, there is a strong social consensus that has been established on whether censorship is happening or not. All of us know whoever is running a light client has observed the pattern of headers and can later open up the blocks and see that oh, this transaction was proposed here, it has not had been included in the series of blocks. And immediately you can use this to do slash ability for a tester censorship. And there are technical details in how you can use inactivity leaf to perform slashing. This is already well known in the ethereum research community.
02:25:03.326 - 02:26:17.334, Speaker A: Okay, so what this does remember, I proposed not only that the concept of censorship resistance is important, but also we need to get the sharp time to censorship resistance. And one way to think about it is if a transaction is censored by our testers beyond a certain time, then you can actually slash these guys. So that's what the observability Gadget revere gives you is this information that the testers are actually censoring is now widespread and available to everybody who cares to monitor the ethereum system via light node. And you can use this to actually then establish strong social consensus to censor nodes. What this does is, along with an assumption that certain fraction of proposals are honest and will include transactions which pay a certain fee, you can actually start getting tight economic guarantees on censorship resistance. If transactions get censored beyond a certain point, you can be sure that you see this pattern in the blocks and because you're seeing this pattern in the blocks, you will be able to slash a majority of the stakers. So with that, I conclude the talk.
02:26:17.334 - 02:26:57.700, Speaker A: I just want to make one point here, which is how this idea fits in with the ethereum roadmap. One of the ideas in the theorem roadmap is that even if builders are centralized, block builders are centralized and high power block proposers can remain decentralized. What we're doing here is to take this one step further. We are saying even if block proposers are centralized to some extent, only a small fraction are decentralized. By having like clients to be highly decentralized who are monitoring the comments, we can actually ensure that these bad proposals are held to task by our slashing. So that's the idea of the talk. Thank you so much for the time.
02:26:57.700 - 02:28:45.740, Speaker A: All right, well, same role. Please answer everyone's question async in Eastglobal TV. And next we have our last talk of the first chapter from Constanza. And while we're waiting, I would like to dare everyone to think of a lightning talk topic. So we put up whiteboards outside of the breakout rooms. If you have a dope idea, especially or contrarian opinion around censorship resistance wealth, you can have your stage over there and it will be in discussion format, no slides required, so be my guest. You okay? So hi, everyone.
02:28:45.740 - 02:29:25.850, Speaker A: My name is Costanza and I work for the Swarm Foundation, a decentralized and chancellorship resistance turbid and communication network. Today I'll be talking about the various level of Internet censorship and how Web Three can help us to do so. I'm going to use the Wikipedia case study before I start a disclaimer. First of all, I'm not a lawyer and this talk is not legal advice. And everything I'm saying is a personal view. And I do not represent an organization that I am or avoid affiliated with. So let's start.
02:29:25.850 - 02:30:02.180, Speaker A: What is internet chanceorship? There are several layers to consider for Internet Chancellorship. This is because Internet Chancellorship is the spread of fake news. Think about troll farms that obfuscate the truth. Chance is shadow banning. If a tree falls in a forest but no one is there to hear it, doesn't make a sound. Chanceorship is preventing people from accessing content. Chancellorship is deplatforming.
02:30:02.180 - 02:30:56.720, Speaker A: Chancellorship is cutting off people from accessing Internet service providers. Chancellorship is cutting off energy power from Internet service providers. Chanceorship is not giving people the materials necessary to build the hardware. Chancellorship is arresting someone to force them to do any of the above. So in this talk, we're going to focus on how Wikipedia gets transferred and spoiler. Those are the three ways in which it happened and how the forum network can help. So what do Venezuela, the UK, russia, China and Australia, and all the countries in red have in common? They all at some point transferred Wikipedia.
02:30:56.720 - 02:31:54.970, Speaker A: And the list is actually much longer. You can find a Wikipedia article on Wikipedia transfership, and this is because many in fact don't know that Wikipedia was transferred by seemingly unassuming actors like France. Question is why? The official explanation is always the same protecting people. Whenever something doesn't follow the narrative that a government approves, they say that it's press fake news, it discloses classified information. So basically, anything that doesn't agree with the government narrative of a country is a reason good enough to stop Wikipedia. And there is two ways in which it can happen. On a human level, by arresting people, by stopping the infrastructure, and on a technical level, by preventing people from accessing the content.
02:31:54.970 - 02:32:41.868, Speaker A: So, as we can see in this day, censorship is quite sneaky and you can protect, you can decentralize your code, but there is a human component. This is what happened with Tornado Cash when the founder got arrested. And this is what happened with Wikipedia. About ten years ago, the France intelligence Agency, the equivalent of the CIA, contacted the Wikimedia Foundation to ask them to take down a page because it contained classified military information and broke the French law. So the Wikimedia Foundation asked for more details. Which part does it goes against? The law. There was no response from the French CIA.
02:32:41.868 - 02:33:21.060, Speaker A: Case closed. Not really. Not long after a Wikipedia volunteer was arrested and ordered to take down the page under the threat of custody and charges. What is funny here is that it had no connection whatsoever to the article. It didn't even know that it existed, it didn't edited. It the only reason why they chose him, because it was quite well known within the Wikimedia community, so it was very easy to be identified. Now there is a plot twist and there is a happy ending.
02:33:21.060 - 02:34:08.450, Speaker A: The article was restored by a Wikipedia volunteer from outside of France and karma is a bitch. So the article became the most read page on the French Wikipedia. Now, I'm mentioning this case because it's absolute, it was like ten years ago. But this is way more common than we believe. Transfership on a human level by threatening and arresting people is the most common type of chanceorship we have. And of course we are all well aware of other examples that happen close to us. But then you can also transfer using the middleman, the infrastructure, by threatening them.
02:34:08.450 - 02:35:21.224, Speaker A: So threatening means that the government that wants to transfer content can impose sanctions over an infrastructure middleman over an association. And this is what happened with Tornado Cash when the GitHub repo was taken down. And what happened recently with Wikipedia. November 2022 a Russian court fined Wikimedia Foundation 2 million robots for not deleting two articles on the Russian Wikipedia. February 2023 a Moscow court fined the Wikimedia Foundation 2 million rubles for not deleting articles about the army. April 2023, a few months ago the same court fined the Wikimedia Foundation 800,000 robbers for not deleting the lyrics of several songs by a rock band. So what about blocking content? So this is the third way in which you can transfer Wikipedia by preventing people from accessing it.
02:35:21.224 - 02:36:22.412, Speaker A: And there are two actors at play here, governments and ISPs Internet service providers. I see some confused faces here. So yes, ISPs private actors acted on their own and chancellor Wikipedia in the past. This is because, like most web three organizations, as of today, the Wikipedia infrastructure is hosted in six data centers between the US, Europe and Singapore. Data centers that belongs to private organizations like Equinix Cyrus, one OCOM Group, Halas in a very centralized fashion. So until a few years ago, wikipedia was accessed through unsecure Http protocol. So basically, third party could chancellor a few entries of Wikipedia targeting them.
02:36:22.412 - 02:37:17.040, Speaker A: So anything that was deemed problematic and offensive and that will not fit their agenda. And yeah, like we saw before, that was done by governments and by ISPs. ISPs private entities were deciding what people could and could not read. That changed finally in about 2015 when Wikipedia started running on Https. So partial censorship was not possible anymore. So as of today, if someone wants to target Wikipedia, they have three options some countries completely drop their ban and just accept it. Some other countries they ban completely wikipedia so you can access it at all.
02:37:17.040 - 02:38:11.280, Speaker A: Some other countries are threatening people to delete the entries. And I know what you're hypothetically and I can't stress enough that this is not legal advice. If you want to use Wikipedia in a place where for whatever reason it is not available, how do you do? Yes, you can download a VPN, you can use Store and you can try to access Wikipedia. And that is a great solution, except that it's not because VPN is centralized. VPNs are centralized so they can be blocked by governments or ISPs they are not incentivized. So there is no guarantee that people will continue to use them if they are transferred or blocked. And this is what happened to me last time I went to China in 2019.
02:38:11.280 - 02:38:56.380, Speaker A: I had been to China a few times before and I always use a VPN that was working just fine. But in 2019 when I got there, the VPN that I normally will use didn't work. So I was cut off from the internet. And that's why we need a decentralized and untappable solution that doesn't rely on that. So here is a pretty dope asynchronous mirror of Wikipedia which is hosted in a decentralized manner on the forum network. So anyone connected to it can access and search through the complete set of information. How does it work? There is two components here that makes it transorship resistant.
02:38:56.380 - 02:39:55.600, Speaker A: First of all, when you upload a file, the file gets divided into small chunks and each chunk is stored on the network on several nodes. And then there is the Kadema routing nodes communicate with each other in this way. So we have Alice and Alice wants to send a message to Dave, but she doesn't know Dave. She's not connected to Dave, but she's connected to Bob. So she sends a message to Bob because she knows that Bob is somewhat closer to Dave. Now, Bob doesn't know Dave but he knows Carol and he knows that Carol is more likely to know Dave. So he sends a message to Carol and Carol is like yeah, I know Dave and she sends a message to Dave and this is how hallis communicates to Dave and to any other nodes in the network.
02:39:55.600 - 02:40:54.960, Speaker A: Now, what is important here is that by following this communication pattern, it ensures that not Dave, not anyone else knows that the request started from Alice and in the same way Alice doesn't know that Dave is the final endpoint, it can be someone else. So this communication strategy has the added benefit of anonymity for both the senders and the receiver. So it guarantees anonymity at the network level. What happens is that thanks to chunks and to CADMIA routing nodes don't know what they're storing, don't know who is storing what. And that gives them plausible deniability. So node operators cannot be held accountable. So that prevents from middleman chambership.
02:40:54.960 - 02:41:44.576, Speaker A: So what can we learn from here? We saw the three ways in which Wikipedia gets censored blocking access to content, deplatforming and arresting people. And this is important because Wikipedia is just one example of permissionless. Publishing. Publishing your website, your application on form will give you total ownership of your content, making chanceorship more difficult. So what is next? I'm not sure it's public yet, but we are launching Worms 2.0, which includes Etherdrot, a packer to help with censorship resistant publishing. And finally, and this is legal advice, get yourself a shadow with Super Lawyer.
02:41:44.576 - 02:43:03.570, Speaker A: Thank you. All right. Thank you so much, Constanta. I think next we will switch to our proc stage. But before Tim goes on, just want to make an announcement that in about 20 minutes, in the room across from this stage, we will have our first breakout session hosted by Harris from Ezekien on the topic, a discussion topic of what if we do want to censor. So if you are interested, feel free to check it out. Testing.
02:43:03.570 - 02:43:29.280, Speaker A: Okay, things are working here. No idea if they're working on the live stream. Let's see if somebody can give us a queue. It's great. Are we live on? Does anyone see the live stream? Okay, we're right. Nice. Well, yes or no? Maybe? Okay, let's give them a SEC.
02:43:29.280 - 02:44:11.582, Speaker A: Oh, can you hear us in Istanbul? Oh, it's working. Okay, neat. So, welcome everyone, to the Prague version of this. So we split the event today across both Istanbul and Prague. We'll also have some remote speakers and we're sort of kicking off the second chapter of today. So we had a lot of great talks giving high level overview of censorship resistance across different parts of the Internet. But now we really want to dive one level deeper and start this at ethereum layer one.
02:44:11.582 - 02:45:10.350, Speaker A: So, the next series of talks are going to be deconstructing censorship resistance on layer one across a whole bunch of angles. First, we'll have Dan O'farron, one of the core devs on the Beisu team. Talk to us about how Stateless can help for censorship resistance. Then we'll have Adon, the founder of Blocks IO, who will talk to us about DVT and how that can improve censorship resistance. Followed by that we'll have Nix from each staker talking about the importance of solo stakers. And then Sebastian talking about possible negative endgame, what happens if we don't have IP level privacy? And followed by Tony from the EF talking about PBS and how that relates to censorship resistance. And we'll wrap up this layer one chapter with Sajida talking about observability of censorship resistance.
02:45:10.350 - 02:45:57.280, Speaker A: So, yeah, stay tuned for this. We have our first two talks in Prague. In Istanbul, there's a breakout room at the same time. And then we'll have some more folks coming in from Istanbul, some folks remotely over the next couple of hours. On to you, Daniel. Can I slide the ticket? Cool. Just gonna work like I hoped.
02:45:57.280 - 02:46:34.258, Speaker A: It's always the worst part. Traffic. There. We go, is everything cool with AV? And pick me up on the microphone. Okay, cool. So I just want to say it's great to be back in Prague. Five years ago, I started my journey in Crypto.
02:46:34.258 - 02:47:18.466, Speaker A: I'd started at Consensus a couple of weeks before they had a Pegasus offsite the week after DevCon. So it's kind of coming full circle for me to come and talk about some of the things that are on my mind about censorship resistance. So I'm going to talk about mind your own business, state Prison Transaction verification, and then what on earth does this have to do with Parallelism? And we'll get to that. But first, a little bit of context about what mind your business is and what I'm going after with that. So this is a picture of something called the Fujiocent. The Fujiocent was the first currency circulated by the US. Not the first currency minted by the US mint, but the first actually circulated currency.
02:47:18.466 - 02:48:01.682, Speaker A: And there's a lot of Trivia and a lot of Coin information that goes with that. But what's interesting to me is this little model put on the bottom of mind your business. It's something that Benjamin Franklin was really excited about and he was sharing with people that you should always mind your business. And it's kind of a strange phrase. It had a lot of different implication 200, 300 years ago than it does today. Because when you hear the phrase mind your business, usually what you think of is mind your own business. And that's what people tend to worry about when they talk about censorship, is they're worried about cameras and the government and everyone looking into things that quite frankly don't matter to them and minding things that just really they shouldn't be caring about and then being invasive and looking into all those things.
02:48:01.682 - 02:48:42.846, Speaker A: And people want privacy in this regard, so that what they do in private, stays private. So when you hear the phrase of mind your business, you sometimes put in mind your own business saying, Stay out, stay out. This isn't you. This is kind of an outside in looking view of it. And honestly, the government is not the worst version of this mind your business situation. I think surveillance capitalism is probably a bigger impact of this whole mind your own business situation, where you got people who are companies who are building these giant data centers to collect all of this data and to combine it together and to figure out whether it's better to sell you an ad on a cookie or an ad on a car. And they're using all this massive amount of information to do it.
02:48:42.846 - 02:49:32.320, Speaker A: But when I think of mind your Business, I actually think of a Netflix series called Inventing Anna. And there's a very pivotal scene in that where Anna this woman who's trying to do a confidence game on high society in New York to build her dreams for an art studio keeps getting kicked out of hotels and keeps know she doesn't have the money but she's living like she has all sorts of money. Another character named Neff is one of the concierge of one of the hotels that she's worked living in. And Neff is one of her closest friends. If she has friends that really understands because these two, they recognize people that have hustle in their life. They recognize people who are making things happen. So when things are starting to collapse at the hotel that Neff works at, she gets Anna to the side for a moment and she tells her mind your business.
02:49:32.320 - 02:50:09.942, Speaker A: And what she sees saying there is something not about don't stay out of my business. What she's saying is take care of your business. You have bills to pay here. You need to pay them because things are ending. And I think that's really when we talk about mind your business, we're talking about taking care of your business, taking care of the things that you need to worry about, being able to pay your bills, make sure that your checkbook balances properly, make sure that your bed is made, make sure that your car is running properly. And these are the things that we really need to worry about in a censorship resistance world. It's like, can I still do the things that I need to do? And that's kind of the counterpoint to privacy.
02:50:09.942 - 02:50:37.114, Speaker A: I need to worry about it. Do other people need to worry about it? Well, I don't know if other people are going to worry about it, but I need to take care of my stuff. So this brings us to the dark side of scalability, which is kind of the direction that things are starting to go. This is a problem related to success. It's probably one of the better things to happen to Ethereum, but it's still a problem. Let's take an example of getting paid on chain. Let's say you're a box packer, a barista or a high school teacher.
02:50:37.114 - 02:51:32.770, Speaker A: And in the future you've been moved to having your payments happen online. If you want to prove that you've been paid, if you want to prove that the contracts have executed properly and that everything is there, you either need to don't run the execution and just hope everyone's analysis of it runs or you need to execute it yourself. And execute it yourself. You need to run every previous transaction that leads up to that to prove that people had the balance and then when they had the balance that they took the balance and then they paid you and all of the other various side effects of that. So to calculate all this information and get all this information, it takes a rather beefy computer in the cloud to calculate all of this. And typically to run a node you need something like four cores, two terabytes of hard disk, 200 gigabits of bandwidth and 300 I ops and that's not something that a high school teacher is going to use their salary to spend on just to verify that they can get paid. This is a problem for broader and wider adoption of crypto.
02:51:32.770 - 02:52:03.038, Speaker A: We want people to fully participate in the censorship resistance. And it's no more truer than Polynia, who yesterday posted a post just yesterday. And I'm just going to read what he said because or she. I don't know if it's a here or she, but what they said was very insightful into the problems that we're having with these growing nodes. They said the more transactions the network processes, the higher everyone's hardware requirements. The more nodes in the network, the more inefficient and slower it becomes. Or alternately, you limit accessibility.
02:52:03.038 - 02:52:58.178, Speaker A: So very few people in very few places can run unsubsidized independent nodes effectively leading to a Dystopia that is infinitely more centralized than traditional finance. And I like to call this censorship by wealth. If you are not rich enough, you cannot participate in the system. And this is kind of the opposite of a lot of the enablement that we've been going for in Ethereum to make sure that everyone at all different levels can participate in their financial freedom. If this goes unbounded it's going to be more effective than banks ever could have done. So how can we address this problem? How can we solve this? How can we make sure that you can mind your business in the entire world economic system without having to process the world's economic systems? That's where state proofs and transaction verifications come in. State proofs are a witness of the block to say here's what was happening before and here's the data that you would need to prove it.
02:52:58.178 - 02:53:52.610, Speaker A: And transaction verification is actually running these blocks and proving the verification we have there. So instead of drinking from the fire hose while the world burns down, it's a small drinking fountain in the park providing the refreshing water that you need to run just your transactions in your blocks. Typically, these things include the minimum things, like a header, the block header that you're verifying for the block, the accounts that were read to or written from, read from or written to the contract storage that was read from. Or written to any intermediate tree nodes that are needed to calculate the state route to prove that you have a consistent state, the code that you need to execute. And maybe in some situations we might need to include some prior block hashes depending upon which operations you execute it in. And if all those things are in a state proof then you don't need those giant machines in the cloud. You could verify this block with a phone that you keep in your pocket and I'm not even talking the high end phone.
02:53:52.610 - 02:54:23.226, Speaker A: This could be like the $99 special that you get out of Google Fi. With this sort of information you can verify your transactions occurred in a much more reasonable system. There's a problem though, is that we don't have it today. And why don't we have it today? The problem relates to our current Merkel Patricia tree. Our merkel patricia tree. If you've seen the typical images of it, you'll see a nice, cute binary tree with maybe five levels and really small consistent proofs. But the reality is these trees are 16 nodes wide.
02:54:23.226 - 02:54:45.460, Speaker A: They're often 30 layers deep. And for a block proof, typically it takes up to a megabyte. Bad block proofs will take up to two megabytes. So we can do this today, but we can't do it in a way that can be efficiently be spread worldwide for transactions at scale. And this is, by the way, at about 12 million blocks. 12 million gas blocks. 15 million gas blocks take more.
02:54:45.460 - 02:55:10.762, Speaker A: 30 million gas blocks are going to take even more than that. So this gets worse and worse. The good news is there is a solution that we're working on to address this size problem and it goes by the name vertical trees. There's even an EIP for it. So we take these big 16 area blocks and we compress them into witnesses. So instead of needing 16 values to prove that your next step of the block is true, you only need three. You need to know where you are in the parent commitment.
02:55:10.762 - 02:55:44.050, Speaker A: You need to know what your value is. You need to calculate a special little thing called a proof. I don't fully understand the math into it, but I know that the side effect is it takes what used to say kilobytes into a matter of tens of bytes. So vertical trees are basically a tree of these vector commitments. And what's even better about this is if you look at some of the details, it fixes the side problem because rather than being 16 wide, these things are 256 wide. So we even make the tree shallower. In addition to having smaller leaves, you have less leaves and smaller leaves.
02:55:44.050 - 02:56:14.850, Speaker A: And we're packing everything into this tree that we need. We're packing all of the account state, we're packing the code, we're packing contract state and known state. These things are going to be in the vertical tree and they're going to be available and accessible in a much smaller system. And from this we can reasonably, as part of the protocol with every block, send out a proof in something that takes kilobytes instead of megabytes. And this will allow us to scale. We've almost made it. We can almost do it today.
02:56:14.850 - 02:56:59.486, Speaker A: But what happens when we grow? What happens when we have billion gas blocks? What happens when we have transactions on the scale of Visa on one chain and one network? So this is where parallelism comes in. And when people talk about parallelism, this is kind of a topic on Twitter that people talk about. But I think there's a stealth way that we can use parallelism to help solve these issues. When we talk about parallelism, there's like three layers of places we could put the parallelism and I think we've only really touched on one or two of them. The first I term prefix parallelism. This is where before you submit your transaction, you put information into the transaction that you think might be useful for parallelism. You might use access lists to say hey, I'm going to be accessing these storage slots and nothing else.
02:56:59.486 - 02:57:31.466, Speaker A: And systems can use that in their transaction to schedule so that you won't have conflicts. And another version of parallelism that's been out for years is called sharding. Instead of doing everything in one block where we have a billion gas, let's have 1000 1 million blocks and split it up into smaller shards. Sharding is actually a parallelism solution. When you look at it. What people are working on today is what I term infixed parallelism. This is where you take parallelism into the execution of the block stuff that Monad is working on.
02:57:31.466 - 02:58:10.710, Speaker A: There's so many M words, I want to call them modular. But Monad's working on a solution that they borrowed from Diem which then became apptots and something called block STM where they're taking the execution of the block and they're using optimistic concurrency control to just execute it in parallel. And when things go wrong, they re execute it with a new information. They've also introduced another interesting idea that I'll come to later in the talk called Delta Writes. Instead of writing value goes from one to two, just say value increases by one. And that's a parallel optimization. That's something that's used in a lot of parallel systems to make sure that the impacts don't collide.
02:58:10.710 - 02:58:58.386, Speaker A: But I think the most interesting area of parallelism can be applied in what I call post fixed parallelism. This is where you've executed the transaction and you know the details about the transaction and you apply information to your output to say, here's how you can execute it in parallel. So you might notice which transactions conflict and you could put metadata into the transaction receipts to say these transactions conflict and must be done in a certain order. And from this we can identify something that I'm calling a compatible transaction group where you have groups of transactions that can be included or removed and all the side effects will be the same regardless of how many of those that you evaluate. Now, I've been thinking about parallelism for a time and here's a tweet just from just July. But I've had graphs for this parallelism stuff for years as Tim could attest to. We had a little thing in consensus.
02:58:58.386 - 02:59:36.290, Speaker A: We were thinking how could we parallelize this? And the problem is actually the database back four years ago why I didn't go into parallelism. But it's interesting we should talk about databases because when you talk about database transactions there is a famous acronym called Acid which talks about four characteristics that any database transaction needs. And these database transactions are always done in parallel. They're always distributed, they're always done with a bunch of people at the same time. The first concern is atomicity that what you do only succeeds or passes in one group. The second is consistency. The work that you're doing won't cause problems in the work someone else is doing.
02:59:36.290 - 03:00:17.200, Speaker A: This is important in issues like in larger data collections to make sure that when you add to a map that you're not going to make the map have a self referential loop. The third is isolation and that your transaction only interacts with its own world and doesn't need to worry about anyone else. And the final one is durability, is it's actually stored in the database. But of these four principles, I think the most important one to parallel transactions is that of isolation. We can take our transactions, we can isolate them from the other transactions in the block. And if we isolate them, we only need to care about the transactions that you put in there. And you don't care about the other 999,999 transactions in this million transaction block because you can identify the consequences that come from this.
03:00:17.200 - 03:00:56.006, Speaker A: And as ETH as one of the repliers said, you know what sounds like a topological sort problem kind of is. So here's a simple seven transaction block. You can see that some of them have dependencies and some of them cause dependencies. If we wanted to just worry about our transaction, if we don't conflict with other transactions, it's easy. We can just allied the other six transactions from our block, witness, just evaluate ours and be confident that our side effects will be seen. Gets more tricky though, if we're downstream from other people's transactions. If we want to make sure that our side effects are consistent, we need to see other people's side effects.
03:00:56.006 - 03:01:49.290, Speaker A: So this is what building parallelism into a protocol would do, is it might identify these conflicts. You can efficiently get your transaction groups that you would need to evaluate to make sure that yours is true. And another one, we don't even need to worry about other people as we go downstream. If there's a transaction that impacts multiple people, you just care about what your ancestors are. And again, if you're just the upstream transaction, you don't care what the side effects of the downstream are because you're only concerned about your own side effects. But I think the Holy Grail is the situation where, yes, you do have transactions that have changes before you, but that you can not care about them, that you can get the necessary information in the block to make. Sure that if you evaluate just your transaction, that the side effects are going to be true and correct and everything that you evaluate to make sure that you can verify this transaction.
03:01:49.290 - 03:02:22.102, Speaker A: One of the steps towards this is an EFP proposed a couple of months ago. That brings in the S credit and S debit operations. And this is basically bringing delta rights into Ethereum. Instead of writing that we're going to set block one from 100 to 200, we're going to say we're going to add 100 to block one and we're going to take 100 out of block two. So this allows us for a situation where to allow us to prove more interesting things. Like, say, let's say Alice has 200 coins and there's three transactions that affect Alice. 100 is sent to Bob, 100 is sent to Christy and Dave sends her 300.
03:02:22.102 - 03:02:59.166, Speaker A: So from that precondition that if Alice has at least 100 coins, you can do any of the next three transactions in any order. You can do any of the three transactions you feel like you can do all of them, you can do one of them, you can do two of them. And all the side effects in those three transactions are all going to be the same in. This is the power that parallelism postfix parallelism can provide for us in transaction verification. If you can prove these ranges and also saves a tiny bit of gas, the gas golfers are going to love this. So it might be easier to get this in than we think. So from this, we can produce groups in the protocol of compatible transactions.
03:02:59.166 - 03:03:26.470, Speaker A: We can identify sets of transactions. And here's my definition. It's a set of transactions where you can have the transactions in a set done in any order, and also you can evaluate any subset of the transaction within it. And the side effects of those transactions are all going to be the same. So you could have some one or all and you could do them in any order. And if it's in a compatible set, then it doesn't matter what you do there. Now, combine this with a ZK validity of the block proof.
03:03:26.470 - 03:04:34.042, Speaker A: We can align almost all the other data out of the block proof and provide this to someone to say, hey, I paid you. And here you can evaluate the transaction and here you can observe the side effects. And with a feature like this, this is going to allow us to mind your business, mind all of your business, and you only have to mind your business if that's the only thing you care about. So again, this is my vision for how transaction verification can really help resistance to censorship by wealth, so that everyone on any device can verify that their transactions were part of the Ethereum chain. Oh, nice. Hey, everyone can hear me well, right? With the audio? Perfect. My name is Alan.
03:04:34.042 - 03:05:20.362, Speaker A: I'm one of the co founders at SSV's core team. SSV is the first implementer for DBT, which is distributed validators technology. I started out life actually in the Ethereum Foundation as a research project. The idea was, how do you take an Ethereum validator and being able to distribute it into shares and those shares operated by independent operators, node operators, with the idea in mind that if you can do that on a large scale you can actually decentralize a lot of the control for each and every validator. And that's kind of where censorship, resistance or at least what DVT can contribute to that comes into play. I mean the state of staking on Ethereum is pretty well known for everyone. It's pretty challenging.
03:05:20.362 - 03:06:03.286, Speaker A: There's a lot of centralization happening specifically because it's hard to run your own nodes. A lot of people don't have necessarily 32 E. And so what happened was a lot of that stake is being put into the hands of staking services and protocols. And those staking protocols became very large and also the actual companies and entities running that infrastructure became very large. That causes a lot of issues. I mean today you probably have around five or six entities, unique entities that control about two thirds of the stake on Ethereum, many of them in the same regulatory geographical location which is in of itself not doing great for censorship resistance. It creates a lot of challenges for Ethereum.
03:06:03.286 - 03:07:03.038, Speaker A: It creates a lot of risk both for the users, obviously, whoever is staking in a large staking service, it's a big target. So they might be more impacted by hacking or even accidentals. But also because the way slashing on Ethereum works, if a very large staking provider gets slashed, the impact or the penalty becomes greater than just a single solo staker getting slashed. There's also systemic risk on Ethereum itself, amongst other things, censorship or the idea that you can decide, quote unquote, which transactions or which actions you can do on the blockchain just because of you controlling a mass amount of validators. There's a bunch of different reasons why censorship can happen. I want to focus on three of them. Obviously there's more, but there's always that malicious attack that creates censorship and we'll kind of go through what that means.
03:07:03.038 - 03:08:08.706, Speaker A: There's business decisions that cause censorship and there's regulatory reasons that cause censorship. All three of them and amongst other obviously reasons why censorship can occur are dangerous because ultimately we want an Ethereum that processes everything and is not swing that way or the other. So a malicious attack that can cause censorship obviously starts with some malicious actor taking control of an entity or a service provider that runs a lot of stakes. So it can be through hacking, it can be through internal, just internal work somebody did or if it could be even an accident somebody did within the same entity or same company. The censorship there might not be, it could be both specific or very broad. Again, it's mostly to cause havoc and it's for the most part temporary, hopefully temporary. And so that's kind of the malicious part of some malicious entity, third party or even internal trying to do harm.
03:08:08.706 - 03:08:44.314, Speaker A: And part of that harm can be censorship. Obviously that regulatory censorship or regulation based censorship is something I think that our industry in specific has a lot of challenges with. It can be forced or self imposed for the most part. It's very specific. So it's for very specific type of transaction. It's not broad and it's evolving. It's something that starts out in one place and in a year, two years, three years will be a whole different set of censorship calling filters or conditions.
03:08:44.314 - 03:09:36.202, Speaker A: And it's for the most part long lasting. So it's not something temporary, it's something that when an entity being forced or decides to censor because of regulation, it's probably a decision that will follow for three years. And the last one is really the business case. It has a lot in common with regulation, but it's mostly driven by, for the most part for rewards or just dollars and for the most part self imposed. It's very specific, it's still evolving and it's long lasting. And so for example, you can decide as an entity, I'm not including some transactions because I can't be bothered to spend gas on them or just processing time or whatever the reason is. But all three of them ultimately lead to the same non desired kind of outcome, which is not all transactions are born equal.
03:09:36.202 - 03:10:16.010, Speaker A: And that's a problem. And I think there's a bunch of different solutions or at least ways to mitigate that. I want to focus on two. So one is it's something that I think for the most part we saw as a community being pushed around, or not pushed around, but being kind of promoted, which is just increase the number of unique entities or people that run validators and actually run validators that process and propose blocks and so on and so forth. I think it's a great thing to strive for. Personally, I think it's very limiting, it's not very scalable. Obviously that's something we want to see, but I think we should be looking for more practical type of solutions.
03:10:16.010 - 03:10:48.306, Speaker A: And the other one I want to talk about is DVT distributed validators technology. That's something I've been working on for the past almost three years. And I think it has a lot in terms of value. It can add or mitigate some of the censorship risks. And so what is really DVT so DVT is the ability to take an ethereum validator and split it up into shares. And those shares operated by completely independent operators, node operators, those are kind of connected through one another in a group. We call them clusters.
03:10:48.306 - 03:11:43.338, Speaker A: Clusters can vary in size, so it can be 4710 or any other number of node operators within that cluster. And DVT really combines two pretty proven technologies. So one is threshold signatures with BLS, it's super, super easy to do. And the other one is just consensus protocol, a thin consensus protocol which lets those operators, node operators, decide on what they want to sign and then use threshold signatures to actually sign it. And the consensus protocol really gives us liveness and fault tolerance in general, just being very robust against both offline nodes and malicious nodes and so on and so forth. And so that's really what DVT stands for and what it really does. And if you combine additional kind of layer to it through the key generation process, if you use DKG, for example, then you can even take it a step further and say, okay, nobody holds the actual key.
03:11:43.338 - 03:12:47.466, Speaker A: And so there's less surface of attack and it opens up some kind of new properties specifically around regulation in terms of responsibility and who really owns the key and the validator for that matter. And so DVT, with DKG, I believe, can bring us to something very interesting. I tried to kind of put it into some graphical way of kind of showing it around, but this concept of censorship resistant cluster is something I think is worth talking about. The idea that you can take a cluster, configure it in a way that really reduces the ability to censor through that cluster. And if you do it on a large enough scale, then you can have a big chunk of the validator set, really 99.9% censorship resistant. And so what is this censorship resistant cluster? So the idea is that you can mix and match different types of operators, node operators, into something which gives a lot of protection.
03:12:47.466 - 03:13:20.946, Speaker A: So in this case, what I did was I took four institutional, well known institutional staking services, regulated. Some of them in the US currently hold a lot of stake. And their value is really that they're probably the most robust and scalable out there. They can handle the scale, they can handle being attacked. They've been around the business for a long time, right? That's the bottom line. And so you have four of them and the cluster size is seven. And so the three additional ones are just solo stakers.
03:13:20.946 - 03:14:11.250, Speaker A: They can be smaller institutions, they can be actual solo stakers, whatever the setup you want. The idea there is that you have seven different unique entities. Four of them could be potentially regulated and censored in their own way. But because they're attached to three others which are private and completely different type of an operator, those three only need just one more of those institutional stakers, institutional staking services, to sign something with them in order to broadcast it to the beacon chain. So imagine that for example, there's coming up some new regulatory framework in the US. Saying certain types of transactions will be censored. Well, the solo stakers only need one more entity through the four others which are institutional to agree to sign with them a block.
03:14:11.250 - 03:15:03.554, Speaker A: And that's something I think pretty plausible in the real world. Not all of the staking institutions are in the US. Not all of them treat risk at the same way, and so on and so forth. And. The flip side of that is that you still have the robustness of four institutional staking powerhouses. And so if one of those or maybe even two of those solo stakers fail because they're not as robust, maybe they are even amateurs, the others can recuperate because again, DBT holds within it a consensus protocol which gives you fault tolerance. And so I believe that this type of combination where you mix and match different types of staking node operators and staking services, you can really make a long stride forward in, at least on the surface and at least conceptually, make sure that it's not as easy as today to censor.
03:15:03.554 - 03:15:55.882, Speaker A: Because today really again, we're going back to the first slide and talking about around five entities controlling the majority of the stake in Ethereum and most of them in the US. It's pretty easy to censor. The only thing that the regulator needs to do is just send them a letter. I think none of them will say no to censor a specific transaction, although the implications are really big. But imagine that even Coinbase, like the most heavily regulated company out there, imagine them in one of those clusters and imagine the validator key was created in a DKG. Coinbase can say, all right, that they don't control the validator, they are part of a committee and they can simply outstand of signing that specific block where the specific transaction might be contagious for them specifically. But you still have six other entities who can sign it and the threshold is four out of seven.
03:15:55.882 - 03:16:39.400, Speaker A: And so you have that bandwidth to say, okay, maybe this one I'm sitting out as Coinbase, but the others can still continue in signing it and nothing happens on the surface. And so my personal belief is that this type of approach is very, very plausible and it's definitely something that can be happening today. I mean, SSV has been around for a few years on Testnets, we launched on Mainnet. This is something that can happen even today on Mainet. No change to the Ethereum network at all. Signatures are completely transparent for the bitcoin chain, for that matter. And so I believe this is a good approach, take a lot of the risk out without major, major engineering and changes to the network itself.
03:16:39.400 - 03:17:17.786, Speaker A: Like a few words on SSV. SSV is a contract based DVT network. So the idea is that you have a bunch of interconnected node operators and they're all synced through a smart contract. That smart contract decides basically, or rather its users decide which validators run by which cluster. And again, cluster is just a set of operators that run a specific validator. And it's a global network we're running on multiple data centers and continents and so on. And because it's a contract based network interacting with it super simple, just a simple web app and you can start running your validator.
03:17:17.786 - 03:18:11.250, Speaker A: I truly think that having the discussion to integrate more unique solo stakers or unique entities that run operators through something like DBT is a very simple way to take a lot of the risk out of censorship. And I think the risk for censorship is primarily due to those three factors business regulation or a malicious activity. And I think DBT handles and can help in a lot of those cases. Thank you. Sweet. So this was our second talk in Prague of this block. We're going back to Istanbul for the next one and yeah, surprisingly back on schedule, even a bit early.
03:18:11.250 - 03:20:52.686, Speaker A: So Nick's is up next in Istanbul in about seven minutes. Yeah, topic we're going to be talking about is are solo stakers valuable for censorship resistance? My name is Nixo. I currently lead a staking community called ETH Staker, which is first and foremost a community that is committed to the health and decentralization of the network. And that means that we support the validator set any way we can. We create solo node operators when we can, and we also support existing node operators. We do that by creating and supporting resources, tooling and facilitating community events for stakers. The takeaway from this talk is that solo stakers are mostly a fallback.
03:20:52.686 - 03:21:41.594, Speaker A: I'm glad that Sriram already mentioned it in his talk. It's a small percentage of the validator set, but it is a critical line of defense. And they sort of set a standard of behavior. They act as auditors, and if there's some sort of amount of censorship going on that's degrading the value or the quality of the network, they don't need to go through some sort of governance process because this is a permissionless network. So they just need to participate in a censorless way. So why is a large entity more likely to censor? So a large entity has customers that it has obligations to, and it has a duty to maximize staking rewards, which means that it's going to be connecting to mev, boost or mevboost. And at that point, censorship is really in the hands of builders and relays.
03:21:41.594 - 03:22:21.890, Speaker A: And builders and relays are known entities with a limited landscape, so they're relatively easy to target for any entity that has an interest in censoring certain transactions. So how is a solo staker different? They're generally not subject to the same pressures as each other. And as large entities they're abundant. So this is almost like a meaninglessly large number. But the last number that I saw was that solo stakers actually represent 35% to 75% of nodes on the network, whereas they're only 6.5 Ish percent. Those are both numbers from rated network.
03:22:21.890 - 03:22:57.630, Speaker A: So they're actually a large amount of people. Whereas when you go to a large staking operation, it's usually like two, three, four people who understand the system and making decisions for that system. They can be geographically located anywhere. They're under different ISPs, they're running different hardware and software because they don't have to have commercial setups, which often look very similar to each other. They're not a commercial business. So you can't target them with the same pressures that you would use to target any sort of business in general. It's a lot of work and very little reward to target solo stakers.
03:22:57.630 - 03:23:50.878, Speaker A: And quick note the way that solo stakers, censor or not censor, is solo stakers can build local blocks. Any staker, any validator, can build local blocks. And when they're building local blocks, they're not censoring because they get it blind. And then if they choose to use mevboost to maximize their rewards, it's just in the hands of the builders and the builders of the relays, whether they're censoring. But there's also a flag that they can enable on mevboost, which is the Min Bid flag, which allows them to set a target for if the block coming in is higher than that with mevboost, they'll take that. But if it's lower than that, they'll just build locally. So who are solo stakers? We're going to give like a little profile of solo stakers to sort of give you an idea of why they're so important and how people can support them.
03:23:50.878 - 03:24:36.262, Speaker A: So these are two screenshots from East Acres YouTube channel. And the first screenshot is our live streams. And you can see that the first or three or four of those are just network upgrades and they're highly attended and it's just people interested in watching network upgrades happen. And the second one is our pre recorded uploaded videos. And the first one is how to shop for Ethereum hardware so that's people who are interested in becoming validators. And the next three are sort of targeting people who are already running nodes. And so from both of these things that you can see that validators, solo stakers are generally a highly engaged subset of people and they range from less technical to more technical.
03:24:36.262 - 03:25:31.822, Speaker A: Less technical folks are the ones who are following the guides and the more technical folks are the ones who are writing the guides. The more technical folks who are writing the guides are generally really proud of what they're doing and this is their hobby and they're happy to be engaged. So they come back to the staking community and sort of help people troubleshoot, help people get on board. And I'm all the way on that less technical side and I like to think that I'm uniquely positioned there to sort of bring people onto this scale because if I can run a validator, anyone can. So they understand how to update, upgrade and troubleshoot their nodes and they're highly engaged in the network. Solo stakers often fundamentally care about the network and I'm going to prove that to you over a few slides. So liquid staking token holders and staking as a service provider, customers require less understanding about the network as a whole because they generally just have to go to a UI and deposit their money there.
03:25:31.822 - 03:26:29.510, Speaker A: And so they don't necessarily have to have a fundamental understanding of staking to be able to participate in the consensus layer. And so their interests generally lie in maximizing rewards. And when you have a bunch of customers who are just interested in maximizing rewards, that can often aggregately influence the operators who are running their stake. I think a lot of you already know about client diversity, but generally we want lots of clients on the Ethereum network because if one of them goes down, we don't want that affecting the network as a whole or affecting the value of the network. So in 2021 there was a social layer campaign to increase client diversity and run minority clients. And that was generally a bottom up sorry campaign. And I would say that it was very successful.
03:26:29.510 - 03:27:15.800, Speaker A: The supermajority of validators went from running Prism to having a pretty balanced consensus layer landscape. So this is data from the execution layer clients and data from the execution layer clients is generally harder to get at and the reasons for that are outside of the scope. This talk. But this data is from Ethernodes.org. The Beacon Chain guys. People associated with Beacon Chain put this together and the way that this data is collected is it connects to a node with an empty peer slot and then it sort of gathers data about what execution layer client it's running and then it disconnects. And in that time it doesn't actually get any information about how many validators that node is running.
03:27:15.800 - 03:28:20.570, Speaker A: So this is more of an overview of the node execution layer client landscape, but what we care about is the validator client landscape. So the same guys, the Beacon Chain guys did another data set where they basically reached out to a bunch of pools and asked them what clients they're running. And this is survey data. I think it covered like, I want to say, 40% to 50% of the network. And then Hani Abu from clientdiversity.org extrapolated this to the rest of the network and came up with this data, which looks a lot different than the data on the left and it's a lot more concerning over here. So given the fact that solo stakers homestakers map to a very large percentage of the network in terms of nodes, but a very small percentage of the network in terms of validators, I would say that the left one overrepresents solo stakers and the right one overrepresents large staking pools and large staking operations.
03:28:20.570 - 03:29:26.382, Speaker A: So this is just evidence for the fact that solo stakers are generally a lot more responsible in making sure that they're supporting the health and decentralization of the network. When you spin up a validator on rocket pool, what it does is it sort of randomly chooses your clients and it automatically sets it in the graffiti what clients you're using. So it's a lot easier to measure and they also do pushes in their community to run minority clients. And so just from this you can see the rocket pool validators who I think like 70% of them are running from home, 30% are on all nodes. They're mostly running lighthouse TECHis and lighthouse TechU and Nimbus, whereas the overall validator set is running Prism and lighthouse. And so that shows that people who are running from home are more engaged, know what they're doing, they take action on network health. And this is just the top four reddit posts from Estaker in the past year.
03:29:26.382 - 03:30:00.246, Speaker A: Two of them are about liquid staking provider centralization concerns. One of them is about execution layer client campaign. And then the fourth one is a technical guide. And so this is what solo stakers, the solo staking community, is upvoting and engaging with. They're sort of values based. So solo stakers are concentrated in developed nations, which is not ideal. More than 50% of them can be found in the US, germany and the UK.
03:30:00.246 - 03:31:01.440, Speaker A: And I hope that I'm not exaggerating when I say that I think that East Acre has had an outside influence, an outsized influence on who is staking and the resources that they're using to stake. And so East Acre has a knowledge base and up until this year it's only been available in English, but there has been a push this year to make it available in more languages and so it's now available in Spanish, Dutch, French, Malay, Portuguese and Turkish. And some of those are in progress and need more help. So we're attempting to help validate our geographic diversity. One of the last points I'll make is that solo stakers are really risk averse and they're careful. Diva Liquid Staking Protocol recently did a token launch and they did an AirDrop where they favored solo stakers. And a lot of them didn't claim it because they said, I would rather turn down free money than claim something with an address that I'm using to stake and I didn't have to go very far.
03:31:01.440 - 03:31:46.150, Speaker A: Both of these posts, one from Discord, one from the subreddit, are from people who are wondering should they censor certain transactions? They're located in places where they're worried about running a validator if they should be censoring or not. And so they need a little bit more clarity and need to know that they're not on the hook for these kinds of things because they do want to comply any way they can. They're just nerds running computers that generate rewards. They're not like rule breakers or crazy people. So just an overview. Solo stakers understand the fundamental nature of staking. They're engaged, they pay attention to what's going on on the network, they place a high value on network health and decentralization.
03:31:46.150 - 03:32:43.930, Speaker A: They're careful, they need some clarity, and they're motivated mostly by stable income and security in their investment. Overall, the takeaway is going to be a bit muddled. I don't think solo stakers necessarily have an impact on day to day operations on sensor surprise resistant because a lot of them are connected to mev boost. At this point, I think 95% of the network is connected to mevboost, and I would guess that that 5% is disproportionately made up of solo stakers because large business operations do have an obligation to their customers to maximize rewards. And so solo stakers sort of act as a critical social layer. Feedback fallback, and they're standard bearers, and they can act as auditors of the network. And so when it's business as usual, censorship resistance is basically in the hands of builders and relays, but in critical situations, they sort of act as the Night's Watch from Game of Thrones.
03:32:43.930 - 03:33:27.182, Speaker A: If everything is going on, you're not paying attention to the fact that they exist. They're just doing what they do. But when the White Walkers comes out, they are a critical line of defense. So how do we ensure that solo stakers continue to participate? More resources, more education, more support, and all of the above in more languages? We solidify validators as neutral parties without a burden or ability to censor. We lower the cost of altruism in local block building. So that can be things like mev, Byrne, or the Min bid flag. Tweets my friend Lottie SLAuS from the East Acre community recently mentioned to me that he wished that the Min bid flag that the value you set there would be relative to market conditions rather than absolute things like that.
03:33:27.182 - 03:34:51.230, Speaker A: So what can solo stakers do? Build your local blocks or turn on your mid bid flag. And that is it. It looks like we're doing quite well on time, so I think Sebastian, you can actually go ahead. I want to ask the audience, now that we're doing good on time, would you like some IRL QA? In addition to furiously typing in a side chat, which I have a lot of respect for, one who has been sitting here for the past 3 hours typing furiously in a side chat, raise your hand if you want to do live QA for this talk and all the ones that follows. All right? Okay. We'll have a sizable minority. All right.
03:34:51.230 - 03:35:29.848, Speaker A: Thanks for having me up here kind of last minute joiner. My name is Sebastian. I'm founder of Hopper and work on privacy. And since for me, privacy and, yeah, censorship are deeply interlinked, I'm very happy to talk something about something that I'm kind of passionate. So, first of all, I would like some stats here. Who has been using any EVM chain in the last 30 days? Okay, that was a mandatory arm stretching exercise. Now, how many of those people have been using exclusively their own nodes when interfacing those EVM chains? Okay.
03:35:29.848 - 03:36:04.470, Speaker A: No RPC providers in the room. Good. Now, as you do that right? So as you rely on other people's computers to interface any EVM chain, who do you like? As it turns out, all of you actually trust. And there's a narrative which is not new, is it? Maybe this company I want to be very clear that this is not meant disrespectfully. I'm very grateful that there's somebody who runs infrastructure that we all are too lazy to run ourselves. But maybe you don't trust that company. In fact, actually, you trust that company.
03:36:04.470 - 03:36:46.320, Speaker A: Or that guy. Or that guy. Well, what does trust even mean, right? So trust in this context of like, we trust in fuhrer it's all evil. What does that even really mean? So, firstly, it means trust not to censor you. And how do we get that trust? Well, luckily it's not that bad, right? Luckily it's not that bad because all of Ethereum, most of it anyway, relies on free and open source software. So I can inspect that code, modify that code and run that code myself. That's kind of cool.
03:36:46.320 - 03:37:23.228, Speaker A: But actually it also requires standardization. So I'm kind of grateful that we have this whole EIP process and people standardizing things because it means switching costs are low. And thirdly, and we heard about it a few times already, retail hardware requirements are pretty important because it's not just one of the very experienced gentlemen that I showed before, but every one of us on their dub node at home who can run a node. That's cool. Now, secondly, is trust to deliver correct data. And that of course makes sense. And the obvious solution is, again, run your node from home.
03:37:23.228 - 03:38:09.740, Speaker A: But as we've seen that all of us are too lazy to do that. And if we didn't change that in the first eight years, maybe we're not going to change it in the next eight years. There, luckily, is a solution and that is light client verification again mentioned. But I would say here in this room, can we please start using that? Also a shout out Vitalik mentioned before, helios from a 16 Z crypto. I know it's great that these big VCs push that forward, but there's another one called Keffler Sh yeah. Run by Schresched and a bunch of his friends, which is very cool and yeah, very efficient. Now, finally, and that's the part of my talk that I would like to dive deeper in, is trust to not track your every move that you take on the web three.
03:38:09.740 - 03:39:09.680, Speaker A: And as it turns out, that is pretty broken today. And I'll go through what that means in a more broken down fashion. But basically, strong full stack privacy is a necessity because how much does it help you that nobody can technically censor you on accessing the nodes, nobody can deliver you fake data when they step one step behind you and observe over your shoulder everything that you do? Yeah. So specifically, let's look at it from kind of a layer stack approach, right? So let's start with the application layer. So we'll look briefly at tracking and other web two Ugliness later on. So I think we have to subscribe to some values and agree that user tracking is evil because if we don't agree on that, a lot of the other stuff it just all breaks down. It doesn't help you if we have perfect consensus and execution layer privacy, if then on the application layer we track the hell out of users.
03:39:09.680 - 03:40:11.940, Speaker A: But that being said, there's of course problems on the execution layer, right? So on chain privacy is needed. Again, we have a bunch of these things going on. Yeah but again let's please use them. And then interestingly, we have P to P level leaks and this is not just on the peer to peer layer of the execution layer itself, but also kind of the auxiliary tech around it, right? Solvers builders indexers, that's all infrastructure that is leaking information that can be tracked of individual users and finally of course consensus layer. Yeah, validators are not private and unfortunately, I know there's great movements made to a single secret leader election but that does not really fix privacy concerns. Cool. So luckily we're not alone, right? We have the old world which we try to decouple from that protects our privacy and I think it's fair at least for half a second to acknowledge that.
03:40:11.940 - 03:41:38.188, Speaker A: So we have things in us Europeans that have something called GDPR, there's those Californians that have CCPA but it's not just state actors, it's also corporations which kind of self subscribe to privacy policies, sometimes better, sometimes worse. Yeah, lots of room for improvement there. But as this old world admittedly, I brought up these names of this organization and the people running them, right? And my point is you can enforce privacy privacy regulations because there are identifiable individuals and corporate players which act in a space. Now what do we do? We decentralize all the things right? Now what does that mean? Right? That means we remove these trust guarantees that are provided by laws and regulations of countries, states and private for profit corporations. We're replacing them by trusting all rundos on the internet to not data harvest everything they can about me, to not use it against me in the worst possible way. That is not great. Yeah, so that is not great and my point being here is yolo decentralization without regards for privacy is a problem and in fact it makes the trust assumption with regards to privacy much worse than a centralized world that all of you get away with today.
03:41:38.188 - 03:42:46.084, Speaker A: And yeah, I would like to dissect that one a little bit more to drive that point home and then think about what we can do to fix that. So connecting to a nonprivate execution layer again allows some rendals on the internet which run that infrastructure to link all your ethereum accounts, right? People here have a POAP well cool, because there's infrastructure providers maybe at some point very decentralized ones to which you have no trust assumptions whatsoever which can link that Poop account, your ENS account to your savings account. That's broken. There's infrastructure providers which will be able to link that to off chain identities. So I find it actually totally fair that GDPR in Europe considers the IP address personalized information because you can totally link that to an email if you have a single form where you subscribe, for example, with any of the providers that you all use. And finally, and that's something I know, there's a bunch of mev folks in the room that I find very interesting. These providers see everything that you see in a truly decentralized world without before you see it.
03:42:46.084 - 03:43:20.800, Speaker A: Right, that's pretty interesting. Now it all boils down to me again. I work on the transport side. I work on a P to P side. Your IP address. Even if we were to go forward and think about perfect on chain privacy, your IP address is going to be your primary Identifier on the web three for all of this above, which is something that yeah, I'm happy that Juan and Vitalik acknowledged that before, but I think we have to talk more about the specifics and solution space here. Cool.
03:43:20.800 - 03:43:57.164, Speaker A: So how exactly can you then screw users on a web three that is kind of yolo decentralized and having not many regards for privacy, I'll walk you through an example, a fully decentralized app uniswap ETH. Okay, so I guess most people here interacted with ETH domains. What's the tech stack for this hypothetical example that again I hope for, right? I hope we do get to a fully decentralized world. I just think there's some problems. So how does the text deck for that look like? So it's ENS, obviously, right. That resolves to IPFS. And once you load the page, there's the graph delivering data.
03:43:57.164 - 03:44:29.332, Speaker A: And then you use decentralized RPC providers such as, for example, pocket to serve requests. Now, what happens? First, our malicious actor is going to run a bunch of IPFS nodes. In fact, you don't even need to run the full IPFS nodes. You just need to get exposure to the DHT and you are identifying active users by harvesting their queries. You're saying, okay, Sebastian, congrats, you learned that I'm accessing app uniswap ETH. What do you get from that? Well, I prepare for my next step. I know that you are coming online and I want to target you.
03:44:29.332 - 03:45:03.984, Speaker A: So I am firing up a bunch of graph nodes. Not and that's know, a lot of people give attention not to feed you malicious information. That's not the goal here. The goal is just to de anonymize you and harvest data about you. And this is pretty bad, right? Because again, on this uniswap interface, you click that drop down like Vitalik showed you and people correctly identified as uniswap. You click on these drop downs, all of these drop downs load data. So there's somebody feeding you that data in a properly decentralized world who knows every button you click, even without tracking before you see it.
03:45:03.984 - 03:45:52.876, Speaker A: You don't need to be a super powerful AI to figure out what's going to happen. And finally, of course, you can frontrun the mempool. One thing that I find fun, and just wanted to mention, it's not just the transactions that you can harvest if you've accessed an RPC provider, but also benign looking things like ETH estimate gas. Right? So if I know that some guy might be very reliably sending transactions, I don't have to wait for the transaction to pop up in the mem pool. I can just look at the ETH estimate gas because I know the lady is going to click on the confirm button anyway before she sends it out. So, yeah, that is something which you can totally use to front run the mempool in a truly yolo decentralized web three. Finally, again, this is not meant in any disrespectful fashion.
03:45:52.876 - 03:46:41.120, Speaker A: I know that all Dimensioned projects are aware of these issues and are working towards solutions. But this is an example for what we need to consider as we decentralize all the things. So what about consensus layer privacy? Just a brief summary of an experiment that we run. We've been running a modified version of a Lighthouse node. Again, our code is freely available here that did nothing else but collect all Attestation data and linking pub keys to the IP addresses. And we've managed to correctly identify after a couple of days, all Hopper team members which run validator nodes on the nosis beacon chain. So, yeah, I mean, that is a problem.
03:46:41.120 - 03:47:30.656, Speaker A: And that is obviously a problem because you can take out a node if you have correctly identified them. So I get this a lot, right? Sebastian? Is this really going to happen? So A, is privacy really a problem? And is anyone ever going to exploit that? So let me just quickly answer both these sub questions. Firstly, this is today's sad state of ethereum privacy. And to be clear, yes, I do want to call out Uniswap here. Yes, I do want you to look at the network tab when you interface DApps, right? Small d so this is happening when you interface uniswap. And the interesting thing is this is not on app Uniswap.org. This is the IPFS deployment, okay? In the IPFS deployment, they're logging stuff such as my wallet address.
03:47:30.656 - 03:48:01.480, Speaker A: They're linking it to a unique thing called Device ID. Well, where would that be used? Oh, it's used to link all my different requests that are being made. You see what I was attempting to swap there, when exactly you see every single freaking button click in there. Like you even know the exact version of MetaMask that I'm using. So if there's a zero day in MetaMask, well, congrats. There's a bunch of DevOps guys which have full access to all my vulnerabilities. Please, let's not be like uniswap.
03:48:01.480 - 03:48:44.520, Speaker A: So the second one is and Tony, right after me is going to go much more in detail of the very sophisticated analysis that's happening there in. The mev landscape. But to me, what is going on there? This is a data harvesting MVP on Ethereum, right? We see that this is basically a billion dollar game and it's happening. So the question is, to me this is just data harvesting mempool data. This is again the tip of the iceberg, which is a very small subset of the data that you could have access to in a fully decentralized fashion. And it's already a billion dollar game. Now there's something we have to do about that to not let that game just grow in an entirely unbounded fashion.
03:48:44.520 - 03:49:31.380, Speaker A: And you might ask the last question. Well, okay, but are people really going to exploit that? We know who our most wanted next Ethereum users are. We want the institutions, right? Don't we want the institutions? Well, look at what the institutions do and think about the cute mempool that we are harvesting today. Isn't that very cute compared to hedge funds that are literally harvesting data of millions of people? Like harvesting data of a freaking space. Yeah. So you think that transport layer information is a tinfoil head future? No, I don't think so. I think it's inevitable we will have actors on Ethereum that will harvest all data that is available and decentralizing things makes that way easier for those actors.
03:49:31.380 - 03:49:58.140, Speaker A: Cool. So again, that was kind of my conclusion. Strong privacy. Tag is our primary insurance provider to prevent exploitation of every single web three user. And actually we are kind of aligned there. It doesn't matter if you're talking about the individual or if you want to protect these trillion dollar hedge funds from one another. We are aligned that we need privacy to make Ethereum a safe space to interact.
03:49:58.140 - 03:50:28.984, Speaker A: And just to wrap up, I initially showed kind of some of the issues we had on the application layer, like tracking, right? So we have to defend the core values. I know Ethereum are nice people and that's something I personally really value and appreciate. But still we have to call out the actors which are not aligned with our values. So I take that. Start here today execution layer on chain privacy, right? That's cool. But use them, integrate them. And more importantly, we need support on the legal front.
03:50:28.984 - 03:50:55.392, Speaker A: I know most of us are tech people. We don't like to talk to lawyers, but I know at least two projects on that list that came to me and said, hey Sebastian, what should we do? My team is afraid to work on privacy. This is an issue. Right? We need to provide guarantees for the developers of our magic technology that they are safe to build what they're doing. Finally p to P leaks. Yeah. Solvers, builders, indexers and so on.
03:50:55.392 - 03:51:21.112, Speaker A: mixnets are great. I'm not going to show what we're working on. I'm just going to say Hopper is a mixnet. We use that and we specifically use that as middleware on the RPC layer. I think middleware is an underappreciated building block. So I just also wanted to give a shout out. We heard, I think, also vitalik say before, how do we deal with forced inclusion? Well, I would say forced inclusion is, again, something that shouldn't happen through a user front end.
03:51:21.112 - 03:52:00.800, Speaker A: This is something that should happen through an RPC wrapper, and I hope somebody works on that because I want to use something that's truly censorship resistant. And finally, consensus layers, yes, validators are not private, and SLI doesn't fix that, but strong privacy tech does. On the flip side, I know latency issues are hard, so that's the reason why we focused first on the RPC middleware stack, working on RPC over hopper, and if anybody wants to support that or use that, please come to me afterwards. And with that, thank you so much. And thank you for jointly upholding the values of Ethereum in a bear market. That's easier. Please uphold the values when a bull market is coming around.
03:52:00.800 - 03:52:35.544, Speaker A: Thank you so much. All right, let's take up to three questions. Sure. Anyone getting grilled? Great. That's someone in the back in a yellow shirt. Hi, Sebastian. Here Miko from Web three.
03:52:35.544 - 03:53:19.924, Speaker A: Privacy now, it's an existing question, like how privacy Projects People Association could stop fighting each other and collaborate, share experience, help each other to build much more good ethics and knowledge and tooling instead of just doing these fuds on Twitter. Yeah, great question. I think, again, in the Ethereum space, we have a lot of collaboration. I embrace working with anyone who's doing that. I would basically ask all players for civil, you know, work along with one another. I have to say, I see this a lot in DFI space. Right.
03:53:19.924 - 03:53:44.770, Speaker A: There's a lot of competitors still, people working composability. I think other layers of the stack have a lot to learn from that. But, yeah, that's maybe not an answer. Maybe I'm too much of a techie and not a sociologist. So that's also an answer. We need more diversity in the space of professionals that help us. I think there's another question there in the back.
03:53:44.770 - 03:54:42.470, Speaker A: Hello. A lot of the developers are worried about developing privacy tech because everybody can see kind of people that use their tech. So if you have a profit incentive there to keep your project running and you say, oh, well, we bounce stuff going through our product, then it makes you comfortable. So do you think it's possible to have a privacy tech with full deniability where you don't know anybody's using the privacy tech to begin with that makes you feel more secure as a developer? Yeah. Privacy by default and plausible deniability is something that we absolutely should strive for. I think the big question is how exactly do we get there? Right? And this is a question both for users and for developers. I'm, as a non American citizen and person, do advocate for the use of tornado, know tornado cash is an important privacy tool.
03:54:42.470 - 03:55:52.708, Speaker A: But yet again, some people are too scared, right? So US regulators have successfully scared people from even talking about tornado cash. That's crazy. That's literally, I think, you know, the most powerful players in the space have to step up and push back against that and have a strong voice in that because it doesn't help if young projects that are just raising their seed round, who have to answer that question to VCs anyway, are put in the spotlight for it. So that's why I hope to get more support for that from the strongest players in the space. All right, anyone else? Yeah, you've spoken a lot about driving that consensus around these principles. How do you see that? Do you have any other thoughts on how that's going to manifest, how that could manifest most optimistically in the next couple of years? Optimistically in the next couple of years? That's a very tricky one. So honestly, and this is a very controversial take, I do not see that any of the infrastructure that we're building on is ready in the next couple of years for onboarding a billion users.
03:55:52.708 - 03:57:11.770, Speaker A: I do see that there's a lot of homework that all of us have to do on decentralization resilience. That's, to me, the core goal and privacy. And, yeah, let's not rush to cut corners, let's not build, I don't know, on chain gaming just because there is some VCs chasing money in that one. Thank you very much. Since now we're still ahead of the time after Tony speaks, let's change the game up a little bit. You need to answer a question from the previous speaker. So that means whoever spoke first needs to actually pay attention.
03:57:11.770 - 03:57:53.090, Speaker A: Perfect. Yeah. Thanks everyone, for showing up. Let me quickly introduce myself. My name is Tony, I work as a researcher at the firm foundation. And today I want to dive a little deeper into the PBS stack and especially focusing on censorship within the PBS stack. Just to give you a very quick outline what I'm going to talk about, I will start with very shortly explaining what type of censorship I'm meaning when I talk about censorship.
03:57:53.090 - 03:58:37.140, Speaker A: Then we will look into the PBS stacks or relays builders validators. And finally, I want to quickly cover, in my opinion, quite interesting example, which will involve a comparison of bitcoin and ethereum. So if you ask Chet GBT, you get this very, very general definition of what censorship is. So it says like, censorship is the suppression and restriction of speech, communication, other information and so on. But of course, this is much too broad for our context. And indeed, I want to mainly focus on the beacon chain. So every type of censorship we can see on the beacon chain, which will also be part of this talk now.
03:58:37.140 - 03:59:24.370, Speaker A: So let's get into it. The first type of censorship is not proposing blocks with transactions to or from targeted entities. And with meaning transactions. I'm of course also speaking of internal transactions. So it's not only the normal transactions that I'm talking about, but more or less every call to any address that can be censored in this case. Next, a much harsher form of censorship would be not attesting to blocks with transactions that interact with a certain entity. And finally, a very harsh form of censorship would be even reorgang out certain blocks or excluding them, ignoring them if they contain a transaction of a certain entity.
03:59:24.370 - 04:00:36.570, Speaker A: And if we think about censoring, right? We also have to answer the question what is censoring? First, of course, if you don't like your neighbor, you can censor him, which would already be censorship. But in the ethereum context, when we talk about censorship, we are mainly talking about OFAC, right? But surprisingly, OFAC is actually not the only list existing, right? There are other countries that also have their enemies. And here on this slide, you can see some countries with their own sanction lists. And although we only talk about OFAC all the time, there are actually all the countries have their own lists. And the OFAC list is therefore so dominant because it was the first that really first included some bitcoin addresses, and then later on also targeted some Ethereum addresses like Tornado Cash. So for my talk, I will also mainly focus on the Ofaclist, just because the Ofaclist is the only one that has a real impact on today's ethereum landscape. To quickly tell you something about the methodology I use.
04:00:36.570 - 04:01:28.762, Speaker A: So how do I even know that a certain entity is censoring or not? Right? This is not that straightforward. But there are actually a bunch of cool ways how you can determine is a certain entity censoring or not. And one cool way is just using a binomial distribution. So we assume that the probability of a block containing a certain transaction so containing Ofakt Sanctioned Content is binomial distributed. And by doing so, we can just calculate what is the probability the likelihood of a certain entity proposing a certain number of blocks without any OFAC Sanctioned Content. P here is the probability of a block containing a certain containing OFAC Sanctioned Transactions. This means 2.18%
04:01:28.762 - 04:02:12.570, Speaker A: of all blocks since the merge contained OFAC Sanctioned Content. And now it's basically very simple. The larger the sample size, the more sure we can be that a certain entity is censoring. So for example, if you propose ten blocks, then it's not that easy to tell if you're censoring or not, right? This would not be very accurate. But if you propose 1000 blocks and there was no OFAC Sanctioned Content in your block, then we can be quite sure that you might be censoring the chain. So this just as a starter. And now we can dive into the actual censorship of the current network.
04:02:12.570 - 04:02:56.370, Speaker A: So starting with the validators, if we look at the validators, it looks actually quite good. You might say. So the graph shows you the distribution. So the share of slots and we can see around 15% of all slots as of today are produced by Censoring Validators. And now you might ask who are these Validators? Basically you can go to Tornado Pix and there you can see which entities are including tornado cash transactions and which are not. And in the first four columns you can see the number of blocks of those entities, the number of blocks with sanctioned content. And then let's focus on the last column.
04:02:56.370 - 04:04:15.230, Speaker A: It tells you the percentage of OFAC blocks of a certain entity and I want to highlight especially those entities. So let's look into them. Figment is the first entity which has a very low OFAC inclusion rate, right? So we can see around zero point 32% of all Figment blocks contain OFAC sanctioned content. If you compare it to Lido which has 1.78, it's much lower right now you might say, okay, why is it still above zero? But we will talk about that later then Kraken, right? So if you look at Kraken, it looks like they started Censoring very recently, right? So you can see also Kraken has a very low OFAC inclusion same as other validators like Celsius and some smaller ones like Staker Bitstamp, Qcoin Bitfinex, Everstake Pool Bitpy or Cryptostake.com. All of those entities have a very low inclusion of OFX sanctioned content which might point to them Censoring. Next up we have relays, right? Relays were a big topic, especially around the merge.
04:04:15.230 - 04:05:05.230, Speaker A: Homemade Boost ecosystem was launched in parallel to the merge, more or less. And it started with mainly Flashbots being the only very dominant relay. So we can see that at the beginning of the year we had almost 80% of all relayed blocks being Censored. This was just because the Flashbots relay was so dominant and almost all the blocks were relayed by flashbots. This meant that around 80% of all blocks relayed were in the end censored by those entities. Then over time we saw many other relays coming up like Ultrasound relay, Agnostic Gnosis relay, the Istos relay, also blocks, there's a blockstart relay that is non Censoring. And the situation improved quite dramatically.
04:05:05.230 - 04:05:52.734, Speaker A: If we look into the numbers, we can see the same picture that I just explained. So we can see that flashplots block native Eden, they are all sensoring, right? So they are on the very bottom of this table. On the very top you can see the non Censoring relays and something that is quite interesting. For example, let's focus on blocks. Route regulated. Blocks Route Regulated is also a sensoring relay. But you can see there was a block in the last 24 hours, right? So in the last 24 hours, of course mistakes happen and from time to time some of transactions just slip through, right? And we have all seen all these security checks at our hotel and stuff.
04:05:52.734 - 04:06:52.562, Speaker A: And you know this OFAC block might have. So it felt very similar for him, right? So it was not that sophisticated. So the check was not that sophisticated. And from time to time, even the non censoring relays relay sensored blocks or to be sensored blocks. And in order to do sensoring properly, you would really have to simulate that transaction, right? It's not enough to just check where the transaction comes from or what's the first context? Which contract is touched? First, you really have to look into the state and see does a certain transaction touch the state of a certain sanctioned entity? And only then you can be sure that I have to censor it or not. Next up, we have the builders and the builder landscape looks very, very scary. Right? At the beginning, it was quite good.
04:06:52.562 - 04:07:29.070, Speaker A: Builders were non censoring. But over time, many of the builders felt the pressure of OFAC. And now we are around 80% of censoring builders. This means even if you connect to a non sensoring relay, the probability that you get sensor blocks are extremely high and more or less as a validator, you can do nothing about that. You can connect exclusively to noncensoring relays, but it won't help you because the builders are censoring. Again, let's look at the table. And we can especially focusing on the top builders here.
04:07:29.070 - 04:08:15.920, Speaker A: So we can see our Sync builder, Beaver Build, flashboards builder 69, Gambit Labs and so on. Those are all censoring builders, right? And it's not like they were censoring since the merge, but many of them started very recently. On the other side of the spectrum, we can also see builders like payload de or Moneyfold that have a very, very large tornado cache inclusion rate. So, for example, for Moneyfold, it's almost every second block includes a tornado cash transaction. And for payload de, it's also at 28%. So we can see both sides of that. So some are censoring very good and some are really trying, probably really searching for tornado cash transactions to make sure they get included very quickly.
04:08:15.920 - 04:08:55.850, Speaker A: Finally, I want to quickly cover a topic that is quite old. Maybe to ask the audience, who has ever heard of a Feta fork? It's from Bitcoin, very old concept. Okay, one hand. Nice. Then let me explain you what a Feder fork is. Fedafork? It was first proposed in the Bitcoin Talk forum by Andrew Miller in 2013. And what a Feder fork is, it's like? How can I censor the whole network with having less than 50% of the hash rate? And how this works, it's actually quite simple.
04:08:55.850 - 04:09:40.406, Speaker A: Let's assume we have two entities, right? We have Alice and Bob. And Alice doesn't like Bob, so she will not build on top of blocks that contain a transaction of Bob. Very simple. Importantly, alice announces that publicly. So everyone knows that Alice, with her 20% hash rate, she will not build on any block that contains a transaction of Bob. This also means alice will reorg blocks out if they contain a transaction of bob. Next, we know because Alice has a hash rate of 20%, right? We know that the probability of having two consecutive slots is around 4%, right? Because of Alice controls a hash rate of 20% and 0.2
04:09:40.406 - 04:10:55.578, Speaker A: to the power of two is 0.4. So you arrive at the 4%. So now, as a miner, you might think, okay, if I propose a block that contains a transaction of bob, then there is a 4% chance that Alice will reorg me out because the 4% so she can build two blocks and then has the longest chain. So for all miners, this creates an incentive to also censor bob just to make sure that they will not be reorked by the 20% hash rate of Alice. And what about Feder forking on Ethereum, right? What happens if some big stakers announce that they want to reorg out every block that contains OFAC sanctioned content? Currently, you need five entities to get up to over 50% of the total stake. So if you have Lido Stake, Fish, Coinbase, Kraken and Figment all for example, saying that they will reorg out blocks that contain ofax sanctioned content, we are already above 30% of the stake. And this would then mean, so we assume the strongest form of censorship, they will reoccur and announce that publicly.
04:10:55.578 - 04:12:21.130, Speaker A: And the result would be that economically rational, validators would also have to censor just to make sure that they will not being reoccurred out. The cool thing is, if we compare bitcoin to Ethereum in this situation for bitcoin, you can do that with below 50% of the total hash rate for Ethereum, you need at least 51% in order to win the fork choice. Finally, this brings me to a very important topic because we have not seen such a harsh format of censorship yet, right? So there were no entities, at least as of my knowledge, that were really trying to reorg out ofex sanctioned content from the chain. But if that would happen, we would still have social slashing, right? So if that would happen, we could still, in contrast to bitcoin, counter that by social slashing those entities taking their stake away if they try to attack the chain through censorship. And this is basically all I have here. You can find some more dashboards and stuff, especially Tornado Pixel and Censorship Pix, some open source data if you want to experiment and look into the map boost stuff yourself. And yeah, you can find my contacts and I'm happy to answer any questions if there's.
04:12:21.130 - 04:13:01.108, Speaker A: All right, any questions? Hi, thank you so much for the talk. One quick question. The first one is why people only care about O five. What about the other ones you mentioned? The second one is can you explain a little bit more about the 50% for Ethereum and how does your proposal boost come into play? Right? So the first question it's very political, of course. Right. So we just saw already some cases where Ofax sanctions were enforced very harshly. Right.
04:13:01.108 - 04:13:24.876, Speaker A: When you think of the tornado cash developers, and I think the US. Is just very powerful. They're also very flexible in interpreting who is accountable, who has to obey their laws, and who not. And also the US. With the OFAC list, they were the first to really include ethereum and Bitcoin addresses. Right. So, for example, let's take the EU sanction list.
04:13:24.876 - 04:13:54.472, Speaker A: There are also some entities that are on the OFAC list, but not with their ethereum addresses. So it's very hard. Probably we all violate sanctions by proposing we violate EU sanctions by proposing blocks, but we just don't know it. Right, because we don't know their addresses. And OFAC just makes it very clear which addresses are allowed and which are not. And the second question regarding proposal boost so proposal boost is more for the timeliness. Right.
04:13:54.472 - 04:14:38.984, Speaker A: So after that slot, proposal boost doesn't give you any weight in the fork choice rule. I hope that answers it. Yeah, really good presentation. Also, two small questions. The first one you mentioned about, there are some relays on the censorship resilient. Right. But how do they prove that they don't really censor transactions from the builders? Yeah, that's a very good point, because you, as a validator, if you connect to a non censoring relay, you have no guarantees that the relay is only accepting non censored builders.
04:14:38.984 - 04:15:11.448, Speaker A: Right. So currently relays that are non censoring are just open for everyone. There is no relay that says, okay, I will reject blocks that come from a censoring party. So you as a proposer, you can more or less do nothing at the moment because there's no relay offering that service, which would be very cool. So if someone wants to spin up a relay, I would definitely connect to that. If you would say, okay, I will reject all the blocks that come from censoring entities. The second question right.
04:15:11.448 - 04:15:48.204, Speaker A: You mentioned about social slashing, right? Right. How does that work? Social slashing has never happened before. Right. And as you say, it's a very extreme measure to counter censorship. So social slashing could be done like we do an irregular state transition and just remove the stake of one entity. So this requires coordination, social coordination, which might be itself very hard to accomplish. And if we would really get to that point, you will see then it would feel like the block size war at Bitcoin.
04:15:48.204 - 04:17:07.272, Speaker A: So probably the community will split up in two camps, some being for the social slashing, some against it, and then in the end, we would have to discuss it. Do we as a community want to take such strong measures or not? Yeah, it seems like the presentation focused it seems like the presentation focused mainly on the political aspects of censorship, while the most concerning chart was the builder one. And I feel like there's not only political aspects, but also economical ones. And if you looked at the charts like the two biggest builders, like Beaver and Rsync, I feel like their incentives for censorship are actually not political, but more profit maximization. So because they do sex arbitrage, that's why they censor. And so I'm wondering, how do you see that economical aspect of censorship and if we can fix censorship also on the protocol level side, by reducing stacks, arbitrage opportunities and stuff like that. So normally, let's assume, right, all builders have access to the same transactions, but the non censoring builders in addition have access to Tornado cash transactions.
04:17:07.272 - 04:18:06.320, Speaker A: Right? So if we would pay huge sums in priority fees for these Tornado cash transactions, then we also contribute to non censoring builders getting more blocks on chain. Right? But the problem is, for Tornado cash at least, you don't need a very quick inclusion. So users don't pay much for withdrawing or depositing to Tornado cash, right? So by having a builder, including a Tornado Cash transaction doesn't give him a big edge over the other builders. And that's why it doesn't really help, for example, Titan, who is a non censoring builder, to include Tornado Cat transactions. But in general, the more transactions, the more transactions you can select from, the better your block should get. So it's not just about sex tax arbitrage and that stuff, it's really about having access to transactions. Great presentation, Tony.
04:18:06.320 - 04:19:16.156, Speaker A: Before we get to a world where we're less reliant on relays, some of the ETBs proposals that have been put forth by yourself and Mike and others, how do we incentivize more decentralization at the relay level until that time? What do you think are some of the best approaches? Yeah, this is a very good question and also very hard to answer. Of course, I would say the first steps were already taken by having some funding for the relays. I think that is very important because for a very long time, relays just relied on being altruistic and doing some good service for the whole market. When it comes to relay decentralization, flashbots did a very good job open sourcing all the software they produced. Also, Chris from Flashbots put out great documentation how to spin up your relay. And I'm sure he's also very helpful when it comes to how do I set up a relay in the end. But yeah, this is a very good question because of course, also relays have this centralizing force that builders might not want to send their bundles, their blocks to every relay because of course, it might be a security threat for them.
04:19:16.156 - 04:20:15.352, Speaker A: So, yeah, we can encourage builders to distribute their blocks better. But apart from that, I don't really have a really good answer to that. Well, it looks like our three questions rule becomes six when everyone asks. That's it. Well, there is a new game role of the speaker who speak before you needs to actually think of a hard question. Okay, so let me try to connect it to what are the issues for block builders on a privacy world? So, basically, do any of the PBS changes that might or might not come have implications from a privacy side? Yeah, that's a good question. So I don't think EPBs will have a big impact on that.
04:20:15.352 - 04:20:52.092, Speaker A: Inclusion lists would have right? Inclusion lists are already defined by Mike, and you can look at the EAP already. So inclusion lists are definitely, I would say, the answer to partly solving the problem. But especially builder censorship is a very important topic because it doesn't only affect the L one. Right. It's also, if you think of privacy focused L Two S, like Aztec, they might have difficulties getting bandwidth by just posting their Blobs on chain. Imagine there is only one builder guaranteeing L Two to get the Blobs on chain. Right.
04:20:52.092 - 04:21:19.072, Speaker A: This doesn't work, really. Right. So, I mean, Aztec is not sanctioned or something, but as we saw from the history, privacy tools might be sanctioned in the future. So I think we should prepare for that and also help privacy focused L Two S to kind of avoid these difficulties. But great question. Thank you. Wonderful.
04:21:19.072 - 04:22:29.144, Speaker A: All right. Thank you, Tony. Thank you. Up next, we will actually have a remote speaker zooming in, so whenever there she is. Hi saj Toulouse. I've previously been working on the merge at consensus with the Bezu client team, and currently I'm working at Block Native on the Observability in Web Three. We've been working for at least nine months on relay and block building operation until we suspended that.
04:22:29.144 - 04:23:21.876, Speaker A: And now we're really focused on illuminating a bit more what's happening on the Amb supply chain. So I'm going to dive into that in this talk. We'll be switching off cam and I'll see you after. Cool. So I was actually thinking of skipping a bit the first slide because I think Connie did a great job at covering the OFAC angle. Basically, my point here is when we talk about censorship, we often focus on OFAC compliancy, and for good reason. This was a big issue last year, especially since we had some centralization going on at the relay layer, with one relay flashboard being the dominant one, and also at that point OFAC compliance, which meant that basically it was enforcing the compliance at the whole Ethereum network level.
04:23:21.876 - 04:24:25.720, Speaker A: I actually wrote an article about this a year ago and I was able to dig up some numbers. At that time, around 80% of the ethereum network was served by Map Boost, and 80% of all Map Boost blocks came from flashboard. Today, the situation is much better, much improved, as we can see on this chart. But also something that is interesting is that because we're able to identify this issue, monitor it, the committee was able to take action, and we've seen the emergence of new relays non censoring. Relays such as Sultry Samp is a great example of that, helping mitigate this censorship threat. We've also seen research happening in the space thanks to the data that was available and actually seeing that the impact on the inclusion rate and delay of censored transaction was actually not as bad as we anticipated. So it added a bit more nuance on our understanding on what censorship actually meant regarding OFAC for transaction inclusion.
04:24:25.720 - 04:25:27.260, Speaker A: So skipping a bit on that part and moving forward to the block building landscape, I actually took this meme from Tony. He didn't use it in his previous presentation because this is a great way to illustrate the problem that we have now. The power has shifted from validator to builder. We often discuss about how much of a problem it could be that validator can enforce their preference over block content. But today, in this PBS world that we have, it's really the builder who has all the power and is able to decide what is going to go on, chain or not. So not only that, but successful builders are now mostly vertically integrated, aka searcher builders, high frequency traders, if you will. So this position is going to allow them to profit from mev at the transaction level, but also at the full block level by leveraging any mev left behind at the end of the block.
04:25:27.260 - 04:26:32.880, Speaker A: In fact, we could even argue that mev, which consists of manipulating transaction ordering, is a form of censorship in itself. And so those integrated builders, they're very profitable and because of that, they're more likely to keep dominating the market compared to neutral builders. So here we can see that about 82% of all Ethereum blocks are being built by these three builders. And I think that speaks also to some of the question I heard at the end of Tony's talk, two of which are at least vertically integrated searcher builders, two of them are OPAC compliant. So the point of this is to show that when you have this level of centralization censorship, pressure can definitely come from within and we should watch for it. It's not always about the regulatory environment and this is where the prechain layer plays an important role as it helps us reveal what actors are doing and if there is any kind of manipulation going on. It may be that actors of the supply chain have some incentive to ignore a transaction or delay it to get a better outcome for themselves.
04:26:32.880 - 04:27:39.556, Speaker A: It's actually hard to say. Currently there is no way to enforce good behavior and the social recourse is limited by the lack of observability and the complexity of the strategies that are being implemented. Basically, if someone is censoring, either intentionally or accidentally, what can you do about it, especially if you're not even aware of it? So this brings me to the point of the need of observability on Ethereum. And just one thing worth noting. When I say the supply chain is almost equivalent, at least in my mind to saying Ethereum at this point because around 93% of all blocks are metus block at that point. So, looking at very interesting phenomenon the rise of private transaction on ethereum. It's also interesting to see that private transaction has been more and more popular, but ofas are also gaining in popularity thanks to interesting capabilities such as refunds which redistributes part of the value to the transaction originator, but also thanks to the privacy property they can offer via the introduction of hints.
04:27:39.556 - 04:28:54.050, Speaker A: Aka programmably private order Flow, which was introduced by MapShare. But some of the Ofa or private RPC endpoint users are not getting the financial value they should receive. For example, when they use the refund parameters, they're not seeing their intents being respected. For example, when I transact, I expect my transaction to be settled as fast as possible or I can also expect that I'll get the best outcome I can possibly get. Some guarantees that are staying in writings are not always respected and sometimes important information can be left out from public documentation. And so the question is who is watching out for these things? And if no one, should we accept the status quo? So looking at the OFS supply chain, which is a variation of the traditional med supply chain, the difference we can see here is that the transaction gets to the Ofa nodes to be auctioned off to searchers instead of lending directly in the block builder private MEMP pool. And in pink here you can see the actors that you have to trust today and where we should get much more observability on, especially the Ofa block builder interaction which are probably the ones where we know and are able to observe the least.
04:28:54.050 - 04:30:03.780, Speaker A: If you don't have observability, then you need trust and that's something we should not accept from a system design perspective. To give a practical example of why this matters, I'm going to give you an overview of a case study that my colleague Blair Marshall worked on this week was actually able to present some results at this event during DevConnect. So just to give you a bit of context on how we came about this, we have Transaction Boost, an aggregator that is helping users to send their transaction privately to several RPC endpoints by only having to configure one. The goal originally was to provide an increased customization but also observability through a status API. So I've added a screenshot here to show you exactly what the transaction originator is able to see when they use this service. So a user reached out to us. Turns out they were sending over 5000 plus transactions via Transaction Boost only configured nefshare as a recipient endpoint.
04:30:03.780 - 04:32:00.908, Speaker A: But his transaction were lending in the blocks of the top five builders and he received refunds around 60 only across four out of the five builders, which seemed pretty OD, especially since the fifth builder wasn't producing any rewards, but still was winning 20% of its blocks with the user's transaction in it. So at that point, Blair decided to use the Hintsight library provided to the community by flashboard and he was able to identify 19 transactions that could have received a refund but did not. Instead, the block builder's background boat claimed the opportunity. So the user could have received potentially two ETH of refunds, but he never actually knew about this until this analysis was done and he never would have. So this raised the question, is there an information advantage here if you're a vertically integrated searcher, aka a builder searcher on MapShare compared to just the searcher, since the builder get the full transaction at the same time that searchers participating in the OSA get the transaction that is lacking some information for privacy sake? So how much is the block background in both of that builder taking advantage of its position as an integrated builder? That was one question and at that point in the conversation I was kind of looking at everything like this. But then the plot ticket, our immediate next stop was is this censorship, whether accidental or intentional on the builder side? Well, we can't answer this. We nor our users have a way of knowing if the builder actually received the bundles from MapShare.
04:32:00.908 - 04:32:53.970, Speaker A: Was MapShare able to generate those refund bundles and why did the builder not receive them? And if he did, did he decide to ignore them? But the short answer is we don't know why because we don't have the equivalent of a relayed data API for ofn builders. We have no idea who received what and when. At least we are able here to provide some clarity to the user and discuss it with all parties involved, which hopefully is the first step in the right direction. If you want to read more about this case study and the methodology behind it, you can check the thread from Blair and we're going to post a blog post shortly with more details in it. Actually, it's also going to contain some other findings that we were able to uncover this week with other types of interesting behavior. But this just goes to show how much there is to observe, to analyze and to think about in order to improve the ecosystem. We really need more people to look into this.
04:32:53.970 - 04:33:41.760, Speaker A: So I think by that point we all agree that we need more observability on the Led supply chain. But how? If you care about privacy and maintaining the trust of your users who sent you their transaction or their bundles, you quickly see that it's not a straightforward problem to solve. On the other hand, allowing users to get wrecked for their own protection doesn't make much sense either. So another factor here is the complexity. Observing mempool is hard because they're fragmented, globally distributed and constantly changing. So compiling accurate and complete data and making sense of what sophisticated actors are doing is really hard. We know that on chain and pre chain data allows us to track vertical integration spot interesting behavior.
04:33:41.760 - 04:34:30.770, Speaker A: It's not just about what happened on the Blockchain, it's also why. And the less observability we have, the more we rely on trust and struggle to identify suspicious behavior going on, whether accidental or intentional. If we don't fix the observability issue, we are less likely to build the market that people will want to transact in, which is a net loss for the whole community. It is also important that while we're building these games, we do not lose track of the original mission, which is to create something better, more transparent and more inclusive than Trad Five. The reality is that today some people are able to leverage programmatically information they receive to extract value before others even have the chance to look at it. If ever we can't rely on trust, we need safeguards and monitoring. The need for more observability couldn't be more clear.
04:34:30.770 - 04:35:19.264, Speaker A: So at Block Native, we decided to take a holistic approach to try and solve this issue. And we've built an observability platform that we for now call the Transaction Explorer. Gives you the power to visualize the mempool in real time and is going to be fully open source and open to contribution from the community very soon. We believe it will give the ecosystem a new understanding and appreciation for the prechain layer and the infinite possibilities within it, such as studying mev flow, censorship, private mempool, interaction between all these actors from the supply chain, and much more. The early feedback we've received so far has been encouraging. We're currently previewing the platform with a small cohort of users who are doing research and analysis on exactly the topics that we've been discussing today. If you're interested, you can DM me.
04:35:19.264 - 04:35:49.850, Speaker A: This was made possible by a grant from the Ethereum Foundation, and the platform will be publicly released and open source in the upcoming weeks, so stay tuned. On that note, thank you all for your attention and see you on Telegram. If you want to continue this conversation. Thank you. Bye. Is Sagina still on or she's already hopped? I'm still there. Oh, perfect.
04:35:49.850 - 04:36:55.446, Speaker A: Well, can't see you, but we can hear you. So first, any questions from the Istanbul audience? If not, if our proc audience wants to ask a question, please send them in the side chat. But first, we'll complete the game. We'll ask Tony to ask Sajita a good question. Yeah, thanks a lot for your talk. My question would be, what do you think? Which role does private order flow play when it comes to censoring? And especially as a user, how can I route my transactions? Or to whom should I root my transaction to make sure that I don't contribute to censorship? Excellent question. I would say the role it plays is that it's recreating some silos.
04:36:55.446 - 04:37:56.794, Speaker A: Like, we had this public mempool, which was open and people could see what was happening there. Now with the rise of private mempools, we're seeing a black box effect. And when you have black boxes, people are able to have all types of behavior that they want. It's very hard to observe them because you don't have access. And so this is a great field for censorship behaviors to emerge, whether they are informed by regulatory pressures or profit seeking incentives. In terms of what users could do to mitigate that, I think it is to actually send to several, if not all RPC endpoints as long as it fits the guarantees that you are looking for. Because if you are sharing the flow more broadly, you are reducing the ability of one actor to have informational advantage over others and to sort of take liberties on your transaction in a way that would not conform to your intent.
04:37:56.794 - 04:41:59.172, Speaker A: So yeah, that would be my advice. All right, I think. Prague, you're up next. So, Tim hey guys, I don't think we can hear anything. So doesn't look like they can hear us either. No, no. Front Ends why and how and just as let's say why the title now has been shortened to just Alternative Front ends, it is because we believe in Istanbul.
04:41:59.172 - 04:42:51.384, Speaker A: Okay, so I'm waiting for okay, I keep saying random things exactly as Tim suggests until we get the sound in Istanbul as well. Just ping me so when you can hear us from Istanbul. So meanwhile, I can just tell you that Prague is a lovely city. No, I'm just joking. Okay, it's gone. Okay, perfect. So, getting back to the title, so the original full title was Alternative Frontends and Decentralized Frontends Why and how? And we just shortened it to Alternative Frontends because every talk that we had until today shows that front ends should be decentralized.
04:42:51.384 - 04:43:28.836, Speaker A: So that goes without saying. So we've seen that we can deploy decentralized front ends and using if limo until the process supports properly ENS resolution, but then ENS to IPNs. To IPFS. So basically we have a way to, let's say, ensure that from a domain we are pointing to the right resource. But what's the resource? Exactly. So, talking about front ends, we take the source code, which can be pretty big, we'll get back to this. We generate, build artifacts and then we store these artifacts on IPFS.
04:43:28.836 - 04:44:54.690, Speaker A: But if we look a bit more precisely at the source code of these artifacts, which are now safely deployed on IPFS in a decentralized manner, and we look around it, we see and we find some links to here, let's say an API. And here it's normal IPFS. And if we use some tools like built with or others, we see that this is pointing to an EC two instance which basically does not fill the build enough. So when you're a project, we are writing your smart contracts, you deploy them on chain that can be properly decentralized. Of course, and there's many talks on the L one that just finished now, the front end itself, the build artifacts, you can put them on IPFS, but there's also an API which is not decentralized, at least not by default and not quite often. And I would say one more thing is the client code can be responsible for doing the RPC calls and managing the RPC calls. And even Vitalik mentioned it that the nodes themselves, the decentralization should be well thought and that includes the way these connections are written in the clients themselves.
04:44:54.690 - 04:45:49.456, Speaker A: So decentralized versus alternative. Why alternative go as well? Beyond decentralized, project can be maybe forced to shut down. Front end operators might have legal risks and teams can lose interest as well, abandon the code base. So we see from the market going from bull market to bear market and some project disappear. But the smart contracts they're still on, basically users, if it's a DeFi project, can still have liquidity that they can freely withdraw using the contracts. But if there's no more front end, for many users, it will be harder to do so. That's why the importance of having alternative front ends matters for everybody and especially for the users.
04:45:49.456 - 04:47:12.830, Speaker A: And the main question then is how can we trust these alternative front ends and how can we trust, even beyond the build artifacts, the API, knowing that for a reason of client diversity, which will definitely help us resist censorship, we probably need not a redeployment of the original front end repos. So the key issue, it's trust and how easily when we see a front end, when we know this is an alternative front end, how can we trust this as a user if it's not the original project? How do we know that this front end is safe to use? And if we look at, let's say, a simplified architecture, so we have our build artifacts, we have multiple SDKs which have been embedded in those artifacts, create an interface which connects to RPC, API, et cetera. So obviously we should trust the URL or the ENS. When properly decentralized, we should trust the API. And we've seen that most often it's centralized. And we should trust the ARPC node. And that's another thing, and which is one beefing we're going to talk right now about is we should also trust the front end implementation itself.
04:47:12.830 - 04:48:39.828, Speaker A: Because if you look at what's a front end and for instance, this is an example of one single page of uniswap and liquidity, which overall is 500 lines of JavaScript code, not counting a lot of different libraries, SDK components, hooks, et cetera. So if we include all of them, we're talking thousands of lines of code to just build an interaction. So we are including web three react here, react itself, lots of lots of components. And what's lost among those lines is the semantics of the transaction that we want to perform. What exactly are we going to compute to build the transaction and then submit that transaction. And if you look, you can go on hundreds of lines and you have bits of the semantics which are spread in this code base, some in the page of the method itself, some in some components or hooks and put together. You see tiny bits of computation, a bit of slippage here, a bit of determining whether it's native ETH or an ERC 20 token, how do we then call the estimation, et cetera, et cetera.
04:48:39.828 - 04:49:38.796, Speaker A: So the front end code is very complex and it has a lot of dependencies. And because of that, one of the main problem if we want to have alternative front ends and if we want to gain trust in those alternative front ends is it's hard to verify and it's hard to maintain as well. This code base evolves permanently and each update basically should trigger a whole new audit or a new look at. And if you multiply this by the number of projects, you have hundreds of projects, thousands of projects on chain. If you want to make sure that each of the front end that you use is safe, there's a lot of work. We thought at OK Contract about one solution that involves building a common implementation for front ends. Right now, project A has its built artifact monolith, project B, two and three as well.
04:49:38.796 - 04:50:34.540, Speaker A: And the bits of semantics are highlighted in color. They are here among a lot of boilerplate or generic code. What we should do instead is maybe build a unique engine which works for any kind of transactions and having much shorter specifications and descriptions of the transactions that we want to perform. And that will simplify considerably the way that the time we need to spend basically to look at them, to make sure that we can trust them. And as well we can also have a generic layer for UI generation and that layer will help mostly for security. So we are reducing a bit of freedom on how we can design things exactly as designers want. But since it's automated, there's less code as well to edit.
04:50:34.540 - 04:51:33.308, Speaker A: So what's this? It's trust. And the second thing is minimalism. And the way to minimally describe what transaction, what interaction we want to do is to specify it properly. And for that we will introduce really soon the open source repos of Lambdascript, which is a purely functional language that specifies a transaction kind of, let's say, low level intent or high level description of a transaction. This is, for instance, what it looks for a swap, but if you look for ad liquidity, it's about twice the size. It's still very, very short. And basically it says, okay, we're sending to the wallet that submits the transaction token a is fixed but could be left as a search box, the path, the deadline, how we compute the amount out mean, which is the parameter that the method requires.
04:51:33.308 - 04:53:08.620, Speaker A: And this definition basically we can use a compiler to generate some bytecode which describes this transaction at compile time. We can detect some errors if the transaction is not properly specified and then have a common transaction engines, we take the user inputs and build the transaction directly from clients. Because of the separation of the specification and the runtime, basically it's a much smaller amount of code for each project and each interaction that makes it easy to verify. And the single common runtime that will fully open source of course, as well can be multiple times audited and independently. For instance, now we're working with optimism and we'll probably try to audit on their side and several other people will be able to audit that common runtime. And another thing in trust is that since we have this shorter description of the interactions, anyone should be able to attest that this is a correct one. And for many people in fact, that the community cares about, like the project itself, maybe us, maybe chains or trusted members in the community, or the Ethereum Foundation, who knows, can create attestations that, okay, this interactions to add liquidity on that project is valid, the computation is valid.
04:53:08.620 - 04:54:21.156, Speaker A: So basically we can attest that this is correct. And these signatures should be stored on chain so that it's completely separate from the rest of the API nodes which provide the definition. And the last step is, as I mentioned, the automated interface generation. So UI matters for the end users. And if we only have the definition that we mentioned about the semantics, and then we have a common universal runtime and a definition to UI generator as well, which is common for all projects, then we can be sure that there are less problem with the security of the build artifacts that we can run. You all maybe remember that Badger Dow was hacked through the front end for 120 mil. What happened about two years ago was that the attackers managed to inject some code in the front end to make approvals, in fact user tokens to their own addresses.
04:54:21.156 - 04:55:28.670, Speaker A: But they were clever. In fact, people started approving tokens and they didn't do anything, they just kept the approvals and just watched the approval going. And when a whale came in and approved for 50 million, now they say, okay, it's time to collect our benefit. And they reaped every approvals that they had. So because of that, we need to really minimize the way in fact we have code in our front ends and that includes for us, no external dependencies as well. In a similar manner, KyberSwap was attacked through Google Tag Manager. And if you look at most of the project today, and this is a discussion that was mentioned a few talks ago about data collection and privacy, basically, most of the front ends right now use Google Tag Manager, and Google Tag Manager is a vector for injection attacks as well.
04:55:28.670 - 04:56:40.944, Speaker A: So if we have these two enzymes we have our program, so the short definition of the semantics that we directly compile to a UI automatically and we also have the runtime that will from the UI build the transaction and that works. So in the, let's say, testnets that we are doing right now, these are actual screenshots of different kind of interactions that we can generate. And so this is not fully customizable, but we'll have an SDK for that, which is another thing. But for these interactions it's still nice enough for the end users and we believe it's a way to reduce the complexity and so to increase the trust. So if you want to take away two things is we talked about trust and minimalism. And I think that trust minimalism is the way to properly build alternative front ends. So if we look back at the architecture, what we propose is to have this single alternative UI.
04:56:40.944 - 04:58:00.524, Speaker A: We can just take the definition, the short definition of the semantics and build a UI for that. I didn't have time today to mention how we can have decentralized API nodes as well for that, but that's definitely a way to do it. So we can deploy these static builds which can provide alternative UIs default front ends using generated UI and universal runtime and as well decentralized API nodes. So this can create, let's say, a repository of interactions where we can find interactions and alternative UIs for most of the DeFi or NFT operations or the new use cases that will come for blockchain. And what we will be able to have is the community vetting that the definitions are correct and independently, that the common runtime for this interaction is correct. So that's the conclusion of this. So if you want to contribute maybe I think we could work on an EIP to specify the transaction part and really looking to have also others contributors to that.
04:58:00.524 - 05:00:00.744, Speaker A: And if you're a project and want to ensure you have alternative front ends, we'll pretty soon release everything, but you can contact us to be in, let's say, the private betas before we publicly launch. So you have the URL where okay, contract on Twitter and we just created in fact a telegram group if you want to join it and we'll probably announce things there. Thanks. Do you have any questions? Yeah, any questions? Final question? Yeah, all you mentioned very proprietary vector attacks specifically by the injection of the Google Tech Manager and so on so forth. We were having here the web three privacy, also the meetup before the events over here. And one of the aspects which are referring to the DeFi projects is that quite many of them, I don't know due to the VCs requirements or something, they are using the Google Tech Manager and all these things to identify the user adoption and so on. This is a tremendous issue and I don't know in which extent it is being solved by the formal specification of the transaction, when actually quite often this vector is misused by replacing the two address which is then combined with the secondary attack vector attack of having the phishing smart contract which seems similar but behaves differently.
05:00:00.744 - 05:01:43.808, Speaker A: So is this the formal specification which would be attested and so on? Is this also addressing this issue that we are interacting with a different contract or that we might have the replaced only like the beneficiary address? Good question. So basically I sum it up as how can we trust that we are interacting with the right contracts basically when we specify the program. So the definition of the semantics that includes the contract. So when I mentioned that the community can be involved like the project itself signing that and attesting that, yeah, this is a genuine interaction that not only includes the values computed and submitted, but also the addresses that we're interacting with. So if someone creates a fake token that will show up in the short definition which anybody can review and most probably nobody that is trustable will vet for these kind of fake interactions. Another question, just a second part of the question was if there was the attack directing towards the Beneficiary address, so not only towards the smart contract replacement, but just replacing the Beneficiary. Yeah, okay, the Beneficiary address then it's a user input and if you see in the definition let me come back here.
05:01:43.808 - 05:03:08.040, Speaker A: Okay, so here we see that the Beneficiary is ourself and what we can do is so for now, we have an additional field in fact in the specification, which are some security rules that say that this two value is sensible and that, for instance, it should be either the wallet submitting the transaction or somehow an address which is whitelisted for that user. And this is just the beginning, but there's probably a lot that we can do in this space as well. There are some questions on the chat basically asking about how does discovery work for websites in IPFS? Is there a DHT crawler? So can you talk a bit about that? Yeah, so here in what I mentioned. So basically we'll probably want to for the alternative front end. So there's two ways to answer. First, we'll have just one main deployment of the Enjine which takes a parameter and the parameter being the Identifier of the transaction specification. So basically there's not too many in fact deployment.
05:03:08.040 - 05:04:13.230, Speaker A: There should be one single address and IPFS CID, and most probably a CID which has been audited. And if we have a development version, basically that's another deployment. But the one that we should point to once we have finished properly implemented a first revision is the audited one. And there was a second part of the question sorry, asking about DHT specifically. Yeah, so right now we don't do anything specific, but yeah, of course there's room for improvement. Cool, thanks. It no worries.
05:04:13.230 - 05:07:10.932, Speaker A: Yeah, maybe there. If your computer is very close, maybe it would be easier getting the screen configured, right. Can you hear me? Yeah. Right. So today I'm going to talk about account obstruction, but not, as usual about use cases, but to focus on censorship resistance and why it is harder with account obstruction. So, in order to understand this, we need to think what is an account? And one way to look at an account is the entity that can operate on Chain, that can operate on Chain directly without any intermediaries. An EOA satisfies this requirement.
05:07:10.932 - 05:08:11.820, Speaker A: With an EOA, an externally owned account, you can sign a transaction, you send it to a mempool and it gets included. A smart contract wallet unfortunately doesn't satisfy this requirement and you cannot use it directly on Chain. You need the help of another account of an EOA in order to operate it. And this creates a big UX problem because we are not going to be able to bring the next billion users that we like to talk about if we need them, to keep two funded accounts, one for gas, one for everything else and to sign each transaction twice. Once for the gas payment and once for the actual transaction. So what can we do? So the common approach until ERC, four, three seven was to use a centralized relayer. And chances are that if you are using a non 43 seven smart account, that you are using such a centralized relay.
05:08:11.820 - 05:09:21.200, Speaker A: The way these relays work is by sending what's called a meta transaction. Basically the user signs a transaction that cannot be used on chain directly. It sends a transaction to a relay, the relay signs the transaction with an EOA that is funded, it's owned by the relay and by the relay operator puts it on chain. Then this meta transaction gets peeled off by the smart contract wallet which handles the transaction and then reimburses the relay. Now, this approach works, but clearly it's not great for censorship resistance because it works as long as it works. But what happens if, for example, the company that runs the relay goes bust so they stop paying their Amazon bill and suddenly you're trying to transact with your account and it doesn't go through. So there may be a liveness issue or maybe the server gets attacked.
05:09:21.200 - 05:10:46.700, Speaker A: Someone attempts to denial to do a denial of service against the server at the worst possible time for you and that's exactly when it's going to happen because it's not random. Then the server operator could also extract mev because they get to delay your transactions when there is price action in order to front run you with 100% success because you cannot win a race against the server you're interacting with. So there's this issue and of course the plain old simple censorship, because the server is operated by a human and humans can be coerced, so someone might get the server to censor you at the worst possible time. Or there's just the privacy issue where the server keeps logged so it knows your IP address, which is associated with your real identity, and it sees your transactions and you don't know who they are sharing it with. So we need a better approach. Now, the naive solution would be let's have many servers, let's say run multiple servers, but that's not really decentralized because if these servers are operated by the same entity, then they are going to censor you together, they're going to go down together. So the next logical step would be let's make it a decentralized and incentivized network, which is what we did a few years ago with GSN, the gas station network.
05:10:46.700 - 05:11:27.612, Speaker A: So there's a network of relays that get paid to do the work. It's permissionless, anyone can join and you can use it to send metatransactions. However, there's a catch when using this to manage a smart account. What if the account behaves inconsistently? Maybe it's not deterministic. So when the relay sees the transaction, it looks like it's going to reimburse it and to pay it. But when you put it on chain, it actually doesn't. It detects that it is now running on chain and it doesn't pay.
05:11:27.612 - 05:12:18.744, Speaker A: So the relay can lose money and we need to mitigate this risk. So there are several mitigations that may seem possible, but each of them actually hurts censorship resistance. For example, we could keep a whitelist of known account implementations so the server only agrees to serve these accounts that it knows are not going to grief it. But then who gets to decide which account implementations are legitimate and which ones should not be served? So that's not a great approach. Another one is to whitelist users. Let's have the users open a username with a captcha or something, open a username on the server. And if a user misbehaves and doesn't pay even just once, you stop serving that user.
05:12:18.744 - 05:13:01.460, Speaker A: So that works. But it's a permission system and if you can block a user for not paying, then you can also block the user for other reasons. So we are back to the censorship problem. Or you could just try to keep a reputation for accounts don't require users, but if an account doesn't pay, then you stop serving it. That approach doesn't work because of a lack of civil resistance. Anyone can spin up any number of accounts and keep gripping the server until it's out of funds. So the server might try to be clever to simulate the transaction, make sure that it pays, and then use something like Flashbots.
05:13:01.460 - 05:13:52.360, Speaker A: Send it to the Flashbot relay and ask the relay to only include it if it pays, if it really pays the fee. So that would work until someone is determined to attack it. But when someone does want to censor it, they're going to flood it with non deterministic transactions that are going to not pay on chain. And Flashbot will spend a lot of CPU simulating it, but these transactions will never be included. After a while, Flashbots will block this relay and we are back to square one. So clearly we need a better approach. We need an approach that takes these things into account, otherwise we end up either with a vulnerable network or with one that is permissioned and cannot offer a censorship resistance.
05:13:52.360 - 05:14:52.360, Speaker A: So ERC 43 Seven aims exactly to solve this problem. It focuses on fully obstructing on fully obstructing the account without compromising on a censorship resistance. So there are no centralized components, there are no centralized component and nothing is permissioned in the system. And because it's a full account obstruction, it means that the validation is actually an EVM byte code getting executed, which opens up many attack vectors that we need to address. So what does the protocol need to achieve in order to solve this? First of all, we need it to be permissionless for bundlers. Anyone should be able to add bundlers to the mempool and these bundles should be able to offer their services, but not to do anything bad to the user operations. And we need it to be permissionless for users.
05:14:52.360 - 05:15:46.302, Speaker A: Any user should be able to propagate something into the mempool and no one should be able to censor it. We need to ensure that bundlers get compensated for the work as long as they do it correctly and that they cannot be griefed. Because if they can be griefed, then if they can be grieved, they will lose money, they will go down and we will not have a network. And we need to protect the entire network against denial of service attacks, which can be surprisingly easy to perform against such a network. Okay, so first of all, what we needed to do, how do we achieve this? The one thing we had to do first is to split the transaction to two phases. We have a validation phase and execution phase in validation. In validation you could have a separate gas limit.
05:15:46.302 - 05:16:38.514, Speaker A: So let's say you have a 5 million gas transaction that would be very expensive to simulate, but you can limit it. You can say it has a validation gas of only 200K, which means that the amount of CPU you have to spend simulating the transaction to decide whether you should include it is very limited. So the CPU impact per transaction is much lower this way. Then we need to also make sure the transaction is deterministic. If it's valid in simulation, it needs to also be valid on chain. That means that we cannot allow environment access such as block number during validation. You can use any opcode you like during execution, but certain opcodes should not be used during validation and you really don't need them.
05:16:38.514 - 05:17:27.570, Speaker A: You don't need to look at a block number to validate your signature. Otherwise you could have a transaction that you could have an account that is for example, valid during even blocks and invalid during OD blocks. So now someone could propagate a transaction to the mempool that is currently valid because the last block was an even one. But then when someone tries to include it on chain in the next block, which is odd, it's going to revert. So we prevent that by not accepting the transaction if it accesses the block number, even if it would currently be valid. So we have a list of these environment opcodes that are banned. Another problem we had to deal with is mass invalidation.
05:17:27.570 - 05:18:51.242, Speaker A: That means performing a denial of service attack against the entire network by sending a very large number of transactions that are valid. So they do get propagated, but then invalidate all of them by front running them with one transaction. That makes a state change, making them all invalid on chain. So that would keep all the nodes constantly busy doing unpaid work and unable to perform any paid work. So to prevent that, we needed to enforce certain storage rules such as the account should not during validation the account can access its own storage or storage associated with its address, such as mapping of this address in other contracts, but it cannot access anything associated with other accounts. So this means that in order to invalidate N transactions you need to write to actually write on chain to end slots, and that's extremely expensive, so this attack doesn't scale. Then we also need to make sure that if a transaction is valid alone, it is also valid on chain together with other transactions in the same bundle, because otherwise someone could produce a transaction that invalidates another transaction.
05:18:51.242 - 05:19:52.420, Speaker A: Now, we already established in the previous rule that transactions that validations cannot during validation transactions cannot access the storage associated with another account. So validations cannot invalidate each other, however, execution can. So if for example, we had a transaction that we have transaction one, which during its execution modifies a state that transaction two validation will look at and then transaction one can invalidate transaction two. So this would make it very hard to build a valid block or to build a valid bundle. To prevent that, we perform all the validations before any execution, so the validations cannot invalidate each other. And by the time any execution runs, everyone all the accounts already agreed to pay for the gas. So now if they're going to mess with each other, they could revert each other's transaction, but still they pay the gas, so the network is safe against this denial of service.
05:19:52.420 - 05:20:48.418, Speaker A: Now there are some global entities in the system such as paymasters. A global entity means that the entity could be used in the context of multiple accounts at the same time. For example, a paymaster sponsoring the transactions of multiple accounts during the same bundle. But this means that if it is allowed to access its own storage, it could keep a flag to detect that it's running in a bundle. That it gets called twice and then invalidate a bundle. Since we cannot fully prevent this attack, we had to also add an enforcement through a reputation. So if a paymaster, if such an entity causes a lot of validation, then it will get throttled by the mempool, so nodes will stop propagating and serving it.
05:20:48.418 - 05:21:46.550, Speaker A: But it wouldn't work if we don't have sibil resistance because then someone can keep deploying more and more of these entities. So introduce staking. Now, it's not classical staking in the sense that you cannot get slashed, but it has an unstaked delay, so it serves as civil resistance if you get throttled. If a paymaster gets throttled and it wants to deploy with a new address, it has to either wait for the unstaked delay in order to restake or it needs to stake an additional amount. So to sustain the attack, you need to keep staking more and more funds, which makes it not scale. So I think for the sake of time I'm going to skip some other attacks. But as you can see, we had to cover numerous attack vectors and try to reach to a minimum set of restrictions during validation to keep everything permissionless and still safe against attacks.
05:21:46.550 - 05:22:50.666, Speaker A: Right, I'm skipping a bit. Why do all the bundlers need to implement exactly the same protection? Technically you could have slightly different rules that still achieve the same level of protection. So the reason to have this as a standard where everyone enforce the same rules is related to another form of dos against the network. Because let's say if you wanted to dose this peer to peer network and remember this permissionless, you could set a node that keeps spamming other nodes, sending them a lot of invalid transactions that all use the maximum allowed validation gas and then say no, it's not valid, and then you could keep the network busy. So we need to prevent that. And the way nodes handle it is if they receive a transaction that is valid. The transactions are always propagated together with the block hash they were validated against.
05:22:50.666 - 05:24:13.762, Speaker A: And if as a node you receive a transaction, you see that it's invalid when simulated against the same state, the same block hash, it means that someone is trying to doss you because there is no legitimate reason for it not to be valid. So in that case, you treat it as a spammer and you block it. Now, what happens if we have slightly different implementations of the rules in different bundlers? What would happen is the bundler, someone would propagate a transaction that is valid for some but invalid for others. So they would treat each other as spammers, disconnect from each other, and we end up with a lot of small fragmented mempools instead of one big mempool. Is that a problem? So it is, especially if you think about censorship resistance, because each such mempool is small, it has less nodes, so the less nodes you have in the mempool, the easier it is to censor you, it becomes much more, much more centralized. We also lose the robustness of the MultiClient approach because ERC 43 Seven took the same approach as Ethereum, where we have multiple clients, we have multiple bundler implementations with different programming languages, so it's unlikely that the same bug will exist everywhere. But if each implementation has its own rules, then we are going to end up with a mempool per implementation.
05:24:13.762 - 05:25:25.100, Speaker A: So now a single software bug could take down an entire mempool and the users will not be able to propagate it. And we also lose economic security because now each mempool only has a small subset of all the available transactions, so it cannot construct the most profitable bundle, which means that there is less incentive to participate in it, so you get less participants. So to prevent this, we need to have multiple implementations of the bundler, but only compatible ones, and Ethereum needed to deal with the same problem and found solution for it because Ethereum has multiple clients, but it has very clear specs of how they should behave. And we have a lot of testing. We have a reference implementation, we have compatibility tests, we perform fuzzing to try to detect cases where it would break on census. So ERC 47 takes exactly the same approach. We have specs for the rules, we have a reference implementation, we have compatibility tests, and once the peer to peer network is up, we're going to fuss the hell out of it.
05:25:25.100 - 05:25:59.266, Speaker A: So to conclude, we see that it's really easy to design an account obstruction protocol if you don't care about account obstruction. But once you start thinking about it and going down the rabbit hole of decentralization, it becomes infinitely harder. And that's why it took us a couple of years to get it right and hopefully we did. Now, smart account developers, wallet developers generally don't care about censorship resistant. They could even use a centralized RPC. They don't care about it. They only care about user features.
05:25:59.266 - 05:26:37.090, Speaker A: And that's okay because they're a product. As a product, they're building a product. When you're building a product you care about user features, you don't think about worst case scenario that your users don't care about until it happens. So in order to get censorship resistance, they could just use an SDK that makes full use of ERC four three seven, and then they get censorship resistance for free. But this free censorship resistance actually is provided by the bundlers. So it only works if you are using a compatible bundler, which unfortunately not all bundlers at the moment are. So if you are going to run a bundler, you should pick one from the list.
05:26:37.090 - 05:27:09.258, Speaker A: There's a list that gets generated by the tests and it shows you which ones pass the test. So you should choose one that is compatible. And then soon, when the mempool, the peer to peer network comes up, it will be able to participate and get the full benefit of it. Right. And do we still have time for questions or are we done? We can do one question. There you go. Thanks for the presentation.
05:27:09.258 - 05:27:40.710, Speaker A: In one of the middle slides, you mentioned there that the validators should not be using all the Opcodes, especially those which are relevant to the environment. Right. And you specifically mentioned the block ID or block number Opcode. Right. I guess that you could also count the timestamp opcode in the environment set of the Opcodes. The timestamp is often used in approvals, right. Or in whatever which is related to the time frame.
05:27:40.710 - 05:28:09.982, Speaker A: There is quite a significant application usage of the timestamp. How would you reflect this? Right, so excellent question. We also had to think about it in the first version two years ago. We didn't. And you couldn't check the timestamp because if you could check the timestamp, then you could create non deterministic behavior. Then we realized that the validation function could return a time range. So you don't need to check the time.
05:28:09.982 - 05:29:01.490, Speaker A: Instead, the return value for the validation function says, okay, it's valid if the time range is between this and that. So now you can implement any logic you like, but instead of checking the timestamp, you return the timestamp that you expect. So now you cannot use it for non terminalistic behavior, but you can use it to implement any time based validation. Right. Thank you very much. Okay. All right, I guess we're back to Istanbul.
05:29:01.490 - 05:29:25.146, Speaker A: Next, we have the last of our chapter two speaker, Garrett, talking about alternate data transport layers. Yeah. Thanks, Tina. Hello, everybody. Yeah, and thanks also to Tim and everyone else who made it happen. Such a great conference today. Yeah.
05:29:25.146 - 05:30:33.810, Speaker A: In general, alternate data transport layers have been an interest of mine for many years now, because whether it's interfacing with Ethereum or other networks, most people don't consider the actual lower level than Ethereum of the stack, which first is the Internet and then even lower than that. But whether you're interfacing with the Internet or just Ethereum, the RPCs can censor you, ISPs can censor you. And looking at these layers of the stack is really interesting, especially if you care about censorship resistance. So looking below the level of ethereum as L zero, you can go L minus one Internet. The Internet in general is very decentralized from like a physical infrastructure perspective, super resilient to naturally caused outages and so on. But ISPs have a knack for being government regulated and can censor anybody at will like that. So it's mostly a problem of deliberate censorship rather than natural outages.
05:30:33.810 - 05:31:18.960, Speaker A: So from one perspective, it is sufficiently decentralized, but not so much on where it actually counts and the access to it. So if you look at the energy of the universe, that's sufficiently decentralized, you don't have to look about that. Electricity infrastructure is pretty good as well. You can deploy that yourself and you don't have to worry about that. So the internet is really where it starts to matter and I encourage everyone to look at whatever we're building from the entire opening up to that entire perspective. So yeah, internet is not decentralized enough. The censorship risk is just conditionally high just because it depends on your location, the government that's imposing the regulations on you and so on.
05:31:18.960 - 05:32:21.238, Speaker A: And it's also, like somebody said earlier as well, it's an economic wall as well. In many developing countries there's these kind of packages where you can buy only access to just WhatsApp, for example, for a fixed fee per month and then that is your entire internet reality. So you can't even get access to the whole internet if you just don't have enough money for it in general. So thinking about how we can solve these problems and give people anywhere in the world access, especially in places where the ISPs are super prohibitively expensive or in general, just restricting certain kinds of transactions and information flow is a complicated problem. So yeah, one potential solution to that is what we'll talk about. But first, why obvious? I think this is pretty obvious to everybody who's here. We want to make sure everybody has equal access to communications and can evolve as a part of a collective humanity together.
05:32:21.238 - 05:33:32.602, Speaker A: And it's just going to happen way better if everybody has this freedom of communication. Basically what I've been doing some research on over the past few years is radio. And you can use these radio waves to people communicate all the time just as like hobby as well as military. And there's so many use cases for really long range radio, but it's very low bandwidth. So what you can expect out of systems is very 10 Kbps or something like that, but that's plenty if you're just sending transaction data. So if you want to make sure that you have a little piece of information like I want to send a friend of mine some bitcoins or ethereum or whatever your favorite cryptocurrency is, you can just do that over radio waves. So the basic steps listed here, which we'll go over, it only requires really one non internet connected actor to transmit a message out and it to be received by one actor who is connected to the internet and then can pass that message along to whatever memory pool there is.
05:33:32.602 - 05:34:44.740, Speaker A: So yeah, first there's tons of software out there that you can use to encode data into audio, which then is super compatible with all the existing infrastructure that we have to broadcast radio signals. Most radio is in the form of audio, but this converts it into like a digital format. So yeah, there's tons of encoding algorithms, tons of open source software. This is a really good one called Fldigi that has built in error correction and tolerates a significant amount of loss depending on the encoding algorithm that you use. And then, yeah, you can just broadcast that. There's a lot of people that are known to be very bitcoiner prepper types that really are into building out self sufficient infrastructure and have camps in the woods with broadcasting stations and stuff like this. And there's one example from 2019 where people transmitted a bitcoin transaction across all of the United States completely just peer to peer directly wirelessly without going through any intermediaries that could possibly censor it.
05:34:44.740 - 05:35:53.720, Speaker A: It's pretty incredible that really long range can be achieved with very low power, with devices that you can build relatively easily. You can transmit across the entire world, you can bounce signals off of the Moon and, and back. There's a repeater on the International Space Station. There's tons of ways to get messages out even if you're living in a very difficult situation. So then, yeah, all you have to do is use some relatively inexpensive hardware like this radio costs less than $50 to receive the signal. You can attach a hefty antenna to that which you can build out of basic materials that you can find at any hardware store. And yeah, you just connect that back down to a similar software package to decode the encoded audio stream to get the transaction data out of that, then yeah, all you have to do is to decode that and the visual representations of the audio basically is just like little blips on different parts of the frequency bandwidth that you're actually using.
05:35:53.720 - 05:37:09.818, Speaker A: And it's really, really fun to look at these signals to start sending these back and forth to friends and just see how it works. But then, yeah, all you have to do after you decode the transaction data is just like any other transaction that you would normally interact with. You just send it to the mempool and it gets in the queue with all the others, just like it originated from somewhere else on the internet. So what you're effectively doing is building a proxy for people who don't have access to whatever part of the Internet they actually need, or the Internet in general to submit these transactions. So yeah, the biggest issues around this are coordinating which frequency and which encoding algorithm do we want to use. So creating a standard for that could be something that's really interesting. Yeah, this is actually a really huge issue, but figuring out some kind of standard for that, as well as potentially creating a protocol which automatically saves the data and then runs it through all potential ways of decoding it and then automatically processes data accordingly could be interesting as well.
05:37:09.818 - 05:38:15.670, Speaker A: As in a lot of jurisdictions, you're limited to a very low wattage of how much you can actually transmit and this can limit the range. But with, for example, if you're using a low frequency transmitter with about three watts of power, which is generally legal in most places, you can transmit thousands of kilometers so this is a really interesting technology for that. But yeah, so in general, the way forward is going to be a big mix. But I think as long as people keep thinking about this layer of the stack and working in that direction, it's looking bright. But yeah. So in addition to just being a dumb transmitter of data and not being sure whether anybody's out there receiving it a thing that requires a bit more infrastructure, because you have to also be able to receive a signal. Again and the receiver has to be able to send but that's implementation of Acknowledgment receipts so that at least you know that your transmission has been received and transmitted to the blockchain.
05:38:15.670 - 05:38:58.446, Speaker A: That would be an obvious thing. And then once you have bi directional communication set up, you can actually implement IP networking and then you can have multi hop networks where instead of just being point to point, you're communicating with different users through a whole thing. So you can actually run IP network on radios. It's super low bandwidth, super high latency. But when what matters is getting the data out in an otherwise censored situation, it can be super useful. Yeah. Otherwise standards, guides, I mean, a lot of the hardware that you need for this, you can find at pawn shops and hardware stores.
05:38:58.446 - 05:39:55.160, Speaker A: So just making guides and distributing those to folks who might find them useful is a project that some people like the M 17 project are kind of working on, but it's definitely not like they haven't made it easy yet. And there will also be other alternatives other than this. It's a lot more expensive, but launching our own Dow owned constellation of satellites as an alternative to starlink, things like that. So in general, if any of you folks are interested in working on this kind of thing, there's a few discussion groups that are starting as a result of this day. Some of them are focused more on the Lib PDP stack. If you're interested in working on the Internet level or below, yeah, you can hop in that group, but yeah, happy to take any questions. Thanks.
05:39:55.160 - 05:41:12.894, Speaker A: Any questions? Greg, it hi. Hey. Great talk. I'm curious, what projects do you see either currently practicing this or ways that you think that community can get engaged in capacity building around this skill set? You're talking about making guys and being able to just go to palm shops and get the hardware that you need. Are there good practice implementations of this now or are there any things that you would want to start like a hackathon or that you think would just work out as well as a workshop or something for our community to tangibly get hands on with it? Yeah, there's a huge, vibrant community of amateur radio operators all over the world that frequently speak with each other. And there's a subset of that community which does digital transmissions pretty regularly. So there is.
05:41:12.894 - 05:42:53.520, Speaker A: Already that the infrastructure and kind of coordination is like. The problem is most people operate these things either in emergency situations only or just as a hobby. But I guess the biggest thing where people can get more active is specifically building tooling around discovery of which encoding protocol is being used, automatically decoding that and archiving it on the internet or broadcasting it to the appropriate mempool, stuff like that. So I think the biggest thing that really needs to be built out still in addition to standardizing these kind of things is just some simple software packages which can automatically process things more oriented toward the crypto space instead of just hobbyists sending each other messages. But yeah, the best way to get people engaged is to just get some basic hardware, start transmitting and joining those communities that already exist and getting more people who are already a part of them, probably to spin those up. But there's already a few good examples of web based software defined radios where you can tune into a web page at many different people's volunteers houses or universities and you can choose where on the spectrum you want to listen to. You can stream that data to your computer, try decoding the different data streams that are there already, but spinning up more of those and allowing people to access the audio streams and remotely define which frequencies to tune into is probably a pretty interesting place to start.
05:42:53.520 - 05:44:08.942, Speaker A: By the way, it's been almost like a year or two since hardware has been OPTN conferences. Congratulations being the first. Yeah. Gary, thank you for your presentation. It's really inspiring and people have never thought about it maybe for example, like me. So for me the question will be have you ever think of other applications of such attempts of radio transmission? Like for example, you can use it as a payment in terms of closed range or if you are close by things like that, do you think there will be other chances of application of those kinds of tabs for payment? Can you elaborate on that? That's interesting. Yeah for example because you can just one touch and with another guy nearby and you don't even need to use mobile phone other things and then you just make a Bitcoin payment and transactions or something.
05:44:08.942 - 05:45:06.830, Speaker A: Yeah, the cool thing about Bitcoin is with UTXO you can have a significantly long off chain transaction history that you can then audit just by using transaction hash after another. For instance, in Bitcoin if replaced by fee is disabled for those transactions, then yeah, you can have strong assurances that you can have a sequence of offline transactions transmitted potentially through radio waves like this that eventually gets settled to the network. And I'm sure you can have similar solutions through different means for Ethereum and other networks too. But yeah, that's definitely an interesting application. Yeah. Are there any people actually trying to using that to actually transmit more complicated transactions like on ethereum or like other smart contract transactions, you definitely can. On average, with a system like this, you can get like 10 kbps.
05:45:06.830 - 05:45:34.714, Speaker A: So even if your transaction is a couple of hundred kilobits, I mean, only takes a little while to send. It's definitely a different experience from just clicking it and having it be instantly there, but you click transmit and then you wait like two or three minutes and then it's there. But yeah, it can totally be used for that. I mean, you can upload really large files if you want. It just takes a long time. Just like you can think of it like a dial up speed connection. Yes.
05:45:34.714 - 05:46:05.142, Speaker A: Thank you. Thank you very much. Yeah. All right, I guess that concludes. Thank you. Did I miss something? Did I miss a question? Well, next we have our next chapter, our roll ups and their different approaches. Well, more specifically, the modular stack.
05:46:05.142 - 05:47:24.850, Speaker A: So we now have nashq, and let me just open this up well for this section, given that their approaches are quite different. So I'm going to ask everyone, every speaker who speaks after the video speaker, to ask them a question. All right, let me start. Today I'm going to talk about the modular roll up world and how you can attack it in the context of censorship resistance. I will start with this slide, as I promised, I will keep a little John in the side corner every time I redefine things. I will basically use definitions that maybe not everyone will agree with, and then we can discuss it after the talk. I am a research engineer at celestial labs.
05:47:24.850 - 05:48:04.470, Speaker A: I'm a contributor to rollkit. My name is Nash. And the motivation for this talk is basically before ethereum did everything, we could rely on censorship resistance for transaction inclusion, proof verification, ordering. But now we realized, and we have specialized protocols that can do those things right. We will have DA layers that specialize in data availability. We have shared sequencers which do sequencing. We will have provermarkets right.
05:48:04.470 - 05:48:55.430, Speaker A: And using all those softwares, we now have the realization that, oh, we now inherit their censorship resistance. And how does this affect the roll up itself? And basically we'll go through some examples, some attacks, and I'll start off with how I define roll up. Roll ups are blockchains that post their transaction data to another blockchain and inherit its consensus and data availability. And roll up blocks consists of roll up data and roll up headers. The roll up data is a batch of transactions or the state difference. I will only focus on the batch of transactions. And roll up headers is metadata about the block, which at minimum includes the commitment of the transaction.
05:48:55.430 - 05:49:59.846, Speaker A: So this could be a basic roll up. A user submits a transaction to a sequencer. The sequencer batches it. The roll up full node sees the batch and has finality the roll up light node doesn't get the batch by definition. So it will need someone to produce the header with some cryptographic commitment or some guarantee and it will now trust that guarantee and it's final. And in that process we had a bunch of steps that we were able to delegate, right? We were able to delegate data availability like we already did that, but also inclusion which means what transactions are inside the block ordering means which order the transactions are. The execution is what the state route will be after I execute the state transition function and basically produce the header.
05:49:59.846 - 05:50:33.620, Speaker A: And proving is using some cryptographic primitive to confirm the validity of the metadata like ZK proofs or validity proofs, fraud proofs. So back to that basic roll up. The sequencer can do inclusion or ordering. It can be an ordered batch or an unordered batch. We could have the header producer do the execution and also probably the proving. And we have a mix and match. Right? We start off with the most basic roll up.
05:50:33.620 - 05:50:59.100, Speaker A: The most basic roll up is a base roll up. I post my transactions directly to the DA layer. Then ISF roll up full node can read from that DA layer. What that means is that the DA layer gets all the mev. I can extract it, I can reorder it, censor it, whatever I want. I'm leaking mev to the base layer. That's the most easy attack.
05:50:59.100 - 05:52:13.246, Speaker A: Now maybe I don't want to leak the mev to the base layer, maybe I want to leak it to a shared sequencer, right? But the shared sequencer can do the same thing. The shared sequencer can give you soft confirmations for faster block time. But the finality will in the end be through the DA layer and the auto batch that the roll up full node can actually read. So the shared sequencer is also incentivized to extract value and get bribes. Now, another attack is when the shared sequencer does not provide those soft commitments, right? Why we read from the DA layer is basically to force them to post it because it won't be final until we get it. And what the DA layer now can do is to collude and censor the sequencer blocks batches on the DA layer so the roller full node will not be able to get the canonical chain. It's not that the DA layer can reorder the transactions.
05:52:13.246 - 05:52:50.590, Speaker A: The transactions are already fixed but they're not posted on the DA layer yet. It's now a symmetry of knowledge between those two full nodes and a delay of finality. Okay, now imagine we have two shared sequencer schemes. One through the shared sequencer, one through the base layer. We have some kind of escape hatch. We have a frog choice rule where we say if in a DA layer block there's a shed sequencer batch and base batch. We always prioritize the shed sequencer batch.
05:52:50.590 - 05:53:38.458, Speaker A: Now we think we figured it out, we can use both. But the DA layer still has the control. Now because they can censor the shared sequencer batches and now because they're only base batches they can reorder those. And basically we are back to square one where we can trigger the fallback and extract the mev. Right? We covered sequencing now let's go to execution. So far we only had roll up full nodes which means they were only in Pessimistic mode. I need to execute all the transactions to confirm the validity.
05:53:38.458 - 05:54:31.380, Speaker A: The roll up light nodes do not execute transactions. They don't get the batches. They need some commitment. The header producer will get the transaction batch from a DA layer and be able to commit over that header and the stage route with some economic guarantee. And if the roll up full node sees that there's fraud, it can send a fraud proof to the roll up light node. Now the difference between this diagram and the diagram before is that we ignore the ordering, right? It's the same transaction batch living on the DA layer but we say hey I don't care, I'm going to reorder it again. Because why not? The centralized header producer can reorder it and then maximize it in some kind of function.
05:54:31.380 - 05:55:30.660, Speaker A: But maybe we don't want that. This header producer maximizes it for themselves. So let's try to create a competition and have permissionless header production. Now we can reorder transactions to maximize some objective function. The forktress rule, it could be the most mev extracted, the most gas burned, the most user welfare, whatever that means and the most funds transferred to the community pool. But here we have the next attack where if you have more than one header producer per roll up height then you leak mev to the DA layer again profitable censorship again where the Foxrous rule will be again highest bribe. Because the header producer can bribe the DA layer to say hey, I produced the biggest mev, I'll give you a cut, please censor the other ones.
05:55:30.660 - 05:56:33.346, Speaker A: Okay, this was the optimistic case. Let's try to do it with the ZK case. We have a ZK rollup and we now have a decentralized provo market. This provo market is basically incentivized that we can create proofs for the DA layer. The DA layer does ordering and inclusion again and the header producer does execution. This attack is where we censor proof generation and propagation. Where because the light node finality depends on the correctness of the validity proof and we can imagine an end game where an end user will run their light node, does the availability sampling, creates a, gets a validity proof and gets the whole correction, the end user will wait and basically have a delay.
05:56:33.346 - 05:57:22.882, Speaker A: It's a censorship method to delay light nodes. But light nodes are off chain at the user subjective. And I do think with good proven market incentives and because we propagated through PTP and we assume no Eclipse attack, this can be solved. The problem comes here when it's not an off chain light node, but an on chain light node. Right. If I want to have Bridging and we have to realize currently we talked about sovereign roll ups. We talked about roll up designs that didn't bridge yet, but we want to have a bridge, and a bridge equals a on chain lite client to execute.
05:57:22.882 - 05:58:19.340, Speaker A: To basically create that transaction, initialize that bridge, I have to create a transaction which includes the ZK proof. So me creating a transaction with the ZK proof will go through the whole pipeline of the second roll up or the second blockchain. And now maybe something controversial. If this roll up, imagine this is Ethereum. Did we now create a sovereign roll up that bridges to Ethereum? Is it now? An L? Two? Are those two the same thing? Maybe. Okay. And this attack basically now says that because we're dependent on the censorship resistance of the other blockchain and maybe the relayer, but he can probably get obstructed away.
05:58:19.340 - 05:59:32.782, Speaker A: We have the attacks that I previously mentioned again, but for that blockchain and controlling the funds and message unlock might give you access to mev. You could imagine that a person is trying to bridge collateral to save themselves from a liquidity. And if you are now the other blockchain, you can censor the unlock of the ZK proof to make sure that he gets liquidated and then he misses out and capture that attack. All right, optimistic, Bridging is very difficult in that sense because the censorship resistance is tightly dependent on how you generate, how you calculate the fraud proof window. If you go here and look at the bridge, depending on what kind of censorship properties there are, you need to increase or decrease the fraud proof window. And depending on which kind of stack you're using, you might have different kind of properties going through the whole pipeline. So you need to now be careful.
05:59:32.782 - 06:00:49.850, Speaker A: How do you even calculate that fraud proof window? And so far, those seven days, if I remember correctly, were just set arbitrarily. If we now have more protocols in between, it will be more difficult to set those fraud proof windows correctly. So there needs to be more research in that topic. Okay, so now let's see all of the things together in a big mesh, a user submitting to a shared sequencer, the shared sequencer publishing the ordered block to the DA layer, the header producer getting that ordered batch and basically executing it, creating a ZK proof propagating that. And then we're also going to bridge with that ZK proof. And in all of those little things, we have possible attack vectors of censorship resistance. So what is the solution here? Basically have strong censorship resistance at each layer, especially the DA layer.
06:00:49.850 - 06:02:15.794, Speaker A: It's very important to realize that because there are so many protocols now, we really have to make sure that we try to maybe mitigate some things. Right? If I enforce a shared sequencer batch and I ignore all base batches. I am mitigating the extraction of the base layer, and the only thing that the DA layer can do is delay finality. But maybe that's also bad. So we want to have very strong censorship resistance at the DA layer, and maybe you can achieve that through threshold encryption, where the proposer doesn't even know what they are putting or what's. Also very interesting an idea I think from Elijah have multiple proposers per block, where you could imagine that having multiple proposals for the DA layer can be very additive. And depending on who proposed what, you can basically split censorship resistance and have much higher guarantees to get included.
06:02:15.794 - 06:03:20.950, Speaker A: And if you have those guarantees for the DA layer, you don't have to worry about a lot of the things building on top of that. If you want to research more about this, I recommend you two talks. One is about exploring Mev capture and modular systems. It was at the Modular Summit, which is talking about multiple proposals per block. And the other talk is Profitable censorship Mev, which talks about different kind of sequencer schemes and how those sequencer schemes could extract or mitigate Mev leak. And I left some time, so I'm happy to answer some questions. Maybe we'll serve the question with the last speaker.
06:03:20.950 - 06:04:29.610, Speaker A: Hey, thanks for the talk. I got the question that super relevant to the network were building at Astec, in which we face a similar situation to networks that do compression in the sense that they remove signatures from transactions. So in that sense, what gets posted to the VA is not enough for the full roll up node to be able to verify that the chain properly. How do you see that interacting with the attacks that you mentioned today? So if you cannot fully verify the you basically should be able to verify all the data. Like run a roll up full node. If you're not only posting to the DA layer but also to ethereum mainnet, that means that you have two DA layers and one of the DA layer is Call data or Ethereum mainnet. So you have to run an ethereum full node to be able to get the same DA guarantees.
06:04:29.610 - 06:06:04.616, Speaker A: Other questions? All right. Do you think there will be a convergence on non ethereum DA layers, and are there any network effects associated with that? I do believe that roll ups who use the same DA layer benefit from interoperability. You can imagine that using the same file system you can obstruct away a bunch of things, right? For example, imagine a relayer in the Cosmos ecosystem. You have to read the transaction and post the transaction on another blockchain. But because the A layer is shared, you can now read the namespaces or the parts where the roll up posts are cross and be able to define your folktrust rule that you have to accept those bridge transactions. So in terms of interoperability there's, I think, a huge network effect of using the same DA layer. Any other questions? All right, I think we'll move on to our second of the chapter.
06:06:04.616 - 06:07:08.090, Speaker A: Thank you. It's good. Let me see if I can set up a clicker. It's fine. Okay. Testing. Hello.
06:07:08.090 - 06:07:39.600, Speaker A: Okay. Awesome. Hey, everyone. Welcome. Today we'll be talking about a little bit about Aztec network and how we're building private, state and private execution for fully programmable privacy. I'm Santiago, I'm engineer at Fasteclabs and well, today's talk will be split into three. We'll start with a very high level discussion, then we'll go very, very low level into technical details and then something in between.
06:07:39.600 - 06:08:23.760, Speaker A: So hopefully there'll be content for everyone and also no one that will enjoy the whole talk. Let's start on privacy and censorship resistance, and the link between the two, also known as how I convinced Tim Antina to get me on stage today. So, first of all, why privacy? We have said a million times that privacy is a human right. And it's not just that. It's that the whole world around us is private. Like, our users expect privacy from every application they use, where it's finance, it's banking, it's voting, gaming. It's not that if I don't need privacy, if I got nothing to hide, it's that everything is and should be private by default.
06:08:23.760 - 06:09:36.676, Speaker A: But the actual question is not why privacy? But why privacy at this event, right? And the catch is that privacy is one of the means, one of many, to guarantee censorship resistance. If I cannot discriminate something, I cannot censor it. In particular, I really liked a quote by Jordy during a panel a couple of days ago when discussing the privacy aspect of zero knowledge proofs, that CKPS are not a means of hiding, but of revealing exactly what is meant to be revealed and nothing else. That goes back to a typical example, right? If I'm opening a bank account, I shouldn't be revealing my age, my race, my gender, where I live, et cetera, should be just revealing the exact information needed. And I really like the analogy, because with smart contracts, we are used at having code that is low when it comes to execution. And with zero knowledge proofs and privacy, we're defining the rules of what exactly gets revealed for each application, and we cannot agree on that. And we cannot have a third party pop up and suddenly start censoring based on information that they shouldn't have had access to in the first place.
06:09:36.676 - 06:10:26.520, Speaker A: And the thing is that we have already been using privacy in the context of ethereum ready for some time, or at least have been discussing about it. I see that I'm the second person in a row to have a reference to John in their slides. But for instance, encrypted mempools is a way of using privacy to prevent not just toxic mev extraction, but also to prevent censorship. A sequencer that cannot see inside the transaction, cannot censor it. So hopefully I've convinced you that privacy makes sense in the context of censorship. So I can now go into what I wanted to discuss in the first click, which is how we implement this. So what is privacy for us in the context of the Aztec network? Just the only shield.
06:10:26.520 - 06:11:10.832, Speaker A: And for setting context, aztec network is a private first two that works on ethereum, that's fully programmable. That's all you need to know. So we're seeing it as private user identity, private function execution operating on private state. So for any third party observer of a transaction that happens on the network, it should be that someone has done something on some state, on some function, some contract. Basically nothing gets revealed. Want to make sure that there is zero information leaked whenever a transaction is sent while retaining full programmability. So how do we do that? We do that by moving execution from the sequencer from the nodes to the client.
06:11:10.832 - 06:12:44.720, Speaker A: So whenever a user sends a transaction in the network, what we do is we execute that transaction locally and generate a cr knowledge proof of validity for that transaction. So what that means is that every transaction that's sitting on the pool on the mempool is a co knowledge proof that proves the validity of that execution with a set of state changes that are completely opaque to a third party observer. And that's it, there is no information leaked whatsoever. How do we do that? Basically, for every function in every contract on the network, we generate a unique circuit. So when we're writing a contract in this context, each of these functions will be compiled to a unique circuit and we choose to do it that way, and not by virtue of a VM, because these functions need to be proven client side. We want each of these proofs to be generated in a browser with 1GB of Ram in a mobile device we cannot ask for half a terabyte of Ram in order to generate a proof for a user, not given that we want the user to keep privacy, but by running everything locally. So how does this look like? Basically, each function, each call within the stack generates a co knowledge proof of correct execution and that gets aggregated recursively with another circuit which we call the kernel circuit, taking terminology from Sigsi and that circuit takes care of basically gluing together the entire call stack hiding any sort of information.
06:12:44.720 - 06:13:56.744, Speaker A: The kernel circuit also is going to hide exactly which function and which contract got executed and produce a single serial knowledge proof for the entire transaction. So this means that each of these individual proofs is small enough to be run in consumer grade hardware sorry, in a mobile phone and then gets aggregated and broadcasted to the network. But if we're running private execution, client side on each user, we need a representation of state that's amenable to this kind of execution, right? Like in the AVM, we have account by state that works wonderfully because we can have multiple transactions all operating simultaneously on the same state. Here, if different users are working together, it's a bit more difficult to map that to account based storage. Not just that, we will also end up leaking information if we have subsequent updates to the same storage slot. So for private execution we use a different representation of state. We take a page out of Sika shot of Bitcoin and use a UTXO like model in which we have custom nodes representing state.
06:13:56.744 - 06:14:47.044, Speaker A: I want to highlight here custom like every smart contract, every dev can define the shape of the nodes for representing their own state. Like for a payments application or for a token, let's say a value node that just carries the value. The amount of funds in that particular note is enough, which is the shape that we're already used to. But let's say that we are building something like a card game, like a Magic the Gathering inspired one, in which we can represent, for instance, each card with a specific node that has the attributes of that particular card. Again, the notes are the representation of state and are not bound to financial applications. They are completely custom and used to represent arbitrary state. Now, these notes are stored locally by each user.
06:14:47.044 - 06:16:06.332, Speaker A: So each user has their own representation, their own private state, which is kept locally within their wallet. But we need to map those nodes, that private state, to the global blockchain state, right? This means that whenever I want to send information to another user, I create a node for that I encrypt it with a recipient's public key and broadcast it through a network so to make sure and to provably send it to them. But I also need to create a commitment to that node in what we call a global data commitments tree. In other words, if the only proof I have for using a note is that I have it locally, users could be able to create notes, create state out of thin air. So whenever a note is created, we add a commitment, a hiding commitment to it in what we call a private data tree. So whenever a user needs to generate a proof that uses this particular piece of state, they need to prove membership of that node in this merkel tree, consuming a node, basically deleting a node, render it outdated, is done by nullifying the node. Node is nullified by emitting what we call a nullifier, which is a hash of the node mixed with a secret generated by the user in a deterministic way such that the nullifier cannot be linked to the node commitment.
06:16:06.332 - 06:17:11.224, Speaker A: In other words, when we create a node, we add it to an append only tree. When we want to consume a node, we just register it was used without any observable link back to the node. This allows us to update nodes to change state without having any link between the transactions. How does this look in code? We are using Noir, which is a rust like DSL for writing circuits augmented with a framework for writing contracts and having ease interaction with private state. Here in particular we have an implementation of a very simple counter contract that keeps a counter for different users and allows incrementing them. And what's interesting is how this is implemented with nodes under the hood. So what ends up happening is that we have one node representing state, in this case one node for each counter of each user and when we want to update it, we consume the node with the old value again by emitting a nullifier and create the new one.
06:17:11.224 - 06:18:02.520, Speaker A: So basically updating state is deleting the node that represents the old state and creating a new one. And by virtue of nullifiers there is no link between the two operations. So we're effectively updating the same slot without revealing any linkage between the two. It's also worth mentioning that whenever a user needs to read a value of a node needs to create a proof by using a value of a node, we need to destroy the node and recreate it with the same value. Why? Because if execution happens in the user device, it needs to happen on an old version of state. Like the user doesn't know when their transaction will land in a block, they don't know what's the exact state that their transaction is going to operate in. That means that the only way to ensure that they have a fresh version of state is by consuming it and generating again.
06:18:02.520 - 06:19:24.640, Speaker A: If they happen to be using an old version of state they would be emitting a nullifier associated to that piece of state. It would already be in the tree and it will be registered as a double spend, which is the only other condition we have for validity for transactions. Transactions are zero knowledge proof and are valid as long as that proof is valid and there are no duplicate nullifiers. So, bottom line here is we have a state representation that allows us for each user to run functions privately, generate a proof of them and broadcast those changes in an OPAC way. However, it's worth mentioning that if every time we need to read the value, we need to invalidate it and recreate it, which implicitly invalidates all other transactions in the pool that we're referring to it, this doesn't align well with composition, right? It's known that CK snarks are maybe not the best tool when it comes to concurrent updates to the same share private state. So for instance, this model is great for implementing a private order based decks, but not so good when we want to do an AMM where we have a single shared, constantly updated piece of data such as the liquidity, the amount of. Each token in the pool that gets constantly updated.
06:19:24.640 - 06:20:25.572, Speaker A: So to address that, the network actually runs a hybrid model, private and public. What does this mean? This means that every transaction, along with a set of opaques that changes, can also emit a set of execution requests. And here we are in the land that we're familiar with. Basically the transaction asks the sequencer to run a series of public executions on their behalf. And here public functions map to an account based state similar to the one from the AVM and can concurrently operate on the same state. However, having this duplicity of both private and public state in the same chain makes it easy to run operations such as gathering and unlocking funds based on some sort of private condition, then swapping them in public state and then shielding them back into private state. The idea is that every private transaction can in queue a set of requests to be executed in public.
06:20:25.572 - 06:21:31.260, Speaker A: But how the developer manages this difference allows for this duplicity of what needs to be run in private, what needs to be run in public. What's the problem here? Even though we have made composability easier, now we're introducing a censorship vector, we're starting to reveal actions that transactions do. And with that, let's go into the third and last part of the talk, which is about decentralization. Given that we are building a network, private first, in which censorship is of the utmost importance, we want to make sure that transactions cannot be censored, cannot be stopped. And for that we are designing sequencing and proving protocols that are both fully decentralized, that are going to be decentralized from day one. The network is not going to launch without fully decentralized sequencers and provers progressive decentralization is not an option here. And we're also working on governance mechanisms that are compatible with them, that can provide security, provide upgrade paths, but guaranteeing the censorship resistance of their users.
06:21:31.260 - 06:23:01.028, Speaker A: And we are doing this decentralization in a decentralized way. We have been putting out RFPs throughout the year, asking the community to contribute with proposals for each of these areas and we'll continue doing this and we really, really encourage you to jump into the forum, link in a couple of slides and help us here. We are converging to a sequencer selection algorithm called Fernet, apparently Argentinian guy named it, which basically depends on random elections of staked sequencers on the network based on a verifiable random function. The idea behind this is having promoting the centralization among the set of sequencers and we're currently evaluating different options for proving that pair well with the sequencer proposal, both cooperative and competitive networks. In competitive networks we know that we can foster innovation, competition between the different providers in researching better techniques for faster and cheaper proving. And in cooperative networks we know that we can foster a higher diversity which should lead to lower censorship. In particular in Aztec we have designed a roll up topology that, if we want to, allows us to parallelize the proving across many, many different machines that can run in consumer grade hardware.
06:23:01.028 - 06:23:56.040, Speaker A: Like each of these small nodes within the massive proof tree should take no more than around 32GB of Ram, give or take. So again, we can completely paralyze and decentralize the proving activities. So, to sum up, we have a lot of problems to figure out, a lot of challenges ahead, and I encourage you to please join the forum. Join the discussion. Help us build strong, robust, healthy, private and censorship resistance protocols, not just for the network that we're building, but also to generate open source knowledge that can ideally help all other networks in the ethereum ecosystem. Thanks. All right, Omar.
06:23:56.040 - 06:24:31.940, Speaker A: Thank you. Santiago, it's very interesting to me that you won't launch Aztec until you are completely decentralized. This is very interesting. Do you have more or less a time frame when you will release Aztec? I know it's a hard question. Cooper, I see you at the end of the stage. What's the answer here? When are we launching Aztec testnet? Next year. Q two next year, ideally for the testnet.
06:24:31.940 - 06:25:03.082, Speaker A: Yeah, fair point. We already have a local development environment which basically has most of execution part of it figured out. But yes, the testnet is where we are going to bring in the implementations for the decentralized protocols, which is probably the juiciest part right now. Thank you. Sure. Anyone else? Quentus, I saw you. Hi.
06:25:03.082 - 06:25:52.872, Speaker A: Thanks for the talk. My cursory understanding is there seems to be quite a lot of similarities with what Anoma and the Helix team is trying to do, but also some differences in how the public state and these kind of things are handled, the more programmable aspects of the chain. I'm curious if you can speak to some of the main differences there, if you've looked into them much at all. I'm not that familiar with the design of Anoma, I'm sorry. Well, then I would like to ask Anoma to comment. I'm going to take the opportunity to shill, if you go. On our GitHub repo, we have our tag of book which lays out a couple examples that you can play with.
06:25:52.872 - 06:26:18.620, Speaker A: And you can see there is a similarities in the execution model. It's not quite the same, but it does take inspiration from Zexi, which I think this model does a little bit as well. So there are some overlaps there. But check out our repo. There's a couple of toy examples in there which I think everybody would find interesting. Great. Anyone else? Awesome.
06:26:18.620 - 06:27:26.620, Speaker A: Hold on, we are running massively early. I'm a little worried about our remote speaker. They're just waking up. Hi. Did you research, maybe any WebAssembly proof generation schemes to simplify users life? What do you mean by WebAssembly proving schemes to allow users to generate proofs from the web interface? Maybe? Yes, sorry. The idea is that proofs should be generatable from the browser that's already happening. We have a release of Noir WASM, which is a WASM compilation of Noir basically, that allows you to generate proofs fully in the browser, but proofs are written in Noir and compiled to circuits with the specific proving backend that we're working with, which is currently honk.
06:27:26.620 - 06:27:41.310, Speaker A: Not sure if that answers the question. Sorry. Yeah, that makes sense. Okay, thank you. Great. Thank you. Ed, since you're already here oh, one more.
06:27:41.310 - 06:28:37.888, Speaker A: Well, yes. Well, Ed is ready, but, Ed, you will have to start thinking about the question for the next speaker, Omar, who's currently asking his second question for his previous speaker. Do you have plans for something like escape hatches or forced transactions or another mechanism? Aside from the centralization? Yeah, there are a couple of proposals in the forum by one of the engineers around sort of forced inclusion of transactions. Still, I think it's relevant to go back to the early discussions today on the timeliness aspect of censorship resistance as well. Like, forced inclusion usually doesn't pair well with timeliness when it comes to forcing an exit or forcing a transaction inclusion. Still, yes, it's something that we're exploring, and ideally, we would be able to ship with both. If not possible.
06:28:37.888 - 06:29:10.660, Speaker A: For sure, we're going with decentralization. Thank you. Anyone else? Well, just as a reminder, you can always send your questions to Evglobal TV. And thank you. Thank you, professor. Next, we are zooming in. Ed.
06:29:10.660 - 06:30:06.250, Speaker A: Sorry, my bad. I think we have your slides. Do you need your laptop or I can use the link. Yes, I can use the thank you. Okay. Thank you very much for coming here, and thank you very much for having me. It's a pleasure to be talking here.
06:30:06.250 - 06:30:43.812, Speaker A: Thank you to organizers for making this possible. It's an amazing conference with a lot of cabbage along the way, but we are here and amazing speakers, and thank you very much for having time for me. So I'm going to be talking about escape hatches as an origin anti censorship solution for specific types of transactions. So we don't want to talk about universal transactions. That means every transaction, but just specific transactions. Just a quick disclaimer. My talk does not necessarily reflect the opinion of Star Wars, the starring foundation, or the Star community.
06:30:43.812 - 06:31:17.184, Speaker A: Overall. This is my own opinion, and if there's any mistake, any stupid thing that I might say, it's on me. So the hypothesis here is that it is fine. It's okay. If not all businesses want to implement decentralization right at that moment, like immediate decentralization, that is okay, but they might want to implement self custody and antisensorship in a different way. In this case, the escape hatches. I think this is okay, and we need to think that or think about that.
06:31:17.184 - 06:31:48.840, Speaker A: Decentralization is not the end. It's a mean to an end that, in this case is self custody and antisensorship. And there might be another path. There might be another ways for specific applications to be able to apply antisensorship and also self custody to applications. Now decentralization of course is the goal. Decentralization is the best thing that I think that we can go for. However, we know that centralization is very hard to attain, it's not simple.
06:31:48.840 - 06:32:34.772, Speaker A: And if we think as a business, they might not want to immediately decentralize, but they want to create a profitable business that is also self custodial. And for that we might have another option that are the scape hatches. And businesses and entrepreneurs needs to know this. They need to know that there's a possible way for them to legally, and this is an important word, legally claim that they provide self custody to their clients. This is very important in order for us as an industry to get more entrepreneurs to build on top of our networks. Now let's think about, let's put our heads in the head of a business owner, an entrepreneur. This person is not a crypto native.
06:32:34.772 - 06:33:27.288, Speaker A: They might be a web two company and let's call the company Trading Fintech A. So for this Trading Fintech A, the main priority of course is profitability. They want to earn money, they want to earn resources, they want to be able to pay the families of the employees. They want profitability and sales. Custody could be an add on, could be a value, an added value for their clients. Maybe this company heard about the crazy FTX story and they heard about the crazy founder of FTX and how they rob millions of persons, millions of dollars and they want to be able to tell their clients hey, this is not going to happen with me because whenever you want you will be able to withdraw your money. So I promise you this, you will be able to withdraw your money whenever you want.
06:33:27.288 - 06:34:04.516, Speaker A: So this FTX case won't be happening. But notice again that the priority is profitability and this is another value that they can add to their clients. Now, non censorship for them and actually legally would mean that users should be able to withdraw their funds independently, that is without third parties. So they can withdraw the money. Permissionless, they don't need to ask permission to nobody. So this is the escape hatch. And for this we need to define what escape hatch and what the powers of escape shells will have.
06:34:04.516 - 06:34:47.264, Speaker A: Escape hatches and we will review it later, need to be very precisely defined. They need to be as minimalistic as possible. And in this case we will have only two transactions that we care about, that we care for them not to be non sensorable, sorry, not to be censorable or for them to be self custodial. And these are the full withdrawal and the force rate. Basically, whenever you want you can have your money back and whenever you want you can make a trade that you want to do. This is for them being self custodial and non censorable. Now, what is the moral of the story? And I think that you can agree with me that there are a lot of business like this.
06:34:47.264 - 06:35:08.840, Speaker A: I am not saying like something crazy. This is an actual business case that we have seen several times already. Of course, I won't say names, but this is common. Companies might not want to decentralize immediately. Maybe they want to decentralize later or maybe they don't want to decentralize at all. But they want to provide self custody and it's okay. And we want that.
06:35:08.840 - 06:35:55.192, Speaker A: Okay, we want that. But we need to make it as easy as possible for them to do this because decentralization is very hard to do. And we can see that with layer two. I think nobody has already a decentralized network because it's hard. So the moral of the story of the story is that self custody is a selling point for companies. I like to think of myself and maybe I don't know what you think, but we are kind of middlemen creating tooling for entrepreneurs to actually build the services that will bring self custody and non censorship applications to the whole world, to millions of people. So for the entrepreneurs, they care about profitability and for them self custody is a selling point.
06:35:55.192 - 06:36:38.708, Speaker A: We are not FTX basically. And also entrepreneurs care about the regulatory scope. And for them, in order to be legally self custodial, you need to be able to claim and also prove that the users can withdraw all the funds. And this is not a theoretical case, this is the actual case. You can say that you are noncustodial if you show and prove that users are able to withdraw the funds whenever they want. Now, let's imagine that this trading fintech company A is very good. They have a lot of business acumen and everything went right.
06:36:38.708 - 06:37:27.270, Speaker A: So they were successful on this. So they boost profits and user satisfaction is great for them, but at the same time they also boost security and autonomy. And we as a crypto industry with our own values, we care about that. We want security, autonomy for everybody as long as possible. We want to bring it to everybody, right? So it's a win for them, but also a win for us with our own values that might be different from theirs. So in this case we could say that Blockchain deliver on its promise of self custody and I am saying promised, sorry, delivered. Because escape hatches of course are not perfect forced transactions, forced withdrawals are not perfect.
06:37:27.270 - 06:38:17.140, Speaker A: But still they provide a non censorship tool that is very relevant and in practice has been already implemented several times in the StarkEx ecosystem. So I don't know, maybe this is something that we need to think about. Like what do actual entrepreneurs in the sense of services that go to the people what they want? How can we make it as easy for them to provide self custodial services to the rest of the millions of people. So, as a conclusion, let's remember that the trading fintech K is aiming for immediate self custody for users. It's important for them, but that doesn't mean instant decentralization. So immediate self custody is not the same as immediate decentralization. This is important.
06:38:17.140 - 06:39:05.488, Speaker A: We can provide other ways as the scape hedge. Now let's go deeper into the escape hatch, what they are, because it's important for me to say, and I forgot to mention it before that when we are talking about decentralization, the centralization is the best thing that we are looking for. Of course, for example, in the STARnet case we want to have everything decentralized and we are working towards that. However, decentralization is very useful for all types of transactions. It doesn't matter the transaction, you create a smart contract, you deploy it, you have different types of transactions and all of them will be non censorable and will provide self custody and so on. However, escape hatches provide self custody for certain types of transaction. As we show with our business case, those are forced withdrawal and also the forced trade.
06:39:05.488 - 06:39:41.676, Speaker A: And I will show you an example, a specific example and a real example. But before, let me tell you what an appchain is in the case of STARnet. However, I don't want to shield STARnet, it's what I know the most. But the appchain concept, you can see it in other layer tools, so no problem. Basically, an appchain is a chain that is dedicated to a specific application. We could say it's kind of like the layer three, where you will have applications with certain rules, both that they want to be fast, cheap and also keep the security of the layer one. And basically they are specific applications, not universal blockchains.
06:39:41.676 - 06:40:26.420, Speaker A: And if you go into Ltobit, you will see that from a lot of the different layer tools. Several of them are actually specific applications. So, for example, we have STARnet, Mantle, Polygon and so on and these are universal blockchains, universal layer twos. So they have a lot of different transactions and decentralization is effectively the best way to go. However, we have applications such as dYdX immutable X, Loop Ring, Apex, CK, Space and all the ones that you can see there in purple that are actually exchanges, NFTs, Dex, et cetera. So these are application layer tools. This is no new and actually a lot of them are coming from the Starkx ecosystem.
06:40:26.420 - 06:41:02.648, Speaker A: You can maybe recognize them like sorre dYdX, immutable X. And what is interesting here is that these companies already implement escape hatches successfully. And when I say successfully, it's really successfully. This is the dYdX case. You can see in L two bit all the force transactions, that is all the uses of the scape hatch that have occurred already and more than 150 transactions have been already forced for whatever reason. It doesn't mean that dYdX is doing something malicious or something like that. It simply means that people are trying the Scape hatch and that is perfect.
06:41:02.648 - 06:41:50.680, Speaker A: And we have had even transactions of millions of dollars. So Escape hatches have been managing the transactions of millions of dollars already in production with dYdX and other applications that are on top of Starkx. And I don't know, maybe you can tell me the questions, maybe I'm wrong, but I have not heard any complaint regarding censorship in dYdX yet or this type of applications they are passing. And that's enough. We want to withdraw our funds from dYdX. Do we want to do something else with dYdX in case they become malicious? I think what I care the most is getting my money back and that is enough for Escape Hatch. Now let's look at the architecture of escape hatch in the STARnet ecosystem.
06:41:50.680 - 06:42:33.008, Speaker A: So, the Scape hatch in STARnet is inspired by the Starkx escape hatch like the one that I mentioned before with dYdX. However, this is the new version of the escape hatch and this is going to be possible to be used as an app chain. So permissionlessly, because the Starkx, you need to ask permission to build on it. It's not ideal, of course. So that's why we have STARnet. And we will allow people in app chains that we could call the layer three to build whatever app chain that they want, such as dYdX for example. We can imagine it as a layer three, as an app chain, so we can imagine them as an app chain.
06:42:33.008 - 06:43:20.790, Speaker A: I am not telling you that they will become app chains, but they could. And this is the new implementation of the Scape hatch. So basically what we have at the bottom is the layer one, the ethereum layer one. Then top on the right we have the layer two app chain with two different smart contracts called the force transaction handler and the balance calculator. Basically the balance calculator has the balance of the resources of the user and the force transaction handler basically handles the transactions. We have the user in the middle who is able to call Escape Tool and then we have the sequencer. So let's imagine that for whatever reason this person wants to withdraw his funds, her funds from the fintech trading company A that we talked before.
06:43:20.790 - 06:44:08.260, Speaker A: This doesn't mean that the company had to be malicious or something like that. It could be the case that they just want to try it. So imagine that they start the execution of a forced transaction. So the first thing is that they will call the force transaction Q smart contract in the layer one. They will call it and then maybe another person will call the same smart contract another transaction and another transaction and will have an effective list, order list of different forced transactions. Then these transactions will be sent to the STARnet core contract in layer one, which handles the L one to l two messaging and they will notify the app chain. That indeed we have already a queue of four transactions that we need to revise.
06:44:08.260 - 06:45:13.924, Speaker A: This way our trading fintech a will be notified that they need to do something with these four transactions and then we have certain incentives. So two things can happen here. Let's assume that the transaction was valid so our user is actually claiming for funds that belong to her, okay? So then our application will see the petition and will determine if it's valid or not. Let's assume it's valid. They will say okay, this transaction is valid and then they will notify the user that indeed is valid. And the user will be able to use the escape tool which consists of basically Madana, which is our sequencer, and then Stone, which is approver to create a proof of funds and send it to the Verifier in layer one. The Verifier will create a fact to the started appchain bridge so that the user can effectively obtain her funds from the started app chain bridge.
06:45:13.924 - 06:45:43.904, Speaker A: That is a successful case as the ones we saw already with dYdX. This is what is actually happening there. Both could be the case that the transaction is invalid. We can think that the person that is asking for the resources is actually malicious and she is trying to spam the network and then she sends an invalid transaction. And in this case the company will say okay, this is invalid, they will notify and nothing happens. Now let's think that everybody in our company die. Everybody die.
06:45:43.904 - 06:46:01.512, Speaker A: Or they turn malicious or something like that. Then they have seven days. They have seven days to tell if the transaction was valid or not. The first transaction is valid or not. Seven days. Most likely seven days. Sometimes it could be 14 days.
06:46:01.512 - 06:46:37.460, Speaker A: The most normal thing are seven days. If during those seven days they did not answer to the queue, then they will be freezed, the app chain will be freezed and this is a huge penalty for them. So they will be freezed, they won't be able to make any money. And that is actually what is happening with the Starkx applications that already are using this mechanism. And they will be freezed and then everybody will be able to withdraw their funds. So they got freezed. And me as the user can use the same escape tool to use the balance calculator smart contract and see how many funds I actually have.
06:46:37.460 - 06:47:20.532, Speaker A: And they will be able to withdraw using the STARnet upchain bridge, the resources in the layer one. So this is in case the sequencer got malicious or everybody die or something like that. This is the architecture right now. Let's talk about what are the problems with escape hatch. They are not perfect. And if you ask anybody that is working with escape hatch, they will tell you that the main problem, the main issue that they have, they think about this is the denial of service risk so they can easily get spam. For example, you can attack dYdX by sending a lot of force transactions.
06:47:20.532 - 06:47:55.360, Speaker A: Like, I don't know, imagine a million forced transactions and dYdX has seven days or something like that. I don't remember. Seven days, 14 to comply them all. In case they do not comply with them all, even if a single transaction is not attended in seven days, then they will be freezed, they will be frozen and you will be able to claim the money that you're claiming for. So this is a way that you can attack this type of networks. So escape hatches could be of high risk in those senses. Now, how we are solving it in STARnet is that basically it is very expensive.
06:47:55.360 - 06:48:26.600, Speaker A: It's very expensive to do a force transaction. So imagine it's 1 million, I don't remember, but I think it's 1 million gas to do force transactions. So if you do 1 million transactions, then it will be 1 billion the cost of the spamming attack that you're doing. So this is of course not the best way to do it. We are still thinking about what is the best implementation in order to prevent type of attacks. But if we make it as expensive as possible, they won't be able to. Spamming will be very expensive for them.
06:48:26.600 - 06:49:03.688, Speaker A: And at the moment we haven't seen any spamming attack yet. So that means that this is working for now, but we might need to think about another approach. Now, another problem is the contract upgradability. If you can update your contract, then you can bypass the freeze. This is another problem that we need to think when we're talking about escape hatches. So maybe the two most important ones is the spamming risk and also the upgradability. Yes, basically in Starkx, to the best of my knowledge, you cannot update your smart contract as easy as possible.
06:49:03.688 - 06:49:42.072, Speaker A: So this is something that we have to take in mind when we implement it in the STARnet App chains. So basically, what are our next steps in STARnet? And I want to finish with this. We will implement escape hatches for App chains. And this is completely new, it was announced yesterday. We'll have escape hatches for the App chains. And specifically, I think it will be with DeFi applications, like for gaming or other type of applications, it will be different, it will be a little complex, but for DeFi we could have escape hatches for them specifically like those that dYdX are using software and so on. So I think this is very cool.
06:49:42.072 - 06:50:05.280, Speaker A: And the second thing is the question, the open ended question. Should we implement escape hatches for the public? Start layer two. I don't know. It's a technical challenge. It's a big technical challenge because as I told you before, escape hatches need to be very minimal. They need to be as small as possible with as minimum transactions as possible. Otherwise their attack vector is much, much bigger.
06:50:05.280 - 06:50:56.476, Speaker A: Yes. To finish, I want to tell you that all this is relevant because, again, I like to think of myself as a middleman creating services for entrepreneurs to actually build sorry. I am a middleman creating tools for those that are building services that can take self custody and antisensorship to the millions of people that are in the world. So we need to make them as easy as possible for them to be able to claim, to legally claim and prove that they are self custodial. If not, these entrepreneurs, maybe they won't care. They won't care, and they will go on with their life because decentralization is too hard for them and self is impossible. So they will go on in their life and maybe they will become the next FTX.
06:50:56.476 - 06:51:37.688, Speaker A: Thank you. I think I went over the 20 minutes. Do we have time for questions? Um any question from the audience? Three, two, one. All right, well, thank you for the talk. Next. Great. I see Ed here.
06:51:37.688 - 06:52:49.738, Speaker A: So let's zoom ed in. And Ed, if you have a question for Omar, as the name of the game for this chapter is to ask the previous speaker a tough question, but he can answer in the side chat now, whereas you can ask out loud. I see. Let me just ask, do you think that some kind of escape hatch, either built into an L two protocol or added onto it, should be thought of as a necessity? Or is this just a nice to have, but now I can't hear the room. Okay, thanks, everybody. Thanks for your time. I'm sorry I couldn't be there with you in Istanbul or Prague today, but I want to talk about improving deadline protocols via censorship detection.
06:52:49.738 - 06:53:45.690, Speaker A: So this is a little bit different to talk about censorship detection as opposed to prevention, but I think it's an important and useful thing to be doing. And the reason is simply that, of course, obviously, we'd like to prevent censorship. But even in systems that prevent censorship, the worst case censorship time that you see is longer than you'd like it to be. So Ethereum being a good example, right. Ethereum has a certain resistance to censorship, and I'll dig into this a little bit. A lot of it repeats earlier talks from today, but in practice, usually on ethereum, you can get much faster inclusion than the worst case guarantee. So the idea here is that by being able to detect censorship on chain, that is, a chain to be able to detect whether it's being censored, that you can actually make protocols more efficient.
06:53:45.690 - 06:54:37.680, Speaker A: But let me talk a little bit more in detail about what I mean by that. So I'm talking here about deadline protocols. And what I mean by a deadline protocol is any protocol that requires parties to act before a deadline. So a classic example of this is something like an. Onchain auction where parties have to submit their bids before a deadline or some kind of interactive protocol that has some default thing that happens if a party doesn't act or if nobody does anything by a time. Of course, the example that is of most direct interest to me is fraud proofs and optimistic roll ups, right, where some party might make a claim on ethereum about what is the correct outcome of execution on arbitram. And other parties have to respond by a deadline if they think that's wrong.
06:54:37.680 - 06:55:19.390, Speaker A: Similarly, the veto in an optimistic sidechain kind of design, that's a design that's like an optimistic roll up, except instead of having fraud proofs, you just have some kind of committee veto. In all of these cases, you have some kind of deadline. If a party misses a deadline, then either that party will be disadvantaged or the protocol will not work as well. So any protocol that assumes an honest party will be able to act before a deadline is a deadline protocol. And these are pretty common. So sure. Okay, so that's what we're trying to protect.
06:55:19.390 - 06:57:01.310, Speaker A: Okay, so our threat model here is the idea that there's an adversary and the adversary is targeting some particular deadline protocol, and they want to censor transactions in that targeted deadline protocol. Not necessarily all the transactions in that protocol, but the transactions that are submitted by certain honest parties or certain kinds of transactions or certain kinds of transactions that will advance the protocol in a way that the adversary doesn't like. So we assume that the adversary will be trying to compromise ethereum, block proposers or block builders and compromise them either by becoming a proposer or builder at scale or by paying proposers and builders to behave in a certain way or by attacking them some other way. So we're going to assume the attacker has some control over some fraction of the proposing or building activity, and the adversary's motive here will be taken as financial gain. That is, the adversary has the idea that they can corrupt the operation of the deadline protocol by using their proposing and building power. And if they can do that, they can get some financial gain within the protocol or that they can discredit the protocol in order to get financial gain. So in an online auction, they might bid low and then try to keep other bids from getting in in some kind of an optimistic l two protocol, they might try to put in a false claim about the execution and then try to censor any attempts to disagree with that and so on.
06:57:01.310 - 06:57:50.446, Speaker A: So that's our basic threat model. Okay, common responses to this are basically two things. In a low stakes protocol or in a protocol that's not carefully designed, you might just ignore the issue or make deadlines a little bit longer. Now, that might be a rational thing to do. If the stakes in your protocol are low, you might figure either a that no attacker is likely to find it worthwhile to attack your protocol in this way that an attack would be too cumbersome or expensive to do given the low value in a particular protocol. You might also decide that, well, there is a risk of an attack, but we would choose to make our protocol more responsive by having faster deadlines. And that's a good trade off.
06:57:50.446 - 06:59:04.760, Speaker A: But in a high stakes protocol, that's really not going to cut it. And the usual approach in a high stakes protocol is to make the deadline longer than the worst case assumed censorship. And of course, the extreme case of this is something like an optimistic roll up where on Arvitrim and other similar protocols the deadline for action in the roll up or dispute protocol is conventionally set to seven days because seven days is the worst case. Assumed censorship attack on ethereum that would not trigger some kind of a social response. Why seven days? Well, it's basically a social census and it's kind of thing that Vitalik and other people say is safe to do in public. And so the worst case assume censorship, there is seven days. Obviously we would like that to be shorter, but in a protocol like Arbitrum, where an attacker could plausibly steal billions of dollars by carrying out a successful attack of this sort, we really do need to work with the worst case assumed censorship time.
06:59:04.760 - 06:59:59.826, Speaker A: Okay? So the key idea in this talk, as I hinted earlier, is that we're going to design an on chain test for censorship on ethereum with one sided error. And what I mean by that is that the test will say one of two things. It will say either that there has not been significant censorship since sometime t zero that's in the recent past, or that maybe there has been censorship. We don't know. Right? And the test is designed to be correct when it says no significant censorship. Correct in its statistical sense that we have extremely high statistical confidence that the result is correct. And then the idea is that in a deadline protocol, we can shorten the deadline if and only if the test says no censorship.
06:59:59.826 - 07:01:02.730, Speaker A: So we might say, for example, that the deadline in some optimistic roll up is seven days. But if the test says that there's been 3 hours with no significant censorship, then we can declare that 3 hours to be enough. Right? And so it's sort of another form of optimistic protocol. Now, of course, the challenge is how do we do that? How do we build an on chain test for censorship? It might seem a little paradoxical. How can the chain know that its input has been censored? In fact, I don't know of any way of any example where it's possible to build a test with one sided error in the other direction where the chain can know it's been censored. But it turns out it is possible in many cases to build a test that allows a chain to know that it is not being censored. So let me talk about how to do that in Ethereum just by way of review, because I know earlier speakers have talked about this, and to establish the terminology I'm going to use, we can talk.
07:01:02.730 - 07:02:24.726, Speaker A: In censorship attacks on Ethereum, there are basically two different levels or strengths. What I'll call weak censorship is an attack against a particular transaction where some block proposers refuse to include the unwanted transactions in their blocks. Strong censorship, which typically, by the way, is applied on top of weak censorship. The idea is not only to attack particular transactions to try to keep them out, but to attack blocks. So if an unwanted transaction, unwanted by the sensor is included in a block, then the attacker either refuses to attest to the block with their proposers to try to prevent that block from getting accepted, or if the block does get enough attestations, the attacker will reorg the chain to exclude that block. So weak censorship, as is pretty well known, as long as some block proposers are not participating in the censorship. But strong censorship has the undesirable feature that if the attacker does control enough of the proposer or builder Power, they can sustain a strong censorship attack for a long time.
07:02:24.726 - 07:03:52.302, Speaker A: Okay, so defeating weak censorship and this is just well known. Again, review and setting up terminology for later. If we suppose that some fraction f of proposers are honest, which means that they build blocks that are not deliberately excluding or the blocks they propose are not deliberately excluding a transaction. And we're assuming here that the transaction that is the target of censorship has gas parameters and other characteristics that make the transaction valid so it could be included. And also that it includes a generous tip so that a rational proposer or builder who's not trying to censor would include it. But suppose some fraction F of proposers are honest in the sense that they're going to build blocks that are not deliberately censoring this targeted transaction. And then if we say, well, let X be the number of honest slots, that is, the number of slots in the consensus protocol that are built by honest proposers out of N total slots, then we have this result that says basically the probability that the number of honest slots is less than or equal to some number k is this binomial sum? And this is essentially just the formula for flipping a weighted coin, right? We're flipping a weighted coin which with probability F comes up as honest and with probability one minus F comes up as dishonest.
07:03:52.302 - 07:05:13.260, Speaker A: So this is basic stuff, right? All right. Against strong censorship, again, the assumption is that the attacker adversary is doing weak censorship, but when the weak censorship fails, they'll somehow suppress the honestly produced block and we'll assume the adversary, we have to assume the adversary controls enough proposers to do this. So the key observation here that makes the test possible is that the attacker, if they're going to carry out a successful attack, they have to turn every honest slot in the consensus protocol into an empty slot, a slot that does not include a block in the canonical chain, right? So they can do that either by arranging that there are not enough attestations to the block or else by reorganating it away. But either way, in the eventual canonical chain, any slot built by an honest proposer will need to be made empty by the adversary in order for the attack to succeed. So then it follows that if the attack was successful, the number of honest slots during the attack time is going to be less than or equal to the number of empty slots, right? Because every honest slot will be empty. But of course, some slots might be empty for other reasons. And then of course, the other nice thing is that we can measure the number of empty slots on chain over some interval of time.
07:05:13.260 - 07:05:59.770, Speaker A: We can look at how the timestamp advances, divide that by twelve, that gives us the number of slots. And then of course we can also see how many blocks were added to the canonical chain during that time subtract. And that gives you the number of empty slots, so we can tell the number of empty slots, and that's an upper bound on the number of honest slots. Okay, next step. Now let's go back, say again, suppose a fraction of F of proposers are honest and non censoring. And as before, we'll let X be the number of honest slots out of N total slots, and we'll let Y be the number of empty slots out of the same N total slots. Now, we know from the previous slide that x, the honest slots are less than equal to Y the number of empty slots.
07:05:59.770 - 07:07:31.080, Speaker A: And so this bound on probabilities follows that the probability that Y the number of empty slots is less than some bound can't be bigger than the probability that the number of honest slots was less than that bound. And so it follows that if a strong attack has occurred, that we have this equation at the bottom, that the probability that the number of empty slots was less than K, given that an attack has occurred, is upper. Bounded by this binomial formula, which is just the probability that X is less than or equal to K. Copied over from the previous slot. So now we have a statistical property that will, we have this statistical property that will hold if a strong attack has occurred, right? And so now we can say this allows us to build a statistical test of the hypothesis that a successful attack has occurred. So in other words, it says if an attack, we can build a test such that if an attack occurred, that test will detect it with high probability. So if we can reject the hypothesis that a successful attack occurred at a very high confidence level, very strong confidence level, say p equals ten to the minus six, meaning that the probability that the test would miss an actual attack is less than one in a million.
07:07:31.080 - 07:08:33.114, Speaker A: That is, if k slots were missing out of n total slots, and this equation holds, then the test can say that there's no censorship. Okay, so now if we're given values of k, the number of actually empty slots, and the number of slots that elapsed, and an assumed value of f, the fraction of proposers, who we assume will behave honestly, then we can actually implement the test. And the way to implement this test is in practice, we'll choose these parameters in advance and we'll pre compute that summation off chain and then build a simple test that we can do on chain. So, for example, just running the numbers, if we assume 10% honest proposers, we can report no censorship. If at most 34 out of 688 slots are empty, that's about 2 hours and 18 minutes, 688 slots. Or with the same assumption, we can report no censorship. If at most four slots out of 225 were empty, that is no more than four empty slots out of 45 minutes.
07:08:33.114 - 07:09:18.700, Speaker A: And by the way, these tests would always have passed in the entire history of ethereum up to now. Well, since the merge, which was the first time that a test like this was possible. All right, now there's a couple of annoying issues that we need to get past in order to make this real annoying issue. Number one is the adversary gets to know in advance the next few proposers. Worst case, the adversary might know the next 64 proposers, and so they can wait to launch the attack until it knows that all of those will be its friends. And so we need to tweak the test a little bit. The mitigation here is to just add 64 slots to the end of the test, assuming that there will be no evidence that the attacker can arrange that there will be no empty slots out of the first 64.
07:09:18.700 - 07:10:13.398, Speaker A: The second issue is that if the test fails, we'll be tempted to do it again over the following end blocks. But that's actually unsound. That's an example of what in applied statistics is called p hacking. Basically, that if there's an epsilon chance of failing each time, and we do the test over and over until it succeeds, then we don't have an epsilon chance of error. So the mitigation here is, if we're going to do up to, let's say, r repetitions, we can do each one to a confidence level of epsilon over r, then we'll have overall an epsilon confidence, at worst that we ever get it wrong. Or alternatively, we can set a total budget of epsilon and spend that over a set of repetitions, taking advantage of the fact that we probably won't need more than one. Either way, we need to make sure that we don't P hack by trying the test over and over till it succeeds.
07:10:13.398 - 07:10:46.440, Speaker A: Okay, next steps here. What can we do for optimistic roll ups or optimistic side chains? You can decide on what value of F is safe to assume. I think you could reasonably do the test assuming F is 5% or 2% or 1%. It's kind of a policy decision. You can then deploy on ethereum a censorship oracle contract with some wired in values of these parameters. And we've actually built a test version of this on I forget, either Gorely or Sepolia. And then you can update the timeout in your protocol to be adaptive based on the censorship oracle result.
07:10:46.440 - 07:11:14.998, Speaker A: And that's it. Thanks, everybody. Please, if you have questions, please put them in the chat in the chat room that people are seeing in the event. Thanks, Ed. I was told that he may not be able to hear me anyways. I can hear you now. Oh, all right.
07:11:14.998 - 07:11:57.642, Speaker A: It worked. But anyways, so please chat with Ed any questions about his presentation. But now we're going to switch to another remote speaker for chapter four. The last one of the day, we're at hour seven of the eight hour marathon. And here we're going to actually zoom back out into the real world. But we're going to start with theory with Milash. All right, I think that's my cue.
07:11:57.642 - 07:12:56.494, Speaker A: Hi, everyone. For those of you who are here in person, I'm sorry I can't be there, and I'm sure, well, you must be exhausted, so I'll try and keep this. So I'm males Bhai I'm a professor of economics at Rice University and also a researcher at Special Mechanisms Group. Let me just try and get my slides on. Clearly not doing this right. All right. Are the slides showing correctly? Tina? I believe that you're going to share screen and should be sharing no, that seems to be awesome.
07:12:56.494 - 07:13:45.002, Speaker A: All right, this is obviously yet another talk on censorship resistance. It's in the same vein as some of the earlier talks you saw today by Sriram, for example. And here's where we sort of come at this. So a lot of the talks that you've seen today think of censorship resistance as the idea that valid transactions make it onto the chain, right? That if there's a valid transaction sitting around in the mempool, it will get included. And a lot of our hand wringing and concern has been about the idea that, for example, OFAC sensor transactions take a really long time these days to make it onto the chain. That's all that as written. We currently guarantee valid transactions will make it onto the chain eventually.
07:13:45.002 - 07:14:42.058, Speaker A: Now the question is, is this enough? As long as valid transactions are making it on chain, is this enough for us to do the things that we want to do with blockchain. So I'd suggest and submit that for a lot of valuable transactions and not just sort of for our goals of credible neutrality, but also for that, this is not enough. So a lot of things are not just about getting on chain eventually, but getting on chain on time. So Oracle Updates is an example of something that you want to be guaranteed to get on in a timely fashion. All sorts of financial transactions, ARBs, liquidations are stuff that you want to get on in a timely fashion. And it's not just stuff that we're doing right now that requires this sort of censorship resistance, that requires stuff to get on in a timely fashion. It's also stuff like the stuff that you could do if you did have those sorts of guarantees.
07:14:42.058 - 07:15:25.600, Speaker A: So being able to guarantee timely inclusion opens up new mechanisms that you can't do right now. So on chain auctions are currently really hard to run for reasons we'll discuss. You could potentially do faster roll ups without a seven day window. All of this would be possible potentially if you could stay away if you had censorship guarantees. Now, the problem that I'm talking about is not sort of I'm not the first person to discover it, so indeed it was one of the first things thought about. So this is from Vitalik's blog post, and the date is June 6, 2015. So it's a thought process that has been circulating in the community for a while.
07:15:25.600 - 07:16:07.242, Speaker A: And here's sort of the thought experiment I want you to think about. So suppose I write you a European option that expires on blockx. So this is for a thought experiment. This is not for a real sort of smart contract that me might want to write, but think of it as I sell you an option and that option pays you the difference on block X between the price of Ethereum and the strike price. So today the price is 2000. I tell you, okay, I will pay you the difference, the positive difference between Ethereum's price right now, between Ethereum's price in block X and 2000. So if it goes up to 2100, I owe you $100.
07:16:07.242 - 07:17:19.858, Speaker A: If it goes down, I owe you nothing and we walk away. Now, for our simple thought experiment, the idea is that this contract is written poorly. It says that if you want to exercise this option so if you want to come to me and say, hey, Malaysia, the price of Ethereum is up, pay up, you have to submit a transaction in that block. So you have to submit a transaction in that very block. And the trouble with aligning, or the trouble with writing a contract like that is that, for instance, imagine the price of Ethereum has gone up to 2100, which means you have $100 gain if you can get a transaction into the block. The trouble is, I am willing to pay up to $100 to censor your transaction if you put only a tip or a priority fee of $90, it's actually profitable for me to somehow pay the proposer to censor your transaction that is not include the transaction. Because even if I pay this proposer $91, he'd prefer to censor your transaction rather than include it.
07:17:19.858 - 07:17:57.230, Speaker A: I have still like a $9 profit. So that's sort of the thought experiment that Vitalik walks us through. And I'd argue that the trouble. There are a lot of lovely things to love about PBS and there's a lot of reasons it was done. But one dark side of PBS is that it sets up a market for censorship. So blocks are auctioned off to the highest bidder in PBS, and that means that a motivated censor could in principle offer a block without the underlying transaction, with a higher bid, and no one would ever know. That's why we're now trying to undo this potential issue with things like inclusionless.
07:17:57.230 - 07:18:29.814, Speaker A: Now, we did a simple version of this a few months ago, just to check how easy it is. And with a better engineer than me, I should be honest, but with a good engineer, it was literally 2 hours of work to spin up a public builder, spin up like an open source builder, put in a few bids and then land a block. So we actually landed a block and we had exactly one transaction in the block. You can check the chain yourself. The block contains one transaction. The graffiti for the block is the first sensor of Rome. And there's a link to our paper.
07:18:29.814 - 07:19:05.670, Speaker A: So that's the block. It was $100 and a few hours of great engineers time. So not completely cheap, but if you have a builder lying around, this is an easy thing to do. And of course, our block was empty and obvious. It was there just so people knew that this could be done. But part of the issue, which you've probably heard about multiple times today, is that if there was a sophisticated builder who left out just one valid transaction because they had a side note or they had a side payment guaranteed by somebody else, you'd never have known about it. And this is problematic.
07:19:05.670 - 07:19:44.974, Speaker A: So we need a definition of mean. Going back to Sriram's talk, one of the things Sriram said in an audio space that stuck with me discussing this was that if you can't measure it, you can't improve it. So we need a definition of how should we measure the level of censorship resistance a protocol or a blockchain is getting. And to do that, we need to abstract away from the machinations of a specific protocol. So let's just walk away from everything and think of a public bulletin board. So a public bulletin board is just a place where people can post stuff and it has two operations available to it. One is a read operation.
07:19:44.974 - 07:20:21.706, Speaker A: You can do it for free and it always succeeds. The interesting operation is a write operation. So it takes some underlying data and it takes a tip T and either succeeds at writing the data to the bulletin board at a cost of T or fails. So those are the only things, two ways you can interact with a bulletin board. Now, what's our definition of censorship resistance? Our definition of censorship resistance is a function fee. And this function fee is the amount it would cost a censoring party to cause a write operation to fail. So there is a censorship party, a censoring party.
07:20:21.706 - 07:21:03.830, Speaker A: We don't know their objectives. They might be OFAC there might be something else. There might be like me in the thought experiment from a few minutes ago trying to stop you from getting this option, being able to exercise this option. Now, the ideal censorship resistance of a chain is of course infinity. You want it to be extremely expensive for a censoring party to do it. But you can now think through with this definition. What is the censorship resistance of a particular thing, of a particular protocol? So if there's a single designated block, that's the relevant public bulletin board fee of T equals T if you have a burn.
07:21:03.830 - 07:22:01.130, Speaker A: So if with the IP 1559 we have the burn and if B is the base fee, then actually it's cheaper to censor because the proposer is not getting part of the associated tip for inclusion. Some part is getting burnt. So the proposer is only getting the difference. The proposer will be willing to censor for anything larger than T minus B rather than T. A bulletin board that consists of K consecutive slots has higher censorship resistance. So if you think of K independent proposers, then given a tip T, it would cost K times T for the censorship to fail and for K large this gives excellent censorship resistance, but it does it at a cost. What is the cost? Any read operation, any operation that you want to do with the data, for instance, run an auction would have to wait the length of time of the K blocks to make sure all the relevant data is in.
07:22:01.130 - 07:22:46.570, Speaker A: So what do we do in the paper? It's late and you guys have been doing this for 7 hours. So in the paper we study how on chain auctions perform as a function of the censorship resistance. We have a model of a bunch of bidders who can submit private bids and public tips and there's one more bidder who's a censoring bidder who can enter the auction, or they can bribe the proposer to leave some competitive bids out or both. The summary of the findings, which I'll tell you is I'll link it in the last slide, is that if the censorship resistance is low, the auction is going to perform poorly. So the revenue of the auction is going to be low. The majority of the surplus, that is the profits that are made from this auction don't actually go to the seller of the good. They are split between the censoring bidder and the proposer.
07:22:46.570 - 07:23:41.950, Speaker A: Meanwhile, if you have high censorship resistance, you restore proper functioning of the auction. Okay? So, so far all I've told you is that censorship resistance is a good property woohoo and some ways to write a public bulletin board or set up a public bulletin board, restore high censorship resistance. But of course, the only solution we've told you so far is to have K consecutive blocks. And of course that's a time issue. So if you're doing something time sensitive, a liquidation, an Oracle update, you might not want to wait K blocks to get the degree of time. Our solution, well, is to end the proposal monopoly. So, as an economist, a lot of the issues that we see are seeing here is because even though there are a lot of proposers, a lot of potential validators in the ethereum system or in any blockchain for any given instant, for any 12 seconds, there's only one of them.
07:23:41.950 - 07:24:19.414, Speaker A: And that monopoly power is what's causing this distortion. So our solution is to have multiple concurrent block proposals. It's more of a wireframe solution, it's not a working engineering solution yet, but some people are working on it. And essentially, kuncur and block proposals, any write operation is sent to all of them. So the block is the union of the blocks proposed by these multiple concurrent block proposer. And we allow for conditional tipping. So for instance, you can submit two tips, a little tip, small T, and a large tip, capital T.
07:24:19.414 - 07:25:02.454, Speaker A: If multiple proposals include the data, then each of them gets paid the small tip. And if only one proposer includes the data, then that proposer gets paid the large tip. Now, what's the idea? Why does this work? The reason it works is that conditional tipping sets up a prisoner's dilemma among the block producers. So every block producer is thinking, should I include this tip or not? Should I include this transaction or not? If every proposer is thinking about this, they're thinking, well look, if the other proposers are not including it, then I can make a large tip, capital T from including it. So it's very strongly incentivized for me to include it. But of course, if everyone is including it, then I own. Or if at least one other person is including it, I only get paid.
07:25:02.454 - 07:25:57.290, Speaker A: Little T. So the idea is that this conditional tipping separates the cost of getting something onto the chain, which is K times Little T, with the censorship resistance of the chain, which is K times Cap T. So you can now have a lot of censorship resistance, but cheap inclusion. Now of course, you need to do stuff with spam and throughput and so on, but that's a separate set of concerns. This is, I think, already, if you don't care about transaction ordering, and you can layer on transaction ordering. But if you're trying to do something like just a pure chain to run an auction, for example, where you care only about the set of bids, not the order in which they arrived, this is a chain that's ready to go in terms of arranging this sort of thing. So, in short, whatever we talked about, I've tried to introduce a novel measure of censorship resistance.
07:25:57.290 - 07:26:53.850, Speaker A: It's one of many measures. So, for instance, Sriram's time to censorship resistance is a different measure. And the community, I think, needs to think about not just what we want, but also what are the measures of how we measure it. So which are the ones we're prioritizing or optimizing for? I don't want to shill my specific definition, but we do think that this one gives a useful way not just about censorship per se, but also about thinking about the viability of various mechanisms on chain. So the possibility of censorship and the absence thereof opens up not just it doesn't just take away the censorship risk, it also opens up the design space for a designer in terms of what mechanisms they can credibly or they can safely implement on chain. Faster fraud proof windows, more efficient DeFi protocols. All of these are possible with higher censorship resistance.
07:26:53.850 - 07:27:38.474, Speaker A: So that was my talk. I'm happy to stick around for questions. The paper is up on Mechanism.org Library along with some of our other research, and we'd be very happy to hear from you with thoughts, comments, anything else. I assume no questions, but in still is that still the case or can we have audience questions? Okay, well, site chat. See you there. Malash well, we do have thank you.
07:27:38.474 - 07:28:12.994, Speaker A: Yeah, we do have Justin Well in person. So your slides are up here. Some of them are from last year. It is okay. All you need to do is to do the slide karaoke, but completely differently. So you have to tell us the delta. Oh, and you need to tie as many talks as possible from today, which you were not here.
07:28:12.994 - 07:28:56.574, Speaker A: So good luck. Okay, so backstory on the slides is I tried to do a new set of slides for every talk, and I've had five talks. This is my fifth one. And I was like, okay, I'm just going to reuse slides for the last one. And then I looked back on my old slides from, I don't know, 18 months ago, and the state of the art has changed so much that I had to do new slides from scratch. So now this is my fifth new slide deck from scratch. So I'm going to be talking about weak censorship, and it's going to be in three parts.
07:28:56.574 - 07:29:57.490, Speaker A: One, I'm going to talk about definitions of censorship and weak censorship, and then talk about the problems with weak censorship, and then finally talk about solutions to weak censorship. So my definition of censorship is to invoke this test, which I call the Append test. It's a very simple test. If you have a transaction which is publicly available but didn't make it in a specific block, you need to ask yourself, could it have been appended at the very end of the block? And if the answer is yes, it was appendable, then the transaction was censored. If the answer is no, then that's fine, the transaction was not censored in that specific block. And there's multiple reasons why a transaction might not be appendable is because it might have been invalid, or maybe the block was full, right? If the block is completely full, you can't append more transactions. Or if the validator was offline and the slot is empty, well, there's no block, so you can't append a transaction.
07:29:57.490 - 07:30:27.594, Speaker A: So that's my append test for censorship. Now, there's two types of censorship. There's weak censorship and strong censorship. Weak censorship is when the censorship is temporary, so the transaction actually makes it on chain, but it's delayed. It could be a delay of a few seconds or a few minutes generally. And then there's this other notion called strong censorship where a transaction just never makes it on chain. It's kind of this permanent censorship.
07:30:27.594 - 07:31:06.890, Speaker A: And this is really bad because it's effectively a 51% attack on ethereum. And we have some really, really big issues if permanent censorship happens. And so this talk is going to be about weak censorship, which is the censorship we've seen so far on Ethereum. We've never seen strong censorship. So, yeah, we're all familiar with the Mev Pipeline, which starts with the user and ends with the Attester. And there's kind of this travel, right, from intent to proposal. And the reason why I show here the Mev Pipeline is to try and tell you where weak censorship lives, where it comes from.
07:31:06.890 - 07:31:49.190, Speaker A: So at the very top here, we have, I guess what I label the private domain, right, the user and the wallet is kind of stuff happening off chain. And so there's not much we can do. It's in the private domain. And then at the very bottom, you have strong censorship, which originates from attesters, right? If you have a 51% attack, it's the validators, the attesters that are doing this attack and leading to strong censorship. And so the weak censorship is the stuff in between, from searcher to proposer. Okay, so what are some of the problems with weak censorship? And there's at least three of them, and they all have to do with inclusion. One is inclusion latency, meaning that transactions take longer to come on chain.
07:31:49.190 - 07:32:33.186, Speaker A: There's something I mentioned, it could be a few seconds of delay or a few minutes, but there's another problem, which is inclusion bandwidth. And I'll give more details about that. And then finally there's inclusion mimetics. And roughly speaking, the less important problem is actually latency. It's the one that people think about immediately, but it's the less important one. The most important one is the inclusion mimetics at least in my opinion. Now, there's this kind of formula for inclusion latency, which is you take the latency of the L one, which is, for example, 12 seconds, and then you divide it by the amount of blocks which are not being censored.
07:32:33.186 - 07:33:20.322, Speaker A: So, for example, if only half of the blocks are not being censored, then you divide by one half, which is the same as multiplying by two. And so your latency kind of doubles. And this is relevant for tornado cash transactions today that are tornadoes on the OFAC list. And very roughly speaking, there's 75% censorship, meaning there's only 25% of lock space, which is neutral. And so actually, you have a multiple of four there on the inclusion latency. Now, inclusion bandwidth has to do with roll ups, not transactions, but more so for roll ups if you have a censored roll up. So one example would be Aztec.
07:33:20.322 - 07:34:15.720, Speaker A: Aztec is trying to build a roll up on Ethereum, and it's trying to have this private kind of mixing service, I guess, within its roll up. And it could just, like tornado cache, get censored. Now, one of the problems with a weak censorship is that if only 25% of block space is neutral and 75% of it is censored, then now Aztec can only consume 25% of the Blobs, and so its max capacity, its maximum bandwidth, is actually only 25% compared to another roll up. And I think this is an even bigger problem than the inclusion latency. For inclusion latency, people will say Bitcoin has ten minute block time, and so a few seconds of delay is not a big deal. And maybe that's the case. But for roll ups and bandwidth, it's a huge issue.
07:34:15.720 - 07:34:55.620, Speaker A: And then there's what I think is the biggest issue with weak censorship, is mimetics. It's just a very bad look that 75% of Ethereum blocks are censored today. It's kind of a sign that governments kind of indirectly have influence over ethereum. And when you even just mention the word censorship, the first thing that comes to mind is censorship is bad. And so it's just not good from a marketing standpoint. And it's also been used by journalists as a way to criticize ethereum, and it's also been used by Bitcoiners and various other critics of ethereum. And so I think it is something that we need to fix.
07:34:55.620 - 07:36:13.822, Speaker A: And the reason I think we need to fix it is because there's this mimetic chain going on, right? Censorship resistance is at the very beginning of a chain which ends with monetary premium. So censorship resistance gives us credible neutrality, which gives us social legitimacy and means that e for the asset can gain the so called monetary premium, which is very important from a utilitarian perspective. Why? Because monetary premium gives us a huge boost in economic security as well as a huge boost in economic bandwidth for applications. Now, what is the situation today in terms of censorship? Unfortunately, five of the top six builders are censoring, and these are their seven day dominances. And so you can see the top two builders account for roughly 60% of ethereum blocks, and they're both censoring. And so if we look here just with these builders that are listed, that's about 75% of ethereum block space, which is censored. Now I think it's a pretty bad situation because we've had 75% so far.
07:36:13.822 - 07:36:44.840, Speaker A: But actually the progression has been in a worrying direction. If you look at Beaver build here, builder zero x 69 and Gambit just a few weeks ago, they were non censoring. So something happened. They flipped to becoming censoring. And so it's possible that we're actually going to have much more than 75% censorship in the short term. And one of the reasons has to do with searchers. So it turns out that searchers have a huge amount of power.
07:36:44.840 - 07:37:29.778, Speaker A: Take for example, Jared from Subway, who's like one of the big searchers, searchers provide flow, bundle flow to builders. And today Jared from Subway provides their bundle flow to both neutral builders and censoring builders. But imagine that Jared from Subway gets a new job or was acquired. And now is Jared from Citadel. Well, Jared from Citadel might, you know, we're Citadel, we don't want to send our blocks to non censoring builders. We're only going to send them to censoring builders. Well, now as a neutral builder, you just have to go out of business because you're not going to win a significant portion of blocks if you don't receive the bundle flow from Jared.
07:37:29.778 - 07:38:36.426, Speaker A: And so there's these few searchers out there or ofa providers whereby if they suddenly decide, hey, we don't want to give our order flow or bundle flow to neutral builders, well, we're going to see an eradication of neutral builders. And it just takes one of these meaningful searchers to do so. And so a possible situation is that layer one, the dominance of layer one neutral block space is basically going to be the non mev boost portion, the self built portion, which is about 6%. So this is where we might be heading very, very soon. And it's even worse than that because the portion that self build is also kind of shrinking over time as more and more validators that are somewhat unsophisticated realize that they're losing a lot of money and kind of activate mev boost as opposed to self building. Okay, so I hope I've convinced you that there's real problems even with weak censorship. It's not just strong censorship which is a problem.
07:38:36.426 - 07:39:11.154, Speaker A: Now, let's talk about some of the possible solutions here. So there's basically four solutions that I see encrypted Mempools inclusion lists, mev burn and Enshrined PBS. And basically there's four different actors that now will have some sort of power over improving the situation. So let's start with users. Users with Encrypted Mempools will have the option to encrypt their transactions and basically say no. You can't see the content of my transactions. And that's going to be very helpful.
07:39:11.154 - 07:40:08.346, Speaker A: For censorship resistance, we're going to have proposers who now with inclusion lists are going to be empowered to force include transactions on chain. Again, helping with censorship resistance. We're going to have attesters with Mev Burn that are going to require that the proposer picks the most valuable block, therefore making sure that any block that does censorship is much more expensive to get on chain. And then finally we're going to have the relays with Enshrine PBS that can just piece out and disappear. Okay, so let's go through each of these four solutions encrypted Mempools, Inclusion Lists, mev, Burn, and EPBs. So let's start with EPBs, actually, because it's very simple. The idea of EPBs is to remove the relays completely.
07:40:08.346 - 07:40:52.598, Speaker A: So relay censorship goes to zero. Nice and clean formula here. The next one, which is a bit more interesting is forward inclusion lists. So the idea of an forward inclusion list is that as a proposer, I will self build a block of transactions. And this block has to be some sort of a block template for the next builder in the next lot. And this next builder has the option to reorder transactions and insert transactions, but cannot delete transactions from that list when they're building their block. So this is where we are today.
07:40:52.598 - 07:41:27.806, Speaker A: Before inclusion list, the neutral block space on Ethereum corresponds to the block space built by neutral builders. But with inclusion lists, we're going to have this additional component, the plus inclusion list percentage. So just to give you an example, let's say half of the builders are censoring, half of it is neutral, and half of the proposers are forcing transactions on chain. Then basically we're going to have half. Plus half is one. But then there needs to be a corrective factor when they overlap. So one half times one half is one quarter.
07:41:27.806 - 07:42:14.414, Speaker A: So you subtract one quarter, and basically we'd be up to 75% of neutral block space on Ethereum. So with inclusion list, we can significantly improve the layer. One neutral block space dominance. Another really, really powerful technology is Encrypted Mempools, and there's various flavors of mempools, and there's various talks online that you can find on that. But here I really want to look at the economic consequences of mempools. So today, before we have Encrypted mempools, the cost of censorship is absolutely minuscule. It's basically just the sum of the tips of censored transactions.
07:42:14.414 - 07:43:11.122, Speaker A: Now, there's very, very few censored transactions out there, and they each pay a very, very small tip on the order of one GUI per gas. So in terms of revenue that's sacrificed from the builders, it's very, very small. But what the Encrypted mempools do is that they basically transform the costs to the sum of all the tips from all the encrypted transactions. And the reason is that if I want to censor now, I have two options. Either I include the encrypted transactions, but now I take a risk. There's a risk that within those x encrypted transactions, one of them is a transaction that I want to censor, or I just censor all the encrypted transactions. But if the vast majority of encrypted transactions, if the vast majority of transactions are encrypted, then now I have to basically censor everything.
07:43:11.122 - 07:44:03.678, Speaker A: And so the cost of censorship goes up dramatically, maybe by a factor of 1000 x here. Now, another really cool technology is mev burn. So right now this is the same formula as in the previous slide. The cost of censorship is the sum of the tips from censored transactions. But what mev burn does is that it adds another component to the cost of censorship, and specifically it adds the base fees of the censored transactions. So now, as a builder that wants to censor, I have to cover both the tips and the base fees. But it turns out that tips in practice are much, much lower than base fees.
07:44:03.678 - 07:44:53.202, Speaker A: So generally speaking, to give you an order of magnitude, tips about one way per gas, but base fees is, let's say, 30 gray per gas. So there's a 30 x delta between the two. And if we combine the two technologies, mev burn with encrypted mempools, so we have 1000 x here, we have 30 x. So we're basically making the cost of censorship, roughly speaking, 30,000 times larger by compounding these two technologies. And what I believe will happen is that censoring builders will just go out of business. It will be unprofitable to be a censoring builder once these two technologies are in place. And then there's this one final idea, which I want to mention.
07:44:53.202 - 07:46:01.538, Speaker A: It hasn't been disseminated very much, but if we go back to the inclusion list, there's a bit of a problem here, which is that the percentage of proposers that will start using inclusion lists might be relatively small. It might be 2030 40%. And really we want it to be as high as possible, ideally 100%. And what we can do is we can apply the same ideas as mev burn, which is to maximize the block, but for the inclusion list itself. So, for example, we can have a rule which says that a block is only valid if the inclusion list was built in such a way that it maximizes the amount of base fees in the inclusion list. And so it's now to the incentive of proposers to build inclusion lists with all the transactions that they see in the mempool and basically removing the option to not use the inclusion list. And so I think we're in a very, very good position from a research perspective and from a design perspective, I believe we have all the tools to fight weak censorship.
07:46:01.538 - 07:46:36.650, Speaker A: It's just a matter of time until it's solved. And that's it. Thank you. Question. Question. Okay, which one do you want to just read the question. Will encrypted transactions will make the block builder lose mev revenue despite gaining more censorship tip.
07:46:36.650 - 07:47:35.550, Speaker A: Okay, I guess one of the two consequences of Encrypted mempools one is that it removes sandwiching to a very large extent, and so it removes the amount of mev that can be extracted from users and in a way that's kind of orthogonal to censorship. Really. The important property from a censorship standpoint is kind of this binary decision as a builder, either I include all the censored transactions or I include none of them. It doesn't really make sense to include some of them just because every Encrypted transaction looks like just any other Encrypted transaction. It just looks like random noise. And what I'm trying to claim here in the talk was that if you decide to not include any Encrypted transactions, then you're just going to go out of business. And therefore the only builders that will remain are those that include all the Encrypted transactions.
07:47:35.550 - 07:48:05.688, Speaker A: I'm not sure the first one is for you. I think there are some shipments. Okay, gotcha. I think there was a couple of questions over there. Great presentation, Justin. Thank you. Is there a particular order of operation for some of these solutions that should be implemented first in protocol? Yeah, great question.
07:48:05.688 - 07:49:02.220, Speaker A: So the nice thing about Encrypted mempools is that they can happen at layer twos, actually. And so I believe that Arbitrum is pushing an Encrypted mempool, and also they can happen at layer one, kind of off chain. So you can think of SUAV or even Mev Protect as being a centralized Encrypted mempool. So Encrypted mempools were starting to make progress already. I guess an important one that I think should be done soon is the inclusion list. Mike has been doing a great job pushing the design forward, and I believe we even have an EIP, and it's not a difficult one, so I would advocate for doing that one soon. EPBs is more involved because it adds one additional round of attestations.
07:49:02.220 - 07:49:49.580, Speaker A: So I expect that will take at least a couple of years. And mev burn depends on EPBs. So mev burn would have to happen after EPBs. So just to recap, the way that I see it is lots of experimentation with Encrypted MEMP pools, no hard fork required, and then inclusion lists that we should prioritize as an easy upgrade and a powerful one. And then enshrine PBS and then mev burn. Hey, Justin, I have a question about inclusion list. So if I understand it correctly, the idea is that if I see a transaction that I don't want to include, I have to push it to the next builder and they will have to include it.
07:49:49.580 - 07:50:19.492, Speaker A: Yeah, but I think that the way this mechanism is working is basically dependent on what is a legal interpretation, because we are presidents in law that forcing someone to commit a crime is a crime. If I force it, I go to jail as well. Right. So the problem is it could be. I mean, we rely on some old farts taking a decision at some point. It could take years. So maybe we will save for a bit.
07:50:19.492 - 07:51:26.830, Speaker A: But I guess that what I'm trying to say is that it may be that if you have a certain interpretation of the law, then you wouldn't want to risk to even use the inclusion list. So I understand the need for mandatory inclusion lists, but again, I think that there is an externality for people that maybe think they will just end up being in trouble, not now, but five or six years on the line. So what do you think about that and how do we solve this? Right? So there's a few points here. One is inclusion lists versus the last idea that I presented, which is mandatory inclusion list. The way that would likely happen is we do inclusion list first and see how things go. Now, if we look at inclusion list alone, as you said, there's kind of this weird thing where the current proposer kind of forces the next builder to do something that they might not want to do. Actually, they don't only force the proposer the builder, they also force the proposer kind of this combo to include transactions that they might not like.
07:51:26.830 - 07:52:15.310, Speaker A: I guess what might happen as a consequence is that some builders just disappear. But I think that's maybe a good outcome. Why? Because it's kind of good to be left with builders that are comfortable being neutral in terms of the proposals that's maybe more problematic. Like, it's possible that some companies, some regulated companies, I don't know, might stop staking. So I don't want to speculate, but some very, very regulated company might decide to stop staking. I mean, I'm just thinking out loud here, but maybe right with their ETF, they might start staking and then we have inclusion list and then they suddenly stop staking. But is that a bad thing if BlackRock doesn't stake? I don't know.
07:52:15.310 - 07:53:26.176, Speaker A: I guess another thing that comes to mind is that it's very much unclear today that Censoring transactions or not Censoring transactions being neutral is illegal OFAC as an entity has provided zero clarity. And I believe that there's no jurisdiction in the world of the 200 jurisdictions in the world that has provided any kind of clarity that any of this is illegal. And there's this prevalent thought within the legal people that I've been talking to that validation blockbuilding. And all of these activities are just part of I don't know what the legal term is, but like this just infrastructure stuff which has nothing is just like running the internet or being an ISP or whatever, it should be neutral. Just like OS, people who build phones or people who write software for operating systems. I guess another thing to say is that we're not lawyers. I'm not a lawyer.
07:53:26.176 - 07:54:41.480, Speaker A: We're trying to design things in such a way that is pure technology and the good news is that you can't put pure technology in prison. So if ethereum forces illegal behavior, as you said it, well, the nation states are welcome to put ethereum itself in prison, but they will fail. And I think there was a question is that the only I'm curious in a potential post PBS world when, like cow swap models with intended solvers might become more relevant, do you see that? Should we consider that in our design choices? And what do you see there as potential paths? Yeah, that's a great question. So I think it's most relevant for mev burn. So I have this new thesis that mev will tend to zero or at least mev that leaks to the proposer. And so it's possible that mev burn will have no impact or very little impact if there's just no mev to be burned in the first place. And there's several reasons why mev might go to zero.
07:54:41.480 - 07:55:39.470, Speaker A: If you look at the total amount of mev that goes to proposers today, it's about 800 E per day and a very significant portion is from Sandwiching, which should go away with encrypted mempools. And then the other portion is from centralized exchange, decentralized exchange arbitrage. And there there's these better designs, as you said, inspired by Calswap, but even better where there's no mev that leaks to the proposer. Instead, mev is kind of re internalized and given back to the LPs. So what is previously or what is currently toxic order flow hitting LPs and kind of arbitraging them and extracting mev should disappear. And now if you look at all the mev and you remove sandwiches and you remove sextex arbitrage, well, you're not left with much. And so it is definitely a possibility that mev burn might not be a priority in two, three years.
07:55:39.470 - 07:56:53.820, Speaker A: Did your model account for the off chain actors captured? Right, so there's also another class of mev which is just dgens just posting transactions on the mempool and not getting any protection or degens using wallets and bots, these new bots. And I think what will happen is that some of the mev will also be extracted by these off chain wallets. It's kind of very surprising to me that MetaMask hasn't added a button when you send a transaction which is so there's two buttons. There could be send a transaction now or send a transaction and give me $100, right? Because for a lot of time you can actually get money back from making the transaction. And actually, maybe this is a startup idea just build MetaMask with two buttons one which says send transaction and everyone says send transaction and give me free money. Any further questions? There seems to be some strong opinion in the side chat. Don't look anyways.
07:56:53.820 - 07:57:40.000, Speaker A: Well, at 21 minutes 2020 1st minutes, you have not yet tied the entire day together that you missed 1 minute. Mev is solved. It's just a matter of time. Fundamentals are strong now it's just a matter of education. Okay, thank you. All right, great. Now we have our final speaker, whom I was informed decided to give up the rest of second half of his talk to improvise because the game role got harder and harder.
07:57:40.000 - 07:58:38.820, Speaker A: All right. It's projecting already. All right. So I think Tim put me last because this last session is supposed to bring the conversation back to the level of abstraction we started with. And I think Tim knows that I'm not capable of diving below about 5 meters in these waters, and these guys, I don't think, have come up above 100 meters in the last hour. There were, like, combinatorics formulas in the last three talks. Wow.
07:58:38.820 - 07:59:42.598, Speaker A: 7 hours. And I'm impressed you guys were able to keep up. So this talk I decided I'm going to make it about foundational design principles. Because one thing I've learned in over a decade of consulting in different technical industries, most of which are such that I can't go very deep I've noticed that strong technical people who come up to high levels of technical leadership, invariably they have really strong foundational design principles guiding their entire work. And what tends to happen is if that foundational design principle is a good one, all these masses of intricate detail that you have to deal with, they tend to go mostly right, and luck kind of favors you in dealing with them. Whereas if your foundational design principle is off, everything starts going against you. So you start to get all these millions of details wrong.
07:59:42.598 - 08:00:24.854, Speaker A: So since I can't talk about the details anyway, I want to talk about foundational design principles. So before I get started, I'd like all of you to kind of think about what foundational opinionated design principle do you bring to your work in building crypto technology? Because that's what we're going to talk about. Okay, so this is a famous quote that's about a century old. You can do some digging to see who started that. People attribute it to George Orwell, but that's apparently apocryphal journalism is printing something someone does not want printed. Everything else is public relationships. I was trying to find a way to port it to crypto, and this is what I came up with.
08:00:24.854 - 08:01:05.342, Speaker A: Censorship, resistance is completing a transaction someone does not want completed. Everything else is yield farming. I am not technical enough to know whether this is an accurate idea or even, like, in the ballpark, but it sounds kind of right to me based on what I've heard today. So I'm kind of, like, 50% confident in it. Okay, so this is going to be a very easy talk as far as technical comprehension goes, but it might be a challenging talk as far as introspecting on your moral beliefs goes. So this is a picture I took on a walking tour yesterday of Istanbul, and the guide pointed out this stone. It's on the side of Kapi Palace.
08:01:05.342 - 08:01:45.182, Speaker A: Most. People miss it. It's near a fountain, and tired tourists might sit on it. And he told us that this is actually the chopping block used by the executioners of the Ottoman Empire. And he told me something very interesting, that for executioners, the Otoman Empire always picked deaf and muted, so they could not hear what the condemned person might be pleading might be saying in their defense, asking for mercy. They could not hear and they could not speak. So it's kind of like not quite censorship resistance, but flip it around.
08:01:45.182 - 08:02:20.540, Speaker A: This is like a dissent resistance from the Sultan's point of view. And there's a fountain nearby for the executioner to wash the sword. And the other thing he told us was that anything the condemned man had it was usually a man. Anything the condemned man had on him when he was being executed, like jewelry, personal possessions, it all went to the executioner as a tip. And since we've been talking a lot about tips and blocks today, here's a block. You get tips for doing things on that block. All right, so this is one anecdote I wanted to bring up.
08:02:20.540 - 08:02:57.186, Speaker A: Here's another one. Another part of the tour was the Hagia Sophia. It's everything it's reputed to be. So if you've been spending all week here and have any time left and you haven't been, please do go. But actually, I found a few interesting sites of censorship here. As you all know, Islam has prohibition against representation of human forms in the religion, and it's not fully enforced in a very conservative way. But since the Hagia Sophia was originally a church, there are obviously iconographic elements throughout the church.
08:02:57.186 - 08:03:25.470, Speaker A: And the one on the left over there, that's on top of what used to be the main altar and now is the sort of prayer niche of the Islamic prayer ritual. And there's pictures of, like, Jesus and Mary right above it. And since that face is Mecca, you can't have representation there. So that part is covered up. That's the middle one. So the middle one is just above the altar. So that's Jesus and Mary covered up.
08:03:25.470 - 08:03:56.966, Speaker A: The one on the left, this is in the entrance to the main chamber. And this is, I think, Justinian offering Constantinople to Jesus or something like that. So that image is visible, but there is a little curtain there that's attached to a rope, so you can pull it up and cover that up if necessary, if there are people praying right outside. So there's an option to censor over there. And on the far right, this is to the left of the altar. So it's not facing Mecca. But if you're facing slightly left and up, there's an image.
08:03:56.966 - 08:04:45.202, Speaker A: I think that must be Gabriel or somebody, but that's not So and Hagia Sophia. It struck me as interesting that it translates to Holy wisdom. This seems like a pretty wise approach to handling censorship in a very pragmatic and charged context. Okay, sorry, what am I doing? Okay, so foundational design opinions. So I'm about as much of an outsider as would ever speak at an event like this. And my sense of the foundational design opinion that drives not just censorship resistance parts of the technology, but all of crypto is the exit versus voice dichotomy with a strong exit bias. So most of you have probably not actually read the book.
08:04:45.202 - 08:05:16.894, Speaker A: Perhaps you heard Balaji's talk about ten years ago when he made this a meme in Silicon Valley. But yeah, this is a book about how when you don't like what's happening in an organization or a society, you have two choices. You either exit or you voice your opinion. Right? And they're not a symmetric pair of choices because voice is by nature more informative. You complain, you say things. So voice is a more informative opinion. An exit taken alone, it just provides, like, warning sign that people are leaving.
08:05:16.894 - 08:05:55.486, Speaker A: It's kind of like a negative signal. And loyalty, which many people miss, it's part of the book's title. Loyalty affects or modulates this decision. So you might choose exit versus voice depending on the loyalties you feel. Right? And some of the points the author Hirschman makes about exit versus voices, exit is fundamentally bias towards economic solutions versus voice being a bias towards political solutions. Right? So there is a strong economics bias. But think about this.
08:05:55.486 - 08:06:26.594, Speaker A: Crypto has a strong uncritical exit bias. Like I said, it goes way back. Things like Forks, things like run your own Node decentralization. But censorship resistance, if you ask anybody outside of this kind of context what they think it means, it's going to be a strongly voice oriented problem. You use the word censorship in normal conversation, you're going to hear about newspapers being censored, journalists being jailed. So it's a strongly voice oriented problem. It's not about people leaving, it's about people staying in and fighting.
08:06:26.594 - 08:07:21.610, Speaker A: Right? So it's not that you're being censored in one medium, so you go off to another medium. It's not that I don't know, you're deplatformed of one social medium and you go pick another one. It's not that kind of choice. Voice is typically a choice that has to do with sorry, censorship resistance is typically a voice problem. So the question then becomes the default opinionated design tendency of crypto, which is exit oriented. Is there a fundamental tension there? And I think there is. Okay, so exit, if you think about like a reduction, ad absurdum analysis of what that leads to, if every time you enter into a conflict with somebody and you choose between exit and voice, and you constantly keep choosing exit and you keep going to smaller and smaller contexts, what's going to happen? You're going to keep fragmenting, you're going to be unconstrained.
08:07:21.610 - 08:08:02.130, Speaker A: This is an approach that frames censorship resistance as being unconstrained. So you're going to go more and more sort of like forking away and you will remain more and more unconstrained, but with fewer and fewer relationships until you are perfectly unconstrained with zero relationships. This I think of as the libertarian endgame of you are alone on your island. Nobody can censor you, but nobody's listening to you anyway. So there's a fundamental problem with this line of thinking, right? And this is typically what libertarians celebrate as sovereignty. And the philosopher to read about what sovereignty means is Hannah Erwent, and she made, like, a really powerful point that's really stuck with me. This is from her book The Human Condition.
08:08:02.130 - 08:08:26.526, Speaker A: She points out that sovereignty is not freedom. You alone on your desert island is not freedom. That's sovereignty. The difference is that you need other people around you to experience true freedom. So freedom, by definition, is something that only exists in a plurality of other people. It does not mean you're assimilated into a borg where you have no individual identity. In fact, she explicitly rejects that.
08:08:26.526 - 08:08:51.590, Speaker A: It means you are like in the public square. You're constantly talking and so forth. So that's freedom and an exit oriented bias will lead you further and further away from that fullest sense of freedom. And from the point of view of Hannah Armond, sovereignty is a kind of degenerate human condition. You're less than human. You're subhuman. And this is like a strong statement, I know, but I honestly believe this about most card carrying libertarians.
08:08:51.590 - 08:09:30.610, Speaker A: Okay, another huge wall of text. This one. I asked GPT to pull out some quotes for me from the novel by Sartre No Exit. And you've probably heard the phrase hell is other people. And most people don't quite know the context of where it comes from, and they assume it's something like, you're annoyed by your neighbors, and if you're stuck with your neighbors forever, it's going to be annoying and that's going to be like hell. That's kind of like the superficial interpretation. The actual interpretation in the novel is when you are in relationships with other people, inevitably they see parts of you that you don't see yourself.
08:09:30.610 - 08:10:21.490, Speaker A: They hold up a mirror, they reflect your union shadow, things like that. And what you feel is trapped or tormented by the mere existence and gaze of others. Simply other people looking at you, holding up a mirror to who you are, reflecting parts of your identity that you might find uncomfortable or distressing. That's what hell is other people means. So being in relationships with people, in a nexus of relationships with people, and being free rather than sovereign is hellish. So that's kind of an interesting paradox, isn't it? Like, we are defining freedom in a way following Hannah Arendt that if you also go with Sartre is hellish. So we are defining freedom as a kind of hell that you choose to live in, right? So think about this, what this says about the default exit bias of crypto.
08:10:21.490 - 08:11:38.282, Speaker A: Okay? So I kind of see this much more in the Bitcoin community, of course, than in the Ethereum community. In the Ethereum community, you kind of see libertarian leanings, but you do see people slowly pulling back occasionally towards questioning fundamental libertarian principles, asking if sovereignty is really the be all and end all. There are the right philosophical curiosities driving the question of what should our fundamental design decisions and design opinions be but exit and voice? I think because it requires a level of, I don't know, introspective self awareness to understand properly and most people their idea of picking exit over voices. You read Iron Rand's atlas Shrugged at age 16. That's the limit of the philosophical questioning you've ever done. And then you go around basically parroting like, sophomoric libertarian talking points for the rest of your life, and you never really go beyond that. But if you take the exit and voice dimension truly seriously, it's actually really hard being in a nexus of other people and being truly free and being in hell is other people.
08:11:38.282 - 08:12:21.626, Speaker A: That's what it takes to navigate the exit voice dichotomy properly, and barely anybody does that. Most people are like, I want to live on my desert island with my guns. It's like the cartoon picture. And I think it's kind of like unnecessary to tie the design of complex technologies like ethereum to self growth and self awareness. You don't have to do that. Is there a way to approach the fundamental design question of something like Ethereum without having to be, I don't know, an enlightened philosopher and processing these questions? So I think there is. So I want to offer you another alternative spectrum that has been really useful for me over the last few years.
08:12:21.626 - 08:13:10.540, Speaker A: This is professor Emeritus of safety and accident investigation research. He studied nuclear reactors, air crashes, things like that for decades. Eric Hall Nagel and he came up with this principle he calls the eto principle efficiency thoroughness trade off, which basically says that you have to choose between being efficient and being thorough. And this can be hard to get if you don't have a bunch of varied examples in your mind. But think about nuclear reactor safety. That's not something you want to efficiently do profit maximizing and solve for very narrow legible cost functions and do very efficiently and maximize your profits. You want to be very carefully checking every possible failure mode, thinking through all the contingencies that could happen.
08:13:10.540 - 08:13:53.682, Speaker A: Nuclear reactor safety is a thoroughness, biased domain. Airline safety, like airplanes, you don't want them crashing all over the place. Again, thoroughness driven field, right? Whereas other things, they can be efficiency driven. Like if you're creating Google Maps or any kind of mapping algorithm for getting from point A to point B, you probably want the shortest distance or shortest time or something like that. That's solving an efficiency oriented optimality problem. You don't want to wander all over the map, right? So think of thoroughness as wandering all over the map, checking everything, making sure everything is sort of like covered. So the Eto Fallacy this is a principle that Holnagel came up with after doing a whole bunch of accident investigations.
08:13:53.682 - 08:14:50.022, Speaker A: I guess it's this idea that when something bad happens, whether it's an air crash or a nuclear reactor meltdown or FTX melting down or the tornado cash thing you guys are all talking about all day, there is a tendency to look back once the data is in and say that you should have done this, this, and there's something fundamentally a causal and impossible about that. You can't do that. You can't fix an efficiency bias in X anti efficiency bias with an X post thoroughness bias in investigation. You can't say you should have been that thorough in covering that stuff, right? You have to have a thoroughness bias straight up. You have to have it on day one, not after the accident happens. So that's the Eto Fallacy, which he uses as a critique of like most accident investigations being bullshit. Exit versus voice had its own implications.
08:14:50.022 - 08:15:32.626, Speaker A: So exit is like economics biased and voice is politics biased. Similarly, this principle has its own biases, I think. Efficiency has a strong corporate and private utility bias, so things like shareholder value or efficiency metrics, and it creates atomized customers, people who are naturally primed to become like libertarian pilled and become completely isolated and atomized. Whereas thoroughness has a commons and public utility bias. So citizen values and it tends to create peoples. So peoples as in like in a town square, for example, all interacting who are bound in webs of mutualism. So efficiency versus thoroughness also has implications, just as exit over voice, but I think they're less ideologically loaded.
08:15:32.626 - 08:16:10.416, Speaker A: Yes, to some extent it's a similar spectrum here, but I think it's a little bit more orthogonal and it's important. I want to re emphasize that webs of people is not being part of a borg. It means finding your freedom in relationships with others. Where I think Ursula Legan had a really good quote about this, which is, to be whole is to be part. So until you're part of something, you can't be fully whole, fully human. So think of that as thoroughness. This is my last slide and I did have like improv stuff that I had in mind, but I'm actually not going to go there.
08:16:10.416 - 08:16:40.472, Speaker A: I'm just going to stop here and let the discussion take over. But yeah, I am a consultant. I have to include a two by two in every presentation I do. I think currently the crypto world is strongly exit biased and strongly efficiency biased because it does have equivalence of shareholder value maximization and so forth. And I think it needs to get to a slight voice bias, at least in the ethereum corner. Let Bitcoin explore the space of strong exit bias. Somebody needs to do it.
08:16:40.472 - 08:17:18.864, Speaker A: But ethereum, I think, can be more voice biased and it can be much more heavily thoroughness, biased, which means it's going to start looking like a public commons way more than private. And I want to make a point about so there's a meta thing going on here. I earlier used the example of exploring a map and the shortest path, as by the way, by training. I'm an aerospace controls guy and I did a lot of research in path planning and robotics back in the day. So these are natural metaphors for me. But yeah, you don't want to go from where we are to where we need to be in an efficient straight line. That would be both ironic and defeat the purpose.
08:17:18.864 - 08:18:21.420, Speaker A: If you try to go efficiently towards thoroughness, you can kind of see the problems that might occur. I think the trajectory in green is kind of what you need to do, like explore the design space a little bit more inefficiently Lazily, wander around, see what the implications of exit versus voice and thoroughness versus efficiency are. And maybe that's the right place to land, maybe it's not. Yeah, I think I'll stop here and yeah. Any questions? We have Justin's twin, who is very opinionated as usual. And if the AV crew can help scroll up a little bit, there was a few walls of tax or shrink the funds anyways. Well, at the same time, questions? I guess I did the walls of death.
08:18:21.420 - 08:19:21.180, Speaker A: I'll read that later. Yeah. Thanks a lot for the speech. It's very interesting, intelligently, challenging to understand this new concept, but that feels into a very interesting concept of the principle versus the result as well. In the last slide, I'm curious on how you comment on there's a lot of things happening in the crypto space or even the financial world, right? People follow the sound principle but not necessarily achieving the most effective and efficient result, whereas some people are very result driven sometimes, of course, they don't follow the first principle actually, even against laws, things like that. So curious with the methodology you just presented, even with the thoroughness and efficiency and all that, how to comment on that. And one little question you mentioned about most of the time, the bitcoin ecosystem community and the ethereum community.
08:19:21.180 - 08:20:04.888, Speaker A: Can you articulate a bit more on the difference? Thank you. That's a lot to respond to. Yeah, to say a little bit more about principles and actually living and embodying them in how you can everybody hear me through this mic? Okay, yeah. A simpler way to understand it might be in traditional startups, you've got the lean startup versus Fat startup notion, right? So lean means you're like being very cost efficient, very efficient. You're experimenting but in a very efficient way, testing your hypothesis in a very agile way and trying to get to product market fit very fast. Whereas Fat is much more like you're in a fundamental R and D mode. You're exploring very lazily and I think that's actually a good way to understand the efficiency thoroughness distinction.
08:20:04.888 - 08:20:53.884, Speaker A: And a faculty member I met a couple of decades ago put it in a very interesting way, which is he said something like, when you take money from NSF or any funding agency, your job is to do the research in the least efficient way possible. And that was like mind blowing for me. And what he meant was the point of the research university and being a faculty member and mentoring students, doing their PhDs and so forth, is to make sure that you're not so focused on the goal that you go straight at it and efficiently solve it without wandering in all the unknown territory that you're exploring. Right. Because think of that as like fat execution. You're like wandering, learning a lot more, and your proportion of exploration to outcome is really high. And I think these are natural personality types as well.
08:20:53.884 - 08:21:25.880, Speaker A: So it's not that efficiency and thoroughness just like one is good, one is bad in certain contexts, efficiency is good in other contexts, thoroughness is good. Right. So it's like people self select into contexts that I think suit their personalities. And sometimes the field itself needs to undergo a change, like a very efficient field. If a series of accidents happened, then maybe efficiency oriented people need to leave and thoroughness oriented people need to come in and clean house. So it's kind of like a self correcting cycle is how I would put it. And your second question, ethereum versus Bitcoin.
08:21:25.880 - 08:21:51.052, Speaker A: I think, honestly, the cartoon view that outsiders tend to believe that Bitcoiners are much more libertarian in Rand sense. And Ethereum people are more open to pragmatic mixes of more mutualist versus libertarian philosophies. Some are even outright socialist. That's roughly correct, I think. So that's why I wouldn't give this talk. At a bitcoin forum. I think I would get stoned.
08:21:51.052 - 08:22:32.830, Speaker A: But in an Ethereum forum, I think some people might agree with me questions. So I was very deeply into a dow called Nomsdao and we recently started thing called Rate Crate. Basically, I think your framework have you ever studied their governance model for nonstop? Not in any detail. I'm just vaguely familiar. Yeah. Oh, yeah. I just think your framework, Exit and Voice is a great framework to think about.
08:22:32.830 - 08:23:21.618, Speaker A: I would recommend you to take a look and you might find something very interesting here. Yeah, I mean, Exit Invoice has been a popular framework for analyzing not just crypto but all of Tech for at least 1015 years now. And yeah, it keeps coming up. He's like, I think, the second favorite economist of Tech types after Ronald cohes. Well, I do wonder if you have looked into after this eight hour no break marathon of talks. Basically, me first started talking about an event around censorship resistance thank you. Because it feels like something I'm in crypto, but it's always something that comes up as a secondary concern.
08:23:21.618 - 08:24:10.790, Speaker A: We're talking about mev, and then like, oh, there's censorship resistance concerns, or we're talking about L two S and there's censorship resistance concerns. But it was never like a full day event or even just like a place where this was the first class topic. So our goal today was to try and put a bunch of content focused on this across all layers of ethereum and try to have it as like a single place that people can obviously attend today, but then go back to into the future. And then the secondary goal is to try and get more people to think about this stuff directly. So not necessarily just think about how do I build this thing? And then, oh, add censorship resistance after. But consider this as a first class oh, sorry, they tried calling me from Istanbul. Okay.
08:24:10.790 - 08:24:29.226, Speaker A: Is it good? I hope so. We're seeing someone's telegram. Okay, let me just see if it broke. Everything okay? Seems like it's not too bad. Okay. Shit. Where was I? Yeah.
08:24:29.226 - 08:25:21.518, Speaker A: Okay. So first thing makes censorship resistance a first class topic. And I think the second thing is getting people to think about this more actively so that if you build something, you sort of consider censorship resistance from the start, not as like this afterthought. And then the third bit of this event, especially with the whole situation that played out with DevConnect, that sort of led us to think, how can we make it as accessible for people to participate both in person and online? And then obviously the two venues is a direct result of that. So one thing that was actually quite neat is today during the day, as soon as the first talk by Juan finished, a bunch of people were like, well, we should upload all the slides in censorship resistance places. So all the slides have been uploaded to both or I don't know what's both for three. But anyways, the IPFS swarm and Rweave, the IPFS and swarm links are part of the agenda that's linked here.
08:25:21.518 - 08:26:11.840, Speaker A: And then there's a full Rweave upload as well that you can access from here. And I'll add this to the censorship WTF agenda. But yeah, it was pretty cool to see this happen like seven minutes after the first talk, people starting to get that together. And then in parallel, there were a bunch of the speakers that started coordinating on like, okay, what are some stuff that we can work on to improve censorship resistance? And it came towards a bunch of things around led P to P and networking. So if you're interested in that part of the stack, there's a telegram group link here where you can continue the conversation. And so to wrap up, I guess I just wanted to thank, first of all, everybody who's like, sat here for 8 hours through all of this. I know this was a lot and really appreciate people spending their time doing this.
08:26:11.840 - 08:27:06.782, Speaker A: Second, the speakers. So I think everyone who spoke just created this sort of censorship Resistance 101 archive that we now have as a single bundle that's extremely high quality. So I didn't expect we'd get something so comprehensive. So it's really great that we'll have this archive and can refer back to it. The third thing, so all of the organizers, we had to work with a lot of them to make this to work and it was quite chaotic. But the folks from the DevConnect team in Istanbul, the folks from the ETH Global team who helped stitch both places together, and then the folks from Prague here that obviously have this whole second event set up and then to wrap up, there's two more people I want to explicitly thank. So Tina, which I mentioned already, has been working with me on designing this event for months now.
08:27:06.782 - 08:27:36.540, Speaker A: And then Fred from the Flashbots teams has been the guy actually doing all of the stuff behind the scenes and making sure that we have everything that we need. So a huge thank to both of them for working with me and getting this all together and yeah, that's it. Thank you all very much for coming. Thank you, Tim. Thank you everyone. And yeah, round of applause for anyone who sat there. More than 4 hours, raise your hand.
08:27:36.540 - 08:27:54.480, Speaker A: Oh, man. 6 hours, raise your hand. Oh my gosh. 8 hours. I see I hear there is a happy hour dinner. We should go anyways. Yeah, that's it.
08:27:54.480 - 08:28:43.980, Speaker A: We will share all of the well, it's already shared all of the slides and this video, this is live streamed and the live stream is already immediately accessible on YouTube. And finally, I think we're going to figure something out about cutting the talks into shorter chunks. And finally, the slides are already on various level of permanence. So if you want, you guys are more than welcome to sit here and continue to watch this debate or discussion. Yeah. All right. I hope you have a good day, good week, and I'll see you next time.
08:28:43.980 - 08:28:48.720, Speaker A: You it.

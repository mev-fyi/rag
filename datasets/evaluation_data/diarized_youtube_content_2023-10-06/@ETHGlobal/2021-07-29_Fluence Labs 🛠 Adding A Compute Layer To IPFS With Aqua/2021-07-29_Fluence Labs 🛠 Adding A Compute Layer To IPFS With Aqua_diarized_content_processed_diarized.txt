00:00:06.970 - 00:00:30.034, Speaker A: Okay, sweet. Looks like you've got a critical mass. So I'm just going to kick this. So yeah, really excited that everybody's here for this workshop. We're going to be going over Fluence and their new Aqua and basically adding a Compute layer to IPFS. But I'll let Bernhardt do all the talking on that. But yeah, otherwise, of course, same rules apply as usual.
00:00:30.034 - 00:00:55.854, Speaker A: So if you have any questions or any thoughts as we're going through the workshop, please drop a note at the end, be some time for Q A. And then of course, once this is over, if you ever need to grab anyone on the fluent side, there's a channel in the Hackfs community. Of course, this is part of the Hackfs event that we're running. Starting, kicking off officially. Yeah. Excited to learn about Aqua. I'll turn it over to you, Mr.
00:00:55.854 - 00:00:56.910, Speaker A: Bernhardt.
00:00:57.490 - 00:01:29.678, Speaker B: Hey, thanks everybody. Thanks for having me. Thanks for being here. And the workshop is really to show you how to combine Compute with storage and Compute being Fluence and storage being IPFS. And let's get right into it. So Fluence fluence provides an open, permissionless secure peer review protocol and the associated network and open source tooling. And the protocol is actually geared towards and focuses on Compute, leaving the developer to take care of store in a peer to peer environment.
00:01:29.678 - 00:02:29.210, Speaker B: So obviously it makes sense to start looking to match your store with the Compute peer to peer. And IPFS is obviously a clear candidate for doing so. Before we dive into that, I want to just give you a few things on how things actually work on the Compute side. Basically, Compute is done by services. Services are deployed on peers and services are comprised of WASM interface type modules that are executed on a general runtime we call Marine, which has been developed by Fluence, is also open source. And services, even though they're WebAssembly so, you know, there are no sockets and sandbox, they can actually do execute external effects like downloads, uploads, modify, replicate, and that allows you to fetch URLs and of course work with IPFS files through CIDs. So on the right I got a little peer to peer network where the greenish things are the clients, thin clients, and then we have the service.
00:02:29.210 - 00:03:22.778, Speaker B: Of course they're all nodes. One is a relay and on the right you get the service that is basically an adapter that can call out to various APIs and of course, IPFS. And this is what we're going to do. Now the question is, how do you program that flow? So we have these services, we want to interact, we want to compute on a file, for example, we want to interact with IP address. How do you do it? And this is where Aqua comes in. Aqua is a purpose built programming language environment that basically allows you to program network routing and which functions or services to call in what sequence on which peers and it makes it extremely easy and it's open source. And we believe that over time it will truly commoditize peer to peer programming because it's extremely ergonomic, especially if you've ever done peer to peer.
00:03:22.778 - 00:04:22.874, Speaker B: You will see this in a minute. Now, one more foundation piece influence the compute side. We have the notion of a particle and the particle is a conflict free replication data structure that combines data, the compiled Aquascript and some metadata. And what that allows you to do is basically you're looking at a push processing model instead of a pull processing model. So if you look at a client and you really want to go by analogy you basically literally can think that a client starts composing that first particle and then literally flings it onto the network which usually is through a relay. And then on this relay the Aqua virtual machine starts looking at the attached it's not bytecode, we call it Air aqua intermediate representation goes through the compiled Aquascript at that stage looks if the service is there on that node. If not it determines which node it needs to go to and some of its dynamic resolution and service discovery.
00:04:22.874 - 00:05:18.094, Speaker B: And so what you end up having is that particle moves from node to node to source to service and executes and updates data along the way. It's eventual consistency. So eventually what comes back to the client is the final result of your computation. That of course is in direct contrast to your average client server implementation where you have request response going back to the client. Request response going back to the client. So this is a very interesting and very effective peer to peer model which allows for very thin clients browsers IoT devices with very thin low bandwidth requirements and low compute requirements and Aqua is at the core of all that. So in a nutshell to actually start looking at Aqua if you look at the little diagram so we got a client, we got a relay node and we got network.
00:05:18.094 - 00:05:52.158, Speaker B: Of course the relay is stylized, the relay is part of the network. But basically what happens is we have a service, let's call it a greeting service and the client here flings that particle that represents that greeting service workflow onto the relay node. The relay node then checks whether or not the service is on that particular node. It's not. We're going to node I whatever it is over in the network we call the service. We execute now the WebAssembly on Marine and then we return the results back via relay to the client peer. At the bottom we get the greeting service.
00:05:52.158 - 00:06:44.720, Speaker B: So it's super easy. This is Aquano and basically what we need to declare is we need to declare our interface with the service keyword and we got our namespace greeting service which eventually will tie bind to a service ID which is unique for every service deployed on any one node. And then we have a function which takes two arguments string and a boolean and returns a string. So basically what the greeting service which we don't have that's out there on the network that has been deployed does it basically has a boolean greet that's true or false and a name that's string. So if the name is hack of S and the greet is true, then the response would be hi hack of S. And if the greet is false, then the response would be by hack of S. So it's a very advanced hello world example.
00:06:44.720 - 00:07:32.170, Speaker B: If you look more in the function signature you have the node reference, the peer ID and the actual service ID and then that function which constitutes our workflow for our application. And if you implement it the right way, it's a decentralized application that you now go on node. So you could be on the relay, you could be right here. But we want to execute on the node specified here on that peer because that's where we know that the service is which is defined by the service ID. And on that node we now establish that binding to that service ID. We call the namespace with that function, we get the result back on that node and then we return the result back to the relay and eventually to the client. This is what we indicated in the diagram.
00:07:32.170 - 00:08:42.050, Speaker B: Aqua in a nutshell, if you've ever done any peer to peer programming and you look at the diagram and you look at Aqua, you will be more than pleasantly surprised of how easy it is to program networks and compose services into applications in a peer to peer environment. With Aqua, of course, this was the compute. So how about the store? The way we deployed it is we deployed a fluence node with an IPFS node as a sidecar. And the reason for that is that we have a bunch of WebAssembly services just like the greeting service you just seen that provide subsets of the bindings to IPFS. CLI, among other things, allows you to add and get from IPFS. This is called the Fluence IPFS adapter and it involves the Fluence Node file system. And what that allows you to do is it allows you to use Aqua to compose IPFS related services and fluence compute services in one seamless interface, one seamless programming environment, one seamless workflow, which is if you ever tried, which I hope you will for the next few weeks, it's super exciting.
00:08:42.050 - 00:09:25.938, Speaker B: And the way it actually works is if you have a file in IPFS, it needs to go from IPFS to the Fluence node where the service is hosted that makes the call. So it needs to go from IPFS to the Fluence Node file system and then it's available for the WebAssembly code to compute on it. And this is what Aqua allows you to do now from the academic to the Pragmatic. Basically the compute services as we said are WebAssembly modules. They need to be stored somewhere. And of course you write them, you compile them, you have them on your local machine. That's not really a great way of doing it.
00:09:25.938 - 00:10:20.126, Speaker B: A much better way of doing this would actually to store your WebAssembly modules on IPFS. Of course once you store them IPFS, you also want to deploy them to whatever node you want to go and you want to use Aqua to do that. And luckily for the rest of the presentation there is a demo for that. So let me switch to the terminal real quick. So all right, so basically what we're doing through the demo is we have a service. Service is written in Rust and it compiles to WASM 32 wasi and the Marine macro takes care of that. That enforces our WebAssembly it requirements and gives compiled direction directives into the WASM 32 wasi target.
00:10:20.126 - 00:11:11.986, Speaker B: And all we want to do is basically with this service we want to take a file and we want to compute its size that's it not a big deal. So what we do then is we let me see, where am I? Come on. And we have a pre built script to compile it. It should be super fast because I've already done that and it is, and this is what the script looked like. So we take this Rust code, we compile it into WebAssembly. We do this with marine which is part of the fluent stack, and then we copy the file into the artifacts directory which is right here. And then we have one more step and basically this is super nice what marine allows you to do.
00:11:11.986 - 00:11:57.054, Speaker B: It allows you to export and export the marine structures, the interfaces into aqua ready code. So this is what we're basically doing here. We are exporting those interfaces, those type interfaces, and we write them to a process file, Aqua, which is right here. Here it is. Sorry, the one up here. So you don't have to do a lot of cut and paste and you can reuse everything you've done in your WebAssembly component. Okay, so now we're all dressed up and nowhere to go, right? We have this service and it's sitting on this module which we want to be a service and it's sitting on my laptop.
00:11:57.054 - 00:12:35.280, Speaker B: And what we really want to do is we want to get this onto the Fluence network so we actually can compute something file size that is. And for that we want to get it onto IPFS. Now before we do that, we have a web app for that and we're then going to use the IPFS desktop to kick off the storage of the module. Okay, so we have a web app. It's react. It's coming, it's coming, it's coming. All right, here we go.
00:12:35.280 - 00:13:28.250, Speaker B: Okay, so in order, as I mentioned before, IPFS is high card to influence node and in order to get going we need to get going with a relay. And we've just listed three relays here. And actually, let me show you something. We have a network, a test network called Stage, and that only has that has six instances of fluence nodes with IPFS sidecars. And the first three are the ones we picked for picking a relay to do the demo. So we connect now, this browser is now your client peer into the peer to peer network with fluence. Okay? So this client is now interacting with the fluence node.
00:13:28.250 - 00:14:25.150, Speaker B: And among other things, what we got back from this interaction is we got back the RPC address of the IPFS sidecar. And what we can do now is we can go and hook up our desktop to that sidecar IPFS node. Okay? And we discovered five peers, which makes sense, right? We're on the relay. It's associated with that node, and we had a network of six, and our peers are five. So now what we can do is we can put a file down there. And the file we wanted to put down there is obviously our WebAssembly file because that's the one we eventually want to upload. Come on, drag and drop.
00:14:25.150 - 00:15:14.586, Speaker B: All right, it's here, and it should be processed any minute. All right, here we go. So now we have our WebAssembly module on IPFS and using the desktop deployment for this part, and we got the CID. So what we can do now is we deploy this service. We deploy this service from IPFS onto the fluence network on that particular node, and all we need to give it is the CID, and we have the IPFS RPC address. And okay, so now we have this service deployed, and this is the unique service ID. And now we have a service that calculates file sizes.
00:15:14.586 - 00:16:15.090, Speaker B: So we could use the file we already have, but I want to drag and drop something else in there's. And okay, that's 428 bytes. We add the CID in here. So now that the service we deployed from IPFS is now ready to go, and we can calculate the file size, and it is 428. Yay. Hey, sometimes things just work out. All right, so let's have a look at behind scenes, because the whole point of the exercise wasn't just that this works, but that this works with Aqua, that it gives you a unique and highly ergonomic interface to manage not only your compute workflow, but also your IPS workflow.
00:16:15.090 - 00:17:03.038, Speaker B: And let's have a look at our process files. So this is all it took. There's a little bit more to it, but this is fundamentally all it took here to deploy the service. So just like before in the greeting service, we have our relay, our Air ID, we use the CID, we get the IPFS address, and then we have what we call an error, which is an arrow function, or actually a callback. You can call it callback, and then we return optionally. The service ID, which is what we wanted. What we do is we specify our service ID as a return value, as a stream, and service ID literally is just an alias for a string.
00:17:03.038 - 00:18:07.238, Speaker B: And then on this relay we want to get the results for the IPFS get. So this is from the previously mentioned IPFS adapter code that comes built in, essentially ready to use for use, and it gets us the result, basically. And the result is, can we download the WASM file from the IPFS to the node? And if that's successful, we calculate a few things including WASM file hashes and we create a blueprint because services influence our logical construct depending on one or more modules, and one or more modules may be part of one or more services. So you basically build a JSON config file, simply said, it's called a blueprint. And on that we can create a service which then returns the service ID and that's it, this is all there's to it. To deploy a service from IPFS onto Fluence Compute, peer to peer network, which is like what, ten lines? This is awesome. Again, obviously I'm excited, but it's really cool.
00:18:07.238 - 00:19:29.810, Speaker B: And now if you want to calculate the file size, it looks longer, but the signature is broken up on multiple lines, basically the same thing. However, we have two error functions or callbacks. One is the log size because the application we just saw was in react. So we can basically use a coroutine, which is down here, the co coroutine to initiate the callback while the rest of the Acro program runs and we have another one callback for our error. And again, all we need to do is can we get the file? If we can get the file, we now call that service, we deploy it and basically using the path onto the fluent node file system and we calculate the size. And if this calculation is successful, we log it back straight to the react app in this case and we write our file size also somewhere else and we can put it back onto IPFS if we want to. And then there is a remove service capability, which I probably should do because I got to clean up after yourself, right? So are there any questions on this end from anybody? I don't see the chat.
00:19:29.810 - 00:20:29.618, Speaker B: Okay, well, if you have any questions, please now, or if it occurs to you later, please don't hesitate to bring them forward. So that was in a nutshell. So just going back, if you're coming from the fluent side, you can now deploy your modules from IPFS to any node you want. It's a real improvement on the workflow and if you're coming from the IPFS side, you have a real easy way and to build applications that use IPFS to store and bring Fluence Compute to the table. And your gateway drug is Aqua, which is amazingly awesome in order to do that. So for the hackathon. We got three prizes each, $2,000, and the first prize is for the best use of Aqua to use Fluent Compute for IPLD.
00:20:29.618 - 00:21:27.014, Speaker B: So anything you want to do in terms of indexing and searching of hosted blocks, websites, blockchain IPLD data, which would be really close to my heart. Not that anybody cares, but I think it's a super exciting area. And of course, content, addressable, archives, readers and writers should also be able to be built on Fluence Compute. The next $2,000 are available for the best functional solution, providing a performant IPNs solution with Aqua. So IPNs isn't the most stellar performant performer and we feel that the alternatives right now are somewhat limited. I haven't seen personally, I haven't seen anything on the blockchain that is performant. And General DNS is, in my opinion, a rather centralized solution which really gets in the way of your decentralized web3 application space.
00:21:27.014 - 00:22:12.530, Speaker B: And I believe we could use Aqua DHT as a name registry or a name registry cache to potentially speed up IPNs. And this is basically a price for somebody trying to do that. Now, aquad is a distributed hash table that is fully programmable with Aqua. So your workflow stays exactly the same in terms of tooling and even interaction of the Compute, the IPFS and then the DHT. So this should be doable. And if anybody wants to tackle this, I'd be super excited. And the last price, not last, but the third prize, $2,000, is best integration of Fluence with ceramic or textile data layers or identities.
00:22:12.530 - 00:23:02.774, Speaker B: Obviously both projects are also building. IPFS are super exciting and provide the missing store and then some element to the Fluence protocol's compute. And any work in there would be super exciting for all of you, both Fluence and ceramic or textile, obviously. And there's a repo and it has pretty much all that written up in there. And if you need to follow up on that and we have a bunch of resources available to you to hack through the next few weeks. Documentation, discord, both our discord and of course, the Hackfs Fluence Discord Channel. And there are some YouTube videos if you want to learn more.
00:23:02.774 - 00:23:59.714, Speaker B: And if you get stuck, please feel free to set an appointment with the core team and we try to help you out. Obviously, we are hiring, who isn't, but we are. And I think you should if you're in Rust or compiler work, you should definitely look us up. And I use Aqua to basically say thank you and good luck. Now I see the chat and the question is this like a remote procedure call? Well, is it like one well, functionally, yes, you make a call, but it's not. The difference is the particle. And does that answer the question or do you want me to get into it? Go into it.
00:23:59.714 - 00:24:28.890, Speaker B: Okay. Rabbit hole. All right, yes, rabbit hole. So Basic RPC is based on client server and client server is a request response model, which is a pull model, which we don't use. So in that case, in that sense, it's not like RPC. However, of course you do make remote calls. However, the remote calls do not go between the client peer and the node.
00:24:28.890 - 00:25:29.342, Speaker B: It operates as a workflow along the way. So the particle that travels from node to node is your medium that takes the Mutability or Immutability data usage and then updates the data in that spot. So it basically travels where in RPC you have this strict client to server back forth, back forth, back forth. And in that sense, it's not the same at all, actually. However, the outcome is somewhat similar. Now, we can use RPC calls from Compute Services to make calls to APIs and solutions that are not part of that are not natively deployed as Compute services on the peer to peer network. So in that sense, you can use them.
00:25:29.342 - 00:26:00.202, Speaker B: But is what Fluence is doing like a remote procedure call? No, it's not. Did that answer the question? Cool. All right. Any other questions? All right, I have a surprise. I hope that's okay. I think we didn't spend all our allocation. So there is this say thank you and good luck service here, right? Which I use.
00:26:00.202 - 00:27:02.240, Speaker B: So thank you for having me, thank you for being here, and good luck. And we'll pay $250 to the first person who provides the peer ID and output of the say thank you and good luck service in our Hack FS sponsor Fluence Labs channels before tomorrow, 2400 EDT. So midnight. And basically what that requires you to do is you have to read it up a little bit and figure out how service deployment works and how to find them. But the first person who posts in the channel, the peer ID and service ID and the output of that good luck service I've mentioned before, $250 before midnight tomorrow. Anybody else? Okay, well, I could have gone a little slower.
00:27:03.940 - 00:27:28.212, Speaker A: It was almost perfect timing. That's a hell of a good surprise at the last minute. So I heard it here first, folks. Everybody else who's going to be catching up on YouTube afterwards is not at the same advantage of you. So it's a good opportunity to look through everything and win $250. Awesome. Well, big thank you for the workshop.
00:27:28.212 - 00:27:53.870, Speaker A: Big thank you, of course, to Fluence for being one of Hackfs's sponsors for this event. Really excited to see what people build using Compute later on top of IPFS. And of course, if you joined late or are watching this us or want to watch this later, it's going to be up on our YouTube channel right away. So ETH Global on YouTube and you'll be able to catch it there. Awesome. Thanks again and hope everybody has a lovely rest of their day.

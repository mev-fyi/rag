00:00:00.250 - 00:00:30.294, Speaker A: And just follow up with the audience there will appreciate that. And with that, we are ready to move on to our next talk. So the next talk we're going to be doing is going to be by Andrew and Janice. Andrew is from Consensus and Janice is from the Graph. And so they'll be talking about how do we actually manage state channels at scale. This is something I'm really excited about and I want to hear their thoughts. How do they actually pull this off further Graph? And just how do we think about this as a large infrastructure problem.
00:00:30.294 - 00:00:37.160, Speaker A: So I see both Andrew and Janice are here and I'll let them kick off with their SlideShare. Thank you so much and welcome.
00:00:38.990 - 00:01:28.570, Speaker B: Thank you. I think Janice is going to be sharing his slides. All right, yeah. Thanks everybody for attending my first webinar. I'm going to be talking about the recent goal of the State Channels team to build a highly scalable state Channels wallet. As Kartik said, I'm Andrew Stewart, I work on the Magmo team at Consensus and we're part of the State Channels community, the State Channels organization, which is a community of researchers and developers implementing open source state channel solutions. I actually have the pleasure of giving my first joint presentation with Janice, who's the tech lead and the co founder of the Graph.
00:01:28.570 - 00:01:43.380, Speaker B: We actually started a collaboration with the Graph a couple of months ago to integrate Nitro state Channels into their query payment model. And so Janice is here with me as well.
00:01:44.630 - 00:02:20.300, Speaker C: Yeah, welcome. Glad to have you all here. So the structure of our talk will be as follows. We'll talk about the Graph and its use case for state channels, especially going forward. Looking forward to the Graph network. Then we'll talk about State Channels by introducing the general concept, but also how it applies to the Graph specifically. And then we're going to talk about not really Jetpacks, but we're going to talk about the improvements we made to push the boundaries of State Channels forward in the past couple of months.
00:02:20.300 - 00:03:30.446, Speaker C: Let's start with the graph. The Graph, for those of you who don't know what it is, it's an indexing protocol for organizing and efficiently accessing data from blockchains such as Ethereum, and storage networks such as IPFS. Back in January 2019, we had Graph Day, a one day conference where we launched a hosted service that's a currently centralized solution to basically do everything that we want The Network to do, just in a simpler way. So that everybody could start using it right out of the gate and didn't have to wait another two years or so for the network to develop. That's been in running since January 2019 and has since been picked up by a lot of well known projects. You can see some of them here, uniswap Synthetics, Ave, Dow, Stagnosis, Aragon, ENS, and many, many more are using the Graph in production today. And you can also see that when you look at the daily query volume that we're processing.
00:03:30.446 - 00:04:56.350, Speaker C: So right now we're at about 300 million queries served a day for all of the projects that are using us. And that comes down to about 3000 to 4000 queries per second served. We recently launched our testnet, or incentivized testnet called Mission Control as we're moving closer towards the graph network launch. Now the graph network will replace this centralized hosted service where everything is run by a single company that you have to trust to stay around and keep everything running, and also that you have to trust with your data. We replace that with a decentralized service and decentralized network and a query market around that. The way this looks then is that instead of hitting a centralized service, the consumer will pick from a variety of indexes that are running around the world based on certain criteria and will send these indexes queries for the data. And there are incentives baked into the protocol to incentivize indexers to, first of all, index these data sets that we call subgraphs, keep them available, serve queries for them and get paid for these queries.
00:04:56.350 - 00:06:09.400, Speaker C: And then there are a bunch of other incentives around that to keep the network healthy, such as curating, subgraphs or delegating to indexes that are doing good work and so on and so on. If we use the hosted service as oh yeah, one thing I should say. So initially you want to start not with the consumers directly interacting with the indexes and paying them directly. Rather we'll start with so called gateways that sit in the middle and that the apps send queries to like the hosted service today, or like any other API service where they don't have to pay for the queries. And then these gateways will select indexers based on certain criteria that can be customized and will handle the payments and also the validation of query responses on behalf of these DApps and users. So when you see consumer here can also for now, think of them as gateways. If we use the hosted service as a reference, then we'll see a decentralized network that processes about 4000 queries and payments per second.
00:06:09.400 - 00:06:49.250, Speaker C: Looking at for reference visa, they process about 16 700 payments per second. They can peak at 65,000, but the average is about that. So we're looking at double that average for the hosted service right now. And if we can translate that to the network, then that would be a decentralized system processing that. Now, you just heard 4000 paid queries per second on ethereum with its block times of 15 seconds and ten transactions per second throughput. How does that work? And for that I'll pass it over to Andrew.
00:06:50.230 - 00:08:31.460, Speaker B: Yeah, the state channels team would naturally ask at this case, can we use state channels to pay for queries? And to start answering that question, I'll first ask what are state channels? Well, state channels are a L2 scaling technique for ethereum that enables trustless, instant and zero fee transactions amongst a fixed group of users. They're not exactly instant because a payer and a recipient are rarely in the same location. And in addition to be trustless, they do incur a small computational overhead to verify payments, as we'll soon see. But in any case, for graph queries, state channels are a perfect application because once a gateway selects an appropriate indexer, you now have a fixed set of peers who want to exchange some asset, such as ether or some token for some information, such as the query response. For those who aren't familiar with Nitro state channels, I'm going to walk through the lifecycle of a toy two party state channel that's funded directly with two on chain deposit transactions. So for starters, if we had, say, Alice and Bob here with five tokens each, and they wish to trade tokens between them, they can use an on chain adjudicator to mediate the off chain token transfer using a Nitro state channel. They do so by exchanging signed states which the adjudicator will use to release funds based on states supported by all the parties in the channel.
00:08:31.460 - 00:09:26.770, Speaker B: So to start off, they both sign what's called the pre fund state. Here, in this case, the initial outcome of the channel, allocates five tokens to Alice and five tokens to Bob. Once Alice has the pre fund state signed by Bob, it's safe for her to deposit into the adjudicator contract. Even if Bob refuses to deposit, the Nitro protocol ensures that Alice can recover her tokens in bounded time, even in the presence of front running attacks. After Bob sees Alice's deposit, it's safe for him to deposit and the channel can, from there on, be used to make payments by simply updating the outcome in the channel. For instance, if Alice wants to pay one token to Bob, she can sign a state update where the tokens are allocated slightly differently, with four to Alice and six to Bob. In this case, she's given one token to Bob.
00:09:26.770 - 00:10:25.030, Speaker B: Now, Nitro state channels are term based, meaning that if Bob doesn't want to make a payment, he needs to pass the buck back to Alice in order for Alice to be able to make the next payment. I'll note that there are applications of Nitro state channels that can avoid this, but this allows wallets to make simplifying assumptions that enhances the security model. Now, suppose after making a few payments, they decide to finish with the channel and settle the bill. What they do is off chain. They co sign a final state indicated here by the Asterisk with the final outcome, and they give it to the adjudicator in the onchain transaction. When the adjudicator is given a final state signed by all the parties, the channel is instantly concluded on chain. In other words, if the peers in a channel collaborate, then they can recover the funds without having to wait a timeout period.
00:10:25.030 - 00:10:54.370, Speaker B: Once the channel is concluded, the adjudicator distributes the tokens according to the last outcome that it held. In this case, Alice would get eight and Bob would get two. Now this is just a toy state channel with a simple outcome. In general, you don't want participants to be able to update the outcome arbitrarily and for the graph in particular, you might want to make payments conditional on certain features.
00:10:55.430 - 00:12:17.290, Speaker C: Yeah, so this example translates pretty well to the graph network as well. One thing that our payments, where our payments are a little bit different from just accepting a new balance is that they are conditional on the index serving a query response that matches the query, and that's correct for this query. So what in our case consumers or gateways will do is they will send a query along with a conditional micro payment that can be unlocked with an attestation for the query response. So that is for the indexer to say I've successfully executed this query against the correct data and I'm serving the correct data back. And based on that, that's basically the rules of the state transitions and how payments can be made off chain between the consumer or gateway and indexer. Yeah, there's one thing to note here, these attestations, if they are incorrect, for instance, they can also be disputed later on chain, so these transactions don't have to be final. If it turns out that the data served was not correct, the graph network will most likely see us entering new dimensions in terms of scale.
00:12:17.290 - 00:13:28.546, Speaker C: As more DApps adopt the graph as the technology for querying their underlying blockchain data, we will likely see thousands of them. We already see, or have I think, between one and two, maybe 3000 subgraphs that were created over time on the hosted service. So there's plenty of interest there. And those thousands of apps will likely power millions of users. And to serve that traffic, we'll have dozens of gateways and we'll have hundreds, if not thousands of indexes that either index specific data sets or variety of data sets. And so there's a lot of scale that requires the whole system to be very responsive and to have, for both queries and payments to have high throughput low latency to be reliable that queries don't fail and payments don't. Fail to be trustless as well, because you don't want to trust a gateway that you don't know or an indexer that you don't know, that you don't even interact with.
00:13:28.546 - 00:14:19.780, Speaker C: If you interact with it through a gateway, These gateways, if we think of them as deployed around the globe to reduce latency, they are largely independent when it comes to the state channels. So they will all have their own set of state channels that they manage with indexes. They will have potentially their own balances. They may be run by completely different people with different keys. So for looking at the scale of state channels, this overall network is not extremely interesting. What's more interesting is to look at a specific pair of consumer or gateway and an indexer and to see how many paid queries we can execute between these two, what? Well, next we hit and how we can remove those.
00:14:21.830 - 00:15:30.010, Speaker B: So to discuss the issue of the throughput through a single gateway, index, or pair, I'm going to first look at the critical path required to make a payment. What does a gateway and indexer actually have to do to process a payment? So the first thing is the gateway needs to construct a payment state s one. It then needs to sign it, store it in its database, send it to the indexer, and then wait for a receipt state s two from the indexer. Meanwhile, the indexer is waiting for the payment state s one from the gateway. Once it gets it, it's going to push the payment state into its database. It's going to then construct a receipt state s two, sign it, store it in its database, and send it back to the gateway. Once the gateway receives s two, it then pushes it into the database and the payment is then processed.
00:15:30.010 - 00:16:35.070, Speaker B: So, starting out, we could initially hit on the order of one payment per second. Given these steps, it was a bit more than one, but it was that order of magnitude. And why was it so slow? Well, each of these steps from one to six on the left and on the right, mapping steps. If you only have a single channel, the gateway can't do anything to process another query until it receives a receipt from the indexer. Likewise, if you're interacting with your database, your application can't do anything until it gets a response back from your database. So to increase throughput, we definitely need to use more channels. So creating parallel payment channels is where the Nitro protocol really shines, where we can fund a single ledger channel with a single deposit on chain and use it to fund many payment channels via ledger state updates off chain.
00:16:35.070 - 00:17:17.420, Speaker B: By using many of these parallel payment channels, we could initially hit about ten payments per second, which is still slow. So why is it slow? Well, node JS, first of all, node JS is a multithreaded language runtime, but it only provides a single dedicated thread for running both the event loop and your application code. So you can't use more than 100% of a single core for this thread. If you ever hit 100%, you're going to have a bottleneck. So, for instance, signing state updates need to be as quick as possible, and initially they were slow. Janice came in and helped us with that.
00:17:20.030 - 00:18:16.590, Speaker C: So one thing that or the first step of constructing a state for a new payment that you can then send over to the indexer is that you have to encode the application data. And that is very similar to how you encode a lot of data in Ethereum, you use an API encoder and you pass that data in. And if you write a JavaScript or TypeScript application or library, you're likely to use Ethers or Web three JS. In this case we initially used the Ethers API encoder and it turned out that that was fairly slow because I think it's implemented in JavaScript. Luckily, the application data that kind of represents our state transitions. So like the conditional micro payment or the adaptation, they are fairly simple. They have a few fields like the payment amount, a request identifier, response Identifier, a signature by the indexer.
00:18:16.590 - 00:19:30.178, Speaker C: So in this case it was very easy to just write like an almost by hand custom encoding routine that does this in a much faster way than a generic encoder would. And I think that boosted the throughput about 25%. After you've encoded your application state, you will put it into the new state or your application data, you put it into the new state and before you can send that over, you have to encode that again and hash it and sign it. And these three different steps were all using slow JavaScript based code. So again, the ETH Avi encoder to encode the state, a JavaScript Catcher, 256 hash and a JavaScript method to sign the outcome of that. And one thing that's really nice about JavaScript is that you can very easily extend it with well, initially if you run Node JS, you can initially extend it with maybe native code. But today we also have a WebAssembly which we can run equally in the browser as well as Node JS.
00:19:30.178 - 00:20:35.690, Speaker C: So one thing we did here was that we replaced the encoding of the state, the hashing of the state and the signing of the state, which were initially three different steps in a single call to a WebAssembly module that was written in Rust and compiled to WebAssembly using Wasmbinegen. And that ended up being a JavaScript package that's as convenient as any other JavaScript library to import and to use. And what you can see here is you don't have to encode the state upfront. Also not doing several round trips to WebAssembly, we're doing a single round trip to WebAssembly to perform all these operations there. What we use for this code is in Rust is ETH Abi, a library written by initially parity now open Ethereum team, which we're also using pretty heavily at the graph and it's kind of like partial equivalent to Ethos JS. In the rust world. This gives us another boost of about 20% in throughput.
00:20:38.430 - 00:21:50.900, Speaker B: So when it comes to storing states safely, we're using a postgres back end, but we chose to use objection a JavaScript Query Builder library to interact with the database. But the result is that if you write JavaScript code like this, you're constructing the same query at runtime over and over again. In this Snippet, you want to construct a join statement between the user table and the emails table. And it actually takes a nontrivial amount of time to construct and dispatch these fairly simple SQL queries, which is just wasting our precious main thread CPU cycles. And it's not actually that bad to just write the SQL query that you want by hand as a prepared SQL statement stored in your source code. That means that all you need to do is fill in your parameters and send it off to SQL. And if we switch to a library like PG Promise that embraces this technique, we can actually seemingly boost the throughput by something like 400% in a single threaded application.
00:21:50.900 - 00:23:01.946, Speaker B: So with all these optimizations together to hit with 100 payment channels running in parallel, for instance, we can hit on the order of 100 payments per second in a single threaded JavaScript application. That's clearly still not enough. These days you can get a powerful multicore server and we're only using one of those cores. So if we want to increase throughput more, the natural thing is to hire more workers. We can just spawn worker threads in a Node JS application and offload as much of the critical code as we can into a worker thread. And then as long as we have enough CPU cycles to schedule more work, and as long as our database can handle more database connections, we can scale throughput linearly by just paying for more CPU cores. With this strategy, we can then hit the next order of magnitude around 1000 payments per second.
00:23:01.946 - 00:23:18.990, Speaker B: But the main thread bottleneck will always remain. If you only have one main thread that's running on one core that has to do a certain amount of work, you just can't scale any more than that. And the solution here is again obvious. We should hire more managers.
00:23:22.390 - 00:24:18.674, Speaker C: And by managers in this case, Andrew means more gateways or more not threads, but processes that can manage more threads. So one thing you can do is horizontally scale the gateways and have them all use their own database connections and their own worker threads to do basically the same thing. Put them behind a load balancer and you're good, right? There are a few complications here when it comes to state channels. Due to their sequential nature, you can't use the same channel in two different gateways at the same time. So these need to be synchronized a little bit, otherwise one gateway or two gateways might try to use the same channel at about the same time. One does it, the other realizes that channel is now busy, decides to retry pick a different channel. But maybe one of the other gateways has already picked that.
00:24:18.674 - 00:25:23.880, Speaker C: And so there's kind of a race to find a suitable channel which needs to be optimized a little. So a very naive way to do this would be to just have them use completely disjoint channels. Like a gateway would do that is or like two gateways would do that are deployed to completely different regions on the globe, both managing their own channels, having their own keys and managing the channels with the index bus completely separately. That has the downside of having to create a lot of channels in the first place to have to fund these channels. It's a lot of overhead just to get this extra scale. And since they are all able to connect to the same database, all that's really needed is kind of a lookup table that allows all of the gateways to efficiently and atomically pick a channel in the database that's not used yet and at the same time mark it as used so that nobody else will use it. And then there's very little overhead in picking a channel.
00:25:23.880 - 00:26:30.190, Speaker C: Yeah, it makes sense to kind of move the channel management out of the critical path as well. So that doesn't block any cycles in the main thread of any of the gateways. So one approach that we've taken is to move the channel creation logic and all of that into a separate service that runs alongside these gateways and manages just the channels, and then the gateways just execute against the channels that they find in the database. And so if we run more applications going from starting at 1000 requests payments per second, where does it end? Well, we'll see that's still one of the open points here. We've yet to see where that takes us, but we're very optimistic that we can take it to the numbers that we need to sustain the usage that the hosted service has seen already and carried over to the network.
00:26:32.770 - 00:27:53.510, Speaker B: So to try and wrap things up, I'll quickly summarize that we're making significant progress at increasing the throughput of our State Channel wallet by optimizing the critical path, making a multi threader wallet, and building tools to synchronize the sharing of a pool of payment channels. I'll just add that most of the work outlined above so far is open source. There is some part the channel management software that Janice was talking about, it's still loosely coupled to Graph specific code, but we plan on open sourcing that in the near future. And in conclusion, the the Graph has provided the Graph is providing a highly scalable and robust network for indexing and querying decentralized data. And our collaboration with the Graph has been a really welcome boost to prove that State Channels can work well at scale. With the upcoming Graph network mainnet launch expected later this year, state Channels are going to be one of the few highly scalable, decentralized payment solutions used in production. So we're really excited to continue with this collaboration.
00:27:53.510 - 00:28:18.990, Speaker B: Yeah, to just wrap it up, I'd like to thank the Ethereum Foundation for their past and their ongoing funding of the State Channels project, as well as ETH Global for organizing this session, and everybody from the Graph for welcoming the State Channels team into their project. Yeah, thanks everybody for your attention and enjoy the remainder of your talks.
00:28:20.530 - 00:29:03.390, Speaker A: Andrew Yanis, thank you so much for this amazing talk and also a very beautiful presentation. We have a few questions coming in from our audience and I have a list of handful of questions that I'll ask you. We have a couple of minutes here and luckily Mike Kirzner from Channel's Team has been answering a lot of them already. So there may be some repetition here in the answers, but I'll kind of ask the smaller ones for you. I guess my first question here is just for the audience to better understand what's possible here. How programmable are state channels? Are they only supporting just transfers and any conditional logic? Or do you actually get more complexity on programmability here if you use state channels?
00:29:05.890 - 00:29:58.430, Speaker B: So the Nitro protocol focused on simplicity, with the goal of targeting the majority of applications that we could imagine using without adding too much complexity into the protocol. So therefore we're currently limited to state channels where the state transition logic is a pure function of the existing state. So you can write arbitrary code that determines what transitions are valid in solidity, but the code must be a pure function of the current state. And that's the only limitation of the Nitro protocol right now. There is some research into escaping that constraint, but that's without a target use case, it's not considered right now.
00:29:58.580 - 00:30:10.580, Speaker A: So maybe just to follow up on your answer then does that I guess maybe it'd be great if you can also answer what additional liveliness assumptions you have to make for Nitro and kind of how does that change?
00:30:11.190 - 00:31:01.250, Speaker B: Yeah, so we actually have a pretty good blog post or a blog series about this. So we were able to formally verify at least a portion of not formally verify. We have a TLA plus specification of a part of the Nitro protocol itself that can prove that as long as you have the ability to submit a transaction, then you will not lose your funds. If you can submit a transaction within a block time, like maybe within a 1 minute time or something like that, you're guaranteed not to lose your funds in spite of an attacker who's willing to spend an arbitrary amount of money front running your transactions.
00:31:02.630 - 00:31:31.818, Speaker A: Awesome. A question for Janice. So as a developer and CTO graph, how has the developer experience been for you to sort of integrate state channels into the wallet API? And I guess it's mostly about how do you think about these libraries just being immediately ready to be imported into your project or just kind of what you're working on as a developer and just kind of how easy they are to use. So we'd love to kind of get some insights into how using state channels in production has been for you.
00:31:31.984 - 00:32:33.290, Speaker C: Yeah, they are not used in production just yet, but they will be very soon. Exactly. So the collaboration started out, I think, with the Saychilds team adding a server wallet into their repertoire because our gateways that we're developing our indexes are both running node JS processes, so that was badly needed. Before that, I think the wallet was primarily targeting the browser, so that was necessary first. After that, the integration was pretty smooth. The interfaces that we now use to the libraries that are maintained by the State Channels team to kind of manage the capacity of channels that we need to handle the throughput in terms of queries are now automatically managed by the state Channels team libraries. And that's kind of the code base that Andrew mentioned is loosely coupled to the graph.
00:32:33.290 - 00:33:14.782, Speaker C: So we have these identifiers for which we need to generate a certain number of or ensure a certain number of state channels, and at some point these identifiers go away and then the state channels need to be closed. So this lifecycle management, I think, is pretty generic. You can imagine that in a lot of other situations as well. So that should be fairly easy to decouple from the graph and reuse in other places as well. Yeah, the cooperation has been really fruitful and the end result is really good. Well, wouldn't say end result yet because we're still working on those horizontal scaling improvements. But yeah, overall it's been a really good experience.
00:33:14.782 - 00:33:32.514, Speaker C: And from the first moments that we talked to the Stage team about their design, their approach, and how they wanted to move everything that's not that's potentially slow out of the critical path and so on, everything made sense pretty much from the start and that was really nice.
00:33:32.712 - 00:34:05.550, Speaker A: Well, that's a wonderful testimonial for all the work the Sage Town theme has put in the last two years. And maybe I'll just kind of close off with another question, which is a lot of hackers here for the hackathon this month that are planning to do scalability and integrate that in any L2 solutions in their projects. So kind of having used state channels for the graph, do you think the SDK and the Stage Channels project is at a place where almost everybody can just import that and get a very high thousands of PPS built into their projects? Even if it's for a hackathon?
00:34:08.610 - 00:34:36.150, Speaker C: I think that's more a question for Andrew to answer. I think what you will need for that kind of scale would be to have these libraries more generalized. I mean, you can manage your channels manually, you can scale them up yourself. That's not too hard. But yeah, those libraries that manage the channels on both ends, that will be pretty crucial for everyone to reach that kind of scale.
00:34:37.230 - 00:35:16.770, Speaker B: I think that's right, yeah. Unfortunately, it hasn't been able to be a priority to get this stuff out to be usable to the community. We're sort of running at a pretty breakneck pace trying to meet the scale that the graph. Network is going to run at, and it's our priority once we do that, to release these tools to the developer community. So I regret saying it, but I'm not sure that it would be ready for a hackathon that's ongoing this month.
00:35:16.920 - 00:35:35.000, Speaker A: No worries. I think this is just a milestone for all of us to kind of achieve, and especially as it gets integrated into the graph at the scale that they're waiting at, I think this is just a good recipe for others to take from. So thanks again, Andrew and Janice, for an amazing presentation and answering my questions. I still have.

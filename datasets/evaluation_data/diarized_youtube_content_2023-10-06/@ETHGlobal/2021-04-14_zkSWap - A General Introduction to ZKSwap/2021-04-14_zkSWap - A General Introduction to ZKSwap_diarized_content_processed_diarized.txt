00:00:00.090 - 00:00:00.522, Speaker A: Seconds.
00:00:00.586 - 00:00:11.570, Speaker B: Yeah, actually wait, hold on. Let me turn on my okay.
00:00:14.420 - 00:00:35.050, Speaker A: Great. Welcome everyone, to the ZK Swap and a quick introduction to ZK Swap. Taking the session today is Howard you? And with that, I will pass it over to Howard to give a quick introduction to himself and share his screen to kick the workshop off.
00:00:35.500 - 00:00:50.030, Speaker B: All right. Hello everyone. Thanks for joining the workshop. I hope you're having fun so far at the global hackathon. Wait, can you see my screen?
00:00:52.420 - 00:00:57.810, Speaker A: Yes, you might want to just put it into full screen.
00:00:59.380 - 00:01:10.710, Speaker B: Full screen, new share. What do you see over there? Should be sharing the whole screen.
00:01:12.920 - 00:01:24.280, Speaker A: Yeah, you're not sharing the whole screen. I can still see your desktop background and then a window open with ZK Swap wiki.
00:01:24.940 - 00:01:35.150, Speaker B: Yeah, that's it. Okay, I think that's it. I'm not showing the slide. So can you see the slide now?
00:01:36.240 - 00:01:39.020, Speaker A: No, I'm still seeing ZK Swap wiki.
00:01:44.160 - 00:02:14.850, Speaker B: Choosing the whole desktop. Sure, we can see the slide. Just maximize your browser window. Do you see the slide now? Okay, now I'm the Wiki. Is this okay?
00:02:15.300 - 00:02:16.610, Speaker A: Yeah, that's perfect.
00:02:17.860 - 00:03:07.468, Speaker B: Okay, sorry about that. Thanks everyone, for coming. Yeah, I think the whole rollout system is moving really fast and the whole layer two ecosystem is evolving very quickly as well. So I really have to apologize for the lack of documentation and probably inaccuracy in the documentation as well. So some of this may be a little bit confusing because it is confusing because the parts are changing. So if you guys have any questions, just interrupt me in the middle and I'll try to answer it the best as. So I am the smart contract engineer at Decadeswap, so I mostly handle the smart contract component of decayswap.
00:03:07.468 - 00:03:53.820, Speaker B: So there's really quite a bit of stuff I don't really understand myself. I'm not super familiar with how the zero knowledge proof system works, so I just know some basics. I'll try to answer and probably relay some of the questions to the technical team, but I'll just try to do my best. So maybe a little bit of overview of our project. So it's one of those layer two token swap protocols, is an am on layer two, and we launched in February this year and we have about 20 people on our team. And so far we have 1.5 billion in TBL and about a billion dollars in liquidity.
00:03:53.820 - 00:04:36.824, Speaker B: But we do about 150,000,000 in trading value in a day. Doing pretty okay. We have a payment and we can do liquidity mining on layer two. And we also have swap and based on CK roll up. So it's using validity proof instead of proof, and all the data necessary is on chain and there's no exit period. So pretty much the property of decay rollout. And we've done a lot of optimization on the proofing speed and the data storage requirements.
00:04:36.824 - 00:05:51.700, Speaker B: So so far we've managed to get it to about 100 times the capacity and throughput of layer one ethereum and the gas cost per transaction is about one 50th of what it costs on layer one. And for users, the interaction is pretty much instantaneous. If you have played around with the Mayor two applications before, it's really quite a game changer in terms of the technical challenges we faced, it's really having to do with the Digger knowledge system. The complexity of the Digger knowledge proving system is directly proportional to the complexity of the application logic. And in our system we implemented the an at the circuit level, so we had to do a lot of data compression and try to make the data as small as possible. So the circuits just directly proportional to the size of the input as well. So a lot of complexity in the input would also sort of recursively precolate down to the circuit level as well.
00:05:51.700 - 00:07:06.364, Speaker B: So there's a lot of optimization opportunities in terms of the design of the data structures and we've done quite a bit of work on the proof generation itself as well. So we had a GPU implementation of the Plunk algorithm and the TBS reaches above 100 and we improved the implementation by three times and there's still quite a bit of room for improvement as well. So we started working on this since last August, so we haven't finished all of our optimization ideas yet. I think the proof team is saying they probably have another five times improvement that's possible. We'll see if that happens. In terms of optimization technique, another big area is the aggregation proof where we take instead of generating one proof per block, we combine multiple blocks into the same proof and on chain we could just do one verification for multiple blocks. So that saves quite a bit of gas as well.
00:07:06.364 - 00:08:12.752, Speaker B: And with this improvement, we are looking at about 1400 gas per transaction. So most of the gas cost is really on chain data and just verifying the ZK proof. As I said a little bit earlier, the aggregation proof helps quite a bit. And in terms of our roadmap for 2021, we're looking to support user listing of tokens just probably later this month or next month. So one thing about token listing as well, there are hard limit in the circuit as well. So I said earlier that data complexity, data structure complexity is a big issue. One optimization technique in the CK roll up system is using token ID instead of token addresses.
00:08:12.752 - 00:09:02.964, Speaker B: So on Ethereum you can essentially launch infinitely many ERT 20 tokens and each of these tokens will have their own address and that's fine. But in decade roll up system, because the token IDs we can only support like 16 bit of token IDs. So that's much lower limit for the number of tokens that's possible on the system. And this is really because of the circuit complexity. As we mentioned earlier, this cordero is still working on optimization for the proving system. So there's still quite a bit of improvement there. And we are seeing some bottleneck in the proving system.
00:09:02.964 - 00:09:58.310, Speaker B: So when we were doing our liquidity mining program, our system was congested just because the proving system couldn't catch up with all the demand. And we'll also probably do governance token this quarter as well. Coming up we'll be doing a stable coin swap on layer two, something like curve on layer two as well. We'll be working with exchanges and businesses in Asia and internationally to integrate our payment system into their wallets. So also providing on end services for exchanges and then going even a little bit further. Well, we'll be working on General EDM on there too. We can have DeFi composability on our system as well.
00:09:58.310 - 00:10:58.970, Speaker B: Yeah, and for the hackathon, so we'll be looking at probably for the community to try their hands on building arbitrage tools. So just maybe looking at prices on decay swap and compare the prices on their centralized exchange and try to do arbitrage there. I think there's quite a bit of arbitrage opportunities. And one interesting property of our system is the LP tokens. Even though the liquidity exists on their two, we also issue corresponding LP tokens on their one. So there's probably some interesting things you can do with these LP tokens. So maybe you could use them as collaterals for different lending products or build derivatives on top of the BLP tokens so we'll see what sort of ideas the community would have.
00:10:58.970 - 00:11:27.730, Speaker B: Yeah, and this is sort of our social media, as you would expect. There's the Twitter DK swap official and also like the Telegram group, the official Telegram group. So you have questions and ideas you could probably DM these groups. So this was a quick overview of our project, if there's any, we can probably take some questions before we move on.
00:11:33.780 - 00:11:49.690, Speaker A: Yeah, thanks. Harlow. Yeah, there was a question from YouTube, but I do see that a representative from Zkswap is answering that in the YouTube chat as well. I did paste it in the chat channel here.
00:11:50.060 - 00:12:01.470, Speaker B: Okay, let's see where's the chat can you maybe read a question?
00:12:05.760 - 00:12:22.130, Speaker A: So is it not 100% ZK roll ups and it is validity? It was announced that a separate 100% ZK roll ups would be released mid March, but there is no separate product. What implement is ZK swap currently?
00:12:25.460 - 00:13:30.568, Speaker B: I think there are different security properties. So there's the data availability problem and there is also the transition, let's say the transition security. So transition is about doing following the rule of the system and there's no way to cheat. So as far as that part is concerned, we are fully secure and data availability is more about whether you could sort of recover the system if we go down. So if we just sort of nuke our servers, then there needs to be a way to use on chain data to recover it. So right now there are some data we couldn't recover because this data is not on chain, but theoretically this data could be backed up somewhere else and you could use that data to recover. So you could put a backup on filecoin, then you can recover from filecoin, something like that.
00:13:30.568 - 00:14:11.380, Speaker B: But in terms of security and safety of the fund, there's nothing to worry about. It's more about recovery, but coming up, the plan is to launch to provide full recovery as well. So that's probably not going to be an issue going forward. But we're also considering different ways to provide the same cheaper ways to provide the same data availability properties. That's something that's still sort of floating around even in the ecosystem at large. So that's one area that's still being explored.
00:14:13.480 - 00:14:20.920, Speaker A: Okay, cool, thank you. Another question is where are ZK swap servers for l two computation?
00:14:22.620 - 00:14:23.610, Speaker B: I'm sorry?
00:14:25.260 - 00:14:29.660, Speaker A: Where are ZK swap servers for l two computation?
00:14:31.760 - 00:15:14.360, Speaker B: Who's providing the services? Is that the question? Who's providing the proofs? The proving computation? Yes. Okay. Yeah, right now the proving system is just we are providing the proofing computation. It's quite hardware intensive. So the DK swap protocol, we have lots of machines doing the proving. Yeah, I mean, that's pretty much the answer. And there's really no way to decentralize this either because the proving needs to be serialized.
00:15:14.360 - 00:15:39.680, Speaker B: So it doesn't really make sense to have a cluster where you distribute the zero proofing process. Otherwise you are really just redoing the proofs across the cluster. I'm not really sure if there's a good way to decentralize this mechanism.
00:15:44.180 - 00:15:44.496, Speaker A: But.
00:15:44.518 - 00:15:57.210, Speaker B: Then again, the security of the system doesn't depend on whether the proving infrastructure itself being centralized or not. So it's really more an availability issue than anything else.
00:16:00.380 - 00:16:25.024, Speaker C: So I'm Natalie from Ziki Swap. I would like to jump in for the previous question about the 100% ZK roll ups. We have actually updated to the full ZK roll up version on March 22 and you can check it on our Explorer Zkswap info and all data availability is on chain right now.
00:16:25.222 - 00:16:31.010, Speaker B: Okay, cool. Yeah.
00:16:31.960 - 00:16:43.060, Speaker A: Maybe we just do one more question before you continue. And that question is, do you plan to support ZK Swap with tokens from multiple EVM compatible.
00:16:50.220 - 00:17:50.524, Speaker B: Cross chain? Bridging is a whole kind of work in itself, so as long as there's ERC 20 on their one. Ethereum, however, is created either through a bridge or through some sort of cross chain issuance. There's a lot of DeFi protocols going on where they launch different versions of their own protocol on different EVM chains. And on each chain, effectively there are siloed tokens of the same protocol. So as long as there are tokens on Ethereum, then we are happy to work with different chains. As far as, like as far as crossing different layer twos, I think that's still in the air and nobody really knows how it could work. There could probably be bridges between different layer twos in the future.
00:17:50.524 - 00:18:25.210, Speaker B: I think there are projects working on that. I think it will happen in the future for sure. We also have EVM compatibility planned on our roadmap, so once that happens, I think it will be easier to build bridges between different layer twos. But so far, you really have to go through layer one. Yeah.
00:18:27.420 - 00:18:32.280, Speaker A: Thanks. Yeah, I think you can maybe continue with the rest of the session.
00:18:32.620 - 00:19:17.956, Speaker B: Yeah. As I said in the beginning, a lot of the documentation is really quite rough right now because we're just working really hard on the features. So there's some basic APIs where you can get a list of supported tokens, like account info and account balance. These are all there too. All the data queries are pretty straightforward, so I'm probably not going to get into too much details about all these list of transactions. This is pretty much like the API that DK swap Explorer uses. I think these are pretty straightforward.
00:19:17.956 - 00:20:21.740, Speaker B: So I'm going to spend more, maybe a little bit more time, dissecting the structure of layer two transaction and the process of creating a layer two transaction. So there's like one API, one post API for creating and submitting layer two transactions. And it's the same API for different operations. I think the main operations are swapping tokens, adding liquidity, removing liquidity and sending transferring to recipients. And these are all using the same Restful API. But the transaction structure will be different for all these different operations. This is the documentation for the Restful API and for making transaction.
00:20:21.740 - 00:21:19.744, Speaker B: Here's a document that sort of walks you through how layer two transactions could be constructed. So first we start with crossing from layer one to layer two. This is a matter of depositing some money, calling the API contract, the contract API methods, and depositing some fund into the decay swap contract that will be picked up by the system. And a corresponding balance will be created on layer two. So this is pretty straightforward layer one operation. Yeah. So we'll just move on to the interesting part.
00:21:19.744 - 00:22:15.420, Speaker B: So this is just like typical Ether JS thing. You load the DKS contract, then you load your wallet and then you just call the method the Deposit ERC 20 method to deposit the money onto there, too. So that's pretty straightforward. It takes about 20 minutes, 1520 minutes for this to complete. And on layer two, the way layer two works, the layer two system uses a different set of key pair and uses different cryptographic primitives than from layer one. We have to generate a private key on the front end. And the private key for layer two is generated from a signature.
00:22:15.420 - 00:23:14.550, Speaker B: So you actually use the MetaMask wallet to create a signature and using the signature as the seed for the layer two private key. So the layer two private key is deterministically generated from layer one wallet. So this is like the process of how you generate that. Yeah. And you have to register the generated private key with the layer two system because for every account on layer two you are assigned an account ID. The account ID is actually limited, I think that to about 40 billion accounts. So there's like an opposite to how many accounts there could be.
00:23:14.550 - 00:24:13.088, Speaker B: Again for data compression reasons, for efficiency, data efficiency and circuit efficiency. Once you generate a key and you register with the layer two system and then for every operation you make, you use the generated layer two private key to sign the transaction. So here's the code that signs a layer two transaction. So you use the private key generated above and then all the transactions are actually just concatenated bytes. So for example, the first byte will determine the operation. The operation will be either transfer, swap, adding liquidity, removing liquidity. So the first byte is the operation.
00:24:13.088 - 00:25:29.064, Speaker B: And then for each operation it's just a series of bytes of the data that operation needs. And we have some missing documentation here because we are still working on some parts of it. But we have an example of swap transaction on there too. As we said, the transaction is really a sequence of bytes. And for the swap transaction, the very first byte is the swap operator. So it's like the type stands for swap and then just a sequence of different sequence of the necessary parameters from which layer one account to which one layer two account and then the token amount in, token amount out, et cetera, et cetera, the chain ID. This is for security reasons to prevent replay attack on different, possibly different layer two chains, possibly different layer two systems on different chains.
00:25:29.064 - 00:26:34.700, Speaker B: So you could theoretically have a layer two system on say, finance chain. But if the layer two system doesn't have a chain ID, then you could possibly replay binance chain layer two on the ethereum chain, layer two. So the chain ID is there to prevent that happening. So this is a sequence of the succession data necessary. And then you concatenate everything into one byte that you create a signature of this bytes. Then you just pass in the whole thing as a JSON structure to move to the API, to the restful API in the previous page. This is really the data that goes on layer two and then be packaged into a layer two block.
00:26:34.700 - 00:27:40.068, Speaker B: Then that will be approved, will be generated and submitted on layer one and verified. And there's one extra thing for sort of usability and security, but it's not really relevant to layer one. So we actually generate the layer two private key in the web application. So theoretically user could just click a button and then just send the transaction immediately without having to go through MetaMask this thing here. So we actually still sign message with MetaMask wallet. So this is really just to give a feedback to a user. So when the user clicks a button, then a MetaMask request, which is the MetaMask wallet, will pop up a request prompting the user whether a signature should be provided.
00:27:40.068 - 00:28:30.024, Speaker B: But this signature is really not necessary for the security of the system. It's really to provide that experience of user confirming something. And the other possible security issue is, suppose there is an injection into the website. Then it's possible that the injection just creates malicious transactions onto layer two and the layer two system. We don't know any better. This message is also a way to double verify that a transaction is both verified by a layer two key and by a layer one wallet. So this way we can sort of mitigate the possible risk of an injection attack.
00:28:30.024 - 00:28:48.670, Speaker B: But this is really not strictly necessary for the layer two smart contract. And if you go into the smart contract, you wouldn't see anything related to this signature. Yeah, that's pretty much all I had to share.
00:28:48.980 - 00:28:49.840, Speaker D: Just jump in.
00:28:49.910 - 00:28:50.528, Speaker B: Sorry.
00:28:50.694 - 00:29:09.750, Speaker D: If you go a bit up to the JSON file that you showed yeah. How would you go about generating this whole JSON file? Using the simplest way possible. What extension would you use? Would you use webfree JS? And how would you get that?
00:29:10.280 - 00:29:41.570, Speaker B: Yeah, we are preparing an SDK. Before that's ready. You just really just kind of cobble together something by yourself. But I think we'll have an SDK quite soon. In a week or two. When that's ready, you just import the NPM package that you have. You can just use the API that way.
00:29:41.570 - 00:29:47.650, Speaker B: Yeah. Does that answer the question? Yeah. Thanks.
00:29:48.740 - 00:29:51.660, Speaker D: How would you generate a signature, then, without the SDK?
00:29:51.820 - 00:30:19.240, Speaker B: You would just sign using the covered boxes. It's really quite primitive. There's the DK sync crypto So we use the same cryptography as DK Sync. Right. Then, as I said, you concatenate the transaction data into one message, one buffer, then you sign it with the CK Sync cryptography. So you could do it just by hand in your script. Oh, okay.
00:30:19.240 - 00:30:42.930, Speaker B: Thanks. If you're just doing some sort of arbitrage, then this is actually pretty straightforward. You don't need to wait for the SDK, do it? It's probably like thousands of lines of code, so it's not that bad. Still kind of ugly, but it's not too bad. Yeah.
00:30:45.160 - 00:31:13.720, Speaker A: Great. Thanks so much, Howard. I really appreciate you taking everyone through that session. If any of your questions weren't answered in the chat, I will be posting them in the ZK Swap Sponsor channel and the ZK Swap team will reply there. But thank you so much. And Howard, if there's anything you'd like to close off with otherwise.
00:31:15.980 - 00:31:17.000, Speaker B: Good luck.
00:31:20.460 - 00:31:23.520, Speaker A: Great. Thanks, Howard. And thanks, everybody for joining.
00:31:24.500 - 00:31:24.910, Speaker B: Thanks for.

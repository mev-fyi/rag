00:02:18.210 - 00:03:05.538, Speaker A: All right, welcome, everybody. My name is Kartik. I'm one of the co founders of Eve Global, and we are here today for day three of Hackaths Judging. And for those of you who don't know, especially the ones watching this recording, after Hackath Fest was an event we did in partnership with Protocol Labs Global. And over the past month, we've had 470 hackers from over 50 countries working across 19 different time zones working towards building projects that use the best of tools and technologies from the Ethereum under the File Coin ecosystem. And just about three days ago, these 470 hackers submitted what they worked on for the past month. And we kicked off this whole week of judging and demos.
00:03:05.538 - 00:04:08.858, Speaker A: And we're super excited to announce that we've had 130 projects that have come out of this event, and we're taking this entire week showcasing and demoing these projects and giving them the opportunity to tell everybody else about what they worked on and share this thing with our judges and our sponsors. So before we move into these demos, I want to do a quick logistical overview of not only how judging itself and how this call is going to go, but also how generally the event itself was set up. So the logistics of today are fairly straightforward. We're going to have about 13 teams, where each team will have about four minutes to demo what they built, and we'll have a four minute session on Q and A. And just to make sure and minimize any AV issues, we've asked all the teams to prerecorded their demos so they'll be playing those demos pre recorded as they come on and move into a live Q A with our judges. A quick overview on how the event itself was set up. Each project you'll see could be worked on with a team of up to five people.
00:04:08.858 - 00:05:16.270, Speaker A: A lot of our team projects chose to work on them independently and by themselves, too, and that's totally all right. And all code you're going to see today was written over the course of this event. And the only criteria we had for a submission to be valid was that they must incorporate the tools and technologies from the Protocol Labs and Ethereum Ecosystem. So we have a really creative mix of the best of what you can do with decentralized storage and smart contracts, and we're super excited for everybody else to also see what our hackers and attendees worked on over the past month. A quick overview on how judging itself is structured. Our judges will be rating our projects and teams on these five categories, so they'll be looking at how technical, original, or practical a project is, along with how easy it is for somebody to use, whether it's a web app or a developer tool. And the last one we call a category factor that lets us incorporate anything we might have missed from the categories above and help understand and do a catch all for things that may not be fully covered in the four sections above.
00:05:16.270 - 00:06:02.974, Speaker A: And before we kind of move into this demo, I want to just emphasize that this event is not a competition. The hackers are very much here to learn, and they're here to share their excitement and show you what they have been able to do over the past month. And the judges are here primarily to give feedback and understand what you wanted to do and how you can take it to the next level and just make that even better. And not everybody is here trying to become business. So although you'll see certain things that are going to be definitely becoming commercial over time, the goal for us is to encourage experimentation. And that's kind of how we like to emphasize every event, because we want other students to understand what is possible in the world of web3. So with all of that, these are the teams that are going to be presenting today, and we're going to be demoing them one by one.
00:06:02.974 - 00:06:49.886, Speaker A: And we'll also have a quick break halfway through the demo so our judges and everybody else can rest for a few minutes. And doing the hard job are our three judges. And I'd like to welcome Lasse Clausen from one KX capital. We have Jimmy Lee or Cake from Protocol Labs and Aiden Hyman from ChainSafe, who will be doing the hard job today to really kind of learn about what everybody did and give their feedback and share the excitement with all of our hackers. So with all of that, I want to kick off our very first demo for today, and I'd like to welcome team Geoweb to come on and share their demo. So I'll let Geoweb kick it off from here. Hello.
00:06:49.886 - 00:07:27.622, Speaker A: Welcome to the hackfs demo of the Geoweb project. The Geoweb is a new type of web experience that's navigated by geolocation on the Geoweb, as you move through the world with a smart device, content is discovered and served based off your physical location. It can function like a metaverse covering earth's surface. Potential use cases span from simple notifications and data feeds to augmented reality. Our digital land registry and Harburger smart contract are built on ethereum. Content for our demo is stored and retrieved with IPFS, but naturally, we could also support a filecoin integration. Our digital land registry is the DNS of the Geoweb, but instead of domain names, it maintains land parcel ownership.
00:07:27.622 - 00:07:53.038, Speaker A: Digital land parcels are NFTs. They grant the owner the exclusive right to anchor content within their boundaries. The Harburger smart contract administers the Geoweb's digital land market. A Harburger tax is a market structure with two basic rules. First, property owners pay a tax based off the self assessed value of their property. Second, anyone can force a sale by paying the owner's self assessed property value. It's an elegant way to administer a market with minimal centralization.
00:07:53.038 - 00:08:18.938, Speaker A: It also has the nice side effect of generating tax revenue that can be used to support the network and other public goods. Here we have our demo registrar UI. You can go check it out yourself. At Geoweb ETH, we're using MetaMask for user ID and wallet functionality. Land parcels claim in the registry show on the map as markers. I actually own the land out here in Denver, so let's go check that out first. This is the detailed view that you'll see when you click on a land parcel that you own.
00:08:18.938 - 00:08:39.902, Speaker A: The items of note are the owner assessed value and the CID of link content. Both are editable here. You can also click through on the CID to see the content. In this case, it's a draft of the Geoweb light paper. Check it out if you're interested in learning more. Now we're looking at a parcel that I don't own here. The link content is the COVID-19 policy for a restaurant.
00:08:39.902 - 00:09:02.106, Speaker A: We'll come back to that in our next demo. Someone else owns this land. Currently, that means I can't place content inside the parcel boundaries, shown here in red. It's similar to property rights in the real world, but I can always buy the land on the Geoweb. I just have to set my new price and submit the transaction. Note that the previous owner only gets paid their selfassessed price, not mine. And finally, let's claim a new parcel of land.
00:09:02.106 - 00:09:27.954, Speaker A: We're using a single Geohash to define land for now. So I can just double click anywhere on the map to pick my parcel. I set my value, associate some content, and claim the parcel. We didn't set a minimum claims value here, but in a production system we do auctions or have a claim fee. Now that my transaction has gone through, I'm the proud owner of some more Geoweb real estate. Let's walk through a simple Geoweb user experience. We're going to simulate walking up to the restaurant that we saw in the last demo.
00:09:27.954 - 00:09:59.722, Speaker A: The owner of this land parcel, presumably the restaurant owner, has decided to link their COVID-19 policy on the Geoweb. As we enter the land parcel, we get a push notification and content is automatically resolved on our phone and watch browser apps. Next, let's walk over to a nearby park. What's there? A picture of a cat on a bench? Why not? Geoweb users don't need to take any extra action other than moving throughout their day to discover useful content that they might not have even known existed. These aren't siloed apps. They're all part of a unified open web experience. We started with simple text and image content.
00:09:59.722 - 00:10:43.334, Speaker A: But as the Geoweb ecosystem matures, new schemas and browsers can be developed to support any digital experience that builders can imagine. Finally, let's go back to the restaurant and see our COVID-19 information to close the loop on the demo. In isolation, these use cases may seem trivial and can be accomplished with other methods, but as you zoom out to the network level, the value of the geoweb's open frictionless experience becomes apparent. Smartphones put the Internet in our pockets, smart glasses and the next generation of smart devices will put the Internet in our field of view, and it will radically change our relationship to it. We're building the geoweb for this future, and it's grounded in our user first Ethos and web3 technology. On top of that, we believe we can structure the network economics to support public goods and pro social aims. Thank you for taking the time to check out the geoweb.
00:10:43.334 - 00:11:17.430, Speaker A: We look forward to any feedback and questions you may have. Wow, pretty cool. Awesome. So I'll let the judges take it from here and have them just kind of ask any questions they may have. The app sort of the push notifications that I could get. Is that an SDK or are you planning to make this like a proprietary app? Yeah, that's a good question. I think for the hackathon, we're focusing on the registry component, and this demo was really made just to show off what could happen.
00:11:17.430 - 00:12:05.880, Speaker A: But we imagine maybe we could build SDKs for multiple third party apps to use. Or perhaps you could have multiple browsers so we look analogous to web browsers. Like there could be Chrome, Firefox, there could be multiple independent parties that create their own browsers. But SDK is an interesting idea too. Yeah, generally it's pretty hard to get to drive users into your very proprietary UIs, so it makes sense if you're able to go to a lot of other UIs via SDKs, et cetera. Yeah, for sure. I think with focusing on the land registry, trying to build out that infrastructure, then hopefully build an ecosystem around that that other people can build awesome stuff on.
00:12:05.880 - 00:13:30.358, Speaker A: Do you see there being an issue in that? I can dictate what the policy is for a restaurant just by buying their land from them. Yeah, it's tough. There'll definitely be questions about identity and who controls what. The goal, hopefully is to build enough network value that people want to own their own land. And essentially the Harburger contract always opens the opportunity for someone to buy it, whoever is willing to pay the most. There's obviously reasons people could do that for bad purposes, but if we introduce some friction for bad actors with decentralized identity and then provide users easy ability to block, say, a parcel of land or block a certain user, then hopefully that essentially deincentivizes people from trying to buy land and do malicious actions with it. Do you think that to achieve what you're describing, you would need to basically change the economics of it and not have it be a harbor tax? Plainly put, to keep it as a decentralized administration? That's the best we've come up with with Bitcoin.
00:13:30.358 - 00:13:55.720, Speaker A: Obviously people believe that it has value and they therefore invest their mining power to it. In our case, it's not mining power. It's like you have to pay your harbor tax to protect your piece of land. So obviously we're banking on economics and incentives to make it feasible. Thank you. Great job, guys. It's awesome.
00:13:55.720 - 00:14:38.322, Speaker A: Are you guys using IPFS to store all that policy information and also locations as well? Yeah, so everything you saw is stored in IPFS. The mobile demos themselves are just looking up the content through IPFS gateway. We did experiment with using an actual IPFS node on iOS, but the end demo didn't have that. But yeah, right now it's all pinned on Pinata and stored in IPFS. Very cool. Great. Thanks so much, Geoweb.
00:14:38.322 - 00:15:06.702, Speaker A: If there's no more questions from the judges, we'll move on to project Web Three API. If you guys could share your screen. Yeah, sure. Coming right up. And please just holler if you can't hear the audio. Web Three API is a developer tool chain that brings the ease of Web Two to Web Three. Integrating Web Three into your applications today is difficult.
00:15:06.702 - 00:15:43.654, Speaker A: App developers and protocol developers are slowed down by the need to be in constant coordination to maintain compatibility. JavaScript smart contract SDKs limit DApps to just the browser prebuild steps hinder developers ability to build dynamic applications. And lastly, JavaScript limits performance and creates attack vectors. We can do better. We built a Web Three WASM runtime for universally compatible smart contract APIs. This allows protocol developers to implement user friendly wrappers in a language agnostic way. These WASM modules paired with a subgraph or historical data querying combine together to create a single GraphQL schema that defines the entirety of the protocol.
00:15:43.654 - 00:16:09.010, Speaker A: We call this GraphQL schema a web. Three API. Web Three APIs live on IPFS and are addressable using ENS. They can be queried from any language or platform node. Browser, c sharp, C plus, plus, rust, Go, Python, you name it. DApps only need to include our lightweight client to query any Web Three API. In summary, Web Three APIs instantly integrate into your applications, run on all devices, and interact with your favorite peer to peer protocols.
00:16:09.010 - 00:16:37.370, Speaker A: Here we have the web3 API. CLI. This command line tool allows you to manage a test environment, query Web Three APIs, and also build and publish a Web Three API. First off, we'll make sure that we have a test environment set up for us to use. So we say W three test environment up. If we look in the background, we have lots of different docker containers that are already running. These are representing our different peer to peer protocols that our Web Three API will be talking to, like IPFS, the graph, and ethereum.
00:16:37.370 - 00:17:18.410, Speaker A: Next, we'll build our package. And so first off, we need to build and publish the contract. And so now that we have the test environment set up, let's build and publish the contract like you normally would with Truffle, Ethers or Biddler. And then lastly, we will build and publish our Web Three API. What this command is doing is it's compiling the WebAssembly modules, and then it's building the subgraph. And then lastly, it's uploading it to IPFS and ENS. When all is said and done, it prints out some handy Uris that we can use to go and further inspect our package that's been published.
00:17:18.410 - 00:17:49.118, Speaker A: Here it is. On IPFS, we can see all of our files and these files, as you can see, the Web Three API, these files are identical to our Protocols Build folder. And so now that we have it all published, let's actually use it. And so normally, you would write your tests in, let's say, JavaScript, and you would run it with Jest or some other test runner. But we developed something that we think is a little easier to get up and running with. So with this command, we will execute a recipe, a query recipe. It's written in JSON.
00:17:49.118 - 00:18:30.638, Speaker A: And what it does is it makes different queries to the protocol. Here you can see gets and sets made to the contract. Here are your transaction receipts and the value returned from the view functions. And then lastly, we have a query to the Graph where it's going to fetch the historical data that's been cached in the Graph node. All of this in this small little app package where you can just define your contracts, mutations, queries, and your subgraph and publish it all as one. Through the magic of Webassembling GraphQL, we're able to bring smart contract protocols into applications with lightning speeds, all with minimal technical knowledge required. Any developer armed with a Web Three API, client and CLI are ready to traverse the world of Web Three.
00:18:30.638 - 00:19:26.222, Speaker A: We now have a blazing fast DevLoop, multiplatform support, dynamic applications, and secure and efficient SDKs executing inside of a WebAssembly virtual machine. Here's where it's currently at in development, client applications can fetch, parse, and execute Web Three APIs using a combination of ENS, IPFS and GraphQL and WebAssembly, the WebAssembly Smart Contract APIs executing in the client can communicate with PeerToPeer networks. And we have the startings of a user friendly CLI that allows developers to easily build, test and publish their APIs. Here are some things we're planning on in the immediate future. And here is our current North Star Web Three hub, a place for developers and users alike to come, discover, use, and fork Web Three APIs for their specific needs. Web Three hub will allow users to visualize the GraphQL schema of the API they're looking at, query the API in its entirety, and lastly, publish User friendly Dashboards at the drop of a hat. Thank you so much for listening.
00:19:26.222 - 00:19:50.074, Speaker A: This has been Web Three API presented to you with love from Diorg. Come help evolve Web Three with us, and hopefully we'll make the world a better place. Great. I guess we'll turn it over to the judges for some questions. Just nice. Very nice demo. Very cool, awesome, thank you.
00:19:50.074 - 00:20:21.702, Speaker A: And yeah, we kind of didn't show a lot of the code for a reason to make it more digestible, but if you'd like me to pop open that project and show you what the Web Three API actually looks like, I can do that for you. Great work. Really awesome. Sweet. This is going to open up a ton of possibilities. Yeah, definitely. That's the whole goal because currently people are writing their wrappers for their protocols in JavaScript.
00:20:21.702 - 00:21:20.434, Speaker A: And if someone wanted to build, let's say, like a game at Unity and C Sharp, or write some server side application or anything else, they'd have to kind of rewrite the integrations for how to use Uniswap or let's say like Dai or something like that. Because we all know that smart contracts become a bit more complex as you get to optimizing them and you really kind of need this application layer SDK. Cool. Do you have any plans to take this project further? Absolutely, yeah. So if you visit Web threeAPI dev, there's a mailing list that you can sign up for there. What we're planning to do is gather initial charter customers to where we can talk to existing protocols, see how we can best support them, and basically implement a Web Three API for them. And then that'll kind of harden the standard, harden the tool chain.
00:21:20.434 - 00:22:13.270, Speaker A: And once we have a few protocols, then we'd like to onboard more and more DAP developers and lastly launch the Web Three hub where we're planning to host all of these. And the Web Three Hub will be something where you don't have to publish to it like, let's say a GitHub repo. You have to make a GitHub repo on GitHub. Since all of these Web Three APIs are published on ENS, you can simply just use the Web Three Hub to view your Web Three API that's published permissionlessly on your own ENS. And then the cool thing with the Web Three Hub is to be able to have dashboards. So this will allow you to in markdown, basically say, here is my list of users, and then here's kind of the associated query with it, and then maybe here is on each user I want a button to be able to add rewards to them. And here's the query that that button invokes.
00:22:13.270 - 00:23:24.574, Speaker A: And the whole goal is to be able to create user interfaces for your users without having to create the UI yourself so that protocol developers can just author this markdown, author these queries, and then these dashboards are ready for their users with their protocol. Cool, and if you'd had a little bit more time in this hackathon, what more do you think you would have done? Yeah, so there were a few shortcuts taken in the JavaScript client that we had developed, namely supporting web workers, because currently the Asynchronous fetching and WebAssembly is done using nodes, workers that aren't browser compatible. So anyway, making it browser compatible, and then secondly, creating the Python client so that we could show you a demo of how this is actually multiplatform. Great, thanks. It sounds really great. Next up we have Project Vpgill. If you guys wouldn't mind sharing your screen and kick off your demo.
00:23:24.574 - 00:24:30.528, Speaker A: Thanks so much, Jordan. My name is Aaron looning and I am Team VP Guilds. And this is my Hack FS 2020 submission. VP Guilds is a decentralized social media community platform currently hosted on Fleek, built with Near Protocol and Textile Hub threadsdb. How it works It uses near accounts as textile identities for Textile gets associated with the Lib P two P identity that is used to receive a Textile Token to create user and app level threads using textile threadsdb in order to ensure ongoing access to user and app data. In the event that browser local storage is cleared, the Near Account Lib P two P Identity and Textile Thread IDs are encrypted and stored in the near chain inside the DAP. The near contracts link and store unique ideas on chain to content, comments, profiles and so on, and Textile Hub collections and records set up to store the actual data on IPFS.
00:24:30.528 - 00:25:18.020, Speaker A: And finally, it's all been deployed to Fleek, which I have to say was an absolute uncomplicated pleasure to do. Welcome to the community platform for Vital Point Guild. We're going to log in using our near account authorizing vital point, Guild. Once logged in, we'll head over to our profile page and set some basic profile information. The profiles will be extended in future, and of course we have the ability to delete edit as necessary, which updates the records being stored in IPFS through Textile. Heading back over to the home page, I want to post my monthly Guild Contribution Report standard form publishing toggle date selection full Editor with support for image and video. Once submitted, the unique post ID is stored on chain, pointing to the textile record, holding all the data which has been sent off to IPFS.
00:25:18.020 - 00:25:40.492, Speaker A: Of course need the ability to manage both published content and draft content. This is handled with user and app level threads. When user publishes, record is mirrored in the app thread. If not published, it resides only in the user thread. Adding a draft piece of content is done the same way as published content. Just don't flip the switch. Now notice there are no passwords or signing interruptions in all this.
00:25:40.492 - 00:26:14.136, Speaker A: The keys and identities are managed by the wallet, browser, local storage and encrypted on chain, making the user experience well, fast and recognizable. And the app never has access to any data the user doesn't want to share. Further, if they did share and change their mind down the road, they can delete it and it's gone. Communities are no good if it's just you talking to yourself. So let's log out and log in as another user again. We'll set up some profile information like threebox does for Ethereum. We'll probably evolve to see that profiles become a composable component, such as only making them available to any DAP on near that wants to use them.
00:26:14.136 - 00:26:42.096, Speaker A: Like a plugin module. Of course, with data stored on IPFS or Filecoin, because we're building on a blockchain, tokens are built in. Notice the user's account balance in a minute, we'll come back to that. But first, let's go leave a comment on our other user's post. Basic functionality one to expect on a community platform. Again, the content is linked by ID to its parent and the data records stored in a textile collection. Cool.
00:26:42.096 - 00:27:10.312, Speaker A: Now there's a conversation happening. Let's get back to the money. So far, this demonstrates basic functionality whereby one user may want to reward another user. I also envision attaching value to likes and other gamification mechanisms. Clicking the button transfers one near, and we can verify it in the user's wallet. Notice that all of these actions are using such minuscule gas amounts that they aren't affecting the overall account balance. As a full featured community platform, it's obviously not production ready yet.
00:27:10.312 - 00:27:42.708, Speaker A: I consider this more of an MVP, proving that this decentralized community platform is possible and potentially inevitable. It will eventually evolve into a fully decentralized white label social media community platform that people can use to grow and engage their communities. Invite you to try it out. Get in touch with me or check out the code on GitHub. Want to thank you for your time and another great Fglobal event with hackfs. Thanks, Erin. Yeah.
00:27:42.708 - 00:28:21.650, Speaker A: Over to the judges for some questions. I'd love to know where you're planning on taking it. Like, do you plan on having a completely open source and having people add modules that they would like to see in their guilds? Thank you. I think you're muted. All right, start again. Yeah, so I kind of built it right now for the guild that I'm trying to run and build the community around that. But yeah, I see making everything so that anybody that wants to run a community can basically take it and build out their community with it.
00:28:21.650 - 00:29:40.830, Speaker A: What was the hardest part about working on this? Pretty much just getting to know how Textile and how near and all those things work. I just got introduced to near at the last F Global hackathon, actually, and I kind of rolled into the ready layer one hackathon. So I kind of saw this as an opportunity to dive into that more. And then when I found Textile, got really excited about what we could do there in terms of kind of replicating what's happening in WordPress with tables and stuff like that, to kind of build these things out pretty easy. Out of everything, what do you think was the kind of the accomplishment you're most proud of out of everything? I think finally getting Textile to work and replicating or giving the app access to the app level thread and the user access to their threads and then kind of replicating that. I understand Textile, I think, is doing more fine grained access control in the future, which will probably make all that simpler. This probably isn't the greatest way of doing it, but it's working for now, and it's pretty happy to get that going.
00:29:40.830 - 00:30:23.372, Speaker A: The other part that was a little difficult, I had no intentions of querying a back end authentication server to get the Textile token or the encryption key in order to encrypt some stuff on near. I never did figure out a way to get around that, but that's kind of something I'd be looking at trying to figure out in the future. Awesome. Thanks. And great music throughout the video. Thank you two for that. Erin, I guess what made you pick NIA? I think it was just opportunity, time, and plus the fact that I'm enrolled in their VP Guilds program.
00:30:23.372 - 00:30:48.820, Speaker A: So I'm trying to build out that community. They currently use a community platform called Tribes or Tribe for their community engagement. And I figured if I'm going to build out something on Near, I'd like to have something built on near to do that with. Great. Thanks so much. That was a great demo. Next up, we have Project Orbit.
00:30:48.820 - 00:31:36.890, Speaker A: You guys can share your screen and take it away. Chad hi, everybody. Hi, there. I'll Quickly. Hi. Hello. Our project is called Orbit, and it's a strategy game.
00:31:36.890 - 00:32:08.080, Speaker A: Our team is comprised of three developers and a designer based in Asia. What we built is a coordinate based map strategy game with avatars, tokens, and interplanetary narratives. How the game works is players use avatars with unique DNA to battle for tiles on planetary maps. Or tokens are mined by owning the tiles. Maps and state are kept on Ethereum, and it's a combination of Risk and Go board games. The game mechanics work like this. One is, you can buy a tile anywhere on the map.
00:32:08.080 - 00:32:58.496, Speaker A: If the tile is already owned, the previous owner is given two X, the price in ETH. Number two, you can take a tile, and this is done by allocating or tokens to surround the von Neumann neighbors on a particular tile. Number three is you can battle. So you can place your or tokens directly into the von Neumann neighborhood of an opposing player, and this results in a Risk roll that is determined by randomness. And also you can do an aerial attack, which is you can attack any particular tile anywhere on the map by allocating your tokens there. Okay, I'll quickly demo our app for you. This is the Orbit strategy game, and the first thing you have to do is you need to create a new avatar.
00:32:58.496 - 00:33:34.800, Speaker A: So I will go ahead and I'll create a new avatar. Let's call her Sarah, and she'll be a female, and I'll change her hair color to blue, and her eye colors eye color will be pink and. Skin color. Boom. Okay, so we create a new avatar, sends a transaction to the network, you confirm it. This is an ERC 721 token with unique DNA, and that includes strength, intelligence and vitality. And this is used in the bias of randomness in the in game risk role.
00:33:34.800 - 00:33:57.290, Speaker A: Okay, so what you can do is you can play on a 112 x 63 planet map. We hope to create many different planet maps, but we only have Earth available. This is stored in a smart contract on the Ethereum network. So if you want to play, you need to join the game. Which I might have already joined. I haven't. So I'll join the game first.
00:33:57.290 - 00:34:43.700, Speaker A: And the idea is that first you can buy any tile on the map, so it incurs a fee of ETH. You can buy a tile, and for every block that you hold one of these tiles, it mints you new or tokens. So the or tokens are an in game resource and they're used to bolster defenses against attack and also to allocate to another coordinate for attack. Similar to how Risk works, it also has principles of the Go game. So if you allocate or tokens to a diagonal neighbor, you can then acquire the two von Neumann neighbors. So for future work, we want to improve the game narratives in UX. We need to test and harden the solidity code.
00:34:43.700 - 00:35:12.694, Speaker A: There's a lot of work to do for debugging the UX and polishing the client and also implementing the contract method calls that we haven't already done. We need to create new planet contracts. We would really like to implement the chat with Textile Space Demon. We haven't done that, unfortunately, yet. And hopefully we can raise funds to keep our team together and the project going. Thank you very much for your time. Thanks, Chad.
00:35:12.694 - 00:36:29.800, Speaker A: Sorry. Yeah, over to and if so, did you know quick question is sort of have you thought about sort of gas fees or how you can batch this and how many for a game like this? It seems there's a couple of calls that at least at the current moment, are a bit challenging with the current Ethereum sort of gas fees. That is true, yeah, gas fees are definitely a thing. So we haven't necessarily thought about batching yet, but we have optimized the contracts in a way that we're sending minimalistic data. Chris is on the call, maybe he could speak of that if he wanted to, but yes, that is an issue. You mentioned that if someone owns land, they get paid two X, the price of the land, but on the slide it said that the payment by the user who's buying that land is three X. Can you explain the economics a little bit better in regards to how you buy land? Sure.
00:36:29.800 - 00:37:00.590, Speaker A: Thanks for the question. Yeah. The contract will take one X. There's a governance contract that controls all assets that go into the contract so the idea is to restrict the notion that you want to buy. You can initially buy, but you want to acquire Or Tokens and play the game that way. We don't want to have the game restricted to simply just buying and people bullying around with ETH. We want the game to happen with Or Tokens.
00:37:00.590 - 00:37:52.670, Speaker A: Cool, thanks. Is it just one large game world, or do you have multiple game sessions? Well, we have planets, so we only have one planet now called Earth, but we can create multiple different planets, and each planet can have any different type of game mechanic. We just have a relatively simplistic game mechanic right now that is related to what we have, but it's Earth. But the idea is to have interplanetary competition as well. So each planet is a different contract, and the governance contract controls which contracts are active in the ecosystem. So if I go between planet to planet, I can use my tokens, but the mechanics of the planet may be totally different. Correct.
00:37:52.670 - 00:38:51.010, Speaker A: The tokens are universal. However, you're minted tokens in a particular planet, but you would have to withdraw them into your wallet and then put them back into another planet. Cool. What was the biggest challenge you guys faced when you're working on this game? Well, I think probably working for me as working primarily on the front end, working with Web Three and making network calls into MetaMask and getting transaction payloads figured out and making sure that everything's happening, doing the event management and making the UX transition happen based upon the delays and lags in the block times. So the UX is the biggest issue, and I would say that handling those transactions is the biggest issue. Got it. Awesome.
00:38:51.010 - 00:39:19.910, Speaker A: Great work. It looked beautiful. Thank you. Aiden, I heard you mention a random function. What did you use as your source of randomness? Go ahead. Yes, so I wrote that in. It's not really true randomness, but it's something that the users can't really control within an inordinate amount of money being spent.
00:39:19.910 - 00:39:50.518, Speaker A: And all it is is it's a hash of the last block hash the last block number, and maybe something else in the environment that's available. Cool. Thanks so much. If there's no more questions from the judges, we can move on to our next project. But thank you so much, Project Orbit. That was a great presentation. Next up is Askenda from Project Anwan Boosting create and Share.
00:39:50.518 - 00:41:42.096, Speaker A: If you could share your screenplay. I don't think okay, great. He is not going to be speaking over the there is going to be no audio for this video. As, canda you be giving a little bit of context for the project you're presenting? There was a brief demo at the end. Is there any way we can kind of look directly at that? That'd be really useful. I mean, even if you don't want to speak, just walking us through that might be helpful. Yes, I can speak now.
00:41:42.096 - 00:43:21.260, Speaker A: Sorry for the video without audio. No worries at all. And the idea is very I think the idea is very simple. People can write article and save their article on IPF or FalcoIn and people will send FalcoIn as a gift to the water and the good article will storage forever in this way. This idea is very simple and I'm still working on it. So does it also act as a wallet as well for filecoin? Will you be keeping users filecoin as well? Yeah, we are on filecoin tour and also on IPFS now what? Do you have a plan next for the project? My next plan is about the FalcoIn storage. I'm also Felcoin storage minor so I want help people storage del fail or article on falcon more easily.
00:43:21.260 - 00:44:49.066, Speaker A: And the other part is about send FalcoIn as a gift. I also wanted to make it more simple. What was the most complicated part of the project that you found? I think the most complicated part is about the FalcoIn storage because I wanted to help people store detail article on felcoin node as much as much as help people article on more bell coin node so should use some Felcoin. I also will help with storage and first and when it run very well, people will help storage the article too. If they like article I think they will help storage that article for longer. Cool, go ahead. I think it says you should never change the content and article on one of the census.
00:44:49.066 - 00:45:47.700, Speaker A: So is there any way the author can change their article after they've published it? Sorry, I didn't get it. Can you speak again? Yeah, there's just a statement of the first sentence should never change the content in an article. And I was just wondering if the author wanted to change the content in the article in the future, will you add that feature? Yes, I am considering it. I think I will use IPNs. Cool, thank you. What was your favorite part about working on the project? My favorite part is felcoin storage. I think it's really exciting about Felcoin because it's really hard.
00:45:47.700 - 00:46:25.506, Speaker A: But I'm helping Felcoin project run better because it's in testnet. I'm running many tests on it. I have already successful storage and retrieval on it too. Cool. Thanks so much. You can stop sharing your screen. If there's no more questions from the judges, we'll move on to our next project, data Exchange and Analytics Optimization.
00:46:25.506 - 00:47:28.520, Speaker A: If you guys could share your screen. Hi, and welcome to the data exchange and analytics project. The main idea of our project is to generate a decentralized data microphase with any type of data set that can be used to train ML models using our automated service pipeline. The idea is to use IPPs with Flick Space Demon to upload and control the data sets per user using their buckets creating folders with the Ethereum address. The data will be completely encrypted and the user will have full control. When a user uploads their data set, an NFT will be created so it can be selled or transferred with another user. Our project divides in four different categories the decentralized data marketplace to keep the data assets secure, to buy and sell private data, and to use the data pipeline and create AI models.
00:47:28.520 - 00:48:08.628, Speaker A: Welcome to our web application MVP. We use MetaMask as the authentication service. The idea is to later on use TreeBox to validate the user identity. Once you are connected, we will have a section for the data marketplace of people that have already uploaded their data sets and are currently available for purchase. The next view will be the data analytics, which we will look similar to this current view with a difference that only your purchase data sets would be displayed, as well as your own data sets you uploaded that may or may not have set for purchase. There are two ways to upload a data set. One will be using the sidebar or clicking on the top right button.
00:48:08.628 - 00:49:18.300, Speaker A: Once you select that button, you will view this window where you can proceed to upload the data set. Once you select the data set, you will need to fill out information such as description, price, category, et cetera. Once the file is uploaded to IPVs, NFT will be generated using smart contracts with Ethereum. For now it will be uploaded the document using IPVs libraries, but the idea is to later on use Space Demon from Flick to use that same node to train the ML algorithms. Now we will test the hash document to see that it was correctly uploaded and we can see that it is working. Now, moving on to the pipeline. The pipeline will be divided in four main categories.
00:49:18.300 - 00:50:07.432, Speaker A: The first one will be to identify the data set content. We want to explore what the data set is about and identify which type of problem we are dealing with, especially if it is a classification regression, clustering, et cetera. In order to do that, we will request the user to identify the target variable that will help us define the type of algorithm as well as the hyperparameters needed for them. The user will have the opportunity to tune these hyperparameters if they wish to do so. If not, then we will use what they seem fit or use the default values to proceed. Once we have categorized the type of problem we are dealing with, we will proceed to select which models we want to run. For this initial prototype, we focus on classification algorithms only, which will run five different ML algorithms.
00:50:07.432 - 00:50:51.690, Speaker A: However, if the user wants to run only a few of them, they will be able to choose which ones or all of them. Next, the training will begin and finally a model will be generated where the one with the best performance will be the one that wins. We will show comparative plots of the performance of each of the models so the user is aware of how each model behaved. Our idea is that our data and the algorithms are in the same cloud server offering this application as a data exchange and analytics as a service. It's a really cool project. Hi, my name is Taylor and I'm from Lucidchart. Today you'll be learning all about entity.
00:50:51.690 - 00:51:28.230, Speaker A: How large do you guys expect your data sets to be? Sorry, I was just curious how large you expect your guys'data sets to be for the we expect it to be big. Right now, the tests that we did were with data sets, like dummy data sets with around maximum of 10,000 rows. But we expect to have the enough power, like computer power to run stuff with GPU and stuff like that. Awesome. Very cool. Yeah. Thanks.
00:51:28.230 - 00:52:32.970, Speaker A: Amazing work in working on this kind of what would you see as being kind of the biggest challenge and then moving forward? How did you overcome that challenge? Okay, I think the biggest challenge where they use all the tools around the IPVs principal or Textile and Flick we don't finish to implement the tools of space demo, but the idea is use spend demo of Flick to put all the big data in the same server as machine learning algorithms. So I think this was the hard work and also predicting because we wanted this to be not only for people that already knew how to do data science, but to anyone to use it. So in order to predict what type of problem we're dealing with, it will be kind of hard. So at the beginning, we just want to maybe categorize what the user will be doing. But yeah, that will be another challenge. Awesome. Thanks.
00:52:32.970 - 00:53:30.800, Speaker A: Great work. Thank you. Is there anything new that you guys learned from this past month in hackface everything? Yes. I don't have too much experience as a front end developer. My skill is more back end. So I was to learn all about the LGs and implement all the JavaScript libraries for her around all the web3 she don't know. Yeah, basically, if you had more time, what would you add? What would you ideally build as next thing? Yeah, I think if we have more time, maybe we'll create all the marketplace for the data.
00:53:30.800 - 00:54:14.758, Speaker A: The idea is create Nfits to transfer the data or sell this big data. Another hand is create some backend services to implement all the Flick solutions to buckets and files and put all the files encrypted in that server with all the GPU for machine learning algorithms. Great. Thanks so much. I hope you guys continue working on this project. It was a really great demo. Next up, we have project secure beam.
00:54:14.758 - 00:55:39.150, Speaker A: Thank you. You guys share your screen. Definitely winning. You're winning. Coolest music for sure. Thanks. Thank you.
00:55:39.150 - 00:56:10.016, Speaker A: I saw some German. I'm from Berlin. Berlin has really good music like that so I saw some German screenshots, descriptions and stuff. He's a German guy. Great, thanks. I might have saw something that I didn't see super clearly, but was that a Dropbox Paper thing that you were sending from Dropbox over to your security? That is just a default file from Dropbox where I think they introduced Dropbox Paper. So it's just a functionality of it.
00:56:10.016 - 00:56:39.844, Speaker A: So it was a very clean Dropbox account which I connected through OAuth and yeah, then it's just listing. It awesome. It's a really cool project. Oh, cool, thanks. Thank you. If you had more time, what would you add? Definitely more aspects of decentralized software like Orbitdb. We are not able to authenticate Orbitdb to make it really private.
00:56:39.844 - 00:57:16.310, Speaker A: That's of course a core functionality because we aim to make it like a decentralized cloud client and enable users to of course connect more. Cloud storages like Dropbox is already in, let's call it an MVP and we are working on integrating Google Drive or Box or any other cloud service that you are able as a user to migrate to. Ipves. Awesome. Great work. Thank you. Thanks.
00:57:16.310 - 00:58:08.884, Speaker A: One question I had, is everything happening client side or does someone need to run a server to sync the files? No, everything is happening on the client side. That was one of the hardest goals we liked to achieve because in my experience, it's easiest to just open the browser point to some URL and that's it. And all the functionality is there. So that is one key feature we aim to leave as it is to just work as a web. Yeah, we aim to introduce PWA on decentralized and authenticate with Orbitdb to make it really private. But yeah, there is no server involved. So just currently for hosting it's in the link of the description.
00:58:08.884 - 00:59:17.896, Speaker A: But as soon as we get it on IPVs working so the PWA itself, it will be an IPVs URL and future plans for the project. Have you got anything in line there? Yeah, of course we aim to extend the functionality of sharing content and of course moving content to Ipves to keep track of the content and to connect of course more cloud services like Dropbox and Google Drive and father cloud storages. And yeah, that's what we are currently aiming to, to make it really easy for the end user to migrate all their personal cloud services to IPVs and to have the exact same experience, like for example, their Dropbox client. That's the aim of the project. Cool. If there's no more questions from the judges, thank you so much. Project secure beam.
00:59:17.896 - 00:59:37.110, Speaker A: That was great. Thank you for the opportunity. Thanks, bye. Yeah, cool. Next up we have project ISCC registry. If you guys could share your screen for the judges. Hello.
00:59:37.110 - 01:00:07.266, Speaker A: My name is Titos and this is the ISCC Ethereum IPFS registry. Hack. A proof of concept for decentralized media content registry. So what is the problem with the current crypto hash based content addressing. So the main problem is that from a human perspective, content is really something different than data. And cryptographic hashes identify data and not content. So for example, if you look at these two images from human perspective, they are the same content.
01:00:07.266 - 01:01:06.030, Speaker A: But if you create a cryptographic hash for content addressing, then the hashes will be completely uncorrelated because the data that is underlying the two different image encodings is very different. So what the ISC solves it, it will create the same content ID, or at least a part of the content ID will be the same if the structural visual perceptive content is the same or similar. The idea of this hack is to implement a decentralized registration protocol. So we take a full IAC code, everybody can generate it for any kind of digital content, and then you can register it on any public blockchain. And what the protocol does, it indexes or watches, observes the different blockchains, and comes up with a short ID that resolves to the full IAC code. But it is owned by the person who registered the code, and it is globally unique and short. So what the hack does, the hack actually do? So, a fair warning.
01:01:06.030 - 01:01:31.466, Speaker A: This is not an end user application. It is nerd stuff, command line stuff. And what we built is a proof of concept of the whole flow for decentralized registration protocol. So here's a demonstration of the actual hack. We have many moving parts. So we have a local test environment ethereum blockchain. We have an IPFS daemon running.
01:01:31.466 - 01:02:08.454, Speaker A: And here we demonstrate the command line tool. So what can it do? We have basically four commands. One command is to deploy the contract to the Ethereum chain. Then we have the observer service that watches the contract for new ICC registrations. Then we have a command line tool command for registering ICC codes and for resolving ICC codes. So let's first deploy the contract. Irag deploy yes and yes.
01:02:08.454 - 01:02:50.630, Speaker A: So the contract has been created on the chain, and the local configuration has been updated to use that contract for registering ICC codes. Now, the next thing that we need to be running is the observer service. So, Irag, observe. So this basically is a service that watches the blockchain for registration events and then calculates the unique short ISSC ID. So now we can register some digital content. So let's try with register. So this is the ICC code that has been generated.
01:02:50.630 - 01:03:18.380, Speaker A: We say yes to registration and the contract has been called and the ISCC has been registered. And this is probably the ISCC short ID that has been generated. We don't know for sure because there can be race conditions. We need to ask the meta index to be sure. And we can try to resolve this new short ID. Resolve. We have that short ID.
01:03:18.380 - 01:04:12.210, Speaker A: Yes, and it works. So the short ID resolves to on chain data, the full ICC code, the wallet ID, who registered it, and the content ID that points to the metadata of the registration which is stored on IPFS. So this metadata was extracted with the ICC generator encoded in Seabore, stored on IPFS, and is now resolved from the short ID. Thank you for your time and thanks for this great hack event, which was really a lot of fun. And I learned an awesome amount of new stuff that was an awesome project. Could you go into detail about some of the challenges you faced working with IPFS? Well, IPFS was actually quite awesome to work with. It was very easy.
01:04:12.210 - 01:04:49.710, Speaker A: I have two challenges at least. I'm working on Windows and I'm coding in Python, so I was pleasantly surprised. With IPFS, everything went quite smooth. The big challenge was for me, I wanted to do the CID by myself without having to have IPFS running to come up with the content ID. And there was some trouble with the protobuff not being deterministic in serializing the stuff. So I was not able in the short time to reproduce the CID from Python. But yeah.
01:04:49.710 - 01:05:43.580, Speaker A: Are all of the CIDs on IPFS, are you able to access them right now from IPFS gateway? I don't understand your question exactly. I'm just wondering if, for any of the things that you uploaded for your project, can I access them right now over an IPFS gateway? Yeah, well, there's not much you get because it's CBOR encoded, so what you get is Seabor encoded. But yes, the things that I registered should be available on IPFS. I'm not sure, I don't have it running now. But if you resolve the short code to full content ID from the CID, you don't get the content, but you get the metadata which is encoded in Seabore, which might point to the actual content. That's up to the registering party. Cool.
01:05:43.580 - 01:06:25.704, Speaker A: Thank you so much. You're welcome. Sort of high level. Can you catch me up on sort of the why do you use this? Or who uses this? Well, okay, so it's a quite broad initiative, and it's on the protocol and infrastructure level. So the idea is to have a new kind of content Identifier that itself basically does retain similarity between different kinds of content. So if you have these IAC codes, you can index them, and if you decode them, they are actually feature vectors, bit vectors. So you can compare two ISCC codes against each other and you can see how similar the content is.
01:06:25.704 - 01:07:17.032, Speaker A: For example, if you have one image and you have it in JPEG and you have it in PNG or a video content, so it's specific to all the different content types. Basically, we are turning a search engine inside out by the Identifier being something that retains similarity between nearest neighbor kinds of content. So basically the idea is to have an open infrastructure for content recognition and indexing based on open, standardized fingerprinting of media content. Okay. Very interesting. Great work. In terms of next steps, kind of what do you see as being kind of the well, this is the passion kind of project funded all by my passion.
01:07:17.032 - 01:08:03.540, Speaker A: So I'm not sure what will be next. I guess bringing the protocol forward, maybe having a user interface to show how this could be an end user application to register and make your content discoverable and yeah, indexing for nearest neighbor search could be also something that's next up. Awesome. Thanks for that. Great. If there's no more questions from the judges, thank you so much. Project ISCC registry.
01:08:03.540 - 01:08:35.730, Speaker A: Next up we have Project Rick, Lou, if you guys could share your screen with us. Can you hear me? Yo, yo. How goes peoples? Good to see you. Good to see you too. Should I just start it then? Awesome. Oh, maybe. Hey, how's it going? It's good.
01:08:35.730 - 01:09:10.190, Speaker A: So we should probably get this hack FS thing done and out of the way, right? Yeah, for sure. Because I own Rickmoose ETH on Robston. If we head over to Rickmoose Waxlit.com, we'll be able to see all the articles I've currently posted during testing and we can click on the first one and see. Here is a article I ported over from my Medium site. Eventually I'll be porting all my articles over. Hey Rick, would you mind full screening that? Oh, sure.
01:09:10.190 - 01:09:35.440, Speaker A: I didn't realize it wasn't full screen for you. Does that work? Yes. A brand new article. Enter Rickmoose East and it'll bring up the editing page. From here we can start creating a new article. I've got one I've actually started that I never finished publishing on Medium, so we'll use that as a demo. So here we just use General Markdown to create the article.
01:09:35.440 - 01:10:09.052, Speaker A: We'll upload an image which will get put on IPFS and the link will be injected into our article. And then we'll just continue to copy and paste the components that I've already written prior. Once we are done editing this article, we're going to save it so we can share it on IPFS. If you notice in the URL there's a key. That key is used to encrypt the article. All articles in Waxlit are stored encrypted until published. Now that we're done, we're going to share this link with Lou and get some feedback to see what she thinks with the article.
01:10:09.052 - 01:10:39.060, Speaker A: So far, I'm reviewing this article. Everything looks good, but I think it would be nice to put a caption on the picture. Now that we have Lou's stamp of approval, we will go off and we will publish this. When we publish, the file doesn't change. It remains encrypted. In IPFS, we simply blurt the password out into the universe on the blockchain so that everyone has access to it. No data is stored on chain.
01:10:39.060 - 01:11:29.832, Speaker A: We simply use our contract to verify the owner of the ENS name and log entries which can be queried using Getlogs later. This fully allows for revisions for deleting and updating articles. And our new article is ready for the world to see. And as you can see, our new article is already showing up in the list of articles for Rick Moose. That's all. Oh, it was back to me yet. Can you hear me? Cool? Yes, we can hear you.
01:11:29.832 - 01:11:45.896, Speaker A: Excellent. Thank you for sharing such oh, sorry, Aiden. Go. No, please. Thank you. Sharing such a cool project. So I heard in the presentation you mentioned that you are encrypting things until published.
01:11:45.896 - 01:12:38.716, Speaker A: Could you go into more detail about that? So, yes, actually, they're always encrypted. Basically, when you create a new article, it generates a brand new 16 bytes key and that's used using asctr probably 256, something like that, anyways, to actually encrypt the content. So it's always stored encrypted in IPFS, this would normally be an issue because IPFS does not serve content that's not popular. Most, like bitswap, requires content that is more frequently used, but because eventually the encryption key will be released, that means that even encrypted data will be used by many people, because once they're seeing the published data, they're still loading encrypted data, but they have the decryption key right there in the URL. And so it means that anybody who has that URL can preview it. But if somebody's just looking at IPFS, they can't see what your secret article is about yet. Got it.
01:12:38.716 - 01:13:03.636, Speaker A: Thank you. And the reason for doing it this way is that because you wanted that sort of internal preview mode and then publish it. Exactly. Because if you're used to Medium, like, you get this magic little link, you can send somebody, well, it's for that. But it's also because you might decide never to publish an article. You might want to just keep it as a secret. Maybe you're organizing some coup against the government because they're arresting people in Portland or something.
01:13:03.636 - 01:13:53.444, Speaker A: So you might want to keep some sort of private information out there and just share the link around. And once the link disappears, if no one has the link, the content is now just permanently lost to the ether because it's stuck encrypted in the universe. Incredible work, Rick. Lou, this is awesome. What are your kind of next steps? Do you see yourselves working on this and kind of releasing a version where we can start moving away from of what are major features that you still don't have or do have and you're proud that you accomplished in a short amount of time? Yes, I definitely plan to continue this because I hate Medium. I always say Medium feels like that banker who says they don't care about your money, they care about you, but you can see them staring at your pocket the whole time. So I don't like that feeling of Medium, actually.
01:13:53.444 - 01:14:18.910, Speaker A: So one of the things I'm really proud of, Lou, can cover her protocol buffer implementation and all that. Good. Stuff. Go for it, Lou. Okay, so for this project, we tried to make it simple, so we actually didn't use any of the protocol buffer library. We actually had to write it ourselves. And we also kind of query multiple IPFS gateway to pull the data.
01:14:18.910 - 01:14:56.264, Speaker A: If one of the gateways down, then we actually can automatically go to the next gateway to get the content. We also verify the content in browser, so that's like the feature that we really want to get into this app. Yeah, right. So as long as you've loaded this static web page, all the content you're seeing you are guaranteed is correct. If a gateway tries lying to you, it won't work. Lou also didn't mention, but she also implemented this on the put side. So before putting the data, it gets chunked up and she verifies that what the pinning gateway says is actually what was put in there.
01:14:56.264 - 01:15:14.352, Speaker A: And so gateways can't lie to you for getting or putting. Awesome. Oh, sorry. One quick thing. What Aiden said, the other thing I want to really get in is like a Weisswig editor, kind of like what medium has. This was just kind of the shortest. Awesome.
01:15:14.352 - 01:15:25.124, Speaker A: Awesome. Thank you so much. It was really great to see how usable it was. Kind of by the end, though, you're saying you want to do all these things. It's still pretty usable right now. It's a great work. Awesome.
01:15:25.124 - 01:15:40.800, Speaker A: Thank you. Great. Thank you so much, Project Ricklu. That was a great presentation. Cool music. Thank you very much. Cool.
01:15:40.800 - 01:23:13.820, Speaker A: We're going to take a five minute break now before the next team comes up. So when we see all the judges are back online with their videos on, we can get the next half of the session started. Cool, great. We'll just wait a couple more seconds for the judges to get back to their screens and put their videos on, and then we'll kick it off with the next team. Cool. It looks like everybody's here. Our next project up is Project Grid.
01:23:13.820 - 01:23:56.590, Speaker A: If you wouldn't mind sharing your screen for the judges, we can get the next session started. Hi. We are social labs, and we're presenting grid protocol. My name is Benny, and this is my teammate Nathan. Who are we? We are two recent grads at UC Riverside, and we're just into crypto. So for this project, I worked on the UI, our smart contract, and then also our subgraph. For this project, I worked on the UI and the smart contract.
01:23:56.590 - 01:24:55.780, Speaker A: So the idea behind this is that we identify a problem where there are multiple social networks, and we wanted to use Web Three so that we can bootstrap themselves quickly. What do I mean by that? Well, we want to create the platform as a service where users can own their content. For the solution, we identified where you want to take the social brand followers and following, and you want to put it in a free and open protocol within the blockchain. Then you want to take your following to any social network out there, essentially almost all of them, where you want to put Web Three so you can onboard the users faster. We have a short demo of our project. So we can see here a UI that shows all of the accounts on our local Ethereum network. We can view users, looks like we're already following that person.
01:24:55.780 - 01:26:11.930, Speaker A: We can go over here and we can follow someone. And then after having our UI update, we'll see that we are now listed as one of their followers. We can unfollow, which then sends the transaction to the blockchain and updates the states that we're now no longer a follower. So how does that all work? We have a smart contract that holds mappings of who's following who between Ethereum addresses. And then there are functions in there for follow, unfollow, delete, follower, and then each one of those will also emit an event when it's been performed. Then we have a subgraph that indexes all these events so that they can be queried by any application that wants to. And then we have our UI that shows a simple interaction of following and following other users that are part of the social media network.
01:26:11.930 - 01:27:08.160, Speaker A: So what else would make this even better that we didn't have the time to get to? So essentially what we did here was just implement like a free subscription tier. But really what we wanted to do was to let users set multiple tiers of subscriptions where they could also be paid sort of like patreon or substac. And then users could set content hosted on filecoin and FPS, that would be only accessible to people who have paid for the subscription. I thought that might be implemented with an NFT kind of thing. And then also if you just want to follow someone for free, it seems like you shouldn't have to pay $0.50 or a dollar or whatever in gas fees. So ideally that would probably run on some kind of layer two solution that can minimize or even eliminate that cost.
01:27:08.160 - 01:28:15.150, Speaker A: That is all, thanks for watching. Thank you, bye. Great. Did you guys learn anything new during this past month at Hackabace? Yeah, I didn't really know anything about Solidity or GraphQL coming in, so that was pretty much all new. So I really like this concept and it's like one of the core Web Three kind of concepts that you own your data. Do you think you can extend this? So maybe any content I've posted, et cetera, is also sort of associated to my profile and I could port it over to another UI. Yeah, so we're thinking about ways to do that and couldn't really land on something that seemed good enough, I guess.
01:28:15.150 - 01:29:55.870, Speaker A: But ideally you would have your content be in there also that would be a much better upgraded version. Sorry if I'm kind of missing the mark here, but is this kind of like a way of being able to kind of, I guess, track all of the profiles or all of the things that someone has so I would be able to know what all your official accounts would be? Is that the idea of this project? Kind of, yeah. It's like we wanted to have the most important part of a social media profile is the people that you follow, people who follow you or friends or whatever that connection looks like. And so we thought that if we could move that data into its own independent protocol separate from the platform that it's running on, then it gives more power to the users because they're capable of exiting platforms they don't agree with. And then when they go to a new platform, all of their friends or everyone are still there. What was your experience working with IPFS? So I think the only IPFS stuff in here was just with the graph. Awesome.
01:29:55.870 - 01:30:32.824, Speaker A: Really cool. I mean, definitely see the beginnings of something like a keybase, for example, where you could potentially be linking to a whole bunch of things. So, I mean, really great work, especially being that this is your first time in the space from what you've said. So congratulations. Nice work. Cool. Do you guys have plans for your project going forward? Yeah, we want to expand it to be able to have paid subscription tiers.
01:30:32.824 - 01:31:38.118, Speaker A: So we think that being able to do, like, a patreon kind of thing would be really good because that's how a lot of people support themselves, and then we can move that into something that gets, like, the advantages of blockchain. Cool. Thanks so much. If there's no more questions from the judges, we will move on to our next project, which is Project Linchpin. If you wouldn't mind sharing your screen for the judges. Hello, I'm scott stevenson, and I'm joined by my teammates, nate hart and yusuf kuwidi. Linchpin is a bundle of many applications anchored by Protocol Labs, IPFS, Lib, P to P, and the public Ethereum blockchain.
01:31:38.118 - 01:32:32.858, Speaker A: Our first order of business for hackfs was to determine if we were going to be able to provide value to the sponsors. So we had to ask ourselves, do we understand the objectives and the prizes? Do we have the technical ability to not only satisfy the objectives, but to also deploy a working solution? And also, will the judges see our submission as meaningful and worthy of granting resources? So our Hack FS research revealed the following to us, the power is in the Content ID or the CID. These CIDs should serve content that can be found by web3 domains. We've made it through and are really excited to show you Project Linchpin. Now, Linchpin is a bundle of many applications. Each one of these application either creates a CID or executes a transaction on the ethereum blockchain. Now, ultimately, we choose to lean into two use cases.
01:32:32.858 - 01:33:19.582, Speaker A: One is legal agreements in the digital space, and the other one is enterprise level claim management. Now, we have experimented with textiles, buckets in, threaddb, some powergate, and using filecoin, and the results are still ongoing that we use IPFS every day in our business. Our main deployment for the hackfs submission is going to be the claims dashboard application. Now, as you'll see today, the lines between information, entertainment and business applications are now starting to merge together. So imagine a place where you buy a digital ticket to pass as a tool to unlock fun and services, and that you're going to be able to keep it as a memento. Now, think about games with NFTs as the reward system. That's where Linchpin is going to step in.
01:33:19.582 - 01:33:57.594, Speaker A: I believe we should only touch the expensive blockchain as little as possible, and that's where the CIDs come in handy. The CID, the bare minimum onto the ethereum blockchain and then referencing back a content hash to deliver all of the bulky content is where we believe the future lies. Now, some of the smart contracts that you'll see here today that we use are very compact. They're very short because all we really needed to do is just pass that CID. Now, some of the other contracts, such as the NFT deployments, are more sophisticated because they have a lot more features, and we like to show those and how those show up in other people's user interfaces. Like, for example, OpenSea. Now at the heart of the Linchpin project.
01:33:57.594 - 01:34:35.010, Speaker A: It's a pretty simple design and it's something that Linchpins are perfect for. So we're going to use IPFS for content. We're going to use the public ethereum blockchain as the settlement layer, and we're going to be using Linchpins as a user interface, user experience bridge between the two. So everything in our demo is served by IPFS and CIDs or by the front end that passes information from the memory. And there is no backend databases in this demo. So you may ask, how are we going to make money with Linchpin? Well, we're going to make money by doing custom installations for people that have an application that need a front end for it. Another way is we're grow fees that are built into some select smart contracts that we deploy.
01:34:35.010 - 01:35:43.450, Speaker A: We're also going to be using NFTs not only as gateways to services, but also as a reward system to incentivize coworkers or teammates in the digital space. And finally, we're going to test and deploy projects in web two space as well as also in the metaverse. Now, what would a generous grant allow us to do out of hack FS? We want to build a small team of developers with a management layer built in like a Dow or a decentralized autonomous organization to handle the accounting. Now, finally, the Metaverse is a perfect metaphor for IPFS in web3, and it's what the Linchpin project is all about it's. What joins these two great technologies together, IPFS for content, ethereum for settlement, and the linchpin is what's going to join them together in a neat user experience. Hey, Scott. So I'm going to be honest, I didn't really understand what it is because I don't think there was an actual demo.
01:35:43.450 - 01:36:17.542, Speaker A: Could you just 20 seconds explain what exactly it actually is? Yeah, just hold on 1 second while I stop this video from playing right there. The way that we approach can you hear me? Okay. You can hear me? Okay. Yes. Okay. The way we approached the hack FS is because all of us on the team already had some experience working with IPFS and some of our other projects. And what I was really trying to do is bring a lot of those other in process projects forward.
01:36:17.542 - 01:36:58.018, Speaker A: And ultimately I said, IPFS has been around for a while. We understand the content ID, and getting that out there on the storage layer. Now the threadsdb, what textile has provided, what slate had provided through all of the videos that I watched at the beginning of hackfs, that kind of opened up our eyes to some other things that we could do with our user interfaces. And that is what you see on the left hand side if you're saying what is actually our submission, it's a dashboard. It's a dashboard that queries the ethereum blockchain for information. And that information was gathered from the CIDs, because we use CIDs all the time for JSON files or for graphic files. So we just wanted to make sure that there was a dashboard available.
01:36:58.018 - 01:37:54.626, Speaker A: So where we implemented IPFS and textiles is in basically adding a claim. So if you go into here, you add a claim, it goes out using threaddb, and we get the user ID, we get the thread, DB get the CID, we bring it back into the dashboard, and then we start to log all of that information. So this would basically be set up as, let's say, an insurance office. So they're trying to track insurance claims of people that got into car accidents. So the whole entire operation is based on CIDs and the ethereum blockchain. And then at the same time, we're very interested in using NFTs as a device to either track legal claims or the content that is actually stored on IPFS or the actual claim information that the insurance adjuster or the claims manager needs. So I had a really hard time kind of like linking these two, which on the left hand side, it's the dashboard, and on the right hand side, it's actually the content of the NFT.
01:37:54.626 - 01:38:22.602, Speaker A: So if you're saying, really, what is the demo? It's kind of a combination between these two user interfaces, which I think that you guys, as judges, would probably just go try out yourselves to see all the IPFS functionality in the background. Are you storing raw data on IPFS, or are you storing like maybe a PDF file. Everything. I mean, we store everything. Songs for some things. We do NFTs. I do Vox files with NFTs now, so there's a lot of things that even OpenSea.
01:38:22.602 - 01:39:02.586, Speaker A: And the NFT sort of like marketplaces. There's a lot of information that they will query off your JSON file. But I'm starting to see ways that you can operate a little bit outside of that to start to do additional parameters in there to actually, let's say, the art industry. And my teammate Nade in here, he comes from the Art NFT space. So I was trying to use their schemas and say, how could we expand out of this and start to track like, royalties or licensing agreements that are attached to the NFTs, but we need to expand off the existing NFT standard because they can be so much more powerful. So a big part of this is, yeah, we need to chase down the NFT space, but simultaneously. That's what I loved about Web.
01:39:02.586 - 01:39:41.766, Speaker A: Three API. Today they're providing us these things that I thought we would have two or three years ago. Now they're becoming available today. So my job in Linchpin is really going out and finding those little mini applications or those many tools and really now starting to plug them together. So what is my business going to eventually be? It's making sure that we're an assembly company, that all of you great coders out there provide those tools out there and somebody starts to plug them all in. Because I'd like to have a super app, like the super app that everybody can use, but it's too complicated. We need to break it down into these sort of bite sized Morsels and deliver somebody like an escrow contract or a little Art NFT or little things like that, because that's what we need.
01:39:41.766 - 01:40:30.226, Speaker A: I think in this space, you guys are great developers, but we need little bite sized pieces that people can sort of like, bite off and chew on. Great. Thank you so much, Scott from Project Linchpin. That was a great demo. Next up, we have Project Monetizing decentralized content, and I will be playing their video for them on the Internet. Are broken. The digital age has provided revolutionary ways to create and distribute content, but capturing value has always proven a challenge.
01:40:30.226 - 01:41:38.122, Speaker A: We've seen only three primary streams of monetization, resulting in questionable behaviors. This is exacerbated by limited means of controlling distribution and duplication, and amplified by an inability to verify authenticity of purchased content. We've built modular microservice protocols that empower developers, content creators, and consumers to better monetize and enjoy digital content without compromise. We're not the first to tackle this issue, but we are taking a step back to understand the challenges from a full stack point of view. By thinking systematically and leveraging emerging Web Three technologies, we have built a full lifecycle solution focused on three interoperable but nondependent microservices smart contract based payment services providing greater flexibility in how value is captured without compromising user experience. Advanced digital rights management distribution using cutting edge decentralized computing and encryption such as Network Trusted Execution Environments and an HMAC based authentication service to verify content from upload to storage to retrieval. In looking at the bigger picture, our solution encourages innovation in payment and distribution models.
01:41:38.122 - 01:42:32.990, Speaker A: Let's take a closer look at the content creators experience using our protocols. Troll connects to Web Three, where her Ethereum address is connected to a smart contract which manages her uploaded content, payments and Purchased Content. She uploads her latest work, which creates its own smart contract. This unique contract records the payment terms, storage location, file information and access to its encrypted content for any client who purchases it. She has several options for payments micro Payments, where users buy a digitally unique copy of the content or just purchasing one time access subscriptions, where a user can purchase access to all of her content. Conditional Distribution, where would be free at first, but premium for subsequent views when uploading. Her content is encrypted using a symmetric key for transport and sent to a Networked Trusted Execution environment using Lib P to P.
01:42:32.990 - 01:43:08.634, Speaker A: Upon initial encryption, an HMAC is created as a root proof of authenticity. This proof will follow the Content throughout its lifecycle. The service decrypts and re encrypts content for storage using a newly generated bare metal key. The storage encrypted content is passed to the storage service using textile. The storage key is encrypted and stored on chain for retrieval. The service will only accept a request from the Content Smart Contract which has verified access to the user attempting to view it. Once confirmed, it reverses this process, providing the consumer with a temporary key HMAC and Content.
01:43:08.634 - 01:44:06.054, Speaker A: A consumer sees a piece of content they would like to view, this user can either buy the content directly and own it forever, subscribe to that publisher to see all of their content, or we are introducing a couple new ideas into the payment process. If a user has a prepaid $5 a month budget when purchasing, they can simply send a gasless signed message to their funded Pay Three User Smart Contract to access the content. Alternatively, we've introduced the concept of sponsored consumption. An ad agency could offer to subsidize users content consumption in exchange for that user's personal data found within their contract. This would allow advertisers the opportunity to forge direct relationships with consumers and generate higher quality leads, better facilitating a connection between user and advertiser. We would like to thank Protocol Labs and ETHGlobal for sponsoring this hackathon. We believe an Ethereum Native Solution with limited dependencies is critical to the adoption of decentralized storage networks.
01:44:06.054 - 01:45:01.810, Speaker A: By providing storage site encryption with payments and authentication, DApp developers may provide consumers a new way to enjoy digital content. We look forward to the opportunity to continue developing these concepts and helping the Ethereum community grow. Awesome presentation. Thank you. Just curious, what was it like to work with Textile Buckets and would you do it again and did you run into any challenges? I'll go ahead and let my teammate sing answer that. He was mostly in that world, actually. I love working with Learn and working with Tesla buckets in particular for our Use case that if there is any particular publisher or people want to change their content, those IPNs link of those buckets won't be changed.
01:45:01.810 - 01:45:49.622, Speaker A: So if the publisher already have delivered those IPNs link as advertising anywhere for promoting their content and updating the content won't need to change anything. People will just automatically get the updated content. Awesome. Have you thought about if you're doing especially sort of files? Because I understood each image or file is essentially its own smart contract and so you're deploying that own smart contract can be pretty gas intensive. I guess for a hackathon this is totally fine, but do you guys probably spend a lot? Yeah, it's certainly some cost challenges. There maybe a side chain or something to deploy those. But yeah, for now we weren't really worried about the cost.
01:45:49.622 - 01:46:05.980, Speaker A: That would be something we would dig into after the hackathon needs. Yeah, fair enough. Absolutely. And it could still be for high value actually images. Absolutely. If the content was worth a couple of bucks instead of just $0.25, then it would probably be fine.
01:46:05.980 - 01:47:27.620, Speaker A: Alternatively, scale's network as a layer two mandates the use of Intel SGX for the validators and they don't have transaction fees, so we already have some level of integration with their network that would allow us to still pin to Ethereum but reduce the cost of those smart contracts. What do you think was the hardest part about working on this project? For myself and Moises in particular? Figuring out we spent a lot of time researching into how we can provision these trustless execution environments. It's something that we have a few ideas that we need to dedicate more time to using things like Threshold signatures and these networked tes, but definitely some high level encryption cryptography stuff that would help enable this better. But at least from my end, that's where we spent most of our time. The subscription solidity stuff became a little bit more complicated than I initially thought, but kind of got a model built in. So happy there. Do you want to speak more to that and just discuss what exactly you had issues with? If you don't mind.
01:47:27.620 - 01:48:05.490, Speaker A: We have this kind of like a four stack solidity contract system and then every time you'd have to make a change to one thing and kind of have to adjust it down the line in terms of the users buying it, what they're storing in their contracts. So everybody has their own contract and just managing all the storage of what was happening every time a subscription or purchase happened just required a lot of going back recompiling and that just took a lot of time. Great. Awesome. Thank you. Thank you, everyone. Yeah.
01:48:05.490 - 01:49:01.586, Speaker A: Cool. Thanks so much, guys. That was a great demonstration. I loved all the doggy pictures. Next, this is our second last demo for the session coming up, and it is Project DeFi Hedge. If you guys would share your screen for the judges having trouble hearing, I think it's muted. Could you try sharing your screen again with just clicking the Share Sound audio? Hi, I'm Julian Traversa presenting DeFi Hedge, the decentralized protocol for fixed rate lending and interest rate swaps.
01:49:01.586 - 01:50:00.490, Speaker A: For those unfamiliar, interest rate swaps allow one lending party to lock in a fixed rate while another party takes on a long position on the market's floating rate. In traditional finance, interest rate swaps represent an overwhelming majority of the world's derivative volume, estimated around 524,000,000,000,000 annually. That said, as DFI continues to grow, we expect more and more users to demand both fixed rate lending and leveraged interest rate exposure, two currently unserved markets. We plan to meet this demand with the introduction of DeFi Hedge. As the first trustless and decentralized market for truly fixed rate lending and interest rate swaps. DeFi Hedge allows users to both protect themselves from risk and leverage their capital, all with no counterparty risk for hack FS, we had initially planned to develop our offchain order sharing system using Web P, two P similar to Zero X. However, with other priorities in the way we pivoted towards hosting our decentralized application on IPFS using Unstoppable and Pinata, that's about it.
01:50:00.490 - 01:51:00.500, Speaker A: Let's get into the demo. To begin, our first user, Alice, wants to protect herself from the volatility of the DFI interest rate markets. Assuming a current 8% floating rate, alice wants to place an order for one year 5% fixed rate lending agreement. Alice first approves the DFI Hedge broker contract to access her Dai and, once approved, places her order. Once confirmed, Alice's offer is active for other users to accept. Our second user, Bob, is confident that the floating rate will remain high and wishes to leverage his capital in order to take advantage of the high dive rate. Bob can then fill Alice's offer, knowing that should the floating rate remain at 8%, he will have yielded 68%, a rate nearly one magnitude more than the 8% he would have otherwise been receiving.
01:51:00.500 - 01:51:45.970, Speaker A: Once Bob's order is confirmed, both users funds are pooled and minted into C tokens on the compound protocol, earning interest for the duration of the lending agreement. When the lending term has completed, either user can initiate a return of funds paying Alice her fixed rate while returning the remaining funds to Bob as expected. To demonstrate this, I've created an additional agreement which should return zero Two F to my wallet upon release. With that confirmation, zero two F has been returned to my wallet and our demonstration is complete. Thank you. Okay, that's about it. Cool.
01:51:45.970 - 01:52:31.220, Speaker A: So if I understood it correctly, it does rely sort of on. It's a two sided marketplace, so you need create liquidity on both ends, is that correct? Yeah, it's a two sided marketplace. So in terms of what limits its growth, I do expect there's going to be demand for people wanting to long the rates or people that have an in on a position on a rate and they can even control it. There's a lot of manipulability to that, and there is a demand for that. So I do expect the limiter to be the demand for fixed rate lending because that is a kind of untested market right now. I believe Aave has stable rates which are like pseudo fixed. They are kind of fixed, but they can manually edit them later on if the rates actually vary too much.
01:52:31.220 - 01:53:01.354, Speaker A: So, yeah, it's something I'd really like to introduce. Yeah, I think it definitely can learn a lot from lend. That's how they started. I think that was their original idea. It was kind of very similar. So maybe talk to the founder and kind of see what their learnings were, really. What was your experience working with? Sorry? Yeah, IPFS all that.
01:53:01.354 - 01:53:36.070, Speaker A: Yeah. Specifically pinata and unstoppable domains. Did you find it easy to store data on Pinata and then put domain over it? Well, I had kind of put that off and initially decided, well, if I don't have time for P two PT order sharing system, obviously I can try to pivot. And I gave myself about two weeks to do it, and it probably took me like 45 minutes. Yeah. It was really surprising how easy it was to host a service. I plan to, as I upgrade over time, continue to host it because it's great to provide resilience.
01:53:36.070 - 01:54:08.306, Speaker A: I think that's actually really important as things go into the future. And your application is mostly client side, right? Yeah, right now it is. So all of that was just a proof of concept. Everything later on is going to be more similar to Zero X, where there is an off chain order book and it's all shared with Lib, P two P, and then there is a client side where you're going to be having an exchange at some point there, and they're going to be validating orders and all that. But right now it's all client side. Awesome. Cool.
01:54:08.306 - 01:55:08.686, Speaker A: Thank you. Awesome. In regards to the lipidap side of things, have you done any research on it in terms of how you plan on implementing it? Well, lucky for me, almost all of the infrastructure I have to build is almost the same as everything Zero Ops has done because it's essentially just an ERC 20 trade that's rooted through compound and then time locked. Everything they've done is really helpful in terms of their Zero X mesh. I'm not sure how much progress they've made since March is when I really researched into it, late March, but they wanted to implement a whole lot in terms of slashing. Exchanges if they're having any sort of order validation, or sorry if they're not showing orders at any point, or even having geographical based system with Libby TV. So these are all things I think are really impressive.
01:55:08.686 - 01:55:58.510, Speaker A: And at the end of the day, I think I'm most of the time going to be, if not copying a lot of what Xerox has done, learning a lot from what they've done. Awesome. Thank you so much for the demo and everything. Yeah, thanks for having me. Do you feel like you implemented everything that you wanted to over the past month, or is there stuff that you still plan on working on? Well, again, the big thing right now is building out the decks. I got pretty lucky in that loop ring recently, open sourced their decks, so a lot of the infrastructure that I need is already provided for me for that as well. So over the past month or so, what did prevent me from just doing the order sharing system, which is next on the chopping block, is break apart their decks.
01:55:58.510 - 01:56:42.980, Speaker A: And really, I'm probably about two thirds the way done with all that right now. Right now I'm building out my back end, and at that point, I can then integrate Lib P, two P, for all the order sharing. Great, sounds cool. If the judges don't have any other questions, we can move on to our last team. But thank you so much, project. It was great. This is the last project for the session today, and I just wanted to give a quick shout out to all the hackers who presented today and who stayed with us on this call from all parts of the world.
01:56:42.980 - 01:57:47.418, Speaker A: And in saying that we can introduce our last project, Pyre, you can share your screen with the judges. Hello, my name is Austin and this is my hackath project, Pyre. The problem Pyre is trying to solve is managing Paywalled content distribution without any middlemen approaching the app. As a content creator, first thing in the process is to publish a file. This info is passed to fleekspace daemon, which creates the bucket from the title, adds the file from the path, and then returns the bucket info. Following that, the returned info is again passed as parameters to the new content function on the Pyre contract, creating a new ERC 721 contract. This new content can now be browsed in your published content list, along with some basic steps when approaching the app as a collector, you can view the new content and the library of all previously published content under the Collectible Content list.
01:57:47.418 - 01:58:25.350, Speaker A: To collect the content, a purchase function is called in the NFT contract, sending the payment to the contract's owner and minting a new token to your address. All of your collected content can now be viewed under that list. At this point in the process, the user can consider the file to be in their cloud storage or a sort of cold cloud storage. To request the content from the network. Pyre uses lib P to p's pub sub. All online peers automatically subscribe to the contract addresses of content they are the publisher of or have already collected. A requesting peer signs a message and then publishes it to the Pub sub channel defined by the NFT contract address.
01:58:25.350 - 01:59:16.722, Speaker A: A peer who receives a request recovers the ETH address from the message sender and then confirms it owns a balance greater than zero. With that contract. They will then get the info returned from the space daemon, share bucket function and dial the requesting peer with the bucket information. Once received, the requesting peer will join the bucket through the space daemon and then pull the file to their local machine. Now they are free to save the file to more traditional cloud storage or the potential to build in support for Fleek's own storage is also present here. And just this morning I got an email announcing Fleek's new space app, and I'm very keen to see how integrating that could smooth this process by providing a more user friendly GUI for managing your published content buckets or managing your collections library. After working on this project for a month and getting a better idea of how all the moving parts behave, the final vision for the project has changed.
01:59:16.722 - 02:00:07.026, Speaker A: Instead of being a standalone DAP and single portal to all of this functionality, I would like to see this become more of a content management system similar to WordPress. If you're familiar as a blogger, you log into the backend of your website, write your posts, and WordPress does some SQL magic to display that in a blog template. Only. With this architecture, instead of content being pulled from a SQL database on the web server, the published content for sale can be pulled to any client that can reach Ethereum. A standard frontend API could be made available for view react or Angular components to build reusable purchase buttons or other features for websites. Much of that API is already present by virtue of being ERC 721 compatible. Currently, these files do not touch filecoin, but I would like to have a storage receipt from that chain as proof the content exists somewhere tied to the NFT contract instead of the bucket.
02:00:07.026 - 02:01:11.350, Speaker A: It would still look to retrieve the file from the thread bucket layer before resorting to filecoin, else the collector doesn't know if the file exists prior to purchase, and Pyre doesn't yet fully solve the problem of relying on no middlemen until there's a filecoin proof to fall back on, with Fleek acting as the middlemen in the meantime. Lastly, something that would be a key incentive for honest peers would be to build in reward features tied to the payment function, such as a referral program where if my friend sends me to an artist, I can provide my friend's ETH address and they would get a cut of the sale. The big feature that may need to take advantage of offchain scaling is for every token holder to eventually get a cut of each sale after them. Once you get into 100K sales per item, that would be a ton of microtransactions. However, building that last one in would turn your collection not only into an investment, which digital collections largely lost the property of being, but one that could return dividends over time. Thank you very much for watching my presentation. Wait, just curious what happened on that last slide? I missed the reference.
02:01:11.350 - 02:02:23.766, Speaker A: Was that a graphics card that died during the thank you very much for watching my presentation, was just figuring out how to unshare. Yeah, the graphics card died on the Monday just before everything was supposed to be due. And it was really bad timing because one of the things that I couldn't test out was file sharing between two different X 86 computers. I have a bunch of pies, but the space daemon doesn't run on Arm. So what you just saw was Brave and Firefox swapping two files between two different MetaMask accounts and properly exchanging the payments. But because it was only one single instance of space daemon that I could manage yeah, it's kind of a dummy demo at the moment. I did try it in virtual machines, but it was running into a problem for sharing the threads via the console, spat out an error with just could not reach the textile thread addresses.
02:02:23.766 - 02:03:30.814, Speaker A: So it's probably the virtual machines, but I would have liked to have tested that out on the bigger machine. And is the plan to move to do some stuff on IPFS when you have more content address publishing for some of the files? Sorry, could you repeat the question? Is that plan, like, when you guys have more like you have more publishing of public pages or long form whatever to move towards IPFS? Yeah, that's probably where I'd like to see the incentivization come in, is being actually, it was the demo video for building the presentations. I think it was Web three torrent, something similar. But on IPFS would be nice, because one of the problems with my project right now is that if the initial publisher goes offline or there's not a root seeder to provide the key or the content, there needs to be some sort of incentivization system. So something like that built on IPFS to get people to send content that way. To maintain one root seat of the content would be one of the next things to build in, for sure. Awesome.
02:03:30.814 - 02:03:46.022, Speaker A: And I would like to do that on IPFS. Yeah, keeping everything in house under fleek was really a big attractor for using their sponsorship tools. Was just a one stop shop. Thank you. Great presentation. Thank you. Yeah, great work.
02:03:46.022 - 02:04:28.882, Speaker A: I was just curious. You spoke briefly about moving towards, I guess, making this more of a framework for people. Do you want to speak about kind of, I guess, the project and how kind of that evolved to being the path forward because it doesn't seem like you started out with that being the path. Yeah. Initially I was thinking coming into it, I'd like to build just a single web app because it's the easiest way to get multiplatform support, just mobile, everything else. But then looking at the tools, the space daemon does require a direct installation to use. So as soon as that started to get implemented and certain things needed to be installed and then yeah, super.
02:04:28.882 - 02:05:25.026, Speaker A: Last minute the space app was announced. It just seems to make more and more sense to have a portion of the functionality of this content management system to be only operational if someone has the software running on their local machine and then the rest of the features just available on the web app. As an example, the Fleek storage JS library currently lets me join a bucket just in the JS library without having anything installed. So in theory, the way that this would work is the publisher would need the space clients to do all of the encryption, managing the threads and all that. But then the content, the person consuming the content would download it. They'd get it, they could verify the hash, make sure it is their content, and then issue an ad to their fleek storage. And then if there's a I'd have to build it.
02:05:25.026 - 02:05:53.838, Speaker A: But a UI interface that would be able to operate just on any web browser as long as you have the Fleeks API key to then get your content anywhere from your mobile device. Did that answer your question? It gave me context to more than just my question. But thank you for that answer. Could you give me a second chance at answering it better? No, I would say that's better than what I expected as an answer. Oh, okay. Thank you. Right.
02:05:53.838 - 02:06:48.282, Speaker A: Could I expand on the content management system, though, just a little bit more? Sure. I believe you still have a few minutes. Okay. Just because I'm not a designer myself and I don't really feel my UI is functional, but a lot of artists I've been talking to, a lot of my friends are from the music scene. It would probably be better to give them the freedom to set up their own storefront and just having various components to plug into. I don't think WordPress has the ability to support that functionality. But if they're going to Squarespace or any other framework that supports react components, angular or anything else like that would be the idea is to provide as easy a possible method for content creators to just publish and then somebody to consume without talking to anybody in between and a content management system like WordPress.
02:06:48.282 - 02:07:10.994, Speaker A: Because right now that's all you need is you just need to go download WordPress, set up a lamp server, you didn't talk to anybody you could just share your IP without registering it. And it's that level of simplicity and reusability that I was going. Awesome. Awesome. Thank you so much. Thank you. Thanks, Austin from Project PIA.
02:07:10.994 - 02:07:40.042, Speaker A: That was great. Yeah, that was the last demo for the day. And I just want to say one big thanks to our judges for joining us today and doing the hard job. And, yeah, I just hope everybody has a great rest of the week and thanks so much for joining us for this judging session. Thank you and for all the people who made this happen and for all the hackers. What an incredible day. A lot more than I expected.
02:07:40.042 - 02:07:57.560, Speaker A: So thank you so much for all your hard work this past month. Yeah, I'm blown away. This is awesome. It was so much fun to see all these projects and everyone's so skilled and talented. Really fun to be here. Most of the time I was quiet because I was speechless. Awesome.
02:07:57.560 - 02:08:02.100, Speaker A: Cheers, guys. Thanks, everyone. Bye. Thanks. Have a great day.

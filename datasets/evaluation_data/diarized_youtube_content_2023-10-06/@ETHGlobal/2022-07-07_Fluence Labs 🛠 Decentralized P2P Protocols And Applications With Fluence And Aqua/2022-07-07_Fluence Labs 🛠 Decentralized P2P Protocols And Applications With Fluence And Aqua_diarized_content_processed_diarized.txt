00:00:06.090 - 00:00:23.438, Speaker A: Oh, there we go. And if you don't like asking questions in front of everyone, feel free to just drop them in the chat. We'll be monitoring that and then we'll have Bernard answer them at the end and yeah, Bernard, feel free to take it away.
00:00:23.604 - 00:00:45.050, Speaker B: All right. Hi, everybody. Thank thanks for having me. Years gone by since the last hack effect, so it's super exciting. It's almost right a summer and very happy for everybody to be here. So the workshop is half an hour, so we're not going to be able to get everything done. I usually try to get done, but hopefully we'll get enough done.
00:00:45.050 - 00:02:00.882, Speaker B: So ask questions, put them in the chat, ask them, and we'll stop periodically and obviously we can deal with them at the end as well. So the workshop is all about decentralized peer to peer protocols and applications and how to accomplish that with Fluence and Aqua big statement, and we'll spend the next 30 minutes or so unpacking that very statement. So what's Fluence? Fluence is a stack that includes a decentralized peer to peer compute protocol, a network and a whole bunch of tooling. Everything's open source, very permissive, Apache, TV, blah, blah, blah. And the network in it by itself, it's bootstrapped by Fluence because it's peer to peer protocol, peer to peer network, it's open, it's permissionless, so anybody with a node that's protocol compliant can join and participate. So you've probably seen all this how we got from web one to web3, and I don't want to dig into the details of it, but the important part is that we want to decentralize through peer to peer networks, which is very different than just decentralizing. Decentralizing a bunch of services is easy, but it doesn't give you the Web Three attributes we're looking for.
00:02:00.882 - 00:03:13.260, Speaker B: And if you start decentralizing with peer to peer or on top of peer to peer networks, you actually get those desirable peer to peer web Three attributes. And those attributes are reducing your deplatforming risk, reducing costs a lot, reducing rent, taking both at the network and the application level, increasing availability, increasing failover, all much cheaper, reducing your censorship exposure, reducing your exit barriers. If you lock into a system like some cloud providers, it's easy to get in, very difficult to get out. Same with social networks, easy to get in, impossible to take your data out. This is where peer to peer type decentralization comes in and is super helpful. And if you look at what we want to do, we want to decentralize a lot of things or everything in order to unlock those Web Three attributes. And we've seen it on the crypto side, particularly in decentralized financing with crypto smart contracts, DeFi, a lot of decentralization has been happening.
00:03:13.260 - 00:04:36.690, Speaker B: And what we really want to look at, though, is we want to look at the stack a little bit more. If you want to look at it from an OSI perspective, and drop down a little bit more into how we decentralize at the quote unquote internet level. So if you look at storage, for example, IPFS filecoin, are we many more or a few more? All peer to peer decentralized storage allow you to control your data. That doesn't prevent others from copying your data once you use it or allow them to use it. But you have your data, you control it, you can move it. If you're in a social network and we get to network in a bit and you want to move, you have your data identity super important, right? Self sovereignty. And again, the technology around decentralized identities, verifiable credentials and the whole linked data structures that we've been building for the last few years in conjunction with cryptographic tools really unlocks an entire different way of how to authenticate and authorize yourself in a variety of systems where you or the user stays in control of their data, including their authentication profiles, which are increasingly based on cryptographic tools like key pairs instead of just the password login which are stored at somebody else's machine.
00:04:36.690 - 00:05:37.650, Speaker B: Networking particular social networks, very very difficult to get out of them. And if you look at efforts like Mastodon, for example, which are super, super cool, starting to build a real alternative to some of the big players, and as the new generation of people with more, I don't know, requirements or even entitlement towards controlling their own data grows up, I think you'll see a big switch in those adoption of social networks. And where we really want to get to is computing, right? Because computing can also be decentralized. And if you need an example analogy, centralized computing today would be for example, Amazon Lambda or Google workflows. And so you can start thinking how do you decentralize this? And this is where fluence comes in. So it was a very long wind up to getting where I wanted to go. So there are different ways of decentralizing computing.
00:05:37.650 - 00:06:35.814, Speaker B: So if you look at it from a smart contract perspective or on chain perspective, you're operating in a deterministic context. So that's not good enough for everything, for global, for universal compute, but it's good enough for on chain compute and that's what really matters. But you need to usually supply off chain capabilities to support on chain capabilities and it's a very interesting model, but it's limited. Then you can start looking decentralizing from hardware marketplaces, for example. So you look at Gaul and Livepeer for example, very high intensive compute using aggregate compute resources and a lot of the management actually is on chain. So those are specific compute instances by and large and that use on chain for management. And then we want to get into general purpose peer to peer compute.
00:06:35.814 - 00:07:27.222, Speaker B: So I told you peer to peer networks are interesting for a variety of reasons because they enable things like failover availability much much cheaper than structured centralized networks. And even though we do structure peer to peer networks by structured I mean actually built, designed and managed. Like if you look at virtual private network, for example, in Amazon and a general purpose peer to peer compute solution. Basically you can do any computation, any computation. We want the functions. If you think of it as a lambda service, we want this to be function addressable. So it's not Rest or JSON RPC, but function addressable which is the equivalent to content addressability you see in IPFS and valid.
00:07:27.222 - 00:08:03.270, Speaker B: For example, we want a universal run. And in the fluent case we want WebAssembly because it's super portable and we really believe it's the future of modular business logic expression. And we want the network open and be permissionless. So this is what we want to bring to the table and this is what bringing to the table. So Fluence is decentralized peer to peer compute. Let's skip that one. So what does it actually look like? So if you look at the right, we get a peer to peer network.
00:08:03.270 - 00:08:44.142, Speaker B: The upper left and lower left green circles are peer clients. Could be a browser, for example, could be a node application, could be a hosted script. We'll get to that in a minute. Then you get nodes in peers in the peer to peer network. Those are the blue rounded square ones and these nodes can host services, which is your business logic expressed in WebAssembly modules. The relay fundamentally is a peer that is publicly accessible. Not every participant in a peer to peer network is necessarily publicly accessible.
00:08:44.142 - 00:09:54.726, Speaker B: Could be nodes being behind a map, for example, or it could be a browser which doesn't necessarily which can't hold their connection, right? So you need a relay in order to reestablish connection with that browser if there is something coming back, for example. So if you think about a use case, for example, you can think about a spell checker or a document processor. So in the upper left corner, this is a browser and we typed text, one hawk FS rocks, okay? And now we have two services which we wrote as WebAssembly services and we deploy them. The first one would be an emoji injector. So you send a text now to that particular service and that service now looks oh look, there is one we inject a thumbs up PNG, right? That's the state change. That service operates on that data, which was our text. And then the next service would be spell checking and it's a really super smart spell checker, so it knows it's not FS, it's hackfs.
00:09:54.726 - 00:10:43.050, Speaker B: So again we apply our state change. And now in our workflow we could specify, hey, save that text, this spell check and moji injected text in, I don't know, PDF, whatever you want to do and save it on IPFS. So how do we get to IPFS? I'll explain it in a minute. And then finally, or simultaneously, in parallel, we say hey, send that text to some recipient I want to go to, which happens to be the peer client in the lower left. If you look at it from this peer to peer perspective. So we get peers that connect to each other. These peers are capable of hosting WebAssembly services modules.
00:10:43.050 - 00:11:31.222, Speaker B: And those modules, these services can take on any business logic you want. It's just fundamentally no limit. So we can have this emoji injector, we can have a spell checker, and we can write adapters to other resources out there in the general Internet. So it could be to microservices, it could be to other peer to peer protocols like IPFS. And by the way, we have a fully functional integration with IPFS. So if you want to integrate with IPFS for your project, you don't have to write anything it's fully available for. And now, I told you before that we use function addressability, not Rest or JSON RPC.
00:11:31.222 - 00:12:50.142, Speaker B: So how do you get from here to here to here if you're not using Rest or JSON RPC? Because if you really look at it, what you're seeing here is well, let me tell you first how you do it. We have a language called Aqua, which is specifically designed for peer to peer programming. And what basically allow you to do it allows you to compose services into protocols or applications and use function addressability, where the function addressability of the service in particular, for example, would be the peer ID that's hosting the WebAssembly modules and the service ID, which is unique associated with those WebAssembly modules. So that gives you a tuple, fundamentally. And Aqua helps you resolve that tuple very quickly, very easily, at a very high level. And what you end up then is a data push model, which allows for super thin clients, right? I'm not talking browser thin, I'm talking like, smartphones in the $8200 range, not the $1,000 range. I'm talking about like, really light Chrome OS clients.
00:12:50.142 - 00:13:33.102, Speaker B: I mean, thin, thin, thin, hardware based clients, but also browser, of course. And so we end up with a data push model, right? So I take my text, I write this script in Akbar, basically says, hey, take this text and drive it to the emoji injector. So basically, we create something here, we throw it onto the first relay. It's a browser here, relayed. On that relay, we figure out, hey, we need to find this peer with that service. Magically, it's not magic, but it happens without you having to actually do anything. It then finds that service, the service applies its state change to that data, and it says, hey, are there any steps left in that workflow? Yes, spell check.
00:13:33.102 - 00:14:31.934, Speaker B: So find that peer with the spell check service, apply the spell check state change, and then, hey, are there any steps left in that workflow? Yes, we want to save it in parallel to IPFS, the final state, and deliver it to that client we write it to IPFS. Nothing left, nothing left, terminate. So you may want to be able to send something back to the originating client, but you don't have to. And this is a very different model than your typical client server, right? Where you have the client server, client server, client server, client server, a lot of churn, a lot of bandwidth requirements, a lot of activity. This offloads everything if you want to the network. Okay, so how does this work? We have Aqua, the language and then we have with that language comes Aqua compiler and Aqua virtual machine and we also have Marine. Marine is a general purpose WebAssembly It runtime.
00:14:31.934 - 00:15:30.418, Speaker B: So the WebAssembly we're using is called WebAssembly It and that is different than you may have encountered as WASM bindgen, which is entirely built for the front end for the browser. Yet it does run in the browser because we make Aquavm which executes a lot of that stuff available for browser deployment. But it's a different type of WebAssembly in terms of runtime perspective. So you're looking at WASM time as the underlying runtime, not mind gen. Okay? So every node, every peer in order to be a successful participant in the network runs and we have full reference implementation office, of course you don't have to build that stuff if you want to run a node allows you to basically comes with Marine runtime and Aqua VM. So you take this Aqua script and I'll show you in a minute what it looks like. You compile it and then you send it to the network.
00:15:30.418 - 00:16:14.482, Speaker B: The network then on the network, Aqua VM, wherever it hits first, doesn't matter. Whatever relay it hits, it says hey, find this peer, find the service, just like we went through before. Once we find the peer and the service, we load it into Marine, we execute it, we apply the state changes, go back to Aqua VM, keep going. So you get this data push. So basically the critical aspect for this data push model is what we call a particle. You can think of it as a spark package and that's basically compiled Aqua plus your Genesis data at the beginning and some metadata and this is packaged up at the client level. So at your browser say we have this browser and we have this text.
00:16:14.482 - 00:17:19.914, Speaker B: So it's packaged up in this data structure and now this client finds whatever first relay available on the network and it literally flings this particle onto this relay and this relay says hey, look, this is a valid data structure and Aquam now looks at the script. What has been executed? OK, not executed, emoji injector find me the peer and then we find the peer, we go on this peer, which be direct, right? We may have to relay through a bunch of other peers to get there, but it gets there, that's the point. And then Aquavm, you basically now look again, what has been, oh yeah, here we are in the right peer. We need this service. Is the service available, yes or no? If it's available, start executing. You load it onto Marine, you run through it, blah, blah, you keep going and then when it's all done, you get your state change back. Now the script gets marked up.
00:17:19.914 - 00:18:02.230, Speaker B: This is where the metadata comes in of what has been executed and goes on to the next peer that has the next service until the workflow is fully exhausted. Let me go here. Okay, so what does Acla actually look like? So assume we written a WebAssembly service. The WebAssembly service is a fancy grater that takes two arguments a name and boolean. And the function is very simple. If the boolean is true, let's just say the name is hackfs. Our response from running that function is hi hackfs.
00:18:02.230 - 00:18:44.114, Speaker B: If the boolean is false, it says pi hack FS. So very simple hello world kind of example with added variable in it. So universal. And that's our service we deploy. And now we want to use Aqua to actually utilize that service, right? Because you can't access it through Rest or JSON RPC. There is no IP driven link towards it, it's all peer based. Which of course is one of the big advantages of peer to pin networks, right? Because the peer ID, which is basically a hash of the keys of the peer, are independent from the IP address.
00:18:44.114 - 00:19:27.730, Speaker B: So if the IP address turns or you rotate it deliberately, you can still find that peer just by the peer address in the network. So as long as the churn isn't faster than the DHT updates, you're in good shape and the peer is always available. So we use Acro for that. And if you look down here so the first two lines remember I said we have this WebAssembly service called the Greeting service and it has a greeting. So basically we specify an interface. We call it Greeting service, which takes some service ID. And this is the function we wanted to call greeting takes a name and the boolean and returns a string, right? Hi by akaves.
00:19:27.730 - 00:20:57.086, Speaker B: Okay, so now we got an interface corresponding to our WebAssembly service in our Aquascript. Now we actually want to write the function that executes that greeting. And if you look at the function signature, the first two parameters are the name hack FS, right? Greet, true, false. And then when we deployed our WebAssembly service to that node, we know what ID is and we got by deployment, we got a service ID for that Greeting service and of course we return a string, as we discussed before. So now all you have to do is you basically say on that peer, on that node and the string is actually your ID. So it's like one, two, three, DK, blah blah blah and on that node create a binding of that interface to that particular service ID then use that binding as a namespace and execute that function associated with it. Our greeting for those two parameters hack FS true, capture that as a result on that particular node, and then return that result in this particular instance back to the originating peer, which is different or could be different than the node actually hosting the service.
00:20:57.086 - 00:21:59.154, Speaker B: So if you look at the diagram, what we have is we have a client peer browser, for example, and we now connect to some relay node available. And then we find that node that actually that peer that actually hosts the service. This may not be a direct route, maybe going through many, many nodes, many, many peers. We execute that service on that hosted peer, on that peer that's hosting the service, and then we get the result back first to the relay node and from the relay node back to the client. If you had to do this manually in Lib, P to P or any other sort of general purpose approach, you'd be writing a lot of lines. I mean, depending if you're in C or Rust, whatever, it probably be several hundred in Python probably would be, I don't know, probably 50, 60, maybe 100. And there's a lot of routing related work to be done and it's all abstracted away from you.
00:21:59.154 - 00:22:44.966, Speaker B: So this is actually super powerful. And now let me go back to so are there any questions at this point? Okay. All right, so what tooling is available to you? So we have a Rust SDK, so WebAssembly is fundamentally okay, hang on. Okay, I'll get back to this question at the end. Okay, I'll get back to this. But it's a very good question. We have a Rust SDK to create those WebAssembly services.
00:22:44.966 - 00:23:45.210, Speaker B: We are looking at adding additional languages right now, but right now it's just Rust, and that's actually a very cool SDK. So if you come from JavaScript or non Rust, don't worry about the Rust because it's WebAssembly, everything's passed by value. So everything that's important but also difficult in Rust, like lifetimes, generics object traits, blah, blah, blah, all that stuff doesn't exist, if you will, for the purposes of writing WebAssembly code, because everything's passed by value interface types are very limited. So there's nothing fancy going on if you know Rust, scala, Python, whatever. Honestly, it's the first four or five chapters in the Rust book, and I believe it's a very easy tool set. They use cargo it's cargo to deal with, to compile and debug and run tests honestly, like four or 5 hours. Plus, looking at examples, you should be pretty productive.
00:23:45.210 - 00:24:53.002, Speaker B: And one of the things that Rust SDK allows you to do is actually when you write your WebAssembly code and you do in Rust in this case, and you run your unit integration test, it's on the code. But that's not necessarily what you want, because we're actually cross compiling into WebAssembly. And what the Rust SDK allows you to do is it basically allows you to write tests using the modules you've combined, you compiled, you cross compile those WebAssembly modules as the reference for your unit integration test, which is actually really powerful because you're actually testing what would be out, if you will, on the peer to peer network as opposed to the code that's going into the cross compilation pipe. So very helpful. We also have Fluence JS, so it gives you everything to write a Fluence client, peer to peer client, or a Fluent, depending on how you set it up, if it's long running or not. And it includes full Aqua VM. And actually I think by now the marine runtime is fully available.
00:24:53.002 - 00:25:54.882, Speaker B: So you actually can deploy WebAssembly services onto the fluent JS client and or very the Aqua compiler actually generates TypeScript or JavaScript wrappers around the compiled aqua for you to easily use in JavaScript. So how's that different than anything else? It's different in the sense that you are running the node. So if you want high availability and cheap availability and failover, it's up to you to create that environment. Which basically means you have to host a bunch of nodes. Whereas the other model with rust nodes was with WebAssembly, which is just you send it out, you host it wherever you want to, and you let the running of the services be somebody else's business. We'll get to that and you can basically build and failover in the Aqua script very easily. Okay.
00:25:54.882 - 00:27:14.654, Speaker B: Aqua itself, it's a high level language, it's a compiler which basically takes a high level language and intermediate presentation, which is actually we call it Air. You can think of it bycode it's not bycode it's a list like structure, but it is and it has a command line interface that helps you do certain deployments and a lot of other stuff. Okay, so one of the things that's coming soon is a marketplace and the economics, we currently don't have any economics available. So back to the original question in what incentives peers to host services? Right now, none. The idea however, is that peers that host services charge services or service providers for running the services and it's going to have an onchain component and we're currently working out a variety of models and part of it is also proof of execution, but that's coming. So the incentive is to get paid by services based on quote unquote contracts hosts and service providers negotiate, which is fully automatic, not that dissimilar from what Foddercare does, for example. I hope that answers the question.
00:27:14.654 - 00:28:07.466, Speaker B: If not, post another one. Yeah. So is it possible? Yeah, of course it's possible, but we haven't done it yet, but we're working on it. So there are different ways of doing these verifications, right? And some are actually at the level of the business logic itself. So you write a Web Center service and then you write a Snark or Stark to prove the execution of the correctness of the execution of that particular service. That's one way of looking at it, but that's not very universal. And one of the problems you might run into this on a per service issue is that a lot of these services are not deterministic, right? So, I mean, you have Http calls, for example, and if they don't terminate, that doesn't mean it wasn't executed properly.
00:28:07.466 - 00:28:59.520, Speaker B: It just means that the end resource endpoint wasn't available, which is not an execution failure in itself. So what I'm working on right now, what we're working on right now is basically figuring out a general execution proof that just proves that whatever arbitrary service was provided, and it's not that arbitrary, but that service provided actually has been executed. Not that the result was correct because I said it's non deterministic. We don't know what the result actually is. But yes, that's coming. And that's going to be a super important aspect of the ecosystem and sort of the trustlessness or level of trustlessness available in a permissionless open network, which is very different from Blockchain, right? Hope that answers the question. If not, come back.
00:28:59.520 - 00:29:56.542, Speaker B: How much harder is JS compared to rust SDK? It depends on your background. Honestly, I don't think the Rust part is very hard, but if you never used it, it's probably harder if you're coming from JS than not. But I definitely give it a try. Honestly, I don't think it's that hard. Okay, so we get a bunch of real integrations, which we don't have time for, but we have Bounties. So we have two name Bounties and how do I get rid of the Chat way? Chat best use of fluence off chain compute. Very open, not whatever you want to do, but use Fluence and Aqua to maintain the D in your DAP, to keep it decentralized.
00:29:56.542 - 00:30:36.560, Speaker B: So if you're using, for example, a bunch of hosted providers like infuria Alchemy blah blah blah, you can do verification by replication, which is what safety has done. We got an example on how to do it and look at the examples repo. And so there are two prizes for a total of $5,000 and then a protocol, basically build a protocol with Fluence and Aqua. And examples are for examples. For example, that's a redundancy. Examples are decentralized across chain bridge relay, for example, which is a huge, huge centralization choke point right now in a lot of bridges. And work on that.
00:30:36.560 - 00:31:16.060, Speaker B: There's more. And finally we're on GitHub Discord Telegram, Twitter, we're hiring, if you're interested in that stuff, contact us. Any questions, you can schedule a call with the team because at the end of the day, we want you to succeed. I'm not going to write your project for you, but we want you to succeed both in terms of learning about web free learning about fluence, and actually successfully implementing your ideas. I mean, that's the whole point. And so whatever we can do to assist you in that. That's what we want to do.
00:31:16.060 - 00:31:37.682, Speaker B: We also have a repo that has some additional information, so let me put that in the chat for you. And if you don't have anything mean, I could go on for another 2 hours, but obviously that's not going to work, so might as well stop right here.
00:31:37.816 - 00:32:00.002, Speaker A: Yeah. Thank you so much, Bernard. That was super, super informative and really helpful. We all learned a lot. Yeah. If you have any questions for Bernardo for fluence labs, drop it in the Fluence Labs discord channel. They'll be there to answer all your questions and help you with your projects and yeah, thanks so much, Bernard.
00:32:00.146 - 00:32:06.840, Speaker B: Love the hey, thanks for having me. Good luck to everybody, and I'm looking forward to some awesome submissions. Awesome.
00:32:07.850 - 00:32:09.570, Speaker A: Bye, everyone. Bye.

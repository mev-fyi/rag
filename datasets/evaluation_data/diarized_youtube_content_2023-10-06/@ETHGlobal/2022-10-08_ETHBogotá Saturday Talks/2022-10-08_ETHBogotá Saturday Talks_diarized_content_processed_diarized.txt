00:00:00.170 - 00:03:59.800, Speaker A: On no way to stop me now I can't hear a word it's no way to stop me now no way to stop me now I can't hear a word it's no way to stop me now no way to stop me now I can't hear a word it's no way to stop me no way I can't hear your place it's hard for me to stay away are the lights out or I hate that. I wonder if you're still awake. Damn, it hurts because you know I want to be there, all dressed up in your favorite shirt. It's the worst when I tell you that I don't care. And if I'm being honest, it don't work. I look for a way out a way out just to make you watch me leave and if you're calling my name out it's too loud I can't hear a word it's no way to stop me now no way to stop me now I can't hear a word it's no way to stop me now no way to stop me now I can't hear a word no way to stop me now wait. I can't hear a word no way to sativa can see pieces of my heart like windows in the dark looking out for something that's missing colors that don't change I'm through the shades of gray staring in the night for vision and I shoot up a bed my hope in the end sing it as a way can someone save me? I'm all out of love you say you've got enough for the both of us I make it, baby and I should have a flat don't my hope in the air singing as a singing as a way singing as a west can someone shape me shame? Quiet, it's too loud my faith is on the ground you lay down there with me when I'm lonely I guess I assume they can see this touching every scar fix the jagged parts they cut you but you still want to hold me and I should have hope in the.
00:04:04.430 - 00:05:35.680, Speaker B: Tell me when okay? Yeah. Got you water. I like the mood lighting. Can I also take it off? Can I hold it? Is that okay?
00:05:35.750 - 00:05:39.250, Speaker A: Yeah. Test.
00:06:03.150 - 00:06:17.226, Speaker B: Good morning. Buenos. Yes. Miyamo Jeff. My name is Jeff and welcome to working with Blockchain node provider Infrastructure. I'm one of the ETHGlobal mentors. I'm also a co founder at a company called Curvegrid.
00:06:17.226 - 00:07:16.254, Speaker B: We're a blockchain infrastructure company based in Tokyo, Japan. So this session is a little bit different in the sense that a lot of the things that I'm going to talk about today are less applicable to a hackathon and a little bit more applicable to after the hackathon building taking your DAP that you've hacked together over the weekend and turning it into a production decentralized application. So that's just something to keep in mind this weekend. This hackathon do whatever it takes to get things done, to get things working. But I think this is sort of after the hackathon, after the weekend, what are some of the things you can do to build a production DAP? So we're going to go through sort of three different sections today. The first is a quick overview and reminder refresher on how DApps interact with the blockchain. We're going to talk about the blockchain as a distributed system and these two parts are very important to think about.
00:07:16.254 - 00:07:53.926, Speaker B: The third part, which is how we actually work with blockchain node provider infrastructure. Everything I'm going to talk about today is also 100% applicable in the case where you run your own nodes. But there's some extra things to think about if you're going to use a node provider. What is a node provider? Node provider is a company like Quicknode or organization like Pocket Network infra Alchemy that runs blockchain nodes on your behalf and that you use as a service. So blockchain 101, I think everybody knows exactly what is going on. In this diagram you have a DAP with a front end, a back end. There may also be other components like a database.
00:07:53.926 - 00:08:30.978, Speaker B: It may talk to a third party API and of course it's talking to the blockchain, a blockchain node. This is the part that we want to focus on today, right? The blockchain node interaction. I'm going to go fairly quickly through this part because I think a lot of this is refresher. But again, I want to set the stage for the kind of the meat of what we're going to talk about today. So how does a typical DAP interact with the blockchain? Well, it can call smart contract functions to read data. It can query and listen to events. And those are two distinct things, right? Querying events is reading past events from the blockchain and listening to events is listening to present and future events from the blockchain.
00:08:30.978 - 00:09:04.094, Speaker B: We can do other things that don't involve smart contracts like reading ETH balances. And then we can write to the blockchain by calling a smart contract function to compose a transaction, signing it and submitting it to the blockchain. So these are different typical DAP interactions with the blockchain. You would use these interactions or you would compose these together to build DApps that would do any number of things. Here's a few examples of things that DApps typically do. Display a dashboard of token balances of a particular user. Display those token balances sorted by balance.
00:09:04.094 - 00:10:08.882, Speaker B: So taking all of the token balances, whether it's ten or 100 or a million, and sorting them by balance, displaying all the NFTs that are owned by an address, and other kinds of essentially blockchain state aggregations, right? So the first three of these really fall into the category of I'm reading some data from the blockchain, I'm processing it and I'm doing something with it. I'm displaying it to the user or using it to make decisions, et cetera. Still setting the stage here some common smart Contract interfaces and I just want you to keep these in mind when we talk about some of the things later in the talk. So I think we're probably all familiar with the ERC 20 balance of function. Provide an address, get back a balance. Another one that many of you are probably familiar with is the ERC 721 Enumerable function which allows us to basically provide an address and an index of the NFTs that that address owns, retrieve a token ID. And this is in a case you would use something like this ERC 721 Enumerable or any kind of enumerable Smart Contract capability.
00:10:08.882 - 00:11:24.510, Speaker B: When you want to basically ask the Smart contract what are all the things that you know about? I want to go through them basically in a loop from off chain and then ERC 721 transfer event, right? And events of course are emitted by Smart Contract functions and you listen to them off chain and process them. And they're intended to be used by Smart contract developers to indicate the state chains on the blockchain to make it very efficient to build scalable DApps. So again, just keeping these in mind for the rest of the talk. So some strategies for reading data from the blockchain. Right? Again, keeping in mind what we've just talked about, you can call a Smart Contract function, you can call a balance of or you can call one of the enumerable functions. But then the question becomes how often do you call it? Do you call it every certain number of minutes and cache the results? Do you call it every block? Are you doing this per address? If you're building in a hackathon it's fine because maybe you've got one or two or three addresses. But what happens when you need to start enumerating through the balances of NFTs in a loop for 100,000 addresses? Is that the kind of thing that you can do every single block or not? Well, it turns out a much more efficient way to do that of course, is to process, is to listen to events, process them and cache them off chain.
00:11:24.510 - 00:12:28.366, Speaker B: And this is of course something you can either build in house or use open source or use what we would call a third party chain indexer service. This would be something like the graph or our own multibas event monitor capabilities. Or you can also use a third party higher level API. So something like an NFT marketplace API that will just give you all of the NFTs that a particular address owned or owned at a particular point in time or all of the DeFi prices and balances. The key difference between these three is the first two are essentially much more decentralized and you have complete control over the data that you're getting, how you're processing it, the certainty or quality of that data. Right? If you're reading it directly from a blockchain node or from a node provider, you're calling a Smart contract function or processing events. If you're using a third party, higher level API, the trade off is much easier to implement.
00:12:28.366 - 00:13:05.518, Speaker B: Right. Because they've done much more of the hard work for you, probably cheaper. But you're giving up some of that control and knowledge over, let's say, the quality of the data. And I'm not advocating for you should do this or you should do that. These are all things to be aware of, right? These are the trade offs that we make in software engineering when we're building applications. Okay? So we've talked about DApps, we talked about reading data and if there's anything to take away from the first part of the talk, it's that there's different ways to read data. And the way that you read and process the data depends a lot on the size of your application.
00:13:05.518 - 00:13:36.810, Speaker B: Right? Another thing that when you're architecting, adapt and thinking about working with blockchain nodes is the blockchain itself, right? So we're going back to blockchain 101. This is a blockchain. It's a decentralized ledger. It consists of nodes communicating in a peer to peer fashion over the Internet. And every node of course, keeps a copy of the ledger. I think this is pretty familiar to everyone here. The key thing to think about with this is that a blockchain is essentially a type of distributed system.
00:13:36.810 - 00:14:55.010, Speaker B: In classic distributed system theory or practice, we have the Cap theorem consistency, availability, partition tolerance. You can only have two of three of them, ethereum and most EVM chains optimize for availability, right? You're always going to be able to get data from a node that you're talking to and partition tolerance, they're able to survive the blockchain partitioning in different ways, right? There's a network break, I mean, there's an earthquake and an undersea cable gets cut and Asia is separated from North America or there's some kind of network congestion or an attack or a bug. In node software, the compromise that they make is on the consistency. And the key thing here is eventual consistency. Right? And when we're building a DApp, when we're thinking about how we interact with blockchain nodes or node providers, we've always got to be thinking it's eventually consistent. It's eventually consistent, right? And that drives a lot of the complexities around the systems that you build in a production DAP. There's so much to talk about here, but we're talking about ultimately node provider working with blockchain node provider infrastructure and not different ways that nodes resynchronize.
00:14:55.010 - 00:16:30.414, Speaker B: So I'm just going to keep this very simple and say the nodes can get out of sync and I've written here, not just nodes, but also the network. Right? And so what you have to start thinking about is I might be talking to a blockchain node, but actually I have to think about all of the components in the system as being a distributed system. Right? And again, in hackathon it's very, very simple. You have your Python script or TypeScript, or JavaScript or Go or C or Java that's talking to a blockchain node, doing a single blockchain node, potentially, or a test network that's doing very low volume of transactions. But as you start to add more components into the system, the entire system itself really becomes a distributed system and you have to start thinking about, wait a minute, there's these eventually consistent portions throughout the entire system, right? Not going to go into full Distributed Systems 101, but it's just something to keep in mind that again, this isn't just blockchain nodes, this is the entire system that we're thinking about. And so the key thing here is how does a client that's connected to one or maybe multiple of these nodes handle conditions like this? And when I say multiple nodes again, I don't just mean multiple blockchain nodes, it might be different parts of the infrastructure, right? My client might be connected to a blockchain node here, but then sourcing some data from a pricing API or other data from an NFT API. Do all three of those have the exact same view of the world at the same point in time? And the obvious answer is no they don't.
00:16:30.414 - 00:17:30.158, Speaker B: So how do we start to think about that? So the big question should you run your own blockchain nodes? And this is not controversial at all, this is just Jeff's opinion, but it sometimes kind of becomes the elephant in the room. My overriding long term view is yes, we should all run our own blockchain nodes, no question. But we're not quite there yet, right? And so what I want to do is try and enumerate some of the reasons to think about running your own nodes versus outsourcing this to a node provider. And again, I don't work for a node provider, but we do make heavy use of them. So we have a lot of experience with both running our own nodes and using blockchain node providers. Good reasons that you may want to run your own blockchain nodes are for education hackathons. You're learning for development and testing, right? You're doing a lot of iterative potentially destructive R and D activities and testing activities.
00:17:30.158 - 00:18:45.158, Speaker B: You may need access to the internals of a blockchain node. For example, you may want to enumerate what some people term internal transactions, which is state changes that aren't exposed through the standard RPC API, like ETH balance changes, or contracts being created within other contracts. Or you may have other very specific performance requirements, right? I think in a production DAP, or sorry, not a production DAP in general, these would be great reasons to run a blockchain node, a reason to use a node provider. The first one I think is Cost, right? Anybody here who has run blockchain nodes in the past understands or currently understands that if you're doing it in production and we're talking highly available, you're running a DAP that's being used by in anger, let's say or at a good scale by a large number of people, it costs a lot of money, right? Because you can't just run start blockchain node and you're done. I mean, we're talking you have to think about what happens if the node fails, what happens if the server goes down, what happens if there's a problem on the network. Right now you're running real production infrastructure and there's a cost behind that. Not only the actual, let's say, server and software cost, but engineering time and effort.
00:18:45.158 - 00:19:53.054, Speaker B: And as with many things in this world, it's often easier to let somebody else do this. I think a good analogy for this that we can all keep in mind is it's no different than making the decision between running your own server, whether it's a Raspberry pi on your desk or a server in a data center or a VPs Virtual private server through a service like DigitalOcean or Vulture, or you use a cloud provider, right? Microsoft Azure, Google Compute Platform or AWS. And there's no right answer, right? It's going to depend on your use case and what makes sense to you. But I would argue that for most production DApps, the answer today is node provider, right? So we've talked a lot until this point about some of the ways that we think about reading from blockchain nodes, interacting with blockchain nodes. Now we're going to talk about not just how we think about interacting with and architecting adapt to work not just with blockchain nodes, but the particulars of node infrastructure as well. Node provider infrastructure as well. So speculative node provider.
00:19:53.054 - 00:20:55.010, Speaker B: This is just a block diagram and how it might look if Jeff, who is not a node provider, was thinking about building it. This is what you think that you may be talking to, because this is what, when I'm developing on my laptop, it's spin up a local ethereum dev client and I'm connecting to it. Most DApps, many DApps I should say, will be using one or two kinds of clients, right? Https for doing smart contract function calls, potentially, and then WebSockets for listening to events. And that's critical, right? Many DApps need to have both of these capabilities. But what you're actually talking to when you're working with a blockchain node provider looks something like this. And you can Google, I mean, there's lots of talks on the internet by various node providers and some of them throw up diagrams that look very similar to this. If we start at the bottom, of course, it's not just one node, right? They're running multiple nodes again for redundancy.
00:20:55.010 - 00:22:22.962, Speaker B: On top of that, there's some kind of load balancer that's taking block updates, taking event updates from the nodes and essentially arranging them, right? Am I getting this? Node is having a problem and it's 100 blocks behind. Let's drop that and we'll take the data from the other nodes. That's what, let's say the load balancer, the node load balancer would be doing on top of that, I probably at some point want some kind of distributed cache, right? The reason when you do certain kind of JSON RPC calls to a node provider that the responses come back faster even than your local node is that they're not going all the way down to the node. They're saying, oh, you want blocks zero to 10,000 from three years ago? Well great, I'll just serve that from my cache and there's some kind of local cache and then they've probably got some kind of large scale distributed cache off to the side as well. Then on top of that, they're going to have multiple HTPs and WebSocket servers, again with a load balancer in front of that and all sorts of antidos protection to actually talk to you, the DAP at the top. So when we talk about the cost of running your own node in production, in a generalized sense, these are some of the things, some of the infrastructure that you invariably end up having to build and operate, that you end up being able to offload to a node provider, that can be very helpful. It's great.
00:22:22.962 - 00:23:08.846, Speaker B: Everything is sunny and wonderful, rainbows and unicorns. I've got my DAP, it's got a high performance node provider. I don't have to worry about running nodes. But what do we have here? We have a bigger, more complex distributed system, right? And the key point here is that any one of these components can fail. And you may be the one to notice the failure, you may be the one to notice the issue, or you may be the one to notice the bottleneck. Maybe I want to query not 10,000 logs, but 10,001 logs and I get an error back, which I didn't get from a different node provider, which allows me to query up to 20,000 logs. Or I have multiple WebSocket connections for my DAP, let's say four.
00:23:08.846 - 00:23:57.326, Speaker B: And one of them is misbehaving. Well, maybe there's an issue on a particular WebSocket server, right? And so these are some of the things, when you're starting to architect or build adapt at scale that you have to start thinking about. Yeah, I've talked about some of these, but just to kind of enumerate them, right? Using a node provider doesn't get us away from node issues, right. If a blockchain or a blockchain has issues at the core level or is taken offline for a period of hours, there's going to be node issues. We can mitigate some of that because we're offloading the upgrade and management of those nodes to the node provider, but at some point we could certainly be exposed to that. There can be load balancer issues. I mentioned that.
00:23:57.326 - 00:24:48.346, Speaker B: Again, you think you're connected some of your WebSocket connections or some of your HTP requests are fine, but others fail cache coherency. I'm getting back data that does not match what maybe I'm seeing on a Block Explorer like ether scan right. Or polygon scan the data here is not the same as the data there. And what do I do about that? There could be an issue with the overall node provider. There's many node providers, just like there's many cloud providers. There could be an issue with a particular one that's, let's say a concentration risk if I only work with one node provider and then I have to deal with all the fun things around the blockchain, right? reorgs, blockchain reorganizations, blockchain forks, and I have to be thinking about that. These issues are no different than if I was running my own blockchain nodes.
00:24:48.346 - 00:25:33.070, Speaker B: And then of course, DAP issues. Like there's something broken in my DAP and is it my DAP or is it somewhere in the infrastructure as well? So for all of the benefits that we get from performance, increased performance, not having to worry about upgrades, et cetera, et cetera, there are other things that at some point we're going to have to deal with, right? I would love to give you all the answers and you should use this pattern and do this and do that. But I think probably what you're figuring out is this talk is more about getting you thinking and posing questions rather than handing you the answers. Because like many things in software engineering, it's the journey, not the destination. And that's how it's always going to be. And that's a good thing. That's interesting and exciting.
00:25:33.070 - 00:26:17.718, Speaker B: So just adding some questions to this. So thinking about all of this together, right? And what does this really mean? The first question is how much downtime can you survive? And anybody here who's worked in big it for big corporate companies, the answer is always zero. I can afford zero downtime. But that's not realistic, right? Everything goes down sooner or later. The question is how much you can survive. In classic sort of, let's say, business continuity theory or thinking, you've got two considerations, right? One is recovery time objective and the other one is recovery point objective. Recovery time objective really means how long does it take to get yourself back online, either through failing over to alternative infrastructure.
00:26:17.718 - 00:27:26.900, Speaker B: In this case, if you're running your own node, it would be spinning up another node docker, run docker and getting that working and switching everything over. If it's a node provider, it's switching over to the other one. If you've got an account or madly creating an account and putting your credit card in or whatever and switching everything over, that's recovery time objective, how fast can you be back online? And the second one is recovery point objective, how much data can you afford to lose? Right? The blockchain is eventually consistent and very strongly eventually consistent. And it's proven that over the last seven years with the ethereum blockchain and longer than that for some other blockchains as well. But what happens when you're doing things like storing data that's coming from the blockchain in your own database, right? And that gets out of sync. Somebody put some data in to mint an NFT, and some of that's gone into your database and some of it's gone onto the blockchain because you're doing some kind of semi decentralized activity. Or maybe it made it onto the blockchain, but not into IPFS, right? There's data loss there.
00:27:26.900 - 00:28:05.946, Speaker B: How much can you survive? And that would be recovery point objective. And again, there's no answers here. It's questions. It's going to be different for each production DAP how much data loss can you afford? And yeah, this relates again to Recovery Point objective, actually. How much data can you afford to lose? How much redundancy do you need? Again, I need one server on every continent. I need two servers in every city. That might be realistic someday, but there's a cost to all of that, right? And it's not the kind of thing that is going to be realistic at the beginning.
00:28:05.946 - 00:29:11.150, Speaker B: So you have to think about that. How much do you automate, right? If something breaks, do you even have the ability to tell, is this a real problem or is my monitoring just broken? And I think my one suggestion here would be automate very little at the beginning and then enough so that you can sleep at night and not get woken up. And then what's your budget? Right? One thing I want to talk about here around budget is that node providers can be inexpensive. I listed cost is one of the reasons to use a node provider, not potentially and not run your own nodes for production applications. But a lot of that depends on how you architect your DAP right? And it comes back to everything we talked about in the first part around. Am I enumerating? Every NFT. That all of the users that I know about every single block, am I making requests from six different servers in parallel.
00:29:11.150 - 00:30:09.942, Speaker B: And pretty much every blockchain node provider out there has some kind of concept of number of requests per month. And I think one trend that we've noticed in the past six to twelve months is often have been differentiating, different kinds of requests based on the complexity. So for example, if you just want to know the network ID, they may charge you at a multiple of one. If you want to make a smart contract function call, maybe that's a multiple of five. If you want to query past logs which uses their very advanced Caching infrastructure and gives you response very quick, maybe that's a multiple of 25, and so on and so on and so on. And I think one of the challenges there is trying to compare apples to apples in terms of cost and performance and what they offer. And that's just something to keep in mind, right? And of course you can trade off some of these costs by doing your own Caching as well.
00:30:09.942 - 00:30:12.514, Speaker B: But that of course brings in additional complexity.
00:30:12.562 - 00:30:12.966, Speaker C: Again.
00:30:13.068 - 00:30:47.780, Speaker B: Not for ETH. Bogota. This is all production DAP for when you want to scale after the hackathon. So thank you. I do want to highlight one of the we have this we get a lot of questions around. First of all, let me also say we actually work with basically all of the node providers. So the company that I co founded, Curvegrid, we have a blockchain middleware and we have relationships and business commercial relationships, basically all the node providers and they're all great in their own special ways.
00:30:47.780 - 00:31:36.146, Speaker B: But one question we often are asking ourselves is which one should I be using at this point in time or which one should I be using for this use case? So we've actually put together a public dashboard called Web Three Arena. We haven't officially launched it yet, but I'm happy to share it with you here. And basically it gives you a few different metrics and we have more that we're going to expose over time around the responses that we're getting from different node providers. So right now I think I have the last 30 days polygon main net selected. I'm sorry that we don't have all the node providers out there. We're certainly working on that. We'd love to talk to you if you're a node provider and add your data into here, each of these different boxes here, these four boxes sort of describe the kinds of data that we're looking at.
00:31:36.146 - 00:32:08.810, Speaker B: So we're looking at the latest block number by calling ETH block number on a five minute interval. And as you'd expect, they're all pretty much in lockstep with one another. We're looking at HTP errors. So it's really quite brain dead simple. We just call ETH block number again every five minutes and see how often we get back an HTP error. If there's no lines there, it's because we haven't received any errors in the last 30 days. I think one of the ones that we're very interested in, because we do a lot of work with events, is WebSocket disconnections.
00:32:08.810 - 00:32:58.074, Speaker B: So many node providers that we've found architect their HTPs stack very differently from their WebSocket stack. But WebSockets are the only way that you're going to be able to listen to events. And so in this way what we're doing is just doing S subscribe, which is subscribing to new events, to the zero address. So an address that's never actually going to receive events and we just want to see how often we're getting disconnected. The reason a disconnection is important is it's effectively like we've lost connection with one part of the distributed network. And so when we reconnect, we have to go through like a resynchronization process. And anyone who's run a chain indexer or used a chain indexer before knows that that starts to get very complicated.
00:32:58.074 - 00:33:22.970, Speaker B: So Web Three Arena IO would love your feedback ahead of the launch, looking to add more and more metrics to that. And. Just operating it as a service to the community. In case you ever want to know which node provider should I be using for my particular blockchain, my particular use case at every given point in time. Thank you. My name is Jeff ETHGlobal mentor. I'll be at the mentor table and walking around it in the discord.
00:33:22.970 - 00:33:48.060, Speaker B: You can also find me on discord as well. And that's it. We've got a couple of minutes left. Any questions in the room, I presume we can bring the mic around or you can just shout it out and I'll repeat the question. Going once, going twice all right, I'll hang around afterwards. Happy to have you come up and ask me any questions. Thank you very much.
00:33:58.370 - 00:37:22.350, Speaker A: Glory is all the Olympia, I mean, nearly die. So let me try to make this right, to show you that I'm sorry for messing up too many times and never telling you that I can't be without you and I can't breathe without you when you stop love me like you do. Love me like you do. Love me like you do. I know maybe I wasn't the best behave because, you see, I'm trying to get up and change my way you won't make it easy why won't you let me hold you back? To tell you that I'm sorry forever can you go? Never let in you know that I can be without you without you loving me like you do you make diary you make diary.
00:37:41.550 - 00:37:43.114, Speaker C: Promise me one thing.
00:37:43.232 - 00:38:20.290, Speaker A: Give me and I'll give you the world girl, that's a star say that. Love the game. You try to outrun they try to outgun they can't get enough of a touch I do the ship with a rush. Good.
00:38:21.080 - 00:38:51.992, Speaker D: Hey, everyone, how's it going? My name is Jacob Kabontomsky. I'm a member of the Privacy and Scaling Explorations Group at the Ethereum Foundation. And today we're going to go over some zero knowledge proof basics. And we're going to go over a template DApp project that uses zero knowledge proofs. So kind of go over all the things we're going to cover today. We're going to set up the template repository. We're going to go over very high level kind of how zero knowledge proofs work, specifically non interactive zero knowledge proofs.
00:38:51.992 - 00:39:26.536, Speaker D: We're going to go through a single EdDSA signature demo, time permitting. We'll also go through a modification to that to handle multiple EdDSA signatures. And then I'll cover some additional resources for follow up if you want to learn more. And then finally, we should have a good amount of time at the end for any questions people might have. So first, for the template I'm going to be going through today, we're going to just go over some of the kind of setup instructions. This is called ZKP app boilerplate. It is an app that some colleagues of mine have made.
00:39:26.536 - 00:39:57.276, Speaker D: You can find it@github.com at privacy scaling explorations. ZKP app boilerplate. You can choose either to just clone it directly or there also is a useless template if you want to have something you can directly commit to on GitHub or show off. As far as the dependencies go, like kind of a standard DApp, it does use the Node JS ecosystem and hard hat for all of that. It also uses yarn and yarn workspaces for kind of managing everything in there. It does also require new machine rust and circom.
00:39:57.276 - 00:41:09.210, Speaker D: Two, those last two which are there are links for those on the main README for installing, take a little bit of time to download and run, especially on kind of the local network. Here what you get with that boilerplate is going to be a kind of react web app. You're going to get the proof verification contract and a very simple EDSA DSA mouthful circom circuit that you can kind of mess around with. All right, what are zero knowledge proofs? So in a general kind of setup for that, we have a prover and a Verifier. And so generally the prover is going to be the person who generates the proof and the Verifier is going to be the person who checks it. And so in order for the prover to generate that proof, it's going to provide a number of public and private signals as well as with the kind of proof itself to generate a proof that it's going to use to send to the Verifier. We're then going to send from that prover to the Verifier that proof plus all of the public signals, but none of the private signals in for that.
00:41:09.210 - 00:42:02.696, Speaker D: And then finally the Verifier is going to check whether that proof is valid using those public signals and that proof. So basically we're just going to generate it, transmit it and then verify that proof. This is also known as a non interactive proof. In some zero knowledge proofs there is kind of a back and forth where the Verifier will ask questions of the prover that it has to answer successfully. This requires kind of a lot of chatting and so it has been simplified down to kind of this three step process as far as how that looks from those two different entities, the prover and the Verifier. They kind of have a different view into what's going on inside of that proof. In this case, for the prover, which is going to be the D app actually generating it, you're going to have your public and private inputs which in this case are just going to be numbers A and B.
00:42:02.696 - 00:42:33.620, Speaker D: There's going to be a check inside of the circuit. In this case it's very simple. A times B equals C and there's going to be an output at the end of the proof which is just going to be that result C. So essentially the prover has kind of that full global view over everything that's going on for the Verifier. It does not know any of the private inputs that are going into that. And so it's just going to know the public inputs. In this case, A, it's going to know the output and it's going to know the check that's being run.
00:42:33.620 - 00:43:16.140, Speaker D: So in this case, it knows nothing about B. For this simplified example, it would be pretty easy for someone to figure out the private inputs. So if you had an output of C, say six, and an input A of two, input B of three, well, six divided by two is three. But in more kind of complex examples, it's going to be more difficult for the Verifier to kind of reverse engineer or figure out what those private inputs are for this demo app. What we're going to have is we're going to have the DApp connect to their browser wallet. It has a prover inside of it that's going to use to generate those proofs. We're going to submit them as an actual ETH transaction to a ZK app contract.
00:43:16.140 - 00:43:37.930, Speaker D: So we're going to have that proof plus those public signals as the data inside of that transaction. And then finally, and submit that to an RPC endpoint or a node. And inside of the EVM, that Zkapp contract is going to talk to our Verifier contract, which will be generated from those circuits and it will basically just return a simple boolean saying whether it was successful or not.
00:43:40.380 - 00:43:40.888, Speaker A: Cool.
00:43:40.974 - 00:44:09.792, Speaker D: So let's go ahead and dive in to that example. For this case, let's go ahead and just start with the repo. I already have most of the dependencies installed. So you normally would just have the, as I said, rust Circom. And then you're going to also just do a normal yarn install to download all of the NPM dependencies. You then to compile all the resources in the repo we'll just call yarn build. This is going to compile and transpile all of the circuits for Circom.
00:44:09.792 - 00:44:43.788, Speaker D: It's going to generate that solidity code. It's also going to compile all of these solidity contracts as well. So right now this can also take a little bit of time. This, I think on average for me takes between about 40 seconds to a minute. On this older laptop right here, you can see it's generating the actual circuit. One thing we're also not going to go over in this is going through the actual as part of generating those circuits. You'll generally have a setup ceremony to generate kind of trust for that proof that's kind of all abstracted away inside of this project.
00:44:43.788 - 00:45:17.780, Speaker D: But you can certainly dig into it to see more how it was happening there. Yes, sir, we're going to get into that right after this. So we finished that step and so let's go right into what is the circuit. So I'm going to go through this repo and in general there's going to be, as I mentioned, kind of the different components. We have the actual app up here, which is going to be the actual web app that's run. We have the circuits and then we have the contracts and the circuits, the circuits being the lowest level one. And so let's go ahead and dive in right away to that main Circom.
00:45:17.860 - 00:45:18.696, Speaker E: Can everyone see this?
00:45:18.718 - 00:45:49.804, Speaker D: Okay, cool. So in this sample code we have here and let me scroll down a little bit, we're using Circom Two. We are bringing in a library. We are using the Circom lib has a EdDSA Poseidon Verifier, which is what's going to actually verify those signatures that we send in. And so we're going to talk about let's go to this template and I will go down a little bit. Okay, so inside of our sample we have all of our signal inputs. They're split into public and private.
00:45:49.804 - 00:46:43.350, Speaker D: In the comments, we'll get into how we actually define what's public and private at the bottom of the template. The first input is going to be M, which is the message that we're signing. Ax and Ay are the public key and that's going to be the two components of that. And then private, we're going to have the signature and then the R eight in X and Y are essentially components of that signature as well. We're going to instantiate as a component that Verifier here, enable it, and then we're going to pass through all of those inputs to this Verifier to be enabled for even a more simple circuit. You can go to something like Zkrepple and let's see if this will zoom. Yes, one of the simpler circuits you can do is just doing that multiplication like I mentioned in that first example, which would just be A star B output C.
00:46:43.350 - 00:46:48.992, Speaker D: For this one, though, we're going to be demoing with those signatures in there so we have this sample.
00:46:49.056 - 00:46:49.284, Speaker E: Okay.
00:46:49.322 - 00:47:37.364, Speaker D: And then finally for our main, we're going to define our public components, which are Max and Ay, and we're going to instantiate that sample down below. So this is a very simple single signature verification circuit. What this actually is going to generate when we run that transpile is a bunch of additional assets, including some JS code and some kind of lower level bytes for that circuit. What the actual verification contract looks like is pretty complicated. It's going to have a library built in which is going to be doing all of the pairing cryptography that's going to be involved in the proof verification. So you can see a lot of that here. And then I'm not going to spend too much time on this, but feel free to dig into it later.
00:47:37.364 - 00:48:23.236, Speaker D: And then we actually have the verifying contract. And the important part of this one is going to be this proof. The proof is going to have three components, a, B, and C, which are just going to be points from that pairing cryptography inside of it. And then we're going to have the actual verify function. So this is what's going to end up being called to verify the proof that we pass in, as well as all of the public inputs signals that we're going to pass into there as well. Since this is a generated file, you should not modify this directly because your changes will get overridden on the next generation and this just ensures that the proof is valid as well. So that kind of covers the circuit and then what we're going into as far as generating on the solidity side that we're going to use to verify that.
00:48:23.236 - 00:48:58.640, Speaker D: So now let's actually go into the demo app that we're going to use to kind of show this off. And for that you just run after you've kind of set everything up and built. You do yarn demo. You do need an address to kind of bootstrap this process. For me, what I've done is I've actually loaded in the hard Hat account at number zero and just loaded that inside of MetaMask. You also need to reset your transactions to make sure that the nonces that you're using in that wallet match up with your newly started kind of hard Hat node. For that you can also use another address.
00:48:58.640 - 00:49:40.188, Speaker D: Just make sure you transfer some ethereum to it so it has gas to pay for the local network. And then this is just the note, once again to reset those MetaMask accounts. So this is going to do a bunch of different steps there. Let me think if there's anything else I'll jump into before that. So this demo app contained within it basically has a bunch of different components. It will deploy the contracts for you through the interface. It will have a way to generate the signature that you need to pass in as that public signal and then finally it will be able to generate that proof and submit the contract there.
00:49:40.188 - 00:50:21.970, Speaker D: So let's go ahead. Yes, starting up there. How's everyone's hackathon going thus far? Good, bad. Nice. While we're waiting on that, I can talk a little bit about this, which I think is helpful. This is Zkrepl Dev. This is kind of an online editor you can use to modify circuits.
00:50:21.970 - 00:51:00.240, Speaker D: In this case, you can actually test and define everything inside of here and it allows you to actually run the circuits. You can change the inputs here as well. So, for example, if I wanted to say, get 100 as an output or let's just say 120, let's see if that'll run. Yes. And so we can see here we have the different parameters that we passed in the generated assets from. That the hash that we're using for this Poseidon hash component. And then finally, importantly, that input output, which is 120, which was what we expect from ten times twelve.
00:51:00.240 - 00:51:27.860, Speaker D: All right, we are still spinning up. There we go. Okay, so to start off, this is going to connect to your local wallet. It also supports Wallet Connect. If you're using a different device. I'm going to go ahead and just connect that Hard Hat account here. Next we're going to deploy the Verifier.
00:51:27.860 - 00:52:05.910, Speaker D: So that's going to be that generated contract that we had and that will be a transaction. As you can tell, my Hard Hat network is extremely busy right now handling all of these transactions. And then finally, we're going to deploy the ZK app contract. All right, so we've deployed it, we've connected. Let's look at actually that Verifier contract to just kind of go over what's inside of that. So this is our verification contract. We have an interface that we're going to use for that verify proof function that we're going to pass through.
00:52:05.910 - 00:52:44.716, Speaker D: And then for the actual ZK app, we have defined that proof structure. Here's the Verifier that we're going to connect to. And then here's just a simple list of records that we're going to store after each signature verification. The actual call we're going to do into this contract is record, which we're going to pass in those public signals. Once again, that message and then the two components of the public key and then the proof, which is then going to call verify. And then if that is successful, we will just add to that records variable inside of the contract. For the verify, we wrap that generated Verifier contract in that interface called Verify proof.
00:52:44.716 - 00:53:38.912, Speaker D: And then we just get a simple result did it work or did it not work? And then finally, to kind of see updates on whether it succeeded, we have a total records that we'll check on the actual demo app itself, which is going to be this highlighted amount right here. Let me zoom this in a little bit, too. So first we're going to create that local signature. And so that was pretty quick. What this is doing on the front end inside of our react app is going to be using the signed EdDSA signature here, which is going to be using a local component to kind of generate that signature. Normally in Ethereum for EOA accounts, you're going to use an ECDSA kind of cryptography which is going to be very similar to EdDSA. The major difference from what I've seen is that EdDSA does not use a random nonce as part of the signature.
00:53:38.912 - 00:54:26.048, Speaker D: So the signature should be deterministic for any given public key and message. Otherwise they're very similar with some differences in the curves and some of the other things they're using. So we went ahead and generated that signature. We're now going to create a local proof with that public input and signals. And as you can see, we kind of enabled that there. So now we have our public signals and we also had our private signals, which is the signature and the components of that signature. Now we have the proof and now we're going to submit those as an actual transaction with the public signals and the proof to that ZK app contract and there we go.
00:54:26.048 - 00:55:03.100, Speaker D: So it was verified and confirmed. We have our records updated. So we now have one record inside of there. I could potentially I don't think there's anything preventing me from sending the same proof again since this doesn't verify that there's any sort of confirmation for that. But yeah, that is kind of that basic DApp example running through that. And then let me also show real quick just what it looks like inside of the app for that submission for the send transaction and so let's see here 1 second proof, proof, proof.
00:55:05.600 - 00:55:06.156, Speaker E: Yes.
00:55:06.258 - 00:55:46.270, Speaker D: So we generated the proof and set it here into the state variable we're passing it through the actual call we're going to have to send. The transaction is going to be just like any other kind of contract interaction. So in this case we're going to go to our ZK app contract, we're going to connect our signer so we can do a write to that and then we're going to call the record with those public signals and the proof. Once again the components of that record are going to be the public signals, the message and then the public key components and the proof with those A, B and C components that were generated in that build step. And so yeah, that is our kind of very minimal basic functioning Zkat boilerplate. Are there any questions?
00:55:47.600 - 00:55:48.350, Speaker A: Yes.
00:55:54.400 - 00:57:05.380, Speaker D: So this signal is actually creating the signature. So we're taking a let me go into that real quick. So we're going to grab our account that we've connected and use that as our private key, very secure obviously and then using the public key that we generate off of that, using that signing signature, that signal, that's input inside of this set for this, that is going to be our actual input. That's the signal is that actual signature along with the public key or sorry, not the signature for generating the proof. The signature is one of the private components that we're passing in. So to go back once again to our circuits here so we've just generated the signature which is this input S and then we also pass these other components in the R eight which are derived from that signature. This message is just going to be I believe, let me find that is going to be the simple constant, just 1234 and hex.
00:57:05.380 - 00:57:14.970, Speaker D: So that will be the M component that we're passing in here and then for Ax and Ay is going to be that public key. Does that make sense?
00:57:16.700 - 00:57:18.730, Speaker C: Private part of the.
00:57:27.220 - 00:58:20.210, Speaker D: So yeah, when we go to actually generate that proof right, we do not need a private key but we're only providing as our public inputs that message and the public keys, our private inputs in this case it's a bit contrived but it's the signature essentially that we're doing as the private input. So when we and that DAP are generating that proof. We are going to have both of those components, the signature and then the message and private key. When the Verifier and the contract is running, it is only going to be able to see the message and the public key for that public input. It cannot see the actual signature itself that we've used to sign it, but it knows it exists and it verifies via the kind of underlying cryptography and math in that proof that that output is correct. Cool yes, sir.
00:58:21.240 - 00:58:23.270, Speaker C: I didn't understand why.
00:58:28.760 - 00:58:29.268, Speaker E: Do you need.
00:58:29.274 - 00:59:54.064, Speaker D: It in the first place? To generate the signature locally. But you don't need the private key inside of the proof to actually verify that signature because you already have the components you need to verify the public key, the signature and the message. In this case, you could generate an ECDSA signature, but you could not generate that EDSA signature. For that, we actually have to go and use the JavaScript code that we generated from that build step inside of our client and I can dive into that real quick as well. So that's going to be inside of this sign component and then this hook has been set so we can just more conveniently use it. So we have this from our circuit library and then inside of there is where we're going to actually init the signer with a private key and then we're going to use that component once again here to actually sign that message. Cool james? Yes.
00:59:54.064 - 01:00:06.690, Speaker D: Eventually, if you are using, say, more account abstraction, you will have the ability to generate different signatures that you could use from a wallet natively. Cool yes.
01:00:10.660 - 01:00:13.056, Speaker C: Would it be possible to maybe use.
01:00:13.078 - 01:00:15.292, Speaker D: A system like this to show verify.
01:00:15.356 - 01:00:23.100, Speaker A: Ownership of something asset on chain like an NFT or something, without having to reveal if I was submitting a proof.
01:00:23.260 - 01:00:25.008, Speaker D: To show that I have another wallet.
01:00:25.024 - 01:00:27.104, Speaker C: That actually is the owner of NFT.
01:00:27.152 - 01:00:28.329, Speaker D: For example, I look at a lot.
01:00:28.329 - 01:00:29.716, Speaker C: Of these examples online and I kind.
01:00:29.738 - 01:00:34.088, Speaker A: Of see these A times B examples and that makes sense to me where.
01:00:34.094 - 01:00:35.400, Speaker D: It breaks down a little bit.
01:00:35.550 - 01:00:37.416, Speaker E: Where I want to use this for.
01:00:37.438 - 01:00:44.228, Speaker D: The tool is actually to do things on chain and we can feel like preserve prices.
01:00:44.324 - 01:00:46.984, Speaker A: How would I kind of explore that next step?
01:00:47.102 - 01:01:36.490, Speaker D: So that is a bit outside of the scope of what I'm going to cover here. The general thing that I'm not covering here that you would bring in is something called a nullifier. And essentially you have an internal state managed by say like a merkel tree and you use that nullifier to essentially claim or burn ownership when you're moving those assets around. That's what, for example, Zcash uses for transferring those different assets. I would probably look more into examples that are doing that kind of more asset transfer based thing. There are also our group which I'll bring up a link at the end to our website. We have a number of projects that build on top of this technology for anonymous social media applications, asset transfers within, say, like a ZK or optimistic roll up.
01:01:36.490 - 01:01:52.080, Speaker D: And that would probably be a good place to start to kind of investigate that more. I think there's also been some other talks that dig in more to that more asset or kind of nullifier based circuitry. But for this we're just going to cover and for my own knowledge personally, just kind of this higher level basic circuit.
01:01:53.220 - 01:01:53.970, Speaker E: Yes.
01:01:55.380 - 01:01:58.370, Speaker C: What information is the Verifier actually check?
01:02:01.560 - 01:03:08.310, Speaker D: Yeah. So the Verifier is only checking do the Verifier only has access to these top three components. You as the prover or in this case the DAP has those private components, but the Verifier doesn't have access to those through how the math, once again, a bit above my understanding. The cryptography and mathematics involved in that verification process allow for the Verifier to be sure that given those public inputs and the output that comes out at the end, that C, that it is a valid proof and that those were valid inputs for that proof. Does that make sense? No. Yes. So yeah, inside of that check for that proof, that is what is actually going to run inside of that Verifier component we brought in.
01:03:08.310 - 01:03:17.770, Speaker D: That is what is actually going to check that that private signature input in its kind of abstracted form matches the inputted message and public key.
01:03:20.180 - 01:03:20.976, Speaker A: Cool.
01:03:21.158 - 01:03:22.290, Speaker D: Any other questions?
01:03:22.740 - 01:03:23.490, Speaker A: Yeah.
01:03:26.500 - 01:03:28.050, Speaker C: What can you do with it?
01:03:28.820 - 01:04:31.700, Speaker D: You can do a lot of things. One of the bigger ones, as gentlemen over here mentioned, is being able to kind of privately swap assets is a big use case. You can do things where I've seen examples where you may as, say, like a bank be able to have someone verify who they are by passing in, say, their Social Security number, date of birth and a pin as private inputs and having a circuit that runs to verify that they are the correct person without revealing those private inputs. So I think in a lot of cases, the big two ones that are kind of always mentioned are going to be scalability and privacy. There's going to be a lot less data for some larger computations that you pass from these proofs and these signals into your actual verification, say, on chain in the EVM versus if you were to directly run all the computation yourself to check those in a contract in, say, like normal solidity code. And then obviously the other big component is going to be privacy. So if you have inputs you do not want to reveal to anyone else, any case where you might be able to use those would be potentially a good use case to use a ZKP.
01:04:36.540 - 01:04:37.290, Speaker A: Cool.
01:04:38.540 - 01:05:16.132, Speaker D: I think I have roughly about two minutes left. So I'm going to jump right to the end. I am going to skip over kind of that multiple example for the zero knowledge proofs. But if you want to check it out on this repo, there's actually a branch already set up for this. You can ignore those wonderful errors. You can actually just go and there's a tutorial in that README and a branch for that that you can check out that modifies the circuit. So now, instead of just doing one of these signatures and messages and I'm sorry, one of these kind of payloads, it now can do.
01:05:16.132 - 01:05:58.800, Speaker D: In this case, we're setting it to three. But you can see here how you can kind of expand upon some of those simpler examples and build them out into kind of bigger use cases. Finally, a couple of other things if you want to look for some additional resources. Ethereum.org has a really good overview of zero knowledge proofs, and the further reading has some really good deep dives into the actual technicals of what math and cryptography are being used to generate these proofs and verify them. The Circom docs are really good if you want to learn more about writing circuits and the different components you can put into those Circom Lib, which I showed with that sign. Verifier has a lot of templates and primitives you can use when building circuits.
01:05:58.800 - 01:06:42.524, Speaker D: I showed off the kind of online Circom editor you can mess around with things. And our group also has a bunch of Zkjs Libs in ZK kit that you can use in your kind of scripts, servers or front end applications. Along those lines, if you want to learn more about us and some of the applications and things we build, you can find us@appliedzkp.org. And then finally, if you have any questions about this project or anything else ZK related, you can jump into our PSE discord and we have a channel called Got a question? You can also find that discord on that applied ZKP website. And I believe I'm out of time. Oh, one last question. Sure.
01:06:42.524 - 01:06:43.710, Speaker D: You're welcome.
01:06:48.190 - 01:06:48.940, Speaker A: Cool.
01:06:50.670 - 01:06:52.140, Speaker D: Awesome. Thanks everyone.
01:07:18.350 - 01:10:23.058, Speaker A: Like I thought it dream seven away. I'm a single. You're breaking, you're breaking, you're breaking. Sam. Sam. I wanna feel you the one who care for you. I want everyone wanna feel you.
01:10:23.058 - 01:11:29.100, Speaker A: I know you feel. I wanna you don't want to count for you know I want to do papa Sam SA.
01:12:02.950 - 01:12:40.534, Speaker C: Hey guys we are starting the lecture and the worship about Sirtora soon. So just for you to be ready, the worship is going to be hands on and you will have the chance to use our tool practically. And for that I would ask you to install docker, the ones who didn't get the instruction by mail. So please have docker ready and Visual Studio code and remote containers extension for Visual Studio code. But docker is the heavy part because of the Internet might be a bit too slow. So I would recommend you to start installing it now if you don't have it on laptop, the. Docker desktop client.
01:12:40.534 - 01:12:43.940, Speaker C: All right, you.
01:12:47.030 - 01:15:08.080, Speaker A: The one for you. I want you ram sam it. Yeah, got it. You want to use this step? Okay. So use yours if you want.
01:15:11.090 - 01:15:12.400, Speaker E: It's not working.
01:15:14.710 - 01:15:15.266, Speaker A: Yeah.
01:15:15.368 - 01:15:19.854, Speaker E: What do I have to do? Maybe use yours.
01:15:19.902 - 01:16:31.020, Speaker A: Can you use yours? Take this. Take yours. Love dream. Dream once in my life, wish I didn't there you.
01:16:37.790 - 01:17:10.070, Speaker E: Hello everybody. Can you hear me? Fantastic. So I'm only the introduction, so don't worry. It's basically a hands on workshop. But I thought maybe I can give you a little bit sort of high level interview about sort of overview of how this tool works. I really encourage you to ask question during the presentation. So the pain point that we are addressing, I'm sure you know, but it's not specifically to web3 that you have buggy code.
01:17:10.070 - 01:17:55.090, Speaker E: I think there are a lot of code analysis tools in web Two and in web3. And what my feeling as somebody who's working it mainly from the academic side that they don't work and there are two reasons why they don't work. And you can see it from most existing tool is that they have false positive and they have false negative. They miss errors and actually most of the errors that they report are not real. And this is actually where you will see if you can come and stay in the workshop. Yua and Sasha and Armin, they will actually show you how to make this tool which actually works at the moment is only in webtree and Solidity and Viper. But we think that this tool can be used also outside the area of webtree.
01:17:55.090 - 01:18:29.706, Speaker E: What Satora is doing. And we are building different tools. I'm only going to show you and this on the workshop. It'll be only the Satora approver, but Satora is building different tools for code security. And the other side of the coin, which is something Satora doesn't do, but it's equally interesting for us and that's why we are here is the connection with the security team. So basically there are security teams like Code Arena actually interested in spare Bit and others twelve bit that interested to use this technology. And there is synergy between the people, between the community and between the tools.
01:18:29.706 - 01:19:21.326, Speaker E: And that's actually something we love about it. And of course, if you want to engage with us, you will get actually a trial key and you can try the tool. And if you want to work with us and also with Colorina that's actually doing this, that's great. So basically the glue, the interface between the community and the people at the moment is this CVL language that you will learn and you will learn from the team here. Basically it's a language for expressing properties of your code. So you write some kind of properties of your code in our language and then you can use our tools to do many things and in particular we can find bugs for you. So maybe just sort of, just to give you intuition why I said that actually existing tools do not work.
01:19:21.326 - 01:19:44.786, Speaker E: I'm actually using one of the best air for tools. So this is slitter. How many of you know Slitter? Fantastic. How many of you use Slitter? So Slitter is fantastic tool because it's actually very easy to use. But the problem with Slitter, and you can see that here, I ran it on a very, very small contract. It's a tiny, it's basically a low word. And you see many, many red arrows.
01:19:44.786 - 01:20:20.546, Speaker E: Do you want to guess how many of them are real? None. Exactly. So the problem we want tools and what you will see today is tools that you have arrows that when they are produced, they are produced with actually sort of a test case showing the violation. So how does the Satora tool work? You will see. Actually today you will learn. But the idea is that you kind of write your code twice. You write once you write your code in Solidity or Viper or Rust or any other language, and then you write what you think about your code.
01:20:20.546 - 01:20:48.506, Speaker E: These are specification, these are some properties of your code. And the tool can do two things. The tool can give you a proof that's very interesting, but it's a bit boring. It says, okay, verify. But the most interesting use case of this is finding bugs which are hard to find. And we have actually used this tool before auditing and after the best auditing and found very interesting edge cases in your code. Some of them you can actually use to actually deplete completely the money.
01:20:48.506 - 01:21:30.230, Speaker E: So this is the tool that we are using. It's basically a tool that actually automatically either prove property or actually find test cases indicating violations of these properties. I have to warn you, we are addressing a very, very hard computational problem. It's considered the hardest problem in computer science. And this means that the tool is doomed to fail in certain cases if your code is too complex, if you have inline assembly, we can handle it. And we need sometimes help from the user. So there are failures of the tool and there are mechanism where you can handle failures.
01:21:30.230 - 01:22:11.250, Speaker E: So if your code is too complex and this is unavoidable, because we are addressing a problem in computer science, which is called undecidable, which means that the computer will always and since our tool is automatic, unlike existing framework, if you have this tool is automatic, you just write what you think about your code and it's almost like unit testing. You get approved or you get a violation inside cetera approver. I'm not going to be able to show you. But there's a lot of technology involved. There's a lot of technology. And interestingly, the tool actually doesn't analyze your solidity code, it analyzes your bytecode. So it invokes the compiler.
01:22:11.250 - 01:23:03.042, Speaker E: And then after that it analyzes your bytecode and it's implemented a lot of sophisticated method that we actually have developed and it were developed in academia in the last 30 years. In order to work them, most of them are relevant not just for blockchain, they are relevant for low level code. In particular, I want to point out that we have sort of a very, very we pointed out about Slitter. So inside Sartora there is actually a very, very complex slitter. There is a very, very complex code that checks your code. And actually this complex code, by the way, it found many bugs in the Solidity compiler itself, which are acknowledged by the Solidity. And the other thing that we are doing at the moment, you can think of Satora like a kind of smart compiler that compiles your code into a mathematical firmware.
01:23:03.042 - 01:23:44.340, Speaker E: But this is a naive solution and usually it works in certain small code. So what we do, we do a lot of things to make your tool work on realistic code. And this is a lot of complex things. There's some information on our website we actually just published yesterday evening, a white paper we encourage you to read and I don't know if you got it, so we just published it for this workshop, so please read it. And also I'm here this week and there's a lot of people on the team, the R D team is coming, so please ask us questions. This is just one acknowledgement from the Solidity team about Bug security. Bug actually was fined by the Satora program.
01:23:44.340 - 01:24:24.478, Speaker E: So how does it work? You will see later from Eura. But the idea is you write your code and you write some invariant. You see, for example, this is a very, very simple kind of transfer and the invariant says that the total is equal to the sum of balance. Or maybe you say that the sum of the balance doesn't change and the tool can actually give you a proof that this is preserved. And maybe it's boring because it's very simple code, but this is the kind of piece that you can prove. And of course, if you have overflow in your code, then the tool will identify that and give you an edge case for the overflow. But if you do not have a overflow, for example, you're using Safe Mass or you're using Solidity .8,
01:24:24.478 - 01:25:14.850, Speaker E: then in fact it can guarantee generate a proof and it generates the proof on the EVM level. So that's nice, but that's kind of boring. I said this is a bit more interesting here is I guess it's kind of a trivial bug, but this is a case that you have a bug, a code with a bug. I'm sure most of you have seen this bug, it's so silly. But still, do you know what's the bug here? So the problem is that this code does not maintain the invariant here. Do you want to guess? There is a violation, the tool will find it, but I'm sure you will find it too. So what can get wrong here? It's almost like the same code.
01:25:14.850 - 01:25:46.346, Speaker E: It's done in two steps. Basically it's assigned to a local variable and later on and then this local variable is stored into storage. Nobody can help? No. So let's assume it's a U int. So balance cannot be negative. Overflow is an interesting thing, but let's assume we are working with safemas because otherwise the previous code also. So let's assume overflow is a bug.
01:25:46.346 - 01:26:15.974, Speaker E: But I'm looking into a more interesting bug. This bug, by the way, allow you to a lot of money was stolen using this bug. So it's more interesting than overflow. It's almost trivial, but still b z. Yes, reentancy is not a problem here because it doesn't call other code. We can check rentancy, but here it doesn't call other code. Yes, exactly.
01:26:15.974 - 01:26:40.430, Speaker E: Fantastic. Thank you very much. So it's a self transfer and you see the tool actually can find it. So this is the kind of thing that we want to find. And I can show you that we found many more interesting errors because this is a very, very simple error. But still, you know, visit lost few minutes. This is a kind of bugs that we want to prevent before the code is shipped.
01:26:40.430 - 01:27:18.134, Speaker E: So the biggest value of this technology is inside your development. It's basically integrated into your CI. So every time you change your code, you run this thing, you write this specification. And if you write this specification right, you can reuse them every time you change your code. We are finding that sometimes different customer can reuse the same specification, which is fantastic. So what you will learn is writing specification and specification. One way to think about them, and this is of course go back to Aristo, is invariant.
01:27:18.134 - 01:27:49.058, Speaker E: You write some things that you think if this is the property that all your states in your program has to satisfy. And in DeFi the interesting thing, when you have assets, you want to basically make sure that you have enough assets to cover your bill. And this is what you have to write. And you will see later in the workshop that you write these invariant. And what Satora does, it does two things. It's basically build you these tools. And these tools you can actually write invariant and you can check them.
01:27:49.058 - 01:28:39.160, Speaker E: And it's basically a tools for the community, for auditor, for security researcher, for developers to write this environment and to check whether they hold or don't hold. How is Satora doing today? So you see that actually Satora is actually protecting some of the most important protocols in this space. We are actually analyzing many, many lines of code. Actually, if you count in EVM, it's even more the things that we are and people run it like there's companies who run it actually more than us. It's a cloud based, you will see the thing that we are very, very proud of, the bugs that we have prevented. So with this technology, we have prevented a lot of security bugs. And I will give you just example, but you'll see a lot of our website and some actually acknowledged by our customers.
01:28:39.160 - 01:29:17.138, Speaker E: So maybe I just give you a few kind of examples that we found. So, sort of the biggest property that you can think for DeFi is solvency, which means that even if everybody goes to the bank, you can still get your money. So maybe insolvency means that you are bankrupt. And these are insolvency issues which are found by the Satora approver after manual audit. So these are teams which are very, very careful about security. They use the top, and you see that they use the top auditors. And we run the tool after the top auditor said that the code is correct.
01:29:17.138 - 01:29:57.546, Speaker E: Okay? And these are the bugs that are found by this technology. And I think this is actually how you can measure this technology. How many bugs are found? How is this technology compared to other tools? So of course, there's no silver bullet. And even if we run formal verification, is not actually silver bullet. So the idea is manual auditors course can find bugs that formal verification will not find, especially if you don't have the right specification. And writing specification, as you can see, is actually hard. So the idea is that manual audit actually supplement formal verification.
01:29:57.546 - 01:30:23.990, Speaker E: And you should do them both testing and fuzzing. It's very interesting. It's usually cheap and actually Satora is building, but that's usually peaks and inputs, so the coverage is much less. None of the bugs that I showed you in the previous slide were actually found by fuzzings. But it's of course things you want to do. And I mentioned already static analysis like SLITA, which is incomparable, it misses some bugs. And actually most of the bugs that are reported are not real.
01:30:23.990 - 01:30:45.226, Speaker E: So that's very, very different. But of course useful. I want to give you just one example and I think it doesn't have significance, but this is a true phi. This is a team that using the Satora approver. They have done kind of study. They basically use the Satora approver with auditors. And they inserted bug manually.
01:30:45.226 - 01:31:33.190, Speaker E: And they want to know who found the bugs. So what you can see, it's kind of interesting. Many auditors, even good one, they missed bug. Satora also missed one bug. But Satora, and of course Satora, I mean, with the rules that they wrote, but with the rules that they wrote, you see that actually Satora found more significant bug, the tool, than all the humans themselves, all the human together. So the idea is this tool is really, really useful if you compare that to human, because humans are very good in intuition, but identifying edge cases, this is a case that a machine can sometimes be better than human, especially if you write the right requirements. I want to sort of give you a little bit of sort of technical contents.
01:31:33.190 - 01:32:02.150, Speaker E: You will see actually much more with Yura and Sasha. So the idea is just give you an intuition of what is going on. So I took a very simple case of the sushi. So basically sushi, but that's actually AMM. You have basically constant product pool. So you have two tokens and the multiplication is constant. So for example, you have 50 tokens a and 200 B tokens.
01:32:02.150 - 01:32:39.602, Speaker E: And for example, you want to buy 50 b tokens. Okay, so this is what happened. You buy 50, then you have 66 and you see that why do you have now 66? Do you want to tell me why is it that you have 66? What's the rule that is maintained here exactly? The multiplication is constant. So this is the environment that we maintain here. So we maintain the environment that the multiplication is constant. So that's the idea. And if you want to think about it even more simply, it's basically you maintain the fact that if one of the tokens is zero, the other is also zero.
01:32:39.602 - 01:33:20.030, Speaker E: And this is a very simple variant of the code. Okay, but guess what? The trident broke this environment. And when this environment is broken, all the money is lost. Okay? So our tool basically found and this is the code actually the code is not very complex, but still, you see, it has some nonlinear math. So it's burnt single. This is an operation and the tool finds an edge case. It's actually a very rare edge case, but under this rare edge case, you can break the environment and as a result, you can actually get all the tokens in the pools.
01:33:20.030 - 01:33:52.486, Speaker E: So how does it work? You see this true ctardance by the way. You see, I told you it's a simple code, but it's already actually 2000 line of solidity code and it's actually 24,000 line of EVM. So actually the tool handles actually quite significant part of the code. And basically the environment that we maintain is that both of them need to be zero or none of them is zero. And this is a very simple invariant. But look what happened. It found the case that Ellis bends her holding and gets 200 tokens.
01:33:52.486 - 01:34:50.582, Speaker E: And as a result, you see now basically the B tokens is zero and the A tokens is not zero and the environment is broken. And what is the significance of it? The significance of it is that somebody, and this is something of course that the Satora tool doesn't do. The Satora tool doesn't find the exploit, the Satora tool only finds the violation of the environment. But then we manually look at that and show the team that actually you can now once this environment is broken, you can actually exploit the contract. And how will this work? So basically, this is the case, you have this Trident, you have Ellis and Bob. So Bob basically deposit 108 tokens and 100 B tokens. Ellis now deposit also altogether we have 200 A tokens and 200 B tokens.
01:34:50.582 - 01:35:19.010, Speaker E: Everything looks fine. There is also something about LP shares, but I'm not showing to you because it is not relevant to us. But of course there are LP shares. I'm not showing it to you, it's not relevant. And then Ellis transfers eight tokens to Trident. So you see now there's a lot of money in the case, but now Ellis can burn her holding and she can basically get this 200 token. And now you see the environment is broken, as we see.
01:35:19.010 - 01:35:57.082, Speaker E: So what happened now when the environment is broken, what can you do? How can you take the money? So I'm not asking you because you're probably not familiar with the Sushi code, but the idea is in the Sushi is so the environment is broken. So basically, as Ellis, she pays one token and she gets all the Sushi. Okay? So she gets all the money. Basically, you see that now Bob is left with nothing and Ellis got all the money because the environment is broken. So this is exactly what we want to prevent. And actually formal verification is one of the tools to get this. I want to give you just another example.
01:35:57.082 - 01:36:40.446, Speaker E: It's even more interesting, I think, because it's example that found by a team. It's found by the maker team. And basically this is a code that was actually live for four years. And actually this code, I think holds about $6 billion. And you see there's actually Kud Berry, fantastic developer at the Sushi team, sorry, the maker team, he basically wrote the environment with the Sator approver, and then Sator Approver said it's not invariant. And usually, you know, when we work with static analysis tool, when it is a violation, we suspect the problem, there is a problem in the tool. But no, in this case it's a problem in the code.
01:36:40.446 - 01:37:11.000, Speaker E: The invariant is broken because there is a problem in the init case. So basically there is a complicated invariant. It's a bit complex. It has some sum about and actually what it says is that it's a stable coin. So the die actually represent a stable coin. And guess not, guess what, the tool actually can show you that under certain cases it's no longer a stable coin. And it actually show you, you see that the init has an edge case.
01:37:11.000 - 01:37:37.402, Speaker E: In the edge case of the init, it's not a stable coin. I want to actually just give you a little bit of why we are doing all these complex things. So there's a lot of other projects, they are open source. At the moment, we are not open source. Including these are a lot of some fantastic academic colleagues. I guess there is a Misten lab, they have the move language. So a lot of people have actually formal verification and it's called vanilla.
01:37:37.402 - 01:38:19.438, Speaker E: And what they do they reduce to Smt, which is what we do too, but it's only the beginning. So basically the idea is that you can actually build a tool for formal verification, at least an initial tool, very easily. You basically reduce it's like you take your code and you convert it to mass and then you use a solver either to find bugs or prove their absence. So that's basically the idea of the Vanilla solver. You see, I take this code with a bug and you see that actually each line of the code is converted into a mathematical equation and it looks almost the same, but it's not exactly the same. In the left hand side you have a code, in the right hand side you have mathematics. In particular.
01:38:19.438 - 01:39:11.162, Speaker E: For example, in the left hand side you have 256 integers. In the right hand side you have mathematical integers and in the right hand side we can actually reason about the behavior precisely and then basically the tool automatically finds the bug. This is the vanilla verification and this is something that I'm not going to explain to you, but if you do this vanilla verification on interesting code, it will not work. And what we have in Sartora, we have mechanism to avoid that and we are not actually doing this vanilla. We are starting with this vanilla verification but we are doing more things to make formal verification work. And the key idea is actually specialization. We basically sort of do things which are specific to DeFi.
01:39:11.162 - 01:39:55.840, Speaker E: We understand something and we understand some invariant, some properties of your code that makes this formal verification feasible. And this is actually why we can catch all these bugs. So when I told you that we handle EVM, I cheated a bit in a sense that we actually handle EVM that we like, but we can check if the EVM is the EVM we like. And of course this is checked by computer. So the tool is fully automatic. The tool handles your code and checks the properties and verify. And basically I'm just repeating we need this simplification for financial systems because there's a lot of things that make formal verification hard in financial system, nonlinear mathematics and other things.
01:39:55.840 - 01:40:30.294, Speaker E: I just want to point out that we found, as I said, many bugs in the compiler basically using our analysis. So these are bugs that we found. All of them are disclosed and actually fixed I guess designed usually a week by the Solidity team. Let me just give you one to give you intuition. So basically there is persistent storage in the EVM and it's separated from the memory. And you see that actually this is the code that the Solidity compiler had to check that. So you see that anybody spots the bug here.
01:40:30.294 - 01:41:20.692, Speaker E: So basically do you see anybody with a good eye on code? Do you see the bug here, it's actually very silly, but it was found by our tool, but a human also. If you look at it, do you see the bug? So this code is buggy. It's meant to check your memory that you don't do buffer over, but in fact it allow you to do buffer over. Do you see the bug? Okay, so basically you see that this here it says if a length is greater than 31, then it says if a length is equal zero, this is not reachable. And even worse, it is not checked where it's supposed to be checked. So this is redundant. The problem is that the solidity compiler guy, I guess he worked too late.
01:41:20.692 - 01:41:52.260, Speaker E: So instead of writing this if here, he wrote the if here. So this is a bug in the compiler itself, which was actually caught by the Satora tool. And that's the idea. So basically it allow you to actually read memory, so you can read memory out of bound, which we don't want. And of course this is actually prevented by us using formal verification. I think we are preventing more interesting bugs, but then we need specification. But this is a case that we even don't need the specification to find bugs.
01:41:52.260 - 01:42:31.468, Speaker E: I want to conclude basically this tool for formal verification that you see, it's basically give you the ability to check the properties of the code. And we reason about very, very complex things on your code. I think we have this analysis, which we call pointer analysis. We analyze the memory in a precise way, I didn't explain, but if you want, there are a lot of information in the website and in the white paper. And basically the importance of this technology is the bug that we are preventing. Maybe just to give you a quick overview, because you probably hear a lot of tools. There is a K framework, there is Cock framework, there Isabel, a lot of tools.
01:42:31.468 - 01:42:59.192, Speaker E: So these are academic tools, they're very interesting, a lot of people have been working on it. And on the right hand side you see industrial tool. They're equally interesting. These are things like meets wheel by consensus and kidnain mantico and sliter by twelve of beat. So these tools are very scalable. These tools are very hard to use and you can check because it actually require different things. And where is Satora? Hopefully Satora wants to be somewhere in the middle.
01:42:59.192 - 01:43:17.650, Speaker E: Satora wants to be almost as expensive, sorry, as expensive, as powerful as this, but it wants to be something that you can use and you can judge yourself if you stay for the workshop, if this is where we are. But if you want to compare, we have teams which used to work in Maker and you can ask them.
01:43:19.700 - 01:43:20.016, Speaker A: To.
01:43:20.038 - 01:43:48.250, Speaker E: Use in K. For example, the Maker team, they work long time with K framework and you can see. So basically using our tool is much easier. It's almost like a unit test and you will be the one to judge. I think I'm done. There are a lot of people in the team, we have a lot of people, some of them are here. We have expert in formal verification in tools, we have wait, doesn't move.
01:43:48.250 - 01:44:48.572, Speaker E: Yeah, we have a lot of experts which are here on the DeFi. So I'm missing the slide. I want to basically finish this talk by the sort of tell you few lessons and of course I've been in this space for a long time. Formal verification is a very beautiful area of computer science and a lot of very good result. I don't know if you know, in computer science there's thing which is called touring award like a Nobel prize. The most number of touring award are informal method but there are a lot of myths, people miss a lot of things and there are a lot of myths about formal verification which are not real. And I want to basically point out to you because a lot of hype here, especially in the area of smart contract, but not only so the biggest myth on formal verification is only for proof, but actually I think it's wrong.
01:44:48.572 - 01:45:36.520, Speaker E: The biggest value of formal verification is actually finding bugs, not actually the proof. And actually I'm not the first one to say it's, actually people have applied formal verification hardware and by far they reach that. The other thing which is actually not well understood is that people think that formal verification is hard because it's hard computationally it's of course true. But the hardest part in formal verification is actually writing the specification. And I think this is where in blockchain it's very interesting. There are a lot of other things and I already mentioned that formal verification does not replace auditing. But maybe the last thing, this is what I want you to come from this talk is that formal verification is not a one time deal and you don't want to start it late.
01:45:36.520 - 01:46:21.560, Speaker E: Formal verification is something that you want to integrate into your development and you want to start early. And if you are an early project and if you are working on early project, whether you're using our tool or not, it doesn't matter. But start thinking about at least formal specification and even later formal verification or even tools like Nkitnow Slit or any other tool when you start development that's much easier and that's much more useful. I'm done. I want to say basically we are working on this area of DeFi or smart contract. You will see a lot of things, but we have a lot of things about the specification and we have a lot of other tools for checking their specification. So I'm ready to take questions.
01:46:21.560 - 01:46:36.450, Speaker E: I'm hoping you'll get some questions but you also get the other people who will give you more technical and hands on experience. But I'm happy to take questions, no questions. Thank you. Very much thank you for your time.
01:46:41.460 - 01:50:56.270, Speaker A: Whoever you are you killed a lot on my soul. It's all about love. Wherever I am ever I killed it alive on my soul. All of my love. Wherever I am, whoever you are you killed it a lot. On my soul all of a love I go down on me I won't let the sun go down and I'm taking my chance so I call my friends and I tell them to make it I follow my heart don't ask for questions don't have much time so I hope you waited I won't let the sun go down on me I won't let the sun go down I won't let the sun go down feels alright to be wilder because alive like mine is always right there. If I tell you what I really think of you would you want to try to love something new? I won't let the sun go down on me I won't let the sun go down I won't let the sun go down on me I won't yeah, so.
01:51:06.340 - 01:52:34.420, Speaker C: So everybody is ready to start the second part. So after after Muli here gave the high level view of the Certora approver and tools and what is the idea of the whole thing? Our next step is to do something more technical, to dive into how actually working with Certora looks like. And we would like to explain you how to define these properties of the code, how to feed them to the prover, and hopefully we'll have the chance to actually use the tool and write rules of your own. So, like I mentioned before, the practical part will require docker desktop and downloading our docker image, which might be a bit slow with the Wi Fi because many people are here, but we'll see. We'll manage it. So how will the workshop look like? First we will talk about the Sertora approval technology which is mule already discussed it at length from the high level point of view. Then we will give some introduction to the CVL where CVL is the Sertora verification language.
01:52:34.420 - 01:53:32.092, Speaker C: It's the rule that the custom language that we use to define properties, to define rules how the code should behave. Then we will dive deeper after the introduction to CVL we will dive deeper into some CVL features like parametric rules and invariants. Don't worry if you don't understand these terms. We will explain everything in detail. And after we finish explaining all the CVL and the features, we will move to the exercise. Maybe we will have a short break and have to install the docker image for the exercise. So the exercise will be you will try to provide ERC 20 token code box and you write simple rules and basically find this bug and idea is that you can get a feel, get a taste of how it is to do formal verification.
01:53:32.092 - 01:54:07.736, Speaker C: Just pretty interesting. All right so let's start this example sigmundi discussed it what the Approver do. So I will not talk a lot about it. Here is the good code. So we give the correct code and the invariant total supply equals to the sum of all balances. We give both of them to the prover and the proverb says it's fine, the property, the environment always holds. Somebody turned on the mic, thank you.
01:54:07.736 - 01:54:54.570, Speaker C: And when we give the buggy code to the prover and with the same environment, the prover will find a counterexample, which is a self transfer, like somebody mentioned here. So when from equals to two, then the property doesn't hold because kind of new tokens are being minted out of thin air. So everybody understand this part. So now let's give a high level view of Sartora Approver architecture, how the whole process works. So, like we see, first of all, we take the smart contract code and the rules, the specification, how the code should work. So there is some kind of transformation of the smart contract code. We will not discuss that in detail.
01:54:54.570 - 01:55:44.276, Speaker C: And eventually the smart contract code and the rules, they both are combined by the Serator Approver into VC. And VC here is not the venture capital, it's a verification condition. It's a big logical formula that combines both the code and the rules. And this huge logical formula is being fed into several open source constraint solvers. Now, the job of these constraint solvers is to find the variables which do not satisfy the logical formula. So when this set of variables that doesn't satisfy the formula is found, then it's the counterexample. Then it means that the rules don't describe the code properly.
01:55:44.276 - 01:56:40.780, Speaker C: So it means either there is a bug in the code or the rules are not written properly. And if the constraint solvers don't manage to find any variables that violate the formula, then it means that the formula is correct and it means the rules are correct. That means that the rules describe the code correctly. And we call that we prove the correctness of the code. So this is the big scheme, how the Certura prover is built. Okay, so after all these abstract diagrams, let's dive in and start to talk about CVL, how we write this part. So, in this workshop, we work with ERC 20 code, which is probably the most common smart contract in existence.
01:56:40.780 - 01:57:33.948, Speaker C: And we want to start by proving that the transfer function works as expected. All right, so this is CVL. This is for most of you probably first view of the CVL. And CVL is very similar to solidity. It's been designed to resemble solidity so that the Solidity developers will find it easy to work with. And this keyword rule, like it says, it describes one property about the code. So what we want to express what do we want to express? We want to express them transfer functions properly, that after the transfer is called on the token, then the sender's balance is reduced by amount and the recipient's balance is increased by amount.
01:57:33.948 - 01:58:43.692, Speaker C: So this is the basic structure of the CVL rule. First we do some operation and then we describe the assertion. We assert something. We describe what should the state be after the operation has been executed or performed. So here we see there is all these variables, but I guess we're all developers here, so we cannot use variables without defining them or declaring them somewhere. So let's see how we declare these variables. So my balance will be balance of message sender, which makes sense? Message sender sends the tokens and recipient balance is the balance of the recipient then we call the transfer and we check the balances again my balance after the operation, recipient balance after the operation and we do the assertion right? So if these assertions are true, then it means we've proved the correctness of the transfer function.
01:58:43.692 - 01:59:29.954, Speaker C: We prove at least that the balances are increased and balances are handled correctly. Maybe you can see some definition is missing in the code, right? Anybody can see which variable just is mentioned but is never declared. Yeah, the contract also and some local variables. We see the recipient and the amount they're just mentioned here. But actually the compiler would not know what is these variables. So let's handle that. Let's pass this recipient and the amount as parameters to the rule.
01:59:29.954 - 02:00:24.760, Speaker C: So basically rule is similar to a function syntactically and we can pass any parameters to this rule. So now when we use the recipient and the amount in the call to Smart contracts transfer compiler knows what it is. It is this parameter to the rule and the way Sartora Approver works you can think about it as if Sertora Approver will try all the possible combination of these parameters, all the possible amounts, all the possible recipients. Of course, it's impossible to actually try all the possible amounts, it will take long time, but because we use logical formulas then we can think about it as if trying all the possible values here. But there is still another thing which we didn't declare. And this is the message sender. So what is this message sender? We all know message sender from solidity but in Seville it's just a little bit different.
02:00:24.760 - 02:02:06.300, Speaker C: Before we talk about that, we should mention that these variables like recipient and amount, they can also be declared inside the function inside the rule and it's identical syntax, just different syntaxes to express the same thing. Just declare these variables for the compiler, so we see we can pass it as parameters to the rule, we can declare them inside the rule, we can pass something as a parameter and declare another variables inside the rule, it's all the same, doesn't matter. So now let's talk about message sender. So the actual syntax in CVL, so in civil, to refer to the environment variables we use a data type called the Env struct and this struct contains all these variables that are built in in Solidity. So in Solidity you can use MSG sender, MSG value, block number, et cetera in CVL because it's not solidity, it's different execution model. So we use this env struct and we can refer to message sender, message value and block number and the others as fields of e of this env struct. So env is the data type and e is the instance, right? So to take the message sender balance, we just say balance of e MSG sender, we just have to make sure that the e is declared so the compiler knows what we refer to.
02:02:06.300 - 02:03:20.926, Speaker C: And another thing, another thing where another important way we use the environment, we have to pass it to some smart contract functions. So when we call transfer, we need to give it the environment as well, because the transfer depends on what is the message sender value, what is the MSG value, what is the MSG sender. So we need to give the environment and then what happens is Approver tries the transfers with all different environments, different message sender, it will try everything. So now our rule is complete, but there is still something is missing. What is missing is the declaration of this smart contract calls. So we know that ERC 20 includes balance off, we know that ERC 20 includes transfer, but we also need to declare them for the CVL compiler, right? So how do we do that? We use methods block. So here is an example of a small methods block and in this methods block we have a declaration of balance off.
02:03:20.926 - 02:04:15.970, Speaker C: Now you will see some keywords that you are not familiar with from Solidity, which is env free. What does it mean? Env free means that we declare functions that don't use the environment, they don't care about message sender, don't care about message value. Usually it's going to be view functions like here we have balance off, we have allowance, these are view functions, they don't change anything, they don't care about the environment. So we declare them in methods block as env free. And it means that when we invoke these functions, when we call these functions from the rule, we don't need to pass the environment of these functions. That's why you can see here that when we call balance off we don't send the environment, we just send this parameter with the address MSG sender. At the end of the day it's an address.
02:04:15.970 - 02:05:02.434, Speaker C: But when you call the transfer, we need to pass the environment on top of the usual transfer parameters, which we all know, which is the recipient and the amount. Okay, so now we wrote the message block, now we have the message block, now we have the rule. And let's see what happens when we actually execute this rule with the Certora approver. This is the output, this is the output of the tool. So when we run the rules it gives you a web page which is dynamically updated with the execution results. And we see on the left side the name of a rule was Transfer. Here.
02:05:02.434 - 02:06:04.534, Speaker C: It's called transfer spec. It should be transfer. And we see that the rule failed. We see this scary red icon. So what could be the problem in this rule? Can anybody say why is this rule incorrect? Why is there counterexample self transfer? Yeah, there is a problem here with self transfer. Yeah, because there is a problem with self transfer. But let's see how Sertora approver helps us understand the problem, helps us understand the so when it shows as a counterexample, it shows what is the state of the local variables in this counterexample.
02:06:04.534 - 02:06:41.698, Speaker C: So if you see here we look at the recipient and we look at the message sender, we see they are one and the same. Yeah, it's zero x 401. So it kind of gives us a hint that the problem here is with self transfer, right? If we zoom in on the local variables, we see the same thing. So the problem is, yes, if we send the token to ourself, the assertion says my balance after should be my balance before minus the amount. But obviously, if we send the token to ourselves, the balance stayed the same. And this assertion is incorrect. So this is how the Certora approver shows as a counterexample.
02:06:41.698 - 02:07:17.694, Speaker C: In this situation, of course, the problem is not with the smart contract code, the problem is with the rule. It's just not written correctly. It doesn't take the self transfer scenario into account. So how do we handle that? It's very common, very common scenario. Because a rule is mostly correct. There's just one situation where it's not correct. So what we do, we add the require, we say let's only look at the scenarios where the message sender is not equal to recipient.
02:07:17.694 - 02:07:56.750, Speaker C: Let's ignore completely the scenario where message sender is equal to the recipient, because it's not interesting for us. And for this we use the require keyword, which basically kind of a precondition. So here we have a precondition, here we have the operation and here we have the post condition. And when we run the rule with this requirement, it will succeed, because now it's correct. So for most of you, it's the first introduction to CVL. This is how rules look like. This is how we write the rules.
02:07:56.750 - 02:08:47.358, Speaker C: We went over rule declaration, variable definition, methods, block and what is the NVA variable? So this is basic intro to CVL. Congratulations. Now you've already seen Seville and know the basis of it. Now let's do something a little bit more complicated. Now let's move to another rule where we want to say that whenever transfer is called, the recipient's balance always increases. What we do is we take the balance before balance of the recipient. Then we transfer some tokens to the recipient, some amount of tokens, then we take the balance again and then our assertion is that the balance after should be greater than balance before.
02:08:47.358 - 02:09:43.620, Speaker C: So I guess most of you already see what can be problematic with this rule. When the amount is equal to zero then this inequality will not hold because the balance after will be equal to balance before. So what do we do about that? Like we mentioned before, we can add the require. So we just require the assumption, we can say okay, let's require that the amount should be greater to zero and then the sertora prover will ignore the scenarios where amount is equal to zero will not look at these cases. Another thing we can do is use an if statement which is a little bit clumsy but it also works. So we say if the amount is greater than zero then balance after we assert balance after is greater than balance before. If the amount is not greater than zero then we don't care, we just return true.
02:09:43.620 - 02:10:42.386, Speaker C: But there is a more elegant way in CVL to express this if statement and this way is to use an implication which we use. Basically it's quite common to use with CVL. Implication is a logical operation which is not present in solidity but it's very useful for assertions. So just a reminder implication, this is the truth table of implication. So it's always true, but only if false predicate implies true predicate then the whole implication is sorry, if the true predicate implies false predicate then the whole implication is false, it's true in other cases. So this is the syntax for implication and it's short and it's elegant way to express this kind of assertions. So we say if the amount is zero implies that the balance after is greater than balance before.
02:10:42.386 - 02:11:50.374, Speaker C: I think we all can agree that it's more elegant syntax and more readable than using if statements and it simplifies the rule because we don't need to use the requires at the beginning. So basically we define oral logic in this implication, right? But what happens when we run this? We will still get some error. And what is the error? Yeah, the self transfers that we had before when the recipient is equal to message sender. So how do we fix the error? Yeah, now we already know a few ways how to fix this kind of error. So again we can add a require that says recipient is not equal to message sender. We could also use an implication, it's not in the slide but also implication could be added here, it just would make it a bit more clunky this assert in the end. So basically implication is like an if statement where the else block contains assert.
02:11:50.374 - 02:12:43.242, Speaker C: True. And just to summarize the ways to work with assumptions, either there is a require as a precondition or we use implication in the assert. Okay, so questions? Until now everything seems clear. Awesome. So now let's move to another syntax, another part of CVL syntax which is revert. So in general, if we use the syntax that we looked at until now, like precondition operation post condition, the proverb only looks at non reverting path. So if during the execution of smart contract it did the revert, then the proverb completely ignores this execution pass.
02:12:43.242 - 02:13:35.862, Speaker C: It will only look at the passes where there was no revert. So in this example, this is a counter, a bit counterintuitive. So let's look at this function foo which reverts if the parameter is ten and now we write a CVL rule which is supposed to test foo. So we invoke foo with ten and we say assert false. So assert false of course means that the rule will fail because we can never assert false and expect true but the rule will succeed. Why? Because when we invoke full with ten it always reverts. So the Certora approval will always ignore this execution path and it will never reach this line, it will never reach this line and the rule will succeed.
02:13:35.862 - 02:13:51.098, Speaker C: So this is a bit counterintuitive part which important to remember that it all one question about reverse does it handle internal reverse internal revert and try catch.
02:13:51.114 - 02:13:51.680, Speaker A: It.
02:13:55.500 - 02:13:57.290, Speaker E: Because I catch it.
02:14:01.040 - 02:14:04.460, Speaker C: Interesting question, how do we handle try and catch.
02:14:09.280 - 02:14:09.928, Speaker A: The code?
02:14:10.034 - 02:14:13.330, Speaker C: If the if the revert is caught inside the solidity code.
02:14:18.490 - 02:14:28.440, Speaker A: We just basically just look into.
02:14:30.170 - 02:14:42.990, Speaker C: The exactly right. So then internal revert is equal to normal revert and then it will be considered the reverting path.
02:14:46.610 - 02:14:48.160, Speaker F: This call.
02:14:50.370 - 02:14:54.560, Speaker C: Contract cause the point to access.
02:14:56.650 - 02:15:22.640, Speaker E: Does the outer function, doesn't revert function in solidity I use try call external function catch the catch catch and then they continue out of function that I test this. Yeah, so if you consider the success, if you have like.
02:15:35.260 - 02:17:10.990, Speaker C: Right, so we'll we see that the proverb normally will consider non reverting pathes but sometimes it's very important to consider reverting pathes as well. So of course code sometimes we have to verify, we have to prove that the code reverts correctly corrects when we expect it to reverts when we expect it to revert and doesn't revert when we don't expect it to revert. So how do we look at reverting passes as well? So CVL has a syntax for that and the syntax is we invoke the function with this little addition add with revert. So this keyword tells the proverb to consider all the passes both reverting and non reverting and how do we know if this function call reverted or not? So we have this boolean variable last reverted which is another keyword in CVL and this boolean variable just holds the result of the previous function call. It's true if the previous function call reverted, it's false if the previous function call did not revert. So this is an example of a rule that uses this syntax. So it says user must not be able to transfer more tokens than they own so what happens is first we had a precondition that says the balance of the sender is less than the amount, right? So obviously we cannot transfer more tokens than our balance, right? So this transfer should revert and then we call transfer this invalid amount.
02:17:10.990 - 02:18:27.504, Speaker C: And we expect, we assert that this call reverted, that the last reverted is true again, because the amount is too large, because the amount is larger than our balance. But when you use revert, there is a lot of small nuances because function may revert for several reasons. We expect it to revert because the amount is too large, but it may revert for many other different reasons. And it's important to remember when we work with reverting passes, now we will look at different scenarios where the function, where the simple function transfer reversed for many different reasons. So first of all, first of all, when we execute this rule, okay, so now we do it a little bit different rule. Now we say the balance is legitimate, right? We transfer with revert and we assert that the call did not revert, okay? Now the balance is greater the amount. So we are allowed to transfer this amount, but we say, okay, let's consider the reverting passes as well as non reverting.
02:18:27.504 - 02:19:22.180, Speaker C: And we assert that there was no revert because it looks good, our balance is good enough, and we try to transfer tokens, but we're still going to get a lot of rewards. Why? So the first reward will be because message value is zero, is not zero, sorry, right. Because message value means there was some ether value sent to this function to transfer, but the transfer is not payable, right? So it will revert because it doesn't know what to do with this. ITER sent to it. So normally when we don't use this add with revert, the proverb would ignore all these kind of scenarios. But when we explicitly tell it don't ignore reverting passes, it will find us all the possible rewards. So because MSG value is part of this variable of E, and like we mentioned before, sartora approval will try all the possible combinations.
02:19:22.180 - 02:19:58.652, Speaker C: Of course it will try E with all values of V, including where message value is one, two, whatever is greater than zero. So here it reverts because message value is not zero. Okay? So we fix that. We say require message value is zero and we expect it to work. But no, it will not work because now it will revert due to overflow. Because when the recipient balance is too large is almost maximum. And when we try to send the recipient three tokens, now we get an overflow.
02:19:58.652 - 02:20:31.116, Speaker C: And now, because let's assume that we use the new solidity, newer solidity versions which checks overflow by default, so it will revert because it cannot add three to this max uint minus one. So it reverts again. So now, okay, let's add this condition. Let's add this precondition let's say, okay, balance of recipient plus amount should be less than max. You in. So we don't get overflow, but now we get a different revert. And what is the different revert? It says message sender is zero.
02:20:31.116 - 02:21:09.264, Speaker C: Right. Because most of the ERC 20 tokens, they do not allow transferring tokens from zero or to zero. And Sertora approval is going to try all the possible values of environments. So of course it will try the environment where the message sender is zero because we didn't explicitly tell it not to try. So now we have to add this condition require message sender is not equal to zero. But we're still going to get a reward because the recipient is zero. And only after we added all these preconditions, now we can run the rule successfully.
02:21:09.264 - 02:21:48.032, Speaker C: And what is the point of all this? The point of this is to explain that when we work with reverting passes, usually there is many of them and sometimes there is more than we expect. So every time we have to look why did we get this revert? Is it interesting? To us, these cases are not so interesting. So we just have to add a precondition and filter them out. So there's a lot of nuance, there's a lot of work involved with working with reverting passes. It's more complicated. Yeah. How long does it take to run a rule? It depends on the code complexity.
02:21:48.032 - 02:22:21.170, Speaker C: So, for example, the simple ERC 20 code running a rule would take maybe 30 seconds of a minute. But when the code is very complex, it can take even an hour. It really depends. And sometimes even we can get a timeout. Like the prover might not be able to prove the formula if the code is complex enough. And then it's a very advanced topic. How to make the code simpler, how maybe to split it into modules, maybe simplify some code.
02:22:21.170 - 02:23:11.160, Speaker C: Yeah, it happens often in real time, real code, not the demo ERC 20 token. Yeah. Can you check the apple? You mean the message? The no, we don't have the message, but we use the trace, cold trace and the variables to understand why it reverted. So the summary of with revert and last reverted. So basically, when we use at with revert, we tell the tool to get to the assert. Even when no non reverting passes exist, last reverted can be used to check situations. It should revert fairly easily.
02:23:11.160 - 02:23:42.416, Speaker C: And checking all these liveness properties is less straightforward. Like we showed, we have to look at a lot of nuances and add a lot of requires. It's common. So another how to say check spot. We finished another part of the explanation of CVL, so we went over transfer spec check addition of transfer rules. Transfer revert. Transfer does not revert.
02:23:42.416 - 02:24:01.880, Speaker C: We already seen example of four rules. We explained the env variable in more detail and we explained with revert and last reverted. And now sasha will explain another parts of another civil features.
02:24:12.240 - 02:24:40.980, Speaker F: Hi everyone, I'm Sasha, also work at Settora. Now continue. Euros talk about other features of the Seville. He explained you, he showed you the properties that we can verify over the transfer. But in ERC we know there are also many other things, for example, allowance and how confident we are about allowance, that it's correctly. Well, it's ERC and we know that it's okay. But let's say you got a new token, you don't know what's going on there.
02:24:40.980 - 02:25:15.084, Speaker F: We also need to check it. Then we start to write a simple rule. We start with defining the rule. Then we usually prefer to start it's like a good practice from the assertion where you express your formula. For example, here we want to say that if allowance was changed, then the message sender was the owner. Pretty simple, but also it can help you to understand what do you need for your rule. For example, we definitely need to call approve because the properties that we want to verify is for now it's only on approve.
02:25:15.084 - 02:26:13.460, Speaker F: We defined the necessary variables to call it and we made a call to approve itself. And the only thing that left is allowance before, allowance after. Simple call, simple rule. If we run it in our tool, we will get it as verified. But what does it mean in general? And now it's the time to talk about the coverage. It's like one of the important property of our properties that we try to improve this part to make the coverage more like if the contract is covered like 100% that we know it's like the perfect it's not easy to reason about it, but we try to do our best. So according to that rule, we can say does it increase the coverage? Is it well written? Is it passing? It might be objective, but we should do our best to improve the coverage.
02:26:13.460 - 02:26:54.210, Speaker F: And what we can say about coverage of allowance? The good thing that we proved that approved is only called by the owner. That's good, but what about other functions? There are many other functions and they can change allowance. One approach is like the most straightforward, but the most tedious. You write specific rule for each function of our contract. Let's say you decided you don't want to check few functions because they don't change anything. There are still many like transfer from increased decrease. Allowance might be tedious and we have a better way, a simpler way to do it.
02:26:54.210 - 02:27:26.252, Speaker F: We introduce notion of parametric rule. They don't ask if the owner called a specific function. Instead we ask if any function was called and what the outcome of that call. This is the rule we have is very specific. We want more generalized and the question how we can do it. Instead of proof, we want to call any possible function of a contract. For this we use method F.
02:27:26.252 - 02:28:01.728, Speaker F: Method is a. Keyword. It means that instead of F, the tool will try to use any public or external functions of the contract. I want to state it only public and external. So if you have something private or internal you need to change the visibility or make another function which calls it like you create a public function which calls your internal function. Then we need to define the arguments of the function and they can be different. Here you don't.
02:28:01.728 - 02:28:44.080, Speaker F: Need to specify it because we have another keyword called it arc. It means that the tool automatically will assume necessary arguments for each function. Like if it's like, only one address as an argument, or it's like unit and address. We don't care right now. The rest we simply copy from the previous version of the rule when we did it only for approval only. And now let's try to run and see the magic happens on the left. Side you can see all the function that our tool try to call and we are the only one but there is one red dot that we don't really like because it's a violation.
02:28:44.080 - 02:29:42.630, Speaker F: I mean, if it's a bug it's good because we prevented it, but it also might be in feasible state. Here we see that it's like transfer from and it's legitimate way to change the allowance as we know it. But let's try to understand what's the real reason of it. And in our verification report, we can get a call trace. The call trace we get only for violations. To see the scenario, to understand in what way we could to violate the property and to understand if it's the bug in the spec that we wrote or it's in the bug in the code. Here we see the arguments that we used for transfer from the sender is 401 the same as owner, recipient is F and also we want to check the emessage sender because this is what we use in our assertion and as we can see here, it's another address, it's four to six.
02:29:42.630 - 02:30:24.804, Speaker F: That's why we've got a violation because the sender is stated in the transfer from the same as owner. But the message sender is not an owner right now and what we can do about it because we have a violation, but it's not a problem. Code we can change our property a bit. And the way to do it that instead of saying that allowance is changing, we want to ensure that if allowance was increased, then the message sender should be the owner. Any questions at this point? Okay. Now, if we run it, we see that it's passing. Well, that's good.
02:30:24.804 - 02:30:57.650, Speaker F: We checked something and we increased allowance in allowance. But there are still some unverified parts about other functions. For example, how we can change allowance. One proposal that we have is to check if allowance was changed by specific functions. And for this thing we use another feature of CVL. It's called method selector. The most of the rule we take from the previous version, but we change the search a lot.
02:30:57.650 - 02:31:44.376, Speaker F: Here we see if allowance before and after different. Then we check using the selector appselector equal then the function signature selector and we know like for example we could write the code and see what changes it briefly like approved transfer from Increase Decrease allowance. We check it here. We can use them in one block with or we cannot use and because in any specific run f can be only one method. So that's why we use the or and if we run it, it will be verified. So we again increase the coverage. Now we're more sure that there is no other way to change allowance.
02:31:44.376 - 02:31:47.890, Speaker F: We are more confident here and.
02:31:50.900 - 02:31:51.216, Speaker C: We.
02:31:51.238 - 02:32:29.592, Speaker F: Covered the main things about the rules. But the rule is only one thing which we use to explain our properties. There is another thing, we call it invariant. It's a property of the contract state that is expected to be true whenever a contract method is not currently executing. As I said, it's like another way to write the properties, but it's only applicable for several types of them. The types of the properties is not a part of this talk. But in general we can reason about valid states of a contract and high level properties.
02:32:29.592 - 02:33:06.692, Speaker F: By high level properties we usually mean if we reason about external dependencies or not dependent on the implementation. On implementation, some properties they are not dependent. Like in ERC, the total supply should be greater or equal at the balance of one user. Just like the simple example. Like some benefits of an invariant, usually it's smaller in the size because it's smaller in the size. It's one of the reasons because why it's really comfortable. It also covers a bit more than a rule because the rule doesn't cover the state after the constructor.
02:33:06.692 - 02:33:52.364, Speaker F: Invariant can do it. Invariant we also can rewrite as a rule every invariant. But not every rule can be rewritten as an invariant. And one of the main disadvantages if you want to check any specific scenario, for example in a parametric rule I showed you that we can call only method F but you can define method F and method D and to see some other interesting outcomes of it. This is an example of the properties that I already defined that the total supply is greater or equal of balance of a user. And on the top you see the invariant itself pretty simple, like only two lines of code and this is how it looks in a rule. And also it can help you to understand what is an invariant.
02:33:52.364 - 02:35:04.636, Speaker F: Invariant is simply the requirement that we defined then any function call, parametric call and then the same assertion this is like how it looks like. But there are several violations we won't stop a lot about how to fix because invariant is more like additional topic for this workshop. But I want also to show you the benefits of invariant in terms of the size and comfortability to use it. Because for example, the first thing that we will see in that violation that in our searching right now we assume only balance of one user and the contractual will be like the total supply equal to balance of a user. But what about all other users? They also can transfer do something. And this is what happened in the contractample for that rules we change a little bit our invariant. Now we assume two invariants, but there still will be the violation in transfer, because it's a parametric call and two and emessage sender in transfer, they can be different from the addresses that we check.
02:35:04.636 - 02:35:42.260, Speaker F: And this will be the violation. In this case we need a preserved block. It's just a set of requirements that will be applied only for transfer. This is how it looks in invariant. We need to make sure that the two equal to account from our invariant and that message sender equal to our sender that the balance of we check. But if we try to write the same in a rule, it takes much more space, much more lines of code, not really comfortable. Of course you can put this if block inside the rule, but then the readability will be awful.
02:35:42.260 - 02:36:27.480, Speaker F: It's better to make as a separate function. But here we need to use again selector, define variables, write some constraints and then we need to call the transfer. So you write the transfer two times instead of one time here, for example. But it doesn't mean that if you define this function, it's always the bad thing. For example, it's good in reusability. If you need to use this function in several rules, like welcome to do it, it's a really good thing because you optimize the size of your code. And as I said, not everything we can express as an invariant.
02:36:27.480 - 02:37:14.212, Speaker F: And this was an example just only for transfer, for all other functions which had violations kind of the same. The main point is just to show you another feature of CVL, how to explain the properties and why it might be good to use it for now. That's it. We covered many things, there are still more things to do, but they are more advanced and it's advanced topic not of this workshop. We wrote the simpler rules, we saw how it can be written. We talked about environment variables, methods, block and what does it mean environment and n free. We considered reverting paths, parametric rules, how we can select methods in parametric rules.
02:37:14.212 - 02:37:33.630, Speaker F: We talked a bit about the coverage, which is kind of a subjective thing. And the last feature was the invariance. Now I think the Euro will take over to talk about the workshop, the practical part of it. Thank you.
02:37:38.900 - 02:38:14.400, Speaker C: So we went into a lot of several features, a lot of theoretical stuff. And now let's try to do some hands on work. So we're going to work on Open Zeppelin ZRC 20 token contract in which we inserted some bugs, really simple bugs. So if you look at the solidity code, you will see the bugs immediately. They're not super interesting. The interesting part is to try to find the bugs using formal verification. So the task will be to write a unit test rule which verifies transfer and the parametric rule.
02:38:14.400 - 02:39:04.292, Speaker C: And then there is a bonus task which is a bit more complicated. Parametric rule? Yeah. So what we're going to do so first of all, you should have the docker desktop on your laptop and you should clone our tutorials repository. So can the people who participate in this exercise raise hands? Okay. So the people who will participate in the exercise so follow this step. So start the docker desktop, then clone the repo. And wherever you run into some issues.
02:39:04.292 - 02:42:15.782, Speaker C: So we have Sasha Armand here, miri will help you with anything. So clone the repo and just follow the steps on the slide it. So again the who followed the exercise, please raise your hand if you run into any issue. We will help you. So yeah, this is the steps. You clone the repo. In the repo there is like files which describes what tasks to next, sorry.
02:42:15.782 - 02:42:37.330, Speaker C: There is also the next slide that explains that you have to go to the CVL workshop folder and see the spec. So this is the actual exercise. If you go there, I will just show you.
02:42:42.540 - 02:42:43.290, Speaker A: It.
02:44:33.450 - 02:52:00.166, Speaker C: So if you start with people who follow, start with the docker, clone the repo, open the correct branch of the repo switch, checkout of the correct branch. And then you have to use the reopening container command in Visual Studio code, use the remote containers extension. This comment will ask you to download our docker image. And then from this docker image you do the exercise. Changed the name. So we're going to do a small change of plans because the internet here is a bit slow to download the docker file. We're going to do some live coding demonstrations how we actually solve the exercise.
02:52:00.166 - 02:53:33.350, Speaker C: So it's going to be more clear for you guys. So our task is yeah, our first task is first exercise is to write a unit test rule that test the transfer function. And we basically need this, we need this assert to we basically need to write rules. At the end of it, this assert will be checked. Right. So how are we going to do that? First of all, like you remember, we need to declare the environment and since we test a transfer function so we're just going to call it with some random recipient an amount. Now we also need to declare this recipient an amount and we need to declare these variables balance Sender after and Balance Sender before.
02:53:33.350 - 02:57:42.706, Speaker C: So Balance Sender before will be will be the balance of the message sender. So all these functions like balance off and transfer and others already declared in the methods block, there is no need to declare them again and the balance sender after will be clearly the balance after the operation. And now the rule looks ready. So according to the instructions we can execute it. We have some mistake here because we didn't declare the type of the variable usually the same, the same type. Now after the rule compiles after a few iterations, now we execute it. And what does it mean to execute it? We have already script, the script just runs the sertora run command CLI tool and we tell the sertora run to verify the ERC 20 contract with the setup spec.
02:57:42.706 - 02:59:04.558, Speaker C: So like we mentioned at the beginning of the talk to the Certor approver, we have to give the smart contract code and the rules. So here this is the smart contract code and these are the rules. So what happens here is that there is some kind of static analysis happening locally and then the tool sends everything to the cloud. So the main chunk of the tool runs in the cloud, just some small local static analysis runs on the computer and most of it runs on AWS. And here we get some command line outputs and eventually it will give us the link to the web page where we'll see the execution results. Here we have a link to the status page and verification report, which is the interesting part. So we're going to click on that and see that the transfer correctness function which we written, which we're writing right now, has failed.
02:59:04.558 - 03:00:06.848, Speaker C: So it's interesting to find out why it failed and we open the call trace. Okay, so in the beginning the balance was two and then we try to transfer 15 tokens which is not supposed to work because with balance of two we should not be able to transfer 15 but it still did not revert. So there is some problem there because like we mentioned, the Certora will only look at non reverting pass and normally if the code is good and you try to transfer 15 tokens from from balance of two, the code would would revert. But here it did not revert. And now we look at balance sender after and it's become huge. So it's obviously an underflow here. It's obviously an underflow.
03:00:06.848 - 03:01:18.284, Speaker C: So this assertion doesn't hold because now balance sender after is huge. It's almost maxi inch and balance sender before was very small zoom. Yeah, so we see the problem, possible problem is with underflow. So now we can go look at the code. What is this bug that you found? And it's a very silly bug. So basically what we did is what we did is we just say unchecked, we do this transfer unchecked. We don't check that the sender has enough balance to send the tokens, and we do unchecked subtraction.
03:01:18.284 - 03:02:44.040, Speaker C: So that's why we have this underflow underflow problem. And the point is that we found this bug not by looking at the code. We found this bug by writing a very simple rule. We call it the unit test rule because it just checks one function, one particular scenario. And the Approver found this problematic case for us. We just try to send too many tokens and the code doesn't check that the balance is greater or equal to the amount. But when there is no check, it just says, okay, we have enough tokens, so let's go.
03:02:48.090 - 03:02:48.840, Speaker A: Ahead.
03:02:50.650 - 03:03:53.520, Speaker C: Now for exercise two we want to write a parametric rule that verifies fixed total supply. So we assume that we work with the tokens that has fixed total supply and we want to write a rule that says no function call ever can change total supply. This is a bit more interesting rule so how we're going to do that? So this is our final assert. So again we do environment method method as we already have. Let's do call data arcs for the F invocation. Let's get the total supply before total before this total supply function is already declared here in the methods block. It's just access to the public variable.
03:03:53.520 - 03:04:43.774, Speaker C: And now the magic part is calling any function with any arguments. And again, we will take the total supply after the operation. And this is a rule. Total supply? That's a very good question. But this would require much more rule writing than we can do. Now, basically, for this, we would need to track locally if the total supply variable is updated correctly. For this, we would use a local state.
03:04:43.774 - 03:04:55.220, Speaker C: In several which we call ghost ghost variable. Basically, like we would have a several variable which tracks the solidity variable it requires a bit of.
03:05:04.870 - 03:05:05.826, Speaker F: Changes happen in.
03:05:05.848 - 03:05:07.860, Speaker E: The balance it will be.
03:05:11.830 - 03:05:54.766, Speaker C: Balanced and then supply and understanding supply. Thank you sigma, how you do? Yeah, you're right. If you want to really work verify everything we need to prove that the total supply variable is updated correctly. After we prove that we can already use this proof and use the total supply variable and assume that it's true. It's good.
03:05:54.908 - 03:05:55.600, Speaker A: It.
03:07:45.750 - 03:08:19.850, Speaker C: Now when it finished checking, we see that the total supplies fixed rule also failed. And it failed on a few different functions on Approve, on transfer from, on cruise allowance decrease allowance. So let's see the first one White felt on Approve. So when we ran Approve, the total supply was 15. Then we executed this generic function, F, which in this particular case was approved. And then we see that the total supply changed. It became 17.
03:08:19.850 - 03:09:32.722, Speaker C: So something happened inside the approve function. And if we drill down the cold trace into the deep inside the proof, we see that for some reason, something changed in total supply. So this cold trace gives us a place to look in the code it tells us to look at function underscore approve. Maybe something wrong is going on there. So let's check this function in the solidity code so we can see immediately that the total supply has just increased the approve just increase the total supply by the amount asked to approve. So it's a very silly code. Again, the idea is to show how we can find the bug not by looking at the code, but by writing a very generic rule that the total supply should not change.
03:09:32.722 - 03:10:34.600, Speaker C: And immediately we see that the approve function does something suspicious, changes the total supply for some reason. And obviously the increase allowance. Decrease allowance and transfer from they also call this underscore approve. So it's all the same bug. And we found a problem in the code just by writing a very short, very concise parametric rule that says check total supply, do any operation, check total supply again and make sure they're equal. So this was the second task questions. And now let's do the third exercise, which is the can transfer balance.
03:10:34.600 - 03:15:30.630, Speaker C: Basically, it's a rule that says that any user can transfer their entire balance out. Must sorry. Yeah require that, but we can do your way as well. So now we did this transfer with revert, which we discussed in the presentation. It requires a lot of preconditions to make sure that we don't get reverts on things that don't interest us. All this stuff, we don't care that if the message sender is zero, the recipient is zero, stuff like that. So now it's now the execution, the verification completed, and we can go to the report and look at this.
03:15:30.630 - 03:19:28.970, Speaker C: Can transfer balance rule and troublemas whitely stone malicious.
03:19:33.310 - 03:19:47.290, Speaker F: Which shows sender with message.
03:19:48.620 - 03:19:49.560, Speaker A: Sender.
03:20:00.030 - 03:20:16.680, Speaker F: Can transfer balance web page.
03:20:18.890 - 03:20:19.910, Speaker C: Browser.
03:20:20.730 - 03:20:35.600, Speaker F: You um, the opportunity which I bought to a set of switches shift to look, don't switch case.
03:20:40.690 - 03:20:56.644, Speaker C: Amount, message value. Okay the material so private lenovia could.
03:20:56.682 - 03:21:14.330, Speaker F: Fill up a car and it's not returns messages. Talk about.
03:21:17.900 - 03:21:24.770, Speaker C: Private netlish. Come sender requires something list.
03:21:27.140 - 03:21:52.530, Speaker F: Sound transfers of whitelisted, no stack, no PD loopwater.
03:21:55.870 - 03:21:56.650, Speaker C: Peter.
03:21:59.710 - 03:22:07.500, Speaker F: Loop addresses optimistic loop condition address. I.
03:22:14.910 - 03:22:19.210, Speaker C: Decided to soft new wet listing.
03:22:20.110 - 03:23:10.090, Speaker F: You non mock address whitelist unit can transfer shut both valuation validated for can transfer bounce violation.
03:23:11.920 - 03:23:12.670, Speaker A: It.
03:23:20.320 - 03:23:24.990, Speaker F: Transfer cold race reward case.
03:23:29.210 - 03:24:48.178, Speaker C: Whitelist revert now whitelist beautiful. So our final task was our final exercise was to write a rule that verifies how a user can transfer the entire balance out. And what we did, we added all these requires for all these preconditions for cases that don't interest us, so we don't fail on message center zero, recipient zero, or message value greater than zero. So we filter all the things that are not important and then we just call transfer with revert and assert that there was no revert because all the conditions are correct for a transfer. But we still see that the function failed, the function reverted. And when we drill down the cold trace we see that there is a line, something about whitelist in the smart contract code line two seven nine. So we will go to the smart contract to the line two seven nine and we see that the transfer function in this token, it requires the sender to be whitelisted, so only whitelisted addresses can transfer.
03:24:48.178 - 03:25:41.780, Speaker C: That's why we got to revert, because actually this is like an example for a malicious token that doesn't let addresses transfer tokens out unless they are whitelisted. So there used to be like rock pool tokens like this, maybe a couple of years ago. You can buy this token, but you can never transfer it out, you can never sell it. So this is another example that this is not even a bug. This is kind of an example for a malicious code. And we can easily detect it with a simple rule that tests that users just can transfer their balance out, right? And the proverb immediately finds a country example. Any address like here 40 one, it's not whitelisted, so it cannot transfer the tokens out.
03:25:41.780 - 03:26:56.790, Speaker C: This concludes the hands on exercise which unfortunately difficult to do without slow WiFi and without installing all this docker image. But you can see how it's possible to write the rules on the faulty ERC 20 token and detect all the three bugs which were inserted into it by the rules, which are quite simple. This is it. And for people who stayed here for the whole time, we have a bonus price. We have a sertora T shirt which you can pick up. We have green color, gray, black and white. Thanks everybody.
03:26:59.960 - 03:27:13.320, Speaker A: Miss every thought of you it's like I sorry. Dreaming I've been singing you breaking.
03:27:15.820 - 03:27:16.276, Speaker F: You'Re.
03:27:16.308 - 03:28:44.820, Speaker A: Breaking me a lot of you breaking so tell me if you wanna because I got this feeling I wanna hear I can't believe it with every thought of you. It's like I thought it dreamed away. I'm a singer. You're breaking you're breaking you're breaking a lot of light, Al. Tell me you wanna, because I got this feeling I wanna hear because I can't believe it. With every thought of you, it's like I sorry. Dream away and I've been singing.
03:28:47.080 - 03:28:47.830, Speaker F: You.
03:28:51.340 - 03:35:21.320, Speaker A: Breaking me a lot of love you're breaking me a lot of so tell me you wanna see? I wanna hear with every thought of you. It's like I thought in Dream away I've been singing you're breaking, you're breaking you're breaking wanna you don't know I want to do but Sam, it for you. I want to spend my life with you my wanna you I know you feel it I wanna you sam SA.
03:37:00.710 - 03:37:01.650, Speaker E: Smoking.
03:37:04.460 - 03:41:25.740, Speaker A: SA wake up high dreams and we don't eat you sam sam blue breast lighting but ship on wake up behind us I was tell me that sonny there's a beyond honey, when will you give me I'll call me cause I for you crazy prize oh, you have something something in your eyes are positive there are no limits for us so we're gonna shut up so high make it feel so high you never know why don't think about it. Make it feel so high I'm gonna take your place I know you never now take a place.

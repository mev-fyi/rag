00:02:31.720 - 00:03:07.270, Speaker A: Good morning, good afternoon. Good evening, everybody. My name is Kartik, one of the co founders of Ethgobal, and welcome to the ETH Online finale and our Merge and Scalability Summit. You're all watching this thing on Ethgobal TV. Just a quick reminder for anybody who is interested in asking any questions, whether it's to our panelists or any of the speakers today, you can just sign in and put your questions on the chat, and we'll be able to relate those questions to all of our speakers. Also, anybody who signs in and engages with everybody out here gets a NFT POAP token. So if you are interested in getting those and collecting those, be sure to say hi.
00:03:07.270 - 00:03:36.636, Speaker A: So this event is organized by Ethgobal. For those of you who are joining us for the first time ever. ETH Global is an organization with a very simple mission. Our goal is to bring on thousands of developers into the Web Three ecosystem. We do this by running hackathons and Summits online and all across the world. And this is our biggest event ever. It's been an amazing last four months, and we've done so many incredible things on Summits.
00:03:36.636 - 00:04:06.244, Speaker A: In the hackathon piece, we had six different Summits we hosted over the last four weeks. We talked about what's happening with NFTs and creators all across the Web Three ecosystem. We highlighted what's happening with the Ave Grants ecosystem. We had a whole summit on the latest in the world of governance and dows. We also highlighted what's happening with the Compound Grants ecosystem. We had a whole summit last Friday on Developer tools and what's going on with the latest in tooling. And today, of course, is our merge and Scalability summit.
00:04:06.244 - 00:04:41.830, Speaker A: Along with the hackathon finale. It's going to be a long, jam packed day, so be sure to buckle in. And on top of that, the Summits were blended together with a month long hackathon. This is one of the biggest events we've ever done. In fact, this is the biggest event we've ever done in our history. We had over 1150 hackers participating from 77 different countries, spanning 19 different time zones. On top of that, we had over 160 mentors, 54 partners we were working with, and over $350,000 in prizes that are going to be given away today.
00:04:41.830 - 00:05:23.724, Speaker A: So let's jump right into ETH online finale. This has been an incredible event. We never saw the scale we could accomplish with all of our efforts with the past couple of years. And all in all, we saw 218 projects come out of this hackathon. This is an incredible number of people working incredibly hard on so many creative and cool ideas. And from these 280 18 submissions, we landed across 17 teams that we want to highlight today that will be presenting what they built over the course of this hackathon. So in no particular order, these are our 17 finalists.
00:05:23.724 - 00:06:12.560, Speaker A: We have nifty pixels Blice Djogs pay magic just mint wagme variety finance VLN. MYSO silo finance riddle lonesome shark ansub Neptune Docs network blockhook and NFT Metadata Explorer. We'll be bringing on these teams to demo what they've done. And as we were looking at these 17 projects, we saw some really unique and very obvious categories that they really kind of highlighted. There's a lot of stuff around NFTs. We have an incredible representation of DFI's, and there's a lot of web three tools and utilities that make our lives easier as we scale what we can do as communities in these ecosystems. So what we're going to do is we're going to bring on the first set of teams to come and present.
00:06:12.560 - 00:07:11.364, Speaker A: But before we do, I want to quickly take a second and just say that just because somebody was not in that list of 17 projects, it does not mean you were not good enough or you didn't do something great. I want to congratulate every single of these 200 projects to make sure that you get to continue working on this thing. The goal of these events is to really focus on experimentation and learning, and there are so many things you can do after, during, and before your event to continue improving and learning about what else you can do. We're also here to help you even after the event ends. So whether it's on our discord or email, anything that we can do to make sure that you're not stuck as you continue building these things, we're there to help. So congratulations to all 200 of these teams and we really hope that you continue building for actually, those of you. Before we jump in to see the list of all projects, you can head over to ETHGlobal showcase ethgobal.com
00:07:11.364 - 00:07:38.540, Speaker A: to see the list of all projects along with their demos, as well as descriptions on what they built. So let's jump right in. Our first category is NFTs. What we're going to do is we're going to bring on our first team and they're going to go in order so each team will present and we'll move on to the next demo. There's a lot of stuff to do today, so we won't be able to do questions. So we'll have these six demos back to back, starting with Nifty Pixels. So without further ado, let's welcome Catherine on stage.
00:07:40.260 - 00:08:00.608, Speaker B: Awesome. Thanks so much. Hi. So we're team Nifty Pixels and we are making a Pixar NFT marketplace where you can draw and sell pixar right in the same place. My name is Catherine. I'm a designer and artist, and my partner's name is Matt. He's an engineer.
00:08:00.608 - 00:08:48.150, Speaker B: We're both based in California and we are both huge fans of Pixel art. Nifty Pixel is a platform that lets you draw, mint and sell your Pixel NFTs all in a few seconds, all on the same website. We're super excited to see what happens when we give people all around the world the same 32 x 32 pixel canvas and the creativity that comes out of it. We built Nifty Pixels on the polygon blockchain for two reasons. One, it's more eco friendly, and two, it's really grid for creators because the gas fees are so low that you really don't need an upfront investment to be part of it. Our front end is built on React Relay and Ethers JS, and our backend is built with the graph Rweave and Firestore. And now let's jump into a quick demo of how Nifty Pixels actually works.
00:08:48.150 - 00:09:37.668, Speaker B: So, hopping over to the website Niftypixels IO, this is our homepage, and since we launched on Tuesday, we've actually had a lot of awesome artwork already being minted on our site. So we've started featuring it here. But I'm going to jump straight into the creation and the Pixel Art Editor. So our Pixel Art Editor has a lot of awesome tools that allows you to create basically whatever you want. On this 32 x 32 canvas, you can fill areas, you can choose whatever color you want to work with. But for the purposes of this demo, just so that we can actually mint a nicer NFT, I've already created my artwork here and filled in the name and description. So all that's left for us to do is really just tap create NFT, which is going to mint our piece.
00:09:37.668 - 00:10:17.024, Speaker B: So on MetaMask here, I'm just going to quickly edit the gas fees to make sure that for the demo, the transaction goes through faster on Polygon. And once I confirm, the minting process has started. And now I'm going to jump over while this is minting to my profile. So once that piece on a break mints, it's going to show up in my profile. I've already created 18 things and collected two pieces from other awesome artists on the website. But here, just for the demo, I'm actually going to try listing something that I minted yesterday, but I haven't listed on the marketplace yet. So on my activity, I can see that I minted it.
00:10:17.024 - 00:11:02.480, Speaker B: And now I'm going to go ahead and list it. I'm going to list it for about five matic, which is around $7 in USD. And once I tap list for sale, I'm just going to go ahead and confirm in MetaMask and again, just going to quickly edit these gas limits to make sure that things go smoothly in terms of it getting picked up for the demo. So while that's listing, I'm going to show you what the marketplace looks like. So once that lists, it's going to show up here in the marketplace. And we already have a lot of awesome artwork here. And just as a demo of what the buying process looks like, I've been eyeing this piece, Lollipop Skull, so I'm going to purchase it from this awesome artist.
00:11:02.480 - 00:11:57.724, Speaker B: So the purchasing process is, again, really easy, and gas fees on Polygon are really low at fractions or just like cents. So I'm just going to edit it for the demo again, but it's really easy to just go ahead and purchase whatever strikes your fancy on Nifty Pixels. So while that's purchasing, let's hop back here. And on my profile, you can see that the piece that we just created together on a break is indeed minted, and it is now listed on my profile. So, yeah, it's a really easy system of going straight from drawing right into having everything be available on the marketplace. Everything that's minted and created on Nifty Pixels is also available for viewing on OpenSea. So every time something gets created, people can also see what they've created and collected from Nifty Pixels on their OpenSea profiles.
00:11:57.724 - 00:12:39.020, Speaker B: Our mission is to make the world's largest collection of original one of one Pixel, or NFTs. And we feel like we're getting there. Since we launched on Tuesday, we've had a lot of awesome artwork, and it's just super exciting to see everyone pitching in. I'm going to hop back here. As for our future plans for Nifty Pixels, we want to grow the marketplace and continue having more creators add their artwork and see what happens. We want to add challenges, so seeing the creativity that comes out when we add additional constraints, like limiting people to only using one color palette per time. And we would also love to explore enabling collaboration between people.
00:12:39.020 - 00:12:57.270, Speaker B: So, for example, letting people stack their Pixel artwork together to create larger canvases and collaborate on their artwork. So thanks so much for watching. If you want to try Nifty Pixels out, it's live right now at Niftypixels IO. We are super excited to see what you create and thank you so much for your time.
00:12:58.840 - 00:13:14.820, Speaker A: Amazing. Thank you so much. Catherine, I was going to say, not only is this the first demo that also went live and you did a maintenance demo, this is incredible that everything worked out, too. So this is great. Congratulations. And everybody check on Niftypixels IO. All right, next up, we have Splice.
00:13:14.820 - 00:13:39.884, Speaker A: So whenever you're ready, let's start with the next demo. Yep. And here we go. Tim. Well, then I will start, I guess, first of all, congrats to the great presentation just then and welcome Ethan online. Thank you for having us here. And welcome to our final presentation for Splice.
00:13:39.884 - 00:14:25.168, Speaker A: My name is Timothy Becker from Berlin, and I'm here today together with my amazing Splice team around. Emily Wheel from New York City, stefanardo from Berlin, and Thiago Tavares from Porto. Yeah. And in that sense, I'd say let's get started. So what is splice? Splice is a generative Art project that renders deterministic validated header images for existing NFTs. Why header images? Well, because of actually this Twitter post from a founder of an NFT collection and because we have seen the immediate need actually on that sense. I mean, people who love their ball date, their cool cat or actually any other collection want it to have a matching generative Art header image accentuating and showing it off instead of miss pairing them like these two that you potentially see here right now.
00:14:25.168 - 00:14:45.072, Speaker A: And I'd say with that said, I'm passing on to Stefan and to show you in that sense how it actually works. Thank you, Tim. Wish me luck with our demo. Okay, here it comes. So we are live on a centralized domain called Get Spliceio. You all can go there. And we are actually only launched on a testnet, which is Coven.
00:14:45.072 - 00:15:15.264, Speaker A: We're using NFT port in Covalent to get the assets of a user that you already hold. So for Coven, we actually created test NFT contracts. And I would like to show you how you can create a Splice NFT out of an NFT you already own. So this account that I'm currently on got quite some NFTs in his wallet. And I'm going to mint Coolcat number 17. So every time we see some latency here, this is usually due to IPFS. So please excuse if this takes sometimes longer.
00:15:15.264 - 00:16:04.028, Speaker A: So, to mint something, we first extract the dominant colors of that image and then we are creating some kind of randomness out of the collection address and the token ID of that Coolcat. Next, the user may choose a style for the cool cat and for demonstration reasons, it will just click through them. So this is how it could look like, or this is how it could look like, and so on. These amazing background images have been generated by our New York City based artist, Emily, and we are very thankful for all the work you have put in here. So for demo reasons, I'm going to choose this one, which we are calling District 1618. The first thing I'm doing, I'm saving this as a PNG file on my local machine and then I'm persisting this on IPFS. And this is now done using NFT storage.
00:16:04.028 - 00:16:46.092, Speaker A: So we're using Protocol Labs little service here to create or to store the metadata of our now to be minted Splice NFT. And this one is also storing the Splice image data. Now, the problem here is that is user can come up with any kind of image that I would like to have minted. And this is why we have some kind of server set component that we're invoking using an Oracle. At least we try to do so. A chain link oracle, actually. So the flow is that I'm requesting the validation of the background image and my server will then render exactly the same thing that the user has rendered in their browser and validate that this background image is really a match for that cold cat.
00:16:46.092 - 00:17:16.080, Speaker A: And this usually takes quite a while because it has to get all the data from IPFS. Let's wait for another 5 seconds if this works, otherwise I'm falling back to something I prepared. No, as you know, IPFS may take a while. So let's jump to something that I prepared. This is a cool cat that went through this process. And you already can see that the Oracle set. So this is what the show will respond, that it may be minted, and then you can finally mint your Splice.
00:17:16.080 - 00:17:32.990, Speaker A: Now this is of course a different cool cat, but let's mint that and once it has been minted, it will show up in your Mysplice section. This just may take a while. Here it is. And if I reload here? No, the server is finally ready. You see that? It just took a while. Exactly. So here it is.
00:17:32.990 - 00:18:07.796, Speaker A: Okay, with that, back to Timothy. Thank you, Stefan. So, to continue, what is next or our next steps? Well, we want to onboard NFT collections to our Splice contract. Furthermore, we want to let artists create their own algorithms, which once approved, can be minted as style NFTs. Furthermore, we want to integrate a dynamic pricing model using a bonding curve that takes several aspects into account. For example, the current market price of a requester's NFT. And we want to establish a Dow based community around Splice.
00:18:07.796 - 00:18:38.112, Speaker A: And I'd say our last point is we want to achieve our vision and become the ecosystem for creative building blocks of the Web Three. And I'd say, if you love the idea, if you want to cooperate or support us, and of course become part of the Slice community, follow and text us on Twitter. And of course, join our discord. Thank you. And get splice. Awesome. Well, thank you so much for that creative, really super creative idea.
00:18:38.112 - 00:18:59.732, Speaker A: I want to update my Twitter banner right now and showcase some of my NFT headers. Congratulations. Next up, we are ready for our next demo, and that is Project Djen Dogs. So Mark, whenever you're ready, let's get started. Thanks, Kartik. My name is Mark Kerry. I'm from Toronto, Canada.
00:18:59.732 - 00:19:47.080, Speaker A: And I'm here to present my project dgen Dogs. Dgen dogs are NFTs that do DeFi. One dog gets minted each day, not all at once. In a big drop, each dog is sold at auction, but the auction proceeds go to the treasury, and the treasury then invests in DeFi and then yield. Earning tokens are streamed back to the NFT holders. So once an auction is settled, the ETH proceeds get sent to the treasury, which triggers the following the ETH gets swapped for Dai on Uniswap V Three using a chain link Oracle to minimize slippage. The Dai gets deposited on compound, so it starts to earn yield and comp reward tokens.
00:19:47.080 - 00:20:41.220, Speaker A: Some of the CDI tokens representing the deposit gets upgraded to a super token via the super fluid protocol. Then those tokens start to stream back to dog owners in real time streamanomics. So 10% of the auction proceeds start to stream back to the owner of that dog. 40% of the auction proceeds are shared among all current dog owners at the time of the auction, and 20% of the proceeds are streamed to the ten before dog owner. So for example, that 20% of the Dog ten auction proceeds are streamed to the owner of dog zero and so on. All streams are sent using superfluid with wallet balances constantly updating as the tokens flow into the wallet. And when the NFT ownership changes, the streams redirect to the new owner.
00:20:41.220 - 00:21:17.270, Speaker A: Why stream to all dogs? Streaming the yield to the owners of the previously minted dogs provides a direct incentive for all dog owners to participate in the community and ensure the success of future options. I think that could add a really interesting community aspect. Here's the streams visualized. You can see the 10% going back to each dog. The 40% at the top gets really busy as you things progress because you're sharing it with all the previous dogs. At the bottom you can see the 20% streaming to the dog ten before. Okay, live demo.
00:21:17.270 - 00:21:50.228, Speaker A: Here's the DAP where the auctions happen. At the top of the screen you can see the balance of the treasury of the compound die. And you can see that balance is slowly going down as it streams out to the owners of the NFTs. Here's my balance next. And you can see it's slowly going up each second because I already own at least one dog. So I'm not going to show any bids here, save a bit of time. But this auction here for dog number ten is already completed.
00:21:50.228 - 00:22:58.430, Speaker A: So I'm going to settle the auction, I'm the winner, so I've got an incentive to do that. And settling the auction is where all the D Five magic happens. So now the auction is settled, the NFT gets transferred to me and the next auction begins here for dog eleven. We can see over here, this is an ether scan what basically just happened. This is an example from a previous transaction but you can see that the proceeds got sent to the treasury and then the DeFi happened. The swap for the Dai, the deposit to compound the upgrade to the super and as well as the transfer of the dog itself and the minting of the next dog. You can also see over here on superfluid my balance increasing each and every second from the streams from the treasury contract.
00:22:58.430 - 00:23:36.940, Speaker A: Since the dogs are ERC 721 NFTs, they can be listed on platforms like Openc to be sold or traded. Also show this is the ether scan contract for the actual dogs. And you can see the D Five holdings are here. Tiny amount of comp tokens and some compound dye and the superversion of the same. Finally, next steps gather a team gas cost optimizations. Exploring other DeFi options, other potentials ave balance or urine. I think the options are kind of limitless there.
00:23:36.940 - 00:24:17.210, Speaker A: Explore and simulate alternatives of the incentivized streamonomics model. Smart contract, refinements to support a fully decentralized operation which would include sort of formation of a Dao and governance considerations perhaps support for doing resale auctions in the DAP itself and of course, a mainnet launch. Thank you for the opportunity to present that is Dgendogs. Thank you so much, Mark. Glad to see it's already live, or will be soon live on main net for everybody to try out. So I encourage everybody to give that a shot. Super cool use of superfluid.
00:24:17.210 - 00:24:25.020, Speaker A: All right, next up we have Stephanie from NFT Metadata Explorer. Welcome.
00:24:39.910 - 00:24:40.980, Speaker B: There we go.
00:24:42.550 - 00:24:43.262, Speaker A: Yep.
00:24:43.406 - 00:25:06.860, Speaker B: Hi, everyone. Today I'll demo my Metadata Explorer site generator for NFT projects. But first I'm steph. I also go by Oceans 404 on Twitter. I'm a software developer and Web Three enthusiast. To kick off the demo, I'm going to run my script that will create a new website for Board Ape Yacht Club. While this is going, I'll explain my project.
00:25:06.860 - 00:26:16.302, Speaker B: So if you are an NFT collector like I am, you know that before reveal, all of the different NFTs in the collection have a blank photo so you don't know what you're getting until after the devs. Flip the metadata so that you can see all of the different traits and the image you've purchased. If you're in a lot of discords, these are some of the most frequent messages you'll see one reveal. How do I see my NFT? In order to see your NFT, you have to go to OpenSea and refresh the metadata by clicking this little button. Sometimes it refreshes, sometimes it doesn't, and you get to see your image, but you have to wait for the entire community to hit refresh metadata to get a sense of which traits are rare and to see everyone's NFT at the same time. To solve this problem, I've created a script that takes some inputs and creates a new website that shows all of the images and the metadata in one nice UI. So all I need from a collection is the collection name, a human readable name, the contract address, the collection start ID, and the collection size.
00:26:16.302 - 00:27:00.554, Speaker B: And after I run the script, which you just saw in my command line, it will output a site that looks something like this. This is the Sad Girls Bar site that I generated for the last demo, and this works for any collection. So I've done this for a few of my favorite projects. You can see Superlatives on the left, humanoids on the right, and it works. And how the script works basically is it calls the Smart contracts token Uri function for every token. Then it processes and sorts all of the metadata to figure out the different trait, frequency, rarity, and relative ranking. It creates static JSON files that have the metadata and rankings and passes those files to a front end template.
00:27:00.554 - 00:27:46.586, Speaker B: From there, the script runs NPM run Build to create a production react build, and it uploads to Skynet, which is a decentralized platform for serving websites. So this is the Sad Girls Bar site I generated the other day. And let's explore this while we wait for the other site to complete. So it's loading right here, but this is the NFT Explorer for Sad Girls bar. The home screen shows all of the different Sad Girls the art, and you can see and explore some of the different traits and find something that looks interesting. So this one's cool. It seems to have a skull and a red shirt, a flower crown.
00:27:46.586 - 00:28:14.520, Speaker B: Let's explore other NFTs that also have that skull. So the hands are holding a white skull. And here's some more that have this same trait hands with a white skull. If I wanted to filter for Buy now, I can do that by clicking this nice button. These are all of the listed ones. On OpenSea, we can query for more. And I really like this one.
00:28:14.520 - 00:29:13.430, Speaker B: And to Buy on Openc, you can just click the photo you're taken straight to Openc, where you can see the price is zero point 49 E. So you can buy it here, or you can just keep exploring using my site. So it looks like the creation is done for the other site I was generating during this demo. And all I need to do to check it out is copy and paste the ID from Skynet into my Chrome browser. And if all goes well, we'll see the Board Ape Yacht Club NFT Explorer that was just generated during this demo. It'll be very similar in look and feel to the Sad Girls bar site because it uses the same templating and you can explore the same way, but it has the Board Ape traits and everything like that. I love the solid gold ones someday.
00:29:13.430 - 00:29:53.894, Speaker B: Yeah, that is my demo. Some future plans I have are to create a user friendly front end form so that artists can just plug this info in and spin up sites for themselves. I also want to create a caching layer between the front end and Openc so that I have more reliable pricing. I also want to work with a UX designer to iterate on design and improve my rarity sorting algorithm. Thank you so much. Let's connect on Twitter. I'm Oceans 404, and I had such a great job hacking, or great time hacking, rather.
00:29:53.894 - 00:29:55.080, Speaker B: Thank you.
00:29:56.090 - 00:30:09.702, Speaker A: Thanks, Steph. Well, you also did a great job. I'll congratulate you on our end. This was really cool. I'm looking at all the comments. Others can't wait to try this out. So hopefully we get to start a lot more of these Explorers.
00:30:09.702 - 00:30:10.742, Speaker A: So congrats.
00:30:10.886 - 00:30:11.674, Speaker B: Thank you.
00:30:11.792 - 00:30:36.020, Speaker A: Next up, we have just mint. So, Santiago, whenever you're ready, feel free to kick off your demo. Hello. Good afternoon. So we are just mint. I'm Santiago, and with Ignacio Tiravazo, we built a batch based random loot box generator. We're both from Argentina, and we're thankful to be here.
00:30:36.020 - 00:31:26.050, Speaker A: So first off, what is a loot box? It is a mechanism that game developers use to distribute content to players. It is one of the most common gameplay rewards mechanics. It is estimated that 70% of top Steam games use some form of loot box mechanic concretely. They are virtual items that are remittable for ingame loot. Loot in turn gains meaning inside the game context and they range from skins to ingame advantage. They also promote user interaction and provide feedback to players. So Glute boxes have sparked a new gaming business model where revenue now becomes a stream.
00:31:26.050 - 00:32:22.290, Speaker A: This is great because development cost of developing games continue to increase. It is also estimated that by 2022, loot boxes will be a market of $50 billion. So what have we done? We created a loot box Minting service for game developers that want to express loot boxes as NFTs. You also can think of it as an affordable random mess provider, so developers do not have to repaint the bill and saving development costs. We also believe it's a gateway to the metaverse. So in game items can be expressed inside the metaverse. How does it work? It's a patch based system to generate pseudo random numbers using as a source of entropy chainlinks PRF.
00:32:22.290 - 00:33:13.170, Speaker A: So in essence, what we are doing, we are batching multiple requests for randomness and processing them together in order to share the cost of the Oracle fee. This allows us to generate multiple random numbers from a single seed. The process is asynchronous. Due to the Oracle, to fulfill its promise takes a few blocks. It is deployed in Mumbai and by So this is our humble demo. In order to showcase our service, we build two mechanisms that consume this randomness from our service. First is a raffle.
00:33:13.170 - 00:33:51.410, Speaker A: The winner of the raffle gains a loot box. In turn, the winner claims the loot box and gains the loot. So in order to participate, you need to buy a ticket. In this case, we already bought a ticket and we are participating in the raffle number 20. So many people could participate, even though it's in testnet. Around 1000 could participate and only one participant will win in this case. So in order to be picked a winner, a batch needs to be processed.
00:33:51.410 - 00:34:23.882, Speaker A: In this case, I already have a confirmed transaction. We can see how we transfer zero one link to the Oracle. This takes around a few blocks to confirm that are three to four minutes. So in this case, we're just going to show you what you get when you win. In this case, it's this loot box. The loot box needs to be claimed in order to show the loot. So I'm going to claim this loot here.
00:34:23.882 - 00:35:03.554, Speaker A: I have prepared a configured transaction that shows how once claimed, we get transferred or R loot token, which is our random loop that we want. And we can expect some properties from it here. Just claim refresh quickly. We can see that since the previous batch was confirmed, we've gone from 20 to a new raffle, 21. So buying a ticket, we'll. Be participating in the new raffle. So here we can see some properties, in this case rarity, color and material.
00:35:03.554 - 00:35:53.706, Speaker A: These properties are derived from the hash we receive from a service. We can give each byte certain meanings and express certain properties from the hash. So game developers are free to give meaning to each byte. Going forward, we believe we need to improve the front end launch in mainnet include new game mechanics such as shuffling properties, combining loot, and include a game resolution mechanic. It's been a pleasure building online and thank you for your time. Thank you, Santiago. This is a really cool and we're glad that you were able to present live.
00:35:53.706 - 00:36:13.790, Speaker A: So congrats. And with that, we are ready for our last demo in this category. So our last NFT project is wagme. So we have Matthew and Parker here. Whenever you're ready, feel free to kick off with your demo. Cool, thanks. I'll let Parker take it away.
00:36:13.860 - 00:36:14.142, Speaker B: Yeah.
00:36:14.196 - 00:36:28.318, Speaker A: All right, fantastic. You want to share your screen? Yep. Fantastic. Hi, everybody. I'm Parker. And hi, I'm Matt. Yeah, and this is our project, Wagme AI.
00:36:28.318 - 00:37:09.486, Speaker A: So first of all, what is the problem that we're actually trying to solve here? It's that the NFT space is very fragmented. It's very hard to discover good NFT projects that aren't in the middle of some Hype driven bubble. And on the opposite end of the spectrum, there's a lot of noise, whether a given NFT is for real or not. To be frank, there's a lot of random shit out there. So our solution is to build this all in one dashboard for on chain analytics for NFTs that provides everything an enthusiast would need in assessing where the best opportunities lie. We use on chain indexing combined with some advanced data analytics using machine learning and natural language processing. I know I hit some buzzwords, but now I'll pass it off to Katz to show you what exactly we've built and why.
00:37:09.486 - 00:37:23.182, Speaker A: It's going to be amazing. Cool, thanks. Yeah. So this is our website. I'm going to go through a quick demo. We have sort of three discrete features here, and I'll go through each of them in order. The first one I'd like to go through is the hot collections.
00:37:23.182 - 00:38:12.660, Speaker A: So we index every single OpenSea transaction right when it happens on the blockchain. And this gives us a great overview of the entire NFT space because Openc accounts for like 95 plus percent of volume. So we track the number of transactions, and this is in the past hour, the total volume in terms of ether, the total ether transacted, the average price, the min max, the floor and ceiling price of the NFTs in each collection, as well as a Hype score, which relates to what Parker is talking about. This is done using sentiment analysis on a representative sample of Tweets. In these Hot collections, we can zoom in to a shorter period, like 15 minutes. So these are just sales that happened in the last 15 minutes or zoom out to a period of 24 hours. This one sometimes takes a little while to load, but there we go.
00:38:12.660 - 00:39:04.130, Speaker A: If we go back to the 1 hour view here, if you're more interested in collection, you can click on its name to pull up some more stats. Here we have a bunch of summary stats. So total supply, the number of unique holders in a collection of that collection, sorry, floor price and then average price and some volume stats too. We also provide cute graphs of Mints here and you can go all the way up to seven days or down to 15 minutes trade volume, which is always pretty interesting, as well as sales. So here we have the sales in the last 24 hours and you can also switch from floor price to ceiling price to average price. Our next feature is a Mint tracker. So much like how we index every single transaction, we also index every new Mint of any ERC, 721 or 1155 NFT on the blockchain.
00:39:04.130 - 00:40:05.350, Speaker A: So yeah, in the past hour we can view every collection that has had at least one NFT that's been Minted and also of course sort them by the number of Mints and as well by the unique Minters. And we found this is quite predictive of things like community involvement. Finally, we have a very experimental feature based around Rarity. So this uses a very similar formula as more popular websites like Rarity Tools, except we use a fully automated system that scrapes the metadata as soon as it becomes available and allows you to view Rarity. So obviously we haven't been able to index all collections yet, but this is a demo of what you would see. So you'd be able to view all of the NFTs sorted by Rarity and of course you'd be able to search for the NFT you own. Okay, so where is this project going after the hackathon ends feature wise? There's a couple more features that we want to build up before launch.
00:40:05.350 - 00:40:40.690, Speaker A: One of the big ones is that Rarity as a metric will tell you how rare something is, but not how much it's actually worth. People right now will just kind of haggle say this NFT is worth this or that, this or that. So what we're going to do is to deploy an online ML model to ingest some real time transaction data to give up to date prices on every single NFT within a collection based on both its Rarities and the names of the actual traits. Awesome. Yeah. We're also planning on building out new features, perhaps extending to other EVM compatible chains. Sorry, just like Matic, because there's a lot of NFT activity on there too.
00:40:40.690 - 00:41:00.214, Speaker A: And even some more experimental features like looking at mempool data. So transactions that haven't even been confirmed yet. We're definitely going to continue building post hackathon and we're hoping to release this soon. So if you want, we have a discord link on our website, wagme. AI. I've already gotten some dings that some people have joined the discord. So thank you for joining.
00:41:00.214 - 00:41:28.702, Speaker A: If you're interested, please come by and we'd love to chat with you. Thanks. Thank you Matt and Parker. That was an amazing demo and can't wait to see what the Nifty Pixels Project looks like on the Wagme Explorer. Great. So with that, we are ready for our next section. I want to congratulate all six teams from the NFT category and next up we have the DeFi category.
00:41:28.702 - 00:41:54.940, Speaker A: So we're going to bring on these six projects. We have variety Finance, BLND, MYSO Silo Finance, Rise DOL and Lonesome Shark. So without further ado, we'll kick this off with Variety Finance as our first demo for DeFi. And whenever you're ready, feel free to get started. Hi, good morning. Good evening. Thank you for having us.
00:41:54.940 - 00:42:51.402, Speaker A: Quick introduction to our team and let me just share my screen as well. So I'm Joshua here. I'm joining you from the sunny side of Singapore along with my team members kojo from Ghana, eura from Netherlands and Ethan from the US. So it's truly a decentralized team and really enjoyed working with everybody here. And we're introducing Variety Finance, which is an automated market maker with impermanent loss protection. So really when we love DeFi and we are liquidity providers ourselves, and liquidity provision is really the fundamental building blocks of the rest of DeFi. They allow the exchange of any tokens, even tokens that you just minted yesterday or any ERC 20, and provides liquidity through automated market makers.
00:42:51.402 - 00:43:54.610, Speaker A: They come with a lot of risks and we've seen it as liquidity providers. And one big one is the impermanent loss, which is the temporary loss of funds as a result of the changes in the prices that results in third parties having to arbitrage the current pools that we provide liquidity to. This is especially problematic with any VM L two site chains where unison V two like protocols are very dominant. They have high TVLs and they represent billions of dollars in the entire ecosystem of these blockchains. The common solutions that has been already in the market is really twofold. One is higher trading fees to compensate liquidity providers as well as additional token incentives distributing more of the native token. For example, we understand there's a protocol called Elk Finance that distributes more Elk tokens in order to compensate liquidity impermanent loss.
00:43:54.610 - 00:44:45.810, Speaker A: This leads to two different problems. Higher trading fees result in bad user experience and more token incentives. It's basically just token dilution which overall lowers the TVL. So we're looking to redesign this problem for any new V two type protocol out there. And our introduction is operational coverage for liquidity providers. How we will do it is we will use our very own flash loan arbitrage contracts that we would sell our arbitrage, our pools with other V two like pools and channel this into an LP protection treasury fund. This reduced the risk and uncertainty for liquidity providers making them sure enough confident to provide liquidity to the protocol and allow easy exchange indexes.
00:44:45.810 - 00:45:40.830, Speaker A: This fund can then be used for retroactive public goods or decided as a portion to be fed back to the LPs. To achieve this, we introduced a new role known as the LP Protector. They will be the ones helping to execute the self arbitrage contracts. They may not necessarily need to know the contract code, but all they need to do is provide their wallet address and then perform the arbitrage. So really what we've done is we've copied the router the factory and we introduced our contribution. Here is the farm for the distribution of variety tokens for higher APYs and as well as a flash node arbitrage contract for liquidity LP protection. Really just the last picture on our future possibilities.
00:45:40.830 - 00:46:16.830, Speaker A: We're looking at as well as cross chain arbitrage insurance pools as well. So incentivized staking with much higher APYs which will withdraw these pools to cover any implement loss in those situations. And lastly treasury governance based on the Dow structure. To help with the distribution of this implement loss treasury we could collect from arbitrage or insurance. Let me just jump quickly into the demo. So all you need to do is come to variety finance. We've currently deployed it on the Matic test network so it will ask you to switch to that network.
00:46:16.830 - 00:47:22.274, Speaker A: And what you see here is Verdi created a few fake tokens. So we have fake USDC with Shiba new tokens and you can quickly start making any relevant swaps. So once you make swaps, of course you affect the market price. And what we've done for this hackathon is we duplicated a completely set of protocols, another set of uniswap two protocols and it's actively arbitraging if they see a difference between the separate set of pools. With this set of pools and of course with the standard features you have the ability to provide liquidity provision and to stake those LP tokens into high APY farms. So really the UIUX is identical to almost every other unison V Two but the difference is the ability to defend LPs and ensure that LPs get the best out of their buck. Thank you and it's been a true enjoyable experience for this hackathon.
00:47:22.274 - 00:48:11.298, Speaker A: It's been so professional and really enjoyed ourselves and we look forward to deploying this on potentially the polygon mainnet and in terms of where we will want to get ready for polygon mainnet, we will also look at further development of analytics dashboard to show how much of the improvement loss that we are able to save and capture for our LP providers. Thanks everyone. Thank you so much Joshua. This was an awesome demo and it's such a cool way to think about adding on and improving V Two. So congrats and with that we are ready for our next team. So next we have VLN. So we'll get Daniel on shortly and whenever you're ready we'll get you started.
00:48:11.298 - 00:48:46.926, Speaker A: Perfect. Thanks Cardik. Thanks everyone. Really a pleasure to be here. My name is Carlos and I've got my colleague Eric and we're part of VLN and we're excited to submit our project for ETH Online 2021. So just in terms of what we built, we built an automated liquidity provisioning vault and what that means is we did this for Uniswap V Three. So we are big fans of Uniswap V Three, but as you know, there's a couple of common challenges or opportunities that you encounter when you're a liquidity provider for Uniswap V Three.
00:48:46.926 - 00:49:59.362, Speaker A: One of them includes positions do fall out of range and so that requires a rebalance. Now you might run into swap fees or high swap fees when you'rebalancing and that could eat into profits for smaller investors. That also might generate some permanent loss on their capital as well. And of course some gas fees can also be cost prohibitive for smaller investors as well. And so we looked at what was already, let's say in market and there's a lot of really great providers that do active liquidity management, but we thought we could create perhaps a unique design for ETH Online 2021. And actually, what inspired us was a tweet that was provided by Hayden, who said that his favorite vault design was one that allowed you to maintain a 50 50 allocation so similar to uniswap V Two and everything that people love about Uniswap V Two, but also leverages concentrated liquidity so that you can earn higher income and allows you to rebalance with no fees or permanent loss. And in fact, Scott Lewis replied to his tweet with a series of steps that you could take to accomplish this manually using a lending pool and reserving some of your assets in the lending pool and using the lending pool to swap your assets so that you're not swapping directly with uniswap when you're doing a rebalance.
00:49:59.362 - 00:50:43.160, Speaker A: And so we thought this was actually pretty creative and so we decided to automate this for our hack. And so our hack actually automates the solution, but we thought, okay, beyond that, what's really important is that there's kind of three key features. One, it's got to be really simple to use in terms of automation, so it's got to automate the entire process. It allows them to essentially earn interest from both lending pools as well as uniswap and then finally allows smaller investors to keep more of their money. So perhaps if they're pooling their funds, they can actually save on gas fees. And so this is what we set out to do. And I'm going to show you a demonstration here of all the great work that the team did in this past few weeks.
00:50:43.160 - 00:51:13.934, Speaker A: So you should be able to see the screen here. So this is VLN. It allows us to connect with our MetaMask. And from here we can actually open up a new position, select our vault. So in this case we're going to do ETH and USDC, allow us to deposit some funds. So we're going to go ahead and put some ETH and some USDC and I'm going to submit that transaction from there. I just want to show you the admin side.
00:51:13.934 - 00:51:49.942, Speaker A: So we did spend a bit of time. For now we've got like a manual way to kick off the rebalance. Obviously the next feature very shortly, very here is going to be that automation to handle the management component of it. But you can see that there's funds in the vault at the moment. And then when I click on the rebalance, it's going to take that position, put a certain number of funds in uniswap to earn that concentrated liquidity. And then the remainder larger position is going to go to the lending pool that we can use for rebalancing as positions fall out of uniswap. So I'm just going to go back here for a second just to make sure that my transaction was deposited.
00:51:49.942 - 00:52:31.370, Speaker A: And you can see it was. So that's great. And then what I'll do is I'm going to go ahead and from the admin side I'm just going to kick off that rebalance so that you can see. And so we'll give this a second. But you'll see it actually place the funds, a portion of it in uniswap and a portion of it in compound while we're waiting for that. So as you can imagine, what we're doing is if we put up the deposit, what we're doing is we're taking a portion, let's say 20% of that that's going into uniswap for concentrated liquidity. And then the remainder of the 80% is being split 50 50 and being placed into compound to be able to handle future rebalances.
00:52:31.370 - 00:53:01.046, Speaker A: One of the things that we're going to be doing is obviously automating the management component. So as it falls out of range, then this will automatically be taken care of. But for the hackathon we have this kind of manual piece that we've kicked off. So you can see, I just went back to the screen, you can see a portion is in uniswap, a portion is in compound. We should be able to view our transaction here on ether scan. So 37 seconds ago and you can see it going into kind of compound and uniswap. So yeah, that's about it.
00:53:01.046 - 00:53:35.540, Speaker A: I'm just going to go back to our presentation here for a minute. So our roadmap, we're going to continue to work and improve the vault in terms of safety and security. We're hoping to launch a first version of the vault on mainnet before the end of the year and integrate more lending protocols just to continue to build resilience in the application. We just wanted to thank ETH online. Definitely found it to be an extremely professional experience. We learned so much not only technically, but also just from everyone that we were able to collaborate and cooperate with. So thank you so much for that.
00:53:35.540 - 00:54:15.926, Speaker A: Thank you so much, Carlos. Next up, we have MYSO. So we'll get the MYSO team ready in a second, and whenever they're ready, we'll begin with our next set of demos. So, Daniel, feel free to get end. There we go. Okay, so, hi, my name is Etienne, and I'm very excited to show you DeFi's first loan option that lets you borrow, but without any liquidation risk. And the way this is done is by using so called zero liquidation loans.
00:54:15.926 - 00:55:06.778, Speaker A: And what this means for you is that your DeFi borrowing experience is going to get easier and less stressful because you no longer have to worry about liquidation penalties, LTV monitoring, or unpredictable borrowing rates. So now, in the demo, I will show you how you can get started with these euro liquidation loans. So, the first step is we go to MYSO finance and we head over to the borrow and lend section. So let's say we have one REPT ETH and want to borrow die against it. So we can select the corresponding currency pairs and then choose the pool that matches our collateral currency and borrow currency. So next we have to define the amount of wrapped ETH we want to pledge as collateral. So we can do that over here.
00:55:06.778 - 00:56:00.894, Speaker A: And now down here, we can see the indicative loan terms, so we can borrow 1300 die and lock in a repayment amount of 1477 die. And what this means is that at Expiry, we will have an option to reclaim our original ease collateral for this repayment amount. And what's important to note here is that no matter what, we will always be able to get back our collateral. Even if the collateral price drops during the loan lifetime, or if there's a flash crash, our collateral is safe and it will never be sold to liquidators. Okay? So next we need to approve this amount of collateral such that it's ready to be transferred to the liquidity pool. We can do this over here, and once that transaction is confirmed, we can continue to the last and final step. But before that, we just need to do one last thing.
00:56:00.894 - 00:56:51.806, Speaker A: We need to define what's the minimum amount of die we expect to receive from the AMM. And this basically serves like a limit order to prevent slippage when trading with the AMM smart contract. So once that's set, we can trigger the final borrowed transaction and we're done. And the best part about this is that we don't have to care about any kind of liquidation issues. So no risk of liquidation penalties, no need to monitor our health factor, no need to watch out for increasing borrowing rates. So instead, our loan terms are fixed and we can see them down here, the repayment amount and so on. And we can also verify the transaction on Ecscan and see that we indeed have received the corresponding amounts we were shown before.
00:56:51.806 - 00:57:37.610, Speaker A: So that's now the active loan and this loan will expire in around eight days. So what happens after these eight days? To show this, we're going to head over to another loan pool that has already expired. So we go to the settlement section, and here we're shown all liquidity pools that are ready for repayment. So if we select one of those, we can see all the loans we have with this given pool currently outstanding, and we can then choose which of these loans we want to repay. So we see that we have 0.2 rep in here, and we can reclaim it for around 3.69 die.
00:57:37.610 - 00:58:54.478, Speaker A: And now, as a borrower of a zero liquidation loan, we have an option to choose how we want to repay our loan. So obviously, we will only repay the loan in Dai if the collateral is worth more than the repayment amount. So in this case, let's say I click approve, and then I can allow the smart contract to transfer Die on my behalf such that I can receive back my rep ETH. And once that transaction is confirmed, I can then trigger the final repayment and note that in case the price would have dropped, I wouldn't have had to exercise this option, obviously, but I could just have left the collateral with the AMM and thereby implicitly repay the loan with my wrapped ETH. And once that is finalized, I will then receive an update notification that the state of the loan has changed to repaid. And I can then also verify on Ether scan that I received my original collateral back. So, all in all, a really simple and cool new way to do DeFi borrowing.
00:58:54.478 - 00:59:23.994, Speaker A: And if you want to learn more about the AMM mechanics and the financial engineering involved, please go to the website and check out our white paper. So we're super excited to continue working on this and to bring zero liquidation loans to Mainnet soon. So thank you very much for your attention. And also thank you to the judges at East Global for their support. Thank you so much. That was an amazing demo and looks like I see a lot of people excited on the chat. So with that, we are ready for our next demo, and that is Silo Finance.
00:59:23.994 - 01:00:01.782, Speaker A: So ed whenever you're ready. Thank you, Karthik. All right. Okay, my name is Ed, and I'm one of the co founders of Silo Finance. Silofinance is easy and secure lending protocol for any crypto asset. There are two security design approaches in lending protocols shared poor markets and isolated markets. Shared poor markets have a big advantage of allowing for maximum efficiency of capital.
01:00:01.782 - 01:00:42.790, Speaker A: Users can borrow any asset for any asset that is available on the protocol, of course. However, there is a big security trade off. Single bad asset can drain the whole protocol. So these protocols must be a gatekeepers of which assets they support. On the other hand, Isolated Markets have superior security. Each asset has its own pool, and because of that, no one asset can affect any other asset in the protocol. However, there is an efficiency trade off because each borrowing pair that users may want to use requires a separate pool and liquidity.
01:00:42.790 - 01:01:24.470, Speaker A: Silo Finance chose Isolated Markets approach for highest security. Let me show you how that works. In Silo, anyone can create any market for any token at any time. Each market is a pair of an asset and a bridge asset. In this case, it's ad, token and matic. Later on, we'll go back to the bridge asset and I'll explain why we need it. Ad Silo is already created, so I'm going to skip that step and go directly to the Quick Borrow.
01:01:24.470 - 01:02:07.790, Speaker A: I'm going to provide collateral in Ad Token and I'm going to borrow Link. All right, let's click Borrow. I'm going to increase gas because this is my net transaction, so hopefully it will be mined really quickly. Keep in mind that Adsilo is a pair of Ad and Matic, and yet I can safely borrow Link using Ad token as collateral. In a minute, I'll explain how that's possible. But let's take a brief look at what's going on here. There's few things to unpack and we'll get back to this in a minute.
01:02:07.790 - 01:03:05.042, Speaker A: So let's go back to the bridge asset. Why do we use bridge asset in Silo? This brings us back to the trade off that isolated markets have sorry, which is fractionalized liquidity. Each pool is its own pair. So the protocol ends up with tens of pools for the same asset, and most of them have little to no liquidity. And as a result, no asset is served properly. So how is Silos solving liquidity and efficiency problems while not compromising on security? Do you remember when I said that each Silo is a pair of an asset and a bridge token? That means there is only one pool per asset which allows for liquidity concentration. Then we use bridge asset for maximum efficiency in a borrowed transaction.
01:03:05.042 - 01:03:40.830, Speaker A: Let's go back quickly. Here you can see that I'm depositing one Ad to the Ad Silo and I'm using that as collateral to borrow zero point 15 wrap Matic. Then I'm taking that Matic and depositing to the Link Silo as collateral. And in the end, I'm borrowing Link. That means I end up with two borrow positions. But both of them are using Matic, so they cancel each other out. If Matic price goes up or down, I can easily rebalance my position without any need for external capital.
01:03:40.830 - 01:04:28.010, Speaker A: And also, the bridge token separates Link liquidity providers from the risk of Ad token. If Ad Token goes to zero link with liquidity providers are not affected because they are actually exposed to the Matic, not Ad. And for that reason, I can safely borrow Ad as collateral. I can safely borrow link and collateralize ad token. And this is how Silo brings together security of isolated markets, solves the problem of fractionalized liquidity and has efficiency of shared poor lending protocols. Thank you very much. If you want to learn more about Silo, visit us at silo finance.
01:04:28.010 - 01:04:45.062, Speaker A: Find us on Twitter. We're planning to launch on Mainnet, so stay tuned. Thank you so much. That was an awesome demo and I hope everybody checks this out when they're ready for Mainnet. Next. We have bayou. Bayou, whenever you're ready.
01:04:45.062 - 01:05:44.780, Speaker A: Let's get started. Hi everyone, my name is Bayou. In the next five minutes I will show you what is Rajdel and let me move it. Okay? What is Rajdal? Rajdal is permissionless leverage token market protocol. Basically, you can create any leverage version of any ERC 20 token that available in uniswap. For example, if I want to refresh my it, I just simply deposit my it to Rice girl and I will receive leverage token in exchange, if the price of it is increased to 20%, I will gain around 40% of it. And unlike a margin protocol or future trading protocol, you don't need to worry about the liquidation because the leverage token are automatically rebalanced.
01:05:44.780 - 01:06:40.428, Speaker A: And that's the basic of threshold. And so what you can do is if you are investor, threshold is a simple way to leverage your asset. You don't need to worry about liquidation managing the position and you don't need to pay the management fees. If you are farmer Rajdal offer new sort of yield interest and collateral asset from creation and redemption fees. If you are deposit USDC in it market, you will receive interest in USDC and also from creation and redemption fees. If you are protocol developer or Dao, you can create reference version of your governor token by simply creating new market in. With that you can deposit your asset to earn more interest and that's the basic of Rajel.
01:06:40.428 - 01:07:28.472, Speaker A: So how it works? Basically, for each regional market, there are two components. The first one is Regal file and the second one is the ETF. The lender can deposit USDC to default and the investor can mint the ETF via the smart contract. Tragedy is built on top of uniswap and chain link. We use channeling to make sure that when we swap an asset, when we swap an asset, the price is not high or low like that and we use uniswap because we want to utilize the deep liquidity and that's how it works. So, time to demo. Basically, there are two pages.
01:07:28.472 - 01:08:13.760, Speaker A: The first one is for investor, the second one is for the lender. For example, if I want to supply an asset, I just simply here deposit an asset. For example like ten USDC and this one, when I deposit USDC, I will receive RP token. In exchange, RP token's value will increase over time. The design is similar to C token that use it by common. Protocol. And if I want to withdraw my USDC, I just simply do it here like this one and that's it.
01:08:13.760 - 01:09:08.530, Speaker A: Then when I burning the FB token, I will retrieve my USDC back. And for the Epsteol, for example, if I want to refresh my It, I just simply do it here and I just mean the It rise like this. And for example, I want to leverage my It, my robot just simply minute and that's it. With this, I don't need to worry about the liquidation or managing my deposition. If I hold some interest, it is automatically rebalanced for me and we'll talk about this later. And for example, if I want to close my position or ready my rapid, I can do it like this. For example, I want to redeem my ten.
01:09:08.530 - 01:10:12.380, Speaker A: See, when I burn the Iteratorizer, I will achieve my robot back. And this one is what happened in the background is basically when the investor menu leverage token, rasidol will borrow some USDC from Spout and swap it to robotic via Uniswap. And if the investor want to bring the leverage token rasul will sell some gravity and repay the debt for the investor. So that's the overview of the rational. Okay, now our goal and the future plans, the market cap of the crypto on checks is very huge. We want to bring it to the DeFi ecosystem. And our plan is to support Uniswap V three top Oracle and Ontario asset.
01:10:12.380 - 01:10:28.604, Speaker A: And we plan to deploy it on my net. So you can follow our Uni and automator at Razor. That's it for Razor. Thank you very much everyone. Thank you so much. Bayou, that was a really cool implementation of this idea. This is awesome.
01:10:28.604 - 01:11:06.206, Speaker A: And with that, we are ready for our last DeFi demo. So next up we have Jonathan from Lonesome Shark. Jonathan, we got to unmute you quickly. Hi, I'm Jonathan Penn. I'm from Singapore. And we are Lonesome Shark. One of the problems in DeFi today is that borrowers are losing money due to liquidations.
01:11:06.206 - 01:11:38.800, Speaker A: And this can be costly. That is why, to address this problem, we have built a liquidation platform based on Ave, flash loans and chain link keepers. This is how it works. I've logged into our account on Aave's testnet. These are our positions and I will show you later. Why am I showing you this? On the right tab is if you go to lonesomeshark. XYZ and scroll to the bottom.
01:11:38.800 - 01:12:02.950, Speaker A: This is our onboarding process. It's a three very simple steps. Next. Click on connect. We support both MetaMask and wallet connect. Then click on Launch app. This is the dashboard you will see and we use an API to pull the collateral and debt information from Aave to ours.
01:12:02.950 - 01:12:34.602, Speaker A: Only those assets which you have collateralized will appear here in our dashboard on and it'll be highlighted in green, Ave and Link. As you can see here. Ave and link. Next we set the current liquidation threshold you want to be notified on and the maximum gas limit for the Flash loans from our contract. In this case, it's 1.1 and 100,000. Then sign up, minimums will appear.
01:12:34.602 - 01:13:14.180, Speaker A: We hit Confirm. This is the fees to set up the Flash loan. Next. Again, we see here that only the assets that we have collateralized appear here in purple, in this case, Aave and Link. We currently only support these two assets at the moment, and so the rest are grayed out. I select Aave and minimize faucet. Again, I Confirm, and this allows us to use your collateral to repay the loan.
01:13:14.180 - 01:14:09.150, Speaker A: Then we click next, then start monitoring. The first MetaMask window that pops up is to allow the keeper registry to use your link, Confirm. So Chain Keepers is running behind the scenes to monitor the health factor, which we have set here. And the moment it hits this threshold, it will trigger our Flash loan smart contract, or should I say, your Flash loan smart contract. And we also do support dark mode, which I'll show you in a minute. This second MetaMask window, Confirm, is to send the funds to the Upkeep registry. Hit Confirm, and here's the document I was talking about.
01:14:09.150 - 01:14:54.094, Speaker A: And here the monitoring has started, and your ETH is protected. We are still fixing out some kinks in our code. So that is why, if I can show you potentially what it will look like when we do get it working, is if you go to the History tab, you will be able to see a list of all your previous Flashclone transactions and his details. Going back to the slides. This is a team. I'm the project owner. Fabrizio is our architect, and he does full stack.
01:14:54.094 - 01:15:28.880, Speaker A: Mike is our front end and Ashish our designer. Before deploying to Mainnet or L Two, we hope to improve the product user experience by adding more assets and integrating with other lending platforms. Also, we plan to apply for Ave chainlink and Cello grants. We are currently live on COVID testnet, so please come check us out. And if you run into any issues or have any feedback or any questions, feel free to connect with us on Twitter and discord. That is the link to our repo. Thank you very much.
01:15:28.880 - 01:15:51.880, Speaker A: Thank you so much, Jonathan, for that awesome demo and being the last demo for the DeFi category. All right, next up, we are ready to get started with our last category. That is utility. So we're going to have Neptune and sub Docs network blockhook and paymagic. Come on. So, without further ado, let's welcome Makato from Neptune. Hello, everyone.
01:15:51.880 - 01:16:44.390, Speaker A: So let's go ahead. So, Tim Neptune here. So we're about to present you our intensive layer built on stack overflow. So the problem that we saw is that Web Three protocols for them, it's really important to have a good technical documentation to lower the barrier to entry for new developers. But right now, all the Q A happens on Discord, which is highly inefficient. Our idea is to come up with a financial layer that is built on top of Stack overflow, allowing protocols to incentivize its community and to answer questions and therefore bootstrap its documentation while fairly rewarding their contributors. So, let's dive in into our website.
01:16:44.390 - 01:17:17.326, Speaker A: So this is Neptune. You can have some more information there, but let's go directly to our product. So there we go. User will typically connect Stack Overflow account and MetaMask wallet to a website. So let's go ahead and do it here. What you see there is that we are using Decentralized Identity standard Tree ID that enables us to link all our user information to this Decentralized Identity. And who's using this is Ceramic.
01:17:17.326 - 01:18:00.400, Speaker A: So we are using this protocol called Ceramic that allows us to build user centric data application, which means that all the information is stored from the client side and therefore anyone can just permissionlessly access our user information without having to request the information from our API. So it enables composability and anyone can just go ahead and do it. So there a user will just sign up to the different protocols he want to contribute to. So, for example, if we go on Uniswap, uniswap previously locked fifteen k of rewards. So let's register. There we go. I'm the only one.
01:18:00.400 - 01:18:44.960, Speaker A: Let's go ahead and do the rest. So, all the information from Ceramic is stored on IPFS. So that's also why it could be slow sometimes to log it. All right, now that I'm signed up, I can just go ahead and contribute over Stackware flow, answering and asking questions. And the only things I have to do is that when I do it, I have to put the tag of the protocol I'm contributing to. And then after, Neptune will just scrap all the information from Stackwareflow websites to get the number of votes that you receive during this period. So let's say that you contributed, you answer for some questions, and then after some times, you can just go in your profiles and claim the rewards that are due to you.
01:18:44.960 - 01:19:33.970, Speaker A: So the rewards are a weighted share of the number of upvotes that you received compared to the total number of upvotes from the registered users. So right now, I'm the only one contributing to Uniswap, which means that at the end, I will take the 15K for myself. But if you start contributing that, I will be deleted. So the more outputs I have, the more rewards I have. And one final thing that is really interesting right now, it's not on the user side, but it's more on the protocol owner. What is really important for us is to enable the protocol to have some validation about what gets rewarded or not to have some moderation. So let's switch Wallets and assume that this wallet is the Uniswap protocol owner.
01:19:33.970 - 01:20:22.250, Speaker A: So there we go. Let's connect my identity and then as you can see, there is a new tab that is open which is moderation. What is it? It's just that we are scrapping all the question and answers that are claiming a reward for the uniswap protocol for this period of contribution. And we're presenting them so that the protocol owner can just either approve a question or refuse it. And therefore you can just feel if those question and answers are legitimates and if they do deserve rewards. So if you want some more information about it, he can just go ahead and look into it, but otherwise he just can approve them all. And there we go.
01:20:22.250 - 01:20:53.400, Speaker A: Once it's finished, the moderation is done and he can just click to AirDrop all the rewards. So the AirDrop function is still to be implemented. So stay tuned Neptune, so that you will soon be able to contribute to your favorite protocols and get fairly rewarded for it. Thank you very much online and see you for another one. Thank you so much. And with that, we are ready for our second demo and that is team Anslap. So Alex, whenever you're ready, feel free to get started.
01:20:53.400 - 01:21:51.240, Speaker A: Hi everyone, my name is Alex and we are NSAP. We've built on chain subscription platform where subscriptions are NFTs. We work in a team of four people. We are from Moscow, Russia. So what we've built is a subscription platform where each subscription is an NFT token and a user can subscribe with ERC 20 tokens on checkout page with just one click. And we've also built a dashboard to manage and create subscriptions. Let me show you a demo.
01:21:51.240 - 01:22:28.580, Speaker A: So here you can see a dashboard@dashboardandsub.com, you can connect with your MetaMask account and you can see a list of subscription products you have. Each subscription product has name, an ID, a price in token and a period. You can create a subscription here. And when you create a subscription, you can choose an optional image. This image is going to be associated with an NFT token your subscriber received. Let me show you this demo product you have.
01:22:28.580 - 01:23:11.940, Speaker A: So you can see a checkout page. This is the link you're going to share with your users. On the left side you can see a subscription name, a price, a period and an image which is an image of an NFT. On the right side we've built a checkout page, a checkout widget. You can choose an account here, you can choose a network and a token you're going to pay with. So a user can click subscribe, which is going to be a two step process. But the first step, a token approval has to be done only once.
01:23:11.940 - 01:24:25.670, Speaker A: When it's done, a subscription checkout is just a one click process. So what is happening there is a user pays 50 USDY and she has an access for 15 minutes to this product. So subscription has been successful and user has been charged and you can check this NFT on your wallet or on some marketplace. And now, when a user has a subscription, we've built this demo app to demonstrate how this subscription can be checked to give a user some content, to show some content or give a permission, this can be checked on your front end, this can also be checked on your backend. And this process is as simple as just checking an ownership of some NFT. And this NFT Token is going to be burned once a user hasn't paid for it the next period. So our platform consists of smart contracts, a checkout web page and dashboard.
01:24:25.670 - 01:25:32.960, Speaker A: And this demo app, the way it works is our smart contract is ERC 721 NFT, where subscription, where subscriptions. Each user's subscription is an NFT token. You have to manually charge users from your dashboard each period, but it can be automated in the future. We have no backend server, we are hosted on Ethereum and IPFS and we also let users pay in any ERC tokens and we're going to swap them through uniswap on chain, but it is not currently supported in our checkout page. In the future, we're going to move NFT to ERC 1155, such that each subscription product represents NFT Token. We're going to build a subgraph to display subscription analytics. We're going to launch on polygon and other layer one solutions and we're going to start working on layer two.
01:25:32.960 - 01:25:56.870, Speaker A: Thank you. You can try our demo@nsap.com, you can subscribe for updates in our Twitter and we're also fundraising, so contact me if you're interested. Thank you. Thank you so much, Alex. That was a really cool demo. And next up, we have Docs network.
01:25:56.870 - 01:26:45.000, Speaker A: So whenever you're ready. Hello everyone. So let me share my screen. So today I'll be presenting Docs Network, which has the goal to monetize on train reputation. So, about the team I'm Hugo Roussel, French cybersecurity engineer based Munich, and I was a solo team. So the problem I found is that your Ethereum address now represents your trading activity, your art taste, your engineering skills, your gaming activity, governance, popes and everything. But all of this is made in Epsodonim way and there's still no way to contact a random Ethereum address that you find on Ether scan, for example.
01:26:45.000 - 01:27:41.000, Speaker A: So I created Docs Network, which has the goal to help on chain participants get in touch. So, the platform works in the following manner you incentivize address registration with monetary rewards. Contact is done by email and all the payments are streamed using superfluid. If you're not happy with someone you met, you can stop the stream, so there is no risk for the buyer or the seller. So what has been done creating the full set of smart contracts and a proof of concept application is live at Docstop Network. Potential use cases include protocol makers talking with heavy protocol users, NFT bargaining on OpenSea copy, trading, solidity questions and everything. So what's next? Bootstrapping a community reviewing the smart contract protocol and improve the web application.
01:27:41.000 - 01:28:08.394, Speaker A: So with that, let's jump right into the demo. Here we have two windows for party A and party B. And here party A, zero x 41 registered his address for 25 die. And here I'm party b. And let's say I'm in the mood of address shopping. So I go here, I see the bounty of zero x 31. I can click here to see that on Zapper.
01:28:08.394 - 01:28:53.600, Speaker A: I can see his activity on the different chains, and I see that he's a top 100 digit score. Say, hey, that's nice, let's have a chat with this guy. So I can put my address here, I will approve the die and then I can buy the bounty. Okay, so while this is confirming, I will show you other features. So for example, you can put a bounty as well. So you can say, I'm looking for this specific address and you can say, yeah, for like $100 I will be willing to talk to you. So here apparently it worked, so that's great.
01:28:53.600 - 01:29:36.480, Speaker A: And if I go to my email address, I received a new email from Docs Network, the address you bought for 25 die registered using this email. And if I go to party A, I can see here that the stream started. So if I'm not happy here, for example, the email address does not look correct. It's one, two, three. At Gmail I can go back to my account, we'll refresh and I can stop the stream. So this is an old stream from a previous test and I can stop the stream or if the guy never replies to my email. So with that, I think this is all for the demo.
01:29:36.480 - 01:30:06.150, Speaker A: The front end is itself hosted on IPFS. You can visit today at Docs network. It's still on the testnet, but I will be interested to move it to Mainet at some point. And with that, I would like to salute the organizers, the sponsors, and all the participants. Thanks a lot. Thank you so much, Hugo. Next up we have the Blockhook team and we have Barack and Jasper.
01:30:06.150 - 01:30:50.302, Speaker A: We're going to show what they built, so whenever you're ready. Great, one moment here. Hi folks, I'm Barack. And I'm jasper. And we are team blockhook. Jasper and I have been actually working on many blockchain projects previously, and in many cases we found that we frequently needed to respond off chain to things that are happening on chain transactions and events, whether it is to process metadata, generate images, do our own internal analytics, post to social media. And it was really tricky.
01:30:50.302 - 01:31:22.266, Speaker A: Either it required a lot of infrastructure or using services that were prohibitively expensive and not really well suited for the task. So in this hackathon we've created Blockhook. It's a blockchain tracker that watches for registered events and triggers API webhooks in response. So the blockhook your dashboard looks like this. You can just sign in with your ethereum wallet. No need for username password, you just sign a transaction and basically to create a new hook, you enter our wizard here. And let's say we have a use case where we want to kind of track the sales of NFTs.
01:31:22.266 - 01:32:00.342, Speaker A: Now, this could be for your own project or for us. We're just going to track the sales of any NFT on OpenSea so we can give our hook a little name here. We support a few different networks, so we support Mainnet as well as Rinkbee, as well as Polygon Mainnet and one of their testnets as well. But for this, we're going to stick to Mainnet here and you just can copy in the address of your contract. And now, if the contract is verified, we pull in the Abi through the Ether scan API and you can find the events that are on the contract here. If you didn't have a verified contract, that's no problem either. You can either choose from the most common contract types.
01:32:00.342 - 01:32:35.346, Speaker A: So for instance, if this was an ERC 20 contract, we have the template here, or you can always enter in your own event signature. But thankfully, the openc contract is verified. So we can just pull in the contract address here. And for us, we want to listen to the orders matched function here. So whenever this event is emitted, we'll be calling a webhook. Now, what's great about our service is that we can actually see the parameters that are emitted with this event. So all these arguments, dynamic data passed through every log with everything from the Buy, hash, sell, hash, maker, Take or Price, as well as metadata.
01:32:35.346 - 01:32:58.814, Speaker A: And for us, we also support either Get or post hooks. So for us, we've had a lot of fun experimenting with different use cases. So we actually have a little discord bot we've set up. Hold on, let me pull in the URL here. We can paste in this URL here. This is going to be a post request. And we can also pull in some pre formatted little JSON object here.
01:32:58.814 - 01:33:32.626, Speaker A: And now, what's great is that exactly what I was talking about. We can actually pull in this dynamic data into our request either in the URL or in the data itself. So for us, we're going to pull in Price, then we're also going to pull in the maker. And let's also pull in the taker here. So the buyer and the seller, maybe even to be a little more clear, we'll do the buyer and then we'll do the seller here. And then we can add this action to be called every time this event is emitted. We can have multiple webhooks per action, but for us, or rather multiple actions per hook.
01:33:32.626 - 01:33:54.042, Speaker A: But for now, let's just keep with this one hook here. So next we can review our information, make sure all of this is correct, and then once we hit Create, we have our own custom bloom filter. And I'm looking for matches in the back end, and I already here in our little Discord bot. We can see that we're already getting the trades from the latest Block. So we can see that here's the price. We can see the buyer. We can see the seller.
01:33:54.042 - 01:34:34.742, Speaker A: And this will keep on ticking as new blocks are added to the oh, yeah, we got a big bunch there, so it's always pretty exciting. A lot of action on OpenSea, it seems. Yeah. So this is blockhook. And quickly on what's next beyond the Hackathon, we're really excited to get this to the point where it's functional. And listening to the Blockchain, we can see this functional utility that we actually need in our projects. We're excited to add support for more networks beyond Ethereum and Polygon, as well as being able to listen to transactions and events that are pending in Mempool, which is something we think would be really useful, and, of course, making it to production and available to you all to use in your projects.
01:34:34.742 - 01:35:00.754, Speaker A: We want to say really thank you to the hackathon team. It's been a blast. And the organizers, thank you for choosing Blockwork to be one of the finalists. Yeah, thank you very much. Thank you so much for that awesome demo. I feel like I can already see people excited to use this, so be sure to tell everybody how to get started with this. All right, next up and Our last demo for today is Pay Magic.
01:35:00.754 - 01:35:41.550, Speaker A: So, Corbin, whenever you're ready, let's do the demo. Hi, everybody. I'm Corbin, and along with my colleagues David and Seth, we built Paymagic. Paymagic is the first d five payments tool built specifically for dows and crypto teams. So Sending Out Batch Payments, sending Out Airdrops vesting schedules, streaming payments, you can do all that from One easy place with Paymagic. So, as we all know, in 2021, the Dow Space is absolutely blown up. The number of Dows the number of people that are in Dows, the capital that Dows are allocating is Just going absolutely exponential.
01:35:41.550 - 01:36:12.250, Speaker A: And to coordinate all these members within a dow, you need different types of economic transactions to get everybody aligned. Right? Devs and designers need to be paid salaries or bonuses for completing work. A lot of these dows are issuing grants or paying other protocols to collaborate. Dows are rewarding their communities and tipping different discord members. And then lastly, dows are also starting to sell tokens to investors. All these different types of transactions are needed to run. Dows today.
01:36:12.250 - 01:37:07.070, Speaker A: And there are a couple different applications that allow Dows to do these important types of transactions, but there's no way for them to all be accessed in one place and be accessible by nontechnical folks that are serving Dows. So we built paymagic to solve this. We started out by building four different types of transactions. So Dispersed payments, so Sending Batch payments out to A Lot Of recipients setting up vesting schedules, so setting up vesting token contracts to send tokens to investors or different contributors, streaming payments powered by Superfluid and Airdrops as well. So Paymagic is currently available on mainnet polygon and coven. And I'm going to go through a quick little demo of the Dispersed functionality and the vesting functionality. So we have a pretty easy little page here for users to fill out.
01:37:07.070 - 01:37:53.490, Speaker A: Again, we want to make sure that non engineering operational folks can do this type of thing for the Dao. So there's first an approval step, which we kind of take you through. And then there's a second step. I am going to bump up the gas here because things on Polygon have been a little fogged lately. So we'll confirm that transaction, that's going to be our approval step on the token. And then our second step is going to be actually sending out all these batch transfers. Now, the batch transfers work exactly like your normal token transfers, so if you look at them on Ether scan, there's going to be events emitted for each of the different recipients.
01:37:53.490 - 01:38:46.034, Speaker A: They'll be able to see that reflected in their wallet or portfolio management app. So there we go with this first. And so second is after closing around, a Dow or a Crypto team generally sets up a vesting schedule with their different investors that participated in the round. So for this specific vesting schedule, we have a start date of today, we have a one year clip and then a vesting period of four years. Again, another one here is we have first an approval step and then we have the actual contract. It's actually deployed on chain. Again, doing this on Polygon, so it's a little bit cheaper than doing it on Mainnet.
01:38:46.034 - 01:39:31.388, Speaker A: But these vesting contracts are available on mainnet as well, if there are any Dows out there that would like to use them. So we confirm that one. I hope this transaction gets confirmed easily. There. And there we go. If you look on Etherscan, you'll be able to see this vesting contract and the investor, the early team member, whoever's receiving these tokens, are going to be able to claim through Paymagic very soon as well. So we had a great time building this application kind of on our backlog for the futures to build in Nosisafe support, deploy to other networks, add new payment types, and make the application much slicker overall.
01:39:31.388 - 01:40:01.740, Speaker A: If you're a Dow or crypto team that would use this functionality, please get in touch and we'll kind of start building to your needs. And if you'd like to get involved, join our Telegram group and we'd love to find a way to have you support it. Thanks so much. Thank you. Corbin. That's a super cool demo and I feel like the second we start seeing more and more Dows, all these things are going to become super useful utilities, whether it's investing or mass payment. So can't wait for more Dow tooling to come in handy and be useful for everybody else.
01:40:01.740 - 01:40:39.028, Speaker A: So congrats. All right, with that, we have now gone through all 17 of our finalists and I hope you enjoyed a lot of these demos or if not all of them. There are some of the really cool projects that our judges highlighted and we wanted to showcase them. Today. Of course want to remind everybody again that there's over 200 other projects that came out of this hackathon. And you can check out all these projects with anywhere from their videos to what they've done and how they work by going to showcase eighthmobile.com. All right, so let's wrap up the finale and get ready for the summit.
01:40:39.028 - 01:41:57.040, Speaker A: So we just saw 17 incredible demos and there are a lot of other things that happened during this hackathon. And we want to talk about all the prizes that have come on from all those projects. So before we jump into all the prizes, I want to just make sure I take a minute to thank all of the partners that we work with that made this event possible. So I'm going to first thank our presenting partners. Avi grants Sublime Finance Balancer Compound grants Scale Labs Ethercard Skynet Uniswap grants program Superfluid Finance morales and Variable Protocol We have our pillar partners alchemy one inch admph BitCo enzyme chainlink ETH blockart fluence paraswap and pocket network polygon zero x all coin live peer radical MakerDAO, the Graph Conjure. We have our provider partners Biconomy, covalent ENS, Metis, NFT, port newsypher, reflexer Teller, textile Umbrella, uma, urine Finance, dxDAO, swivel Finance, zora status and POAP. And our supporter sponsors aztec coinspect charge particles ZK, two near ChainSafe alumnus cap Blocktimen, quant Stamp and Maple Finance.
01:41:57.040 - 01:42:32.728, Speaker A: All right, so let's get ready for some prizes. So we have a few of our partners that we've asked to record a quick video showcasing and announcing the winners themselves. So we'll bring some of these on ourselves and then I'll get into listing every other prize and our sponsor winners. So first up we have Adam from compound and I'm just going to talk about who won the compound prize. Hey, everyone, Adam from compound here. We are very impressed with all the project submissions for the compound bounties in this year's ETH online hackathon. We decided to divide up the prizes for the top projects.
01:42:32.728 - 01:43:11.770, Speaker A: For the prize pool bounty, each of these teams wins $500. Antifinance blockhead decentralized learn and earn delgado, Fay and Pinatas. For the supply use case bounty, each of these teams wins $1,285. Beehive citizen Dow dgen dogs lovey private lossless prediction market VLN and when passive income. Congratulations to all the prize winners. Join us in the compound discord at compound finance slash discord if you plan to continue building your project on top of compound. See you again soon.
01:43:11.770 - 01:43:41.810, Speaker A: All right, so those were some of the compound winners. And don't worry if you didn't catch them. We'll walk. Through all of those prizes again. So you saw Adam, announced the main winners, and then we have all these projects that have won the pool prize. So we have 14 individuals sharing the $9,000 in the normal prize category and then six projects with eleven people winning $3,000 from the pool. Next up, we have Superfluid and we'll quickly see who won.
01:43:41.810 - 01:43:58.648, Speaker A: Hello everyone. Francesco and Superfluid. Very excited for if online. Amazing event. As usual. We were sponsoring with $12,000 and we received an astonishing 30 free submissions this really, really incredible time. So here go our winners for the best gamified experience.
01:43:58.648 - 01:44:36.820, Speaker A: Fluid Miners, a new take on token offerings with a gamified experience for the most futuristic hack. Streaming collateral, which allows you to borrow against your streaming salary. For the best financial innovation, we had Paymagic, which is a tool for DAOs to make payments, and for the best coordination mechanism, Osmotic funding, which allows you to use conviction voting to fund your projects. And our top hack is Dgen Docs, which is a great NFT project. Love the artwork and looking forward to see this one go live. And thanks everyone for joining us at Efonline. See you at the next hackathon and keep hacking.
01:44:36.820 - 01:45:14.660, Speaker A: Cool. Thank you so much. Francesco and I'll just quickly announce these teams too. So we have Djin Jogs, streaming collateral, pay, Magic, Fluid Miners and Osmotic funding that have won 1500 each, except Djogs, which is the top Superfluid project with $2,000 in prizes. And then we have all these incredible projects that have won the Superfluid Pool Prize. So 33 projects with 66 individuals are going to be sharing $4,000 equally. Next up, we have Scale and we'll have Selene talk about their winners.
01:45:15.160 - 01:45:50.710, Speaker B: Hi everyone, this is Selena at scale. So winners of the Ethereum Hackathon Denali prize. We have the team Help Me Dev, which enables you to get a developer for your tag project, kilimanjaro Prize Team Passport, which is a passport for pets. So to verify the record authenticity for international travel. And NFT Prize Team Community Garden, which is an NFT platform for all of us for plants and parks and everything. So congratulations to all and thank you so much.
01:45:53.560 - 01:46:13.850, Speaker A: Awesome. All right, so I'll repeat the winners again. So we have helpme. Dev that won Denali Prize for $3,000. Passpet won the Kilomenjaro Prize for $2,000. Community Garden won the NFT price for $2,500. Next up, we have Daniel from Skynet and we'll see who their winners are.
01:46:13.850 - 01:46:53.392, Speaker A: Hello, ETH online. Thank you to the over 50 projects that built on Skynet and home screen. This hackathon, you are building the web three future of decentralized front ends and we'll share in our prize pool of $10,000. Our best home screen build of $2,000 is going to superheroes. We love the DFI crowdfunding mentality, the excellent use of Skynet and home screen tooling, and the ability for anyone to deploy mature DFI contracts right from their decentralized front end. We share our goals of building a better web three where anyone can participate. Thanks, Daniel.
01:46:53.392 - 01:47:19.260, Speaker A: And then to repeat the winners, we have superheroes that won the best use of the home screen $2,000 prize. And we have these amazing list of 50 projects sharing the pools prize. So it's 39, sir. So we have 39 projects that are going to be equally sharing $10,000 amongst themselves. And congratulations to all the Skynet winners. Next up, we have Morales, and we'll have Ivan from Morales. Talk about their winners.
01:47:19.260 - 01:47:34.128, Speaker A: Hey, guys. This is Ivan from Morales. And I'm here to tell you the winners of our prize pool. First and foremost, a big shout out to everyone who participated in this hackathon. So great results, so many great DApps. Big shout out to you. You truly deserve it.
01:47:34.128 - 01:48:14.032, Speaker A: And I do hope now that you've tried Morales, you have another tool in your toolbox to build great DApps, to build them quickly, and to deliver even more value to your users, your community, your token holders, dow, and so on and so forth. Now, our winners are as following. Number one, for $2,000, we do have Music shares for $3,000. We do have Fin, aka financially intelligent NFTs. And on the first place, for $7,000, we do have peer to peer betting. So these projects really surprised us a lot. They really, really showed what you can do with Morales and most importantly, what's possible in the crypto world.
01:48:14.032 - 01:48:35.322, Speaker A: Big shout out to them. See you guys in the next hackathon. Keep building. Thank you, Ivan. So I'll repeat the Morales winners as well. So, we have the first place project that won $7,000, and that is P to P betting. Finn won $3,000 for the second place prize for Morales.
01:48:35.322 - 01:49:02.520, Speaker A: And Music Shares is going to win $2,000 for the third place for Morales. All right, let's now go into all the remaining projects. So we have Ave Grant style. So the first place winner for the Ave Grant style prize is guilds of God's Battles. That is going to be winning $7,000 as a team. Then we have Lonesome Shark winning $3,000 as second place for the best Civave. And then Project Finland winning $2,000 for the third place.
01:49:02.520 - 01:49:29.490, Speaker A: Next. We have balancer. So just some geeks will be winning the $8,000 1st place balancer prize. And then Balancer Chat will be winning $4,000 for the second place prize. Next up. We have variable protocol. And the first place prize winners for the variable protocol is color pixels with a $4,000 prize.
01:49:29.490 - 01:49:57.494, Speaker A: Then we have Sublime Finance. And NFT bulls will be winning the $4,000 prize from Sublime. Next up, we have the Uniswap grants program prizes. So we have VLN that's going to be winning $4,800 as the first prize. You have Variety Finance as a winner of the runner up prize with $3,600. And then there are two honorable mentions. We have Finn with one, $800 as a prize as well as leverage.
01:49:57.494 - 01:50:30.046, Speaker A: They're both going to be sharing that honorable mention prize. Then we have Zero X and Rainbow will be winning the first place for the Zero X prize in an amount of $2,000. Then we have One Inch and Inchy will be the recipient of the $2,000.01 inch prize. Then we have 88 mph and Phantasm Finance will be winning the $3,000.88 mph prize. Next we have Alchemy Sharetools.org
01:50:30.046 - 01:51:12.210, Speaker A: will be winning the first place prize in a $2,000 amount and then we have Blockhead as the second place prize winner with $1,000 prize. Then we have BitCo. Crypto Parks wins the first place BitCo prize with $2,000 and then Blockhead wins 1500 for the second place. Best use of Bitcoin ecosystem prize. Next up we have Chain Link. So we have Silo Finance winning $4,000, launchlim Shark winning $2,000 and Unstoppable Streams winning $1,000 for 1st, second and third respectively. And on top of that we have all these incredible projects, 32 of them sharing $3,000 equally amongst 84 individuals.
01:51:12.210 - 01:51:59.822, Speaker A: Then we have conjure finance with Cred Spot and Strangers United winning the pool prize. So both of these teams will be sharing $4,000 equally. Then we have Enzyme Finance and Just Some Geeks wins $3,000 for the best use of enzyme prize. The Dow Treasury Management through Discord wins $2,000 and Zodoid wins $1,000 for the third place enzyme prize. Then we have Eat Block Art and Eat Block Art Split Fitting is going to be winning 40 96 for the first place price and the best use of Eat Block Arts. Then we have the Graph and we have a lot of amazing winners for the graph. So the best use of Subgraph goes to Balancer Chat for $1,500.
01:51:59.822 - 01:52:33.834, Speaker A: Beehive Blockhead, Leaf Finance and Rainbow they are all going to win 1500 each. The best new Subgraph prize goes to Mocha with $1,500 as well. The best news subgraph two runner prizes are going to go to Metaverse, Ad Style and Orange with 750 each. Then we have Live Peer huddle. One wins $4,000 for the Live Peer prize. We have Dbeats with $2,000 and Color Pixels for $1,000 for third place. And we have all these incredible teams as well.
01:52:33.834 - 01:53:07.026, Speaker A: So eleven of these projects will be sharing the $1,000 pool prize equally from Life Peer. Then we have Maker Dow and we have Osmotic Funding winning $4,000 for the first place prize. We have Museum of Nifty Art winning $2,000 and Unstoppable Streams also winning $2,000 for the third place. Then we have Filecoin a lot of prizes here as well. Best use of NFT storage. First place winner goes to Dexter with $4,000. Best use of NFT storage.
01:53:07.026 - 01:53:54.482, Speaker A: Second place goes to Crypto Parks for 2503rd. Place goes to Splice with one $500. Best use of Web three Storage goes to Soundly for $4,000 and Paperfax wins the second place with 2500, and Link ENS wins 1500. Then we have Pocket Network and the best RPC usage goes to Blockhook for 1250. 2nd place for RPC usage price goes to Blockhead for 500 and Crypto Parks gets 250 for the third place. And the most creative first place prize goes to Proxy Poster for 1250 and Lee Finance, Bridge Analytics wins $500 and then Balancer Chat wins 250 for the most creative third place prize. And then we have also all these projects that are going to be sharing the pool prize with Pocket Network.
01:53:54.482 - 01:54:26.282, Speaker A: So 16 projects will equally share $4,000 for the pool prize. Then we have polygon. The best use of DFI project on Polygon goes to Variety Finance for $2,000. Play to earn NFTs with island goes to $2,000 as well for the best gaming project on Polygon. And then we have Paymagic as the winner of the open Track on Polygon with $2,000. Next we have covalent. All these projects are going to be sharing the pool prize.
01:54:26.282 - 01:54:59.260, Speaker A: So we have seven projects here that'll get an equal sum of 31 50 divided amongst each other themselves. Next up we have ENS. So the best use of ENS goes to Link ENS for $1,000. And the two runner ups are ENS Gallery and Argo App Protocol that are going to be receiving $500 each. Then we have NFT Port. All these amazing teams are going to be sharing the NFT port pool prize. So we have 19 projects that are going to equally split the $4,000 from NFT Port.
01:54:59.260 - 01:55:50.822, Speaker A: Then we have New Cipher and Orange is going to be winning the $4,000 best use of new Cipher Protocol. Then we have POAP and POAP GG will be winning $3,000 for the best use of POAP Protocol. Then we have Reflexor and we have these four teams that are going to be sharing the pool prize. So we have Silo Finance, Pinatas, Crypto, Perks and MYSO. And they'll be getting $1,000 each. Next up we have Status and we have these five teams with Balancer Chat, Huddle One, Levi, Stream, a Buy and SuperCard Game, sharing the $4,000 amongst themselves for the $4,000 status pool prize. Then we have Teller and the best use of Teller goes to Paperfax with a $2,000 prize.
01:55:50.822 - 01:56:38.262, Speaker A: Then we have Textile and we have Arbor, Greeting, NFT, AirDrop, Levy and Metaworth sharing the $4,000 prize, getting $1,000 each. Then we have Uma and Antifinance and Floor Wars are going to be sharing $2,000 or $4,000 and getting $2,000 each for the Uma prize. Then we have Umbrella Network and we have Pop with the best use of Umbrella winning $4,000. Then we have Urine Finance and Widow will be getting $4,000 for the best use of urine in the project. So those were all of our prices. There are a couple more that we're still collecting and we couldn't get them in time for this announcement. So we'll be announcing all those remaining ones all on Discord for all of the hackers.
01:56:38.262 - 01:57:03.554, Speaker A: But these prizes have now been awarded on to your project submissions directly. So if you missed the last few minutes or weren't able to quickly read through the pool prizes. Then you can just head over to Showcase Ecoboost.com and head over to your own project. And on the right sidebar, you will see which prizes you have won yourself. So congratulations to everybody here. Super excited to see so many amazing projects come out of it.
01:57:03.554 - 01:57:51.214, Speaker A: And let's share some final closing thoughts and get ready for the Merge and Scalability Summit. So we got to say a lot of thank yous because this has been our biggest event ever and there's so many people that made all of this possible behind the scenes. And it wouldn't be good if we don't get to highlight everybody's work and contribution and the time they've given. So there's so many parties here that I want to bring up. I want to start off with all of our judges who spent countless hours going through these 218 projects, talking to them, hearing their demos, seeing the demos, giving them feedback, asking questions. So without these amazing judges, we would not be able to do this today. So thanks to all of our judges, we ran six summits.
01:57:51.214 - 01:58:34.590, Speaker A: This is the most amount of Summits we've ever done at any given time. And we have so many amazing people that are anywhere from incredible developers, to speakers, to founders, to creators and community builders in our Web Three space. And they took the time to talk about what they're excited about. And I want to thank everybody here for giving their time. Also, I'll specifically thank our tech mentors who are there doing a 24/7 coverage of being able to answer any of your questions. All these people help us out and make sure that anybody who's trying to learn and better themselves gets the right support they need. And without their help, we'll have so many people locked on so many things, and we're super glad to have them with us for the course of the hackathon.
01:58:34.590 - 01:59:37.726, Speaker A: And then we have our amazing partner mentors talked about over 160 people who are here behind the scenes promoting and supporting everything that's happened for those thousand plus attendees. And I want to thank everybody here for giving their time and being with us behind the scenes to answer any questions, whether it's about their protocol or about anything from the front end team or solidity or back end or random debugging things, you name it, they were there to make sure that nobody gets unanswered. So I want to thank everybody here for making this happen. And of course, a lot of this stuff that you see now, whether it's this live stream or the judging stuff, we are coordinating this in the background with the help of all these amazing volunteers. Doing a call with 20 time zones and 50 countries all in two hour window, is not easy. And without their help, we would not have this smooth experience that we do now. And of course, I want to lastly thank the Ethoba team these are the people behind the scenes.
01:59:37.726 - 02:00:38.280, Speaker A: They're answering your questions, whether it's on Discord or email or debugging things or pinging anybody. If you have not heard back from somebody and doing everything from the dashboard to the showcase to making sure that you have the right information you need to be successful as part of the events and coordinating all these talks and anybody you want to bring on to the space without their help, we would not be here. So I want to thank Moaz, Nisha, Shanghin, Luke, Emily, Andrew, Jacob, Heather, and Liam for making all this happen. And let's kind of jump back and pause for a second. So we had 17 projects come on, and we called them the finalists. They came on and they did their demos, and we really showcased what everybody was excited about and all the crazy things that they built. So for those of you who are joining us for the first time, we call our projects in our finale finalists because that's the best work we have for these.
02:00:38.280 - 02:01:20.434, Speaker A: And our events are not designed to be competitions. We don't really want to make them competitive or make them 1st, 2nd, 3rd, or really make them focused on price or prize. And when we kind of say somebody's a finalist, those two us are our winners for this occupancy 17 teams. In this case, equally coming first. And I want to congratulate all 17 of those teams for being the winners of Ethan line. And as part of that, every team member on these 17 projects will be receiving $1,000 each in Dai or USDC. So congratulations to all 17 of you, and I hope that you continue building what you're doing.
02:01:20.434 - 02:01:54.270, Speaker A: I saw so many comments here about going to Mainnet soon or being able to have everybody else watching this try it out. And I can't wait for so many incredible projects to come onto this ecosystem and be used by thousands, if not millions of others. So congratulations to all of your finalists and we'll be in touch with you as well as anybody who won a prize today over Discord and over email. And we will dispersing all the prizes over the next week. And of course, I'm going to get this question a lot. Everybody's going to ask about Poaps. Don't worry, you signed in.
02:01:54.270 - 02:02:47.582, Speaker A: We know who you are. We know your email addresses, and we'll be sending an email over the next few days to claim your Poaps directly. All right, so today is a very special day for us because not only is this the end of our biggest event ever, we never thought we would be at this scale, let alone working with people from so many different parts of the world, but today is actually the fourth year anniversary of ETH Global. Ethgobal was started the same day in 2017, and it blew my mind when I realized this thing that it's been 40 years and it's been such an incredible experience having all of you being part of our community. So I pulled together some really quick stats on what's happened so far. These are just some of the things I want to highlight. There's so much more that has happened in the past four years.
02:02:47.582 - 02:03:41.082, Speaker A: We've had people spend over 100,000 hours watching the thousands of videos we have on tutorials, workshops, whether it's summits or technical talks, we've helped bring on over 30,000 people in this past time. Four years, over 3500 projects have been created and some of them are now amazing and incredible companies, whether it's one inch or CryptoKitties or Dapper labs. And since the beginning, we have dispersed $3 million in prizes. That has helped support a lot of people from anywhere from earning some capital to pay for school or their work to just getting excited about web three and jumping in full time. On top of that, there's a bunch of other stuff, whether that's that companies that have come out of e Global have raised over $200 million. They're collectively worth over 4 billion. Hundreds of jobs have been created from this network and thousands of friendships that I can't possibly measure.
02:03:41.082 - 02:04:28.986, Speaker A: But I know I've met some of so many of you through these events and so many of you are good friends now. So it's amazing. It's been incredible for the last four years that we've gone to work with so many creative and passionate people. And I want to sincerely thank everybody for being part of the global community and can't wait to see what the next four years look like. So thank you everybody for being part of this. And let's wrap up the finale and then we'll take a quick break after this to kick start the summit with our amazing speakers, talking about ETH two and everything that's happening with merge and how do we scale ethereum so this concludes ETH online. Obviously, this wouldn't be any global event if we don't tell you what's coming up next.
02:04:28.986 - 02:05:12.334, Speaker A: So I'm super excited to announce that in two weeks we'll be beginning our next hackathon, and that is called unicode, which is in collaboration with the Unisoft grants program. So I hope that all of you who had a great time learning about what's happening with web three, come work with us and join us for unicode. And applications for unicode are now open. So if you head over to unicode eatpoba.com, we'll be seeing all of you in two weeks for this next hackathon. So with that, we'll take a quick 25 minutes break. Our summit is scheduled to start at 03:00 p.m.
02:05:12.334 - 02:31:38.886, Speaker A: Eastern, so in 25 minutes. And in the meantime, I hope everybody gets some time to stretch, get some coffee, or eat or say hi or enjoy on the amazing prizes that you've won. And we'll see you in 25 minutes. And in the meantime, I hope all of you enjoy some lo fi beats and we'll see you all shortly. Thanks, everybody. Good morning, good afternoon and good evening, everybody. My name is Kartik.
02:31:38.886 - 02:32:19.874, Speaker A: And welcome back to the ETH online finale and merging Scalability Summit. So you're all watching this in our global TV platform. For those of you joining us now, and we're not part of the original past few hours for the finalist projects, be sure to sign in and say hi. We will be taking questions for our Summit talks today. So if you have any questions for our speakers, if you want to get any clarifications or want them to answer anything, you can just log into the chat and post your question and we will be able to relay that to the speakers. And if you don't know already, this event is organized by ETH Global. ETH Global is an organization with a very simple mission.
02:32:19.874 - 02:32:43.962, Speaker A: Our goal is to bring on thousands of developers into the Web Three ecosystem. And we do this primarily by running hackathons and Summits. And ETH online is no different. This is our biggest event ever. We ran six different Summits over the past few weeks. We talked about what is happening with NFTs and Creator economy. We talked about the ins and outs of the Compound grants and the Ave Grants ecosystems.
02:32:43.962 - 02:33:28.030, Speaker A: We had a whole summit on the latest in governance and DAOs and what's going on with tooling to the best practices. And then we also hosted a Summit last week on the latest on developer tools. And this brings us to our last Summit of this event, which is everything that's happening with ETH Two, with merge and scaling Ethereum. So let's get started. On top of those Summits, we also had our biggest hackathon ever. We had over 1150 hackers from 77 different countries spending 19 different time zones participate. We worked with 54 different partners, 160 mentors, and are giving away and gave away over $350,000 in prizes.
02:33:28.030 - 02:34:05.894, Speaker A: So it's been a phenomenal past five weeks for all of us at ETH Global. And here is the exciting conclusion with our last Summit for this event. So let's talk about what the next 4 hours look like. This is our MERS and scalability summit as an agenda. We'll have a quick overview of what's happened this year in Ethereum from Josh Stark from the Ethereum Foundation. Then we'll have Danny Ryan come on and talk about the end of proof of work and all the work that the two team has been doing. We're going to have an amazing panel with Ben Superfitz, Carl Dapline and Evan on client diversity.
02:34:05.894 - 02:34:40.514, Speaker A: For e two. We have Marius talk about the merge perspective from the execution layer. And Guillaume is going to talk about statelessness and vertical trees. Then we're going to conclude the day with Vitalik talking about how do we upgrade our infrastructure for a role centric version of Ethereum or World of Ethereum. And then the last talk will be an AMA with Gucci, who is the Executive Director of the Ethereum Foundation. So without further ado, let's begin with our very first talk of the day. We have my great friend Josh Stark talking about here in Ethereum.
02:34:40.514 - 02:35:12.480, Speaker A: Josh wasn't able to join live so we ended up getting this recorded and we'll be playing the video here next. And without further ado, let's get started with The Year in Ethereum. Thank you, Karthik, for what I'm sure was a great introduction. Thank you, everyone, for being here. I'm very pleased to be speaking at Ethanline this year. My presentation is titled the Year in Ethereum two Underrated Developments. Let's jump in.
02:35:12.480 - 02:35:56.282, Speaker A: So, to start off hi. I'm Josh. I work for the Ethereum Foundation and I've worked in the Ethereum space for a while now. Previously, I founded East Global, the company putting on this conference and also a company called L Four. If you want to follow me, I tweet at the address you see on your screen and you can also find my writing at Stark Mirror XYZ. So each year, myself and my friend and colleague Evan Van Ness write this blog post called The Year in Ethereum. We've been doing it since 2018 and this year I've been thinking about what's going to be in the 2021 edition.
02:35:56.282 - 02:36:30.502, Speaker A: And I want to kind of share some of my thinking about this. And in particular, what I want to talk about are two big developments and two underrated things about them. So, as we'll see in a second, some of the things that happened this year are very obvious. But I want to kind of dig into what might be not obvious about them the things that might be underrated or not appreciated. And I want to try and convince you that these things really matter as much as anything else that you see in your Twitter newsfeed. So let's jump into it. Number one the year of the NFT.
02:36:30.502 - 02:37:21.474, Speaker A: I'm sure this is a surprise to everyone watching this that I rate this as an important development this year. This is a pretty amazing graph. Right on the far left here, we have the kind of brief heyday of CryptoKitties which was a project in Q Four 2017. Since then, not a lot of interest. NFTs, at least in terms of the number of active people buying and selling them on Ethereum or the market value of what was being traded a year ago today. It wasn't much different than it had been for the preceding two years. A little bit of activity, but just comparing with the recent peaks it's really been an astonishing story of growth in terms of users and the value of the assets being traded.
02:37:21.474 - 02:38:32.430, Speaker A: Now, of course, NFTs are not just on Ethereum but Ethereum does command most of the market share at least in terms of the value of the assets and the amount of money changing hands. And NFTs, of course, also expanded pretty substantially into other categories as well. There's a game called Axie infinity built by a developer in Vietnam. And when you kind of rank the value of their assets that make up the Axio Infinity protocol, this compares to some of the largest gaming companies in the world. And the last graph I want to share here is just the comparison of the NFT search interest for search interest for cryptocurrency. It's incredible to think, I mean, imagine telling someone in 2015 that in a few years, an application that will be built on ethereum, a project that no one believed would ever ship, and even if it did, that it would ever work would have a higher amount of search interest than the entire category of cryptocurrency. It's a pretty astonishing change and it should make us humble about what might happen over the next five years or even beyond.
02:38:32.430 - 02:39:25.860, Speaker A: Now, if you ask someone what NFT is, they're probably going to say one of these things today you have profile pictures, you have art, you have ENS names, you have game items, you have blog posts or crowdfunding on Mirror. There's a pretty wide variety. But remember that NFTs are just things that conform to a standard. You can attach any kind of digital file or asset or anything to NFT token. And we're really only beginning to explore what that might look like. The other component of the story this year is the amount of mainstream interest from celebrities and big brands and institutions like Christie's. It's exciting and validating to have something that once was such a small niche thing as a crypto, know, on display in Christie's on Jay Z's profile picture in Times Square.
02:39:25.860 - 02:40:14.130, Speaker A: It's pretty incredible, right? It's all fine. What I'll say about this, know, celebrity interest and interest in big brands, it comes with the cycle. We also saw this in different ways in previous cycles, where crypto is cool when the numbers go up and not cool when the numbers go down. So while it's validating to have a lot of celebrity interest or whatever, it's not the most important thing. It's not the thing that really matters or that when we look back in ten years we'll say riddy mattered. So what does matter? Here's the thing that I think is underrated about all of this. The most important thing to me about the NFT boom over the last year is this a new kind of person can now make a living on ethereum.
02:40:14.130 - 02:40:58.654, Speaker A: By make a living, I mean make money, support themselves, build a life, build a career out of that's incredibly exciting. So what do I mean by this? One way of telling the story of crypto is through the expanding circle of people who can make a living from it. From 2010 and 2013, if you were making a living on crypto, it probably meant you were an investor. You bought Bitcoin, the price went up, you held good for you, you made a living, and maybe much more than that. From 2014 to 2017, in. This kind of next era. You have not just investors, but developers and also people that work for crypto companies.
02:40:58.654 - 02:41:34.326, Speaker A: So early companies like Coinbase are coming online, they're hiring people. Individual developers are launching Altcoins or other layer one protocols. We're seeing the first ICOs like ethereum. It's another way to make a living and maybe much more. For some of the people on this list from 2018, 2020, things don't change all that much. The details change, right? If you're an investor, you have new investment products, you have new ways of making money as DeFi comes online and so forth. If you're a developer, you have new kinds of applications that you can build and make money from, and there's lots more crypto companies coming online and a greater variety.
02:41:34.326 - 02:42:25.318, Speaker A: But it's still like you need to be one of these types of people in order to make a living from Ethereum. But this year, all that changed. This year, now, for the first time, people who are creatives, people who are artists, musicians, writers and also gamers can make a living on Ethereum. That's an incredible zero to one moment that happened this year and is not going to stop happening anytime soon. Now, to earn a living using Ethereum, you don't need preexisting capital to invest, which a lot, or even, I would say, most people in the world do not have. You don't need to be technical, which most people in the world are not. You don't need to be into finance or investing or understand what a derivative is, again, because most people don't.
02:42:25.318 - 02:43:10.518, Speaker A: And you don't have to work for a crypto startup because most people can't or won't or don't have access to the opportunity. All you need to make a living on Ethereum now are three things. You need to create something that has a digital form, you need to build a community of people who value what you create, and you need to use Ethereum. That formula gives access to making a living to earn income to a huge proportion of people that did not have it previously. And that, to me, is the most exciting thing about the NFT boom of this year. And remember, this is not going to stop. NFTs are a blank canvas, and we've barely explored that canvas.
02:43:10.518 - 02:43:58.930, Speaker A: If we can imagine a hypothetical graph of everything you can do with NFTs, it might look like this the space of all possible NFTs, we've really only scratched the surface, the very kind of first, smallest corner of what can be done here. At a certain point, NFTs stop being an area of technical innovation and become one of social innovation. What do people value? What can they coordinate around? And that design space is absolutely huge and it's only going to continue to expand as more and more people get into this, more and more people realize that they can earn an income from it. So that's the thing that equity matters about NFTs this year. So that's the first theme. Let's move on to the second. The year ethereum scaled.
02:43:58.930 - 02:44:52.378, Speaker A: And this is not the year that Ethereum finished scaling, but I think it is the year that it really earnestly began to happen for the end user's perspective. In 2018, I wrote a blog post called Making Sense of Ethereum's layer Two Scaling Solutions. And at the beginning of that blog post, right at the top, I wrote the following for Ethereum, 2018 is the year of infrastructure. This was going to be the year when early adoption will test the limits of the network, renewing focus on technologies built to scale the network. Now, I didn't include a hard prediction in that because I didn't want to be held accountable to it. But I do remember that I was very optimistic when I wrote this, that within a year, maybe two state channels and Plasma would be live. And being used to scale the world of applications on Ethereum state channels is live, but it's got a niche interest or kind of a niche use case.
02:44:52.378 - 02:45:30.546, Speaker A: And Plasma, as we'll see, kind of evolved into something else. A few years went by, not quite this many, but let's call it around three. And here we are. Things are really happening. More than $3 billion is locked into layer two protocols where users are using those assets in a way that is performant, but still secured by the core Ethereum protocol security layer. Just to collect a few examples, there's lots of layer two solutions out there, but a few things that happened this year alone. Arbitram has been on Mainet for a while, but it opened up to everybody in August.
02:45:30.546 - 02:46:17.566, Speaker A: Optimism is on main net since August, but it's still Permissioned ZK sync has been on testnet since May 31. And Starkx is used by a bunch of different projects, including dYdX, Immutable, X, So Rare, all of which went live on main net this year, and Diversify, which went live last year. There's a lot more to learn about layer two protocols and all the various projects that are out there right now. I do recommend Ltob.com as an incredible resource to learn about them. So the other thing I wrote in this blog post is that something that held up pretty well. I think that we should expect that there will be new and unexpected layer two protocols that improve on the existing models we have today, or make new trade offs between the different competing interests.
02:46:17.566 - 02:47:09.640, Speaker A: And this turned out to be right on. If we look at all of the projects listed on Ltb.com, basically everything on this list, the technology didn't exist three years ago. Plasma kind of did not turn out because there were real limitations to that approach, but it spawned the world of roll ups, which turned out to actually work. And so if we remove the two Plasma projects from this list, everything you see here did not exist. The technology did not exist when I wrote that blog post. It's a real testament to both the strategy of the Ethereum community of having a programmable layer that can be the basis for many different types of scaling solutions and also the incredible community of people who have been researching and innovating and taking risks and building companies and building these protocols over only a few short years.
02:47:09.640 - 02:47:52.050, Speaker A: So that's all obvious. It's all great. It's very exciting. What's underrated about it? What I think is underrated about this is that as these projects launch and we gain experience from them in production, the long term architecture of the greater Ethereum Ecosystem is coming into clearer view. And it's like we've kind of been on this journey and we reached the top of a hill and now we can see more clearly where we're going. The journey is not over, but now we have a vantage point where the landscape is a lot more clear, a lot more obvious to us. So I think the future looks like this.
02:47:52.050 - 02:48:40.002, Speaker A: The future is modular with Ethereum at the core. And I want to kind of run through what that modular future might look like. And I should first caveat that this is not an official roadmap of any kind. This is not the official view of the Ethereum Foundation. This is my synthesis and summary of what I'm seeing in the ecosystem and also my adaptation of what I've learned from others writing and research. Two particular sources I should mention are, of course, the Roll up centric Ethereum Roadmap blog post from last year by Vitalik and also more recently, a whole bunch of blog posts from a writer named Ipolinha on Twitter who's a pseudonymous writer who's really produced some excellent stuff. That has helped me see the future more clearly and helped many others as well.
02:48:40.002 - 02:49:09.340, Speaker A: So both great contributions from community members right here. I strongly recommend you read both of them. Special thanks to Paulina Also for giving me some feedback on this presentation. I really appreciate your time and what you've done for the community. So let's talk about what the modular future looks like. And let's begin with a simple model of Ethereum. And I want to kind of run through the basics that makes this all possible and why we end up where we think we're going to end up.
02:49:09.340 - 02:49:47.190, Speaker A: Ethereum has two basic functions it executes things and it secures things. It has an execution function and a security function that are very intertwined, but we can distinguish between them. The execution function is what processes your transaction, right? Ethereum runs smart contracts. The Ethereum virtual machine or the EVM takes transactions, updates, state. Great. This is the layer that apps and users interact with. If you send a transaction, it's handled by execution.
02:49:47.190 - 02:50:30.258, Speaker A: The other part of Ethereum is the security layer or the security function. Ethereum, of course, maintains consensus over the state of the EVM and proof of work and proof of stake ensure that there's an extremely high cost to trying to mess with that state. So you can be quite assured that once your transaction is finalized, it's going to stay that way. Apps and users might not interact with this layer in a direct sense, but without this layer, of course, there's not much point to the execution layer because it wouldn't be secure. So here's our little box representing Ethereum. And here it is performing these two functions, execution and security. The problem is this simple model doesn't scale.
02:50:30.258 - 02:51:16.962, Speaker A: As we've learned, we want execution to be fast and cheap because it needs to scale to the demands of the 8 billion humans who are eventually going to want to use it. But there's a trade off. If we try and make Ethereum fast and cheap in a kind of naive way, it becomes less secure. And without that security, I mean, we just can't compromise on it. Otherwise the execution layer is no better than a spreadsheet or a database held by some group of people who we don't necessarily trust. For Ethereum to be trustless, decentralized all these things, it needs to be secure. So what's the solution? The outline of the solution we've known for a long time, which is that we need to modularize, we need to have kind of separate environments that handle different parts of this need.
02:51:16.962 - 02:52:00.530, Speaker A: And this is the insight behind the layer two protocols I talked about in that blog post from three years ago. And it's the kind of basic function of roll ups. And really what I'll be talking about here today is roll ups because they are the dominant scaling solution that are now being implemented and used. So the basic idea is this. We have Ethereum at the bottom and we have this other environment that is doing execution. Now, Ethereum still does execution in the sense that of course the EVM still exists, but where the app and the user like what they're interacting with, where all the actions happening, it's happening on this other environment. And so we're going to kind of hide this box just for simplicity's sake.
02:52:00.530 - 02:52:44.110, Speaker A: So the idea is we create these modular components that can still preserve the security guarantees we care about. How is this possible? It works like this in a simple way. Here's the execution layer and let's imagine that you want to use uniswap. And so in this case, uniswap is going to run inside this layer two, this roll up. And instead of just doing everything on main chain, we're just going to store some data on Ethereum mainnet. We're going to take the information about the trades you're making, the outcomes of those trades, the state updates and so forth. We're going to roll it up and kind of compress the data and put it onto Ethereum mainnet.
02:52:44.110 - 02:53:25.360, Speaker A: The data we're putting there has two functions. There's kind of two components to it. One on the left is data that proves the validity of the transactions, right? A kind of a receipt that shows somebody or can be shown to somebody to say like, no, the transactions that happened off of Ethereum, they're valid transactions. They followed the right rules for updating state. And then there's also just the raw transaction data itself of these state updates and what changes were made. So let's talk about the thing on the left, because this is at the core of the security that is being inherited here. The reason that layer two can be secure is because of what's happening here.
02:53:25.360 - 02:54:12.038, Speaker A: These proofs of your transactions are what lets these transactions inherit security from Ethereum. And there's two ways that that works. One way is the optimistic way. Optimistic roll ups function as follows you are always able to prove later that your transaction was valid. You don't run the proof every time we record state to the Ethereum main net, but we preserve the option of doing so later. And so if there were a problem, a challenge or something went wrong, you're always able to go back to that data, produce a proof and say, no, I'm fine. I can show you that this transaction actually did happen, that it followed all the rules.
02:54:12.038 - 02:54:50.380, Speaker A: So that money that Bob sent to Alice does actually belong to Alice. Now, the other way to do it is a ZK rollup. And the very simple description here is that we're using special ZK cryptography moom math, as it's sometimes called, to create a proof that transaction was valid. And this is still scalable or saving us time, because this proof is much, much smaller and cheaper than just doing the whole thing on Ethereum in the first place. So we're still getting scalability gains from this. So that's the proof side of the equation. The other part of this is the raw transaction data.
02:54:50.380 - 02:55:36.562, Speaker A: So what's going on there? We need this for a few different reasons. Excuse my slides. The raw transaction data has to be stored and available somewhere for a few different reasons. Users need to know what data is in the block, right? If you are using uniswap on layer two, you need to be able to go check somewhere. What was the update? What was the outcome of my trade? Where is this money now? You need the information about what has been happening to be available somewhere. And you need to be able to rely on that. The other nodes that might participate in the roll up network to produce the roll up blocks also need that data to produce their own blocks.
02:55:36.562 - 02:56:29.922, Speaker A: And optimistic roll ups need the data in order to produce the fraud proofs that would actually secure your transaction. This brings us to the third function of blockchain infrastructure. We've talked so far about execution and security, but we also need data availability. And data availability is basically the function or the layer that stores transaction data. And it's needed for all these reasons that I already talked about for security to enable decentralized roll ups where there are kind of multiple entities that produce blocks and also just for users to know what's going on. We didn't have to kind of talk about it explicitly before because in this simple version of Ethereum, ethereum already provides for the kind of data availability that's needed because full nodes store this information. So it's able to be checked by Wallets, by Block Explorers, so users can get access to it and so that other nodes can produce blocks.
02:56:29.922 - 02:57:10.546, Speaker A: But once we're in this environment of having modular components, we need data availability that scales a bit further. And so there are some new requirements. So this is the third thing that our blockchain infrastructure needs to provide. So three things execution, security, data availability, or ESD for short. Now, as we kind of get here, this is really kind of giving us a better picture now of what the future might look like and what the different components of a modular blockchain world will look like. Now, of course, we have this kind of version of here's what Ethereum does and here's what layer two does, et cetera. But we can also just think of it more abstractly.
02:57:10.546 - 02:57:50.100, Speaker A: I mean, forget Ethereum for a second. Forget layer two, forget everything. You know, these are the three things that users need to have useful blockchain infrastructure. They need a security layer, they need an execution layer and they need data availability. And there's different ways that we could build an infrastructure around these things to enable them all to work in concert. And when we think about what the future looks like, we can think about, well, what projects or technologies are best placed to be the most successful solution for the different components of this world. So let's talk about that.
02:57:50.100 - 02:58:33.334, Speaker A: A security layer. We probably don't need too many of these. And the reason is that while it's actually better and more secure to have a small number of security layers that have a lot of pooled security instead of a whole bunch of separate security layers that are kind of carving up the available security in terms of assets and economic security. So right now, really only Ethereum and Bitcoin could play this role because they are just orders of magnitude more secure than any other layer one blockchain. And Bitcoin can't do this stuff. Bitcoin just cannot run the ZK proofs needed for ZK rollups. It just cannot run the contracts needed for optimistic rollups.
02:58:33.334 - 02:59:27.410, Speaker A: And so it just can't provide this function, but Ethereum can. So probably the security layer for the world's blockchain infrastructure is going to be Ethereum execution layers. We can have lots of those. What we're seeing in the market now is there's lots of competition between different projects as they compete on how they use the security of Ethereum, whether they use it at all the execution environments, the technology available to developers, all sorts of things might allow these to compete with each other. And we are seeing that in the market now. Now, some of these will be layer twos meaning that they will actually use the security of Ethereum as a roll up and others might stay separate or independent for whatever reason. But they're still serving a purpose for the broader ecosystem to enable users to use these applications.
02:59:27.410 - 03:00:00.860, Speaker A: Now, we kind of fill in some of these names. This is what we see today. There's a whole bunch of layer two projects that are using Ethereum for security and then we also have projects that might not use it and are either side chains or separate L ones or something else. There are still bridges between all these things. So you can move assets onto them but they're not using the security of it. So here's what the kind of execution environment landscape looks like today and it could grow to include many more projects or consolidate in some way in the future. We don't know what that looks like because we haven't got there yet.
03:00:00.860 - 03:00:37.090, Speaker A: Then, of course, there's data availability. And here too, we'll probably have some competition. One of those data availability layers will likely be Ethereum eventually. The plan is to add to Ethereum data shards that will enable a really large amount of data availability that is secured by Ethereum to be used by roll ups and others. And then there will probably also be other data availability layers that are separate and enabled to be used by anyone. And there already are some of these on the market right now. And so then we'll have this right? We'll have some of these projects that are layer two projects will use data availability on Ethereum.
03:00:37.090 - 03:01:53.498, Speaker A: Others will use a separate solution. Some might even let users choose which provider they want to use or change between them as needed by what the user wants or what the application needs. And maybe someday these separate layer one execution environments might decide to use Ethereum as a security layer. If it continues to be far more secure than their own security they're able to provide then it might make sense to specialize on being an execution layer and leave the crypto economic security piece to Ethereum and make it easier for your users to benefit from that and all that comes with it. So this is what Link might see that this is what's in the valley ahead of us or it's at least one potential version of the future. And at least for me, thinking about this and seeing projects actually launch and what they're actually doing and what solutions they're actually using makes this picture a lot more clear. It kind of gives us an idea of what the kind of basic components are that the world's blockchain infrastructure needs to provide and how all these projects might relate.
03:01:53.498 - 03:02:47.198, Speaker A: And I think this will become increasingly clear to more of the community and more of the market and projects will start to see themselves as fitting into a certain piece of this landscape. Right now there's just all these different blockchains layer, one side chains, L, two whatever. And I think most people don't really understand how they interact. They're all just kind of separate little islands that make different claims and have different relationships, but no one can really make sense of how it all fits together. And I think something like this is becoming more clear and will make more sense. So this is the beginning of what might be considered the greater Ethereum ecosystem, of how these different protocols will interoperate, how they will support each other, how they will collaborate as one large community as opposed to many separate communities. So that's what I think is the underrated thing about these rollouts.
03:02:47.198 - 03:03:26.590, Speaker A: Not only is progress happening, but it's progress that lets us see further into the future than we could before. I want to remind you, of course, this is not an official roadmap, this is not the official view of the Ethereum Foundation. This is my synthesis and summary of mostly other people's ideas, predictions and guesswork. So take it seriously, but perhaps not literally. Thank you so much for your time. I really enjoyed being here today, giving this talk, and I hope you enjoy the rest of the day. Thank you so much, Josh, for that incredibly simple and clear explanation of how everything is going to be set up.
03:03:26.590 - 03:03:53.494, Speaker A: And the great thing about this thing is that it sets the stage for what the rest of the day is going to look like and let's jump right into it. So next up we have Danny Ryan from Ethereum Foundation doing his talk. And it is titled The End of Proof of Work, which is already a hot enough of A. So let's let's get right into it and I'll let Danny take over. Welcome, Danny. Thank you. Actually changed the title name.
03:03:53.494 - 03:04:05.434, Speaker A: I think it's called killing proof of work. Now a little more aggressive. Even better. Okay, so y'all can see this. Everything is great. Okay, cool. Today.
03:04:05.434 - 03:05:00.438, Speaker A: I'm talking about killing. Proof of work on ethereum, at least. But we might inspire others to kill Proof of Work too. The subtoc is when, why and how merge. First, I can talk about a little bit about when recently, which if you were following in the past week on the internet, many developers and researchers met together for the Amfora interop and we had much progress on the merge, specifically on killing work, proof of work on unifying the Beacon Chain consensus with that of the execution layer of ethereum today. This was pure joy, this picture. This was like t minus two minutes before our final kind of closing dinner and we successfully had launched a test net of 100 nodes, 10,000 validators, had proof of work going, had proof of stake going and they came together and we're all cheering.
03:05:00.438 - 03:05:50.922, Speaker A: Actually, we're all looking at a screen and cheering because of this tiny little text that appeared on the screen which says entered proof of stake stage and then subsequently watch that proof of stake finalize the merge. So when? Sooner than ever. I know when I began to work on proof of stake in 2017, everyone was saying Casper is coming. And it was, but it wasn't coming quite as soon as we thought it was. But now this is actually soon on all core devs. Today we're talking about how long to push back this difficulty bomb in December for kind of a final stretch. We have a testnet up today that you can go and check out, but at the end of November, targeting a reboot of the testnet with the latest and likely to be final specification updates.
03:05:50.922 - 03:06:23.606, Speaker A: So it's coming when it's coming? Why? I talk about this a lot. Three S's to increase security, increase sustainability and scalability of ethereum while retaining decentralization. These things are hard to do. It's one of the reasons it's taken a long time, but here we go. I'll dig into each one of these and we can better understand what I mean when I say this. So security, I make a claim proof of stake is more secure than proof of work. I'll give you at least a high level intuition as to why that is.
03:06:23.606 - 03:07:26.998, Speaker A: So first one is it's less centralizing with respect to the crypto economic asset at play. So what is proof of work? What is proof of stake? It's really proof of dedication of scarce resource to the protocol in proof of work, that's mining hardware and the burning of energy in proof of stake, that's the dedication of the end protocol asset itself, ether. Both of those things are easy to prove to the protocol that you've dedicated to it. And that's why they're good versions of a crypto economic consensus protocol. You could imagine like proof of car would work, but it's hard to demonstrate that you dedicated a car to a blockchain, but that's the intuition is scarce resource. But the thing about proof of work is you get these economies of scale. The large players are entrenched in supply chains, they're building their own chips and so they can take some amount of capital and more efficiently turn that into profit, as opposed to like the home hobbyist, which is getting second generation hardware, maybe even used hardware light in the supply chain.
03:07:26.998 - 03:08:36.338, Speaker A: And so their function of turning their capital into profits is not quite as good as those entrenched in the supply chains. But with ETH and with proof of stake, the crypto economic asset is ETH itself. And thus the conversion of that into staking rewards is as much pure function lacks these economies of scales we see with proof of work, the asset is also highly liquid and available. It's kind of implied by the previous, if I want to stake, I go get ether, you can get ether in 10 million different places and there's a very active market of trading. Thus you get a pure function of return of capital and you don't have these mega centralizing factors that you do in proof of work. There's also a higher security margin and I don't know if this is very widely spoken about. So we take crypto economic capital, whether that be mining power and energy or the staking asset and a proof of stake protocol and we dedicate it to the protocol so that's this white block crypto economic capital and then you get a return.
03:08:36.338 - 03:09:25.854, Speaker A: So some amount of issuance, staking rewards and fees and other ways that you can get a return on that investment. And in proof of work that's your security margin is that return. And so that's a carrot. We incentivize you to put up your capital to make this thing more secure and you get a carrot. The thing about proof of stake is that not only do we have a carrot, but we have a stick. And so the security margin isn't just the return, but because the asset itself is in the protocol, the asset can not only be rewarded for positive behavior, but penalized for negative behavior. So this might be penalized for being offline, not doing your job very well or in the extreme where you're doing something explicitly nefarious, you could actually lose all of that capital.
03:09:25.854 - 03:10:24.402, Speaker A: So the intuition here is if you try to attack proof of work ethereum, no one can come. Well, somebody probably could, but the protocol cannot go burn your mining farm down whereas in proof of stake those assets are literally in the protocol and so the protocol can identify attacks itself and burn your virtual mining farm down. So we get a much higher security margin. And so for the same amount of crypto economic capital securing a protocol, we get a much better security margin. Stick and carrot, better than just carrot, we also get better emergency recoveries. So in proof of work, when you get attacked in a 51% attack, that entity now just is in God mode. And they can reorg and double spend and reorg and double spend and vitalik in a post long ago called this is Bond camping attack, where essentially, like, you come back alive, you're back at the head of the chain, and then you get attacked again.
03:10:24.402 - 03:10:56.366, Speaker A: And you can just do it in perpetuity. You can't really get your feet underneath you again and secure the chain. And this is because those attacking assets, the mining hardware and the energy are extra protocol, they're outside of the protocol and so the protocol can't do anything about it. Once you have enough capital to attack the chain, it's game over your spawn camp forever. And so you can say to the miners please stop spawn killing us, please. And they'll just say stop spawning, we're in god mode. The nice thing about proof of stake and I.
03:10:56.366 - 03:11:48.494, Speaker A: Alluded to this in the security margin is that attacking capital can either be burned depending on the type of attack or can be socially intervened. So many attacks are actually detectable by the protocol itself and can burn nefarious capital. So if you try to rewrite history you get to do so once and then you get all your assets burned as opposed to proof of work. And certain other types of attack, like potentially censoring can be identified and at least socially coordinated around. So we cannot socially coordinate out a subset of mining censoring mining capital, but we can, because the asset is in protocol, socially coordinate in the event of an issue and essentially fork out evil people's assets. That's a nuclear option and one I don't actually expect to see, but the threat of it is actually pretty powerful in and of itself sustainability. The third is this is Ethereum proof of work.
03:11:48.494 - 03:12:10.578, Speaker A: Well, it's probably more like Bitcoin proof of work. I think they use a lot more energy than us. But because the amount of mining power that secures a protocol scales with the value of the protocol, eventually that's where we're going to end up. And that's not where we want to end up. We want to end up more like this ethereum. We want to build new beautiful utopias with ethereum. So we need to kick out this energy hungry component.
03:12:10.578 - 03:13:20.620, Speaker A: And that's the third s of Y proof of stake and we can take a deeper look at this. The estimated energy consumption of Ethereum right now is 80 terawatt hours per year, which is a lot that is akin to the energy consumption of Chile and would put it, if it's its own country, like in the top 40 countries of energy consumption in the world. Bitcoin is actually much worse, orders of magnitude worse and is more like on the order of Poland and is maybe in the top ten, top twelve in terms of countries energy burning in the world. So let's look at some quick napkin math on what this means when we get rid of proof of work. So a normal computer, which I think my computer looks something like this, takes about 400 kilowatt hours per year of energy just to keep it on, do its normal processing, light up its screen and talk to the internet. On Ethereum today there are about 10,000 nodes, give or take some amount. And so that's four gigawatt hours of energy per year.
03:13:20.620 - 03:14:16.190, Speaker A: So that's kind of the baseline to run all the computers on the network. And then you have this other thing, the mining, which is that 80 terawatt hours of energy. And so when we get rid of proof of work we actually just become a network of nodes, a network of like the energy consumption is literally just the amount of computers on the internet that are running Ethereum, which is not that much energy. It's a bunch of laptops, it's a bunch of home servers. And so we get to take this 80,000 gigawatt hours and slash it out and we just get the four gigawatt hours of running about 10,000 nodes. And even if that scales, even if that goes to 100,000 nodes in the network, which would be awesome, it's 40 gigawatt hours on the entire usage of energy. And so to contextualize that a bit, that's a 99.995%
03:14:16.190 - 03:14:55.514, Speaker A: energy reduction. That's insane. And the intuition there is because you don't have to secure the network, the dedication of the resource, the scarce resource is not energy. The dedication of the scarce resource is ETH itself in proof of stake. And so that is how we're going to go from this to this 99.95. And the crazy thing is if ether ten x not making price prediction but if a proof of work asset ten x's, the new equilibrium for the amount of energy you're burning also scales linear with it. So we also get out of this like this hamster wheel thing of energy.
03:14:55.514 - 03:15:18.850, Speaker A: As the protocol becomes more valuable, we'll burn more energy. We don't want to do that proof of stake, more secure, more sustainable oh, I didn't do the third one. And more scalable. Oh that's I messed up that slide. Anyway, that said 10% faster block times. So we're coming from like 13.6 seconds to 12 seconds and less variance in timing scalability.
03:15:18.850 - 03:16:12.130, Speaker A: We actually do get that scalability gain but that's not like the main reason proof of stake is going to be more scalable at the merge. It's going to give us just a little bit of marginal gain because you get more regular block times and you get a little bit faster block times. But that's not the end of the scalability narrative with proof of stake. What it actually does is it opens up the door for more sophisticated consensus mechanisms with proof of work. Because the consensus participants are extra protocol, we cannot sophisticatedly orchestrate them to do more complex things in our consensus protocol. And what it really does is it allows us to utilize Sharding which takes consensus participants and randomly samples them in a very secure way to do distributed work across different subsets of the protocol at any given time. So Sharding the intuition is that we get to get more out of our consensus mechanism.
03:16:12.130 - 03:16:58.286, Speaker A: So the merge lays the foundation for more scalability because by moving from proof work to proof of stake we can architect more sophisticated consensus mechanisms to come. So I'm going to shift into we did when relatively soon we did why the three S's more secure, more sustainable and more scalable while retaining decentralization. And now we're going to do the how. The how and what it's going to look like. So this is ethereum after the merge. It looks like a blockchain because that's literally what it is. It is a single unified blockchain and to an end user it looks and feels like a blockchain.
03:16:58.286 - 03:17:39.578, Speaker A: It looks and feels actually exactly like Ethereum does today, except it's a little bit more secure, it's mega more sustainable and we all get to hang out in a nice, more secure land. But let's dig in a little bit. This is what it looks like after the merge. We have the consensus layer, we have the beacon chain supporting the security of Ethereum. And then we have the execution layer where all the transactions and accounts and state and stuff lives. If we dig in a bit deeper, we can take a look at this consensus layer. If you're familiar with the beacon chain, you have slot, you have a parent, you have randomness, you have deposit route for bringing in new validators, you have all these system level operations like attestations and deposits and exits.
03:17:39.578 - 03:18:04.310, Speaker A: And then you have the execution layer embedded in this beacon block. That, again, is all the things that you know and love and hang out with in Ethereum today. That's what it looks like after the merge. And actually this execution layer references itself. So we have kind of this like sub blockchain inside of the blockchain. That's an important point that I'll reference in a minute. So this is the execution layer.
03:18:04.310 - 03:18:44.866, Speaker A: This is from the perspective of a user today on proof of work and after on proof of stake. This is what everything looks and feels like. The outer consensus that gives you security is for most use cases and for most users, that's an implementation detail, right? As long as I'm getting sufficient security. So this is what Ethereum looks like today. Instead of that proof of stake consensus layer as the kind of outer secure shell, we have a proof of work consensus layer and we have that execution layer embedded in proof of work instead of proof of state. So this is what the consensus layer looks like after the merge. We don't need to really go into that.
03:18:44.866 - 03:19:18.010, Speaker A: I think that's a bit extraneous, but essentially it is consensus and we have some stuff we can shove into consensus in this blank spot. And Ethereum after the merge is simple and we're going to show you how we get there. So this is ethereum today. The beacon chain was launched at the end of last year, in December. And the beacon chain is a consensus mechanism. It's a proof of stake consensus mechanism and is primed to come to consensus on things other than just itself. And parallel to this beacon chain that is running very successfully is the proof of work chain.
03:19:18.010 - 03:19:47.430, Speaker A: This proof of work chain, as you see, runs in parallel. It has all the user activity today. And the idea is we want to take all this execution layer activity and shove it into the beacon chain and let go of our energy burning proof of work overlords. So this is what it looks like. The execution layer is chugging along in proof of work. We hit a terminal total difficulty. So essentially this block exceeds some threshold of total difficulty that will be decided upon in a few months.
03:19:47.430 - 03:20:42.120, Speaker A: And at that point the proof of stake validators say you're mine now and continue make a continual chain, a continual sequence of history from where the previous execution layer lived into proof of stake. And from the end user they go from here to here to here to here and they just are hanging out in a proof of stake chain instead of hanging out in the proof of work chain. And we can finally move on with our lives and finish this proof of work business. So again, the key is that we have these two things in parallel right now. The proof of stake doesn't really have any much valuable things for users. The proof of work has all that and at a point of transition in time, the proof of stake validators take over the mantle of securing the execution layer of Ethereum. And the nice thing is that to an end user it just looks like this.
03:20:42.120 - 03:21:15.570, Speaker A: The first two blocks here could be proof of work. The next three and forever are proof of stake. And to the end user it just feels and looks like a continuous blockchain. That's major, major design goal like ethereum is a fantastic place with tons of activity and tons of security and lots of things and needs uptime and it needs consistency. And this merge process has been designed with that in mind. There is no downtime and there's no migration process. You literally just continue to use your DApps and the security gets better and we get rid of all that energy consumption.
03:21:15.570 - 03:21:55.282, Speaker A: And after that we take that consensus mechanism. This is a bonus. This is something we do after is you shove more things in the consensus mechanism. We have that execution layer inside of the consensus layer and then we also add the sharded data layer where the validators not only are processing the EVM and that transaction payload, but they're also being randomly sampled across shards to provide a scalable data layer. Cool. So there's some engineering implications here. I alluded to it at the beginning but we have different types of client teams now.
03:21:55.282 - 03:22:31.654, Speaker A: We have what we're called ETH one clients. Those become execution layer clients. They build execution engines for this post merge world. They essentially take their client, subtract out proof of work and begin listening to the beacon chain. And so if you're building geth is primarily a sophisticated execution layer that handles transaction processing and state management and all that hard stuff and a very minimal kind of brain called proof of work. And we're essentially cutting out the brain and listening to the beacon chain after. And what we call e two clients.
03:22:31.654 - 03:23:12.540, Speaker A: What is that? These clients become consensus layer clients and what have they been doing for the past few years? They've been creating highly sophisticated proof of stake engines and those drive that layer of the software after the merge. And so what does this look like? It looks like two pieces of software living next to each other. The execution engine being driven by this engine API. You have user APIs that remain entirely stable. All those web three libraries. Then you have these beacon APIs where if you want to query about validators and different things about the consensus, you ask there. And actually the nice thing is we can take a Web Three library, web three JS, Web Three Pi, whatever it may be, and just namespace these things.
03:23:12.540 - 03:23:34.334, Speaker A: The standard API is still a bit web. Three e. No problem. And then we can add some additional APIs, web Three beacon. And so I can continue to use the same software and if I want to get a peek into the consensus layer or the proof of stake consensus layer, I can just call Web Three beacon. And the nice things there. There's a bit of UX work to do here.
03:23:34.334 - 03:24:08.730, Speaker A: Obviously running two pieces of software is harder than running one, but there's some nice efforts on doing a unified GUI on the two, maybe some unified CLIs. Peter was working on this thing called Minority that maybe doesn't help the UX, but it does a nice multi client thing. Check it out. Anyway, that is it. I will shill these NFTs one more time. If you want to check out if you want to own a piece of Ethereum history, you can go to this OpenSea when merge page. I think the floor has been bought up.
03:24:08.730 - 03:24:58.378, Speaker A: But if you want to donate to the researchers and developers working on this day in and day out, you can go buy an NFT, support the cause and these will be distributed to those that work on the merge after or on the merge chain. I think I have a few minutes. If there's any questions, I'd love to chat. Yeah. Thanks, Danny. One question from one of the audiences like you talked about killing proof of work kind of extrapolating way too far out. What does the world look like with post quantum kind of pieces coming in and any concerns that you may have now for proof of stake in that world? Yeah, so there are a number of things that we want to do in the next few years.
03:24:58.378 - 03:26:06.094, Speaker A: So that involves killing proof of work, that involves creating a more sustainable state solution, that involves bringing Sharding online and probably a number of iterative improvements to the EVM. Once we get a lot of that in place, ethereum becomes like a very sustainable piece of architecture for the internet. Except for this one glaring problem which depending on the person you ask, could be in ten years or could be in 50, and that is to make the protocol quantum resistant. The entire internet, including Ethereum, is going to have this problem and it is on the roadmap to replace all non quantum resistant components with quantum resistant components as soon as is feasible. So that was a design goal in a lot of the building and designing of the beacon chain was there needed to be a known post quantum analog for any of the tools and gadgets we were using. So like signature aggregation, we use BLS that's not quantum resistant, but you can use Starks to do the same thing. You wouldn't want to do it today because it'd be very expensive.
03:26:06.094 - 03:26:49.566, Speaker A: But we do expect in the next five years or so for that to be a much more palatable solution. And so in that probably five plus year range, I would imagine we slowly kind of swap out some of these components for quantum resistant components. Awesome. Well, hopefully Jared, that was a satisfying answer. One other question I have for you, Danny, is and you kind of talked about mostly what's in the future and how we're looking at killing proof of work. Could you give us an update on basically what's happening right now with the merge timeline just from your review? Just high level items. We got a couple of minutes, so we'd have to we talked about this a bit on all core devs this morning.
03:26:49.566 - 03:27:54.130, Speaker A: At the end of the interop, which was last week, we had a general thumbs up all around of we had a number of spec refinements and mostly simplifications that came out of the interop and those will certainly be done by the end of October. Then throughout November, client implementations will iterate to get these spec changes done. I think we'll do a few short lived testnet launches in November with a target of a sustained testnet at the end of November to run through the holidays. Then we come into January and are able to make a little bit more clear decisions about timeline. From there, it's either going to be something where we're feeling pretty good and it looks like March, April, maybe early May, or things have surfaced where we need more time, more testing and at that point we would have to kick it down the line. I'm very confident. I think that the work that we've done and the momentum behind this thing is pretty extraordinary at this point.
03:27:54.130 - 03:28:35.914, Speaker A: And I think in January we're going to be feeling pretty good. There will be in December a hard fork and upgrade on the proof of work chain to push back the difficulty bomb. And I believe that would be pushed back for about early May, mid May. And so really that is what we're tempting to do right is before we hit that difficulty bomb and if not, we'd have to kick it back maybe a month or two. Well, you heard a year second because I think you heard it first at the world core desk call, but this was great. Hopefully we get things sooner than outlined, but that's the plan, what happens next. So thank you so much Danny.
03:28:35.914 - 03:28:54.390, Speaker A: And if there's any other questions, we'll rely them to you over email. Thank you very much. Appreciate you having me. I'm excited to have you on. All right. With that, we are ready for our next talk. And that is a incredible panel, talking about all things clients for each two and client diversity, which we know is a really important topic here.
03:28:54.390 - 03:29:17.600, Speaker A: We have a lot of panelists for this one. So we have Superfiz from each taker. We have Carl from Ethereum Foundation. If that line from ChainSafe and Evan Management Week in Ethereum and Moderating, this will be Ben, who is product owner at Teku. I'll let Ben take over and ask all of our panelists to intro themselves. So without further ado, let's hear about client diversity. Welcome, everybody.
03:29:17.600 - 03:29:32.482, Speaker A: Thank you, Cardik. And good morning. Good day, good evening, wherever you are. Ethereums. It's great to be here. We are missing one. I think lion should be joining us shortly, but I don't see him yet.
03:29:32.482 - 03:30:06.866, Speaker A: But let's do some intros. So I'll do myself first. I am proprietor of What's New In ETH Two, which you can find at ETH Two. News. And as Cardig said, I am also product owner, product manager of the Teku ETH Two client, which I'm not representing Teku here today in this client diversity panel, but I hope that gives an interesting perspective. Evan, you're first on my screen. Yes, I'm Evan Vednas.
03:30:06.866 - 03:30:34.390, Speaker A: I'm most famous for trying to cancel Ben for using the E Two nomenclature. Still, I also have a newsletter called Week in Ethereum News and I've done stuff for a while. I guess that's my bio. Thanks, Evan. Carl, everyone. I'm Carl Beek. I work as a researcher with the Ethereum Foundation on all things Ethereum Consensus.
03:30:34.390 - 03:31:12.180, Speaker A: Lately, been doing a lot of fork choice stuff and yeah, caring a bit about client diversity. Thanks, Carl. Hey, Superfizz. Hey. So I'm superfizz. I am probably like an old school miner and with a couple of friends, I decided it would be a great idea to co found a group called ETH Staker. And through ETH Staker, we promote involvement in the beacon chain by normal people and we work to be welcoming first and knowledgeable second.
03:31:12.180 - 03:31:40.060, Speaker A: Wonderful. We love ETH staker. Lion, you made it. Say hi and give a quick introduction, please. I'm not hearing lion. Yeah, we can't hear you. How about now? Yes, it's good.
03:31:40.060 - 03:32:09.666, Speaker A: Sorry. So, yeah, I've been part of Dapnode since 2018. OG DAP, helping make running nodes easier. And then when Ethereum came ethereum two came. So making staking simple to non ecoplippo has been one of the mottos. And I'm also CORDEP in lodestar, so it's awesome to see this space from both sides of the equation. Great.
03:32:09.666 - 03:32:59.758, Speaker A: Thanks, panel. So I'm going to start by setting the scene and then we'll get into some Q and A. So the context I want to begin with is the Ethereum Two beacon chain. So this is the proof of Stake network that we've built today, we have almost a quarter of a million stakes, which is 8 million Ether worth today. And this is staggering when I calculated earlier, $30 billion worth being managed by our e two clients. And so these stakes, each one of these stakes is managed by a piece of client software from one of five teams my own teku or Lions, Lodestar or Lighthouse or Nimbus or Prism. And according to the best statistics that I've seen, this stake is quite unevenly distributed between these five clients.
03:32:59.758 - 03:34:12.214, Speaker A: It looks something like Prism having between 60 and 64%, almost two thirds of the stake. Staked on the Prism client lighthouse around 22%, teku between 14 and 17 and a half percent and Nimbus and Lodestar each below 1%. And these numbers come from a new analysis by Michael Sproul from the Lighthouse team, which uses a really ingenious technique to kind of fingerprint clients according to the blocks they make. So to kind of get to the meat of the client diversity thing. So let me ask you first, Karl, there's been a lot of hand wringing lately about this imbalance, this uneven split between clients on the network, in particular this dominance of Prism. Why is this a problem? Why are we concerned about this? So within any consensus mechanism, right, you have a set of people trying to agree on something. And by going down this road, which we went for ETH two, we get one specification.
03:34:12.214 - 03:35:20.930, Speaker A: And from this we built out many clients. And these many clients allowed us, at least in theory, to have a more robust network. By having a failure in one client, hopefully not affect the network as a whole because one client would hopefully only have a small portion of the network and we could contain that failure and hopefully fix that mistake. In theory, this is true and is in practice as well. But what we've had now is that Prism has, according to these statistics, become a really dominant client. And this means that more and more nodes become convinced that what Prism says is the truth, becomes the truth. And so in a world where we have more than one third of the nodes in the system so even just with more than 33% Prism nodes or any client, if they have a bug or start disagreeing with the rest of the network, then we're going to stop finalizing blocks on ETH Two.
03:35:20.930 - 03:36:27.240, Speaker A: The chain will still make progress. But there will be this nice finality gadget which gives you economic security, economic guarantees of how transactions have gone and that they will forever be a part of the ethereum chain that will no longer be guaranteed until a future date when we can get this one third back online. And following the canonical chain. So even more than 33% is not ideal. And so with the between four and five main net clients that we have at the moment, we should ideally have somewhere around. We should ideally have about 25% in each of these clients which means it'd be below this threshold and life would be all dandy. This is further accentuated with sort of a second threshold we have which is what we call a supermajority which is where you have more than two thirds the 66% which according to the statistics Ben was digging into a bit earlier where Prism is hovering just below.
03:36:27.240 - 03:37:59.380, Speaker A: And what happens in this scenario if there is a bug in Prism or Prism does for whatever reason start forking off or producing bad blocks the Prism nodes themselves will think that it's the rest of the network which looks like one third from the Prism nodes perspective that's making the mistake. And so the Prism nodes will happily go on and build a completely valid chain from their perspective and this will progress on. And the result of this is that these Prism nodes, they have their economic finality sort of guaranteeing the wrong thing which is not a part of the canonical chain which is really scary. Instead of this failure mode where we have sort of one sort of degraded quality of the chain but everything still progresses, we now have a problem where we need to go in at a sort of hard level and correct these Prism nodes. So that will require database corrections for the Prism nodes. We'll have some serious issues to avoid slashing conditions because the Prism nodes will make votes on top of each other which will have certain opinions about the chain but that'll be incompatible with what the rest of the chain actually did which would be the sort of correct chain. And so this is the sort of kind of scary scenario where everything's fall off in one direction and ideally this would never happen and all those good things but in practice we never know.
03:37:59.380 - 03:39:26.238, Speaker A: I think we're at this tipping point where anymore and if there is a fault, really hard to correct, not impossible to do. So we've seen chains do this in the past but a correction to do that would look terrible and would give all your favorite maxis, non ethereum maxis that you disagree with give them a lot of ammunition for having to sort of go in and manually hard fork away from any quote unquote problems. So this is really what we're trying to avoid by preventing any node from getting to this two thirds threshold, right? Yeah. So the point is that once a client has finalized its own chain so in this instance Prism had made its own chain recovering that and bringing all the clients back together again isn't a matter of a kind of fix the bug and move on. There's this slashing thing going on whereby they fundamentally disagree and for either side to join the other chain means that a bunch of validators are going to get slashed which is going to be horrifically expensive. So this is a kind of new feature under proof of stake, which doesn't apply in proof of work, right? Proof of work, the chain splits, you just kind of fix a bug, network comes back together, we're back on the longest chain and everything's cool under proof of stake. It's really complicated to fix.
03:39:26.238 - 03:40:13.150, Speaker A: Yeah, that's sort of a feature of this finality that we have. Right? So it's a bug and a feature because we have the system where we can agree that this will forever be a part of the chain, this finality mechanism, if something goes wrong and we have something that we think is a part of the chain that's not or there's disagreement about what is a part of the chain. And some people bake in incorrect ideas. That's really hard to get out of the system without these sort of financial guarantees we have triggering and slashing a lot of stake. Cool. And just to be clear for everybody, we're not dunking on Prism here where any client that has this supermajority would be a problem in this scenario. Just so happens that Prism is the most used client.
03:40:13.150 - 03:41:07.946, Speaker A: Evan, you are on record as saying that the long awaited merge to proof of stake could be delayed unless we kind of sort out this client diversity issue, unless you have more evenness in the clients. Can you unpack that for us? Is that a genuine threat or are you just whipping up some hysteria you want to mute a little bit early? So I missed the last part of your question. But look, we can't turn off proof of work until we can do it safely. And to do it safely, we need to have a client at a reasonable distribution. Know, I think Carl said in a lot of words something that I'm going to TLDR for people who are staking with Prism. If you are staking with Prism right now, your ETH is wildly at risk. That has nothing to do with the quality of Prism's client or any other client.
03:41:07.946 - 03:41:40.730, Speaker A: It has to do with the fact that the spec incentivizes decentralization. And right now you are not contributing to decentralization. It's the opposite. So let me say that as clearly as possible because I actually get a lot of friends that when I tweet, things slide into my DMs unhappy with me, telling me that I'm the one that doesn't understand the spec. I say like, no, you're the one that doesn't understand. You chose to stake with Prism. I understand you did a lot of Prism testnets and you are comfortable with it.
03:41:40.730 - 03:42:31.770, Speaker A: But unfortunately, the spec is very clear that decentralization matters and you are not contributing to decentralization. And so your ETH is at know, we've sort of talked about like Carl talked about about one third and two thirds. And those are obviously the important thresholds. But there's some thresholds that make a little bit that are important as well, which is to say that if we lose. Finality and Prism has 49%, you're going to get slashed or you're going to lose from the inactivity leak, which grows exponentially. You are going to lose a lot less if Prism is under half of the Staking clients, whereas if Prism is 65%, you're going to lose. I mean, depending on the circumstances, a lot.
03:42:31.770 - 03:43:05.060, Speaker A: Maybe half, maybe all. People get upset when I say this, but I don't know. I'm just stating obvious facts. So to do it safely, to turn off proof of work safely, which is a longtime goal of ethereum, we need better client diversity. Anyone want to comment on that? Or we can leave it for pick up a bit later. Go on, fizz. You're right about a lot.
03:43:05.060 - 03:43:37.418, Speaker A: If we lose finality, Prism clients could be slashed. Absolutely true. But we need to acknowledge that that is currently a low risk event. And I do think it's very important for people who are on Prism to consider using minority clients, especially Nimbus right now. But if we use scare tactics, if we make our user base afraid of the chain, then they're going to be afraid to interact with the chain. Rather, I think, education and promoting the ideas. That why we need client diversity.
03:43:37.418 - 03:44:22.270, Speaker A: Using the right tools for the job, getting people to say, I may need to change validator clients a few times and I'm okay with that, is much better than the scare tactic of saying get away from Prism, where you're going to get slashed. Because what we have then is a reflexive action where Prism is vilified, where people start trashing Prism and saying terrible things about it to get other users away from it. And what's likely to happen is others will go to lighthouse, and then we will have lighthouse with the supermajority. The only way to get away from it then is to trash lighthouse. So rather than this fear mongering and no, that's not fear, Evan. You're not fear mongering. I think you're stating a very possible scenario.
03:44:22.270 - 03:45:19.230, Speaker A: I really do believe, though, that education is the best way to get people to make these informed decisions. And rather than reflexively doing everything we can as quickly as possible to get people off of Prism, we develop these multi client tools. We develop quick switch tools so that home users aren't intimidated, they're not afraid of losing their stake, but instead they can click two buttons, let it happen, and they feel empowered. They're supporting the network, and they're not operating out of fear. I think that our big difference would probably be that I believe education is the way to reach our goal. And you might be more willing to hit people with what you would call the hard reality that they're going to be slashed. And I recognize that potential, but I think the likelihood is low.
03:45:19.230 - 03:46:13.530, Speaker A: So you say the fear of them switching clients is that they would lose. I think that's something that we can talk about should people be afraid of that if you take your client offline and you have the Slashing protection database for a day and then you come back up with another client. I haven't done it because I run minority clients, but I'm pretty sure that that is like a pretty much 100% no risk scenario. We can talk about that later. However, if there's that fear, okay, that's a fear. It's amorphous fear. However, there is a very concrete fear which Prism stickers do not seem to have currently, which they should have, which is that if Prism has a bug, then the network will lose finality and we're in a bad spot and the inactivity leak will start melting away their stake.
03:46:13.530 - 03:46:50.086, Speaker A: And that is something that they probably should be afraid of. They should at least understand it and be cognizant of the fact that that is a risk that they are taking. We have this really neat thing in East Staker where we have a lot of first time validators first time stakers people who it's their first time engaging with a network in any real way. And so they found guides, they found the Coin Cashew Guide or Samarisot's Guide and they installed Prism. And I'm proud of them. They did a great job. They are participating with the network.
03:46:50.086 - 03:47:52.294, Speaker A: I think it's just so important that we continue to meet them where they are rather than stand on our high horse and make these bold demands of what they should do when they are our user base, they are our you. I want to get to Dapline, but since you got the Mic fizz and this is relevant, we're focused in the recent answers on the current solo stakers on the network. Are they the key to turning around client diversity? Who is responsible for making this happen? What's the route from where we are to where we need to get to? That's a great question. In my mind, there are a couple of different ways to look at this. I think that we do need to look at institutional stakers and after some conversations with leaders from the EF, I feel confident that outreach is being done. But what I can focus on is my scope. And my scope is the home users.
03:47:52.294 - 03:49:07.358, Speaker A: And while I do encourage them to switch clients, I really feel like there's a development gap or a software gap there where they I don't know if deserve is the right word, but what the community should offer them. Are these graphical tools, these easy switch tools, where they don't have to put their stake out on a limb to hope that they're switching right to support the network. Because our users generally have two concerns. They have a large investment and they want to support the chain in the community. I value both of those things and I don't put either one of them ahead of the other. And so what we need to do to reach them and colfax through Steakhouse is working on these tools and I know there are other efforts. Working on these is to take the existing implementations and put wrappers around them or interfaces with them so that users can go to a web interface, they can see their stats and hopefully in a few months they'll be able to select a drop down that says switch from Prism to Teku.
03:49:07.358 - 03:49:40.290, Speaker A: And yes, I did it, I saw you there. And so when we have that functionality, I think the users, they'll feel supported. They're not going to lose their stake and supporting the network will be within reach. So what we need from the wider community is more support on this effort. We need money, we need developers, we need thinkers to kind of put as much effort into this easy switching as we've put into some other very important things. Cool. Yeah.
03:49:40.290 - 03:50:14.458, Speaker A: There are other things to consider. The majority of stakers are not on the network yet. I mean, I think probably we're about a quarter of the way there, maybe to the total stake. So if everyone in future adopts a minority client, that could correct things. And the majority of stake on the network is actually managed by Staking Services, institutionals stakers. And again, I think they will have the most influence. I love the army of solo stakers.
03:50:14.458 - 03:50:40.966, Speaker A: I am one for the record, I run a minority client. But you can guess. But maybe the solo stakers, it's kind of unfair to pressure them too much because actually they're not going to move the needle a huge amount. And it's really others who need to take responsibility. The professionals. Right? Yeah. I want to be really careful about that.
03:50:40.966 - 03:51:21.006, Speaker A: That disempowers them. They are an empowered group. And so I think that we're about 40% of unidentified validators and I know that there are some whales in there, but a lot of that are homestakers and so a lot of the responsibility is institutions. But let's not disempower those homestakers and say that nothing you do matters, because it does matter. One person switching is going to move that needle one hair and that matters. One person from prison to Nimbus, it does matter. At least I think we need to believe that and we need to act on that because that's the health of the network.
03:51:21.006 - 03:51:49.100, Speaker A: I call myself the Beacon Chain Health Consultant, if you don't know. Yeah. So I think it exists at multiple levels. So absolutely the easiest way to sway it is to go to your favorite big institution. If they're running a majority client, we speak to them and try get them to diversify a bit. That moves the middle bunch. But everyone has a role to play in this and contributes to the overall distribution, which is what we care about.
03:51:49.100 - 03:52:38.502, Speaker A: We also don't want a scenario where the big institutions run one set of clients and solo or private validators run another set because then if we have faults now we're starting to get splits in our community between individuals and institutions, which is also not a great thing to have. And I also think your role as a staker, part of it is to be worried about these kinds of things. To observe that you have reasonable uptime and that you are picking a client that's not completely dominating the network. These are important roles and it is literally what you're paid to do. Right? This is the reason you earn rewards back, is to do this safely and securely to improve the decentralization. All these things are important. And part of all of this is to choose reasonable clients.
03:52:38.502 - 03:52:59.220, Speaker A: And so you don't have to do it all the time. Don't panic about it, don't change things if you're not comfortable, but at least spend some time thinking about it. And if you do feel like you have the capacity to change away from a majority client, I really think you should consider doing so. Great answer. Yeah. A couple of points I haven't thought of. Love it.
03:52:59.220 - 03:53:32.238, Speaker A: Lion, you've been very patient. You're a client dev. What do we client devs need to do to promote client diversity? Yeah, it's a good point. Prism has done a fantastic job and that's why they are killing it. It's obvious all the clients should see what they are doing, why they are killing it, and why people love them. They clearly said graphical interface and Windows support. That's it.
03:53:32.238 - 03:54:25.166, Speaker A: If everyone does that, then it would be much easier and as everyone has said, easy. Switching, standardization, that's the key. Another point is that people like Def or however has access to this tool should see what's the funnel of going into staking. Why do people choose prism? There has been people saying, oh, because it looked cool. Okay, but where were you looking at? Is there any resource that can actually provide this information that hey, there are more clients, just go pick those ones because reasons so, yeah, I think those are the key things that we should work on. Yeah, I think one of the issues up to now is we haven't really had good data on client diversity. We've had sort of some guesses, some bad data.
03:54:25.166 - 03:54:49.940, Speaker A: It's very hard to get good stats. These stats that Michael has produced are a game changer, I think. Yeah, but we will probably never ever have actual data. That's a worrying thing. Like in reality, Prism could be a minority client and we just don't know. Well, we have the great data that Michael Sprout data. Go ahead.
03:54:49.940 - 03:55:09.226, Speaker A: So, a few things. One is this is partly by design, right? Part of having a robust, secure, anonymous, well, pseudo anonymous network is that it is hard to extract this data. Right. It's not here's the sign up sheet. Put your name and address and we'll find out. We'll find out how to do all that. That's not how any of this works.
03:55:09.226 - 03:55:53.900, Speaker A: And it's part of what makes it so hard for us to have this data. And as much as we want it to help explain things, we also don't really want to have to bake this in because it exposes individuals. We work very hard to avoid that as well. And it's not that we're not looking, you can look very hard. This tool that everyone keeps talking about, Michael Sproul's thing, is really some very ingenious stuff. To try extract it, you probably can't do too much better, which I think is a really cool thing because it shows that we have actually built a robust network. So it's like trade offs that exist here.
03:55:53.900 - 03:56:36.070, Speaker A: We have other data sources, we have node trackers, there are a few that have been built out there's the Eat Staker survey, which Superfizz has been very involved in and there's some interesting data. Watch out for some interesting alpha that's going to come out of that soonish. There is data, it's just not so obvious. Sometimes we only find out when the things go wrong, right? I mean, we knew back in February when what Prism share of the network was when all their clients simultaneously stopped producing blocks. So it was like 70% at that time. So we're moving in the right direction. Evan, you unmuted.
03:56:36.070 - 03:57:27.290, Speaker A: Yes, I unmuted to say exactly that we actually did know how much the Prism has on the network as of last time there was an issue. We have seen some evidence of migration, it has just been slow evidence, slow migration. And one of the reasons I have delayed pushing client diversity harder is because we can't really see the needle. When we can see a very clear representation of these proposals and know exactly where we're at, then we can measure progress and we can know what initiatives are successful and what aren't. Can I talk for a minute about Prism and how they became successful? Yes, sir. So Prism is successful. I think this is opinion, but it's also based in experience.
03:57:27.290 - 03:58:23.082, Speaker A: In fact, Prism is the only client that has a native Windows installer and a large part of the user base is Windows centric. They're not ready for Linux, they don't want to secure shell into a server and so that's a big boom. Another thing is that they have provided 24/7 support in their discord since the topaz testnet. And so they were doing these public testnets. We were giving PO apps out for them, we were holding launch calls and I feel strongly they were doing this work to promote the beacon chain. But what ended up happening was rather than simply promoting the beacon chain, it created this Prism allegiance, which it is what it is, but I don't think that was intentional on their part. They were trying to promote growth of the community, those two things.
03:58:23.082 - 03:59:04.450, Speaker A: Well, they did. And it's not that anyone else didn't do their job, it's that they hit on two really successful ideas and that's also a great we onboarded a lot of home stakers by helping them feel comfortable through all those testnets. And we wouldn't have we can complain about Prism dominance, but we also have this really strong base of home stakers that might not exist if it weren't for Prism's engagement. Yeah, they were first. They were first by a long way and I think that really established the name recognition and they did a terrific job. I mean, really awesome. What has surprised me is how the institutional stakers have just followed exactly the same patterns.
03:59:04.450 - 03:59:24.430, Speaker A: Yeah, I'm wondering Ben, you guys didn't do your job well. What happened? Yeah, the background to that. Okay, first thing, just to come back on Fizz. Teku runs just fine on Windows. You have to install Java, but it's not too much of a lift. Yeah, Teku, the client aimed at institutional stakers. Guys, come on.
03:59:24.430 - 04:00:08.650, Speaker A: Why are you not using it? A few large institutions adopting Teku would really balance things out more. I mean, the real interesting questions are around Nimbus lodestar where the plans are. So this brings us lion. When I asked you about what client devs can do, you framed the response in terms of effectively, I'm going to paraphrase you here in a way you won't like, but make all the clients the same interfaces, same experience for users, just drop in replacements for each other. We've taken a different approach with Teku. We've said no, we are not going to address certain parts of the market. We are the client of choice for institutional stakers.
04:00:08.650 - 04:01:01.774, Speaker A: To an extent. Nimbus has targeted a group, the low power constrained device market lodestar itself. You're looking at Light clients in browser, this kind of thing. Devil's advocate here, but maybe a different route to diversity is really to double down on specific use cases for each client rather than everybody try to be the same. Any thoughts? It hasn't working out that well, right? Everyone specializing Seku, Nimbus and as, we are at the bottom of the list and at the end it's a very specific use case. So while the specialization it makes sense if you are just going to go out for stakers. I don't think it makes that much sense in our case.
04:01:01.774 - 04:01:35.000, Speaker A: Our libraries are widely used on browsers and other types of applications and we try to make our node kind of the backbone of flight clients as a hopefully future replacement of infura. But that's kind of a parallel effort. People just staking right now. And the same for Nimbos. I mean, you cannot just put a node on the phone yet and you will still just run it on a machine as you would for anyone else. And you can do both. We can still follow standards and be special.
04:01:35.000 - 04:02:39.978, Speaker A: If you want to migrate somehow you still need the standard. I think some of those definitely comes down to just being early, right? The need for Light clients is much less until we really have the economic value attached to the proof of stake chain, right? Post Merge Light client is going to be a lot more interesting. Having stuff that compiles well down to mobile devices is going to be fantastic. And there are multiple ways to improve security and diversity of a chain, right? You can be a validator, which is what we've been focusing on today, but you can also just run a node that helps everyone, right? And you now have your own source of truth. So this is another way we can help improve the network. And then once that starts happening, we may see people starting to care a little bit more about having a super lightweight client they can throw on in the background on one of their other machines or something like that. So I think some of these specialization use cases, we just sort of haven't really reached that point yet, which I'm excited to see.
04:02:39.978 - 04:03:12.658, Speaker A: And then the other thing, I think that ties in a bit to Teku and what we're talking about earlier, and that's some of the discussions that I've been involved in with these institutions have been rather scary considering how large they are. And that's just that they didn't really do any research. They just didn't look, hey, we see everyone's. Like, we heard the word prism a lot. Must be good. Cool, let's go. It's honestly been that bad and sort of you'd expect, based on the haircut they take off staking rewards, that they would care about these things and that they would care about time diversity.
04:03:12.658 - 04:03:53.540, Speaker A: But in the cases of some of these institutions, they're just simply not true. They didn't put in the time to do the research and they're not really worried about uptime. It's just like an extra service they happen to provide and pulls in money. For them, the approach was sort of money first and improving a network second. And overall, they didn't even consider the incentives of the network they're participating in, which is ultimately bad for them as well, because as Evan was saying earlier, you don't want to be running a majority client in these scenarios. It's strictly worse for you. So I think they need to consider some of these things a bit more.
04:03:53.540 - 04:04:13.706, Speaker A: There's a name for that. It's called negligence. Honestly, I agree. Entirely negligent. Very seriously. Let me put a counter to you about that, which is very relevant, which is actually you could call it completely rational behavior. And the thinking goes like this, and I suspect there's a lot of thinking out there.
04:04:13.706 - 04:05:05.206, Speaker A: We will adopt the majority client because it's too big to fail. So if prison fails, 60, 70% of the network gets into a mess, of course they're going to get bailed out. I mean, obviously they're going to get bailed out. We're not going to let the beacon chain go down over this. So they'll be bailed out if they were running like a 5% client or a 10% client, then they're taking a risk because nobody's going to bail them out if there's a horrible bug, right? Completely rational. What's wrong with that reasoning? How are we going to push back against that? The network doesn't have to go down. If you use common sense and exercise that diversity, then you ameliorate the risk of that network going down and slashing and needing to be compensated because it doesn't exist.
04:05:05.206 - 04:05:38.326, Speaker A: So in game theory, it makes better sense for them to choose a minority client to prevent an outage that they would need to be compensated for or want to be compensated for. But kind of Carl said something that really interests me. I don't think these institutional stakers care. They are not focused on east. They don't care about our ecosystem, they don't care about our growth, development transactions, any of that. They're there to make money. And the least amount of money that they can put into this to make a return is what they're going to do.
04:05:38.326 - 04:06:33.938, Speaker A: It's one of the reasons I really encourage users not to stake with those institutions. They don't care about what we are doing. They're there to make money. And so the best thing that we can do is either solo stake or stake with a trustless, open, decentralized solution, not give your money to the big exchanges. And again, this is gross negligence. I think this cannot be repeated enough because staking pools especially, say, public companies in the United States or anybody that has a nexus to the United States, given the United States court system, loves to try to enforce its will on the world. If a staking service loses their clients ETH and gets a massive inactivity leak or gets slashed, I don't think that whatever legal language they have in their contract is going to protect them from the fact that they were willfully grossly negligent.
04:06:33.938 - 04:07:05.186, Speaker A: And so eventually they're hopefully going to figure this out. The question is whether Ethereum loses finality and pulls a mini solana, not a real solana, because they went completely down. I think there are a few interesting things to explore here. One is that there's a failure spectrum as well. We've been talking a lot about the worst case scenario where there's a catastrophic bug and everyone gets slashed. That is very unlikely. These clients are coded incredibly well.
04:07:05.186 - 04:07:31.370, Speaker A: They've been battle tested through multiple test nets. We've had excellent bug bounties which have found things but haven't, not lately. We've had audits for everyone. It's an open source ecosystem. So many eyes on all of these clients. So that really helps out for all of this. But there are other more subtle failures which can cause temporary failures of liveness.
04:07:31.370 - 04:09:05.682, Speaker A: The majority client could stop producing attestations, which is not like a hard fork, but it does mean we're now going to start having to leak the balances of those clients. And I think if there's a more subtle failure then we may not bail everyone out because that's not so easy to do at a layer. And I think Ethereum, as much as we can have the debate ethereum in the past we have made decisions to handle the whole Dow situation, right? And we've seen the blowback from all of that in spite of what, okay, we can get into that now. But relative to that, I think we will bias a lot towards not going in that direction, even if it causes loss of value for a lot of people. And I think another interesting thing is a bit to what I was saying is you can end up in the scenario where there's a split between institutions and private individuals. And if we start seeing that where sort of private individuals are running minority clients and have really worked to diversify and institutions are focusing on a majority client because easy and negligent and whatever, it's going to be very hard to convince the entire ecosystem to want to bail out the institutions because they didn't care about and don't care about the ethereum ecosystem in general. And so why should the community care about bailing out their E? Please, let's talk about debate at the scenario.
04:09:05.682 - 04:09:58.606, Speaker A: It's fascinating. I don't believe we should bail out anyone, to be honest, and see why it's actually necessary. Seriously, if there is a bug and the network splits, the minority network would either leak everyone or expect everyone to get slashed. But the network could continue. It will still include execution data, but it will not be finalized. So if people accept the non finality and the risk of reorgs, which is what we actually have today, the network could just move on. Who decides which is the right network? I mean, you got, say, 70% of stake on a Prism only network that was forked off due to a consensus bug and you got the rest of the stake on the other clients, which is not yet finalizing, but eventually will due to the inactive delete, which is the right network.
04:09:58.606 - 04:10:22.266, Speaker A: You've got two completely separate networks. Now we have a spec. It's not the first time that happened in Ethereum, right? Evan's a spec maximalist. Yeah, but we haven't had finality in Ethereum before. This is new, right? So two chains that are fundamentally incompatible. I agree with Evan on this, right. We have a definition of what it means to be compliant with the Ethereum chain.
04:10:22.266 - 04:11:21.362, Speaker A: So I think the clients that have followed the specifications have by definition, they have the canonical chain. Whether or not it's finalized via something that's outside of the definition of what literally is Ethereum, that's irrelevant. But I do think the failure, terrifying failure mode where there's a fork off and the result is everyone's going to get slashed and it's a supermajority, right, greater than two thirds. I think it's unrealistic to expect that not to be bailed out. As much as I hate to admit that it is just so much value that at least the discussion would be very intense. But I think we'd ultimately settle on merging that back in, possibly with financial penalties and we can get into what exactly that looks like. But I think it's unrealistic to expect that just to burn all that money and pretend we're all good without it.
04:11:21.362 - 04:12:08.098, Speaker A: To be fair, your hypothetical is not the case of what we are experiencing today where we do not have a supermajority. We might be somewhat close to having a supermajority, but we don't have one. It very quickly becomes a supermajority evan because of the way the chains constructed. So let's say Prism's got 63%. There's a consensus bug they end up on a chain where their validators are proposing blocks and attestations, but nobody else is. Everybody else will very quickly get their balance leaked away and it will only be a matter of days before Prism's got 66% and finalizes. The closer they are to that 66% threshold, the less time we got to fix it.
04:12:08.098 - 04:12:42.560, Speaker A: And it takes at least a day, maybe two or more to get a fix out. So there's a real gun against the head in that scenario. The further from a supermajority 66% below that, the better. Takes me to the thing earlier. That's why we can't turn off proof of work safely until we are lower than where we are now. And so it's this theoretical two thirds in a month we could have Prism below 50%. Prism could easily be below 50% in a month.
04:12:42.560 - 04:13:21.286, Speaker A: It's not an act of Congress, it really just takes a concerted push by everyone in the community to say we have to do this now, we're not messing around anymore, everyone work together. And I don't mean to be kubaya, but I'm just saying it's not that difficult to make it happen. If we just all push in the same direction for a moment in a month this could be an honest I've been trying for over a year. You have been trying and I have been trying, buddy, we're together. But I'm saying not that easy. Well, because it's a few voices. It's a few voices shouting in the woods.
04:13:21.286 - 04:14:08.346, Speaker A: It's not everyone working together and we have that potential as a community to move together. I think that's one thing. If we don't bail out and we burn half of the supply, that would be like the most ultrasound money thing we could do. Like the ultimate meme IEP. One five nine lovers would be hey, there's a great comment about incentives and so one of the reasons I was so excited about Michael Sprouse data is that we can identify by proposal what client someone is running. And that gives us the opportunity to take a snapshot and say today we know what you're running and if you change from Prism to Nimbus then we can offer you a POAP and those poaps can be incentivized. Personally, I feel.
04:14:08.346 - 04:14:46.520, Speaker A: Like it's still a great idea. Some of the thought leaders didn't really love it, but it's worth considering or talking about incentives for people who change from not necessarily money directly, but incentives for people who change from the majority to a minority client. Yeah. Making it proven, not getting slashed, not getting slashed. It's a real thing and nobody cares. And frankly, nobody believes me when I say it again. I have to tell you that I talked to the Staking pools over the last 15 to 18 months.
04:14:46.520 - 04:15:23.634, Speaker A: They all think that we're a data center chain just like every other DPOs POS. Basically the same chain. I think that is like as much as I was shitting on institutions earlier, I do think we're making some of the right moves in that direction. Right. We've opened up some discussions with them and they've acknowledged that the approach they took was wrong and that they will try dig into this and diversify a bit there. I've been really excited to see if you go on Reddit on Eatsaken, be like, hey, I'm having this problem with Prism. Help set me up.
04:15:23.634 - 04:16:05.040, Speaker A: You will get sort of ratioed out by people shouting at you to pick any other client. Please, just not prism. They better be friendly. Sorry. That's good. But in all seriousness, I think we're reaching a point where it becomes very possible to see this change happening rather quickly away from these clients. And I think there's a lot of awareness, certainly in the Ethereum community due to the thought leaders shouting about this for a long time and complaining about this for a long time and working with these institutions to try and help them diversify and see the errors in their ways, even if they don't majorly care for our own good.
04:16:05.040 - 04:16:49.180, Speaker A: Right. I'm going to change tax slightly on an optimistic note. Have you got something optimistic, Evan? I wanted to say that my understanding from staking pools is that they have sort of seen the light and that they now spin up non Prism clients, but they have not switched all of their validators from before they saw the light. And I think most of them probably I think there's probably some fear. I think a lot of it is also they just don't understand that there's no real loss for taking their entire validators down for a day. And they're worried about justifying their services to people and losing their penalties. And I think they really just don't understand the risks that they're taking.
04:16:49.180 - 04:17:33.450, Speaker A: Or they don't care. No, like I said, I think that if they realize that they could get sued for not just possibly the loss of the entire whatever happens in a bad scenario, but maybe even something punitive like Carl says, to make money, not to lose. I think Carl hit the nail on the head. They believe they'll get bailed out and they might be right. I don't agree with that, even though I support Home Stakers. I don't promote a bailout of anyone who gets slashed. When you signed up as a validator, you accepted the terms and you know the terms.
04:17:33.450 - 04:17:54.240, Speaker A: If you make poor decisions, if you get slashed, and I hope everyone from East Staker hears this, you accepted the risks. You need to make better choices. If you get slashed, it's on you. This is important about ethereum. This is why it's secured. We designed the system, particularly in this way. It's necessary and makes it better for everyone.
04:17:54.240 - 04:18:20.060, Speaker A: I mean, personally, I have to say that having listened to this panel, I all of a sudden am worried about a bailout, whereas I never was before. So I think that the message isn't even clear from this panel. I am 100% against the bailout. I will probably sell all my ETH and quit if we bail stakers out who did the wrong thing and we're pushing for centralization same entire time. I mean, it's absolutely wrong. You have a responsibility. It's what you're getting paid for.
04:18:20.060 - 04:18:47.918, Speaker A: If you're going to get paid, get the rewards, you have to realize the risks you're taking. I'm going to move I agree. I'm going to move us on. Let's say that everyone listening does the right thing and that we get all this sorted out and in six months time we're at like 25 cent on each client. It's all rosy and then we do the merge. I looked at Ether nodes today. Geth is at like 63% of the network.
04:18:47.918 - 04:20:03.180, Speaker A: Sounds familiar, right? Is that going to be a problem post merge? Is there an issue on the execution engine as it will be the ETH one client side? Is that an issue for client diversity as well? And do we need to get that more even? What do you think? Yeah, I think what's really annoying is that at least in consensus, there has been so much effort and money and talent spent at creating four clients that are almost equal in capabilities and still we don't achieve diversity in Ethereum. One you can say, okay, there is only one client that has all the longevity and features and there is another one that's going away, another that's coming in, but there is no equal to death in a way. And still in consensus, we don't have the diversity. So, yeah, just wondering how the hell we are going to achieve that in execution. Yeah. So Carl, I'm interested. Is it actually a problem having not the same level of diversity amongst the execution engine side of things or is it just as critical as on the beacon chain side of things? Ultimately, we can run into a similar diverging situation.
04:20:03.180 - 04:21:12.030, Speaker A: If we have a supermajority and it goes off in one direction, we can run into all these terrifying things we're talking about earlier. But I think we got a few things county against it. One is that this code has been running for very long and these clients really have been around the block and they've been tested by crazy amounts of value locked up on the Ethereum system. So I think that really helps us handle that. The other thing is that you start having these pairings between the execution client and the consensus client, and from all the pairwise combinations, you end up with way more possibilities of you can run this execution client and this consensus client. And the results of this means that overall, each individual pair sort of counts as a different way to fail in this regard. And so this starts helping us build up a bit more resilience against these kind of mistakes.
04:21:12.030 - 04:21:39.058, Speaker A: And so I'm a little bit less worried about it on that side, although more diversity is always better in this regard. And I think another interesting thing to just quickly point out for everyone listening here, ethereum. We are unbelievable in terms of diversity. Even with supermajorities, no other chain comes even freaking close. Go try find an alternative client for any of the top ten right. Bitcoin, you'll find a few. Any of the others.
04:21:39.058 - 04:22:00.574, Speaker A: There are no other viable clients. No one else has anything. This kind of brings me to my kind of final question. Carl perfect segue, which is this. And we haven't got time because there's a couple of audience questions we'd like to cover, but it's a big one. Was client diversity a mistake, as you say? I mean, no other chain. Bitcoin doesn't have it.
04:22:00.574 - 04:22:31.274, Speaker A: No other chain. No other chain I've come across sweats this at all. They're quite happy with their monoculture. Why in Ethereum are we bearing this burden, which is so complex? Because we care about having the most robust chain and the most decentralization. It is strictly better to be more diverse. We want to be the best chain on pretty much any metric that this community cares about. And this is one of the really important ways of achieving that.
04:22:31.274 - 04:23:04.730, Speaker A: And I think not having a diversity of implementations only serves to weaken you. I really don't see the downsides. No capture of governance by cordevs like, say, an orange meal. I was going to make a comment about another chain. Decided not to. Can I shoot one thing in here? It's been itching at me just a little bit, and that is the specialization thing. And I know some of you are fans of client specialization.
04:23:04.730 - 04:23:50.210, Speaker A: I really think that we should avoid client specialization in the long run because that means that conglomerates form to kind of tribalize clients. And while it works for a little while, I think in the long run that kind of tribalization specialization is probably not healthy for the network. Rather, we should all look at all of the clients and seek to balance rather than picking one that is made for us. Just a thought. Lyon, any closing thought before we move on to audience questions? Yeah. Lodestar is production ready? Lodestar, is production ready? Go try it now. Link in the description subscribe.
04:23:50.210 - 04:24:08.950, Speaker A: Nice one. On that note, you can run multiple clients, right? Don't run multiple validators at the same time, but you can run multiple beacon nodes. You don't only have to run one. You can have multiple easy backups. All those wonderful things. Don't run multiple validators. Good warning.
04:24:08.950 - 04:24:22.214, Speaker A: All right. Thank you, Kartik. Thank you, panelists. Let's move. Kartik, if you have some audience questions yeah, that would be great. Probably one of the best discussions we've had. This is getting people excited, I think, briefly.
04:24:22.214 - 04:25:03.660, Speaker A: I think they might still be there. The prison team is on the chat. Also commenting, this is a question from Danny Ryan. I know we've kind of talked about the problem and I feel like we'll get to sort of statements here. What distribution of the various projects do you think is actually realistic? What would satisfy each of you to say, this is sufficiently diverse and we can agree that this is not a supermajority? Can you ask preferred and launchable. Because that's two different questions. But I mean, Preferred is everyone at 20% and Launchable is under 50%.
04:25:03.660 - 04:25:56.026, Speaker A: And frankly, Prismatic guys are heroes. And I think as well as the Gaff team, they get it. They understand that client diversity matters. Imagine how you're going to feel if bugs are inevitable and any client look at Geth, which is a very hardened piece of client software, over five or six, seven years now. And I know the network launched, but it existed before the network launched and we still have had security updates that could have caused forks at least twice, I want to say three or four times in the last year. If I'm a Prismatic developer and I literally am living and breathing my client and I've done an amazing job, I have a lot of people using it. I don't want to see my people get staked because frankly, they might turn on me and I don't want that.
04:25:56.026 - 04:26:19.239, Speaker A: How would I feel then? It would be awful. I mean, those guys are heroes and they should be recognized as such. And I would hate to see something happen where people turn against them. Second it. I would go 30 30 2010 and ten. And your reasoning, it's good and it's realistic. It's not like 2020.
04:26:19.239 - 04:26:44.250, Speaker A: 2020. That's not realistic. I align with Evan. I believe for launch. Well, I align with him mostly. We are below 66% for Prism. I believe that we need to safely be below 50%, close to 50%, nearing 50% for Launch.
04:26:44.250 - 04:27:22.674, Speaker A: And below that, I'm not sure it matters so much what the other diversity is. But Prism, we should have the opportunity to celebrate them so much more than we do. But instead it is all reserved because we're trying to increase client diversity. And so it's mutated. We should be singing their praises, but instead we have to say, well, there is Prism, but you really should choose something else. So congrats to the Prism team. Congrats to all the clients for developing a valuable product that supports our network.
04:27:22.674 - 04:28:19.894, Speaker A: By the way, I have a Tweet storm about. We found two bugs in Go language in the past year in Ethereum, right? So even the fact that Prism and Geth and Aragon are all in Go is know it's a problem. I mean, stuff could like we could talk about crazy scenarios and you know, like, I think bitcoiners are going to be well, just everyone. When we turn off proof of work, they are going to be gunning to find every single little thing. Just like the Dow in 2016. I mean, the amount of people that just want to watch the world burn by finding a bug is huge and if they can find something by fuzzing the heck out of golang and they find something little and they figure out how to exploit like they will use and they're not wrong for doing that. Use a boomer language like Java can never be a bug in JVM.
04:28:19.894 - 04:29:05.990, Speaker A: Of course, everybody knows. I'll kind of blend a couple other questions in and it's okay if we go a couple of minutes over time because the next speakers graciously agreed to enjoy this discussion with all of us. What have we tried as incentives instead of other than just shouting? And should there be incentives? Maybe that's probably a better way of phrasing that the only person that shouts is me. I don't want to say it directly. There are incentives, right? Well, the incentives are the risk. You run more risk by running the supermajority client. And the problem with risk is that people are not sensitized to risk.
04:29:05.990 - 04:29:40.050, Speaker A: They're not considering the everything goes wrong scenario. So when people make lazy choices, they don't see this. The only other incentive that works, in my experience, is a POAP. So people will do anything for a PO app. So yeah, if we can find a way to make that work, we have the mechanics for that. What we really need is just community agreement that it's the direction we want to go in. And I really think when that happens, hopefully in the next few weeks, we'll start seeing a sea change of people.
04:29:40.050 - 04:30:20.640, Speaker A: Like Ben said, people will do anything for POAP. It's not a bad cheating. Yeah, well, we thought about the mechanics to prevent cheating. We have, we have proposal data and essentially what you would need to do is have a history of proposing on Prism and then a future of proposing using a minority client that's extremely I don't believe it's cheatable, but we'll have to see. Go ahead, Carl. Seems like you were going to say something. If not, I may have another question.
04:30:20.640 - 04:31:12.800, Speaker A: No digging to your next question. Got it. So I think, Carl, you actually talked about one of the reasons kind of multi operating system support kind of helps with diversity. And we kind of talked about having a Windows client is actually essential, but you also vouch for individuals instead of institutions, kind of having enough power to make this happen. So this question comes from Jeff and his question is, what do you think specifically? We need to maybe get more people excited about having all the other clients been supported on Dapnode so they can kind of run that on their own and maybe increase the pool of people who can easily run their own instances. Yeah, I think it's kind of sad that we haven't seen Dapnode supporting other people. There's promises to change that and I think we'll get there.
04:31:12.800 - 04:31:37.414, Speaker A: But we're not there right now. And unfortunately that means that a lot of people have defaulted towards that. Windows support is much less of an issue now. There are multiple clients that support Windows, but that was an issue in the past. So I think all these things sort of have changed. But I think people have been rather sticky in the client. Like once you set up, they don't want to touch it.
04:31:37.414 - 04:32:05.246, Speaker A: I've spoken to a bunch of people who found it a rather stressful experience and a complicated experience. I know it took me many hours and it's my full time job. I wrote a bunch of the specs, I know what's up. It took me many hours still to configure my personal setup. So I know the effort that goes into these things. But I also want to stress that you already understand, like if you've set up any client, you already understand a lot of the things that are going on. It's the same core ideas.
04:32:05.246 - 04:32:33.494, Speaker A: There are still beacon nodes and validator clients. Everyone uses this terminology. These setups work like this. You're still going to be looking at opening and closing ports, all those things that you did in the past. If you ever want to switch clients, you're not starting from scratch. It won't be as bad as what you had to do before and it's rather easy to set up. And I think that the other thing which I don't think we touched on yet, a little tangential and that's that all the clients are profitable.
04:32:33.494 - 04:33:06.658, Speaker A: You're not making any like there's no measurable difference really, in terms of which client you're picking for. Moving forward. All the clients seem to be getting prism is not going to get you higher rewards. Absolutely not. And particularly if you calculate the expected value for the Prism failure. Prism is probably the worst client to pick in terms of your overall value you can have as a staker. You reminded me in this question I'm not going to talk about rewards, I've tweeted about that enough.
04:33:06.658 - 04:33:39.084, Speaker A: You reminded me in this question it's not just about client diversity and my bad, we should have covered this. There's also stuff like if everyone runs on AWS, this is equally a problem. AWS goes down. We have exactly the same issues. Everyone runs on one same operating system that has some fatal bug, then that's going to be a problem. So we need to think about diversity in all things. Right, well, we'll make the final question, hopefully optimistic.
04:33:39.084 - 04:34:14.972, Speaker A: Twelve months from now, what is everybody's prediction on client diversity and what it will look like? We can start with Evan. I think we're going to do good. I think we're going to do good. I'm not optimistic about it, quite honestly. I think this is an emergency. It's the most important, pressing problem in Ethereum and I'm the only one that's been talking about it for 15 to 18 months. And I'm tired of talking about it because I feel like I'm out on my own, shouting into the void, and nobody really amplifies my message.
04:34:14.972 - 04:34:49.850, Speaker A: And because of that, even my friends that are hardcore Ethereum enthusiasts are in my DMs, telling me that I'm a fudter. It's very frustrating for me, personally. I feel like our message is very muddled. And so if you ask me honestly, I'm not very optimistic about it. I'm a lot more optimistic. As I say. I think we starting to see an inflection point where we've seen people in the community start to be louder about this, in contact with some of these institutions who are promising to make changes.
04:34:49.850 - 04:35:37.824, Speaker A: And I think it's sad that Evan feels he's on his own here. I don't think that's entirely true, but I'll happily give you this. You'd definitely be beating the drum on this for a very long time and strongly agree it is very important for the safety future of Ethereum and very much want this to happen and to have more diversity. But I also don't think Ethereum is not going to blow up. We have really robust clients. Even if it was 100% prism, we still have a very good system, so don't want to overfut it, but it is a very important issue to be concerned of, one of the biggest in the space. Evan, you are definitely not alone.
04:35:37.824 - 04:36:26.740, Speaker A: I have been shouting the same thing. You've been shouting from a different perspective, and I know that Carl is working in the same we come from different angles. I am an encourager and you are using a slightly different tactic, but we align. I think that in a year yeah, I like being a good cop. In a year, I think that we're going to have easy switching tools and I think people will identify less with a client and more as a staker. And with that goal achieved, people will have those interfaces looking at Stakehouse to develop something like this, where they can click a button and say, yesterday I was prism and today I am Lighthouse. And I think then people will identify as stakers and the ecosystem will be much more vibrant.
04:36:26.740 - 04:36:57.356, Speaker A: I think that's a perfect note to end this. I want to thank Carl, Mine Fizz, and then for being an amazing panelist. And Ben, thank you for facilitating this entire discussion. This was absolutely incredible. And if in the future there's ever a bailout conversation, we'll be sure to live stream it on ETHGlobal and make sure you're all on the other side of this. But thanks again, everybody, and really appreciate you coming on and being part of this discussion. Thanks, Karthik.
04:36:57.356 - 04:37:06.596, Speaker A: Thanks, everybody. Bye bye. For sure. Thank you. Bye bye. Thank you. All right, with that, we are ready for our next talk.
04:37:06.596 - 04:38:00.550, Speaker A: Next up is Marius, and Marius is going to be talking about the merge, but the perspective from the execution layer. So, without further ado, let's welcome Marius. Hello, everyone. What a nice discussion. I didn't really prepare that good, so I hope that I can deliver something after this. Um, from my perspective, I think it's very important to have this client diversity, especially on the execution layer. And we're always trying to promote it, always trying to build tools and at least get the other execution clients on the same amount of testing that we do in yeah, I'm hopeful about the future.
04:38:00.550 - 04:39:24.080, Speaker A: All right, let's start. My name is Marius. I joined the Ethereum Foundation one and a half years ago working on the Gas client, which is right now the biggest client on Ethereum. And so today I'm going to talk about the merge from the execution layer perspective. First of all, what's an execution layer client? I already said it, it's Gas or Nethermind biso aragorn and well, it used to be open Ethereum, not anymore. And yeah, so those are the clients that currently run the network and they have mining consensus module built in, which basically does the verification of the proof of work and during the merge and afterwards, we're going to take out this module and replace it with a consensus layer client. So the consensus layer client is going to follow the beacon chain and the execution layer client is going to follow the ETH one network.
04:39:24.080 - 04:40:45.188, Speaker A: Yeah, and so we have an API between those two. So the consensus layer client basically has to tell the execution layer client what to do. And some of the responsibilities of the execution layer client is to maintain the state of the network. This is all the accounts, all the balances for everyone, all the smart contract, smart contract code, all the states in the smart contract. So, I don't know, if you store your NFT, then the data that you need for your NFT is stored in this state and the state tri, which is basically used to prove that all the nodes have the same state. And we also need to maintain the historical blocks and we need to provide access for both of them to nodes that just joined the network. So if you join the network and you don't have any state, you will get the historical blocks from all the other nodes.
04:40:45.188 - 04:41:50.780, Speaker A: They send it to you, and then you can either execute them one by one, but this takes a long time. Or you just download the state and then only verify that the state corresponds to the newest block that you downloaded from your peers. And this is also going to be something that we will still maintain after the merge. So this sending and receiving of the state and the historical data is still the responsibility of the execution layer. We also store and distribute the transactions. So if you send a transaction, typically as a user, you use MetaMask. And MetaMask then talks to a node, either your own node or a node run by infura, and they will then send the transaction, distribute the transactions throughout the network.
04:41:50.780 - 04:43:07.484, Speaker A: It will create and execute the payloads. So basically, once the beacon chain says that we are the ones responsible to create a new block, the consensus layer asks us, hey, execution layer, we want a new block. So you take all the transactions that you currently have, you sort them and then you pick out the best 200 transactions, execute those, put it in a block, and then return this block to the consensus layer. The consensus layer will then take this block, send it throughout the network, first seal it so like, sign that this is the block that is valid, and send it throughout the network. Yeah. As I previously said, we have to provide an API for the consensus layer clients to do this interaction with us. And we also provide the JSON RPC API endpoints.
04:43:07.484 - 04:43:55.510, Speaker A: So those are basically things like ETH underscore Send Transaction or ETH Call, ETH, Estimate Gas, all these things that are used by wallets, MetaMask or applications to basically interact with ethereum in the larger sense. And this functionality will still be retained by the execution layer. So this will be provided by us. Yeah. So a bit about the design of the JSON RPC API. This is specifically the engine API. So in the top right, we have the consensus layer client, which basically tells the execution layer client what to do.
04:43:55.510 - 04:45:17.980, Speaker A: And this arrow is basically this API that I'm going to describe right now. We have the prepare payload method that starts the payload preparation sys. So basically give me a new block, take the transactions that you have in your node and execute them and return me a valid block and the Get payload. The reason that those are two different methods is because you want to give the execution layer a longer time to prepare payload. For example, if you want to do reshuffling of transactions looking for mev rewards, whatever, you have two calls, two different calls, and then you have the execute payload call. Whenever a consensus layer client gets a new block from the other nodes in the consensus layer network, that is like one of the things that's different between now and after the merge. Now the execution layer clients will distribute the blocks.
04:45:17.980 - 04:46:24.992, Speaker A: If a new block is mined, then this node will send the newly mined block throughout the network. This is not going to be the case anymore. Now it will be that the consensus layer client will distribute the block and the execution layer client will only distribute historical states, historical blocks. And so once the consensus layer client receives a block from the network, it will call execute payload with the payload within the beakj block and that returns valid if the payload was executed correctly. And then we have another method called Consensus Validated. This is a method that might not be. So this engine API is pretty new and it's still under development.
04:46:24.992 - 04:47:20.088, Speaker A: It might change a bit in the future. And one thing that might that we might delete is the Consensus Validated RPC call because that is not really used by the execution layer. Basically it just tells you that a block was valid. Regarding the beacon chain specification, the idea behind it was that once the consensus layer got a block it will call execute payload. And while the execution layer is executing the payload, the consensus layer will verify the signatures. And once the signature on it is verified it will call Consensus Validated. Might be something that we won't do in the future.
04:47:20.088 - 04:48:35.344, Speaker A: And the last method is fogjace updated, which basically just notifies the execution layer client of the current head and the last finalized head, last finalized block. So with the execute payload you just execute the payload but basically you don't move the chain to that hat. With Foxcher is updated, you will set the chain head and this means this is now the current head, the most recent block. And if we don't have this block and you say hey, this is the block that you need now, then we're going to start synchronizing from the other nodes in the network. Yeah. So a bit about the merge itself. So right now we are in this part left here we have the proof of work chain which is chugging along and we have the beacon chain which is also chugging along.
04:48:35.344 - 04:49:56.760, Speaker A: And the condition for the merge is the total difficulty, the total terminal difficulty. So every block has a difficulty which is derived from the amount of work that you have to do for this block. In proof of work. If you sum all of these difficulties up from the blocks, you arrive at the total difficulty. And the total terminal difficulty is basically a parameter in the consensus in the execution layer clients that says once this total difficulty, total terminal difficulty is exceeded, we will stop the proof of work chain and go into the proof of stake chain. After this is the merge point and after that the blocks are embedded into the beacon chain blocks. So the execution layer blocks are embedded into the beacon chain blocks.
04:49:56.760 - 04:51:13.040, Speaker A: Yeah, a bit about the switch. Our clients of course need to stay in sync with the proof of work network up until the point of. The merge and we also already need to provide all the payload calls. So execute payload, create payload, get payload because we don't know if we might be the one client that gets to propose the first beacon chain block. And on the first Foxjoice updated call we check if the total terminal difficulty is reached and if the head block hash is valid and if so we switch to proof of stake mode and this means we also disable block propagation. As I said before, we don't send out the new blocks anymore, only the historical blocks and we set the chain head to the new proof of stake block. Yeah, one thing that I wanted to talk about is the reverse header sync.
04:51:13.040 - 04:52:38.670, Speaker A: This is something that's new with the merge and basically it's about the way that we synchronize the network. So if you join the network you only have the genesis block. So it used to be that you will just ask your peers about all the blocks that they have and you will start from the genesis block and then synchronize to the next block. There are sibling blocks or can happen that there are sibling blocks that are on the same block height, different blocks on the same block height and you will always take the one with the higher total difficulty so you will always take the chain with the highest total difficulty. And so basically you start at a genesis, you go forward in time now with the proof of stake chain. Creating these sibling blocks requires solving the proof of work and this is something that's hard and in proof of stake. Creating this sibling blocks is pretty easy if you don't finalize them.
04:52:38.670 - 04:53:58.490, Speaker A: But yeah, the idea is we need someone to tell us what's the actual hat and this is done by the beacon chain. So basically the beacon chain synchronizes and then after the merge tells us hey, this is the new head here, find the way back to the genesis and we can look up this. We have this header and we know, okay, in the header is the parent hash. So we look up in the network which header has this parent hash and then we find this header and in this one we look up the parent hash and so on and so on until the genesis block. So basically we synchronize the network from the news block back to genesis and this is the reverse header sync. So a bit about the interrupt. This is a picture photoshopped by Depline from the previous panel by the way.
04:53:58.490 - 04:55:08.952, Speaker A: Yeah we started implementing an initial version of all of this. It's built on Guillaume's catalyst. Guillaume is going to give the talk after me and he worked a lot on all of this during the Rayonism hackathon and laid the foundation for basically what I'm talking about today. Peter also worked on the reverse header sync and we already managed to test all of this with four out of the five consensus layer clients. Yeah, one small project that I wanted to show regarding the execution layer is Mergepuss. It's a new project that I started on the last day of the Interop because I was so bored. And it basically creates random inputs to the Merge API and it can be used for differential fuzzing between different implementations.
04:55:08.952 - 04:55:58.060, Speaker A: So, again, we're always trying to build tools that can not only be used by Gas, but also can be used by other clients to make sure that they receive a comparable level of testing. To us, it does things like execute Payload and Foxchest updated and verify the current head. So, like in random operations. And you can find the code at my GitHub. Some next steps. We have to clean up all the changes we did during the interop. Of course, all of them are a bit hacky right now.
04:55:58.060 - 04:57:05.670, Speaker A: We have to refactor the downloader to allow for this reverse header sync. We have to work a bit on the minor and the block production and also refactor some of the existing JSON RPC APIs because they might not work with the way that POS is done after the merge. And then more testnets, testing, testing, testing. For us, it's really important. We don't want to start the merge procedure when we finish the code, but we need enough time to test it because Ethereum grew so big. It's a billion dollar network and we don't want to crash it. So we want to be as conservative as possible with this, even if it takes a bit longer.
04:57:05.670 - 04:57:50.704, Speaker A: And yeah, you can also join. Like, we have a long running testnet. There was one started in Greece at the interop. We deprecated this now and we started a new one, or Peritor started a new one. And yeah, that's basically some I collected some Q as from Twitter already. But Kartik, if you have other questions from the audience, we can also absolutely. I think I saw that tweet and the thread and there were so many awesome questions that came in, so I think you should definitely answer a lot of them.
04:57:50.704 - 04:58:53.350, Speaker A: One question I'll add to this list is a question from Danny Ryan, which is, what are you most concerned about from an el client perspective? As in what keeps you up at night? There easy stuff. It's not much keeps me up at night anymore. After like, one and a half years in the Gas team, I think I've seen a lot. We had issues in Gas, we had issues in Go, in the language itself, in the standard library. I'm pretty confident in our ability to adapt. If there's an issue, we can find it and fix it rather quickly. The last few consensus issues were found in a matter of like half an hour to an hour or something.
04:58:53.350 - 04:59:50.650, Speaker A: We have a cool, great suit of tools for testing the EVM stuff. The only thing that I would say what keeps me up at night is that we might finalize something that is objectively wrong and that we might have to break finalization. And I think that would be really bad. It would be bad for ethereum. It would be really bad. And this is the only thing that I really worry about. And I hope things like proxies to run a validator of multiple execution layer clients is something that could help there.
04:59:50.650 - 05:01:02.270, Speaker A: That makes a lot of sense. There's another question that came in just now from Trent. The question is, can you tell us more about the minority project Peter teased about earlier? Just give us a little context and you can jump right into your Q A. Yeah, I'm not sure if I should talk about it too much. Basically, I think the idea was born in Greece that you can run multiple execution, layer clients for one consensus, layer client for one Beacon Chain client, or maybe even run multiple Beacon Chain clients with multiple consensus layer clients with multiple execution, layer clients and multiplex between them, and then take, like, a two out of three majority vote. And this is something that he's very interested in working on. Well, Trent is a little bit disappointed, but we can maybe have you quickly on some of your questions.
05:01:02.270 - 05:02:07.424, Speaker A: Yeah, so I think Hudson asked whether it was more difficult to fork the code after the merge. It's a bit more difficult, I think, but shortly after the merge, we will still have to retain all the functionality from pre merge. And so yeah, there's not a big difference. Once we are comfortable in in post merge land, we should really find a name for that. I don't want to say ETH Two, but in proof of stake land, then we might start deprecating some of the features. In Gath. The ETH balances will be maintained on the execution layer.
05:02:07.424 - 05:02:45.810, Speaker A: So the execution layer holds all the information of the current state. Will execution layer and consensus layer share the same process and storage? They won't. They will, at least for the merge and probably a long time afterwards. They will reside in separate processes that talk to each other via the standardized engine API. They will have different storages. They will have different storage formats. And I don't think it makes sense to unify those.
05:02:45.810 - 05:03:59.640, Speaker A: Which layer will propagate the blocks? The consensus layer will now propagate the blocks, the beacon chain blocks which contain in them the execution payload. How is the transition triggered? As I said, it's the terminal total difficulty. If this is exceeded, the block that first exceeds the total terminal difficulty will be the last proof of work block. What's changing for users? Do you need to upgrade your nodes? Hopefully for the average user that just holds Eve, there's not much impact. You don't need to upgrade your wallet or whatever. You will need to upgrade your node, your guest node. And you will also need to run a consensus layer node or maybe in the future, a consensus layer lite client that will feed all the blocks to your execution layer node.
05:03:59.640 - 05:05:30.244, Speaker A: How does the block proposer collect the transaction fees? The execution payload or the assemble parameters in the create payload has a field called fee recipient, which basically is the same thing as we used to have with the coinbase address. So the block proposer sends the that's how it is right now. It might change with the proposal separation in the future, but the way it is right now, the block proposer can specify where the fees should go, and those will be paid out instantaneously once the block is mined. And the last one is something that's still up for debate. And just really quickly, we have a testnet up and running. If you go to Pithos minus Explorer, ETH DevOps IO, and you can see that there's a lot of client combinations currently, all with gas. The other have some problems, apparently, to run this test network, and you can join it from home to test all of this out, which is really cool.
05:05:30.244 - 05:05:45.112, Speaker A: So go do that. Thank you very much. Awesome. Thank you so much, Marius. This is a great overview on what's happening with the execution layer. And if you have more questions, I'm sure Maris will pull back on the chat and answer them directly. So thanks again.
05:05:45.112 - 05:06:24.626, Speaker A: And with that, we are ready for our next talk. Next up, we have Guillaume, and he's going to be talking about statelessness and vertical trees, a really interesting and awesome topic. And without further ado, I'll let him introduce himself and take it from here. Welcome. Looks like we may be having some audio issues. We'll try to see if we can hear you, but right now, no audio is coming in. Okay, there we go.
05:06:24.626 - 05:07:03.480, Speaker A: It's slowly coming in. Can you hear me now? It's very faint, but it's coming through. Okay, let me guess. No, that's correct. I just spent the last this is manageable. If you can just say that one more time. So I think the other device was where the audio was coming from, but let's give that one more shot.
05:07:03.480 - 05:07:22.290, Speaker A: What about now? There you go. Perfect. Okay, perfect. Yeah, I just spent the last 30 minutes configuring the audio. Okay, then let me share my screen and then we good to go. Here we go. All right.
05:07:22.290 - 05:07:40.870, Speaker A: Can you guys see my screen? Not yet. Okay, classic share. There we go. Okay, perfect. Yeah. So cool. Thanks for having me.
05:07:40.870 - 05:08:35.384, Speaker A: So I'm going to talk about statelessness and vertical trees. So I'm Guillaume from the guest team. Just, like, been like in the past six months, I've been working on what comes after the merge. So we wanted to share a bit, let's say an overview of what to expect after the merge. Like, the merge is the big thing on the horizon, but there's more exciting things coming after that. So yeah, I've been mostly working on vertical trees, but I've been asked to give a broad overview of statelessness in general, what's coming, so I'll cover a bit of that as well. And the first question is why do we want to achieve statelessness? And it's pretty simple, in fact.
05:08:35.384 - 05:09:21.780, Speaker A: Have you tried to synchronize a node recently? It's taking a long time. You need a lot of data. So that really prevents a lot of people from joining, like smaller devices, phones or raspberry PiS. I mean, raspberry PiS technically can do it, but it's not very sustainable. There's a lot of centralization associated to this, like a lot of people using Fiora. And there's also the problem that, for example, a DAP developer or anybody, there's a lot of data to download, but not everybody is interested in all the data. In fact, most people are not interested in the data.
05:09:21.780 - 05:10:18.184, Speaker A: So it would be great to have just to be able to download the data that you care about and keep going on with the rest of the network. So these are the goals that we're trying to achieve. And so there's basically three components. Statelessness has three main components. There's vertical trees. This is the technology we're going to use to basically make statelessness possible because it allows for very small proofs or much smaller than what we used to have until now. There's the state expiry, which is something that has been attempted many times in the past, but is coming back with a new technique called address space extension that I will cover.
05:10:18.184 - 05:11:19.480, Speaker A: And the last component is state networks. So since syncing the state is so difficult, the question is can you just avoid dealing with all that? Yeah, this is the question this answers. So let's get into the vertical trees. Currently we have a Merkel Patricia tree, so it's using hashes each level. Hashes is children and so on until the top. And hashes have been very useful in the past. But the problem with hashes is that if you get the whole commitment, sorry, if you have a vector of values and you just want to prove that one value is in the vector and you don't want to reveal what's next to it, you can't really just take the hash.
05:11:19.480 - 05:12:56.150, Speaker A: You can't really just take the hash and take that value and somehow prove that this value is at this specific position in the source data. The only way you can prove that is by passing the entire vector. So you have other an alternative technique that has many similarities with the hash is a vector commitment. You have a vector, you commit to it, you provide a commitment, but they also have the ability to find an opening which is a smaller piece of data compared to the size of the vector that you can use. So if you have the commitment plus the data, plus the opening, you can prove that this data was indeed at this location in the vector and you can use this to hide some data if you don't want to reveal all the data. But the reason why we care about this is not because we want to hide data that is public, we just want to use it so that we don't have to pass all the data. And this is quite important because if you want to prove that something is in the current tree, because you're using a hash, you have to pass all the siblings of a given node along the path, so that's 15, like the Merkel Patricia tree has each node has 15 siblings or 16 children.
05:12:56.150 - 05:13:56.548, Speaker A: And you have each time, at each level, you have to pass all 15 siblings. And the depth of the tree on average is seven, eight, so you have 15 times 832 bytes. It's a lot of data. So because of what I explained about vector commitments, you could use vector commitments to just pass the data that you need, add some commitments and that's already, for each level, much less data. And on top of that, the average depth is four. And the reason for that is because since you only pass, like, the number of siblings doesn't matter, you can have much larger nodes with many more children. And because your tree becomes much larger, it becomes automatically less deep, so more shallow.
05:13:56.548 - 05:15:13.120, Speaker A: So you move on from a structure that is really high and not that large. I mean, the MPT is quite large, but a vertical tree would be larger and it would be shallower, which means you also reduce the number of items in your proof, which contributes to making the proof smaller. And there's also an interesting point that I'm not going to cover really today. It's the fact that currently you have a tree for all the accounts and then each account has its own tree for storage. We're no longer having that with vertical trees, everything gets merged into one giant tree. But yeah, I won't cover that. It's just interesting to know one question that comes often is people say, okay, but if you have a commitment, if you don't have to pass the siblings, why not pass a single vector commitment with only the data you want? And that's a good idea, but calculating a commitment takes a lot of time.
05:15:13.120 - 05:16:15.568, Speaker A: Just like calculating the hash of all the data takes time. So what you do is you try to look for a sweet spot that makes smaller proofs but doesn't require a lot of time to compute. And so we chose 256 children. Initial implementation or initial proposals were 1024 children, but it made things more complicated to implement and 256 children seems to work. So this is what we went for. So yeah, just a general comparison of proof sizes between Merkel and Veracle. In the first case you have the leaf data, sorry, in both cases you need to include the leaf data, but in the case of Merkel, you have for each level, which is roughly seven, you have 15 siblings, each of which is 32 bytes.
05:16:15.568 - 05:16:59.984, Speaker A: So if you have 1000 leaves, that's roughly three megabytes. And we're getting in block size. So we want to have the proof integrated inside the block. And as a result, that makes a block that is bitcoin territory, basically, and in fact bigger than this. So instead of having a block every ten second, ten ish 15 ish seconds that gets propagated over the network. You need ten minutes, maybe more. So that's why the Merkel tree and that's why we want to switch the tree that we use to store the data, because that's impractical.
05:16:59.984 - 05:18:10.216, Speaker A: Whereas vertical trees so you index, you have the index that the child is in the node, you have the value, you have the commitment to it. So it's a slightly larger value, but you only have four levels and you don't have the siblings. So you end up even though you have a tiny overhead, it's not insignificant, but it's definitely not the biggest contribution. So you end up with a block size of roughly 150K. Sorry for the proof. So the block size, it basically doubles the block size and that's much more manageable, right? So the next idea is state expiry. And the idea is that because the state is getting too big in ethereum, there's the state bloat problem.
05:18:10.216 - 05:18:49.956, Speaker A: And because you end up when you store something on ethereum at the moment, you pay some gas. But the implicit promise is that this value you store will be kept forever. So that's effectively free. We want to go back on that promise a bit because it causes state bloat. So the idea is that after a while the data expires. Of course, it's not completely forgotten. We start with a fresh tree.
05:18:49.956 - 05:19:56.776, Speaker A: We delete the data from the previous tree, actually from two trees ago, but we keep the root so that if you have a proof of your data, that your data was present in the tree at that time, you can resurrect it, you can bring it back to the current epoch. So you pay an extra cost to bring it back. But if you don't need it, you can still just keep the proof and just let it wait for the time you need it to pay the resurrection cost. Right now we divide the time into periods. The period zero is the one we're currently in. But when the state expiry scheme becomes active, you will have one period each year or each six months. And when that happens, you freeze the tree of the previous period and you start with a fresh tree.
05:19:56.776 - 05:20:53.820, Speaker A: So we had peer zero. What you do is you start adding values to it. And so far you still have to keep the data of the previous period. And when the period one comes to an end, what happens is you start again from a fresh tree, you are still obliged to keep the data of the previous period. But the period before that, you can delete the data and you just keep the root so you can start adding more data to it. And when you want, for example, if someone wants to recover data from period zero, they pass a proof and that gets included. So the data gets brought from period zero into period two.
05:20:53.820 - 05:21:48.970, Speaker A: One thing that is not specified on this diagram is that the data had to be absent from period one. So when that green data got recovered from period zero, there was a check that it was not present in period one. If you find yourself at period three and you want to resurrect something from period zero, you have to pass a proof of absence. You have to prove that the value you're trying to resurrect was not in period one. Because otherwise what could happen is, for example, Alice has some funds in period zero. She transferred them to period one, then she transferred some funds to Bob. Period two happens, period three happens.
05:21:48.970 - 05:22:36.166, Speaker A: And then Alice resurrects the funds she had in period zero. And that's a double spend. So to make sure this does not happen, you need to pass a proof of absence. Right? So this state expiry mechanism comes with what's called an address space extension. So we had addresses that were 20 to 32 sorry, currently in Ethereum, the address are 20 bytes and they are the first 20 bytes of the hash of your public key. So now we want to make those address 32 byte long, but we don't reserve those 32 bytes. Like this is not the whole hash.
05:22:36.166 - 05:23:22.230, Speaker A: We only take 26 bytes of the hash. And then the remaining six bytes are used for well, half of them are used for versioning and future use. And the other three bytes are used to denote the epoch. Sorry, I keep saying epoch, but it's actually a period. It's used to denote the period that the address was first accessed. And the reason for that is because there's a cost associated to resurrection. So for example, if Bob wants to send Alice some tokens to Alice but Alice hasn't resurrected the address either.
05:23:22.230 - 05:24:09.640, Speaker A: Bob pays for the resurrection cost to resurrect Alice's account. But if he doesn't want to, then he can send it to an address that is also controlled by Alice. In the sense that for example so I have this example here. For example, let's say Alice owns the public key sorry, the private key that controls address. She has a balance here. And then let's say Bob has address one, for example. So both those addresses have the counter zero because they have been seen for the first time in period zero.
05:24:09.640 - 05:25:19.290, Speaker A: Then period one happens. So this is not in the period one tree, but Alice might receive some funds from Bob. And Bob's, instead of resurrecting this address from Alice, actually sends it to Alice, but with an address containing the current period. So it's seen for the first time at this address in period one, and Alice still has the private key that controls this hash, so she's still the owner of the fonts, but it's like she has two addresses with one private key. She has two addresses now, and in period two, Alice might want to get the value she had locked during period one. So she passes a proof to resurrect the address and we can see that the value that was in period zero is now available in period two. When Bob sent some funds to Alice in period one, this value was not overwritten.
05:25:19.290 - 05:26:07.070, Speaker A: Alice now has 1234 ETH in one address and 9101 in another address. So that's an interesting scheme. It's also a fairly complicated one because I like to make this joke. Address state extension like ASE can be pronounced ASE, which is sweat in Japanese. I think implementing it is going to require a lot of sweat, but yeah, it's nice because it makes state expiry. At least it proposes a concrete approach to state expiry, which is something we've been talking about for a few years already. The problem is that it's still quite complex.
05:26:07.070 - 05:26:53.706, Speaker A: A lot of contracts on chain today expect a 20 byte address and they actually use the twelve remaining bytes for something else. So it would not work. Like if they are given a 32 byte address, it's going to break the contract. So there's a good idea by the Ipsilant team bridge contract. I'm not really going to talk about this today. It's quite involved, but it's promising, but I don't want to make false promises. It's a very complex scheme and statelessness thankfully does not entirely depend on it.
05:26:53.706 - 05:27:53.118, Speaker A: So it's nice to have, but we can still launch without it. The last component is state networks. So the main proposal is by the Piper and the Python team, the portal network. And the idea is currently you have to get all your data. Like when you want to participate in the network, you need to download the data from all of it, most of which you don't care about. So the idea is to provide a network alongside the block propagation propagation network, where every machine on the network only stores a fraction of the data. And if you need it on a per need basis, you can go and query that data to one machine or to a subset of all the machines as you need it.
05:27:53.118 - 05:28:31.594, Speaker A: And that's quite nice because it has many applications. First of all, you don't have to store all the data, obviously. But even if you want to be, for example, a Validator in East Two, you don't really have to store the data yourself. You could just send your request, ask someone else to store the data for you, and request the data when you need to propose a block. Of course, I didn't say that. But that data is validated. You have to pass a proof, which is where vertical proofs, once again, are interesting.
05:28:31.594 - 05:29:25.402, Speaker A: Although I guess miracle proofs could work at this stage. So the roadmap is, yeah, basically veracle tree is almost there. At least we have a prototype. We are going to build another prototype using rust vertical. So, yeah, there's guess that currently is able to produce blocks with vertical proofs and Ethereum JS is interested in writing a stateless stateless client that will just execute blocks without actually downloading the data. And then when vertical has been delivered, address space extension can be also delivered. But if it turns out to be way too complex, you could also skip it.
05:29:25.402 - 05:30:31.954, Speaker A: And the portal network, like I said, doesn't really require vertical proofs per se, so it could be delivered independently. And when you have at least two, but preferably three of these things, you achieve statelessness. So, yeah, I'm running out of time, so I'm just going to, like I had this slide to explain a bit what stateless Ethereum would look like in the future. The biggest thing to know is that your data like, to realize that your data won't be kept accessible forever. You have to keep your proof or you have to pay someone to give you a proof. But it allows for nice, more decentralization, because ultimately you would not need to rely on infuriora or on miners or validators. The data could be spread all over the network and you could just download what you need.
05:30:31.954 - 05:31:28.562, Speaker A: And you could also why not make a profit by hosting data for other people? So, yeah, overall it gives a more decentralized world, a more accessible world, because there will be lighter clients will be able to join. So, yeah, all those people that are currently priced out of the network because for whatever reason, they don't have the space or the bandwidth or whatever to join. Ultimately, we hope, can also join the party. And yeah, that's it. I don't know if we have time for questions, but I think it's we are a little bit over, but I think we can do a couple of questions because hopefully I think they're a simple one. So there's three questions here. Some of them might be related to each other.
05:31:28.562 - 05:32:04.720, Speaker A: So the first one is what kind of proof is used to bring back data after state expiry? So that depends. The first tree is MPT, but it will be converted to vertical. At least that's the plan over time. So initially, let's say it's going to be a vertical proof. Yes. Got it. Would Veracle trees help lower gas prices by letting us store more transactions for block? That's a good question.
05:32:04.720 - 05:32:30.040, Speaker A: I'm going to say no. Maybe Vitali can pitch in on this one. I think he's in the chat, but my understanding is no. All right, well, maybe Vitali gets to come in when we promote in a minute what possible alternatives. Are there to ASV. Okay, Gay, I got promoted. Okay.
05:32:30.040 - 05:33:25.130, Speaker A: The question was if would vertical trees allow us to increase scalability, I guess gas prices, right? Increase the gas limit and lower gas prices. I guess maybe, right? Because right now, state size is one of the big bottlenecks on increasing the gas limit. And if we add vertical trees and if we add proposer builder separation. So if we have both of those things, then we can move toward the world where the only actors that need to be stateful would be the builders, which would be a much smaller number of nodes. So if we have that world, then the negative consequences of letting the state blow up to like a terabyte or would be lower. Right. So I think increasing the estimate would be safe there, but then adding state expiry as well would allow us to go even further.
05:33:25.130 - 05:33:59.614, Speaker A: We'll do one more quick one. Can users pay stakeholders trustlessly or will this happen out of the protocol? Sorry, I didn't quite hear. Can users pay stakeholders trustlessly or will this happen out of the protocol? Yeah, okay. I'm not an expert in the protocol, but I know, like, if I compare to light clients, that's exactly what happens. So, yeah, I'm going to say yes, it's going to happen in the protocol. Cool. It's easy to implement.
05:33:59.614 - 05:34:23.130, Speaker A: Let's say Trent, hopefully that's a satisfactory answer. If not, we'll ask him to put the answer in chat and follow the discussion there. Thank you so much. That was a really awesome overview and yeah, appreciate your time. Well, thanks for having me. All right, next up, as you've already guessed, is our speaker, Vitalik. Vitalik is going to be talking about upgrading infrastructure for role of centric ethereum.
05:34:23.130 - 05:35:20.750, Speaker A: So whenever you're ready, V, feel free to kick it off. Great, thank you. I'm going to, I guess, share the screen and then I'll use the magic trick that you taught me to only share a portion of the screen and then okay, there we go. Do you see it? Okay. Yes. Okay, so great. So today what I will talk about is basically thinking about this concept of a roll up centric ethereum something which was a vision one year ago and is, I think, on the cusp of becoming a reality or even is beginning to become a reality today and kind of think through some of the kind of side issues, various pieces of infrastructure that we sometimes don't think about in order to make a roll up, centric, ethereum world.
05:35:20.750 - 05:36:31.730, Speaker A: Something that actually is a pleasant environment for people to live in. So just to kind of recap a bit, the concept of roll up centric ethereum started to be introduced around the end of last year, I guess this post literally from October 2020. So twelve months ago, and this came from an observation that basically showed that if you look at our current roadmap, any way that we could realistically do the roadmap, we have a proof of stake first, then data sharding, and then only after that, possibly other kinds of sharding. And so in the ethereum base layer roadmap, there's only room for relatively small amounts of scalability, like with burgl trees, maybe two X or three X, but can't really go far beyond that. Right? And the problem is that we need much more scalability. Like even today we need at least a ten x, and in the long term, we need 100 to 1000 X. So the only technology that is available, and that was actually making a huge amount of progress even back then, is roll ups for the layer two scaling solution.
05:36:31.730 - 05:37:43.382, Speaker A: So this was a kind of brainstorm of, well, given that roll ups are Ethereum's best hope, what would a roadmap that's designed around that fact actually look like? And the answer, basically is, well, we have a lot of technology that we can already do to make roll ups work and to make roll ups work better. So we have obviously roll ups themselves, a lot of work being done on fraud proving, a lot of work now being done on the Zkevm to make EVM capable ZK roll ups possible, some work being done on wallets. The projects themselves have been making huge progress over the last year. And sharding itself, right? The first step of sharding is the data sharding. And data sharding by itself is enough to increase the amount of data space available to these roll ups by a factor of close to 100. So basically, a lot of things are already happening to make roll up centric Ethereum actually be a reality. And today roll ups are sort of kind of here, right? So there is optimism.
05:37:43.382 - 05:38:06.180, Speaker A: You can do things on optimism. There is Arbitrum. You can do things on arbitram. There's woobring and ZKsync. You can make payments on Woobring and ZKsync. There is polygon, which is not a roll up, it's a trusted side chain at present. But they bought Hermes and they seem to be on a track that will get them to being a ZK roll up at some point in the future.
05:38:06.180 - 05:38:54.322, Speaker A: Roll ups are kind of underway and you can use some of them, but it's not quite there yet, right? The scalability of a lot of them is far from optimal. So, like, for example, when I wrote my blog post on roll ups, one of the things that I talked about was how to get the really big scalability gains. You have to do a bunch of compression work and get the transaction size down to 16 bytes. And optimism and Arbitrum yet have not done this, but they're on their way to doing it. But until then, wild transactions still take more than 100 bytes. Fees are not quite as low as they can be. Blueberry and ZK sync are at that level already, right? So their fees are sometimes like 20, sometimes 40 times lower.
05:38:54.322 - 05:39:33.134, Speaker A: Than ethereum itself. And once these roll ups do add proper compression and they do add better signature schemes, then they'll be able to get down to these role levels as well. So scalability is still a work in progress. EVM roll ups still have training wheels, so they still have centralized backdoors, just because the fraud provers are either not quite finished or they're still in beta and people are not quite comfortable fully entrusting things to them yet. It's sort of come kind of on the way. But we're getting there, right. The roll of centric ethereum is not just a division now.
05:39:33.134 - 05:40:33.090, Speaker A: It's something where there's a very clear path to it and people are already starting to use projects that are either roll ups or that are kind of well on their way to becoming roll ups. So, so far, roll up centric ethereum is, I would say, just still a success, obviously a work in progress, but everything is a work in progress. Even the merge is a work in progress. But we've had a successful test at two weeks ago, so it's happening. But there are still things that are missing to make roll up centric ethereum actually easy to use, right. You can talk about roll ups being available in theory, and then you can talk about, well, roll up centric ethereum actually being an A blockchain environment that you as a user would want to live in. So what is the gap between those two things? First, kind of motivating question.
05:40:33.090 - 05:41:32.766, Speaker A: Right? Why can't I use a loop ring that pay for coffee? Right? We want what blockchains? Our big application of them is cryptocurrencies, and we want cryptocurrencies to actually be useful as currencies. Right? And what's the point of a currency if you can't use it to also pay for the small things? Right? So obviously you can't use the base layer to pay for coffee because the base layer is expensive and the base layer is meant for big and important things like layer two commitments. But we have layer twos and we have lubring, and lubring is already quite efficient and lubring does payments. So why can't you use lubring to pay for coffee today? Right? I think there's a lot of reasons for this. One is just that there hasn't really been a serious effort toward making it happen. But I think another big part of the answer is that loop ring today is kind of a bit of an island, right? If you're within loop ring, you're within loop ring. If you're not within loop ring, then it's kind of hard to move funds to being within loop ring.
05:41:32.766 - 05:42:00.826, Speaker A: Right. You have to do a layer one transaction. Layer one transactions are expensive. Then on top of that, you have to wait. So the UX of getting into loop ring if you're outside of loop ring is not very good. And if you're inside of loop ring, there's not that much that you can do inside of blueprint, right? Like you can exchange, you can trade, you can have tokens, there might be an NFT feature, but you can't have your fancy DeFi stuff. Like you can't have fancy NFT auctions.
05:42:00.826 - 05:43:05.298, Speaker A: You can't make a CDP and then borrow some coins from that CDP and then stick those coins into another magic DeFi thing. There's a lot of fun stuff that you can do in a full EVM environment that you just cannot do in loop ring because loop ring doesn't yet support that functionality, right? So there's basically two ways of solving this. One way of solving this is for loop ring itself to turn into a ZKE EPM roll up and that's technology which is in progress. But another possible solution is to make it easy to get into loop ring if you're not yet in loop ring. So cross roll up bridges, right? This is the sort of thing that I've been thinking about for a while that other people have been thinking about for a while. So here on the left I have this post on Ether research where I give some ideas for how you could make NFT wrappers, where the NFT could be issued in one roll up and then the NFT could be moved to another roll up and you can have NFTs jump between roll ups. And you don't need main chain transactions for this.
05:43:05.298 - 05:44:07.320, Speaker A: There's a project called Hop which is trying to make a trustless or scalable bridge to go between one roll up and another roll up. I had another post on Ether research that tries to do a roll up to roll up bridge that only requires one side of the bridge to actually be EVM capable. So you'd be able to have a decentralized bridge between say, optimism and loop ring. So crossroad bridges are important, and I think we want crossroad bridges to be trustless. So to have trustless, safety and trustless liveness, to be infrastructure that we can count on to just exist. But this is still something that is in progress, right? So the more work can happen on crossword bridges, the more we can make it very easy to move between any one of these ethereum layer two domains to any other ethereum layer two domain, the better. But this is something in which there has been some work, right? There are already some limited cases where you can hop from one roll up to another, but it's still something that needs to be worked on a bit more.
05:44:07.320 - 05:44:43.886, Speaker A: So crossroad bridges is one problem that needs some work, other problems. So let's take ENS. ENS probably the single most popular or most successful non financial Ethereum application. And it's a use case where it actually makes sense to use a blockchain for it. Lots of people have east names. I have a name Vitalix ETH. Lots of other people listening to this probably have a ETH name status to the Ethereum chat application status.
05:44:43.886 - 05:45:45.722, Speaker A: Users have used ETH names as usernames inside of status. Blogs can have ETH names. So if you go to Vitalik ETH and try to access it as a website, then you can find a copy of my blog. So lots of different applications of ENS and ENS seems to be doing great, right? But there's a problem, which is that it takes more than $10 to update an ENS record, right? So if you want to buy an ENS name, if you want to update a record, if you want to do anything through ENS, then you need to pay more than $10. So, like, for example, if I want to update the ENS record for Vitalik East as a blog to update the IBFS content hash, then that's something that I have to pay more than $10. And so it basically costs me like I forget some number of dollars, somewhere between ten and 30. I forget every time I want to update my blog if I wants to keep it updated with the NS.
05:45:45.722 - 05:46:45.126, Speaker A: So can layer two fix this? Right? And the answer is it should, right? Layer two should be able to fix this and we should be able to move ENS over to layer two in order to make it so that these record updates, instead of costing $10, they can move that go down to costing $2 today, $0.25 tomorrow, and two cent two years from now once shorting is stabilized. But we need to have a standard for how to resolve ENS domains stored inside of layer twos. So there's two ways of doing this. One way of doing is to say we're just going to socially coordinate ENS as a whole, moving over to one particular roll up, right? So we might say, oh, ENS, we're going to choose Arbitram, right? And ENS is going to live inside of Arbitram. And ENS will just work the same way it works today. But instead of talking to the ethereum blockchain, they'll talk to the Arbitrum roll up.
05:46:45.126 - 05:47:44.710, Speaker A: So I think this is not a great solution. And the reason why it's not a great solution is that, first of all, it creates a long term dependency on one specific roll up. And so far we're not yet sure which particular roll ups will prosper which particular roll ups the world actually wants to use. And second, people might have other reasons why they want to live inside of some other roll up. And so it would be nice if EVM can live where they live, right? Like people are not necessarily going to have an account on every roll up. And if one particular person just likes optimism, they want to live inside optimism, then they should be able to have their ENS domain inside of optimism. So what would be nice is to have some kind of cross roll up standard, right? So ENS should stay rooted in the ethereum chain, but there should be a standard where if from the point of view of the Ethereum chain.
05:47:44.710 - 05:49:09.154, Speaker A: You move an ENS domain over to a roll up contract. Then you would be able to manipulate and do things to that ENS domain inside of the roll up. So good news is that there's this protocol called Durin ERC 3668 Secure Off Chain Data Retrieval which is trying to serve a bunch of use cases but where this is one of the use cases, right? So basically the idea of Durin is that you would be able to set your ENS record to be set to an address where that address defines an off chain record keeping system. And that off chain record keeping system, it would basically have a smart contract where it would point you to a place where someone trying to get the data would be able to grab the basically state inside of either the optimism role or the arbitrary role or whatever role you choose. They'd be able to grab the state that shows what is the current state of that particular record. And then the contract would also have a merkel prover. And so you would be able to fetch a merkel proof and verify the merkel proof and you would basically still be able to actually get what the current state of that record is automatically, right? So basically from a client's point of view the client's point of view would be like step one it would think that you have an ENS record on Ethereum and so it would call the ENS contract.
05:49:09.154 - 05:49:44.062, Speaker A: It would try to access your record on the Ethereum base layer. Then it would realize that your record is stored in this particular contract which is an off chain data retrieval contract. It would call it the contract would return a off chain data lookup error. Then that error would contain instructions about where you would go and get the merkel proof. Like it could be a list of URLs and it could be a huge number of URLs. So we have a lot of redundancy. And then you as a user would just try pinging all these locations and you would ask for light client proof.
05:49:44.062 - 05:51:02.218, Speaker A: And then of the state associated with that record you would get that light client proof. So that's step two. And then step three is that you would locally do an ETH call and you would call a proof verifying function on that same contract and that proof verifying contract would verify the proof and it would also tell you basically what is the state that just got verified. So that would actually tell you that, hey, that function was actually supposed to return some particular value. Now, in order to update the state or this internal state you would not have to send Ethereum transactions, right? Because these are all state updates that would happen inside of a roll up. And the only things that would happen on chain is that merkel roots of the roll up state would continuously be getting updated on chain right? So on chain you'll just be merkel roots that get updated and then all of the actual operations that happen inside of the roll up would be happening off chain. So this is a nice solution right, because it allows you to basically extend your kind of ENS infrastructure so that it automatically can go and fetch the state of your ENS records inside of a roll up.
05:51:02.218 - 05:52:10.222, Speaker A: So if I have vitalik ETH, I could move vitalik ETH into a roll up and then if I want to make any record updates, I could do those inside of a roll up. Or potentially, if he wants to handle the use case of people registering new subdomains, then someone could make an entire subdomain move it inside of a roll up and then all domains that are subdomains of that domain could then be registered and everything could be done with them inside of a roll up. So for someone like Status, if they want to make it possible for people to register new names at the cost of a few cents instead of $10, then they could register a subdomain and move that subdomain to inside of a roll up. Or they could even have different subdomains inside of different roll ups. And users would be able to register a U domain, and that U domain would be a subdomain of that domain. But they would be able to do the entire process purely inside of a roll up. And the infrastructure that actually gets ENS record data, client side would just be able to do all of that and will be able to fetch the data from the right roll up automatically.
05:52:10.222 - 05:53:19.250, Speaker A: Right? So the client side software would not even need to update to be able to handle new roll ups so new rollups would just be able to add themselves into the system automatically. Very versatile. So it can work with optimistic ropes, it can work with UK roll ups, it can even work with polygon for now. So that's definitely something that I am very excited about and hopefully with this sort of thing we can finally have an ENS world where ENS domains are cheap to register again light clients. So this is a third piece of infrastructure that we're making a lot of progress on today, right? So in the world of just ethereum after the Altair fork we're going to have this concept of sync committees. A sync committee is basically this committee gets committed to inside of the Beacon Chain block headers. And then that committee is going to basically sign messages attesting to a block header.
05:53:19.250 - 05:54:51.726, Speaker A: And then that block header can be as signature can be verified against that block header and against the sync committee. And so this provides this very cheap algorithm where a client will be able to keep up with the Beacon chain at a very low cost. Right? At a minimum cost of something like 40 day plus maybe 500 to 1000 bytes for every single header that they want to verify plus merkel proofs. So with Altar you're going to have these async committee inside the beacon chain and with the merge, the beacon chain and the execution chain are going to merge. And so you're finally going to have a path where you're going to have these sync committees that will actually verify ethereum blocks and we're going to be able to have trustless Light clients, right? So today wallets like Infuria and basically wallets like MetaMask and every wallet that exists today either talks to Infuria or they talk to some centralized system. In this light client world, instead of talking to a single server, they could talk to end servers, right? So they could have collection of end servers that they talk to for redundancy they could receive and they could validate merkle proofs from each one and whichever one is online they could get proofs from it and they'd be able to validate merkel proofs locally, right? So you would not have to trust the servers to be honest. And because you would have n of them instead of one, you would not have to trust them for Liveness, right? For Liveness you would just have a one event trust assumption.
05:54:51.726 - 05:56:40.774, Speaker A: So there's a big opportunity here with the merge and with the likeliance to finally move away from this kind of centralized inferior world and move toward a world where we actually do everything much more trustlessly with proof verification. But there's a question, right, which is does a move to layer two protocols risk reversing these gains? This is a like client of Ethereum. But now if we're going to be talking about a world where you don't just have ethereum, but you also have people using optimism, people using Arbitrum, people using polygon, people using loop ring, and then next year, people are going to create three more roll ups, how are Light clients going to be able to handle that world? Right? And the risk is that if we don't provide a good way for them to handle that world, then what's going to happen is that Infura is going to be the one that creates nodes for all of these systems and they're just going to end up trusting Infuria. So how can we move away from centralized trust Dystopia and make sure that these gains and decentralization actually apply not just to the base ethereum chain, but also apply to layer twos? So there's a good news, right? The good news is basically that we can use ideas very similar to Durin to create a generic layer two like client system. Basically the idea is that systems like optimism and Arbitrum and with these layer twos they could return a list of URLs or they could basically return some kind of mechanism by which the clients can get proofs for a particular piece of state that they want to access and they can provide a function for verifying proofs, right? So the function could be a merkel proof verifier. It could be a polynomial commitment. Verifier could be whatever.
05:56:40.774 - 05:57:30.674, Speaker A: And clients, they would first poke the layer two contract. The layer two contract would provide a list of locations where they can try to get proofs. It doesn't have to be like the URL standard is very extensible, right? So eventually this could be an address of a peer to peer network as well, right? So they would provide a list of just kind of ways of getting proofs. The clients would get proofs. The L two contracts would provide a function for verifying proofs. And then clients would verify these proofs automatically. And so any software which is a light client of Ethereum would then automatically be a light client of every L two that supports this standard, right? So if you have any light client which supports Ethereum, then it would also be a light client of all of these L two protocols.
05:57:30.674 - 05:58:58.942, Speaker A: Now, this is amazing, right? And it's amazing because basically we'd be able to keep these really nice trustlessness properties not just for Ethereum the way that it works today, but also for this kind of allure two expanded universe of Ethereum of the future that's going to have much higher scalability, much lower fees, and greater decentralization compared to today. So those are three of the examples of very big and important situations where we need other infrastructure in order to make layer two ethereum a world which is as usable and as decentralized as we want it to be. There's also plenty of other examples today, right? So, like, Wallets needs to be able to jump between layer two sufficiently. We need to make sure that security for L two S works well. We need to make sure that exchanges on all of these systems work efficiently. We need to just figure out every individual D five platform needs to work, figure out is it going to live inside of a single L two? Is it going to cross L twoify itself? So there's a lot of these pieces that need to be worked on. But the good news is that in general, layer two centric ethereum is not just a vision.
05:58:58.942 - 05:59:50.558, Speaker A: Layer two centric ethereum is a reality which we are in the process of building today. Still a lot of rough edges, but these rough edges are continually being worked on, continually being improved as we speak. A lot of really impressive work happening on ZKE EVMs, both the Hermes team and Barry's team doing a lot of good work. A lot of amazing work happening on off road groups for optimistic roll ups. I saw both Optimism and Arbitram are doing some really amazing stuff. There's Optimism, and then there's George Hotz and all of his amazing work on Canon and basically, literally compiling GEF into an environment where you can then compile it into a Trubit like system. Then there's Arbitrum, which is doing, I think, recently had a blog post where they're taking a similar path.
05:59:50.558 - 06:00:38.050, Speaker A: So a lot of really amazing work happening on layer twos compression is something that I personally have kind of been pushing really hard. And I say I expect this is one of the things that's going to start happening pretty soon. So I expect we're going to just see continual decreases in transaction fees on optimism and arbitrage. But we have to make these roll ups not just work well as individual roll ups, but we have to make layer two Ethereum as a system easy to use. Right. It's not just a matter of scaling up from Ethereum being a city to Ethereum being a country. We also need high speed trains between the cities, right? And we need high speed rail to go from one city to another city without having to pass everyone pass through downtown.
06:00:38.050 - 06:01:20.880, Speaker A: So at the same time, though, these are things that we actually can do. The tools are there. We can build these things. There's a lot of opportunity for building these things. There's an optimism of retroactive public goods funding gadget, which may well retroactively fund you if you help to build these things. So there's a lot of opportunity, but there's also a lot of work to be done, right? I hope that people listening to this and I hope that anyone can kind of be part of the solution and help kind of actually build out this world so that we can actually have this amazing layer two Ethereum of the future. Thank you.
06:01:20.880 - 06:01:41.634, Speaker A: Thanks, Natalie. That was awesome. Got a few things to dig into. We have time. So speaker joins in a little bit early. We can end up too many things. But you just talked about this interesting project Jihoth is doing with the optimism.
06:01:41.634 - 06:02:41.046, Speaker A: Go to Met. Can you just walk into tell us more about what that is, what's happening and how does that work and sort of let's kind of get some little bit overview on that and then what do you think your opinion is on? Sure, yeah. So Canon is really fun, right? It's basically this EVM fraud prover. And the way that it works is that instead of creating a new EVM implementation and then worrying about whether or not it's compatible with the existing ones, basically what it does is it takes an existing Ethereum client. So in this case, GEF, and it compiles or it compiles basically a version of GEF that is I guess you can think of it as a stateless client and then it compiles that. So it takes a block and it takes proofs and it verifies that it's correct. It then compiles that into this architecture called MIPS, which is basically a very simple virtual machine.
06:02:41.046 - 06:03:25.846, Speaker A: And then separately there is a project which is basically building a true bit for that virtual machine, right? So basically a kind of interactive fraud prover. So it'll take like a billion computational steps of this virtual machine to. Actually run. But then you would have this game where if someone challenges the results, they have to provide 100 intermediate values and then the original creator will then decide which of those intermediate values they disagree with. And then the challenger has to provide 100 intermediate values beside those intermediate values. You kind of start narrowing down where the actual disagreement is and then finally you just execute one step of nips on chain and we figure out whether the challenger or the original prover is correct. So same technology as TrueBit.
06:03:25.846 - 06:03:50.670, Speaker A: Right, except you just apply this directly to this kind of EVM verifier that you basically took by just directly compiling an Ethereum client into it. This mechanism is really nice because it's also very general. Right. So it's very easy to update. So if Ethereum has a hard fork, very easy to update. There's no separate implementation that needs to be updated. You just updated existing implementations.
06:03:50.670 - 06:05:01.734, Speaker A: You could even extend it to do things that are fancier. So, like, one idea that you could have if you want to be clever and you want to be really robust against software bugs is you could do the same thing for GEF and Nethermind and Beso. And you have three fraud provers and then you have a separate fraud proving process where if someone proves that a particular block is valid under one client but not valid under another client, then you raise an alarm. And then for what happens to that roll up, you can delegate it to governance, but then you raise an alarm and potentially that's something you could even create an automated bounty for. Right, so there's a lot of really fun things that you could do there. I was just going to say maybe just to get a little bit clarity on one of those things. So because of this providstal arbitrary computation model, do you think this is an extension to roll up in this case where you can now do more with roll ups that we couldn't do before, or is this more of an adjacent thing? I think it's like allowing us to do what we've known was possible all along.
06:05:01.734 - 06:05:30.178, Speaker A: There's no one who ever, I think, ever doubted that you can make an EVM roll up. I think it's just like a whole bunch of details. Right. And this is just a way of making those details happen much more quickly and easily. Got you. Yeah, because all you have to do is you have to just create a true bit for a very simple virtual machine and then the rest is just compiling existing software to it, which is something that you have tool chains for as well. Interesting.
06:05:30.178 - 06:06:07.340, Speaker A: Okay, no, that makes sense. We're going to be slightly off topic on this one, but I know this whole thing was focused about roll up centric world, but maybe it'll be good to contrast this with state channels. What do you kind of think about that? I can't go to specific, but let's say any habitable thoughts on that when I just had that question. And I have two specific questions around state channels that we can dig into. Right? I think what we've learned over the last few years is that state channels are a very specialized technology. They're amazingly good at a particular set of things. But users don't just want to do a particular set of things.
06:06:07.340 - 06:06:42.310, Speaker A: Users just want like dumb EVMs. So I think there is this really big and important central place for dumb EVMs. But at the same time state channels have really important roles. And I don't think it's state channels versus EVM roll ups. I think it's state channels and EVM roll ups. I think state channels can form a big part of creating efficient bridges and decentralized exchanges between different roll ups. State channels can still be useful for kind of micro payments and kind of multi payments to individual parties.
06:06:42.310 - 06:07:30.102, Speaker A: Roll up centric ethereum and sharded ethereum and all of these more scalable ethereums also imply in moving toward a world where no single node is going to have all of the data to figure out what's going on locally. And so nodes are going to have to talk to other nodes. And like I talked today about how when a node talks to another node when it receives responses, how it can use merkel proofs to verify those responses but we haven't talked about yet is how those nodes get compensated. Right? And you could consider a client node having a long running relationship with a provider node and that long running relationship could be paid for with estate channels. So that's just like a very simple way of paying for requests. I pay you for a bit and then you send me an answer. I pay you a bit and you send me an answer.
06:07:30.102 - 06:08:44.874, Speaker A: And so the amount by which either party can cheat the other is extremely low. So that's another example of a use case for stage channels. So I think between like clients and data provision and across roll up bridging, there's lots of stuff for state channels to do within the roll up course that makes sense. And I think one thing we've seen in the past is that for state channels, wallet integration has sort of become challenging because wallets have to manage the state. But given the success of what we've seen with the world of roll ups CK or optimistic in the last year, we've also kind of seen in parallel state channel projects like Connects or Seller kind of pivot into multi chain approaches where they connect with other chains. Is that still a possible future for an alternative to the roll up strategy or do you think roll ups? My personal view is that roll ups are just better than side chains because roll ups, they benefit from the full security of ethereum. And basically, there's this kind of nice tight coupling property right where you can trust that the roll up state is kind of like an application on ethereum.
06:08:44.874 - 06:09:40.762, Speaker A: Can unconditionally trust that a roll up state is correct? Right. Whereas if you have a bridge between two kind of chains that are both quote, sovereign and they're separately sovereign, then if one of those chains gets 51% attacked, then the bridge stops telling the truth, right? Or if the bridge gets attacked, then the bridge stops telling the truth. Whereas a lot of the bridges they do still rely on multi six or whatever. Whereas with roll ups, the roll up bridges have 100% accuracy from the point of view of inside of the chain. Right? Now, obviously it's possible that there's a 51% attack on Ethereum and then optimism gets reorbed. But if that happens, then whatever thing you did that depends on optimism is also going to get reorganized, right? So you're actually 100% safe. So I think there is that really important kind of tight coupling property that you get from being inside of a common security layer, which the roll up Ethereum verse is.
06:09:40.762 - 06:10:55.046, Speaker A: So I view that as being a benefit of doing roll ups, but at the same time, there's going to be other applications that are very low value per transaction, and so it might not make sense to pay the fees even for roll ups. And like, okay, fine, those applications could still be in a side chain in the short term. And then in the long term, once AZEK Starks are good enough, then everything should be either a ZK roll up or a yeah. What do you think of, I guess, monolithic changes versus multi roll up futures or just choices there? I think realistically, multi roll up is inevitable. First of all, there's just already multiple roll ups and there's these different approaches. Even if we assume that there's trade offs between ZK roll ups and validiums and some people want to be one and some people want to be another, you're going to need bridges between them. A multi roll up world just it feels more scalable because you just naturally have much more parallelization different roll ups use different shards, and the different roll ups have different computers that are creating the proofs for them.
06:10:55.046 - 06:11:51.820, Speaker A: So right now, the multi roll up world feels more likely. Obviously, it's definitely possible that I'm wrong. Kieran we do just get like one ZK roll up that ends up dominating the whole thing, but we'll see what happens. Do you think Bitcoin could be a roll up one day? Oh, fun. Well, for Bitcoin to be a roll up of Ethereum, the community is going to have to accept proof of stake, which I guess we don't understand. We'll see kind of coming back to the world centric world, as you kind of just talked about. There's a lot of things where inevitably you can have anywhere from one roll up being more popular to just kind of having some specific features that are valued more from one or valued or offered by wonderrollup than the other.
06:11:51.820 - 06:13:14.614, Speaker A: What should change or what changes for a developer when they're thinking about deploying an application? Obviously there's some trade offs on compatibility or composability. Yes, you may have different parallel worlds, but it also, I think, at some point makes development not as easy. Would you agree with that? Or kind of the question is what are the challenges for developers when moving their applications to roll up land? Yes, I think the main challenge is that an application has to decide whether it lives inside of one roll up or whether it's natively cross roll up. And if it's a natively cross roll up, then you have to actually think more about the infrastructure of what being natively cross roll up actually looks like. And even if it lives inside of a roll up, then there might be cases where people just want to kind of bite off some portion of the activity of your application and move it over and do it inside of another roll up. Right, so you do have to kind of think about cross roll up nuances but even if you don't, then if you don't, then I guess the challenge is that you lose composability with applications that live inside of other roll ups. Right? Like if you have uniswap inside of optimism and some DeFi thing inside of Arbitram, then you can't do synchronous operations between the uniswap and that DeFi thing.
06:13:14.614 - 06:14:22.794, Speaker A: But I think realistically there's going to be a copy of uniswap with at least some liquidity inside of every domain. So inside of every roll up, inside of every side chain and obviously on the base chain as well. But that's basically how to kind of interact with the newly found kind of ability to move between domains is something that application developers need to think about. The thinking around ENS and the thinking around NFTs would be one example of that. How would, say, loot work if we assume that we want loot to be accessible to people that aren't willing to burn $40 on doing every operation? And what happens if some loot is inside of optimism and other loot is inside of Arbitram? Like, how do you recognize loot that's in different roll ups? Very similar challenges to ENS, right? Well, for a good reason. Like a loot is an NFT and ENS is an NFT for more experimentation if you have no cost transacting. Yeah, that makes a lot of sense.
06:14:22.794 - 06:15:19.066, Speaker A: Another question which is indirectly related to one of your slides from the Talk Walts, are the first interaction and barrier for an end user and kind of writing mnemonic key phrase every time won't scale for an average user or hard drives. So I'm just repeating what do you think about the current state of wallets and what solution do you think we should implement? Make that especially with layer two in mind. Sure. So for wallets and keys. As I've said many times, I'm a huge fan of Social Recovery wallets. And I think social Recovery wallets for your hot wallet for your assets that you need, for everything you do that's convenience oriented and multi SIG wallets for everything that's not convenience oriented. And I think the same wallet can manage both, right? But then in order for that to happen, we need account abstraction.
06:15:19.066 - 06:16:33.078, Speaker A: And recently, myself and GSN people and netherminds people have been collaborating on ERC Four Three Seven, which tries to make account abstraction work without any protocol changes by kind of doing this overlay using user operations. So very much encourage people to look into that as well. And that's something that I think people should very much be starting to hack around at this point. And I guess the good thing that's happening now, right, is that all of these roll ups are moving toward being just EVMs. And so if you have one wallet, you should be able to take that wallet software and just deploy it on every domain. So if you can have one wallet, probably same address on every domain maybe, and you have the same wallet software that could actually manage your kind of wallet and your funds inside of each one of them, then I think that could be really convenient and really amazing. And then basically, I think the fewer wallet applications that users need, the more effort they could put into kind of the backup and key management for each one.
06:16:33.078 - 06:17:07.774, Speaker A: And so the less the risk of unfortunate security accidents happening and the better the experience for people. No, that's absolutely fair. Do you think there are any other well, actually, I think the answer is yes. But what are some, I guess, open problems for the world of roll ups to still figure out in order to sort of achieve that goal? Either they're still open questions or considerations. I guess the sequencers need to speak this account abstract. They need to speak. ERC, four, three, seven.
06:17:07.774 - 06:17:48.860, Speaker A: If they do natively, that would be amazing. Realistically, I think roll ups are a better experimentation ground than the main net because they're cheaper. So I could easily see account extraction wallets taking off in layer two before they take off in layer one. Got it. Okay, so just still on kind of the sequencers managing account abstraction, right? Yeah. Sequencers should the optimism and arbitrary sequencers should ideally just speak ERC 4337 natively, and that should be one of the priorities for them. Well, I know a couple of L Two projects watching this, so hopefully we get to work on L Two.
06:17:48.860 - 06:18:16.680, Speaker A: All right, well, I don't think I have any other questions. Thank you so much for taking the time today. Thank you, too. Awesome. All right, everybody, we are running a little bit ahead of schedule. So what we'll do is we'll take a quick five minute break and then we'll do our last talk of the day, which is going to be an AMA with Gucci from the Ethereum Foundation. So sit tight, enjoy the next five minutes as a break and we'll be back.
06:18:16.680 - 06:24:43.800, Speaker A: All right, welcome back, everybody. We are now ready to kick off with our last talk of the summit and that is going to be An AMA with Aya. We're going to bring her on in just a second and this is going to be super fun. We're going to talk about everything from Ice vision for Ethereum, Ethereum Foundation, what's happening with a lot of the initiatives around the EF and a few more things. So without further ado, I'd like to welcome her on stage and join me in this interview. Good morning, Aya.
06:24:45.020 - 06:24:49.240, Speaker B: Hello. Good morning. From here, Kadik.
06:24:50.140 - 06:25:07.520, Speaker A: Perfect. We'll keep this light and fun. I have a handful of questions here and I'll kind of ask them. We'll change up orders, we'll go deeper into anything that fits. But I want to kind of start off with asking what is your vision?
06:25:12.260 - 06:25:46.620, Speaker B: My vision for ethereum. Right. So I call it I'm pretty sure you have heard of it. I call it infinite garden. And this is inspired by the book Finite and Infinite Games by James Cars. And where finite games are played for the purpose of winning and infinite games are played for the purpose of continuing the games. And when I think about Ethereum, I don't just think about the technology.
06:25:46.620 - 06:26:37.070, Speaker B: Technology is great, but how we work together, how the ecosystem people work together to continue the play. And then I think it's very special. And that vision influences technical decisions too, and also how implementations are being done. And I think that's very rare in this modern society and also even rare in the blockchain space. And then the garden is for its diversity and its organic growth. And then I think this ecosystem wasn't really designed. It kind of organically happened everything like what you are doing too.
06:26:37.070 - 06:27:12.490, Speaker B: We didn't really design everything at the beginning. Like when we first met, you and I. I remember when we first met in San Francisco. A lot of exploration and working together, discussions and all these organic things. It's more natural. And then keeping the call in a weird way requires strong vision, deeply rooted in our mind, not just how we describe in words.
06:27:16.140 - 06:27:44.112, Speaker A: This helps us set the frame for a handful of other questions we have. So as long as people keep this in mind, this will be insightful. So maybe we'll switch gears. So I asked you for your version of Ethereum. I guess if I were to say what is kind of actually, I'll back up. You've been part of the Ethereum Foundation for three years now. You came on as executive director comparing well, let's start with like, three years ago.
06:27:44.112 - 06:27:53.060, Speaker A: What did you want to achieve when you joined and what were some of your aspirations there? And then we'll kind of roll into the infinite garden.
06:27:54.520 - 06:28:56.810, Speaker B: Yeah, so first of all, very honestly, I didn't start with like, okay, I became the Executive Director of the Ethereum Foundation and here's a list of things I want to achieve. I could not start that way because no one told me or no one knew what the EF really was or who EF was. And that is hugely tied to how the system is. And it's also like a live creature and it is changing. So it took a while for me to even think about what I need to achieve or what I need to start with. So that is the first thing is to really understand and observe. I wish I had some time to become like almost like a chief Observation officer or something.
06:28:56.810 - 06:29:49.560, Speaker B: Just watch everything and learn. Yeah, so it took really a while while everything was already going on. But within that there are a couple of things. Maybe the first one was more clear, even without deeper observation is that the first one is to create a system to support teams and projects outside of the EF. Then this is actually related to some of the principle that I describe and then we call it subtraction. If we care about the long term health of Ethereum, like, the ecosystem has to evolve outside of EF. And that is what I wanted to achieve.
06:29:49.560 - 06:30:54.008, Speaker B: I wouldn't say I knew exactly by when, but I knew that has to happen. And when I joined in 2018 in the Ethereum Foundation, there were already many activities outside of EF, but there was not enough support system for the project outside. And this was also something Vitalik wanted to fix. And we created ESP Ecosystem Support program, which we didn't really start with calling it that way and to officially receive applications and give financial support. And then we started to think about like, wait, money is not the only thing EF can support. Or maybe actually there are others, we should encourage others to give financial support, but there should be something only EF can do. So we started doing more proactive funding beyond just receiving applications.
06:30:54.008 - 06:32:03.670, Speaker B: And example of some of the teams that include Ethropol in Geekcoin or like Austin, a lot of crazy stuff that Austin is doing, he's great. And then nomics labs and some devex work and more. So that is the first thing and naturally it's also related to the first one. But the second thing is to add more coordinating activities or functions either within the F or also I mean, we do need to do that within the F. That's how the F works too, but also outside in the ecosystem. And then for the things to happen organically, like projects like Get sorry Z, those teams were born from the EF, but there are a ton of other important projects in the ecosystem. But they still have to work together.
06:32:03.670 - 06:33:15.630, Speaker B: And then when the ecosystem grows, that creates new challenges, right? So two main challenges, I think, in the decentralized system or decentralization in general is redundancy and lack of ownership can naturally happen. And I saw it, so that's why I can clearly say it. So when this is a startup or company, you just start adding managers and create hierarchical reporting system. But since Ethereum is open and decentralized and EF to some extent that we try to be that way and EF managing all to purpose. So how do you coordinate and let others execute and make decisions even, is a continuous goal like we must pursue and we have to keep improving the ways.
06:33:16.080 - 06:33:44.912, Speaker A: Yeah, a lot of themes here you've touched on. And it's funny because until you brought it up, I totally forgot, but Iqbo was part of the first wave of the grants for recipients and that's how we ended up bootstrapping our first couple of events. So it is definitely true. There's so many things that you could not have imagined back then that are now helping out create this ecosystem and more sustainable.
06:33:44.976 - 06:34:42.730, Speaker B: Yeah, I think we never really talk about this because we don't really have the chance. But how we started when you and I first met and then talked about the way East Global was functioning was also very different, right? Yes. And then you executed a lot after that. And then it's not like EF told East Global, here's just the thing, it was never like that. It was more like you propose the idea and then you just keep doing it. And then we saw, oh wow, they are actually bringing in a lot of developers, so why don't we support more of this? And then it's always collaboration exactly between what we think of and then also what you discover. And then you help the entire ecosystem to hire, recruit more people.
06:34:42.730 - 06:35:02.990, Speaker B: So that's kind of like a great example. Not everything has been that way. And then it requires two ways, interactions and collaborations and open mindedness and everything.
06:35:08.480 - 06:35:17.430, Speaker A: It's actually super interesting because today's special day. Because today is ETH Global's fourth birthday. Can't believe it's years.
06:35:17.960 - 06:35:19.380, Speaker B: Happy birthday.
06:35:22.280 - 06:35:35.130, Speaker A: This doesn't feel like it's been four years. It feels like it's been one, but at the same time, the one year feels like it's been four years. So there's a lot of lessons and things that we'd never thought that have been happening or has happened.
06:35:35.820 - 06:35:40.730, Speaker B: Yeah, you couldn't plan this COVID pandemic either.
06:35:43.260 - 06:35:55.570, Speaker A: So speaking of things that you didn't know as you were joining and kind of said you didn't have a checklist, maybe concretely answering this now, what would you say the vision and the mission of Ethereum Foundation is?
06:35:56.660 - 06:37:21.372, Speaker B: So I briefly touched that. But I think the vision of EF simply is the healthy Ethereum ecosystem. And then to understand what the definition of healthy and healthier, you need to understand the vision of infinite garden I just described. And then our mission is to help the ecosystem go towards that and just growing the ecosystem, that is also important then we do care about the longevity of Ethereum, but the size and the length, those are not the only important things. Or especially if we think about what only EF can do and especially now when Ethereum is growing quickly and the ecosystem is growing quickly and new people are coming in and I do think maintaining the health is something like maybe we can contribute more than others. That is, again, wasn't very super clear from the very beginning, but I feel.
06:37:21.426 - 06:37:32.300, Speaker A: Strongly so now what would you say then are sort of the principles that help you achieve that goal? What needs to be done from a mindset perspective?
06:37:33.040 - 06:38:54.580, Speaker B: Yeah, so I think the very important principle is like long term thinking. And again, if we look at everything, how things work in in the world, unfortunately a lot of systems, current existing systems are not built that way. But if we are dealing with the technology that can build systems that are supposed to be used in society, we do have to think about the time that we do not exist. And Ethereum has been doing it already. Like if you think about the time we don't exist, you can understand immediately why proof of work is not the option. So that ATM has been making that technical decision too. So that is something the reason why I want to keep it as our core principle is because it's more like seeking the balance.
06:38:54.580 - 06:39:45.908, Speaker B: Normally everything goes toward short term without us even knowing about it. What can we do quickly? We use cell phone and then receiving messages from everywhere in the world. We just think about, okay, what is nest? We have so much information we need to consume and like, you zooming out and then think about, okay, like, what is the bigger picture? What what it it's going to what is this going to look like in five years or even ten years or 50 years? Yeah, it is challenging, right? Like, even in our life I don't.
06:39:45.924 - 06:39:47.640, Speaker A: Know what I want for breakfast tomorrow.
06:39:52.800 - 06:40:33.050, Speaker B: Yeah. Do you pick what you eat now? Thinking about how that would affect yourself in five years or ten years, it's hard. There are some people who do that, but then it requires strong will. That's something. Of course I'm getting help from tremendous members of people at the Economy Foundation. But try to at least internally first, letting people understand and then there are a lot of other short term quick work that other people sometimes you do have to do that. Like you have to finish it.
06:40:33.050 - 06:40:39.800, Speaker B: But I think that's very important for the Eternia Foundation.
06:40:40.300 - 06:40:59.970, Speaker A: Absolutely. Speaking of the foundation, I think a lot of people I don't think have a really good idea of what the foundation is currently in terms of how big is it, how does it work. Could you give us an overview of the operational side of the foundation. Sure, a lot has changed, but tell us what the foundation is right now.
06:41:00.340 - 06:42:00.660, Speaker B: Yes, and then I know it was a big mystery for me too. I had no idea until joined outside of ongoing development teams like Gas or Rigidity. Big difference from the time before I joined is that now we have a bigger operation team compared to before. But within the operation we have of course the organizational operations, which is for EF to function as an organization. And it's a nonprofit organization. So we do have regular operations like finance and legal. But our main operation work is what we call now we call ecosystem development or Ecodeb, which includes all different efforts to grow the ecosystem and keep it healthy.
06:42:00.660 - 06:43:02.632, Speaker B: This is kind of like being redesigned now. More like we don't really change activities, everything. It's more like how we design. We are about to just do that. So the team, you know, the teams like ESP DevCon are also part of it. But we have more functions now and some people are in charge of coordinating things for enterprise size and the new research topics that we need to discuss more, how to support each topic or things like core devs goals are happening for the community, but someone needs to coordinate, make sure that it's actually happening. Like, we don't really manage the discussion, but we try to help whatever the coordination needed.
06:43:02.632 - 06:43:44.900, Speaker B: If they don't need us, that's great. So we have about 50 people in that work, like very broadly. But again, everything is collaborative work. Like you and I talk or we talk. So there is no clear line between internal external often. And I think that it's important to keep it that way. But for the purpose of having discussions or having execution or ownership, we do have to have some what we call clusters.
06:43:44.900 - 06:44:26.290, Speaker B: And Josh Stark is the genius of this, describing it that loosely, kind of like described organized. But that's still kind of, for now, people to be even internally, people need to understand what others are working on so that they can do best job for themselves too. So a lot of the coordination, for example, like ethereum.org or other things too.
06:44:27.080 - 06:44:34.740, Speaker A: Talked about ecosystem being a really focus here. How many people are dedicated to the ecosystem development right now at the foundation?
06:44:35.400 - 06:45:10.210, Speaker B: So that's about 50 people, but it's rapid, 50 people. Some of them are like yeah, not just like EF, but then we need to involve them in this discussion. Then we have to bling someone in between people. I think that's the right way. So I don't have the number, but around 50.
06:45:10.740 - 06:45:32.810, Speaker A: That makes a lot of sense. That's great. Actually a really good number, which means we got a lot of more things done. I want to talk about a handful of initiatives you've helped sort of kick off with the time, while your time at the EF One project is the. Next Billion. Could you tell us more about what that project is and why everybody should care about it?
06:45:33.260 - 06:46:20.484, Speaker B: Yes. So the team Next Billions started last year. But that was something I cared and I think it's more like last year I thought, okay, this makes sense. This is not just my passion, this is good for Ethereum. And then when you look at the current state of Ethereum, ethereum has made tremendous achievement on the technology and the existence and scaling. But I think it's time to think about who would benefit most next or actually when this is going to be used. And then more builders are going to build who will be next, builders or users.
06:46:20.484 - 06:47:06.870, Speaker B: And then you can understand what I was thinking. The term Next Billion, I didn't create it, but it's not really probably widely recognized. It means people in developing countries because they represent that next 1 billion. The current world population is 7.7 billion or so. And then at least three, four of the next 1 billion would be from developing countries. And we know that the reason why I think it's important to look at Next Billion is not just for the numbers, but again, like, Ethereum has overcome a lot of technical challenges for the platform.
06:47:06.870 - 06:47:58.432, Speaker B: I do think implementation is going to be a bigger challenge, like the challenges around implementation. And when you implement a new system, you want to focus on implementing the new system instead of having to take down old systems. So there's a huge advantage in the regions that do not have established old systems. And also, as always say, people from Next Billion are creative. I don't say the others are not creative. It's more like they have to be creative just to live sometimes. So the constant blame training has given them potential to build something very creative.
06:47:58.432 - 06:49:23.100, Speaker B: And then we've been already seeing it. And then from that team, that program we started this year is the EF Fellowship program. And then basically, the idea is to work with selected change makers who can kind of show this kind of like being an example of what I just said, and then show an example not just for them to finish a project in their country, but that example could be copied or be kind of relearned by the rest of the work. So we picked those examples and I've been kind of advocating their work, trying to speak. Whenever I get a chance to talk at an event, I include them, I talk about them. So one fellow is truly from the team or city, and then he's working basically what they call GovTech or Latin American government. They're supporting technologies for public sectors.
06:49:23.100 - 06:50:21.360, Speaker B: It's not just governments. But the reason why he came up with it is because he wanted to fix a lot of things around him in his life. And he realized that in order to fix that, the system needed to be changed. And some of the systems are of course run by public sectors and you can of course create public goods without existing public sectors. But there is some, I call it actually natural sandbox that Latin American countries have. They don't really officially created it but somehow it became like a natural sandbox because they have flexible minded policies or maybe they don't even have policies around anything yet. So it's been interesting.
06:50:21.360 - 06:51:38.888, Speaker B: It's happening like really right now. I joined a talk last week or two weeks ago for the Columbia government was kind of like organized it and then there is a lot of excitement. I mean we already see that in the news of different countries. Some of them just decided to use crypto for their business or for other things, but not beyond that. There are a lot of things it's actually using ATM for the system, for the documentation and ID and all that and so you're going to hear more exciting things coming up from the region and of like we picked Colombia for there and then there are other ferros are all great. And then again, this is not really for one project to make progress. I really want the rest of the world to learn from it and we are actually looking for the next cohort.
06:51:38.888 - 06:52:09.264, Speaker B: This was the first piloting year and we have four members in the first Cohort and we are recruiting the next year's Cohort. So if you know any meaningful projects or teams or even like ideas from the emerging economies, please do let us know or shop at me. And then yeah, we are currently recruiting.
06:52:09.392 - 06:52:31.870, Speaker A: That's awesome. We'll share that as a global and for everybody watching it right now live, hopefully you also reach out to I as well. I kind of just realized that The Infinite Garden also is the name of a documentary on Ethereum that's being filmed right now is the EF or are you involved with that documentary or could you tell us a bit more about that?
06:52:32.560 - 06:54:05.512, Speaker B: Yeah, so that was also speaking of really Infinite Garden, how things, everything happens organically. This was also interesting. How it happened is I recognize the new challenge for the community to keep the vision why Ethereum is going. When you have newer people, it's hard for them to understand because especially when you can't really understand what's special about Ethereum just by reading the white paper and then you do know that very well. And then I wondered what was the best way to describe what Ethereum is when it is not just about the tech. And around the same time we met the documentary team optimist through our friend Morgan and then the idea of Ethereum described in the documentary sounded more natural because you do need to tell stories to fully understand and you need to also show people around. So I spoke with the team or we spoke with the team and it's not like we are going to do this more like they already have an idea and then wanting to create documentary about item and then they understood our culture pretty well from the beginning.
06:54:05.512 - 06:55:20.230, Speaker B: So I said yes to be part of it and then did. But even if Vitalik and myself are being part of it, this is supposed to be about the community. So it's been evolving naturally. You see our faces in their description, but we're just really tiny part of it. And then they've been talking to committee members naturally and then they just decided to do the fundraising with NFT also this wasn't really planned from the beginning and I was asking them how are you going to fund the film? Because that was also important for me to make decision, for us to make the decision and then they're like oh, we don't really have so and then that was the best way for the Ethereal documentary to be funded. And then we were not really digital, they just did the NFT fundraising supported by Mirror. EF was not part of it, but that is the beauty of it.
06:55:20.230 - 06:56:00.176, Speaker B: And the director Zach told me normally main investors would have control over the creative decisions. So I thought that was wonderful, that NFT can give freedom to artistic direction. And then how this happened naturally was also amazing. So I'm excited about it, but we don't know how the story goes. And then they keep running, they keep meeting different people in the community, so it'll be surprised for me too, and very excited about it.
06:56:00.358 - 06:56:24.970, Speaker A: That's awesome. Yeah. I think all of us are eager to see what the final story is that comes out, what they think represents the cream ecosystem. Getting a little bit serious here. What has surprised you the most over the last three years of being the executive director at the foundation? So.
06:56:28.140 - 06:58:18.696, Speaker B: Almost all of them. I had many heart attacks, but I thought I already had it because I've been in the crypto industry for a while. But great positive surprises too. But I think the one thing is before working on execution, it was surprisingly hard just to figure out who the hell EF is and how the ecosystem should be. And I kept wondering why is it so difficult? I couldn't really describe in a very smart way in the beginning, but now looking back, I think it was right to take time and I shouldn't have been able to explain it. So that was probably the biggest supplies, how this was really hard to or there was no manual to learn from and then I still feel that way, but now I have more people to discuss together with and then yeah, it is very interesting and exciting, but I just realized that we are dealing with live creature. So I used to be a teacher and I was in education and when you deal with human being or growing kid or a teenager, you can't really just decide, make the decision or the list of goals very fixed.
06:58:18.696 - 06:59:31.652, Speaker B: You have to constantly flexibly, reshape or change your mindset yourself too. So that was surprised that this is actually very similar to my oldest work in education and then also the rise of like I'm just mentioning it because this is recent, but this is not the only thing. But how something like NFT, which has been there for a long time, what happened is it's always out of your control or my control or our control supplies are supposed to happen and I'm pretty sure I will hear something surprising tomorrow. When I look at the list of the news in the Ethereum every week, I'm always amazed and sometimes like oh.
06:59:31.706 - 06:59:35.472, Speaker A: Wow, this is garden is just becoming a jungle.
06:59:35.536 - 06:59:44.650, Speaker B: Yes, it is jungle. Yeah. It's a good thing, but it's hard to keep up with.
06:59:45.500 - 07:00:07.570, Speaker A: Absolutely. You initially touched on this thing where you obviously joined three years ago and you had a plan and kind of spent all this time understanding in the direction that the EF should move in. What has been working well with the plan that you've had and how would you kind of say things are going?
07:00:11.940 - 07:01:25.016, Speaker B: The very perfectionist Japanese side of me would never be able to say anything is working well. But again, I believe we are doing something no one has ever done before. If we try to do it in the right way, it's not just a nonprofit foundation, it's a lot more than that. Like foundation meaning just giving grants to everyone else. So again, like, you know, like it took a while to figure out what this is about and then what we are supposed to do. Actually, last year when I joined, I felt everything was thrown at us. Like the EF almost like oh, we have to do everything and then always we prioritize ethereum, right? That's what we are supposed to do.
07:01:25.016 - 07:02:38.130, Speaker B: We don't really work for the EF. We more like the EF works for the best of the Ethereum. But last year I realized that, okay, there are a lot of improvements we need to do at the organization. It's more like when you're not healthy, you can't really support others. So I created a team to do the organizational improvements, meaning they also have to do a lot of things. We don't really have a lot of people, but hey, let's just actually do sprint planning every week to make even little progress on everything because we tend to prioritize ethereum and ethereum keeps growing and we just never have time to look at us and then how we do things or things like HL and how we actually take care of our people. So last year, two years after I joined but why don't we just not prioritize that compared to the rest of the things, it's more like hey, let's make progress every week.
07:02:38.130 - 07:03:55.560, Speaker B: So there is a dedicated team now. So we are making little progress little by little thanks to the team members there. And then gradually we are able to actually see ourselves with better views and then understand, oh, this is how we should describe this is what we care, this is how we should explain to the new people today, yet what we really care. Instead of like trusting everyone to understand everything without explaining so things like onboarding, so we are making good progress. And then again, someone like Josh, he is an excellent project manager. I don't know, he keeps getting things done and is still smiling, never looking exhausted. So I'm like, I'm always impressed with so we are making progress thanks to great people like Josh.
07:03:55.560 - 07:04:00.520, Speaker B: And then again, that's still ongoing.
07:04:01.820 - 07:04:17.730, Speaker A: I think where you finish a little bit of structure is not a bad thing. And if anything that's helping you move faster into prioritizing everything that you want to do for the Ethereum ecosystem. Maybe on that same note, what is not going well?
07:04:19.540 - 07:05:15.040, Speaker B: Yeah, well, a lot of things were not going well and then we tried to change that and then we are making efforts and then again we are making progress. I would say still finding the right balance. Still people expect EF to do more or a lot. And then internally there is also tendency, okay, we should do this, we should do this to add more. And then yeah, we do need to add more to help more. But finding the right balance and then really helping people to understand we do need to seek the balance. Like we thinking about, okay, if we start doing this, how long are we going to do this? And then we can't do this forever kind of thinking.
07:05:15.040 - 07:05:58.768, Speaker B: So that is a challenge. But also now we feel ready to make more progress and redesign things. Hiring is not easy. And to be honest, I don't know if it's not working better. It's more like we have to get better at hiring people, especially at EF ecodev type of operations. And I explained the coordination and supporting support work outside of dev and researchers. Finding talented people itself is always of course not easy.
07:05:58.768 - 07:07:26.670, Speaker B: But finding those who are aligned with our principles or have potential to be aligned with our principles, that is really hard. And again, EF is a nonprofit organization, but it's not easy. Especially weirdly when the market is doing well. That's my honest a lot of choices. Yeah, finding mission based people, I'm pretty sure those people exist there, right? But we get more noises and then we need to screen more than the harder wintertime, I would say. And then also the times, especially since last year is we used to actually rely on the places like Ethrobot hackathons or those events because those are the place we can actually see how people are interacting with others and then kind of like easier to find or you can't really see that in the resume and things. So that is a big challenge since the COVID started.
07:07:26.670 - 07:07:41.276, Speaker B: Yeah. So if anyone knows the great creative ways to find people and also, for example, ESP is hiring the lead supporting.
07:07:41.308 - 07:07:52.870, Speaker A: Grants and research or want to help with the foundation, yes, you can get in touch with me or Aya, and we'll be happy to get you to the right person to learn more about that.
07:07:53.320 - 07:07:55.380, Speaker B: Yes. Thank you, Karik.
07:07:56.600 - 07:08:10.250, Speaker A: All right, so I know we've talked about the past and the present a lot, but I want to ask one final question and we can wrap it up. What can we expect and look forward to from the Ethereum Foundation in 2022?
07:08:12.480 - 07:09:02.180, Speaker B: Yeah, I mean the technical side and research side probably have been already described by Danny and vitalik enough outside of again, like we are redesigning things so you will see more, maybe better description of what we are doing. And we are working on improving our website and things like that related to sharing our vision and our principles and our ways in a better way. And other than that, you will hear, I can't say this today, announcement related to DevCon very soon. I know everyone is waiting for it. Something extra. I hope this will be a good surprise.
07:09:02.260 - 07:09:04.604, Speaker A: I don't know, maybe if I say.
07:09:04.642 - 07:10:26.976, Speaker B: This and then again, EF fellowship program is recruiting the new Cohort and you will hear a lot of progress that the current Cohort members has been making. It is very inspiring. Yes, things like client diversity, well, diversity in general that we do care and I do care too. And then not just like a regional diversity for the ecosystem, but also there are a lot of efforts that are being made for client diversity and you will hear more of the efforts in that. Yeah, we hope to share a lot of positive things and as EF we will try to share more information. This has been kind of since last year, this has been kind of like a heads down, working on improvements and everything. So hopefully we can share more that work efforts and outcome.
07:10:27.168 - 07:11:05.856, Speaker A: That's amazing. I think from our perspective, we do notice the change and the velocity and communication that's been happening, keeping everybody informed so I can say it's working well. Aya, thank you so much for this amazing chat. We do have a couple more slides I want to go through. I think it'll be great for you to stick around for that for a second. But to summarize, everybody looks like there's a lot coming in the next twelve months. We got each two, we got efforts around client diversity and of course what everybody is probably more excited about is the next defcon and whatever this new announcement is.
07:11:05.856 - 07:11:20.890, Speaker A: So I hope we get to learn more about that and the dates soon. But I really appreciate this and thanks for everybody who stuck around and watched the rest of the summit with us. Thank you so much.
07:11:21.580 - 07:11:23.828, Speaker B: Thank you, everyone. Thank you, Kartik.
07:11:24.004 - 07:12:20.964, Speaker A: All right, so before we end this, I want to take a quick second to just thank everybody here on what an amazing past four years it's been. eGlobal started on the 15 October in 2017 where we did our very first hackathon called Eat Waterloo. It may feel like forever now, but a little thing called NFTs were invented there four years ago, and we're finally coming back and seeing how long it takes for something like this or just in general technologies to kind of propagate and get excited and be used in new and creative ways. So it's been an incredible past four years. These are some of the stats we pulled for this. We have over 100,000 hours of content that's been watched from the talks and workshops and interviews we've done at our events. We've had over 30,000 people been onboarded.
07:12:20.964 - 07:13:31.920, Speaker A: We have seen over 3500 projects been created in this space since we started, and we've given out $3 million in prizes that have been given out to the attendees with nothing in return for all their amazing work and getting them excited about what's possible with Web Three. On top of that, it's not just this. We have some other tangibles people have formed a lot of companies from these projects. We've seen over $200 million raised by companies formed from ETH Global hackathons, which currently represent over $4 billion in market cap. Hundreds of jobs and opportunities have been formed, and on top of that, thousands of friendships that there's no way we can measure, but we know that we ourselves are the beneficiaries of these incredible things. So I want to thank everybody here for being part of our community, and it's super excited to wake up and work on all these amazing events and summits and talks and helping everybody sort of learn and get more excited about Web Three like we do. So I want to thank everybody one more time, and with that, we are at a close for ETH Online, which has been our biggest event in our history.
07:13:31.920 - 07:14:02.070, Speaker A: So thank you so much, everybody who participated in the summits, the hackathon, the talks, the questions, and I wish you all a happy Friday, and we'll see you in a couple of weeks for our next hackathon, which is Unicode. So we'll see you all on Discord and ETHGlobal TV and Twitter and every other place on the Internet. In the meantime, hope you enjoy your weekend, and we'll see all of you shortly and enjoy some lo fi beats. Thanks, everybody.

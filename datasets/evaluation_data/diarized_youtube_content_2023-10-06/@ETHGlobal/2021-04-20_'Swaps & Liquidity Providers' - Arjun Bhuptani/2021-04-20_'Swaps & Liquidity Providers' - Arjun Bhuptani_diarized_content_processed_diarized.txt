00:00:00.330 - 00:00:24.160, Speaker A: Up next we have Arjun Bhuptani, the CEO of Kinex. Really excited to hear more about what Kinex has been doing. And another little bear market tidbit. Kinex has been around for several years doing state channel research. Started off by receiving a grant from the Ethereum Foundation for some state channel work with SpankChain and now Pivoting to vector Payments. Really excited to see the progress you guys have made.
00:00:25.370 - 00:00:37.774, Speaker B: Awesome. Yeah. Thanks so much. Eva. I guess let me start by sharing. Cool. This talk is called Cross Chain Swaps and Liquidity Providers.
00:00:37.774 - 00:01:43.710, Speaker B: I missed the providers here. But the idea behind this is that I want to cover kind of a little bit about the ideas behind why Connect exists and what it means for as we go into this layer two ecosystem of this new layer two world and give a little bit of an overview of how Connects works and then also where we're planning to go. So I think the first kind of core thesis that we started with was that ethereum layer twos need interoperability. This means a lot of things. So of course there's layer two exits fast layer two exits fast optimism exits that Bartech just talked about. But then we're also seeing that there's a big need for just broader L two to L two communications. And the core idea behind this is that especially with Ethereum gas fees increasing kind of exponentially over the course of the last few months, we've seen that users kind of want to treat ETH layer one as like lava.
00:01:43.710 - 00:02:49.714, Speaker B: If they can avoid having to go through ethereum layer one at all, then that ends up being like a ten x experience for them. And not having access to that kind of brings about the same sort of minimum liquidity or minimum value requirements that currently exist on ethereum layer one itself. So, for instance, pricing out users who don't have tens of thousands or hundreds of thousands of dollars in order to make large and expensive trades on uniswap, those same users now end up having to deal with the same problem. Even if they're on a solution like Polygon and trying to get to another solution like Arbitrum, they have to deal with the same problems. Unless you have native layer two to layer two interoperability and we're seeing that this is becoming ever more necessary. So when we started talking about layer two interoperability last year, it was a really controversial topic. I think the philosophy at the time was that people would be moving to a single layer two ecosystem and that there wouldn't be this plurality of different solutions out there on the market.
00:02:49.714 - 00:03:47.538, Speaker B: And even if there were, over time everyone would just aggregate to one thing. What we're seeing though is that that's not really the case. We have a diverse set of service providers providing different layer two solutions and then also D five projects and other kind of key players in the ecosystem going to different solutions as time goes on. So we've seen in the last two months every single D Five project that's out there, pretty much every single DeFi project has announced some sort of multi chain strategy. And this begs the question of how do you deal with cases where users have funds on one system and want to get to another system and ideally do that again in a way where they're not having to deal with significant layer one gas fees and the one week exit window. So there's a bunch that's out there on Interoperability and on Ethereum fast on layer two fast exits. And so here I'm just going to try to give the highest and broadest level overview around what it means to communicate between different blockchains.
00:03:47.538 - 00:04:54.534, Speaker B: So there's three general approaches that people have seen so far and everything that's out there kind of falls into one of these three approaches. There's native cross chain validation. Basically, the idea here is that the virtual machine of one chain natively validates the virtual machine of another chain. This is hard to do because it typically either requires you to have custom chain implementations or it's extremely expensive. So for instance, roll ups fall into this category where you have ethereum validating a lot of the roll up state and either that's happening through fraud proofs or validity proofs with CK roll ups. And the native validation aspect of this is kind of what keeps rollups trustless a mental model for a roll up is that it's also just kind of like a POA side chain, but it has a trustless bridge. And I think that's a key part of it because fundamentally, when you think about it that way, that means that the entirety of this layer two problem really comes down to how can you build trustless bridges? Now? What does it mean to have this kind of validation? Luckily, native crosschain validation is trustless.
00:04:54.534 - 00:06:02.110, Speaker B: It's entirely trustless and it's about as trustless and generalized as you can possibly get. And that's what makes roll up so powerful and that's also what makes things like IBC so powerful. However, there's sort of this trade off space then around the amount of time that it takes to make updates and the amount of amount that it costs. So if you have purpose built chains that are designed to be communicating with each other this way, or at least one of the two systems is purpose built, like with the roll up, then the cost is not super high. I mean, it's still somewhat high in the sense that you have to keep publishing roll up blocks because you need data availability, but it's not like you're paying thousands or millions of dollars in order to submit transactions between chains, which is unfortunately what ends up happening in the case of things like the Neo Rainbow bridge. However, on the flip side of that, you also have exit windows for things like Optimistic roll ups. And so in those cases, you have this one week exit where you have to where you could do things like Bakerdough suggested, where you provide liquidity for the exit, or you have cases like ZK Roll Ups where you can do that in a single block.
00:06:02.110 - 00:06:54.286, Speaker B: Now the other two approaches are a little bit different because they're kind of exist in a slightly different paradigm where you're not having to have these native systems that are purpose built to be interoperating with each other. Instead, POS and one on one swaps are both mechanisms that can be used against existing chains. So things like side chains, even other non ethereum layer ones. So examples of POS and MPC bridges are THORChain ren as Bartek just talked about, like MakerDAO's optimism, exits kind of fall into this broader category and like the polygon POS bridge. And the core idea behind this is that there's some third party validator set and that acts as an oracle. And that third party validator set has some mechanism to keep them trust minimized. So there's some economic bonding mechanism that reduces the trust on this party, on this set of party.
00:06:54.286 - 00:07:44.426, Speaker B: Now of course the idea is if you're going for maximal trust minimization where you are defaulting to ethereum's trust model which basically means ethereum's economic security. Having a POS MPC model means that you are diluting that economic security. You do have a secondary mechanism like a secondary economic backstop. In the case of Maker, it's basically the MKR token that is used as like the Oracle backstop. In the case of THORChain, it's Rune, et cetera, et cetera, et cetera. Now, depending on the mechanisms, the cost is usually low to medium and it's usually anywhere between slow to fast. And there's like a lot of variety here because this is sort of like the broadest category where you can have a lot of variability in how people implement solutions.
00:07:44.426 - 00:08:28.970, Speaker B: And then the last approach is a one to one swap model. So the core idea here is take this end party consensus system or this end party oracle problem and turn it into a one to one system. And the cool thing with one to one systems is that both people have skin in the game and because both people have skin in the game, you could kind of expect them to always behave in a way that's economically rational for them. They're not ever going to behave in a way where they're losing their own funds and if they do, then it's only their funds that are on the line. And this includes constructions like atomic swaps. It includes what we're doing, it connects with channels. But the idea here is it is trust minimized in the same way that native cross chain validation is trust minimized because it just inherits the core properties of the base chain.
00:08:28.970 - 00:09:43.240, Speaker B: Now of course there are downsides to this as well and I'll kind of talk about those as we go on so how does Kinex work at the highest possible level? What we are is just a regular old state channel network. And with any kind of regular state channel network you have a set of liquidity providers. These are state channel nodes, we call them routers that basically front the liquidity in a receiving side channel in order to get a payment in ascending side channel. And all we do is we extend this model across chains. So, basically, if Alice wants to send funds from Arbitrum to Optimism, so say she wants to send ETH from Arbitrum to Optimism, what she would do is send a payment in a state channel in ETH to a liquidity provider to a kinext router. And the connects router would send a corresponding payment in a state channel back to Alice. Because we're using channels here, we can make sure that those two interactions are atomic and that enforces the fact that there's no way for the router to kind of steal Alice's funds and there's no way for this whole cycle to not complete once the router has actually initiated the process of completing this transfer.
00:09:43.240 - 00:10:31.334, Speaker B: Now there's definitely a lot of nuance to this. This is again the highest possible overview, the highest level possible level overview I could give. But there's a few key design principles that we've baked into this that we feel really strongly about as part of our core assumptions. So first of all, we think it's really important to utilize the security of the underlying chain. And the reason that this is important is because we don't quite know what mechanisms are going to be used for ethereum layer two solutions in the future. Right now we see roll ups as the most dominant mechanism for a very secure model for layer two. But there's also downsides to roll ups that people that I think are not really discussed often enough.
00:10:31.334 - 00:11:36.780, Speaker B: And those downsides are things that I think people will start to see once we start to get roll ups live around the actual absolute scalability of a roll up model versus other models that don't necessarily post constantly to chain. And this is kind of like the core idea behind ZK rollis versus ZK Porter that I think Alex from Zksync is talking about. And either he might have already talked about or he's talking about. So our goal is to say, okay, well, we don't necessarily know what mechanisms are going to be used to bridge between these different chains on the base layer, quote unquote. But we do know that whatever mechanism is used, you do always need this ability to allow for fast, cheap swaps between different assets and kind of going back to this model. The good thing about that philosophy is that that means we can work in tandem with existing POS MPC bridges and existing native cross chain validation models. Because the fundamental assumption with our one to one swap model is that an asset already exists for us to swap into, right? There's no way for us to do what we're doing with Connects unless you already have liquidity on the receiver side.
00:11:36.780 - 00:12:50.034, Speaker B: Second, this is kind of building off of the same core idea don't create lots and lots of representative assets. So Bartek was talking about how there's this problem that is going to show up with optimism. And we've already started to see with XDI where every single new person that builds a mint and burn bridge into XDI or into another chain ends up creating new representative assets which are not really fungible against one another and you can trade them against one another, but this just increases the complexity of these assets massively. I had this problem myself yesterday when I was trying to swap where I ended up giving liquidity for Aave on polygon and I ended up with Amusdc, and I tried to swap it for something else on Quickswap. And it turned out that Quickswap only has liquidity for ma USDC, which is actually the liquidity that you put into Aave in USDC on ethereum and then bridge to matic rather than the other way around bridge to matic and then put into Aave. So there's just like a huge user experience mess there that we are currently barreling towards that I think folks really have not been aware enough of yet. And then the last idea is kind of one that I've touched on already, which is don't incur those layer one costs between when moving assets from layer two to layer two.
00:12:50.034 - 00:13:49.038, Speaker B: We've had a number of users come up to us and say, hey, I had $40 or $50 on this chain that I had pretty much just given up on in dust as dust, because I didn't think that there was any way for me to get it out of XDI or polygon or whatever and get it into another system that's unreasonable. Like $50 is a lot of money for a lot of people in the world and we shouldn't be pricing people out in that way. So is it working? Yes. We've seen that this model doesn't just work, it actually scales pretty well. It's incredibly capital efficient because we're actually netting off liquidity going in different directions. So you can have swaps that are going from a lot of this is like BSc to polygon interactions. We have a lot of swaps that are going from BSE to polygon because people are onboarding to polygon and then a lot of swaps going in the other direction because people are trying to exit into Fiat.
00:13:49.038 - 00:14:27.586, Speaker B: And all of this $4.3 million in volume is actually happening on about, I think about $4 million of this volume is happening on about 250K in liquidity, which is insane. That's an incredible capital efficiency. And you can also see very clearly the point where the DeFi apes discovered that this was a model that works and it's incredibly cheap because that's where we eight X our payment volume. Now, this model doesn't really exist without its own drawbacks. And there's a couple of things that we're working on in the kind of like short to medium term that we think really need to happen in order for us to keep scaling this up. Because if it keeps going up in this direction, we're going to keep running into problems.
00:14:27.586 - 00:15:08.862, Speaker B: The first thing is automating router rebalancing. So the biggest kind of user experience hurdle that we're dealing with right now is that you have these routers holding liquidity pools on each chain. And then a user, similar to what Bartek was talking about, where users come and do larger transfers, a user comes and does a larger transfer, pushes all of liquidity to one side and now nobody else can do transfers. A part of that is solved by just having deeper, more liquidity depth. But ideally, what we want to do is create an incentive for people to come and rebalance this thing for us. And that way we or whatever, whoever the router operator is, isn't actually having to do this themselves all the time because that's expensive and it's a pain. And then second of all, there's decentralizing scaling of liquidity itself.
00:15:08.862 - 00:16:19.122, Speaker B: So how can we have more routers in the system and aggregate liquidity across all these routers? So something that we're starting to explore now is the concept called Virtual AMM. We all kind of understand the AMM model, which is let's take the price between two different assets or perhaps even potentially many different assets in liquidity pools and bond that to a pricing curve. For Uniswap, that pricing curve is like a constant product function for stable swap. It's a more complex equation that optimizes for stable one to one assets and things like that. And the core idea behind this and what makes this really powerful is that the price between these assets moves as a function of the available liquidity within the system. And because this price moves, you now have this incentive that gets created for other people to come and arbitrage this thing if that price doesn't actually reflect the true price of the asset in the market. So for instance, if I go and I swap one ETH for one maker not one ETH for one maker, but if I go and swap some ETH for maker on uniswap and I basically end up putting more liquidity of ETH into the ETH pool and I reduce some of the liquidity in the Maker pool.
00:16:19.122 - 00:17:10.790, Speaker B: That will change the price between ETH and Maker on. You know, say Bob is a person who is watching this interaction and has liquidity in maker and he sees that the coinbase price of maker is actually lower or higher than the price that is available on uniswap. He now has the ability to go and arbitrage it. And I think this is one of the things that makes uniswap so powerful is that it's just so easy to arm. I think we can take the same kind of concept and apply it to these routers. And we're calling this virtual AMMS because it's not like these are like actual AMM contracts on chain. It's just that we are bonding the swap rates that the router provides between assets in this assets on Arbitrum for assets on optimism, and we're bonding that swap rate to, again, another AMM curve.
00:17:10.790 - 00:18:38.622, Speaker B: Now, the cool thing is here we're doing the same thing that we're doing with Unisoft, where over time, as you continue sending like ETH on Arbitrum to ETH on optimism, this actually changes the price between these two assets. And that difference in price reflects the available liquidity on those systems, which again, incentivizes somebody to come and push liquidity in the opposite direction. The cool thing is that because we're not actually taking control of the rebalancing mechanism ourselves, we're just incentivizing that somebody comes and rebalances this thing. That means the ways that we have to rebalance this thing, the ways that other people can come and rebalance this thing, are dependent upon not just the existing Bridging mechanisms like roll up exits and entries, but also on other liquidity that you can find through OTC trades, through swapping, through Fiat. And I think the idea behind this is that even if in the case of something like Binance Chain where the Binance bridge ends up being taken down, there is actually a really interesting mechanism where people can still continue doing virtually uncensorable swaps between in and out of Binance Chain because they can continue arbing through the Binance Exchange or through OTC. Now of course, the swap rate might be awful, but hypothetically this ends up being a lot harder to censor. The second aspect of this and this kind of gets into how do we scale this thing up and make it available to a lot more people a lot more quickly, is aggregating liquidity across a bunch of different routers.
00:18:38.622 - 00:19:30.814, Speaker B: We call this route auctions. So the core idea behind this is that when Alice wants to send liquidity from Arbitrum to optimism in ETH, she doesn't really care that much which router she's routed over or sometimes which several routers she's routed over. All she really needs to do is broadcast the network saying that this is the entry liquidity that she wants and this is the exit liquidity that she wants. And the cool thing is that over time, what we can do is have many, many different routers providing this kind of liquidity in the same way that you have many different liquidity providers on Uniswap or on any other AMM system. And Alice can be routed over one or many of them concurrently. If we put this together with the virtual AMM model. What's really interesting about this is that Alice has an incentive once she kind of hears back from all of these routers who are willing to supply this liquidity, she has an incentive to always pick the cheapest one.
00:19:30.814 - 00:20:23.220, Speaker B: And that's always going to be the router that is the most unbalanced. So you end up creating this really interesting economic flywheel where over time, through the combination of these route auctions where Alice is broadcasting to the entire network saying, hey, I want to swap X for Y, and routers returning saying, okay, I'm willing to provide that liquidity for X amount of dollars. And the combination of that and then also the fact that these routers are pricing their liquidity based on an Mm curve means that Alice is always going to end up in a position where she is actually de facto rebalancing somebody else's liquidity. So you have this really cool flywheel where the network sort of starts to rebalance itself over time. Now, of course, there's still space for arbitrage, and that's still an important role within the network. But the idea is that over time, you can end up with a system where you don't really need so much ARB anymore. You just have this very, very efficient mechanism for targeting where the liquidity is most needed.
00:20:23.220 - 00:21:15.780, Speaker B: There's still a lot of really interesting stuff here. It's a big open space that we're exploring. We absolutely would love to get people involved in building on top of us. So if you're interested in getting involved, you can build on us by checking out our hacker kit. It's at Connect network scalingeath. And then you can also hit us up on Discord in order to start participating in some of these open research questions that we have around like virtual AMMS, penalizing disbehavior, route auctions and a lot of other things that we're working on in the future that we think can help make this into a very interesting mechanism for communicating directly between different layer two ecosystems and also to layer one. Our mental model for Connect is sort of like this cross chain clearing hub that sits on top of any of the chains within the Ethereum layer Two ecosystem and allows you to kind of net off volume between them.
00:21:15.780 - 00:21:25.270, Speaker B: Cool. Thank you all for coming to my talk, and I hope you all have a good rest of your scaling ethereum. Awesome.
00:21:25.340 - 00:21:32.186, Speaker A: Thank you so much. Arjun, it looks like we might have a few minutes. Do you have a minute to maybe answer a few questions?
00:21:32.368 - 00:21:33.500, Speaker B: Yeah, absolutely.
00:21:34.670 - 00:21:42.750, Speaker A: Awesome. The first one I have is how are you thinking about Connects and vector payments in regards to E Two and the transition?
00:21:43.810 - 00:22:30.730, Speaker B: Yeah, there's obviously a lot of open design questions around East Two right now where I think the current model of E Two is that shards are basically going to be like data availability layers for roll ups. And in that model, the idea of having many different roll ups actually only becomes more powerful. So what our philosophy is that with East Two, we're only going to see a dramatic acceleration of the trends that we're already seeing where people are moving to a bunch of different ecosystems and you're going to be fragmenting across these ecosystems. It kind of sucks because obviously fragmentation means poor user experience. But also that is sort of the definition of decentralization, right? Decentralization isn't always going to be the easiest path.
00:22:32.290 - 00:22:49.170, Speaker A: Yeah, for sure. And one last question, maybe. What are you most excited about now that we're finally at this place, several years after doing so much research? Now the DFI apps, NFT apps can actually start using these L2 solutions. So what are you most excited about as we move into production?
00:22:49.910 - 00:23:55.320, Speaker B: Yeah, that's a really good question. I'm sure a lot of the other L2 researchers will like, I'm sure they feel the same way, but it sort of feels like a catharsis moment where there's been so much uncertainty for so many years around what layer two will look like and how it will work. And we've gone through so many iterations that have just not worked, and that's both within Channels also with things like Plasma and now roll ups. And of course, there's still a lot of open questions that will have to be solved, especially once users start using this stuff, because as we've seen with Channels, users end up just breaking your shit all the time and there's nothing that you could do about it. And that's just how user testing works. But I think what I'm most excited about is to kind of get to this next step where we actually have some of these things that we've been talking about for years actually start to come to reality, and we can think about what comes afterwards because we've been stuck on these problems for so long that we haven't been able to progress past them yet.
00:23:56.010 - 00:24:00.920, Speaker A: Right, yeah. Looking forward to it and what Scaled Ethereum will look like.
00:24:01.690 - 00:24:05.430, Speaker B: Yeah, hopefully we can have a scaled Ethereum. East global conference.
00:24:06.090 - 00:24:07.160, Speaker A: Yeah, exactly.
00:24:07.610 - 00:24:08.406, Speaker B: Awesome.
00:24:08.588 - 00:24:10.666, Speaker A: Thank you so much for joining us, Regen.
00:24:10.778 - 00:24:12.220, Speaker B: Awesome. Thank you so much for having me.

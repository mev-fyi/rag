00:00:00.330 - 00:00:13.390, Speaker A: Excited to intro our next talk and that is Carl. Carl's going to be talking about the optimistic virtual machine, the OVM. And Carl's from Optimism. And without further ado, I'll let Carl kick off with his talk. Hey, Carl.
00:00:13.890 - 00:00:58.526, Speaker B: Why hello. How's it going y'all? Very exciting. This has been looking forward to the scaling Ethereum hackathon, the the best topic for a hackathon possible for a so, hello, I am Carl. I'm going to talk to you about just optimistic Ethereum, a quick overview and the future and a scalability deep dive, aka, what do we really mean by scalability? So let's get started. Let me actually turn on a clock. There we go. So let's dive in.
00:00:58.526 - 00:01:18.866, Speaker B: If this is what you think scalability is, this is incorrect. If this is what you think scalability is, this is incorrect. Scalability. The transaction fees are way too high, thankfully. I have been talking about this for a long time and people seem to get the picture now, so that's really nice. 15 seconds, 15 minutes. These are all way too slow.
00:01:18.866 - 00:02:05.710, Speaker B: We need super quick, super quick transactions with low fees. It is unacceptable. But let me go back a little bit, a little big time travel and talk about who I am. What's Optimism PBC and how did we really get here? So I actually started out working at Consensus for a little bit. Then I kind of traveled around the world with Vitalik and talked on some stairs, know, ranted like I'm doing now. And know, had a little introduction to cryptocurrencies and worked on this crypto economics book with Jing and told my friend, oh, you should really get into crypto. And they got really depressed because he was my last friend who wasn't into crypto.
00:02:05.710 - 00:02:36.542, Speaker B: And then my friends got me out of that depression. Thank goodness. We formed Plasma Group with Kelvin and we were like, oh, can plasma scale Uniswap? No, it cannot. And so we worked on this thing called optimistic rollup and we created Unipig and we created this new thing called Optimism. And Synthetics was like, oh, Unipig was pretty cool. Let me take a then, you know, Mark joined and Krista joined and Josh joined and Annie and Liam and Gigamesh and it's a big happy, explosive family. So that is amazing.
00:02:36.542 - 00:03:16.570, Speaker B: And the optimistic Ethereum family is growing bigger and bigger and this talk is going to be all about community, it's going to be all about Ethereum. But before we get into all that, let's go into a little bit of technical stuff. Little bit of technical right here. And then we got after the technical stuff, we got some design principles which is less technical, and then we'll go into the rest. So what is optimistic Ethereum? It's a minimal addition to Ethereum that enables an EVM based layer to roll up. But what does that really mean? Basically, it's just ethereum inside of ethereum. So very technical work coming in.
00:03:16.570 - 00:03:28.618, Speaker B: We got ethereum. It's the l one right? That's the base layer. And then we got optimistic Ethereum, which is L two. And it's in ethereum. Wow. Very crazy. It's a little recursive.
00:03:28.618 - 00:04:10.630, Speaker B: And before you ask, yes, in fact, you can do L three and put optimistic Ethereum inside mystic Ethereum. But let's dive in. Okay, so how does this work? Okay, first, you all can take a look at a bunch of presentations that Ben and Kelvin did yesterday. And we've got a bunch of presentations on this. So I'm not going to actually take too much time, but optimistic Rope is the optimistic Ethereum is a combination of optimistic Rope and the OVM. And optimistic Rope gives us security and the OVM gives us EVM expressibility. And so I'm going to give you a 1 minute presentation.
00:04:10.630 - 00:04:24.714, Speaker B: One minutes, of course, for what exactly that means. All right? Three, two, one, go. Let's see how I do. Okay, optimistic roll up. We've got the security portion. So Ethereum is processing all these transactions. It's a tired doge.
00:04:24.714 - 00:04:42.598, Speaker B: It's doing too much work. And so then bumping on optimistic Ethereum comes in. Don't fear, let me help you do some transaction processing. And then it goes bad. And then the Verifiers prove fraud. And then it goes well, and Ethereum is happy and a happy doge success. Okay, so that's how optimistic rollup works.
00:04:42.598 - 00:04:53.622, Speaker B: Vin eyes. And this is how the OVM works. So normally, you have smart contracts. They talk to each other. But we need to put EVM inside of EVM. We need to put Ethereum inside of Ethereum. That means we need container virtualization.
00:04:53.622 - 00:05:12.814, Speaker B: Boom. So we take the OVM. The OVM. Is this container virtualized EVM? We can run it inside of the EVM. So now we're diverting calls to the container contract, this virtualizer contract, and all of the stateful operations, they go through that. That's how we maintain a sandbox. And that's how this thing works.
00:05:12.814 - 00:05:29.350, Speaker B: It's kind of similar to the diamond pattern and stateless execution. Bam. That was actually 1 minute. I did just record it. So very good. So optimistic roll up, right? For the fraud proofs OVM is for the container virtualization. It's to give us EVM inside of an EVM.
00:05:29.350 - 00:06:07.490, Speaker B: That's optimistic ethereum. But what is optimistic Ethereum really like? What is the essence of this project? Because technology is only one aspect of the puzzle. So the optimistic Ethereum design principles, two of them that I'm going to talk about today are incrementalism and minimalism. So incrementalism, it's really fun to say things like, oh, we've solved scalability. Oh, there's this big breakthrough. Wow. And the world explodes, right? I said those things, in fact, many times.
00:06:07.490 - 00:07:33.786, Speaker B: And it's fun to an extent, but in reality, progress looks a lot more like this, right? We're like slowly carrying building up the kind of global intelligence of the human species, right? And it's been getting built for a long time. So we're little tiny cogs in that greater machine. And that is really what things are like. And so there's a real scalability solution in ethereum that doesn't get talked about nearly enough and that is geth that's open ethereum, that's turbogeth that's these incredible researchers that's these people that for instance, in the past few years we've increased the scalability of ethereum over two x, right? Like the scalability is not something that just kind of comes out of the blue. It is based on a huge amount of work from a lot, a lot of different people, including research that is being implemented as EIPS, like changing the gas prices of various Opcodes or introducing access lists or the most cutting edge research like things like vertical tries for stateless clients. This is the stuff that really gets us scale and tooling, right? We've got a ton of incredible tooling in the ethereum ecosystem, tons of folks working on it. And that is required if you're trying to build a production piece of software, you need production level tooling.
00:07:33.786 - 00:08:22.266, Speaker B: And so all of this stuff is built on open source software and public goods. And it's so exciting to be able to work and build technology that utilizes all of this different tooling. And so that is what we're trying to do with optimistic ethereum, right? We're trying to build on top of that software and kind of fit in like a puzzle piece. That means that we must support the OVM, I mean the EVM. That means that we can implement this incredible research that's being done and we can make use of the implementations of that research that are built for ETH One. It allows us and of course open source everything that goes without saying. It's like we can be a test bed for ETH one point x.
00:08:22.266 - 00:08:57.938, Speaker B: And so the other thing that I want to talk about is minimalism. So a wise sage named George once said that every line of code costs $100. So you better not write a lot of lines of code because it's expensive. So really what this process is, it's really just this surgical precision that you need to have when you're, for instance, upgrading geth to be optimistic death, right? You need to minimize your diff. You need to minimize the lines changed. And the reason why is because we're standing on the shoulders of giants. This is a kind of weird photo, but it's standing on the shoulders of giants.
00:08:57.938 - 00:09:37.382, Speaker B: And so that goes for the protocol itself. We can't diverge from ethereum too far because the further we diverge, the less we can kind of make use of this incredible ecosystem, right? We're trying to maximize our leverage, maximize our impact. And to do that, we need to make use of all of the technology that has been built before and also all of the tooling that's been built before. We have to fit in like a puzzle piece and be that test bed for e .1 point x that I talked about. So those are some of the main design principles. The other one is got to be love, got to give love, got to be nice to each other.
00:09:37.382 - 00:10:01.370, Speaker B: So anyway, that's that okay. So next we got the path forward. This is a kind of overview of where we're headed. And then we're going to, after that, talk about this whole kind of deep dive into scalability. It's a little more technical then, but before we get into the technical stuff, let's stay at a high level. So we're currently on pseudo main net. We've saved folks over $10 million.
00:10:01.370 - 00:10:26.478, Speaker B: It's pretty cool, pretty sweet. And we came up with a few names for these releases. I'm going to talk about a bunch of releases and these are subject to change. But the first release is inconspicuous, medium sized animal. This is the mascot for this incredible release. And we need to go to full mainnet next. And the thing that will take us there is improving our upgradability infrastructure.
00:10:26.478 - 00:10:46.826, Speaker B: So I was actually planning on talking about that in this talk, but I ran out of time. So the upgradability is a future talk coming up. There's just too much to talk about on this other stuff. So anyway, the code name chalk marker, this is our full main net. And so the reason why is because we write on Windows with chalk markers. Chalk markers are great. You should buy them.
00:10:46.826 - 00:11:17.234, Speaker B: They're great to write on Windows. So our full four releases categories that I have here are chalk Marker, then Irritated Window Cleaner, and then Poor airbnb rating. And finally, the final finale ultimate release is iPhone four. So for each one of these releases, there's various things and we'll go over each one. So first Chalk Marker, we've got instant upgrades. We've got arbitrary contract deployment. So arbitrary contract deployment, that's good.
00:11:17.234 - 00:11:53.386, Speaker B: But we've got no slashing and we've got a single sequencer with OVM self upgrades. So what does this really mean? It means that we've got these guardrails right. We're definitely not at the decentralized end goal that we want to be in, where we know that there are things that are fundamentally broken about how the protocol works. This would not be sustainable long term, but it gives us the flexibility to actually iterate on and try out the software that we are building. No eggs were harmed. The next step, we're getting better. We're closer to the decentralized utopia with delayed upgrades.
00:11:53.386 - 00:12:23.530, Speaker B: So instead of being able to instantly upgrade the contracts, they're delayed. And we've got slashing and we've got a single sequencer and we've got some simple compression for data availability optimizations. And so we're getting there, but we're still a single sequencer, we're still running it. And that we definitely do not want to be doing that soon, as soon as humanly possible. Then the next one is poor airbnb rating. So now we're really decentralized. We got super delayed upgrades, multi sequencer.
00:12:23.530 - 00:13:03.286, Speaker B: We're starting to mess around with speculative execution for scalability purposes. We've got pluggable compression and some fun stuff with gas limit rating using an EIP 1559 curve. Anyway, all of this stuff. But there's one fundamental thing that we're missing and that is e two. And so finally the kind of nirvana iPhone four is we've got e two shard Blob transaction feed. So in other words, we can use the e two shards for our data availability. That means that we can scale up to use all of the availability, all of the kind of availability that is provided by you two.
00:13:03.286 - 00:13:42.750, Speaker B: And we're actually going to talk about what that really means very soon. And we've got some other fun stuff like optim upgrade support that allows you to kind of fork the chain arbitrarily and concealed transactions and Zkevm, all these fun things. So this is the kind of high level progression, right? Starting out centralized, more flexible. We have to have upgrades throughout this entire process and then we get more and more decentralized one thing at a time until we are fully integrated into ethereum and decentralized. So that is the path forward. Okay, so we did design principles. We got the roadmap.
00:13:42.750 - 00:14:23.258, Speaker B: Now we're going to go back into some technical stuff because there is I can't help myself. I can't help myself. I'm going to talk about technical stuff no matter where I am. And this is one technical question that has come up so many times. It is what is scalability? Like when people say scalability, okay, it means something goes up. But do we actually talk about what is that thing that's going up? Is it transactions per second? What does it mean to increase your, quote, transactions per second? That doesn't actually give you a picture, a vivid image of what the blockchain infrastructure needs to be. So let's talk about that.
00:14:23.258 - 00:15:07.262, Speaker B: When you have a scalability problem, that means that you are constrained, you are resource constrained, meaning that you need to increase the supply of a resource. So there are three blockchain resources and I'm going to claim that this is essentially universal across blockchains. And all of the designs of blockchains that you will see have these three components and you'll probably hear about it in different words. Everyone uses different vocabulary to express the same thing. But here I'm going to talk about it as availability, compute and storage. Those are the three blockchain resources. And so we're going to actually use an analogy to get a little bit more of a vivid image of what this means.
00:15:07.262 - 00:15:54.586, Speaker B: So note, I have no idea what a water processing plant is but I'm going to use it anywhere because it felt about right. I just like vaguely remember from biology class or something. Okay, so we have got this availability. It's the pipes. It's the pipe going into the flagellation basin and the flagellation basin is the kind of compute, right? We're doing something, we're churning up the water and then it's going into the storage container, the kind of water cooler looking thing that holds all of this water. And this water is like the trusted computation that fuels humanity, right? Just like we have water, we need trust. We need trust in our computation and we need to build a universal trusted computation layer for humanity.
00:15:54.586 - 00:16:25.222, Speaker B: That is the goal. We need this system. It is one amazing machine and we can get there. So, availability, let's actually dive in a little deeper. What does availability mean? Well, messages are propagated throughout the network on these blockchain systems and we come to consensus on what the next block is. And so availability is essentially how much data you can come to consensus on over one period of time. So the more the better.
00:16:25.222 - 00:17:01.026, Speaker B: Obviously, the bigger the pipes. And we're measuring this in bytes per second. So the more bytes you can come to consensus on, say these bytes are in the blockchain, the better. And then you've got compute and that's the Flotulation basin. And essentially what that is, it's how much math you can do and trust that that math is computed correctly. And so it's like your smart contracts, how many executions of your smart contract can you do and how many cross contract calls and all of that kind of stuff and how many state routes can you produce. And so essentially, in some ways, it's just like how much you can do.
00:17:01.026 - 00:17:24.460, Speaker B: X times y equals k over and over again. If you don't get that, ask your neighbor. So we're going to measure this in gas per second. Now, notably, gas per second is not really quite right for reasons that you'll kind of see later on. But we can think of this as more like the gas of pure opcodes per second that we can do and form consensus on the result of. So that is our computation. Pretty simple.
00:17:24.460 - 00:17:42.526, Speaker B: Finally, storage. This is a little different from the first two. Storage is how much we can actually store in a single node. So this is measured in bytes. It's actually a fixed quantity. It's not a kind of quantity over time, like a rate of change. Instead, this is just a cap.
00:17:42.526 - 00:18:01.906, Speaker B: And currently we're at like 70GB, maybe it's 80GB, maybe it's 90GB. I'm always out of the loop about this. It just keeps growing and changing. But whatever, maybe it's at 60. Anyway, so s store and create it's for all the things that you store in the blockchain state. I call it storage, but it's really in the blockchain state only. It's not the history, it's the storage.
00:18:01.906 - 00:18:44.082, Speaker B: So for instance, if it were to grow to 200GB or something like that, then nodes might start falling off of the network and have to be replaced with nodes that are run in data centers. And this decreases decentralization and is not good, especially for layer one. We need to keep the state low and we need to make the computational requirements of running a layer one node as low as possible. And notably, this resource actually, the state actually always grows, basically. I mean, technically you can reduce it, but almost no one does it. And so it's always growing. And so even without changing anything, our blockchain Ethereum is fundamentally flawed because it will explode at some point.
00:18:44.082 - 00:19:18.730, Speaker B: This water basin will just burst because there's just going to be too much state in the chain. And this is a ticking time bomb that literally is something that we need to essentially save Ethereum from soon. And we're going to talk about that. That's some stateless client work. But anyway, if we want to support all of humanity on this thing, unfortunately we can't in this current state of affairs, right? Like, look at this thing. It's tiny and there's nothing in this water basin that will this water cooler is just going to fill up. So we need to increase these pipes.
00:19:18.730 - 00:20:04.062, Speaker B: We need to also increase the computational power, put some workers in there, and then we also need a drainage system that drains everything. And this would be the ideal blockchain, but let's kind of go into a more mathematical kind of abstract representation of this stuff. So we've got three resources availability, compute, and storage. Let's not talk about, well, first, the availability and the compute. There's technically an unlimited supply if you gave it an infinite time frame, but it's more constrained by the rate of growth. But in the storage case, it's cap supply. So let's just kind of ignore the cap supply for now.
00:20:04.062 - 00:20:35.270, Speaker B: That's a little bit of a different topic and I'll talk about it soon. But let's talk about scalability in ETH One. So both the availability and compute of ETH One are limited by the gas limit. So what does that mean? That means that as the availability usage increases, the compute usage has to decrease proportionally. And similarly, if the availability usage decreases, the compute can increase. That's basically. Like you can send a transaction and you can either send a huge transaction or you can send a small transaction that does a bunch of computation.
00:20:35.270 - 00:21:10.562, Speaker B: Both of them affect the gas limit. So the gas limit is 12 million. And if you used all of it for the availability, you get about 70 available data. So the pipes are kind of 70GB or 70 my gosh, it's way smaller than those two first things. Or if you spend it all on compute, you'll get about 800,000 gas per second. So now let's take a look at not just ETH One, but let's look at optimistic ETH One. This is ETH One and optimistic ethereum kind of running side by side.
00:21:10.562 - 00:21:57.982, Speaker B: So boom, boom, boom. We got this other optimistic compute. So the ETH One gas limit is 12 million. Let's say the OETH gas limit, for the sake of this example is also 12 million. And so now we've got equal usage across all of these different resource constraints. But notably you can increase the availability or the compute of ETH one without affecting the gas usage or the gas resource consumption of optimistic compute. Right? The optimistic Ethereum, you can spend all of your money on availability, all of your resources sorry, on availability and you can then also spend all of your resources on the optimistic compute.
00:21:57.982 - 00:22:43.950, Speaker B: And so this is actually fundamentally just how you are actually able to scale up the total resource constraints of Ethereum. So we've achieved more scale. That's really exciting, but let's keep going. So notably, this gas limit, this 12 million gas limit, death has been increasing this over time. It has been an incredible amount of work by a bunch of folks. And not just death, but I mean, all of the Ethereum clients have been increasing it over time and in fact could increase it even further. And in fact some folks have been experimenting with in practice using things like 140,000,000 gas limits, which is just kind of mind boggling and does give you a ten x performance and it's technically possible, but it doesn't come free necessarily.
00:22:43.950 - 00:23:18.380, Speaker B: It does require increasing the full node requirements. And so that means that instead of this node, you need that a node of this size, you need that size. And actually in layer two it can be okay because you can increase the full node requirements without affecting consensus. And I have another talk about that, but you can't increase it infinitely. This is not a perfect solution. And storage the state bloat problem becomes way worse, right? Because you're bloating up the state really quickly, you're going to burst sooner and it's just as simple as that. But don't fear, the Ethereum community is here.
00:23:18.380 - 00:23:56.774, Speaker B: This has been a problem for the Ethereum community since the early days and this is why we are building on Ethereum. So the great thing is Berkele tries, I'm very excited by this. This is combined with stateless clients. So in order to provide the release valve on the water cooler, you can actually create stateless clients and that will essentially drain the water. It allows nodes to throw away old state. That's why it's called stateless. Instead of holding on to all of the state, you're throwing a bunch of it away.
00:23:56.774 - 00:24:45.094, Speaker B: And so that allows the storage to not grow over time. It's just draining the water, it's just deleting the stuff from the state. Technically you can revive it, but you have to prove that it was in the state in the first place. But notably, this actually also has implications on full node requirement increases. So normally you compute your blockchain doing single threaded work, you go just one block at a time. But if you provide all of the witness data for all of the blocks, then you can actually, as an Ethereum node, compute the validity of each block independently of one another and just compute it all in parallel. And that gives you definitely a huge scalability increase just by utilizing more threads on your computer.
00:24:45.094 - 00:25:29.202, Speaker B: And that's pretty cool. That's a really interesting synergy that doesn't actually come with a lot more complexity on top of the stateless client design. And we're building stateless clients in ethereum, in optimistic Ethereum, we can be the test bed for Ethereum one point X. And so even crazier you can go full ZKE EVM, improve all of the block's validity up front and that scales logarithmically with the amount of computation that's even Crazier. And that's the final boss. But this is how you can actually address these problems. And with those things addressed, you can make the optimistic ethereum gas limit huge, absolutely massive.
00:25:29.202 - 00:25:57.450, Speaker B: And we've gotten more scale, but now bump it on availability is the bottleneck. And so guess what? Optimistic e two. Well, ETH Two is here to solve the availability bottleneck. For phase one, we don't worry about compute, we only care about availability. And that's literally what E two does. It just scales up the availability by using random sampling and erasure encoding for the consensus on the future blocks. So it's pretty sweet.
00:25:57.450 - 00:26:32.166, Speaker B: And so now you can combine this massive amount of availability with this massive amount of optimistic compute and they scale independently of one another, just like on ETH one. And boom, we can max it all out and we can reach scalability in nirvana. This is what we mean when we say scalability. This is scalability. It is a big set of pipes with a big fluctuation basin going into a big tank of water and that tank of water is being drained by the stateless clients. And we are happy and clams. We are happy, happy clams.
00:26:32.166 - 00:26:45.374, Speaker B: You can almost see the blocks in there. You can almost see the blocks. And so that's ethereum, that's optimistic ethereum. That's the combination of the two. It's great. So I appreciate you all and thank you. And the time's up.
00:26:45.374 - 00:27:08.740, Speaker B: Let's do this. Okay, I will do one. Shout out. Shout out to this amazing thing. If you want to work on a crazy experimental EIP that is called virtual call, reach out, let me know specifically if you want to work on some geth code because it is, it is extremely cool. Anyway, that's it. Thank you.

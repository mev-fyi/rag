00:00:00.170 - 00:00:53.214, Speaker A: Just as a reminder, we've got some bounties for this weekend, so we're giving out $5,000.03. So it's $1,000 for each winner. And three of them are for best New subgraph, and two of them are for best new App built on the graph. And I'll kind of explain what exactly that means. So so the graph is a protocol for indexing and then querying data for web3. So that would be from blockchains or like, storage networks. And the problem that we solve is that as soon as you start building an app on a blockchain like Ethereum, you quickly realize that you kind of can't just rely on getting the data directly from that blockchain, from like an Ethereum node, for example.
00:00:53.214 - 00:01:29.770, Speaker A: And the issue is usually if you want to put something up on a screen, you need to filter to just find specific data. Usually you need to kind of transform that data ahead of time. And so you end up doing a lot of filtering stuff on the client and that really slows your app down. And so there's this kind of like missing indexing layer that allows you to just run queries like you're used to when you're building an application. And so that's where we come in. So today there's kind of two ways that you can try to solve this problem yourself. And most teams have done one of these two.
00:01:29.770 - 00:02:39.962, Speaker A: So either you build a custom proprietary indexing server and this is what actually most teams probably do, where it's just a bunch of custom code that's like talking to an Ethereum node, stuffs the data in a database and then serves it up over an API. And that's really fragile because everyone's doing this kind of processing work differently. There's no way to really have consensus. And if people are building applications on top, there's no way for me to know if you did that computation correctly. The other way you can try to do this is to just load everything on the client and then filter locally on the client. And if you do that, you can kind of keep it decentralized, but you end up waiting a very long time for that data to sync. So at the graph, we're building this protocol for having a network of nodes that can index that data for you, but it's pushed off to the network, so you don't have to do all of the indexing client side, but we're kind of doing this in stages.
00:02:39.962 - 00:03:12.860, Speaker A: And so we open source our graph node implementation july of last year. And then in January, we launched a hosted service where we run a bunch of these indexing nodes for you, and then we're going to be launching our decentralized network as a next step. So let me kind of walk you through first. The graph explorer. So who here has seen this? Sweet. Okay, cool. So then I'll walk you guys through it.
00:03:12.860 - 00:04:25.568, Speaker A: So this is where you can see all the data that's kind of being indexed on our hosted service. How does that work? He's like, I've seen whatever desert that is. How do I? Oh, yeah, mirror. Cool. Thank you for that. Okay, so this is where you can see the data that's being indexed on our hosted service. And so these are what we call subgraphs, and they define how to index the data and make it available over GraphQL.
00:04:25.568 - 00:04:58.552, Speaker A: Who here knows about GraphQL? Okay, most of you. So GraphQL is Query language from Facebook. That's kind of a replacement for Rest. And it's just a really nice, easy, convenient way to fetch data from a server. So here we're looking at the Moloch subgraph. Molok is a dao for funding Ethereum infrastructure. And you can browse kind of the domain model here, right? So this is the schema.
00:04:58.552 - 00:05:21.796, Speaker A: So you can see that there are votes and proposals. So a proposal has this information. It's got applicants, for example, token, tributes. These all have types. And then you can traverse across. So see the applicants, et cetera. So you define the schema up front here's all my objects here's, how they relate to each other.
00:05:21.796 - 00:06:02.604, Speaker A: And then you can query using GraphQL, where here, for example, we're getting the first five votes for each vote. We want to display the members and the proposals. And for the members, we're asking for the ID shares and for the proposals there. And you can see the response perfectly. Kind of matches what we asked for. Now, one good trick we should have a little thing that calls this out to you is you can hit CTRL space in here and you'll get a drop down with the different kind of fields that are available. And then you can query and you can seamlessly traverse these relationships.
00:06:02.604 - 00:06:54.640, Speaker A: So, for example, Peepeeth, I think, is a really cool one. So they have like a contract on Ethereum, and then they've got a bunch of the data is on IPFS, but this is basically like a Twitter kind of thing where these tweets or peeps are stored on IPFS. And we index all of that data. So you can see like, a peep has this content references an account, and the account has all of this info. So you can query for the peeps and then get the account, like name and avatar URL, for example. And then you could easily build a Twitter client that gets all of the data like this through the Graph. So let's take a look at what it takes to build one of these subgraphs.
00:06:54.640 - 00:07:35.010, Speaker A: Okay, so step one for everybody, if you're interested in building on the Graph this weekend, is go to our website and join the discord. So it's the graph.com discord. There's a link on the right discord. Drop in there and jump into the hackathons channel and say hello. And if you have any questions, we'll be there all weekend and we can help you as you're going along your second biggest friend is the docs. So from the website you can click on Docs and we've got a really great tutorial and it'll define everything.
00:07:35.010 - 00:08:55.124, Speaker A: And so this is pretty comprehensive and should get you most of the way there. But the first thing I want to do from here when you want to get started is you'll sign in and I should probably do this with sign in. So you sign in with GitHub and we piggyback on GitHub for permissions basically for teams because there's a lot of teams that use the graph. So basically if you're an admin of your on GitHub then basically you can deploy these subgraphs under your organization name. So here you can see the accounts for each of these subgraphs are basically it's like your GitHub info and so we pick it back on the permissions for that. Then you can check out your dashboard and this has like subgraphs that you've created and this is where you get your access token. You'll need this when you deploy your subgraph from the CLI and you can start by creating a subgraph just through the UI.
00:08:55.124 - 00:10:29.808, Speaker A: So you come here and give it a name subtitle which shows up in the card. So my awesome subgraph and then subtitle here and then your card will show up in the community subgraphs with the others and then the next thing you do is actually you can create that, it'll show up and then you can go build your subgraph. So what is a subgraph? If you follow the examples or the kind of quick start in the docs, we have these really good CLI tools. So you just install graph CLI and then you can use that to graph init which will create like a scaffold for you. And if you already have a contract that's deployed either to a test net or on main net, you can do from I don't think we have it in here, but we'll actually I don't know. There's like a blog. Post, I think, where we have this, but it's from contract and then you can give it a contract address and it'll just scaffold one for you that basically brings in all of the events and then indexes them.
00:10:29.808 - 00:11:17.480, Speaker A: So that's just like an easy way to kind of get started. But then you end up with a directory that kind of looks like this. And the first thing to look at is this subgraph YAML file. This is kind of the entry point and this is where you define your data sources. So probably you have an ethereum contract and you can point to the specific address. So this could be on main net or it could be on one of the testnets rinkabee covan you can also run this locally with Ganache. So we've got some getting started guides that will walk you through having like a local development environment using Docker compose.
00:11:17.480 - 00:11:57.524, Speaker A: If you're going to be working on your contracts locally. You can do that as well. Then you basically specify these event handlers and these handlers are going to get called anytime one of these events are triggered. And then you can process that data at ingestion time and that data will get indexed. I'm going to walk you through that part and then I'll open it up for questions because I'm going through a lot of stuff. But this is the GraphQL schema. So this defines the shape of your data.
00:11:57.524 - 00:12:39.760, Speaker A: And this is actually like a really great place to start as well. Even before the manifest, if you're just thinking through basically what would the perfect API be for consuming whatever I'm building. This is where you're defining the domain model for your application. And so you want this to really just represent your app as best as possible. So this is the Moloch example where there's proposals, votes, applicants. So you set this up and then this is how people will be able to query for this data using GraphQL. And then the last piece is the mappings.
00:12:39.760 - 00:13:56.008, Speaker A: So this is how you specify how to transform the data at ingestion time. So you got an event and then you want to process it somehow and basically store these entities into our store abstraction and then that's where they get indexed. So these mappings are written in a language called assembly script, which looks and feels just like TypeScript, but it's strongly typed so that it can compile to WASM. And that way we can transform the data in a deterministic way, which we think is really important. So from these mapping handlers, you have access to the event data, the transaction data, the block data, and the smart contract state as of that block. And then you can do arbitrary kind of logic on that and then save that data into the store. So one thing that's really cool is I highly recommend that you get something like a Visual Studio code, which has strong TypeScript support.
00:13:56.008 - 00:14:52.300, Speaker A: And when you build your subgraph and then there's like a build step, we auto generate all of these types for you. So you can write these handlers with autocomplete and type safety. So, for example, here I want to handle this proposed event, and on the event I can see that I have access to the block and the transaction data, so I can see what's on the transaction. So I can get that, or you could get the params for the event and then we'll decode the name. So if the event has named parameters, you can see what those are called. So this is how you get data from the event transaction block. And these things that you're creating, these entities are like objects that you're saving to the store.
00:14:52.300 - 00:15:27.624, Speaker A: These are also auto generated for you from the GraphQL schema. So here you'll have this directory that's generated for you that has all of these entities that are just the types that you define in your GraphQL schema. And so you can just create these objects, you put them in the store and they're indexed. Okay, that was a lot. So let me open it up for questions. How much of that made sense? Raise your hand if you followed. Awesome.
00:15:27.624 - 00:15:28.760, Speaker A: Sweet.
00:15:30.060 - 00:15:41.644, Speaker B: We're live, we're here. Can you tell us more about the event? Is it more for like real time applications where you want to process?
00:15:41.842 - 00:16:11.712, Speaker A: Yeah, so this is all real time. We react really quickly to new blocks getting mined. Basically, as soon as the transaction gets included in a block, the graph node will pick it up and process the handler if your event was emitted. And then that becomes available immediately. Yeah.
00:16:11.846 - 00:16:30.132, Speaker B: So in this scenario maybe I missed it. So this for example, would be a DAP and then I want to handle data more intelligent way, my DAP. So we deploy it to my web application and community came to the graph in real time based on that and just be able to process it in a smaller way.
00:16:30.206 - 00:17:21.820, Speaker A: Yeah, exactly. Really? I mean, 90% of DApps probably have a server that's running that's actually doing this kind of thing. And because you can't really do it directly on Ethereum, you can try to use web3 JS, which in a hackathon you can kind of get away with it because there's not a lot of data. But if there's like ten transactions that have only ever happened on this contract, you'll be fine. But if you have hundreds or thousands of transactions, suddenly you have to load them up, load all the logs to then filter and then transform things on the client. So it really doesn't scale. Anyone who's building on Ethereum should probably be using the graph to index that data so that you can just query what you need from your applications.
00:17:21.820 - 00:18:08.320, Speaker A: Did you mention I did, I didn't go into a lot of detail, but yeah, that init tool which is described in the docs, if you just do the quick start in the docs, it'll walk you through using like graph init and it'll scaffold that for you so you don't have to start it from scratch. So that's why here I'm keeping it a little more conceptual to make sure everyone knows how to use it. The init tool just creates the scaffold. And then there's these build tools. So you do like a yarn build which is calling like GraphQL to TypeScript or JavaScript.
00:18:08.900 - 00:18:11.040, Speaker B: Is that what you mean by scaffolding?
00:18:11.460 - 00:19:19.704, Speaker A: No, by scaffolding I mean it's just creating these example files for you. So it'll create like an example manifest file, an example GraphQL file, and an example mapping TypeScript file with just like an empty function just as a starting point. And then when you run yarn build, if you look at the package JSON, so these are like if you're familiar with kind of JavaScript tooling, you can just run like yarn build and that actually runs graph build and then you can also use it to deploy so you can say yarn deploy. And this one, I pointed it to this URL, but it'll actually come set up to deploy to the hosted service. So you can just deploy it and then while it's deploying, you'll see it like syncing in the Explorer. So let's see, this was just updated, but this was just created. Oh, cool.
00:19:19.704 - 00:20:10.810, Speaker A: People are probably already starting to create stuff. Most of them are fast, sometimes they can take a little bit longer. This might yeah, people are doing a lot of like active development. We're running two hackathons concurrently. So if if for any reason your subgraph fails after you deployed, probably because there was like a bug in the handler, you can click on the logs here and you can see basically all the activities. So this would show you every time an event was triggered, what handler it tried to call, and then you can basically just see that and then you can filter on errors if there's an error. And this is how you can see why that would have happened.
00:20:10.810 - 00:21:00.818, Speaker A: Yeah. Sorry. No. Yeah. So this is just public endpoints. Oh yes, good question. So does everyone here know how to build UIs with React? Or there's maybe different UI libraries of choice? If you're using React, we highly recommend Apollo, and if you go to our GitHub, there's a ETH Denver DAP example, which is a really good kind of example, DAP for building a front end that uses GraphQL.
00:21:00.818 - 00:22:25.568, Speaker A: And so this uses Apollo as the kind of client library and you basically just pass in a GraphQL endpoint into Apollo and it integrates nicely with React and it'll hit your GraphQL endpoint for fetching that data. So yeah, these are just public endpoints. So there's an Http endpoint that you can use for queries and then a WebSocket endpoints that you can use for subscriptions. So we actually handle like live queries where if you just use the word subscription at the beginning of the query in GraphQL, that makes it a subscription and then you'll get push updates over WebSockets whenever the result set changes. No, for the time being we don't have any rate limiting. I mean we have like DDoS kind of protection, but other than that it's all just there. Now at some point in the future we're going to add a pay tier where it's just kind of to cover the cost of the servers and we're going to be experimenting with basically like gas costing because essentially this is going to be running on a network of nodes and those nodes need to be compensated for the compute that they're doing.
00:22:25.568 - 00:22:34.420, Speaker A: And so there's going to be like a gas kind of costing model, but for now it's all just we don't have too many limitations.
00:22:35.880 - 00:22:37.332, Speaker B: Can you talk a little bit about.
00:22:37.386 - 00:23:19.460, Speaker A: The actual nodes you have postgres? Yeah, so if y'all are interested you can go to our GitHub. The main repo is graph node. It's written in rust. And yeah, we use postgres under the hood as the database. It's kind of an implementation detail. We kind of, like, reserve the right to change the database in the future, but you just access it through the store abstraction, and then we use it. When you run the queries.
00:23:19.460 - 00:23:23.060, Speaker A: What specifically are you curious about?
00:23:23.210 - 00:23:25.076, Speaker B: How do you use IPFS here?
00:23:25.258 - 00:25:11.480, Speaker A: So what we use IPFS for is what we use it as the protocol for is we store these subgraphs on IPFS. So what happens is when you build and then deploy, what you're actually doing is you guys have two minutes, okay? What you're actually doing is we take the manifest and we upload all of the constituent files to IPFS, and then we take the manifest itself, we replace the links with the IPFS hashes, and then we upload that to IPFS, and then we get back the hash of the manifest. And that's like a unique content hash that uniquely identifies your subgraph so that's the subgraph ID. So anyone could basically get this file and it would give them everything that they need to index the subgraph. So that's how we use IPFS. And then you can also use IPFS if you have data that's on IPFS, in order to access it, you just have to make sure that you log it or somehow that IPFS hash is anchored on chain, because right now we only support Ethereum as the root data source. But in response to an event, you can, for example, get an IPFS hash, and then you can cat the data from IPFS and then access that from your mapping handlers.
00:25:11.480 - 00:25:42.904, Speaker A: Yeah, so anytime you make a change, you get a new ID back, and then you can deploy updated versions. And so we support kind of versioning. Yeah, it's the IPFS. Hash. Exactly. One more thing I should mention is Jorge, our engineer back there, just recently added call and transaction trigger. So this is a cool new feature.
00:25:42.904 - 00:25:59.760, Speaker A: Before, you could only trigger on events, and now you can also trigger anytime a smart contract function is called that can also be a trigger if you need that cool. All right, I think that's it for time. All right, thanks for dropping. Bye.

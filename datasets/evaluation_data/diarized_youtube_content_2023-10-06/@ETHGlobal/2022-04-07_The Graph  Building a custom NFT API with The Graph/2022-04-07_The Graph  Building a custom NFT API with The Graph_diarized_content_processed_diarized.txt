00:00:00.170 - 00:00:13.150, Speaker A: Shop on behalf of the Graph on building a custom NFT API. With the Graph, questions go into the zoom chat and Nader will address them at the end of the workshop. And with that being said, I will pass the mic off to Nader.
00:00:15.410 - 00:00:57.934, Speaker B: All right, thank you for the intro and really happy to be here. I am been involved with Dows ever since I kind of got into Web Three, maybe a couple of months after that. Since then, we've actually launched a Dow in the last week at the Graph called Advocates Dao. We're working on another dow. I've also helped launch, or did launch developer Dow and participating in Friends of Benefits and interested in a bunch of other ones. So it's cool to be here for the topic of dows, but in particular from the perspective of a developer, what I'm going to be talking about today and presenting a workshop on that you can also take and do at your own pace. Or you can do it like today, or you can do it a week from today, whatever.
00:00:57.934 - 00:01:35.722, Speaker B: The content is open source and you can pick it up at any time. But I'm going to be building an API on top of a Smart contract. And a lot of Dows, including developer Dow, are kind of built on an NFT or an ERC 20 contract. So I think the example that I'm going to give today will hopefully be a good example for people that are thinking about building out user interfaces or applications that interact with the data from their Dow smart contracts. So that's what we're going to be doing today. We're going to be building an API on top of an NFT Smart contract and it's quite a bit of code that we're going to be going through. So I'm going to be kind of going through it fairly quickly.
00:01:35.722 - 00:02:24.170, Speaker B: But I've done my best in this workshop to create a piece of content that allows anyone to kind of take this completely end to end without having to worry about messing up anything because all of the code is copy and paste. So anything that I'm doing here, it should be very well documented in this workshop. So feel free to try to follow along. But also consider that if you do not want to follow along in the a sense of building this yourself, you might just follow along and watch me build this. Maybe check out the code and stuff in the workshop and then try to build this on your own at a later time. So, with that being said, I'm going to go ahead and share the link to the workshop here. The main two things within this workshop are just the README itself.
00:02:24.170 - 00:02:56.370, Speaker B: So the README is like a step by step guide for you to use and be able to build what we're building. And let me go ahead and share my screen to kind of like, take a look at this. So this is the GitHub repo. It's GitHub.com Dabbit three. It's the very first project that should show up in my repositories custom NFT subgraph workshop and I also pasted the link there. But the two main things to think about here, this README file is really just a tutorial kind of.
00:02:56.370 - 00:03:50.322, Speaker B: And then the code base that we're going to be building is linked here. There's no need to actually clone this because if you want to be successful here, you might actually want to build this from scratch. So what we're going to be doing is doing just that building from scratch. And the NFT smart contract that we're going to be working with is the crypto coven smart contract. So if I go ahead and click there, you'll see that on Ether scan we have the crypto coven smart contract and we see that we can link to the actual contract code and we're going to be kind of referencing this a little bit in this workshop. And then the last thing that I'll point out is that most well actually I think almost all, if not all ERC 721 contracts are written fairly consistently. They have mostly the same functionality and one of the functions that you'll often see is a base Uri, or I'm sorry, a function called get base Uri.
00:03:50.322 - 00:04:35.842, Speaker B: And this kind of returns the base Uri for the IPFS metadata. And this is something that we're going to be working with in particular here with the crypto coven smart contract. So if you want to get the metadata off of almost any NFT, you can usually go copy this IPFS hash and go to IPFS or any IPFS gateway, paste in the hash and then paste in the number of the token. Often it ends with JSON. And then here if we wait a couple of seconds this should hit the IPFS gateway, retrieve the metadata and then kind of give you an idea about the information that's stored on this token. And once this returns at some point we can kind of take a look at it and get an idea around the metadata that we're going to be working with. So I'll give that a second.
00:04:35.842 - 00:05:24.788, Speaker B: Maybe I'll paste in one that I've retrieved recently that might be cached. So it looks like it's taken a little time for that to come back but we'll come back and look at that in just a moment. But really all this is going to be doing is returning a JSON object and in that JSON it's going to kind of give us information or metadata about the NFT. So it'll be things like what is the image, what is the name, the description, other information about the NFT. So with that being said, we're going to go ahead and start off by going to thegraph.com and if I go to thegraph.com here you're going to see that we have this drop down here with different products.
00:05:24.788 - 00:05:26.870, Speaker B: And if you go here to.
00:05:29.080 - 00:05:29.396, Speaker C: The.
00:05:29.418 - 00:06:02.000, Speaker B: Tutorial, you'll see that we're going to be opening the graph hosted service. So you can either click this link to open it directly, or you can go here and click on hosted service. And this is the service that we're going to be using to build our API. Now the graph has two different types of ways that you can build APIs. One is with the hosted service, which is a centralized service. That was the original iteration of what the graph was. But more recently we've released the decentralized network, which is more of like a web3 way to build out these APIs.
00:06:02.000 - 00:06:39.660, Speaker B: So depending on the features that you would like, you would choose one or the other. But ultimately we're kind of moving towards building everything on the network because we want everything to be decentralized. But as of right now, there are certain features that are not available there. And in particular with IPFS, if you want to interact with an IPFS gateway, you cannot do that from the decentralized network. So therefore, we're using the hosted service. Now to get started, we're going to go and sign in and this will essentially just ask you to authenticate with your GitHub repository. If you're using the decentralized network, it'll just ask you to authenticate with your MetaMask account.
00:06:39.660 - 00:07:27.516, Speaker B: And then once you've signed in either with GitHub or MetaMask, then you can now create your first subgraph. So what I'm going to do is click on my dashboard here and I'm going to click Add Subgraph. And here we're going to kind of give the subgraph a name. So I'll call this ETH Global and then maybe crypto Coven API or something like that. The subgraph name can really be whatever you'd like. And then the subtitle will be an NFT API for the Crypto coven smart Contracts. So with that being said, I'm going to go ahead and click Hide because this way it doesn't show up because I've actually built a couple similar to these.
00:07:27.516 - 00:07:54.628, Speaker B: And since we're doing just a workshop, I don't want this to show up for everyone else to see. And then with that you're going to be given your boilerplate, I guess you could say, or the place that you're going to end up deploying to within the dashboard. So now if I go to my dashboard, I should see that this one shows up here and it says like, not deployed yet. So this is going to be where we deploy in just a moment. Once we write our code, I'm going.
00:07:54.634 - 00:08:00.996, Speaker C: To try to refresh this gateway and I'll give that some time and then.
00:08:01.018 - 00:08:33.420, Speaker B: I'm going to go back here to the workshop. Okay, so we've already done this part. We've gone to the hosted service, we've gone to the dashboard, we've created the subgraph, and now we're ready to start writing some code. So the code that we're going to be writing is going to be done using a boilerplate project. That the CLI will essentially scaffold. And it's really kind of like a starter project that you'll use for almost all of your subgraphs. And a subgraph is essentially like the term that we use for a GraphQL API launched or deployed to the graph.
00:08:33.420 - 00:09:30.650, Speaker B: And to kind of get started, you need the graph CLI to be installed. So you can either use NPM or Yarn and you can just copy this command here and say NPM install G at graph Protocol graph CLI and this will go ahead and install the graph CLI. And then after this is installed, you'll have the graph binary. And then using that binary you can do a bunch of different things. Most importantly to get started, it'll allow you to scaffold out an example project to get started with. All right, so after the graph CLI is installed, you should be able to run graph and see the graph binary is there. And if you want to run Graph Help, it should give you a good idea around some of the commands that are available.
00:09:30.650 - 00:10:13.940, Speaker B: So now that we have the graph binary installed, we can run graph init and this will walk us through and set us up with all the different things that we need to kind of get started. But instead of just running init alone, we can actually pass in a few flags to kind of define a few different properties that we'd like to work with. So I can go down here and I can see that we have a couple of ways, like I mentioned that we can do that. But for us we can go ahead and go to this command here where we're going to say graph init and we're going to pass in the contract from which we're going to be creating and that's going to be this crypto coven contract address. We're going to set the protocol to be Ethereum. We're going to set the network to be Mainnet. We're going to set the contract name to be Token.
00:10:13.940 - 00:10:49.136, Speaker B: And then we're going to pass in this flag called Index Events, which I'll walk through in just a moment. So I'm just going to copy this entire command here and this will go ahead and initialize a subgraph with a few different configurations. Now I mentioned earlier that we're going to be deploying to the hosted service. So I'm going to choose hosted service as opposed to Subgraph studio for the subgraph name. You'll look here and you'll see that I have your username, the API name. And the way that you would get that is it's going to basically just be whatever username you have. So for me it's Dabbit three and there would be this.
00:10:49.136 - 00:11:32.850, Speaker B: So you could just say type that in or you could even go here to the slug and the URL and just copy that because that's going to be the same. So either way you would say your username, the API name and for me that's going to be Dabbits, three Eglobalcryptocove and API. And for the directory to create the subgraph in, this is up to you. This is just going to be the folder name. If I was building a full stack project where I had a front end and a bunch of front end code, I often use the naming convention of just subgraph. That way anyone that comes into my code base knows this is a subgraph as opposed to if it was standalone. But since we are building a standalone project, then I'll just leave it at this name here.
00:11:32.850 - 00:12:23.090, Speaker B: The network that we're going to be indexing is Ethereum Mainnet so I can keep that as the default. The contract address, we pass that in here so I can keep that as the default as well. You'll notice that there's a little checkmark here that says Fetching Abi from Etherscan. So what this is going to do is the CLI is going to go to Etherscan using this contract address and it's going to go find the Abi, which you can also find at the bottom of any contract that has been verified on Etherscan. And this Abi is like something that we're going to need to scaffold out some boilerplate code that is specific to our smart contract. And it's really cool because the CLI actually went ahead and fetched this and saved it locally for us to use. So we don't really have to do that.
00:12:23.090 - 00:13:29.140, Speaker B: For the contract name we're going to use Token because the NFT is a non fungible token. So the name Token just makes a lot of sense but this could really be whatever you would like it to be. So we'll give this a second and what this is going to do is go ahead and create that boilerplate code and while that's doing that, we can go back here to IPFS and we can see that the IPFS gateway, it did indeed return our metadata. So for the crypto coven IPFS hash slash the token, you get all this information. So we have the description, we have the external URL, we have the image, we have the name, we have all this information. So why is this important? Well, it's important because the whole purpose of us building out this API is that we want to store and make queryable information about this smart contract and the information that is pertaining to it. So by default, ERC 721 doesn't give you a whole lot of information.
00:13:29.140 - 00:14:29.006, Speaker B: You'll get stuff like the token ID, you'll get things like the owner, you'll get things like the base Uri, all that stuff. But typically what you end up needing is the metadata that is linked to the combination of the base Uri and the token ID. So therefore what the graph can do is it can basically call out to IPFS and it can read the information that comes back from IPFS like the description, the image and all this other information. And we can actually index that and store it and make it queryable. And hopefully if that doesn't make a lot of sense now, it will once we're done building this thing. So once the subgraph has been scaffolded out, we should be able to go ahead and open this up in our text editor. I'm going to go ahead and open this up in my text editor.
00:14:29.006 - 00:15:06.094, Speaker B: Had to change into that directory. So this is the boilerplate for the subgraph that we're going to be building. So the CLI just generated all this code for us. There are three main pieces of code or I would say three main files that we're going to be working with to define and create the specific code that we're going to need for our API in particular. One of those is the schema GraphQL. This is where we define our data model. So in our case, our data model is going to be a token type.
00:15:06.094 - 00:15:29.746, Speaker B: The token type is going to have different fields that we want to be made available for our application to consume or query. So like I mentioned earlier, that metadata is going to be kind of like important for us. So those are going to be essentially actually fields on our type. So what I can just go ahead and do though to get started, just go ahead and delete all that. So we don't need any of that code. I'm just going to delete everything and save that. So we have the GraphQL schema.
00:15:29.746 - 00:15:58.190, Speaker B: This is going to be our data model. The other file that we're going to work with is the subgraph YAML. This is the main configuration for your subgraph. This defines everything that you need to know about what's going on in your subgraph. This is the main entry point for an indexer that is going to index the data from the network that you're indexing. This is where the indexer looks to understand what's going on in your API. So when you deploy this, it first reads the subgraph YAML.
00:15:58.190 - 00:16:37.294, Speaker B: It then finds information like, oh okay, we're going to be indexing Ethereum mainnet. This is the contract address that we're going to be indexing from. Here. We're going to be going a little bit more into depth in the actual specifics of our own subgraph and things like that. But these top level items could be things like I think we currently support near and we could also say instead of Ethereum mainnet, maybe Ethereum would be more like a placeholder for EVM. So maybe we'll want to also instead index Arbitrum or Polygon or whatever. So you can kind of define all that information here.
00:16:37.294 - 00:17:18.810, Speaker B: You can also have multiple data sources. So here we're only indexing a single contract. But there are so many applications running on the graph that have multiple contracts that are indexed in a single subgraph. So that's just stuff to keep into consideration. So we're going to come back and update this a little bit in just a moment. So those are the first two files we're going to look at and then last we're going to look at the mapping, which is the, I would say business logic for our subgraph. But to get started, let's go back to the GraphQL schema and what we're going to do is go here to our workshop and you're going to see that we have these entities defined in our schema GraphQL.
00:17:18.810 - 00:17:25.422, Speaker B: So the first entity that we're going to define is the token. So I'm just going to copy that code there and paste it here.
00:17:25.476 - 00:17:29.006, Speaker C: So that's this code here and the.
00:17:29.028 - 00:18:00.514, Speaker B: Token entity is going to be the main entity that we're really worried about. For this API, we want to query for tokens. So for the single entity we'll name it Token. But this will also be available for us to query plural of or an array of. We have information like really base information like the ID, the Token ID, the token Uri and things like that. But we also have stuff that is coming off of IPFS. So if I go to IPFS here, you'll see that we have this external URL.
00:18:00.514 - 00:18:31.226, Speaker B: So that points to a centralized it looks like website, like cryptocoven XYZ or maybe this is I don't know if it's centralized, but the idea is that it's not like an IPFS endpoint or something. This is actual URL. We also have information like the image. So I can click on image and you'll see that the image is right there. So all this information is important to us. So what we would like to do is in our data model, define fields for the description, the image and all these things. So that's what we've done here.
00:18:31.226 - 00:19:12.634, Speaker B: We have the external URL, we have the image, we have the name, we have all this information, and we want to make this queryable, meaning that we can hit an API endpoint and we can say, give me all the tokens. And then I might want to do stuff like I want to search for tokens that have a description that matches this. Or I might want to do some full text search that contains this word. Or I might want to say I want to find all of the tokens and all of the owners of those tokens. And this is another thing that's pretty powerful about the graph is that we can do relationships between two different data types. So right now we have this single data type of token. But we're next going to create a type of user.
00:19:12.634 - 00:19:35.400, Speaker B: So we're going to say type user. We're going to give it the entity type. This is important and it's kind of like a directive that's graph specific. And if you tag any type with entity, this means that we're going to be able to index it. And for the user type, we only want two different fields on there. We want the ID of the user. This is going to be their address, this is going to be their Ethereum address in this case.
00:19:35.400 - 00:20:05.978, Speaker B: And then we also want to define a one to many relationship between users and tokens that they own. So this way we can do bi directional queries. We can say we want to get tokens and their users, but we can also say we want to get users and the tokens that they own. So you can kind of query either way. And the way that we make this happen is that we add this at derived from directive. And this is cool because it allows us to easily model relationships between data. So I'm saying derived from the field owner.
00:20:05.978 - 00:20:53.706, Speaker B: This owner is going to essentially be an address. That address is going to allow us to kind of define the relationship between those two items. And the last thing that we want to do is we want to define a full text search field. And this is really powerful because obviously full text search is one of the most powerful features that you often interact with on client side applications. It's just super nice to have. It just makes the flexibility of building UIs just so much better and the experience is a lot better. So with our full text search directive here at Fulltech Search we can define things like what is the entity that we want to make searchable? So in this case, the only entity that we're worried about making searchable is the Token entity.
00:20:53.706 - 00:21:24.358, Speaker B: So we're going to say the entity is Token. The fields is going to be an array of fields within that token. So for us we're going to say we want to make the name, the description, the type, and then these horoscope fields of sun, moon and rising. So this is going to give us a query called Coven search that we can pass text into and get information back, which is going to be really nice once we kind of are done with that. So that's our GraphQL schema. I'm going to be going a little faster because we have eight minutes left. I want to make sure I finish.
00:21:24.358 - 00:22:09.400, Speaker B: The next thing that we want to do is go back in our subgraph YAML. And what we want to do is we want to update our entities, to match our entities defined here. So we have a token entity and we have a user entity. So we can match that by just saying token user. The next thing that we want to do is we want to set a start block and the start block is the indexer is going to go to the contract address and it's going to start looking for transactions. So if we give it the first transaction to look for, it can kind of know where to start as opposed to starting at the very beginning of the Ethereum network, right? So to do that we can just look for the start block on Ether scan. There's also a new tool that someone from the community created just this week.
00:22:10.810 - 00:22:13.178, Speaker C: See if I can find it.
00:22:13.264 - 00:22:27.680, Speaker B: Yeah, so it's start block Versaille app so I can paste in a contract address. So let's go ahead and try this out. I guess we can paste in this contract address.
00:22:29.090 - 00:22:38.286, Speaker C: Whoops. And then this should give us the start block and let's see if that.
00:22:38.308 - 00:23:11.414, Speaker B: Matches the one I have. Yes, that's right. Cool. So the start block, Versaill gives you the start block or you can go to Etherscan either way. So I'm going to set the start block and then the last thing that we want to do is define the event handler. Now the way that we index data from these networks is that we look for some way to identify some state update within the contract. And then when a state update happens, then we know that there is some information that we can use to kind of understand what's happening within that state update.
00:23:11.414 - 00:23:45.958, Speaker B: Typically like a function call or something and we can take that data and we can do whatever we'd like with it. Now there are a few different ways to listen to different state updates, but the most important and I would say the most popular is an event. So when someone emits an event, then that means that we can listen for that event and we can do stuff with that data. So if someone updates some state within the contract, they might emit an event. And I guess in theory you don't even have to kind of make a state update. You could just actually emit an event. So either way, as long as an event is emitted, we want to be able to listen to that.
00:23:45.958 - 00:24:36.342, Speaker B: Now in ERC 721, you have this transfer event which is really powerful because it's called when a token is minted, it's called when a token is sold and it's also called when a token is just transferred from one party to the other. So just with this single transfer event, we should be able to get almost all the information that we need about every token and keep up with the updates as they happen. So this transfer event is what we're going to listen to and then we want to call a handler function. So this means when this event is fired, we want to call a function within our subgraph. So we have this handle transfer function and this is where we're going to write our business logic. And if I go to SRC mapping, this is where we're going to have a handle transfer function here. So I can go ahead and just delete everything else and I'm actually going to delete all this stuff.
00:24:36.342 - 00:25:14.606, Speaker B: And the only thing that we're going to work with is handle transfer and to work more easily with both from within the subgraph. We want to talk to the Ethereum network like we would from a front end, maybe using Ethersjs or Web three JS. The Graph TypeScript Library offers some helper functions, but even more specifically to that, we can actually use the abi that we have for this contract along with the library that we provide together to give you a nice interface to talk to the smart contract, to read the contract. So to get that code, we can actually just generate it from the CLI.
00:25:14.638 - 00:25:18.274, Speaker C: By running Graph code gen. And this.
00:25:18.312 - 00:25:33.178, Speaker B: Will look at your GraphQL schema as well as your subgraph YAML and generate some code that's going to be showing up right here in this generated folder. So what we're going to do next is go down here, I'm going to.
00:25:33.184 - 00:25:36.330, Speaker C: Go ahead and import some imports.
00:25:37.870 - 00:26:24.010, Speaker B: We have an IPFS and JSON helpers from the Graph TypeScript library. We have APIs that allow us to interact with the smart contract itself as well as like an event for type safety. And then we also have a couple of APIs that allow us to interact with the Graph node. And you can think of the Graph Node as the database where we're storing this information. So the functions that we'll call are things like token save or user save and things like that. Now this is the business logic of what's going on and I'm getting close to being out of time. So I'm going to probably not walk through all of this, but I will hopefully walk through a bit of it just to kind of give you an idea of what's going on.
00:26:24.010 - 00:26:25.514, Speaker B: So I don't need all that code.
00:26:25.552 - 00:26:28.940, Speaker C: Actually just need this much here.
00:26:32.590 - 00:27:22.810, Speaker B: So we have the IPFS hash hard coded here. Now you can also read this IPFS hash from the contract, obviously, but if someone's updated the IPFS hash, maybe some metadata has been updated and therefore it might fail. So you have to consider do you want to read it from the contract or you just want to hard code it here? In this case I've hard coded it. The handle transfer event is again, the only function that's going to be firing that we want to listen to and we have to think of like two scenarios here. What we want to do is we want to think, okay, if this token has already been saved in the Graph database, then we know that we've already kind of set a few different properties on that. But if it has not, then we want to go ahead and set a few basic properties. So there's two main pieces of I would say there's two main cases here.
00:27:22.810 - 00:27:59.798, Speaker B: The token has been created or it has not been created. So if the token has not been created, what we're doing in this code here is we're essentially just like creating the token and the token is going to need to adhere to this schema here. So we need to go ahead and need to go ahead and set all these. Different fields. So we want to set the ID, the token Uri, IPFS, Uri, and we're doing that all within this mapping. And essentially what's going on here is like we're getting this event. The event has the token ID, it has the user that's transferring it from and the user that's transferring it to.
00:27:59.798 - 00:28:49.238, Speaker B: And then using those three pieces information, we can get all the other information that we need. How do we do that? Well, all we need to do is know this IPFS hash to call out to IPFS, append the token ID, and then we get that metadata by calling the IPFS API here and getting so, like, I'm not going to go through all this just because of timing and stuff, but really all we're doing here is we're calling IPFS. You could think of it as just like fetching that metadata from IPFS and we're saving that to the token object and then we're saving the token here to the store. And then we also are doing the same thing with the user. If the user doesn't exist, we go ahead and create the user. The user only has a token ID associated with it. With all that being said, we're now ready to deploy and then we'll be done.
00:28:49.238 - 00:28:52.770, Speaker B: So what we're going to do to deploy is we're going to run Graph.
00:28:52.850 - 00:29:00.650, Speaker C: Auth and Graph Auth will authenticate our CLI and it's going to ask us.
00:29:00.800 - 00:29:10.174, Speaker B: Subgraph studio hosted service. We're going to choose hosted service. It's going to ask us for our deploy key. I'm going to go here to my dashboard and I'm going to copy this.
00:29:10.212 - 00:29:13.662, Speaker C: Access token and then I'm going to.
00:29:13.716 - 00:29:59.338, Speaker B: Run Yarn deploy and this will go ahead and deploy our API and then we should be able to test it out. Now after you've compromised your access token, you can actually go to dashboard and refresh it to get a new one. So don't worry about that. But we're going to wait a couple of seconds and then once this build is complete and it's deployed, we should be able to refresh and see that we have our API syncing. That means our API is now starting to be indexed. So all of the data that we defined is starting to be indexed and we can actually start querying it. So we have a query playground here, so we can go ahead and say, okay, I want to get the tokens and these are the fields that I want returned.
00:29:59.338 - 00:30:15.620, Speaker B: We can actually go here on the right hand side and see that we have this graphical, I'm sorry, it's Schema introspection, editor or viewer where we can say we want to get the image, the description, name, external. Yar, we are that. So whatever we want to get.
00:30:16.070 - 00:30:22.598, Speaker C: And now when we run that we.
00:30:22.604 - 00:30:26.306, Speaker B: Should see that and then we can do stuff like click on the image.
00:30:26.418 - 00:30:29.526, Speaker C: Or open the image up and see.
00:30:29.548 - 00:30:56.560, Speaker B: That we have cryptocoven showing up the external URL should have all the metadata or not the metadata, but it should show you something like that. All of that stuff is there and then the last thing that I'm going to show off is the full text search because the full text search is pretty cool. So we defined this field called coven search, so I can use that to search for any text.
00:30:57.090 - 00:31:00.382, Speaker C: So maybe I want to say chaos.
00:31:00.446 - 00:31:11.308, Speaker B: Or something like that. Then you'll see that anything with the word chaos comes back. If I want to look for the.
00:31:11.314 - 00:31:15.628, Speaker C: Word Okta, you'll see that anyone with.
00:31:15.634 - 00:31:35.888, Speaker B: The name Okta comes back. So we have a full text search. We can return any information that we want. We deployed all this and we indexed it all within less than 30 minutes. So that's pretty cool. If you wanted to build out your own indexer from scratch, it's typically a very resource intensive process. People I've known have spent weeks or even months building out their own indexer.
00:31:35.888 - 00:31:55.928, Speaker B: So this was a fairly short demonstration. I did have to run through things fairly quickly to kind of like get to the end. We did still go over on time, but I appreciate everyone's patience today. If you want to learn how to build on the graph, I would check out the docs, I would check out our YouTube channel where we have a bunch of tutorials and stuff and I would check out this exact workshop.
00:31:56.024 - 00:31:56.670, Speaker C: Thanks.
00:32:01.340 - 00:32:29.970, Speaker A: Awesome. Thank you so much, Nader. That was super interesting and I'm sure everyone on this call and who has been watching on YouTube have learned a lot. So once again, thank you so much for taking some time out of your day to do this. For all the Dow hacks hackers. For the rest of you, we do have some workshops left for the rest of the day, so hope to see you all there. And with that being said, I hope you all have a great rest of your Thursday or Friday, depending on where you are.

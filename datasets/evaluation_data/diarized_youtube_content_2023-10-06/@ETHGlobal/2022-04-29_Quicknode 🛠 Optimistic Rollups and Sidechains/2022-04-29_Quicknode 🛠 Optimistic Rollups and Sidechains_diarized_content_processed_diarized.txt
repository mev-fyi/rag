00:00:12.570 - 00:00:43.406, Speaker A: You want to get started? Cool. We're live. All right. Hello, everyone. My name is Anthony Campolo. I am here from Quicknode, and we're going to be talking about scaling ethereum and various different layer two scaling solutions, including sidechains ZK proofs and optimistic roll ups. Just a little background about myself.
00:00:43.406 - 00:01:38.862, Speaker A: I'm fairly new to professionally working in the Web Three space. I've been very interested in it since around 2017 is when I first kind of became hip to ethereum and what was going on. But I didn't really learn to code until around like 2018, 2019 and came through a traditional web dev sort of boot camp experience and learned JavaScript and React and stuff like that. And I have been getting more into actually coding Web Three stuff over this last year and have started working at Quicknode, which is a node provider. And this talk isn't really about Quick node at all, though. Many of the chains we'll be talking about are available if you want to host a node for on Quicknode. But I actually got hired, and then the week before I started, they said, hey, you want to speak at ETH Amsterdam? So my first kind of two or three weeks at the company have just been ramping up and creating this talk.
00:01:38.862 - 00:02:10.518, Speaker A: And when I was talking to my coworker about kind of what the topic should be, it's like, well, you do NFT APIs. Everyone likes NFTs. NFTs are fun, and NFTs are very fun. But I was like, Now I want something a little more like meteor. So I picked a very dense technical topic just to challenge myself. And this is something that if you have been following the scaling story over the last four or five years, you're probably going to be familiar with a lot of these terms and a lot of these concepts. If not, this is going to be a really great overview of all the different things and all the work that's gone into scaling ethereum.
00:02:10.518 - 00:03:05.594, Speaker A: And the first thing we should talk about is what is the problem here? Why do we need to scale ethereum at all? And this is because the Ethereum network creates a new block every twelve to 14 seconds. So there's a certain bounded limit to just how much throughput the actual chain the main chain can have. And the idea of how to scale it is kind of split into two big buckets you can think of. There's the layer one scaling and the layer two scaling. So layer one is how do we make Ethereum faster? How do we get more transactions to go through Ethereum or larger transactions? Because this is why I use the block instead of the transactions. Some people usually say you have this many transactions per second, but that doesn't really tell you all the information you need because a transaction could be a lot of different things based on the size and what's actually happening within the transaction. But you have solutions that try and scale layer one.
00:03:05.594 - 00:04:13.054, Speaker A: So this is things like Sharding or previous things like Casper, and you have layer two solutions, which is what we'll really be talking about today is going to be layer two, which is the idea that what if we offload computation and take it off of Ethereum and do it somewhere else? So that question of what is the somewhere else is the big question here. And we're going to look at lots of different somewhere else's, but most of them are going to be a blockchain that's going to be the somewhere else. But we'll get into that as we go. So first thing that's kind of interesting or worth mentioning is that a lot of these ideas were kind of circling around even before they were actually implemented. So there's a really interesting interview with Carl Floss on the Bankless podcast where he tells the story of optimism. And this is kind of a spoiler alert, but optimism, once they kind of crack the code and figure it out, they went and told Vitalik and he's like, oh, that sounds a lot like that shadow chain thing that I came up with back in 2014. And this isn't like as that story illustrates, this is not really work that optimism was based on.
00:04:13.054 - 00:04:50.702, Speaker A: They weren't even aware of it. But after the fact, they realized, oh, this was already prior work leading to it. And so we see here we have the main line state, which is the main chain, and then we have the shadow chain. And so kind of what is that shadow chain is the other layer two that we're going to talk about. And so along with the shadow chain idea, there's also the bitcoin lightning network. And this is the same idea of how do you scale bitcoin because bitcoin has many of the same limitations in terms of throughput and scalability that Ethereum has. And the bitcoin lightning network is the same idea.
00:04:50.702 - 00:05:48.250, Speaker A: You want to offload computation off of the main chain. Now, what's different, though, is that the lightning network was not a separate blockchain, it was another network with all sorts of mechanisms involved, which isn't super important, but the idea is that it's a separate thing offloading computation. And this work kind of came together and merged with plasma. And so Plasma you now have Joseph Poon, who did one of the authors of the Lightning paper, and then Vitalik, Buterin who had already had the shadow chains idea. And with Plasma, this is the abstract of the paper. It's a proposed framework for incentivized and enforced execution of smart contracts, scalable to a significant amount of state updates per second, potentially billions, and enables the blockchain to represent a significant amount of decentralized financial applications worldwide. So this was kind of the vision of Plasma.
00:05:48.250 - 00:06:42.738, Speaker A: But if you actually read the Plasma paper, it's not exactly an implementation, it's more of a theory and a system. And it's important to figure out what that theory and that system is and then we can kind of talk about how it became reified. So again, we have a child chain and then a root chain. And so lots of different terminology. And mostly it's just there's always a layer one and a layer two and kind of what terms they use to represent layer one or layer two tends to shift depending on who's writing the paper or implementing the thing. But here we have the communication between the chains is secured by fraud proofs. And this is really the key idea that we're going to build on throughout this talk, is the fraud proof what happens if someone tries to propose a block that's different or fraudulent or gives themselves a million dollars when they didn't have a million dollars before? This is a key problem that we need to solve here.
00:06:42.738 - 00:07:28.110, Speaker A: And so you have each child chain has its own mechanism for validating the blocks, and the different solutions we'll be looking at today will have different mechanisms for doing that. Also different consensus algorithms. So the different fraud proofs can be built on different consensus algorithms. And depending on which consensus algorithm you use, you will have the different trade offs that go along with that. Now let's look at the pros and cons of this idea. The first pro is that the layer two lets you have lower fees and faster computation. This is the core idea and why we want a layer two in the first place and why all of the things we're going to be looking at are all different layer twos.
00:07:28.110 - 00:08:14.062, Speaker A: It also reduces the amount of data processing that happens on layer one. That's kind of a consequence, or the first part is kind of a consequence of the second part. And then you can create compatible layer one scaling solutions like sharding, which I talked about in the beginning. You have things to scale layer one, and hopefully those can be compatible with the way you're scaling layer two as well. What are the cons, though? Now? The cons is that as I said, the paper is more of a system and a theory than actual implementation. And this is why plasma was really confusing for a lot of people for a while. When you would talk about plasma, you would have people not being entirely clear what they're talking about because plasma is not a single thing.
00:08:14.062 - 00:08:43.750, Speaker A: It was a group of many different implementations that were based on this first core paper. So you had plasma MVP, plasma cash, plasma debit. There's even a separate plasma MVP called more viable plasma. So it's very confusing. And you then had these tool chains being built around it that have pretty much been deprecated. Now you could think of it like, oh no, plasma was a failure and they scrapped all that work. But that's not really what happened.
00:08:43.750 - 00:09:29.474, Speaker A: The people who are working on plasma are the same people who work on the later solutions that we're going to look on here like optimism. And the funds could only be withdrawn after a lengthy waiting period. This is another idea that's going to reemerge throughout this talk. And it's almost a philosophical point of do you want your system to be set up in a way where you can stop and have a waiting period? So you're thinking of something like the Dow hack. We needed time to actually coordinate and fork the chain to make it correct. So sometimes having actually a period of time where something can be challenged, that itself is a key part of the security mechanism. So you sometimes can't really get away from the waiting period.
00:09:29.474 - 00:10:25.350, Speaker A: And some of the solutions we'll be looking at will have say, a seven day waiting period where your funds are going to be locked up and you can't withdraw until that seven days is over. And whether you're okay with that is kind of whether you believe in this idea that that's a built in, almost social mechanism to allow coordination. In the worst case where you need to coordinate a new chain. Essentially next thing we're going to look at are side chains with side chains. It's the same idea where you have a layer one and a layer two. But you're being very explicit in that that layer two is a brand new blockchain that we're creating. And this blockchain will have all the properties of blockchains that we're used to in terms of it needs a consensus mechanism and has a linked list that's append only and can't be tampered with all the things that we love about blockchains.
00:10:25.350 - 00:11:06.454, Speaker A: And you're going to have the separate layer two running parallel to layer one. And for all of these that we're going to talk about, they're going to be specifically Ethereum is going to be the layer one. But really these ideas could be transferred to almost any chain you can think of. If it's a chain that has the same sort of scalability problem as Ethereum and then you have a two way bridge that connects the two. Now it'll also have its own consensus algorithm and block parameters that go along with that. The pros and cons of this is that first pro is that it's an established technology. We already buy into the fact that blockchains work the way that we think they do.
00:11:06.454 - 00:11:39.162, Speaker A: And so if we know a blockchain works, then it makes sense that we would use it as a solution for the same problem. And then another thing that is general property of a blockchain like Ethereum. It supports general computation. So if you're going to offload computation from the main chain, you need to make sure you're offloading it to something that can actually do that. So it needs to be turned complete. It needs to have a programming language, needs to be compatible with whatever computation is going to happen on the layer one. Now the cons is that it's less decentralized.
00:11:39.162 - 00:12:29.920, Speaker A: And this is an interesting point because it's not really like a theoretical limit to side chains. There's no really inherent reason why a side chain needs to be less decentralized. It's more of just like an empirical fact because Ethereum itself has been around for years. It has a very good decentralized network of nodes already. So you have this bootstrapping problem of if you're going to have a whole separate blockchain that's going to have a whole separate stack and that's going to require a whole separate set of validators and nodes together, then there's kind of a cold start problem there. And that if you want to have it be as decentralized as Ethereum is anyway, you need to start up this whole blockchain with all these people. So in practice, sidechain implementations tend to be less decentralized, at least in the beginning, and need to grow to become as decentralized as something like Ethereum is.
00:12:29.920 - 00:13:43.906, Speaker A: You then end up with a separate consensus mechanism that is not secured by the layer one. And this will introduce additional complexity because if you already know you have a sound consensus mechanism in your layer one, then you may be wary of, well, what is this other chain doing? And how do I know this other chain isn't vulnerable to like a 51% attack or all these other sorts of attacks that blockchains can potentially be vulnerable to? And then you also have a quorum of validators which can commit fraud. You can think of this kind of like an off chain 51% attack. So if you're relying on this second chain and you have a network that's not very decentralized, then it can be easy for enough nodes in that chain to get 51% and then break that consensus algorithm. All right, now we're going to actually start looking at some of the implementations here. So, so far we had plasma and plasma led to a lot of implementations that didn't really pick up. But the ones we're looking at now are actually in practice and people are using them and any of them can be accessed through an RPC provider like Quicknode.
00:13:43.906 - 00:14:26.114, Speaker A: So Polygon is a side chain and it's a clone of the layer one chain that supports transferring assets to and from layer one to layer two. That should make sense all the things we've already been talking about throughout this talk. You have one chain and you got another chain. Two chains talk to each other. Now the layer two is a new blockchain with its own consensus mechanism for creating blocks. So Polygon is not an exact copy of Ethereum, it's a new chain itself. This leads to other ideas that are not necessarily going to be separate blockchain with its own consensus algorithm.
00:14:26.114 - 00:15:19.718, Speaker A: But we're going to now see things called ZK roll ups, which are using zero knowledge proofs. And zero knowledge proofs are very mathematically, kind of dense idea. But the simplest way to describe it is that it's about verifying a secret without sharing it. And there's an interesting thought experiment that I actually found helped me kind of understand this is you can imagine you have approver and validator. So approver has to prove that they are not colorblind and then the validator has to validate whether that is true or not, even though that validator themselves is colorblind. And the way this works is imagine the validator has two beans, one in each hand, one is red and one is blue. So you can think of this kind of like the Matrix got the red pill, you got the blue pill, and they are going to have them behind their back.
00:15:19.718 - 00:15:50.994, Speaker A: And then they're going to show them. They're going to either switch the two in their hands or they're going to keep them in the same hand and then they're going to show it to the prover. And then the prover will say whether it was switched or not. So the prover can see whether it's switched or not. And they can verify that. And they can do that without needing to actually tell the validator what the colors are because they know whether they switched or not. And then when they show it, that person can validate that.
00:15:50.994 - 00:16:32.538, Speaker A: And that doesn't require actually knowing the colors themselves. And this is really useful because it allows the person to validate without actually sharing that secret. But the thing is that it's kind of probabilistic if you think about it. Because what if you just guessed the first time and you said it was switched and you happen to be right, so there's a 50 50 chance you actually knew that or not and you're actually proving it and then you do it again. Then you prove it a second time and then it's slightly more likely 75%. And then as you do it over and over and over again, if you continue to prove it, then the probability that you're actually proving it goes up and up and up and up. And it's an interesting question to ask yourself.
00:16:32.538 - 00:17:32.366, Speaker A: What percentage would you be comfortable with? Like is 99% enough? What about 99.99.99? But eventually it gets to the point where you can say, okay, yes, you have actually proved this and that is what a zero knowledge proof is. Now, if we look at how this then factors into all this other stuff we've been talking about, you have your layer two scaling solution and then you have your layer one computation ESP performed on layer two. And then for every roll up block, this is on the layer two, you have a state transition zero knowledge proof which is generated and verified by the layer one. So they will create this proof which is going to prove that they have actually done all the transactions correctly. And then this allows having a lot of transactions all kind of rolled up together. And then that combination of transactions can then be put back on to layer one.
00:17:32.366 - 00:18:12.798, Speaker A: And you can kind of think of it like it's being compressed. We have a lot of information, a lot of computation that's happening off chain, but then they can kind of roll it all up and then put it back on the layer one chain. Now with ZK roll ups, we don't actually have real implementations running on main net right now. ZK sync is pretty close. They're on testnet and they have a lot of funding and they are kind of the closest, at least that I'm aware of, that are about to be on main net. But there's no implementation right now for ZK roll ups. And that's why there is going to be sidechain implementations and then there's going to be optimistic roll up implementations that we're going to look at.
00:18:12.798 - 00:18:58.522, Speaker A: But the ZK roll ups are still kind of in process. But I felt they're worth mentioning because they're very important to the development of the next thing that we're going to look at, which are the optimistic roll ups. But first let's look at the pros and cons of ZK roll ups. You have reduced fees per user transaction and this is true of many of the solutions that we're going to be looking at here. And then you have less data contained in each transaction because they're being all rolled up together and then put onto layer one. And then it doesn't require fraud game verification. This is what makes ZK roll ups different from optimistic roll ups, which we're going to look at after this, which require fraud proof.
00:18:58.522 - 00:19:57.966, Speaker A: Verifier cons is that computing zero knowledge proofs requires data optimization for maximum throughput. So basically it requires very specialized algorithms that are written by people with very specialized PhDs in this kind of stuff. And this in one sense is good. It's a pro because you know, that's being built on really solid long term research that's been done for a very long time. But there's also like maybe 100 people in the world who really fully wrap their mind around this stuff. So if you find this interesting, this is a good thing to kind of get into because they need more people and help. But the security scheme, it assumes a level of unverifiable trust because you're kind of trusting that the algorithms are sound and that the fraud proof is correct and you really need to audit that and know that it works because you aren't really having kind of fraud way to kind of call fraud on it.
00:19:57.966 - 00:20:40.822, Speaker A: You're just saying like, well, you can't defraud this in the first place because it's fundamentally built in a way that can't be defrauded. With optimistic roll ups, though, we're going to have fraud proofs and we'll get into that as we go. Now with ZK rollups, you start by proving to Ethereum that the transactions are valid, whereas with optimistic roll ups you assume the transactions are valid. And then leave room for others to prove that fraud. And this is why it's optimistic because it's kind of like if you've ever heard the term optimistic UI. Optimistic UI is when you kind of fire a request off to the server and then you give a response back to the client. You assume that it worked and it's the same thing.
00:20:40.822 - 00:21:20.022, Speaker A: Optimistic roll ups. You're going to assume the transactions are valid and correct and you're going to leave the window open for anyone to say this is not valid, I want to call fraud on this. And so there's a mechanism built in to do that. And there's going to be two separate different mechanisms though that we're going to look at to do that. The pros and cons is that it's compatible with EVM. This is really important for the two implementations we're going to look at which are Arbitrum and optimism. They both say that we want to be compatible with the EVM.
00:21:20.022 - 00:21:58.486, Speaker A: And so that means that you could have computation that would run on the EVM and work on optimism or Arbitrum. And you don't need to necessarily change the code. Hopefully the stack should be basically identical. And that means that it's more flexible than ZK roll ups because it's basically just like running almost a clone of Ethereum in that sense. And then you have all the data is available and secured on chain. Now, the cons is that it has more limited throughput compared to ZK Rollups. Because ZK Rollups you can really take a ton of transactions and smush them all together.
00:21:58.486 - 00:22:59.450, Speaker A: And it requires an honest majority of Ethereum Validators and at least one aggregator that does not censor the transactions because you actually have to have someone to call fraud and activate that fraud proof. And it only requires one person though. So as long as you feel that there is one trusted node within this quorum, then you can feel confident that they're going to call fraud on it. The first implementation we'll look at is Arbitrum and this little thing here. So this is from the white paper. And the first I looked this, I was like, what the heck is going on here? But it actually makes a lot of sense if you just kind of look at the middle pieces, you have the challenge and then when you have the challenge it goes to Bisected, bisected goes up to waiting and then we'll check whether it is confirmed or not. And then it goes to Pending and you either recallenge and then you do the loop again or you say, okay, this is good.
00:22:59.450 - 00:23:29.842, Speaker A: And then you exit and this will then kind of slowly chunk it down little by little. So if you think of like a binary search, it's a little bit like that. You can think of Alice and Bob engaging in a back and forth. And then this is refereed by a layer one contract to resolve that dispute. And that's being resolved through the Bisection. And this is based on dissection of the dispute, which is what the image is showing. Now.
00:23:29.842 - 00:24:20.340, Speaker A: The next one is optimism. And with optimism, we don't have this same Bisection idea with optimism, instead, we have a challenge window. And so with this, you have a period of time which you need to wait and say, okay, throughout this period of time, we're going to allow anyone to verify whether this is actually valid or not. And if not, then they can challenge it, and then the computation is rerun and verified whether it actually worked or not. And if it goes unchallenged for the duration of the challenge window, then it's considered final. So in optimism, you have a seven day window. And then once the commitment is considered final, the layer one smart contract can accept it, and then you are all good to go.
00:24:20.340 - 00:24:54.478, Speaker A: Okay? And then these are the citations of all of the stuff that I talked about. And these are links for QuickNote, if you're curious. So the three different implementations we looked at are all available. If you want to spin up a node on QuickNote and connect to it, check out our Twitter. We have some events, and we have an event in two days at 730, so feel free to come hang out at our house, Hacker house. And then we're also hiring. So I am still fairly new to the team, but we're hiring in lots and lots of different areas and parts of the company.
00:24:54.478 - 00:25:19.382, Speaker A: And we also have Discord, so feel free to check out our discord. Yeah, that is the whole talk. Thank you. And does anyone have any questions? We got a couple of minutes here. If not, that is totally fine. Appreciate you all being here. I hope that all made sense.
00:25:19.382 - 00:25:55.822, Speaker A: This is a very interesting, dense technical topic, and that was kind of a whirlwind overview, but this is work that is very consequential and important to Ethereum. I think most people around, like, 2017, when CryptoKitties happened, everyone was like, oh, wow, this is really slowing down the network. And then for a while, people were like, it's not really that big of a deal, because you had the whole crash. And then now, over this last two years, now it's really a problem. I mean, I can say personally for myself, I have an ENS domain. I don't know if any of you have a ETH kind of domain. And when I bought it, it was $15 for the domain and $200 for the transaction.
00:25:55.822 - 00:26:10.040, Speaker A: So this is definitely a serious problem. And it's great that there's lots of projects out there trying to address it. And hopefully this gave you a bit of an idea of what is out there and available you can check out. Yeah, please do.
00:26:12.970 - 00:26:31.806, Speaker B: More asked about your opinion or perspective, but obviously there's these different methods that people are proposing scaling. Obviously, a lot of these systems get proposed and then when they get tested in the real world to find out what's wrong with them.
00:26:31.828 - 00:26:32.880, Speaker A: Right, sure. Yeah.
00:26:33.410 - 00:26:48.034, Speaker B: Do you have any predictions about which ones are going to be more successful or more adopted or like if there's going to be tests or kind of potential issues with any particular method that you talked about?
00:26:48.152 - 00:27:54.706, Speaker A: Yeah, sure. So the three that were kind of like the implementations for polygon, Arbitrum and optimism, they are all running on main net right now and you can put money into those things and they are running and you can treat them like a real blockchain that you can invest in. So with those, the proof is in the pudding in the sense that they are already operating and you want to be able to separate between what is actually a scaling solution that you can look at and that you can interact with today versus ones that are still kind of in the works. So that's where the ZK roll up stuff is still kind of in the works and it's running on testnet and it's still unclear what form that's really going to take. So you can look at something like ZK sync and you can say, okay, this is on testnet, it's probably going to be on mainnet in a similar form, but you can't really say whether it actually works or not versus things like arbitram and optimism and polygon. Those are running and you can say, okay, this is something I can point to and say is working. So I think that's the main thing is that I feel fairly confident that we're going to continue to see Arbitrum and optimism and polygon continue to run and operate.
00:27:54.706 - 00:28:14.780, Speaker A: And they seem to be stable and working and then the ZK roll up stuff is still a bit more experimental and theoretical, and that we're not entirely sure how that's going to pan out. All right, cool. Well, thank you so much everybody.

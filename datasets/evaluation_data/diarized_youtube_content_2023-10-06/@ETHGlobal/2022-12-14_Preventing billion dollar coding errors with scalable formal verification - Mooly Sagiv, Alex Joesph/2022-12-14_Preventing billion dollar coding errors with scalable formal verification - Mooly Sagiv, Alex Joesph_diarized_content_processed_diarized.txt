00:00:06.410 - 00:00:30.022, Speaker A: Thank you for coming. I'm going to talk now about formal verification. For many of you, it's probably a foreign concept. How many of you of you are developers? Fantastic. That's the talk for you. How many of you know about formal verification? Sound great. So I've been working on formal verification for a long time.
00:00:30.022 - 00:01:06.146, Speaker A: You can see, and I think it's actually an interesting domain for many things, but I think it's a perfect application for DeFi. We heard Jeremy's talk about balancer and actually it's related to what we're going to show you. It's technology for checking the correctness of DeFi. And I have an hour for the talk. I'm going to use only half of it, and the second half will be a demo with our tool which is publicly available. You can try it and you can get a free version of it. There's also paid version of it.
00:01:06.146 - 00:01:49.342, Speaker A: It's a subscription. Hello. Do I have to do something? Okay, so what is sertora? Sertora is a company for checking correctness of code. Seltora is a company which is global. We have 90 people on the team. I didn't write the list of all of them. Our team consists of several people, and I think we have about 25 people with PhD in formal verification from top schools in the US.
00:01:49.342 - 00:02:21.222, Speaker A: In Europe, Israel, and we combine it with other people who are security experts. I mentioned only few of them here. And I think we are very, very grateful for collaboration. In particular have a collaboration with Rajiv from Sekureon. And basically this helped us to embod people into this domain. And some of them are here and working with us, like Alex Joseph and others, that actually bringing more people into this space. And we are looking for more.
00:02:21.222 - 00:02:44.542, Speaker A: We are looking for more. And there are different ways that you can collaborate with us. You can work in Setora, but you can work in customers that work with Setora. You can also work in the community. For example, we have a large grant which was just approved Ave. So basically you're going to write correctness Ave, and we are doing it with other protocols. We are also working with some of the auditors.
00:02:44.542 - 00:03:21.638, Speaker A: For example, spearbeat and Code Arena. So basically, Code Arena is a content company, and as part of the content, you would write correctness rules and you will check them with the Satora program. We also, of course, acknowledge to our connection in Israel, specifically to the IDF. So we have, I think Amit Heavy was a senior person in the IDF for code vulnerability, and he leads our security team. So everybody knows about this bug. And we heard about bugs in many places. There are a lot of bugs.
00:03:21.638 - 00:04:14.110, Speaker A: I want to actually point out to you the two ones which are my favorite. This is the Nomad act, and the other one is the compound. So these are cases that basically the quad actually was good actually and was even audited. And for example, in the case of compound, it was even checked compound, they use a very good auditors and they're also a paying customer of Sartora and they use Sartora. But what happened after they checked the code with Sartora, somebody changes the code without running Satora and as a result there was a hack which was exploited. So this is why we want to use this technology to check the code before it is deployed. So, in the domain of security, there are different tools.
00:04:14.110 - 00:04:48.626, Speaker A: The simplest tool you can use is testing. Basically you test your code and all developers we use testing or we use Fuzzing. There are also tools that help you make the Fuzzing easier. In the area of web two, there is AFL. This is a very very nice tool which was used to find many many bugs. And in the area of web3, people are developing similar technology. In particular, twelve bit is developing echidna and Paradigm is developing foundry.
00:04:48.626 - 00:05:30.790, Speaker A: These are very nice tools. They basically test behaviors. The problem with these tools, they are very useful, but the problem is them that's hard to find bugs which are somehow happen in rare situation. And I'll give you one like this, but you can see many of them in the Satora proverb that actually these are bugs that happen after many states and it will be hard to detect them if you start running from initial state. So that's one technology, it's not unique to web3. It was of course in web two, but it's also useful in web3. It's probably less useful in web3 than in web two because many of the security bugs in web3, they are specific.
00:05:30.790 - 00:06:14.754, Speaker A: It's a managed environment. The second technology which has been around for ages, it's static analysis. So, static analysis, it provides more coverage than Fuzzing. And there are tools available, there are industrial tools mainly for web two, that checks the code for correctness and it covers more behavior than testing. But the problem is these tools that basically they have the ability to basically miss errors and they have false positive and false negative. In this context, Sartora actually has built a very interesting case. In the Sartora prover we analyze the bytecode and actually we can prove certain properties automatically without the human.
00:06:14.754 - 00:06:44.298, Speaker A: And this is something which is integrated into the Sartora prover. There is a static analysis which is integrated. The right hand side are techniques which are supposed to provide more coverage, but they are potentially more expensive. And they are called formal verification. Intuitively formal verification means showing that your program does what it's supposed to be. And there are two branches of formal verification. The one which I'll be talking today, which is called automatic formal verification.
00:06:44.298 - 00:07:10.674, Speaker A: The idea is the human writes the properties and the machine is trying to reason about these things. And this is working by compiling the tool into some kind of mathematical formula. And this is what's integrated into the Sartor Approver. And there are a lot of open source tools. In particular, the Daphne Tool by Microsoft Research. It's a similar tool. It's a tool that basically compile your code into a mathematical formula.
00:07:10.674 - 00:07:52.606, Speaker A: The difference is that the Sator Approver is more scalable. And you can see, for example, the Satora prover, you can run it on thousands of lines of code, which is not something. And this is unique, not just in web3, the ability to run on such a huge code. And we have a proprietary technology that we develop that help us scale this. This is why we have all these talent people that are helping us building the stuff. So this one, it's to give you effective proof and bug finding, because it doesn't start, unlike fuzzing, it doesn't start from initial state. But it is expensive, because the problem is computationally expensive.
00:07:52.606 - 00:08:30.174, Speaker A: We usually in computer science, we call it undecideable, which means that the computer will not always do a perfect job. And the other branch, which is also useful, it's called interactive, sometimes called manual formal verification. So the idea here is that not the computer is doing the job, the human is doing the job, and the computer is only checking you. And there are tools in the area of web3, there is the K framework. In web two, there is tools like Lean. So these are tools or cock, these are tools that check your proof, you are writing your proof. So in this case, you can never get wrong.
00:08:30.174 - 00:09:09.274, Speaker A: You write your proof and from the proof, you extract your code. This is a nice tool which has been used in a nice methodology, which has been used in many cases. The problem is this kind of approach that is very, very hard for human to use. Even for small things like, ERC, 20, you may have to spend ten months to prove this property. So this is very, very high, this technology. So maybe just to give you a hint on static analysis, so this is one of the most useful static analysis tool, which is called Slitter. How many of you know Slitter? Great.
00:09:09.274 - 00:09:44.834, Speaker A: So I just ran Slitter on the bank. Bank is a very, very simple code and it has many, many red lines. Do you want to guess how many of them are real? Error? Zero. And the reason is not because Sliter is such a technology, which is bad. Of course you can improve the technology behind Slitter. But the idea that Slitter does not know what the code is supposed to do, the Slitter is basically running a generic test on your code in terms of comparing the tools. So I try to compare.
00:09:44.834 - 00:10:05.582, Speaker A: You have basically the other extreme. This is the extreme that you get very high coverage. I mentioned k hawk lean. So these are the tools that get high coverage. And the other extreme. These are the tools which are easy to use. And I mentioned foundry, but there are other tools which are easy to use.
00:10:05.582 - 00:10:38.230, Speaker A: And Satora is trying to build something in the middle. We are trying to make something easy to use as maybe not as easy, but close to using a fuzzer, but give you almost the coverage that you get from interactive term program. And I think we are there. We actually have a lot of things that we have done. In particular, we are analyzing the executable code. We are not even trusting the compiler. We are checking the executable code.
00:10:38.230 - 00:11:12.750, Speaker A: We also make the tool very easy to use. And you will see, if you see, Alex will show you and you can see it with the demo. And the other thing that we do, we involve the programmer in the loop when it's hard for the tool to analyze the code. You can use modularity, you can basically make your code more modular or tell us how your code is modular. And the more your code is modular, it will be easier for our code to analyze. So what do we do in Satora? We do two things. We have an open source language called CVL.
00:11:12.750 - 00:11:36.922, Speaker A: It's a language for writing properties. This is something that we want everybody to use and it's something that the properties of your code. This is the CVL. And then we are developing technology. We are developing three kind of technologies. The first, this is the technology for checking the code. At the moment it's proprietary, but you can use it and you can use it as much as you want.
00:11:36.922 - 00:12:13.190, Speaker A: The second technology, which is coming actually very soon, is developed by Chandranandi. And Chandra what she's leading, she's leading the project for checking the specification. And this is an open source tool. It's essentially a mutation testing for solidity in which you can check if your specification is okay. It's checking that the CVL is okay and it's making the task of writing CVL easier. And the third technology that we are building now is a monitoring technology. It's the idea that we want to monitor the CVL when the code is executed and when the transactions are executed.
00:12:13.190 - 00:13:07.350, Speaker A: So what I want you to get from this talk, and hopefully this is what you get when you use the sartora, is the ability of the beauty of invariant. And invariant, these are sort of the essential properties of program. It basically means these are the properties that if they have to be right and if they are wrong, something is bad. Okay? So in area of DeFi, the interesting thing is like solvency, it means the bank has enough money to cover the loan, it has some kind of property. And these are the invariants that you have to work when you are using Satora. So let me give you a very simple but interesting case of a solvency. So the most intuitive solvency says that if everybody goes to the bank, the bank can still pay the money, pay its debts.
00:13:07.350 - 00:13:45.630, Speaker A: And solvency is an interesting property for all the DeFi protocols. And what Certora does, as mentioned by Jeremy in the previous talk, Certora works with customer. And usually we work with them either before audit or after audit. These are the cases that we work with customers after audit, which means they completed the audit. And after that, they checked the code with the Satora approver. And you can see here, these are bugs that are found by this technology after the audit was completed. And all of them, these are solvency.
00:13:45.630 - 00:14:07.290, Speaker A: I'm going to show you one like this. But the idea these are bugs which allow you in a rare situation, to take the money from the contract. And this was found by our tool. And it was found after a very, very good auditor. Of course, an auditor can also find bugs after us. We are not replacing the auditor. We are complementing the auditor.
00:14:07.290 - 00:14:36.810, Speaker A: So how does the Satora approver work? You will see in Alex demo. But the idea is the user is a static analysis like Slit. But you're not only writing the code, you are also writing the invariant. And the tool can do two things. It can give you a mathematical proof that the invariant is maintained. That's very interesting. But the most interesting case, and this is what I showed in the previous slide, it show you a violation.
00:14:36.810 - 00:15:19.390, Speaker A: It show you a potential rare case that the program starts from a state which satisfies the invariant into a state which violates the environment. This state is not necessarily the initial state. It can be a state which happens many, many after many steps of execution. And that's the beauty of formal verification. It gives you an inductive reasoning why your program is correct independent of how many times it's executed. So, of course, since we are talking about a computationally hard problem, the tool is doomed to fail in certain cases. And in our case, the failure means not false positive or false negative, but it means timeout.
00:15:19.390 - 00:15:50.858, Speaker A: It means you run the tool for 2 hours and you don't get a result. And we have a technology that we are building to improve it, but it's always doomed to fail in certain cases. And here you can use modular reasoning. We are doing many, many things, but at the end of the day, if the code is complex enough, the tool is doomed to fail. The technology is very useful. And I already mentioned that as part of your CI, we integrate like tools, like Circle and JIT. So basically, every time you change your code, you run the tool.
00:15:50.858 - 00:16:44.190, Speaker A: And that's the difference with a manual audit, in the sense that this is a continuous process, you run the tool, you change the code, and assuming that the environment remains the same, you basically maintain the same environment throughout code. Changes. So this is essentially the tool that you want to integrate into your CI to keep the code safe. The Sertora Approver actually is fairly complex technology and I won't be able to explain this in this talk, but there is a white paper that I encourage you to read which actually explain everything behind the Sartor Approver. I'm just going to give you the basic idea. So basically we run the compiler, the Solidity compiler and then we have our own decompiler, we have our own decompiler that decompile the EVM code into something that we understand. So this is these three others code.
00:16:44.190 - 00:17:10.806, Speaker A: It's actually something that we understand. At the moment we are supporting EVM, but eBPF is coming and WebAssembly is coming. So we will support other blockchain. So we are basically building this stack to support all the blockchain that is important. Maybe Cairo, maybe others. So this is all in these three others code and then we have our secret source. We have actually tools that simplify the code.
00:17:10.806 - 00:17:55.410, Speaker A: And that's very interesting. We run some static analysis. But this static analysis is not used to find bugs, it's used to actually simplify the code. And the interesting thing about this, and I don't know if you have seen in the process of simplifying code, we are making certain assumptions about what the compiler generates, but we are of course checking them. So we are not analyzing arbitrary code, we are checking some properties and I don't know if you notice, we actually produce many of the bugs in the Solidity compiler. So these are bugs which were automatically identified by Oil tool and they are bugs in the Solidity compiler itself. So this is actually an acknowledgement from the Ethereum Foundation.
00:17:55.410 - 00:18:25.614, Speaker A: The other thing that we do, we take the code and generate a mathematical formula. Here we are building on Smt. How many of you are familiar with Smt? Few. Fantastic. So Smt is actually a technique. I mean if you ask people in computer science they think that satisfiability is a hard problem, they're of course right. But the idea is even though it's a hard problem, there are actually tools that actually can solve many, many instances of that.
00:18:25.614 - 00:19:08.218, Speaker A: And the idea is there are even tools for Smt and we actually use all of them, we contribute open source to them. So basically part of the things that we do in this pink is we make Smt reasoning easier. And if you don't know what's Smt think about linear programming, think of some kind of mathematical reasoning. So what we do, we actually and we also going to do more. We do a lot of things to reduce the number of timeout, to reduce the failures and in particular we care about financial systems because this is where all our clients are. So I'll give you a very simple example, we'll give you more. So this is a very simple code.
00:19:08.218 - 00:19:59.290, Speaker A: You see, you transfer and the environment that you want is that the total is equal to the sum of the balance and you run the tool, you see the tool automatically identify a bug in which L is transferred to herself and basically the money is gone. And this is a case, sorry, increased, so the sum is increased, my mistake. And these kind of bugs, these are the bugs that we are finding with these kind of techniques. These are the violation of your invariant. And so this is a case, it was found by the tool. When you are correcting the code, we can actually produce a mathematical proof that the invariant is maintained. It doesn't mean that the code is bug free, but at least it means that the rule that we check is maintained.
00:19:59.290 - 00:20:53.070, Speaker A: So that's the idea. Actually we have two type of customers and maybe now three. One of them are security researchers, which is fantastic, they are using the tool, which is great like in the spearbeat now with us ave code arena the other one our developers and the third is us. And the interesting thing people that use us, the maker team, they have actually very good team, I think about seven or eight solidity developers that are using this tool and they are checking invariant about the code. And the environment that Kurt wanted to check is that the coin is stable. So everybody know what makers does, right? So maker implement a stable coin. So the environment says that the coin is stable and in fact the tool found out an example in which in certain cases it is violated.
00:20:53.070 - 00:21:40.446, Speaker A: So this is something that was found by the tool. And basically, you see there is a need function and the init function, the environment that has is that the depths is equal to the sum of the collateral. And the tool actually find that in certain cases you can violate this invariant. And when you fix the code, it show you that this invariant holds. So this is a very very good use case of this technology finding bugs in your code. And these are potentially hard to find bugs that we are finding with this kind of technology. I want to basically close this first part by showing you a critical bug which again found by the tool and Alex will show it later.
00:21:40.446 - 00:22:20.246, Speaker A: So this is the Sushi Swap Trident. It's a code and actually related to the talk that we've seen by Jeremy. It's basically implement what Jeremy said, the dual liquidity pool and you see the code here there's bears single. This is a code which is in solidity. It's probably hard for you to see the bug, but I mentioned it in red. Basically the code is not using it's more interesting bug than the bug that we have seen in the previous slide because the code is actually not using correctly the API. And as a result there is a rare bug in the code and this rare bug is found by our tool.
00:22:20.246 - 00:23:00.114, Speaker A: And this rare bug will allow you to completely deplete the money in the contract. Okay? So what is the nature of the bug? So you have to say what is the invariant? And the simplest invariant about liquidity pool is that the multiplication is constant. But I even use something simpler. It's basically say if you have two tokens, they cannot be that one of them is zero and the other is not zero. So if one of them is zero, the other one better be zero. And here you see Bob and Alice in the trident. And there is an operation in the code that says burn single in which Alice burner holding.
00:23:00.114 - 00:23:55.686, Speaker A: And what happened this actually you see the number is 400 and the number of B is zero. So basically you see that the environment is broken now. Okay? So this is a violation which was found by our tool. By basically running our tool, we found this violation. We found this, I have to say, before the code was deployed, most of the bugs that we found of bugs that were found before the code is deployed, when we are finding code bugs, after the code is deployed, we are very, very quiet about them. So what's going on? So in fact, what's going on here? This bug is a bug which is very, very you notice that the system also always start from our environment. So the question you can ask yourself how can you have this invariant? How can you violate this environment and what are the implications of it? So this is the case that you see what happened here.
00:23:55.686 - 00:24:28.174, Speaker A: Alice deposit 100 coins, bob deposit 100 coins and then Alice transferred 200 coins. So basically you A is 400 and the token B is 200. Now the burn single, that basically violates the environment. And finally what happened? Ellis swapped the money. So basically Ellis give one coin and get all the money and Bob lost all his money. So this is a bug which was found by our tool, but our tool doesn't see all of that. That's the beauty.
00:24:28.174 - 00:24:54.054, Speaker A: Our tool only reason inductively. So what does the tool sue? It looks into these two states. It looked into one state which satisfies the environment. There is a transition from this state into a state which violates the environment. And that's the beauty of the induction. Of course, if you work in manual formal verification, it's exactly the same. You reason about execution.
00:24:54.054 - 00:25:31.954, Speaker A: We start from a state, satisfy the environment into a state, violate the environment. So that's the idea I want to close before I let Alex present the demo. I want to actually sort of tell you some things. And these are of course not just my own experience. This community has been along for a long time. Formal verification has been used in hardware industry, especially after several high important bug were identified. So the question is what's the value of formal verification.
00:25:31.954 - 00:26:07.102, Speaker A: And this is something that we are trying to understand. Some of them, of course, are not just for Web Three. So the first thing that people think about formal verification, in particular in Web Three, you see a lot of people speaking about that formal verification is about proofs. But I think the most value of formal verification are bugs. These are hard to find bugs that you are finding during the process. And I think that's we see, and I try to make it in this talk. And when you use a Satora proofer, you can see that it generates a proof.
00:26:07.102 - 00:26:56.994, Speaker A: And of course the proof has some value, especially if your environment are okay. But the most interesting thing, these are bugs that are prevented. The other thing I already alluded to that is that the hardest problem people think about formal verification, it go back to Rice Theorem and others that say this is a computationally hard problem and of course it is the case, but we think that the hardest problem is actually coming up with these invariants. And actually that's why we need the secure, that's why we need people like you to help us write interesting invariant. And we are trying to incentivize people to write interesting environment, like for example with the Ave, we incentivize people with money. If you write a good environment, you get a reward for that. The other thing is that, and that's also people are thinking about it.
00:26:56.994 - 00:27:27.546, Speaker A: When you think of formal verification, people say, oh, I formally verified that. And one of the giant of computer science, Knuts. How many of you know Knuts? Great. So Knuts of course, is a fantastic computer scientist at Stanford, which has contributed to many fields, including formal verification. And one of the jokes that he said, I don't believe this code, I formally verified it and I've never tested. I think this has a very good thing. The idea is that basically formal verification is just one thing.
00:27:27.546 - 00:27:59.974, Speaker A: It doesn't guarantee that your code is correct. It only guarantees that the environment are maintained, which is of course, increase your security, but it's not a bulletproof. The other thing in the Web Three that people think and they approach us, they say, look, auditing is expensive. We want you to replace formal auditing. It's not what we are trying to do. We are trying to complement auditing. I already mentioned that there are auditors who use Sartora, the human and the computer, they basically help each other.
00:27:59.974 - 00:28:32.670, Speaker A: It's not like an automatic, automatic car when you just have it because you need the human. For example, the human can actually find bugs after us if we don't have the right rules. And then we can update the rules. The human even already we have seen auditors that found bugs in our rules, which is fantastic. It's just another artifact of the code to analyze. And we want the human and the human auditor and the tools to help each other. We are not replacing the auditor.
00:28:32.670 - 00:29:09.418, Speaker A: And maybe the last thing I want you to take, and that's again, something that formal verification is something that you need to think as early as you can. Whether you engage with Sartora or not, it doesn't matter. But you need to think of formal verification, in particular formal specification, as early as you can and use the tool. Even use our tool as early as you can, even when it's feature complete, use the tool. So this is the idea. You want to use this technology as early as you can because it will prevent bugs and it's easier also to use it because the code gets more complex. It's harder to use this technology.
00:29:09.418 - 00:29:48.802, Speaker A: So we want you to start use this tool as early as you can. So, in conclusion, I want to basically tell you sort of three things. One is that bugfinding is hard with our tool. Without our tool, it's hard. But Sartora actually makes it interesting by using this inductive reasoning, by the idea that you write an invariant and we are looking for violation of this invariant. The other thing that I didn't get a chance to explain, but there are talks that we explain that and there are technical people on our team. We are actually producing something which is interesting in terms of new algorithms.
00:29:48.802 - 00:30:22.738, Speaker A: We are actually innovating in the area of static analysis and innovating in the area of constraint solving. And we are combining these techniques. And you are welcome to listen more. What I talk to you is the idea of automatic formal verification. This is the idea that you write invariant and it's like a quality assurance tool that checks the invariant and either find a violation and this violation can be rare or prove absence of violation. So this is it. Please, if you want to scan the technology paper, I suggest what we do now.
00:30:22.738 - 00:30:51.980, Speaker A: I will answer some questions if they are and while I'm asking questions, but maybe just let people scan, alex will set the demo. Please stay. The demo is interesting, but I'm happy to take questions on my talk on formal verification. Please, if there are questions, I would love to take some maybe while you said you can set them. Everybody scan? Yeah, you have question.
00:30:56.590 - 00:31:26.534, Speaker B: Would formal verification still work for systems that are not closed? So, for example, for, let's say, a DeFi application like uniswap, right? You can probably write an invariant where the total USD value of assets in a pool will always remain same after swaps, right? But say for a system which is not closed source, like a cross chain liquidity pool where tokens are coming in on one chain, but they're actually leaving on another chain. So would formal verification still make sense in a scenario like this? What do you suggest here?
00:31:26.652 - 00:31:50.430, Speaker A: Interesting. So the question is, will formal verification make sense in a. System that is not closed. So the answer is it makes the most sense when you have a system which is not closed, but it's more complex. And we work with compound, for example, who's calling uniswap? We work with bridges that actually some of the code is not available. So the idea is modularity. You basically have a requirement on one thing.
00:31:50.430 - 00:32:21.030, Speaker A: For example, uniswap is monotone. And then the question is do you trust this thing or do you check it? So you can do two things. When we analyze the code of compound, for example, we made certain assumption on the uniswap. And the question is do we check them or we don't check them. At the moment, we don't check them. We can check them statically or dynamically. So the idea is, when we work with some clients, they actually call other clients and it's actually the beautiful thing of formal verification and you even seen it that you are finding an API violation.
00:32:21.030 - 00:32:56.250, Speaker A: You are finding a case that I'm calling your code and I'm not able to actually satisfy the precondition for this. So yes, this is actually the most useful application of formal verification is code. And actually there are a lot of interaction between the code and yes, we can do it either statically or dynamically. We can do it statically. It means that we need to analyze both pieces of code. We can do it dynamically. Or sometimes it's just assumption because sometimes it's code that we don't see somebody is calling an oracle or somebody is calling something that is not in, something that we can analyze.
00:32:56.250 - 00:33:28.574, Speaker A: It's a breach, for example. But it actually is the case. We are finding bugs because if you have a bug with respect to the assumption, now you are implementing the compound money market and it is calling the uniswap. And the question is you are writing these assumptions and then you are checking the correctness of the code, not with respect to the actual code, with respect to the assumption that you made. So yes, it is very useful and it is one of the most useful application of our clients. But it's not easy.
00:33:28.692 - 00:33:29.726, Speaker B: That clarifies a lot.
00:33:29.748 - 00:33:37.380, Speaker A: Thank you. There's another question here.
00:33:39.590 - 00:33:48.630, Speaker B: So when you have these formal verification specs and you say that formal verification is competitionally expensive, do you mean that.
00:33:48.700 - 00:33:51.378, Speaker C: You'Re fuzzing the invariant and you're checking.
00:33:51.394 - 00:33:59.586, Speaker B: All of the states like in a brute force method? Or does that computation go into calculating a mathematical proof that this state will never occur or is it like a brute force?
00:33:59.698 - 00:34:23.034, Speaker A: So our technology doesn't do fuzzing, we don't enumerate the behaviors. What happened is that we compile your code into a mathematical formula and the mathematical formula enumerates all the behaviors. And the question when it work and when it doesn't work. It's a very, very hard question. In general, for example, when you have linear equation, it's easier to solve. So we are not enumerating the behaviors. That's the beauty of this technique.
00:34:23.034 - 00:34:58.650, Speaker A: It's actually giving you exhaustive think. Like if you have, for example, in the ethereum, you have like an integer which is 256, two to the 256. We model it as an arbitrary integer. So we give you a mathematical proof and when is it hard? When is it easy? It's very very hard to know. We actually have a lot of algorithms and sometimes they surprise us how well and how sometimes it's really surprising these constraints over that they can actually succeed on things which are very very complex for a human. But sometimes hard. For example, when you have interest rates.
00:34:58.650 - 00:35:17.038, Speaker A: We came to know that we are not doing fuzzing. We are enumerating all behaviors. That's very very different. It's of course more expensive. But we are doing fuzzing, we're not doing fuzzing. We are basically enumerating all behaviors. And of course it's done by this reasoning about formula.
00:35:17.038 - 00:35:50.598, Speaker A: You write a formula like say x square is equal to four and then basically the system will find out that x is two. So that's the idea. We write a formula and then we have open source tool that we are using to find a solution to the formula. And a solution to the formula it means you have a bar and if you find out that there are no solution, we can generate what we call a proof tree, which is actually indicate that you don't have a bar. But this proof tree enumerates infinite number of behaviors. We are not looking into finite behavior. That's a very big difference from fuzzing.
00:35:50.598 - 00:35:59.790, Speaker A: We can do fuzzing, for example to get initial answer and we are actually doing it because sometimes it takes 2 hours until you get an answer and the user is frustrated.
00:36:02.550 - 00:36:22.022, Speaker B: Great, thank you. Which Smt solver have you used and why? Which Smt solver have you used? I'm assuming either Z three or CVC four and which one do you think has given you more empirical? Empirically can you comment on the performance of these?
00:36:22.076 - 00:37:10.694, Speaker A: Yeah, so that's a very difficult question because I'm friend of all the people, but fortunately, actually it's very surprising all. So it's actually on different benchmarks, on a different code, they behave different and historically Yikes is much older and people have invested less. But we find that in some of our example yikes does fantastic well, ztree does CVC. We are also supporting Satora. We raise money to support here we are supporting of these kind of things and we are improving. We are adding now support for Z Three for large bitwise operation. We are working with the answers and also we are thinking of combining them because they have this idea of learning lemmas and sometimes even when you have a timeout you learn something and we can actually combine them.
00:37:10.694 - 00:37:31.660, Speaker A: So we are agnostic at the moment we are using the three of them and our user I think there's a flag, but I don't know alex there's a flag which one to use, but I think most users just let the system choose. Yeah. And there are machine learning techniques that we are doing to optimize that. Yes.
00:37:32.670 - 00:37:36.418, Speaker B: So just to extend on mean since I've seen it in your tool chain.
00:37:36.454 - 00:37:57.362, Speaker A: So just for other people, this Smt solver, these are techniques that are used under the hood here, which are used of course in Microsoft we basically compile the code and the environment into huge mathematical formula, sometimes few megabytes. It's interesting that it works. And this few megabytes of formula, it gives to the solver and the solver gives the solution. Yeah.
00:37:57.496 - 00:38:11.450, Speaker B: So in a tool chain I've seen that you have a lot of custom software right. For your certain application, for your certain requirements. Right. Similarly, have you thought of just creating your own solver? Combining all the strengths of if at all?
00:38:11.520 - 00:38:49.234, Speaker A: Yeah, so that's very interesting. So the question is have we thought of creating our own Smt solver? We don't know at the moment. We have been around for four years. I think it will be difficult for us, but maybe we are more thinking of contributing small things to existing solvers and supporting them. But yeah, it's very interesting to build something specifically for DeFi. What we are thinking more is sort of thinking something on the opposite, trying to tell some kind of design pattern. Tell people if you write the code at the moment, one of things that we are doing, we used to charge a flat price for using the service, but we are no longer charging a flat price.
00:38:49.234 - 00:39:14.320, Speaker A: If you have code which is complex, you pay us more. But the idea is we want to actually reduce the price by telling you if you write the code this way and if you write it more modular, it would be easier for us and it will be cheaper for you. We are trying to scale up but yes, down the road maybe developing a server for DeFi. I know the Ethereum Foundation is interested in that, but yeah, it's interesting.
00:39:20.290 - 00:39:46.182, Speaker B: So the challenge now has transferred to writing specific and very tight invariants. That doesn't seem like an easy task for a complex project. Invariants might get easily complex and there might be bugs in the specification. So you mentioned there's another project which kind of checks the correctness of invariance. Could you please tell a little bit.
00:39:46.236 - 00:40:24.194, Speaker A: More about yes, so you're absolutely right. So the issues that if, you know, I mentioned in computer science we mentioned KNUS, but another giant of computer sciences I'm sure that most of you know is Daxter and I mentioned that Dajkstar, of course invariant go back to a platon. But Daxter said that you cannot write a program without writing the environment. That's of course correct in principle, but it's very hard to write invariant. You are absolutely right. And we also find out that when we are writing environment for our clients, we made them wrong. But the idea is, the question is, what does it mean wrong? If it's wrong in a sense that it finds a bug that our tools say, and then we check the environment, that's one thing.
00:40:24.194 - 00:41:07.806, Speaker A: But the thing that we are worried, we are worried from invariant that actually holds and give you a false confidence on your code. And we already have one client who actually use us in addition to auditing. And then basically, if somebody found a bug and they didn't accuse the auditor, the customer actually wrote the invariant and there was no failure of the tool. The problem that the invariant was topology, you write something like seven is greater than five. And the tool of course was able to prove that seven is greater than five, and it's increased the confidence of the protocol. So now, if you look into the Satora, even if you look into the version that you have, this cannot happen. We have basically a vacuity checker.
00:41:07.806 - 00:41:30.358, Speaker A: We have something that checks. If we have a bug, it's a bug. But if we verify your property, we try to check if it's vacuous. We try to check, for example, these kind of bugs we can avoid. And what we do, we do mutation testing. We mutate your code, we take your solidity code and you change it. And if we change it and the environment still holds, we suspect that something is bad.
00:41:30.358 - 00:41:59.940, Speaker A: And this is very good for us because as a company, we are basically engaging with larger community and the ideas people are submitting environment and we have no idea this environment good or bad. So we are using these tools to evaluate the environment that the community submit. For example, in the average project, I think we have 25 security who are submitting environments. So we are using these tools to check the environment, both the environment that are produced by our team, but which are written by other people.
00:42:04.630 - 00:42:17.400, Speaker B: So you mentioned about correctness preserving transformations. Could you elaborate a bit on that? Like how do they preserve the correctness or how do they work or give an example of that? Maybe.
00:42:19.150 - 00:43:16.730, Speaker A: I mentioned the correctness preserving transformation. So this is of course we basically did wait, so I don't know how much the way code is generated in the EVM, but it's basically what this idea was called, bump allocator. So basically memory is allocated and what we observe certain properties of this bump allocator. And in order for that to simplify the code, this is how we identify many of the bugs in the solidity compiler itself. And we are actually submitted an article about that and we will publish it, of course. So these are results that basically these are techniques called static analysis, which actually infer some properties of the code. And intuitively, the idea is, for example, you have a load and a store and instead of letting the smt reason about it, we can reason about it.
00:43:16.730 - 00:43:40.254, Speaker A: And this is a game changer. It takes something from timeout and convert it to seconds. It's a game changer. Of course, the Smt, it's a complex technology. The less you can call it, whether all the Smt solverates, the better. And we want to do more like understanding the values and this how we say correctness preserving transformation. But of course, we haven't proved that they are correctness preserving transformation.
00:43:40.254 - 00:43:49.954, Speaker A: It's code that we are written in our tool. But of course, up to a bug in our tool, they are correctness preserving transformation. Yeah, that clarifies.
00:43:50.002 - 00:43:50.760, Speaker B: Thank you.
00:43:55.930 - 00:43:57.480, Speaker A: I think we'll let you.
00:43:59.790 - 00:44:40.374, Speaker B: So I'm going to take you through a bug that Muli also spoke about. It's the bug that we found in the Trident constant product liquidity pool. The idea is to give you some sense of how you work with the Sotora approver to find bugs. If you want, you can also start working with me if you go to demo. So just go to Certora.com and look for the demo button on top right, you will land on this page. Just go to the interesting bugs part and click on the custom product broken piece and this page will open up.
00:44:40.374 - 00:45:45.814, Speaker B: So on one side you have the solidity code that we are trying to verify. On the other side, we have the spec that we've written and the tool takes both of them together and mashes them together, does a bunch of optimization and then comes up with the logical formulas which are then fed into the Smt solver all that stuff that Muli spoke about. But let's first look at the solidity code and then we'll look at how we went about verifying this. So it's essentially, as I said, it's a constant product liquidity pool which implements an ERC 20 protocol also for the LP tokens that it mints and distributes. So for those of you who don't know, liquidity pool is basically where you provide liquidity and people use that liquidity for various applications. In this case, this liquidity pool was going to be used for an automated market maker. And it was a constant product pool where people like you and me, we can supply liquidity to the pool.
00:45:45.814 - 00:46:15.362, Speaker B: And as an IOU, we get back some LP tokens. These LP tokens from a liquidity provider standpoint can be redeemed for your share of the liquidity. So you get back some part of the protocol. So you'll get some part of the liquidity pool. So you get back somewhat of both the tokens. The idea here is that I'll talk about the properties later. I'll just quickly run you through the contract here.
00:46:15.362 - 00:46:37.530, Speaker B: So it's an ERC 20 contract. On top of that, it builds functionality for the liquidity pool. So we have two tokens. It's a classic two token constant product sort of a pool. So we have two tokens. The contract also keeps a track of the reserves that we have for each token. It also keeps a track of the product that it adheres to when it's swapping tokens.
00:46:37.530 - 00:47:21.580, Speaker B: This product, of course, goes up and down based on the overall liquidity in the pool going up and down. But when you're swapping before the swap and after the swap, the product needs to remain the same. There's a mint function which basically mints the LP tokens whenever you add liquidity to the pool. And these LP tokens are essentially shares that you hold in the liquidity pool. So when you redeem it, you get a part of the liquidity, the tokens that are sitting in the liquidity pool. There's a bunch of logic in here that is not relevant for this discussion, so I wouldn't go into it. This is the most important or most interesting function here.
00:47:21.580 - 00:48:13.914, Speaker B: So typically in a liquidity pool contract, when you're redeeming your liquidity pool tokens for the underlying assets in the pool, you would redeem the tokens and the contract would give you back two tokens, some amount of each of the two tokens in the contract in the pool. But there is a special function here which is called Burn single. What it does is that when you are redeeming your liquidity, it allows you to pick one token that you want to get paid in, instead of two tokens. It allows you that extra functionality where if you choose to get paid in just token One or token Two, you can do that. So what this function does is it does two things. First, it withdraws your liquidity based on the amount of tokens that you have, essentially what share of the liquidity pool you own. Based on that, it calculates the amount of each token that you're supposed to get.
00:48:13.914 - 00:49:20.190, Speaker B: And then after that, it does a regular constant product AMM sort of a swap where it exchanges one token for the other, the token that you want. So the functionality for finding out the amount that you're owed by the pool is here, where it's calculating the amount of tokens you get for each token by looking at the liquidity and the total supply. So that's your share of the pool, that multiplied by the balance for each token and that gives you the amount. And then when you come further down, this is where it's taking a token and looking at the amount of that token that was calculated in the step before this. And then it's based on the new state of the liquidity pool, where of course now the reserves have gone down because you've withdrawn some amount from each of the tokens. So based on the new state, it's going to figure out how much tokens you are eligible for of token B for the given token a amount. And then it adds that amount that is calculating here to the amount that was calculated here.
00:49:20.190 - 00:50:25.274, Speaker B: And that's the total amount it'll transfer to you in one single transaction. Okay, now I think I'll go to the spec after this. So the idea here was that as a liquidity provider there are certain things that you would be wary of. If I'm providing liquidity to a liquidity pool, I would want to be sure that I should be able to withdraw that. So if I have LP tokens I should at any point in time be able to exchange those LP tokens for the underlying liquidity pool assets. Similarly, if I'm depositing something into the pool I should definitely get some LP tokens which is a proof that I've supplied liquidity to this pool and so I'm eligible to withdraw the money that I've supplied back. So the idea essentially is that from a liquidity provider standpoint, if you have certain reserves in the pool, then there should be liquidity pool LP tokens out there in circulation.
00:50:25.274 - 00:51:34.986, Speaker B: Otherwise there's no way to withdraw the funds that are in the liquidity pool. Similarly, if there are liquidity pools in circulation, liquidity pool tokens in circulation, then there should be reserves in the liquidity pool itself because otherwise the tokens that you hold, they don't mean anything because you don't get to withdraw any liquidity that you supplied. So all these properties that I just spoke of, these are fairly high level properties. You don't really need to look into the exact implementation of the liquidity pool. Everyone can get that concept that if you've invested, I mean supplied some liquidity to a liquidity pool, you should be able to withdraw it and you should get liquidity pool tokens which are essentially a proof that you've supplied liquidity. So when we paraphrase that into a logical expression, this is what we get. So this is essentially the invariant that we had written here, where we are saying that the total supply of liquidity pool tokens can be zero if and only if the reserves of the underlying assets are zero for both.
00:51:34.986 - 00:52:39.998, Speaker B: The tokens. And when we run this very simple intuitive invariant which doesn't need you to look at any implementation, just a very high level thing that makes sense to you. When we run this against the tool it shows us a specific bug that we found. So when you run the tool, essentially I'll tell you how we run the tool. So we invoke the tool and we give it the contract that we want to verify. We specify the contract that we want to verify in the solidity file and then we specify the specs that we want to verify the contract against and any other helper files. Like we would need some ERC, 20 implementations here to model some of the calls that are happening to, ERC 20 contracts and then the compiler that we need and some other flags that I don't think we need to get into right now.
00:52:39.998 - 00:53:26.442, Speaker B: But yeah, essentially we are giving the tool the solidity file that we want to verify, the contract that we want to verify and the specs that we want to verify. And this is what the report looks like. On the left pane here, you have a bunch of rules and invariants that you've written. So if you've written multiple rules and invariants that you've run with the tool, you would get a list here. And for each rule, it will either show you a green circle with a tick mark or a red circle with a cross on it that says violated, and it lets you do a deep dive. This was an invariant. And this tells me that this invariant failed in the preserved state of the invariant.
00:53:26.442 - 00:53:56.530, Speaker B: So I want to talk a little bit more about how invariants work with Satoraprover and Mulli. Feel free to add if you want. So, invariant, we prove invariants using induction. Invariants are proved in two stages. First, when the contract is deployed and the constructor is run. After that, the tool verifies whether the invariant that you've written, whether that invariant holds or not. And then if it holds after that, the tool will assume an arbitrary state which still conforms to the invariant.
00:53:56.530 - 00:54:55.000, Speaker B: And then from that arbitrary state, it will call any function in the contract. And after that function is executed, it will again check if the state of the contract adheres to the invariant that you've written. Once both of them are verified, once you've established that after the Contract has been deployed and constructed, the invariant holds. And after starting from an arbitrary state which conforms to the invariant and running any arbitrary function in the contract, the state of the contract still conforms to the invariant that you're testing against by induction, you can prove that this contract, this code, will always adhere to the invariant that you're trying to verify. So the first stage of the invariant is what you see here, what we refer to as in state. This is what is verified after the deployment and the construction. And we see that the tool tells us that what's happened here.
00:54:55.000 - 00:56:09.998, Speaker B: Just give me a minute, guys. Okay, so instate is, as I said, the first stage of invariant checking, where it checks it right after construction and preserve state is a second state where it checks after that, when it assumes an arbitrary state which conforms with the invariant and then checks against all the functions in the contract. So the preserve state is what is failing here. So this has to fail for at least one function in the contract. So when we click on it and do a deep dive, it shows us that burn single is the function. I hope everyone can see this is people on this side able to see this. So burn single is the function which is causing an issue for us.
00:56:09.998 - 00:56:51.238, Speaker B: So again, we further click on it, click on the error. And now you start seeing things popping up on the right side, then it is a bit wonky, yeah? So this is a section that shows you all the rules that you've written. Within those rules, if you drill down, it'll show you further exactly what part of the rule or the invariant has failed and specifically which function has failed you. This part will tell you the call trace. Call trace essentially showing you a detailed view of the entire execution that the tool has gone through and it'll help you understand exactly where the error is. This section is where we have the variables and call resolution. This section gives you more information about the exact values of the variables in invariant.
00:56:51.238 - 00:57:32.700, Speaker B: Since we don't have many variables, you don't see much here. But if you write a rule and I'll show you what a rule looks like, you've already seen what an invariant looks like. If you write a rule in which you've specifically defined certain variables that you want to track the state against, that you want to track against the state, then all those variables will get populated here. And you will very clearly, quickly, clearly see a snapshot here of what the value was for those variables before and after some function was called. And it makes it a lot easier for you to understand the counterexample. Now I'll take you through the call trace to explain to you what's happening here. I'll get to the preserved block after this.
00:57:32.700 - 00:58:21.820, Speaker B: It's an additional functionality we have on invariance, which makes it a little more useful when we have additional specific preconditions that we want to apply with invariance. But yeah, you see here that the tool says assume invariant in prestate because that's where it starts when it comes to proving specifications, proving invariants in preserve state. So it assumes an arbitrary state and it ensures that that arbitrary state conforms with the invariant. And then it runs a function. In this case, it's running the burn single function. We click further and it tells us more details about it. So at this point, let me take you back to the burn single function so it'll be easier for you to understand what's happening here.
00:58:21.820 - 00:59:48.210, Speaker B: Mint burn single? Yeah, so the burn single is getting as parameters and a token address liquidity, which is essentially the total number of LP tokens that the person has and the address of the recipient. So the address that gets all the tokens that are withdrawn from the liquidity pool, that address. So what it's doing is it's using this liquidity to calculate the amount of tokens for both the tokens that need to be paid out to the user from the liquidity pool. So it's using the liquidity, the total supply, using that fraction on the total balance of the contract for that token, calculating the amount similarly for the other token, and then it's burning the liquidity tokens because now you've withdrawn the liquidity. And then based on the token that you've supplied here, it decides which token needs to be swapped into the other token. And that calculation is done here through the get amount out function where you supply the amount of the token that you want to swap out of and you also provide the latest state of the liquidity pool. So this is the reserves of the two tokens after the liquidity has been pulled out.
00:59:48.210 - 01:00:38.654, Speaker B: So the amounts are updated by reserve minus whatever amount you're withdrawing from the liquidity pool. And then after that, that amount is added to the amount of the token that you want to withdraw. And then we do a simple transfer of that token, that amount to the recipient. It seems fairly straightforward. But where things go wrong is that the specific example that the tool shows us here is that when we call the burn single function with certain amount of liquidity and some recipient that's not important right now, but we see that the tool is showing us in call trace these steps where first the function is checking for the reserves, it's checking for the balances. And these balances are being used to calculate these amounts. So we see that clearly here that it's checking for the reserves.
01:00:38.654 - 01:01:10.480, Speaker B: It tells us that it checked for the reserves and the values that it got back were five and four for both the tokens. Similarly, the balance amounts that it got were 15 and four for both the tokens. And then it checks the total supply, that is a certain amount. Bear in mind this total supply and the liquidity that's been giving us. So this liquidity is smaller than the total supply. It's supposed to be a share that you hold in the liquidity pool. And after that we call the burn function.
01:01:10.480 - 01:01:47.900, Speaker B: Right now we are here. So we've seen these steps, we've seen this step and in between we've gone past this calculation where amount zero and amount one has been calculated based on the liquidity and the total supply that we've saw, we've seen. So after this, we go to the burn function and then we are looking up the tokens for so this is the lookup that you see here for the tokens and eventually we end up calling the why is that call.
01:01:53.090 - 01:01:53.454, Speaker A: Yeah.
01:01:53.492 - 01:02:50.458, Speaker B: So eventually we end up calling the get amount out function and that is this function which is helping you swap from one token to the other. And one peculiar thing that we see here is that basically you're providing it some amount of a token that you want to get rid of and that's this amount and you're telling it that right now the state of the liquidity pool is this. And if you notice that one of the reserves for the liquidity pool has already gone down to zero. And that begs the question as to how this happened. If one person we can clearly see here that this user has a certain amount of liquidity which is clearly less than the total supply, which can be seen here. If somebody's really good with hexadecimal math, you can see that it's. Clearly a subset, which means that the person does not own the entire liquidity.
01:02:50.458 - 01:03:50.210, Speaker B: So if they've done a withdrawal, it shouldn't be the case that they've completely drained out the reserves for any one token. But that seems to be the case here. So that takes us back to the code and we want to understand what happened. And that's when we realize that the way these amounts are being calculated is wrong because we are using these liquidity shares and multiplying that with the balance of the contract. And we see here that the tool shows us that the balance of the contract is different from the reserves that it's tracking the liquidity pool against. You can see for token A, the reserves are five and the balance is 15 here. So if you calculate the same small share against an inflated balance amount for a token, it could very well be the case that inflated balance could be equal to or greater than the actual reserves being maintained in the liquidity pool.
01:03:50.210 - 01:05:02.262, Speaker B: And here in this specific example, what the tool is telling us that the balance was such that for this given amount of liquidity and total supply, this amount ended up being exactly equal to the reserve of token zero. In which case when we called the get amount function, this value ended up being zero. I mean this value ended up being zero and the other value was whatever was left after the swap. And if we look at this function in more detail, we figure out that if one of these reserve values is zero, then what happens is that the output value that it's returning, which is basically the number of tokens that you'll be able to swap into, that number is essentially equal to the total reserve. So what's happening here is that in this particular case, when you call the burn single function, it's allowing you to withdraw the entire liquidity of the second token. So the balance for the first token was inflated because of which the share that was calculated was wrong. It was equal to the reserves of that token.
01:05:02.262 - 01:06:18.610, Speaker B: And then when you called the get amount out function, it ended up giving you the entire liquidity that you had for the second token. So at this point we've already broken the variant and that's what the tool tells us. The tool tells us that we've reached a state where one of the reserves has gone down to zero. When the total supply of liquidity pool tokens is still nonzero, one of the reserves has gone down to zero. So this has told us that that intuitive sort of property that we had thought of in the beginning, that if there are liquidity pool tokens in circulation, then there shouldn't be a case where you can get to a state where one of the reserves or both of the reserves are drained to zero. But that's fairly possible. But now the question is, how can someone exploit this weakness of the code? And we looked into that and the attack basically is that you take a flash loan you take a flash loan, send that money over to this contract, and in the process, you end up inflating the balance of that token in the contract.
01:06:18.610 - 01:07:40.046, Speaker B: The way this contract keeps a track of total reserves versus the total balances is that there's a function called update that's called you should see that function. Yeah. For instance, here. So every time it's messing with the reserves of the contract, after it's done messing around with it, it will check what the latest balance is and then update the reserves accordingly. The same thing happens in the Mint function when you've added more liquidity to the pool and it's given you some liquidity tokens at the end of it, it'll make sure that that newly added liquidity is also captured in the reserves that the contract is tracking. If you take a flash loan, send that money over to this contract and jack up the balance for one of the tokens, but you don't end up calling the Mint contract. Then what you've done is that the reserve? Continues to be what it was but the balance is inflated way beyond the reserve value at this point if you using your tiny share the limited number of LP tokens that you have if you call the burn single function you will be capable of essentially your share gets inflated.
01:07:40.046 - 01:08:26.154, Speaker B: So what happens is all these numbers get calculated against these numbers, they get calculated against an inflated balance number. So for the same small share, you're getting a much bigger number. And if you manage things such that this big number is exactly equal to the reserve value at that time. Then you can make the get amount out function to give you the entire liquidity of the other token. And once you've done that, the next step of the attack is that you call the swap function here and the swap function will again. This time you reverse it. This time you give it the other token with just one amount and again because one of the liquidity pools has been drained.
01:08:26.154 - 01:09:26.546, Speaker B: The Token B has been drained. So this time around, because that was zero in the computation, it will give you the entire liquidity for Token A. So what you've done essentially is you've drained the entire liquidity for both token A and token B there are still LP tokens in circulation and there are no reserves to back it. So our tool told us that it's possible with the get single function, it's possible to get into a state where you break the invariant. And then looking at that example and thinking a bit more on how to make it a complete exploit, we figure out this overall larger exploit. It should give you some sense of how powerful the tool is, because you've not even had to look at the implementation of the protocol. You've just, from a liquidity provider standpoint, thought of the very basic thing that the protocol should give you in terms of security, and that is the ability to withdraw your liquidity at any point of time.
01:09:26.546 - 01:10:20.386, Speaker B: And just put that down into a simple, logical formula and run that against the tool and the code and you get this invariant. The tool obviously is much more dynamic, while the strongest properties that you can verify with the tool are invariants, which are as simple as this one because they cover a large part of the code. An invariant like this, as broad as this, can break because of any small functionality, any small function in the code. So you're not restricting your checking to any specific part of the code, but you're looking at the entire contract. So these are the strongest invariants. If you can think of high level invariants like this, which pertain to any part of the contract, they'll always give you the best results. But the tool also allows you to write more specific rules.
01:10:20.386 - 01:11:23.094, Speaker B: We have something known as you can write rules. Rules are essentially a combination of a prestate, some function execution, a post state, and then an assertion based on the state transition that might have happened. You can write rules for specific functions, you call specific functions, then track what happened in the state change and assert the change that should have happened and see if the contract breaks out of that rule. In any case, you can write more general rules where you can have so what we call parametric rules. These rules are run against every function in the contract. So you write some preconditions about the state before then any function here. So this call basically means that the tool will call every single function in the contract with any arbitrary arguments.
01:11:23.094 - 01:12:17.250, Speaker B: So this call data ARGs is a dynamic data field which the tool populates with all possible ways, in all possible ways to fit all possible function signatures. And it gives you complete coverage in terms of the inputs that you can feed into these function calls. And then it checks the state after that and any assertions that come after that. So you can use some aspects of the tool to write even very specific unit tests for small functions. So like as Mooli mentioned, that sometimes the code, I mean, this tool is bound to fail. It's only a matter of how complex the code is. And when we encounter very complex codes, sometimes we have to take a more modular approach, which involves looking at the most bottom level contracts, looking at individual functions in those contracts, verifying the functionality of those contracts.
01:12:17.250 - 01:12:32.670, Speaker B: And once we are very sure that those functions work exactly the way they're supposed to work, then we summarize those functions and we assume that they work correctly for the more higher level contracts. So that sort of eases the job that the prover has when it comes to verifying the more higher level contracts.
01:12:33.410 - 01:12:33.774, Speaker A: Yeah.
01:12:33.812 - 01:13:15.600, Speaker B: So you can write rules very specific to certain functions. You can write more generic parametric rules to test out function execution, or you can write very high level properties using invariance, and the tool will tell you if your code is capable of breaking out of it. So, yeah, that's what I had. Any questions? What's that? The tool is free. Mooli has said this many times, but let me say this again. Go to the demo page. Work with this as much as you like.
01:13:17.570 - 01:13:18.174, Speaker A: It's free.
01:13:18.212 - 01:13:36.338, Speaker B: You can plug in your own code here, your own spec here. We have tutorials, free tutorials on GitHub. Please learn. I'm very new to it. I went through securium. I learned the tool in a matter of two weeks and then used it on a project. It's very easy.
01:13:36.338 - 01:13:54.006, Speaker B: We have a very strong community support internally in Satora. We give a lot of importance to that. So if you're curious, if you want to learn the tool, there are a lot of people out here to help you. It's all there. It's up to you. It's easy to learn our language. CVL is very similar to solidity.
01:13:54.006 - 01:14:31.110, Speaker B: So if you're familiar with that, it should be very easy for you to learn Satora prover. And yeah, use as much as you like. It's free. And get more used to it. And talk to us if you're interested in working more with us. Anything else? Mulli? Yeah, good. No, we are you asking if we work with multiple contracts.
01:14:31.110 - 01:15:38.518, Speaker B: These properties, they don't necessarily have to be from one contract. Like, if you have one higher level contract and that contract interacts with multiple lower level contracts, which then again, go and interact with other low level contracts, these properties will be verified on the system as a whole. So the invariant is checking every function that it gets from the high level contracts all the way down to the lower level contracts, unless you apply some sort of a function filter. That's, again, another feature that we have. But yeah, it runs across the board, and when it runs on higher level contracts, there are nuances to how the tool models that interaction, that intercontract function calls. If you like, it can assume the worst case scenario, assume the most arbitrary behavior coming back from that external function call, or if you have specific implementations that you want the tool to work with, you can link specific implementations. Or we have something called dispatcher, which again, adds more nuances as to how these calls are routed.
01:15:38.518 - 01:16:24.038, Speaker B: But, yeah, our philosophy is that we want to be extra careful, so we always over approximate. When in doubt, we over approximate. So if you don't specify any particular implementation or if there are multiple implementations, but you don't tell the tool how to use those implementations, the tool will go ahead and assume the worst case scenario that this call could return anything. So it will do all that heavy lifting of checking all possible scenarios there. But if you're very sure of the nature of that interaction, the implementation on the other side, then you can make life easier for the tool by giving it the exact implementation. So again, the tool is bound to fail if the code is complex enough. And if these interactions happen with a lot of what we call havocing.
01:16:24.038 - 01:17:09.206, Speaker B: havocing is essentially assuming that haywire. So if you give it a lot of havocing, chances are it will fail. But yeah, the art is in finding that balance. How do you get this very powerful tool to work for your project? The tool can sometimes timeout. So before writing rules, specification, do we get a sense that this particular rule will timeout or like after running the tool? Only usually what we do is before starting on a project, we do something known as a sanity check. Sanity check is a very simple rule which says that this is the function. It's a parametric call.
01:17:09.206 - 01:18:06.646, Speaker B: If you remember seeing the parametric call, where we just do an F ARGs call, which is a call to every single function in the every single external function in the contract and all the contracts in the scene, actually. And we just call the function and do an assert false. So an assert false is bound to fail as long as the prover gets to that point. But if the code that you're trying to verify is extremely complex, so complex that the tool is not able to get to that point where it's just too caught up in all the execution and all the branches and all the loops that are happening in the functions, then it'll never get to the assertion and it'll time out before that. In that case, your rule will pass because you never got to the assertion and the default is that it passes or it times out. If you do a sanity check, then it times out. So the first thing that we do with any complex project not just complex, any project, unless it's just one single solidity file.
01:18:06.646 - 01:18:51.440, Speaker B: And it's very obvious that it's a very simple thing, which is the Rarity. I've never seen such a project in my time with Satora. But yeah, the first thing we do is to do a sanity check, which gives us an idea of which functions are passing, which tells you which functions are easy and which functions are failing, or rather timing out, which tells you that it's too complex. So it gives us a sense of where we need to optimize things and how do you need to break it up. Anything else? Ask OS. Are you guys curious about Sotora? Do you want to work with it?
01:18:53.270 - 01:18:54.020, Speaker A: Yeah.
01:19:01.190 - 01:19:27.820, Speaker B: Hello? Yeah. If we complete all the challenges, whatever you're given, can we become an official formal verification engineer or something? Yeah, I think Moly would be the right person to answer that. So, yeah, we partner with communities like that, and we pay people in the community who write rules using our tool, write rules, and verify code using our rules. Mulli, he's interested to know.
01:19:29.710 - 01:19:30.138, Speaker A: If I.
01:19:30.144 - 01:19:45.854, Speaker B: Complete all the challenges and everything, will I officially become a formal verification engineer? Certification? I don't know if we do that. That's not the point of these challenges. These challenges are to get you a sense of how the tool works.
01:19:45.972 - 01:19:53.458, Speaker A: Yeah. So we have engagement with Secure. We have engagement with Secure. Is that the question of how to study?
01:19:53.624 - 01:19:54.818, Speaker B: Is that what you're asking?
01:19:54.904 - 01:20:02.162, Speaker A: So we have an engagement. I think there is an online so.
01:20:02.216 - 01:20:35.726, Speaker C: Sartora has collaborated with Alex Said online communities, and one of them is Securium. And Secureum is an online community of ethereum security smart contract, security focused, interested aspirational experts, the whole thing. Right. So the collaboration in this particular case was really to learn. I mean, Sertora had a workshop that goes deeper than these challenges. I think Alex's point here was these challenges are really for educational purposes, right. They don't lead to a certification.
01:20:35.726 - 01:21:09.000, Speaker C: But Sertora has collaborated with Securium and Ave as well, where once you learn the tool, you can apply it on the code base that is within the scope, and the top performers are given I think there were certifications as well from Satura. I'm not sure, but Securium has issued NFTs that show that, hey, you've got this. Sartora knowledge and expertise, and there have been monetary financial incentives as well.
01:21:10.690 - 01:21:22.940, Speaker B: It all right, guys. Come talk to us if you want to know more.

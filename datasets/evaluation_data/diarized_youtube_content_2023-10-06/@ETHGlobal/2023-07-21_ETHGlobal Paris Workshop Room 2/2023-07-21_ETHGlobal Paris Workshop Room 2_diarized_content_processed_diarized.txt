00:03:19.700 - 00:03:22.680, Speaker A: Okay, so hello?
00:03:22.750 - 00:03:23.370, Speaker B: Hello?
00:03:26.700 - 00:03:27.592, Speaker C: Can you hear me?
00:03:27.646 - 00:03:50.448, Speaker A: Yeah. So good morning, everyone. Well, good afternoon, actually. Welcome to East Global. The first talk. And yeah, today we have some sweet things for you. Ideally, I'll be talking about some of the things that developers fall in love when you embrace them, when you discover them, when you think, okay, how could I be doing this before? Right, let's get started.
00:03:50.448 - 00:04:16.680, Speaker A: So we are in 1970. Welcome to Digital Equipment Corporation. The computer they released was called PDP. How did it work? The entire system was basically one program, right? And if you needed to change something, basically there was one program running the entire thing. There used to be one program for every architecture. There was no way to add to remove. It was basically something monolithic.
00:04:16.680 - 00:05:00.010, Speaker A: But then came operating systems. So you have a trusted kernel that can basically do everything it likes. And then you have untrusted programs that interact with the kernel to do things so that you can have many programs and you can basically forget about what's behind. And how does this look like? So at the top you have, let's say, the network, basically the things that the hardware itself. And then below you have different programs that might need to interact to these resources. For example, if you want to use Spotify, spotify will talk to the kernel in a kind of standardized and abstracted way so that it can use the speaker, so it can use maybe the network display, whatever. Right.
00:05:00.010 - 00:05:36.384, Speaker A: But fast forward into the future. Where are we, let's say, 50 years later in, let's say, 2017? Yeah, well, I think we're at the same place because back at the time, every protocol that needed to be made had to be made from scratch because there was nothing to build an abstraction on top of. Right. So basically, well, writing the entire protocol every single time, there was no way to add and remove features. There was no way to easily customize things. But then this changed. This started to change when Argon in 2017, released Argon OS, the first version.
00:05:36.384 - 00:06:13.884, Speaker A: It was the first solution to a problem. It was revolutionary in many terms, and still, as of today, it is unhacked, it's very robust. And it worked based on templates, right, as a different template for NGOs, for associations, for for profit companies. And it was good for some of these use cases, but at the same time, it had some challenges for it to be used in simpler use cases. And some of the lessons learned is that there are not two equal communities. Two dows are going to always need different things. They are going to have different flows.
00:06:13.884 - 00:06:54.680, Speaker A: They are going to require something new to them. At the same time, the same dow always evolves over time. You can start today and you have no idea of what your community is going to look like in the future. What you will need and you cannot. I mean, it's super hard to design for this ahead of time. And another lesson being learned is that many times Argones has been forked and has been implemented for very big projects like Lido, Decentraland and so on. The thing is that this is not ideal because you need to fork and maintain a big code base, right? So if you can extend instead of forking and maintaining a whole thing, that's a big bonus.
00:06:54.680 - 00:08:04.852, Speaker A: And for this, this year, in 2023, March this year, we have released OSX, which is basically a massive leaf forward, which consists of two components. So we have a Dao core and then we also have untrusted plugins or external addresses, let's say contracts that can interact with the Dao core. Doesn't it sound a bit familiar to you? I think it should, because basically we're talking about the same concept of an operating system, which is there are some plugins, some contracts, some wallets that want to use the Dao, right? They want the Dao to do something with shared resources, pretty much like programs do in an operating system. So for example, if a plugin wants the Dao to transfer some dai to another address, there will have to be some governance proposal on the plugin. But essentially the plugin will need to have permission to go to the Dow. And then the Dao internally has a permission database, which is basically the bible of everything that can happen within this community, right? But then we've been talking at least the title is about the Unix of Ethereum. Let's get a bit into this.
00:08:04.852 - 00:09:03.972, Speaker A: What's? The Unix philosophy. If you're developers, you're most certainly aware of some of the basic principles of it, which is writing programs that can do one thing and do it well, right? Doing components, building programs that can work together, that they can talk to each other very easily, that you can compose, that you can combine and architect something bigger than just the program itself that needs to grow indefinitely. And also flexibility if you build small pieces, these small pieces should be able to work in many scenarios, not just for one specific use case, right, but should be reusable by many other tools. So again, you can build more complex things and more interesting things. This is a very simple Unix program. All it does is just opening a file, reading some data and reading it back, writing it back, et cetera. The blue dots here, the blue functions here, they are the absolute simplest things you can find.
00:09:03.972 - 00:09:53.296, Speaker A: You don't have an open file function, you don't have a write buffer word. No. You have a generic function that works everywhere for every single kind of thing. But on top of this, for example, with programs like the one we had here, imagine we compile this, we eventually have a layer on top in which we can start composing some of these programs, some of these binaries that we made to make something more interesting, more complex and more accepted away. How do we translate many of these terms? Let's say for ourselves, for Aragon OSX? So in Unix, everything is a file, okay? For us everything is a permission. Because eventually you want to execute something, right? There are system calls like read, write, exec, etc. For us there is dow execute, asking the kernel to do something permissions.
00:09:53.296 - 00:10:27.808, Speaker A: For example, change mod, change group, change owner. Well, we have granting and revoking permissions. And then we have some of the basic utilities like las, copy, et cetera, which are some of the plugins that we ship ourselves. And some of the plugins that anyone can do, can be a multisig, can be token voting, et cetera. There are some additional guiding principles that we have inherited not only from Unix, let's say, but some other languages, like for example, Rust. We like there to be only one correct way of doing things right? We like clarity, we like developers. We want developers to be explicit about they do.
00:10:27.808 - 00:11:10.428, Speaker A: If this code is going to be audited, it needs to be obvious what the code is doing. We don't want any hidden magic behind the scenes. At the same time, we want people in general, the community, to only pay for the gas for features that they need and that they are using. Just no hidden bloat, not just shipping 20 million things that you don't use, but they are there, right? And it needs to be easy to understand and to reason about because after all, it's all about security. So then let's start talking about plugins. Because Argonnex is basically about a community, is basically something valuable that needs to be protected by many people. There needs to be many people behind for this to be secure.
00:11:10.428 - 00:12:09.570, Speaker A: And for this we need plugins. What is a plugin? Basically a plugin is our way to solve a small problem, a small custom problem, following the index values of his. So make it simple and stop remaining the wheel. Basically reusing everything else that we as Argon offer for free. Basically plugin versioning upgradability, so shipping new versions, allowing people to easily upgrade to the newest features that you ship, maintaining data, maintaining statuses, using the permission management system, which is one of the top most beloved things about the initial versions of aragonos. Also interact with other plugins, also combine different plugins together to achieve the custom scenarios that your dow needs and more that we're going to see really soon. And the end goal of this is stop remaining the wheel because we want to ship fast, because we don't want to be rewriting things that have been already solved in the past.
00:12:09.570 - 00:12:46.412, Speaker A: So how does a plugin look like? So first of all, the green box here is, let's say the plugin that for example, we would like to have a multisig, okay? But at the same time we're going to need what we call the plugin setup, just above. Right. What does this plugin setup do? It's a contract that the developer does which manages installations, updates of the plugins and uninstalls. It's basically a script in which you can do basically everything. On top of that, when you want to publish a plugin version, you publish the plugin setup. We have a registry and then in this plugin registry you can create your own repository. You even get an ENS if you want.
00:12:46.412 - 00:13:27.080, Speaker A: And then you keep publishing different builds. If you choose your plugin to be upgradable, people will be aware that there is a new version. They can create a proposal and they can get the latest and greatest features that you just ship to them, even yourself. And then on the other side there are all the goodies to just make all of these accessible to UIs, to any applications that you can think of. So in the end, what's the landscape that this leaves us? Let's say. So as I said, there are not two dows that are exactly equal. So most likely you could, for example, want to start with a dow with maybe one of the SIG plugin and then maybe eventually install another one, maybe install a token voting one.
00:13:27.080 - 00:14:21.740, Speaker A: And maybe in the future maybe you want to do off chain voting and you install a third one and you decide that you want to remove one of the other ones. So you're basically decoupling, let's say, the shape of your dow, the shape of your community from how the actual dow works. So for example, here at the top, imagine that there are many operations that the Dao can perform, many functions. These functions, they have different roles associated to them. When you install a plugin, you granted some permissions and depending on the permissions of this plugin, the address can perform these operations. Right? But if tomorrow, for example, I decide to remove the multisig plugin, let's say I am doing a clean uninstall and then I could install maybe not a multisig, but that's open voting that could do the exact same thing, but with a different logic. So you're basically setting yourself to be feature proof in terms of evolving, operating without committing your dow to be, as it is today, forever.
00:14:21.740 - 00:14:51.460, Speaker A: So let's see some code because my whole point of the presentation is to show you how easy it is to do a plugin. So this is the absolute most simple plugin that you can get. All you have to do is inheriting from plugin clonable, for example, or from plugin upsgradable. You get for free all of the tooling. You can just simply forget about the rest. In this example we have a plugin. What it's doing is preparing a list of actions.
00:14:51.460 - 00:15:36.228, Speaker A: And these list of actions, eventually we connect to the Dao to which this plugin is linked, let's say, to which this plugin is listening to the permission database and we're asking the Dao to execute these actions. That's it. That's the hello world. That's the hello Dao, let's say plugin that you can build. What if, for example, our plugin wants to start using some additional permissions for itself? What if we want to restrict the plugin itself? We don't want just anyone to go there. We want some function to be guarded. So first of all, we will need to create here our own permission ID, which is basically a byte 32 computed by hashing some value.
00:15:36.228 - 00:16:21.904, Speaker A: And then below on the function that we want to guard, we are going to add this modifier. This is the basic building block. Then only the people who holds the permission, in this case my plugin permission ID on the Dows database is going to be able to use this. This is something fluid that you can grant, you can remove, you can evolve, you can iterate, you can have another plugin with a different logic, you can have a different version of this plugin with maybe fixing a bug, et cetera. So it gets really flexible for you to just evolve. How does a plugin setup look like? So there is the Iplugin setup interface which is basically the methods that your install script should implement. So this is a two step process.
00:16:21.904 - 00:16:58.312, Speaker A: Step number one you prepare the installation, the update or the uninstallation of a plugin. And then step number two, Dadao has a proposal and eventually the community accepts and decides to apply the permissions that you have requested. And essentially the plugin becomes installed, updated, whatever. Here you have some example of one of our own plugins. So the Motorsick plugin, what you have is the constructor we do the initial deploy to have, let's say, the implementation on chain that we will then carbon copy. We don't need to deploy every single time. So we use proxies.
00:16:58.312 - 00:17:37.576, Speaker A: So in this example, what we do is pre installation. Your function will receive some parameters that you're going to encode with the settings of this particular plugin. And then you can just simply copy this line that we provide you the tooling to just use it. And then this creates a proxy with your specific plugin instance you get your very own plugin. And then the last step is requesting permissions. This may seem about burbus, but essentially what we're doing here is, well, we're building a list of permissions. So we're saying please allow the Dow to upgrade the plugin settings or please allow the Dao to upgrade the plugin itself.
00:17:37.576 - 00:19:13.112, Speaker A: And at the same time, oh please Dao, allow the new plugin to use, to do execute or to do something right. So you do your wish list of permissions and then the community assesses whether they like them or not. And eventually, if they approve them, these three permissions here are going to make it to the DAOs permission database. Okay, so what is a permission? As we saw before, basically it's a source of entropy, a string hashed which is then a number and we use it to shield functions and permissions they look like granting permission to who to do what on where. So allow the dow to do this on the plugin. But what if we want things to be a bit more, let's say more granular? What if we want some conditions to be a bit more restricted, right? So you can use permission conditions which is nothing more than a contract that you can define, right? So for example, when you have some plugin trying to execute some operation, you could tell the dow okay, whenever someone wants to perform this action, ask this contract and if this contract says yes, you just continue, right? So they allow for us to basically decouple the fact of the features themselves with the restrictions and this prevents things like plugins going super complex because you need to combine a matrix of I want to do this but not that, but yes, but no, it gets extremely complicated. If you can decouple these two things.
00:19:13.112 - 00:20:21.310, Speaker A: Again, you can have very composable, very modular things, a very modular protocol without needing to rebend the wheel because most of the time some of these conditions will have been implemented by someone else, right? Same as plugins, some of these plugins will have already been implemented by someone else and you can just pull them and get, let's say their upgrades for free as well. So in the end, permissions for us would look like grant permission to a certain contract to do a certain role on some target optionally when a condition is met and with this you can just go and build the moon. So this is how simple a permission contract would look like. The only thing it would need to implement is basically the is granted condition, it would receive the parameters of what is being attempted to do and eventually it needs to return yes or no in this case, first parameter being greater than the second one. So this is all I've got for you. There's much more. You can just find us Carlos and Juliet, we will be here around.
00:20:21.310 - 00:21:05.310, Speaker A: We have here a couple of plugin examples for you. So one is an example of a plugin to understand how it works and the second one is more of a project in which you get a plugin and you get also all of the integrated testing and some JavaScript. Client for it to connect on a UI and also some basic subgraph indexing in case you want your Uri to be more user friendly. And all of this. Feel free to take pictures of these QR codes at the same time you can also go to Devs Argon.org and you'll get all the whole documentation of the protocol and also you can join us on discord. So some people from the community are very active, also helping around.
00:21:05.310 - 00:21:30.690, Speaker A: And, yeah, the TLDR for me is the sky is basically the limit. If you don't have to remain the will to build the next Big thing and you can focus on customizing only what you need and recycling everything that there's around, then basically you're ready to Go build the absolute next big thing. So that's it? Pretty much. I'll be happy to ask many questions and expand any of the topics that you think.
00:21:34.100 - 00:21:34.850, Speaker B: You.
00:21:46.060 - 00:22:39.196, Speaker A: Thanks for the presentation. I would have a question about the initial deployment of a DRO. Does the initial deployer or owner needs to write code as a smart contract to set up everything and to include plugins? Or is it just a call to an existing contract so you could decide to deploy it yourself, but most likely you want to use something that we call the Dow Factory. So you call the Dow Factory, which is a contract that we deploy ourselves, is there. And then you pass it a list of the plugins that you want it to have. Right. So by default, the deployer, if you happen to deploy it yourself, you would be kind of having total permission on it with the intent of installing a plugin and then dropping this permission and yeah, can give you more examples on that.
00:22:39.218 - 00:22:39.500, Speaker C: Absolutely.
00:22:39.570 - 00:22:54.192, Speaker A: But yeah, there's a contract that does everything for you. Thank you very much for the speech. Can you please tell us what are your most popular plugins for now, which you created? I mean, your team and what are.
00:22:54.326 - 00:22:56.956, Speaker C: Custom plugins your clients and other dows.
00:22:56.988 - 00:23:43.468, Speaker A: Created that are very commonly used? So we ship four standard ones. We ship the multisig plugin. We also shipped another variant which is called the Address List, which is a version of it which is intended for everyone to vote. Whereas in a multisig you only expect some people to just say, okay, in an Address list, you have an explicit list of address and they vote. And then you have the bullion of this, which is token voting, so you can vote with an ERC 20 token, et cetera. It supports delegation, it supports many of the things that you expect. Then there is another interesting plugin, interesting, we call it internally the Dictator Plugin, which is basically the admin plugin in which one address is able to do everything.
00:23:43.468 - 00:24:19.064, Speaker A: This in cases that, for example, you need to experiment or you need to kick start the dow, you could manually grant permissions to yourself. But the idea of having a plugin, the benefit is that everything is encapsulated. You just add it as a whole and remove it as a whole. So you could start us with this plugin, then upgrade to multisig, then upgrade to any of the other ones that you would say regarding what the community is doing. I don't know, maybe Juliet Carlos can expand on this. But the idea as of now, depending which we are, is people do their custom thing. It's not that they're just publishing plugins around.
00:24:19.064 - 00:24:40.512, Speaker A: This may well become, let's say, the next step. But at this point it's more like not needing, I mean, being able to recycle and just adding the extra plugin that does this very small thing that any of the existing plugins could not possibly solve for you if this replies the question. Hi, can you hear me?
00:24:40.566 - 00:24:41.490, Speaker C: Yeah, I guess.
00:24:41.940 - 00:25:36.540, Speaker A: Thank you for the presentation. I'd like to ask if I'm going to use the Aragon OS Six, will I be able to use the auto generated client as it is done on the Aragon app? Sorry, I have trouble. Could you think of it? Lava? Yeah, so I can close the door. Thank you. Yeah, thank you. So let's say I'm going to use the Argonio Six to create my dow. Will I be able to use auto generated client as it is done on the Argon app? So what we ship is the Argon SDK, which basically provides all the tooling to interact with basically ethereum IVFs and subgraph.
00:25:36.540 - 00:26:57.592, Speaker A: Then on top we build abstraction layers so that you can interact with anything related to the Dao in general. But at the same time, we also sorry about that. So the second example here you get an example of a JavaScript client that uses the SDK to just add the custom things that you need for your client. So the idea is that you get maybe 95% of the tooling there and you can just right away start calling web3, call this contract or IPFS, fetch this data, et cetera. So it's not auto generated because the custom bit that only, you know well, you know, what do you want? We can't possibly know how you intend to use for example, maybe you want to use the graph or maybe you want to use a back end and index something there, or maybe, I mean, there's no general rule here. And last question, could I use SDK to work with already existing one dows that are created from the client as well from the app, for example, to fetch the data to get all of the dows? As long as you can basically call the contracts, as long as you from JavaScript, you can simplify the information, obviously. So again, the message is the SDK gives you all of the building blocks for you to build on top.
00:26:57.592 - 00:29:15.570, Speaker A: We use it ourselves to build our own plugin clients. Right? And you can just replicate this, just write the custom 5% thing and forget about the rest because we did it's of and creating a professional.
00:30:03.110 - 00:30:36.940, Speaker D: No sound in here. Yeah, these lights are so bright.
00:30:39.200 - 00:30:40.590, Speaker B: It's fine, it's fine.
00:32:48.230 - 00:33:28.290, Speaker D: Hi everybody. My name is Shay, I'm from Flashbots and today we're going to be talking about mev, about the history of strange things in the mempool briefly. Hold on. There we go. At a glance. This is what we're going to be talking about today. I'll share with you kind of the history of interesting things that have happened on Chain, we'll talk about new emergent phenomenon and then about how you as a user searcher or an application developer can leverage these tools today.
00:33:28.290 - 00:34:45.230, Speaker D: As a brief introduction, if you are not already familiar with Flashbots, we are a research and development organization dedicated to mitigating the negative externalities of mev. So we develop protocols like the ones you see here, mevgeth, Mevbooth and Mev Share, as well as products like our Bundle Relay for searchers, the Protect RPC for users and wallets and our Block. And the purpose of this is to ensure that the mev supply chain stays decentralized. But what does that actually mean? If you will indulge me, I want to start by taking a quick walk down memory lane, looking at some of the interesting things that have historically happened on Chain. And I'm going to start if you are an OG, you may have seen this slide before. It is a deck put together by one of our mates a few years ago to show how searchers were engaging with the very earliest form of Flashbots. And I want to share with you some of my favorite anecdotes and stories from this because I think they're quite illuminating and still true with the market of searching in Mev today.
00:34:45.230 - 00:35:56.960, Speaker D: So to begin with, way back in the early days of Flashbots, one of the earliest interesting scenarios we saw was when a searcher named Nathan entered the chat. So Nathan was a very sophisticated searcher, who in this example we see, he was able to bait essentially a sandwich bot and steal about 250K from them. And this is actually an example of one of the earliest kinds of exploits in Mev, affectionately known as salmonella. Essentially the way this works is that you create a token which simulates differently from how it executes. So the sandwich bot in this case actually run by miners, was able to buy the tokens but then couldn't sell them back and whoever baited them was able to drain the pool. We also in the early days saw a lot of PvP games between different searchers that were competing and fighting with each other. So this is a very cute screenshot, actually, of two of these searchers who had, I think one of them had wrecked the other one left them a nice message on chain saying, good game, well played.
00:35:56.960 - 00:36:34.168, Speaker D: And then finally, another theme we see is the entrance of new paradigms, new protocols for searching. So this example is of uniswap v. Three. It's really interesting actually. When Univ Three was launched, there basically were very few people who actually upgraded and integrated it. It took months before we actually saw a competitive landscape of Univ Three searchers. And I call these examples out because there are kind of three key themes here, three constants, if you will, in the history of searching.
00:36:34.168 - 00:37:18.460, Speaker D: And they are, first of all, that there are new exploits that emerge, maybe used to be the salmonella exploit now it's something like the low carb crusader. The second theme is that there's also new paradigms that emerge for searching. So different protocols, different ways of thinking. And the final constant is that despite all of this, in the face of all of this change, searchers adapt with style. So you see the very cute P to P messages. This one, I don't know how easy it is to see on the screen, but this is an example of a searcher who is actually recently trying to integrate a new protocol called Mevshare, and they realized that their bot was not going to be that profitable when it first launched. So they called one of their functions the charity function, which I thought was very cute.
00:37:18.460 - 00:38:00.324, Speaker D: But what's happening now? Like, what is the new frontier in searching today? That was a few years ago. What's happening today? I want to share with you a few things I've seen in the past couple of months that I think are quite interesting and allude to maybe a new paradigm in searching and in mev more generally. So I'll start with this one. Like a month, maybe two ago, we saw this token launch happen. And it's a pretty standard token launch. The team announced it on Twitter in advance. And immediately after the token was launched, we saw this bot essentially backrun the launch to basically snipe and grab a bunch of the supply.
00:38:00.324 - 00:38:26.524, Speaker D: The reason it looks weird is that the token launch contract had a clause that tried to prevent people from basically loading up on this token. But as you can see, that was no barrier for the searcher. They were able to just kind of get around it by making a bunch of requests. So all of this is pretty classic token launch, token sniping stuff. Nothing weird here. But there are two weird things. If you take a closer look at the block where that searcher transaction landed.
00:38:26.524 - 00:39:10.476, Speaker D: The first is if you actually look at the original transaction that launched the token, you will see something strange, which is that this is a flashbots bundle. This is a response from the Flashbots blocks API, which tells us that this was actually a private transaction. It's kind of weird. How did this searcher know to backrun them? The transaction itself was private. What's happening there? The second thing you might notice is there's actually a third transaction after the launch transaction and the backrun, which is a transfer from the builder to the original launch address of about $20,000. That's weird. So some portion of the searcher's bid was actually refunded back to the user.
00:39:10.668 - 00:39:11.440, Speaker B: Weird.
00:39:11.940 - 00:39:37.716, Speaker D: I have one more example for you. Yeah. Essentially, how did somebody backrun a private transaction and generate so much value? One more example, which is in this block. I want to take a quick look at another similar case. These three transactions, about a week ago, we saw first a user make a trade on a Dex.
00:39:37.748 - 00:39:37.896, Speaker B: They.
00:39:37.918 - 00:40:08.912, Speaker D: Were swapping some ETH, about ten ETH for this random token called Woofwork. They actually got completely wrecked, not by an Mev bot just because I think the pool was quite illiquid. They basically went from Ten ETH to almost $0. Very sad. You can see this is also a private transaction, okay? People make bad trades all the time. This isn't that unusual. But what is kind of interesting is again, we saw a searcher back running them in the same block despite this being a private transaction and that searcher knew which pool the user was trading on.
00:40:08.912 - 00:41:23.400, Speaker D: Weird, we also yet again saw a refund from the builder to the user who made the original trade. So what's happening? What are these weird phenomena that we're seeing? This is actually not a fluke. This is an example of a new emergent phenomena that's happening today on chain and it's called an order flow auction. So essentially the status quo right now is users will either send their transactions to the public mempool or they will send them to private channels like for example, botsprotect, which is where these two examples came from. And searchers are able obviously to see what happens in the public mempool, but they're not able to see what happens in the private mempool and that's actually pretty suboptimal. While these private channels are really great for protecting users from things like front running, as we have seen there's a lot of value that is on the table to extract even just by back running these transactions, which is something that's fairly neutral usually to the original user. In just these two transactions alone, there's about 15 ETH on the table that's just sitting in these private channels.
00:41:23.400 - 00:42:27.192, Speaker D: So order flow auctions try to find a balance between protecting users and internalizing the value they generate. The premise is that when users transact on blockchains they generate value. And right now that value is primarily captured, as we have seen, by searchers or the validators they have to bid to for inclusion. But we want to give users a fair price for their transactions and the way that we do this is by allowing searchers to bid for the right to execute them, essentially allowing us to strike this balance between protecting users and internalizing or refunding them the value that they create through mev. So this is essentially what we're trying to do is allow some valuable actions to be taken on private order flow. The problem though with all of this is that searchers can't exactly be trusted. So users are using these private channels for a reason, they don't want to get wrecked.
00:42:27.192 - 00:43:13.420, Speaker D: We need to find a way to kind of balance that concern with allowing valuable mev to be generated. And the trade offs here really come down to privacy. The more information you have as a searcher, the more efficiently you're able to backrun or bundle some user transaction. And this is also good for the user because it means that they're able to get a higher bid in the auction. On the other hand, if you reveal too much information, somebody could generalize front run you on another domain or take some other action that negatively impacts the user. So at Flashbots, we have thought a lot about this exact problem, this trade off. How much information do you share? And what we found is that it's not a one size fits all problem.
00:43:13.420 - 00:44:00.940, Speaker D: Different use cases need to share different amounts of information to strike this balance between protection and value internalization. And we call that concept programmable privacy. Concretely, the idea behind programmable privacy is that you control what information you share. And we call these pieces of information hints. So an example of the hints that you might see are things like the contract address or the logs, maybe the call data, maybe nothing the transaction hash that a transaction emits. And what's very interesting about this is it creates a new paradigm for searching. As a searcher, you will have to actually update your strategy to search on these hints and incomplete transactions rather than on complete transactions that you're used to seeing in the mempool.
00:44:00.940 - 00:44:42.340, Speaker D: So for the rest of the time, what I want to talk about is one particular protocol for order flow auctions that uses this concept of programmable privacy. I'll talk about what it is, how it's architected, and then how you as a user or an application developer, a wallet or a searcher can interact with it today. And that protocol is called mebshare. So if I take a quick step back to orient us, if you have seen any Flashbots presentation, you have probably seen this slide. If you have not, here's the slide. You will see it many more times after this. But essentially this is the mev supply chain.
00:44:42.340 - 00:45:22.772, Speaker D: In other words, it's all the steps that happen from when a user submits a transaction to when that transaction is included on chain. And that includes the user's intent, which is then signed through something like a wallet, submitted and bundled by searchers, merged into a block by a block builder and then finally confirmed by a proposer or validator. And to zoom in a bit. Where mevshare lives is right here. So at the very start of the transaction or mev supply chain and the protocol is pretty straightforward. It has about three steps and there's really one primary actor which is called the mevshare node. And the mevshare node is responsible for doing a few things.
00:45:22.772 - 00:46:16.680, Speaker D: First of all, it receives transactions from users. Second of all, it shares whatever hints that user has asked for with the searchers that can publicly see this data. Then it receives partial bundles from searchers which are just like usual bundles, except because we don't share the full signed transaction as a searcher, you're not going to be able to put a transaction in your bundle. So instead what you would include is an identifier for the transaction whose hints you thought matched whatever you wanted to put in your bundle. So for example, that Identifier might be the transaction hash. So a partial bundle would be a normal bundle, but with some transactions and some hashes. Finally, step three, the matchmaker will receive all these partial bundles and then it will convert them into full bundles by inserting the signed transactions that correspond to the hashes that searchers have specified.
00:46:16.680 - 00:47:36.684, Speaker D: And the resulting full bundle is then sent on to a block builder. Pretty straightforward. So how does this fit into the existing Flashbots architecture? Like that protocol is all very interesting and high level, but how do I touch it? Where does it live today? What does it mean for me as a user, a wallet, application developer or searcher? So here is where it sits. If we look back at the original diagram, flashbots Protect is a protected or private channel that users or wallets can submit transactions to. And what we've done is Flashbots has implemented one instance of a Mev Share node, which is that party that sits in the middle of the protocol and that node can be accessed directly through the Flashbots Protect RPC. So these things are now combined together and what this does is allows searchers to, in a safe way try to generate additional value on top of this private order flow. So Flashbots Protect is now upgraded and has a bunch of useful properties for users, it gives them both protection and now with Mev Share, the ability to internalize Mev that they generate.
00:47:36.684 - 00:48:21.648, Speaker D: And for application developers or wallets, it gives you a lot more options about how you actually design your application in an meva aware way through this configurable control panel where you can decide what information is shared with who and how. So to go a little bit more specific, concretely, as a user, the way that you would interact with this is really easy. There is a button on the Flashbots docs. You just click the button, it adds the RPC to your wallet. I think it takes maybe two or three clicks, depending on what wallet you're using. And it's fairly straightforward, all you have to do is switch out your RPC to get these benefits. As a maybe more sophisticated user or an application developer or a wallet, you also have more options.
00:48:21.648 - 00:49:01.852, Speaker D: These are available to everyone, but especially recommended to folks who are developing their own applications that want to kind of tinker with how the Med Share protocol works. So you can select a number of things, including the hints or privacy settings that you want to share, as well as the other block builders that you might want your transactions to be forwarded to. For example, to have increased inclusion rates. You can also select things like how refunds are distributed, what percent of the searcher's bid goes to what address or another. And you can also configure even more advanced things which we call validity conditions. A refund is one example but it's basically a way of telling a block builder how it is required to treat your bundle. Happy to talk more about that after.
00:49:01.852 - 00:49:49.310, Speaker D: If anyone is interested. As a searcher though, what does this look like? I think this is the biggest step change with something like mevshare and programmable privacy is how searchers are going to interact with this new paradigm. Well, there are about two or three things that you'll want to think about and the first is how to consume data. You're going to be using hints instead of mempool transactions which means you have to listen to the mevshare event endpoint, listen to the nodes hints instead of listening to the public mempool. And you're also going to need to parse a different object. You're going to parse something that has these hints in it rather than a full signed transaction. This is an example of what some common hints might look like.
00:49:49.310 - 00:50:44.860, Speaker D: The second thing is you'll have to change the way that you think about sending bundles. In particular, we talked earlier about partial transactions or sorry, partial bundles which just include the hash of a transaction. So you'll have to adopt that new paradigm. And the way that we do this is through a new API we've gone from interesting piece of this once you've got all the integrations hooked up is how you actually change the way you think about your searching strategies. So you're not able to do things like simulate a full transaction anymore, which means that you're going to need to move or change the logic that you use as part of your bot. And there are about two ways that we think about this broadly. The first approach I would call on chain searching and basically what on chain searching is is moving all of the computation you used to do off chain into a smart contract that's executed on chain.
00:50:44.860 - 00:52:10.404, Speaker D: So as an example, if you're used to seeing the amount that somebody is trading in their call data or their logs, you might actually have to use the reserve deltas on chain to run a calculation like at execution time to figure that out. Now the other way you can think about searching on a programmably private transaction or set of transactions is to do it in a more probabilistic fashion. So for example, instead of knowing the amounts and the direction that somebody's trading, you can just guess basically say well, I'll send two transactions, one for each direction that they could possibly be trading on this pool and then I'll also for each of those directions send a bunch of different possible sizes. If this is an ARB, for example, the thing I would emphasize and stress to all of you is like, it took about three months for anyone to really become competitive on uniswap v. Three mev share is also very early, and this paradigm is new. And that means that as a scrappy early searcher, you actually have a huge advantage. We're sponsoring some prizes for the scrappy searchers who want to try this new paradigm, as well as wallet application and other developers who are interested in experimenting with mevshare.
00:52:10.404 - 00:52:35.650, Speaker D: So I'll briefly talk about what those prizes look like. The first thing is we're giving a prize for the coolest mevshare bot. Essentially come up with something weird, deploy it, land some bundles. This should be open source. We're also giving away the prize for a design that uses mevshare in an application. So really get creative with this. It can be fully implemented, it can be an architecture spec.
00:52:35.650 - 00:53:08.940, Speaker D: But the idea is to have some sort of specification for a new configuration, a way of using validity conditions or hints in an application. Also, please make it open source. There's a theme. Finally, we're giving out a prize for an onboarding viral website for the Protect RPC. We currently just have this button in our docs. We want to see what interesting things you might come up with. All these value props we've talked about today, how would you want to communicate that to somebody? Again, we build open source software, so please make this open source.
00:53:08.940 - 00:53:36.304, Speaker D: And that's it. I think to conclude, there are, like I mentioned at the beginning, three things that remain constant in mev. New exploits emerge, new paradigms emerge, and searchers adapt with style. So we're very excited to see all the stylish ways you will interact with this new paradigm. You can reach out to me and the team will also be in the discord for the rest of the hackathon.
00:53:36.432 - 00:53:45.140, Speaker B: Yeah, that's it's.
00:59:39.550 - 00:59:41.020, Speaker E: Right away I'm saying.
01:02:25.210 - 01:03:17.724, Speaker B: Hello everyone. I'm Vivian from Privacy and Skilling Exploration Team. And today I'm going to talk about how to hack on the ZK project. And this is the slides. There's a link and then the first link is the slides. So you can see the examples and links inside. The PSE provides price.
01:03:17.724 - 01:03:59.576, Speaker B: So I'm going to introduce a little bit. So we provide five K and we will choose four projects. And these four projects can choose either three of these projects. And first one is Semiform and the second one is UniRep and the last one is E, two Ezk EC, DSA. And I will going to introduce these three projects later. Yeah, so you can choose one of them to hack and I will introduce a little bit about ZK. Really short.
01:03:59.576 - 01:04:48.372, Speaker B: So here's an example. So how we verify a transaction is correct. How we verify that this equation is correct, then we provide plaintext X so the minor and others can verify oh, you know the X of this equation. Yeah. So what ZK does is that we provide a proof and then you don't know what is the equation. And then on Chen you just verify, approve and then tells you if it's correct or not. So it is ZK.
01:04:48.372 - 01:04:51.080, Speaker B: Do on chain.
01:04:51.740 - 01:04:52.490, Speaker A: Yeah.
01:04:55.180 - 01:06:39.304, Speaker B: If you want to know more about zero knowledge you can go to the Ethereum website and there is a zero knowledge proof page and then zero x. Park is also provides some materials for you to learn about ZK. Yeah so I'm going to introduce the first project called Semaphore. And Semiform is like an identity system and then you can generate identity and then you can generate a membership proof of a group and then also you can include a signal in the proof such as to vote or endorsement some information in this proof and there is a semaphore website and then you can getting started in this website yeah so what Semaphore can do is something like you can prove that you are a member of one of a group and then you don't reveal who you are. And like I said, you can endorse and signal. So you can include a signal in this proof to prove that I want to say something like voting always toll Boeing. Yeah so I will provide some example codes.
01:06:39.304 - 01:08:15.604, Speaker B: Here how you generate and random identity. So you install the Semaphore identity package and then you use a new identity function to create identity. And there are several secrets or public signals in this identity, they are called trapdoor, null, fire and commitment. And you can go to the documentation to see the definition of this different terms. Yeah, so this is basically how you create an identity and then you can add your identity to a group and then you install a package called Semaphore protocol group and then you can create a group with index one and then you add a member in this group with an add member function. Yeah, and then how you generate a ZK proof and you install the package called Semaphon protocol proof and then there is a generate proof function inside and then you can generate external nucleifier and signal in your proof. An external nullifier is used to prevent your action being doing twice.
01:08:15.604 - 01:09:09.790, Speaker B: For example, if you want to vote an event and then the external nullifier is the name of the event like the topic and then your signal is your vote. Like you vote one or two or three or something like that. So the signal can happen many times, but the external nullifier, it can only happens once. So you include this information in your proof and then code it with the generate proof function. Yeah, and there's a verify proof function as well. So you provide the proof, and then the group dips and then the group dips is the mercotree dips. I think it's provided in the.
01:09:11.600 - 01:09:12.252, Speaker A: Group.
01:09:12.386 - 01:09:14.476, Speaker B: Object so you can just use the.
01:09:14.498 - 01:09:15.420, Speaker C: Group dips.
01:09:19.120 - 01:10:38.616, Speaker B: And also Semaphon provides CLI to install the package easier. So you install the CLI and then you can use Semaphore create and your project directory to create your project and if you want to explore this command, you use the Semaphore help to help you understand this command. Yeah, if you want to learn more about Semaphore you can use the demo app or go to their discord to ask them questions. And then we are also in the first floor so you can find us and then ask us about if you have questions and their documentation. Yeah. So the second project is called Unirap. So UniRep is a private and non reputable data system and it is also provides anonymous to users.
01:10:38.616 - 01:11:34.622, Speaker B: But in the same time the user can prove how much data they have and then you can go to this UniRep IO to see the document. Yeah. So what it's used for? You can use it for the reputation or data application. For example, you have GitHub and then you want to prove that you have how many stars in GitHub and how many followers in GitHub. You can use this protocol. So you turn the web two data to web3 and then you can generate a zero knowledge proof to prove oh, I have such amount of stars in GitHub. Also you can prove the membership of oh, I'm a user of GitHub.
01:11:34.622 - 01:11:35.700, Speaker B: Something like that.
01:11:36.710 - 01:11:37.122, Speaker A: Yeah.
01:11:37.176 - 01:12:56.482, Speaker B: And there are some example application by our collaborators. So the first one is trust list so you can sell product and then you choose which buyers you want to transaction with and the users are anonymous. And then the second one is what I said, you can bridge your web two reputation to web3. Yeah, and then the third example is social media. So we can build an anonymous social media and then other people can upvote or downboard a post and then if you are not able to generate a positive proof in the future, you are not able to post in this anonymous social media. So it can help to manage an anonymous social media in web3. And then the last example is voltage.
01:12:56.482 - 01:14:37.672, Speaker B: So it is like a voting system but it's different from Semaphore is that in the end of the hack zone people finish voting and then you can prove that how much votes I have. Yeah, it is a little bit different from Semaphore. Yeah. So to install this package you use the NPN install Unirap core and they are the file of the following example codes because they are pretty much sorry. Yeah, so the example here is that if we want to deploy a Unirap contract, we use the deploy unirap from the contract package and then you just connect your wallet and then call the Deploy UniRep smart contract. And if you want to connect to a deployed Unirap contract you provide an address and then the provider or your wallet and then you can connect to a deployed smart contract. Yeah, and then the protocol is like this floor.
01:14:37.672 - 01:15:59.864, Speaker B: So the users are just providing proof to the Attesters. And then the Attester or Relayer will submit the proofs to smart contract to verify these proofs. And then the users can see the data on the smart contract and then know which is my data. And then you can generate a valid proof to prove them. Yeah, so the attacher here is like an application and then you set up rules for the data, how user can get data. Like, for example, the GitHub GitHub is an Attestor and then the developers are users in this application and then the GitHub will manage how user get received stars or followers and something like yeah, so the Attester is pretty much like an application and set up rules for users. Yeah, so you can sign up an Attester with a wallet here's a wallet example.
01:15:59.864 - 01:17:53.220, Speaker B: So you call the smart contract and then call the function a tester sign up and provide an epoch lens. Yeah and you can go to the document to see the definition of epoch or epoch key and then there's another way to sign up and a tester is using a smart contract. You can call the UniRep on chain with the smart contract. Yeah so if I am a user of this application you can generate so how to sign up a user. So user can generate a semaphore identity here and then synchronize all the ontrad state with the user state class. So you provide a prover, it is used in a circuit, it help you to provide a zero knowledge proof and then you provide unirap address contract address and then you provide a provider and then your semaphore identity and then you use the start and wait for sync to start syncing. The whole event happens in UniRep contract and then you can generate sign up proof with the gen user sign up proof function and if you want to return then you just call the user state stop or it will keep synchronizing all the states.
01:17:53.220 - 01:19:35.720, Speaker B: Yeah, and when user generates this proof in client the user should submit this proof to the Attester or application itself and then to call the Attestor only the Attestor can call the unirap contract to send the proofs on chain and then update the unirap smart contract date. Yeah, and how users receive Attestations or data or reputation the user should generate a temporary identity called EPA key. So you can imagine that you have a list of wallet accounts and people cannot link all these accounts to you. But in UniRep you can generate a set of epoch keys and then you can prove that all this asset is yours. Yeah, so epoch is one of this address but it only lasts for an epoch. An epoch can be like one day or seven days or one week or something like that. So if the epoch is too short, you're not able to use this epoch key for a long time but if epoch is too long you should use the same identity for a long time.
01:19:35.720 - 01:21:33.150, Speaker B: Yeah, so this is how it generates a temporary identity called epoch key. Yeah and when the Attester see this epoch key he can send data or Attestation to this epoch key. Yeah so in this example, the Attestor send the index zero data index zero to five yeah, because we provide for example six data lens so you can change six of them. Yeah, but in this example is that if we define field index zero is the GitHub stars and it increased by five so you give the index zero to five. Yeah, it is how if you don't want to know more about data you can go to the documentation to see how data is defined. Yeah and when an EPA ends, the user should call the user state transition to receive all the data to the user itself so after user state transition the user can prove how much data he has. Yeah, so he sent example to generate a user state transition proof and also the user should submit this proof and then it can be submitted by relayer so yeah, I use the signer here but not relayer.
01:21:33.150 - 01:23:13.884, Speaker B: Yeah and after user transition the user can generate a proof to prove how much data he has. For example, if the user have five and then he can prove that oh, I have at least three. Yeah, so you don't have to review all your assets or amounts of data but you can generate a valid proof to prove oh, you are in a certain range of data. Yeah and then you can also build a tester with the CLI it's more easier and this CLI will provide circuits and contracts and relayer and front end so you can start the app by yarn build and with hardhat node and then deploy your smart contracts and then you can start the relayer and front end client. Yeah so the last project is called E two E ZK ECDSA so it's a private ECDSA signature verification. So you prove the ownership of Ethereum address. Yeah, so the problem with the previous example is that you have to generate a new identity secret but it is really hard to manage many different secrets.
01:23:13.884 - 01:24:15.420, Speaker B: So this example is that you can use your wallet to generate a proof so you don't have to manage a new secret. Yeah, and then you can use the Zkedsa for a verifier contract so your contract can still verify assets but with ZK proof and then you can use for an anonymous AirDrop or discord verification bot. Yeah, I'm really not familiar with this project so please go to the website to check how it can be used. So this also an example code here.
01:24:19.750 - 01:24:20.500, Speaker A: Yeah.
01:24:23.990 - 01:25:12.330, Speaker B: And there is a demo app so you can prove your assets with your wallet in this link. Yeah so we have these three projects and five K bounties so if you are interested in one of these projects, please hack it. Yeah so if you have more further questions you can go to the PSE discord. Now there are many people there to answer questions for people, yeah, and thank you.
01:25:29.940 - 01:31:19.850, Speaker C: Connection, but for you.
01:32:34.340 - 01:32:56.880, Speaker B: It'S possible.
01:32:56.950 - 01:33:36.430, Speaker A: To cover this light on it. Hey. So I'm Leo. I'm from CISMO. And so today we are going to do a workshop. So there will be very few presentations, but more like trying out a bit, our tutorial, our boilerplate and stuff like that. So I hope you enjoyed.
01:33:36.430 - 01:34:44.870, Speaker A: So at CISMO what we do is that we leverage zero knowledge proof to enable users to aggregate their identities and selectively declose some piece of personal data directly to applications. So here we can see we have zero x one and zero x two and we are able to aggregate this data, generate a zero knowledge proof of some small piece of personal data inside it, and bring it to an application with a single sign on. So SSO flow, I'm going to do a demo right now so you will more understand how it works. So for a bit of context around this demo last year, what we have done is we have printed a code of tornado cash with a two meter high artwork. So it was a physical piece of painting. Two months ago it arrived on Twitter and people asked us to have it and to have a version of it. So what we did is we did a lottery to be able to gain this artwork.
01:34:44.870 - 01:35:56.854, Speaker A: The problem was, okay, we wanted to gate this lottery only to users of tornado cash, but when you use tornado cash, you can deposit and withdraw a lot of times, so it's highly UNC bill resistant. So we decided to also add a way to have CB resistance to enter this lottery. We use Gitcon passport for that? So Gitcon passport is a way to connect your Twitter, your GitHub. So it's a bit like Doxing because all happen in your public identities and it analyze your activity, basically the commits you have made, the tweets you have made, and based on that, it will give you a score of CBD resistance and for instance, a score of 15 is a good score of CB resistance. Let's say I am human. So here Sismo is very interesting use case because you want to prove that you have used on ado cache with a very private wallet you don't want to reveal at all and you want also to prove that you have a Gitcon password. So basically that you are CBL with your very public wallet ENS.
01:35:56.854 - 01:36:36.134, Speaker A: And so using CISMO and Sysmo Connect, you will bring these two data without revealing the address that was used behind. So let's go to the demo. So we have what we call the App Store. So it's apps CISMO IO, you can go there and try it out. You click on demo here and here you can see the lottery registration. So basically this is the application lottery registration. To be able to enter, you are going to do SSO flow sign.
01:36:36.134 - 01:37:07.070, Speaker A: In with CISMO and requesting data from the user to be able to enter the two data we request. Here is okay, I am well a tonadocache ethereum depositor on Mainet and I have a Gitcoin passport with a score more than 15. So I do sign in with CISMO. I'm redirected to my CISMO data vault. So the CISMO data vault, it's like a password manager when you import all your different accounts. So this one is a demo one. So we can see here there is a lot of accounts that already have been imported.
01:37:07.070 - 01:37:54.070, Speaker A: I can show you mine, my real one you will see. So I won't do all the one because otherwise I will DOX myself. But you can see I have a lot of accounts and I import them just once, like in password manager in one password, for instance, you import your different accounts when it's imported, it's linked to your vault. And in Sysmo data vault you have what we call the vault secrets that you will be able to use in zero knowledge proof to prove that you own these different accounts. So thanks to that, you will be able to prove to application that you own your different accounts if you want. And we will see this later how to use a devex to request some proof of ownership of different accounts. But you can also do some membership.
01:37:54.070 - 01:38:35.182, Speaker A: Basically, what is this membership? You have groups of all the accounts that have exactly the same characteristics. For instance, here you have the tonadogash ethereum depositor groups. If we see the content of the group, it's all the depositor on main net. So it's basically all the accounts that have made this action. So what we are going to do is that we are going to prove in the runner edge proof here. So all happen in the browser that we own an account that is inside this group and we are going to send back this proof to the application that will verify it, verify it off chain or on chain. If we take the Gitcon password, it's exactly the same.
01:38:35.182 - 01:39:18.430, Speaker A: So you have the group of all the Gitkin passports and we can see here the content and there is a particularity is that it's a key value data group. So the key is the account and the value is the score of your Gitcon passport. And what is interesting here is that you can do predicate or statement around this value the application can request and this is what's happening here. That okay, you are part of this group, but also you have a score that is more than 15. And the application won't know exactly which score I have inside, but the application will know that I have more than 15. This is just what is interesting for the application. So I do generate ZK proof.
01:39:18.430 - 01:40:08.680, Speaker A: The ZK proof is generated, it's sent back to the application and I can verify my ZK proof and I will be able to enter the lottery. So here the flow. The verification happened off chain, but it can also happen on chain. We have a solidity library that we can call to verify the proof. So we have what we call the factory. The factory is a UI dev tool that enable to browse the different data groups and create data groups. So data groups here are very important because it's a source of data you will be able to use inside your application.
01:40:08.680 - 01:40:43.042, Speaker A: So we can see here, for instance, there is around 1000 groups that have been created. So you can go there, it's all open and you can search. For instance, the gitcoin passport one is here. We can see the last generation, the next generation. So the groups are snapshot groups, they are run at a daily frequency and you can choose basically the frequency you want for your group to refresh the data. I will show you how we can create new data groups. So you can do all in the UI tool.
01:40:43.042 - 01:41:19.760, Speaker A: Also you can do a manual group. Like basically you just put your addresses, your list of addresses or you can use what we call data providers. Data providers are just a way to fetch data from the outside world. So for instance, here we have a lot of data providers that have been made by the community. Also you can also code your own data providers that will appear here for all the other developers. So we can create a group together. I propose that we use like the GitHub one.
01:41:19.760 - 01:42:10.830, Speaker A: Here you can see the different accounts we have. We have like web3 accounts, but we also can have like GitHub Twitter or Telegram accounts. So basically, if we do a group of all the GitHub contributors of the repository, you will then later be able to prove that you are part of this group without revealing exactly who you are. So basically you can import your reputation from your web two activity in this example or bring some web two activity and web3 activity together in one proof. So here we can take for instance, I don't know, let's take the Foundry one. So it's an interesting one, I think there is no group for this one. So you just need to put here the repository.
01:42:10.830 - 01:43:15.730, Speaker A: So here we know that there is 274 accounts that contributed to Foundry. Just continue. So here you need just to put a description and specification around your data group so other people can search for groups and reuse them for their own application. So when you create groups, you just bring data for all the other people to be able to generate zero knowledge proof out of it. So let's say data group of all the contributors to foundry. So data groups of all committers to the so in the specifications. What is good is to put the very more precise one, like to put all committees to the repository.
01:43:15.730 - 01:44:17.930, Speaker A: Okay, so let's say foundry GitHub contributors data groups here you specify the frequency you want. So either once it will be computed just once or week or daily. Let's put daily because then we will have updated data each days. Here public information is to be able then to contact you if we want to change the group or whatever. So I will put mine because I'm the one that did the group and let's go. Okay, so you see your group is being created. What happened here it creates so the factory is a UI tool on top of the Sysmo hub which is a repository that contain all the infra that computes all these groups and puts them in merkel trees in what we call posadon merkel tree to be able to use them inside zero knowledge proof.
01:44:17.930 - 01:45:27.240, Speaker A: So it computes all these merkel trees, sends a root on chain and then it's available for everyone to be used. Here what happens. So you can see the code, you can directly code your own groups by hand as a developers and do really more complex stuff like using multiple data provider together, computing some score around it and trying to normalize stuff, whatever you want once we have this group, so we can do zero knowledge proof out of this group. So what will happen here? It will be automatically checked. If all is good then it will be merged automatically and when it's merged it's deployed. For instance we can see an old one. So you will understand for instance if you see today there was this group that was created and so here we can see that the group is generated, the merkel trees are created and then the root of all these merkel trees are sent on all chains and then they are available to be used in Sysmo Connect.
01:45:27.240 - 01:46:07.074, Speaker A: While it's generating and deploying. We are going to effectively use Sysmo Connect through an app. So we have provided some boilerplates for that. You can go to stocks, CISMO, IO and we have here all the sections built with CISMO Connect. In the overview you will see exactly what I demoed you. So you have a button you need to forge the request you want to do for the user. So basically you will say okay, I want that he's part of this group, this group and this group.
01:46:07.074 - 01:47:03.814, Speaker A: The user generates his secret proof in his browser, send back the ZK proof to the application, your application and you can verify it off chain or unchained. Okay, so sorry. So if you go to the installation here we have a create system connect script that will basically set up all the different bowler plate we have. So let's start running it. What is the name of your project? So let's say workshop. So when you start the script asks you for an app ID. What is an app ID? It's basically when you create an app on top of Sysmo, it's like when you do connect with Google, you need to register your app.
01:47:03.814 - 01:47:36.030, Speaker A: So the prover part will allow only your front end to be able to request data from the user. So it's for security reason, basically. So you create your sysmo connect app. So it's very easy. It's permissionless. You just need to go to the factory again and to create your Sysmo Connect app. So let's say is Global Workshop app for East Global Workshop.
01:47:36.030 - 01:48:13.340, Speaker A: So it's fun when you add a picture and authorized domain. So here you can put like Localhost to test in localhost. And then once you deploy, you can update it to add the authorized domain for your app. And by creating this app, you will have an app ID. So this app ID is the one you will put into your piece of code. Like when you install the front end and the Sysmo Connect button and the Sysmo Connect verifier. Okay, so you put your app ID here, it will connect it.
01:48:13.340 - 01:48:44.200, Speaker A: And let's start by the off chain. So we have an off chain and an on chain boilerplate. So you can do what depending on your yeah, sorry. I am so sorry. Is it better like that? Thanks. So let's go to the off chain one to start. So it will set up a next JS application with CSMO Connect installed in it.
01:48:44.200 - 01:49:26.974, Speaker A: Okay, let's go to workshop. Yarn dev. So here you will see okay, you have the front end, you have your button, and this is what is used to request your ZK proof. You have the System Connect config where you have your app ID and the different data you want to request. And then you have your API, your backend to verify the proof. Okay? So when you launch it, you will arrive on a very simple front end that you can modify to just do your needs. But here you can see what we are going to request.
01:49:26.974 - 01:49:59.238, Speaker A: So we are going to request authentication. So it's basically proof of ownership of an account and claim requests that are basically proof of membership into a group ID. You can see the different group IDs here. So you can see when we click, it goes directly to the different group ID. Sysmob contributor, for instance. Okay, we do proof CISMO generate ZK proof. So here you have like six different ZK proofs.
01:49:59.238 - 01:50:29.720, Speaker A: So it takes a bit more time in the browser to run it's around 2 seconds by ZK proof. So if it takes a bit of time, okay, it was pretty fast. It verify. Okay, then it's verified. So it calls the back end and verifies the result and prints the result here. So then you can use them to do whatever you want, store it into the database or whatever if you want to update. So let's try to update it.
01:50:29.720 - 01:51:22.740, Speaker A: So here you can see the button. It's very easy. You just need to put your config sorry, just need to put your config with your app ID and here you can impersonate accounts. You have your app ID that was automatically filled and you have here the account that you can impersonate. So you can change this to say okay, I want to so we use Foundry. Let's impersonate Gaconst, which is Georgia's. Okay, I think I've think I did a mistake here.
01:51:22.740 - 01:52:05.482, Speaker A: Okay, so we do again your approval with CISMO and we can see here. So we have our ISGlobal pari workshops. I discovered the app ID and changed here the impersonated account. So now I use Ger const. Let's go see our group how it goes. So it's been sent on chain, so yeah, it will be ready in around two minutes I think. So during that time it send.
01:52:05.482 - 01:52:36.114, Speaker A: Let's try to set up maybe unchained border plate. So we will have the unchained one. So we are using Foundry for this one. So I don't know if you are very familiar with Foundry, but we also have a package for RDATs. But we advise you to use Foundry and we have these boilerplates that are all well set up. So I think it's a good reason to start on Foundry directly if you want. And it's really like a ten x tool when we compare to the old adat.
01:52:36.114 - 01:53:40.264, Speaker A: So I really advise you to do it. Okay, so we start again the create CISMO connect app. Let's take again the CISMO app. ID. So we have this one and we take the unchained one. So in this bowler plate you have a font folder where you will have a next JS application with all Wagme and VMs that will be able to allow you to call directly your contract. And you have an SRC folder here with AirDrop Sol that is using CISMO Connect to verify the proof.
01:53:40.264 - 01:54:28.030, Speaker A: So it's very easy, you just have to put it here and to import it from this library. So all this is in the documentation also. So in the installations part, then you have a claim with CISMO function where you will have the Sysmo connect response that you will be able to verify regarding the data you wanted. So you need between the front end and the back end or here the smart contracts you need to have exactly the same request, otherwise it will fail because you request something and you verify it. But if it's different, it does not correspond. Basically it's like a signature. When you do a signature, you verify your signature against a specific message and you verify that your public key corresponds to this verification here it's exactly the same.
01:54:28.030 - 01:55:22.656, Speaker A: So let's go to we don't have a lot of time, so I'm going to modify it to just put our new group ID and to use an authentication of type vault. So I will explain you just later what happened. So we are going to say, okay, I want to verify a claim request from being part of this group. So let's go on our so it's almost finished. Okay let's go to browse our groups. Okay so our group is here, we can see the content of the group so we have all the contributors. Our gear consists here so it will work in the value.
01:55:22.656 - 01:56:20.764, Speaker A: The data providers was developed to put the number of commits you have made. So then here it's interesting because we can do request of having done like more than 50 contribution into this repository. We take the group ID here and I can put it directly there. Um, now if I go to the button part so we are looking for the Sysmo connect button. Here we see our config. Well we have same so our different impersonator address. So let's change this one to have the GitHub const and let's change our request.
01:56:20.764 - 01:56:46.040, Speaker A: So here we have our authentication request and our claim request. So we say we need to have exactly the same between the font and the smart contract. So we put a vault. So here, let me explain you the vault. We have created an app and we are doing zero knowledge proof from a user to an application. This app has an app ID. This app ID is a random number.
01:56:46.040 - 01:57:28.890, Speaker A: Basically, inside your Sysmo data vault, you have a secret that is stored in the browser in the Sysmodata Vault, like the password manager. And if you hash in zero knowledge proof this secret with the App ID, you will have a unique number the Vault ID that will identify you to the application. This vault ID is very important because it can be used as a nullifier for your app. Let's say you do an AirDrop. You can just store this vault ID as being used and the user won't be able to claim again his AirDrop or on upchain. You can use it like a bit more as a user ID into your app and it's like an anonymous user ID. But you will be able to authenticate each time and you don't need an email or I don't know or whatever.
01:57:28.890 - 01:58:30.940, Speaker A: So let's go do here just verifying this is okay, I think this is almost done. Sorry the group ID is here and here we go. Okay so when the create system connect app has launched it says you need to launch local chain. This is just so you can deploy your contract easily and don't pay each time on your local chain. Sorry I need to go to the unchained foundry and launch my chain and same here, I will go to the front end and do yarn dev. So all should be explained here, I don't know why. Okay, so all here should be explained.
01:58:30.940 - 01:59:22.670, Speaker A: When you run it you have all the explanation on what to do exactly here. So let's go to our new system connect it's because I have the off chain one. Sorry. So I will launch it again. Okay, so what happened when you launch the front, it will also deploy your contract into your local chain. And each time you modify your contract, it will redeploy into your local changer contract. Okay, so here it asks me to connect my wallet, asked me to just I need to switch, sorry.
01:59:22.670 - 01:59:51.590, Speaker A: Okay, so we say I am in this local chain, I'm connected with my account. I do claim with CISMO. I see that. I request only ownership of my vault ID here. It's my random number that will be computed in zero net proof. And here we are checking that gekkunst, which we are impersonating. Here is part of the foundry GitHub repository group.
01:59:51.590 - 02:00:40.410, Speaker A: So what happened here is that we download the World group in the browser and we generate the Zkpoof out of this group. So all happen in local in your browser. I think this is because the WiFi is a bit slow, but let's try again. Maybe let's take another group. I think we were going to take the rest one that we already have. So if we change the group, we need to change it also in the contract. Let's go again.
02:00:40.410 - 02:01:25.906, Speaker A: I'm a bit out of time, sorry. Okay, let's do claim with ISMO again. So now we have the rest GitHub Contributor group, we do generate Zika proof, we are redirected back to the application and we can do our claim with CISMO. Okay, so sorry for that. Yeah, I think we are running out of time, so I won't keep you more. If we want to build on CISMO, go to Builders CISMO IO. Here you will enter a telegram channel where you can ask for help for whatever happens.
02:01:25.906 - 02:01:31.300, Speaker A: And we will be here doing the support all the weekend. Thank you for your time.
02:01:32.030 - 02:07:29.510, Speaker C: Um, question. How do I mirror it? How do I mirror the display advance, maybe?
02:07:39.400 - 02:07:41.780, Speaker E: Okay, so maybe build a display.
02:07:44.220 - 02:07:47.492, Speaker C: I'm trying to change the mirroring. Where do you do the mirroring?
02:07:47.556 - 02:07:48.280, Speaker A: I'll do it.
02:07:48.350 - 02:07:52.830, Speaker C: Thanks. Okay, great.
02:08:00.580 - 02:08:02.130, Speaker B: Thank you.
02:08:06.100 - 02:08:06.850, Speaker A: Hello.
02:08:11.780 - 02:08:39.660, Speaker C: Hello. O. That always works. Thank you, everybody. You all actually showed up for this, so go you. We are going to have fun. And we're also going to roast the organizers for having terrible WiFi at the hackathon.
02:08:40.000 - 02:08:42.028, Speaker A: Boo. But good food.
02:08:42.194 - 02:09:15.510, Speaker C: Yes, but yay food. Right, so the plan always is to start five minutes late because who actually needs 30 minutes? And here we are. So we're going to talk about reputation and making it useful and portable. And then we're going to talk about some SDKs that might be useful or interesting for some of your hacky hacks. I am David Phillips. This is me on the Bird app, the Twitter. I put this picture in there so that you know I'm cool.
02:09:15.510 - 02:09:39.560, Speaker C: Respect me. Yeah, that's me. Yes, I'm a California native, born and bred. Now reside San Diego. Now I reside in New York. And now I'm here to chat with all the Parisian wonderful hackers and people from around the world, but we're just going to jump into it. So, quick context.
02:09:39.560 - 02:10:09.640, Speaker C: Show of hands. Who has heard of DIDs or who has built something with them? Yes, exactly one third. Oh, exactly half. Welcome. So we're just going to do a quick overview. Contextualize, like what is identity? How do we see this in the world? And then how does this evolve into this digital analog hybrid crazy future that we have going on? Traditionally, we use credentials to get access to things. Passports, right? We all had one to come to the country in the US.
02:10:09.640 - 02:10:36.720, Speaker C: They're really militant about making sure you have an ID card to get into a bar. Even if you look 50, they won't serve you a drink. But these credentials generally come from black boxes. They're institutions that we don't really have control over, insight into, or deep understanding of how they work or why they work, how they do. But they allow us to do lots of nice things. These credentials, these identities that we carry around or proof of identities that we carry around in our pockets. We can ride airplanes, we can get mortgages.
02:10:36.720 - 02:11:27.452, Speaker C: So right now there's this massive trend and that's ongoing and it's not slowing down. So just a couple of data points for you. 8% more time, year over year has been spent online every year for the last 15 years. So we're starting to run into this thing of we have these really nice, really nice versions of physical ID cards in analog identities. But that all starts to break down when we look into the digital world. How is it useful? How do we take ourself with us to different parts of the internet? Because if more of our lives are happening online, well, wouldn't I like to have some credibility when I show up to a different ecosystem? So that brings us to the next point. It's like, okay, we all have wallets.
02:11:27.452 - 02:12:08.604, Speaker C: Is a wallet an identity? I would argue no. Some people would argue yes. But I think good identity ultimately is sovereign, secure, and portable. And that's the litness test that it needs to be able to pass. And so identity, our wallets are great because they are secure and they're sovereign. But a wallet address isn't necessarily useful beyond the bounds of a specific blockchain ecosystem. So we can build all sorts of wonderful history in ethereum, but it breaks down when we go over to Twitter or some e commerce platform or anywhere else that we do things that are important on the Internet, racing along here.
02:12:08.604 - 02:13:31.000, Speaker C: But what we are going to look at today is what is an identity graph? How can they be constructed and how can they become super powerful tools, not only as a vehicle of individual sovereignty, but in terms of what you can reliably gain access to or how you can represent yourself online. So what is a did? Yeah, what is a did? So a did is a key pair. Yes, a did is a key pair. So you have a public key and a private key. The way Nextid works is you can basically have the same keys that you're using on Ethereum and it is a key pair that is used to sign and certify control of an Identifier or an entity on the internet. So as you see in this little visual you have an avatar or an ID that is a key pair, that is a did and you're signing a message to say I own or I control this Ethereum address. I own or I control this lens profile, this ENS or a reddit or reddit account or a GitHub account.
02:13:31.000 - 02:14:57.350, Speaker C: And so what we're doing is we're taking these disparate Identifiers, these different pieces of ourselves, and we're creating a single graph that is a more holistic representation of our self. We'll get into why this matters and why this can be cool in a little bit. But I'm just going to pause there and take any questions that have come up from anyone because small group I cans. So the cool thing about DIDs is you don't actually need a specific ecosystem or a blockchain, because a cryptographic signature is, as a standalone unit, publicly verifiable, it's really easy for me to look at a signature and say, you've proved by signing this message, like when you sign into any DAP, you've proven that you control that address without basically giving them your private key for them to be able to execute transactions. And so we don't have like in did world, we don't have the need for distributed like a single distributed ledger because there is no double spend problem. There's no like, oh, this is a transaction that's being used to spend money. It's very much using a base cryptography unit to say I control a Twitter account or I control this address.
02:14:57.350 - 02:15:34.752, Speaker C: Was that a little helpful? Great question, great question. Yes. Who creates dip. So who creates the standard? Who creates a did for a user? For a user? So because it's a key based technology, it is by nature sovereign in that sense. And what I mean there is you as the key holder, you can only create a did, you can only modify this graph if you hold the private key, the private public key pair. Yes. No, this is great.
02:15:34.752 - 02:15:38.930, Speaker C: No, this is great. I'm sure common questions, how you can share.
02:15:42.220 - 02:15:42.970, Speaker A: Yeah.
02:15:46.160 - 02:16:15.988, Speaker C: So when you sign into Adapt today, have you signed in with Ethereum? Yeah. There's not really a huge question of does the person who signed this message to gain access to the system, did they control this public, did they control this address? So it's the exact same mechanic in this system as that system. I know that, but I'm just wondering, have you been thinking and trying to solve exactly that?
02:16:16.154 - 02:16:22.304, Speaker E: Because it's like it's the problem that we have. I have whatever credentials are public, private.
02:16:22.352 - 02:16:25.424, Speaker C: Key email, who is behind the IP?
02:16:25.472 - 02:16:26.716, Speaker E: Who is behind the ethereum?
02:16:26.848 - 02:16:33.450, Speaker C: So are you talking about that from like an Attribution and KYC standpoint, for example?
02:16:34.060 - 02:16:34.376, Speaker A: Yeah.
02:16:34.398 - 02:16:59.250, Speaker C: So we're a bit agnostic to that part of the world. There's a lot of people thinking about that problem, doing really great work on it. And we support all of those use cases where there are people that want to build really rigid KYC systems. There are people that want to build fully anonymous did graphs. And we try to treat them both the same to power them both. Yeah, of course. There's one more question.
02:16:59.250 - 02:17:01.492, Speaker C: Okay, cool.
02:17:01.546 - 02:17:02.550, Speaker A: I'll keep moving.
02:17:04.760 - 02:17:23.370, Speaker C: DIDs are basically a self issued key pair and they're used to certify ownership and control. So you're taking an avatar or a bonding entity. You're saying I own this other thing. Pretty simple, just a connecting fiber, like in a spider web.
02:17:32.240 - 02:17:32.844, Speaker A: Yeah.
02:17:32.962 - 02:18:23.100, Speaker C: So for the today we're going to we think about it as like this is doxxing technology or this is a violation of privacy because there's a lot of different strong ideas in our field. We like to think of this or conceptualize the data and identity. There's above the water iceberg and there's below the water iceberg. Below the water requires some sort of selective disclosure, but all of us probably have some sort of public online presence. Excuse me. Thank you. So we focus entirely on what do you want to present to the world about yourself that similar to you participate on Twitter, so you're generating a public data footprint.
02:18:23.100 - 02:18:49.056, Speaker C: So now we get into a little bit of how that gets built and how that gets generated. There are three key pieces to nextid that we're going to talk about and how to use them. So there's proof service. This is you create and store the DIDs. There's relation service which is querying them. So if there's anyone that's ever created a did for anything, we've ingested almost all of them. And so it's a simple API backed up on Rweav.
02:18:49.056 - 02:19:24.370, Speaker C: So it's publicly available. But you can relation service is a way to query them. You get the data. So you create the data, you read the data, two different services. And then the third thing we're going to talk about is a nice new way that we've packaged those things together for universal profile experience. So we're going to talk a little bit about what a universal profile experience is in a minute. But that's the part that we are most excited about and that we really hope that you have a look at as well because we would love your feedback because we just released it this week.
02:19:24.370 - 02:19:53.624, Speaker C: It is not in the App store, but there are docs available for it. Yeah, super good question. So we talked a little about what the identity graph is, revisit how it can look. This is an actual example from our system. So this is my co founder, Yeezy. We have here. The Ethereum address and then that was linked to a Twitter, which was linked to a keybase thing.
02:19:53.624 - 02:20:57.600, Speaker C: And now we actually all the way over to GitHub lens profile and then our next ID binder. So what we think is really cool and exciting here is if you have any node in this graph, you, when querying our system, can return and resolve to any point of it. So what that means is if you're building a wallet, for example, and you're like, it would be really nice if I could have a secure way of sending someone money using their Twitter handle. If someone's interacted at any point with the did system and bonded their Twitter, which is the most common activity now, it becomes trivial because I type in David's Twitter or at David and then I know beyond a shadow of a doubt, I'm certain that the owner of that Twitter is the owner of that address. So I can send money on basically any chain. So we're going to just jump into the universal profile SDK here. Pretty simple.
02:20:57.600 - 02:21:41.470, Speaker C: There's basically four different endpoints and I'm happy to get into details or just talk directly to you after, but the docs are all there. This is At API Web three bio, so please check that out and let us know if it sucks. We want to hear about it. It doesn't. And then I'm going to jump over to proof service in just a second. But I'm going to live demo. Why not? Where is it? And cool WiFi, don't fail me now.
02:21:41.470 - 02:23:05.500, Speaker C: Bear with me. One secondary. So what you're able to do with it always breaks when you demo. Yeah. So this is a universal profile view and this is what you're actually able to get with that API is all of this stuff that our friend Gisi has done is available in this display and you're actually able to plug this into your apps so that when someone signs in with an address, you hit our API and say, does this person have an ID graph? And then it returns the did graph. And so you're able to create a super rich display of user information without forcing them to manually port that over once again, like they have 100 times before. So we have hundreds of thousands of current users that have DIDs, and then there's a module where you can actually prompt them to create one for the first time as well.
02:23:05.500 - 02:24:08.938, Speaker C: Any thoughts or any questions there? Yeah, random question. So you said that did independent of ecosystems, right? They can be, yes. So the question is, where do the dies here live? Are they Ethereum or are they somewhere else? So we use all the same cryptographic processes that Ethereum uses because those are best in practice, but these actually live on Rweave, so they're totally decentralized database that everything gets pushed to. And then we keep a copy of those in AWS and have a really high performance API to make it so you can actually do things with them super easily. Are you guys transactions that are done out there and pushing them into our wave. So we don't try to DOX or aggregate any data that a person doesn't want aggregated about themselves. And so a really important thing is like a did is not a transaction between two addresses.
02:24:08.938 - 02:24:53.390, Speaker C: It's a signature certifying that the same party controls two different Identifiers or two different entities. Yeah, so our APIs are really high performance. They handle about 50 million calls a week right now. So we do actually have some users and we look forward to welcoming you into that family as well. So on the proof service side, it gets a little bit more technical and I'll try to say higher level. And now we're getting a bit more into the weeds towards the end. But the way, for example, that you can actually create a did that binds an address to a Twitter is with something called a proof post.
02:24:53.390 - 02:25:39.882, Speaker C: So we have our avatar, or what we call just think of those as keys, your did keys. You're posting a special string on Twitter that our system ingests is the verified. Basically you have to post a special string that the system generates for you to say, yes, this is the cryptographic signature that says I own this Twitter account. So it's like you tell us, you're telling our back end, I own David PCO. That's my Twitter handle. Yes. And then you have to post a special sequence of characters like zero, x, 1234 on your Twitter account to then complete the generation of that proof that you own that entity.
02:25:39.882 - 02:26:26.390, Speaker C: And then the did gets issued in the system or by your did gets issued by self through the system. So a little bit maybe unfamiliar, but promise you when you look at it, it's a three step system and is pretty easy to build on. So if you're interested, this is kind of our full stack and structure detailing where stuff lives, how the model and data storage works. Love to talk to you more about this, but I don't think it's too important to go into right now. And that's where we're going to wrap it up. So thank you guys for coming. If you have any questions, I have five more minutes to monopolize the space and you have been wonderful.
02:26:26.390 - 02:27:07.862, Speaker C: Yes. Thanks, Ben. So the integration to these other kind of web two properties, is it done via OAuth or maybe I missed that? The answer is yes. And we like to bypass OAuth whenever possible to reduce and eliminate platform risk. And so we do that with that proof post mechanic that I showed or that I showed a second ago. Because for example, a post based social media won't turn off. They're not going to eliminate everyone's abilities to post, but they do turn off APIs, right? So you just essentially do it out of band.
02:27:07.862 - 02:27:21.360, Speaker C: Yes. We don't count on their consent to be able to certify that ownership or their collaboration, though we do have it in some cases. Any other questions? Yes.
02:27:22.290 - 02:27:26.494, Speaker E: Hey, so the title of your talk.
02:27:26.532 - 02:27:45.302, Speaker C: Is about reputation anywhere. Do you have some research on having some reputation score or this kind of process just to assess reputation or provide.
02:27:45.356 - 02:27:48.294, Speaker E: Any signals or insight regarding that?
02:27:48.412 - 02:28:20.580, Speaker C: Yeah. So reputation is there's a lot of different approaches for it, and I think the easiest one to talk about is Gitcoin passport, where the more things that you have linked together, the higher degree of probably the higher score you have of being a person, what we view as reputation might be a little bit different than we have historically or traditionally. And what I mean there is.
02:28:22.870 - 02:28:23.186, Speaker A: What.
02:28:23.208 - 02:29:14.980, Speaker C: I mean there is we treat humans and machines the same. We don't really care that much if a machine is participating in a certain ecosystem because machines can provide value. So I'm not sure I'm really directly answering your question, but what's important here is that you have a persistent footprint that can travel with you beyond a single chain or beyond a single platform. So what we want to enable the same way that DeFi allows for monetary and transactional portability across DApps, what we want is to create a world where wherever you go online, you've brought the parts of you that matter along with you.
02:29:15.430 - 02:29:16.180, Speaker E: Okay.
02:29:18.310 - 02:29:21.890, Speaker C: Did is exactly the glue. It's the webs of the spider web.
02:29:21.960 - 02:29:22.194, Speaker E: Yeah.
02:29:22.232 - 02:30:19.480, Speaker C: And after you can build on top of all that, any kind of algorithm that will score the reputation. I guess you are not doing this, but you're providing the glue that's enabled to link you on chain off chain, social network and so on that. And there's other standards called Verifiable credentials that are getting great adoption where you actually can package up a government issued ID without disclosing what that ID is and say there is a government issued Credential associated with this address without showing your name or height or address or anything like that. So this is the glue layer, and then the other pieces, they get built and put in on top of that. So if you did want to have a proof of personhood on top of a did system, there's a lot of cool things people are doing there. Yeah. Thanks everybody.
02:30:19.480 - 02:30:32.780, Speaker C: Next ID is our website. Next ID find docs and then the other link that I already gave you as well. Thanks, guys.
02:35:43.720 - 02:35:44.564, Speaker E: Okay.
02:35:44.762 - 02:35:45.524, Speaker C: Is this okay?
02:35:45.562 - 02:36:07.224, Speaker E: Can you hear me? It's good for the mics. Brilliant. Sorry for the slight delay in starting. I'm also holding my charger, which I hope I can plug in at some point. I'm low on battery. Hi, everyone. My name is Angus, and I'm going to talk to you today about Mino Protocol and Snarky JS.
02:36:07.224 - 02:36:27.472, Speaker E: So it's July 21 today. There's my name. Yes. My name is Angus. I do developer relations and I talk to people about Mina Protocol and tell them about building ZK apps with Snarky JS. I live in Edinburgh. In Scotland? There's a picture of me doing steganography so blending into the sign.
02:36:27.472 - 02:37:03.944, Speaker E: And also if you see the keynote, like main stage presentation tonight, you might see me in a pickle costume so you can follow me on Twitter as well blockchainbeard and send me memes. That would be cool. Today the structure of the talk will be introduction to Mina Protocol and Zero Knowledge Proofs. We're going to talk about Zkapps, how they work with Mina, Snarky JS. That's how you build zkaps. That's the TypeScript library. And we had a program called ZK Ignite, which I'll tell you about, but I think the applications have just finished.
02:37:03.944 - 02:37:16.896, Speaker E: But you can still find out about how you can get involved and some next steps, particularly how you can get support for the hackathon this weekend. Right, my bags arrived, so here we go. Thanks for carrying the whole thing up.
02:37:16.918 - 02:37:17.372, Speaker C: Yastin.
02:37:17.436 - 02:37:59.008, Speaker E: I thought it was probably easier than trying to explain to him where the adapter was in my bag. I've got quite like a complex packing system. So zero knowledge proofs. Who here has heard of CK? Good. Lots of hands going up for those of you who are watching the stream. So I'm going to do a kind of speed run introduction to Zero Knowledge Proof just so everyone kind of has the requisite knowledge to be able to understand what Zcaps are and how they work. So it says here you can use zero knowledge proof to prove and verify information in a private, trustless and decentralized way.
02:37:59.008 - 02:38:35.396, Speaker E: So that's good for blockchains. If you know anything about Blockchains as well. A good way to think about it is a good way to think about what you can do with a zero knowledge proof. You can prove to someone that you know something without revealing extra information. Right? And so that can be different in different contexts. A good way of thinking about it is the game where's Wally, that's what the character Wally looks like, he's called Waldo in the American version. So there's this giant picture of loads of crazy stuff going on in this kind of big map and you've got to find this character called Wally.
02:38:35.396 - 02:39:45.216, Speaker E: And so if you want to show someone like, prove to someone else that you know where Wally is, you can show them the map or like the picture and you can just point to the Wally character, but then that person knows where Wally is as well, right? So then they can go and say to other people, look, I know where Wally is. So the way to think about what you can do with a zero knowledge proof is you get the Wall E map, you get a large piece of like white card, you cut an exact Wall E sized hole in the card and then you lay it over the map. So then you can show that to someone and say, look, there's Wally, because you can see the little Wall E character, but you can't see any of the contextual information around. You don't if you looked at the map after that, then you wouldn't just be able to pick out Wally because you've not seen where he is relative to anything else. So that's kind of a way that you can think of what zero knowledge proofs can do. And so there's actually lots of use cases that you can use zero knowledge proofs for. Something that people are talking about a lot is using them to increase scalability and do roll ups and things for various different L two S.
02:39:45.216 - 02:40:58.696, Speaker E: And so also the idea of having a zkvm where you can kind of write computation and prove it using zero knowledge proofs, it's also good for things like private transactions. Voting identity is here. Identity obviously very important in our digital world, right? The concept of identity and proving certain things about your identity but then not revealing all of your information at once is something that you can do with zero knowledge and just this idea as well of verifying computation, right? This is a slide as well. We're going to take a look at zero knowledge proofs and compare them to some other cryptographic tools that you might have used and take a look at the kind of what's called the kind of prototypes, I think, for how you use them. So something that you need to know as well about zero knowledge proofs, the proofs that Mina uses, you can verify in constant time. So it's very fast and you don't have to see all the inputs that somebody used to produce the proof. So you can choose, you can keep inputs private or you can make them public.
02:40:58.696 - 02:42:07.488, Speaker E: So that's something that's very good for privacy as well, if you want to offer your users privacy and not having to make all their inputs to methods public. So here you go. You've probably used a hash function before. So in a hash function, you put some data in like as a string and then you get out this other string, right? And hash functions have a number of properties, but the main thing that we're considering here is the fact that if you have some data and then you put it through a hash function, you can verify to someone else, right? You can give somebody else the data, then they can use the hash function. So when you get the same string out, then you know you've got the same data, right? So you can verify the integrity of data with a hash function. Similarly, with a public key signature, you can take some data, you can sign it with a private key, and then other people can use the public key to verify this message or data has been signed by some private key, right? So then zero knowledge proofs. The way that they work in Mina is you write a computer program.
02:42:07.488 - 02:42:55.432, Speaker E: So you give people some code to do some computation, and then they do this kind of compilation step and they generate this string called the verification key. Now, when it comes to people using your code, right? So you give them the code that you've written and they run this thing called the prover function. So this is here in the middle prove, you have a program that you're running, and then you have some public inputs and some private inputs that generates the proof, right? The ZK proofs that we're talking about all the time. So that generates a string. That's the proof. And then you can run the verification function, which uses the proof that you've generated when you ran the computation, the public inputs, but not the private inputs. And the verification key that you created when you kind of built your ZK app, right? And that comes out as a boolean.
02:42:55.432 - 02:43:33.656, Speaker E: So you can verify that a proof is either valid or not valid. Okay? So, hash function, you put data into it. But now what we're doing is we're saying using this cryptography, you can let someone prove that they've done some computation, right, that they've run some program. So that's how Mina works, right? We use zero knowledge proofs to verify all the computation that happens, all the transactions that happen. It uses ZK. So that's why the banner downstairs says, the world's first ZK blockchain. It's a layer one built entirely using ZKPs.
02:43:33.656 - 02:44:18.964, Speaker E: Okay? And as I said already, ZKPs are great for privacy and scalability. So Mina has a number of these advantages. Verifying the state is very quick, so it's constant time, as I said, so you can verify the state. And these proofs stay the same size. And Mina has a feature as well called recursion, where you can kind of use proofs as input to generate new proofs. So the actual blocks in the chain are linked together by having a kind of proof of their state. And then that gets kind of put into the next when you generate the state proof for the next block, you use the previous state as a kind of input.
02:44:18.964 - 02:45:02.372, Speaker E: So in that way, you can verify all the blocks leading up to the current block. And it's very fast to verify. So that also, you may have heard that it's a 22 kilobyte blockchain, so you can verify the state of your account. So you need the state proof, which is like 1, so and then there's some metadata, but with 22 can verify the state of your account on the meter network, and you can sync a node with just that small amount of data. So that's pretty cool. This isn't just stuff that we're kind of telling people about, though. There's people doing work.
02:45:02.372 - 02:45:35.596, Speaker E: The Nil Foundation are working on this thing, this kind of way to take amina proof and then verify it in the EVM. So then you can imagine doing a bunch of compute using Mina. You create a proof that you've done all this compute and then you can verify that in EVM and then make things happen in an EVM blockchain, but do all the compute using Mina. So that's going on. We can link you to that. It's still in research page. We also have openmina.
02:45:35.596 - 02:46:32.256, Speaker E: So this is an actual blockchain node that runs in a web browser, which is pretty cool. So then if you want to build apps and have users use your apps, they can spin up a node in a web browser and they don't have to go through some sort of third party service or node provider or something. So that's cool. So now that I've told you about ZK proofs and how Amina uses them, you're probably wondering how can I build stuff with zero knowledge proofs as well? And that's where we come to ZK apps. Okay? So there's kind of the smart contract functionality. It lets you build what we are calling ZK apps, but there are apps that use zero knowledge proof. If you've heard of Ethereum, if you've done development using EVM, the model that the EVM uses is on chain computation.
02:46:32.256 - 02:47:42.448, Speaker E: So you verify computation by having all the nodes in the network executing the same code, and then they all get the same result, right? So in the diagram here, you've got someone, a user using this computer they want to call some smart contract method. And then all the nodes on the Ethereum network process, they run the method and they apply the updates or whatever. So you're replicating all that computation amongst all these nodes. Now mina is different. So ZK apps actually use off chain computation and then on chain verification. So the way it works is you write some code, the user runs your code, produces the proof that they've run the code, and then the Mina network will take that proof, verify the proof, and then apply the state updates that the user wants to do by using the ZK app. So that's quite different, right? So all the code is run client side and then they are passing this proof in a transaction and then the proof gets verified.
02:47:42.448 - 02:48:33.832, Speaker E: So it's very different to the EVM kind of model that I just explained. So there are a number of advantages to using off chain computation, mainly privacy. So as I said, you can choose which of the inputs that users provide to smart contracts. You can choose to make them public or keep them private. So that's good for privacy. There's no gas fees as well in the way that you think of them usually. So the cost of using the Mina network doesn't scale with computation.
02:48:33.832 - 02:49:20.616, Speaker E: So you can do as much computation as you want, and all you have to pay is the single transaction fee to send the proof to the network. So in that way you can do as much compute as you want, you just produce this one proof and then you pay a transaction fee to the network. So no gas fees, that's pretty cool. There's composability as well. So it allows you to do things. You can design your apps in a way that is kind of modular, but then also you can basically build your own roll ups as well. So this feature that I mentioned earlier called Recursion, so you can take a proof and then you can use that as an input to another proof.
02:49:20.616 - 02:50:32.740, Speaker E: So there's some cool things you can do with that and I'm going to tell you a bit more about it later on in the presentation. And then also the idea that because the state proof is small and fast to verify, then the idea is that you can kind of verify that in different places. So you can use Mina to do compute and then verify it in other places or in other blockchains. So just to walk through the kind of process that you need to think about when you're building ZK apps, the way that it works is that compile step that I was talking about earlier, when you generate the verification key and you deploy your ZK app, you send this verification key to the network. So here there's a box with a key in it that goes to the nodes on the network. So this verification key is public and that's what you use to verify the proof that people generate. So then when a user uses your ZK app here it's hosted@microzkapp.com,
02:50:32.740 - 02:51:26.976, Speaker E: so they use your ZK app, they run the code with some inputs and then they generate this proof. Then what happens is they send that proof in a transaction and then the nodes on the network use your verification key from earlier and they say whether that proof is valid or invalid. So if you have a valid proof, there might be some state updates to apply, but then if it's invalid, the transaction gets rejected. So Zkaps are built of methods. So if you want to build Zkaps for the hackathon, you're going to be writing methods. And there's a kind of diagram here and it's saying that methods have arguments. So inputs you have smart contract state, so you have a very small amount of on chain storage to store state for your smart contract.
02:51:26.976 - 02:52:21.956, Speaker E: You have some values from the rest of the world, so database or server or something. And so then when you run a method, the outputs are you can kind of apply updates to your smart contract state or you can apply updates to the state externally as well. So that's kind of what goes in and out of methods. And so if you want to write methods, you're going to need to know Snarky JS. So Snarky JS is a TypeScript library, so if you want to petition to have it renamed to Snarky TS. You can argue with people on GitHub about it. So then it's the TypeScript library for defining zero knowledge proofs.
02:52:21.956 - 02:52:59.220, Speaker E: So you can create there's the low battery warning. You can create, prove and verify zero knowledge proofs. So there's tools that you already know and love if you are familiar with TypeScript. So we have good integration with Visual Studio code IntelliSense, which is very useful. And you can use tools like NPM and Jest for testing. So the idea of Snarky JS is to make your life easier and to make it easy for you to build apps using ZK. This is the five step kind of quick starter.
02:52:59.220 - 02:53:27.688, Speaker E: So all you have to do is an NPM install. There's a CLI tool that is designed to make your life easier as well. It can help you setting up, building and deploying your projects. And then we've got some flyers with this information on it as well. So come to the booth and you can get some. Otherwise this is in the docs as well, which I'll link you to. So the idea is here you can kind of get started, install the tools and deploy ZCAP in just five steps.
02:53:27.688 - 02:54:08.696, Speaker E: So if you want to write Sonkyjs Smart contracts, you need to know about field elements. That's the kind of the numbers that you use in zero knowledge cryptography. There's this concept of using finite fields to do operations. So that's the basic unit of data that you need to use. You can store a number almost up to 256 bits. And so we have a type in Snarky JS called field. And so there's a kind of little example here of how you would declare this constant sum in a programming language that you're familiar with already.
02:54:08.696 - 02:54:37.056, Speaker E: You would just use the numbers one and three. But in Snarky JS you need to say, I'm using the Field type. So then here that's what's here that's saying make a field, give it the value one. And then it's got a built in method which is add. And then it's saying add this other new field that I'm creating here with a value of three. So, fields, you have to use fields for everything. That's just how the ZK cryptography works.
02:54:37.056 - 02:55:19.010, Speaker E: So we also have other built in types again to make your life as a developer easier. So things like merkel trees, public private keys and signatures, things like that. So these have built in methods as well. So hopefully you should be able to find types and methods to do what you need to do. And if you think one is missing, you should build it and enter it for the hackathon. This is a quick the basic example smart contract that comes with the CLI tool. And so I was just going to walk you through it quickly.
02:55:19.010 - 02:56:07.744, Speaker E: At the top here, I think if you can see my mouse, this is saying so it's using the state decorator that's saying that you're storing this on chain. So you get eight fields of storage for a ZK app. And so here it's saying we're going to store a number in that state. You kind of create a smart contract by extending the smart contract class. You declare some state that you want to store. I was trying to scroll down. So you declare what you want to store on chain in the state.
02:56:07.744 - 02:56:55.616, Speaker E: And then here is some things where this is setting up the permissions for who can do what and how to interact with the ZK app. So you can read more about permissions in the docs. So the init method initializes your ZK app. So here it's just going to say this state variable that we've declared we're going to set to one. And then there's an update method here that's saying we're going to get that field from the state. We're going to verify that it actually equals the current state and we're going to add two to it. So then it's saying add two.
02:56:55.616 - 02:57:36.424, Speaker E: And then this assert equals this method is then saying we've added two to it and we're going to check that the new state equals the old state plus two. So this is kind of thinking about what you're proving and then it's saying here we're going to set that new state. So when you call this method, then it adds two to the state. And then next time when you look at the state there'll be number plus two there. So that's a very basic example. That's what a smart contract looks like. I said to you earlier that I was going to tell you more about recursion.
02:57:36.424 - 02:58:39.754, Speaker E: Recursion is a very cool feature of Snarky JS. So this example has this card game here. Nobody ever mentions it, but so I thought I should start pointing out that it's probably the worst card game ever because everyone has exactly the same cards and I think isn't that one of the most powerful hands you can have in poker, right? So everyone's got like one in a million straight flush or something. So if you imagine a card game, a turn based game, because you can take proofs that you've already created and use them as input for making other proofs, you can have a player. So player one will run the kind of game logic and produce a proof that says I have taken my turn in a way that is valid according to the rules, like the logic of the game. And they can generate a proof that says that they can pass that to player two. And player two can verify the proof.
02:58:39.754 - 02:59:18.990, Speaker E: So they can verify that player one has taken their turn in a way that is valid. They can then take their turn. And then when they produce a proof that they've taken their turn, they can use the proof that player one handed them. And so then when they produce a new proof, player three can. Check that player two is taking their turn in a valid way, but also that player one has taken their turn in a valid way as well. So you can kind of imagine passing around the proofs around the players, add infinium or until the game ends. And then also you notice as well that there's no blockchain in the middle here.
02:59:18.990 - 03:00:08.262, Speaker E: So you can kind of do this off chain, passing proofs around and verifying things without putting things back on the blockchain until you want to. So in that way, recursion lets you do a lot of cool things, but you have to think about things in a slightly different way. Here's a couple of examples of things people have been building on Mina for our ZK Ignite program. So people are doing L2 S to enhance privacy and scalability. Someone's made a keyless wallet, so things that use social recovery and shamir secret sharing. So that's pretty cool. And someone made Biosnarks, which is to do with sharing data in the biotech industry and verifying things as well while keeping sensitive information private.
03:00:08.262 - 03:00:49.142, Speaker E: So there's actually a whole list of loads of different projects that people have been building for our ZK Ignite program. We can link you to this kind of list and you can look at that and see what kind of things people have been doing and how they've been doing it for some inspiration. Next steps for the Hackathon if you want to build stuff, come and talk to us at the booth. We'll be there to answer questions and talk to you about your ideas. The docs have all the information there. Obviously that's docs minorprotecall.com. We have a Zkapps Q A channel on our Discord server which is full of people who are really responsive, knowledgeable, and helpful.
03:00:49.142 - 03:01:21.218, Speaker E: So if you have questions, technical questions, you can go onto the Discord server. It's discord GG slash Mina protocol. I think that QR code goes to the Discord as well. And yes, so you can ask your questions on there. There's also the ETH Global Discord server. We have like mina sponsor or sponsor mina channel. And so you can go on there as well and ask questions about things you're trying to do, or book a slot to come and meet someone at the booth or something.
03:01:21.218 - 03:01:43.386, Speaker E: And also you can DM me on Twitter blockchainbeard. That's really just something that I put in there to try and get more people to follow me. So thank you for listening and if you have any questions we have about five minutes, do we? No, I've got a timer though, so five minutes? Yes, five minutes. Hello?
03:01:43.488 - 03:01:46.220, Speaker B: Verify the proof is on a transaction as well?
03:01:46.670 - 03:02:05.220, Speaker E: No, you can verify the proof off chain, but if you want to change the state of things on chain, then you need to send it to the network. And one of the nodes needs to verify the proof that you've run a ZCAP. Any other questions.
03:02:06.630 - 03:02:14.180, Speaker C: Can you elaborate on how the recursion works? Like is the book passed among those smart contracts or how that will work?
03:02:15.270 - 03:02:39.200, Speaker E: How you code the recursion? Yes. So I think I will answer that question by saying you should come to speak to us afterwards because we have to finish, but we can talk to you more about how to think about recursion and how you write the code for it. And if anyone else is interested, come and speak to us as well or see us at the booth. Thank you very much, everyone.
03:08:44.060 - 03:08:44.810, Speaker C: Okay.
03:08:46.780 - 03:08:47.530, Speaker A: Hey.
03:08:48.620 - 03:09:03.900, Speaker C: Hi everyone. My name is Nick. So I'm going to start. I have a backend to meet at 1inchh. So today I want to talk about our latest innovation. It's a one inch fusion. Maybe you are familiar with Uniswap X right now.
03:09:03.900 - 03:09:28.884, Speaker C: So we had it before it was mainstream. And let's start with some small introduction. Vanish actually is one of the leading projects on the market. Vanish was started at Ethereum, New York at the same heck as we have right now from Ethereum Global team at 2019 by two members. Right now we have several protocols and we have about 2.8 million users. Actually a bit more right now.
03:09:28.884 - 03:09:58.856, Speaker C: It's about 3 million users. We have billions of volume going through us. We are leading dex aggregator. And not only that aggregator, we have multiple other protocols. We have aggregation protocol, limit order protocol, one inch fusion protocol, and also we recently released one Inch developer portal for the developers to make it easier to use APIs with no limits and more adjustable limits for them as well. And also we do have a non custodial wallet on iOS and Android. So let's recap.
03:09:58.856 - 03:10:46.856, Speaker C: What is vanish. Aggregation protocol is basically One inch aggregation protocol allows you to have uniswap like experience, but with a bit better rate. Because we are trying to aggregate liquidity across multiple DEXes, not only uniswap but across DEXes like curve, balancer and about 70 more. Basically every time you are trying to make a swap, we are trying to split your initial token, source token like one inch for example, in this example, to some small subpaths and actually trying to try to pick the best pair token, connector token. So let's imagine that we have a one inch token and you need to get some die token in the end. But we're trying to build a path across wrapped bitcoin or like wrapped Ethereum for example, USDC. And only after that we go to the dai.
03:10:46.856 - 03:11:15.720, Speaker C: And the logic of that is because we want to minimize the slippage, we are trying to aggregate all the pools rates across multiple DEXes and find the way where the rate is a bit better. So it's the best strategy if you want to get lower slippage on the market. We have about 220,000,000 volumes during the day. Actually. All the analytics about aggregation protocol and all our protocols is open source you can check this out on June Analytics. One inch basically. One inch basically.
03:11:15.720 - 03:11:39.344, Speaker C: Yeah, it's quite transparent. Here we have a little smaller volume, but I made this screenshot like at 06:00 A.m., so it's a bit smaller. How varnish protocol, aggregation Protocol works basically is as a developer it's quite easy to integrate that. Basically you need to fill some data. It's actually source token, destination token and the source amount of this token. We have an API for that actually.
03:11:39.344 - 03:12:21.752, Speaker C: It's a backend algorithm that calculates the best path, but it's executed on non custodial smart contract basically. So it's also verified and audited by about seven companies. First you need to make a quote. Basically you're trying to understand what will be the return amount from source token to destination token. If you are okay with this return amount, you basically call another API handle called Swap and it will return to you the call data that you need to execute on chain transaction to the one inch Aggregation router. This is quite simple and that's how you can integrate one inch Aggregation Protocol. Okay, actually you can also try right now aggregation Protocol on developer portal with no limits.
03:12:21.752 - 03:12:37.500, Speaker C: It will be pretty adjustable. It's our latest innovation. So latest API, aggregation like latest API for developers. So check this out please. We also have Bounties for that today. Okay. We talked about Aggregation protocol.
03:12:37.500 - 03:13:24.652, Speaker C: I can say that it's one of the best way to sell something on the market price. If you'll try to compare something to the Dex, to the success like binance, it's like market sell for any token. So it's just one atomic transaction with the best potential path, but it's only market sell. But what about limit orders? When you want to specify some target price for any token and you just want to wait until it will be executed, it's a bit more advanced and we do have a limit order protocol for that, that allows you to do a lot of fancy things. For example, it's gasless. So for every user you don't need to pay for gas because basically you don't do anything on chain except approves of tokens sometimes. Also it allows you to do additional callbacks.
03:13:24.652 - 03:13:56.860, Speaker C: For example, you can use post interaction methods to withdraw some liquidity from Ave for example. And only after that interact execute this limit order from part of the user. It's one of the most optimized protocol on the market. It's open source as well. It's also outdated right now it's a part of Aggregation router like contract. So let's try to understand how it works as well. So from one point we have a user, basically user do very basic logic.
03:13:56.860 - 03:14:43.588, Speaker C: You just need to understand which token you want to swap. You specify the conditions for swap. For example, I want to sell if one Ethereum for 2000 die and I have some time constraints, for example for one week. And what you need to do just create this structure and sign it from your private key and send this signed transaction with the structure to manage limit order APIs. And that's it. You can do it with our front end, we implemented basic functions there so everyone can try, can try that, can try that out there. Okay? And on other part we have a kind of professional market taker who is trying to fill these transactions.
03:14:43.588 - 03:15:21.830, Speaker C: This is the entity who is trying to pay for gas on chain. And actually this is the entity who can make some profits from that potentially. We also integrate this market taker to our aggregation API as well. So every time somebody is trying to swap something, they can also execute limit orders as well on the aggregation part. Everyone actually can participate in that and be like a resolver a taker there. But there is an issue that you need to understand how to calculate the exit price. So you need to take care about the gas price that we'll need to spend to execute the order.
03:15:21.830 - 03:16:14.204, Speaker C: Yeah, why I'm talking about that is just to understand what we are talking right now. That we have a market makers that's basically the users who create something and send it to the entities and the market takers that trying to execute these orders from trying to fill these orders and get some profits. In this case, usually market takers it's like developers, it's professional like some companies that doing that and makers, it's basically users who have interface for everything. So this is like main scheme how it works. So we have users that signing orders, sending it off chain and some takers that getting these orders off chain and executing these orders on chain. And there is verification that everything is correct with the signatures and all the rules on chain as well. So it's kind of permissionless.
03:16:14.204 - 03:17:02.836, Speaker C: We don't care where you get this order, we only care the structure and the data there. So that's how a limit order works. But there is a small issue that it's not very comfortable for users because you basically want to sometimes to sell on the market side. But we have a lot of issues right now with MIF for example, with attacks like sandwich attacks on multiple blockchains. It's also quite expensive and it's bad UX sometimes because of the gas prices. So we just questioned us ourselves what if we want to try to solve all of these issues at the same time? What if you want to sell on the market price? But we actually don't care too much that it will be one atomic transaction. We want to have just the best market price during some small time interval, like five minutes for example.
03:17:02.836 - 03:17:58.440, Speaker C: And we also don't want to have some issues with Mifatax for the users because it's extremely painful to explain them. What is that? How to be protected from it? It's quite hard to be natively protected, but we want to make it happen and also it must be guzzlers because it's one of the best experience you can get potentially sometimes. So we are trying to build something like that and actually this is a one inch fusion. It's our product that helps you to have the same uniswap like experience, our previous experience with aggregation rotor but it allows you to have gasless execution NIFT protection by default and basically in some cases it's almost better prices that we have on the market because you have almost limitless liquidity there because any resolver can accumulate. That just a small example. For example you're trying to swap this is actually the real life transaction. It's like 3000 ethereum wrapped ethereum to USDT.
03:17:58.440 - 03:19:02.940, Speaker C: So it's actually a Dutch auction that we have at the same at Uniswap X that allows you to have during some time interval the price is going down. We're starting from the price that is a bit more expensive than on the market and we are waiting until somebody will be starting to fill it. The main point here that there is an open market of competitors that trying to fill it and the motivation for them to execute this transaction is that when it's going a bit closer to the market price they are trying to arbitrage that and get some profits from the arbitrage. Basically that's the main point of it and because of the open competition, not because it's one on chain transaction, because it can be multiple limit order transactions that will be executed for one order, we have a bit better prices and yeah, basically that's the main sense of it. We also recently tested that with 11,000 Ethereum as well. It was also executed better than one on market prices with one on chain transaction. So vanish Fusion is very useful for large trades.
03:19:02.940 - 03:19:51.676, Speaker C: So let's talk a bit about gazos execution. So, as I told before, makers basically do the same as they are doing on limit orders. They're just signing some transactions, some data that is off chain. You don't need to pay for gas except you need to make one small approved one inch contract from the token usually most of the tokens support permit function so it's also gasless per approve for the contract. After you did a permit or you made an approved, you just need to sign this transaction, the auction and set it to the back end, to the limit order storage and after that it will be actually shared with the resolvers, with the entities. They will be fighting for your order, trying to fill it and they will be paying for gas. So as you can see, it's a bit gasless but it's not gas free.
03:19:51.676 - 03:20:28.264, Speaker C: So actually every user will need to pay a bit in gas but not directly with Ethereum but with the gas rates during the execution of the trade. So like every resolver will be executing this transaction not on the market price, but sometimes a bit below because of the gas price. That's how it works. We don't have any magic that makes everything executed for free. That's the case here. Let's talk about beef protection. So it's also not that simple because of course users don't need to think about that right now because we don't have any on chain activity from the user side.
03:20:28.264 - 03:21:08.368, Speaker C: But we do have on chain activity on the resolver side on the market taker side. So every resolver needs as a professional, we do assume that resolvers on our site like in One inch Fusion are professionals that actually know how to handle MEF attacks and in this case they have an issue with me attacks, but users don't have this issue. So we are trying to focus, like trying to allow professionals to solve these issues, not users. And it's pretty simple point about image liquidity. Basically because we have a price auction, it's about five minutes, it's pretty customizable. Let's imagine we do have some not very liquid token. For example, some shitcoin.
03:21:08.368 - 03:21:47.548, Speaker C: And there are some cases when you want to swap this shitcoin to another coin, if you will. Trying to do this on some DEXes with one atomic transaction, it will be pretty high price slippage. Because let's imagine there's not enough liquidity on this chain. But there are some liquidity for example on other chain. If you have a price auction during eleven amount like minutes of time, some resolver can try to arbitrage to bring this liquidity for example from cross chain and execute this order on better prices that you will have if you will do one atomic transaction. This is like the main point of auctions that you can accumulate resources during the price execution. You have enough time for that as a resolver.
03:21:47.548 - 03:22:26.508, Speaker C: That's why we have a bit the best possible solution for sleepage that we can imagine right now. So the main picture actually looks like that. Basically users just need to do two things. Sometimes they need to give a permit or approval to the one inch router contract and sign the off chain order. After that it goes to database shared with the resolvers they are pricing for this order and executed using one inch aggregation router as well. Actually, it's quite easy to become a one inch resolver. We have a pretty decentralized way how we can make it.
03:22:26.508 - 03:23:19.040, Speaker C: One thing that you need to do is just to register as a resolver on the smart contract side and also you need somebody, maybe some entity to delegate you some unicorn power. Actually it's staked one inch token that allows that will bring you to the top ten resolvers who will be executing the orders in our system. So if you want to execute orders of market takers of users of one inch, you just need to get to be on top ten of resolvers. If you want to be in top ten, you need somehow to motivate the users to delegate to your pool. And the system works like that. You basically can motivate them by sending some token. Right now it's only one inch token to the full factory and users will have a motivation to stake delegate the tokens to your factory and they will get some rewards on that automatically.
03:23:19.040 - 03:24:40.650, Speaker C: So it's an open competition who will be on the top ten? That's like the main reason why that's the main point so that users will delegate to the only entities that have the maximum APY and if the MPI changing they will redelegate to other entities. That's why it is always kind of not they are not forced to send rewards but they need to compete with each other for that. So that's like an opposition how it works right now there are two options how you can work with anich fusion basically the first one trying to integrate it into your app, the app or like any DeFi app where you need to execute any swaps it's quite simple, you just need to have an fusion SDK. Right now we have it on TypeScript as one of the most popular languages in the market right now and here is one more option, it's a bit more advanced. I'm not sure it's quite useful for the hackathon but it's still pretty profitable as if you want to build some business or doing some market making it's just become a resolver for each fusion as well. So if you were interested in becoming a resolver you can talk to any our community member here we have a large booth so yeah, just talk to us and also if you have any questions to Vanish Fusion to integrate it to integrate it you can just ask me later. Right now we are trying to code.
03:24:40.650 - 03:25:00.656, Speaker C: We have a vanish network documentation here with SDK. I will try to code a bit. I actually made a small repo with one inch fusion 101. You can just scan it. Basically everything. What you need to do is there. I will try to show some live examples right now, right here.
03:25:00.656 - 03:25:31.530, Speaker C: But we will not have enough time. You can just launch it on your own. Only one thing you need. There is JSON RPC Endpoint There is a default one there, but maybe you will need your own custom endpoint. And one more thing you need some ethereum. You need basically private key there with some Ethereum on it to execute transaction ethereum chain or any other chain basically you can switch between networks. So yeah, I'll try to do some life example how it works and just explain how one inch Fusion 101 works.
03:25:31.530 - 03:26:03.670, Speaker C: We'll try to basically try to simulate the case as a developer trying to integrate Vanish Fusion to its own app. Yeah, it's pretty on node JS right now. But let's imagine you'll try to use a front end like react or something else. I just don't want to focus on that right now on the user interface part, because we have quite not enough time. So we do have a pretty basic structure here. I will try to make it a bit more visible. 1 second, please.
03:26:03.670 - 03:26:37.608, Speaker C: So you just need to open index JS file index JS file to see the main default picture. Basically. What do we have here? We do have flow where firstly you can potentially make an approve of source token to the one each contract that you want to swap. That's the first step. So if I will put through, it will basically just make your sequence approved to one inch contracts. That's the first step that I just automated. The second part is more interesting part, it's trying to make a quote from using one inch order SDK.
03:26:37.608 - 03:27:33.024, Speaker C: Basically quote, what will be the return amount for the source amount of tokens and the last part is basically do the swap basically creating fusion order that will be actually a real transaction it will be off chain but it will spend some resources from your account. And yeah, in the end of all, we're trying to search for all orders that we do have on this address through actually just database. So this is like the main three things that you need to have. Checking the approve doing that approve for the specific token also quoting some data and after, if you are okay with this data, you can execute the swap and after that you can check the all history of these orders. This is like basics that you need as a developer to integrate Van H Fusion. So if you'll take a look on the config side, it's pretty simple. Example I just put everything here.
03:27:33.024 - 03:27:55.988, Speaker C: It's not like production ready code. It's just like some ideas brainstorming. So we do have here some hard coded tokens. I will try to focus on ethereum right now. So I just picked network ethereum. Here I have some hard coded vanish token amount that I will use for quoting and potentially for swap, if we have enough time. And, yeah, I have my private key hard coded as an env variable.
03:27:55.988 - 03:28:24.368, Speaker C: I will not show you my private key, but, yeah, you can just put your own later. So let's try to basically run something. I want firstly to run a quote and trying to take a look what will be the return like the return from API of the quote. So for that I just hard coded some variables for Boolean. Variables to not to do everything at one step. Let's just do only quote. So a proof and swap is false and quote is true.
03:28:24.368 - 03:28:45.882, Speaker C: Let's run some code. So we do. Have here basically the quote. It's the first part. And lower. We just have a history of all orders on this account. Let's take a look on basically the return amount and the structure that we do have from one inch API for the quote.
03:28:45.882 - 03:29:22.070, Speaker C: What is important here and how we can work with that later. So basically it's just JSON file and it's quite large, but we don't actually need to focus on everything. Sometimes we need everything, but the main things that we need to see here is basically presets presets. It's actually the hard coded ways how the auction works. We have price formulas for you, so you don't need to calculate it on your own. It is possible to use a custom price mode on auction but it's not available on one inch HDK yet. It will be available quite soon I think.
03:29:22.070 - 03:30:08.470, Speaker C: And the main point why we didn't do this right now is like yet it's because it's quite hard to manage the risk in this case and the custom preset is quite painful and you can lose some assets there or it will not work as expected. In some case you need to be sure that you want to specify these parameters, not as default ones for the execution. So in most cases you don't need to do this. So let's take a look on the presets. And basically the main point here is that we executed a quote for swapping 101 inch tokens to some route ethereum and this is like the return amount that I got here. It's calculated in way. Let's try to understand what is the real number here.
03:30:08.470 - 03:30:41.974, Speaker C: I'll just open Google for that. So this is the amount that we got from the quote and we can just double check that we have something the same on the front end of an inch for example. So let's take a look how the front end works. What will it will return for the same amount of tokens. So we will pick a veraptive and the swap will be from one inch. So it's 101 inch tokens. So the return path is quite the same as we have here.
03:30:41.974 - 03:30:51.980, Speaker C: It's like zero point 17. Yeah, it's quite the same but precision just is different here. We are not showing all the numbers on the UI right now.
03:30:53.150 - 03:30:53.706, Speaker A: Okay?
03:30:53.808 - 03:31:35.714, Speaker C: So right now let's imagine that we are okay with this trade and we still want to swap some one each token. Let's try to make an approve. So basically as a developer, what you need to do is just to understand the two token amount from the source token amount, that's actually the price that you will get of the destination token in the amount of that. There are some additional data about that. You can see the prices like from token in USD and two token of that pure one token actually and the volume of that in USD as well. And we do have a parameter called recommended preset. It's basically you can just use the recommended presale by default.
03:31:35.714 - 03:32:43.970, Speaker C: It quite often is a fast preset for the fast swaps. When you have a small amount, it's pretty easy to do fast swaps because the price auction, the longer it takes, the harder the price formula works and you need to do something with that because the price can go down significantly if it's not a fast preset. So let's try to execute this order and during the moment when I will be doing that, I will be happy to answer any of your questions. So if you have any questions, just raise your hand. I will be trying to swap at that moment. Can you do a transaction like limit of So? Yeah, it's quite possible. Right now it's not possible in the interface, but using the our code, the source code that is MIT based on the GitHub, basically you can use Smart Contract like not only externally owned account but Smart contract own account to do execute the swaps.
03:32:43.970 - 03:33:21.398, Speaker C: It works for aggregation rotor, it works for fusion because basically what is fusion? It's a fusion of aggregation rotor as limit order. Basically you're just creating a limit order and in limit order it's quite adjustable protocol and you can do whatever you want there. You can use externally owned account, non externally owned account. You can actually not only execute limit orders with years to 20 tokens but almost with any entity with any token. For example with NFT tokens actually what you need to do to make it possible. You just need to implement a transfer function for the limit order. There are several examples in our documentation, in our GitHub.
03:33:21.398 - 03:34:03.338, Speaker C: I just recommend it to everyone. If you want to try limit order aggregation protocol or like fusion SDK, you can just also try to take a look on the tests of smart contracts there. There are multiple use cases that sometimes are not public from a user interface, but they are already written. So you can just use them as a starter for your case. For example, if you increase the time on the auction phase like faster than a slow one, you'll get a better price. It doesn't work like that because the price constantly going down. If you will increase the price, we will try to make a formula more complex because it will be going down most lower because you have a minimum amount that you will return.
03:34:03.338 - 03:34:51.082, Speaker C: So the auction works like you'll never go to zero. It's like some between some price intervals but because of the market it's kind of predicting how it works. If the price goes too much down during long amount of time, you will just wait too much and you will not get enough tokens. It can be failed. Basically like when we start an auction, we're trying to understand okay, what is the market price right now? Let's imagine like 2000 ethereum and we are trying to say okay, the starting point will be a bit more above of the market price and let's imagine what can happen. What is the minimum return amount that you want to get? What is the minimum the lowest rate that you are okay with? For example, it's like 1950 die for ethereum. So during this.
03:34:51.082 - 03:35:27.430, Speaker C: Interval you are okay to swap. So we have built a price auction like a function that is going down to this amount, to this rate. And let's imagine we have a ten minutes. What will happen in these ten minutes is quite hard to predict. Sometimes the price going down too fast and if it's below the 901,950 ethereum 9950 die, you will just get nothing because it will be not profitable for resolvers to execute the transaction. So it's not a fact that it's not a statement. Sometimes it works like that, it just can iterate a bit more.
03:35:27.430 - 03:36:03.310, Speaker C: It's quite possible that something can go better, but it's not a guarantee that it will happen. So like the interval, the more you wait doesn't mean that the price will go to your interval, like to your target price. Yeah. So the race will be not definitely better. It can be it depends on the amount of money that you have. If it's a large amount of money, like for example, if I like $100,000 in this case, it's much more better to wait a bit more because of the volume. The reason for that is that basically resolvers will need more resources to accumulate to accumulate to execute this transaction.
03:36:03.310 - 03:36:50.310, Speaker C: If it's $100, it's quite easy. But if it's a large sum, they need somehow to arbitrage that. And that's why sometimes when the price the auction time is a bit longer, that's why sometimes the price is better for the large amounts, but it's only worse with large amounts mostly. And there is no any guarantee actually sorry, are partial fields possible? Partial fields are possible with fusion mode. So yeah, that's one of the main points for how you can save on gas as a user. Basically it's off chain transaction for you and it's on chain transaction for resolver. But actually resolver can budge multiple user transactions into one on chain transactions.
03:36:50.310 - 03:37:07.270, Speaker C: So basically they share the gas price across multiple transactions. A bit more optimized. There are multiple ways how we optimize that. That's why auction is a bit more gas profitable for the users. They are also matching orders sometimes. So it's actually quite efficient. It's like economy of scale.
03:37:07.270 - 03:37:35.940, Speaker C: The more users will have, the better it will be working and the more cheaper it will be working for the users. Yeah, I just want to comment that we just executed the transaction. So this is we have as a result of executed transaction and we have actually several orders in the history before it was one. Right now it's two transactions. We'll try to take a look what happened on this account. If you have any questions, just ping me. Okay? I had no questions.
03:37:35.940 - 03:38:34.706, Speaker C: You showed the fusion mode order flow earlier. Which parts are on chain? Yeah, let me show it again. I think I can modify this picture later. But basically here everything started from here. This part, like if the limit orders part is on chain part is actually down like the line here all here is on chain because there is always field transactions using one each network using limit orders contract basically and makers basically users are trying to make approve to the limit order contract as well. This activity happens on chain and everything else, the matching they're like accumulating and all the calculation when it's profitable happens off chain. Basically what we do on chain we're trying to minimize the efficient, like to maximize the efficiency of the contracts, trying to do as minimum as possible on chain.
03:38:34.706 - 03:38:57.834, Speaker C: The minimum you can do is just to verify that they verify that rate is okay and just execute the transaction, just send the funds that's like the minimum you can do on chain. Yeah. Okay, I think we can finish. Thank you for everything. Yeah. I will be open there for any questions. Thank you.
03:38:58.032 - 03:39:01.890, Speaker B: Thank um.
03:40:59.550 - 03:41:00.634, Speaker C: Yeah, I think I think.
03:41:00.672 - 03:41:02.714, Speaker E: One of one of our teammates talked.
03:41:02.752 - 03:41:05.100, Speaker C: About it's not.
03:41:10.230 - 03:41:11.740, Speaker B: Yeah, but.
03:41:15.150 - 03:41:34.960, Speaker F: Great. All right, thank you so much for everyone being here. So my name is Tom and today going to pretty much be talking about mobile first and this workshop and just general overview is around why we should be building on mobile and pretty much a quick example app of how to build a Web Three mobile DAP with Wallet Connect.
03:41:36.530 - 03:41:37.182, Speaker A: Cool.
03:41:37.316 - 03:41:52.280, Speaker F: So just as an introduction for myself, my name is Tom, I lead devrel relations at Wallet Connect and spent several years as a mobile engineer prior to this. Hence my interest in doing a lot more mobile development at Wallet Connect.
03:41:53.930 - 03:41:54.582, Speaker A: Cool.
03:41:54.716 - 03:42:39.762, Speaker F: So for those who aren't as familiar with Wallet Connect, the simple way to put it is we're a protocol that enables two parties to connect and the two parties we essentially have is DApps and Wallets in this space and we're encrypted trustless, open source and chain agnostic. So we started several years ago one single QR code and now we would say several hundred wallets power us and many DApps use us under the hood. So we really try and facilitate connections between the two parties. I E. Wallets and DApps. So that's maybe how you might be knowing us and I might want to just quickly touch on what we've been working on recently and how this kind of relates to our hypothesis and reasoning for mobile. Cool.
03:42:39.762 - 03:43:34.502, Speaker F: So just as an introduction. So to further extend, maybe give you insight that Wallet Connect is more than just a QR code signing protocol and also a common question we get is is Wallet Connect a wallet? The answer is no, we're not a wallet. We're a wallet infrastructure, an adapt infrastructure, kind of like as a communication protocol infrastructure and these are the things that we've been busy on recently. So Web Three wallet is something that a lot of wallets I guess, use under the hood and most of the 300, 400 wallets that are out in the space that we power, they're the ones that using that one. So this has lots to do with chain switching and things like that that you might have seen recently. And then Web Three wallet modal is kind of the part that we want to talk about today, particularly around DApps. So every time you might have seen a Connect Wallet button and a QR code, that's kind of the core product that we started with.
03:43:34.502 - 03:44:20.260, Speaker F: So a lot's been happening in that space and I think more recently you guys have might have seen communication signed to happen within Web Three. So I did a talk on mobile wallets the other day, and it's kind of interesting in that we started in 2017, 2018 particularly with, say, a wallet called Toshi Wallet, also known as Coinbase wallet, and they were actually doing messaging four years ago, they actually kind of stopped that. And now it seems like it's kind of opening the floodgates of that. So we're also in the works around Web Three inbox. So Web Three inbox is around push notifications, notifications and chat. So this is something that, these are the product suites that we've been working across and particularly wanted to focus on web Three modal today.
03:44:21.770 - 03:44:22.374, Speaker A: Cool.
03:44:22.492 - 03:45:07.140, Speaker F: So Web Three modal, I guess some alpha of what's coming up. It looks very different to what we have right now. This is the direction we're heading in. So you might be very familiar with connecting with MetaMask, connecting with Moat, Coinbase and any of your other respective favorite wallets. So this is what Moat Web Three modal focuses on and pretty much every wallet you have out there, whether it's a cloud based, smart, contract based, web based, mobile based, they're all available through Web Three modal these days. And we're going to be extending it further with other features, new UI. And today I want to particularly talk around how we're going to work on, just do a demo on the light version of why, how quick it is to spin up mobile development these days.
03:45:07.140 - 03:45:40.634, Speaker F: Cool. And just since we're all here for hackathon and to win prizes, I think that's all we're here for, of course, but to learn. So thank you for being here. So we have around 20 grand of cash prizes to give out this week weekend. First one particularly around mobile, that's kind of what I'm speaking around and we've got some documentation all across all of this. But we got six grand for Web Three mobile. If you use React, Native, Flutter, Swift or Kotlin to spin up a DAP going to provide some prizes around that innovation.
03:45:40.634 - 03:46:32.062, Speaker F: This is our first time doing this track and six grand around that. So if you're interested to work on ZK Proofs and ZK Snarks and then use Wallet Connect as a connection through that, there are many great ZK EVM kind of blockchain systems out there, so feel free to use that. And another topic that you guys might have seen is 6551. So this is around token bound accounts and it really relates to the wallet space. If we talk about wallets right now, everyone talks about AA account abstraction, which is great. It's another form of onboarding and personally another one that I'm interested in, 6551 token bound accounts. So the TLDR of it is if you generate from Tom ETH and then you purchase a crypto punk or whatever, then that is kind of as generated as a token bound NFT wallet account that you can start to identify yourself as.
03:46:32.062 - 03:47:06.554, Speaker F: Okay, this punk now gets if you think maybe more around loot, I think that's a bit more plausible. It's kind of like a composable way to build your inventory and identity. So really excited about that authentication. So this is something like really interesting partners like Instagram and stuff have used to kind of verify, okay, I am zero x, one, two, three, connect sign and authenticate. So it's a really simple API and really encourage you to do that. And the last one is for those who aren't developers actually here. And we're doing a design track of our cloud app.
03:47:06.554 - 03:47:37.346, Speaker F: Looks a bit bland, can do a lot more improvement. So feel free to drop a figma and trying to recreate. Like how would you do user design flows that's mobile innovation, auth and cloud. And then we have a pool prize of anyone who wants to just work on web, three modal web based stuff. You'll be in a pool prize, $200 or so. So that's that. I kind of wanted to go around a thesis around mobile and it actually might work to talk about the wallet DAP paradigm first.
03:47:37.346 - 03:48:20.318, Speaker F: So wallet connect has an extreme pleasure to talk to every single wallet out there, to talk to every other DAP out there. So yeah, every day we get to talk to them, we have to understand what they're facing. And I don't know how much you guys have talked to wallets in this ECC week, but a lot of them have just been like, wallets are the problems, wallets are the problem towards the gateway and stuff like that. And they're like there are three camps actually around the future of mobile. There's strong pessimism of like, oh, wallets aren't doing enough in innovating. Fine, if you want to take that camp, we can stay there. There's the other one of there's going to be a super wallet that's kind of around this thing called the Fat wallet thesis by a 16 z a while ago.
03:48:20.318 - 03:49:09.426, Speaker F: And it's kind of like, hey, there's going to be a few wallets that are just going to do really well and then unlock innovation for us. And then the third camp is there might be really niche wallets out there that are really just specifying on chat NFT and all of these things. So there probably are many other hypothesis of how personally that I'm seeing how wallets are being talked about but the thing is, we also have to focus on the DAP paradigm, is why we're here for the use cases. If people are, pardon my French, are going to shit on wallets not being good enough, there also has to be better use cases within the DAP paradigm, particularly on a mobile friendly environment. So that's kind of what I've particularly seen a lot around ETHC more recently is sure, there are problems on wallet we're fixing with onboarding AA and all these cool other bolt on features. But we also have to start now focusing on the DAP paradigm. It's kind of a chicken and egg problem.
03:49:09.426 - 03:49:47.710, Speaker F: So here at Wallet Connect, we really started on mobile. First we figured out a way of how do you connect your browser to your wallet back three, four years ago. And now we just really want to extend it to like, how can we make this even further? How can we make this Connect wallet button as seamless as possible? How do we make actual better use cases out there? So that's currently our take. And as to why we're really focused on mobile alongside, like, MultiChain and a lot of these other things. So that's currently our stance, that we really want to help innovate and provide better dev tooling for both sides of this spectrum, right on this Wallet and DAP paradigm.
03:49:48.850 - 03:49:49.550, Speaker A: Cool.
03:49:49.700 - 03:50:29.450, Speaker F: So just before I get into the demo and the development of things, so you might have seen this as web3 modal. And what we do is we're really experimenting a lot more so this could be considered the full version. We're going to be releasing social login, emailing and pretty much you can access all of your wallets and wagme as a library ethers. And we're making it as composable as possible. And for the sake of builders and hackathons, it's much easier to use our light version. It's kind of just think about the skinnier version that allows you to bring your own library, allows you to bring your own tooling and have it go there. So that's just some distinction just to give you more clarity if you do read our documentation.
03:50:31.070 - 03:50:31.820, Speaker A: Cool.
03:50:32.590 - 03:51:28.880, Speaker F: All right, so this is kind of taken from a previous thing in that I think we really need to this kind of actually is the wallet and DAP paradigm actually onboarding is wallets. Let's just think about the left hand side is more about wallets and the right hand side is DApps, right? So we really need to start thinking about like cool account abstraction, MPC, web author and all these cool things that are coming out there are great. We're getting there, we're getting to a better place, but that stuff needs to be fixed for sure. But then we have to start thinking about the DAP features. And that's where we're trying to bring more tooling into the DAP side of how do you financially read and write through staking and all of these really cool ideas that you guys are going to hack on this weekend. How do we innovate more on NFTs or Onboarding in that same paradigm? So maybe token bound accounts, namespaces, identity. There's ZK identity with Sismo and then there's like ENS Lens, DIDs Disco, all these cool things.
03:51:28.880 - 03:52:07.578, Speaker F: Transaction simulation, those are copy paste but MultiChain. I think that's also something we've really missed. I fail to see many good MultiChain applications either on the Wallet or DAP side. And I think it's because we're still figuring it out and right now with the whole L two summer or whatever we want to call it, L 100s, however many L's layers we're going to go down, we really need to focus on this. So this is why we're really trying to encourage these DAP features. Cool. So yeah, this is on the right hand side is a GitHub repo of an example we have that I built out.
03:52:07.578 - 03:52:42.014, Speaker F: So this is the most relevant thing for the hackathon if you end up wanting to build a React native wallet Connect modal. So just as an FYI, I'm not leaving out any native folks out there. There is Kotlin, actually there is Swift and then there is Flutter. So I'm not trying to leave anyone out there, but this is just for the most easiest boilerplate thing and just as a general thing of development out there. Wallet connect across several SDKs. We do unity even. And yeah, this is just for React native.
03:52:42.014 - 03:53:06.922, Speaker F: React native seems to be very popular within the DApp framework and Wallet framework. So that's just also a heads up if you're willing to bootstrap in that network. So that's just the GitHub repo. Hopefully that worked. So this is our one liner. Of course, it's like pretty bland, pretty quick. There are some polyfills that you need to do and this works for React native CLI, but also for Expo.
03:53:06.922 - 03:53:59.210, Speaker F: We're actually thinking a lot more and optimizing on Expo for any React native developers out there. As a mobile developer three years ago, Expo wasn't there, but now we're really in a place where I can just spin up an application for React native and mobile, get it done very quickly. So really bullish on Expo and how we've done that. So I might quickly show you a demo before I get through all of this code snippet. So I am not going to risk doing a live demo because the WiFi and even though I love Expo development, I think it's just going to take a bit of time to compile left hand side, some code that I'll go through in a bit. So the right hand side is let's just kind of assume this is the simulator. So if I go back here, it's just some tutorial says that the state of it is not connected.
03:53:59.210 - 03:54:14.350, Speaker F: And then we want to go through the connect button. So it's just a pressable function. Very simple. Yeah, you guys can see it. Yeah, let me zoom in on the code for a bit later. So, yeah, pretty much just clicking the connect button. This brings up a UI.
03:54:14.350 - 03:55:03.330, Speaker F: You can bring along your favorite wallets that you use these days, probably MetaMask, Trust or whatever else that you use. Pretty much click into it. Then I pick Trust wallet, enter your code, whatever has your address, zero x six, something, redirection and voila. So I think if we can get to a state where we're easily figuring out how to do wallet development in a very seamless manner, I think that's the goal. And there are probably more JS web developers than JS mobile developers or even native mobile developers. And that's the short truth. But I think what I want to pause and think about is that if in three years we're still using MetaMask extension as the first onboarding for your grandma or your child or your friend, we've kind of messed up.
03:55:03.330 - 03:55:43.018, Speaker F: So I think we want to get to a place where we're trying to push more and kind of ask for better ways to do handling of mobile and just ranting on and thinking about it. There's better ways that we can even handle keys and do opclaves and web authent through face ID and native account abstraction, all these things. So there are really cool things in the mobile space that are happening. And I really wish that we moved towards there because once again, in three, five years, if the majority of us are still onboarding through MetaMask, like window ethereum, we kind of messed up. So that's my personal take. So, yeah, that was the connection. I believe it kind of restarted.
03:55:43.018 - 03:55:45.120, Speaker F: Just take you through the whole flow again.
03:55:51.420 - 03:55:51.832, Speaker A: Great.
03:55:51.886 - 03:56:20.790, Speaker F: And then you're connected. So that's your zero x address. And then I can press a disconnect button and then from then on so this is the boilerplate for those who are in these platforms. You can use something like Ethers or VM or Wagme. And there are other native libraries for Swift and Kotlin that you can use to help you think about the use cases. So it kind of comes back to this, how do we build better use cases out there so that we can work with this whole wallet and DAP paradigm of things?
03:56:21.480 - 03:56:21.940, Speaker A: Cool.
03:56:22.010 - 03:57:03.910, Speaker F: So that's that still keeping it quite short. So going back here, so this is just essentially the wrapper of the schema that I wanted to share. Essentially you'd be just importing a wallet connect modal just as a UI component, project ID, so that's through cloud, so that gives you better tracking and measurement and just understanding about your project. And then there's DAP side exporting of the function going through it, opening up the modal and just injecting some data. So what's the name, your DAP description? URL and redirect. So this is something I want to point out for mobile developers out there or anyone. If you don't redirect your app, people are going to get pissed off so please do that.
03:57:03.910 - 03:57:40.252, Speaker F: You need to actually really figure out just doing these schemas is really essential. A lot of even the top wallet out there does not do this very well so please handle these kind of things. So like you saw when trust quickly redirected back that's very important. So something to take into consideration. Cool. This is further extending the code of it and the most important line is const open and Use Wallet Connect modal hook. So we just made it really simple and we give you the power to think more around the provider and stuff like that.
03:57:40.252 - 03:58:19.200, Speaker F: So opening function, disconnect function is done through the provider is connected as a boolean address. So pretty bare bone stuff that we've given you and really don't want to complicate mobile development for anyone. So the function of handling that's pretty self explanatory and then we just use the hook to open. So that's that. I'm going to do one quick run through all of it just in the Vs code format so you kind of understand where everything is happening. So yeah so very typical. If you understand JS, it should be pretty self explanatory.
03:58:19.200 - 03:58:57.720, Speaker F: If you haven't done react native project ID, go get it yourself. Providing the metadata of what you do, that's fine. Here I imported the use Wallet Connect modal just through the top hierarchy here I can, I don't know if the internet is great but these are the other parameters you have. I think I've exposed most of them. So this is what we have. Great and then all you have to do is wrap it really with this and then you can handle the rest of your app. So if you want to navigate and do that, do this as the top hierarchy then some very simple styling.
03:58:57.720 - 03:59:41.888, Speaker F: So yeah, that's the code there. I wanted to wrap things up and yeah so once again just finishing it up really encourage you to kind of think about when people are talking a lot around wallets DApps and all of that. There's really this negative camp that I'm really feeling as a sentiment wow, wallets aren't innovating. So let's really try figure out how can we encourage better DAP development as well on mobile so that people can feel more reassured. Okay, these wallets are having actual good use cases, so it's a chicken and egg problem. But I really encourage you guys to give mobile a crack if you have the opportunity. But if not for the rest of the hackathon, feel free to innovate on different sectors.
03:59:41.888 - 03:59:56.020, Speaker F: Feel free to think about authentication, or if you're a designer, think about the cloud. So wanted to wrap it up and for us at Wallet Connect we really think the future is built on mobile. So thank you. And these are some documentations.
03:59:56.600 - 03:59:57.350, Speaker A: Cool.
04:00:10.780 - 04:00:17.692, Speaker F: Yeah go for it. If you want to do ZK snarks of token bound accounts built on react native. Go for it.
04:00:17.826 - 04:00:21.720, Speaker B: Yeah, but would that qualify for both prizes?
04:00:21.800 - 04:00:34.908, Speaker F: Yes, that would qualify for both prizes. So if it's innovative enough and you build, say, a React native app, but it also exposes token bound accounts and this and that, you could technically enter in the two tracks.
04:00:35.084 - 04:00:35.904, Speaker C: Yes, makes sense.
04:00:35.942 - 04:00:36.690, Speaker F: Thank you.
04:03:52.220 - 04:04:00.508, Speaker B: Are we good to okay, cool. Okay, cool.
04:04:00.674 - 04:04:01.340, Speaker D: Hi, guys.
04:04:01.410 - 04:04:26.484, Speaker B: I'm Emily. I'm the developer advocate for Linea. If you guys haven't heard, we launched Mainnet on Tuesday. Big round of applause. This workshop is not so much about building, but more so talking about where to build and why you should choose linear. Right. I'm not sure where we sit in terms of the technical background from this group.
04:04:26.484 - 04:04:48.616, Speaker B: So I'm starting from like ground zero. If you glaze over in the beginning, that's totally okay. But we'll get into something more complex later. So anyways, what is linear? So linear will be a type two ZK roll up. Right. Now, amongst the ZK roll up space, no one is actually type two yet. I'm going to explain this later, but keep in mind that this is what we are.
04:04:48.616 - 04:04:51.436, Speaker B: So, starting off, why do we care about L two S?
04:04:51.458 - 04:04:51.596, Speaker C: Right?
04:04:51.618 - 04:05:27.892, Speaker B: So if you've heard of the blockchain trilemma, essentially it's a pick two situation between scalability security and decentralization. Ethereum basically has chosen to focus on security and decentralization. And with the boom of ethereum, you guys have probably experienced high gas costs and transaction times being slow because all of that is like a competing kind of computational cost. So what do we do? It's something called like a layer two solution. We've moved up to something called the roll up centric roadmap. What that means is, starting from a layer one, it's basically the underlying foundation and base blockchain. That's where consensus happens, that where data is stored.
04:05:27.892 - 04:06:06.012, Speaker B: The history is there examples, bitcoin ethereum avalanche, et cetera. Once we move into layer two, this is actually what we care about. So layer twos work by pulling the execution computational, I guess, capacity off of ethereum. The important part to clarify here specifically is that roll ups have been the, I guess, decided solution because it posts that data back to ethereum. So if you guys are familiar with polygon proof of stake, so you might have heard you have polygon proof of stake. That's what you know, that's like an OpenSea, et cetera, versus polygon Zkevm, which came out recently. Polygon proof of stake is a sidechain.
04:06:06.012 - 04:06:43.196, Speaker B: It is not a layer two solution. All of that data is stored within polygon. So that's why kind of you've seen this pivot towards roll ups because it is a much more secure system to leverage the consensus mechanisms and community around ethereum that like a separate alt layer one or a side chain would have anyways. So that's what a roll up is. How does it actually work? So the anatomy of roll up has well, the anatomy of an optimistic roll up has kind of this structure of there's an on chain contract. So that's going to be on your L One that stores your roll up blocks. That's where the data is stored.
04:06:43.196 - 04:07:04.896, Speaker B: It monitors updates. The next piece is the off chain VM. So this is where the computational stuff comes. So that's going to be what you hear of the Zkevm, which we talk about later. And the last piece, I just kind of grouped them up together. But operators validators, aggregators, sequencers. You can kind of think of this basically as the entity that takes in all that transactions, orders.
04:07:04.896 - 04:07:40.332, Speaker B: It figure out what is going on and then posts that data back. So moving on, I'm going to name two key vocabulary words you need to know when thinking about the different types of roll ups, right? So specifically we have the deposit process. So that's moving ETH from l one to l two and then the last piece is ETH from L two to l one. That's withdrawal. So this actually withdrawal is the key difference, one of the key differences between optimistic and ZK roll ups. So let's actually talk about it. So optimistic roll ups, you might have heard Arbitrum optimism, huge TVL, they're the first ones to come through, right? So essentially what they do is they assume transactions are to be valid.
04:07:40.332 - 04:08:23.896, Speaker B: So to take a step back, like I keep mentioning, data availability. What the important thing here when we talk about the different types of rollups is how do we verify that the data we're proving is true, right? So optimistic roll ups came around and we say, al, let's just assume it's true. Basically we're going to have a seven day challenge period to wait for the community alongside some slashing mechanisms and incentives, to essentially say, hey, this looks fishy, let me run a fraud proof. If it turns out to be a faulty transaction, that will be rolled back, right? There are workarounds like trusted bridges, but we all know bridges are always hacked. So it's not necessarily the best solution. But anyways, so that was kind of the first iteration of roll ups. We knew we needed to do this, but people got smarter.
04:08:23.896 - 04:09:05.084, Speaker B: I don't want to say people got smarter. Research took a little bit longer and we got to the point where we have zero knowledge roll ups. So how are they different from optimistic roll ups? So essentially they have something called a validity proof. So rather than optimistically, assuming they just say, hey, when I post this data back, I'm just going to also post a mathematical proof to a separate verifier contract that will verify that it's true or false. Something I'm just going to mention, and I always say this, I get a lot of questions about, oh, how is privacy on linear? That's a common misconception because people think, oh, ZK, private identity, et cetera, that is a common association, right? Because the property. Of ZK proofs is that you can prove something without having to reveal the information. What it is in the context of a scaling solution is more.
04:09:05.084 - 04:10:07.468, Speaker B: So hey, when we're choosing the different types of mathematical proofs we can use, we're going to choose a zero knowledge proof because that's going to reduce the information as much as possible when we post that data back to be verified. So that was kind of the choice. Examples include linear ZK, sync, polygon zkvm, scroll and StarkNet. So I think there's a lot of different layer twos kind of optimistic versus ZK. But once we get into ZK, what's the difference between all of them? Why do we care about the different kind of pieces? So the first piece I keep mentioning about Zkevm, so essentially this is a Zkevm is the off chain virtual machine that essentially allows you to execute smart contract transactions in a way that ZK proofs can understand. I can't explain how it works, but basically you can think of it know I'm writing a computer program, how do I turn that into like polynomials and math that a mathematical proof can actually run and validate. So that's kind of what a ZK EVM we've been building, right? And that's the differentiator one of the differentiators between all the ZK roll ups.
04:10:07.468 - 04:10:37.592, Speaker B: So this is kind of where I get into the different types. So if you remember that first slide I said will be a type two ZK EVM at the highest level, type four, that's going to be StarkNet, that's going to be ZK sync. You can write in solidity but it is not 100% bytecode equivalent. What that means is tools. You're familiar with Truffle Hard Hat Foundry, you might have noticed you need to download a plugin. Not everything is covered. So you got to be really, I guess what do you call it, cognizant about the functions you write, whether or not it's actually supported by that network, you kind of move further down.
04:10:37.592 - 04:11:03.120, Speaker B: So type two S essentially are fully EVM equivalent. So that's I can write in solidity, I can write in Viper. It's 100% bytecode equivalent. So the tools that understand the EVM don't need to change at all because there's no difference there. So that's our goal. That is also the goal of the other type two Zke EVMs. No one has currently reached that yet, but it's on the way people constantly doing research and we're fully competent.
04:11:03.120 - 04:11:42.024, Speaker B: And the last piece is fully Ethereum equivalent. Basically this means every part of the ethereum ecosystem, I guess, kind of structure is used for developers specifically. There's not a lot of difference in your developer experience. I can talk about this later if you guys have questions about why it would matter, but it's not super important for a hacker, for example. So last piece when we talk about the different types of Zkevms, the kind of idea is the performance and compatibility tradeoff. Is there like building a zkevm is very difficult. I think with StarkNet, for example, they started off with writing in Cairo, right? Because their assertion was basically EVM itself is very hard to prove.
04:11:42.024 - 04:12:27.004, Speaker B: So we're going to change parts of it to make it faster and more efficient and things like that. I think with the proliferation of type twos, basically that thesis has been proven incorrect and people are constantly iterating. So you can also see something like what StarkNet now has a new transpiler on top of it that is moving from solidity to Cairo VM to postback to ethereum. And I think that is just an indicator of why it is important to maintain that kind of network effect of keeping solidity devs in house. Like the ethereum ecosystem has already been growing and stuff like that. So anyways, kind of like how the prover works at a very high level. You can kind of think of it in linear terms in like three different stages or I guess how many stages are here? Four.
04:12:27.004 - 04:12:56.068, Speaker B: So the first part is Arithmetization. So Arithmetization is basically that part where we turn the computer program into math. So we call this traces. Linear is special because we are the only zke EVM to actually directly arithmetize the EVM. What does that mean? It means like there's actually slight differences where they have an intermediary EVM with the other L two S. But that's super cool tech. I don't want to explain other people's roll ups, obviously, because I don't work there.
04:12:56.068 - 04:13:34.816, Speaker B: But the next piece that we do, and this is really what set us apart is something called the inner proof system. So it's called vortex and arcane. So essentially here, I think diving back into why ZK roll ups are really cool, specifically mathematical proofs is you can apply mathematical proofs on top of mathematical proofs and do that recursively. So you have this kind of recursive infinite scale and that's kind of where vortex and arcane sits, right? We use something called lattice based hashing, which is a really interesting thing that is like Plausibly post quantum. What that means is quantum attacks don't exist. But if they were to, we could, I guess, set up our system such that it would be, I guess, resistant. But no one wants to hack a roll up.
04:13:34.816 - 04:13:35.948, Speaker B: They're going to hack the nuclear codes.
04:13:35.964 - 04:13:36.096, Speaker A: Right?
04:13:36.118 - 04:13:56.308, Speaker B: That's how it works. But anyways, it's optimized for recursion. And the last thing is it's really efficient for hardware acceleration, which is kind of something you think about when you think about performance improvements. The last piece is an outer proof. So that inner proof actually does not get it small enough to be posted back on ethereum. That last piece is what you might commonly hear as like Snarks. You might hear words like Plonk gross 16.
04:13:56.308 - 04:14:24.144, Speaker B: That's the last piece. It's really cool because you get to basically compress or verify one transaction and 1 billion transactions in the same amount of time for our ZK circuit libraries. I want to do call out we have an award winning Ganark circuit library. It's open source, it's actually used by different projects. It is the fastest Zke EDM on mobile phones. So when we start proving things on high schoolers phones, like, yeah, we're there. But anyway, so I guess now hopefully you understand this piece.
04:14:24.144 - 04:14:51.384, Speaker B: Let's talk about actually what I think. And I think Linear success so far is really proved by it's not the tech, it's the ecosystem. Right? So private testnet opened in January. I pulled these numbers, I think earlier this morning. 50 million transactions, like wallet addresses, deployed contracts, you can compare this against like Scroll I think was like 46 million polygon Zkvm was maybe like the two to three. I do admit there is an element of having a token versus not having a token. Definitely drives transactions.
04:14:51.384 - 04:16:03.520, Speaker B: But I think there's a lot more to this than just farmers, right? There's a belief in the ecosystem and I speak specifically, we opened three days ago, so we have 13.3 million TVL for that what that means, right? If you look in the order of, I guess you could say all the roll ups ordered by TVL, within three days we jumped from zero row 20 to I think now we are row 16 and we are 4 million away from row 15 and so there's a lot of growth, right? And why are people really interested in this? Right? So first thing finality again, that idea of just ZK versus optimistic, you have faster finality, you have a more secure trust assumption, et cetera. Something you might care about is TDL. So maybe if you're building, you'll start with Arbitrum just because there is much more liquidity to act with for your users. Right? The last piece I think that's really compelling as well as like roadmap when you think about what's next. We're not just what we are now, we are what we are in the future. But I'm going to talk specifically about what makes Linear really different and why we have onboarded so many partners thus far and maybe for developers here who want to actually take your apps past the hackathon, why this is important.
04:16:03.520 - 04:16:39.740, Speaker B: So specifically, it's like if you're building a DAP, you want to make money, right? And how do you make money? You have users. So we are at the same company as MetaMask. We are a default integration. So immediately with Linear you have discoverability, you have seamless UX. You can think of MetaMask features in the future being set in the home of Linear. Right, that's a really powerful value proposition when you dive into consensus is a little bit of a boat, right? So if you guys aren't familiar with Bezu, so Bayzoo is one of the largest open source Ethereum clients. So that means in house we have a very experienced team to do interesting things with those kind of performance operations on the client side for an L two.
04:16:39.740 - 04:17:28.524, Speaker B: So again, kind of building on that ecosystem. Again, if you guys are familiar with inferior, immediately we have that kind of scalability that comes with node providers. And I think the last piece maybe if you guys are familiar with consensus, MetaMask, et cetera, we do actually have a lot of presence in the web two space. So when you think about onboarding people outside of our little click of fanatics, who are people going to trust? JPMorgan is going to trust consensus, right? And I think that's become a very strong value prop that a lot of like I said, the first 140 applications have been really excited about and why I believe and also I guess why all those people are there. So the last piece I guess is not super important. How many of you guys have deployed a smart contract before? Okay, so I'm going to say like majority of the room. So I don't want to actually go through a full demo, but basically in order to deploy a smart contract you need a few things.
04:17:28.524 - 04:18:04.650, Speaker B: So you need ETH to make transactions for you hackers there who are choosing to deploy. You can get it through a faucet or you can bridge it. I'm a bit of a linear ETH whale, so also feel free to ask me. I can just send it to you, it's only for hackers. So anyone watching this, don't send me your wallet address over Twitter because I'm not going to send you any anyways, last piece, right? I think the important part is just, again, you can use whatever you want to use. I think if you're deploying here on polygon and scroll and whatever, please deploy to all of us because it's the same experience. You want to mask those bounties, right? So just kind of an example of what it looks like.
04:18:04.650 - 04:18:15.784, Speaker B: I can show you. Here's my config, basically there's girly, there's linear. Wow. Look, let me write this out live coding.
04:18:15.832 - 04:18:16.264, Speaker A: Woohoo.
04:18:16.312 - 04:18:48.070, Speaker B: Hopefully this works. I'm going to blame it on the internet if it doesn't. Anyways, linear. Do I need to run here? Oh, I have an extra s. Where deploys does that work? Nay. Wow, so easy. Okay, that's about all I have.
04:18:48.070 - 04:19:12.712, Speaker B: Yeah, this is how you can get in touch with me, linear build. This is kind of all of our information. This is a QR code to a website about myself that I haven't updated in quite a while. But yeah, if you have any other questions about linea and stuff like that, feel free to ask me now. I don't know how much time we have left, but am I over time? I talk pretty slowly. Okay, cool. Normally I'm like, Whoa.
04:19:12.712 - 04:19:24.800, Speaker B: But I'm tired. We're good, we're good on time. Okay. Yeah. So if anyone has any questions, please let me know. I can talk a little bit more about, I guess, linear right now. Another thing right.
04:19:24.800 - 04:20:01.160, Speaker B: When I think about L2 S in general, you might hear a lot of the narrative is like, oh, we're so easy for developers, right? But I think it's very much a chicken and egg situation. You want the users for those developers to attract, and so that developer friendly experience is just table stakes. I think that's what Linear understands. We want our tech to be there, we want the experience to be there. But what's most important is that when you deploy, people want to use you. Right? So we already have something called the Ecosystem Investment alliance. I hate the name, it feels like Avengers, but anyways but it's essentially a set of VCs dedicated to funding Linear projects.
04:20:01.160 - 04:20:28.280, Speaker B: I think separately, if you apply for our bounty, there is an opportunity to get filled into our accelerator program as well. So I think there's just a lot of interest basically, in supporting projects past the hackathon. I mean, I don't know how many of your students, but I don't promote quitting college to build in crypto because I like my degree. But everyone has their own journey, and if you want to build, the investment opportunity is there. Yes.
04:20:28.350 - 04:20:42.170, Speaker C: Hey, Midi, could you mention some key protocols that are available in Linear for hackers protocols like Oracles or any kind of protocol they can liberate for.
04:20:43.980 - 04:21:26.324, Speaker B: Really? So if you go to Docs linear build oh, I forgot to mention this, actually. If you use our deploying or what do you call it, infrastructure partners, we will award bonus points. I think our thesis is L two S are supposed to be boring in a world where, what do you call it there's mass adoption or whatever. No one knows what an L two is, right? What makes adapt robust and interesting is kind of the tooling that's built on top of it. So, for example, Biconomy is offering a bounty here. Biconomy launched on Mainet with us, day one. And gaslic transactions are something that's really interesting for user experience, gaming account abstraction, et cetera.
04:21:26.324 - 04:21:56.896, Speaker B: So if you want to do like a Linear plus Biconomy bounty, that is an opportunity for you to kind of see what you can build outside of just like Ha MPX hard hat, run scripts, deploy without the S JS network. Linear, no one cares about that. I mean, we care that it works, but you get what you guys are. Does everyone know what an Oracle is here? Yeah. Okay, cool. Yeah. So, Oracles, we have Pragma umbrella redstone if you're used to using chainlink.
04:21:56.896 - 04:22:12.548, Speaker B: Chainlink is not deployed on Linear. But there are other options as well. Gelato is really cool. It's another option for gaslist transactions. This is notifications. Do you have a question? Oh, sorry, yeah. So the native token is ether.
04:22:12.548 - 04:22:30.870, Speaker B: Yes, the native token is ether. So that is like the purpose of a roll up, right? Everything is like ethereum. Yeah. Oh, you have another question? Stop. I don't know if I can answer all of this.
04:22:30.940 - 04:22:33.510, Speaker C: You have lots of time. We have ten minutes.
04:22:33.580 - 04:22:35.130, Speaker D: I have ten minutes. Yeah.
04:22:35.200 - 04:22:45.562, Speaker C: So we ask until the end. Five sorry, what is the end game in term of decentralization for sequencers and so on?
04:22:45.616 - 04:22:49.254, Speaker B: Yeah, I had this in a different thing right here.
04:22:49.392 - 04:22:49.694, Speaker D: Okay.
04:22:49.732 - 04:23:15.870, Speaker B: So actually, this is something that's really interesting that I think most people don't know. How many of you guys know what multi prover is? Multi prover? Okay, cool. The only person who has a question. So anyways, that's fine. This is actually what I think. Again, I keep positioning linear as something really cool, but actually linear's true value prop, I think, is our commitment to collaboration. So starting off with what's important with an L two, right, is our roadmap.
04:23:15.870 - 04:23:51.940, Speaker B: So we're getting to that type two, like number one, if we want to say we're a type two and commit it and say it publicly, we have to be there so that's on their way. The next piece is like, how do you believe something is secure? So focusing on open sourcing our stacks right now, we want to kind of keep it in house, make sure everything's secure, do all the audits first before that code is publicly released. That's our next stage. And then, yes, a roll up will not exist without decentralization. Ultimately, the key of why roll ups won over side chains is security. And if you have a centralized sequencer and no, you can have bad actors. Not that I'm a bad actor, but you get what I mean.
04:23:51.940 - 04:24:38.318, Speaker B: Maybe I'll leave and then all the bad actors will appear. But the last piece actually is multiproover. So when we talk about just one proving system, what happens? Right? If there's a bug in the prover, everyone's like, I don't want to say fucked. Right? So the multi prover theory is actually saying, hey, we have so many diverse implementations of the Zkevm. And that's kind of also where optimistic rollups have a completely different implementation structure, right? So if I'm passing those transactions through multiple provers to reach a consensus of truthfulness, that is a much more secure model than something like just a single prover. Right. I think it feeds into why you have multi clients on ethereum with Bezu and geth and all these different things, is that diversity is what promotes security.
04:24:38.318 - 04:24:56.838, Speaker B: So we are very committed to every I don't want to throw shade, so I'm just going to say we are very committed to this. So other roll ups, if you want to do this with us, feel free. There are it's in the works. Yes. You have a question?
04:24:56.924 - 04:25:03.254, Speaker C: Isn't multi proving just exacerbating the entire pain point with DK robots in the first place?
04:25:03.372 - 04:25:04.022, Speaker B: What do you mean?
04:25:04.076 - 04:25:07.930, Speaker C: Like, it's just making it slower. If you prove it multiple times or.
04:25:08.000 - 04:25:14.058, Speaker B: Using multiple different implementations, I mean, I guess it could be slower, but ultimately okay. Yes.
04:25:14.144 - 04:25:14.538, Speaker D: Okay.
04:25:14.624 - 04:25:31.070, Speaker B: I think it would be slower, but just like looking at the roll up space, right. Things are getting faster and faster and faster and it becomes a trade off of yeah. Do you care about that versus do you care about security? Yes.
04:25:31.140 - 04:25:41.330, Speaker C: So on that point, would this be like a protocol level change or would it be modular? Like a user could choose? I want multiple provers or I want a single prover.
04:25:42.150 - 04:26:25.620, Speaker B: Honestly, this is phase four, so the actual implementation details haven't been decided. It is a very difficult problem to solve and it requires a lot of coordination. Unfortunately, everybody in the space right now is racing to decentralize. Well, I guess the first part is actually like, racing to mainnet and then racing to type two and then racing to decentralization. And once all that is figured out, then that kind of conversation about, is it fast enough? Is it feasible even? It is a very difficult problem to solve. And those conversations are happening in the sense of we want this to happen together, but not necessarily like we've already committed engineering. Time to figuring it out.
04:26:25.620 - 04:26:27.874, Speaker B: Yes. Last question.
04:26:27.992 - 04:26:31.650, Speaker C: By Security Council, do you mean who's running the nodes?
04:26:31.990 - 04:26:34.918, Speaker B: No, it's stuff like upgrades and things like that.
04:26:35.004 - 04:26:37.190, Speaker C: That's to do with governance as well?
04:26:37.260 - 04:26:37.638, Speaker D: Yeah.
04:26:37.724 - 04:26:41.766, Speaker C: Okay. What does that look like right now? And where is that going?
04:26:41.868 - 04:27:08.400, Speaker B: Right, so right now everything is under consensus. Right. Decisions are made by our engineering team, but again, that information is public and like, what do you call it? I don't think any other protocol is at that level yet where governance actually maybe arbitram's token is what's doing that? I don't know. I can't speak for others, but that's where we are right now.
04:27:08.870 - 04:27:14.850, Speaker C: Is it just a linear fee or security Council?
04:27:15.590 - 04:27:33.634, Speaker B: So we are in phase zero. I don't know if the Security Council has been established yet. I think it's happening. I imagine it will be Bezu MetaMask. Everyone in consensus, like stakeholders, external stakeholders as well. Let me rephrase this. The decisions being made right now are internal consensus.
04:27:33.634 - 04:27:47.840, Speaker B: The Security Council must include outside actors in order to actually be an effective Security Council. Right. So that's where we're at. Cool. Don't ask me any more questions because now I'm sweating a lot.
04:27:49.730 - 04:27:50.430, Speaker C: Thank you.
04:27:50.500 - 04:27:51.680, Speaker B: Yeah, thank you.
04:30:18.470 - 04:30:22.230, Speaker C: Let me know. So good to start. Yep. Awesome.
04:30:22.300 - 04:30:22.920, Speaker E: Thanks.
04:30:23.370 - 04:30:37.526, Speaker C: Hi, everyone. My name is Teddy, and today I'm going to tell you a bit about conduits. I'll do a brief overview and then I'll have Lucas protocol engineering in the team go over more like the details. Any questions that you have, please just raise your hands anytime.
04:30:37.718 - 04:30:38.460, Speaker A: Great.
04:30:39.470 - 04:32:00.462, Speaker C: So from Maker, we've always had predictable rates, something I don't think we've really pushed as narrative that much. So instead of having variable rates that change on a block by block basis or fixed term rates that we're seeing now coming from other companies like Element and Sense Makers, always had governance defined rates that change not that often but they do actually change. The nice thing is when they do change it's through a governance process that's fully open and transparent, you get to see that process and also once that is voted on there's also time delay so you always know exactly when they'll change and actually what will the new value would be. So before you could only access those rates through Maker vaults or what we call then CDPs nowadays we've kind of evolved to be able to offer those rates for various different users. So if you're a borrower nowadays you can go to Sparklend, our new lending market where you're able to deposit your crypto collateral and actually get that predictable rate. You can also be a depositor and that case you'll be depositing your Dai in the Dai savings rate where you'll be actually earning that yield. And we also have an ERC 26 26 representation of the DSR called SDI.
04:32:00.462 - 04:32:45.726, Speaker C: And then finally the one I really do want to talk to you guys today about is the conduits. So conduits are like an adapter between Maker and the rest of the ecosystem. A way for builders to actually deploy Maker capital directly into your protocols whether they're fully on chain or a mixture of off chain with real asset protocols for example. So just a little overview the change of Maker rather than just being a single entity or single protocol. Now we kind of have like two levels. We have Makercro on the top and then we have subdoubs. The subdaos are the entities, the on chain entities that will essentially be providing this liquidity to your underlying protocol.
04:32:45.726 - 04:33:39.694, Speaker C: As you can see here on the middle layer we have spark lent, we have Univ three LP token positions as well as any other protocol that you may want. So how do subdoubs actually push this liquidity into the market? This you can see in green we have on the left hand side the VAT which is the core accounting model from Maker. This is the old school system that is still pretty much still there. And then we have all this new infrastructure created to be able to support this delegated capital allocation. What we really want to talk about though is on the right, the actual conduits. These are contracts that are actually fairly simple that will be able to standardize the way that Maker provides liquidity to any broker on chain. So you can think of them as adapters.
04:33:39.694 - 04:34:20.290, Speaker C: I quite like to think it's very similar to how Unisoft is developing hooks makers, developing conduits. So let me show you. This is the main interface. As you can see, it's extremely simple and really the most important thing that you need to really take care about is inheriting this. And as you can see it's just a deposit and withdrawal function specifically for the hackathon. There's other stuff that we're not really needing to demonstrate effectiveness of your projects, including the different permissions that we have. Let me show you all the different permissions that we have coming from the Roles singleton and also from the Buffer contract.
04:34:20.290 - 04:35:18.834, Speaker C: Now you can have any variety, you can plug it into anything. Pretty much one of the most complex things you can apply to is webull assets because you have that off chain component. In that case, here's an example interface that basically inherits from the previous one where you can see that I want to show you really the request funds function. Essentially a way of asking the external entity, basically saying, hey, can I please have my money back? And then because they'll do their own off chain stuff and then actually basically pay back the money they own. I just want to finish before Lucas gets on top and saying conduit builders are part of this ecosystem. It's not just sub, DAOs and external protocols. This middle layer in the middle is a group of builders that we actually care about a lot and we want to incentivize future building.
04:35:18.834 - 04:35:37.066, Speaker C: So now I'm just going to bring Lucas up and he's going to walk you through a couple of examples. And if you have any questions, please raise your hands. Actually, before you do that, any questions on the overview? All good. Awesome. Stay away. All right. Hi everybody.
04:35:37.066 - 04:36:18.594, Speaker C: My name is Lucas. I work as a smart contracts engineer at Phoenix Labs. I'm currently working on one of the conduits. So just before I go into that, I'm actually just going to bring this up again really quickly. So one of the really exciting things about MakerDAO where we're headed is this introduction of subdos and the ability for them to allocate Dai into DeFi into real world assets and to expand the supply of Dai and earn a yield on it in a really conservative and scalable way. And what I find really exciting about this is the introduction of conduits. So there's many different ways to deploy Dai into the DeFi ecosystem.
04:36:18.594 - 04:37:05.670, Speaker C: You can market, make the peg, you can add liquidity to a lending market such as Spark. You can deploy into real world assets. There's many different ways to earn yield. And what's really cool about this architecture is that individual developers can develop these conduits themselves and propose them to Maker governance. And if they are deemed to be scalable, safe, and reliable, they can be integrated into the core Maker system. So what I'm going to do now is I'm going to bring up some code that I'm currently working on. So you can see this is my arranger Conduit, which I'll turn off my coverage monitoring for and also bring up the interface.
04:37:05.670 - 04:37:49.970, Speaker C: Yeah, I'll probably do one more actually. Yeah, there you go. Okay, so what todayo brought up was the allocator conduit base interface. And so this is what matters for any new developer working on a conduit. So essentially you have just a deposit and withdraw function in terms of adding funds and removing funds from the conduit. And then you have two view functions the maximum amount that you can deposit and the maximum amount that you can withdraw at any given time. So within that, the bounds are pretty open.
04:37:49.970 - 04:38:38.734, Speaker C: Anyone who's working on a conduit can develop any kind of strategy that they want as long as it adheres to this interface. And it's important to note that it can deal in any asset that you like. So a common use case like for example, what I'm currently working on is USDC is typically what's deployed into real world assets because it's easily convertible to fiat. So you can deal with multiple assets within a single conduit, which is important to note. So for my example, I'll just open the interface, keep it simple. So my conduit that I'm currently working on is dealing with real world assets. So the key difference, there's two sort of approaches that you can take to a conduit.
04:38:38.734 - 04:39:53.830, Speaker C: You can either take the deposit in and then move it straight into a protocol or strategy or whatever it is. A good example of that is a spark conduit. So if we want to mint dai, move it through a conduit, deposit it, the deposit function will actually atomically perform the deposit into the Sparklend protocol. And so the Dai will just move through the conduit into that external protocol and live there and the positions will be tracked within the conduit. However, for real world assets, it makes more sense to actually temporarily hold the custody of the funds within the conduit and allow for the arrangers, the real world asset entities that are deploying the capital into treasuries or whatever it is, to be able to come in and have a common place where they can just draw funds and allocate them. And what's interesting about the Arranger conduit is that it tracks positions for multiple entities using the same contract. So what this means is that for multiple allocated Dows, they can all use the same conduit.
04:39:53.830 - 04:40:51.448, Speaker C: And the real world asset arranger that's dealing with this conduit just sees the aggregated available cash to be deployed, they can withdraw that, deploy it into Treasuries, and then add the funds back as they're requested by each of the individual allocators and they can just come in and take their funds. So all of the position tracking, all of the current outstanding positions, all of the relevant information to easily parse out all these transactions into dashboards or whatever it might be, is all going to be available on chain through these conduits, which is a huge improvement over the existing real world asset system where a lot of this stuff is done off chain. So that's one of the big benefits of using conduits. I'll stop there before I go into my testing suite to see if anyone has any questions. Any questions about related to the hackathon building a conduit?
04:40:51.544 - 04:40:51.756, Speaker A: How.
04:40:51.778 - 04:41:00.190, Speaker C: To get started. Sorry, can you speak? Oh, there we go.
04:41:01.140 - 04:41:07.392, Speaker A: Just around like some practical stuff. Where can we find your repo and those type of things?
04:41:07.446 - 04:42:12.064, Speaker C: Yeah. So today you have some links that will be provided? Yeah, no, don't worry. Everything's in the Ethlo dashboard there you should see a link to basically hackathon bounties. You have like an in depth description of all the different assets that you might need for conduits as well as the example that actually that Lucas is showing now on screen. So you can come on in. So I want to stress from a hacker's perspective, this is genuinely one of the most exciting opportunities to write code that could potentially manage very large sums of funds very quickly. The maker system won't discriminate between any sort of developers as long as there's good code that is well tested and has gone through the proper due diligence process, has been proven out, has been audited.
04:42:12.064 - 04:43:26.024, Speaker C: Whatever it is, it will be considered to be integrated into the core maker system and it's a pretty rare opportunity to come in as an external developer and contribute to such a substantial system which will be allocating massive amounts of capital. So if I was a hacker in this hackathon, I would most definitely be working on conduits because I think they're extremely exciting. So regarding the testing, I am working on production level integration testing currently. So I've done more than what's necessary for the hackathon. The scope of what we're defining in the hackathon is going to be to deploy a conduit and then create you can just deploy your own ERC 20 asset. In fact, that's what we actually recommend doing in place of Dai or USDC or whatever and regard like permissioning. We want to, for the scope of the hackathon, eliminate all of that dependency just so that we can focus on the core logic of what is actually happening within the conduit.
04:43:26.024 - 04:44:38.832, Speaker C: Realistically, all of that access control logic is going to be relatively similar across all the different conduits. So it's not necessarily innovative to be implementing that during the hackathon. So we want to remove that from the scope and just make sure that what you guys are working on is what's important, which is the novel deployments of funds. So just a really quick example of a test here is coming in, minting some funds pranking as the operator. This is Foundry, if you guys are familiar, approving, asserting some balances, asserting some state, performing a deposit and then making sure that everything is being updated both within the asset and the conduit contract state. And what I would recommend if you're doing any sort of protocol like an example is deploying into Spark, I would recommend warping through time to demonstrate the accrual of yields through the protocol protocols that have time based yield components. Any demonstration that you can prove out that yield is indeed being generated.
04:44:38.832 - 04:45:10.538, Speaker C: If you're using DeFi protocols, I think is something that I'd recommend. But real world assets are definitely also on the table, so it's really open ended to whatever you guys want to work on. Any other questions? We can deploy on each network. Yes. So I think part of the requirement of the hackathon is to deploy to Gorely. Is that true? Oh, no, it's not. Okay.
04:45:10.538 - 04:45:37.230, Speaker C: Any network you want because yeah, I'm working off of a local fork of Mainnet that's totally viable if you want to do that. In fact, we recommend it if you want to be testing against Production deployed Contracts I think it's a good idea to fork mainnet. It's a good idea to get into Foundry if you guys haven't gotten into that yet for testing as well. It's really easy to fork networks.
04:45:47.800 - 04:45:48.188, Speaker E: Okay.
04:45:48.234 - 04:45:56.410, Speaker C: Okay. I think we're all set. Unless there's anything else no? All Right. Thank You.

00:05:03.540 - 00:05:04.090, Speaker A: You.
00:05:06.780 - 00:05:39.010, Speaker B: Intro about what lifepeer is. Life Peer is building the video streaming layer of Web Three. We've been building this project for the past five years. We've gone through many iterations. Currently the network processes about two and a half to 3 million minutes of video per week. Um, and we you know, those videos are viewed by many million number of users. Just a quick overview about video technology.
00:05:39.010 - 00:06:37.270, Speaker B: Video is about 82% of all the data in the world today. 82% of all the data on the internet. Needless to say, that's the majority of the content that we consume on a daily basis and that's why Life here is excited to be working on this technology and to decentralize the infrastructure. So when we talk about video infrastructure and video streaming technology, how is it done? There's really three steps. There is kind of the ingest and upload step, there is the video playback step and then there's the video processing step. We're going to go into each of those steps just quickly so that we can set the right context. So here it's kind of a typical architecture of a video application of today.
00:06:37.270 - 00:07:27.012, Speaker B: It looks a little complex. I'll go through each of the steps so it doesn't look so complex anymore. The first step we talk about video ingest and upload, right? So this is really dependent on if you're building a video on demand application. So something like a YouTube where you upload a file and have it streamable by anyone on the web. Or if you're building a live streaming application which is something more like a Twitch or Facebook Live, right, where people are watching you in the moment as things are happening. So for live streaming it's about ingesting a live stream, broadcasting it, and for video on demand, it's about uploading a file into a backend on the receiving end. Usually there is a media server that's receiving the content.
00:07:27.012 - 00:08:13.956, Speaker B: It speaks the language of the video protocol, speak the language for also HTP if you want to upload it. And there's many different types of ingest tools that you can use, right? So oftentimes we think of, especially for live streams we think about you can either have a desktop based broadcasting software, something like an OBS studio which is really popular amongst twitch streamers. You can have a mobile app that's broadcasting the video, broadcasting the live stream using the camera on the mobile phone or you can have an in browser broadcasting studio that's only recently starting to get popular and you might have heard of like a Restream or things like.
00:08:13.978 - 00:08:14.550, Speaker A: That.
00:08:17.000 - 00:09:04.448, Speaker B: But those are just end user tools. If you're a developer and you're building an application, there are a few SDKs that can help you to build those types of experiences. So for example, there's a react native component called Node Media Client that allows you to build a mobile broadcasting experience. And then we've actually built a tool called Webrtmp that allows you to build an in browser broadcasting experience that can capture the webcam on the laptop. So that's a little bit about interest. The interest is all about putting the video into the backhand. And now the video is in the backhand.
00:09:04.448 - 00:09:50.320, Speaker B: How do you play that? So here is delivery and playback. Video delivery is oftentimes delivered through a content delivery network or shorthand CDN. And this is because oftentimes there's tens of thousands or hundreds of thousands of people watching the same content. In the case of a live stream, if you're watching the World Cup or something, there's millions of people around the world watching the same stream, right? So in that case, you really need a really scalable infrastructure to be able to deliver that kind of content. And a content delivery network helps you do that. Or if you don't have that many viewers, sometimes you can deliver directly from a media server. And that's also possible.
00:09:50.320 - 00:11:10.780, Speaker B: But when you're delivering it, you're delivering it to a video player on the client, right? So the video player can be either on the mobile phone or it could be in a and in terms of delivery and playback, we think of HLS, which is the video streaming standard defined by Apple. There is adaptive bitrate streaming, which we'll go into later, and then there's the video player. So let's first take a look at like what is why? Why is this thing interesting? Well, HLS is the file that you give to the video player in order for it to play, right? So HLS represents the video itself and the format of HLS is there's a playlist that describes kind of all the different small media segments, and then there's the media segments themselves, which is the video cut up into small chunks. And then the video player simply loads each of those chunks in a sequenced way and then they're able to play it back in real time. Or sometimes if you have two exit, it'll play it faster than real time. So that's really HLS. When you're thinking about a video stream, it's actually tiny little files that are making up this big stream.
00:11:10.780 - 00:12:54.060, Speaker B: So that leads us to the second topic, which is adaptive bitrate streaming. And this is the secret sauce for how video is able to play on the Internet in the first place. Because if you think about this problem, we're streaming video under all kinds of different networking connections from around the world on different types of devices, different sizes of screens, right? There's so many different varieties, but yet everybody expects to be able to watch the video just the same. So in order to do that, what we do is we transcode the video into many different versions of many different bitrates, so that if I'm sitting at home watching a video on my smart TV, I can watch like a really high resolution version of the video. Or if I take out my smartphone and start watching the same video, it's going to be like a shrunken down and lower resolution video, right? And when I'm loading that smaller video, I can load the smaller bitrate video. And adaptive bitrate streaming is saying that as you're streaming the video, you can actually change the version and the resolution of the video that you're watching without a broken experience. So for example, if you're ever sitting at home and you watch Netflix and it starts out really grainy and then it gets crisper over time, that is adaptive bitrate streaming at play, right? So the smaller version comes on at first because your networking is just kicking in and then as the video plays, the player realizes, oh, you actually have a much higher network throughput and it starts loading the higher resolution version.
00:12:54.060 - 00:13:42.264, Speaker B: And this is very crucial for video streaming to work correctly online. And when we talk about video players, it's really a piece of software that you can put in your web application or you can put in your mobile app in order to play that HLS video that I just talked about. Now there are many different SDKs or products that you can use. There's open source video players or proprietary video players here, I'm just kind of sharing a few of them. The most popular open source one is probably Video JS. Okay? So that is kind of an overview of playback. Now let's talk about video processing.
00:13:42.264 - 00:15:21.564, Speaker B: Video processing is something that happens behind in the background that most people don't know but is actually a super important step, right? We talk about that transcoding step and that's how we're able to enable that adaptive bitrate streaming way of streaming video. So usually when the video gets uploaded or ingested into the media server, it gets sent to a transcoding engine that then transcodes the video and then puts it into a CDN or stores it into an object storage. The thing about transcoding is that it is super computationally intense because you can imagine videos are very complex data structures and you have to kind of decode the video, understand what it is, re encode the video into different versions, store them somewhere, and that's really expensive process. So transcoding the workflow looks something like this, right? Where you have that transcoding engine you can for example, ingest like a 1080p version of video and you can transcode it down into a they're all appropriate for different devices and different networking conditions. So that's a little bit overview of video streaming, right? So all of those pieces together makes video streaming work on the internet. So now that's pretty complex for anybody here this weekend trying to build a hack. You probably don't want to think about all those things and put all those things together.
00:15:21.564 - 00:16:00.260, Speaker B: That's way too much work. So at Livepeer we built a decentralized solution to make all of those complexities go away and to make it really affordable. So how do we do that lifepeer. At the core is a set of protocols. It's a protocol that allows people to contribute resources onto a network that then they can also get paid for contributing that resources. And it's encoded as a set of smart contracts in solidity. It's deployed on Arbitrum.
00:16:00.260 - 00:16:49.176, Speaker B: It was first on ethereum. Recently. We migrated to Arbitrum. And it acts in a few ways. One of the most important things that it does is that it acts as a global registry of these orchestrators that represent kind of transcoding capacity around the world. So if I am a broadcaster or if I have a video that I need to transcode, I can talk to this global registry and say, hey, tell me a list of people who have capacity that can do this work for me. And through this discovery protocol, I can not only get a list, I can also kind of start testing, oh, who's closer to me, who has a good latency with me, has good connection with me, and I can start sending my video to them and they can start transcoding that for me.
00:16:49.176 - 00:17:43.450, Speaker B: And of course, the protocol also handles micro payment and all these things. So the value transfer also happens and the orchestrators are incentivized to do that transcoding work. And the other thing that the network does is that it's highly redundant. And what that means is there's lots of orchestrators around the world and there's always an overabundant amount of transcoding capacity on the network. So that if one orchestrator all of a sudden goes offline so, for example, I'm running an orchestrator in the data center, and a data center loses power and everything goes offline. And that's totally fine because the software is resilient enough that it'll just immediately fail over to another orchestrator and it'll continue to work, right? So even for a video live stream, it won't disrupt the experience. And the other thing that you can do is you can double up.
00:17:43.450 - 00:18:39.688, Speaker B: You can use multiple orchestrators at the same time so that if one goes away, it doesn't even matter. In fact, you can just have the two race and whoever gets back to you first, you use that one under the hood. If you look at the live here protocol, I'm not going to go into this whole complex graph. I just want to show this graph in that there's a smart contract. We have the broadcasters and the orchestrators, and there's a verification process here to make sure when the broadcasters are working with the orchestrators, they don't need to inherently trust each other. You can just say, I'm sending my video into the network and I can trust that the network will verify the work for me and I will always get the right results back. And if I don't get the right results back, there is heavy economical penalty so that it's highly disincentivized for someone to cheat.
00:18:39.688 - 00:19:26.680, Speaker B: Very similar to kind of the blockchain design concept. Proof of stake concept, right? If a validator cheats, then they get heavily slashed. Therefore you don't want to cheat. Another important concept here is that there's an on chain portion and an off chain portion. Of course, when we talk about video streaming, there's going to be millions of video streams that are happening on the network, right? We can't be writing transactions for every single one of those streams. So all of the video streaming steps within the lifeure networks happen in an off chain way. And the only thing that happen on the blockchain are the registrations of the nodes which happens only once in the node's whole lifetime, and the payments which can be batched together and happen asynchronously.
00:19:26.680 - 00:20:32.828, Speaker B: Okay, so here I'm just going to go into a little bit of the token economics. The way it works is that people stake their lifeyear tokens to the orchestrators and as the lifeyer tokens get stick to the orchestrators, the orchestrators can earn lifeyear rewards. At the same time, the people who want to transcode their video with the network also paying in ether to transcode the video. So as more demand goes on the network, the more valuable the network becomes because essentially the Live Fear token represents the amount of revenue that you can capture for all the revenue that's going through the network. And then it kicks off this flywheel where the more demand on the network there is, the more valuable it becomes. Then it attracts more supply and then that kind of wheel starts going. So that's it.
00:20:32.828 - 00:20:50.004, Speaker B: That's a little bit about the intro of live here a little intro about video streaming. Now Victor is going to show you some exciting demos around video on demand streaming and also around live streaming. Hello.
00:20:50.202 - 00:21:34.132, Speaker C: Let me set this up. Hello. Right, so I want to show you the capabilities that we have in our service in our API and we're going to start with the live streams. So we have this dashboard page here with the streams you have in your account. I have already registered, I'm logged in here and you can create a stream from here. But you would normally be doing this from your application. So we have an API that you can use and you got an API key.
00:21:34.132 - 00:22:17.040, Speaker C: And then you can create all the objects on demand as your application logic requires. And we can start here. Let me increase this so we can start here by creating a new stream and you give it a name. I'm setting it to record as well. And here we have the fully created object and it has the configured renditions that you want for your playback. So it controls how the stream is going to be transcoded. And then here are the important bits right now, which is the stream key and the playback ID.
00:22:17.040 - 00:23:23.850, Speaker C: The stream key is the secret that you give to the user that is doing the streaming and it's going to give them right, access to this stream, to this channel. And you also have the playback ID, which is the one you use for playback in the stream. And it's a little more public in that sense that many people will be watching, but only one will be writing. And here is the stream that we've just created and say this is an example application that can do video the live streaming from the browser using the SDK that we showed. And all you need to do is to copy that stream key here. So if you say your application creates the stream and then it's going to send this key to your application somehow and it can start streaming to that channel. And then if we see here in the dashboard, the stream should now become active or maybe not.
00:23:23.850 - 00:24:12.052, Speaker C: Yeah, it did. So it's still loading, starting the transcoding and everything. And while it does that, I can also show the playback application. So this is just another example that has video JS player. And all we need to do here is create this URL, which is the playback URL. You can also copy it from the dashboard. So here is the playback URL and in the same way in a real application, you would actually get this specific playback ID from your server, from your back end and then you inject in the front end and you can see the stream as it is happening.
00:24:12.052 - 00:25:00.852, Speaker C: And there's just a little delay of the actual transcoding of the stream. But it's live coming from this web page here. Let me close this. And this was using this webrtmp SDK that we showed which is made for you to stream directly from the browser. And it's good to do quick demonstrations or start getting started with the live peer platform, right? So the other thing I can show you is the API. And so we have here this other tab in the dashboard. It's not the streams, it's actually assets.
00:25:00.852 - 00:25:40.720, Speaker C: And it's where you can see all the files that you have uploaded to the API. And the same way you can create an asset here by giving a URL to import, et cetera. But I can also show that via the API here as well. So the process there is actually done in two requests instead of one. And first you request for an upload URL that you're then going to use to actually upload the file. And this URL here can be called from anywhere. So the idea is that you create this presigned URL on the back end, give it to the front end application, and the user can do the upload directly.
00:25:40.720 - 00:26:43.460, Speaker C: So you don't need to do any kind of proxying of the actual file then to use that URL, you just do a put with the file as the body and here it's already going. And when you import an asset, you get a task that processes the asset until it has all the metadata and the duration of the video bitrate, all this kind of stuff. And you can also call this other API here to list all the assets in the account. You can also read individually, but this is easier for now. And here is the asset we just uploaded and all the specs that we parsed and it also has a playback ID. But let me show you in the dashboard. So here it just showed up, the one we just uploaded and it has download URL here, which is actually how you can play back the file.
00:26:43.460 - 00:27:53.224, Speaker C: So this is just playing an MP4 right now and we are working on adding HLS support for assets as well. But as soon as you upload the file to Live Beer, you can already use it from this download URL. And here you can see that this one also showed up. It actually came from the recording of that stream, the first part of the demo and the recording also becomes an asset later and you can use it the same way and play back the recorded stream as a video file or export it or even create an NFT out of. So let's go into that NFT part exactly. We have this SDK, the video NFT SDK that builds on top of this VOD API and you can use to easily create video NFTs. So it handles both the uploading of the file, the processing in the live peer network in case it's necessary, and the exporting to APFS.
00:27:53.224 - 00:28:23.320, Speaker C: And then the actual minting of the NFT from the exported file. It can be used to build any kind of application. You can use it from the front end, from the back end, from a CLI. And we actually have a couple examples using that. And I'm going to show this one, which is just an application on the front end. And if you are logged in the dashboard, you can go to just mint NFT and you're going to see this UI here. And let's use the same video file.
00:28:23.320 - 00:29:45.638, Speaker C: And this is just the smart contract that we have deployed by default, but you can also use a custom ERC 721 that you have and first step so it's doing the same process that I just showed on postman. It requested the uploaderial, then actually sent the file, then it did some processing and I'm going to explain soon. And then already exported to APFS and it has this hash here, this CID and it's already injected here and now we can actually mint with that CID and this exporting here, currently if you're using Openc, there is a file limit of 100 megabytes. So if the file is higher than that, it's not going to show anything. It's not going to show the preview of the file. But when you do it through the SDK, it's going to check that and it can transcode the file to a lower quality, just so it shows on OpenSea. And it's not just a blank NFT over there.
00:29:45.638 - 00:30:50.646, Speaker C: And here we can see that it finished. Yeah, so it's already available here on OpenSea and I did it on testnet, but it works on Mainet just fine. And yeah, back to the processing. We also intend to add support to other kinds of things, like if you upload a video that has a codec not supported on the Internet, on the web, on most browsers, we can also offer to change that. So that's exactly where we plan on adding more and more functionality with the power of the live peer network. And we can also go through the smart contract if there's time. So just to go through quickly here, I mentioned that you would be using just the default contract here, but you can actually create your own and just change the address here so the SDK calls that separate contract.
00:30:50.646 - 00:31:52.618, Speaker C: And you can do so following this guide here. That is also in the documentation of the SDK. And we have the base code here for the contract. And it's really simple. Just inheriting from an Open Zeppelin contract and then adding a simple logic on the Mint that I can show here is better. We just import the contracts from Open Zappelin, then have our custom one inheriting from it, one that has the storage for the NFTs and then discounters just keeps track of the IDs of the minted NFTs to always create a new one with a different ID. And then we have this event here which is sent after the mint is done and is what the SDK relies on to show what was the minted NFT, the Minted ID of the NFT.
00:31:52.618 - 00:32:39.454, Speaker C: And then this is the main mint function. The SDK also relies on a signature like this, and then it basically creates the new token ID, mints it for the respective owner and sets the Uri to what is sent on the request here. And that comes from that thing we saw here. This is the token Uri that went on that argument. And then that's it. It emits an event which we can use in the front end to show any information about the newly minted NFT. Finally, all the other methods from ERC 721 are already present in this contract just because it inherited from this.
00:32:39.454 - 00:32:52.100, Speaker C: So it supports any tool that relies on these interfaces, like Openc itself. So that's how it just shows up there as we mint it. And I think that's it for the demo.
00:32:54.390 - 00:33:32.462, Speaker B: All right. Thank you, Victor. I want to spend just a few more minutes talking about prices and ideas that you can think about building for the hackathons. Today, Live here is offering up $16,000 of total prizes. I'm really excited to be here and working with the hackers here. The first prize is for $6,000 and we're looking for developers to build the killer video centric social media creator or gaming Web Three application. This is an area that I think is ripe for disruption for Web Three.
00:33:32.462 - 00:34:36.926, Speaker B: All of the components from an infrastructure perspectives are here for us to create a Web Three centric social media platform that can be very competitive to today's platforms like a YouTube or a TikTok. So we're really looking forward to seeing the creativity of hackers here, building platforms like this. The second price is for $4,000. That's for the best use of the Life Peer Video NFT Minting SDK that we just showed. We look forward to seeing how people can creatively use this asset of video NFTs to do all kinds of interesting things and think about kind of thinking beyond the speculative use cases. I think there's a lot of really interesting areas that this can go to. The third prize is for the best video on demand application using Live Peer.
00:34:36.926 - 00:35:31.622, Speaker B: So simple. Think about this as the web3 YouTube. How would a YouTube look different if it's built in a Web Three native way? What kind of features would it have? What kind of value proposition would it have for creators to be able to connect directly with their fans, to be able to directly monetize the work that they do? I think there's a lot of really interesting ideas in here. And finally, fourth place, fourth price for $2,000, we have the best applications of Live Peer in the metaverse. The metaverse can be interpreted in different ways. I kind of think about the metaverse as this just already deployed and already running decentralized infrastructure in general, instead of I think the more narrow definition would be kind of like a rendered 3D world. Right.
00:35:31.622 - 00:35:58.320, Speaker B: So thinking about using video, streaming both video on demand and live streaming into the metaverse or from the metaverse to show kind of people not participating what's going on in there. I think there's a lot of interesting use cases there as well. So that's it. We, I think, have a couple of minutes left. If we have any questions from the audience, we're happy to hear that. Right now.
00:36:02.930 - 00:36:04.062, Speaker D: I have a quick question.
00:36:04.116 - 00:36:08.094, Speaker B: On the so when you showed the live video, so the stream that you.
00:36:08.132 - 00:36:09.666, Speaker D: Just created during the demo, so it.
00:36:09.688 - 00:36:11.650, Speaker B: Was also uploaded as an asset.
00:36:12.790 - 00:36:14.946, Speaker D: The asset that is displayed there, is.
00:36:14.968 - 00:36:17.026, Speaker B: It only one of the encodings that.
00:36:17.048 - 00:36:18.526, Speaker D: Is there, or is that also like.
00:36:18.568 - 00:36:21.046, Speaker B: In the different formats, like the different.
00:36:21.148 - 00:36:23.110, Speaker E: Kilobit streams and so forth?
00:36:26.570 - 00:36:48.910, Speaker C: So the asset that is created automatically is from the source video. So it's just the highest quality version. But when we also do have a recording that is the same HLS that was made during the live stream, so it has all the transcoded renditions, and you can actually download those as MP4 s as well. But by default, we create only the source.
00:36:53.330 - 00:37:01.380, Speaker B: Any other questions from the audience? All right.
00:37:03.990 - 00:37:05.106, Speaker C: Thank you both for the.
00:37:05.128 - 00:37:25.370, Speaker D: Overview and the demo. Given that you're thinking about video all the time, but building it from an infrastructure perspective. If you had the time to work on a hack, what are some ideas that you would love? Just a spare extra 20 hours to work on using my peer.
00:37:29.150 - 00:37:32.940, Speaker B: Do you want to answer that? Maybe we can search over.
00:37:35.570 - 00:38:29.040, Speaker C: Yeah, so something that would be really cool would be a mobile app using the NFT SDK and then you could just make a video and immediately make it into an really really easily. Could be just like a camera phone that creates NFTs out of every video that you create or something like that. And I don't know, could be also more different video NFT so that you can create different interactions with video NFTs. Like you can maybe split your NFT into each one is one part of the video, then you gift it to someone else and then you can merge them together if you have the continuous parts or I don't know, some crazy stuff like that that would be really cool to see.
00:38:32.770 - 00:39:17.520, Speaker B: Yeah, there's so many interesting things that people can work on. I have a couple of ideas. There's been over 100 applications built just in Q, one alone in Live Peer. Some of the things that are really interesting for example, the video streaming application for DevConnect is actually built using Livepeer and is streamed with Livepeer. It's called, I think, streameth TV. One of the interesting things, it was a collaboration between Livepeer and Ethereum, the Ethereum Foundation. One of the interesting things that we did is not only is it now completely open source, anyone can take that website and just change make improvements on top of it.
00:39:17.520 - 00:40:03.578, Speaker B: For example, adding like a chat function or adding the login function. Logging with Ethereum so people can see your ENS, things like that. But it's also modularized. So that for example, the video player that's being used is actually a module. And this video player has some interesting functionalities. One is that you're able to automatically have a primary and a backup stream so that when you're streaming an event you can have two streams going on. In case the primary stream fails, it automatically switched to the second stream and your user doesn't see any breakage in the experience.
00:40:03.578 - 00:40:57.680, Speaker B: But there's so much more that you can add in this video player, right? Just think about what a web3 native video player can look like and what kind of functionality that it can have. Right? You can start allowing the viewers to log in with their MetaMask and show the NFTs that they have in their wallet and the NFTs can then that information can be sent to the broadcaster, the streamer themselves. So the streamers can know the type of people who are watching their streams. Right, and this kind of like an idea off the top of my head. But I guess the point that I'm trying to make is that there's a lot of really interesting toolkits that are already. Built within the Lifepeer ecosystem that you can just take and make Tweaks on top of it to add interesting functionalities. And I'm pretty excited about that.
00:41:01.810 - 00:41:04.126, Speaker E: Would it be possible to add extra.
00:41:04.228 - 00:41:06.770, Speaker B: Transcoding steps like some kind of post.
00:41:06.840 - 00:41:10.340, Speaker E: Processing or like watermarking, stuff like that?
00:41:13.110 - 00:41:47.326, Speaker B: Yes, absolutely. You can do that. Everything in Lifeview is open source, including the lifepeer node itself. The Life peer node currently handles video transcoding for different codecs. It also handles smart AV features. So for example, if you want to transcode but also do scene detection to figure out if someone is streaming adult content on your platform, you can do that. Right? So that kind of gives you an idea of how open ended it can be.
00:41:47.326 - 00:42:10.326, Speaker B: When you talk about just open source and open video processing, you can absolutely add watermarking, you can add compositing to add different kind of artifacts on top of that. So it's not just a watermark, it can become animated. Yeah, all kinds of cool ideas that can come out of that.
00:42:10.348 - 00:42:26.780, Speaker C: One I like it the other way around. Something is not like too dull but maybe too fast. So really catering towards people who cannot watch too fast stuff. I just took that idea. I don't have a question, sorry.
00:42:27.390 - 00:42:33.100, Speaker B: Thank you for your contribution. Any other questions?
00:42:37.330 - 00:42:41.038, Speaker F: You mentioned that there's a penalty similar.
00:42:41.124 - 00:42:42.026, Speaker B: To proof of stake.
00:42:42.058 - 00:42:44.190, Speaker F: I was just wondering what exactly is the penalty?
00:42:46.070 - 00:43:43.470, Speaker B: Yeah, that's a really great question. So that's really in the core design of the live peer protocol, right? And the problem that is trying to solve is that imagine I'm subversive and I ran a live peer orchestrator on the network and I say, hey, I provide transcoding services to everybody and you send video to me. And I start transcoding video for you, but I start ingesting weird videos in the middle of your video. Or I can just simply return blank videos to you. Or I just won't do the work at all. Right, so any of those situations are really bad for the quality of the network and we need to have a way to prevent that. So the way to do that is there's a verification mechanism in the protocol that allows the broadcast, allow the person who's using the network to say I want to periodically verify that and make sure the work is done correctly.
00:43:43.470 - 00:44:28.100, Speaker B: But you won't tell me which segment that you're going to verify. Right? Because I am on the network and I'm signing cryptographically for every video segment that I give back to you. You have clear proof and evidence that I said I did the work. Right. So if the verification fails, you can submit that proof on chain to say, hey, Eric cheated and the protocol will automatically slash me by taking some of my life here token. So because in order to participate, I have to have some skin in the game. And this is where kind of the staking mechanism come in again, very similar to how kind of Ethereum staking works.
00:44:28.100 - 00:44:34.924, Speaker B: A totally different question because not about.
00:44:34.962 - 00:44:37.996, Speaker E: The technology itself, but how do you.
00:44:38.098 - 00:44:44.636, Speaker D: Envision like conquering the world with Live Peer? So how do you compete with, let's.
00:44:44.668 - 00:44:50.748, Speaker B: Say, Web Two or traditional video transcoding services? Is it a competition based on pricing?
00:44:50.844 - 00:44:52.016, Speaker E: Do you claim that you can do.
00:44:52.038 - 00:44:57.712, Speaker B: It cheaper than competition or is it more about that you have more features that sweptree enables?
00:44:57.776 - 00:44:59.190, Speaker E: What's the plan there?
00:45:00.680 - 00:46:08.112, Speaker B: Oh man, what's the plan there? There's definitely that cost aspect, right? Live Peer is ten times cheaper than Amazon Web Services from an infrastructure cost perspective. And that's just because there is so much spare capacity laying around the world that people can donate to, people can put on this network and to make a little bit of money back. Right? So that's really interesting. The other thing that's interesting from the long term perspective, which I think is a lesson that we've all learned from the Bitcoin network ten years ago, is that if you put a simple set of incentive out there and you said this is encoded in the protocol, everybody feel free to do whatever you want with it. People are smart and they figure out how to take advantage, how to figure out how to game the system by improving their performance to make it a little faster for themselves. And when everybody's doing that, that grows organically like crazy. Right? So ten years later, the Bitcoin network is by far the largest supercomputing network in the world in terms of the power of computation.
00:46:08.112 - 00:46:48.836, Speaker B: Right. Because people started building GPU mining software and for a couple of months that was profitable. Immediately it became FPGAs and then immediately it became Asics. Asics kept getting faster and faster and faster. So we already see that happening in the Lifetime network where ASIC miners are coming into the network that are creating video transcoding specific hardware to be able to compete with kind of traditional GPUs. So that will only get better and better over time and that's where the long term cost advantage and scalability comes in. Right, but I think that's just one angle.
00:46:48.836 - 00:47:24.972, Speaker B: The other angle that's really interesting is this Web Three movement that's happening, right? And the Web Three movement is really about ownership. It's about giving people an opportunity to have a more open and transparent system. And that I think is highly disruptive to the existing world of video platforms. Right. You use YouTube. YouTube's take rate is about 50%. That means for every dollar that a creator makes on YouTube, YouTube takes $0.50
00:47:24.972 - 00:47:35.284, Speaker B: from that. Right. That is crazy for a platform that is made up of the videos that people upload. They don't make any videos themselves.
00:47:35.402 - 00:47:36.070, Speaker D: Right?
00:47:36.600 - 00:48:21.430, Speaker B: So using Web Three, creators essentially get to say like I actually own the video myself because it's tied to my Ethereum address which is on the blockchain layer. The application is simply built on top of the blockchain layer. Right. So Livepeer is building the video streaming layer for Web Three that has all these hooks into other Web Three components that together creates this Web Three video application stack that allows people to build these types of Web Three native video applications that I think in the long term are going to be just very disruptive. Cool.
00:48:24.760 - 00:48:27.448, Speaker E: Thank you. Two questions.
00:48:27.534 - 00:48:44.812, Speaker B: First one is, do you think that the network of transcoders will ever be spread out enough that you won't need CDN networks? And is there like an idea in your mind to build out another set of nodes with a different function that.
00:48:44.866 - 00:48:47.436, Speaker E: Access the CDN or anything like that?
00:48:47.458 - 00:48:50.076, Speaker B: And then the second question is, if.
00:48:50.098 - 00:48:52.284, Speaker D: I just uploaded a file to IPFS.
00:48:52.412 - 00:48:55.340, Speaker E: And included that address in my metadata.
00:48:55.420 - 00:48:57.964, Speaker B: For an NFT, would that work? Or does it have to be transposed.
00:48:58.012 - 00:48:59.440, Speaker E: To mint an NFT?
00:49:01.940 - 00:49:51.410, Speaker B: Cool. First question about CDNS. So Live here actually already contains software that allows you to deploy your own edge node around the world in order to kind of run your own delivery. And for a lot of applications, that works extremely well. We have a user of Live Peer who runs an application that has over 80 million minutes a week a month and have over 75,000 streams per month, this pretty popular video streaming network. And they don't use a CDN, they just run Live Peer nodes around the world, like a couple of like three or four locations around the world. And they're able to handle a lot of traffic that way.
00:49:51.410 - 00:50:43.548, Speaker B: So that's the current way to kind of scale your delivery. If you don't want to use a centralized CDN, we're also working on a decentralized CDN solution that allows each life peer node to essentially serve as a seed of a swarm of nodes that are living in people's browsers. Right. So what that allows you to do is to run a live stream and for your viewers to watch the video and deliver the video to each other so it's not always loading from the network. And that's the way to really scale out. And that's really a really good situation for really good solution for when a video all of a sudden gets viral. And that's kind of the worst situation for a centralized video platform because in centralized planning, you already planned out your capacity.
00:50:43.548 - 00:51:26.188, Speaker B: And when something unexpected like that happens, which happens all the time, it can be really disruptive to the network that's already pre provisioned. Right. But in this world when the virality happens, it's great because the people who are coming in to watch those streams are just delivering the video to one another. Right, and that kind of protects the network from this almost like DDoS attack. Right, so that's that second question is about NFT minting. Yeah, you absolutely can just use a video and upload it into IFFs and use that hash and mint the video. However, video files come in all kinds of different formats.
00:51:26.188 - 00:52:22.210, Speaker B: They come in all kinds of different resolutions. Oftentimes they're not optimized for video streaming on the Internet or especially streaming in the browser. Right. So you can think of live peer's network as almost like an optimization or standardization layer that just processes the video so that it makes sure when you're minting the video, you have the best file format to do it, right? Yeah. Is it multiple formats to put in the NFT? Currently, it is one format that's like the optimal format, but yeah, in future versions, we'll add in kind of flags for people to have a little more flexibility there. All right, how are we doing on time? All right, last question.
00:52:29.880 - 00:52:54.460, Speaker F: Is it technical possible to make mint out of one NFT video, more NFTs? So, like, for example, editing video, you have one video and some people wants to make some art out of it and make a second NFT out of the small NFT.
00:52:57.680 - 00:52:59.230, Speaker B: Do you want to answer that one?
00:53:04.180 - 00:54:04.692, Speaker C: So from the live view perspective, the SDK, you could mint the same video multiple times. You can also create the smaller segments of the video and create separate NFTs out of those. But you could also build something maybe even on chain to do something like that. Maybe you have the NFT which points to the video, but it has an offset in the video as a metadata, and then your NFT application knows that it's not owning the full video, only part of it. And then you could create sub NFTs or smaller NFTs from the same video without needing to upload or reprocess that video just by having that reference. But that would be a custom protocol on top of the existing ones. So you would need like your own application to parse it and all that.
00:54:04.692 - 00:54:10.150, Speaker C: But I don't know if I answered the question. Is that, okay.
00:54:13.160 - 00:54:23.690, Speaker F: When you make out of this existing NFT second one or more small NFTs, that, you know, the small entities are actually from this?
00:54:24.140 - 00:54:24.872, Speaker B: Oh, right.
00:54:24.926 - 00:54:25.240, Speaker D: Yeah.
00:54:25.310 - 00:55:16.676, Speaker C: So that's one still, the question is if there's a way to know if the smaller file that was minted as the NFT corresponds to the original one before processing. And that's something that we do want to add as well, which is like, when we do the NFT, we upload not only the final process file in the right field for the applications to show the video, but we also have a custom property that is like the original video is this. And then you have a different IPFS file. And with the proper application, you could go and play the full play or download the full file as well. So you can do both. And right now you can customize the NFT metadata as well. So you could even build that on top of the SDK.
00:55:16.676 - 00:55:18.910, Speaker C: It's already possible to do so.
00:55:20.720 - 00:55:30.060, Speaker B: Yeah. All right, well, thank you all for the awesome questions and thanks for the crowd, and thanks to Eve Global for hosting.
00:57:04.920 - 00:57:30.110, Speaker A: Sam, it.
01:01:45.630 - 01:02:16.302, Speaker E: Very briefly, what is Tatum? Tatum is a framework which helps developers build applications fast on different chains and on different protocols. We support a lot of features out of the box. You don't have to build your own nodes. You don't have to do the RPC calls. You just call one of the ready to use features and you can integrate it directly into the application. You can build basically any app. You can build NFT Marketplace.
01:02:16.302 - 01:02:51.002, Speaker E: You can build the wallet. You can build some D Five protocols, whatever you want. It's just up to you on more than 40 different blockchains. What's the benefits? Or why should you choose to work with some framework over the native RPCs? You don't have to know blockchain. You don't have to know how RPCs work. You just need to know how those common features works under common features or like ready to go features from us. I mean, Mint NFT operation, create wallet, operation, sign transaction operation.
01:02:51.002 - 01:03:41.946, Speaker E: Something very, let's say, easily understandable from the developer perspective, what actually like. What was the development process of building an app inside Atom. You as the developer will start with playing around with the APIs. You obviously has an idea what you want to build. You will just take a look like, okay, I'm going to build, let's say, NFT Marketplace. What I need to do that, I need NFT contract, I need some wallets, I need some APIs. But you find out, okay, tatum gives me, let's say, 90% of these ready to go features, but I need like 10% of some custom RPC call or some custom operations you need to do on a blockchain.
01:03:41.946 - 01:04:23.744, Speaker E: We don't lock you inside the tools we give you. And every good framework should give you freedom. And the freedom means if you don't find the things you need in the framework, you just go a level below that framework, and the level below is, of course, RPC nodes. With the RPC node, you can do whatever you want. And that's basically very quickly, this slide. And now I'm going to focus on some real live demo, real live hacking. I'm going to show you how the platform works, what you need to do.
01:04:23.744 - 01:04:46.330, Speaker E: We're going to Mint? NFTs. We're going to mint NFDS on solana. We're going to mint NFDS on polygon. I'm going to show you how Datum Kms works, what it actually is, and I'm going to show you how you can interact between datum and MetaMask if you want to build some kind of DeFi application. So let's quit this. Let's open postman. My best friend.
01:04:46.330 - 01:05:23.750, Speaker E: And from the start, this whole postman collection and every example I'm going to show today is available on our public GitHub. I believe you can find GitHub.com Tatumio, and when you search for the repositories, it should be DevConnect 2022. So there is visible postman collection. There is present postman collection, MetaMask page I'm going to show later today and some README files. So everything is there. You can just play around by yourself.
01:05:23.750 - 01:06:12.340, Speaker E: So today's workshop is going to say, I'm going to shoot like three different topics. First topic, the most simple one is NFTs. I believe you're all curious like how to work with NFTs. You don't know solidity, you don't know rust. You want to mint NFDS on Solana, on polygon, on anything else out there. And for that we have done the abstraction for you, which means we have already endpoint where you can very easily mint NFT on the chain of your choice. The interface of basically all operations we have is trying to be as abstract, as similar between different chains as possible.
01:06:12.340 - 01:07:03.408, Speaker E: Which means most of the time what you need to change what you need to change when you are doing cross chain application and working with polygon or ethereum or I don't know, solana is just the chain parameter inside the request. You choose Sol, we're going to work with Solana. You choose ETH, we're going to work with ethereum. But let's start from the scratch. Let's start from the first operation. In order to, let's say, work with NFTs, or let's say you want to build an application, your user has to have a wallet or address or something where he actually receives the NFT, or for the address from which he want to send some other transaction, maybe sold or the NFTs away to someone else. We give you the choice very easily to just generate a Solana wallet.
01:07:03.408 - 01:07:50.380, Speaker E: And the result of the operation is address and the private key. I want to say out loud that don't use this endpoint in your production apps because it exposes the private key. It travels through the Internet, which means it's compromised. You shouldn't use it. Of course, we give you other tools which you can use locally in your app, like some client based SDK or Tatum Kms or Tatum CLI, where you can generate those wallets or do any operations with a private key securely in your perimeter. So we've created a wallet. I think let's use it like this for the demo purposes.
01:07:50.380 - 01:08:47.168, Speaker E: I don't care what we have actually done. We have called an API call to our EU region and you need to pass an API key you can obtain in our dashboard when you sign up, which I forgot to show you how to actually do it. So if you head to the Tatum IO, you hit get started. You can create an API key here. You sign up, you create an account and you can create free API keys from which you can build, you can run, you can play around in the list of the API keys. Of course, you can show it, copy, paste, use it in your app. So let's get back to the postman.
01:08:47.168 - 01:09:12.940, Speaker E: So I have created an address I should obviously send some solana tokens there from the Faucet so I can perform some transactions. Let's use Sol faucet. When you create testnet API key in our platform for Solana, we are using DevNet because it's a chain which should be used for developers.
01:09:14.880 - 01:09:15.630, Speaker D: So.
01:09:17.600 - 01:09:53.556, Speaker E: Let'S send one sol to my address and let's check if it's there or not. Looks like it is, so I have some balance to work with right now. The next step for you, you create an address for a user or for your application, and right now you want to mint NFT. For minting NFT. Again we have another operation which is mint NFT. Surprise, surprise. And there are some couple of important fields you need to enter in order to mint NFT for solana.
01:09:53.556 - 01:10:37.620, Speaker E: This is a little bit different than for EVM chains. I'm going to show later how to mint NFTs on a polygon, which is same for any EVM chain. But for Solana you just need to specify the metadata. The metadata are stored on chain in comparison with EVM chains, where you are storing just the URL to the IPFS or some other third party metadata storage. And we are going to use the address on which we're going to mint the NFT. So the recipient is going to be our address and the minter could be our address as well. Let's use the private key of our created address and let's mint the NFT.
01:10:37.620 - 01:11:44.872, Speaker E: I'm going to mint the NFT some random stuff with some default metadata name, symbol and URL of the image I forgot to enter the verified creator which is myself. And the result of the operation are three fields. The first and the most important field is a transaction ID. With this transaction ID you can easily check on the explorer if the transaction actually passed or not, or you can read the transaction through our API. We can see that the transaction looks like path, it's successful and the result of the operation is new token which is minted. And when we check the token address, the NFT address here in the response, which is the same here, you will actually see the newly minted NFTs. For Solana, we are following the metaplex standard which is like de facto the only way how to work with NFTs on Solana.
01:11:44.872 - 01:12:43.996, Speaker E: So we are fully compatible with any NFT marketplaces or whatever which supports NFTs on the solana chain. So great, we have created NFTs and we have sent it to us as the owner. Another step, the logical one is I want to send NFT from my address to somewhere else, which again requires transfer operation. In the transfer operation, you again need to define from who you want to send NFT what's the private key of that address, who's going to be the recipient, and the contract address represents the actual physical address of that specific NFT. For the polygon example, we're going to see a small difference because obviously we are missing some kind of Identifier of the token. There is no token ID for EVM chain. There are token IDs because it works slightly different for solana.
01:12:43.996 - 01:13:32.348, Speaker E: Each NFT is a unique basically program on the chain which doesn't have additional Identifier. So let's use our sender parameters. Like I'm going to send the NFT from myself to someone else and I need to use the correct token which I want to transfer. And the result operation is again the transaction ID which we can verify on blockchain that the NFT has actually changed the ownership from myself. It was sent to someone else very easily, straightforward. In three operations you can create addresses, you can mint NFTs, you can transfer them. Of course, there's much more to that.
01:13:32.348 - 01:14:38.000, Speaker E: In our API documentation you can find everything you need if you want to read operation, read metadata or do some other things with Salana. And now let's do the comparison how the same NFT is minted or how this all is handled on a polygon which is like L two for ethereum. This approach is valid for all EVM chains, ethereum, cello, binance, smart chain, polygon, harmony and anything else we have added in our platform. So again, as for the solana, first step for polygon is generate the wallet. For EVM chains we support like HD wallets out of the box. So we give you the mnemonic and external public key which points to millions of addresses under this one specific mnemonic. So we need to do like two additional steps here in order to get one specific address and one specific private key.
01:14:38.000 - 01:15:17.700, Speaker E: If you want to create an address from the wallet we have created, you need to say I want to create address number zero from this wallet extended public key. Bam. You have an address. If you want to create address number I don't know 1000 you just enter address 1000. You have I think up to more than 2 billion addresses available in one of mnemonic. But I think we are fine with one. So let's use address number zero which is this one.
01:15:17.700 - 01:16:00.640, Speaker E: We should send already some testnet assets. So let's go to Matic Faucet and let's send here some. Of course I'm going to use my personal testnet faucet for this. This could happen only on live demo, right, that the faucet is empty. So let's send here, I don't know, zero point. This is not enough. Let's pick different account.
01:16:00.640 - 01:16:33.530, Speaker E: This one let's send there, I don't know 0.5 matics great. Thank you Matic Faucet for helping. Let's go back. So in order to obtain the private key from the mnemonic we have created again there is operation generate private key from the mnemonic. Again I'm going to say out loud don't use it on production, use some safer ways. I'm going to show you which ones.
01:16:33.530 - 01:16:58.340, Speaker E: So from this mnemonic we are generating private key for address zero. Zero address private key. It needs to match one of the biggest problem when developers are playing around. I have used incorrect index, I have used different Xpap than Mnemonic and it's not working. Blah, blah blah blah blah. Just focus. So we have a private key here.
01:16:58.340 - 01:17:40.794, Speaker E: The safest way how to actually validate if this private key points to the address you think it points to is just import it inside MetaMask and you will see that the address is correct and we have a balance. Safest way, just double check. I'm going to keep this window open. It's wonderful. So we have a balance. We can actually proceed to finally minting some NFTs on EVM chains. When you want to work with NFT, first of all you need to deploy NFT smart contract under the NFT abstraction.
01:17:40.794 - 01:18:34.010, Speaker E: Here we are talking about ERC seven to ones. We also have erclam 55s available for you. So semifungible tokens the let's say steps for working with them are basically the same as for seven to ones. Just a small nuances. So let's create new NFT, let's deploy it on matic chain with some random symbol and we are going to pay the transaction cost from our private key from our address. The result is transaction ID. We have created very, let's say useful some kind of utilities for smooth flow of the application which means you want to deploy NFT.
01:18:34.010 - 01:19:39.670, Speaker E: Obviously you want to find out what's the contract address of the deployed contract. So we have created a very, let's say small utility from this transaction ID. Tell me what's the contract address and voila the contract address is here so we don't have to verify it on a polygon scan or somewhere else. And for example, if you are building some kind of, let's say NFT heavy application when you are like real time deploying new NFTs, you need to do programmatically these kind of operations. You must have a tool for that. So we have deployed a contract and right now we finally can mint our NFT. The difference again between Solana and EVM chains is that seven to one and 1155 standards both requires the metadata to be stored off chain somewhere else and stores only the pointer to that metadata you want to attach to the NFT.
01:19:39.670 - 01:20:30.518, Speaker E: So in order to actually meet NFT you need to have some kind of URL which you want to use. Most of the NFTs out there are using some decentralized storage systems like IPFS Filecoin, ARVU et cetera et integrated. We have integrated IPFS where you can very easily again in one API call. Basically store anything you want on IPFS and you receive the IPFS CID. So I'm going to store some crazy built smart contract compilation information to the NFT. I actually don't care. Usually what you are storing in the metadata is really up to any application.
01:20:30.518 - 01:21:30.886, Speaker E: If you are building some, let's say if you're a content creator and are creating music or art or videos you are storing there some videos. If you are working on a project where you're going to mint those NFT as a utility NFT which could represent tickets, represent memberships, it could represent, I don't know what, some fractional ownership of some piece of land. Why not? You will obviously store the metadata something else than an image. But let's just store this file on IPFS and the result is IPFS Identifier. So in the mint operation we can actually mint NFT with some metadata. We are going to use the deployed smart contract we have deployed as a contract address. We are going to work on matic chain.
01:21:30.886 - 01:22:13.990, Speaker E: This is the recipient of the NFT we're going to mint. This is the private key which will mint the NFT. So we need to use our private key. We are going to send the NFT to us and we are going to mint NFD number one. The token ID in the seven to one world should be some integer or integer really extremely huge integer, 256 bits it can have if someone is interested. So we can create really a lot, a lot of tokens under one contract. So let's mint.
01:22:13.990 - 01:23:32.960, Speaker E: Obviously the result is the transaction ID of the operation and we can check this transaction ID on the polygon scan. The result of the operation is NFT which was minted from zero address to me as a recipient with some metadata attached. Same as for solana. We want to transfer this NFT somewhere else. So we're going to use the same v three NFD transaction operation as we were using for transferring the solana NFD. If you're going to work with ethereum again you're going to use the same operation, that's what we call code ones deploy on every chain. So let's transfer our NFT on the matic chain, right? We're going to transfer NFT token number one to new recipient from we're going to transfer it from our address and here you go again, transaction ID.
01:23:32.960 - 01:24:20.080, Speaker E: In the meantime, polygons can finally loaded our transaction and we can see that we have minted NFT from zero address to ourselves. Token number one. You can see that if we take a look on how actual parameters of the operation look like, you can see that we have minted token number one to this recipient and this is the metadata connected to it. So everything we have entered into operation is visible on the chain. And let's check the transfer transaction. Transfer transaction is again very straightforward. We can see that we are transferring NFT number one from ourselves to someone else.
01:24:20.080 - 01:25:50.064, Speaker E: And basically I don't think I have anything more to say regarding the transfer. If you want to now support not Matic but you want to work on Binance Smart Chain or you want to work on Ethereum or you want to work on Sello or you want to work on Harmony this all is available basically only via changing the configuration of the request we give you not only the write operations, but. If you want to build some reasonable application, and it should have full set of features you want to use, you also need to read. You need to read which NFTs are hold by which addresses, what do you own, what was the NFT transactions, how the NFT travels between the different accounts on the chain. We have these operations available for you as well. We got you covered. So, for example, if I want to see the balance of one specific address, which NFDS it owns, we can just check this one and you can see like, this was my address and the address owns these token IDs on this specific NFT contract with some metadata attached.
01:25:50.064 - 01:26:30.768, Speaker E: So you can see I've already play around with my metadata file. I think I should have used something smaller, but I think you get the point where we are. You can see all the balances of a specific address. The time when those NFDS appears in this endpoint varies how fast we index the data internally. On the faster chains, it's pretty fast. We can scan polygon quite near to real time. For slower chains like Ethereum, it can take like two to three minutes.
01:26:30.768 - 01:27:21.730, Speaker E: Since the transaction appears in the blog, and since we do our internal stuff, there are of course, more operations than just get NFTs by address. Everything can be found in the API doc, which I think I should show how you can get there. Inside the resources, there is a API doc link where you can see list of all the operations we support. And we were talking today about NFT section. So you can see here all the operations you can do on top of the NFT. Here are some write operations, here are some read operations, get NFT transactions by address, et cetera, et cetera, et cetera. Everything you need to do in order to build something real.
01:27:21.730 - 01:28:04.740, Speaker E: This is basically pretty much it in terms of the NFT workshop. And right now I want to focus on the Kms and I want to focus on the MetaMask because, yes, we have played around with the APIs. We have pretty decent understanding how the flow should look like, what operations should we do. But this is actually not how you're going to build your production application. You're not going to send private keys over the Internet to us to sign something. You can do it. Some projects do that, but please don't.
01:28:04.740 - 01:28:38.720, Speaker E: Please don't. This is just for you, for playing around. As I said at the beginning, we have other options how you can build the production application. One of the option is to use our client libraries, tatum JS. It's a JavaScript SDK, which you can download. You can include it in your app on your back end or on your front end and do all these sensitive operations locally. I mean, generate wallets or Sunny transactions.
01:28:38.720 - 01:29:32.720, Speaker E: The SDK looks pretty simple. When I open some, let's say, unit test, which actually shows you how the SDK looks like you are building on top of the SDK. You want to work with a transaction section and you're going to mint NFTs. The body of those calls are near almost the same as for the API calls. It's just the different wrappers on top of some objects in the JavaScript. But basically we are reusing one to one tatum JS format inside rest APIs. But you can use your private key here because obviously you will include this in your back end.
01:29:32.720 - 01:30:53.408, Speaker E: So if you are building some custodial application, some custodial wallet or custodial marketplace and you are already managing the private keys of your users, you can use the private keys on your site. If you're not building custodial solution, but you are building something, let's say more DeFi and you want your users to sign their own operations with MetaMask or with something else. You actually want to know how to do it, how to sign some transaction, how to sign Mint NFT operation with MetaMask. I want to use the same cool features, the same abstraction methods, same Mint NFT transfer NFT operations. But I want to let the users to sign that. I have created very ugly example HTML page where we actually going to connect this page with a MetaMask. We choose some account in the MetaMask and we're actually going to mint that specific NFT using MetaMask with the signing.
01:30:53.408 - 01:31:40.440, Speaker E: And then we can take a look inside the code, how this all was done. I need to choose a correct account for this. I think it was this one. Yep, I think it was this one. So I'm gonna first of all, I need to enable MetaMask, connect some account from the MetaMask, and then I'm gonna internally mint NFT with some specific token ID with some random metadata. I actually don't care what I'm going to Mint, I just want to show you how to mint it. So I don't think this will work because I think I have wrong account.
01:31:40.440 - 01:32:36.400, Speaker E: Exactly. So let's dig dive into the code before that. This is what needs to be changed. I need to use my API key, of course, because I'm going to communicate with the platform. I'm going to perform some post request to the API and I think there was another one here. And what I'm going to do, I'm going to basically use the same request as I was using for Minting. I'm just going to replace the from private key with some placeholder value which we internally understand and we just.
01:32:38.610 - 01:32:38.974, Speaker D: Give.
01:32:39.012 - 01:33:20.506, Speaker E: You the recipe to be used inside MetaMask. So I'm going to use this contract address I have deployed. I'm going to Mint it here to this guy with some metadata and I need to connect the correct account inside MetaMask, which was the last one. EFD. Yeah. So let's connect to MetaMask. Let's try to minfdes and MetaMask window pops up.
01:33:20.506 - 01:33:36.746, Speaker E: It was correctly connected. You can see that I can sign some transaction. Let's sign it. And the result is shown here. Again transaction ID. And we can check it on a polygon scan if it's actually working or not. This looks like a magic.
01:33:36.746 - 01:34:23.886, Speaker E: Internally, it's very simple. Internally, what we are actually doing, we are leveraging the standard MetaMask interface. How the MetaMask connects to the blockchain application where we just work with the ethereum object in the JavaScript world. And then for minting NFT, as I said, we are using the same API call as we're using in the demo. But instead of a private key, we are using a signature ID. Signature ID for us means that we don't sign the transaction with the private key in our API. But we just prepare transaction object which should be signed later on.
01:34:23.886 - 01:35:01.770, Speaker E: It could be signed inside MetaMask or it could be signed inside our key management system, which is stateroom Kms, which I'm going to talk like in next 1 minute. You can enter any signature ID here. We just send the Mint operation. We receive some response. We perform reading. That response. So we're actually fetching the transaction object, which we want to sign inside MetaMask and just do some magic and send the transaction config for signing to the MetaMask.
01:35:01.770 - 01:35:29.490, Speaker E: I'm not saying it's simple. I'm saying it's like 30 lines of code. But this operation you are doing right now could be anything. It could be minting NFT. It could be sending ethereum, it could be transferring ERC 1155. It could be some approval on top of the smart contract. It could be whatever, anything you want to prepare on the client could be signed with this approach, with MetaMask.
01:35:29.490 - 01:36:30.394, Speaker E: So if you want to build quite quickly some DeFi app you want to use MetaMask, you can. Leverage all our pre built pieces of functionality, all the features using this way and just let the MetaMask do the signing. And then like last part of the workshop is going to be the completely opposite type of application. And we're going to talk about the custodial application you want to build and how to work securely with the private keys if you are building a custodial solution. I've seen crazy things. I've seen projects where storing private keys non hashed in the postgres database on their application server. I saw projects who are sending private keys over Internet.
01:36:30.394 - 01:36:59.010, Speaker E: They don't care. Eventually all of them stopped working. Because they got hacked. Or there was some other problems connected. To that. But none of like, if you want to build something really serious, something which should survive at least first hacker attack from some random guy, you need to really understand and pay attention to working with the private. Keys.
01:36:59.010 - 01:37:39.758, Speaker E: If you don't do it properly, you can be really in a bad place or in a bad situation. What's unfortunate is that it's not unfortunate. But more and more new developers are joining web3 space. More and more web two people are trying to build something on top of the blockchain, but they actually don't have any previous experience. They don't know what's the correct patterns. They don't know that private key must be stored securely. They don't know how to do it and what's the correct flow.
01:37:39.758 - 01:38:54.822, Speaker E: And because of these, there's so many problems and so many failed projects or hacked projects out there in data. We understand that and that's why we're trying to guide you using, trying to guide you to use proper design patterns while building your app. And actually you can't do it badly if you follow these main ideas. And the Kms is basically that example. So I'm really going to start showing that because we are bed on time. If you want to like Tatum, Kms is a key management system, which means it's a small tool which runs again on your infrastructure, which holds the private keys, the mnemonics, everything on your side. And it automatically communicates with our API on the cloud, like fetching some transactions which should be signed from the API, signs it locally and broadcasts to the blockchain.
01:38:54.822 - 01:39:53.954, Speaker E: With this setup, your private keys never leaves your perimeter. The private keys lives in your server, secured as you secure them. Because the transactions are being fetched, private keys are not being sent away. If you want to work with the Kms, you need to pull the Kms docker. And first step which you want to do is basically set up a wallet file which will securely hold all your private keys. For that, there is like a bunch of CLI commands you can work with. The most easiest one is generate managed wallet or store managed private key.
01:39:53.954 - 01:40:46.278, Speaker E: If you have like external private key. I have example of these calls in the README. So right now, I'm going to store my pre generated private key for the existing polygon account. I just need to point out the correct volume on my drive and say, hey, Tatum, Kms, I want to store managed private key for a matic on the testnet chain. The docker just start it will ask me for the private key, which I want to store, which I believe is this one. It will ask me for the password, which is used for encryption of the wallet file. For the first time, just enter some password you want.
01:40:46.278 - 01:41:33.240, Speaker E: Second time will have to repeat it. My favorite password is 12345. And the result of the operation is that Tatumkms grabs that private key, stores it in the wallet file, and generates signature ID, which actually represents that private key inside this Kms instance. Right now, my Kms can start fetching transactions which are connected or sent with this signature ID. So let's say I want to mint new NFT. I want to mint NFT number ten. But instead of a private key, I'm going to use signature ID.
01:41:33.240 - 01:42:47.230, Speaker E: This body tells the API internally that, hey, this guy want to store the transaction for the Kms signatures later on. So the result of the operation is not the transaction ID on the chain because no signatures were done, no transaction was broadcasted to the chain. The result is some Identifier of the operation which should be signed later on. You can get the details of that operation using Kms. Get details stuff. And you can see here some, let's say information where the most important pieces are. The Chain we are working on matic the serialized transaction field is actually, the transaction which will be signed inside the Kms and the hashis field represent the private keys which should be used from Kms to sign the payload.
01:42:47.230 - 01:43:43.610, Speaker E: So right now the transaction is still in, let's say, descending state and once the transaction is signed there's going to be new field takes ID present with a specific transaction ID. What we need to do from the Kms perspective. We need to run it in a docker mode. If we want to start kms fetching if we want a kms to start fetching the transactions from our API, we need to run it as a docker demon. Using this command, you are actually saying, hey, Kms, I want to start you in a demon mode. This is my API key so under this API key you should communicate with the API. I want to see only transactions which are connected to polygon on the testnet network.
01:43:43.610 - 01:44:34.834, Speaker E: So right now, I have one transaction pending inside my API key space. So Kms demon will start. You need to enter, of course, the password to decrypt your wallet store. And Kms starts fetching the transactions from the platform. I think we have a lot of transactions there under these signature IDs, which I don't like for any reason. But I think this one is the one, not this one. Let's see if this one got processed.
01:44:34.834 - 01:45:18.702, Speaker E: It got luckily. So let's take a look what happened here. Under my API key I have a lot of other pending transaction which should be signed. One of those pending transaction was mine and the transaction got picked up by the Kms it was signed, broadcasted and the transaction ID was attached to that Kms transaction object. We can right now check on the polygon scan, like if the transaction actually passed or not. And yes, it looks like we have really minted token number ten as we want it. And when you take a look how we actually did it, we haven't sent the private key anywhere.
01:45:18.702 - 01:45:36.800, Speaker E: The private key remains secret and safe inside our Kms. I know it was a lot but right now it's time for any questions you might have for I think we have a microphone somewhere.
01:45:39.990 - 01:45:41.590, Speaker B: I don't need a microphone.
01:45:42.170 - 01:45:43.640, Speaker E: Okay, go ahead.
01:45:44.010 - 01:45:56.154, Speaker F: So thank you very much for your presentation. It's very fair you use MetaMask but can I say assume I could use any other kind of wallet and just.
01:45:56.192 - 01:46:00.134, Speaker B: Replace MetaMask for the connection?
01:46:00.262 - 01:46:33.314, Speaker E: Yeah, for the stream the question is if I can replace the MetaMask with any other wallet, like wallet connect or whatever else. Yeah, if the principles how those wallets are working are similar to MetaMask. So you are passing the transaction configuration which should be signed, then yes, you can use whatever. It's really up to you. Awesome. There's any more questions? We can another one. Great.
01:46:33.512 - 01:46:37.540, Speaker B: Can I implement this with NFC minted videos?
01:46:42.650 - 01:46:44.200, Speaker E: What do you mean by that?
01:46:46.490 - 01:46:50.822, Speaker B: You have it with NFT, but if.
01:46:50.876 - 01:46:53.090, Speaker F: I take for example have an NFT.
01:46:53.170 - 01:46:58.220, Speaker B: Minted video in this case, would this also work?
01:47:01.310 - 01:47:40.450, Speaker E: Well, if you mean like NFT Minted video is like actually the existing NFT already on the chain and you want to remint it again, yes you can. Because technically speaking, this is just mint NFT and I don't care what I'm minting. Like you can mint whatever token with whatever metadata. So it's really up to you what you want to mint. If you want to create new NFT, this is the operation. What's actually inside that NFT, it's really up to you. Okay guys, if you will have any more questions, we are here like yeah, go ahead.
01:47:47.780 - 01:47:53.620, Speaker B: Function. Do you have plans to add Bridging functionality into your SDK?
01:47:57.240 - 01:48:58.010, Speaker E: The question was again for the stream that we have a lot of EVM chains integrated and if we plan to add some Bridging functionality, what we have available in each of our integration of every blockchain is that you can easily, let's say call smart contract. You can perform ride operation on any smart contract available on that specific chain. So if there is a breach already, which is a smart contract based, which usually they are, you can actually right now working with that breach just by invoking that breach method. For example, we're going to send an FD there and call something on a breach. Yes. From the abstraction perspective right now we don't plan to add some custom bridges or do abstraction for existing bridges. If you want to bridge yourself those NFDS and build it by yourself, you have a couple of options.
01:48:58.010 - 01:49:53.830, Speaker E: You can integrate some existing bridge or you can deploy your NFT, contract different chains and basically create your own bridge that you will burn on one or mint on another one and basically will bridge like this with some metadata connections between those or which is even better solution. You can basically send your NFT to some specific address which you own and you say that this is my breach, you will mint another one and do it by yourself? Yes, you can. Yeah, it would be great. Okay guys, I think we are on time. So thank you all and as I said, we are here tomorrow, on Sunday as well to answer any questions. Thank you.
01:49:56.200 - 01:49:57.230, Speaker A: Thank it.
01:50:46.960 - 01:50:47.740, Speaker F: Huh.
01:50:51.600 - 01:51:12.310, Speaker A: Might be all the way back there's. Here.
01:51:34.760 - 01:51:38.430, Speaker F: Hi there. How's it going? Good.
01:51:39.680 - 01:51:45.580, Speaker A: Just in terms of yeah. Okay.
01:51:45.650 - 01:51:46.270, Speaker B: Yeah.
01:51:50.020 - 01:51:51.280, Speaker D: As soon as I get to the back.
01:51:51.350 - 01:51:51.632, Speaker F: Okay.
01:51:51.686 - 01:51:53.490, Speaker A: Just get yeah.
01:51:57.540 - 01:52:22.932, Speaker F: Oh, yeah. I'm I'm moving some things around before sharing. Yeah. Okay, perfect. Okay, cool. Yeah. Okay.
01:52:22.932 - 01:52:23.860, Speaker F: Gotcha.
01:52:25.240 - 01:52:26.150, Speaker D: And time.
01:52:26.960 - 01:52:27.710, Speaker A: Um.
01:52:32.320 - 01:52:51.250, Speaker F: I know someone who's gonna need a microphone right away, actually. We're co presenting. Yeah. Oh, nothing. Just go with it. Look at that way. Okay.
01:52:51.250 - 01:52:57.360, Speaker F: I support that. Sounds wonderful.
01:52:57.440 - 01:52:58.230, Speaker A: Thank you.
01:52:58.920 - 01:53:24.350, Speaker F: All right. Appreciate it. No, I told him that you're able to be closer, so feel free to interrupt anything. Okay. Disconnection. Oh, yeah, it does. I'm just moving things around, so.
01:53:30.160 - 01:55:08.354, Speaker A: Thank you. Like it's. It's going to be a wait.
01:55:08.552 - 01:55:39.188, Speaker F: They said to wait. Moment. Good to go. All right. Hi, everybody, and thanks for tuning in, especially if you're on the live stream watching this from down in the hacker area or across the pond, as they were saying earlier. So I'm Christine from Scale Labs. Really excited to be at ETH Amsterdam doing this workshop.
01:55:39.188 - 01:56:23.760, Speaker F: The primary goal of the workshop is to, one, explain more in depth what scale is all about and also give you an update about V two from a surprise guest, and then also do some live coding for those that kind of want to follow along using some tools that you should already be familiar with. And if you're not, don't worry, we'll slow it down and make sure that everyone can catch up. So before launching into that, just want to remind everyone about the prizes. We do have a lot of prizes to win today, so if you are going for the grand prize, it's pretty much having the best use case of scale integrated within your application. That means potentially using some of our additional features file storage, interchange messaging, et cetera, et cetera. We'll definitely get into what that is all about later. We also have two other categories.
01:56:23.760 - 01:56:59.010, Speaker F: If you're developing a metaverse P, two E or NFT game, all teams that win this will share up to $5,000. And then for partner integrations, if you see any partners walking around that you want to try to integrate onto scale, you can definitely do that. And you'll share up to $2,000 for teams that are hacking on that. And then last but not least, any team that hacks and deploys an application onto the scale network will split $4,000 among yourselves. So, really excited to see what gets built today. And if you have your phones ready, definitely go ahead and scan that QR code. It will take you directly to the information you need to get started.
01:56:59.010 - 01:57:37.132, Speaker F: All right, so what is scale? So scale is a layer that sits on top of Ethereum that pretty much allows you to speed up your smart contracts and then also removes the gas costs. Now, what's great about this is it fits really well within Ethereum ecosystem. So all the tools that you love that exist in Ethereum automatically works on the scale network as well. You don't have to program a new language. You don't have to change your tech stack. You can simply just migrate everything over to scale using an infura like endpoint, as you see here. And I'll get into how you can actually do that using some tools here.
01:57:37.132 - 01:58:09.944, Speaker F: Remix. We might go through Truffle if we have time, but definitely explaining Web Three and Ether JS as well. All right, so how does this all work? We have nodes around the world, and what ends up happening is when you decide you want a scale chain, we group together a subset of those nodes. We take 16. And what this means is your scale chain has its own environment. It allows you to process transactions, but it also has file storage, meaning that you can store files directly to the blockchain. So let's say you wanted to host your website or stream videos.
01:58:09.944 - 01:58:57.248, Speaker F: You can upload that to the file system and have it just automatically displayed to you because we have an NGNX labor that sits on top of that. Additionally, we have interchange messaging, which is a bridge that connects you between Ethereum and scale. So that means that all of your assets you've already developed on Ethereum, you can migrate them over to scale, or if you haven't yet started, you can start minting on scale directly and migrate them later. Thus by saving even more gas. One of the things that we do is we rotate the nodes ever so frequently. So this adds a layer of protection because I know what everyone's thinking out there, 16 nodes. That may not be a lot, but when you think about the random rotation over time, you can potentially have 70%, 90%, 100% of the network might have worked for your scale chain at any point in time.
01:58:57.248 - 01:59:25.344, Speaker F: And we do this to make sure that nodes can't collude. If you want to learn more about that, definitely come see us at the booth. Our VP of Product, Chadwick, would love to go in detail about that, as well as our BD team. I'm going to call out some few brian, Connor, Fabio, who else is here? Alex as well. Can definitely give you a rundown on all that's involved there. All right, but this is the fun thing. We're a multi chain network and it's one of the first of its kind.
01:59:25.344 - 02:00:12.112, Speaker F: So I know you probably have been seeing the news and you've been seeing other networks trying to migrate to do the same thing. It's really cool to see that other applications are now seeing the value about this and now trying to integrate that within their applications as well. So definitely check to see how we're doing it here because one of the things that's really exciting about this week is we are launching something called the Scalverse, which is basically a V two of the scale network. And what that V two allows you to do is add organization around the scale chains. So we listened to our community and our community submitted proposals, which was amazing, that said that they wanted to band together to create Hubs. So we have Exchange Hubs, which is all your liquidity. We have some amazing exchanges, some amazing partners that are going to be launching there over the next few weeks, as well as Marketplace Hubs as well.
02:00:12.112 - 02:01:09.216, Speaker F: We have Marketplaces that said, hey, we want to join the scale network and provide an ecosystem to where any NFT project or any project that has an NFT can list their NFT on the scale network and have it transact in a free environment. How cool is that? And then lastly, because some of the community, they don't necessarily want to manage their own scale chain, they want to use what's existing, kind of like how they leverage Ethereum. And so that's where community chains come into play. Instead of having to manage your own scale chain, if you just want to deploy your application, we have an environment for you to be able to do that in a Hub like environment as well. But then lastly, there are a lot of the applications out there that have said we want our own chain, we want to make sure that our transactions per second isn't deprecated because of another game or another application running and our speed stays the same. And the only way that that is viable is through a multi chain architecture, which is the thing that we started with our vision from the beginning. And so really excited to see this come to life with scale v two.
02:01:09.216 - 02:01:24.470, Speaker F: But there's so much more to that. And I think Chadwick should probably come up and explain a little bit more. You ready to come up now? I don't have a slide for him, so you're going to have to listen carefully to all the additional features coming into scale V Two.
02:01:26.200 - 02:02:36.124, Speaker G: Everyone, Chadwick here, VP of Product. So just to piggyback on Christine's intro, the key thing with the Hubs and with V Two, we've taken the interchange messaging agent, which is the native bridge deployed on scale chains. And for several months that's been operating very well between ethereum and scale transacting and transferring tokens and arbitrary messages between ethereum and scale. And now that we've expanded that to basically help promote and drive the scale verse, the sort of Hub and DAP chain communication model by allowing any two scale chains to transact tokens or messages, basically sending tokens and messages between any two scale chains with the same bridge layer that we have using BLS signatures. But the key thing here is, okay, it's a bridge, but it's a bridge that can transfer tokens between any two scale chains in a gas cost free gas environment. So you don't pay any gas fees transferring tokens between any two scale chains. And the resolution time between any two scale chains is very fast.
02:02:36.124 - 02:03:20.776, Speaker G: It's 18 seconds. So we've taken that bridge from Ethereum to scale and applied this between any two scale chains on top of this. We didn't stop there. V Two includes this, but also includes what we call an RNG endpoint. It's very difficult for solidity developers to find a really good source of entropy to drive the randomness of maybe NFT properties, lottery design, or other deeper functions that you'd want to do in smart contracts. There are other options out there, like VRFs and other options as well. But we decided on scale because of the uniqueness of our architecture and how we use BLS threshold signatures amongst the nodes that comprise your scale chain.
02:03:20.776 - 02:04:21.200, Speaker G: We're able to leverage this in a very easy way to allow developers to basically call a pre compiled contract on each skill chain that delivers a random number for every block that's created. It's a really easy way. It doesn't create any external calls that you have to do. It's basically a very simple assembly code that you can copy and paste in a contract and integrate very easily. We also have an Oracle API. We have the base layer available. Now, we're finishing a few aspects of that, but it'll allow basically any developer to create an RPC call or an RPC call to any external off chain data and then allow the scale chain, the nodes in the scale chain to request that data from off chain and bring that inside, come to an agreement about what that off chain data is, and then present it for available verification and solidity.
02:04:21.200 - 02:04:27.728, Speaker G: And then did I forget anything? I think that was it. Yeah, that's it for V two.
02:04:27.894 - 02:04:54.632, Speaker F: Yeah. So, scale chain transfer. Oracles ring. Oh, my wizard of Oz. So, it's pretty exciting, though, I think we're really excited for the scaleverse because it's really just showing the power of a multi chain network. And I really want to stress that multi chain network started from the beginning, vision number one, and we're really excited to see it evolve into what it is today. With that Oracle piece, though.
02:04:54.632 - 02:05:43.652, Speaker F: I think we're really excited because we do partner with other I think, you know, giving developers the option to have an Oracle that's native to the chain I think is also unique because when you think about what the scale network is trying to do? It's not just creating another blockchain. It's creating a blockchain with a platform of features. So, file storage, the Oracle RNG, the list just goes on. Machine learning, which was something that we sunset it, but we had before. It's really exciting to see scale Labs, Labs scale L2, develop amazing things over and over and over again. All right, so now I think it's really cool to take a step back and see what cool things can you build on scale. And with fast finality, no gas fees and high throughput, it feels like the possibilities are endless.
02:05:43.652 - 02:06:02.940, Speaker F: And we didn't build a blockchain that was just for NFTs. We didn't build a blockchain that was just for games. We built a. Blockchain for every application out there. And that takes time to build. So where we are today means that now the applications can take the features that are there and build these really cool applications. So with Fast Finality, we were able to deploy Oracles.
02:06:02.940 - 02:06:43.724, Speaker F: But other Oracles could also create on this modular system as well. Media paywall authentications. The no gas fees mean that NFT projects can launch their application without having to raise a lot of capital first. They can simply launch their application, prove product, market set, and then move forward from there. And that's a game changer when you think about how things currently operate in Ethereum Ecosystem, being able to just launch your application or your dao without having to figure out how to pay the high gas fees and then high throughput. One of the things that we did at one of the ETH conferences a couple of years ago was we took Unity, we took one of their templates, we put it on scale and saw how it worked. And it worked extremely well, extremely fast.
02:06:43.724 - 02:07:20.824, Speaker F: And one of the feedbacks that we always get from game developers is that when they use a scale network, they can develop for their application and not for the blockchain. And that's a different way of thinking about approaching development. So really cool to see all these different applications that you can develop. Now. What are some applications that have developed on us? Well, Ruby Exchange is a really great partner of ours is going to be launching one of the first exchanges within scale network. And what's cool is that Liquidity Hub that I talked about, the organization, they're going to be at the forefront of that, making sure that you can bring Liquidity in and out very seamlessly. They're really good with marketing, as you can see.
02:07:20.824 - 02:07:54.476, Speaker F: That's one of their videos. Very flashy, very amazing. But what I'll do though is actually show you their application and let me come here. So this is the Ruby application and it's just on the test network for now because they're going to be launching in the next few weeks. But what's really cool is that they're allowing developers to easily bridge over current standardized tokens. USDC, USDT, the list goes on. And if you want to add your custom token, they are a great partner to make sure that you can do that within the scale network.
02:07:54.476 - 02:08:24.104, Speaker F: They've also integrated with our Faucet to distribute Sfuel. And I know I haven't talked about that, but I promise I'll bring you up to speed on that in just a bit. But this Faucet makes sure that anyone that doesn't have permission to process transactions on the scale chain can do so. And I think that was a really cool way of how they integrated that within their application. What are some other applications that have developed? Ivy Cash. This is a really great NFT project. You don't have to have a wallet or understand blockchain to be able to get an NFT.
02:08:24.104 - 02:09:16.008, Speaker F: And they prove that by allowing anyone to create a QR code, present it on a screen, add a game or anywhere, scan that QR code, and simply have an NFT show up in your wallet that's created for you. And so that's a different model than saying, hey, how about you download an application here, understand blockchain, make sure you save your private key, and then, oh, make sure you then change to the correct endpoint. They remove all of the friction for their end users. And so when you think about creating an application with design in mind, using an application such as layer two, that is scale, allows you to do that and achieve that because, again, we have a no gas environment. The last one I'll talk about is going to be Clut Name Services. What's cool about them is that they built an application that allows you to reserve your name. So it could be Christine ETH, it could be my daughter's or her ETH.
02:09:16.008 - 02:09:46.372, Speaker F: It could be Chadwick ETH. But essentially, when you reserve that, it then actually resolves to the wallet address. And they have a really great API as well. So they have two sides of their product. One side is for users to actually get their names, reserve them, and be able to attach it to their wallets. The other side is for DAP developers to integrate that within their applications. So they have a fully fledged built out API that allows you to do that, but not just integrate their name service, but ENS and unstoppable domains as well.
02:09:46.372 - 02:10:16.220, Speaker F: They're covering their entire suite of domain name servicing, which I think is a really awesome way of using scale as well. So when you're buying your names on their application within the scale system, it all happens in the background. The user doesn't have to know that they're on scale, they're just simply there. They're buying their name with a credit card, and that is it. So, again, another great use case for Usability. All right, we're finally at the live demo portion. I hope I didn't kill you by slides.
02:10:16.220 - 02:10:32.276, Speaker F: Looks like I didn't. Everyone's still up. Everyone's still looking this way. That is great. Do I have developers in the room or are we here to watch? I know I have developers out there that's watching on a live stream, but I can't talk to you. So developer. Okay, one, two, three.
02:10:32.276 - 02:10:52.716, Speaker F: Ish three. Okay, three. Three in the room. That's good. So in that case, what I'll do is I'll kind of go through a little bit of the coding aspect of scale because I think it's really cool to see how seamless and how easy it is to get up and running. All right, so I'm going to switch back here to my lovely browser. We're going to exit out of this.
02:10:52.716 - 02:11:25.792, Speaker F: Goodbye, Ruby. We still love you. All right, so the documentation portal and I would back up just a bit because there's a lot of information on here. You can thank again, Chadwick, our VP of Product, for organizing all of this and making sure that everything's ready for the scale V two launch. But if I navigate here to develop, there's a plethora of information on how to use again those existing tools that I promised you guys or just deploying to the scale network. If you already know what to do, you just want to go it alone. But let's use something that most developers are familiar with, remix.
02:11:25.792 - 02:12:05.904, Speaker F: A lot of developers have used this. You've come across this in some capacity for just simply deploying a smart contract. Well, what you'll see here is that all of these tools have step by step instructions on how to use that with the scale network. And one of the things that reigns true with most of these is that the deployment or the usage of these is just as simple as changing an endpoint. So if I go to this MetaMask example here there you go, just changing an endpoint portis. Same thing, simply just changing an endpoint. And I think because of the way the Ethereum space has evolved, all tools that are building within that space makes it so that way you can integrate with other layers outside of Ethereum.
02:12:05.904 - 02:12:28.140, Speaker F: And it's shown here. Now, for Remix, it's more or less the same. You can take this example, smart contract, copy it into Remix and just run it by deploying on the scale network. So let me show you what that looks like if I click on this link. Actually, let's back up. I'm going to open it into a new browser tab. All right, perfect.
02:12:28.140 - 02:12:51.510, Speaker F: We have a simple smart contract called Hello Scale. Super simple. But one of the things that you'll know is that you could always connect it to MetaMask by switching it to Inject. It web3. And here we're on MetaMask. I'll switch it back to Ethereum network. But because we're at the hackathon, if you go to Oops, let's not open that.
02:12:51.510 - 02:13:43.510, Speaker F: If you go to Ethamsterdam scale network, this will give you all the information that you need for getting a scale chain endpoint and accessing a faucet while you're at this endpoint, as while you're at this conference to be able to get it going. So if I click here, there are two scale chains available and I'm going to select the first one. Now, I can go the manual way of copying this open MetaMask and adding it to my list of networks. Or I can do it the automatic way, which is click on this button here and it'll automatically add it for me. Now I'll go ahead and switch networks, and what I want to do is jump back just for a second to the documentation. Because if you want to understand exactly how we created that button, all of the code for doing that is simply here. You can copy paste and just have it work.
02:13:43.510 - 02:14:31.520, Speaker F: So I'm going to go back here to remix. And now that I'm on the scale chain, as you can see, I don't have any SK ETH, which has been rebranded to S Fuel, actually. And S Fuel essentially is a token that exists on a blockchain just to prevent DDoS attacks. It has no monetary value, which means you can use it as an authentication mechanism. So if I come back here, and I'm going to go back and back up a little bit, and what I'll do is, let's see, I'm going to copy this endpoint, paste it here, then I'll come here and get my wallet. Okay, super simple. Paste that here and then simply click on Get S Fuel.
02:14:31.520 - 02:15:04.776, Speaker F: What this basically shows you is just a faucet mechanism for setting up distributing that S Fuel. You can just as easily distribute Sfuel the moment you recognize this user when they log into MetaMask. But now that I have Sfuel, I can go back to remix and simply deploy the smart contract onto the scale chain. All right, just want to make sure everything's connected. As long as this green light is going, we're good to go. And let's go ahead and click Deploy. One of the things you'll notice is just how inexpensive it may seem to deploy the smart contract.
02:15:04.776 - 02:15:39.480, Speaker F: And that's by design, because, again, it's a gas free environment. But we still want to make sure that no one can DDoS you. And so over time, if someone is trying to DDoS you, this number will simply increase by a predetermined number until they've run out of Sfuel. And you can decide just not to top them up, which means they're blocked from running transactions on your blockchain. Now, if I confirm this, that'll do what you expect will happen in any blockchain. It deploys a smart contract to scale. And from there, I'm able to transact with it just like I would if this were running on Ethereum.
02:15:39.480 - 02:16:27.400, Speaker F: And so, just as I promised, very simple to transfer over from Ethereum to scale. Now, one of the other things that we can do is let's check out one of those really cool features that Chadwick mentioned. I like the idea of checking out the RNG endpoint one, because I think the documentation is really well done, where you can simply copy, paste, run. Now I'll copy this and I'll come over here and I'll paste this here. Let's go ahead and save that good. Looks like it's already compiled. And I'll delete that one, and we will simply redeploy.
02:16:27.400 - 02:16:59.994, Speaker F: All right, give that a moment. And this is that random number generator that Chadwick had mentioned. What's cool is that in scale V two, this is going to come standard on every blockchain. And so one of the things that we kept getting asked about is that with scale being a costless environment, do you guys have a random number generator? And if so, can we use it. Do you have Code Snippets? Well, we took it a step further. We don't just provide you the code Snippet. We provide it standardized with every blockchain.
02:16:59.994 - 02:17:27.904, Speaker F: So you can just simply access it. And so every time I click on get random, every time there's a new block, a new random number is presented to you. So a really cool way of using one of the new tools that's coming out in scale V two. All right, so before continuing on, I will pause if anyone has any questions. Straightforward so far. Everyone's following? I see nods. I see nods.
02:17:27.904 - 02:18:08.586, Speaker F: Okay, no one's sleep yet. This is great. I know it's midnight. All right. So again, I think the main thing I want to drive home here is just the simplicity of using the scale network, but also the complexity of the features that we have available. And one of those complexities, I think, is drawn out in interchange messaging. So if you're here building a token and you want to make sure that it can transverse between different chains or different blockchains between ethereum and scale or reverse from scale to Ethereum, this is the documentation that you want to land on.
02:18:08.586 - 02:18:51.482, Speaker F: Now, there's a lot here. We have support for all of the major token standards ERC 20, ERC 721, ERC 1155, and then any custom smart contract. Now, that is very unique because a lot of the bridges out there only support ERC 20. But with the support for all of these, what that means is that you can really transfer any asset to scale, even as far back as CryptoKitties, or create any new standard and simply have it work within the scale network with being able to transfer that back and forth. Now, we have some really cool diagrams here that help you just sort of understand what the flow looks like. So you're not going on this alone. I'm a visual person.
02:18:51.482 - 02:19:38.882, Speaker F: I hope you are, too. And so having a clear way of understanding how to move a token between the different chains is extremely helpful. And that Minting first methodology that I mentioned is down here, where we give you a simple flow of understanding how to first mint an NFT or any asset on the scale network and then move it to Ethereum after the fact, thus by saving you even more gas. So I encourage any blockchain project that's looking to hack at this hackathon to try it out. This would be a really cool way of integrating it within your NFT project, your P two E game, or your Metaverse application. All right, let's go back here. All right, one last thing, since we have everyone's attention.
02:19:38.882 - 02:20:20.374, Speaker F: We do have $100 million in USD for Ecosystem Grants program, and that's going to be specifically for gaming. So if you're here building a game, definitely come talk to us. That way we can see where you are in your development and to see if we can get you into this grant program. But it looks like we had a question before I concluded. Use the scale chain to scale chain bridge. How would you use it the skeleton to scale chain bridge? I'm actually going to go back here because I think let me show this one. All right, great question, by the way.
02:20:20.374 - 02:21:52.050, Speaker F: And the question was for those that are viewing this, how would you use a scale chain to scale chain bridge? The best way to think about that is let's first explain the layout here we have these exchange hubs which are providing liquidity, meaning all liquidity is coming into that one chain and other chains that are creating complementary like exchange hubs as well. We have NFT marketplaces which means that all NFTs are going to be viewable within one endpoint, one chain, which is great for developers because things are able to be shown in collections, which is very important if you are building NFT project. And those community chains where we have a lot of applications that want to share space because they don't necessarily need 70GB for storage or 200 transactions per second for their medium chain, they just want a small subset of that. But if you're going to be launching on your own chain or one of these hubs, how do you communicate between chains and when does it make sense to do so? Well, as you can imagine, if you are launching your Pte game or your Metaverse game or your music application, you are in your own ecosystem, your own container, which means that you might need to bring liquidity over. Now, you can go this on your own and use an interchange messaging bridge, bring it from ethereum, or you can take advantage of the free transactions per second and scale and simply go over to the Ruby Exchange that exists on exchange hub. And when you do that, you would use the scale chain to scale chain bridge to be able to make that connection between your chain and that exchange hub. It's going to be extremely fast.
02:21:52.050 - 02:22:40.722, Speaker F: Everything processes in 18 seconds or less. But what that means is that you're able to bring over the pairs that you need for your game, for your NFT, for anything that you're building, whether it's a stablecoin, whether it's ethereum, whether it's scale, it could be any token that you want to use or any custom token that you want to use. So the normal flow is going to be bringing the liquidity that already exists in the scale ecosystem over to your chain. But there are some edge cases there. And one of those edge cases is if you're creating your own custom token on your own chain and you want that listed on the exchange, you have the same flexibility to use that same skeletal chain to skeleton transfer to push your token to the exchange. That way it's listed for anyone else in the ecosystem to pull down later. So a really cool way of spider webbing this together in a really organized way.
02:22:40.722 - 02:23:49.730, Speaker F: And yeah, the skeleton and scale chain upgrade that's happening this week, actually, you'll be able to start playing around with that relatively soon. Can I store my files in another chain and use one for block data? Okay, so the next question is for file storage. Can I store my file storage, my files in another chain and use another blockchain for the data of the application? Is that correct? The answer to that is yes. I think one of the things that the community realized immediately when Skell said that we were going to launch this multi chain architecture is, oh, I can have five chains for my application and then use them from different modules within my application. And that was a really cool way of thinking about it. And so yes, if you wanted to use one chain for launching your token or running your game or running your application, you can do that. But let's say that you wanted to store all of the files that were going to be accessed for being used within the game or used on your website, or used for machine learning or used for any application.
02:23:49.730 - 02:24:27.602, Speaker F: You'd be able to have another chain that runs side by side to that. And so what's really great is that it means that you can scale horizontally. You're able to start with one chain. And as you need more space, you can either upgrade from a medium chain to a large chain because we offer different types, or you can say, hey, you know what? I simply just want a new chain altogether so that way I can double my storage all at once and maintain the same transactions per second, because I might not need more. 200 is enough. Especially when you think that 200 for one application versus 200 for 500 applications. As you might see in some other networks, that's a different conversation.
02:24:27.602 - 02:24:44.860, Speaker F: When you are on a dedicated chain and you have all of your services just for you, you can think about using those services, not worrying about the fluctuations that anyone else might cause. Yeah, you're welcome. Any other questions?
02:24:48.350 - 02:24:55.694, Speaker D: The IMA bridge, are all the chains sharing one IMA bridge over to the main net or do they have their own?
02:24:55.892 - 02:25:54.330, Speaker F: Yeah, so with the IMA bridge, because each scale chain is only environment, they all have their own smart contracts there, right? And so they connect to the smart contracts between ethereum and scale. But yes, the buckets that you would transact with on the scale chain side are all going to be your own. On the ethereum side, it is going to be a shared environment, but that is really well separated, if you will, based off of the chain that you're interacting with. And so, as you can imagine, that design was put into place to make it easier for scale chain to scale chain transfer. And also ethereum to scale transfer. But yes, essentially on the scale chain, you have your own bucket, your own smart contracts, and what's great is that you don't have to think about deploying these. Everything comes pre deployed, pre compiled, and so, as you can imagine, what that means is an easier way to understand how to connect this on each and every scale chain.
02:25:54.330 - 02:26:34.730, Speaker F: If the contract address is going to always be the same on all the scale chains, you don't have to think about keeping a mapping of that, which I think is a great way of approaching creating the entertainment messaging protocol. So good job, engineering team who's not here, but here in spirit. And we're really excited. Any other questions? All right, well, with that, I'm going to conclude the session, but if you have any questions, definitely come see us at the booth. We'll be around tonight and tomorrow tomorrow there's a special event. I can't tell you what the special event is, but come see Ryan. He will definitely explain that to you.
02:26:34.730 - 02:27:08.180, Speaker F: It's going to be great, but definitely come hang out with us and learn more about how to deploy your application onto scale. And before I go, I will just show this last screen here for those, again, watching this, virtually, definitely go ahead and scan that QR code or simply just put this URL in your browser. Again, we have 16,000 in prizes to be won, so definitely hack with us because at the very least, if you simply deploy, you have the possibility of winning that 4K prize that will be distributed among all teams. So at least give it a try. All right, thank you.
02:29:04.200 - 02:41:01.520, Speaker A: Sam. Sam. Sam. SA sam. Sam. Sam. Open.
02:41:01.520 - 02:53:23.198, Speaker A: Sam. Sam. Sam it. Sam it's. Sam I'm don't sam. Sam. Sam.
02:53:23.198 - 02:55:32.680, Speaker A: Sam. Saiya sam it.
02:56:45.090 - 02:57:27.294, Speaker D: This is deployed optimism. 0.5 seconds, your money back. The first, like, five minutes of this talk are going to be me talking about how to deploy, and the second 40 minutes of this talk are going to be talking about optimism in general, trying to answer architectural questions about what's going on under the hood. So this should be pretty quick because it's very easy. If you were working on optimism, maybe about a year ago, you would have known that optimism used to be really annoying to deploy to because we had this custom compiler and it was a total nightmare and made people really annoyed. So we got rid of it.
02:57:27.294 - 02:58:08.010, Speaker D: And I'll talk a little bit about how we got rid of it, but for now, the reality is it's really, really easy to deploy. Anything that runs on Ethereum should run on optimism one to one. The gas is all the same, the contracts are the same, it runs the same bytecode, you can use solidity Viper, whatever you want, works really well and we spent a lot of time trying to make that happen. So deploying with Remix is very simple. First you got to add your network, the optimism network, to your wallet. So I made this website called Chainid Link. And you go to this link, chainid link, question mark network, equals optimism.
02:58:08.010 - 02:58:20.882, Speaker D: And hit connect. And of course, I probably have signed up. No, there we go. Oh, it's because I'm already connected, so, whatever. I'll sign up to something. There we go. Okay.
02:58:20.882 - 02:58:21.202, Speaker D: Right.
02:58:21.256 - 02:58:21.614, Speaker C: Boom.
02:58:21.662 - 02:58:29.320, Speaker D: Connect to optimism. And I'm connected to I guess this should be optimism. Whatever.
02:58:29.690 - 02:58:30.150, Speaker E: Cool.
02:58:30.220 - 02:58:57.070, Speaker D: All right, so you do this with whatever wallet you have, connect optimism, and then go to Remix and write your contract. And I have a simple contract here that doesn't do anything. It doesn't matter. This is simple, but can be as complex as you want. Save it. Connect MetaMask to your injected web3 provider. And that's it.
02:58:57.070 - 02:59:10.914, Speaker D: Just deploy. And what is this? This is on main net. So there you go. Deploying on main net. That's it. It's easy. It's the same thing.
02:59:10.914 - 02:59:24.226, Speaker D: It's really simple. Just like deploying onto Ethereum, except it's faster and cheaper. Okay, go back to this. Doing it. So with remix. Pretty straightforward. Hard hat.
02:59:24.226 - 02:59:39.046, Speaker D: Also very straightforward. Same general concept. Just add optimism to your network config and deploy. I do have a very brief example of this. Straightforward. Look at me. This is my network config.
02:59:39.046 - 03:00:06.194, Speaker D: That's all. I Daddy. I just added an optimism network, and then I can deploy my contracts. So I have my adder, same thing as before. I have my deploy function, same thing as before. And deploy if it'll ever deploy. There we go.
03:00:06.194 - 03:00:17.266, Speaker D: That was easy. Okay, that's it. It's the same thing. This is why this talk is really boring. It's just showing you how to deploy a contract. Same thing with Truffle. Literally just the same thing.
03:00:17.266 - 03:00:32.842, Speaker D: You just add optimums in your network config. Maybe I can share the slides later if you want the link to this. But very straightforward. Same thing with Brownie, except you don't even need to add it to the network config because it's in there already. And that's it. That's literally all it is. This is not a very interesting talk.
03:00:32.842 - 03:00:47.390, Speaker D: So I will talk about the more interesting side of things, which is how optimism can actually be this easy to use, which is as a result of this concept of EVM equivalents.
03:00:49.330 - 03:00:49.982, Speaker C: Which is.
03:00:50.036 - 03:01:56.290, Speaker D: Sort of a stronger form of EVM compatibility. Where this trick is, the EVM is a very delicate beast. And every time you change the EVM a little bit, you can say that you're compatible because you're compatible with all the RPC endpoints. But if you change the behavior of the EVM, all of a sudden you get into sort of a weird state where you get developers who are relying on some very small feature of the EVM and you've told them that you're EVM compatible, but then this one feature of the EVM doesn't actually work. So are you really EVM compatible? I would say no, but because so many people have said, oh, I'm EVM compatible, that we've come up with this new idea of EVM equivalents where you're essentially just running an EVM that is like a production EVM that's being used to run the Ethereum mainnet. So it's the same exact virtual machine, and you can actually take this EVM and really run like a main net node with it. In this case, we're using Geth's EVM to do this so our client runs Geth.
03:01:56.290 - 03:02:18.134, Speaker D: Okay, let's sort of describe at a high level why is this okay, let's describe at a high level how this whole system even functions, because it's quite interesting. You have your layer one oops, there you go. You have your layer one. And your layer one is pretty you know what that looks like? It's a blockchain.
03:02:18.182 - 03:02:18.682, Speaker A: Right?
03:02:18.816 - 03:02:47.894, Speaker D: And then what we have is these two components. We have this thing called the op node. The op node. And it pulls transaction data from layer one, sort of just like, pulls in layer one blocks. And from these layer one blocks, it deterministically generates a list of layer two blocks. And then it takes these layer two blocks and it executes them. At this point, you just have like a blockchain on layer two, and it's fully derived from layer one.
03:02:47.894 - 03:03:24.618, Speaker D: So just like a pure function on layer one blocks that generates layer two blocks. And then you need to execute those blocks. So executing the blocks just happens in Geth. We take Geth, and Geth has this very beautiful API called the Engine API, which is sort of a new thing for the merge. But what it allows us to do is to treat Geth like a thing that can be driven. After the merge, you will no longer have the execution and the consensus. Parts of Ethereum are being split into two pieces.
03:03:24.618 - 03:03:53.900, Speaker D: So you have the part that executes blocks and you have the part that figures out what those blocks should be. And we sort of realize, oh, well, we can actually apply the same exact idea to layer two. Why not? You get the blocks from layer one. That's the consensus. And you do the execution in this execution client. So in this case, the block execution literally just happens in Geth, which gives you this perfect EVM equivalence because you're not doing any sort of weird translation into a different virtual machine. You're just running Geth so everything just works how you would expect it to.
03:03:53.900 - 03:04:30.198, Speaker D: Okay, first of all, before we do that, does anyone have questions? I guess it's a workshop. It's kind of like a lecture. All right, well, if people have questions, just stop me. We could do the whole microphone thing. Let me move this up. Okay, so this is there we go. Okay, so part of the safety of an optimistic roll up is sort of the ability to prove let's go a little back.
03:04:30.198 - 03:05:06.740, Speaker D: Essentially, if people aren't familiar with the. Idea of an optimistic roll up. You're publishing transaction data. You take transaction data from users, you sort of bundle it together and you publish it to layer one. And then what you're also doing is you're executing these blocks and you're generating the results, right? When you execute a block, you get a resulting state route that says, this is what the state of the system is. You get a bunch of sort of information about the state of the system and we execute a bunch of blocks. And then after a certain number of blocks, we take the state route of that block and some other information about it and we publish it to layer one.
03:05:06.740 - 03:05:46.430, Speaker D: And the idea is that if we've published this data to layer one, then contracts on layer one can actually start to make decisions about what's going on on layer two. You can use like merkel proofs to basically prove something about the state of layer two, given one of these sort of checkpoints, and it allows you to do so. Deposits into a roll up are very, very easy. It's just a transaction on layer one. And this allows you to do withdrawals from a roll up because you can do a proof that says, I can prove that. Let's say you burned this amount of money on layer two. I can prove that to you because I have a merkel proof, but I can only do that if I have something to do a merkel proof against.
03:05:46.430 - 03:06:28.202, Speaker D: And that's what these checkpoints are. So we do these regular checkpoints that get published to layer one. And this gives something that contracts on layer one can execute a proof against so that they can make decisions about what happened on layer two. And this gives you deposits and withdrawals. But the question is, how do you actually guarantee that this thing that is being published to layer one, this state route or this output that's being published to layer one is actually correct? Because it could just be anything. I mean, the whole point of the optimistic roll up is that you are not performing the execution of transactions on layer one. So Ethereum has no clue if the execution result is correct.
03:06:28.202 - 03:07:08.680, Speaker D: You're kind of just telling it this is what the result was, but it doesn't have any proof of this. So what we want to do is we have a program that we're running and we want to prove that that program ran correctly, right? We want to take this now I'm getting these sort of mathematical stuff, but it doesn't really matter that much. We have a program and we want to prove that the program ran correctly. That allows us to say, based on the transaction inputs that we've published to layer one, the output the state route that we published to layer one is absolutely correct and it can't be wrong. So how do you do this proof? Well, whatever you have a program.
03:07:10.430 - 03:07:10.746, Speaker E: What.
03:07:10.768 - 03:07:34.526, Speaker D: Does our program look like? Our program, it takes L one blocks. It generates l two blocks. Then it executes those L two blocks, and then that finds that final state route from the last L two block. It's a very simple program. And then, more generally, what is a program? Because it's important. We have a machine architecture. It can be whatever we want.
03:07:34.526 - 03:07:52.786, Speaker D: It can be like X 86, or it can be something even simpler, or it could be the EVM. And then we define operations within that architecture. Essentially, we have Opcodes. Right. So the EVM has a bunch of Opcodes. X 86 has Opcodes, blah, blah, blah. And it's a series of operations, right? And this is universal.
03:07:52.786 - 03:08:30.900, Speaker D: Like, this is sort of what a program fundamentally is. And what we're really trying to prove is something about a series of execution steps inside of this machine architecture, right? It could be the EVM. We're trying to prove this Opcode happened, then this Opcode happened, then this Opcode happened. And I actually executed those opcodes correctly. So we have this series of steps. The EVM is fully deterministic, right? So given a starting state and the EVM, everyone gets the same result. This is why this entire blockchain thing even works.
03:08:30.900 - 03:09:04.702, Speaker D: And we want to prove that we ran, let's say, the EVM correctly. So we sort of want to prove the correctness of this trace of you just think about it. The list of execution steps. That's what I mean when I say a trace. Just the list of things that happened except on Ethereum. We don't want to re execute every single step because if we wanted to re execute every single step, we'd be wasting a huge amount of gas. And it'd be really, really expensive because the whole point of the optimistic roll up is to sort of not have to do all this work.
03:09:04.702 - 03:10:03.214, Speaker D: And you really don't want this proof process to be executing an entire Ethereum transaction because it's really hard and really expensive. The question is, how do you do something like this with the EVM? Because it's a very complicated program. The answer is, well, either you go and you build an EVM interpreter in the EVM, which is a huge amount of effort and it's not worth it, or you can just do something much cleverer where you take your program and you compile it into a much simpler machine. So our program here is Geth, which is sort of like a slight wrapper around the EVM. And then we have these little other parts that I talked about, figuring out the L two blocks and figuring out the final state route. You can kind of think of that whole thing as your program. And what you're going to do is you're going to compile it.
03:10:03.214 - 03:10:24.470, Speaker D: So you're going to compile it into a simpler architecture, right? I mean, you can compile Geth, right? This is a thing that people do. So you take your program, you compile it into a simple machine architecture. And if we want to get an execution trace out of this, we run our program. It's a compiled binary. We run that with some input.
03:10:26.410 - 03:10:26.726, Speaker A: And.
03:10:26.748 - 03:10:52.058, Speaker D: We run an emulator. And at every step we sort of record what the state of the machine was. So we take what is the state of this virtual machine at step zero? Okay, the memory is this. The program counter is this. The stack looks like this. You take that, you take a snapshot of it and you do that process for every single execution step. So you can't really execute this whole thing on Ethereum.
03:10:52.058 - 03:11:14.690, Speaker D: A single transaction generates a massive execution trace. So you could, I guess, do this proof by just executing every single step on Ethereum and seeing what the result was. It should give you a result. It's a machine, a virtual machine. You can run it on Ethereum just like you can run pretty much anything else on Ethereum. So you can run every single execution step on Ethereum. But it would take forever and it would be really expensive.
03:11:14.690 - 03:12:05.990, Speaker D: So you don't want to do this. You instead introduce this idea of Bisection games. And this is sort of what Trubit really pioneered years ago and getting into some more annoying mathy terms. But you don't need to know about it. The idea of the Bisection game is that if you think about your program as a series of execution steps and you say that the starting step, step zero, is based on a known state, we all agree on step zero, but we disagree. And we agree on step zero because we must have if you think about it from the optimistic roll up standpoint, let's say that each one of the things corresponds to a block. If I'm challenging block N, it's because I disagree with the result that was published for that block.
03:12:05.990 - 03:12:44.766, Speaker D: But doing that is sort of an implicit statement that I agree with the result of block N minus one. Because if I didn't agree with the result of block N minus one, I would have challenged N minus one instead. So you can follow this logic backwards and backwards and backwards. And the idea is that you should be incentivized to always challenge the first thing that you disagree with because you should just challenge the earliest thing. Because if you wipe whatever the point is you're going to challenge the earliest thing. And so we agree on the starting state because the starting state is the output state of the previous block, which we agree on. So we agree on the starting state, but we obviously disagree on sort of the ending state of running this virtual machine.
03:12:44.766 - 03:13:23.310, Speaker D: And we have to figure out which one of us is right. And if you sort of think about it, if we agree on the starting state but we disagree on the ending state, then at some point in the middle. There must be some step where we agree on the previous step, but we disagree on the next one. I could prove it, but it's sort of intuitive. At some point, you got to a point where you disagree. So you want to find out how can you find this first execution step where you disagree? Because if you can just get down to executing a single execution step, that's very, very cheap. And you can do that on ethereum, no problem.
03:13:23.310 - 03:14:14.100, Speaker D: So you want to figure out how you and your sort of your adversary can the person who published this result or this output, this claim about the state of layer two, how you two can sort of play a game and figure out where this first disagreement is. And the process that we do is we generate our execution traces and we generate a snapshot of this machine state at every single execution step. And then we turn that trace, sort of we hash that snapshot and then we generate a merkel tree out of it. So if you think about the machine starts here and then the machine goes into its next state. And remember, this is all deterministic, right? The machine just operates on a state and it produces some output state. So you go from step one to step two to step three. And at each point you're taking a snapshot and you're hashing it.
03:14:14.100 - 03:15:03.470, Speaker D: And then you generate this big merkel tree out of this array of machine states. And so then you want to try to find you and like I said, your adversary are trying to find the first step that you conflict on. And so what you do is you start making your way down the merkel tree and you look at each route and you say, do I agree with this route, this intermediate node of the merkel tree, or not? At this point, let's say we've gone down the merkel tree and we say, okay, we disagree on both sides. Remember, this is in order of the execution. So this means we disagree on the second half of execution and we disagree on the first half of execution, somewhere in the first half. So we always want to find the earliest step. So we're going to start thinking about the first half of the execution.
03:15:03.470 - 03:15:37.500, Speaker D: And let's say, okay, we agree. We sort of go down here and we agree on the first two steps. We agree on this route, but we disagree on this route. And so if we agree on this route, that means we agree on these two execution steps. We agree here, we agree here because we both have the same thing in our little merkel trees that we're comparing, but we disagree here. So now the question is, do we disagree here because this is different or do we disagree here because this is different because they're both part of this intermediate node. And then maybe as an example, you say, okay, we disagree because this is different, but we actually agree on the contents of this.
03:15:37.500 - 03:16:32.270, Speaker D: So by doing this game, we just go back and forth and we compare our trees and we try to find the first node in the merkel tree where the hash is different. And that first node in the merkel tree where the hash is different represents or the first leaf node in the merkel tree represents the first execution step where you agreed on the previous step but you disagreed on the next one. So what we're going to try to do is we're going to try to execute this step because you're saying that the result of this step was X, and I'm saying the result of this step was Y, and we're going to figure out which one of us is right. And we're going to do that by executing this machine step on Ethereum. So how do we do this? It's pretty interesting. We literally just built a machine interpreter in solidity. So we deliberately picked a very simple virtual machine called or just simple machine architecture called MIPS.
03:16:32.270 - 03:17:06.454, Speaker D: And it's about 400 lines of actual solidity code. So you can actually see, like, a VM interpreter on chain for very little code, which is really cool. So just to reiterate the full challenge process, in a nutshell, someone publishes a proposed version of the l Two state. This takes the form of a hash. Then somebody else comes in and challenges that state. And then the proposer and the challenger play this game where they go back and forth and try to find the first step where they disagree. And so you find that step.
03:17:06.454 - 03:17:47.000, Speaker D: So one of them now executes that machine step on chain, literally just like a virtual machine instruction on chain. And it's just a program. Like a machine architecture is just a program itself that takes instructions and generates some output. So you execute it. Then Ethereum knows who's correct because Ethereum is the one doing the execution, so it knows who wins. And if the challenger wins, then the state proposal is invalidated. So this means that somebody else has to come in and say, actually, this was the correct result of executing that block on layer two, or whatever it is, and then whatever.
03:17:47.000 - 03:18:16.926, Speaker D: So optimistic roll ups are a solved problem. I think this is actually very true. They're complicated, but not really in a lot of ways. That architecture that we were describing is actually very straightforward. The changes that we made to geth are like less than 400 lines of code total. And I could have gone on for way, way longer, but I won't. So we can go to questions.
03:18:16.926 - 03:18:28.900, Speaker D: If people have any questions about optimism, how it works, any of these little there's sort of a lot of jargon in here, but whatever. Yes. Do we have a little extra mic? Okay.
03:18:30.150 - 03:18:30.562, Speaker B: Yeah.
03:18:30.616 - 03:18:40.630, Speaker C: Thank you for the talk so far. My beginner question, I would say, would be like what's the benefit for me to deploy to optimism versus Ethereum mainnet?
03:18:42.410 - 03:19:21.298, Speaker D: Sure, yeah. The primary benefit is just that you're going to get essentially the same exact experience as on Mainnet except it's going to be way cheaper and we could do this by kind of separating the execution like Mainnet you have thousands and thousands of nodes that are executing all these things. Optimism, it's just the people who care about optimism. There's just like a lot less people on the network. So it's just cheaper in general. But yeah, so it's cheaper. We've added some interesting stuff to make it also faster, which is sort of these interesting things you can do when you are a layer two.
03:19:21.298 - 03:20:17.430, Speaker D: You can introduce this idea of a sort of sequencer which is a block producer and the block producer can give you really fast, pretty reliable confirmations and so you get sort of a much snappier experience, you get to see what your transaction did within like a second or two instead of waiting 15 seconds. And when constructed correctly, these things basically give you the same security guarantees as Ethereum with basically one added security assumption, which is that there's a single honest participant watching the chain and willing to perform the challenge process if necessary. So you get basically all the benefits of Ethereum with a single honest party assumption. You're not trusting like a majority of some set of validators just like one person on the network is incentivized properly to do this and it's cheaper and faster.
03:20:18.330 - 03:20:21.378, Speaker C: And you also pay with ETH and gas.
03:20:21.474 - 03:20:23.350, Speaker D: Yeah, you also pay in ETH with gas.
03:20:24.810 - 03:20:25.526, Speaker C: Thank you.
03:20:25.628 - 03:20:33.260, Speaker D: Of course, other questions we'll pass the.
03:20:36.190 - 03:20:59.758, Speaker E: I think we read up somewhere online that one of the sort of subtle differences between deploying on Ethereum mainnet and deploying on optimism is that it says something about being careful about using block times for timings in your contract. Could you maybe just allude to where that comes from? Why the block time is not consistent in optimism?
03:20:59.934 - 03:22:22.906, Speaker D: Sure, yeah. So this basically comes from this block producer that we call the sequencer and it's just that you can't make the assumptions around the sort of what's the word? Like the fidelity of the timestamp are a little weaker than on Ethereum and it's because the sequencer has a little bit of room, you have to give them a little bit of room in when they can create their blocks and so technically the sequencer within certain bounds can manipulate the timestamp. It always has to be going up and it always has to be basically within a certain window of the current actual Ethereum time. But there's leeway for them to go admitted into the future or something like that. Right. You can trust it for many things if you're just trying to keep time over the course of, let's say days or even hours, sort of longer periods of time where that minute or two minute fidelity doesn't really matter that much. But if you expect time to work within very tight periods of time, you sort of have to trust that the sequencer isn't going to try to use that to explicitly mess with your contracts.
03:22:22.906 - 03:22:24.880, Speaker D: It's just something you need to be careful with.
03:22:26.690 - 03:22:29.200, Speaker E: If that makes sense. Yeah. Okay.
03:22:34.710 - 03:22:37.298, Speaker D: How does optimism compare to ZK rollups.
03:22:37.314 - 03:22:41.702, Speaker C: In terms of security assumptions and also speed now and also in the future?
03:22:41.756 - 03:23:19.138, Speaker D: I guess that's a good question. At the moment, optimistic rollups are functional. I'll say they're way more reliable. I mean, maybe except for like StarkNet, which is still in Alpha. I guess one of the main selling points at the moment is that they're very functional. You have different assumptions about the safety. Really it all boils down to whether you want to make the one honest party assumption or whether you want no assumption at all.
03:23:19.138 - 03:24:26.998, Speaker D: And the R1 downside long term of the optimistic world is just that you have this basically you need to give people enough time to be able to actually challenge these state proposals. And so you need a window of time that we call the challenge period where somebody can come in and challenge something. Both of these things, I mean the realistic thing is that optimistic roll ups are still 1000 times easier to build. And so there's sort of like the other side of the security argument, which is like, how secure is it if there's like two people in the world that can really audit it? At what point is it? The more complexity you introduce into your system, the more you're opening yourself up to bugs. It's just sort of like security ends up being this spectrum. And we actually think in a lot of ways, optimistic roll ups end up being more secure, at least now in the long term, like, I don't know, very long term for me, five plus years, you might see ZK roll ups. I actually think that the way to build these systems correctly in the future is to do an optimistic roll up.
03:24:26.998 - 03:25:14.918, Speaker D: And then when these state results are published, these checkpoints are published immediately start generating a ZK proof between the last two checkpoints that have been published. So in the worst case, you get this optimistic roll up. If no one's publishing these validity proofs, it's an optimistic roll up. But when people are publishing the validity proofs, the validity proofs, you don't even need to think about waiting the seven day period. As soon as that validity proof is up, you're able to withdraw. So now it just becomes a problem of optimizing your prover so you can get very, very fast proving times and you can just publish these validity proofs very quickly. And so you cut down on your withdrawal time to be just the length of the proving time.
03:25:14.918 - 03:26:04.500, Speaker D: So I think realistically that the future is probably going to be like a hybrid optimistic ZK thing and luckily, optimism isn't designed in a way you can slap this on the current system and you don't have to change anything. I just think it's, like, overly complicated, is my answer for ZK. Cool. Other questions, comments, concerns, opinions? I think we got, like, 15 more minutes. Or if people are tired, we can just go to bed. All right, I think we're just going to call it. We can just do questions afterwards if people have them.
03:26:04.500 - 03:26:05.700, Speaker D: Cool.
03:26:07.110 - 03:26:07.640, Speaker A: All it.

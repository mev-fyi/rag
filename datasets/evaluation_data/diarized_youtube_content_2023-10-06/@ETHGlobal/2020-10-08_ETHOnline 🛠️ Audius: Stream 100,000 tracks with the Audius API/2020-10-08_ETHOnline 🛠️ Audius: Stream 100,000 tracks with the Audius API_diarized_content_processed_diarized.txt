00:00:00.090 - 00:00:04.880, Speaker A: Seeing the audience API, I'm going to let them take it.
00:00:06.610 - 00:00:56.122, Speaker B: Ray all right, excited to be here, everyone. So, yeah, we figured we would give you just a quick overview on what is Audius and things like that for a few minutes and then just really get it into a very hands on kind of overview of to how to use the API and how to actually build something with these. I'm Ronil. Ray is also presenting here. This is how you can reach us afterwards on Discord and elsewhere if you want to. So, yeah, the very quick like, what is Audius? Audius is a digital streaming service that connects fans directly with artists and exclusive new music. But it does that by being fully decentralized.
00:00:56.122 - 00:02:22.794, Speaker B: So audience is operated by a community of node operators, fans and artists basically, that have come together and chosen to share content here, operate infrastructure here or that type of a thing. The very brief why did we feel this was necessary when artists and creative people more generally have not had the opportunity to own their own means of distribution or have any input into the decisions made around how distribution works? You end up with kind of a very unequitable breakdown of sort of the revenue or earnings that happen, somewhat of a predictable outcome. So by kind of changing the incentives around who gets to vote on changes and control what happens on this thing, that's really the intent behind what we're doing. The product has been live for about a year. Today we see over half a million users every month listening to music nearing 100,000 tracks uploaded. And I'll get into the architecture piece in a minute here, but the product has generated over 1.3 million on chain transactions so far.
00:02:22.794 - 00:03:11.674, Speaker B: So that's for things like uploading content, social engagement with content, things of that nature. These are just some of the artists that use Audience. Kind of mostly electronic music heavy right now, but I imagine some names here that folks might know. And then, yeah, very quickly on kind of the architecture of how does a network like this work? There are kind of three important technical components here. One is this sort of ledger of content that exists on a thing called POA network. It's a ethereum side chain that I think actually they're also in this hackathon. If I recall correctly, the team that made POA network also made Xdai and the stake token that recently came out, those types of things.
00:03:11.674 - 00:04:15.482, Speaker B: But the content piece of Audius lives on POA network. And then the other two pieces of kind of technical architecture here are these two classes of nodes, content nodes and discovery nodes that exist in the network. So these are being run by anyone can go run one of these. Everyone from a few advisors to the team are running them to if you think about the common validator folks on Cosmos or networks like that, a good number of those folks also run Audius nodes. So the content node in Audius, its role is basically to host content and keep it available on IPFS. It also has some kind of content management functionality that it does on behalf of the creator. And then those discovery nodes are actually indexing content that exists on this network and producing like a more consumable API.
00:04:15.482 - 00:05:33.414, Speaker B: And that is actually likely the kind of point of interfacing that I would guess many of you all kind of take advantage of in the hackathon. The way the flow kind of works here, for a creator to upload content, they're actually uploading it to one of these content nodes that returns back like a set of pinned metadata on IPFS. Those creators then publish that on chain in a transaction to that content ledger component that triggers the indexing or discovery nodes to basically index that data into their own database and then that makes it available via the APIs to listeners. So a listener searches for content against these discovery nodes when it finds a piece of content it wants to listen to, and the listener clicks play in that client that actually streams the content from IPFS via one of these content nodes. So, sure, that was all a big, huge mouthful. I glossed over a lot of stuff. We'll definitely have more time for questions and chatting through things as well.
00:05:33.414 - 00:05:59.440, Speaker B: But in the interest of getting to the good bits of the discussion here, I'll hand off to Ray, who's going to be walking you all through building with you a simple end to end example of a thing consuming the audience API. So there are sort of two prongs here that we'll get to chat through.
00:06:00.290 - 00:06:00.894, Speaker C: Cool.
00:06:01.012 - 00:06:35.946, Speaker D: Thank you for that overview, Ronel. I guess since we're like a relatively small group, at least not on the live stream, I'd love to know a little bit more about our audience here. If anyone wants to share how much familiarity you have with audience, have you seen it, have you used the product and sort of like, what is your goal of exposure here? The way that I had planned to go about this was sort of work on a front end facing app that consumes some of audience together for the remainder of the session. But I'd love to hear if anyone has any specific things that they're trying.
00:06:35.968 - 00:06:44.126, Speaker C: To dig into there first or their familiarity with audience. If anyone wants to chime in, it's also totally cool.
00:06:44.148 - 00:06:46.080, Speaker D: If not, we can just dive into it.
00:06:47.010 - 00:07:04.210, Speaker E: Real quick question. So I looked at the API and that all looks super useful, but I was wondering, is there any other ways to interact with audience protocol to, say, upload a track or create an account at the moment, or is that still behind closed doors?
00:07:04.550 - 00:07:22.866, Speaker D: It's a great question. We'll get into that. I'll leave definitely enough time to get into that in the latter half of our session. Here. But to go on that first point, let's spend a little bit of time talking about what we have as a public read only API for now, to sort of get folks off the ground, sort of with how to actually stream.
00:07:22.898 - 00:07:24.906, Speaker C: Content and then we can go deeper there.
00:07:25.008 - 00:07:25.514, Speaker D: Sounds good.
00:07:25.552 - 00:07:27.450, Speaker E: I was looking forward to seeing that in action too.
00:07:27.520 - 00:07:42.206, Speaker D: Yeah. All right, so I'm just going to go ahead and take over the screen share right here. And I'm actually just going to share some live code and we can sort of talk through how to use some of these tools and also talk through how we can build stuff for the.
00:07:42.228 - 00:07:43.102, Speaker C: Remainder of the hackathon.
00:07:43.166 - 00:07:47.620, Speaker D: So, going back to Ronell's Deck that he was sharing, can you guys all see my screen?
00:07:48.870 - 00:07:49.620, Speaker C: Cool.
00:07:50.470 - 00:08:28.586, Speaker D: See how we set up this super small demo repo to get folks off the ground. This really touches on a few of the different tools we have, including the public Read Only API, and then also sort of how you would do reads and writes generally your point about uploads through what we use on our clients, which is this Audius Libs JavaScript package. There's a few different ways to slice it and we'll get into some of the details there. So, to start off, I'd like to talk a little bit about what our sort of like public HTP API looks like. This is linked in the GitHub repo here. Let me drop this in the chat.
00:08:28.618 - 00:08:36.386, Speaker C: Too, just so folks have it and.
00:08:36.408 - 00:09:32.878, Speaker D: Sort of talk about why we have sort of two disparate ways of interacting with the audience protocol as it stands. So, going back to what Renil was talking about with the architecture diagram, we really have these two types of nodes. We have discovery nodes and we have content nodes. The idea of the discovery nodes is really to make querying things against the chain as fast as we possibly can, to give people that sort of spotify SoundCloud esque user experience that they expect to see sort of across music players on the web. And with that, we get a lot of really nice standard rest API patterns that we've built a public API around, which is what you will find if you look at the docs page here. The really interesting sort of piece about Audius and how you would interact with a public read only API is because the system is decentralized as it is. We really want to encourage applications to discover from the network what are the services they should talk to, rather than sort of being able to point at a centralized load balancer.
00:09:32.878 - 00:10:37.850, Speaker D: So the first piece of this public API docs section here is all about selecting a host. We have a sort of convenience endpoint, which is this API audience co, which is obviously a centralized location, but this actually serves a set of discovery services, discovery providers that we can actually query for API content so in this docs page, we pick one on the fly, which happens to be this link here. I believe this node is running in Mumbai, actually. And if you were to sort of go along with how you would use this public API is you would query against either API is Co, which behind the scenes is actually just looking on chain to find registered nodes. And actually just sending queries against it, which honestly look very similar to how you would expect like a SoundCloud API or something like that to look like. So you can query against users, you can query against tracks, playlists and whatnot. And sort of to put a little bit of this into more context, this sort of demo app that we have set up here, we'll jump into the code.
00:10:37.850 - 00:10:41.980, Speaker D: Basically what we have going on is.
00:10:42.350 - 00:10:53.030, Speaker C: I think I am in the wrong directory. 1 second here. All right.
00:10:55.960 - 00:11:50.356, Speaker D: We have a very trivial react app set up here with a couple example components. One of these components here is sort of the HTP API example. And really all we're doing here, so in this example, you can look sort of at the top section here is we're fetching the highest trending track this week on Audius. So actually, if you were to go to Audience Co and go to our trending page, you would in fact see that this is our number one track this week. And the way we're able to pull this data is actually relatively simple. Sort of given the complexity under the hood of what is happening when folks are uploading and putting content on these content nodes and registering that content on chain, and then discovery providers indexing it, it sort of becomes much more of a natural sort of web two feel, almost of how you would query for this information. So, basically, what's happening in this component, if you're not familiar with React, you could obviously do this in plain JS.
00:11:50.356 - 00:12:51.150, Speaker D: You could do this in a totally non front end facing application. You could make curl requests against these endpoints. But for simplicity's sake, basically all we're doing here is really we'rendering out a track with an artwork, a title and a name. And the way we're actually fetching that track is sort of when this component mounts, we're hitting an endpoint for trending and we're asking for the time range week. And in order to calculate sort of what this host value is, we're actually on load, hitting this API audience co endpoint and pulling in a list of available discovery writers with a very crude sample function, picking one of them and actually sending our query against that. So what happens here, basically, is when this component is mounted and is running, it will send a single request to the trending endpoint, populate some internal state and actually display that on screen. So we have our number one trending track on Audius this week.
00:12:51.150 - 00:13:15.972, Speaker D: So I want to pause really quickly there. Does anyone have any questions about that? Hopefully you all have access to the API docs. You're able to access that through the GitHub repo there. We can spend more time on this, and I'd like to actually build out a little bit of streaming. And I don't know if folks here have experience with the Web Audio API or something like that, but we can definitely play around with that. But I do want to pause to.
00:13:16.026 - 00:13:26.680, Speaker C: Ask if anyone has any comments or thoughts. Cool. Let's march on ahead. Unless I missed something in the chat.
00:13:28.380 - 00:13:36.970, Speaker D: We're good? Yes? All right, cool. Sorry, there's a lot of little zoom pop ups all over the place.
00:13:38.140 - 00:13:38.504, Speaker C: Cool.
00:13:38.542 - 00:14:48.128, Speaker D: So the second thing going more towards what your question was, Jeremy, is like, how do you interact with this as a creator or someone who is trying to write content to Audience? And because of how Audience is designed with this sort of multiple pieces of a larger ecosystem of architecture that are decentralized. The way that we've found easiest to sort of coordinate that is through this middle layer JavaScript package that we call Audience Lives, which is basically a client side package that stitches together a bunch of network requests, things that manage web3 relationships, things that manage talking to services, things that actually manage like file upload and stuff like that. And so for the purposes of this demo here, up to this point, we've sort of created a very crude sign in, sign out with your Audius account. But I'll actually show how this can work. So I'm going to go to Audius. Hopefully the live demo gods are in my camp today. But I turn off my video, I'm going to sign out, I'm going to make a new account on Audius and then I'm going to log into my new account on Audius on this demo app and then I'm going to walk through sort of like how in code we are doing that.
00:14:48.128 - 00:15:11.720, Speaker D: And it actually is pretty nice. We guarantee if you're using this Audience Libs package, some somewhat normal behavior of how you would expect. Sign in and sign out. And I don't know if folks have read sort of any of the press we had in the early days of launching, but we have our own sort of wallet management tool. We call that hedgehog. I can also drop a link or maybe Romeo, you can help me with that. Drop a link to that in the chat.
00:15:11.720 - 00:15:37.164, Speaker D: The reason that we sort of came up with our own wallet management approach was we really wanted users interacting with audience to feel that this was not a crypto project or a blockchain project, but really a music project. Because that is sort of at the core of what we're doing here is we want to provide a compatible experience to what folks are anticipating with like spotify and SoundCloud, but it happens to be run on chain and we can derive all of these benefits that Ronil.
00:15:37.212 - 00:15:38.848, Speaker C: Was mentioning with that.
00:15:38.934 - 00:16:14.670, Speaker D: So that is sort of all to say that we have on Audius. When you create an actually, if you go to sign up here, you're actually prompted for an email and password or username and password and that actually obfuscates the concept of a wallet away from the user, even though we actually do have that store behind the scenes and I'll show that in this demo here. So I'm going to go make an account. Let's call it ETH online. Find this email plus syntax very useful. I make lots of accounts on audience all the time. I'm going to make a password here.
00:16:14.670 - 00:16:35.668, Speaker D: I'm going to we'll call it ETH Online. Hopefully no one's claimed that handle. And these are a selection of some of the artists that Ronil alluded to on the platform. I don't know who we should follow here.
00:16:35.834 - 00:16:38.020, Speaker C: We can pick some random folks.
00:16:42.430 - 00:17:34.838, Speaker D: And our account sort of is being created. Now, behind the scenes there's a lot of stuff happening where not only are we writing to chain to actually sort of create a wallet and account, we're also writing metadata about our user to one of these content nodes and we're also sort of behind the scenes pinging the discovery service to figure out when we're done. So we should be at this point done. We should have an account if I go to start listening, not turn on push notifications, we actually have an account and there's obviously nothing here. But the cool thing is now that this account is created on the audience platform, this little demo app that we have set up should be able to actually log in with this user. So I'm just going to reload here really quick and behind the scenes and we'll get into this. This web app is using just this JS audience libs package.
00:17:34.838 - 00:17:40.926, Speaker D: So I am going to type in the username and password that I just.
00:17:40.948 - 00:17:45.150, Speaker C: Put in and the demo gods are.
00:17:45.220 - 00:17:56.738, Speaker D: On my side of the court. In a second here we should be logged in. And actually even though we haven't exposed this anywhere in the music facing side of the app, I have an account on Chain now and this is the.
00:17:56.744 - 00:17:58.274, Speaker C: Wallet associated with the account.
00:17:58.392 - 00:18:12.934, Speaker D: So how does this all work behind the scenes? So we just talked about before this HTP read only example. There's also in this public repo a Libs example and I think this is a great reference to get started building.
00:18:12.972 - 00:18:13.526, Speaker C: On top of this.
00:18:13.548 - 00:18:27.806, Speaker D: Obviously, it doesn't have to be in a client front end facing JS context. A lot of these things still hold across the board. But if you are trying to build on top of it, it's probably easiest to do something that has JS because right now this package is really only.
00:18:27.828 - 00:18:29.280, Speaker C: Exposed in JS land.
00:18:30.450 - 00:18:52.718, Speaker D: Basically, what's happening here is in our component itself. As you can see, on the screen. We're basically rendering out either a sign in form with a little button or a sign out button, as well as an account sort of section. As you can see here, my username, my handle and my wallet address, which.
00:18:52.744 - 00:18:54.310, Speaker C: Are all being printed out here.
00:18:54.460 - 00:20:13.294, Speaker D: So what happens here? So, when this component mounts, if you are familiar with react and hooks, which is sort of the latest and greatest interface API programmer tool paradigm, I guess a lot of words could describe it. But basically what's happening here is if you're not familiar with how react works and how hooks work, when this JSX component gets rendered, when the component mounts, there is a sort of hook into that, which is this effect here, which does basically two things. It does an initialization of audience libs, which is this package that we mentioned. It's imported just as any standard sort of NPM package would be, with some config that I'll get into in a second. And then after we have initialized our Libs package, we just call get current user, if there is a user. We set that into a state variable which then controls actually what gets rendered out to the screen, as well as sort of callbacks for our sign in and sign out. And the cool thing about this is because we have this line here where as soon as the Libs package gets initialized, we check if there's a current user libs in its own right, actually sort of maintains user session so we can actually go back and refresh this page and I will actually be logged in.
00:20:13.332 - 00:20:13.966, Speaker C: Still.
00:20:14.148 - 00:20:31.666, Speaker D: The way we're doing this is we're storing in the browser context, in local storage, an entropy key that refers to your account that can be combined with your username and password to retrieve this entropy, which is effectively like a handle onto your private key so you can.
00:20:31.688 - 00:20:34.760, Speaker C: Actually interact and issue rights on behalf of your user account.
00:20:35.850 - 00:21:39.178, Speaker D: So what's happening here on this initialization of this Libs package is we have some config variables which point to where our contracts are. Audius actually, as mentioned, we're deployed on POA as our data contracts are concerned, data contracts being track uploads, user account creation, reposts, favorites, stuff like that. Basically all like the sort of social interaction with the audience ecosystem. And we also have contracts that are deployed on ETH Mainnet which manage sort of this service selection, sort of like where are the discovery nodes, where are the content nodes and stuff like that. So there's some config here both for our POA contracts as well as our ETH Mainnet contracts. The nice thing about how we've constructed the audience libs package, which I will definitely be the first to admit is not the best documented as it stands. So we're definitely here in Discord and on Zoom and whatever to answer any questions that you might run into.
00:21:39.178 - 00:22:46.766, Speaker D: And some of the rest of the team is on the discord channel as well. But basically what this web3 config and ETH web3 config interface look like here is it really is a way for third parties to actually inject their own web3 objects into Libs and have it be constructed that way. So although I just went through the steps of making an account with an email and password and sort of delegated the responsibility of managing that account though audience never has custody over that through this hedgehog product that we've built. You can also create an account with MetaMask and you can also provide your own web3, whether it's any other wallet manager besides MetaMask, you can actually inject your web3 into the constructor of this audience shared libs object and go about managing your account that way. The config for the discovery provider or discovery node and the creator node which is also what Ronil mentioned as the content node that is also sort of configurable here. These are hard coded values. You can actually go to chain though and see the whole list but just.
00:22:46.788 - 00:22:49.058, Speaker C: For brevity we've done that here.
00:22:49.144 - 00:22:57.682, Speaker D: So this method init really is just constructing this audience object, which is our shared audience libs, and it is running.
00:22:57.736 - 00:23:00.066, Speaker C: This initialization method on it.
00:23:00.248 - 00:23:16.646, Speaker D: And then sort of going back to our component logic. Here we are initializing libs, setting it sort of so we know that we have initialized and then just rendering out stuff. And when we actually want to go sign in, So if I'm in this state where I'm signed out so if.
00:23:16.668 - 00:23:18.458, Speaker C: I reload the page here, obviously I.
00:23:18.464 - 00:24:00.040, Speaker D: Will still be signed out because signing out destroys what we've stored is sort of in the browser local storage that references your account. If you were to go here and you're to actually type in an email and a password and click sign in, all we have to do is talk to this shared Loads package account and call login and that given. The email and password will behind the scenes set what we need in our browser storage to actually represent a signed in account. And it happens to return our user object here. So if we were to actually log out what our user is and take a look at the console here I were to log in again that account that we made.
00:24:05.870 - 00:24:12.074, Speaker C: Thank you, last pass this would actually log out our full account object here.
00:24:12.192 - 00:24:21.582, Speaker D: So obviously I don't have very much content here. I am following four accounts though if you were to actually go to my.
00:24:21.636 - 00:24:23.838, Speaker C: Page that we had made and we.
00:24:23.844 - 00:24:26.958, Speaker D: Look at followers, these are the folks that I followed on sign up as.
00:24:26.964 - 00:24:28.320, Speaker C: Well as audience here.
00:24:29.730 - 00:25:18.046, Speaker D: So with all of this information now that we have a authenticated signed in account we could start to begin to do some of the things that you mentioned Jeremy which is uploading a track and although it is not extremely well documented. If you were to go so from this ETH Online demo repo, go to the link to the Audience Libs JS package and actually look at this API folder, sort of we've done a reasonable job of organizing this into various behavioral functions within Audience. So if you were to look at track here, you can do reads, obviously there's get tracks, get trending tracks, similar stuff to what we've seen. But we also have upload functionality here too, and this is what our client is using. So if you are in Audience the client and you go to upload track like behind the scenes, we are just.
00:25:18.068 - 00:25:19.570, Speaker C: Using this JS package.
00:25:20.870 - 00:25:59.706, Speaker D: One more thing I want to call out here with this little component example that we've built is we have another package that has some of our audience styling in it. If you wanted to build something that looked and felt somewhat like Audius, it's actively under development. There are not too many components there, but we do have a shared component library called Stems, which is also open source. If you were to go back to this ETH Online demo repo, there's a link here which will include stuff like fonts and colors, namely, and also buttons and modals and some other nice components.
00:25:59.738 - 00:26:01.614, Speaker C: That we use internally to make the.
00:26:01.652 - 00:26:41.258, Speaker D: Feel of audience try to feel as modern as possible. So, yeah, in a nutshell, that's sort of a high level of what are our various tools we have available to our sort of broader community. As it stands, there is another package that lives on top of Audius Libs, that is a layer of abstraction on top of it, which exposes some of our internal streaming technology. We stream all of our content with HLS. If you're familiar with that, there's this repo called Audience JS, which is a wrapper around this Audience Libs package. So it has all the functionality there, but it also has some built in audio playing capabilities. And our community has actually built a.
00:26:41.264 - 00:26:44.730, Speaker C: Discord bot off of that package, which is really nice.
00:26:44.880 - 00:26:52.362, Speaker D: If you were to take a look here, this is actually if you set this bot up with your discord server.
00:26:52.506 - 00:26:57.630, Speaker C: You can call out to it and have it feed audio back into your channel, which is super sweet.
00:26:59.250 - 00:27:15.298, Speaker D: Yeah, at a high level, that's sort of what we have available. I think we have a bit more time here. So before I jump into anything else more specific, I want to pause again and ask if there are any questions or thoughts or concerns or anything like that, or if there's anything you want.
00:27:15.304 - 00:27:19.350, Speaker C: To add to Ronil. Because I know I've just been rambling into the Zoom vacuum.
00:27:21.290 - 00:28:24.540, Speaker B: No, I think this has been great. The only thing I'll call out so there was a question in the chat about whether the Discovery API is pluggable. And just to talk about that mean all of this code is open source, all of Audius is open source and available. Like anyone is welcome to build any extensions. On top of that they could, which in the discovery logics case, it could be like if you wanted to build a cool new recommendation system, for example, all of the data of who has listened to what, and all the content that exists here is fully, openly indexable. There is an interesting thing though. So functionality that is added to that node software, the discovery node and content node software won't be run by the broader network unless you kind of propose that change back as like a PR and the community merges it and then it gets rolled out, which takes on the order of weeks or so.
00:28:24.540 - 00:29:01.880, Speaker B: So for any hacks that are interested in extending functionality in those areas, the recommendation there would probably be to actually fork the code base and run it yourself for development purposes. Our team can help you get that up and running and then once you're feeling good about the implementation and stuff you have there, it would be awesome to have those changes contributed back to the node software itself. Right? And the community can provide feedback and then ultimately merge those changes or whatever, right? Yeah.
00:29:05.320 - 00:29:18.740, Speaker D: Well, thank you for that. I clearly missed pieces of the chat as I was just rambling here. Is there anything else that folks want us to chat about briefly before we go into maybe how to actually stream.
00:29:18.820 - 00:29:21.400, Speaker C: An audio file itself from Audius?
00:29:24.560 - 00:29:29.230, Speaker D: Jeremy, did that somewhat answer your question or your desires there?
00:29:30.080 - 00:29:40.396, Speaker C: Yes, it did. Awesome. Cool. How are we doing on time? I think we have like half an hour left, right? So we can really dive.
00:29:40.428 - 00:30:16.990, Speaker B: Yeah, so I think we're here. Yeah, you guys are good. We can kind of take this any direction that you all might be interested in or want to learn more about. Talking about how to stream content is probably a great place to start. I know there were some folks interested in building NFT style use cases with content hosted on audience. Being able to know how to play that back and stuff might be helpful, but feel free to drop suggestions in the chat here too, or just unmute and feel free to ask anything too.
00:30:18.320 - 00:30:26.416, Speaker D: Also, if anything that I went over was too brief or you haven't seen in the context of react all that much, you want me to go through it again?
00:30:26.518 - 00:30:27.760, Speaker C: I'm happy to go into more detail.
00:30:27.830 - 00:30:37.860, Speaker D: There, but if it's cool with everyone, we could just kind of jam on this example here and actually make this track that's showing up streamable.
00:30:38.280 - 00:30:43.910, Speaker C: That would be kind of fun. Be a little fun exercise for me because I haven't done this for quite a while.
00:30:45.960 - 00:30:49.624, Speaker D: So if we pop over to our.
00:30:49.662 - 00:30:51.530, Speaker C: HTP example again.
00:30:53.420 - 00:31:12.396, Speaker D: For simplicity's sake, I'm just going to use a generic web audio HTML audio element to actually play some audio back to. US here. And this probably will not work over the live stream because it's definitely not going to take my computer audio. I could try to get soundflower set.
00:31:12.418 - 00:31:14.624, Speaker C: Up here but it might be not worth doing.
00:31:14.742 - 00:31:19.056, Speaker D: But I can push this up as a branch or something. You can all fork it and play.
00:31:19.078 - 00:31:20.210, Speaker C: With it or whatever.
00:31:21.780 - 00:31:38.648, Speaker D: So once we have our track here, we could actually do this as like another effect which in react hooks land will be able to trigger based on whatever we pass it in this sort of dependency array. So we can actually say when the track changes.
00:31:38.734 - 00:31:39.928, Speaker C: Do something here.
00:31:40.094 - 00:31:56.524, Speaker D: So if we have a track we're going to want to go and actually given this track content, we're going to want to query for a URL that will give us a stream endpoint. And so let's go ahead and log.
00:31:56.562 - 00:31:59.630, Speaker C: This out first just to see what we're working with here.
00:32:00.720 - 00:32:07.628, Speaker D: So here's our track object and this is sort of in line with what you would see if you were to go over to our public API docs.
00:32:07.644 - 00:32:17.344, Speaker C: Here and you were to go over to the track section and scroll down. I think we're in trending. So you have an object that looks.
00:32:17.382 - 00:32:32.888, Speaker D: Kind of like this, has user attached to it, has some artwork options, it has mood, a genre reposts, follows some tags, et cetera, et cetera. And just looking here, this is what we have. And if I expand the user object.
00:32:32.974 - 00:32:35.288, Speaker C: Obviously you get a lot more metadata there.
00:32:35.454 - 00:33:03.792, Speaker D: So there's potentially some really interesting social graph stuff that as a relatively small company we haven't had all the time to explore, but there's probably some really cool things we've noticed. There's quite a lot of emergent behavior of community groups on audience. This number one track this week actually falls under the genre Mumba Tone, if you're familiar with that music sphere. But a lot of folks from the Mumba tone community kind of came over to Audience in the last couple of weeks and it's been really exciting to see that. So there's probably some very interesting social.
00:33:03.846 - 00:33:05.120, Speaker C: Graph stuff to explore there.
00:33:05.190 - 00:33:25.096, Speaker D: But going back to our API docs here, if you go over to Tracks, there's a thing on streaming tracks and if we look at what this endpoint looks like, you go to V one tracks, the idea of the track and stream. So if we were to hop over to our example here where we have the ID for the track and I.
00:33:25.118 - 00:33:36.480, Speaker C: Were to actually reconstruct this URL with it here, let's just drop in this new ID.
00:33:40.050 - 00:33:44.594, Speaker D: We actually would hopefully get the song, which obviously I can hear.
00:33:44.632 - 00:33:54.680, Speaker C: And folks, I'll drop this URL in the chat.
00:33:57.100 - 00:34:08.124, Speaker D: Jeremy asks is there a drag and drop file upload component? Is at the moment not is open source in our Audius client repo. It hasn't been moved over to stems, but I can drop a link to.
00:34:08.162 - 00:34:09.310, Speaker C: That in a second.
00:34:10.800 - 00:34:23.488, Speaker D: We do use a third party drag and drop called Dropzone I believe to manage some of that stuff but we have obviously styled on top of it. So yeah, I'll definitely throw over a.
00:34:23.494 - 00:34:26.484, Speaker C: Link in a second. But let me also send this link.
00:34:26.522 - 00:35:06.928, Speaker D: Out to this streamable track and actually what's interesting here is if you look at the API documentation on this, this endpoint actually returns a redirect to the content node that is actually responsible for hosting the content. The way we have sort of set up our content nodes is there's replication amongst the network but the user has when they create an account, elected and like a primary node. So if you were to actually hit this link you do see that it does get redirected to a creator node for the content. You can stream it here and this is a sort of standard streaming NP three endpoint where you can send HTP range headers to actually get parts of.
00:35:06.934 - 00:35:09.280, Speaker C: The content if you don't want to pull the whole thing in advance.
00:35:11.220 - 00:35:14.224, Speaker D: Yeah so let me really quickly hop.
00:35:14.272 - 00:35:23.764, Speaker C: Over to our client to answer Jeremy's question here. Don't remember exactly where this thing lives. There we go.
00:35:23.802 - 00:35:31.348, Speaker D: Drops JS and all of our components these days. One of the reasons this is not in stems yet is we do write everything in TypeScript these days and haven't.
00:35:31.364 - 00:35:32.584, Speaker C: Had the time to move this guy.
00:35:32.622 - 00:35:47.260, Speaker D: Over but absolutely feel free to fork, clone, copy, paste, whatever floats your boat there. So yeah, going back to our little example here. So we had this formed URL.
00:35:47.920 - 00:35:59.104, Speaker C: Just drop this here and let me minimize some of these things.
00:35:59.302 - 00:36:00.896, Speaker D: I realize you guys probably can see.
00:36:00.918 - 00:36:03.830, Speaker C: The chat on my presentation screen too.
00:36:04.200 - 00:36:05.092, Speaker D: Is this big enough?
00:36:05.146 - 00:36:07.830, Speaker C: Hopefully this is big enough for folks to be able to see still.
00:36:08.600 - 00:36:10.004, Speaker A: Yeah, it looks good.
00:36:10.202 - 00:36:10.756, Speaker C: Cool.
00:36:10.858 - 00:36:14.820, Speaker D: So we are going to construct a.
00:36:14.890 - 00:36:17.248, Speaker C: Stream URL for this track and we're.
00:36:17.264 - 00:36:30.124, Speaker D: Going to use the same sort of syntax as we had before. This is our host which is selected on the fly. This is the discovery node that we're talking to in this particular session and we're going to go to tracks and.
00:36:30.162 - 00:36:40.190, Speaker C: We'Re going to put in the ID and stream. So the ID here is going to be this guy which will come right off of our track.
00:36:44.260 - 00:36:54.836, Speaker D: And if folks are familiar with the sort of HTML audio interface as well as the Web Audio API, you can do lots of fun things. But a very trivial way of doing.
00:36:54.858 - 00:37:07.940, Speaker C: This would be to just create a new audio object and pass it in the source and then oops, I typed audience instead of audio. Do you do that Ronil?
00:37:08.020 - 00:37:12.010, Speaker B: I do that all the yes, yes I do.
00:37:12.540 - 00:37:17.960, Speaker D: And I believe the function here is play. So this is just going to potentially.
00:37:18.040 - 00:37:56.000, Speaker C: Oh, host is not defined. We didn't save that into a state variable or anything like that. So let's do that really quick. It here so we don't get variable clash. And now that we have our host, this should hopefully be able to use it.
00:38:00.370 - 00:38:10.942, Speaker D: Yes, I believe the issue here is that Chrome blocks you from auto playing audio. So we need to add a button. So let's go ahead and add another.
00:38:10.996 - 00:38:12.974, Speaker C: Button here to actually play this track.
00:38:13.092 - 00:38:18.050, Speaker D: And doing what we did in the other example, we're just going to use the button that we have in our shared component library.
00:38:19.590 - 00:38:39.740, Speaker C: Not getting Vs code to help me out here, but it should just be importing the button from audience and we're going to say Text as Play Track and our on click callback to be.
00:38:41.550 - 00:38:43.322, Speaker D: Let'S do a similar thing where we.
00:38:43.376 - 00:38:53.920, Speaker C: Store our audio outside of our little use effect here's. And.
00:38:57.010 - 00:39:14.582, Speaker D: There'S a number of ways you could do this. You could also probably just stick the audio on your window object depending on whether you wanted to have multiple audio things playing at the same time. I don't think there's many common applications for doing that, especially if you're playing full tracks, but you could imagine some very interesting remix cross fading kind of.
00:39:14.636 - 00:39:17.080, Speaker C: Stuff on top of that if it was interesting.
00:39:18.490 - 00:39:20.854, Speaker D: So we'll set our audio object here.
00:39:21.052 - 00:39:51.230, Speaker C: And then we will create a callback for that that will respond to updates of our audio guy and then callAudio Play. Let's just guard this just to be safe. So hopefully if this works as intended.
00:39:51.390 - 00:39:52.866, Speaker D: We will get a button here that.
00:39:52.888 - 00:39:57.570, Speaker C: Says Play Track and oh no, we still have some bug.
00:40:00.550 - 00:40:05.700, Speaker B: I think a variable name up at the top may have been off.
00:40:06.310 - 00:40:07.650, Speaker C: Thanks Ronil.
00:40:08.970 - 00:40:14.674, Speaker B: That select Host set host to yeah, I saw that earlier.
00:40:14.722 - 00:40:15.560, Speaker D: I didn't know.
00:40:17.950 - 00:40:25.210, Speaker B: I figured that may or may not be the thing, but I thought the tools would identify that issue better.
00:40:25.280 - 00:40:28.714, Speaker C: I didn't think it so you guys.
00:40:28.752 - 00:40:43.586, Speaker D: Can'T hear what's going on in the party in my ears right now. But Chrome is playing something and it's very loud, but that's sort of like in a gist, like how you could hook into a actually streamable interface with.
00:40:43.608 - 00:40:45.860, Speaker C: The audience public API here.
00:40:46.230 - 00:40:51.218, Speaker D: Relatively low touch. Obviously you could do this all over whatever language. You don't even have to have a.
00:40:51.224 - 00:40:52.274, Speaker C: Front end for this stuff.
00:40:52.392 - 00:41:21.838, Speaker D: You could do it just like sort of our Discord bot, which is a node server. You could do this in Python. You could do this however you wanted. But yeah, it's relatively easy to consume. That's sort of like what our intent was with designing this to give the power to a lot of developers in the App Store. And actually, as it stands today, if you were to go into the iOS App Store or Android Play Store, some of the top music apps actually are.
00:41:21.844 - 00:41:24.606, Speaker C: Running off of the audience API and.
00:41:24.628 - 00:41:26.234, Speaker D: They'Re actually just using this public stream.
00:41:26.282 - 00:41:27.514, Speaker C: API as it stands.
00:41:27.642 - 00:41:37.060, Speaker D: So it's a nice, cool thing, especially about building the type of product that we are having. It be able to be integrated across the board in lots of different services.
00:41:37.830 - 00:41:40.194, Speaker C: It's really cool. Yeah.
00:41:40.232 - 00:41:46.870, Speaker D: Does anyone have any questions about that? Thoughts, concerns, desires?
00:41:50.830 - 00:42:05.710, Speaker E: Are there any tools for things like Scrubbing and skipping or I guess scrubbing through a track and seeing what time you are in the track built into the audience client? Or is that something we do with HTML audio?
00:42:06.530 - 00:42:26.790, Speaker D: So you could do that with HTML audio. So actually, I believe you can actually just do audio current time, I think, and that's in seconds. That would work to Scrub, obviously. But we have exposed a component in stems, wherever it is here, that is our Scrubber.
00:42:29.770 - 00:42:33.430, Speaker C: Where are we at? I don't think I have this open anymore. Stems.
00:42:34.010 - 00:42:52.110, Speaker D: If you were to go in here, this is a list of the components that we have as it stands. The Scrubber here, the index TSX file is the entry point. You would use this similarly to other Scrubbers that you would find in component libraries. I believe we have some examples in here as well.
00:42:52.260 - 00:42:55.310, Speaker C: We might not actually have one for the Scrubber.
00:42:59.170 - 00:43:04.466, Speaker D: Believe we don't. If you do want to see a live example of it, though, you can.
00:43:04.488 - 00:43:12.534, Speaker C: Hop over to our client repo and do a search for Scrubber. It should show up. Yeah.
00:43:12.572 - 00:43:15.798, Speaker D: So this is our mobile now playing page, actually.
00:43:15.884 - 00:43:16.520, Speaker C: But.
00:43:19.610 - 00:43:32.006, Speaker D: The props that this guy takes in are sort of like a media key to uniquely identify what's playing and some props about what has elapsed in the total seconds. And you can get this all from directly from the audio object if you're.
00:43:32.038 - 00:43:33.450, Speaker C: Working in a web context.
00:43:34.670 - 00:43:38.286, Speaker D: I hear noises. I don't know if it's discord or zoom that's talking to me.
00:43:38.308 - 00:43:40.110, Speaker C: I think it might be discord.
00:43:41.010 - 00:43:48.446, Speaker B: I think it's discord folks just messaging us about their hack. So you can ignore it. It's fine.
00:43:48.548 - 00:43:48.862, Speaker C: Okay.
00:43:48.916 - 00:44:25.386, Speaker D: All right, cool. Anyway, if there aren't explicit examples in the stems repo that you're looking at here, you can definitely find them across some of our projects. Also, another thing I want to call out is our Embed player, which if you're a Twitter person and you're into sort of like playing audio from places in Twitter, just looking at our public account. Yeah, this runs off of our Embed player. This is our hot and new playlist. That is an editorial that we publish. But so this component here, this Scrubber, is actually the same thing that we.
00:44:25.408 - 00:44:28.570, Speaker C: Use in our client, which comes from this shared stems repo.
00:44:30.030 - 00:44:41.634, Speaker D: So, yeah, all of this stuff is open source. I will say again that it is not exceptionally well documented, but it's all there. And you can clone it, you can play with it, and it's all the stuff that we use.
00:44:41.672 - 00:44:44.466, Speaker C: There's really nothing that we haven't put.
00:44:44.488 - 00:44:45.746, Speaker D: Out on the table to sort of.
00:44:45.768 - 00:44:46.660, Speaker C: Hack on.
00:44:48.630 - 00:44:53.800, Speaker D: Going quickly back.
00:44:56.650 - 00:44:59.400, Speaker C: Into what were we talking about.
00:45:04.660 - 00:45:05.836, Speaker D: In the context.
00:45:05.948 - 00:45:07.216, Speaker C: I lost my train of thought here.
00:45:07.238 - 00:45:16.772, Speaker D: In the context of our Scrubber component. Yeah, you would just actually I mean, we can try to play with it here, but you would be able to.
00:45:16.826 - 00:45:58.270, Speaker C: Pass in stuff directly from the Audio API here. So let's try it out. And if we hop into that component again and we look at our prompts, we'll say we'll just give it the track ID here.
00:45:59.200 - 00:46:15.940, Speaker D: And this is sort of like a prop that's very similar to the react key. Why you would need keys and different react components rendered as a list is basically to sort of isolate when it should be rerendering and total seconds.
00:46:19.480 - 00:46:23.940, Speaker C: Believe we can just call duration.
00:46:26.440 - 00:46:27.752, Speaker D: We might have to do this actually.
00:46:27.806 - 00:46:32.168, Speaker C: Through the audio context might be more than the twelve minutes we have left.
00:46:32.254 - 00:46:33.576, Speaker D: But I'll leave that up to you.
00:46:33.598 - 00:46:40.748, Speaker C: Jeremy, to hop on if you want. Awesome. Cool.
00:46:40.834 - 00:46:45.310, Speaker D: Any other questions or interests here about things we can talk about?
00:46:46.400 - 00:46:53.730, Speaker A: There's a question from Rob in the chat. Rob, if you want to unmute yourself, you can go ahead and ask yourself.
00:46:58.180 - 00:46:58.930, Speaker C: Yeah.
00:47:02.900 - 00:47:08.736, Speaker B: Go ahead. Sorry, I was just saying I was starting to type a response I also realized I forgot to I mean, it's.
00:47:08.768 - 00:47:11.236, Speaker D: Probably a good question for you to answer if you want to just do.
00:47:11.258 - 00:47:12.390, Speaker C: It out loud, right?
00:47:17.240 - 00:47:17.556, Speaker D: Yeah.
00:47:17.578 - 00:47:20.650, Speaker B: Rob, if you want to ask, I can answer. Yeah, go for it.
00:47:21.340 - 00:47:47.090, Speaker C: Yeah. I just had a question about the monetization parts of ODS between the content owners, the streamers people who play the tracks and then separately is there a Tipping API or anything like that that allows users to tip their favorite artists or whatever like that?
00:47:47.780 - 00:48:42.880, Speaker B: Yeah. So the short answer is right now there aren't any sort of native reward mechanisms in the protocol. The way that I think the community has wanted to take this is to effectively kind of what audience does provide is a set of primitives to allow permissioning of content and the community could tie kind of permissioning of their content to any sort of set of input they chose. That could be a payment, that could be like I have listened to your content more than 100 times before, so I'm one of your top fans or something like that. You can have any conditional unlocking of content happen and then the specific question is there a Tipping API? There is not yet. If that is something you would be interested in building. I think that could be a really cool hack.
00:48:42.880 - 00:48:50.356, Speaker B: We actually do have if you go to an audience profile or here, let me find an example of one that has this.
00:48:50.458 - 00:48:51.670, Speaker D: I can pull it.
00:48:52.200 - 00:49:29.730, Speaker B: It like you can put fill in a field on your profile for how you would like to be. Yeah. In Ray's case here and Ray I guess you're also a Chick fil A fan and AACP donation link is there, but as an artist or content creator, you can fill in anything you want in that sort of donation or tip link. Yeah, there's definitely room for, I think, something that's more sort of Web Three Native there, which could be really cool.
00:49:31.700 - 00:49:33.430, Speaker C: Great, thanks. Absolutely.
00:49:34.120 - 00:49:37.556, Speaker D: It's a great question. I think definitely core to how we.
00:49:37.578 - 00:49:39.460, Speaker C: Are continuing to develop audience.
00:49:41.480 - 00:49:43.476, Speaker D: And I know, Jeremy, you have experience there.
00:49:43.498 - 00:49:52.250, Speaker C: I know we've chatted before and you've done stuff in the tipping realm, so definitely excited to continue jamming on that.
00:49:54.540 - 00:50:43.850, Speaker B: Arth. What you mentioned in the chat that you're considering a generic subscription protocol. That sounds really cool, too. I think that's definitely this general idea of sort of permissioned content tied to sort of unlock conditions, I think could apply in a lot of different cases. This one could even just be as simple as if you want to subscribe to a given individual on many platforms, it's easy to pull whatever content they may be posting here on Audience and aggregate that with content elsewhere and kind of push that as an aggregate to subscribers. Or there are a lot of different ways you could take that, but that sounds really cool too.
00:50:46.910 - 00:50:55.434, Speaker D: Any other thoughts of ideas of hackathon projects or anything that folks are considering? Maybe even people on the YouTube livestream.
00:50:55.482 - 00:50:57.566, Speaker C: If there are any? I don't actually know.
00:50:57.588 - 00:50:59.646, Speaker D: I haven't taken a look there, but.
00:50:59.828 - 00:51:02.594, Speaker C: Maybe paying Discord or something like that.
00:51:02.632 - 00:51:05.490, Speaker B: Yeah, I actually haven't been monitoring questions there either.
00:51:05.640 - 00:51:21.624, Speaker C: Let's see. Let's do don't think I see anything there. Yeah, I'm in the right channel, so.
00:51:21.662 - 00:52:08.488, Speaker B: Yeah, I mean, if that's kind of everything, we can always wrap up a few minutes early here and give folks back their time. But just know that we're here to be helpful. If there's any way I or Ray or any other folks on the audience team here can answer questions or provide feedback or anything else, feel free to DM any of us. If you visit the Audience Sponsor channel, you can see all of our users names there and reach out to any of us. I think we all have DMs open, so, yeah, we're excited to see what you all build.
00:52:08.654 - 00:52:10.216, Speaker D: We can also drop the link to.
00:52:10.238 - 00:52:17.770, Speaker C: This presentation, which has all the other links, too, in the discord to do that right now.
00:52:22.020 - 00:52:32.930, Speaker A: Awesome. Thank you guys so much. That was a really awesome workshop presentation, jam session, whatever you want to call it. Super cool stuff.
00:52:33.480 - 00:52:35.430, Speaker B: Yeah, we had a lot of fun, too.
00:52:36.600 - 00:52:43.700, Speaker A: Well, thank you so much. Looking forward to see what people build using Audius and see you in discord.
00:52:44.680 - 00:52:48.980, Speaker C: Sounds great. Cheers. Thanks, guys. Nice to meet and see everyone here.
00:52:49.050 - 00:52:50.884, Speaker B: Ray's having a hard time there, getting.
00:52:50.922 - 00:52:54.260, Speaker D: The link to oh, I'm working on happening.
00:52:54.330 - 00:52:55.110, Speaker C: It's happening.
00:52:56.040 - 00:52:57.850, Speaker B: All right, see you. Check.

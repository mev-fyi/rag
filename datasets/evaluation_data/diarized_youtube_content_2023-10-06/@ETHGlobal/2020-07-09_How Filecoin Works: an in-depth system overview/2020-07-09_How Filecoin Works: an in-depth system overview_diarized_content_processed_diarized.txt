00:00:04.540 - 00:00:29.046, Speaker A: Okay, Twitter is up and stand by. Stand by. Waiting on YouTube. And we're good. Cool. Awesome. Sweet.
00:00:29.046 - 00:00:44.340, Speaker A: Well, thank you everybody for showing up and coming up to this in depth on Filecoin. I definitely won't talk too long. I'll turn this over to Juan right away. But thanks so much for coming and appreciate the flexibility. Of course. Just as Andrew mentioned. And yeah, get this kicked off.
00:00:44.340 - 00:01:04.706, Speaker A: Hey, everyone. Great to see you again. Sorry for the mix up. That was totally my fault. On time zones. Very excited to get started. I think that this is going to be a useful discussion as a kind of overview of all of Filecoin.
00:01:04.706 - 00:01:59.210, Speaker A: Really thinking about the whole Falcon network, the Falcon project, and then kind of walking through some of the core kind of fundamentals about how Filecoin works. The way I'm going to structure this workshop is that it is mostly conceptual and I want to have some amount of Q A to help guide what is confusing or what people are curious about. But there is kind of a lot to cover. So what I might do is I'll be going through a few sections and then I'll kind of pause for questions here and there. Definitely I'll be checking chat. So just keep throwing your questions on chat. And when it's right, I'll kind of pause to incorporate some of those questions, but I'll kind of keep moving through all of the sections.
00:01:59.210 - 00:02:25.910, Speaker A: Great. I'll be sharing my screen for most of the time. It all right. Can you confirm that you can see this screen that's moving? That looks great. Perfect. Great. So let's see.
00:02:25.910 - 00:03:10.596, Speaker A: I know that it's there we go. So I'm not going to introduce Falcon very much, other than I think the best introduction is just the explainer that we have on the website. So I'll take you through it. I'll mention the mission of Pathway is to build a decentralized, efficient and robust foundation for humanities information. Definitely there's a lot embedded into each of these concepts. So when you think about decentralization, there's a lot of pieces of the tech that are aimed towards that. When we think about efficiency, think about markets and high performance computing and so on.
00:03:10.596 - 00:04:26.590, Speaker A: When you think about robustness, think about networks that are partition tolerant and networks that are able to have liveness through all kinds of kinds of problems and getting robustness of storage based on replication and so on. When you think about the kind of foundation, just think of stable building blocks that people can build applications and other systems and services on top of. So think of a protocol that is meant to, over time, achieve a good set of primitives that won't change. And then when you think about humanitas information, really it's a very broad category, but think everything from very large volumes of data to small dynamic application data. And so this is of course, a massive mission. Think of the Falcon project as a long term effort to achieve all of this. On day one, it's not going to achieve everything, but we're building towards it in important big steps along the way and different kinds of things will work to different degrees at different times in the project's history.
00:04:26.590 - 00:08:45.748, Speaker A: Cool so I'm going to just use this explorable. I think I'll link it as well so you have it if the zoom distribution isn't loading super well, let me find the chat screen all it and I'll just kind of play it here. So hopefully this will work. Well, it's about four minutes. You it all right. Sweet so hopefully that was useful. I'll close this for now and we may return to it.
00:08:45.748 - 00:10:06.880, Speaker A: One important piece here that is kind of described through this is the whole kind of layout of different agents, right? So there are clients that are trying to store data and there are miners that are the storage providers and content distributors. Of course, the visualization is visionary and shows kind of a whole very large network. Of course, on day one we're not going to have a huge network like that. We need to get to that, right? So the process of growth of the network going from zero to 60, we want to do that as fast as we can, but if you think about how networks grow on the Internet, it'll start in a few pockets and then over time expand and demand for that service is what's going to pull it into various regions. There's a lot that we can do to stimulate the adoption in a bunch of areas. I might touch on some of the work that we're doing there, but at the end of the day it's going to be localized based on demand and the demand is going to follow applications. So applications that are built and maybe applications that you're building are the kinds of things that will kind of pull the network into certain regions both in terms of storage and long term archival and in terms of delivery and fast distribution of content.
00:10:06.880 - 00:11:26.836, Speaker A: So one of the things you saw in the Visualization is kind of the difference between storage miners that are these large players that have lots of storage space and then kind of retrieval miners who are more closer to the users and trying to distribute the content as quickly as possible. And so that difference is an important distinction that we'll touch on a little bit later. Sweet I was trying to think about how to represent all of what is filecoin in kind of a diagram and it's really a lot. In reality, these kinds of blockchain networks in general are extremely complex and they're large systems that embed a lot of different kinds of functionalities within a single thing. You can think of ethereum the same way you can think of other blockchains in a similar kind of way. These are sort of the sections of this discussion I'll kind of touch on kind of the basics of the protocol and the network first, and then work our way around touching on the blockchain, kind of the nature of the decentralized market. Then we'll talk about kind of the storage cloud aspect.
00:11:26.836 - 00:12:03.252, Speaker A: Okay, great, you have a market, you can store data and how do you make that really useful and verifiable and so on. Then talk a bit about app platform stuff. I might defer a lot of that to some of the other workshops that are happening. We'll touch a lot on kind of how to build the applications. I'll focus a bit of a discussion here mostly on just kind of what the performance characteristics of serving those kinds of users represent. I'll touch on also the nature of the economy of Falcon. So Falcon represents, at the end of the day, an economy that has to work.
00:12:03.252 - 00:12:37.250, Speaker A: And so thinking about the agents, there is an important piece of the puzzle. Then I'll touch also on the ecosystem that is growing around FalcoIn and some of the various organizations that are participating. And then I'll kind of finish. I probably won't touch very much on the open service stuff. I'll sprinkle that in through the rest of the talk because it kind of relates to a lot with the rest of the discussion. Sweet. So let's dive in.
00:12:37.250 - 00:13:32.604, Speaker A: One important thing to think about in terms of hawcoin is that at the end of the day, it's a peer to peer permissionless network. So that means that parties are going to be honest, rational and malicious. That's kind of the model for them, where hopefully the majority of the parties are rational. And the power of, say, malicious parties that just primarily want to expand resources to harm the network is limited and bounded. So all of the blockchain systems make some assumptions about the resources that say, attackers and adversaries have. But there's still a big distinction between honest parties and rational parties. Making a network that works for rational parties to provide a useful high quality of service is quite complex.
00:13:32.604 - 00:15:07.010, Speaker A: And so that's where a lot of the mechanisms for how certain messages work, how certain proofs work, how rewards work, and so on, that's where all the incentive structure, design comes in, in trying to make sure that the rational case for all parties, for the various types of miners, for the various types of clients and so on works out. And during that entire period, also making sure that attackers that are just trying to harm the network are bound, there are reasonable bounds in terms of attacks. So when you think about a network like this, and this is the same for Bitcoin and Ethereum and IPFS and so on, you can think of it as anybody in the Internet can join and participate. At the end of the day, these are protocols that anybody can implement. You can write any kind of software against this network and send any kind of messages. So you have to be ready for all kinds of unexpected things that might occur and you have to build the system and the project in a way that is where all of what you're doing is well specified. You're using good standards and you know that you're following good Internet development, internet protocol development practices in terms of structuring the protocols themselves, knowing that other people are going to run code and change the protocols and do different things.
00:15:07.010 - 00:16:08.550, Speaker A: And so your protocols should better be robust against things like that. So with that in mind, one of the big parts of the entire platform effort has been trying to specify a system of this magnitude. I think every single blockchain at this point has the level of work and effort that goes into kind of fully specifying that system is really considerable. Cloudfoint is the same and we have a number of different artifacts that we use to try and describe various aspects of the network. We have a large effort to kind of consolidate all of that within a single document that we define as a spec. But as you can imagine, the complexity of these systems and with hundreds of people working on them and thinking about them and so on, that's a living organic system, right? And so the same applies to Ethereum Bitcoin and so on. And I think worth noting as well.
00:16:08.550 - 00:17:33.660, Speaker A: When you think about building a layer, one blockchain with a VM and then with kind of the complexity of the consensus protocol of Hawcoin and the storage market and retrieve market and so on, the layers of complexity start adding up pretty quickly, and so you end up with a very large system. This is one of our big learnings along the way has been just the immense value in drawing hard boundaries as much as possible in trying to build totally decoupled systems where the security assumptions don't bleed through. That's very, very difficult because you end up in a world where even one slight change in one area might accidentally cause a change in another part. So this is one of the reasons many systems that build on blockchains are quite complex to think about and reason about, because the security of some contract running on a chain depends entirely also on all of the security characteristics of the blockchain itself. So all kinds of attacks that might work at one layer have to be considered at kind of the higher and higher layer. So it's quite difficult to yield abstractions that won't leak through. And this is why things like the more scalable chains and so on are headed in the direction of decoupling functionalities.
00:17:33.660 - 00:18:38.016, Speaker A: So I think one of my favorite directions is how Ethereum Two is moving towards having a beacon chain where this is primarily about hard consensus, that's proof of stake oriented and providing randomness and doing that at that layer only and then deferring all of the kind of contracts and transactions and so on to other layers. And so I think that that's a very promising direction and one that Falcon will likely follow. So there's a document that you can look at which is the spec. And so you can find this at this link. I'll drop it on Chat as well though. Warning this is given the kind of velocity that the team has, this has gotten out of date and is in kind of some in between state of reflecting the latest and not. There's a big push to update all of this around so that when we hit Mainet, this is like a really good reflection.
00:18:38.016 - 00:19:42.840, Speaker A: But just warning that if you start diving into this document, some parts of it, especially the actors and the virtual machine and so on, are not well classified or are out of date. And so yeah, I think read this document with caution. It can be helpful in terms of giving you a good conceptual understanding, but don't rely on the details yet. Instead kind of refer to the actual code implementation. So if you have to dig this deep into PowerPoint, I imagine most of you will never have to do this throughout all of hackfs. But if you have to do it and if you have to kind of dive into something, just make sure that right now code comes first rather than a spec, simply because a lot of things are moving very quickly and our team hasn't gotten to propagating those shifts back into this document with that warning in place. Also want to mention a few other kind of artifacts that are useful to specify the protocol in general.
00:19:42.840 - 00:21:08.068, Speaker A: One is there's kind of this just broader kind of research oriented paper that's kind of like if Alcoin is Zcash, think of this paper as like the zero cash version, which is kind of like a conceptual cryptographic protocol. You can take a look at that paper and a lot of the details are right, the actual proofs and some of the constructions have shifted because we found much better ways of doing things and we found much better proofs of replication and so on. So there's been kind of like years of really good research work that has happened on top, right? So you can think of this as kind of like if you think of the definition of ethereum, it's not like the very first version of papers. So again read these artifacts with knowing that the system has shifted and has evolved. A couple of other things that are useful are we have a set of constraint solvers based approaches to picking certain algorithms like Prusa replication tend to imply a lot of things about the system. And so those are we ended up building a bunch of tooling to help us decide and pick certain algorithms based on kind of the set of choices. And this is in progress as well.
00:21:08.068 - 00:22:20.088, Speaker A: We're working on a kind of visualization diagram that shows kind of all of the different components of the entire system and kind of whether the spec is up to date, whether there are tests that are implementation independent and then whether each of those components has been implemented in each of the implementations. And so that dashboard diagram will be pretty useful that'll probably go live in the next two, three weeks or so. Great. So let's dive into kind of the conceptual layering of the system. So think of filecoin as a set of nodes. I'm going to describe a bit more about those in a moment but that have a way of reasoning about files and data and then some subset of those nodes have a set of protocols associated with running the palcoin blockchain and that includes kind of the virtual machine that processes messages. Think of this as the kind of EVM contract layer and then on top of that then we can reason about accounts wallets and payment channels and so on.
00:22:20.088 - 00:23:31.328, Speaker A: And on top of that we can build the whole storage mining process and the storage market and the retail market. So think of this as kind of different layers that enhance nodes. One important detail is that filecoin nodes don't have to have all of these subsystems. So you can think of these individual tanks as subsystems and you can think of say a node that just wants to follow the chain and validate it without doing any mining as just needing to run the blockchain and the virtual machine and does not need at all to run the storage, mining or market side of things at all. So you can have implementations of the protocol that only implement some subsystems. Our main implementations right now implement the whole thing because we want to get to a certain level of completeness with all of them. But there's already a lot of small tools here and there that say implement some part of the retrieval market or implement some part of storage mining but themselves are not say full nodes in a sense that they can also sync the blockchain and so on.
00:23:31.328 - 00:25:08.800, Speaker A: So you can think of programs that plug into the filecoin network as different nodes in the network, but kind of you have to reason about what subsystems are they actually running? Are they able to sync the blockchain? Are they able to validate it? Are they able to mine and produce blocks that gets only a subset of nodes that are able to do that. Like any kind of blockchain network you can think of it as a kind of living system where there's specification, there are improvements that are going to come to that specification based on research and product UX goals. And as those improvements kind of get ratified by the community and get agreed upon then they'll translate into changes to the specification and then changes to the implementations. And at the end of the day the spec is the plan and the implementation is the kind of implementation of that plan. But at the end of the day, the network is what it is and the network is running and all kinds of different pieces of software are going to be connected to that network and all kinds of different things are going to happen there. So you have to think of these as kind of separate things, right? So the specification is what you're hoping to do, the implementation is what you're telling the computers to do. But at the end of the day, the network is a living, breathing system and it's going to be behaving in various ways depending on all kinds of conditions about the system.
00:25:08.800 - 00:25:55.848, Speaker A: And kind of where we are right now is not where this red line is. The red line is kind of like the mainnet launch. We're sort of over here where different Lotus is the implementation that is furthest along to completion that Mainet will launch with gofilecoin, forest and Fujan are close behind and they'll join the network shortly after. Cool. I'll pass for a couple of questions. So one question a client has to pay even to read a file is it to incentivize marrying of content? So the idea there is to model the economic exchange of asking a party to serve data. Certainly like reading a file once or something like that doesn't seem very expensive.
00:25:55.848 - 00:26:38.540, Speaker A: But if you're going to read something millions of times, then it starts adding up. So the idea of hollowcoin is to model that economic exchange and then let parties decide on how to actually pay for that. So the idea of a publisher pays model of distribution is really key to the whole picture. Meaning if you were browsing the web and having to pay for every single thing that you're looking at, that would introduce a lot of friction. So that's likely not the right model. But at the end of the day, someone has to pay for that distribution cost. And so the kind of publisher pays, you can think of that as the way that CDNS and storage systems work today, where you're racking up costs associated with the distribution to end users and they kind of go to the party running the service.
00:26:38.540 - 00:27:30.670, Speaker A: This gets different when you think about programs that are autonomous on a blockchain, storing data and serving it. It could be that contract has no intention or ability to pay for the distribution of that data. But given that it's there and it's paid for in terms of storage, somebody else may want to pay for that. So the ability decoupling, that gives a lot of flexibility. So that's kind of the underlying layer. Now, mapping to those models that are more usual is kind of like a higher. So at the end of the day, the publisher pays model could be done a bunch of ways from publishers giving Falcon directly to their users to kind of spend underneath the hood or by giving them some kind of other token or claim that they can redeem for the content.
00:27:30.670 - 00:28:25.276, Speaker A: Another question when you say blockchain or storage power consensus in the system overview, do you mean a separate blockchain being created for FalcoIn or is this on the Ethereum blockchain through smart contract, this ended up being a separate blockchain. I'll go into why in a moment. The consensus protocol of FalcoIn is a big part of the system design where we solve this pretty fundamental problem around being able to use storage as power in a blockchain. In a normal proof of work blockchain you have this run of equilibrium where a lot of parties want to add as much hash rate as possible to a blockchain. In our case, we managed to make it so that parties are adding as much storage as possible to the network and it's that storage power that counts for producing the block. So it's a much better setup in the future. It's unclear what the future holds.
00:28:25.276 - 00:29:30.772, Speaker A: It could be that as the kind of next generation scalable blockchains emerge, it could be possible to kind of rebase a lot of fog into some of those like E Two or others. But right now it's not clear that we can get there, given just the throughput requirements of fog in terms of just transactions on chain already saturate to get to the kind of storage levels that we want, which is kind of in the exabytes of storage that saturates an entire layered one chain on its own, let alone it's completely unfeasible to put all of that on. All of that traffic on top of Ethereum One today. It could be feasible to put it on top of something like Ethereum Two potentially. But that's kind of a long ways out. Given that you don't control the underlying hardware, what kind of durability guarantees can be provided? Can you require storage providers to swap out disks and do other maintenance? Of course. So that's where the incentive structure design comes in, where how you model the rewards for miners and so on cause that to happen.
00:29:30.772 - 00:30:41.368, Speaker A: Meaning miners put up collaterals associated with maintaining storage online and if they can't prove that they have it online, then they lose that collateral. There's a suggestion to build Bat plus filecoin attention pace for storing content. Yeah, it would be great to be able to do that. Highest Holocaust Protocol lifecycle impacted by Bat so I think it'd be really good to be able to have if you're browsing with Brave, for example, having automatic swaps of Bat to filecoin and then spending the file coin to back up to both retrieve the content or back it up and help kind of websites live longer. I think that would be a really great way to kind of marry the attention with kind of retrieval content idea. Another question I guess the separate blockchain also allows for utilization of Hakmon on various other blockchain platforms such as Cardano and so on. Yeah, in terms of interoperability, yeah, we're super excited about the kind of Internet of blockchains that's emerging through things like polkadot, the Cosmos, IBC and so on.
00:30:41.368 - 00:31:33.350, Speaker A: We think all of that kind of stuff is really promising and really good, and we plan on supporting a lot of this kind of interrupt. I've used a similar diagram somewhere. One SEC. Yeah, I kind of see it as like, there's this new next generation set of chains that's going to emerge with that's going to ten to 100 x the level of transaction throughput that blockchains can do. And Falcon is aiming to kind of get much better throughput in terms of the actual storage of data. And interconnecting all of these things with bridges and so on is going to yield a really rich environment for development. And so we're super excited about that.
00:31:33.350 - 00:32:06.530, Speaker A: One of the really promising parts of this is that a lot of these chains and systems are using Lipidopy to connect. Having even hybrid nodes that are, say, an e two filecoin node will become totally possible, or rather, it's totally possible now. Just somebody has to do it. Great. I'm going to keep moving from this and then take more questions later. Great. So one thing worth noting is that Filecoin came out of thinking about IPFS and the distribution model of that data.
00:32:06.530 - 00:33:35.600, Speaker A: So at the end of the day, it's tuned for how IPFS data and IPS applications and files and so on is modeled. And so that means Falcon itself is built on IPFS, IPLD and Lipidop and so on. So a couple of important pieces there are that how we model data structures and how do we address them, which is kind of with the hash link data structures with using Seabor as kind of like a base format makes it super friendly with a lot of development tool chains where the filecoin data structures themselves, like the filecoin blockchain. And all of this stuff is Seabor, which has a one to one conversion to JSON. So it's super easy to work with the actual data structures of Filecoin in kind of a much more kind of web familiar models and environments, and then you can think of building protocols and applications and so on to then write on top of that system in a pretty nice way. This also means that the entire Falcon blockchain can move around the IPFS network through nodes that don't understand Falcon at all, meaning the blockchain itself, all of the content associated with the blockchain is modeled in the same kinds of data structure. So you can pull that data and you can show it and you can explore it with all of the IPFS tooling and so on, without it having to be Falcon specific.
00:33:35.600 - 00:34:20.886, Speaker A: And of course, Falcon uses Lip to P, which is this modular peer to peer network networking library. And I was mentioning that'll hopefully lead to all kinds of interoperability between networks and systems. One important thing to think about the model here is that and this applies also to e two and applies to polka dot. And any of these groups that are using lipid AP, you can think of there being kind. Of a program that's using lipidp in the library. And then when you build some other system like IPFS or Falcon or something like that, that system is running a lipidp node inside of it. So an IPFS node is also a lipid to p node.
00:34:20.886 - 00:35:30.530, Speaker A: So that means that an IPFS node can talk directly to an e two node or a polka dot node as long as you want it to happen, as long as you want to connect those two nodes. And so when you think about filecoin, just think of a filecoin node being also an IPFS node and also a lip node that just happens to be able to run a whole set of other protocols that are Falcon specific and be able to use Falcon as a currency to mediate the exchange of information. Another way to think about it is, know, there's a world of lipidopy nodes and a subset of those are IPFS nodes, and a subset of those IPFS nodes are filecoin nodes. And there will be ways for IPFS nodes that don't even speak FalcoIn to retrieve or store things to filecoin already with some of the textile tooling with Powergate and so on, you can do this. Cool, I'm going to keep moving out of the so that's kind of in terms of the protocol and the network model, there's a lot there and we kind of covered a lot of ground. So we'll move through the rest of these kind of quickly and also very happy to dive deeper on any area. This is a large system, there's a lot going on.
00:35:30.530 - 00:36:17.854, Speaker A: And so if out of this workshop we find, hey, it'd be really great to do a deep dive on one of these, say like the decentralized storage cloud aspect or the app platform aspect or something like that, we can then turn those into follow on workshops. Cool. So let's dive into the actual blockchain. And so this means kind of how the blockchain itself is structured, how the consensus works, how the virtual machine and the contracts work and so on. So these are kind of like these subsystems within the system. So I mentioned before, kind of like the IPFS data structure stuff. So again, this means that we're using CIDs, which are these content Identifiers, and we're using Cboard as a format.
00:36:17.854 - 00:37:50.990, Speaker A: So it means that all of the data structures in the chain itself are easy to explore and so that might be much more familiar to traditional web developers and so on than a lot of the formats in other systems. When you think about the blockchain it has, think of the same components as you would see in any other blockchain where you. Have a set of blocks that are linking between themselves and you're running a consensus process to agree on the history of events and to also rate limit the set of parties that can produce blocks and so on. You're using a notion of transactions to put on messages onto this chain and those transactions are going to execute some code within the blockchain. And in order to kind of interact with the rest the network, you need a kind of chain sync protocol, like the ability for nodes to reason about what are the blocks that they see, what are the potential different heads of the chain and kind of agree on really figure out kind of what is the right chain to follow and so on. Sort of what a blockchain ends up being. And we can explore the testnet blockchain and so we can go to one of the blockchain explorers, see it's loading.
00:37:50.990 - 00:38:21.190, Speaker A: And so this is kind of an example of the blockchain is down here at the bottom. There's something interesting and different about this. I'll touch on in a moment and you can see kind of like the latest blocks and you can see the latest messages and so on. So let's look at an example block. This has only two messages going through. You can look at the actually, this is a tip set. I'll get into what tipsets are in a moment.
00:38:21.190 - 00:38:48.130, Speaker A: There are two blocks here. You can look at one block, you can see the hash of that block. And I'll increase my font size because that might be hard to see. You can see the hash of that block, you can see the height, you can see the time when it was mined and the number of messages this happened to have, I think zero messages. At least this is what this is saying. There's some other details around the validity of this block and so on. We don't have to think about that here.
00:38:48.130 - 00:39:16.326, Speaker A: And then you see a set of parents. This is one very important piece about filecoin consensus. It is not a linear chain with only a single block along the way. We use a way of having tip sets where at every height there are multiple winning blocks and those winning blocks agree on the set of parents. I won't dive deep into that. There's a few blog posts that explain how all of this works. But that means at a particular height there might be multiple blocks.
00:39:16.326 - 00:40:02.730, Speaker A: This helps with a number of things. One of the things it helps with is potential throughput in that you enter into a coordination kind of challenge and so on. But that could kind of in a limit give you a much higher level of throughput for the chain itself. And anyway, here are messages and here's how you can kind of see an example of what's going on. So this message is kind of from one account to another account. It has a particular nons certain amount of value, gas price and gas limit. It has a very similar model to Ethereum and then it's calling a specific method on that contract.
00:40:02.730 - 00:40:40.280, Speaker A: So I'll get to how that works in a moment. And all of these hashes, so all of these hashes and so on are CIDs. So they're like IPFS content and so on can be explored and you can see the actual data structure and so on. And so now these blocks like exactly the same as the theorem model. These blocks get put together into a chain and then the transactions and so on. Mutate a state tree. I'll dive into that in a moment.
00:40:40.280 - 00:41:35.096, Speaker A: Yeah, here's another look at the tip sets and kind of how to think about them. You can maybe think of like the visualization on the top where there's a number of different tip sets, one by different miners, pointing to a parent tip set. Let me find a blog post that kind of describes how this works. I'll post that here and if you're interested in looking at that more, you can read through that. One other important bit here is that the power that miners are exerting in order to mine and produce blocks is storage power, as we were saying. So it's not a proof of work blockchain in terms of hash power. It's based on actually having hardware.
00:41:35.096 - 00:42:24.556, Speaker A: Here's a mapping of the distribution of storage power in the testnet. And so this is about 20 petabytes worth of data storage going into producing the chain. And kind of pictures of the I was showing these the other day, but like pictures of the mining facilities, you can get a sense of kind of what miners are doing and their setups and whatnot. And most of them are on flat, so you can interact with them and you can talk to them and so on, and you can ask them questions. If you're considering building applications that interact with miners very closely, you can interact with them and talk to them. All right, cool. That's kind of like the blockchain part of it.
00:42:24.556 - 00:43:00.436, Speaker A: So we have a chain of blocks where we're putting messages. We're synchronizing that blockchain. We have a consensus protocol that is using storage power to agree on the chain. Now, what do these messages represent? So they are kind of invocations into code. So that's kind of where the virtual machine component comes in. And this is again a very similar model to Ethereum's where you can think of the same kind of idea of there being a state route with different contracts within that. And you can see the contracts, we call them actors instead of contracts.
00:43:00.436 - 00:44:12.656, Speaker A: And this is because we're taking steps to move the execution model of blockchains to kind of follow the kind of actor model that's very well understood in computer science. So this is a little bit of a different feel that maybe traditional smart contract history and recording contracts and so on describes, we think, the actor model and the message model and so on fits much more what's going on with Blockchains. Once you think about them operating in a scalable way with a lot of different lines of execution. So within one blockchain you have kind of a total view into all of the state and all of the contracts and so on. But that immediately fades away when you start thinking about scalable chains, any of the modern designs or when you think about a world interconnected by different blockchains. And so you really have to start thinking about contracts as kind of these simple message processors that are receiving invocations and sending out data. And so we think of that model.
00:44:12.656 - 00:45:03.612, Speaker A: That's kind of where the actor name comes from. But you can substitute in your mind actor for smart contracts in Ethereum and that's exactly the right way to think about it. So in our case an actor is just points to some code. It points to kind of like the head of its state. It has a non based on in some cases some actors can issue code from or can issue invocations from outside the chain and that's kind of where the nons comes in and it has a balance and that balance is in Falcon tokens. So it's almost the exact same model as Ethereum and then a message. So this is kind of the actual function invocation within the VM, there's an address that's kind of the caller.
00:45:03.612 - 00:46:01.776, Speaker A: There's a receiver and there's a certain amount of value. And then there's also set up parameters sorry, the screen grab that I got here doesn't show it because of go interfaces. But there's also set up parameters that then are passed into the actual code that you're calling. And so I'll give an example of that. And so you can go into this repo and that has the set of actors that operate within Filecoin. Today we're writing those directly in native code. So this is kind of like Bitcoin and Zcash and so on mostly because we want to have in the long term a multivm model where you can run the EVM and you can run some of the WASM VMs that are being developed now and so on.
00:46:01.776 - 00:47:35.520, Speaker A: So we'd like a super compatible world with a lot of different kind of user contracts but a lot of those things are not ready yet so that we're deferring that and kind of thinking that as stuff that will come in the future. For now there's only a set of kind of built in contracts that operate Filecoin and this was also kind of a decision based on security requirements where Filecoin is complex enough, we want to launch it without the additional complexity of dealing with user provided contracts. We want to have that come in as a network upgrade after the fact. So that means that all kinds of user contracts right now should just exist on Ethereum or any other chain that can do some kind of bridging. And in the future we can think about how as chains evolve and kind of the designs for more scalable blockchains like E two and so on really land and we start seeing how those work then we can think about what it would look like to then start putting in a lot of the user generated contracts directly on the chain. Some of the interesting utility for that will be being able to one of the things we want to drive towards and this will take a bunch of interesting R and D behind it, but we would like to be able to deploy contracts that operate on a portion of data and can do so verifiably without having to force all miners to compute that code. So that's a different execution model than what's going on with most blockchains today.
00:47:35.520 - 00:48:25.330, Speaker A: But that's what's going to let you build applications that compute on large amounts of data wherever that data is without having to kind of compute it everywhere. But you can think of that as where Falcon is headed, not at all where Falcon is now. You can dive into the specific contracts here, so give an example of a couple. So like the very basic account is implemented here. It exports two functions. There's a constructor and the ability to retrieve the address and then kind of beyond that, the account is kind of like a privileged contract in that sending value as part of the VM. And this is kind of like the actual code that gets run when you execute it.
00:48:25.330 - 00:49:35.940, Speaker A: You can look at something more interesting like the storage market. We'll dive into all of this in a moment, but the storage market is a contract that has the ability to add certain deals and so you can pass in specific storage deals and look at you polish a set of deals and that makes them submit them to the chain and they get processed and so on. We'll describe kind of how that works, but this is just kind of an example of how those contracts themselves are implemented. All right. And then the state tree is just kind of like how the state itself is housed. There's a tree of where it's kind of addressed by the actual kind of address of the contract the same way as Ethereum and then the state of that contract is stored there because we're using CBOR and so on. The state tree itself and the data structures are not married to any VM model.
00:49:35.940 - 00:50:38.272, Speaker A: And that's kind of why we are thinking of this as kind of like able to be able to work with a bunch of the different VMs. And what that gives us is the ability to then also write other kinds of applications against this where kind of in the future what we're hoping to do is think of the back end part of any web app as being able to be deployed to a subset of falcon nodes and then operating there. But we're laying the foundations for that now that's not here today. See a question is there any thought into how miners could be incentivized to store socially good content for free or is this at a set up for a layer such as IPFS where individual nodes would tend to mirror interesting or valuable content? Yes, totally. So we have a number of things in this direction. I'll touch on them later. We have a notion of verified clients that helps and we have a couple of projects around this where there's a way of just pooling resources for deals and having those deals be given to miners.
00:50:38.272 - 00:51:16.736, Speaker A: And so then you can have large groups of people organizing together to pay and fund for that work. When you really deal with petabytes of storage and so on, you really have to start accounting and making decisions because it does cost significant money to store stuff and transfer it. I think the transferring part is much harder when you want to move around petabytes of stuff, you can't just send it over the internet. You now have to deal with people sending disks to each other through packages or whatever. And at that point really considerable costs started adding up. So you do have to think about the economic flow there. You can't just kind of write it off for free, but that's where the block reward comes in.
00:51:16.736 - 00:52:06.960, Speaker A: So we've come up with a bunch of really clever ways of guiding a lot of the block reward benefit to help store a lot of really valuable data. Great. So I'd love to kind of move on from the VM and start getting into some of the markets and the storage part because that's I think kind of like the meat of what's interesting about Filecoin. But I do want to just make sure that kind of like the VM model and so on is sort of clear. Of course there's a lot of details know super new and whatnot, but if there are any kind of questions on the VM model, I can take them now. Sweet. All right, sounds good.
00:52:06.960 - 00:53:45.670, Speaker A: Let's jump into the markets. All right, so now that you have the concept of, like, hey, there's a blockchain out there, and we can run code, and we also have this storage power consensus thing that is causing based on the block reward is causing a lot of storage to come together. Let's figure out how to turn that storage into something really useful. So really, let's figure out how to take a lot of storage that's coming together primarily for the block reward and then turn that storage into data that you can serve out to users. And so this is kind of like where the decentralized market aspect comes in. So I'm going to move to a different set of slides because I have a bunch of these already. A model is kind of like this, where you have miners and clients put up a notion of pricing information, and what you want the network to do is to help those parties find each other and then execute deals together to agree on some data getting stored.
00:53:45.670 - 00:55:05.874, Speaker A: And so the key thing here is that miners are amassing storage because of the block reward. Now that they have that storage, they want to take deals in order to make that storage even more profitable, right? So think of the block reward as paying for capacity to exist, so paying for a lot of work to be done in terms of causing capacity to exist. And now that that capacity is there and that storage has to be provided, then selling kind of storage in that capacity becomes a much easier question and it also kind of gets subsidized in a way. The block reward is acting as a bit of a subsidy there. So the model for the storage market has evolved a lot over time. What we want to end up with in the long term is kind of like think of a fully commoditized world where you can think of order books for the storage itself. You can think of adding storage bids and asks and so on to a completely decentralized exchange where miners and clients can find each other, can agree on price and a few other characteristics and then can kind of execute deals.
00:55:05.874 - 00:56:40.962, Speaker A: This also means that it opens up all kinds of very interesting DeFi cases where we've barely scratched the surface on this. But when you commoditize anything, you also create the ability to financialize stuff on top where parties can come together and sort of think about reason, about the supply of hardware and the supply of data and so on and then start creating kind of next layer or second layer contracts around, being able to kind of buy a certain amount of storage at a certain point in time and so on, or being able to defer that or things like that. So we think that there's a ton of really interesting DeFi cases here that kind of emerge out of providing kind of the market structures. But yes, at the end of the day, because of chain throughput we had to move all of kind of the asking and bidding and so on entirely of change. So it's not as verifiable so this is kind of like not as verifiable of a spot as we would like, but what we can do is the deals themselves. So once miners and clients interact and find each other and I'll describe a bit of kind of how that happens they agree on a deal and some terms, the client sends data over to the miner, they form a deal, they sign it and that deal is what goes on chain. And then those deals are at that point, now that the deal is on chain, the network can verify that miners are indeed storing data.
00:56:40.962 - 00:58:07.086, Speaker A: So maybe a simple way of thinking about it is this is kind of like virtualized in the sense that the network is sort of an intermediary between clients and miners, where the clients provide the data and the money and lock it up with the network. And then if miners are able to provide proofs over time that they are indeed storing the data, then the network pays out the miners over time. So think of that reward as being unlocked over a period of time. You have to make sure that a lot of the kind of design problem of filecoin is thinking about all kinds of conditions where parties are malicious in this structure and so on. I won't go into detail on this here, but the mechanism design that yielded the way that the deals work and so on has to cover for a whole bunch of really tricky edge cases about this. And so this is kind of like the we saw in the visualization earlier, where kind of miners so clients take a set of miners and then kind of send the data to them and then they agree on some terms and they sort of the data. If you want to kind of see what the actual code looks like for that or the spec and so on, you can go to kind of the storage market part here, and you can dive into kind of what the flows look like.
00:58:07.086 - 00:58:58.942, Speaker A: This is very detailed, like perhaps too detailed. There's some much higher level description description here where you can think of a very basic view of the world where a user contacts a minor, pays them to sort of the data and so on. But what's really going on under the hood is clients and miners are interacting. They kind of select each other, they form a deal, the miner puts the deal on the chain. Once the deal is on the chain, you have verifiability of that deal being in effect. And then for the duration of that deal, the network is going to monitor and make sure that the miners are indeed storing the data. And if they're not storing it, then there'll be significant penalty associated with that.
00:58:58.942 - 01:00:08.716, Speaker A: The way that the data is stored is in the thing we call sectors. I won't go into a lot of details on this now, but if you are interested and curious about how that's structured, you can look at the files and data section. In this document you can see this image sorry, actually not quite this image. I'll get the actual source where that comes from. I'll touch on this briefly because it might affect how you're thinking about applications. But the way that the user's data is stored is that we first think about structuring the data in an IPLD graph or an IPS graph. So if you're used to using IPFS or just IPS add, that's it.
01:00:08.716 - 01:01:15.330, Speaker A: You don't have to think about it very much more. But what's going on underneath the hood is that that graph of files or you can think of it as a textile thread or something like that that entire graph of hash linked objects is kind of pulled together into thing we call a car. Think of it like a tar file but it's just for these graphs and then that kind of bundle gets sent over to the Miner and then the Miner there's kind of like some complex processing that has to happen for the provability of this and the verifiability. So there's a lot of important details about how to make sure that you can indeed verify that that data is getting stored and that's kind of what this proving tree stuff is for. I won't go into detail here, but if for whatever reason this is interesting, I can refer you to content that's in deepa in a couple of talks about it and then you can think of those pieces once the Miner has them. That data gets pulled together with a lot of other people's data and then pulled together into a thing we call a sector. And the sectors have a particular fixed size.
01:01:15.330 - 01:02:16.996, Speaker A: I believe the current proof parameter is set it at 32GB. And so if you have a lot less smaller storage then your piece would kind of ride along with other parties. All of those pieces of data would be pulled together into a sector. A Miner would take that sector and then would store that in the network. Now, how that storage happens, that's where kind of like some of the Falcon magic comes in where how to make sure that that large quantities of data we're talking terabytes to petabytes and so on are indeed verified over time and how do we know with high assurance that that data is there? That's where all the preserve replication come in and the ongoing kind of checks and whatnot. I probably won't go into a lot of detail here now but again, if that's interesting I'm happy to refer you to documentation or have another workshop or something like that. But maybe suffice it to say for now that once the client cares about these kind of graphs of data and just kind of sending them to the miner and being able to kind of refer to these graphs of data by their CID.
01:02:16.996 - 01:02:56.004, Speaker A: And the miner takes those graphs of data, puts them together with other people's data into a sector. You can think of the flow maybe like this, where these are somewhat old slides, but a lot. Of the same kind of model applies. Where there's a deal proposal that happens, the miner accepts it. Then you are actually sending the data over. And then once that is verified, then the deal goes on chain and then the deal is made. There's like a much more rigorous version of this here in the spec itself.
01:02:56.004 - 01:04:18.924, Speaker A: So this is kind of these diagrams and so on are the proper version of the more rigorous version of what's going on here. Cool. I'm going to pause for some questions. So question when you say that the block reward is to incentivize creation of storage capacity then is the plan that the Storage Miner be incentivized to bid for storage deals, is that akin to the Bitcoin miner adding transactions to the block for the tips associated with each transaction? Yeah, because of kind of the crypto economic construction you need to enable miners to just commit capacity and count that as power. But once they have capacity, then they can sell the capacity for deals what we describe as kind of a capacity upgrade where once they have pledged to be storing a certain amount of data and that's kind of made verifiable Falcon checks that that capacity is indeed there, then miners can sell that space and then prepare an actual sector with people's. Data and then we call it sealing the sector. And then they now have a specific amount of storage that they're storing and backing up for people.
01:04:18.924 - 01:05:19.740, Speaker A: Something that might be an interesting hack by the way is just visualizing all of that data. So a lot of the information, the data about all of the data storage is so think of it as kind of like that sector Explorer as opposed to a Chain Explorer being able to see all miners and the sectors they have and the deals and who they're making those deals with and so on. That might be like a really cool hack where just being able to see the there might be a bunch of interesting ways of visualizing that data or seeing the kind of the history of that data. This might be also something that the Chain Explorer folks may be interested in making. But yeah, going back to your question, the block reward covers the very high expense of actually provisioning all of the hardware for a certain amount of time. That's kind of like a big part of it. Then from that, once that you are paying for that amount of space and storage to be through the block reward, then that kind of the remainder is paid by the deals.
01:05:19.740 - 01:06:06.210, Speaker A: Now of course the block reward is on a schedule that is increasing over time. So the block reward subsidy, you can think of it as borrowing over the long term future, kind of like on a decades timescale. The ideal is for the utility of FalcoIn to grow over time to the point where the deals themselves are paying for the storage. But you can think of that as like a 2030 problem, not a 2020 problem. Great. So is there any metrics on how hyper competitive pricing will compare to Amazon S Three storage? Good question. We're not sure, but the cost structure is very different because in kind of s three and so on, you're paying for the actual storage itself.
01:06:06.210 - 01:07:08.784, Speaker A: If you're trying to get the storage. If you're just trying to think of storing data on filecoin, you just have to pay primarily for the transfer because the block reward will kind of offload the actual disk upkeep and disk hardware cost and you have to beat other parties in the market, right? So there's kind of like a very different dynamic about pricing the storage of filecoin, which is different from any other content storage network that we've seen in the past. And so we hope that that will think about a proof of work networks today where the block reward is subsidizing the production of massive amounts of hash rate. So tons of hashes are going happening constantly and they're just getting dissipated. Imagine if you could take those hashes and sell them for something useful. That's what Falcon is proposing. And so the bulk of the cost is going to be paid for by the block reward.
01:07:08.784 - 01:08:01.940, Speaker A: The remainder that should allow us to get some really competitive prices. Now, part of the trickiness though, is once you reach large amounts of data, when you think of petabytes scale, then you have to think about moving petabytes of data. And moving petabytes of data alone requires time. So there's kind of some costs associated with that. So we mostly think about as paying for the cost of getting the data to the miners. Is there a plan to make the Falcon API for storage be sort of plug and play compatible with S three? Yeah, totally. So this is where I think there are already some libraries working on this, but I would actually recommend some of the textile power gate stuff is kind of mirrored in that way, where just think of textile buckets as an S three storage bucket and you just store stuff on textile and then you archive it over to filecoin.
01:08:01.940 - 01:08:53.760, Speaker A: From a developer perspective, you don't have to worry about most of what I've talked about in this workshop. You probably don't have to worry about if all you want to do is just use Falcon as a developer. Because in that case, you can just use powergate to just do all of this heavy lifting for you. A lot of this will be interesting and valuable and useful to people that want to hack and build tools. Like maybe you want to build like a storage marketplace, or you want to build this order book that I'm describing or something like that. Another question, how would miners know when it's safe to delete storage? Is there some type of delete incentive so the deals are timed? So when you agree on a deal, you agree on a certain timescale. And as those deals expire, a sector will also expire once all those deals are expired.
01:08:53.760 - 01:09:43.424, Speaker A: And once all deals expire, then miners can garbage collect that sector and reuse the space. And so that means that miners have to do some have to time the distribution of deals and so on to. Pack deals that are close in expiration time together and so on, and miners can take care of that. Where can I get second part of the question is, is there some type of delete incentive? So there's a different problem here which is not expiration, but rather you want to delete something. And that's a very hard question to answer. We are working with a content policy structure where clients and minors should be able to agree. So it's kind of like work in progress and a bunch of open questions, but clients and minors should be able to agree on content that shouldn't be served anymore.
01:09:43.424 - 01:10:48.984, Speaker A: So if some content you don't want to be distributed anymore is there, you can kind of ask miners not to do that, but there's kind of some incentive structure there. At the end of the day, if any storage system has your data, they could be selling it or moving it around and serving it to other people. Whether it's a decentralized network or a centralized one, that model is not different. What is different is that first of all, you should probably be encrypting things on your client side anyway, so that if the miners serve the ciphertext, then that's useful, but not that useful to another party. But then beyond that, if you want to kind of stop the spread of some data, then it really becomes a market problem. You basically have to outbid the parties that want to distribute that content. And that's just a kind of natural extension of how information spreads on the network, right? So there are a lot of people that say don't want you to view Wikipedia, and so Wikipedia however, is seen as really valuable by other people.
01:10:48.984 - 01:11:32.712, Speaker A: And at the end of the day, it's a market question and a market dynamic that yields whether or not you can view Wikipedia. And so I don't know if that helps answer that. But yeah, I think the question gets trickier when you start thinking about content that's where a certain region or something is kind of like outlawing things. The right model for that is to have kind of like block lists that individual miners are subscribing to. And so miners can say, hey, I'm in this region, I don't want to host any content that's in this block list. So just FYI client, if the content's in here, then I'm just not going to serve it to anybody anymore. And then as soon as the deal expires, then that's it.
01:11:32.712 - 01:12:17.288, Speaker A: And so having that's what allows you to deal with a multinational perspective where different nations disagree about what is okay to share. And even within a nation, different agents within that nation might disagree about what's okay to share. Right? So this is kind of like where there's all kinds of lists of banned books and so on, and yet people distribute them. And that's again an economic problem. Some people are taking some risk and some higher cost. For spreading that content. And that's how you really make a properly decentralized network that allows parties to respect their local laws and so on, and allows parties to disagree and choose to opt to distribute the content anyway.
01:12:17.288 - 01:13:15.028, Speaker A: But that's kind of a choice that's left up to the miners themselves. So you don't want to compel parties to do stuff. Now, given a storage system, given that any kind of like anonymous parties could be moving around pieces of ciphertext and so on, that are really difficult to trace and so on, and that's kind of the same as any other network. And so that kind of distribution is a separate part, but it kind of works in layers. All right, I'm going to move to a different question. Where can I get the last information about how Falcon prevents a generation attack? Or rather a miner claiming they're storing petabytes of valid zeros? Is the white paper the most recent technical deep dive into this? No, you can look at so this is kind of the proofs of replication work that we've done recently. There's a set of novel proofs that we're working with now that just have different performance characteristics.
01:13:15.028 - 01:14:11.066, Speaker A: You can dive into the papers of those. You can look at filecoin research. Once again, I'll post, if you look at this website, eight whole bunch of different papers about this. The one we're using right now is called SDR. I think this is the paper. You can look at this one. This is one of them.
01:14:11.066 - 01:14:51.500, Speaker A: I think the actual SDR paper is a different one, might be this one. This is brgor up. I can get you the actual paper later on. Yeah, if you're interested in diving deep into this, happy to. The other thing you can do is look at CryptoLab, which is the group that's doing this this work and actually implementing it. Look at this repo. If you're interested in looking at the actual code that goes into this.
01:14:51.500 - 01:15:35.012, Speaker A: This has the implementations of the proofs themselves. So you can dive into them here's. Cool. I'm going to move to the next one. What stops a storage minor from refusing to make data available, forcing clients to choose higher redundancy parameters, thereby making it enriching all the storage miners? Does a storage miner know when they are fetching data for preset retrieval? Great question. So a couple of things to note about that. That's an interesting piece.
01:15:35.012 - 01:16:47.868, Speaker A: So I think think about people storing data. At the end of the day, if you want to store data in networks, what you want to do is kind of erasure code things and disseminate them to many miners, right? So if you start with large amounts of data, you'll kind of erase your code it and get some line of redundancy factor. This allows you to have different replicas that give you very high reliability and redundancy without paying a very high factor in terms of into the storage cost. This is very useful when you're thinking about many petabytes of data. If you're thinking of like ten petabytes of data, you want to disseminate those ten petabytes over many miners and you want to be able to just choose a few to retrieve content. So one of the things that helps is a you can do that with many parties and you can agree on certain deal terms and there's deal collaterals associated with them. And in the very basic sense, there is a macro reputation game where if miners start doing something like not serving data and kind of colluding on this and so on, that'll very quickly be detectable and clients, just like miners can form coalitions against that.
01:16:47.868 - 01:17:52.976, Speaker A: So if you're worried about kind of coalitions of miners, note that most of the miners are known organizations, they'll have huge amounts of storage and so on, and clients which are also kind of can be known organizations, at least the really big ones, can also form coalitions against that. And so you can think of like when you think about building tooling for filecoin, think of a marketplace showing the past deals of a miner with all the other accounts and you could associate reviews with that and then right away you can with a very simple reputation system knock out, I would guess, most of the problems in the picture. So that's kind of like totally a layer two solution that's available to you. But suppose that you don't want to do that and maybe that tool doesn't exist or you just don't want to engage in that. You have a few things available. One is you can go for a broader razor coding factor and then breaking it up into small pieces and giving them to a bunch of different miners. And then the hope there is that the collusion won't be high enough, that miners will kind of all agree on this.
01:17:52.976 - 01:18:53.716, Speaker A: The other thing you can do is produce just there's a very trivial solution, which is you construct different clients, you have say, ten different anonymous clients and you make ten different independent deals with in each case like three different miners. And at that point the miners can't really correlate between those. And so it becomes extremely difficult to kind of withhold information. At the end of the day, there's kind of like the macro game of what if all miners don't want to distribute any data? And that's just a market problem. Just given how profitable content delivery is and CDNS and bandwidth costs and so on, given that miners have data, miners will get a much higher ROI by dealing with clients. And so we don't think it's a stable equilibrium at all to expect all miners to collude, to kind of hike prices up like that. If they could do that, then they could collude to double spend as well.
01:18:53.716 - 01:19:52.984, Speaker A: And that's a much more profitable collusion, right? So if you think of as bitcoin miners or ethereum miners in this way, then we're talking about a full collusion between all parties such that they could just as well try to double spend or something like that. Of course, the dynamics of the attack are different, and certainly if you collude to double spend, you're harming the network, so maybe you're harming your investment, and so all those kinds of things apply. But overall, we think there's a whole bunch of different strategies here where we don't think kind of collusions of miners to kind of withhold the data and not serve it is going to be a real problem. We think the more important thing there is just fairly compensating miners for actually delivering the data. And that's a piece here that's important to consider. All right, let's see. I think we've been going for about an hour and a half, and there's a lot of really interesting details here, a lot of really useful questions.
01:19:52.984 - 01:20:21.600, Speaker A: We've touched on the protocol in the network, the blockchain, some aspects of the decentralized market. I haven't dived deep into kind of how the retrieval market works. We started looking at some amount of the questions, started touching on decentralized storage cloud. We haven't made it through the rest of the stuff, and that's probably fine. I think most of the questions address a number of the key things here. I have more time, but I also know that Ethgobal folks are in the East Coast, and so it's getting late over there for them. A couple of options.
01:20:21.600 - 01:21:10.720, Speaker A: Either I can go a little bit longer and maybe have some kind of concluding statements on some of these things, or we can pause and I can do the rest of this Friday or next week. I'd be curious what folks would people prefer to keep going or kind of defer to later? Could I get like a show of hands or something? Looks like most people are saying they want to continue a bit more. We're good? You sure? Yeah. All right. Sounds good. Let's keep going then. It touched on the storage market.
01:21:10.720 - 01:22:06.256, Speaker A: Let's now talk about retrieval because we started some of the questions around that now. But there's one part of retrieval which is, given that I've given my data to a minor, I just want to get it back to that minor. And we think of that as kind of like v zero layer zero of retrieval. Now, that may not be super high performance because you can think of the storage market, the storage part of the equation as tuning for hardware setups where long term storage is the main goal. You want to do really cheap long term storage of a lot of data. So you want to as a storage miner, you want to amass large amounts of hardware and drives and so on to storage large amounts of data. And so that will correlate usually with we think of this as kind of different segments of storage.
01:22:06.256 - 01:24:32.838, Speaker A: Miners will exist, but it'll be some distribution where parties in data centers and in ISPs and so on will be a bulk of the equation and likely a lot of kind of like a really considerable cloud of storage miners that are kind of storing somewhere between 100 terabytes to a couple of petabytes or something like that. And that is totally reasonable to have in a house, for example, where you could put in a mining rig in a house that has kind of that level of storage but it is kind of a considerable investment to be kind of storage miners at that scale moving the content. We should be thinking about the storage market in the retail market as kind of hard drives and Ram. So that's kind of like a good model for thinking about this. Think of the network as fluidly moving from long term storage to kind of like hot cache to deliver content. I actually have a visualization of this that might be useful one SEC, like a million keynote. So in the left side of this diagram is a diagram that comes straight from, I think Google cloud which kind of describes how they layer their cloud infrastructure.
01:24:32.838 - 01:26:08.650, Speaker A: And this is pretty normal and traditional with how most storage clouds end up working where there's a set of core data centers that exist in a few cities and then from there there's kind of a set of edge points of presence which are at a bunch of places in internet interconnects. So these interconnects are a specific type of type of facility where a few different organizations maybe have a kind of connection point in the actual internet. It's really useful to remember that the internet is just a bunch of wires put together with a bunch of different organizations running these wires. So an interconnect is where a lot of those different organizations kind of meet and so it's very useful to have these edge points of presence there because you can very quickly address content and deliver it there. And then there's a whole set of things around edge caching and service nodes edge caching gets into. These are fuzzily defined but you could think of maybe the boundary of points of presence being the ISP layer where some storage groups and so on will kind of ship hardware to ISPs and actually store stuff directly in the data centers of ISPs. So that kind of like the end of consumers can very quickly access some of the content and then finally kind of a lot of nodes in the edges where that might still count ISPs or it might count certain kind of high density areas like universities or large buildings and so on and in some new forms of distribution.
01:26:08.650 - 01:27:36.210, Speaker A: Where we think a lot of this will head is people will have large amounts of storage in their homes and so on and parties will kind of push content to those ahead of time. And that sounds kind of like kind of crazy. But when you think of the storage density graph and cost structure versus the bandwidth cost structure and when you think about the media in movies and VR and so on and the sizes of those media, storage size is greatly outpacing the sorry, storage price is greatly outpacing bandwidth price in terms of cost reductions. So that means that over time people are going to be amassing larger and larger amounts of storage but it's going to be pretty hard and difficult to move that information over the wire. Plus there are speed of light issues, right? If you want to watch something at 4K or higher resolutions and not have to wait for it, you end up in a very different part of the world sorry, very different part of the design spectrum where ideally you're trying to push a lot of things all the way to the users. So that really becomes a game not of storing everything there but of figuring out what you need to store in those regions. And so today the CDN companies are in that business of trying to figure out what to deploy to different regions and what to host in some places.
01:27:36.210 - 01:28:37.260, Speaker A: There are also some interesting groups that are deploying their own boxes directly to that. A good example of that is Netflix. Let me show some of that as well. I think I have it in the same one that's interfering I'll differ that for later. But part of the point is when you think of kind of a topology of the internet, it's kind of like this really large grapevine and it kind of gets closer and closer to the users. You want to try and store some fraction of the content as close to users as you can. And this is where the way we look at it is there's a very clean decoupling between the problem of storing data for the long term and the problem of serving data to users very quickly and they have different economic structures and different data signals and so on that would kind of factor in.
01:28:37.260 - 01:29:56.280, Speaker A: And that's what comes in as a division between storage miners and retrieval miners. So you can think of storage miners as mapping to kind of like the kind of core data center or to some extent some of the edge points of presence in kind of like the most distributed case. And then you can think of retrieval miners as really like all of the edge caching and service nodes that you want to kind of deploy everywhere. And so what you want to do is build protocols by which many different parties can come together and form that CDN and distribute some of the information and the content. There's a lot of interesting open problems on this. So the retool market in Filecoin is way less developed than the storage market, mostly because we wanted to kick off the network as soon as we could and put a lot of it in place and then kind of start the process of building out the CDN over time as kind of the demand starts pulling that. But it's maybe worth noting that this might be really valuable hack material meaning if folks are interested in that aspect of it, the content delivery, fast retrieval, a lot of the primitives are there and it just kind of needs some interesting pieces pulling together some of that functionality to make a kind of auto scaling CDN.
01:29:56.280 - 01:31:13.516, Speaker A: Worth noting there that there's a very large space for strategies and decision making in what content to move where predictably from all kinds of interesting data sources. So think of the DeFi world and what's been done with kind of like Oracles and Chainlink and so on about all kinds of different price indexes and so on. And then think of a world where you have many different agents being able to run their own strategies about speculatively moving content to different places and turning CDNS into like a proper open market is something that we find extremely interesting. And we have the primitives there in terms of we can address all of the content, we have the storage miners and the content there and we have the retrieval process of how a node might be retrieving the data from somebody else and kind of using payment channels to pay for that data quickly. What we don't have is all of that diversity of agents with all the different strategies and so on. So there's a bunch of really interesting hacks related to this. Maybe leave it at that in that maybe to another couple of shots of retail mining.
01:31:13.516 - 01:32:20.390, Speaker A: But, yeah, this might be worth kind of like an interesting deep dive next week of, like hey, if people are interested in looking at the retrial market more closely, I can put together something around. Hey, if you were to. We can make this a hacking workshop where we can look at gossip sub and the pub sub oriented stuff and we can look at payment channels and we can look at trying to piece it together and see how you can do kind of pretty fast delivery. I think something like an interesting hack idea might be having a bare bones client like that, bare bones piece of software like that, that can do the retrial mining piece, but which lets you try different strategies in JavaScript. So, like, the user downloads this piece of code. You delegate some amount of storage to this network, and then you pick a strategy which is just JavaScript file that kind of makes decisions, and then you can give that to a lot of people and then let people come up with a bunch of different strategies of how to pick what content to move where. And that could become a really interesting kind of CDN world.
01:32:20.390 - 01:33:32.184, Speaker A: So that's kind of like the basics of retrieval versus storage. It might be useful to one other really important and really crucial detail for the early days of the Falco network that's kind of relevant right now will be less relevant later on. The storage miners, the way that the kind of things work now is that when they store data, it's not just kind of in a specific facility and so on, that's kind of tuned for large storage and whatnot. But storage miners are right now having to store effectively two copies of the data, one in the clear and one with some encoding on top of that. And that's an artifact of the current proof that we're doing because the current proof that we're doing has a very slow encode and decode time. And there's a very long story as to why we ended up with this one and why we're shipping with this one as opposed to shipping waiting for something that is way faster. But the proof that's going to ship kind of on Mainet launch has a set of characteristics that it's slow and expensive to compute.
01:33:32.184 - 01:34:14.824, Speaker A: Therefore, miners also keep around an extra copy that's in the clear. And so that extra copy that's in the clear is not verified. The verified part is what's encoded and encrypted. So miners could cheat and not sort that extra copy. But miners that do that will lose business pretty quickly because clients will spot that and will seize to use that minor. Now the goal is to have a proof of application that is very fast and does not force that kind of keeping around of a second copy. That's like a hack and a pragmatic solution for now to deal with that kind of expense problem.
01:34:14.824 - 01:35:17.250, Speaker A: But an idea of what that would look like is like these were graphs made based on this is a different proof of application not as the one we're using now, but you can think of it as like giving the sealing process and getting it out of sealing when the proof of replication is slow as being taking minutes to unseal. And so that's kind of like why keeping a copy in the clear is really important. As proofs get cheaper and faster, then storage proofs can actually move all the way into kind of like the milliseconds range. And so being able to decode things really quickly is an important goal. But there's so many different directions and so many important things to build that this is kind of like a problem that we've left for later of producing that proof. For now. The Pragmatic solution is go for security for now with a current protocol and move this proof into a better spot in the future.
01:35:17.250 - 01:35:57.292, Speaker A: We already have algorithms that can do this. It's a matter of but they require either a lot more certainty about they require a lot more certainty about time. I won't go into that. But that's where a lot of the consensus of blockchains is moving towards is using a primitive called VDFS, which are verifiable delay functions. And this is both something that we want to do and Ethereum Two wants to do. And so very likely most blockchains will end up having a verifiable delay function as a primitive. And then if hardware for that exists, then you can really make these storage proofs to be super fast.
01:35:57.292 - 01:36:50.840, Speaker A: It's just a matter of having that hardware and that hardware is expensive to develop. Think of it as like an ASIC for time. Like you want secure time and you can build an ASIC to give you secure time if people are interested in that, happy to give resources to or point you to that. Maybe I'll drop a link is this is research that's pretty useful and valuable to us in Ethereum too, but it's kind of like some time out. So the way that we're thinking about this is once those primitives become available, then we can shift to have really cheap and fast proofs for storage miners. And so storage miners will kind of move from kind of like this world where they have to either be slow or store two copies into a world where they can just store one copy and be really fast. That's kind of like for developers and for end users.
01:36:50.840 - 01:37:35.988, Speaker A: What you need to know is storage miners just have to store these two copies. They have to store one sealed copy and one unsealed copy. And that's kind of annoying, but it's kind of like a pragmatic okay place to be for now. Now, where retrieval miners are is a whole other pretty interesting place where today they kind of may inhabit the region of 100 milliseconds to kind of like a few seconds of latency. But ideally you want to push those retail miners all the way to serving kind of like in sub ten milliseconds world. So that's where we're really building a market can really deliver that because no CDN. The claim of filecoin is that no centralized organization can outpace a market.
01:37:35.988 - 01:38:44.072, Speaker A: And so if you create a market dynamic for solving that problem, then you can solve it in a much better way, much faster way that responds to the actual demand. And so the point is we just got to get the right primitives in place to enable anybody to just add in storage and be able to kind of decide what to get and so on. And so, yeah, this might be like a really good hack material because it could get really fun. We could think about running a competition for different strategies of like, hey, here's this distribution of content information and how much is being requested over time and let's see if your strategy outdoes some other strategy of content delivery. All right, I could probably talk about retail for ever, so I'm going to pause there unless there are a bunch of questions about it. I'll check on Chat for now about censorship. Is storing private data and enterprise data in filecoin totally anonymous what if government requests storage miners to store user data with identification of real names? We can build apps on top of Filecoin, but the cost will be increased.
01:38:44.072 - 01:39:50.704, Speaker A: So you can think of private data in storage networks as layers, right? So users and applications should be encrypting the data before it touches filecoin, and so that data should get encrypted ahead of time. And so, for example, if you use textile's powergate, that happens for you. Powergate handles this for you underneath the hood, where it'll take your data, put it into a bucket or a textile thread, and encrypt it. And it's the encrypted stuff that ends up being added to filecoin. But that's only one layer once you could still be in a world where these ciphertexts are known or the keys are published or extracted or something like that. And so you want further assurance about deleting that content or not storing it or storing it. So different parties want different things here, and that's what becomes a market problem.
01:39:50.704 - 01:40:14.570, Speaker A: So it could be that some well known content, a lot of miners do not want to store that content, period. And no matter how much money you offer them, they won't do it. But other miners in other parts of the world might do it, right? And so they might say, yeah, that's totally fine here. Like, no problem. I can store that content here. And so this becomes entirely a market based problem. But that's only in a world where you know what the ciphertexts are.
01:40:14.570 - 01:41:16.108, Speaker A: If you don't know what the ciphertexts are, then you don't really have the ability to reason about it. Now, there are some jurisdictions where people are questioning the entire use of encryption, right? And so we may see a world where people fight against encryption and remove encryption. And that's a very possible thing. I would imagine miners in those regions refusing to store anything that looks like encrypted content and only agreeing to store stuff that looks like clear text, valuable data. I would say that that's still a really useful service in some domains where, for example, tons of important valuable data is entirely public. So think of most websites, most scientific data sets, most large scale data in the world is kind of public by default. Like, tons of data sets about the world, like spatial imagery, telemetry, like IoT streams and so on.
01:41:16.108 - 01:41:47.012, Speaker A: A lot of that stuff is just public. And so that's totally fine. And you can also live in a world where then people start doing secondography on top of that, where, hey, there's like a whole bunch of files that look to be X but are actually Y. It's just different kind of encryption. It's not encryption, but it's obfuscation going on. And so I think in a world where jurisdictions start out long encryption, that's kind of where I think things will head. But for the most part, in most of the world, end to end encryption.
01:41:47.012 - 01:42:52.696, Speaker A: Is valued, and encryption at rest is valued. At the end of the day, the important thing is that this is a market and there's choice. Meaning miners and clients are agreeing to enter into a contract together and are agreeing on the parameters of that contract, and they can disagree on it, right? And there are collaterals associated with that, right. So if breaking a deal involves sacrificing collateral, but that's kind of like what you enter into that contract with, right? So you can define kind of the parameters ahead of time. We've explored some contracts where you could agree on a list ahead of time and say, if the content you're giving me appears on this list, then a miner gets to break the contract without paying that collateral. And maybe the client pays the collateral because they said something that they did something bad or something. And that's stuff that is interesting to explore, and it's out there for folks to explore.
01:42:52.696 - 01:43:42.110, Speaker A: But that's not kind of like in the base layer. That's kind of like an interesting kind of like, layer two type conditions. All right, I'll mention two other markets briefly. I won't go into detail here, but it's worth noting that a really important market in place that supports all of Filcoin is just the raw hardware market, right? So the prices of disks, the prices of just computers and computing nodes to do the ceiling, and the prices of data centers and so on, all of that market pricing greatly affects the pricing in the storage market and retrieval market. And it's a very important part of the equation when you think about the modeling the economy of filecoin. But you can think of that as like an off chain market. We don't have to worry about it.
01:43:42.110 - 01:44:49.632, Speaker A: We know of some folks that are interested in doing selling hardware for filecoin, and that is stuff that we think would be extremely, extremely interesting and valuable because that can make the economy of FalcoIn very strong. I don't think I'll get to dive into it in depth here, but if people are interested, I'm happy to dive into this later on. When you start thinking about Falcon as an economy and you start thinking about the economic flows of that entity, the more that you can do with that currency and keep it within that currency, the stronger that economy becomes. And so if a lot of the production that's going on into producing the goods of that economy are priced in the currency of that economy, then the better that economy will do. So parties selling the same hardware at the same cost in the currency of that network ends up being an extremely powerful, powerful structure. So if people want to sell disks and mining equipment and so on for filecoin, that's like a very useful thing to do. Another market I'll mention is the loan market.
01:44:49.632 - 01:46:06.852, Speaker A: So this is where collaterals are pretty significant in a large part of making sure that verifiability remains. Meaning we can check that something that a party has done x but if they haven't or they've done something bad then we have to slash some collaterals. So in order to allow all kinds of parties to enter, then having a loan market associated with FalcoIn is a very useful thing because it enables miners that are very new and don't yet have significant amounts of can get loans to create large deployments quickly, as opposed to kind of like starting small and having to wait until that accrues. So we think a very strong DeFi loan market will exist around filecoin to facilitate the loans of collateral to storage and retail miners. And so that's something that I think that is an amazing hack potential for hackfs where if you are pretty familiar with DeFi building a loan market in Ethereum to just do filecoin collateral loans that would be super interesting and valuable right away to a lot of folks. So if you're interested in that you should check that out. Cool.
01:46:06.852 - 01:47:07.228, Speaker A: So I think from here yeah, we touched on this extensively here and there kind of talking about retrieval, mining and so on. The verifiability of the storage is given by the proofs in the protocol so the proof of replication and so on are what checks, what's going on. You can think of the blockchain as issuing a challenge constantly to miners to make sure that they are indeed storing things properly and if they're not they get slashed. If they are indeed then they get rewarded. Now, when you think of turning a large network like this into a very useful storage cloud, a few properties that we want to lean on kind of appear very quickly. One is like the block reward subsidy is a big piece of this. So the block reward subsidy allows us to amass large amounts of storage very quickly.
01:47:07.228 - 01:48:15.152, Speaker A: So the Falcon testnet right now has on the order of 20 petabytes of storage that is larger than any other storage network that's decentralized and it is way larger than many storage systems that are centralized today. It's certainly very small compared to some of the larger clouds but this is a testnet with no economic incentive yet once there are very strong economic incentives we can likely amass hundreds of petabytes to exabytes. I think the binding constraint we think will actually be the chain throughput. So right now we're doing all kinds of complex work to try and squeeze more throughput out of the chain. But we think the binding constraint that's going to actually limit the amount of storage on the Falcon network will actually just be the chain throughput of being able to onboard that amount of storage. So that's kind of like a good problem to have but definitely something that has us looking very closely at all of the scalability solutions that are out there. It's very difficult to make this into off chain state channel kind of work.
01:48:15.152 - 01:49:38.876, Speaker A: There is some potential for that. If people are interested in exploring that as like an interesting hack, it's a very advanced kind of deeper thing, can definitely be looked at, but it is a whole other ballgame. One part is like having this large amount of storage which is really cheap, is really valuable and really useful. Another part is that kind of decentralized piece of the equation of saying, if we can enable a lot of parties to have these strategies and these marketplaces to exist very well where clients and miners can find each other, very quickly, then that can yield all kinds of cost reductions that are available to these smaller players, but that are not available to large parties. So it could be that parties can price certain things at certain points in specific size but not in kind of a very large size or something like that. Or it could be that they might have some added features or added services that some parties really care about. So I've described this in the past as being able to express certain characteristics about the storage facility like saying hey, maybe it's HIPA compliant or maybe it follows certain set of structures for specifically some special type of storage and then being able to charge differently for that.
01:49:38.876 - 01:51:19.320, Speaker A: This allows organizations to specialize in that area without also having to compete with the large clouds, right? So one amazing kind of unfair advantage for something like Falcon against kind of a centralized cloud is that in a centralized cloud you have to compete with other centralized clouds one to one, right? Like parties are deciding either they go with Amazon or they go with Google cloud or they go with some other service and they're kind of comparing all kinds of features against that. When you think about creating a marketplace like this and a decentralized network like this, then you enable the entire market together to compete with one of those centralized players and it really changes the tone of the equation. So this is kind of like the Airbnb version of the world, airbnb against hotel chains version of the world where before Airbnb it was extremely difficult to rent out your home or whatever and that seemed like a crazy proposition. But nowadays it is totally reasonable and totally possible. Well, maybe not right now, but normally nowadays it's totally reasonable and totally possible for renting specific, very tailored kind of cases and stuff that just wasn't even available before. There's all kinds of things that you can do in Airbnb now that just wasn't available from hotels before. And so that's something that we think is likely going to happen here, where there's going to be a ton of interesting specialization, where parties are going to be able to do certain kinds of storage added services alongside storing the data that is going to enable this really interesting kind of storage cloud and market.
01:51:19.320 - 01:52:30.048, Speaker A: That wasn't kind of possible before. So that's a really interesting kind of advantage. But that kind of again requires these marketplace UIs to emerge and so on. Maybe some other stuff to refer to that is normal centralized clouds today require a bank account and like a human to be in the loop somewhere, right? Like if you were trying to hire storage from Amazon, you can't really do it if you don't have a bank account or an organization or something like that. So having a network that only takes cryptocurrency enables programs to do this. So you can now write programs that can hire their own storage and either the program is doing something useful and valuable and itself kind of like in this kind of weird self perpetuating loop which is kind of interesting and scary at the same time. Or you can think of applications as being able to hire their own computing and storage resources on their own for the end user without having to involve the developer.
01:52:30.048 - 01:53:35.832, Speaker A: So that's a different model of application distribution that maybe this is what three box and other versions of you own your data versions of the world look like, where the developer can write all of the application and so on. And then that application itself can just hire the storage on their own without having to based on the usage of a user. Then that application would kind of come in with a wallet or something, or maybe would use a user's wallet from MetaMask or something like that. But that's a very different kind of model of the world that becomes possible and then maybe would probably just touch on kind of like large volume and archival. If we kind of mass this large amount of data and make it super cheap then cheaper than other clouds which if statement there then all kinds of things that aren't done today could become possible. Right now it's extremely difficult to move around scientific data. It's really difficult to kind of back it up in the long term and make sure that it's open access and available and so on.
01:53:35.832 - 01:54:27.144, Speaker A: All kinds of sites and applications could be built that makes that really easy and really cheap if we can count on some stable cheap pricing and kind of a decentralized market associated with this. Cool. I'm going to keep moving maybe yeah, I think we blew through another half hour there the app platform area. I would say there's a lot of content in other workshops that is tuned for this of how to do static assets on IPFS and file client and distributed how to do that. Maybe what I'll mention here is at the end of the day the most important part for any storage network is the applications. So all clients will lag behind applications. Applications is like the main main thing.
01:54:27.144 - 01:55:27.096, Speaker A: So really cool uses of a platform that builds an app that they're kind of like app oriented are going to dominate and be much more important than other things. And so we're super interested in enabling all of this kind of stuff. And this is where developer tooling from folks like Textile and Orbit and so on will become and fleek and whatnot will become really useful to make all of this deployment easy, right? So moving around static assets super simple with Powergate and so on and web apps and so on can fit that with the Slate workshop that it's going to happen on Friday. You'll hear about building desktop apps on top of Powergate and what that looks like mobile apps. I'm not sure that Powergate is also aiming to do mobile. You can also look at what Openbazar has done and what audiences have done in terms of building mobile apps with IPFS content itself. Once the content is on IPFS, you can just back it up to filecoin separately.
01:55:27.096 - 01:56:36.132, Speaker A: So that's like a really interesting possible and some of the very interesting pathways here are enabling any contract on any blockchain to hire filecoin storage that requires bridges and so that interoperability layer that needs to be built out. But that becomes really interesting and really valuable where being able to have these smart contracts that can call filecoin storage from any other chain and kind of reason about that or potentially compute on it, that becomes really interesting. So computing on the storage is a whole other part of the equation where being able to kind of marry something like Golem or what Tribute was trying to do with kind of like scheduling workloads of computing to match the data, that is like a very interesting holy grail of distributed computation. One very important feature is that most computing architectures are laid out such that you move around code really easily to the data. The data is a hard thing to move. Data is really big, really quickly and really expensive to move. So you move the computing to the data.
01:56:36.132 - 01:57:48.910, Speaker A: So that means that mining facilities with a lot of data and the ability to kind of operate over that data would then kind of work very closely with could work very closely with some other network that does the computing piece of the equation, right? And so this could be something like OLEM and so kind of like a tie in there could be really valuable or it could be something like even just using Falcon and Ethereum payment channels, you could use the payment channels as they exist today to schedule workloads. Now, getting verifiability over the computation that's way harder. Like if you want verifiable computation. Now you start having to look at either models, like TrueBit, where you use kind of ensembles to verify that the computation was done correctly, or you can go into the snark and stark version of the world where you are running a much more expensive computation. But you do get some cryptographic proof that it was done correctly. We think that building out a layer of all the data and just getting all these really important data sets in place is like a really important milestone to then enable a lot of that interesting computation to be built. And so there's a lot of different interesting possibilities there.
01:57:48.910 - 01:59:05.204, Speaker A: But we haven't yet seen really good kind of distributed computation models with cryptocurrency yet. We think that as groups like Golem and others continue to expand what they're doing, that'll get really good. Maybe a hack here for those people interested in this might be focusing on computation that's public by default so that you don't have to worry about private sensitive data. And if you can restrict the problem that way, then verifiability gets really cheap because all you have to do is keep a trace around of the computation and you can always replay it later to check if it was done correctly. So that means that all kinds of things like developer tool CI or rendering or complex modeling of scientific computations or rendering or movie rendering, all of that kind of stuff becomes really good fodder for this because you can store all of the assets and process them alongside. And if any party did something bad, you can always check the trace and verify it after the fact. And if they did something bad, then you can slash collaterals and so on.
01:59:05.204 - 02:00:13.544, Speaker A: And so that's a much cheaper model. Doing verifiable computation with private data, that's what's really difficult. Maybe I'll mention one more thing here, which is one very important target use case that we're going for is to be able to host an entire web3 app, like the entire lifecycle of a consumer application entirely on filecoin. Meaning the binaries like the code is back up to it, the binaries and the artifacts that are produced, whether it's a web app itself or a desktop app or something like that, the binaries can be distributed with popcoin. And then when you run it locally in the user's machine, you either have no kind of, like backend business logic because many applications do that, which is like a great case, and you only have to worry about user data. And that user data you can back up to filecoin easily or you deal with some kind of business logic and back end. And that's what you can use either contracts or APIs for.
02:00:13.544 - 02:00:53.316, Speaker A: So you can use either if the business logic can be modeled as a smart contract, then you can put smart contracts on ethereum or other things like that, or you can just hit some API from a centralized service if that's what you need. But then most of the application, just all of the static assets and the entire thing can be distributed around with fogoin. So that's kind of like a good target thing that we're going for. Cool. I'll touch a little bit on the decentralized economy. I'll leave most of the interesting discussion for the future if this is interesting, I'm happy to kind of give a workshop, it's less relevant for hackers. So I wasn't going to cover it.
02:00:53.316 - 02:01:39.110, Speaker A: But I think based on the questions that I've heard today, people might be interested in this. I'll just describe that there are many different parties here and there's a bunch of different strategies that people can take to try and carry out different kind of like economic activity. There's a lot of different business opportunities that happen because of the network. Meaning we're looking at things like first of all, there are things like chain explorers and so on. There are these minor marketplaces that we've discussed. Or there are things like Snarks as a service. You can think of a piece of the computation that needs to be done in Filecoin and then set up a service for that and then use Filecoin payment channels to run it.
02:01:39.110 - 02:02:56.060, Speaker A: Or there's other kinds of operations. So like power gate, like a hosted powergate service, which is something that Textile is doing, is another interesting discussion, a very interesting kind of direction for service providers, right? So you're noticing, hey, applications need this service to run somewhere, then I can build a business associated with that and so on. Similar to how there's just a whole bunch of different businesses around different blockchains like Ethereum and so on. And so there's a lot of very interesting niches that are being created right now as we build the network that are really compelling and interesting business opportunities. Then kind of separate to all of that. There's a bunch of interesting parameters about the Falcon network which include things like details about the storage market, how much data there is, what is the block reward, what is the price of the token, is there a loan market available, and so on. All of those parameters will yield economic structures that would enable agents to kind of either make other economic structures on top of that or would imply some kind of economic policies needed.
02:02:56.060 - 02:03:58.720, Speaker A: Meaning one of the important tasks at hand is setting the right crypto economic construction parameters for setting things like pledge, collateral rates and so on. And so those are very interesting questions that affect the entire economy. And some choices there will yield a good economy that works, some choices there will yield an economy that won't work. So a lot of our bandwidth as a team is going into setting the right economic parameters for the network. One really useful model for thinking about Filecoin is you can model it as a country that exports one good, and that good is cloud storage. And you can think of the currency as like the national currency of the you can think of Falcon, the token, as the national currency of that country. And then kind of clients buying the storage from the miners as trading some other nation's currency for the Falcon currency.
02:03:58.720 - 02:04:55.252, Speaker A: And so again, if you take that model and you think of the economic production inside of that nation then you can reason about the economic productivity of the nation. Can you more efficiently turn the raw materials I. E. Like hard drives and storage facilities and so on and labor into valuable cloud storage better than other economic entities. And if you can do that, then the economy as a whole will perform better. And if you kind of model a lot more of the goods used in the production of that economy as being within the economy, then that economy will do better. So again, this goes into selling some of the hardware directly in filecoin or looking at other parts of the production pipeline and making it part of that.
02:04:55.252 - 02:06:07.352, Speaker A: And so this is a very interesting part of all of these networks is that you're doing something that is somewhere in between companies and nations where you're able to kind of isolate some portion of an economy and then create a group that together is going to work together on some economy in a very interesting way, right? So this is something that probably is different from other blockchains where the cost of production for something like Ethereum or Bitcoin is primarily about producing hashes and producing the blockchain itself. But once you look at producing something else which is producing the and maybe you can think of producing the benefit of having a transactional service. Maybe the smart contract execution is a production of something like Ethereum. In Falcon's case it's about the storage. And so thinking about modeling that way you'll sell all kinds of interesting potential policies and potential opportunities for folks who kind of can reason about that economic construction. Cool. So maybe I'll end by giving a couple of examples of some of the folks in the ecosystem.
02:06:07.352 - 02:06:48.996, Speaker A: So I've shown this slide with a lot of the miners. This is amazing. The level of storage facilities that we're looking at are really amazing. This is one snapshot at a whole bunch of organizations that are involved with Falcon in a bunch of different ways. And so this is a view into the broader kind of filecoin ecosystem. And there's a lot of really interesting groups that are building out stuff either applications or services or helping build the chain itself or helping build implementations of the protocol. There are four protocol implementations built by different organizations.
02:06:48.996 - 02:07:21.552, Speaker A: There's a bunch of infrastructure that's getting developed. So maybe I'll talk through some of the highlights. The protocol implementation so that's protocol labs ChainSafe and Soramitsu we're going to be handing maintainership of gofalcoin out to the community. Then there's a whole bunch of infrastructure players that are building tooling that's really critical for the Falcon network. So we've mentioned powergate a lot. That's one really important valuable tool chain that emerged. Another one is all of the IPFS pinning services.
02:07:21.552 - 02:08:14.640, Speaker A: So infuria pinata temporal and whole host of other pinning services end up being really important and valuable to the Falcon network. Then there are groups like so then there's a whole network called Drand, which is providing the randomness that Falcon uses. And there's a number of organizations kind of helping actually provide that. Then kind of beyond that, there's a whole bunch of very interesting developer tooling that's being built by folks like Truffle and Openwork Labs and Zondax and Nodefactory and a bunch of others. Pretty interesting developments there. Then there's a number of collaborators around research. There's many labs at various universities working on a bunch of important questions in filecoin, including a bunch of very interesting economic modeling.
02:08:14.640 - 02:09:08.176, Speaker A: And then there's a bunch of help in terms of just development of a bunch of really critical pieces. Like all of the it really takes a huge village to produce something as big and complex as this. Things like groups like Supernational and Carbon Five and Finality and Digital Mob have been making all kinds of components like some of the key pieces that are going into optimizing some of the proofs or making Bdfs in the long term and so on. And then there's already laying out a bunch of infrastructure for being able to use a token and being able to use the contract facilities of Alcoin. So you can already start looking at integrations, coming to things like MetaMask through Snaps and other things like that. And then all of that is kind of like infrastructure. Then from there we get into applications and clients.
02:09:08.176 - 02:09:42.096, Speaker A: All kinds of things are getting developed there. And there's a number of other really interesting things that will pop out over the next few weeks. So most of these folks are on Slack. So if you have a bunch of questions, you might end up using libraries from a bunch of different folks. You can poke them on Slack so you can contact them, you can ask questions and so on. And don't be afraid at all about talking about what you were working on and hacking on. And maybe some of them can actually help you think through how to structure some of it and so on.
02:09:42.096 - 02:10:26.840, Speaker A: So I think definitely rely on all these hooks. Cool. So I think with that, I'm going to call it End the Workshop. I'll maybe give a little bit of space for maybe the last two questions and then stop because we've been going for a very long time and I feel really bad that I'm holding up everybody's. Any more questions? No, I think we're good. All right. That was a great session.
02:10:26.840 - 02:10:50.190, Speaker A: Thank you so much. Sorry for taking forever and yeah, hopefully it was useful. Definitely give me a bunch of feedback on Chat. I'll start up a thread there. If people want to hear more about certain things, definitely tell me there. I'll tune stuff for next week or something around based on your feedback. So we'll definitely listen to what you have to say.
02:10:50.190 - 02:11:05.590, Speaker A: Sweet. Thank you so much. Really, thank you so much, Andrew and Jacob, for sticking around this long. I know it's late for you guys, so really, thank you for the time. And thanks for everybody for coming. Thanks, everyone. We'll end it there.
02:11:05.590 - 02:11:12.320, Speaker A: Good night. Good morning. Good afternoon. Take care, everybody. Bye.

00:00:15.990 - 00:00:50.014, Speaker A: All righty. Hi everybody. Thank you so much for tuning in for today's workshop with the graph. We have a presentation on how to build an NFT API with the graph today, and we have Natter who's going to be leading it. And yeah, if you guys have any questions, please save them for the end. He'll try to get to them as soon as he finishes his presentation. But if anything happens and we don't get to get to your question, we do encourage you guys to contact him through the Sponsor the Graph channel on Discord.
00:00:50.014 - 00:00:52.070, Speaker A: All right, Natter, floor is yours.
00:00:52.730 - 00:01:33.502, Speaker B: All right, thank you so much for the intro. And I will go ahead and get to sharing my screen. All right, so, yeah, today I'm going to be talking and showing you how to build a subgraph, and I'm also going to be linking to some workshop materials that you can actually follow along with as well. And maybe I'll go ahead and do that. So if you want to follow along, you can, or if you want to maybe do this on your own in the future as well, you can. Okay, cool. Then I'm just going to go here and copy a command I'm going to use in just a moment and go back to my slides.
00:01:33.502 - 00:02:33.122, Speaker B: Okay? Yeah. So we're going to be building out a subgraph today, and a subgraph is basically an API on top of blockchain data. In the traditional tech stack, we basically can have APIs databases and infrastructure that's built for querying. But really, when you think about blockchains, most of the innovation is done around writes and transactions per second and optimizing that. So therefore you basically have sometimes years of transactions and data that have been written in a way that is just not very queryable. So basically what we have had people do in the past to get around this, they were building out their own indexing servers. So to build out your own indexing server, you basically end up taking this really great thing that we have known as decentralization and centralizing it because you then have a single point of failure.
00:02:33.122 - 00:03:32.582, Speaker B: You have to maintain it. Anytime you need something changed, you now have another piece of infrastructure that you need to deal with. And again, like in the centralized tech stack, we typically would have some API layer that would hit a database and the database is built really optimized for indexing data for web or mobile applications or whatever type of application that we're working with. But this kind of like centralized, I would say this type of indexing layer was missing in the web3 stack. And when you think about an indexing layer, you could also maybe compare it to something like Google. So with Google, we don't have to find a way to go and find all this information ourselves from all these websites. Google basically crawls all this information, stores it in their own servers, and they build like a really nice API on top of it for us to use, which is the Google search box.
00:03:32.582 - 00:04:51.246, Speaker B: And they also have other APIs that we can interact with. So basically the graph aims to solve this by being this indexing layer that sits in between your user interface or your application and a smart contract. And you can basically define a smart contract address, you can define the functions or the events that you would like to index and all of that data will be stored and saved and made queryable and it will also keep up with any future updates as well. So let's say you index at some point in time. Any data that ends up being added or any events that end up happening in the future are also available and you basically deploy once and you're able to then use it to query all of your data. So you now have instead of a centralized single point of failure, you now have a decentralized network of nodes that are all having this data stored for you and made queryable and also done so in a way that is performant. Because if you say you have a few dozen indexers out there serving your data that will serve up the closest request to where the query is happening.
00:04:51.246 - 00:05:55.160, Speaker B: So let's say you have someone in South America or you have someone in the United States hitting one of these APIs. We serve up the closest location for an indexer. And the way that the network operates is through something called the graph network. And the graph network has a few different participants that all kind of work together to make the network secure, robust and operate in a decentralized fashion. So we have indexers, we have curators, we have delegators, and we have subgraph developers. So indexers basically run the nodes and they are basically running the infrastructure where the subgraph developers are deploying their subgraphs to. We have also curators who basically can signal towards certain subgraphs that they think are high quality and then based on that signal, the indexer will choose or not to choose to index that data and make it queryable as well.
00:05:55.160 - 00:06:58.410, Speaker B: Subgraph developers build out these subgraphs for people to query, I'm sorry, for people to curate and then for the indexers to index. And then if you are a nontechnical person but you want to participate in the network in the indexing side of things, you can be a delegator basically, meaning you're going to be backing one of these indexers with GRT and then you earn a reward based on the amount of GRT that you've staked with the delegator. And you get a percentage of not only the query feeds, but also network rewards which are basically essentially GRT tokens that are like inflation that happens every year that are paid to network participants. There's a lot of different applications using the graph. I think some of the most notable ones would be applications like Uniswap. One of my favorites is foundation. You have Livepeer, a bunch of different apps and DFI and all parts of the web3 ecosystem are using the Graph.
00:06:58.410 - 00:07:47.210, Speaker B: When you're querying this data, and I think this is relevant for anyone that's a developer. How do you actually get this data into your app? Well, we basically are using GraphQL and once you've deployed a subgraph or an API, you get an API endpoint. And with that API endpoint you can basically then start hitting your API with whatever queries that you like. And the really interesting thing about GraphQL is that you can basically ask for any of the information that you want and you will only receive that information back to the client. As opposed to something like Rest where you often are just given a large chunk of data. And then you have to basically send extra data across the wire, making it a little less optimal, little less performant. And then you end up having to destructure or filter that data on the client.
00:07:47.210 - 00:08:23.190, Speaker B: So with that being said, this is just kind of like an overview of what that looks like on the client. Let's go ahead and jump into the actual coding part. So what I want to do is show you the link to this workshop. I kind of shared it in the chat, but it's GitHub.com Dabbit three building subgraph. And basically what we want to do is build a subgraph from scratch. And what we're going to be building today is an NFT API that queries all of the data that is in foundation.
00:08:23.190 - 00:09:10.258, Speaker B: I'm sorry, actually we're going to be using Zora today. So zora is a NFT marketplace. So if I go to Zora co you'll see that we know NFTs. So we want to build out our own API layer that will allow us to index and query for these NFTs. So to get started, you need to install the Graph CLI. So if I type Graph, you'll see that I have the Graph CLI installed and you can install using NPM install G at Graphproteocol CLI and you can find that information in the workshop material or on the Graph website. And what we want to do is we want to run Graph init and this will initialize and scaffold out kind of some boilerplate for us.
00:09:10.258 - 00:09:53.554, Speaker B: But we can also pass in some flags. And that's what I copied to my clipboard a moment ago. And this is basically going to set up all of the basic configuration that we need to get started. So what we can basically pass in, the main thing to start here would be the contract address. So this is the actual smart contract on Etherscan and this is the address. And based on that address, we're going to be given a certain boilerplate by the Graph CLI. So we also passing in a couple of other flags because in this smart contract there are multiple contracts and we can define which contract that we want to use.
00:09:53.554 - 00:10:42.866, Speaker B: So here we're basically saying we want the token contract. We do not want to deal with. Let's say there's other contracts like a marketplace or something like that. We're also passing in the index events flag. And what this will basically do, it will look into the contract, it will find all of the events and it will automatically create some boilerplate code for us as well. So some of that boilerplate that is really useful is basically the event handlers. So when we have an event, like an event in an NFT ERC 721 contract might be something like a transfer event where someone's minting a token or someone's transferring a token, then we will automatically have basically a function defined for us.
00:10:42.866 - 00:11:20.478, Speaker B: And then finally we're passing in the Subgraph Studio, which is basically one of the two different ways that you can use the graph. We have a hosted service, which is not a decentralized service. It was basically the initial version of the graph. And then recently in July, we launched the Decentralized Network, which is called for development purposes like us before we published there. It's called the Subgraph Studio. So that's kind of what all those flags mean. So now we can basically hit Enter and we're going to be asked for our subgraph name.
00:11:20.478 - 00:11:56.390, Speaker B: So to get a subgraph name, we want to go to thegraph.com and we want to go ahead and sign in. So if I go to thegraph.com Studio, I'm going to go ahead and actually close that and let me go ahead and disconnect here to give you kind of the full experience. So when you hit the graph.com, you can basically choose right here to go to Studio. And Studio is basically the development environment that we're going to be working in where we can scaffold out a new subgraph.
00:11:56.390 - 00:12:22.834, Speaker B: So I can click Connect wallet. We can connect with MetaMask. I can choose the address that I want to authenticate with. And it looks like it's saying two accounts, so let me get rid of that one. All right, so once we've signed the message, we should see whatever subgraphs we've already created. And I want to go ahead and click Create a new subgraph. So I'm going to click that.
00:12:22.834 - 00:12:55.934, Speaker B: And we'll call this zora API. And now we have our boilerplate like placeholder, I guess you could say actually for us to go ahead and deploy to. And this will give us our subgraph name, which is going to be Zora API. And it's also like the slug right here. So I can go ahead and copy that to my clipboard and whoops, let me try that again. There we go. And then it's going to ask us the directory.
00:12:55.934 - 00:14:00.626, Speaker B: I can just accept the defaults. And then here we see all the different networks that we can deploy to so we can do any of these. And I'm going to go ahead and choose mainnet and we already passed in the contract address so it kind of has that already and then the contract name was already passed in. So you see that there and this will go ahead and scaffold out that boilerplate for us. So what I can do is go ahead and open this up in my text editor, all right? And what we should see is that we have a GraphQL schema, we have a mapping and then I'm waiting for the rest of this to complete. And we should also have a subgraph YAML. So these are like the three main parts that make up a subgraph.
00:14:00.626 - 00:15:09.818, Speaker B: We have again our GraphQL schema which is something we're going to look at in just a moment and it's our data model. We have our subgraph YAML which is our main configuration for our subgraph and then we have our mapping which is something we're going to walk through in just a moment. So I think the first thing that's probably important is for us to define our data model. And basically what we want to do here is we want to define which entities that we want to store and make queryable. So for an NFT API, I think the know thing that makes the most sense would be the non fungible token which we could just call token. And then also what we can do is since we have the address of the person that owns that token, we can also create a user model, and then we can have kind of a relationship between tokens and users. And we can have even more interesting queries available because we can then do things like I want to get all of the tokens owned by this user, or I can say, I want to get all of the tokens and then I also want to get the user and then maybe we can go another level deep and say tokens user and tokens.
00:15:09.818 - 00:16:05.890, Speaker B: So you can do all that fairly easily using the graph and using GraphQL. So what I want to do is go ahead and declare my schema. And here we have two types. One like I mentioned, is for the token and one is for the user. And here we're just basically defining the fields that we want to be made available for us to query. So we want token ID, we want the Token Content Uri, we want the Token metadata Uri and we also want to know the created at timestamp using all this information, we can do all different types of things to query this data. We could say things like hey, I want to get all of the most recently created tokens and I want to order them by date, I want to order them by ID, or maybe I want to fetch a certain only tokens by a user ID, all that stuff.
00:16:05.890 - 00:17:15.346, Speaker B: And then we also have this user entity and we're able to now do a relational, I guess create a relationship, you could say, between the token and the user. So we can now have a one too many relationship essentially in doing that, to do that, we basically just need to pass in the at derived from directive, which is part of something that the graph CLI supports and it allows us to kind of have this additional, you could say, helper that is not part of the GraphQL specification itself. So with our token and our user entity, we're kind of done there and we can now go to our subgraph YAML. And we passed in the address which is already here, we passed in the contract which is going to be the token. So a lot of this stuff was already filled out for us. We don't really have to change that. The things that we do want to change are the entities and these basically are just going to match exactly whatever our data model looked like in our GraphQL schema.
00:17:15.346 - 00:18:09.618, Speaker B: So if you remember, we had a token and we also had a user. So that's all we need to do there. Whatever data that we want stored is just going to be kind of our entities and the entities end up matching your GraphQL Schema one to one for the most part usually. The other thing we want to do is we want to deal with our event handlers. So I mentioned that we passed in that index events flag which is going to look for any events that are defined and called in the contract itself. And based on the abi that is associated with that contract, we have all these event handlers and the two handlers that we're going to be dealing with today are going to be the transfer event. And you see that we have this function called handle transfer and then we also have a token Uri updated.
00:18:09.618 - 00:19:07.546, Speaker B: So we're going to be kind of dealing with those two events and we don't really need these other ones, at least for this example purpose, so I can go ahead and delete those and this ends up being a lot smaller of a code base for us to work with today. So now we have our contract address, which is a smart contract. We have the Abi which was fetched from the contract itself and we have the Abi right here by the way it was pulled down by the Graph CLI. So just figure out that we also have our two entities which again match our GraphQL Schema. We have token user here, we have token user and we've defined two event handlers and this is going to be kind of where the code we're about to write lives. This is going to be really the only actual code that we have to write and what's going to happen in those event handlers. We basically want to write a function that takes some information that is passed into an event.
00:19:07.546 - 00:20:07.198, Speaker B: So let's say the handle transfer event is fired. We're going to have these three arguments passed in. We're going to be having the address of the previous owner, the address of the next owner and then the token ID. So using those three pieces of data that are going to be coming into the function, we can do stuff with it. So we're going to do stuff like create a new token and then set the address, set the previous owner, the current owner, set the token ID and stuff like that. And then the only other thing we might want to do is we can actually define a start block. And the reason we might do that is because if we deploy this subgraph as is, it will go to this contract address and it will start indexing every single event since the beginning of the network that we're deploying to.
00:20:07.198 - 00:21:28.726, Speaker B: But since we know like, hey, this contract was deployed at some point in time, maybe let's just start from that date. We can just go to Etherscan, find that contract, we can go to the transactions, we'll go to the very last transaction, I guess you call this the first, the last page and we just want to copy the block from this event when this first transaction happens. So I can go here and I can just set the start block as that number and this way when we deploy this it will just start right there going forward and we'll just ignore everything before that. So with those two things set we can actually now generate some code that we're going to be using for our mappings. And to do that basically we can run graph code gen and this is going to look at our GraphQL schema and it's going to go ahead and generate some boilerplate code for us in this generated folder. So like this ran successfully and we can now see that we have schema TS and we have a generated token, token TS and we don't really have to do anything there. This is just some code that we can use.
00:21:28.726 - 00:22:13.206, Speaker B: We're not going to actually update that. But what that code is, it's generated some two types of, I would say like functions and things like that and types that we can use. One is a set of functions and methods that allow us to talk to the indexer. So to talk to the indexer we basically wanted to be dealing with the node that we're going to be saving information to. So we can say hey, we want to either fetch information from this node or we want to save some data to this node. We also were given a bunch of functions that can talk to the smart contract itself as well. So let's say that we want to hit the contract and get some other metadata that's there.
00:22:13.206 - 00:23:12.950, Speaker B: We can do that so we can talk to both the graph node as well as the actual smart contract using those methods and functions and types and stuff. So here's the two handler functions again that we're going to be dealing with are going to be the Handle Token URA updated and Handle transfer. So those are going to be like the two functions that we deal with. So the first thing that we want to do is go ahead and import some of those helpers that we had earlier. So these three imports here are going to be dealing with talking to the actual smart contract itself. So we have the token, I would say we were calling it the Token contract, but it's just a way for us to deal with metadata for the token itself. We also have a transfer event and a Token Uri updated event and these are basically just going to define the event metadata for us to have type safety.
00:23:12.950 - 00:24:01.000, Speaker B: And then the other two things that we have are the user and the token. And these are going to be ways for us to interact with the graph node itself, which is essentially going to be an indexer running a node and us being able to either save data or read data. So with those imports, we can now write our two functions. So the first thing that we might want to do is do well, let's do the smaller one first, actually. So we have this function called Handle Token Uri updated. And if we look at our Handle Token Uri updated function here, you see that we have two arguments. We have the previous address, the new address, and then the string which is going to be the Uri updated data.
00:24:01.000 - 00:25:06.302, Speaker B: And the only thing that we are actually going to be dealing with is going to be this content Uri which is going to be the new Uri. So we don't even need to really know the owner or anything like that because we can basically call to the graph node here and just load the token. So we're going to say Token load, we pass in the Token ID and then we reset that new Token Uri field and then we save it. So really just three lines of code here. This is probably the most simple event handler that you'll end up dealing with because really the only thing we care about here is just updating the Token Uri field of the token. And then the other function that we have is the transfer event. This one's a little bit more complicated because we have to take into consideration that this can be a brand new token that no one has ever minted before.
00:25:06.302 - 00:26:08.354, Speaker B: It's like it's being minted at this point in time or this token already exists and therefore all we need to do is handle the transferring of the owner. So we have to kind of deal with both of those cases. So the first case that we do is we go ahead and try to load the token from the graph node and then we could say, okay, if this token does not yet exist, let's go ahead and create the token. So the way that we do that is we say new token, we go ahead and set the creator, we set the token ID, and then we also set the created at timestamp, which is available on the event block timestamp. So this is kind of some metadata that comes in from the actual event itself that's not really specific to a token, it's more like specific to the transaction. And then we also want to go ahead and read the token from the we're not at this point talking to the graph node. We were talking to the graph node here.
00:26:08.354 - 00:26:47.738, Speaker B: Now we're talking to the actual contract itself and we want to fetch the content Uri and we want to set that on the token as well by reading it from the smart contract. And then we also want to read the metadata Uri and set that. And at this point, we've created a new token. We've set the creator, the token ID, the created at timestamp and these two other fields. And then we set the current owner because at this point we know that the token exists. We've either created it or it's been created. And now we just want to update the token owner because if a transfer event has happened, that means ownership has changed.
00:26:47.738 - 00:27:24.410, Speaker B: And then we just save the token. And then here we go ahead and do this similar logic. We check to see if that user has already been created. If they have not been, we go ahead and create that user. And you can see like this save method, anytime you see save, this is you saving or someone saving some information to the graph node. So anytime this happens, that means you now have this piece of data, it's indexed and you're ready to start querying for it. So with that being said, we should be done creating our subgraph and we should be able to go ahead and deploy.
00:27:24.410 - 00:28:06.022, Speaker B: So what I can do now is I can say graph deploy. Well, actually, you know what we first need to authenticate, actually. So let me go ahead back to our subgraph here and you can see that we have some instructions right here on the right where we kind of give you an idea to install the CLI, initialize a subgraph. And then here is the step that we're at now. We want to say Graph Auth and we want to authenticate and allow us to actually deploy this from our machine. So I can just say graph auth studio passing in oops. Well, that's my key.
00:28:06.022 - 00:28:54.660, Speaker B: I guess I just basically made that available. But yeah, the next thing we want to do is Graph Deploy so I can say Graph Deploy Studio and this will go ahead and deploy our subgraph. I'm not even in the right field folder. Let me try that one more time. All right, so I'm going to copy this graph, deploy studio passing in the name of our subgraph. And here we can go ahead and define a version label. I'll just set the version to like zero one.
00:28:54.660 - 00:29:56.060, Speaker B: And if the deployment is successful, you should see like this with no errors or anything like that. And then we should be able to go back here and refresh and see that we have our subgraph being indexed. And you see that we kind of like change. Our UI has changed a lot. Now we're now seeing that we have a playground, we have logs, we have our subgraph details still available, but we should be able to go ahead and start querying our API. So what we might do is just run this query that's available here where we're going to go ahead and get the first five tokens and we're going to get the ID, the metadata and the content. We might also say want to order by created a timestamp and then order direction would be like descending.
00:29:56.060 - 00:30:49.804, Speaker B: And this way we can get the most recently created tokens. And if I query a couple of times, looks like we can go ahead and maybe just copy one of these. So let's go ahead and copy this content Uri and check out what this token looks like. There we go. We see that we have our data coming in, so we have that working there. The one thing that we didn't really do in this example is dealing with IPFS metadata. So one of the most recent APIs that I created with the graph that I open source was the Board API club API, because with the graph you can do stuff like full text search and you can do a lot of interesting things like that.
00:30:49.804 - 00:31:36.220, Speaker B: So what I've done is basically deployed this and I've indexed all of the different traits from this NFT. So like the Board API club, they have all these different things. They have eyes, background, hat, mouth, clothes, so I can say I want to get their hat, want to get their mouth design or the type of mouth that they have clothes, whatever. And we can get all of that. And then I might say, okay, I want to only query the apes that have a puppy vest. So we can say wear clothes, puppy vest or something like that. And here we see that we only have those apes coming back.
00:31:36.220 - 00:32:16.326, Speaker B: And then one interesting thing is that we can also do full text search. So I might say something like, let's see what that query is called. I think it's called token search. And I can say text is equal to like let's say we're looking for any ape that has like red background or red. Something could say red. And here that we see that we have this coming back and I'm not sure, yeah, I don't see the actual red. So I'm wondering if there's interest, something going on.
00:32:16.326 - 00:32:46.642, Speaker B: There maybe I can say m one. Yeah, and this is like the mutant apes. So yeah, you can basically do full tech search using that. And I think one of the things that we might look for would be just like mutants because you have the Board Ape Yacht Club and you have the Mutant Ape Yacht Club and oh, I'm not getting all the fields back. That's why I'm not seeing. Yeah. Mutant Ape Yacht Club is the collection.
00:32:46.642 - 00:33:56.234, Speaker B: And I think the reason that when I did the other full text search and I wasn't actually seeing that, I'm not actually returning all these fields. So if we return the eyes and all these other things, then I'm guessing that the results would actually match what we're expecting. But yeah, so you can deal with IPFS, and the way that this one works is that when we get that metadata Uri, we can go ahead and fetch that metadata from IPFS and then we have an object that comes back that has all these different fields and then we save those as well. It's basically, essentially kind of like taking this mapping that we have here and adding additional fields. And I would say the main thing to consider with IPFS right now is that we support IPFS in the hosted service, but we don't yet support IPFS in the decentralized network for maybe a couple of more months until that update is merged. So if you want to build a subgraph using IPFS metadata still, you can do it without any problem. You just have to use the hosted service.
00:33:56.234 - 00:34:11.620, Speaker B: So that's it for me. If you want to learn more about the graph, please follow us on Twitter, check out our website, check out our docs and you can join our discord and also feel free to reach out to me on Twitter. I'm Dabbit three and I'd be happy to help. Thank you.
00:34:16.870 - 00:34:39.880, Speaker A: Okay, thank you so much Natter, for that really amazing workshop. And thank you so much to the graph for sponsoring ETH Online this year. I do encourage you guys to reach out to Natter and continue this conversation about the graph in the sponsor, the Graph Discord Channel. And yeah, thank you again matter and everybody have a really great day.

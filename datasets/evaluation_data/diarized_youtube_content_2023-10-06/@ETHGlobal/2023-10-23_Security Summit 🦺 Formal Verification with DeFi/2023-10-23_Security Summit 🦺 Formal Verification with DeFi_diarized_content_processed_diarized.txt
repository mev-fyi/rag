00:00:07.130 - 00:01:29.270, Speaker A: I'm Samir from Satora, and today I want to talk about formal verification and its application in DeFi, along with what we do at Satora to allow you to verify your smart, formally verify your smart contracts. So, formal verification is an old computer science approach where you have a program and you have your specification, and you're basically checking your program against your specification, making sure that it is following the properties that you have laid out before. And these tools, they either give you like a bug counterexample showing you exactly how your protocol violates those properties, or it gives you basically an effective proof of how your protocol is successful on all the properties that you have laid out before. So the first question that we can ask is, why do we need formal verification in this domain of DFI in particular? And here I've listed like a couple of bugs from 2022, 2023, oil refinance, yearn finance. And as you can see, all of these hacks have led to millions of dollars in losses. So one thing that is very interesting about this domain of DFI is that the bugs have a very high impact. You can have millions of dollars in losses, and these funds are usually very hard to recover.
00:01:29.270 - 00:02:03.970, Speaker A: So here, safety critical code becomes very important. Like even small bugs can lead to some huge vulnerabilities and can drain the protocols out of their funds. So code safety is very critical. And as you have seen, billions of dollars are at stake. So you need something more than just testing, fuzzing, and auditing safety guarantees. And this is where formal verification can shine. It can give you these strong security guarantees that you need to make these billion dollar protocols robust.
00:02:03.970 - 00:03:03.362, Speaker A: Another interesting thing to note is that traditionally formal verification has been very hard to scale because the code bases traditionally have been massive with lot of files and data structures. But this is not the case with DeFi here. The smart contracts are very modular and they're isolated in the sense that they're just captivating one idea. So it's easier to deploy formal verification in the domain of DeFi, and it's easier to make use of it in this domain. But interesting thing to note is that even though the code is small and modular, bugs are still very hard to find in DeFi with just testing, fuzzing, and auditing approaches. And that is primarily because the bugs that actually lead to millions of dollars in hacks occur in rare scenarios. They are very strategic bugs.
00:03:03.362 - 00:04:08.982, Speaker A: They only occur like tricky edge cases. And this is another place where actually formal verification can shine the most as compared to testing, fuzzing, and auditing. Alone, because formal verification allows you to explore this whole landscape of possibilities and helps you find the bugs in those rare scenarios that cannot be looked with just the help of testing or fuzzing approaches. And as we all know, even though the code on the blockchain is immutable, the code is constantly updated because teams are adding bug fixes and new improvements. So it becomes imperative to make sure that all of these new changes are constantly getting secure with your properties. We need those strong security guarantees for every major update, or every even minor update as well. In this example of Euler finance, which is an interesting example where they had verified, they had formally verified their original code base, securing it safely.
00:04:08.982 - 00:05:17.010, Speaker A: However, it was like a small change in a new pr that actually led to a bug, which led to $200 million in loss. And unfortunately, this new pr was not formally verified and kind of like tells you about the importance of doing formal verification regularly and repeatedly in a regular development cycle. So hopefully, now that I've convinced you why formal verification is essential in this domain of DeFi, let's talk about what other tools are available in the market that can help you get some more security guarantees. So first and foremost comes testing and fuzzing approaches, where you have random testing on many inputs. And some of the examples of these kind of tools are like Echidna and forge, so they're very easy to use. They find a lot of bugs, but the hard to find logical corner cases are not possible using testing and fuzzing approaches like protocols that are dependent, that have many dependencies, or they call one another. Testing and fuzzing approaches are limited in their security guarantees when it comes to such protocols.
00:05:17.010 - 00:06:42.974, Speaker A: Then you have the static analyses approaches. Static analysis tools like slither checkmarks, veracode, where you analyze the source code to find for patterns that could be exploited for hacks. And what these static analyses tools do is they form an over approximation of the source code, like they overappreximate the behavior of the underlying source code. So what can happen, however, is that they can lead to many false positives and negatives, so they can show you issues that are maybe not real bugs to begin with. So that is an issue with the static analysis tools by themselves. The third approach we have is that of like automatic formal verification, which we also employ at Satora, where you have your specification, your formal verification, and you reduce that into an equivalent mathematical formula, a logical constraint, and then you just pass it on to third party constraint solvers like SZ three, CVC five, and they give you either an effective proof showing you how exactly your protocol is verifying the specification, or they give you a bug showing you how exactly where exactly in the protocol a property is being violated. Of course, these automatic verification tools are computationally expensive, and they take a long time.
00:06:42.974 - 00:07:38.522, Speaker A: They sometimes do take a long time to run fully and find a bug. But as we'll see later, the computationally expensive part is not the hardest part about formal verification. And last but not the least, we have proof assistance, where you first write the specification and then you derive a correct code out of that specification. So the code will be correct by design and tools like the K framework and cock help you design such secure, smart contracts. However, the problem with such proof assistance is that they involve laborious efforts. They're very hard to use, they're not plug and play approaches, and they are just hard to scale in general. Looking at all these tools in a more pictorial representation, you can see that testing and fuzzing can find many, many bugs.
00:07:38.522 - 00:08:27.162, Speaker A: They're very useful. And then you have the Satora approver, the formal verification, automatic formal verification tool, which can find even more bugs. And in fact, the Satora approver can find all the bugs as per your specification. So formal verification is as good as your specification. If your program, if the properties that you have written, the specification you have written, is strong and covers all aspects of the protocol, then the proverb will find those bugs related to those areas as well. And then you also have the static analysis tools which find some bugs, misses some bugs, but then again reports some issues which are not real bugs to begin with. So we can also look at these tools in a scale of security versus automation.
00:08:27.162 - 00:10:03.594, Speaker A: So security is like how strong of a security guarantee does the tool provide? How strongly can I say that my code is safe versus automation of how easy is it to use? How easy is it to scale? How can new developers just come and start using it altogether? So here we see that you have some tools like k and cock which provide very high security guarantees, very strong robustness, but they are very hard to use and very hard to scale. Like new programmers have to spend a lot of months beforehand to actually learn the tool themselves to then make use of them in doing smart contract security. And then on the other hand, you have your fuzzing and static analyses tools like Slither and Echidna, which are very easy to use plug and play approach, but they don't really provide a strong security guarantee. So this is where Satora tries to come in and comes at that sweet spot of having, if not as expressible as cock then equally as expressible in describing properties about a system. And of course we try to be as easy to use but not easier, but not easier as your testing and fuzzing frameworks. So this is where we try to come in and make formal verification more approachable to new developers and veterans alike. So at Satora we try to build tools that can help you verify your smart contract.
00:10:03.594 - 00:11:06.866, Speaker A: Formally verify your smart contracts. We have the Satora prover that performs the automatic formal verification at the bytecode level, and then we also have tools like gambit that can help you check the strength of your specification. A specification is just like a list of properties, and so you want to make sure that the list of properties itself is strong. And this tool can help by mutating the source code and then making sure that your specification is catching the bugs in the mutated source code. So this list of properties, the specification is actually written in this language that we have developed internally called CVL, which is like a declarative language expressing what exactly a contract should do at any point in time. We'll see an example in the slides as well of CVL. So here's a very simple example of a very simple contract where you have a very simple function f.
00:11:06.866 - 00:11:36.250, Speaker A: And all we really care about this function is that it should never return to zero. So let's compare how we'll do a testing, fuzzing and formal verification framework. So for testing, you will first instantiate your contract. You're setting a two three, and then you will just check for random arbitrary values. F of zero is not equal to zero, f of one not equal to zero, f of 17 not equal to zero. Great. So for fuzzing you'll do something similar.
00:11:36.250 - 00:12:22.710, Speaker A: You will instantiate your contract again with a specific value of a, and then for all the random values of like 10,000 10,0000, you'll make sure that f does not return a zero. Great. However, so there are two things to note in both of these testing and fuzzing frameworks. A the value of a has been specified. Like nowhere do we say that, okay, a can be an arbitrary value, and b you're still checking for only a limited number of inputs, x ranging from zero 117 or like 10,000 10,0000 values. So this is where satora and formal verification can shine, where you don't need to restrict your program in those manner. Like you see this rule that you write in a CVL, a declarative format.
00:12:22.710 - 00:14:16.330, Speaker A: You say that, okay, let's consider x, which is an arbitrary Un 256 variable, and we want to make sure that f x is not equal to zero. We don't have any restrictions on x, we don't have any restrictions on a what this tool does is it explores all these possibilities magically and tries to come up with the specific values of x and a that can actually lead to a violation of the smart contract. So this is a very simple example, but this goes to show that the strength of formal verification for proving cool properties about your programs, and you can extend this to your complex smart contracts such as ERC 20s ER 720 ones, and other pool contracts that allow you to write more complex properties about them. So here's a brief overview of the internal magic that is happening inside the tool. So you have your solidity file getting compiled to the EVM bytecode using a solidity compiler, and then it gets decompiled to an intermediate representation called Tac. And parallel, you have a formal verification spec which is written in CVL, as we have seen, and that too gets compiled to this intermediate representation, Tac. So both of these things are combined together into a huge blob of Tac, which goes through a bunch of simplifications, optimizations and other things, and then get passed on to a very long mathematical formula, a constraint equation that gets then passed on to third party SMT solvers like z three and CVC five that either give you a bug showing you how your protocol is violating the specification, or they says that there is no bug.
00:14:16.330 - 00:15:06.250, Speaker A: So you're basically getting a proof that, hey, your protocol is verifying is completely valid as per the specification. Of course, there is an issue where the tool times out. And this is because SMT solving is like a computationally hard problem, and there can be cases where the tool times out and does not report either of the two cases. And this is what we do at Satora. We try to minimize timeouts. We try to make sure that the tool can generate an outcome in almost possible cases. So a question that we often get asked is that where does formal verification fit in the development cycle of a developer? And the answer to this is that we try to push a verification driven development approach for formal verification.
00:15:06.250 - 00:15:50.106, Speaker A: We want you to think of formal verification in the same way as you think of testing and fuzzing. For testing, you write your function. You write some unit tests by that particular function before moving on to a new function. In a similar manner, you write your function inside your protocol. In fact, even before writing a function, you think about the property for that function, you write the invariant for that function, and then you come up with that function, and then you make sure using the prover, that the function actually adheres to the invariance that you have specified in the specification. If not, you can go back, maybe change the function, or maybe change the design of the property itself, make it stronger. But if it is verified, great, you can do your development forward.
00:15:50.106 - 00:16:43.052, Speaker A: So formal verification is not something that should only be left till the end of a development cycle. It should be deployed continuously throughout the development process so as to make sure that you're developing a sound and robust system to begin. Another question that gets asked often is that does formal verification replace auditing like manual auditing? And the answer to that is, of course, no. Formal verification, auditing, testing, fuzzing, all go hand in hand to improve the overall security of your contracts. Nothing is like a silver bullet that can help you secure your contracts from all these hacks. So you design your DAP and then you write your code for it, but parallel. You also write a verification like in your CVL.
00:16:43.052 - 00:17:50.270, Speaker A: You formalize that verification and requirements using a formal language, and then you test your code against that specification, making sure that your code follows those properties. But more importantly, you also check the specification itself, making sure that it is actually the properties that you want. Or you can make use of tools like Gambit, et cetera, where you check the specification by mutating the source code and introducing bugs in the source code itself. Then you get a bunch of verification reports, and at the end of the day, of course, a human has to look at those reports to make sure that the code is following the properties. The properties are what you expect it to be, and the whole system is working as expected before you can deploy and publish the protocol. Now, many people think that formal verification can only prove an absence of bugs. However, I think the biggest value of formal verification is in finding those tricky edge case bugs that are very hard to find using testing, fuzzing and auditing frameworks.
00:17:50.270 - 00:18:59.570, Speaker A: Even in the case of like hardware analyses, the biggest value of formal verification has been finding some rare to find edge case bugs. And as I mentioned before, the hardest problem for formal verification is not the computationally extensive part. Yes, it's just true that it exists, but in practice we see that a harder problem is for people to write good specifications about their system. The system design is a harder problem because it requires a bunch of analysis, a deep understanding of the system, and we have seen many a times where the specification falls short of covering every aspect of the system. And as I've alluded to before, formal verification is not silver bullet. It's not going to replace auditing, testing and fuzzing, but you have to think of formal verification as an additional aspect that you can utilize to enhance the overall safety profile of your code base. It increases like everything combined together should make your system more robust against hacks.
00:18:59.570 - 00:19:49.710, Speaker A: And as we saw in the last slide, formal verification is not something that should only be thought of as like a last step, one last time deal. Once you have done the development, it should be thought of at the beginning, in fact, even before you start writing code, so that it can help you design better properties about the system and at the same time write better implementation for adhering to those properties. So all in all, formal verification can be a very useful tool that you can employ in your RS to secure your smart contracts against bugs and hacks. And yeah, thank you everyone for giving me the time. Bye.

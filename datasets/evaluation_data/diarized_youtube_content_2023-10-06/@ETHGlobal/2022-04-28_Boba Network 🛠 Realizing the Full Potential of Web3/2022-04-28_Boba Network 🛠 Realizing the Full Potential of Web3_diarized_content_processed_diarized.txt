00:00:05.930 - 00:00:16.110, Speaker A: A little bit higher. A little bit higher. Like that? Yes. Yes, that sounds good. Okay. All right. Good morning.
00:00:16.110 - 00:01:21.840, Speaker A: Thanks for coming to this workshop about realizing the full potential of Web three. It's it's really about how why we build Boba network and what Turing Hybrid Compute, which is only available on Boba, would help developers build more engaging, more interesting, more compelling Web Three applications. So let's go back in time a little bit, right, to the original creation of Ethereum. And a fundamental premise of Ethereum is that while Bitcoin, which is a ledger, is good, if you can actually program it, it's even better computers better. And our hypothesis is that let's take it one step further. A more connected computer will lead to a more creative and powerful decentralized system. Just to give you an analogy, right, we all have a phone and imagine creating mobile apps without the cloud, right? You're limited to what you can do on the device itself, and that's it.
00:01:21.840 - 00:01:52.118, Speaker A: You can still build apps that run on the phone, but it's not nearly as interesting, right? And that's what we do here. So we started with Bitcoin, bitcoin script, minimal stack based programming language. It's really designed, it's very transactional oriented. It's not terrain complete. And then Ethereum came along. Breakthrough innovation. However, it is slow, as we all know, and there's a good reason for that.
00:01:52.118 - 00:02:33.830, Speaker A: Ethereum wasn't designed to maximize to optimize for raw compute performance. It's designed to be a decentralized system with thousands of uncoordinated nodes that could somehow come to agreement on something. And that's really hard. And in order to achieve that, there has to be a lot of limitations imposed on the kinds of computations that you can do, that we can do. And, for example, you can only do integer operations. Reason is if you allow folding point operations. What if two computers are running on different CPUs and they come at arrive at slightly different answers? They won't be able to come to consensus.
00:02:33.830 - 00:03:25.342, Speaker A: That's why Ethereum is slow and the computational complexity is very limited. We can only do pretty basic computations, can't even take the square root of a number and get a reasonably precise answer. But then l two S layer two S came along. And while the original motivation for creating layer twos is to address the most obvious challenges of Ethereum, which is speed throughput and cost, there's actually an additional major benefit, and that's enabling more complex computations. And that might seem a little bit counterintuitive. People don't think of layer twos as a little bit that kind of benefit, right? Most people think of layer two, oh, faster, cheaper. Oh, that's awesome.
00:03:25.342 - 00:04:20.670, Speaker A: Let's just move our transactions to layer twos. Well, the key difference what is a layer two? A layer two, really is we're decomposing this monolithic layer called Ethereum that combines execution, settlement, and data availability all into one layer. We're taking the execution layer, separating that into its own layer. And we're calling that layer two. And the key difference between layer two and layer one is that the layer two doesn't run its own consensus protocol. Right? The whole point is that we rely on layer one for consensus so that we don't need to go over separating these two. Now suddenly because of that we don't need to worry about what it takes to ensure thousands or tens thousands of computers would arrive at the same answer because layer twos are only responsible for execution.
00:04:20.670 - 00:05:20.638, Speaker A: And what does that mean? It means we don't need to impose the same kinds of constraints on the kinds of computations. You can do as you would need to on the layer one and that changes everything. So on layer twos there's only a single sequencer that produces the blocks. It executes the transactions. And therefore we thought, well, maybe we could use this to our advantage, to develop this advantage to interact with outside world, to call external APIs. And after a year's worth of work we're able to overcome EVM's restrictions by modifying Gas. So we have a customized version of Gas running on Boba network.
00:05:20.638 - 00:05:49.090, Speaker A: It's called LTT for Turing Lt guest with atomic support for generating random numbers and making any external API call that you specify that you try. And it's super simple to use, very easy. These are one line calls. What you see on the screen is a pseudocode. But like, look at the first example. Turing get random. That's all you need to do to get a random number.
00:05:49.090 - 00:06:52.476, Speaker A: On the second example, specify the RPC endpoint that you want to call to, let's say get the current vault for BTC USD pair boom. Like, one call when you're done. Now, how does it work? So let's look behind the scenes a little bit. So our LTT gap is the one that actually makes the external API call on behalf of your smart contract. So it will intercept certain calls that has Turing calls embedded in them and then call the off chain API or brands to generate a random number. And when the results come back, our guest would replace the original call data with modified call data that includes the responses that come back from the off chain call. And this is important because we need to ensure that these transactions can be verified afterwards by the fraud provers.
00:06:52.476 - 00:07:54.180, Speaker A: We need to make sure that whatever we've done is fully compatible with the rest of the optimistic roller architecture. And so we'll write both the original transaction and the modified call data that includes the offchain API responses into ethereum layer one. And from that point on, everything is treated just as if it were a normal Gas transaction. And the key is only the sequencer would call the API, no one else. Because if you let other independent nodes call the same API you might not get the same results back, right? So it's important that only the sequencer makes the calls. And then once the layer two block is written back on layer one and the Verifiers and the Replicas will use the stored responses from the API call from the block to do their job. So here's a diagram that outlines how that works.
00:07:54.180 - 00:08:28.800, Speaker A: So, step one, LTT Gap would intercept the RPC. You would make an RPC call to the Gap, and our guest would be like, okay, is this a Turing call? It is. It calls. The endpoint that you have specified waits for the response to come back. If the response doesn't come back, it's going to time out. We've set the timeout currently at 1200 milliseconds. So when you're writing around this, you want to have a graceful fallback default value in case the external API doesn't come back or takes too long.
00:08:28.800 - 00:09:15.090, Speaker A: So the response comes back. Our get would replace the original call data with updated input that includes the response that comes back from the option call, creates a new block, and submits that to layer one. And then new block is indexed. Replicators has worked the verifier. Everything else just works. It's taken us a while to roll this out on a Mainet because there's a lot of work that needed to happen under the hood. These are some of the changes that we need to make.
00:09:15.090 - 00:10:10.112, Speaker A: So we modify EVM go and modify the Ethereum block format to include the responses from the off chain APIs. And all of the data from off chain APIs are written back to Ethereum layer one. So as a result, we put a limit on the size of the response string that comes back. Otherwise these calls could become really expensive. And then we also added the ability for Gaff to replay these compute requests based on the data that's written to Ethereum. We also modified a bunch of internal data types and finalized in a sample and other parts of L two gas minor worker go. We also needed to modify of services that pass data from layer two to layer one.
00:10:10.112 - 00:10:47.724, Speaker A: How you index layer one, how you inject layer one data into the layer two. Gasp. And then we tested and tested and tested. Finally rolled out touring on Rinkobe during East Denver, and then a month later made it live on maintenance. And by now, developers have started building on Boba using Turing. And I'll give you some example use cases. For example, you can build DeFi protocols based on blockchain assets such as real estate or some sort of bonds denominated in Fiat and Trafi world.
00:10:47.724 - 00:11:35.696, Speaker A: You can now start pulling these Fiat world real world assets into DeFi. There's a team on building on Volpa, creating an NFT lending protocol that uses an off chain machine learning based valuation model to put a valuation on these NFTs so that they figure out how much to lend against these collaterals. Imagine doing trying to do that all on chain. It's just impossible. Too expensive, too slow. But now you get the best both. You might also want to redesign to incentivize your community members to do certain things on social media, for example, to retweet.
00:11:35.696 - 00:12:58.824, Speaker A: And you can use Turing to call Twitter to verify that, to see if someone has actually retweeted something. And after the verification, you can then automatically release or AirDrop some rewards. And since it's all happening on layer two, these transactions are much cheaper, much more affordable than if you do it right on layer one. There are also Dow memberships that would dows that want to connect their members identity with their off chain real world identities. Now, to some of the web Three natives, this might seems like a little weird, but if you think about how web three is growing and looping in more and more mainstream organizations into the movement, you start realizing there will be actually more and more demand to integrate what's happening on chain with what's happening with what already exists off chain. For example, there are college alumni associations out there thinking about, oh, how do we create NFT memberships in our alumni association and identify them as verified members in a metaverse that they created. So in that case, they're not really trying to create NFTs that can be flipped or traded.
00:12:58.824 - 00:13:40.250, Speaker A: They're trying to use NFTs to represent an identity that exists in the real world that needs to be verified. You don't want someone to fake themselves as a Harvard alumni. So Turing also enables that you can create NFTs that could be connected to the school's official alumni directory and verify the real world identity of that metaverse character. You can also create a Twitter activity based token fountain. We've created this. We've created a Boba fountain on a ring. And you can also use our atomic random number.
00:13:40.250 - 00:14:35.556, Speaker A: And bottom line is, if we're able to connect this decentralized computer with the rest of the world, with other network computers, you can now create a lot more intricate. And this here the list here is we're just scratching the surface. Some of these ideas actually came from developers that started trying out Turing. So we've got a detailed write up at this gettouring with a capital T. It's really easy to use. It's just one line call. And what really sets us apart at Boba here is we're enabling developers to build smarter applications on Ethereum.
00:14:35.556 - 00:15:25.040, Speaker A: We're not just scaling it in a traditional sense or making it faster and cheaper. We are augmenting Ethereum by enabling you to build applications that can include algorithms that are much more complex than what you can execute on Ethereum layer one itself. All right, so that's our hybrid compute story. It's live on mainnet, really encourage you to try it and see what you can build with it. A lot of developers are finding that this completely changes how they think about what they can build. It really expands the design space available to you. And, yeah, I can't wait to see what comes out of this weekend's hackathon.
00:15:25.040 - 00:15:35.124, Speaker A: Thank you. Questions?
00:15:35.242 - 00:16:08.290, Speaker B: Yes, just got a quick question about sort of got a quick question about I don't know if it's working, but security. So you said that there was a time limit on requests coming back and having a valid response. Well, do you think it's possible that someone might want to overload the network with requests that might take too long and that might slow down block times or transactions because of that? Is that something that's possible?
00:16:11.140 - 00:16:45.550, Speaker A: It is possible, which is why we put a time limit on it. Of course, we have no control over how quickly the external API comes back. It's a 1200 millisecond timeout. Fortunately, you get a control which APIs you call. And our hypothesis here is that the developers are only going to call you're only going to call APIs that you trust. So these are either going to be your own RPC endpoints. If you're, let's say in that NFT lending model, you're running your own blockchain valuation model.
00:16:45.550 - 00:17:31.340, Speaker A: If it doesn't come back or it's too slow, you have full control on how you want to fix that. And in the case of calling Twitter or whatever, that is a much more established and trusted API. So that's less of an issue. Now, it is possible for a nefarious developer that really intentionally wanted to deploy a smart contract that calls some random API that just never comes back? That is possible. But fortunately, we do control guests, in this case with a trusted party's optimal sequencer. So if that's the case, we can filter that out. That sounds good.
00:17:31.950 - 00:17:56.260, Speaker B: What other sort of functions do you see potentially being created in the future as well? You've got random number and API. Do you see stuff like maybe do a knowledge proofs as well? Possibly ways of having arbitrary sort of code get run separately and then having it proved later down the line that this has been run and it's valid as well? Is that something you're thinking about?
00:17:58.680 - 00:18:00.420, Speaker A: Could you frame that question again?
00:18:00.490 - 00:18:26.044, Speaker B: Sure. Are you thinking about other sort of arbitrary sort of functions that maybe developers want to create as well and having those arbitrary functions run on the network and then maybe having like a proof function, something like ZKP, where you can prove that those functions have been run correctly, the output is correct as well. Is that something that you think about with Vova as well?
00:18:26.082 - 00:18:31.830, Speaker A: Potentially, yeah, definitely. That's something that we're looking at.
00:18:38.100 - 00:18:59.560, Speaker C: Quick question. As you have said, because of the API Turing feature, there can only be one sequencer. The problem that I see is if the sequencer gets attacked, goes rogue, goes offline, right. This would destroy the whole roll up, correct?
00:18:59.710 - 00:19:36.308, Speaker A: Yeah. That's a more general challenge with today's rollouts, in general, not specific to rollout Turing. So we've already begun our work on distributing the sequencers to address this availability issue. And in terms of Brook sequencers. All of the roll ups are going to have to deal with this challenge as soon as we start letting other parties run these sequences. Now, we are not, of course, going to operate a role sequence ourselves, because that will be shooting something in the foot. We have enough skin in the game to not do that.
00:19:36.308 - 00:19:49.720, Speaker A: So the idea would be to extend the same to ensure that other sequencer operators will have enough skin in the game through staking other mechanisms that if they do go broke, there will be severe management.
00:19:50.220 - 00:20:08.300, Speaker C: Okay, but this API feature makes it harder. Right. So if your EVM equivalent, like optimism, arbitrage, for example, to decentralize the sequencer is easier without the API feature, right, because how would you come to consensus?
00:20:08.960 - 00:20:23.280, Speaker A: Yeah, so we won't be running our own consensus protocol amongst our sequencers. We'll be rotating the role of making Turing calls multiple sequences. So at any one time, there's only one that's making that call, but that could still be multiple.
00:20:25.740 - 00:20:47.528, Speaker C: Another really quick question. You pointed out the example of the Twitter API, right. So I imagine you have a smart contract. You do the actual API call inside the smart contract. Right. You have to put the Twitter API key somewhere. Right? And if it's in the smart contract, anyone can see that.
00:20:47.528 - 00:20:49.250, Speaker C: How do you handle this stuff?
00:20:55.920 - 00:21:41.310, Speaker A: We do handle it because we have already implemented a faucet on Rinkbeat that requires a user to go through Captcha. And how do we handle the API key? I'll need to get back to you on that to look at how we implement it. Thanks. Yeah. Thank you. Any other questions? Yes, Calvin, you look very nice today. I did, thank you.
00:21:41.310 - 00:21:48.208, Speaker A: Cool. Will you manage through the hackathon so you get enough sleep? You're okay?
00:21:48.294 - 00:21:50.268, Speaker C: You're excited for the rest of the hackathon?
00:21:50.364 - 00:22:04.540, Speaker A: Super excited. Thank you. That's the spirit. Thank you. All right, well, thank you for coming to this workshop. Please go to Bitlygettouring, check out desktop. Really look forward to seeing you build amazing things on touring and on Boba.
00:22:04.540 - 00:22:23.790, Speaker A: Thank you. It's.

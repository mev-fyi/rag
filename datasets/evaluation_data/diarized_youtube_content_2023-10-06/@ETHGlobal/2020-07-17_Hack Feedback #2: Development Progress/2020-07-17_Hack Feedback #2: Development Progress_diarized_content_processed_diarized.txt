00:00:00.170 - 00:00:42.106, Speaker A: Just going to start the recording. We're taking notes again this week. Standby for the stream set up good? Yeah, we're good. Stream is up. I'll repeat what I just said. Welcome, everybody, to the end of week two and this second hack feedback session. If you can believe it, you've already been working on your project for two weeks, which is incredible, and I've already seen a ton of progress from people who are just starting with ideas or crazy concepts from the first sessions that we had.
00:00:42.106 - 00:01:12.466, Speaker A: So, again, this is incredible and you should all be commended for sticking it out this far. So I just dropped in the chat, the Google doc where we're going to be taking notes last week. This was really helpful for putting links. If you have something that you want to share with somebody who's presenting or just keeping track of who this specific project should reach out to. So if you want to help contribute to that, feel free. I believe the edit permissions should be correct. People can't access it.
00:01:12.466 - 00:01:52.800, Speaker A: Just let me know and I'll get the correct link. All right, so this week was a little different. We do have a sign up order, and so I will be going by that sign up for presentations. Let me just pull it up and then we can get started. And the final note is we do have an hour and a half scheduled for this, but Juan is only able to stay for the first hour. So we are going to be enforcing some time limits. So make sure to keep your description short, concise to the point, because we want to make sure that there's enough time for everybody to get a little bit of time.
00:01:52.800 - 00:02:30.220, Speaker A: All right, so the first team that we had register was James Bork. James, if you're here, you want to unmute and tell us about what you've been working on, describe your project. Yeah, I definitely wasn't expecting to go first to everyone. My name is James. We can put you if you need more time to no, no, it's mean we didn't participate last week, so kind of figuring this out and would rather just kind of get over with. Actually, Stephen, Matissen and Singh are also on our team, so they're the more technical folks. So hope I'm glad to have them here too.
00:02:30.220 - 00:03:12.060, Speaker A: Our project is still named TBD. We're calling it p three. For right now, we're focused on decentralizing sorry, monetizing, decentralized stored content. As a use case, we're focusing on something simple like mixed media journalism. This has been done before, obviously. People have tried EIP 1337, trying to figure out subscription models for Ethereum. We believe that this needs to go one step further beyond just the paywall and also authenticate content and manage the distribution of that content better.
00:03:12.060 - 00:04:37.030, Speaker A: So specifically, I guess, looking at the three different components for the paywall we want to set up, well, we're working on setting up three different revenue streams. So your traditional subscription model, a secondary model, which hopefully using meta transactions, be able to set up a budget for a monthly consumption of content. So it's a better seamless UI experience, I can spend $10 a month and read all my premium news articles, et cetera. And then the third would to be able to take a subsidy from a third party, for example, like an ad agency. So shifting that relationship from the content producer to the actual content consumer and saying I will provide you access to my browsing history, to the articles and the content that I am consuming in exchange for you paying for me going through the web and consuming all of this content, right? Removing that relationship from the content producer and shifting it directly to the content consumer, allowing journalism news folks to go ahead and focus on what they really want to do, which is produce content and build their websites and design around content instead of on advertising. So that's the concept for the paywall. The second bit is the distribution.
00:04:37.030 - 00:06:03.502, Speaker A: We are looking to do a serverless storage side encryption. So receiving encrypted content from IPFS filecoin very likely using Textile, putting that back into plain text, re encrypting with a session layer like a session key, so like a TLS equivalent and then using that for distribution so that the original content is always encrypted on storage. And only when it's distributed is it re encrypted with a temporary key that then expires at a certain point. So obviously one of the trickier things that we're working on is using trusted execution environments like SGX to facilitate that in a serverless way. We're trying to not use a gateway or not use some kind of a node to handle that encryption decryption. And then the third bit, if we have time, is to use some kind of hash based message authentication codes to verify the authenticity of that content from when it's uploaded and have that follow almost like a root certificate throughout its lifetime to the end consumer. So we believe that by fixing distribution and fixing the authenticity, the citation bit of it, we can really enable the subscriptions to work better, but haven't really socialized it beyond our group.
00:06:03.502 - 00:07:24.490, Speaker A: And so kind of wanted to get some feedback on if we're going down the right path or if there's a better way to structure this thing technically. I know it's kind of vague and a lot to consume in five minutes. Steven or Singh, would you guys like to add anything else or if anyone in the call wants to provide feedback. Hi. This is Singh. Another thing that we looking at as a concept wise that would like to see how we can make it more scalable by leveraging Lip P two B as the back end surface. So instead of a traditional Http based back end server, that just telling me I would like to see if we can put this into a Lip P, two P infrastructure such that we can scale it because it's about content distribution, right? So if we are able to spin up all this kind of back end lobe in a more close to the consumer physically, then that would be a lot smoother for all this kind of medium and data consumptions.
00:07:24.490 - 00:08:15.050, Speaker A: Yeah, that makes a lot of sense. I think the idea is really good in general and I think just the ability to distribute and monetizing content in that way I think makes a ton of sense. I think what you described in terms of doing the encryption and the model and kind of then doing the decryption and showing it in sex or something can work a hurdle. There is that sex has been broken a few times and they might fix it, but who knows, definitely increases the bar, right? Most of the security is about increasing bars to some extent anyway, so might be fine. You might consider identity based encryption as well. It's a different option. Instead of using SGX for this kind of model where you're encrypting content to disseminate with a lot of parties.
00:08:15.050 - 00:09:03.110, Speaker A: And another thing you can do is most of it, though, is you probably have a lot of challenges along the way. And so building all of those pieces, getting the encryption to work right, working with SGX or some other mechanism and do the payments and so on, that might be a lot to do in a short time. So what I would do if I were you, I would hack the simplest possible thing first, have the page where you can view the content, whatever that is. It could be a document, it could be video, it could be other stuff, right? So have the page that's going to do the decryption and so on and get the flows working with pulling the content and decrypting it just in the page. It's okay if they leave the key for now and that's fine. And get the payment flow to work. Just get that working and I think you're going to end up with a pretty good MVP.
00:09:03.110 - 00:09:53.610, Speaker A: And then you can worry about then making the decryption and the key harder to take away and so on. Harder as a second thing, but just getting that to work in a page, either just in the browser or through an extension potentially, that might be pretty good. The other option is if you really want to go, you could go native as well, right? You could make an app with either the space even from Fleek or Slate or other things like that, where you can go a full native app kind of flow. That might be easier for some of the content that you want to store, especially video might be easier that way. As opposed to because if you have to pull it and decrypt it and then show it, that might be easier to do natively than on the web. If you do it on the web, you can't use most of the normal video traffic stuff because the stuff is encrypted. Right? I think you might be fine.
00:09:53.610 - 00:10:14.610, Speaker A: They might have already figured that out, but anyway, it might be a little bit tricky. So I don't know, I would imagine a lot of those pieces are there's some technical risk all over the place and just getting the basics of it working before you expand out is going to serve you well. But cool idea. No? Fantastic. Thanks for the feedback. That's actually really helpful. We'll discuss it in our next group call.
00:10:14.610 - 00:10:48.006, Speaker A: Thank you. Anybody else have a quick comment on the project before we move on? All right, let's keep it moving. Next up was enoch. If you're on the call, don't see your name. All right, we're going to move on. Cindy with Pony share. Sarah.
00:10:48.006 - 00:11:34.394, Speaker A: Cindy, any takers? Okay, keep going. Li Yu with IPFS Scholar. All these people registered, but you lucky people will get to take their place. All right, next up, we had Kushi Wadwa with building blocks tech. Same team. Are you here? Peishon Wu. Hi there's somebody.
00:11:34.394 - 00:12:22.280, Speaker A: Yeah, finally. So I thought I will be later, but yeah, then we're the second, so hi everyone. Our team is making a project as a censorship resistant web annotation service. So the idea is coming from that. We thought like nowadays anyone can comment on the web, but most of the data is stored in a centralized way, so it could easily be manipulated. So our project currently is called Public Annotations Network. So a provisioned pen we would like to solve this issue by.
00:12:22.280 - 00:13:25.630, Speaker A: So the current idea is that we would like to have a Chrome extension, but maybe also for other browsers in the future that allows users to annotate content on the web. So any web pages. But for now we focus only on the Twitter to keep it focused. So users could sign annotations with their Ethereum address and publish them to the network through our back end directly on the network. And the annotation content will be stored on IPFS reference to annotation content. The authors of the annotation will be storing an Ethereum smart contract registry so the content cannot be censored. The future more complete version will be like of course we want to build out the product for arbitrary web content.
00:13:25.630 - 00:15:07.838, Speaker A: Annotations also include an incentivization system around publisher services. So more like there will be publishers. They can batch annotations and make submissions cheaper for the users. We would like to hear feedback on general impression of the project also about the interface, because now we want to use Twitter as the demo case and we like to hear how do you think about this demo case? Also for the incentivizing systems, we want to have two ways of users could either save cost and submit annotation directly and then we say now we have publishers where to use the batch. But this is like the current design and we also are open for better idea as well. And a third point would be currently we have basic API and web extension going, so we would like to hear more suggestions about how we could deal with identity management so it's easier for us to onboard users. Yeah, in short, but if you have any questions yeah, one thing.
00:15:07.838 - 00:15:58.960, Speaker A: Hi. This is Dominic. I'm also with the Pan team. So specifically regarding identity management and the system overall, we're building on the Verifiable claim standard by the W three C and specifically the extension of that for web annotations. And, I mean, there's a lot of systems out there that are already building annotation systems, but the only thing they really do well is polishing their product. They don't really care about decentralizing storage and building a censorship resistant solution. It's a free for all of potentially censoring researchers, journalists, or surfacing the content once it pops up.
00:15:58.960 - 00:17:31.670, Speaker A: We really want to remove that trust. But as we built out the Chrome extension and kind of hijacked the Twitter page to sneakily infiltrate their community, we've noticed that we've gotten very used to using MetaMask as an ethereum focused developer team. But MetaMask is not really the peak of UX that you can achieve. And we were wondering whether there's, beyond MetaMask any easier solution services such as three box to kind of attach an identity to an annotation and basically sign it in a very easy, straightforward way without having to worry about generating and storing your public private key pair and managing that and dealing with all the pop ups around that. So any feedback of how any of you guys on the call would hypothetically want to use this or whether you have any ideas on how it would be a cool way to display that on Twitter would be greatly appreciated. So we can polish this thing and make it as easy to use as possible because after all our sorry to cut you off, Danny, but we want to keep the pace going. Yanov, you wanted to go first and then we'll have Juan.
00:17:31.670 - 00:17:59.090, Speaker A: Yeah. So I think you're on a great track. Sounds like a really fun project, and I'm a big fan of the stuff that the Three Box team is working on for Identity. You might have also heard about Ceramic, which they're working on, and that's adding a lot of features to what they kind of started with. Identity around three IDs. And it's, I think, progressing. That state of the art there, but still kind of using some standards.
00:17:59.090 - 00:18:33.970, Speaker A: So I think you're on the right track there. And I think it would be great to get to a point where we really kind of have network effects around these decentralized identities, where kind of like Gravitar just every app just kind of pulls from that global pool of you already have a profile and it's a very kind of social web. And I think the work they're doing there is great for that. So I would take a look at that. Also. I'm with a project called the Graph. Not sure if you've heard of us, but it could be a good fit for what you're building also since it's using Ethereum and IPFS and you're using like a registry model.
00:18:33.970 - 00:19:08.460, Speaker A: So you can build a subgraph which allows you to index all of that data from your registry and the data from IPFS and make all of that available over GraphQL. And that makes it really easy to query that data from the client. So you might want to take a look at that. We've got some bounties for the hackathon. Yeah, I was going to say a really great project idea. I think annotations are a really key part of the web that's been missing for a long time. I think a lot of what you mentioned makes a lot of sense.
00:19:08.460 - 00:20:12.366, Speaker A: A couple of comments. One is you may want to try a hack with hypothesis where you replace kind of like the data store part and make that a thread or a bucket or three box there's like a way to use, I think, three box threads that kind of couple identity. You can store all the annotations there or something like that. There's some question around like a shared group thing or kind of having a public you'd have to figure out some way of doing kind of a public group because a lot of the notations you probably want to also share publicly. But if you do that, then the hypothesis part can handle a lot of the UX of how do you hook into all kinds of content and so on. That's a huge problem and that team has been working on that for a long time. And so maybe experiment with that and then kind of really focus on, hey, it's really about putting the annotations in a different distribution model and tying them to this decentralized identity side of things.
00:20:12.366 - 00:20:48.060, Speaker A: And I think that might be pretty promising. It would also kind of give you a community right away to work with. But who knows, maybe this might be too difficult to kind of wrap altogether. So maybe do like a fast determination whether that makes sense or not. Yeah, that would be my suggestion. Anybody else have any feedback for the Think? Andrew? Oh yeah, go ahead. Andrew, how do you spell hypothesis? It's like hypoth.
00:20:48.060 - 00:21:26.388, Speaker A: Yeah, I just want to say something here actually. Maybe not quite feedback on exactly what you're doing, but this point of confusion, I think that happens a lot around identity specifically. And I have a thread I'll share a link to where I was sharing some because I hear a lot of people going through the same motion. So I thought maybe this would be a good venue to share this. If a lot of people are approaching this problem, and one way to understand it is that identity takes secrets. And if you want to own your identity, you have to own a secret. And secrets you can't store on a network.
00:21:26.388 - 00:21:59.632, Speaker A: There's no network in the world that stores secrets. There's only two ways to store secrets that I know of. One is you store well, there's actually only one way to store secrets that I know of is you store them on real Metal, which means that you store a secret on your computer, you store a secret on your device. And some really good solutions for that are wallets. So local wallets do that for you. They let you put it in a place that has it on your device and some sort of sandboxed way that they're doing that. So MetaMask when it's storing things in your browser is essentially doing that.
00:21:59.632 - 00:22:47.040, Speaker A: You building a browser extension is cool because you can actually leverage some of the same abilities that you can't do if you just have a web app to keep secrets away from the rest of the browser sort of app space. So that's a really good resource. But the only other way to do that really is with APIs. So anything that's not storing your identity on your own metal is actually just asking somebody else to store it on Metal and you trust them to give you your secrets or sign something for you when you request it. There's the only two ways that I know of to manage identity, and there's a lot of really cool wrappers around that. Yanni pointed to a couple of them. Things like magic and taurus have other cool ways of linking with OAuth and things like that too.
00:22:47.040 - 00:23:20.940, Speaker A: But just go with that framework when you're thinking about identities. Identities take secrets. Secrets have to be on Metal. You have only a couple of ways to get secrets on Metal, and it'll help you kind of think through what the restrictions are when you're building a DAP to be decentralized and how you're going to get users in. Just had to I had to vocalize that for people so that you don't get trapped in these sort of like dead ends, I think. Anyway, that's all very insightful. I wrote up a summary of what you had said.
00:23:20.940 - 00:23:40.716, Speaker A: Feel free to add to it in the Google Doc. Cool. Up next we have Jose if you are on the call. Yeah, go ahead. Remember to keep it right, sure. Yeah. No, first place.
00:23:40.716 - 00:24:30.820, Speaker A: Thank you very much for the opportunity to obtain feedback. Well, my project, or my question is kind of a recurrent topic. I have heard different similar topics, so I think it's also about identities. So basically the project we are building is an application where every owner of every wallet, every wallet ID can have an identity in IPFS. Right? So the idea is that you authenticate with your wallet and then you store your data in IPFS. So that data will be encrypted in principle, private. It will be private.
00:24:30.820 - 00:25:50.264, Speaker A: So we want to generate a contract that provides the governance to that data, in the sense that if someone want to access to the data of a different user, they have to pay a small fee to obtain that information. So basically it will be that if you keep your profile in IPFS and everybody who want to access your profile, they have to pay you a small fee. So you are monetizing your data somehow. So we would like to create a smart contract that applies the governance. Basically the contract will store a list of a mapping between wallet IDs and IPFS hashes. I guess the problem or the point I would like to get advice is we want this smart contract to be able to encrypt decrypt that data, obviously without the other users being able to access that data. What we want to do is enable this contract.
00:25:50.264 - 00:27:38.428, Speaker A: So either the data in the IPFS file is encrypted, can only be decrypt by the contract, or the IPFS hash itself is encrypted when we store in the smart contract. Do you understand? Is that clear? So I was wondering, obviously we want to deploy this application in Flick hosting to have a full decentralized app. So I guess the question is how do you recommend to store, let's say, the private key of the contract that will be used to create all this data with some level of security? Is that kind of any idea? If your main question is about kind of how to model holding onto the key and so on, I would probably use still. And this key is an ethereum key that governs a smart contract and so on, then I would follow the same rules for how to deal with those keys, which is usually have an API for MetaMask or for other wallets like that. And then enable have the website just delegate the kind of decryption of stuff out to that key. But I think what you want to do is not quite have that key do it. You want to generate a different key to do the encryption and decryption and then take that key encrypt that the keys that you use for signing, you probably shouldn't be using for encryption.
00:27:38.428 - 00:28:28.320, Speaker A: So there might be something there around you may not actually be wanting to use the same keys. I understand what you're saying of mapping an identity to that, but I think there's a different way of doing it which is you can generate a set of keys that maintain control to the information and then you update a mapping, a pointer on the blockchain. So for example, you could do this with ENS today. So you could say take all your content and put it on a bucket or in a thread or something like that, and then take the root key of that and map ENS to that value. And once you do that, then whoever has that ENS name would then now be immediately able to access that data. Right. And so you can, for example, publish a website to ENS this way.
00:28:28.320 - 00:29:12.190, Speaker A: And then in terms of the public, in terms of private data and so on, that allows you to keep a different set of keys that maintain that infrastructure. And so you would probably have to think about how you want to keep those keys and how you want to recover them and so on, and kind of think about where to put that that might fit in a wallet. Like, for example, you could think about hacking this for now and then saying, hey, maybe MetaMask or things like that could extend to include data wallet decryption keys, which are different from your money wallet. Or you could think of other models for storing keys. I think Andrew might have other comments around. No? Thanks very much. That makes a lot of sense.
00:29:12.190 - 00:29:55.660, Speaker A: I guess it's kind of a chicken and egg problem to have everything decentralized, but at the same time keep the appropriate level of security. But yeah, okay. We can approach in that way for sure. Yeah. Go ahead, Andrew. Yeah, I just thought just because Juan tagged me a little bit there, I'll just explain really quick in threads. The way that does happen is more or less what Juan explained, where you have an identity that signs all the transactions, but the actual individual transactions themselves are encrypted by single use symmetric keys.
00:29:55.660 - 00:30:37.080, Speaker A: So then when they're on IPFS, they're secure. They're quantum proof secure, essentially. But then they're peer to peer. They're not because that key itself is encrypted and that encryption is shared sorry, that's then a key pair. So the key plus the hash are encrypted with a key pair and that's shared with other people that have the read key and so that other people can read that content. So it has a bit of that hierarchy built in to get around some of that. Okay, thanks very much for the feedback.
00:30:37.080 - 00:31:17.316, Speaker A: Any final comments? All right, let's keep it moving real quick before we move on to the next one. We just want to get a let's get a group photo. It's not really going to be a photo, but we did this last week and it's a good way to mark the end of everything. See, Carson's already on top and he knows. Just throw on your videos for just half a second if you can, and hit me with the two for week two. And then we'll grab a screenshot and tweet this out later. Throw up two, week twos if you want.
00:31:17.316 - 00:31:29.370, Speaker A: I don't know, whatever you want to do. There we go. We almost got a full screen that Fireflies AI is taking us in real estate, but this is good enough. I'll take it. Awesome. That's it. Picture taken.
00:31:29.370 - 00:32:27.368, Speaker A: Thanks. Okay, next up, thomas. I think I saw his name TJ TJ here. If not we'll keep going. Susmit Lavanya hey guys, nice to meet you all. So basically I'm from team Cadbury and I have AYUSH ranjan with me on board with the team. He's also presently in the so in meeting, what we are building is that we are actually trying to decentralize Google meeting or the zoom meeting.
00:32:27.368 - 00:33:35.600, Speaker A: So at the end of the hackathon we envision that we all are having the same meeting on our own decentralized platform. So the way that we are approaching this problem is that what we will do is that we will set up a demon in the browser that would be powered by live p, two P WebRTC and we would be having two access that is web camera and the audio. Now, these output needs to be converted into HLS format. So basically what we are doing is that we would be using Ffmez to convert into HLS format. So basically HLS format has lot of advantages because of the bitrates and it was developed by the Apple. So since FFMG is bit computationally means it consume a bit computational power. So we are thinking it to take it like a decentralized transcoding mechanism that we are thinking of.
00:33:35.600 - 00:34:52.136, Speaker A: And on the client side, so all of this information would be published on the IPFS and all of the pinning and all of those IPNs system would be going underway somehow. And then on the client side, this IPNs hash would be there and it would be rendering that video via HLS player. So this is the basic mechanism that we have come up for our decentralized Google meeting that we call as Cadmary meet. Now, the blocker that we are trying to have is that the problem that we are facing is that the Ffmz output is not deterministic. Which means for the same video, if two parties are processing the same video, the output would be different. So this is one of the problem that we are facing and the second is that how do we actually achieve decentralized transcoders? So we have realized that for this actual to put this in place, we would be requiring relayers also and we would be required kind of decentralized transcoders also. And all of this business logic would be coded on the Ethereum smart contracts.
00:34:52.136 - 00:35:45.252, Speaker A: So the transcoders and all of them would actually list themselves on the Ethereum Smart contracts and all of the business logic would go authorization authentication that would be handled by Ethereum Smart contracts. And the other thing that is the analytics. So we cannot put Google Analytics in the website because it does not go with the web three solution. So we need to somehow come up. So we require the footprints that we are getting on the website. So kind of any web three analytics that we have and the decentralized transcoding and the FFMG part like how do we approach this computational task which is non deterministic in nature. Yeah.
00:35:45.252 - 00:36:21.468, Speaker A: So. Have you taken a look at the Live Peer protocol? Yes, we had looked into the Live Peer Protocol, so we had gained some inspiration from them also. But we have some upgrades on the Live Peer Protocol also. Like we are considering their LMPs server also, but we want to keep things simplistic. So basically FFMG is something that we want to convert FFMG to HLS format. Okay. Because I remember they did have to deal with the same determinism issues that you mentioned.
00:36:21.468 - 00:36:56.376, Speaker A: I forget how they actually got around it, but in general, I'm a fan of leveraging as much of other people's work as possible. And I know they've got a really talented team. They've been working on it for years. It's built on top of Lib P to P. They released their streamflow version of their protocol recently, which makes things a lot more scalable. They now have these orchestrators and already a pretty big network of these transcoders. So I think as much as possible, this sounds like an amazing application.
00:36:56.376 - 00:38:07.216, Speaker A: That would be awesome. I think we're spending so much more of our time on zoom and hangouts these days and there's definitely this thing in the back of your mind that's like, where are these videos ending up and who's got control over this data? And it would be a wonderful thing to have really more decentralized. But I wonder if there is a way that you can leverage the existing work that's been done there. Yeah, I was going to say the same thing. I think the Lifeyear folks have done a phenomenal job with a ton of the stack there. And so I would say, yeah, if you can use the infrastructure they already have, even though you might think about other things that could be improved and so on, consider making extensions to their systems or adding pull requests and contributing to Lifepeer as an alternative because replicating that level of functionality and so on is nontrivial. And they've also recruited now they have a pretty significant ton of potential in the network of parties that can do that, transcoding and so on.
00:38:07.216 - 00:38:53.390, Speaker A: Right. And all that's ready. So I think definitely consider doing that and then really focusing your hack around then okay, great. So if you use those systems as building blocks and tools, then how do you get the UI? And you make that a web app or something and you plug into the stream and then focus on all the challenges that come from actually doing the now you have these streams. Great. Now how do you make that into a call? Right, so I would probably decouple those. I think you'll get more out of the hack of actually making the product part of it than making the underlying infrastructure part of it because the product part of it is what's going to give the whole thing legs and give it the ability to kind of start to use that application and so on.
00:38:53.390 - 00:39:53.212, Speaker A: And no question, you could probably figure out improvements and so on and tune the use and whatnot. But that can always come later, right? So you could either improve, spend the next few weeks replicating a lot of the stuff that Lifeyear folks have done, or you could spend them using Lifeyear, building something, building that into a really good product and then deciding later whether you contribute improvements to or move off and build your own. Right, right. So Joanne, actually, if we see we are actually complementing Live Peer Protocol only, so we had taken in consideration to use their LMPs server and all of those mechanics. We have some inspiration from Live Peer Protocol also. So Jiwan, as we have mentioned, that there could be some questions that might become blockers. So can we connect over Slack with you or the other team member that could help us out in the process? Yeah, you should definitely leverage.
00:39:53.212 - 00:40:36.992, Speaker A: There's a number of office hours and you can just ask questions on Slack about how to build stuff with either Lipidup or with any of the other tools. So, yeah, definitely ask your questions there and people should help unblock you. And then a number of us are kind of hosting office hours this week and next week, so you can check out those. Awesome. And Joanne, we already have our landing website up, so it's hosted on fleek and currently Basic UI is done. The other thing that I wanted to ask is how do we actually achieve a kind of web Three analytics? Like Web three Google Analytics. Yeah, I would say that's a very interesting, hard problem.
00:40:36.992 - 00:41:26.316, Speaker A: I would say that requires a whole kind of product team focused on making that a really good solution. It is nontrivial. I definitely would very much support a group trying to go and attack that problem and building that out because there are no good solutions out there. There are some analytics systems that get better at this and are approaching this, but not quite to the degree that I think everybody wants. And so I would say for now, don't do that, don't have analytics for now and then leave it to a problem later. If you really need view counts and whatnot, then consider having a thread associated with you have the streams and so on, and then you take all the metadata and put it on a thread and do that there. Right, so you might run your own kind of view counts and whatnot associated with that piece of data.
00:41:26.316 - 00:41:52.392, Speaker A: That'd be my recommendation. I think we'll probably have to move on to the next one, but really cool stuff and drop a link to what you're building on the document and people will check it out. More demos. Thanks a lot. Thank you. Thanks Susmit and the rest of your team who's here just in general, I want to echo what Juan said. Your first instinct should be if you ever have a problem, put it into whichever slack channel you think is the best.
00:41:52.392 - 00:42:19.840, Speaker A: That's going to be your first place to get resources, get help from any other hackers or mentors or sponsors. Then if you still can't solve it, like Juan mentioned, office hours are the next best thing. That's where you can really get technically deep into some of these problems with people. So make sure to check them out. We have a bunch more scheduled. I'll be putting them up on the calendar tonight or tomorrow, so keep an eye out for those. Next up is Raphael.
00:42:19.840 - 00:42:50.810, Speaker A: His name is Bold, but he is not here. All right, gov, I think Rafael is here, but maybe let's get that away for a while. I had a connection issue. Okay. Go ahead, Raphael. Sorry about that. So I'm developing the app and infrastructure which interacts with IPFS for publishers, independent publishers.
00:42:50.810 - 00:43:55.950, Speaker A: It intends to use Linked data. I was thinking of modeling an ontology. When you fetch data on IPFS, it would hash their ontology. So I'm kind of thinking if that would be a nice path or if I should try to use some other thing. And the idea is basically that you could fetch data. It would index data and to try to give power to people to search their interests and not be you have some search independence, like some searching autonomy. And one of the ideas is to keep uploading this ontology and make it public, like mapping how this data is on IPFS.
00:43:55.950 - 00:45:11.504, Speaker A: And another thing that while I'm developing that I thought is that is to use Pub sub from IPFS as a sort of RSS feed, you see, because I don't know, it's kind of this way of sharing information lost some popularity and I don't know, I thought that would be interesting to always that some data is fed in this application. It can rafael, looks like your audio cut out. I don't know if you're done talking. Do we want to give feedback now or wait till he comes back? Maybe wait because you may not be able to listen. Yeah. All right, gov, do you want to present Quick and then Tomato? We can go back. Yeah, I don't have too much to say, so okay.
00:45:11.504 - 00:45:34.490, Speaker A: Just to remind you guys, my idea is building an erasure coding layer on top of IPFS, specifically IPLD. Now, as of this week. Yeah. So I have just a quick update and also some feedback I'd like. So the first thing is, I think maybe I'll share my screen. Might be worth it. Without going too deep into it.
00:45:34.490 - 00:45:53.424, Speaker A: We're going to try to use the format Dag service and then build on top of it. That's what we're thinking as an approach. So just add an encode and a decode method which is going to add more nodes into the Dag. That's kind of what our idea is. Okay with Juan's. Thumbs up. I think that answers my first question.
00:45:53.424 - 00:46:54.416, Speaker A: The second question, which is perhaps a little bit more problematic, is that for Reed Solomon, you have the standard kind of like various different paths, of which there are many serial paths, of which you're either going to get the data blocks or you're not. And if you get the data block, if you don't get enough data blocks for a path, you can choose a different one. That's kind of how it works. But with alpha entanglements, you have this kind of very cool dynamic structure where you can take a path and see how long it gets you. And if you lose any blocks in the way, you can try a different path and then kind of go there. So the important sort of problem that happens here is that you're going to have to go back a few steps if you follow a path to a certain degree and then you find that you're missing a block, and then if you're not able to reconstruct, you're going to have to try a different path. So you're going to need some kind of history, right? Like you're going to know what your parent nodes are, which is not something a Dag by definition is supposed to do.
00:46:54.416 - 00:47:37.164, Speaker A: So our workaround for this right now is a node cache, which is just like while you're going down these paths, it's like just keeping a note of what nodes you previously encountered in this path and it falls back to the previous one to try to find a different path in case you kind of encounter a hitch. So I want to know if that is the best approach. This is a kind of technical question, and I learned that maybe this is a more office hour question, like just like five minutes ago. So maybe that's something I should think about. But I'm happy to hear your guys'thoughts general feedback even on whether this is the right approach. It sounds fine to me. I think there's a difference between data structures and algorithms.
00:47:37.164 - 00:48:24.704, Speaker A: So I think you want to maintain the one directional acyclical nature of the Dag, but I think it's totally fine for an algorithm operating on the Dag to maintain, like, history. Awesome. Yeah. One thing that ends up happening a lot with this kind of stuff is think of also imagine if you have just a web of documents that link to each other, right, and you're trying to model them in a hash length graph. In reality, you have two graphs. You have one graph, which is the graph of documents talking to each other, linking each other. And then the other thing is the projection of that graph into a version history of how things kind of came to be, in that if you hash link everything, you're probably going to have versions of these documents at different points in time linking to each other.
00:48:24.704 - 00:49:16.508, Speaker A: And then the links might include kind of like a mutable link where you ideally are trying to link one page to another page and link to the latest version of the page. And you might take a snapshot as well. In that link, you might have a reference that points to both the Mutable name and an Immutable copy. So the whole thing always works, right? And so similar to that model of saying, hey, here's how you kind of implement a Mutable graph on top of an Immutable graph here with erasure coding, you might want to consider something like that where you think about the links between the objects being kind of potentially outside of the objects you have the actual encodings and so on. And then you have many other nodes that are the nodes that are linking them together. Right? So instead of putting the link within that one object, pointing to the next one. And so that way you can model your pathways in another set of objects that are very small because they're just links.
00:49:16.508 - 00:50:05.440, Speaker A: And then the actual objects carrying the data are the larger ones that have the data. How different is that from my current approach, which is just adding this into like a special modified Dag? I didn't quite understand that. Sorry, it probably depends on sorry, can you repeat how the modified Dag maybe I missed a key detail there. Could you repeat kind of the exact data structure that you were thinking of? Like the specific links, like what object would link to what? So it's a dag service. Sorry. Yeah, so it takes a Dag service and then it adds an encode and a decode method, and the encode method takes all the links in your dag and then creates redundancies for all those links. That's kind of how yeah, sorry, I got more the level question, which is okay, given that you are adding redundant links to other potential blocks.
00:50:05.440 - 00:50:47.868, Speaker A: So if you have a very large Dag, right? So if you have, say, a dag that's a gigabyte large and you have a lot of little chunks or whatever, you may want to erase your code that differently. Meaning you may not just want to have two completely different copies. You might want to be doing erasure coding of subsets. So you might want to transform that non eraser coded copy into an erasure coded copy, a single other one, and then that one might have all of the links to the actual blocks. And that's where I'm saying you might want to have multiple links. This might be a good topic for office hours. I have some next week, so you can sign up for those and we can go in detail.
00:50:47.868 - 00:51:12.710, Speaker A: If you kind of write up what you have right now and send it ahead of time, I can definitely review it and give some better comments. Cool, where should I send it to? So when you sign up, you can ping me on Slack, actually. Just send me a message on the platform. Slack. Got it. Thank you. Okay.
00:51:12.710 - 00:51:31.356, Speaker A: Thanks Kev. Next up, let's get Adam. He is around still. Hey guys. Yeah. So we missed the hack or the feedback session last week. So we're kind of looking for general feedback as well as answers to a couple of specific questions we have.
00:51:31.356 - 00:52:34.210, Speaker A: But basically the thing that we're trying to build is sort of like an incentivization system for training machine learning models. So the idea would be that you're somebody who has data, but you don't have the expertise to train a model to use that data. So what you can do is upload that data to IPFS basically and submit to a smart contract, sort of like a request for training where you say, here's the location of our training data, here's the location of sort of the data to evaluate the model against. Here's the definition of, I guess what accuracy measurement we're looking at kind of thing or what function you want to evaluate. All those things will sort of be submitted beforehand so that everybody can see and kind of audit them. And then you stake a certain amount of money that's sort of like the prize money, I guess for the training. Each person that then wants to participate can train a model on their sort of off chain whatever computation system upload that model somewhere to IPFS, ideally in some format that's sort of like standard, like TensorFlow, I guess.
00:52:34.210 - 00:53:28.352, Speaker A: And then basically register their submission in the incentivization contract. And then at the end of the sort of time period that we have specified here, the idea would be that each of those models can somehow be trustlessly verified against the initial accuracy function that was submitted at the start of the whole thing. So you can kind of rank all the models that were submitted in order of how well they perform against the initial problem specification. And then we kind of want to have it so that it rewards every participant in the system with a proportional reward depending on how effective their model is. So basically you don't shut anybody out from doing work and not getting paid for it. Everybody gets something, but obviously the person who has the best model gets the most. Other than just general feedback for that.
00:53:28.352 - 00:54:39.892, Speaker A: The two main things that we're looking for here are what would be sort of like a good way to trustlessly verify the model evaluation. A couple of things we were thinking so far are sort of like an oracle that has a compute function because we found one of those, but that doesn't seem like the best option. The other thing we are thinking is potentially something kind of like state channels where you establish direct peer to peer connections and then everybody that submitted a model kind of gets to handshake on what they think the model's outcome is and then agree on the accuracy. I don't know if that's good. Then the other thing is we're worried about the idea of people being able to submit multiple models with very similar accuracies and claim a larger portion of the pie. So how do you prevent that kind of I guess like attack from happening? So yeah, maybe somebody with more knowledge can correct me, but how similar is this to Numerai? They're doing some sort of training as well, aren't they? Or like a bets market on models? Anybody? I'll drop a link. Yeah, it's kind of similar and related.
00:54:39.892 - 00:55:23.332, Speaker A: It's a bit different in that in those you kind of submit that's more around, kind of aggregating the models into a larger meta model that then is going to be doing trading on top of all of that data. And I think this is kind of a more general provide models who train against anything the requester is asking for. Here's my problem, here's my data, solve it. And I'm going to reward proportionally all the people that gave a think related. I think you're going to be able to kind of look at a lot of what Numera has done as a good example to follow. It's a really cool idea by the way. I think this is really awesome.
00:55:23.332 - 00:55:59.600, Speaker A: Especially if you think of all the primitives there that you're making along the way. There might be other ways of using that stuff around being able to register a model and the data. There might be a whole bunch of other applications around that use case still encourage you to just build that one app first and get it working all end to end. But as you're making the things, just the idea of just registering some data and some target goal around a model that might end up building out some building block that somebody else wants to use for something else. So consider that making that into a library or something. Yeah, I think the problems are interesting in terms of verification. I just wouldn't do that yet.
00:55:59.600 - 00:56:51.056, Speaker A: I would just run the verification in some trusted thing for now and then later what you can do is you can think about parties that are verifiers staking some resources against good verification and so they run the computation, they measure how much it took and so on. And then anybody can go and challenge that expectation like if it's way too off in terms of because what you can do with that verifier cloud is the model is known. So nobody cares about privacy in this case, right? You just want to run the function and evaluate that it was incorrectly. So you have a set of verifiers that are staking some money for them doing the work correctly. They go and verify these. They go and run this and submit a result. And then if anybody wants to challenge them, they can challenge them and show that it actually was a different result and then they maybe take the fee instead.
00:56:51.056 - 00:57:27.052, Speaker A: And so you immediately create a network of parties that are just challenging each other and that's fine. And then additionally, you may want to pay proportional to resources. And there you also want maybe a little bit of a you want to also kind of challenge the counting their resources because people might lie. They might give you the correct result when they might be inflating the resources used. And so that might be a factor as well. But I would probably defer all of that until after you have the rest of the thing working because for now you can just run a server and then later you decentralize. It cool.
00:57:27.052 - 00:57:53.396, Speaker A: Thanks. We'll definitely look at all that stuff. I have to jump, but keep going and good luck. Thanks Juan. All right. Yeah. If anybody else has comments for Andrew or sorry Adam, if not, we can move on.
00:57:53.396 - 00:58:32.070, Speaker A: Let's keep the party going. Anmol, you're up next. Yeah, hi guys. So we have been building on Ceramic network. So Ceramic currently today supports identity but what we have been trying to do is add Verifiable Credential support on top of Ceramic. So what we are targeting is we create a new dock type with Ceramic cache which is called Verifiable Credential and that can be linked with the various three ID which Ceramic supports today. And then I think the general idea of Ceramic itself is up the link.
00:58:32.070 - 01:00:13.350, Speaker A: Multiple documents with the identity, the three ID that they have, so that you can have a chain of graphs of the Identifier and then have various set of claims that person holds. And any services who use Ceramic can present those claims to any party. So this is the idea and then what we are present as in targeting is address the revocable part of that Verifiable Credential. So current approach that's been suggested by WT stance is where you either maintain a revocable registry or either issue another revocable Credential status something and that generally requires issuer to have another lookup either with the issuer or at the revocable registry. And we are trying to approach that in a different way because Ceramic documents are generally they are immutable, they are just a link of all the records. So you can maintain the state of the claim itself and use the hash of the claim so that next time the issuer has revoked the claim the Verifier can check the network what is the latest status of that claim? So yeah, these are the two key challenges that we are targeting and then as we see, as in lots of ask that has been building around SSI and Credential, I think this would complement a lot of services that are building on top of Ceramic. Yeah, happy to receive any feedback as such.
01:00:13.350 - 01:01:31.436, Speaker A: Are you building a specific application kind of on top of this? Is this for doing like OAuth style claims or what's? The app? Not building an app, rather the credentials. When you build a credential, the credentials will be stored as a document on in ceramic and that will be linked to the identity that you want to link into so that you can have a chain of graph that the person holds all the claims that a person has. And you can resolve those claims and you can present those claims in the network itself. So, like, now Ceramic itself can support Verifiable claims? That's the idea, yeah. What sort of projects are you looking at for President? Because I know there's been many, many identity projects in the space. So which ones have you considered or using as reference the standard did, Jot, Verifiable, Credential, that's the, which supports Ether. Did, and then we'll be using that as a library, rather.
01:01:31.436 - 01:02:26.988, Speaker A: And then add support for three ID. Right now, the interesting part is the document support for Ceramic and whatever, the whole standard of linking of documents that Ceramic has, and then linking with various profiles the whole tree structure, which Ceramic natively has. And if you add a support variable Credential, you can build a lot of services on top of that. Gotcha anybody else? We'll definitely have to get some identity focused people on some of these next calls. Actually, I think Ceramic has a workshop next week, so once that's scheduled, I definitely come to it. It sounds like an awesome hack. I would just think about what type of app you could build on top just to showcase it.
01:02:26.988 - 01:02:39.056, Speaker A: Might make it easier for people to run with it and use it. If there's a good demo app. Sure. Yeah. We have been trying to do that as a side project. Sure. We'll try to keep that in mind.
01:02:39.056 - 01:03:36.950, Speaker A: Thank you. All right, it looks like we actually hit everybody on the list. Raphael, has your connection improved at all so we can come back to what you were working on? If not, maybe I can try and give you some text feedback in the slack. Hi. Just to end a comment, the application, I actually was trying to build an LDF graph or ontology, you see, to map that data. And the idea was to map the hash of the files. It's basically it.
01:03:36.950 - 01:04:42.280, Speaker A: So I don't know if this would be an interesting architecture for this context. I believe it's really experimental or if I should try to follow some more modern ways to think, because I don't know. Actually this way of using RDFS and ontologies you dropped out again, Raphael. Damn. Well, I guess we'll see if he comes back. Is there anybody else who did not register ahead of time, but is on the call and would like to give us a quick pitch for what they're working on? Give me a wave. Raise your hand in zoom.
01:04:42.280 - 01:05:18.132, Speaker A: Whatever works. Drop it in the chat. Yeah, go ahead. Stillwater garden. I'm unmuting you if you can see that, but you have to accept the unmuted. Yes. You have no idea how difficult this all is for me.
01:05:18.132 - 01:06:12.100, Speaker A: You're doing great. I haven't had this much homework in 50 years, if that tells you anything. And while I'm at it hi, Andrew. I'm the Odball of the group, so I might as well let you know that. And I'm not working on an app or a program because I've never done that before. All I know is I have been involved with listening to and reading information with regards to the decentralized web IPFS, especially textile. And now I'm learning more about a lot more of you who are involved in this entire trip.
01:06:12.100 - 01:07:28.556, Speaker A: And I'm actually developing something that I have never done before, along with a lot of other things. And it's a blog with regards to the formation of the decentralized web and how it's being developed. And it's for basically the general public, because I've noticed that in most of the information, it's all geared to the developers. And I think you want to get on board more of the general public to make this a really accepted network to utilize and possibly to involve. It can be more older people or even younger people to get into the field and get on board. I think this is an excellent avenue for the networks to go, and I'll see what happens, because, as I said, I've had to go back through a lot of history to remember what Andy told me five years ago. That's how I got into this.
01:07:28.556 - 01:08:17.308, Speaker A: And that's about all. Awesome. Yeah. We're very happy to have you. I understand your project is you're going to write a blog, and the past few weeks there's been a ton of information in workshops. So what's your strategy for taking in this massive amount of info? How do you plan to I have had to keep notes and look at the videos a lot. As I said, this is a lot of information after having not been involved in basically being a student in 50 years, as my project is called 73 and Web Three.
01:08:17.308 - 01:09:44.890, Speaker A: That is because I am 73. But I also have a slight problem in that I am also legally blind in the whole process. As I've told my helper, I've never done anything with writing any code or anything. And I am actually trying to learn how to do a little bit so that in the process of the blog, I can have a section about what is entailed in putting all this information together. Because I don't think that people my age who've never been involved in computer programming really have an idea of how it's set up. And then where is this going to go in the future? I think the idea of a decentralized web, which is secure, is a great place to have applications that have to do with storage for medical information and that is then safe and secure. Yeah, definitely a big problem or a big challenge, let's say.
01:09:44.890 - 01:10:55.980, Speaker A: I guess if you do end up putting together your outline, feel free to send it. To me or any of the ETH global team members, we'll be happy to kind of check it out and give you feedback on your draft as it goes through. Yeah, welcome to the community. I think we really do need to be reaching the whole world, and so I think it's great to have people telling the story that aren't necessarily nerds and geeks, just focus on the technology, and I think it is a really interesting time. The ideas behind the decentralized web, I think, have kind of been out for a while, and there's kind of a rich history there, and I think kind of the combination of that with Blockchains is kind of new. I think we need to somehow communicate to a broader audience the benefits to them. And so to the extent that we can do that and I think really applies both for private data and kind of for public coordination.
01:10:55.980 - 01:12:07.336, Speaker A: So like you said, with private data, whether it's medical records or other things that you have control over your own identity data and reputation, that that's something that hopefully, at some point, people realize is important and they can start wanting that as well as just how we coordinate resources and collaborating and trying to collaborate on being more effective as a society that having the neutral platform and foundation for our information systems can really help with that. So, yeah, thanks for diving in and working to tell the story. Okay. I'll keep trying. It's not easy. I've read back some of the initial information that came out on the IPF and everything was all speculative, and this is maybe what we're going to do. And I'm rather surprised at how much is actually the way it is going and being a secure form of working over the web.
01:12:07.336 - 01:12:42.116, Speaker A: Yeah, a lot of the folks on this call are really working to make that vision a reality. Imagine what it's going to be in another ten years. You guys are all going to be part of it too far. We can't think that far ahead. Well, do. Thank you. Yeah, I was just going to say, well, again, feel free to DM me with any draft that you have or anything that you're working on questions, because like I said, there's been quite a few workshops and a ton of content coming out of all this.
01:12:42.116 - 01:13:22.800, Speaker A: Thanks for sharing, though. I appreciate it. All right, it looks like we've got about 15 minutes left with this session, and I don't think anybody else has added their name to the sheet. If there's anybody else here in the session who would like to present and share what they've been working on to get feedback, we've still got a few wonderful experts with us. The textile team and Yanniv are hanging around for a few minutes more, so this is your chance to all right, I saw your your week two fingers. Yeah, go ahead. Kind of hidden with the background.
01:13:22.800 - 01:13:47.168, Speaker A: Yeah. No questions. We stopped by Juan's office hours and the textile guys have been helping out Cody. We're working on the Geoweb project I guess we did decide on. We're going to kind of have two demos. One which is more spatial in nature. It's going to be our land parcels will have the COVID policy and mask wearing policy for all the land as you move around.
01:13:47.168 - 01:14:31.830, Speaker A: So Cody's going to build a Apple Watch complication and a iPhone app. So as you walk up to a restaurant, you'll be able to quickly see, do I need a mask or not? Just kind of, I mean, small, easy, text based, just trying to keep it really simple there. And then Juan had some good feedback about trying to build some more desktop like demonstrations, be able to have the Google Earth view of our land parcels and people still be able to interact with information and link information that way. So no questions. Always open to feedback, though, and looking forward to week three. Cool. Awesome.
01:14:31.830 - 01:15:29.110, Speaker A: Anybody else? I think I saw Phil. Yeah, I've just come onto the call quite late so I could show a bit of what I'm doing. So I'm trying to do like a lyrics sharing application. So the idea is that you have a mobile phone and it would display the same lyrics across lots of mobile phones at the same time. And I'm trying to create ways that groups can share a database of songs. So I'm going to be using, I think, textile spaces for that. And then I've been using three box for the user stuff and I've just really been enjoying the three box stuff.
01:15:29.110 - 01:16:30.220, Speaker A: There's so much there that makes me there are applications I've thought about doing with decentralized web. And when I look into the three box stuff, it's like, oh, this does nearly everything I need to do for something I thought would take me like a year if I was going to do it. But it's just a bit of, I'm not doing this hackathon, but maybe the next one or something like that. And then I've gone into I've been taking notes. So I just joined hearing somebody sort of talking about doing blogs and things like that. I just started using Foam, which is a editor that you can run in Visual Studio, and it allows you to take notes in markdown and kind of link them all together. First time I've used it, but I found it to be hugely useful in hackfs, just because there's like 100 new things that I'm learning and that ability to actually have this graph of notes.
01:16:30.220 - 01:17:10.212, Speaker A: So, so far in my coding life, I've always had a notebook there and every day I'm starting a new page, but the notes are never connected together, so whatever's left at the end of one day is sort of discarded. Whereas this is now allowing me to kind of build a graph of knowledge and things like yeah, very cool. Yeah. You want to drop a link. If there is a link to it in the chat or in the Google Doc, I'm sure other people might find it useful. Are you affirming to roam? Yeah, so it's based on Roam and it basically runs in Visual Studio. So I've not used roam.
01:17:10.212 - 01:17:33.056, Speaker A: But it's inspired by Rome. And then it's quite nice because you get the kind of Visual Studio completions GitHub markdown and all. I don't know what you get in Rome because I've never used it modeled on that model. Okay. Yeah. Cool, cool. Do you want to talk at all about your project? Yeah, I can maybe like questions.
01:17:33.056 - 01:17:58.890, Speaker A: I can maybe show if I've got anything to if I do a screen share, I might be able to show some stuff that I've got. I'm sort of dropping in slightly unprepared. But hang on. Let's see. I've got 1000 Chrome windows open. Okay, I found something here. Okay, let me just bring up a screen share.
01:17:58.890 - 01:19:12.130, Speaker A: So, desktop, can you see a screen here? This is just me trying to sort out the network kind of stuff. So this is kind of three boxy things. So what I'm trying to do here is I've got a bunch of song databases and I want them to be editable by a group of people. And so what I'm using here is a space within three box. And this is allowing me to kind of add key value pairs in here. And what these key value pairs will be in the end is like a database ID and then a sort of private key for editing that database or something like that. And so that way, each database will have its own kind of, I guess, ethereum address as an ID or something like that.
01:19:12.130 - 01:20:08.044, Speaker A: And then that address will be shared between multiple users so that a subgroup of users can effectively have read write access and read access to a particular database. So that's me just adding keys in here. And this is the channels. So basically one of the things I'm trying to do is have it so that each user can have many channels, basically. And a channel is basically a group of users who are all listening to the same lyric stream. And I've been adapting three boxes, ghost threads. So the Ghost threads, with my lyric stuff, basically, you will send a song and then you'll send a series of updates.
01:20:08.044 - 01:20:49.032, Speaker A: And each update will be which verse you're looking at. So behind the scenes, it's using the IPFS Pub sub or Lib PTP Pub sub, which the Ghost threads kind of have. And the Ghost threads, they don't hit the disk anywhere. They only are in memory. And so when you connect, it gives you the last 20 messages and then it adds in other messages as they come in. And so that's kind of what I need for my application. So I've got an idea of, like, having keyframes and then delta frames.
01:20:49.032 - 01:22:03.516, Speaker A: And so a keyframe is when you send a new song and then the deltas are what come in is basically looking at verse one or looking at verse two or something like that. So you're not sending the whole my rendering thing basically needs to see the whole song so that it can decide how big to render the text. So you could use it for kind of slideshows and things like that, so that you could have the slide coming in in a big chunk and then lots of little chunks which are just like bullet points being revealed or something like that. Then I've been creating the kind of sharing mechanism for how you send these via URLs. I got a bit bogged down doing the three box stuff because the refresh was quite slow, because every time you reload the page, you sort of have to auth again, which means that it got quite cumbersome as I was trying to do the kind of making it look a bit better. So this is it kind of authenticating at the moment. It has to authenticate for each space that it opens.
01:22:03.516 - 01:22:38.524, Speaker A: So you can see it takes about 20 seconds at the moment for it to get hold of the data. And this is on a desktop. It's still not come in yet when I've refreshed at the moment here. So it sort of takes a while to authenticate. So I've been working through the kind of visual flow of things and so this is how it's going to look visually. Let's see. So if I go in here so I've just gone into code sandbox, which is good for sort of prototyping.
01:22:38.524 - 01:24:05.436, Speaker A: So I'm doing the UI in here. So the idea would be that you'd drop into the front page of the app. You've got a choice of using remote control or just dropping into an existing session, which you'd normally do by just receiving a link. I've got this kind of QR code page I've been doing, which this is the format of the links that you'll get, which basically has a question, Phil, who do you see this being useful to or what sort of users do you imagine this being built for? What do you have in mind? For me, I'd like to use it for outdoor kind of singing things like maybe carol singing or something like that. But also I can see it being used in general, outdoor things, basically, so anywhere that you wouldn't want to have things that you'd normally do with a projector and lyrics or something like that. But it allows you to do the whole thing in a mobile way rather than being indoors. So it's particularly kind of interesting with COVID because churches are not allowed in their buildings and they're not allowed to sing at the moment.
01:24:05.436 - 01:24:33.344, Speaker A: So it means that you can potentially be more widely spaced and those kind of things. Got you. Okay, I don't want to cut you off, but we don't want to get too deep into your code for this session. Yeah, you've got some stuff going on. It looks very interesting. I'm looking forward to poking around at it if you have a demo at some point. Yeah.
01:24:33.344 - 01:25:44.504, Speaker A: So what's really kind of exciting for me is that I've had a centralized version of this before, and now it always meant that if I was going to scale it, it wouldn't work because I'd end up paying so much for hosting and all these kind of things, or I'd have to take more responsibility than I want to. And by doing it P to P, it means that you can scale it big and have it free, which is what I want it to be. Any thoughts from our panel? It's a super cool app and I think that kind of like live Syncing could probably be useful for a lot of different types of apps. Like you're saying slideshows, things like that. What were you thinking about? Just kind of like advertising. I mean, I guess there's like if you have the QR code or you kind of send a link. Yeah, just kind of post the link and then do people discover it over a DHT eventually? I'd like to have it as being very private or a way of having it quite private.
01:25:44.504 - 01:26:42.876, Speaker A: Obviously with IPFS, it seems like you can probably pick up all the nodes which are and get all the IPS of people. Is that right? If it's lib P to P. So there's lots of countries where there's persecution for the church and things like that, where people are trying to find out who the Christians are and lock them up. And it would be nice to have something that was enabled a private group which would maybe be going down the whisper direction. But also the other thing is just like, yes, I do want it to spread and be used. And in terms of discovery, start off with email. There's a social sharing API which has just come into Chrome, which I'm using, and that means that you can bring up share buttons in Chrome, just sort of natively.
01:26:42.876 - 01:27:36.240, Speaker A: I'm not sure if I've got this on my phone at the moment, but see, we might have to save that for another time because we're going to have to wrap up shortly. Yeah, I was thinking in terms of sharing that you can have like an after event thing. So if people join the event through having seen a QR code, you can then send out a message to those people saying, do you want to be invited to the next thing, basically? And that way people who see it used outside can then start their own groups, basically. So that's the kind of cool. Yeah, really awesome app. All right, I think we can call it there. Thank you for presenting, Phil.
01:27:36.240 - 01:28:02.552, Speaker A: I can echo Yana there. Again, very cool. App. Let's see, there's a few last minute logistics things. Logistics I have to include, as you probably experienced this week was the first time we had a check in. So if you haven't done your check ins yet, please make sure to go into your hacker dashboard and complete that. We're going to be doing these every week until the hackathon is over and it's prerequisite for getting your stake back.
01:28:02.552 - 01:28:30.944, Speaker A: So we just want to make sure people are continuing to regularly make things and surfacing any issues that they have. Andrew or Carson, I know you guys released, you had some sort of release last week specifically for hackafest. Do you want to talk about that really quick for a few seconds? Yeah, sure. I mentioned it on our I don't recall, was our office hours recorded or not this week? I guess it wasn't. Yes, it was. Okay, cool. So you can go back to that too.
01:28:30.944 - 01:29:21.590, Speaker A: But just a real quick thing is we had two releases. One was any teams that are developing on the Powergate. If you are trying to run versions of your application against Testnet, we have a hosted instance of that that you can use. So you can actually see an announcement of those hosted instances on our blog and get details. Just add your information and we'll try to onboard teams to get access to that if you need it for your hack. The other thing was the buckets API. We have experimental version of that that is already connected to a Powergate so that you can create Buckets and then run Archive Endpoint, basically Archive commands on the Buckets and those will create deals on filecoin and so you can do that.
01:29:21.590 - 01:30:06.050, Speaker A: So all our production APIs and all our production documentation plus Bucket archiving commands, and that's available through a version of the Hub that we only have available for hackers called Hub Next. And I pinned on our support channel in Slack, I pinned the details about using that if you want to make use of that. Awesome. Perfect summary. If you're using any of the textile teams tools or products, you have got to go check that out because seems like a really powerful tool. All right, this is the end of week two. I hope everybody has been having a good time so far.
01:30:06.050 - 01:30:44.684, Speaker A: It's almost halfway through the hackathon that'll occur sometime next week, but time keeps moving and you all keep building, which is really awesome to see. And we're looking forward to the kickoff of week three on Monday. Again, there's going to be a bunch of office hours and a few more sessions workshops next week, so keep an eye out for that. We'll send an email either Sunday night or Monday with a list of all that. So thank you everybody, everybody, for sticking around and showing up. Really appreciate it, especially to Andrew and what he dropped out. Thank you again.
01:30:44.684 - 01:30:50.410, Speaker A: We'll see everybody in Slack next week. Cheers. Have a good weekend. See ya.

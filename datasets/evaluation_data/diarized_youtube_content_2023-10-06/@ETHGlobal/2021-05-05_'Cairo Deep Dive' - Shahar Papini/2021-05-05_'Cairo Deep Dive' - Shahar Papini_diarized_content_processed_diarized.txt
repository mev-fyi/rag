00:00:00.250 - 00:00:45.290, Speaker A: All right, so coming up next, we are having Shahar Papini from Starkware, who's co creator of Kero and one of the main engineers there. So this talk basically is from ASIC to CPU. It's a Stark journey and this will be a recorded video also because of time zone. So apologies for that. But the Starcore team is always super happy to answer any of your questions in the channels we have internally or on their own personal channel. So without further ado, we will be getting on with the video, just setting up the technical side.
00:00:45.360 - 00:01:42.270, Speaker B: Hello, I'm Shahabini, I'm an engineer at Stalker and the co creator of Cairo. Cairo is a language we developed to help other people use DK stocks. Today I'm going to talk to you about the ASIC to CPU journey which Starquare had regarding to developing stocks. So first I'll explain what I mean by ASIC to CPU. Explain this analogy. I'll then briefly explain how Starks work and how the protocol does what it does. I'll show the early stages we had while we developed Starks and the intermediate steps reaching to the so called Holy Grail, the universal machine written in Stark, which is Cairo.
00:01:42.270 - 00:02:20.300, Speaker B: And then I'll have some deeper dive into Cairo and look at its features and what's planned ahead. So let's begin. ASIC to CPU, asics are application specific integrated circuits. They're basically chips, they are specialized for the task. They are very fast, they're expensive and very hard to design for. CPUs on the other end are for general computation. They are a lot slower, they're cheaper and very easy to program for.
00:02:20.300 - 00:03:03.330, Speaker B: Software is a lot easier than hardware. CPUs are multipurpose single architecture. It's like a single, asics you can call it, that can run a lot of things, basically trade off between efficiency and flexibility. There are a few intermediate steps, I would say. At one end we have the Asics. FPJ is an architecture which is a bit more generic, easier to program for. It's still not as a flexible CPU.
00:03:03.330 - 00:03:35.410, Speaker B: We then have some GPU, which is a lot more flexible. And the other end we have CPU. So for each of these, I'll have an analogy in the Stark word. Obviously it's not a perfect analogy, just an analogy. So stocks. What is Stark? Stark is a family of cryptographic proof systems that can be used for both privacy and scalability. This basically lets you prove statements.
00:03:35.410 - 00:04:29.810, Speaker B: For example, for statements we can prove the thousand number in the Fibonacci sequence is some number x something. Another example statement can be I have 100 signed bank transactions, they're all signed correctly. And maybe after I apply them to some state and I get some specific other state, basically everything you can do a computation for, then you can make a statement of Stark. Statement Starkware. We focus currently on the scalability part of Starks, not on privacy. Starks can do both. But right now the most burning issue I would say is scalability on blockchain.
00:04:29.810 - 00:06:15.090, Speaker B: This is our focus now the verification time of Starks, that is, the time it takes to verify a proof someone made is exponentially smaller than time it took for the prover and for the length of the computation itself. So they are very well suited for scalability. So in bird's eye view, how does stock work? We have some statement we want to prove. First step is expressing it as polynomials. Basically we call this representation an error algebraic intermediate representation and I'll focus on this in just a moment after we have this error, we just throw it on a bunch of algorithms on Fry, LD, Merkel which comprise of this Tarp protocol and at the other end we get some proof. So how does this error look like? It basically comprises of a trace which is a table with some constant number of columns, let's say two. In this example, the number of rows is some power of two and each cell is a field element in a Stark friendly field we use some specific field with 250 bits, but any Stark friendly field would be okay here alongside this trace we have constraints that we want to prove that the trace holds.
00:06:15.090 - 00:07:36.814, Speaker B: Each constraints need to be some polynomial on some local area of trace. For example, here you can see this second constraint works on the x column at the current row, the y column at the next row. The repetition for these constraints needs to be a power of two. The number of constraints is proportional to the verification time. So we don't want a lot of constraints, we want their degree to be relatively small, otherwise it will be very expensive. And how can we use this to express statements? For example, if we took the Fibonacci statement we could have, let's say, thousand rows here 1024 could say that the first and second element are one and our constraint will be that x two equals x one plus x zero, which is exactly the Fibonacci statement. If we have these constraints throughout all the trace, then it will guarantee that if the first two cells are one one, then the thousand cell is the thousand Fibonacci number.
00:07:36.814 - 00:08:28.062, Speaker B: So in addition, we can also add some constraints that say this is one, this is one, and this last one is one, two, three something. Now that we have this representation, if we can show we have a trace that holds all the constraints, then we are done. The other person can be sure that the thousands number is indeed what we said. So let's start with the journey. At the first stage we had some very rough tools. We were basically building stocks from scratch. We need to design how the trace looks like, how many columns it has, what is the meaning of each trace cell in the Fibonacci example, it's pretty easy.
00:08:28.062 - 00:09:16.750, Speaker B: Each one is the ice fibonacci cell. But when you have very complex logics. You have to assign some cells to be, for example, the current balance of an account, the amount we want to transfer the signature, the public key, all kinds of things and need to represent the connections between them. These are the constraints we want. Constraints of low degree. If we need some constraints of high degree, we'll need to break it up using some more auxiliary trace cells. There is a lot of manual optimization work involved here, so it's kind of a puzzle sometimes to do this, but it's also very hard.
00:09:16.750 - 00:09:56.330, Speaker B: And doing complex logic is complex, it's not easy. I do want to state here that the main metrics we use to define how good an error is. It's first of all, the trace space, which is the number of trace cells. We need columns down type, number of rows. This affects both approval time and memory. And we also have the number of constraints which affects the verifier time in a linear fashion. So we don't want a lot of constraints.
00:09:56.330 - 00:10:21.810, Speaker B: The trace space also affects the verifier, but only logarithmic polylogarithmic is aware. It's not that important. So this was how we did things at the beginning. Then we started to develop some better tools. For example, one of them was our visualizer. We can see the bottom, how it looks like. This is basically the air.
00:10:21.810 - 00:11:00.800, Speaker B: You can see it's one with eleven columns and some rows each cell. You can see the constraint that work on it. We can add some visual features to these things, like output cells. Some things repeat in other periods. In addition to tools like the visualizer, it's also important to have some abstraction. The ability to not think of all the components in the entire air at once. But do some.
00:11:00.800 - 00:11:54.634, Speaker B: Like this part does hashes, this does signatures, this does amounts or state transition, things like that. So doing it on top of air requires some things about automatic placement on the trace and referring to some specific parts inside components. So we had some in house framework. To do all these things took a while. It really helped developing things, but it was still hard doing some complex logic. A lot easier, but very hard. A third step, which I call the GPU the previous step was like the FPGA equivalent.
00:11:54.634 - 00:12:43.362, Speaker B: The next step is actually something we didn't do, something we considered a lot doing and we had some designs for it. In the end, we chose to skip to the fourth step altogether. But I'll show it anyway and the issues there are in this step. So we could design some domain specific language that compiles to an error. It can look for example, this is an example code of this imaginary DSL you can call functions. You're going to have branches and force. There are multiple problems.
00:12:43.362 - 00:13:45.800, Speaker B: First of all, you always pay for branches. Basically, you need to unwrap all the possible flows into the trace. So each possible flow, each possible timestamp needs to have some specific cell in the trace. So you don't gain efficiency by doing branches. You pay trace sales for both the first branch and the second branch. Similar thing we can do, we can say for for loops or recursion it's not possible to do variable number of for loops you must always be bounded because you need to allocate specific trace space for it. You cannot really do recursion for the same reason you don't really know where in the trace you need to work right now.
00:13:45.800 - 00:14:29.714, Speaker B: You can only have things that have this constant flow pretty much. You also always pay for all the iterations. Even if you right now only need ten. You need to pay for all the power of two evasions. And if you sometimes you need only ten, sometimes twelve, then you will always pay the highest. So these are drawbacks we have here. Another drawback is there is no memory or it's very hard to implement memory in this thing.
00:14:29.714 - 00:16:04.100, Speaker B: It's obviously not complete. Another issue for Starks in this case is the way Starks I would say not scale but they are dynamic in the sense that if you have stock that works for thousand rows you can take the same stock and apply it on 2000 rows to have like twice the number of transactions. For example, if we make a stock that handles banked transactions you can put 100 in it, 200 you can use it even for thousands of transactions because it naturally repeats itself. Doing this repetition in this area is not very natural and if you need to do some complex logic it goes out of the window altogether. For example, if you need to do something at the end, for example doing some transactions and compressing at the end, the output or checking something at the end, then there is repetition goes out of the window. So we don't really want to give up that part of stock that they don't work on an instance of a single size but can work on instances of various sizes. This is something we want to keep.
00:16:04.100 - 00:17:04.338, Speaker B: Okay, so what we eventually ended up doing caro caro stands for CPU air, like regular CPU is basically an ASIC that can do general computation and so is Cairo is specific Air that can run a general computation. It's a universal machine turn complete. It's a funny machine. It has a random access memory. A nice feature is it only has a single Verifier because it's single error. So we can and we do we can put a single Verifier contract on Ethereum for example, and the entire world can use it to know some statements are true. In Cairo you don't have to deploy it every time for every project you use.
00:17:04.338 - 00:17:53.854, Speaker B: We can audit these contracts only once and therefore it will be more secure because we can invest more resources in this auditing. There are a lot of benefits, I would say, to having a single verifier. These are example of how Cairo looks like. So Cairo is actually two things. It's the error and the instructions it can run. We call the cairo virtual machine and we have some high language high language that works on top of it, which you can see here. We don't have the drawbacks we present before for the DSL.
00:17:53.854 - 00:19:25.890, Speaker B: We only pay for what we use because each repeating part in the error of cairo is just executing an instruction, single instruction. So if there is instruction within run another branch, it signs the trace. We can have complex non reparative logic, we can have recursion, we can have basically anything that a fun human machine could do. A nice thing we noticed is it's actually very efficient. When we took the Cairo version of Handwritten Air version when we tried to translate it to Cairo it was only about 20% to 30% more expensive. The main reason for that is a lot of applications and this one in particular uses a lot of some built in components in this case hashes and the verifications of signatures which are written in handwritten error but just all the logic on top of it is written in this virtual machine so we basically get the best of both worlds. The hard parts are optimized using head reader error components and we get the logic of a tune complete machine in a high level language.
00:19:25.890 - 00:20:52.442, Speaker B: So, yeah, it was all only about 20% to 30% more expensive. However, the expressibility of Cairo lets us do some more complex logical optimizations which we did and actually was a lot cheaper than the Handwritten version. For example, in the reddit demo we managed to do 300,000 transaction in a single proof lately we even did 600,000 and this is mainly due to this logic optimization that lets us save a lot of instructions and hashes so hey, it's better and cheaper, but more can we ask for? So some of the tooling we have for Kyro first of all, obviously we have the compiler and virtual machine and these are available today. You can check them out. Our site we have the Solidity Verifier which is deployed today on Robson and on Mainet. Basically everyone can use it. There is the sharp tool you can use so we can prove your statements.
00:20:52.442 - 00:21:25.350, Speaker B: Basically, I'll touch it later. We have integration with Ides, specifically Visual Studio code, which we use, and Vim, which some of us use. Language server. There is a tracer and a profiler not written here. It's similar to Debugger. You can see it up here. Basically, after you make a specific run, you can check it out and go through all the steps in your computation.
00:21:25.350 - 00:22:20.220, Speaker B: And we have the playground which you can use today in our site. Play around with Carol and how it looks like. It's very fun. I recommend okay, so important thing I want to touch is why we designed Carol the way we did. There are some things that may seem unnatural to common developers that come from common languages, which we did differently, mainly because we want Car to be efficient and we did it. So it will be very compatible with the Air architecture, I would say so. This is a comparison between physical CPUs and the Air CPU and why some things should be one way in this one and another way in this one.
00:22:20.220 - 00:23:04.738, Speaker B: So first of all, how we measure efficiency in physical CPUs. It's mostly the execution speed, how much time it took to run some computation. In Air, the main metric we use is number of trace cells. This leads to the fungi observation, whereas in physical CPUs adding more hardware on the chip can lead to better times like branch prediction and caching. In errors, it's not really equivalent when you add things. You add trace cells by definition. So we do not want to add trace cells.
00:23:04.738 - 00:24:00.450, Speaker B: We want to keep the architecture as simple as possible so we won't have a lot of trace cells. In CPUs, having multiple registers, it's relatively cheap. Adding some hardware and some links, it's usually okay. In errors it's a bit more expensive to have multiple registers, especially on the Verifier side, because every time we use a register we need to choose between all the registers. This chooser leads to a big constraint or multiple constraints which affect the Verifier side. We want our constraints to be simple so the Verifier won't work hard. The native word in CPUs is bits, 64 bits.
00:24:00.450 - 00:25:21.358, Speaker B: Usually it's a field element because that's how stocks work. Every cell in the trace is finite field element. This means that bitwise operations are easy in physical CPUs because they work with bits and they're hard in Air. So we don't have some opcode, for example, to do bitwise operations. We do plan to add some built in in the future, which will be a lot faster and do it manually in Cairo operations, but it will still be a lot more expensive than physical CPUs. A nice thing we have in Ers is non determinism, basically because it's a language for the Verifier, which means when I write a program I care that it holds some constraints and not necessarily that it's deterministic. For example, when I want to find some element in a big list in a physical CPU, I would have to go over every place in this list or in this array.
00:25:21.358 - 00:26:09.330, Speaker B: I have to go over one by one until I find my element or don't find it. In Air, it's a lot easier. With non terminism I can sort of guess the index where this element appears and I can just check that this is indeed the right element. Obviously, the proverb will have to do this linear work. The proverb still needs to go over the entire thing to prove, but once the proverb finds the right one, he can write just a few cover instructions that say oh, I guessed it's in the 500 place. I check, I read from it, I check it's. Okay? So the number of trace cells will be a lot smaller.
00:26:09.330 - 00:27:03.380, Speaker B: Memory Access in physical CPUs, memory access is usually a lot more expensive. You need to access things that are far from the CPU because the metric is execution speed. In Air, memory access is actually quite chip. I'd say it costs about five trace cells, even less three, and something if we have some optimizations, which is very cheap. So instead of using registers in Cairo, we use memory access. Every instruction has some memory accesses and we have a very minimal amount of registers. An important thing to note is the memory freeing thing.
00:27:03.380 - 00:27:40.446, Speaker B: In CPUs you want to free memory. If you don't, free memory takes up of the entire capacity of memory you have. When you free, you can add more. So it's very good to free memory in error. There is not a concept of freeing memory as everything you ever did in your program, in your run is in the trace. It must be on the trace because you need to prove that everything was consistent. After the entire run you have this big trace, has everything.
00:27:40.446 - 00:28:09.926, Speaker B: There is no point in freeing anything. That also means we don't need garbage collection, for example, which is very nice. You can access everything. In the past. Our memory is also immutable some mutable memory. You cannot change it again because that's basically how it works in Air. In Air, you at the end have this big table.
00:28:09.926 - 00:29:14.074, Speaker B: If you have a specific cylinder, has one value, at the end of the proof it has one value. We can simulate mutable memory on top of this, but it will be more expensive and it's not very necessary. There are a lot of languages today that have the immutable memory model, functional languages, for example, and we implement a lot of things in Cairo and it's not an issue almost at all. When it is, we have some constructs that you can use that act like read, write memory. Like I said, it's basically simulating read, write memory on top of this immutable memory, but mostly we don't need it. And it gives a very big efficiency bonus, I'd say. So, Cairo today we are using Cairo live on Mainet.
00:29:14.074 - 00:29:54.330, Speaker B: We use it both in Diversify, immutable and dYdX. This is a website for the Karl language. You can see all the developer tools and playground and documents. Everything you need to know is there. We have the Sharp, which is the shared prover services. It's available on Robson. You can send from the playground, for example, straight to Sharp or using our developer tools to check it out, basically runs on our provers and then the fact of your run is registered on chain.
00:29:54.330 - 00:30:30.982, Speaker B: We also have a few and obviously want more and to support community projects. For example, for compiling from higher level languages to Cairo. So we want it to be easier for developers to use Cairo. Cairo is efficient, it lets you do zero knowledge proofs. Sometimes you don't need all this efficiency sometimes you just want to compile from your favorite language. We want to enable that. The white paper of Cairo is coming soon.
00:30:30.982 - 00:31:49.550, Speaker B: Hopefully you would be able to see all the intrinsic of the Air and a virtual machine, how things work from the inside. And we're currently working on our StarkNet which is sort of a side chain which uses Ethereum for its consistency and the safety and every developer could just deploy his own Cairo contracts and run them and they will be proved on this chain and you can communicate with Ethereum with L1 hopefully to be seamlessly. So very easy. It's upcoming in the next few months so I hope you learned a bit about Cairo and why it's cool and why it's efficient and why you should use it. I'm Shahava Pini, you can email me, you can tweet, you can see my Twitter handle and if you have some questions I'll be very happy to answer. So thank you and goodbye.
00:31:52.940 - 00:32:01.750, Speaker A: Thank you to all the Star Court team and Shahar for this very informative video. It was a great talk.

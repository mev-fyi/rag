00:00:07.290 - 00:00:22.350, Speaker A: Next up, we're going to bring on our first demo for the day. We're going to bring on Georgia's from Paradigm to tell you all about RET and everything you can do in the world of rust and Foundry. So we'll give him a second to set up, but please give Georgia's a big round of applause.
00:00:25.450 - 00:01:01.342, Speaker B: Thank you all for coming. On the left side of the screen, we're seeing a ref node running right now in production on mainnet alongside a lighthouse node, tracking the tip by running Foundry cast block number on every block. You can see that Ether scan on the right is, of course, internet not going to work. Okay? So block 98, block 97. I will refresh 98 and we can keep doing that. And you will see that it tracks the tip just fine. So it's working.
00:01:01.342 - 00:01:31.994, Speaker B: And it's been a lot of work. And it's unbelievable, honestly, that it's working. So let's get into things. So we're building a new execution layer for Ethereum. In this talk, we're going to go over the motivation, the what, the when, the what's next, and a lot more. First things first, we don't hold anyone to how they should pronounce it. Pronounce it however you want.
00:01:31.994 - 00:02:01.582, Speaker B: I call it wrath. Others call it wreath. Like, one of my colleagues said that I would kill him if I heard him. Call it arith or something. Call it whatever you want, I don't care. Motivation, what when? The SDK, I don't know if we'll be able to get into it because we have limited time and want to respect the next speakers and the future. The Ethereum protocol over time is changing.
00:02:01.582 - 00:02:43.940, Speaker B: There's a lot more cryptography being vulnerable into it. There's a lot more systems, networking. You can see that this is Vitalik's roadmap from a while ago, but you get the idea. Ethereum is becoming a big, complex system that we need to understand and we need to be very principled about. Ethereum also requires client diversity. It requires a healthy set of participants in both the consensus and both the execution layer, such that if a critical issue happens, the network does not finalize a conflicting checkpoint. If it happened, it would be catastrophic and it would be not here next year and would like to avoid that.
00:02:43.940 - 00:03:31.226, Speaker B: An Ethereum client is a piece of software that is a piece of software that usually you would expect that you can run it as a node, but it also is used in various other applications. Examples include indexers block, Explorers, layer twos, mev infrastructure and so much more. But the reality is that the clients are always remixed. I think the Internet is a bit slow, or things aren't loading, by the way, or I don't know why. Anyway, I'll just keep going. Becoming a Core developer is hard. It requires a lot of mental overhead.
00:03:31.226 - 00:03:53.190, Speaker B: It requires learning a lot of things about an entire system. It has a lot of edge cases. It has legacy code, which, again, no shade on the people. We've been building this system for like five, six, seven years. Obviously there will be legacy code, and obviously the abstractions are not going to be clean from the get go. And that's why people reimplement stuff. And the only thing I know how to do well is to reimplement.
00:03:53.190 - 00:04:42.440, Speaker B: So we went back to the drawing board and we're like, okay, let's do something. And also here's some more data points on the motivation. Performance is all we do at Paradigm and in our open source teams. Some people here use foundry, some don't. Again, we will not hold any grudges, but performance in the whole ecosystem is kind of embarrassing and we need to do better. So we went to the drawing board and we thought, okay, why don't we build a node? How crazy can we get? How hard could it be? Let's build bigger, harder things. And we also took it from the foundry angle, which we saw, that worked and got loved so much, which was build things that are like, for the ecosystem, for people to build, for people to have a tight feedback loop, to be able to chat about it and feel like we're building something together.
00:04:42.440 - 00:05:05.600, Speaker B: And also we want to give back to Ethereum. It's given me a job. It's given everyone here a job. Like, we got to do something for it. And I strongly relate to that very much. So, building Node breath is an Apache MIT licensed execution layer. It's an archive node with best in class performance characteristic, which we'll get to in a second.
00:05:05.600 - 00:05:33.698, Speaker B: And the main thing I wanted to talk about in this slide is the culture of the team. Because the culture is what makes its way into the code. And the process that we use for developing our software is inclusive. Mentorship. First. No task is small enough to be broken down into smaller pieces for a lower level contributor to take it on. We pick up people from their pre Rust journey.
00:05:33.698 - 00:05:57.854, Speaker B: I will abuse them until they start learning Rust. And then afterwards they will get in our repositories. They will open an issue, a pull request. Like, our team will come in and mentor. It's a beautiful thing. We have a very high bar, but we expect that people that will put in the work and that they will be rewarded. People get hired from our code bases and our chat rooms, and not by Paradigm only.
00:05:57.854 - 00:06:18.226, Speaker B: Although we do try to hire the best talent out of our code base and out of our repositories. But like, even competitors, and that's okay. The pie is big enough. The thing that we do a lot is that we're like feedback first. There is no room for egos. There is no room for your product is not good. Oh, I'm feeling bad.
00:06:18.226 - 00:06:41.546, Speaker B: You have to tell us the way it is. Because if you don't tell us the way it is, who is going to tell it to us the way it is. We're going to be screwed if we don't have customer feedback. So if anything sucks, please come find us. Swear at us, throw tomatoes at us, I don't know. But get an issue open after you do all of that. And we also don't do calls as much as we can.
00:06:41.546 - 00:07:07.798, Speaker B: We do some the bare minimum, but we try to keep it async first. We try to keep it written precise and no time wasted. Like we work around the clock, we work across main time zones. We're not going to spend time on taking up locks on people's calendars. I have an IP address here, which is the address that you saw running the node in the beginning. Feel free to connect to it. Hit it as hard as you can.
00:07:07.798 - 00:07:39.982, Speaker B: We'll see what happens. There's a grafana board that you can use. All of these are running on the alpha four release which came out last Monday. And just to do a quick summary of the so what paradigm funded the core team of eight, including me. We built it since October, I believe the repository has over 100 open source contributors in this time. Foundry at this point has like 250 ish. I think it has incredible performance, which I'll talk about in a second.
00:07:39.982 - 00:08:21.770, Speaker B: It's feature complete up to Shanghai and we're starting cancun very soon look how to be ready for devnets by end of August, maybe early September. Has most of ethereum JSON RPC and has the two very powerful tracing APIs that people want to use for node infrastructure for tracing for mev and whatnot. And the last part that I take a set of libraries which I don't think I'll have to talk time to talk about, unfortunately. Yeah. Yikes. Contributors? 135 as of yesterday. Two K stars and 300 and 8359 pull requests in the last 30 days with eight people.
00:08:21.770 - 00:08:50.198, Speaker B: How does this happen? You tell me. Like we have a big open source community of people that want to be working with us and we work with them. So if you're a rust developer, work with us and we will do the best, our best to make this happen proper. Okay? We'll work with it. It's enough. I think this chart is a latency chart, so lower is better. This is latency for ETH call on ref and it's unfortunate that we're not able to see it.
00:08:50.198 - 00:09:34.098, Speaker B: But the lower it outperformed like ten x plus or more like in some cases 100 compared to other RPC nodes. We're still making that better. I acknowledge that we're not able to do that already for every RPC call. There's no reason why we won't be able to do it now. So we want to get better at that throughput when you have a system that is able to saturate its load fully, the chart that you would expect to see is a y equals x chart, a linear one that says request in, request out. The node that we're comparing ourselves to around like the 8000 request per second, it starts to break down. On the top of the screen we can see the time and the database size.
00:09:34.098 - 00:10:06.874, Speaker B: The time to sync an archive node from Genesis on bare metal hardware on rate zero and VME disks on two disks that are rate zeroed together at block 17.4 million, which is around as of a month ago. Breath outperforms anything in the market significantly. And it's something that we're extremely proud about. We have more work to do on it. We're not done the database size. We leverage the Arigon design, which means that we're in same rough ballpark with some small content improvements.
00:10:06.874 - 00:10:46.614, Speaker B: Like I don't think the 300gb matter here you're over two terabytes, the next one is four terabytes, the next one is eight and so on. So it's kind of like the same thing but for geth and nevermind, for example, for archive node again, it's not tractable right. How did this load and the previous one didn't? Okay, nice. We built the two charts that you saw earlier. These ones were created with this tool. This is a load testing tool that we built specifically for ref. And now we maintain to develop high performance, high quality, data driven benchmarks for RPC nodes.
00:10:46.614 - 00:11:18.050, Speaker B: I think the Ethereum ecosystem is a bit embarrassingly non scientific, honestly. And here we're trying to take a bit of scientific approach with very clear measurements at the J curve inflection point of the throughput latency graph buzwords. But if you care about performance, you understand what I mean. There is no secret. We do profiling, we use flame graphs, we try to close every feedback loop. We are not like geniuses. What we do is that we know where to measure.
00:11:18.050 - 00:11:47.354, Speaker B: As an engineer, you look at a wide flame graph that is very red and you keep staring at it until you figure out how to make it less wide, less red. Repeat the code will become fast. It's not rocket science. We also use the Ergon architecture, which as I said, is a breakthrough innovation. And big shout out to the team. We use Revm, which is an EVM built in Rust to be high performance. It's the same EVM that foundry uses.
00:11:47.354 - 00:12:18.934, Speaker B: And of course we use the Rust programming language for its performance and safety guarantees. One underrated thing about the Rust programming language is that it's inclusive and inclusivity makes its way into the code after you have started like programming for a few weeks. Yes, it does have a slightly higher barrier to entry. But once you're past that, you can onboard to any code base the most advanced code bases in days. Not weeks, not months. andered me, I don't have time to get into this defense in depth approach. We know how to do security.
00:12:18.934 - 00:12:39.146, Speaker B: I was an auditor in my earlier days. We work with the best security people on the planet. We know how to do security. We hope to do this better. We want to audit it. We don't have the capacity to run a full on fledged audit, so please don't do sales to me. If you want to audit it and you want to put it on your client list, it's free, open source.
00:12:39.146 - 00:13:26.718, Speaker B: We're happy to work with you. We're not going to be able to do something big here, unfortunately, but we hope that the ecosystem is excited to keep this secured. Hopefully, the action items for the group is run a node. I'm not able to run 1000 nodes because I don't have 1000 different pieces of hardware. The main thing that we need to understand how good the node is, is how well, how much is the variance of performance across different hardware types. As you see at the bottom, the disk is king, and we have a GitHub gist here, which explains various performance characteristics of disks and their time to sync their I ops and so on. So we want more work on that.
00:13:26.718 - 00:13:46.440, Speaker B: We will support every platform that we can. And if you want to run a node, don't come meet me after. But please go join the telegram room and we will happily handhold you. I will personally handhold you online if I need to, if I have time. Do we have some time? No. Again, thank you.

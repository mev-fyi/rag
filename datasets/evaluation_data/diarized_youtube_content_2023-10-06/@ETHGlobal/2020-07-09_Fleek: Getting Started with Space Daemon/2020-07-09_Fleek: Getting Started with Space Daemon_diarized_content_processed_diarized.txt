00:00:04.250 - 00:00:05.520, Speaker A: Excited to be here.
00:00:06.610 - 00:00:07.760, Speaker B: Good to hear.
00:00:10.930 - 00:00:11.680, Speaker C: Okay.
00:00:15.650 - 00:00:18.400, Speaker B: I'm going to keep you muted, Rickson. That's okay.
00:00:23.010 - 00:00:27.750, Speaker C: We're up on Twitter and standby for YouTube.
00:00:28.570 - 00:01:00.750, Speaker B: Okay, we're up. Awesome. Welcome, everybody, to the first session on Thursday for Hackfs. Today we have a couple members of the Fleet team who are going to be going over the prizes for hackfs as well as teaching you a little bit about how to use their code in your Hack FS project. So we're very excited to have Bret, Janison, and Guillermo with us today. Huge thanks for them making time and sharing ins and outs of how to use fleek. So we're very excited.
00:01:00.750 - 00:01:44.480, Speaker B: Today is the last day for Staking. Please remember to stake, if you haven't already, for Hack FS. We'll be pruning the channels starting tomorrow morning, so you want to make sure to do that if you plan on participating for the next 30 days. Again, there are a couple more events later today. Check the schedule channel, and you may have received a calendar invite to a few of them if you're interested in learning about some of the sponsors. And we have at least one other sponsor talk with Pinata and then a few office hours. So if you want to get a little deeper with some of the other sponsors, check the calendar, check the Schedule channel, and you'll be able to learn from all of them.
00:01:44.480 - 00:02:13.186, Speaker B: All right, before I hand it over to Bret and the rest of the fleek team, we're going to do a quick show and tell. There's no game this time. Let's see. Everybody can let's see what the game is. Show me a book you have on your desk. Nobody can win this one, but I hope people have books nearby and then just show it. Turn your camera.
00:02:13.186 - 00:02:34.160, Speaker B: Let's see what people are reading. Oh, it's not going to show. There we go. Learning Mandarin Chinese. Andrew, what did you have? Polestoy. Oh, good book. Steal this book.
00:02:34.160 - 00:02:49.854, Speaker B: I'm realizing that the screen share is cutting out a lot of these book titles so I can't read them. All right, throw them in the chat, and that's the end of the game. Hope you all enjoyed. Bret, you want to take it away and tell us about fleek?
00:02:49.982 - 00:03:21.898, Speaker D: Yeah. Awesome. Thanks, Trent. Really excited for this workshop. We are definitely involved and been building on the IPFS ecosystem, so this hackathon is really exciting to see Fleet get some more usage, to see some feedback today, hopefully we'll have some fun. We're going to do a live code along with the space daemon, the fleek space daemon that we just kind of recently released. We've talked about it a bit.
00:03:21.898 - 00:04:08.650, Speaker D: We just touched up our documentation around it, so that's really nice and clean, and hopefully it's easy to follow along and it makes it easy to build peer to peer, privacy focused apps. So we'll definitely get into that. Dive into details there. Yeah, but to start off. So my name is Bret Shearer, I'm co founder and COO of Fleek. We have Janison Sivaraja who is co founder and CTO, who will be doing the code along, and also Guillermo who is one of the engineers on the Fleek team who'll be doing the code along. So I'll kick it off just by sharing my screen and talking a little bit about an overview and the different products of Fleek.
00:04:08.650 - 00:05:12.186, Speaker D: I'll share my desktop. So yeah, this is going to be the Space Damon workshop, but before we get into that, I'm going to just kind of give a bit of an overview and I'll actually show off a couple of the products that we have out, the hosting and the storage, but at a higher level. Fleek is a modern web development tool for building sites and apps on IPFS. We have the hosting product which is like a really easy one, two, three click to get front end or website hosted on IPFS. We've pride ourselves in having really good user experience, easy to use interfaces, we have the fleet storage that is for easily uploading. So we'll dive into that and then the Space Damon. Yeah, I mean, part of what we do is we build on top of IPFS.
00:05:12.186 - 00:06:39.930, Speaker D: We build on top of textile and just different IPFS tools, encryption tools, et cetera, to bring privacy, to bring peer to peer technology, to bring just like the benefits of IPFS, of web3, to end users, to developers with a really good user experience. So that's why we put a lot of care and attention into the UI, the experience on the Fleek co website and app. And so, yeah, you'll see some of that right here. I'll quickly give an overview of Fleek hosting and then I'll actually show you a quick walkthrough of like juan brought this up in a couple of his talks in the beginning, in his intro as well, where it's really like the best option, the easiest way to host your Cider app on few kind of just connect your GitHub, your git provider and then Fleek will detect the framework you're using, whether it's like Gatsby or whatever static site Hugo or React app, et cetera. And then once you deploy it's on PFS and then all future commits to that git provider, GitHub, et cetera, will be automatically deployed. That's kind of how it's like a hosting solution that's really easy to use. We also make it really performant.
00:06:39.930 - 00:07:43.342, Speaker D: So performance is really important. It has a built on CDN and that will speed up the fetching of the website when it doesn't. In the case that maybe it's not moving fast enough on IPFS in some cases, but that's just augmented in front of it to make sure it's always as performant as any site could be. So yeah, just to quickly cover the prize on that, we are giving out $100 just to ten teams that we picked that are using the hosting product. So it's a really easy one to take advantage of. And if you have a good novel idea or something you're working on to just host the site or the front end of an app or web app that you're building on IPFS via Fleek. So I'll show off the actual product real quick.
00:07:43.342 - 00:08:17.398, Speaker D: So once you get in for Fleek hosting, this is actually our Fleek. We use Fleek for all of our apps and sites. So our Docs, our homepage, our blog, everything is hosted on fleek. Our own app is hosted on Fleek as well. So it's pretty meta. I'm on an app, it's called Fleek that's hosted on fleek right now. So, yeah, here's like a bunch of sites we have that we host, but it's really just to show you how simple it is to get off the ground and deploy sites.
00:08:17.398 - 00:09:11.574, Speaker D: So you just three quick steps connect with GitHub, I'll select my repo, and then you just pick whatever repo you want to deploy. This one, I think this one here is just like a gatsby blog, my personal gatsby blog. So once I click that one, it automatically detects it's a gatsby site and it'll fill in all the build settings for you. Here you can see we support a bunch of different ones. Even if it's not listed here, it's supported and we'll just read the package JSON for you. So chances are it'll just be auto filled for you anyways, something that's pretty cool, worth noting that besides web Three, even in kind of Web Two hosting CI CD tools, this is a differentiator Is. We actually have like docker image input here, so we're auto filling it for you depending on what we detect.
00:09:11.574 - 00:10:13.534, Speaker D: And you don't need to have one, but you can actually create a custom docker image and put it in yourself. And you can have extremely custom sort of build settings. But yeah, so then you just click deploy and from here you'll just kind of watch it deploy and it'll go through the logs and at the end of this process, it uploads it to IPFS and you get back a hash or CID and then we publish it onto a DNS for you. So I'll just show off our blog that we have here's a bunch of deploys. We put out a new blog last night. So like the end, it'll give you back this hash and it'll update DNS, or it'll create a DNS if it's the first time and then point it to your domain. So from here you can just click and preview it.
00:10:13.534 - 00:10:54.202, Speaker D: In this case, we've already added a custom domain. You can do all that stuff over here. You can add custom domains. We have ENS support, so you can add ENS to it as well really easily. It's a super simple process. We support a bunch of different wallets. And basically the cool thing about this is that we take advantage of the controller role that ENS provides to keep the user in full control, but to make it a really good experience where all future deploys automatically update the CID, the IPFS hash on future deployments of there's a bunch of cool features in here.
00:10:54.202 - 00:11:53.114, Speaker D: I can go through all these mean you can change stuff, you can enable preview, deploys deploy previews is something we released recently. So basically if you create a PR on that repo, you can preview that deployment without actually having to merge it, which is also deployed in IPFS and yeah, some other stuff there too. So I'll let you guys play around with that and check it out. I guess at this point I'd be happy to take any questions that are coming in on hosting. Maybe I'll pause there if there's any questions. Are we seeing any do you include React and react native? We do include React, like create react app. Oh, for the space daemon itself? Yeah, react native, for sure.
00:11:53.114 - 00:12:41.966, Speaker D: So the space daemon itself will cover it works for native apps for the hosting. It's for web apps, for front end react apps. Can find the framework? Yeah. Okay, Elm, we're adding native support for a bunch of different frameworks. Elm is one we'll have to do that for, but yeah, if you choose other, the input will show empty, potentially. Or if like in your package JSON, you have the build settings, it'll actually detect it. And if we don't know the framework, it'll just fill in the build settings and say other as the framework, even though it'll still fill in the build settings for you.
00:12:41.966 - 00:13:53.430, Speaker D: If it's empty, then yeah, I mean, maybe it's not clear in the package JSON or we didn't detect it properly. Can you mention how the CDN works? Yeah, so the CDN is we actually use Cloudflare as a CDN, so the CDN is on the domain that you add. So these subdomains that we automatically create when you deploy like these kind of random names onfleet Co, like Frostyglittery, five, four, three onfleet and you can always change the name of the site as well. But yeah, basically the CDN is on the domain itself, so the subdomain is pointing to the IPFS hash and then it'll cache the CDN because it's pointing to the subdomain. And then any custom domains you add will also be added onto the CDN. And we have free SSL certs as well. So we use let's encrypt for SSL certs to generate them and put them on the domains.
00:13:53.430 - 00:14:22.814, Speaker D: Cool. So that's the hosting. If there's more questions around that, definitely just ask and then let's go back over to the next thing. So $100 just to ten teams that use that. I mean, it's pretty easy to use. Hopefully if you have any issues, you can always contact us in the fleek channel. We also have our own Slack and our Know.
00:14:22.814 - 00:14:28.450, Speaker D: We've intercom messaging inside of the app. If you run into any problems, just ping us. We're really quick to respond.
00:14:29.030 - 00:14:29.394, Speaker C: Okay.
00:14:29.432 - 00:15:06.154, Speaker D: And then the other product that we have is fleek storage. So this is a really easy way and performant way to store files in IPFS, any file. So whatever file it is, technically IPFS supports actually any file. So it's pretty awesome, super easy to use. We have the web app UI, which I'll show you. We also have the fleek storage JS, which is like a library that makes all the methods programmatically. So I'll show you that real quick, but like via Tech Docs and then yeah, it's really performant.
00:15:06.154 - 00:16:04.874, Speaker D: So the same concept where we publish files. So behind the scenes we're actually using an S three type interface called Minio. When we upload it to IPFS, it kind of has this sort of bucket type of structure. So we're creating a bucket and it's kind of like an augmented bucket on IPFS, where the bucket actually has a hash, the folders, you can have folders within it and files within folders. So that entire structure is completely on IPFS and all have hashes, and those buckets are published to DNS. So you have a URL that you can reference those files. And that URL is augmented with a CDN built in, has image compression and resizing.
00:16:04.874 - 00:16:38.074, Speaker D: So it's just like all this kind of built in really fast tools that just come kind of really packaged and easy to use. So I'll show that super quick as well. Just go over here to the storage page. We have some uploaded here. We use it for all the images for our blogs and stuff. We put it in like a bucket and then reference it via URL to make the builds much lighter. So you click upload, I'll just grab any given file here, drag it in there.
00:16:38.074 - 00:17:19.020, Speaker D: You can drag folders and then click upload, click Confirm, and it's kind of just going through the process, uploading it. So once it's uploaded, you'll show up right here in the UI. So here it is. And this is kind of like a whole management UI to see all the files and manage them. So I can open up this specific file, I can open up the URL with it. So here it is on this fleek bucket. And I can use that URL to reference it within my app.
00:17:19.020 - 00:17:49.634, Speaker D: So yeah, it's a whole management UI. And then we also have just to show you something that's pretty cool is everything is completely on IPFS. So this bucket, I can verify this is on IPFS, right? And what it does is looking up the hash of the bucket on a gateway. Any folder I open also has a hash. I don't know if I have a folder on here. Any individual file is going to have its own hash. So it's pretty cool.
00:17:49.634 - 00:18:07.480, Speaker D: It took a pretty good amount of work to make it where the whole folder structure and bucket structure could be completely an IPFS, but still, super might even if you know what IPFS is, you might not even realize it's just all on it, and it's really quick.
00:18:09.870 - 00:18:10.186, Speaker C: Yeah.
00:18:10.208 - 00:18:46.790, Speaker D: And then I'll just quickly show off our docs here. You can come over here to the storage, and we have the fleek storage JS. So the storage JS, this is just a library with kind of all the different methods, programmatically easy to use. This explains how to do it. Yeah. So get upload is like pin list get file So this is like you can just give a hash and get back the file. Whether or not you store it through fleek or not, it'll just get it from our gateway.
00:18:46.790 - 00:19:38.038, Speaker D: So, yeah, you can come over here, check us out. If you have any questions, definitely let us know. And to reiterate $100 to ten teams to use, that so very easy thing to use. Definitely worth just giving it, putting it something on there and getting a feel for it. All right, so I'll check if there's any questions on that chat. Do videos on fleek stores support streaming? I think so, yeah. Just like a video, like a live stream or just like yeah, if you upload a video, you can definitely play the video and stream it 100%.
00:19:38.038 - 00:20:14.960, Speaker D: Yeah, if that's what you mean, as a database for apps. So database wise, it's just for storing files, but if you actually want schema and store reference as a database, that's where you yeah, no, it's not meant for that. So Textile has something really cool. Like, you can use Textile as a database, for sure. And then our Space Daemon is something more along those lines. It's not really a database. It's just like a bunch of methods that you might use for building an app.
00:20:15.810 - 00:20:30.534, Speaker A: It does come with a Textile built into it. So even if you're not using the Space File APIs, once you run the daemon, you have a built in textile Node with its gRPC exposed, so you could start using that for your database needs.
00:20:30.732 - 00:20:38.694, Speaker D: Oh, cool. Yeah. Sorry. Good point. Yeah. So the Space daemon has a Textile Node built into it. It's, like, packaged up.
00:20:38.694 - 00:20:55.518, Speaker D: So when you download the daemon, it comes with the Textile Node, and so you can use that as a database. What is your encryption story with hosting an IPFS bucket, et cetera, for that?
00:20:55.684 - 00:21:39.062, Speaker A: For the public hosting, they're not encrypted because they're on IPFS, and they're meant for websites that can consume them. So it wasn't a private store. We have plans to change that. But then where we're doing private by default first is on the space side, where the use case is more around your own personal files and selectively sharing with other people. So on that side, on the Space Statement side, things are encrypted by default. It's built on the encryption that Textile is doing for their buckets. To answer that question, for the public site hosting and sites application because they're meant for public sites and viewing.
00:21:39.062 - 00:21:40.570, Speaker A: They're not encrypted.
00:21:43.490 - 00:22:48.562, Speaker D: Yeah. Can the keys for encrypted buckets be shared manually, or is that purely handled through the API calls? So we'll get into the space daemon and you'll learn a ton about that. You can absolutely have encrypted buckets by default on the space. Damon and those can be shared via API, via API calls. We have sharing methods that make it easy to share selectively or within a team, et cetera. Is it possible to change the ownership of the file through fleek ownership of the file? So I guess ownership of the file is an interesting concept. Who actually owns the file? So if you upload a file, you have the file, I guess you sort of own it.
00:22:48.562 - 00:23:42.498, Speaker D: But I don't know, it sounds like interesting use case for adding in some smart contracts, referencing a smart contract for an encrypted IPFS file, and whoever has a contract can maybe decrypt it. We do have some cool use cases with the space daemon where if you have it encrypted, there's ways you could have a sharing URL. And one of the things we're trying to encourage is if you can put the decryption in the sharing URL, which I think we might have already, well, Janice will talk about it. So that could be like ownership of the contract can actually be able to potentially decrypt the file itself. I wouldn't say through the storage, though. It sounds like the ownership is a tricky topic. Okay, so that's good for that.
00:23:42.498 - 00:24:28.454, Speaker D: Now onto the part where we'll get into the tutorial really soon. So the space damage, just to give a little bit of background, there's a JS client at its core. I'll just skip over here. At its core, the space daemon is a go daemon that packages together IPS node, a textile node, so textile threads and buckets. And we'll powergate that's kind of like Astrid, because we're working on the filecoin integration right now in this current Sprint in one installed daemon. So we've made it really easy to install this daemon. So you can check in the tech talks.
00:24:28.454 - 00:25:33.714, Speaker D: We'll show you today how quick it is. And once you install, you kind of have all that packaged in. So the actual daemon itself has a bunch of gRPC methods if you wanted to interact with it directly. But we also created a JavaScript client that just exposes the methods way easier without having to host your own gRPC client and all those methods for us in our own app, we're currently building an app on top of Space Damon that is coming out TBD, but we're actually using the JS client ourselves. It made it easier for us to bundle it up and deploy it. It's much easier to use for our front end developer, for the front end developers in the team, as well as the deployments. Part of the space daemon you get is it has a bunch of file commands that interact with encryption.
00:25:33.714 - 00:26:44.190, Speaker D: So adding files, deleting files, adding folders, even like a bunch of different kind of crud commands that come with encryption already built in. So if we come over to the docs super quick, you'll see we have getting started and we'll walk through this today. It has like a bunch of different kind of crud operations, just expose these files. We have sharing commands, so like a bunch of sharing stuff where all these different kind of different ways you want to share files or buckets within a team or selectively with another person or kind of whatever type of sharing arrangement that you want to do. These are just like kind of out of the box that we'll walk through today. It also comes with identity service packaged in it's, completely open source. So the identity service has currently right now, username and emails.
00:26:44.190 - 00:27:31.098, Speaker D: But we're going to add a bunch everything here we're talking about like the whole space dame itself is completely open source. So we'll continue to add more kind of services if it makes sense, add more onto the services. It's open to contribute. If there's a better way to do anything, we always take approach that's completely private, completely peer to peer decentralized, but gives the best experience possible. But we also want to make it pluggable. If anyone has better ideas, if anyone has things to contribute, we're happy to plug and play. And that kind of brings to one of the points over here where we want it to be like an ecosystem where it can have more extendable types of features.
00:27:31.098 - 00:28:27.274, Speaker D: So maybe it's not just maybe actually video conference. You could do some sort of zoom type thing on top of this, right? We can do not just files, not just file sharing, but other types of interactions where we think can be built on top of this. And other maybe better ways to do identity or better ways to do different pieces that we've created. We're excited about that. At its core, it's really like this kind of this data repository that's completely user controlled, right? So when you use the space daemon, it has the keys for users that upload data. They have their own keys, they have the ability to control that data themselves. And it's completely private because it's all encrypted.
00:28:27.274 - 00:29:55.530, Speaker D: And we think that an app ecosystem makes a lot of sense around this. So one really interesting thing is think about if this is basically a database that lives on the user's computer, that's completely local and encrypted and you can have any user data that's associated with apps could even be stored there. So we definitely want to see a lot of things around that evolve where users interacting with apps have their app data even stored locally on their machine and they don't have to kind of give up their data to different applications. We also think that once you have this space daemon on your machine and you have a desktop app that's using it, or it's just installed locally, then it becomes a way for your entire machine to interact with textile, with IPFS. So this becomes something that other apps can plug into. So understanding what apps you're running that are interacting, that need to interact with your local store, your local IPFS node, it also can even enable web browser applications that are completely peer to peer, because if you're running it locally, it can create that experience around even web apps as well. Not just like desktop apps or mobile apps.
00:29:55.530 - 00:30:55.198, Speaker D: So, yeah, I'll just quickly cover the prize around. This is we're doing $3,000 for the first place team. Some cool ideas just before we hop in is a paid to decrypt file app encrypted image sharing where the keys in the URL are something we mentioned, like being able to share a URL where they could decrypt it, the actual file itself. Decentralized file sharing is an obvious one. It's every single method you would need to do that. And then this is one of the ones I kind of mentioned with user controlled app data, where you can imagine basically creating an example app and then showing a user interacting with it and saying, all right, everything I do on this app is going to point to a local directory and store all my data here and then create some sort of interface where the app can actually interact or use the data without having to store it. Which would be really cool.
00:30:55.198 - 00:31:47.262, Speaker D: And I think there's a lot of even more interesting ways that could be monetized where the user can get paid for letting the app use their data. Maybe there's a smart contract involved that pays them out, something like that. It's pretty endless. I think a lot of the ideas work for this. I would base kind of building on it a bit on all the methods we have available that you could do, but also anything you do to extend the daemon or to improve it or add more functionality also counts. So if you don't see something here and you make a pull request to the Damon and it adds something, that's also awesome too. So without further ado from there, it's coding time, so I will stop sharing my screen.
00:31:47.262 - 00:32:06.310, Speaker D: Maybe I'll just check if there's any quick questions. Hope the computer doesn't crash or they don't lose their wallet. Seed keys associated with user email. Can we get recovery key or something? Is there Janice you want to answer?
00:32:06.380 - 00:32:33.550, Speaker A: Yeah, so that we're still working on right now, but as part of the identity service Brett pointed out, we're going to add a recovery option so you can give an email, get an email or a passphrase backup that you could then restore on another machine. And that's part of the identity service. We have Daniel on the call also, who is building that piece. So I don't know if there's anything to add there, but that's in a nutshell.
00:32:38.770 - 00:32:50.180, Speaker D: Yeah, I think Daniel commented on it. All right, so I'll hand it off to Guillermo to go to the next step.
00:32:51.670 - 00:33:22.240, Speaker C: Okay. Hi guys, my name is Guillermo. I'm a front end developer here at Flick. And now I'm going to show you a little bit more about the space demon. How you can style a demon and how you can use it, how you can interact using the client and of course all directly from the code. So I'm going to share my screen. Okay? Can you see my screen?
00:33:23.330 - 00:33:24.080, Speaker D: Yeah.
00:33:24.610 - 00:34:17.438, Speaker C: Cool. Okay, so first thing first, as Bret mentioned, right here we have the documentation, docs, Flick co, and on the space demon section, you will find all the information related and required if you want to implement this demon. Also you will find information related with the client, the JavaScript client library, and of course all the different methods that you can use or you can implement. Also you will find an examples. So you can go directly to the repo and run some examples with the demon and the space clay. So the first thing that I'm going to show you is how you can install the demon on your machines. So it's pretty easy.
00:34:17.438 - 00:35:07.050, Speaker C: You just need to go to the latest release right here and at the end of the list you will find different binary versions for different operating systems. So you just need to download the version that you need for your operating system and that's it. I already downloaded the binary, so I got it just here and I'm going to show you how you can run the demon. So I got my demon right here. So the first thing that I need to do is change the permissions in order to be able to execute the file. So just a ch mode, that's it. And now I'm able to execute the binary.
00:35:07.050 - 00:35:50.220, Speaker C: So you can execute the binary just as any other binary file. There is nothing new with this super important. The first time that you execute the binary, you will receive this warning. Of course, if you are running OSX operating system, so you just need to click console, go to your system preference, security and privacy and click Allow anyway. So after that you can come back and try to run the demon again. This time you will receive a different message. So you just need to click open and that's it.
00:35:50.220 - 00:36:39.190, Speaker C: You will see a bunch of different logs. This is the important one. If you receive this load, you are ready to start working with the demon. And also you have some other important logs right here that are related with the ports where the demon is exposing the different methods that you can use. In this case that we are going to use is this port, the 998, which where it's running the gRPC web proxy, the space client. Is based on gRPC web. So that's the reason why the space demon runs and expose this gRPC Web proxy.
00:36:39.190 - 00:37:22.140, Speaker C: And that gives you the ability to don't worry about to call gRPC method or integrate something related with gRPC. You just need to download the client, the library client and interact using normal JavaScript functions. So it's pretty simple to use. And I'm going to show you how you can install the client and how you can interact with the demon using this library. So right here I got a tiny project. It's just create react application running with electron on a desktop application. So I'm going to run this example.
00:37:22.140 - 00:37:36.618, Speaker C: There is just a basic setup. There is nothing special with this. Just a simpler react application. Plus electron.
00:37:36.714 - 00:37:38.190, Speaker B: Is that in the repo?
00:37:38.850 - 00:38:23.610, Speaker C: That app, yeah, there is a repo. I can share you later on the chat. But yeah, if you go to the different Flick repos, you will find this example. And also there is another example right inside the Flick library, the Flick client. So, yeah, you can use whatever of those two. Okay, so, yeah, here's the example. I'm going to show you just a few basic operations that you can perform on the client, like create a new bucket or list a directory or open a file inside the bucket.
00:38:23.610 - 00:39:02.940, Speaker C: So let's get started. First thing is, of course, install the client. You can find the client here in NPM. The package is called Flick Spaceclient and you can install it as any other normal package, just Jar. Or you can even use NPM if you want Flick. I'm going to copy and paste this one and that's it. So let's wait for the installation finish.
00:39:02.940 - 00:39:56.620, Speaker C: Okay, that's it. So you have to run your demon on the background. So after that you can start interacting with it. So first thing is of course import the client and add in a few configurations and then you are ready to start using it. So right here I had a folder from a client and as you can see, it's super easy to set up the client. You just need to import them, create a new instance of the client and pass in the URL where the gRPC Web proxy, it's running. So in this case, as we saw before, it's running on this port, 99, 98.
00:39:56.620 - 00:40:49.640, Speaker C: And I'm pointing to my local machine. So that's it. The client gives you a lot of different methods that you can call and perform different actions on the Demon site. So as you can see, you have for example, you are able to add items, you are able to create a bucket to create folders, list the buckets, list directories, et cetera. So I'm going to show you a few of those methods. So the first one is going to be well, I'm going to run the example again. Oh, let's wait.
00:40:49.640 - 00:41:22.346, Speaker C: Let it okay. That's it. Okay. So I'm going to open the developer tools to show you the outputs on the console. So the first thing how you can create a bucket inside using the demon and the client. So right here I had the different components that are here and for the create bucket decode it's right here. So it's super simple.
00:41:22.346 - 00:41:53.538, Speaker C: You just need to import the client. This is the same client that I created before. And once you get your client, you just need to call the method that you need in order to create a bucket. In this case, I'm just adding an unsubmit handler for this form. And right here is the code that you need to create a new bucket. The create bucket just need the slug of the bucket. So basically the name of the bucket that you want to create.
00:41:53.538 - 00:42:52.674, Speaker C: And as you can see, this method returns a promise. So you can use Async await syntax. So it's much more beautiful. You can write with this, then you will receive the response from the space demon and that response expose a method where you can use to get the bucket information. This method the get bucket. So basically it gives you the bucket object and this bucket has a lot of different methods that you can call to get more information about the bucket that you just created. So for example, you can retrieve the name of the bucket that you already passed it out to this function, but you also can get the path of that bucket, you can get the key of the bucket, et cetera.
00:42:52.674 - 00:43:37.000, Speaker C: Also you got a little bit more of information related with the bucket. So what I'm doing right here is just using this helper function that the only thing that it does is it takes the bucket object and use the different getter functions in order to get different properties and just return a simple JavaScript object just to log in a simple object. And so you can see the information related with the bucket. So I'm going to create a new bucket. So here is the bucket that I already created. So as you can see, you have the key, the name, path, et cetera. A lot of different information.
00:43:37.000 - 00:44:16.130, Speaker C: Okay, we already created a bucket. So probably the next thing that you wanted to do is probably create a folder or folders or different directories on your bucket to organize your file. In this case, it's super similar. Actually it's pretty similar to the previous call. You just need to import the client and call the method Create folder. In this case, you need to pass an object with two properties. The first one is the bucket, which is the name of the bucket where you want to create the new folder.
00:44:16.130 - 00:45:24.786, Speaker C: As you can know, you can create multiple buckets so you can interact with different bucket using the same function. So that's why you need to pass the bucket name and also you need to pass the path. The path is the directory on your bucket where you want to create the folder plus the name of the new folder. So for example, if I want to create, let's say that I have a soup folder called just Soup inside of my bucket and I wanted to create a new folder called new Folder that is going to be the path for create a new folder. In the case that the soup directory doesn't exist, what the demon is going to do is just recreate the path that you are passing as a property. So you can for example, create multiple nested folders using this same method. Okay, again, this function returns a promise.
00:45:24.786 - 00:46:05.860, Speaker C: So you can use a single weight syntax and let's create a new folder but right on the root directory. So I'm going to call it Soup folder. Okay, the folder was created. Okay, so I created my bucket, I created a soup folder and next thing probably you need to do it list the directories so you can see what do you have inside of your bucket. So in this case you just need to pass the bucket name where you want to interact with and also the path that you want to list. In this case the soup folder. And I'm going to show you the code for this one.
00:46:05.860 - 00:46:50.094, Speaker C: So list directory, okay, pretty similar. You just need to import the client and call to the function that delisted directories. In this case, you have two different methods that you can use. I'm going to show you those methods. Okay, so you have the list directories and the list directory. The difference is like the list directories. Just need the bucket that you want to list and the function is going to return all the files that are inside of your bucket even if there are soup folders or files inside soup folders.
00:46:50.094 - 00:47:34.130, Speaker C: So you're going to receive all the files on your bucket. The difference with the list directory is that the list directory just returns the files and folders of the path that you are passing as an argument. So for example, if I just wanted to list my soup folder, this method is going to return just the files and folders that are inside of this folder. So in this case, that's the method that I'm using. So I should be able to see what it's inside of my subfolder. So I'm going to call that method. Seems like I receive an error.
00:47:34.130 - 00:48:05.260, Speaker C: Okay, that's it. So here I got the files that are inside of my subfolder. As you can see, there is a default file called Keep. This file is created by default when you create a new folder. So that's why you will see this file when you list the directory for the first time. So yeah, that's it. Next thing how you can upload files to the bucket or to the new folder for example.
00:48:05.260 - 00:48:45.570, Speaker C: Okay, so in this case I'm going to show you the code for the upload files, same thing. You just need to import the client and call the method needed to add items. In this case, we're going to call the add items. But as you can see, this method, it's not returning a promise. In this case, it returns a readable stream. And it's just like any normal readable stream. You can read the documentation on the node JS docs so you can listen for the different events on that stream and output the results.
00:48:45.570 - 00:49:24.420, Speaker C: So this method, what it needs is just an object with these three properties. The first one is the bucket where you want to upload the files. The second one is the target path, which is the path on your bucket where you want to upload your files. And the third one is the source path. The source path are the paths on your machine of the files or folders that you want to upload. So it's an array. So you, for example, can point to different folders on your machine or different files on different locations and upload all those files in just one call.
00:49:24.420 - 00:50:15.400, Speaker C: In this example, I'm just going to upload one single file. So I'm going to just call the test, use my test bucket and the target path. I'm going to upload the files to the folder that I already created, the subfolder, and the path of the file that I'm going to upload. I'm going to find a file, okay, so I'm going to come back it okay. So I'm going to upload this one. So I need the path of that file. So it's located right here.
00:50:15.400 - 00:51:29.174, Speaker C: So I got the pattern. So I just need to add the name of the file which is key TXT, key TXT and that's it. So I'm going to upload the file and here I got a response from the demo. As the response from the method is a readable stream, you can subscribe to the data event and you will receive an event for each of the files that you are uploading. So this item results, which is the response that you receive, gives you information about the file that you already uploaded. So for example, you can get information about if there was an error, for example, uploading the file. Or you can get another information like where is located now the file that you already uploaded on your bucket get the bucket path or even you can get the information from where you uploaded your file on your machine.
00:51:29.174 - 00:52:01.302, Speaker C: So in this case, that is what I'm doing. I'm just printing out the source on my machine of the file that I already uploaded. And that's what you see here. Okay, so last thing probably is how you can open a file that is on your bucket. As you remember, all the files are uploaded to IPFS encrypted. So you can just use your files directly. You need to decrypt that files first.
00:52:01.302 - 00:53:05.690, Speaker C: So that is what the open files method does it just take your file, decrypt that file, and put it into a temporal folder on your machine so you can interact with it as any other normal file. So the Open file is right here. You just need to call the client, call the method Open File, and you just need to pass the bucket name, where is the file that you want to open and the path of the file inside of your bucket, what you want to open. So, for example, in this case, I'm going to list my directories again, and I'm going to try to open the file that I already uploaded. So that's it. Here I got my two files, and I wanted to open this one. So I just need to pass the bucket, which is test and also the path.
00:53:05.690 - 00:53:50.090, Speaker C: So I click Open File and the demon returns the location on my machine where it's located, this temporal file decrypted. So I can take that path and open that file, for example, or see what is inside of the file, for example. Copy of that. Going to copy again. That's it. So there is the content of my file. So I can open file as well using this same path.
00:53:50.090 - 00:54:29.720, Speaker C: And here I got my file. So, yeah, that's it. Basically the basic operations that you can perform using the client. Now Janison is going to tell you a little bit more about how you can share your packet and explain a little bit more about difference method that we have available for you guys. So I'm going to stop my screen, share screen. Okay.
00:54:34.280 - 00:54:38.644, Speaker A: Hey, guys, I'm going to share my screen now. You can hear me fine, right?
00:54:38.842 - 00:54:39.612, Speaker C: Yeah.
00:54:39.786 - 00:54:40.510, Speaker A: Awesome.
00:54:42.320 - 00:54:43.070, Speaker C: So.
00:54:51.680 - 00:54:55.776, Speaker A: All right, can you also see my screen now? And it's on the Doc page?
00:54:55.878 - 00:54:56.528, Speaker D: Yeah.
00:54:56.694 - 00:55:32.692, Speaker A: Okay, awesome. So just kind of starting from there. The thing around sharing is these items are in the reverse order. So right now, what's implemented is sharing a bucket and joining a bucket. And what that means is there's an interface on the daemon that you can hit and you get back the information. So when you call the Share Bucket, you specify the bucket you want to share, and what you get back is the payload you need for someone else to join it. And then likewise, the Join Bucket is basically taking that payload.
00:55:32.692 - 00:56:08.164, Speaker A: Let's say you message that on Slack or email or to someone else, they could take that payload and then put that into Join Bucket, and it'll join that same bucket. Obviously, that's kind of a lower level sharing functionality. What would be ideal is, okay, share it directly by email or even in the app. Like when someone else is using the app, there should be a way to kind of push that invite so that pops up in the app and it adds them to that bucket. So sharing by email or by identity and doing the in app messaging, that stuff is in the works. The first layer was getting the share sharing. That basics down.
00:56:08.164 - 00:56:44.540, Speaker A: And that's kind of what we've been focusing on and got. So that's what I'm going to show today. The other ones are not implemented yet, but now that we're done the base sharing layer, there's some improvements we have to make at that as well, which I'll talk about. But then also add these other more app or user friendly sharing methods. So that's kind of the skinny on the different sharing, why you see multiple ones here and what they mean. On that note, what I have here is I have the daemon. So, first of all, I'm on an EC two instance on AWS.
00:56:44.540 - 00:57:31.970, Speaker A: So you could see that up here at the top. So why I'm doing that is because I'm kind of simulating someone on a machine, starting a bucket and adding folder to it. And then me on my local machine, I'm going to join that. So I'm on this EC Two instance because it's an EC Two instance and I can't run the GUI for the desktop app. What I did was I created little script inside the repo that Gammo was showing around using the client. So what I'm doing simply here is one. Well, because I'm in a node JS environment, we need to drop this in because the underlying gRPC libraries require that.
00:57:31.970 - 00:57:51.156, Speaker A: And this stuff is in the README. Then I'm pulling in the client. I'm cheating a little here and working off the same directory as the example. So I'm not pulling the NPM package. I'm just kind of pulling it in locally. And I'm simply a few simple steps. I'm creating a bucket.
00:57:51.156 - 00:58:26.370, Speaker A: I just kind of called it bucket to share with the timestamp. So every time I run this, it generates a new one, creating that bucket, just logging the results to the console. Then I'm creating a folder within that just called test folder A. And then finally, well, I'm also printing that just to make sure it worked. And then last but not least, I'm sharing it. And you can see that the only piece required for the sharing is the bucket name. And then the console will print that out.
00:58:26.370 - 00:59:05.970, Speaker A: Also, I was copying and pasting this. So that's why you see like four try catches here. It's probably cleaner to have it all together or depending on kind of how you want to handle it. But that's the summary of what this file is, simply doing that basic operation and then the sharing. So what I could do then is run this. I'm using Babel node because I want all the nice JavaScript syntax and I can just run that. And then the daemon on the EC Two instance is running here on the right side.
00:59:05.970 - 00:59:37.784, Speaker A: So I'll just go ahead and run that and we'll see on the logs as it goes through the different pieces there. It's creating a bucket. Okay, so this looks like it's going to time out. Okay. I was hoping it wouldn't do that, but one thing we're trying to fix right now is I'm going to run this again. Okay. So this is maybe a good opportunity to talk about how the sharing is working behind the scenes, show you why I'm getting that error, which I'm hoping I don't get on the next run.
00:59:37.784 - 01:00:28.376, Speaker A: But anyways, when you share a bucket, your machine has a thread running locally, and that is just on your own machine. And when you share it, it generates these addresses. So why are there three addresses? Is because when you run the thread on your local machine, it's listening on all these ports, which is like your local host, your private IP, because there's EC two instance. There's a private IP and there's a public IP. So the idea is if you could share that whole payload to someone else, and then they could join. And what the joining does is it will try each of these. It'll try to do it locally first, and then it'll try to do your public IP and where the Hub comes in.
01:00:28.376 - 01:01:20.152, Speaker A: So then they have the concept of a textile Hub, which is meant for when if okay, that one worked. So I got through that timeout issue. So where I was going with that is the hub acts like a third party replicator backup relay engine. Really? Because even though I generated the invite link here, and it has my public IP, and let's say I had a static public IP that someone can actually reach if my machine happened to be turned off or I'm not running the daemon when they go and try to join that, it won't work because I'm not online. So there's a fallback on the joining side which goes, okay, first I try the local one. If that doesn't work, then I'm going to try joining that same Hub sorry, joining that same thread on the Hub. And that's where it eventually falls back to.
01:01:20.152 - 01:01:56.644, Speaker A: And with that, the way textile has done it, it's great because you don't have to give your textile keys to the Hub in order to replicate. There's two different keys. There's like a service key and actual thread key where you could read and write content to. So the Hub only needs a service key. You can think of it just as it's enough to get the data and replicate it and let other people consume it. But without the read write key, you can't actually see it, and that's what you're sharing here to the user with that. So just to kind of move forward on this demo, you saw that last run.
01:01:56.644 - 01:02:15.848, Speaker A: It didn't give that error. We're working hard to fix that error. Like the textile hub. Node, for example. It's like a lot of network I O traffic going on it. There's about three megabits per second, input and output on the network side nonstop. And then we're using a somewhat small instance for the hub.
01:02:15.848 - 01:02:52.420, Speaker A: That's where I think some of these timeouts are coming from. So we're exploring that. And then also on the gRPC side, both server and client, if there's some tweaking we need to do to make this not timeout. So that's kind of something we're working on right now as we make this more stable. Having said all that, I'm going to take this information now and join it. So now I can just going to copy this into my notepad that you can't see and this bucket to share, nine, six, seven, ending in nine seven. That's the one I'm going to join.
01:02:52.420 - 01:03:34.708, Speaker A: So now I can go to my local machine. So here I'm running another instance of the daemon, but this time it's on my local machine here. And since I'm running it locally, I can leverage the UI that Guerrero has created and try joining it. So if you remember it was bucket to share, ending in nine, six, seven. And just before I join it, if I go and try to list the directory, for example, it's going to say the bucket is not found. But since I have the invite information, I could start popping that in. There's a bucket name there, there's the key.
01:03:34.708 - 01:04:12.624, Speaker A: And then you want to paste in the addresses as well. And what it will do is it will try each of those addresses and then finally fall back to the hub. So now it's joined. So now if I go back and list that same bucket, I could see the folder that was created on here. When it ran through my script, it created a bucket. Then it created a test folder A and then shared it. So now that's what I'm seeing here.
01:04:12.624 - 01:04:57.170, Speaker A: And then now you can kind of do whatever you want on this bucket. Now that you're part of it, you could share it with other people and add stuff to it, like a folder B. And we're working closely with textile on more fine grained access controls. So whether that's read or write or admin those things, we're going to separate out into different access controls and corresponding keys. But that's a work in progress as well. That concludes my demo. There's any other questions regarding the sharing? I could take it.
01:04:58.420 - 01:05:01.904, Speaker D: Yeah, there's a few questions in the chat. You see them.
01:05:02.102 - 01:05:02.850, Speaker C: Nice.
01:05:03.540 - 01:05:11.940, Speaker D: First couple from Thomas, from Jay Rush. Will the user in my app need to be running Space Damon in a terminal window?
01:05:12.280 - 01:05:42.552, Speaker A: No, absolutely not. So the way we're doing it, it goes to the packaging. So right now, because we're in heavy development, that might be the case. But like Bret said, we're building our own app that's going to use the daemon. And the idea is that app should check for the daemon and if it's not there, install it, run it behind the scenes and continue. So it shouldn't be something that the end user is doing. Think of it as a dropbox system tray or even MetaMask.
01:05:42.552 - 01:06:09.770, Speaker A: When you're using MetaMask and you go to a website, they check if you have MetaMask there, and if it's there, then they use it. If it's not, then maybe they'll fall back to another wallet or do something else. It's a similar thing here. So it's in the packaging of the app. And I think it's kind of like if we work towards a standard like that, where any app built on space daemon checks if the daemon is there, and if it doesn't, then installs it and runs it, then that'll be a common pattern that could be used across the board.
01:06:12.540 - 01:06:14.490, Speaker B: That's not implemented yet.
01:06:16.300 - 01:06:40.860, Speaker A: Well, it's mostly implemented in our app, but it's not like a standalone library or something. Maybe that's something we could add to this example, or like our client library that will let you do that piece as well. So I think maybe that's something we could do. It's implemented in our app, but it's not like a standalone library.
01:06:40.940 - 01:06:41.890, Speaker B: Okay, thanks.
01:06:44.020 - 01:06:45.280, Speaker A: The hashes.
01:06:47.140 - 01:06:49.104, Speaker D: Sorry, what did you say?
01:06:49.222 - 01:07:12.636, Speaker A: Yeah, I was just going to move on to the hash question. The reason is because these are like version one CIDs and not version zero. So the QM comes with version zero hashes and textcel uses version one and later. And I think that's what eventually people will slowly move towards as well. And that's why the hashes look different and the encoding is different as well.
01:07:12.738 - 01:07:14.190, Speaker C: Thank you. Thanks.
01:07:15.040 - 01:07:57.032, Speaker A: But there's a nice utility. Maybe I'll share the link after this. But there's a nice site by IPFS that you could paste in, like any CID, and it shows you kind of a breakdown of what encoding it is, what hash function it is, et cetera, and what version. Moving along, I would like to upload my react app to fleek. How could I use daemon as a service? Is it necessary to have the client on my machine? I guess the first thing that comes to mind is to deploy a react app. The best way would be through the sites and not the space daemon. Yeah, the daemon as a service.
01:07:57.032 - 01:08:38.944, Speaker A: That's a good point. Right now, it's local only because the main thing is it's using files. So if you want to upload a file on your machine, you can point to it, and then the daemon will have it locally so it'll work. But as soon as you take that daemon, put it on another server, and sure, you could open the port of the daemon and connect to it remotely, but then the files paths don't mean the same thing anymore. Because when you're using the client, you're talking about paths on your local machine, but then daemon's going to try to process that path as if it existed on the server. But that's not done yet, and we have talked about it internally to try to give that interoperability. So if you wanted to run it in a hosted environment that's remote.
01:08:38.944 - 01:09:13.230, Speaker A: You can maybe instead pass like an upload a file that you pass in the whole stream into it, set up the path, and then the daemon will handle it. So that's something that's on our radar, but it's not possible right now. The goal is to have powergate in there. It's not in there right now. Like Bret said, the filecoin stuff is in progress. But the idea is just like it's running a textile node, that it would have powergate built in and we'd expose everything that powergate has. So you could hit it when you're running the daemon as well.
01:09:14.640 - 01:09:26.050, Speaker D: Yeah, we're working on in the current Sprint. So hopefully while people are still ideating or getting things going, that we can announce that it's in there and it's usable really soon.
01:09:30.840 - 01:10:18.384, Speaker A: And do we have access to textile user orgs keys, encryption methods, et cetera? It's a bit of both. Like right now you could use the hub and do things like users and orgs and have access to that. But the keys and encryption that's also like a lot of it is built in. So the keys actually used for the encryption is built in. But they have a context layer that you can specify keys that are on the machine or the user's keys as a way to access control those inner keys. And I have to see if those inner ones are exposed as well. Maybe they are, but I haven't worked kind of on exposing that.
01:10:18.384 - 01:10:54.350, Speaker A: We've just kind of let it do its thing and we haven't brought those keys out or used our own key at that level. But we do use keys from a user identity perspective. So you need that key to open the context to use the textile. And if you use a different key, it won't work. But there's still kind of like that two layer of keys there. One is like our user identifying key, and then there's keys inside textile that that first key will have access to. And I think it would be useful to expose the inner keys and be able to supply your own.
01:10:54.350 - 01:11:03.360, Speaker A: I have to check if textile enables that first of all. And if they do, then we could expose that all the way up to our API eventually.
01:11:07.300 - 01:11:28.250, Speaker B: Hey, everybody. Hopefully we got to all the questions, but unfortunately we're going to have to wrap this session because we got to prep for our next one at twelve. As always, you can catch the Fleek team in their channel. If there's any final last things the team wants to say, just to wrap this up, please go ahead and do that.
01:11:30.940 - 01:11:39.132, Speaker D: This is what I'm going to do is I'm going to copy the questions from the chat and I'm going to throw them in our fleet channel and we'll answer them one by one in there.
01:11:39.266 - 01:11:39.950, Speaker B: Perfect.
01:11:40.480 - 01:11:52.832, Speaker D: And I'll tag you guys that ask the questions. So. We can continue the combo there. Thanks so much for coming. I'm glad we got through a bunch of coding and get them out of the questions. We'll get to the rest of them. Definitely.
01:11:52.832 - 01:12:08.960, Speaker D: Use the fleek products, use hosting, use storage, use Damon. We have plenty of prizes. Our whole team is in the slack. We're ready to answer any questions you have. We love to help you, even ideate, all the way from ideation to execution. We'll be online. We'll be working hard right alongside you.
01:12:08.960 - 01:12:12.890, Speaker D: So thanks so much for joining it.
01:12:13.900 - 01:12:28.740, Speaker B: Thank you again for coming on and doing all these demos for people. It'll be really helpful. All right, we'll see everybody in Slack, and if you're joining the pinata session in 15 minutes, we'll see you there. Bye.

00:00:50.570 - 00:05:35.838, Speaker A: Sam. WA. Sam. Sam. We ram. Sam. Sam.
00:05:35.838 - 00:12:09.110, Speaker A: Sam. Sam. Sam ram. Sam. Sam. Sam. Sam.
00:12:09.110 - 00:13:24.250, Speaker A: Dam. Sam. Sam.
00:13:37.930 - 00:13:43.430, Speaker B: Hear me okay? Yeah, I think yeah, we're.
00:13:45.880 - 00:13:46.448, Speaker C: Think we're.
00:13:46.464 - 00:14:20.466, Speaker B: A few minutes over time, so we'll get started shortly once people are ready. Thanks, everyone, for coming in. All right, wait till the last few people take a seat and then we'll get started. All right, coming in, coming in. I think we've got to talk straight after this, so we'll try and get started. So thanks, everyone, if you want to take a seat and then we'll be good to go. All right, as you probably guessed, I'm not sure where the noise is coming from.
00:14:20.466 - 00:14:22.900, Speaker B: I think it's coming from out there, but yeah, let's just begin.
00:14:23.670 - 00:14:24.674, Speaker D: All right.
00:14:24.872 - 00:15:06.446, Speaker B: Yeah. So my name is James, and we are Wax. We're a team within the Privacy and Scaling Explorations Group in the Ethereum Foundation. And yeah, our focus is well, PSE's focus is enhancing ethereum through cryptographic research, and we are one of the teams who is exploring a scaling solution. So the privacy and scaling exploration does a lot of things around privacy, but yeah, our focus initially was on scaling. So in today's talk, we'll be talking over the BLS signature aggregation, which is where we began. We'll be talking about user operation compression and reducing costs with that, additional verifications that we'll be exploring in our V two and also integrations and how we can make that easier for everyone to integrate and use.
00:15:06.446 - 00:15:41.946, Speaker B: And then we'll conclude with the summary. So let's begin with BLS signature aggregation. So the problem we're trying to solve is the roll up cost problem. So we all know layer twos are cheaper, but we can actually get more savings by doing something called signature aggregation. For every transaction on a layer two, you've got the transaction data as well as the signature data that gets rolled up to layer one, and that's the significant cost. With BLS signature Aggregation, we use a different signature scheme that lets us combine every transaction signature into one. So instead of having, say, 200 transactions with 200 signatures being rolled up, only one signature needs to be rolled up.
00:15:41.946 - 00:16:29.130, Speaker B: So the cost reduction is quite large for the signatures. And this is possible because rather than use the protocol's ECDSA signature scheme, we're using a different signature scheme which needs to be verified on chain. And for that we need a smart contract wallet. So lots of in at once. But basically the way I sort of visualize BLS signature aggregation is that you'll have many unique transactions sorry, many individual signatures, but they can be combined together or aggregated into one, basically the space of one, but still give you the ability to verify that all of the individual transactions were signed by the corresponding public keys. So again, it's just a nice thing mathematically that BLS does that I don't understand, but we just get to use it from the outside which is quite nice. So we want to make that easier for others to use and benefit from.
00:16:29.130 - 00:16:42.320, Speaker B: Under the hood, it's something like this. Each private key signs a message, so you use the corresponding public key to verify all against the single signature. But we don't need to worry too much about that.
00:16:43.250 - 00:16:43.882, Speaker D: Overall.
00:16:43.946 - 00:17:25.390, Speaker B: The way we can make that work is that within the wallet we'll need something that can sign with the BLS scheme, and that's a client module on the left. That'll then send the signed user operation, as we're calling it, to an aggregator, which will combine many different user operations and BLS signatures into one, and then submit that on the right to the smart contracts on a layer two, which is our verification gateway. And BLS wallets. That's sort of just the pieces, broad brushstroke, but when we zoom in a little bit, this is what it looks like. Adapt will propose a user operation. Now this terminology that we're using is four three seven terminology or account abstraction, as you've probably heard of. And so the user operation can consist of multiple actions.
00:17:25.390 - 00:17:43.586, Speaker B: The DAP proposes that to the user's wallet. The wallet will then sign that user operation. And many wallets in parallel are obviously signing different transactions. Those get combined together or aggregated via the aggregation server. But also there's additional compression that we do to again reduce the size of.
00:17:43.608 - 00:17:44.610, Speaker A: What gets rolled up.
00:17:44.680 - 00:18:19.194, Speaker B: So in the end, basically the essence of this is we're trying to reduce the data that will get rolled up. We'll talk more about compression after with that bundle of operations and the single aggregated signature. We then make the call to the smart contracts. That bridge across to the contracts is what we want to reduce. So now that it's small, we've passed the gap, we've had our savings, we now need to expand it again to fully verify it. So we have the expansion done on chain as well as the verification done. Once we have all those user operations verified, we can then get each smart contract wallet to call its corresponding DAP.
00:18:19.194 - 00:18:37.460, Speaker B: So that's sort of the end to end flow. But with the smart contract wallet, we have to do things on chain that would normally be handled by the protocol, like the nonce and gas. So those are additional parameters. Now we have to send that we didn't have to send before. So let's look at how we can do some compression to save that.
00:18:42.110 - 00:19:09.358, Speaker E: Thank you, James. So yeah, I'm Andrew and let's talk about user op compression. So I want to give some context. Zooming out. You know, I'm talking about compression, so let's talk about the actual bytes that we have to work with. So this is what a vanilla transaction looks like to just send some ETH. And about roughly the second half of this transaction data is your signature.
00:19:09.358 - 00:20:00.318, Speaker E: So you might imagine when we switch to using BLS signatures that the effect of that is going to be something like removing the second half of these bytes. However, the reality is a little bit more complicated than that. And so instead of going from 120 down to 60 by doing that, if you just call our gateway directly in order to process your operation, your transaction data is going to look like this instead. But we can fix this problem with compression. There's quite a bit to do, and then we can realize the benefits of those BLS signatures and also take it a step further and apply that compression in other ways as well for additional savings. So zooming in a little bit, because I don't expect anybody to just understand a big blob of bytes like that. This is the same bytes as the previous slide.
00:20:00.318 - 00:20:45.150, Speaker E: All of the examples, by the way, here are like properly encoded transactions, and a couple of them are posted on Chain as well. And there'll be QR codes for viewing those on the Block Explorer here is just pointing out the bits and pieces that are in there. I'm drawing your attention to the signature that is on this slide. This is part of the transaction envelope that's around that orange data section. So we're using BLS signatures and a different system and all that. But in order to actually get this data on Chain, we still need an EOA transaction, which means that there's still an ECDSA signature involved here. And so that becomes part of the data that's shared between all of the user operations that we bundled together inside of this orange data section.
00:20:45.150 - 00:21:13.930, Speaker E: So let's continue zooming in and have a look at what's inside of those bytes. So this is them. So this is the solidity abi to specify what's going on. And so we just have that little east transfer in there. And so it's represented by those red bytes. The ones that are in black are shared bytes, and we compress those as well. But it's mainly about these red bytes, which is currently sitting at 640 at the moment.
00:21:13.930 - 00:21:53.320, Speaker E: And so those bytes, the compression that we can apply to those, how small we can get, that determines the long term cost performance of this model. So 640 is a lot, but we can also reduce that by a lot, as you'll see. Some of you may be familiar with this tweet from Vitalik last year. We've been inspired by this and also from the Hubble project and also other sources. So I won't go into this in detail. I don't have time. But I'm pleased to say that what we've implemented is very similar to what's represented in the ideal stateful compression in the bottom right corner there.
00:21:53.320 - 00:22:33.278, Speaker E: So without further ado, this is what the same transaction as before looks like when compressed. So we've got the link there. You can go view that on the Block Explorer if you like. But the main thing to note here is the 640 bytes from a couple of slides ago are now represented in just those 17 bytes there instead. And so now that I can fit this all on one slide as well, we can have a look at what this looks like when you include multiple operations into one bundle. So have a look at that empty space in there, just underneath the red bytes. So we're going to include two more transactions.
00:22:33.278 - 00:23:10.602, Speaker E: Let's make them ERC, 20 transfers, which is important to note that you can actually include all sorts of different transactions into the same bundle and they all benefit from the combined signature aggregation. So that's what that looks like there. You see, we can just slot them right in there and we have some ERC, 20 transfers as well. So, continuing to zoom in, let's see what's actually going on with those 17 bytes. How does it represent what's actually happening in that operation? So this is them, the annotations. So all of these fields, I won't go through all of them. All of these are variable length fields.
00:23:10.602 - 00:23:46.730, Speaker E: So in particular, you take, for example, that nonce field is only currently taking out one byte, but one byte can only represent 256 different nonces. So that would be a big limitation if it was only that. But this just expands gracefully like all the other fields, if necessary, to accommodate the extra space. So as you get into hundreds of nonces, then you'll start using two bytes. Eventually you might use three bytes if you're really prolific. And in theory it can go up as much as you need, but you probably won't go more than three bytes. Secondly, I'll draw your attention to this build is particularly special.
00:23:46.730 - 00:24:50.714, Speaker E: So this is representing the BLS public key of that account. And so, yeah, three bytes is not enough to represent a public key. But what we're doing instead is we're saving this data in a registry. So the idea with that is that your BLS public key that we use to identify you, that does need to get posted onto L one at some point. But what we can do is effectively it's compression. We're deduplicating that data, but instead of having to do it within one block or like, within one batch that gets rolled up, like in the Zlib stuff that some of the chains are doing now, instead we're deduplicating it across a much wider time span by just saving those bytes on chain, and then we can refer to them again later. Another thing that we are leaning on quite heavily with the encoding is this format called pseudofloat, which is a format for representing decimal quantities really efficiently.
00:24:50.714 - 00:25:51.826, Speaker E: What this format allows us to do is if you've only got three digits of precision in your quantity, say you're sending 0.1 E, that's only three digits in there, and we're able to represent that quantity in only two bytes. If you need more digits than that, obviously, sometimes you do need more digits, then it again expands gracefully and you can still do that as well and supports the full UN 256 range. Finally, on the compression side, I'll leave you with this to just summarize the amount of bytes that you need for an ERC 20 transfer under different scenarios. So in the vanilla transaction, which is the status quo, today, you're looking at 150 bytes to 180 bytes, depending on how you count them. But if you use Wax, if you're in a bundle of five transactions, then you're only going to have to pay for 55 bytes each. And if you can aggregate into 100, then you're only paying for 22 bytes each.
00:25:51.826 - 00:26:18.250, Speaker E: So this is pretty exciting. We're looking at reducing the amount of call data by almost a factor of ten. And so that corresponds to being able to do ten times as many transactions. So we're pretty excited about that. All the stuff of this compression stuff, that's all implemented in our V one contracts, but we're also looking towards a V two with some new and exciting features. So to talk more about that, I give you Jake.
00:26:21.920 - 00:26:22.952, Speaker D: Thanks, Andrew.
00:26:23.096 - 00:27:15.208, Speaker F: So next we're going to go over for our V two some additional verification methods. We're looking into using the ERC Four three seven kind of framework. Before we jump too much into that kind of talk about what kind of accounts currently exist on ethereum and verification methods we use with those. The most common one you have nowadays is an externally owned account, also known as an EOA, uses ECDSA signatures and the same curve that Bitcoin uses for the Asymmetric cryptography. These commonly are hierarchical deterministic wallets and sometimes can also be multi party computation wallets with a shared private key. But then on the other side, we also have Smart Contract Wallet accounts which really can use any sort of signature or verification sorry, signature curve that's supported inside of the EVM. It still commonly is going to be ECDSA, but we can really use a lot of different things such as BLS.
00:27:15.208 - 00:28:07.400, Speaker F: Inside of that, you may commonly know existing Smart contract accounts with like Safe, Argent and different protocols like that. So those are kind of the two things. There's a very good comparison given by the one KX network that goes over the difference between all of these different wallets. Highly recommend checking it out at another time. I'm not going to go in depth into this, but I really want to focus in on two advantages that Smart Contract Wallets have, which is their ability to be programmed on chain and then also the composability of the different things that you can use inside of those. So with Wax V two, we're using ERC Four Three Seven to implement using that common account abstraction spec. In this kind of what we're going to take advantage of here we have our bundler, which is very similar to the aggregator James mentioned earlier, which allows us to bring together those user ops and submit them.
00:28:07.400 - 00:29:12.124, Speaker F: We have our entry point contract that's going to be connected to our account and then we're going to basically validate those user operations, see if we're going to pay for them, and then we're going to execute the actual main functionality inside of them. One of the cool things about this spec is that the Iaccount interface we use for checking and paying is very generic. It basically takes in a user operation and the wallet basically will tell the entry point and the bundler whether or not it's going to work with that validated data, validation data that passes at the end as part of that user operation. We have a field called signature, which is just an array of bytes. And that array of bytes, even though it's commonly going to be a cryptographic signature, we can really put anything we want in there that can be used for the account and for verification. So now that we have this, what new verifications could we use with this smart contract wallet? Well, we could use some basic Web Auth, maybe have a username and password accessing something. But there's better things we can use, such as Web Auth N, also commonly known as pass keys.
00:29:12.124 - 00:29:54.040, Speaker F: This is basically using Asymmetric keys similar to what we would use in Ethereum and other blockchains for signing into Web Two servers and accounts. It's device and domain specific and it already has support from companies such as Google, Microsoft and Apple. But in theory any Web Two company would be able to implement this as part of a login. And so we can take advantage of the fact that those are Asymmetric. We have those Asymmetric keys to actually allow these to sign for a Web Three account. So anyone potentially with accounts already at these places that has the Web Auth N could control an account using those. Another one is potentially using zero knowledge proofs as a way to sign your user ops.
00:29:54.040 - 00:30:52.430, Speaker F: So on your device, which is the prover you're going to have your private inputs and you're going to have an expensive computation to generate a proof, we then push that proof and maybe the public signals into the signature field of that user op. And then finally in the EVM and that entry point, our contract can go to a verifier contract and verify whether that proof is valid and whether it's going to process that user op. And so in this way we can use those proofs to authorize a user op. This opens up a lot of different possibilities of different things we can do, such as using new signatures and curve schemes that the EVM does not support. So anything we can implement in Circom or newer DSLs such as Noir can be used. For example, you can already do EdDSA signatures inside of Circom, so you could use that for verification in a smart contract wallet. You can also use newer BLS curves like BLS twelve 381, which is what the current ethereum consensus layer uses to validate those.
00:30:52.430 - 00:31:55.380, Speaker F: But really we can also do anything that's provable inside of a proof as part of that verification. So one thing that's being looked into, there's a pending paper that will be coming out soon called contract wallet. Using emails is using an email as a proof, meaning that someone could have a smart contract wallet and actually send transactions just using a normal email message and generating a proof that they control that email address and that the content inside actually matches the transaction they want to do. But you could probably think of a lot of other things you could prove with a zero knowledge proof that you could use to verify via smart contract wallet. Finally, one of the cool things too with the verification is it generally is cheaper to do inside of the EVM than maybe doing a normal solidity based verification. So the gas costs sometimes are linear with the number of constraints in the circuit, but some work that's being done to lower those could eventually make it log of N or constant time to verify those proofs. You still have the issue though on the device where the proof generation can still be very computationally expensive.
00:31:55.380 - 00:32:44.470, Speaker F: So what does this allow us to do? We can have multifactor off situations where we combine and compose both of these together. And so for an account for smaller things you might be able to use one of these methods for sending small things. But if you want to upgrade the implementation or send larger amounts, you would need say two of three to do this. So in this example you might have an ECDSA or BLS signer, your friend may be just using their email to help you, and there may be a bank or institution you trust that also is a backup signer for those. And so for small things like your bank paying your bills for you or you sending money like you would on Venmo or something, you might only need one of these signers. But if someone wants to change the signing scheme or do a recovery, then you might need two or three of these people to do it. But we can have a bunch of different verification methods for that.
00:32:44.470 - 00:33:35.764, Speaker F: Another one, fun one is recovery and migration, which we can have basically people move from centralized accounts to decentralized accounts progressively. So for this example, let's say grandma wants to play web3 poker, she's a poker fiend, she wants to try it out and so she can actually create an account abstraction account with her Facebook login using web authentic. She can then choose her best friends on Facebook to be her social recovery people in case she loses access to that account. Then let's say grandma kills it a poker and makes a ton of money. Now she doesn't want Facebook to be able to rug her and take all that money away. So she and her friends get together and migrate her authentication to something like a hardware wallet so she can really have that secure scheme control over those new funds. And so what this really leads to is kind of almost a Cambrian explosion of different verification methods we can use.
00:33:35.764 - 00:34:05.020, Speaker F: This is when multicellular life kind of exploded into the world 600 million years ago into a wide variety of things we see today. And so using things like our current signatures, BLS, Web, Authentic, ZKPs, we have a lot of different new verification methods we can use. But there also are a lot of cool ones we want to look into that maybe don't exist yet or maybe you will build during this hackathon or some other time. And we're excited to see what those are. And so, to make all this easier, we're going to bring on Blake to talk about integrations.
00:34:08.650 - 00:34:45.090, Speaker D: Thank you, Jake. Yeah. Now I want to talk about what our team is doing to actually get some of this work into developers hands. And in order to do that, we've been recently working on a node module called Ethdk. This is a node module that we're hoping that will allow developers to easily add some of these experimental features into projects that they're trying to get into end users hands. Because we do know sometimes if you're building a product for a user, it could be hard to take the time to experiment or integrate a cutting edge feature that you don't know exactly how it works. So we want to take some of that cognitive load out of the hands of the developers.
00:34:45.090 - 00:35:28.874, Speaker D: When talking about building this node module, there were two things that we wanted to focus on. The first one is just keeping it simple. And with that we wanted to keep it simple just in the terminology that we use. It seems like, for example, this first one I have up here, wallet versus Account, seems like the ecosystem is like settling on the terminology of account over a wallet. So we want to make sure our code reflects that. So that users that are developing with this node module know that they're creating an account and it's a programmable smart contract account. And then another example, this one's, both terminology and in the functionality of this function we implemented is our V one smart contract wallets have a form of social recovery available.
00:35:28.874 - 00:36:04.134, Speaker D: And in order to set that up, you need to call the Set recovery hash function on the actual wallet contract and pass it a recovery hash. But that requires you to know how to generate that recovery hash. So in our node module, we created a separate method called Set Trusted account. The terminology of this better communicates what you're doing. You're setting a different account that you trust to be able to recover the original account. And then we also just pass two parameters. We pass a recovery phrase as well as an address so that you don't have to know how to actually generate that recovery hash.
00:36:04.134 - 00:36:46.422, Speaker D: And then we also wanted to focus on just some sensible defaults. There's a few things that we know based off of building our wallets and our aggregator that you need to do in order to get the full benefits of our tech. For example, as we talked about earlier, the reduced costs on layer twos, you actually need to be using a layer two. You can't do the big deal of signature aggregation on an l one and get the same cost benefits. So we want to make sure that developers know that they should be using an l two. And then also we want to make sure that our contracts are already deployed and verified on the specific networks that we're trying to support. So these variables can be constants within the node module that are easily exportable.
00:36:46.422 - 00:37:28.994, Speaker D: If you wanted to, you could easily override any of those defaults. But we do want you to just focus on using the features and not finding where a specific contract wallet is deployed on chain. So where are we now with Eck? We currently have a beta version published to NPM and it works with our implementation of our v one contracts. And then we've also demoed it in our Instant Wallet. You might be familiar with a Burner wallet. The Instant Wallet is just our version of a burner wallet that uses our smart contracts behind the scenes. And then we are starting the work on our v two smart contracts.
00:37:28.994 - 00:38:17.702, Speaker D: So the hope is that we'll come out of our beta version when we have the v two contracts available. And we could also integrate some of the modules that Jake was just speaking about before me. And to wrap up this section, I just wanted to show a quick example of our v one or our beta version of ETH DK. As you can see at the top, I'm importing a Create account function as well as the networks object and then it's just like a few line of codes to actually create an account and then set your trusted wallet. So here I just call the Create account factory function with a couple config properties and I can await that and then print out the address. And then down below, I just create a recovery phrase and pick an address that I trust and then I can call the set Trusted account. So as you can see, you don't have to know how the contracts are actually set up.
00:38:17.702 - 00:38:43.386, Speaker D: You could just easily use the functionality that we're trying to get into the hands of developers. But yeah, we're really excited where we can go with this, especially with our v two contracts and then with this coming out of the beta version. So keep an eye on the link on NPM and I think to wrap it up, I want to hand it over to john, who is going to aggregate all of the points that we just spoke about. Cool. Yeah.
00:38:43.408 - 00:38:46.314, Speaker E: Thanks, Blake. So to wrap up all that's been.
00:38:46.352 - 00:38:46.940, Speaker A: Said.
00:38:50.310 - 00:39:25.900, Speaker E: Yeah, so Wax started off to bring cheaper L2 transactions to EVM chains to enable new applications. We can do this through BLS Signature Aggregation, which can reduce the call data that gets posted to L One by combining many signatures into a single signature. But the signature aggregation by itself won't get us all the way, so we need to do some cool data compression as well, using the techniques that Andrew mentioned earlier in the presentation. And it's important to mention that the gas savings we've spoken about can be used in addition to the gas savings from L2 S.
00:39:27.710 - 00:39:28.298, Speaker A: So there's a.
00:39:28.304 - 00:40:11.846, Speaker E: Lot of buz around the design space that account abstraction opens up. ERC, Four Three seven in particular is a very unappinionated standard and gives developers a lot of choice in what they can do. There's a lot of unexplored ground, and as Jake mentioned, we're sort of anticipating or hoping there will be a Cambrian explosion as such, of accounts using lots of different verification methods. We're in particular excited to try out Web authent and ZKP email verification in our upcoming modules. And you'll have the freedom to use these modules in various ways. For example, you might be able to use Web Author as a multifactor authentication. Say, if you're sending a transaction that's like, over $5, you can use your Web Authentic.
00:40:11.846 - 00:40:24.190, Speaker E: Then you might use your ZKP email to recover your account. Alternatively, you could even use the ZKP email as your multifactor authentication. The possibilities here are fairly broad.
00:40:26.290 - 00:40:26.606, Speaker A: And.
00:40:26.628 - 00:41:08.720, Speaker E: You can do all this while enjoying the cheaper transactions brought about by BLS SIG aggregation and the cool data compression. And at the top layer, we'll have the Efdk, which will wrap all the BLS components together in an intuitive abstraction for developers to use. So we've just about wrapped up our V one contracts, and we're looking to V Two to apply some of the lessons learned there. And we're starting that now, basically. So V Two will enable BLS Signature Aggregation in a four, three seven compatible modular smart contract wallet, and you'll be able to add additional verification modules in there to enable more expressive transaction verification and recovery options.
00:41:10.050 - 00:41:10.654, Speaker D: Cool.
00:41:10.772 - 00:41:32.130, Speaker E: So, yeah, the future of where transaction costs are going and also Account UX is very exciting, and we're really looking forward to bringing these new developments to the ecosystem. If you want to learn more, please check out our website@getwax.org. And if you want to learn more about the PSC and what we get up to, please check out Appliedzkp.org. Thank you all for listening.
00:41:40.950 - 00:41:42.246, Speaker B: I'm not sure if there's time for.
00:41:42.268 - 00:41:43.382, Speaker D: Questions or one question.
00:41:43.436 - 00:41:50.120, Speaker B: If anyone has no questions, all right, we'll wrap it up there. Thanks again.
00:42:18.040 - 00:42:19.590, Speaker G: Can you guys hear me okay?
00:42:20.060 - 00:42:20.810, Speaker H: Test.
00:42:24.460 - 00:42:26.090, Speaker G: Let me just start it here.
00:42:26.780 - 00:42:27.096, Speaker D: All.
00:42:27.118 - 00:42:58.862, Speaker G: Right. Hey, guys. My name is Nick Fett. I'm one of the founders of Teller, and I'm here on behalf of Gnosischain. So figure out how to click here. Before I get into just what Teller is, I thought I have to at least say the sponsor who brought me here and why Gnosis chain. So, for those of you that don't know about Gnosis chain, nosis Chain is an alternative L One.
00:42:58.862 - 00:43:36.622, Speaker G: So similar to Ethereum, it is an EVM, and it's got the works. So it's got a bridge, explorers, AMMS, all the wallet support. And I know you guys are like, well, why the hell do we need another L One or another chain? But the truth of the matter is, if you actually look at all the L two S or anything that's actually cheap, they're all like, really shitty. There's like a multi SIG or a centralized sequencer or an admin key, and they can rug you at any point. So if you want to actually build a censorship resistant application, come to nosis chain. We'll love you over there. Okay.
00:43:36.622 - 00:44:13.526, Speaker G: Onto Teller. So kind of how I got started with Teller back in 2017. I was trying to build a derivatives protocol. I was trying to do where you could lock ETH into a smart contract. Then you would have long and short tokens that represented like, long bitcoin, short bitcoin. And I know this was like novel back in 2017. Anyway, got an Ethereum Foundation grant to start building that, and you quickly ran into the problem of, okay, well, who gets to say what the price of Bitcoin is? And the problem is that smart contracts can't read outside information.
00:44:13.526 - 00:44:59.826, Speaker G: So due to the fact that you have to be able to replay it for all of time, if you were reading an API, if somebody a year down the road tried to run that smart contract function, they would call the API and it would get a different result. So things would break. So everything needs to be an input. And this input is what's called the Oracle. So who gets to do that is a big problem for things, obviously, such as price feeds when building derivatives and then other things, bridges, other pieces, which I'll kind of get into. So what are the Oracles? So, back in 2017, there actually was an Oracle live on Ethereum. If you guys remember Oracleize, this was Thomas Bertani.
00:44:59.826 - 00:45:40.382, Speaker G: He ran Oracleize, and you would, like, pay him a quarter or ETH, and he would return the result of your API call. And that was literally the Oracle that people were going live with in production back then. This was pre chain link, pre everyone. And that's obviously a really bad Oracle. The reason is that if he died or if he decided to change the value or rug you, you would have no recourse. So you can go beyond that and it's okay, well, how could we make that a little bit better, I don't know. We trusted Thomas, let's trust Vitalik and we'll trust so okay, so we'll do a multi SIG.
00:45:40.382 - 00:46:43.914, Speaker G: And that can also be an know that's like whenever Maker started, they were one of the first people with their own kind of custom Oracle and it was basically just a multisig. They had 14 people and it was a multisig and it worked. You just have the trust assumptions of a multisig. But basically you have to kind of rethink about how you're thinking about an oracle and it's just how do you come to consensus on data. And this is sort of the problem because in the blockchain world we're really sort of honed to thinking about coming to consensus at the chain level, but then at the app level it's still the same way. How do you come to consensus quickly on a piece of data? And you obviously can't build a blockchain now it's actually possible with roll ups, but building blockchains on top of blockchains to decentralize, it gets really old really fast. So we'll kind of go into how we solve that problem and how some of the other people are and how you can use them.
00:46:43.914 - 00:47:30.674, Speaker G: So what are oracles used for? Obviously there's price feeds, bridges. So bridges are oracles. If you have Gnosis chain over here and ethereum over here, they don't know anything about each other. You might as well be reading an API from Coinbase. A bridge basically just reduces the assumption. You have more generalized Oracles where you can ask it any question like who's kind of like at the bottom prediction markets, who's the President of the United States, who won the Lakers game? You can ask it these general questions or you can have very specific Oracles like what's the block header of Bitcoin next? It's still an but and you need some way to come to consensus around things. Insurance as well, anything off chain.
00:47:30.674 - 00:48:16.726, Speaker G: Anytime they talk about, if you hear somebody say like, oh, we're going to put real world data on chain, it's sort of this meme. And the problem is, okay, well, who's putting the real world data on chain? That's an oracle problem. You probably have some centralized entity that is in charge of saying it went on chain or it went off chain. And that's a problem. You should maybe use Tellers to decentralize that a little bit. But as we kind of go into building these generalized consensus mechanisms, the scalability trilemma it holds for oracles too. So if you want this thing to be really fast, it's probably not going to be very decentralized and it's just a trade off.
00:48:16.726 - 00:49:20.022, Speaker G: And so any oracle that you guys see out there that you're thinking about using, if they claim like we can update your price feed with instant finality every block and you're like there's just no way. Besides the fact that it would be really expensive to write that much data to chain because you can kind of think of if you had the question like, who's the President of the United States? What's like a really slow Oracle. If you guys remember, one of the original Oracles out there was Auger or like Gnosis back when Gnosis was a prediction market. And basically what you would do is you would have all these tokens and you would have to ask it a yes question or it would have to be a yes no question. And then people would stake all their tokens on whether it was going to be a yes answer or a no answer, and it would take like a week. And that was an Oracle and it was a great way to do it. The obvious trade off there is it's super slow, so didn't really work for price feeds.
00:49:20.022 - 00:50:15.014, Speaker G: So we've since come to some better solutions, which gets me now to how Teller actually works. So teller, it's kind of a simple Oracle. We really focused on how can we actually be decentralized? We came into this space if we're building on Ethereum, if we're building on Gnosis chain, if we're building on these networks, you're only as decentralized as your least decentralized point. So what you want to do is make sure that the Oracle isn't that sort of centralized choking point. So how can we make sure that this is decentralized in the sense that anybody can do it and anybody can validate it? And so the way our Oracle works is you stake some Teller tokens. So you grab like on main net, it's like a few thousand dollars worth of Teller tokens, not a crazy amount, and you lock it into a smart contract. Then somebody else comes and they tip.
00:50:15.014 - 00:50:56.634, Speaker G: They say, hey, I'll pay one dollars, or probably on Ethereum more since gas is really expensive. I'll pay you one dollars if you submit the price of bitcoin on chain. All of those staked reporters then, right now, they're all like mev bots on our network, they race each other to go and submit the price of bitcoin on chain. You don't want to use it right away though. So this is sort of the caveat that makes it slow is you actually need to validate it because there's no way for the smart contract to intrinsically know that that value is correct once you put it on chain. You could put anything on chain, but it's an optimistic Oracle. So you put it on chain, if nobody disputes it for a period of time, then you can use it.
00:50:56.634 - 00:51:37.154, Speaker G: What is that period of time? Well, that's up to you. If you want to yolo it and say five minutes, okay, you can do that. If you want to wait ten minutes, 15 minutes. Usually it's really fast, like a minute for a dispute just because all the other reporters are running these monitors to catch each other. Because if you catch it, you submit a dispute fee. So a small fee and then if you win, it gets pulled off, the data gets pulled off, goes to a two day long vote, you can win the guy's whole stake. So it's very profitable to win these disputes and then for the user.
00:51:37.154 - 00:51:40.760, Speaker G: So the way that we sort of use teller to make it really fast.
00:51:41.130 - 00:51:41.880, Speaker D: Is.
00:51:44.170 - 00:52:01.550, Speaker G: Once that data gets pulled off chain, you don't have to wait for that result. You as the user don't actually care. The next person would just throw it on chain and that's who your dollar would go to. So the wait period is roughly how long you are going to wait for a dispute.
00:52:03.330 - 00:52:03.806, Speaker D: All right.
00:52:03.828 - 00:53:08.274, Speaker G: And then your smart contract reads the data. So now let's kind of get into what are just some best practices whenever doing these Oracles. And you guys are at a hackathon. So I wanted to try and keep it hackathon focused as far as what can you build with Oracles, what are good use cases for a blockchain? The biggest thing and the biggest problem that most people have whenever they're starting to use an Oracle is like, you'll hear people with very niche use cases. So it'll be something like I think there was one guy, he wanted to do car insurance on the blockchain. Car insurance is really hard. And he's like, well, could there be an Oracle that says whether or not somebody got in an accident? If you think about it, who's that Oracle? Who can actually validate that? And that's a problem of you want it to be something that everybody can validate because once it's put on chain, if you can't go actually see that that person got in a car accident, you can't validate it or say anything about the truth of it.
00:53:08.274 - 00:53:49.970, Speaker G: So there would probably be rampant insurance fraud. And this is a problem with most things. So if you have some calculation that takes really long to run, or if there's the classic example is like, what is it like crop insurance in Africa we're going to make on the blockchain, whether it rains in a certain region. This was always like one of the old examples that people would do at a hackathon. And the problem was always, well, how do you tell if it rained in a given region? It's really hard and it's not necessarily straightforward. Whereas the price of bitcoin we know what the price of bitcoin is. It's very easy to tell if you lied.
00:53:49.970 - 00:54:56.886, Speaker G: But on the price of bitcoin piece too, there's actually a lot of trade offs whenever you're even defining the price of bitcoin. So for instance, if you're talking about the price of bitcoin, you can have, okay, well, if you say what's the price of bitcoin on coinbase, that's a different answer than what's the price of bitcoin as a median between coinbase kraken and binance. And that's actually a different answer than what's the price of bitcoin? If you just answer it and there's actually different trade offs for each one because the first one what's the price of bitcoin on super? Super easy to verify. And if you're using this DeFi protocol, for instance, as like a hedging platform, you know what exchange you're able to hedge and that's super useful for financial tools. The downside, of course, is decentralization. You know, that the person, if you want to throw that Oracle feed, you just have to go throw the API on coinbase and go make some big trades on coinbase. Whereas if you just say, okay, well, what's the price of bitcoin? This is where that subjective data comes in the middle.
00:54:56.886 - 00:55:43.826, Speaker G: Okay, so if it's just the price of bitcoin, well, maybe there's like a 1% wiggle room in there because it's not going to be exactly the same on every exchange. So you sort of have to be okay with that wiggle room. But yeah, just different sort of trade offs you have to think about as you're putting it on. We always recommend any Oracle that's like, oh, just put in your API and we'll go get it. It's like, well, that's a centralized API. You don't want to use that for your Oracle. You have to think about how can you get the data without a centralized API and then you can potentially have a decentralized Oracle in the so, all right, I'm going fast because I know we were started a little bit late.
00:55:43.826 - 00:56:08.654, Speaker G: So going to keep us on time. This is just the basics, how Oracles actually work. So there's several different kinds of Oracles. There's. Push, Oracles, and pull, Oracles. So a push Oracle is one that will push it directly to your smart contract and implement an action. A pull Oracle is one, say, like Chainlink or Teller, where it updates its own smart contract and then you have to run a function and go grab it.
00:56:08.654 - 00:57:08.316, Speaker G: So there are two different things. Usually they're actually converging as time goes on, just because what you can do now is whether it's Gelato or the Keeper network or those, you can just sort of automate the action. Once the pull Oracle is ready, run some action and push it to your smart contract. So that's usually best practice. Now, do we want to look at code real fast? We can show you guys how easy it is to kind of look to build an Oracle. Sorry, can you guys see that? Can I zoom in better? All right, I can zoom in again. The way that Teller works is it's a generic Oracle.
00:57:08.316 - 00:57:38.492, Speaker G: And this is what's kind of important that I wanted to show you guys. We have a helper smart contract. You can just come. So this is sample using teller. It's a repo in our GitHub. You just NPMI using Teller, pulls it into your Node modules and then you can import it and do sample using Teller is using Teller, makes it easy to inherit it. But the way that teller actually works as far as getting what you want and knowing is we call it query data.
00:57:38.492 - 00:58:39.952, Speaker G: So we have these data specs for how we define what a piece of data is. So the spot price data spec what we do is here is we encode the word spot price and then for instance Gnousd and that's asking the Oracle for the Gnosis us dollar spot price obviously there's lots and lots of different data specs that we you know other ones that we have are like snapshot vote result. So you put in a snapshot vote ID and a chain and a contract and it'll go get you a result of a snapshot proposal. Other ones you can do like EVM calls to different chains. So you just need to give it a chain a contract address and then call data and it'll return that call to your smart contract. And these are ones that we already have but you can actually come and it's open source. So we have these hosted on IPFS you can make your own data spec.
00:58:39.952 - 00:59:22.792, Speaker G: So if you want to really think about okay what's something custom that I would want to do really the sky's the limits there's a lot of different pieces that we've done. Another fun one is we do like cross chain balances. So like what we do is we'll return like a merkel route of all the balances. So if you have a token on ethereum, and let's say you want to AirDrop over on polygon to the token holders of a token on ethereum, all you would want to do is you could put like the Merkel. Route of all of those balances over on Ethereum or over on Polygon. And now people can go and claim it and prove that they have that balance. And that's a much more efficient method than bridging over all the balances.
00:59:22.792 - 00:59:57.352, Speaker G: So basically kind of just telling you you can put on whatever you want it's not limited by any type it just returns bytes data so you'll have to decode it at the end. But if you want to return very large strings, you can do that. And then yeah, after you would tip for it or put it on chain yourself. You just run Git data before the query ID. And then this one, this is showing down here. The best practice. Block timestamp -15 minutes.
00:59:57.352 - 01:00:38.512, Speaker G: You're waiting 15 minutes for a dispute, making sure that it's valid, and then you can update it. So that's about as simple as it gets. I'll go back to my presentation. I know they're ending over there, so I'm guessing that means I have to end, right? But I wanted to give kind of before we ended. I know some people were still looking for ideas or if you wanted ideas. These are some of the cool ones that I was hoping people would build, whether hopefully on Gnosis chain or with Teller other ones. So things that you could do, you could build token bridges.
01:00:38.512 - 01:01:15.372, Speaker G: So we were just talking about how you can use that EVM call, but you could make it a mixer, which is what I think people should do. So you could fork some tornado cash code where there's a proof of a deposit, but why don't you just take that proof, go put it on another chain. Now all of a sudden you got a mixer and you could put it on ten different chains if you put a chain ID in there as well. And now you're mixing across chains. So some cool ideas. I want to see somebody do a BRC 20 on chain. So you could use an Oracle to go grab ordinal data from the bitcoin blockchain.
01:01:15.372 - 01:01:51.260, Speaker G: You put that stuff tokenize them, put them on the Ethereum network, maybe get some of the maxis on board. Other things, bounty programs. So we've seen people do this with Oracles. You can use an Oracle to bring on how many Twitter followers do you have, how many discord followers does your channel have, how much volume does your token have? And then you could set up bounties in a decentralized way, like, hey, I'll claim this, I'll get you 500 new Twitter followers. The Oracle will bring on the start Twitter followers and the end Twitter followers. If you bump that number up by 500, you're going to get this bounty. You could do something like that with an Oracle.
01:01:51.260 - 01:02:36.068, Speaker G: Other things that we're working on, you could really go if you wanted to get really sort of econ about it, you could build like a decentralized CPI. So how would you do that? That's more of a question for how do you structure okay, what data do you put on chain? How do you put lots and lots of data on chain? And then yeah, kind of last same thing like music bounties you can put on spotify streams, you can put on okay, did an artist release a new album? Something like that. Lots of different things you can do with an Oracle and hopefully it kind of sparked your guys'interest. So anyway, here's my contact. Thanks. Hopefully you guys learned a little something about Oracles. Definitely give me a follow on Twitter.
01:02:36.068 - 01:02:41.470, Speaker G: Do I have time for questions? Yeah, if you guys have a question or two, I can answer it.
01:02:50.880 - 01:02:51.244, Speaker D: Yeah.
01:02:51.282 - 01:02:58.210, Speaker G: So he asked if we have a token. We do. So you have to stake our token. That's that one, you know?
01:03:20.920 - 01:03:21.284, Speaker D: Yeah.
01:03:21.322 - 01:04:15.784, Speaker G: So he asked like, how do you validate like if you're asking for a cross chain information, how do you validate that it's not a fork of the chain and that's why it's like optimistic. So you would want to wait on it? The person could potentially get slashed if they're doing it well, yeah, it would probably be invalid and we would get voted and disputed. But if you were the user so you would want to wait. It would depend on what value you were bringing over, right? If you were doing a token bridge, for instance, and you're bringing over $10, nobody's going to fork your chain over $10. You can probably read it relatively quickly, but if you're bringing over like $100 million, yeah, you're going to want to wait for 100 block confirmations to make sure that thing's secure. So, yeah, I think that's just general best practice for these bridges. All right, well, thank you, everyone.
01:04:15.982 - 01:04:16.380, Speaker D: Bye.
01:04:16.420 - 01:07:16.614, Speaker A: It SA. Sam. Sam. Sam. Sam. Hello.
01:07:16.652 - 01:07:17.240, Speaker C: Hello.
01:07:17.930 - 01:07:18.678, Speaker A: That's this?
01:07:18.764 - 01:07:19.494, Speaker C: Yeah.
01:07:19.692 - 01:07:20.162, Speaker H: Yem.
01:07:20.226 - 01:08:09.510, Speaker C: Everyone. I'miguel from Wallcoin, and I'm here to talk about world ID, why it's needed, how you can build with it, and how it's really released to integrate, and you should definitely include it in your projects. So usually I will start this talk talking about civil resistance and airdrops and NFT minting and all those things, but I feel like by now we all know why those are a problem. And also the Wall is changing really fast. We have all this AI stuff coming soon. If you look, five months ago, when we didn't have imagine ratio, we didn't have GDP for all these things, the world has changed. It massively even then, and things that didn't really seem like an issue then, like being able to tell who was a human and who wasn't outside of crypto, now are becoming a really big issue everywhere.
01:08:09.510 - 01:09:42.930, Speaker C: And so this prompts a bunch of questions in general, like for projects, for the Wall, for everything, how do you know what's real? But also as we continue to build a system where these things slowly take over, maybe, hopefully not. How do you continue building the systems that you want to do? How do you fairly distribute all the value that is generated by these things? And all these questions relate to personhood the idea of who is a human. And the goal of Wolcoin is to build the largest network of real humans, an identity network and an economic network by giving away ownership for free to every human. Now, when we started this project, the first question that was really clear was, hey, how do you know what's a real unique person? If you want to give something away from free, people are going to try to game that, and if someone does, they kind of like, ruins it for everyone. So how can we ensure that you are a unique human and you haven't claimed whatever it is that we're giving away yet? And what became clear really quickly is that there were three requisites for whatever solution we picked, which were that it was private, that we didn't get a database of everyone in the world's, information that doesn't seem great, that it was inclusive, meaning that everyone in the world would have closer to an equal opportunity to sign up. An example of something that's not inclusive would be maybe like asking for a driver's license. For the US.
01:09:42.930 - 01:10:18.222, Speaker C: That disqualifies most of the world and that it was robust, meaning that it would actually hold billions of humans in the system without breaking and making it easier to scale. And we started looking alternatives like maybe we can use emailer, phone this is not great because I already have multiple phones and multiple emails and that's without trying to get in the system. So it's not super robust. Maybe you can use KYC. This is not great for the privacy reasons because now you have everyone's KYC information, which is an idea. Maybe you can use web of trust, the idea of humans vouching for other humans. This sort of maybe works.
01:10:18.222 - 01:10:55.850, Speaker C: But the issue is you need an initial set of humans that are trusted and you cannot start from zero, which is what we were trying to do. And then the last option is biometrics, something that every human has and in a way you can use to tell if they're human. We started looking into things like fingerprint and the issue with most of these are mostly that they don't contain enough information. So something like Face ID can unlock your phone. Apple locks it out after like 30 inputs. But according to your numbers, one in I think 30 million people could unlock your phone. So works if you're trying to unlock your phone and it locks after 30.
01:10:55.850 - 01:11:21.166, Speaker C: Embeds doesn't work if you try to onboard 8 billion people to a system. So fingerprint doesn't have enough info. Same for face, same from Palm. DNA kind of has it, but it's also like really expensive and really slow. And also, come on, people are already complaining about this being creepy. Imagine if we were taking their DNA and so the thing that was left was irises. And then we started to look at okay, let's say that we go with irises.
01:11:21.166 - 01:12:04.222, Speaker C: How do we do that? Can we just have people take a picture of the iris in their phone and same issue as before, there is not enough resolution. Even if you get really close, the image does not have enough data, enough pixels in it to actually capture it. You depend on lighting. And also not everyone has like an iPhone with an amazing camera. Some people have worse cameras in their phone or maybe even no camera. We try with off the shelf sensors, maybe the ones that they have at some airports where they can just look at you and scan like that. The main issue there is that other than quality, what those systems are trying to do is check if your biometrics match to what they already have in their list.
01:12:04.222 - 01:12:44.000, Speaker C: So it's not saying is this person in the list? It's like saying is this person equal to this person? So that is much easier if you actually want to differentiate between humans. This wasn't enough. And so our solution was unfortunately it seems like we have to make custom hardware and no one wants to make custom hardware because it takes a lot of money of time and everything. But we did it, we ran through a bunch of prototypes and we ended up with this thing, the orb. And the point of the orb is to first of all, make sure that you're real. Make sure that you're not trying to trick it somehow, that you're not showing it a screen with a picture of an eye, or a dog, or taking it to a kindergarten. These are all things that people have tried.
01:12:44.000 - 01:13:21.046, Speaker C: Then it will check that you have a unique iris that you have not already been onboarded to Walcoin. And we do this using an iris code, which is a measure of the randomness of your iris, which makes it so that we don't need to actually store a picture of your iris or biometrics in general. You're more curious about that, you can come find me later and I will explain how it works. And then it verifies your wallet ID. And Wall ID is a name that we came up with for this system that acts as an internet passport. It's an entity protocol. And like any passport, it has a bunch of stamps.
01:13:21.046 - 01:14:08.086, Speaker C: So, for example, when you get verified with the orb, you get the orb stamp, meaning that this person has been verified by the orb. We've also been working on adding other stamps for people that don't have access to the orb yet, where maybe it's not the most secure thing ever. Like again, one of the things that we support is phone number. And people can register multiple phone numbers. But the idea here is that if we have this passport full of two identity signals to prove, for example, that someone is human, you have different levels of how hard it is to get those stamps. And for people that cannot access the orb, it is better having a unique phone number still means something. Because it means that if you want to, I don't know, like attack a system now you need 1000 phone numbers or maybe millions instead of nothing.
01:14:08.086 - 01:14:51.878, Speaker C: So the end goal is the goal. But as we're building this protocol, we want to make it so that us or anyone can add more stamps to this protocol, to add more indications of whether a person might be human or not. And our goals for this system was to make it privacy first, maybe been anonymous, to make it decentralized using the tools that crypto give us, and to make it open source, because it feels like those are the requirements that if I was working a project, I would be comfortable with adding something like this. And yeah, we built a system called Wallad. The system is very complex behind the scenes. It uses serial escaptography, it does all the machine learning stuff from the orb. But we worked really hard to simplify it so that when you are working on it, there is just two things that you need.
01:14:51.878 - 01:16:10.906, Speaker C: To worry about and those two things are signing With Wallcoin. Anonymous Actions signing With Wallcoin is intended for web two applications for the original applications to use as a sign in with Google replacement or any other sign ins and makes it so that they can make sure that the users are unique humans and also have a unique account without actually learning any information with them. So as an example, this is our version of the OpenAI Chat GPT signing page. They haven't integrated that at least yet and the idea would be similar to how they have continue with Google, continue with Microsoft, they could continue with Wolcoin. That brings them to this page where they just scan the QR code with their phone and then when they click Approve sign in, they're signed in in a completely anonymous way and the application only gets a random ID. And then for Anonymous Actions we build something that works across every single type of decentralized application and that gets validated on chain making it so that you can have anonymous actions that cannot be tied to each other. So an example here would be if you are building something like snapshot or a boating platform, you will be able to have a unique action for each governance proposal, making it so that you can still on each proposal.
01:16:10.906 - 01:17:05.060, Speaker C: Make sure that people are only voting once and they are not like attacking the boat somehow, but at the same time not being able to trace people between boats. So you get anonymous vote here, anonymous boat here on different proposals and you have no way of telling if these boats are from the same person or not. But when someone tries to vote twice on the same proposal that's when you can identify them. So in a way it's a fully anonymous captcha like system that lets you tell not only if someone is human, but also have they done this specific action before, which makes it really really powerful and the best thing about it is that it is really really easy to integrate both on and offset. So hopefully the think I may have to really quickly turn the display because we didn't rehearse this before so that it mirrors. There we go. So I'm going to show a bunch of examples about this and maybe a little code.
01:17:05.060 - 01:17:35.834, Speaker C: Hopefully this is big enough so that everyone can see it, if not, you can let me know and I'll make everything bigger. The first one is the demo that I explained about Chattipt. Obviously this is not actual Chat TPT, this is a demo that we made but we basically rebuilt it to show how the experience would be. So you go to the page, you click Login, you get taken to Odd Zero. Now this is really cool. OD zero is a platform that lets people set up authentication without actually writing any code. So this means that even if you are not technical and don't know how to code.
01:17:35.834 - 01:18:44.898, Speaker C: You can still take advantage of Wallcoin by just going in here, clicking a bunch on the OT zero dashboard, clicking a bunch of buttons and now you have signing with wallcoin in your site. So obviously for this hackathon we care about slightly more technical things on chain stuff, but you can also use it without any knowledge of code. So as I said before, I get a QR code and then I just need to go to the walled app on my phone, scan the QR code with my phone and then it would show do you want to verify signing with wallcoin here? After I confirm, it takes me home. And in this case we just made an example of a hypothetical human mode that will be enabled if you sign in with Wallcoin. Another example of this slightly more complex is we go to the wall ID peterbs page which is a little page that we made so that people would be able to adopt for little cats orbs. So this is a page that allows people to mint an NFT and then we give them the physical thing. And implementing this in page is very very simple.
01:18:44.898 - 01:19:32.506, Speaker C: We have this package called Idkit that has a wallet. We create react component and in here you would just pass a bunch of settings like an app, ID action, all of these things. You can get all of this from our developer portal and I will later share a link to the documentation where all of this explained including starter kits and all of that. But the idea here is you just initialize this widget with a bunch of parameters. Then on success, you get the proof, you save it, and then when it's time to actually do something like this, like in this case, actually mint the NFT when you're calling the smart contract. In this case, I am calling it here. Because the way that we built this app specifically allows other people to pay for gas instead of the user.
01:19:32.506 - 01:20:36.134, Speaker C: But basically in here when I'm calling the contract, aside from the address of the user and the name that they have chosen for their little mascot, it also passes the three parameters of the proof in order for the contract to verify them. Now, if I go to the contract which is over here, this is a fork of horsetarakit. So again, most of the code in here you'll see commented out and explained somewhere else. But there's this adopt function that as we saw before, receives an address, the name and then a bunch of parameters and the code here basically is just going to check this nullifier has in a way is unique for this action, but for the same user it's always going to be the same number. So the check is very simple. We first check has this user already done this? If it is, we stop the execution after we call the wallet the contract and tell it please verify that this proof actually is valid, that the user is human. And then when that succeeds, we just mark it as this user has already done that.
01:20:36.134 - 01:21:34.816, Speaker C: And then afterwards is our custom code from the NFT or whatever it is. Like I mentioned before, if you go to our documentation or our GitHub page you will find hardhat starter fund restarter for the smart contracts and then also an off chain, I think it's called off chain. Anyways, the links are in the notion that I will give in a second an off chain starter kit for people that want to validate the proof without a smart contract through our API, which is the exact same flow. But instead of calling the smart contract, you call an API or on chain. And so let me go back to the slides. There we go. And so obviously this has a lot of use cases.
01:21:34.816 - 01:22:15.200, Speaker C: You can imagine for example Airdrops, which is why we initially built it. But also governance voting. Vitalik has been shouting at everyone like stop doing coin voting, it doesn't really work, but no one really listens. And that's mostly because we have no way of actually on chain telling users that they were human before. Now we do. There's also a big decentralized social media movement lately for Lens for example, that tries to figure out the next generation of social media. And algorithms are very vulnerable to manipulation and especially if you have instead of accounts and CAPTCHAs smart contracts that everyone, including Bots can call.
01:22:15.200 - 01:23:05.244, Speaker C: So incorporating some incentive layer for verifying that you're a human also works and there's a lot more stuff that you can play with. Basically a reason for us being here is for you guys to get inspired and then see what you guys can do. If you want to see more concrete examples on our documentation, we have a use cases page that goes more into detail on things that you may want to build with this, what is possible, et cetera. And we also have prices for a bunch of categories. These will all be in this global page and on the Intro keynote in a few hours. So I'm not going to go over them right now, but basically you can play around with it and probably make something cool. We have this SDK, as I mentioned before, developer portal and this is the QR code that gives you access to it.
01:23:05.244 - 01:23:22.630, Speaker C: We are in early stage rolling this out but basically lets you skip the waitlist if you don't manage to actually capture this right now. Don't worry. Come to our booth downstairs. We still give you a QR code. We have like little stacks of paper that have a bunch of QR codes that you all will need. Going to give you like 5 seconds to take the picture. But again, if you miss it, it's fine.
01:23:22.630 - 01:24:06.340, Speaker C: And yeah, as I mentioned before, we have made this page wallcoin.org list 123, which is an ocean page full of resources. It outlines the prices, the QR code that I just showed, the documentation, all the starter kits, a bunch of ideas, basically everything that you will need, this is the one that you need. I probably should have a QR code to do this as well, but it's a pretty easy member URL. And as I mentioned before, downstairs our booth, we have a big stack of papers with a bunch of QR codes and this is one of them. So, to summarize a little bit, we are building wallet, which is global entity protocol. It's fully open source, it's private, it's decentralized, and it lets you check if people are unique humans.
01:24:06.340 - 01:24:39.760, Speaker C: Right now it uses these signals of orb and phone, but we want to continue exploring. Also what are things people might add in the future. Maybe at some point, instead of just being able to know whether someone is a human or not, you can also use proofs to prove other identity attributes. We are again still exploring and we hope that you guys explore as well. And that's it. I think I have some time, so if anyone has any questions, now's the time. Yes.
01:24:39.760 - 01:25:38.590, Speaker C: So the question is if the wallet gets tied to a wallet? And the answer is it doesn't. Basically, the way that wallet works behind the scenes, it's a separate private key that your phone generates. And the reason why it's separate from your wallet is because you want to be able to use this from any wallet at all, thanks to it being anonymous. That means that if you have multiple wallets or even multiple entities, if you have an anonymous Twitter, you would be able to use your wallet ID for some things that they want to do, like maybe volume proposals, and then for some other things from your entity without being able to DOX yourself. So again, the way that it works is it's a separate key. You use that to generate zero edge proofs that is already handled for you from the app and integrated with Idkit, but it is not tied to any wallet and that makes it so that you can use it with any wallet.
01:25:41.380 - 01:25:42.130, Speaker D: Yes.
01:25:47.310 - 01:26:25.814, Speaker C: Right. The stamps as of right now are meant as one time stamps. We may at some point as we are getting more data and as I mentioned, part of the iris scanning process involves machine learning. So as those algorithms improve, we may be able to improve their accuracy and maybe reissue the stamp or have a new one. We are still figuring that out. The protocol is made so that stamps are a one time thing, but you could issue multiple ones in the future. The way that the orb works, basically you need to go to the orb ones and then once you have the key validator on your phone, you don't need to go again.
01:26:25.814 - 01:26:38.940, Speaker C: But in the future as new stamps get added or as some stamps improve accuracy, if it's meaningful, you could think that they maybe make like a B two stamp or something of the sort. Yes.
01:26:43.210 - 01:26:43.670, Speaker H: Right.
01:26:43.740 - 01:27:47.242, Speaker C: So the way that it works is, first of all Orb takes a picture of you and combines that with the public key that your phone generated that is shown to the Orb as a QR code. You have an option to explicitly opt in to let us collect data like the photos in order to improve the algorithms. But by default that is not the case. So in the case where you don't consent to that, the images get deleted immediately after they get converted into the Iris code and they would never leave the Orb for the case where you do consent, they get encrypted and stored in a cloud so that we can use them for training. And then the Iris code and the public key go on chain to a smart contract and then they are stored also as a mapping. Because at some point we want to enable the idea of you being able to go back to an Orb and invalidate the old entity and issue a new one to make sure that if people lose it, they can still go back and recover it. That is not in place yet, but we still need to tie the Iris code to the public key in order to enable that in the future.
01:27:47.242 - 01:28:08.930, Speaker C: The really good news about that is since the public key is not tied to any of the usage and also the Iris code, there's not a way to recover that into knowing who you are without you getting scanned again. It's still fully private, even though we are storing those two pieces of information. Yes. Can you speak louder?
01:28:13.730 - 01:28:14.190, Speaker D: Yes.
01:28:14.260 - 01:28:53.998, Speaker C: As I mentioned, that is the QR code that lets you skip the waitlist. If you scan this one, you get like an invite that lets you skip it. Again, if you don't capture this, we'll be downstairs, you'll be able to get the link there. The waitlist is mostly as a way for us to work closely with developers and make sure that we can give them all of the attention that they need. That we don't have 1000 people suddenly trying this or like thousands of people and we are just being flooded with ideas on how to improve it. But the protocol is ready. It's just a way to make sure that the developer experience is very good by working closely with the developers that we are letting access to and participating in hackathons like this.
01:28:53.998 - 01:29:51.534, Speaker C: So again, this lets you skip it. It's below something that I want to mention before we all go is in previous hackathons we've had this thing where people will actually go through a flow, do almost everything right. Let's say that they integrate the Etiquette widget, which is the preferred way to do this. They would integrate the widget, they would set everything up, they will then get the proof and they will not validate it. And this is not great because it means that anyone with some basic knowledge of hacking or doing bad stuff can just give you an invalid proof and if you never check it then the whole purpose of this is gone. Same thing for if you actually check it but you check it on your client on the front end, then someone can just intercept that request and change it. So unfortunately, if you do that we will not be able to give you the price even if you really want to.
01:29:51.534 - 01:30:30.480, Speaker C: And you've built something really cool. So I feel like I'm saying this at every single conference and someone still forgets so I'm going to be saying it again. Once you get the proof, even if you do it through the API, if you do it on chain, make sure that that proof that you get, you send it either to your backend or to a smart contract and actually validate it there. Otherwise this whole thing has an SGI but doesn't really serve any purpose. So please remember to do that and let's see if this hackathon we can get. No one making this mistake. Yes, sorry.
01:30:30.850 - 01:30:32.880, Speaker B: When you do your World ID.
01:30:42.080 - 01:31:35.660, Speaker C: Not exactly yes or no. These are two separate things. We have the World app which is like the wallet that we get people, that is the application through which you use Wall ID but at the same time it also creates a wallet for you. So the wallet is separate to Wall ID. This is intended because the way that we are in people with Wallcoin is we are all over the world going to every single city that we can think of being having boots there in the streets, in shopping centers whatever, and actually talking to people, explaining to them how crypto works, what wallcoin is, what ethereum is, what stablecoins are all of those things? And so for those people that are getting on boarded to crypto for the first time and don't have a wallet, we also give them a wallet. So when you actually download the Wall Queen app you will get a wallet. Now that wallet is separate from Wall ID and for example, I already have my wallet that I've been using for years and so when I'm using Wall ID, what I do is I connect.
01:31:35.660 - 01:32:16.870, Speaker C: When application tells me to connect I wallet connect with maybe my existing wallet and then I just use the wallet for Wall ID. So these are separate things as of right now? Yes, the wallets that we create when users create the app are Gnosis safe wallets on polygon. That will be optimism soon, but that is unrelated to Wall ID. I think we're off time, so thank you all for listening and if you have any other questions, I'm pretty easy to find. I'll probably be around the booth downstairs. It's very close to the entrance and yeah, come find me. Good luck building with walleye and I'm sure you'll make some really cool things.
01:32:17.280 - 01:34:58.730, Speaker A: It's Sam. Sam. It Sam. Sam.
01:36:20.780 - 01:36:21.770, Speaker H: Hi everyone.
01:36:22.700 - 01:36:23.400, Speaker C: So.
01:36:23.550 - 01:36:51.996, Speaker H: My name is Sergey Kunz. I'm co founder of oneish Network. It's a pleasure to stay here. Thanks for coming. It's good to see people who would like to win up to $20,000 at the second. So we have really nice bunches. But first of all, I would like to introduce who we are, why we are here and why you should build on top of 1inchh network to the end tomorrow.
01:36:51.996 - 01:37:11.832, Speaker H: So, who we are. I am also a hacker. Back 2018. I started with my co founder Anton Bookov to travel around the globe. First hackathon was December 2018. I met Vitalik, butarian I met a lot of other people. And for now it's cool.
01:37:11.832 - 01:37:47.700, Speaker H: It's really cool. I had already like 1516 years of software engineering experience, but never participated on hackathon. And for now we can build with London over just tonight, something which can win a prize and we can pay for our airplane tickets for hotels. Actually, we almost never needed a hotel because we were staying always on a venue. Also, when we built 1inchh first protocol back in 2019, in May, we didn't sleep. I didn't sleep 56 hours. So it was quite hard.
01:37:47.700 - 01:38:23.390, Speaker H: But you see, nowadays we have a huge set of protocols. We started with the aggregation protocol, then we have built liquidity protocol. We came to our dow. Our token was launched by the foundation back in 2020. We have built our self custody wallets because we didn't find the proper wallet out there. The Miramas was really terrible and from a point of view kind of still there are issues with other wallets. That's why we just have different teams working on the space to just not compete, but improve and add value to the space.
01:38:23.390 - 01:38:59.048, Speaker H: We have our own limitora protocol. It's fully decentralized one based on signature, similar to Zero X and other approaches, but highly efficient. We introduced our fusion December last year. We did hackathon over one month with our people in Dubai. They got breakfast, lunch and dinner, spa, gym, pool, family could come. So we just tried to create such an environment which you meet here at TTH Global Hackathon. And it worked.
01:38:59.048 - 01:39:30.112, Speaker H: We were able to deliver in just one month the fusion and we were really happy about that. Nowadays we are also working on institutional products. We try to enter the space of traditional finances and improve the settlements. For example, with our swaps, with our aggregation, we are like three years old. I would say the project almost four years old. The first year we just were working with Anton. In the nights I was working for Porsche and here for near protocol.
01:39:30.112 - 01:40:08.716, Speaker H: And one day we raised money. So in total we raised like 190,000,000 of US dollars and continue to develop new products to ship new innovations. We keep 70 percentage of the aggregation market share. This market we created actually on the hackathon. We came to the idea how to make a swap more efficient by aggregating among decentralized exchanges and choose based on specific algorithm only those pools which make sense to use as a liquidity source. So at the end the user get the best rate limit. Aura's market share is about 80 percentage.
01:40:08.748 - 01:40:09.184, Speaker C: This is huge.
01:40:09.222 - 01:40:30.330, Speaker H: We achieved like in just one year from zero to 80 percentage of the market share and overtook zero x and other protocols. We have four and a half million of wallets who are using one each protocols. It's not huge, but at the end like you can see in the left corner, they generate 330 billions of US dollars since 2019 and we have.
01:40:32.620 - 01:40:32.984, Speaker D: One.
01:40:33.022 - 01:42:07.264, Speaker H: At 80 core contributors around the globe like freelancers who are full time working on one inch network protocols. So we see Dex volume continues to grow and it looks like we can overtake centralized exchanges because decentralized exchanges are more efficient than centralized. So you don't have to trust anyone, you just interact with the smart contract you have no intermediates except validators of course and this is room to grow for us all here who is developing web3 space but we have current limitation DeFi space we have unfavorable swap rates, we have mev attacks. I faced my really painful mev attack last year when Ethereum dropped to 1000 because of tax reasons I had to sell my Ethereum to buy again so to just declare loss in my tax report and I was front run, I lost ten Ethereum. It was really painful for me. So I could use this money for my daughter or I can for charity or whatever but some attackers got it and I went to our teams and I said like guys, it doesn't work, we need solution for this. And then we came to the idea with the fusion I will explain a little bit later and of course we have problem in web3 space that the user experience is very complicated, still very complicated.
01:42:07.264 - 01:43:39.540, Speaker H: We from our side, we try to improve with the vault we have really nice UX UI now we have these kind of meta transactions with fusion it improves but still there's a lot of things to build to the problems front running attacks so someone see your transaction and do something before you extract value from this. The math attacks are like if someone don't know how that works in terms like math, someone is monitoring the mempool and analyze make it sense to exchange before you to exchange after you to extract value from your trade if you're for example, exchanging directly on uniswap so someone is doing this and they make a lot of money. Back in 2022 they just earned one half billions of US dollars just by out of thin air how US government says nowadays. And this is like around ten percentages of the transactions. Now you have two ways. You have the thermy path with using DEXes directly, you don't get the best rates, you don't know really where the liquidity is concentrated, and you don't know where the token is listed. And you face also the map attacks, you face the front running attacks.
01:43:39.540 - 01:44:18.624, Speaker H: So this is not really efficient. And that's why we from our site we call it turnipath like Black Forest. And you don't know which animal can attack you the next time. And we try to build the other side, where we come to our fusion. But before, I would like to explain once again about the aggregation itself. Maybe it's not clear for everyone. I know some people of you are very advanced, but some people still just know that I can go to uniswap and just exchange there.
01:44:18.624 - 01:45:01.260, Speaker H: There's more. We came to the idea with Anton to aggregate among distro exchanges and multiple liquidity sources. Right now we have on ethereum more than 25,000 liquidity sources. Each smart contract with liquidities on liquidity source. So at the beginning we just exchange on one market, just for example ethereum to die. But it makes no sense to just use one market, because if you exchange hundreds of thousands of US dollars, maybe 10,000 of US dollars, it makes sense to use also other markets like USDT market, USDC market ethereum to something else. In this case you see Ethereum to cusdt just compound USDT.
01:45:01.260 - 01:45:50.428, Speaker H: Actually pathfinder, our algorithm pathfinder can also build a path to just put ethereum into USDT lending pool of compound, for example. So in this case we use market makers who also integrated in our aggregation protocol and routing. We have uniswap, we have SushiSwap, you see Part v Exchange to Dai, part v exchange through USDC. From USDC we go to USDT and from Dai we go also to USDT. And then in the end the user get the best experience and best execution rate. Because we actually did an arbitrage this is actually an arbitrage algorithm, which we are using. So, fusion, this is new approach how to exchange assets.
01:45:50.428 - 01:46:36.412, Speaker H: Nowadays it works very well on ethereum. Since when you do the transaction by yourself if you do this transaction by yourself and the amount is higher than around $10,000, someone will front run you, someone will sandwich you and you will lose good amount of money in normal cases like 50 bips, what you will lose. And this is not how it should be. And fusion solved this problem. Fusion is based on our limitora protocol. You just give a signature that you're okay to exchange one asset against another asset in a specific amount. And you would like to exchange for specific rates, not just for one specific rate.
01:46:36.412 - 01:47:42.488, Speaker H: Like if you do a normal limitora. This is a specific grid we call it, which use the current market liquidity because our algorithm knows exactly how many tokens are where and which rates you get for which amounts for which pairs. That's why we can build such a nice grid and you see the price going down from the current Oracle price and goes down to the current market rate if you do market swap. So when you do market swap, you face a price impact. So you get less than you have originally because liquidity is not really huge and every decks needs to earn something uniswap earns like different pools. 30 beeps, one beep, five beep, 100 beeps. So, of course our algorithm can optimize this, but yeah, still, it's kind of difficult here to achieve the best execution.
01:47:42.488 - 01:49:18.748, Speaker H: So we were thinking why should we do a Dutch auction in linear? We could just use discrete which comes directly from the liquidity amount from the current network. So in this case someone exchanged this real case 3700 Ethereum to USDT and they got $2,345 more compared to if they would just execute it by themselves, theoretically she would face the MEF attack would get actually less and also if they wouldn't face the MEF attack because they would use maybe RPC of flashboards or our rabbit hole RPC endpoint which protects people as well from front running attacks. Anyway, this execution was better because we see these partial fields you see here, small partial fields, these are green points. Arbitrage traders, when they see such arbitrage opportunity, they go and hedge on position, on centralized exchanges they exchange also with only hedge with other networks as well. For example, if you're buying polygon like Matic token, they potentially they will exchange it like hedge the position market trade in the reverse direction, another network where they see more liquidity and come back to ethereum to arbitrage back. And actually we allow over time to sell specific amount of tokens by giving a chance to arbitrage trader to arbitrage this trade. That's why it's better than just doing a market trade.
01:49:18.748 - 01:50:37.844, Speaker H: Actually market makers are selling tokens over weeks, months and theoretically you can also set up with a custom mode you can set an order to sell it in maybe two days because you have a shit token. It's not super liquid, but there's some liquidity on centralized exchanges and then if you set such order arbitrage trader try to arbitrage among digitalized exchanges and different networks and also centralized exchanges. How this works under the hood, it's very important to understand it is kind of order book. Some people are switching like swapping in one direction, the other in the other direction, ethereum to Uzc, UDC to Ethereum then our resolvers who are able to settle the trades can match these orders. That's why it's also sometimes very efficient to use also fusion because there are also other people who would like to exchange tokens maybe in the reverse direction the resolvers these are professional market makers. We have a special game theory for tokenomics, we changed it recently also. In December together with fusion release, you need to stick one ish tokens to get unicorn power.
01:50:37.844 - 01:52:03.536, Speaker H: This unicorn power decrease in time based on the burning curve that means you have to maintain all the time to have almost one token to one unicorn power. And with this unicorn power you can become resolver or you can ask someone to delegate the unicorn power to you to became top ten resolver. Only top ten resolver can execute the settlement. So the settlement is done through smart contracts fully in decentralized manner, fully permissionless in terms of everyone can send an order, but in permission manner only specific resolvers who were selected by the community or had enough unicorn power they can settle the trades and have these chance to arbitrage among centralized exchanges. Already said decentralized exchanges also with all liquidity there are market makers like Wintermute trading with only liquidity and providing better rates than you can get on uniswap because they can hedge positions, they can use options in the background to kind of hedge. So what is important us user, you just sign permit, you sign a message, you send it in a network and you don't pay any gas with the execution. Of course there are some gas costs, market makers resolvers need to execute it somehow on smaller amounts.
01:52:03.536 - 01:52:51.220, Speaker H: If you use fusion, you will just get a little bit less destination token. For example, if you're exchanging ethereum to USDC, you would get just a little bit less USDC because the rate would be worser than if you execute by yourself. But anyway, you get the same. If you send your transaction in legacy mode by yourself, you do this aggregation thing by yourself. You pay the gas cost in ethereum and in a fusion mode, resolver pays the gas cost and they take into account how much they pay and if it's profitable for them. If it's not profitable, of course no one will take it. But we set the orders, we have presets, we set specific price ranges in the terms that it's executed very fastly.
01:52:51.220 - 01:54:04.364, Speaker H: So map protection, I said already how it works, how to integrate diffusion itself. We have an isdk written JavaScript, I'm sorry, if someone would like to contribute to write SDK in other languages, you are welcome to ask for a grant. We have a nice dow and 18 millions of US dollars in a dow to distribute for those people who contribute to one each network you can write in Python for example. So how to get a quote? It's simple, you use the SDK, this nice method get quote, you form your request and you get the quote what is the current market rate, market return of the token pair and the amount you would like to exchange? So it means you can just easily build on UI which is maybe more user friendly than ours, or you build a specific product which use fusion under the hood to maybe rebalance a bundle of assets or something so you can place an order. It's also very easy SDK with the proper endpoint network. We have also nice documentation. I will show you where to find it.
01:54:04.364 - 01:54:52.212, Speaker H: You can get all orders. Maybe you can build something what analyze orders or maybe filters the auras based on specific criteria. Or you build an explorer for one each network like fusion explorer is also one thing what you can get maybe a grant here and also you can apply maybe for a grant at the Dow to work on that maybe full time. So you can scan the QR code. You will get the documentation and I have still a little bit time. I would like to show you how it works and of course you can get in touch with us anytime. We are also here downstairs on the ground level we have a booth, you're welcome to come also to get such chips I can a little bit later distribute.
01:54:52.212 - 01:55:18.260, Speaker H: There are some one ish tokens so you can play around with the fusion mode and exchange it in fully gasless manner. So I will show you how it works. So we have here our one inch and I would like to use our one inch wallet to connect. So now I need to find the proper wallet.
01:55:19.560 - 01:55:20.500, Speaker D: One SEC.
01:55:20.650 - 01:56:34.460, Speaker H: Yeah, this one and we can use one inch wallet connect so very easy connected. And now I have some uniswap tokens which I would like to sell and I would maybe sell it to USDC. So by default we have legacy mode because on smaller amounts you can send the transaction by yourself, pay for the gas costs and you will not face the map attack because it's not profitable for the maps under estimated $1,000. But anyway, if you have no ethereum on your wallet, you can still perform the trade because union supports permit. Permit is just allowance signature which you give from your wallet and we will do it now. So we have auto mode which is in three minutes, the expression time is in three minutes which takes into account the gas costs for the arbitrage, for the resolvers and arbitrage traders. So we ensure that trade will be executed.
01:56:34.460 - 01:57:39.598, Speaker H: So I get the notification that I have to give a permission and now I have to sign the swap. And you see here we have pending status, we have expiration time, we have three minutes something we give like 20 seconds for people to sign because sometimes people are too slow, they need to use ledger or other hardware wallets and it should be executed in next 30 seconds, I'm pretty sure. So you see, you will receive at least 529 USDC because gas costs right now are very expensive on ethereum. Of course we are supporting other networks, so you can work with other networks. We have Arbitrum where you don't pay a lot of money. So in meantime, as long as it's in a pending process compared to legacy mode. If you send the transaction by yourself anyway, you have to wait.
01:57:39.598 - 01:58:54.614, Speaker H: Sometimes if you use market gas price, you wait maybe 30 seconds until the transaction is included in the block. It's similar here for small amounts, for bigger amounts you have huge benefits by using fusion. I already explained. We have nice doc portal, you can find it here under more documentation and you get kind of deeper insights, how it's set up, how it works, how to became a resolver. And we have also nice SDK repository, you can also walk through all the examples, real examples. There are some auction calculators to the bounties. So we have the first task where we say we would like to see someone to build on top of one inch fusion, integrate it how you want asset rebalancing mechanism swap interface, integrate one of your products which you already have built somewhere, I don't care.
01:58:54.614 - 01:59:54.170, Speaker H: So for me it's important that fusion is integrated and used somewhere where it makes sense. We have also this thing with the resolvers which I explained oh no, actually we were hearing this sound I didn't recognize. We have this magic sound when it's filled, so it's filled and we got $549 and it's a little bit below than five nine five because it was not profitable for anyone to take this aura because they had to pay the gas costs. The money is not coming from nowhere, someone need to pay in any time. But compared to what? If you do it by yourself, you trade by yourself, you pay anyway the gas cost. So it's comfortable in the case also when you have no ethereum on your wallet. So today's second task we have our resolvers.
01:59:54.170 - 02:00:35.378, Speaker H: You can stake one inch tokens, you can lock up to two years with locking by two years, you get almost one to one inch token to one unicorn power and it decrease in the time. And then you can delegate to the resolvers. There are already some you can also create by your own sum, but of course you need a lot of delegation power. So we have here top ten. And top ten they have 270,000 unicorn power delegated. So 200,000 of one, ish that's unique?
02:00:35.394 - 02:00:36.018, Speaker A: Theoretically.
02:00:36.114 - 02:01:36.374, Speaker H: But you can ask the community, you can ask core contributors as well to delegate to you if you would like to participate here. You don't need really money, you just need support from people. So we have this delegation and these people, these companies who run the resolver, they distribute kind of incentives for people who delegate to them. So it makes no sense for me to delegate to someone just like that. Here you see Apr, how many one inch tokens resolvers distribute. And based on this Apr, most of the people delegate the tokens to earn on that. You can build something on top of this, you can tokenize, maybe these positions you can create, maybe pool the thing is every time when I delegate and when I claim the tokens I need to pay gas.
02:01:36.374 - 02:02:10.626, Speaker H: And it's painful on Ethereum right now since the meme coins. So maybe a good solution would be to create a smart contract which is kind of pool. Everyone can participate, like bring on one ish tokens. This contract can stake and delegate for specific resolver and also move the delegation based on the Apr and also claim rewards and distribute rewards for those who participate. So this could be one of cool ideas. What you can build here. And we have really nice prices.
02:02:10.626 - 02:02:42.090, Speaker H: So for the fusion integration, for the first place you can get $4,000. It's a lot back to my times, I was lucky to get Ethereum New York. I got on $350 to be able to pay the airplane ticket to Stutgart back when you have got one inch. But nowadays it's really nice to see that. Also other projects offer nice bounties which you can really easily earn by just not sleeping two days. Yeah. And open track.
02:02:42.090 - 02:03:09.798, Speaker H: Just come with what you think. I can give you some example. I'm running out of time. We are working on PTP network. PTP Network for storing decentralized manner limit orders like mesh network and fusion orders. And if you build something like this on hackathon over two nights, I would appreciate and you can see nice bounty for $2,500. Thank you very much.
02:03:09.798 - 02:03:18.570, Speaker H: If you have any questions, I will stay outside and yeah, we have here booth. You can also come to our booth and speak with us as well. Thank you very much, was a pleasure.
02:04:49.150 - 02:07:42.090, Speaker A: Dam ram. Ram it Sam. Ram.
02:08:00.730 - 02:08:19.130, Speaker D: It on. Hello. Oh, look at that. If I talk like is it loud enough? All right, a bit closer. All right. Yeah, that's good. All right, we got some stragglers.
02:08:19.130 - 02:08:55.160, Speaker D: This is unrelated to the talk, but if you want to be added to my hackathon social graph, come talk to me afterwards and I'll add your address to this. This is all the people that I've met at the hackathon. All right, here's what we're going to do. We're going to launch a roll up in 30 minutes. This time if I fail, I'm not going to shave my head. I already did that. So you're just going to have to trust me.
02:08:55.160 - 02:09:24.382, Speaker D: Yeah, exactly. Well, last time, to be clear, I did do a thing where I said I would do this in 30 minutes or I would shave my head and my computer crashed. So it was the computer's fault. But whatever, my hair is growing back. So it is what it is. All right, so some context here really quickly. Optimism has been building stuff for a long time.
02:09:24.382 - 02:10:32.630, Speaker D: We've been building this blockchain op main net and we were like, hey, people are starting to use this code to run their own stuff. Why don't we just make that official and make it really easy for people to spin up their own roll ups using our code, and then they can help us build the software because they'll be using the same code and so then they'll be building the software too, and everyone kind of wins. So we came up with this thing called the Op Stack, which is basically the code that powers the optimism collective. It does a lot of things, but one of the most important things that it does is you can use it to run a roll up. So there are easier ways in practice to actually run these things. People now have built tooling on top of this where you can really it's close to one click to deploy these things. There's things like Conduit and Caldera and these companies now that are spinning up that'll help you run a roll up.
02:10:32.630 - 02:11:24.822, Speaker D: But if you want to understand kind of what's going on under the hood and the different components involved, it's nice to be able to do it from source and to kind of just spin up each of the components one by one and get a good sense of what's happening. So this is kind of the slightly more in depth version than in practice, what people would be running in production, but it's worth understanding this. So we're going to be doing it from source, which is always more fun. Okay, so you can follow along with this if you want. If you go to Stack Optimism IO and you go to the Getting Started page, I'm going to keep this on the left here, but I'm really just going to be talking about it so you don't have to see that. And maybe I should make my Vs code a little bigger. Okay, yeah.
02:11:24.822 - 02:11:46.446, Speaker D: So a lot of the Op Stack code lives in the optimism monorepo, big old monorepo. So just clone it, start with that. Pretty easy. And the monorepo has some stuff that you need, some stuff that you don't need. So we're just going to build some of it. But it's really pretty straightforward. I don't know.
02:11:46.446 - 02:11:50.798, Speaker D: Who knows if we even take 30 minutes. We'll find out. All right.
02:11:50.884 - 02:11:51.274, Speaker A: Boom.
02:11:51.322 - 02:12:10.370, Speaker D: Optimism, right? We got the monorepo here. There's a bunch of stuff in it. Don't worry about it, we'll get there. Is this too small? Should I make this bigger? All right, good. Obviously install dependencies, whatever. That's going to take a minute. It always takes a minute.
02:12:10.370 - 02:12:17.110, Speaker D: Whatever. How's everyone doing? You good? Life good?
02:12:17.180 - 02:12:17.800, Speaker A: Okay.
02:12:20.590 - 02:12:57.838, Speaker D: I swear to God, I'm not shaving my head again. All right. As long as I can have 40 minutes. All right, so this is all right. We're done, right? So we installed our dependencies and then we're just going to make some of the components. So I'll tell you in a second what these are. So generally speaking, an Op Stack system or just a client for this system, is broken up into two key components.
02:12:57.838 - 02:13:34.078, Speaker D: Just like in ethereum. You have a consensus client and an execution client. We essentially have the same split. There's this thing called the Op node, the Op node that serves as the consensus client, and then there's another component that serves as the execution client. And now there's actually multiple implementations of this. So we have two implementations of the consensus client, that's Op node and Magi, which is the version that a 16 Z built. And then we also have two execution client options.
02:13:34.078 - 02:13:57.462, Speaker D: There's Op Geth and Op aragon, which are just slight modifications to Geth, and aragon that make them work as our execution client. So you can mix and match between these things. You can run Op node with Op Geth, or you can run Magi with Op aragon or whatever combination you want, just like you can in Ethereum. Right now, we're going to use Op.
02:13:57.516 - 02:13:58.546, Speaker C: Node and Op Geth.
02:13:58.578 - 02:14:29.970, Speaker D: That's just sort of the reference implementations that Op Labs has been working on. And so every single client in the network runs these two services for itself, right? Just like in Ethereum, you run a consensus client and an execution client. We're doing the same thing. And then there's these other things called the batcher and the proposer. So the batcher is a process that talks to the sequencer node and it gets all the data from the sequencer and it puts it on L One. In this case, we're going to be using Gurley. So it puts it on Gurley.
02:14:29.970 - 02:15:23.438, Speaker D: And the proposer is something that exists for now but won't exist relatively soon, which is something that sort of proposes what the output of the L2 is to the main bridge, which allows users to then withdraw funds from the main bridge for testing. You technically don't need to run the proposer, but why not? But you do need to run the batcher, and you need to run one Op node. Op Geth pair together, which forms one node. We're only going to be running one node right now, which is the sequencer node. But you can also just attach more nodes and they'll communicate over a peer to peer network and share blocks with one another. And that all just happens kind of automatically, which is nice. So the only other thing is that we've separated Geth out into its own repo.
02:15:23.438 - 02:16:11.170, Speaker D: We usually do everything in the monorepo, but Geth specifically, we like to have a very minimal diff on top of Geth. That's what keeps things simple. So there's actually a website that you can go to, which is Opgeth Optimism IO. There we go. If you go to Op Geth, Optimism IO, you can see a detailed description of every single line of code that we have changed inside of Geth and what it does. So if you're curious as to what the diff actually achieved, go to Op Geth, Optimism IO. You can see every single line of code with a detailed description of why that line was changed.
02:16:11.170 - 02:16:44.644, Speaker D: Okay, so we've separated out geth. And we have to make geth same way you make geth normally. It just builds, so that takes a second. And we'll also need access to a Girly node. So we're going to be attaching this to Girly. But you can attach this to any chain as an L one. Any EVM chain could put it on polygon, put it on whatever you want.
02:16:44.644 - 02:17:03.992, Speaker D: Doesn't really matter as long as it's an EVM blockchain. You can use it as the L one. Gurley is just easy. And if you need Girly ETH, just ask me. I have an enormous amount of Girly ETH to give away, so just let me know. All right, cool. So we've built most of the software.
02:17:03.992 - 02:17:45.494, Speaker D: Now it's just sort of about configuring it and running it, which is really simple. For the sake of this demo, we're going to generate some keys. There we go. So if you go to the contracts bedrock, repo Bedrock is our upcoming upgrade that runs all this stuff. We have this command, this re key command. The re key command just generates random private keys for you. So I'm just going to take a copy that you don't need to use this.
02:17:45.494 - 02:18:12.030, Speaker D: You can use your own keys, your own accounts. This is just a useful thing to quickly generate private keys and accounts that you can use. And you need to fund them. So these numbers here are pretty high. I don't think you actually need this much ETH in them right now. But Gurley sometimes gets very expensive at random points. Like last week when it was like 10,000 Guay, which is ridiculous.
02:18:12.030 - 02:18:41.958, Speaker D: I recommend probably doing this on Sepolia, like some other network other than Gurley, just because Girly is kind of a mess sometimes. But yeah. So you need to fund all of these wallets with a certain amount of ETH. There's an admin key that deploys all the smart contracts. There's the proposer key, which is going to propose those outputs. And then there's the batcher key, which is going to post that L2 transaction data to L One. Each one of them needs a slightly different amount of ETH.
02:18:41.958 - 02:19:20.920, Speaker D: These are suggested numbers, but you can do more, less, or whatever. So we've just generated keys. The next thing to do is to configure the network. So to configure the network, we've kind of done a lot of the work for you as part of this demo. Where are we? So packages, contracts bedrock. And so if you go to the deploy config folder, inside of Contracts Bedrock, there's a Getting Started network. And the Getting Started network has what you need to fill in.
02:19:20.920 - 02:19:55.202, Speaker D: You need to fill in a couple of things. And most of this is pretty simple. You fill in what says admin with the admin key that you got whatever says proposer with the proposer key, whatever says batcher. With the batcher key, it's just find and replace. So that part is pretty simple. We'll do that in a minute. The other thing is that every bedrock chain needs to sort of tie itself to an L one block that it sort of starts from.
02:19:55.202 - 02:20:23.740, Speaker D: That's where the chain starts looking at data after that L one block. So we're just going to go ahead and find that block. I'm realizing now that I need to get myself an Alchemy endpoint. All right, give me a second here. Okay, so girly. Right? Great. Copy that.
02:20:23.740 - 02:20:59.074, Speaker D: Okay, so it's usually recommended to grab a finalized block. Just why not? And then we're just going to grab some of the fields. So we want the timestamp, the hash, and the block number. Pretty simple. So we pull that out. So we're just going to use block 8,988,274 as our starting block for the network. This is the hash of that block and this is the timestamp of that block.
02:20:59.074 - 02:21:27.380, Speaker D: So we're going to take that hash and we're going to stick it into this thing that says L one starting block tag. And we're going to take that timestamp and we're going to stick it into the thing that says L two output Oracle starting timestamp. And then the rest of this is pretty simple. We just kind of go back and forth, finding and replacing. So we've got admin here. We're going to find and replace that with the admin address. Don't worry about it.
02:21:27.380 - 02:21:54.220, Speaker D: We've got sequencer. Going to replace that with the sequencer address. Proposer and batcher. We could probably automate this more, but again, in practice, you aren't really going to be doing it like this. You'll be using more tooling to automate all this stuff. This just gets you a sense of where the config actually comes from. So that's the first step.
02:21:54.220 - 02:22:22.766, Speaker D: Now we have a configured network. We basically just need to deploy our contracts. So that's simple enough. We're going to create a env file, or you can copy this env file, I guess, whatever. I don't really care about any of that. We need two things. We need the RPC that we got from Alchemy.
02:22:22.766 - 02:22:46.500, Speaker D: That the L one RPC. And we need the private key of the account that's going to deploy everything. In this case, the private key of the account that's going to deploy everything is the admin key. That's simple enough. The last thing is just you need to send money to the admin key. Otherwise you can't do anything. So I'm going to have my Whale account send some money to the admin key.
02:22:46.500 - 02:23:04.904, Speaker D: Come on. What's it doing? I blame the internet. Okay. All right. ETH on op. Girly. Wait.
02:23:04.904 - 02:23:17.950, Speaker D: That's Op girly? I don't want Op girly. I want ETH. On girly. What is it doing? Do I not have chains? Girly. There you go. That's why. Okay.
02:23:17.950 - 02:23:56.270, Speaker D: Oh, this is frame. This is a very good wallet if you're interested. Worth trying, in my opinion. All right, we're going to send girly ETH. I'm going to send five girly ETH to my admin wallet here, if I can find it. Jesus, what is it doing? All right? Yeah, great. All right.
02:23:56.270 - 02:24:09.250, Speaker D: Sign send. Fantastic. Done. Okay, so my admin key has ETH now. Pretty simple. Now I just deploy a bunch of contracts. There you go.
02:24:09.250 - 02:24:58.688, Speaker D: All right, so hopefully that was enough ETH and I can just start deploying stuff, maybe. Okay, so this is the part that kind of takes a while, which is really annoying. We basically just sit here and deploy a bunch of smart contracts. So that's just going to start happening. In the meantime, I can kind of talk about what we're going to do next. It's pretty straightforward. Where are we? Yeah, once all these smart contracts get deployed, we basically just have to configure the op node and configure op geth.
02:24:58.688 - 02:25:32.620, Speaker D: The op node is going to generate a genesis JSON file, which is the same, or it has a command to generate a genesis JSON file. That's the same type of genesis JSON file you would expect for any network. Same thing. And a roll up JSON file which just has some config values in it. And then we need a JWT token for the communication between the op node and op geth. That's exactly how it works in Ethereum as well. It's not different.
02:25:32.620 - 02:26:02.740, Speaker D: So same concept. And then we're going to initialize op Geth. We're basically just going to insert the sequencer key into Geth, which we can actually do now while this is happening, to save some time here. So we can make a directory. We're just going to call it datadir. There we go. We're going to create a password.
02:26:02.740 - 02:26:32.992, Speaker D: In this case, the password is password, so probably use a real password in production, but whatever. And then we're going to take the sequencer key and we're going to dump it into a file. Easy. And now we're just going to import that sequencer key. So should just be able to import it. Boom. So now we've imported the sequencer key.
02:26:32.992 - 02:27:09.944, Speaker D: You can see this address here is the same address that's been imported. And then once we're done with the other thing, we're going to initialize Geth with the genesis JSON, which is how this is exactly how you would initialize Geth in Ethereum as well. So we're almost done here. Once all the smart contracts get deployed, this is actually really fast. Gurley is usually not this fast, so I may actually make it today. We'll see. Well, in the meantime, while this is happening, we can also set up the command for initializing the op node.
02:27:09.944 - 02:27:44.310, Speaker D: We won't run it yet, but we'll get there. So you know what? I'm just going to copy this. You can just copy paste this. I don't know why I'm pasting it like that. Oh, and I forgot my where's my Alchemy key? I'm just going to paste that in there, too. All right, so once this is done deploying, I'll just run this command. We're almost there.
02:27:44.310 - 02:28:12.080, Speaker D: This is the slow part. So close. We'll be there in a minute. I don't know. Any questions in the meantime? Probably got like five minutes. It's pretty simple. You just follow the instructions and then at the end of this, you have a roll up.
02:28:12.080 - 02:29:22.454, Speaker D: The fun stuff, though, is to go in and actually hack on it, which you can do inside the Op stack docs, there's a lot of explainers for what we call Op stack hacks, which are things you can do to mess with the Op stack. So you can do things like add a pre compile, you can manipulate the derivation function. So the derivation function is the piece of code that looks at the transactions on L One and figures out what the L2 blockchain should look like as a result. But you could do stuff like one of the examples that we give is have something that automatically tracks the burn on L One, so every single block track how much gas is being burned in that block and automatically update a smart contract on L2 to reflect that new thing. So essentially the way you can think of all these chains is that they're really just indexers on the L One state. And we made it really easy to modify the indexer. So you can index all sorts of stuff.
02:29:22.454 - 02:30:31.224, Speaker D: You could create like a blockchain that only exists to index uniswap trades, or you could have like, an oracle on layer two that automatically pulls in chain link updates from L One and makes them immediately available on L2. So there's a lot of different things you can do, but in order to do that, you just need to modify the derivation function. And there's a tutorial in here about how you can modify that derivation function. Yeah, so the question was, if you wanted to index like every block and every you wanted to index every transaction as well, you can index literally whatever you want. Yeah, you could build like a whole block explorer that's actually a roll up. Like a roll up that indexes a whole bunch of stuff on L One and then pipes that data into smart contracts on this layer two. And then the cool thing is that the whole thing is you can fault proof it right? You can run these optimistic fault proof.
02:30:31.224 - 02:31:23.056, Speaker D: So then not only can you have a roll up that's actually an indexer, you can also have smart contracts on layer one that read the data from the roll up and act on that data. So, I mean, it depends on how fast you want your proving time to be. If you're okay with the security properties, you can make it like 30 minutes or an hour or something like that, and eventually you'll have ZK proofs to be able to do the same thing, to be able to prove it pretty much immediately. So the future of this is that you have. These very detailed indexers that then report data back to layer one. So the layer one smart contracts can just access all of the information of every other smart contract in an extremely efficient way. Okay, great.
02:31:23.056 - 02:31:51.144, Speaker D: Wait, what is this? Phase two? Did they change? So here's the other thing about this, is that we're also modifying this at the same time. I'm not surprised if they did not update my no, wait, phase two. Wait, phase two. Oh, okay, wait. I think this is good. I think we're done. We're done.
02:31:51.144 - 02:32:05.244, Speaker D: We're done. Okay, great. So I should just be able to configure this now. Boom. All right, so I have my Genesis JSON file that I just generated. I'm going to generate a JSON web token as well. So I've done that.
02:32:05.244 - 02:32:28.772, Speaker D: I'm going to copy that. So I'm going to copy Genesis JSON into Opgeth. I'm going to copy the JWT into Opgeth. All right, we might not get around to running the batcher, but you'll get there. Okay, now we just initialize Geth. That's easy enough. I just run that initialization thing.
02:32:28.772 - 02:32:59.206, Speaker D: Boom. We're done. Initialized. Okay, so the next thing is to run Op Geth. I just need to export a couple of things into export whatever, come on. All right. We have to automate this a little more.
02:32:59.206 - 02:33:54.540, Speaker D: The thing is, we didn't want to automate the tutorial too much because then people would be really confused about what was happening under the hood. But I don't know, that's the wrong thing, too. Okay. All right, just follow this. Export all the things that you need to export, and the address of the L two output Oracle is the last thing that we need. I don't know why we need this. Deployments getting started.
02:33:54.540 - 02:34:32.150, Speaker D: L two output Oracle proxy. Okay. All right, so hopefully this just works now. All right, so Geth is running. That's simple. And now we just need to run the op node, hopefully. And of course that doesn't work because in a different terminal.
02:34:32.150 - 02:35:07.848, Speaker D: Okay. All right, let me minimize this. So we have the two things running. Yeah, so pretty simple at this point. We have op. Geth running. We have the op node running.
02:35:07.848 - 02:35:44.656, Speaker D: It's essentially iterating over the chain and figuring out when it's just loading bits of the chain right now, it has to catch up. So we're at three, two, seven. I don't know what the current girly, what's the current block? Current block is three nine seven. So if you give it a second, in a few seconds, it's going to start producing blocks. At this point, it's going to start producing empty blocks. And I've been told that we have to kill it there. But if you keep following this at that point, we have a sequencer running at this point.
02:35:44.656 - 02:36:04.100, Speaker D: So then we just start submitting it. You just have to run this batcher program and that's it. You just make sure that the batcher has some ETH, start running, and you have a roll up and then you can do whatever you want. So start messing with it. There you go. It's producing empty blocks. Start sending it transactions, it'll produce non empty blocks.
02:36:04.100 - 02:36:17.160, Speaker D: All right, I'm getting kicked out, but if you want to keep chatting later, go to Stack Optimism IO, have fun, mess around, do crazy stuff and I'll be here. All right, bye.
02:36:44.620 - 02:38:49.720, Speaker A: Sam. Sam. Sam. Sam.
02:39:16.080 - 02:39:17.350, Speaker G: Hello everyone.
02:39:17.960 - 02:40:20.820, Speaker D: My name is Alexander and here's with me my colleague Tima. And we are from Polygonid. And today we will demo you how to issue your first Credential and verify it on chain. So let me first start with what's Polygonid? So, Polygonid is a self sovereign identity solution that is leveraging zero knowledge proof technology for ultimate user privacy. Basically, it is scalable, it is Verifiable on chain and off chain. And we are using Verifiable Credential standards and DIDs. So how it works in general.
02:40:20.820 - 02:41:11.134, Speaker D: So we have basically three parties. It's identity holder, it's the user that is having his Credential. There is always issuers that is issuing Credential. So it's like a source of trust. And Verifier, it's a party that is requesting something from the user, like some statements about user based on credentials that he has. And let's see how it works on example, so a user receives Credential from a university. Let's say that basically it's signed by university.
02:41:11.134 - 02:42:26.410, Speaker D: It's a piece of data in Jsonald format and it's digitally signed by the university. User receives it in his identity wallet and stores on his device. It's not on chain, it's on his device. And then when time comes and when Verifier needs to get some data, verifier asks some questions. And for this we designed a special way of asking questions with zero knowledge proofs. We are calling it ZK Query Language. So Verifier generates zero ZK query and gives it to user and user then scans it with his identity wallet and accepts what he needs to share or to prove and generates zero knowledge proof that is then sent to the Verifier and Verifier just Verifies zero knowledge proof and checks that it's valid.
02:42:28.430 - 02:42:29.180, Speaker C: Yeah.
02:42:29.790 - 02:42:30.570, Speaker A: Oop.
02:42:36.510 - 02:43:16.780, Speaker D: And so it's basically it on high level for the builders. We have mobile application and SDK. We have issuer node for the issuer side and we have Verifier libraries on Holang and on JS to verify zero knowledge proofs and generate Zkquery requests. And also on chain Verifier in solidity. And now to the demo.
02:43:18.030 - 02:43:59.954, Speaker A: Okay, just a second. I'll require for the demo we'll change our screen. Initially, I will start with some explanation of the schemas. So before you will start issuing any credentials you need to build your schema, this is actually the data type or like a schema that you will issue. For example, this can be in this case, in this example, this is Kych Credential. It has two attributes. This is birthday and document type.
02:43:59.954 - 02:45:20.058, Speaker A: You can build whatever you want. Maybe it will be in your case passport Credential and you will put five attributes or it will be I don't know, like my Ethereum community member and it will just with one attribute. But you are free to build your own credentials with your structures, with your attributes and design what actually your specific use case will require and you will need. You see here we are using the XSD types, we're not supporting every types, we're supporting just some subset of types because in zero knowledge proofs well you technically cannot use everything. But for example, we are doing some trick with selective disclosure where you can use string values and then verify the string values with zero knowledge proofs. And with this trick you can use actually any type of values but they will be recognized as a string and you cannot verify and use all the power of zero knowledge ZK query language and for example in on chain verifications you always also will be a little bit limited. But if you are okay with to work with integer values and with numeric data types you are fine and you can just build a lot of use cases.
02:45:20.058 - 02:45:53.720, Speaker A: So we have a tutorials for this. I will not spend too much time for this schema builder just because right now you need to build it manually. In couple of months we are planning to release schema builder application. It will simplify this procedure. So you just in the builder, just select your fields that you need and it just generates a schema for you. So it will be not as difficult as it is right now. So right now let's go to the issue.
02:45:53.720 - 02:46:45.074, Speaker A: This is our issuer node. This is open source, you can download and run it on your local machine, install it on your server or something. This is specifically designed for the issuer actually this is like demo application but this is issuer part, it will be not accessed by the users, it will be accessed by the issuer. So you will issue some specific credentials for your community, for your users, for your different developers or for your specific needs. So here you can import schema. I will show you example. For example this one's fetch it preview so you see all the fields that is defined in the schema.
02:46:45.074 - 02:47:44.570, Speaker A: Some fields are mandatory and they are specific for polygon ID and for verifiable credentials like issuer issuance date, expiration date and you have your custom fields like birthday, document type, maybe credit score and this will be a field that you specifically will define. So as I have this schema imported, I'll go back and we'll issue Credential. So we have two options one, the Credential link. So we create like Credential and send a link to the user so he can download it to his mobile wallet or if we know in advance his identity, we can issue this Credential directly to his ID. But at the moment I don't have my identity linked to this node. So I will use the link. This is a time until Credential will be accessible.
02:47:44.570 - 02:50:13.960, Speaker A: This number of possible issues let's say I will put one I select my type and this is a birthday I will put like 1991 1st month first day document type two and I will create a link so now we'll generate a QR code for the user so he can download this credential by his wallet. I will show my wallet. Okay, so we just scan a QR code and we can get Credential to our phone this time usually I should receive the push notification but maybe because of the connectivity here I just need to scan and fetch it. Okay, so you see I have a Credential with this birthday and document type on my phone now I can go to the Verifier. Let's start with the website this is off chain possibility so you can build the gated access on your website and I can ask hey, I can ask this query, this is a code that is hidden in this cure code. Let me make it a bit bigger so we're asking the specific query to the user wallet so hey, do you have this context like Credential with this context in your wallet, do you have this type KCH Credential? And do you have the birthday field that is less than 2000? So if I match this criteria we can generate a zero knowledge proof that will prove like this request to the Verifier. So Verifier will be sure that all the requirements are met.
02:50:13.960 - 02:51:04.882, Speaker A: So let's try to do this, make it a bit smaller. So you see, we have the request on my phone. He's asking if I have Kych Credential if the birthday attribute is smaller than 2000 and I can generate a zero knowledge proof. It takes some moment. So we generate a zero knowledge proof and send it to the back end. So back end can verify zero knowledge proof. Because it's not enough only to verify zero knowledge proofs.
02:51:04.882 - 02:52:02.644, Speaker A: You need to verify zero knowledge proof. And if it match the request that you asked, so you're matching the request and response all the criterias and you are verifying. Okay? It was used like birthday. This birthday is less than 2000. So here, in token, I can show you the token that was sent to the Verifier. You see we have only some meta information and zero knowledge proof so this is zero knowledge proof that is answering on our question. So as a user, I'm not exposing any personal information to the Verifier.
02:52:02.644 - 02:53:01.610, Speaker A: I'm only generating zero knowledge proof with this answer. So the same thing we can do with a smart contract so the smart contract also can be such a verifier that can ask user to generate a proof and prove him some specific statements. So the same request that we did for the website I can do that for the smart contract and in this case the smart contract will be the same Verifier. But you can build some business logic inside your smart contract. For example, you can build the ERC 20 smart contract which accepts only people who are about maybe like 20 years old or from specific country or not from some other countries like I don't know, China, Russia or something like this. It's very based on your specific requirements for your business logic. So, here is an example of this smart contract verification.
02:53:01.610 - 02:54:18.282, Speaker A: Okay, where is storyt approves? Okay, so the question where is storyt approves? Actually proof is generated every time when we are answering this request and share it with Verifier. So if this is website, it will be on the back end of the Verifier. If this is smart contract, I send the proof to the smart contract and smart contract will verify and they generate it on the flight and every time it's sent to the Verifier. So here we just see I connect to MetaMask. So it's how wallet connect is working. First we're connecting and then generating zero knowledge proof and then send a transaction with approve. So here I generate a proof and send it.
02:54:18.282 - 02:55:30.102, Speaker A: Let's take a look on the MetaMask to wait a second. Success. So what is the request inside the smart contract? It's actually the same but we put this in a QR code to give wallet some explanation. Right now our wallet is not fully supported everything because that's why we need to provide some additional metadata with this transaction data, this address of the smart contract and specific methods that you need to call to share the zero knowledge. But inside the smart contract is stored the same request as we had and the same request is verified inside the smart contract. So your smart contract can build a business logic and verify zero knowledge proofs and can request at different verification spot for the users. And based on this, again you can build like shielded access, maybe some business logic, maybe you give to your community members some additional preferences.
02:55:30.102 - 02:56:27.274, Speaker A: So what you can do, you can build like off chain for your community members, issue credentials that they are your community members. And then when you will do a token distribution for your community members, if they can prove this to the smart contract, you will add some, I don't know, additional values of the tokens or distribute some additional preferences in your smart contract. Also we can build owner transferring only if I send a specific zero knowledge proof to the smart contract. Then you can change the owner of the smart contract. So this is query language is flexible. You can build your own business logic and just extend the possibility of smart contracts with some additional business logics that will be embedded in the zero knowledge proofs. What's cool about this that your identity in a different smart contracts will be different.
02:56:27.274 - 02:56:54.200, Speaker A: For example, you can reuse different verifications but your identity will be not tracked in a different smart contract. The same you can do with the same smart contract. For example, the same verification can be used with a different Ethereum address. So your identity kind of decoupled with your Ethereum address. That's why you can reuse verifications, you can reuse credentials and well.
02:56:56.170 - 02:56:56.738, Speaker H: The sky.
02:56:56.754 - 02:58:00.830, Speaker A: Is the limit of what you can do with query language and with these verifications okay, yeah, that's it for the presentation. We will not go too deeply in the smart contracts and in the circuits just because we have very little limited time. So maybe have some questions. Clarifications yeah. Do we have a specific type of proofs? So our circuits, they're kind of generic, you don't need to write your own circuits. What you need to do, you need to define only schema for your credentials and you can use this query language with your specific credentials. So the type of proofs we have like four different circuits with a different type of kind of proving.
02:58:00.830 - 02:59:01.646, Speaker A: So we have two type of proofs. One is a signature, which is just a signature and also merkel tree proofs. So for the mercury proofs credentials must be published on chain and tanker on chain. So this is two type of proofs for them we have different circuits but query language and the rest of the stuff is generic. So you don't need to do anything like to write your own circuits or write your own proofs. Everything is written and embedded in the libraries and you can just reuse all this functionality. Technically you can extend this functionality if you need for your use case, if you want to write your specific proofs based on our identity system this is possible, but this is baby job job signatures used like well, we're using baby job keys specifically to prove something inside the circuits.
02:59:01.646 - 03:00:32.890, Speaker A: So this is specific babyjabjab key that you need, but yes, it is ECDSA you cannot use Ethereum keys for these type of signatures. You need to derive different type of keys. This is like they are on a different but this is working with Ethereum, with polygon, with any EVM compatible chain and kind of the pluggable system where you can build your use cases. So we have actually all the parts of the flow like for the Eshare, for the Verifier, for the user, for the user, for the wallets we have the SDKs, for the eShares we have all the libraries GSDk that if you want to build your own node you can do this. For the Verifier we have verification libraries written in Goa and JavaScript. So cover majority of the cases and again you can write your own if you wish or if you need for the smart contracts. Also, we have some common smart contracts with some standard interfaces that you need to inherit for your specific smart contracts.
03:00:32.890 - 03:01:18.780, Speaker A: They're extending the functionality with ZK set request and set response functions that you can replace or rewrite or build your own specific business logic and verify zero knowledge and verify your specific cases and verify your specific requests that you will do. Because actually in one smart contract you can embed multiple verifications. It should not be just one. Like I want to know your age. Maybe I want to know your age also that you are community member. Maybe if you are participating in my Dao activities, maybe you are like GitHub contributors and so on. But this is specific for the specific implementations that will be built on top.
03:01:18.780 - 03:02:32.724, Speaker A: So, any other questions? Good. So, last thing if you are curious, we have tutorials on our polygon website. Zeroix polygon, ithavio IO and all the things that I showed they are available there. You can just pause the tutorials and you will have the same result. Good. Thank you. Sam.
03:02:32.724 - 03:02:57.460, Speaker A: Sam.

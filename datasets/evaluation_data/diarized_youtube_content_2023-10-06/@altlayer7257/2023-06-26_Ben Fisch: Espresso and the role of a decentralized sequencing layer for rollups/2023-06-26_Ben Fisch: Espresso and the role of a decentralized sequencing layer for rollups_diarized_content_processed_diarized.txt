00:00:00.410 - 00:01:23.414, Speaker A: Sarah. Can everyone hear me all right? Okay, great. So I'll be talking about Espresso and the role of a decentralized sequencing layer for rollups. And I am Ben Fish. I'm the CEO and co founder at Espresso Systems, and I'm also an assistant professor at Yale It. So, first of all, it one way to think about what roll ups are able to provide for the ecosystem is horizontal scaling. And so we can think of this as every application that couldn't exist on a layer one blockchain can actually run its own roll up.
00:01:23.414 - 00:02:18.230, Speaker A: We can also have applications that support other applications on top of them, like VMs or Zkevms being run by companies like ZkSync or Optimism or Starkware, et cetera. But we can think of this as essentially a way of sharding computation across applications so that the layer one nodes only need to verify. These lightweight do, this lightweight verification of either fraud or ZK proofs. But the actual execution of transactions for a given application is done by the application itself. Okay? And it's a slightly different way of thinking about the role of approver. You can just think of the proverbs being associated with the application. The provers of optimism are associated with optimism, which really is an application that represents a VM that hosts other applications.
00:02:18.230 - 00:03:33.474, Speaker A: The other key thing about why roll ups actually help scale blockchains is they leverage heterogeneity. Roll ups wouldn't help as much if all nodes in the system were of equal computational power. They're leveraging the fact that they're actually, especially in the case of ZK roll ups, increasing even the work of some nodes, the powerful nodes that are doing the computation and producing the proofs while making it easier for the weakest nodes of the system to verify the results. So the layer one nodes can be very weak, and we don't get bottlenecked on the weak nodes, whereas at the application layer, the nodes that are actually executing transactions for a given application can be very powerful and we don't need to have as many of them. They don't need to be as decentralized. In fact, the problem is that today, because roll up servers are playing such a monolithic role, they end up controlling too much. So the application layer is not just executing transactions, but it centralizes the entire process of deciding which transactions to include and in what order.
00:03:33.474 - 00:04:44.360, Speaker A: And this loses the whole set of properties that blockchains were achieving in the first place by virtue of their decentralization. So it can lead to censorship, lack of neutrality, it can lead to monopolistic pricing by the servers that are carrying out this entire centralized process. Essentially the way that roll ups look today with centralized servers that are doing both the proving and the entire process of deciding which transactions to include. The L one is just now auditing the integrity of what are essentially web two applications. So we've removed the major role of the decentralized layer one to decide and manage the process of which transactions get included in what order. And they're now just verifying and following along what each of these web two applications are doing. And so that's not a good situation to be in.
00:04:44.360 - 00:05:51.650, Speaker A: So the solution is to separate ordering from execution. And the simplest way to think about this is that the architecture that would save us from this situation is if users would submit transactions directly to a decentralized l one. The L one would only order and make available the transaction data. It wouldn't actually do any of the, it would not execute, right? And then the application layer would just read from the layer one and every application specific server would execute the transactions for that given application and prove the result and state update to the layer one. So this has also been called based roll up which is a relatively new term. But in many ways this is sort of the purest of ideas for roll ups where the layer one is still doing most of the job. It's just that the roll up is only doing the execution.
00:05:51.650 - 00:07:07.466, Speaker A: Users are submitting transactions directly to a consensus network that in a decentralized way is ordering them and making them available. Roll up servers just read from this, do the computation and produce an update. Now, there could be a reason to separate out this transaction ordering and availability layer into what we might call a layer one and a half which would sit between the layer one nodes and the application layer servers that are executing transactions. And what might be some reasons to do that? Well, first of all, protocol modularity and just as protocol modularity for data availability makes sense, right, the protocol that we design to optimize for ordering and availability of data may not need to be the same. That is running the l one and handling the smart contracts and the bridges and verifying the proofs. I'll talk about protocol modularity on the next slide too. In light of things like Eigen layer, we may not even need to think about this separate layer as a separate physical layer.
00:07:07.466 - 00:08:07.534, Speaker A: It may just need to be a separate logical layer. And second is there is an opportunity to make different design trade offs from the l one. So for example, we could design this ordering and availability layer to have higher throughput and lower latency but sacrifice on things like dynamic availability which in the case of Ethereum is one of the main properties that Ethereum's consensus protocol achieves at the sacrifice of other properties. So, as I mentioned, we can think of this layer one and a half that's doing transaction ordering and availability as not necessarily even a separate physical layer. It could be run through services like Eigen layer that enable this by the same set of physical nodes that are running the layer one. Or at least you could subsidize the participation of the physical nodes that are running the layer one. But logically it is separate.
00:08:07.534 - 00:09:25.582, Speaker A: And it could be a separate protocol that operates differently from the layer one's main consensus protocol. A second problem of the layer two ecosystem, the roll up ecosystem, which has less to do with the lack of decentralization and more to do with the sort of a fundamental trade off that happens when you Shard computation is that the liquidity or interoperability becomes fragmented too. So applications on different roll ups are now isolated from each other, whereas when they were all running on ethereum, they were not isolated from each other. And this makes various things like atomicity flash loans, et cetera very complex to impossible. So Bridging becomes complex, certain forms of interoperability are now lost. Liquidity is fragmented. So we can ask to what degree does sharing a sequencing layer and when I say sequencing, since this is an overloaded term that some other people in the industry may use differently.
00:09:25.582 - 00:10:20.500, Speaker A: But if we talk about sequencing as just the layer that is in charge of determining and finalizing the ordering and availability of data, does sharing that layer help with interoperability? So I will discuss three advantages of doing so. The first has to do with partially simplifying cross roll up Bridging anatomicity. The second has to do with mitigating systemic security risks of bridges for the roll up ecosystem overall. And the third has to do with cross roll up building. So let's talk first about partial simplification. So in general, bridges require two atomic legs. You have an asset that is locked on some roll up A and then a representative would be minted on some roll up B.
00:10:20.500 - 00:11:35.210, Speaker A: So let's consider a scenario one where roll up A and roll up B are utilizing different sequencing layers, in other words, different consensus protocols for finalizing their transactions. In that case, in order to implement a bridge, roll up B would need to verify both the inclusion of the lock on roll up A and also its validity. And verifying inclusion means that Roll up B needs we would need to implement in roll up B in the bridge contract on roll up B, some way of verifying the consensus of roll up A. In scenario two with a shared sequencing layer, part of this goes away, right? So now roll up B only needs to verify the validity. It needs to verify the validity. And that could be not by executing the transactions itself, but more likely by verifying a proof from roll up A, whether it's whether if it's an optimistic roll up, it would be receiving it and waiting for the challenge period and then possibly verifying a fraud proof. But if not, then if it's a ZK roll up, then it could be verifying the ZK roll up proof directly.
00:11:35.210 - 00:12:37.162, Speaker A: That still needs to happen, but it no longer needs to implement anything to verify the consensus of Roll up A because they're sharing a consensus and essentially the lock and mint transactions are just in the same transaction bundle that was processed by this common shared sequencing layer. So the second thing I want to talk about are security risks of bridging. In general we can ask what actually goes wrong when consensus protocols are compromised. How can an attacker profit? By attacking a consensus protocol and reversing the finality of transactions. Of course that's an inconvenience overall. But is there a way an attacker can profit which this thus gives it an incentive to attack the protocol? Often the way in which attackers profit is through some form of taking advantage of a bridge that exists. So bridges offer the clearest example of profitable attacks.
00:12:37.162 - 00:13:53.378, Speaker A: An attacker can lock an asset on chain A and then mint on chain B reverse the finality of the lock on chain A and now it has doubled its holdings. The common example of you could send an asset to a centralized exchange, withdraw fiat and then reverse the send is actually an example of a bridge. It's a bridge between a blockchain and an external system which is part of the centralized world, but it's still an external system. Sending money to Amazon to purchase a good and then reversing the transaction on the blockchain is another example of taking advantage of a bridge because it's a bridge between Amazon's system and the blockchain. If everything stays within the blockchain, it's harder to profit from reversing the finality. So of course there are always going to be opportunities for profiting by reversing finality. But if you have many, many roll ups that all have bridges between each other, then it massively increases the profit opportunities for the attackers of consensus protocols that are controlling the transaction orderings and these different roll ups.
00:13:53.378 - 00:15:15.810, Speaker A: And when roll ups share an ordering finale layer, the attacker cannot profit. In this way, reversing the lock on one side of a bridge will also reverse the mint on the other. And finally I want to talk about the advantages to cross roll up building. So when roll ups use different sequencing layers, then a builder who's trying to build blocks simultaneously for multiple roll ups faces complications, high risk and generally slim chances of success. For example, it would be difficult for a roll up to make some kind of economic commitment to its user that it would get slashed if it doesn't include both legs of some kind of arbitrage transaction. Because it's always possible that one of the blocks that it proposes gets accepted and the other one does not because it's dealing with two different consensus protocols now with a shared sequencing layer, because the consensus simultaneously proposes and finalizes without executing, but proposes and finalizes a super block for all the roll ups running on it. Then through proposer builder separation, a leader in consensus may accept from a builder simultaneous blocks for one or more roll ups.
00:15:15.810 - 00:16:19.686, Speaker A: And therefore a cross roll up builder can guarantee any user desired atomicity from flash loans to arbitrage. And it can post bonds which would get slashed if it violated its promise of some form of atomicity to the user. And shared sequencing enables an honest builder to be certain that if it behaves correctly, it won't get slashed. So finally, I want to conclude with some open questions and challenges of shared roll up sequencing. One challenge that arises is around revenue sharing. So how is revenue shared among roll ups that share the same sequencing layer? It's very straightforward for basic fees. All the fees that users are paying on transactions destined for a particular roll up can be attributed to that roll up.
00:16:19.686 - 00:16:57.650, Speaker A: It's very easy to attribute what the marginal contribution of a roll up is to the profit generated from basic fees. And in fact, the fees can even just be directly encoded and paid directly in each roll up itself. It doesn't even need to go necessarily through the sequencing layer and the roll ups can pay a commission to the sequencing layer. There's many different ways that could be handled. That's not a hard problem. The much harder problem is figuring out how mev gets shared. There's maybe less of a concern for rollups that want to mitigate mev and I'm going to talk about mev mitigation on the next slide.
00:16:57.650 - 00:17:50.690, Speaker A: But setting that aside, let's say that rollups do want to profit in some way from mev or get a share of the profit from mev. Well, the marginal contribution of each rollup to mev is not transparent. In fact mev. There is no real public deterministic function that you can just run on a given ordering to determine what the mev is. Rather, mev is typically based on private information available to various actors in the system and is only discovered by running auctions and figuring out what different actors will to. You might think we could simulate the auction with each roll up independently, but it's very hard to simulate an auction truthfully if it's not being run for real. So this is a hard problem and leaving it as an open question that needs to be solved.
00:17:50.690 - 00:19:10.650, Speaker A: The second open question that I think is very important and interesting is whether shared sequencing layers can be mev mechanism independent. So there are many different approaches to addressing mev and it can be a matter of philosophy, right, from optimizing it and democratizing access to mev to preventing it entirely, whether you believe that's possible or not. So there are many examples of approaches from auctions to first come, first serve ordering protocols, threshold encryption protocols, time delayed, permutations et cetera. Some involve various assumptions, such as honest majority assumptions. So the question here is whether a sequencing layer that is shared by multiple roll ups can be agnostic to the mev mechanism favored by each roll up. It could be quite simple, I think, for threshold encryption, because the roll up could introduce its own separate threshold encryption set and all the inputs that come to the shared sequencing layer are threshold encrypted, but it may get more complicated when we start considering other types of mev mitigation approaches. So I leave it as an open question whether shared sequencing layers can truly be mev mechanism agnostic.
00:19:10.650 - 00:19:28.620, Speaker A: In any case, these are all problems that we are working on in Espresso systems. Espresso is developing a shared sequencing layer for the roll up ecosystem, specifically focusing on Ethereum today. So thank you very much. That concludes my talk.

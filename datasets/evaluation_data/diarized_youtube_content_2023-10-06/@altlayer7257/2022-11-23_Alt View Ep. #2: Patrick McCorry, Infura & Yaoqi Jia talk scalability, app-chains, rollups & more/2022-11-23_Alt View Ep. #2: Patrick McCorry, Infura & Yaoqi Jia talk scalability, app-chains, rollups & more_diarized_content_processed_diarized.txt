00:00:10.250 - 00:00:45.830, Speaker A: Yeah. Hello, everyone. Welcome to Alternative view, or simply outview. At Odview, we chat with industry leaders to get to know them and also their opinions and insights on sort of all different sort of aspect exo of crypto industry. And these views may be popular, unpopular, brand new or alternative, or anything in between. And I'm your host, Yaoji from earlier execution layer on ethereum for web3. Today, it's our great pleasure to have our guest, Patrick.
00:00:45.830 - 00:01:30.440, Speaker A: Patrick works with infuriate these days, but he's also quite famous in the academia. He's teaching a lot of these crypto courses in the universities and at the same time his expertise in cryptocurrencies, smart contracts and also applied crypto. He's sort of like the UK's first PD graduate student in the cryptocurrencies, and his work has recently appeared in lots of major conferences. And, yeah, again, welcome, Patrick, and really thanks for being with us. And can you also tell us a little bit more of yourself and also, what kind of stuff are you working on at the moment?
00:01:30.970 - 00:02:13.106, Speaker B: Yeah, I can give a brief intro if you want. Thanks for that, by the way. So basically, my journey in cryptocurrency started back in 2013. I was an undergrad at Newcastle University and I did a cryptography course. And cryptography was really hard because I'm really bad at math and I remember know I would like to do a cryptography PhD so I can get better at math. And so I met my advisor at the time, he was called Fong Hao, and I was, you know, I'm doing a crypto PhD, can you help me? Then he told me about this thing called bitcoin being used in the dark web to buy drugs and maybe a cool thing to look at because it's a cryptocurrency. So I looked at it and there's very little cryptography in it at all, just hash functions and signatures.
00:02:13.106 - 00:02:51.746, Speaker B: But it was a really cool idea and that's how I went down the rabbit hole. So from like 2013 to 2016, I was mostly working on bitcoin. And then around 2016, I moved on to ethereum because I saw this paper at this conference called Financial Cryptography, and there were these PhD students presenting about the papers called a step by step towards secure, smart contracts. And they build this application called rock, paper scissors as a smart contract, which is actually really hard to do, by the way. I always use rock, paper scissors as a challenge for students. But after watching that talk, I thought, wow, this is really cool. I've been spending three years trying to design stuff on bitcoin and it doesn't work.
00:02:51.746 - 00:03:23.478, Speaker B: You're just like punching it in the do anything you want where they manage just to go build this within like a day or two. And so that's where I got my first intro to Ethereum. And then generally throughout these years, I did research. I was a postdoc for a while, some UK university, and then I was an assistant professor. Then I left and tried to do a startup. And then that's how I ended up in inferior because they just acquired the software. So throughout this time, I've always had this large interest in scalability solutions.
00:03:23.478 - 00:03:35.220, Speaker B: So I remember back in 2015 when Joseph Poon came out and pouch came out with the Lightning network paper. Yes, it was very difficult to read. I don't know if you ever tried to read it. Have you tried to read it? The Lightning network paper?
00:03:35.590 - 00:03:42.050, Speaker A: Yeah. And after that, there's another one, right. I think around this plasma or some other new ideas.
00:03:42.630 - 00:04:10.860, Speaker B: Joseph described that as aspirational in his writing. But generally, I remember the lightning paper was a really cool idea. And the first thing I tried to do was summarize it. So I wrote this little paper in 2016 that tried to actually define how you would do a lightning channel. So I had a huge interest in payment channels and then side chains and then plasma, and then. Now roll ups exist, and roll ups are really exciting. They're sort of the pinnacle of what we've all been trying to achieve for about six, seven years.
00:04:10.860 - 00:04:52.620, Speaker B: So I guess just to move on to what I'm working on now, because it sort of leads into it quite well. What I tried to do last year was I've been trying to simplify the language and the mental models around l two or roll up specifically, because every time I talk to some teams or individuals, they're always a bit confused about what a roll up is really trying to achieve. And really under the hood, it's just a bridge. You're bridging assets to an off chain system and you want to make sure that your funds are safe. That's all a roll up is really trying to achieve. That was like a big thrust that I was trying to achieve last year, and I've been trying to do it this year as well, with some presentations, and I've also been doing these educational courses. So I did this online cryptocurrency class.
00:04:52.620 - 00:05:17.226, Speaker B: I think we had about 800 people active at the time when I did it. It's sort of hard to judge. You have all these poop farmers who was just committed asking, but I think after I distilled those, I think we had about up to 800 people, maybe average three to 400 people per class. That was really nice. That was very much very technically focused about Ethereum and cryptocurrencies. And again, roll ups. And generally I feel like I always make this joke.
00:05:17.226 - 00:05:28.760, Speaker B: I'm like this private oracle for inferior teams in the space. People just ask me questions and I try to answer them for them. So I don't know, I like to help other teams out there when I get the chance. So I guess that's what I'm working on right now.
00:05:29.370 - 00:06:04.660, Speaker A: Yeah, super amazing experience. And yeah, as you mentioned, you spend a lot of time researching all different scaling solutions for blockchain space. And in Devcon you also have sort of 1 hour session to talk about how to scale Ethereum. Can you share a little bit more about your study around that? The ways, different ways to scale Ethereum in the past and also the present? Yeah, it doesn't matter, probably not Ethereum or some other.
00:06:08.310 - 00:06:53.658, Speaker B: Yesterday, that generally when I try to do work, I try to do it in a generic way. So it applies to most blockchains because I think that's really important. I started in bitcoin, now I work on Ethereum, but a lot of these blockchain systems are very similar. So it's very important to look at from a generic perspective and not just how does this opcode work, because then you end know just the technical difficulties of a platform. So the skilling Ethereum workshop was actually something the EF asked me to do last minute. They sort of just ping me like the week before being like, oh, you want to run this hour workshop at Devcon about skilling Ethereum? And I'm like, oh, okay, sure, I'll put this together. But generally when we think about scalability, I guess there's two to three different ways to think about it.
00:06:53.658 - 00:07:41.082, Speaker B: One is can we just crank up the parameters, increase the transaction throughput and just make it really cheap for everyone? That's the first, can we just blow it up? The second one is can we shard the network? So the idea is that you have a list of validators and can you split the work across them? So validator a does some work, validator b does some other work, but they don't do the same work. And so you distribute work. So not everyone's doing the same work is distributed. But the problem of both of those approaches is mostly, well, one, TPS is a terrible metric. And anyone ever kicks, my class will know that we should never ever measure a system based on TPS. I hope that's not in your marketing materials by the way. But the best way to think about scalability are three different resources.
00:07:41.082 - 00:08:26.522, Speaker B: One's compute, how much computation can be supported by the network. Two, storage. How big do you want the database to get? That database keeps growing and eventually not a lot of people can hold it. So I think at one stage an archival polygon node was growing by two megabytes a second and you can imagine exactly explodes and eventually doesn't fit on AWS anymore because it's just too big. Three is bandwidth. Given the peer to peer network that you have, how quickly can you send a transaction across the network or a block across the network? If it takes ten minutes to get a block across but you have 13 2nd block times, well, people are going to start falling behind. So those are the three researches you have to care about, compute stories and bandwidth.
00:08:26.522 - 00:09:07.450, Speaker B: And alongside that you need to decide who do you want to participate in the network? Who can be a block proposer, who can transact in a network, who could download the database, who could check the database. The entire cryptocurrency field is about trust per verify. We trust the block proposers to order transactions, but we verify everything they do. And the verification bit is really the bottleneck to scalability. We have to make sure that we have to artificially constrain the compute stories and bandwidth to allow people at home to verify the network in real time. I guess the real bottleneck there. So there's a step back a bit.
00:09:07.450 - 00:10:11.546, Speaker B: So the issue is that we can't just increase the parameters because then we kick people off the network. We could try to do sharding, but sharding is sort of the same problem where eventually it gets too big anyway and also it's very difficult to implement. So the third way to scale the network is really to do these off chain protocols and it's really again about could we have a base layer, the settlement layer, like ethereum or another network that holds all the assets and everyone can check that that system is fine and well and correct and well maintained and decentralized. Then could we move our assets to an off chain system without having to trust that off chain system? And that's sort of the goal of the roll up centric roadmap. I can move my arbitram, but I don't have to trust arbitrum of my funds. And by doing that then on arbitram you could take the first two approaches, just scale up the resources because they have a very different trust model there, and it can very much be a very heavy duty machine that runs that system. So that's sort of, for me, scalability, just in a nutshell, is all about bridging.
00:10:11.546 - 00:10:21.330, Speaker B: We just need to build really good bridges to move our funds from blockchain a to blockchain b. And that's really at the heart of all scalability. And of course, those three resources.
00:10:22.390 - 00:11:31.546, Speaker A: Yeah, totally agree with you, especially when you mentioned the compute, storage and also bandwidth. I think it's not just like sort of the limitation for blockchain. I think you can also apply this to the traditional web two world is like in crypto, right? We have multicentralized network, and then on top of this, we know that recently there are hot topic around this monolithic and the modular blockchain. Right? And also in your talk, you mentioned about in the early days, we mainly talk about scaling ways for the monolithic blockchains, right? As you mentioned, probably we can have better hardware and we can have better consensus algorithms to precise as many transactions as possible. But right now, we are sort of trying to find ways to create these modular blockchains. Either these roll up ways to do this option computation, but we have some settlement on the l ones. But for the past few years, we tried all different ways.
00:11:31.546 - 00:11:40.380, Speaker A: Why do you think the current way, like the modular blockchain, is a better way to scale compared to this kind of monolithic way?
00:11:41.790 - 00:12:26.506, Speaker B: Just alluding to what you're saying for the monolithic blockchains, we've been trying to scale a one big blockchain for many years that was sort of at the heart of the block size wars as well. Back in 2015 with bitcoin, should we have a 1 mb block, or a two megabyte block, or an eight gigabyte block or gigablocks? And that was really the issue there, was that we just considered the one blockchain as monolithic, and we have to consider all three resources within that one entity, compute, stories and bandwidth. And we know that we just can't scale it that way because it just kicks people off the network. It just becomes, basically becomes a centralized database. Because not anyone can. That is correct. So for the modular approach, I mean, I made this joke during the scaling Ethereum workshop, but I think it's a great way to describe it.
00:12:26.506 - 00:12:50.766, Speaker B: All we really did was rebrand those three resources. So if you consider compute, compute becomes an execution layer. How much execution can we do for the contracts? Storage becomes a settlement layer. The storage is the database of all the assets. And so that's storage layer, that's a settlement layer. That is also the truth of who owns what funds. And finally, bandwidth.
00:12:50.766 - 00:13:27.422, Speaker B: Bandwidth is the data availability layer. How much data can we send across the network so that everyone receives it in a timely manner? And that's all the network really guarantees, by the way. We don't guarantee historical data is around, we just guarantee that data was published at a certain time and anyone could have got it at that time. But what's nice is by separating it out to compute the execution layer, storage, the settlement layer, and bottom of the data availability layer. By making these layers, it gives you like a much more focused goal on how to solve the problem. So now we can have an entire blockchain system, maybe something like Celestia, which is just data availability. And that's the only thing they focus on.
00:13:27.422 - 00:14:14.240, Speaker B: Settlement layer would be Ethereum, which is my bias opinion anyway, which would be minimal compute basically enough execution to deal with the bridging the bridge, but otherwise it holds all the options. And then the execution layer are the roll ups or these off chain systems. Even your startup is really focused on the compute layer. Could we launch this, do as much computation as we want, and then eventually settle back? Yeah. So I think by separating out these three layers, it makes it much easier for us to actually think, well, we can actually build another system that solves this problem. So I feel like it's actually really nice mental model we use. So I do like the modular description for how we can solve these problems.
00:14:14.930 - 00:15:03.580, Speaker A: Yeah, as you mentioned. Right. So right now we sort of position the traditional, these three pillars, right. The compute, storage and bandwidth into this execution, settlement and data availability layer. And apparently Ethereum right now is positioned as the settlement and the data availability layer for most of this execution layer, or we call roll up solutions. Right. And how do you feel about the current roll up space, for example, the optimistic roll ups and ZK roll ups? Do you feel like they have achieved sort of some promises we previously saw and what kind of drawbacks you feel that they have at the moment?
00:15:03.950 - 00:15:33.954, Speaker B: Yeah, I mean, I love and hit them. I don't know. I think there's a love hit relationship. We just step back a bit. Looking at the roll up evolution, we had the v one rule ups last year, which was like the ZK sync and the Starkx. They only support payments, transfers and swaps, basically a single state transition, basically no smart contracts, such that as long as we did something, we both ended up with a balance at the end and they worked really well. For the most part, DyDX was fairly popular, ZK sync was fairly popular.
00:15:33.954 - 00:16:12.020, Speaker B: It sort of solved a very nice niche there. But the issue was that we needed to do more than just payments. If we want to really build the long term dream of a roll up centric room up, we need to support smart contracts off chain. And that's what all the V two roll ups are trying to achieve now, to be much more general. So both optimism and arbitrary, it's basically go Ethereum, they're running. It's the Fuma EVM they can support alongside their own additional features. You have the ZKE evms coming out, or the zkvms, which is again, just a different crazy experimental machine like Caro, like a very funky register based system.
00:16:12.020 - 00:16:40.390, Speaker B: It's crazy that something like Ethereum can check the proof and keep that accountable. So now the V two rule apps are coming out and they're trying to be much more general purpose. But I think what I get annoyed about with all these roll ups is, again, there's three problems to consider. So one is how do we guarantee the data is available? So it's one on this party copy of the database. Everyone solves that by posting it to Ethereum. That's fine, that's easy. We solve that problem, the next one's like the state transition integrity.
00:16:40.390 - 00:17:21.494, Speaker B: How is the bridge convinced that this off chain database is correct and well, and all transactions are valid? The protective funds on the roll up. And again, that's like the fraud proof versus the validity proof. That's fine. That's the biggest thing everyone talks about, and that's being solved. But I get really annoyed about is the last as a censorship resistance, that entire system, all the operators go offline. How do we guarantee we can get our funds out? And that's actually the difference between a side chain, we can call it, or a layer two. So the original side chain paper in 2014 by blockstream, it couldn't solve the liveness issue, it couldn't be censorship resistant.
00:17:21.494 - 00:17:56.978, Speaker B: If the other system went offline, then all your funds got stuck. And the problem I'm facing now is with a lot of these roll ups, they're not going to be censorship resistant from the get go because it's too difficult or too hard, or they're just not ready for it. And so really they're just like vanity projects in that sense. They're just like these vanity side chains that are pretending to be layer twos. As a community. We need to call them out more on that, because it's ridiculous that they're not building these censorship resistance systems and don't place enough emphasis on it. So I get really annoyed at them when I talk to them.
00:17:56.978 - 00:18:16.540, Speaker B: I'm just like, why are you not doing this? This is like the whole point of a roll up is to guarantee that my funds are safe even if the system goes offline, and many of them won't be when they go live. So that's my biggest problem with them. But otherwise I do like what they're building. Of course, if I was going to pick one thing that I really get annoyed at is that.
00:18:17.390 - 00:18:30.400, Speaker A: Yeah. Regarding the sort of the censorship issues. Right. Do you think if we have better decentralizations of the sequencers approvers, it can be improved for this kind of issue?
00:18:32.130 - 00:19:10.810, Speaker B: I think for censorship resistance, and I'll get to the decentralization aspect as well. Before we go into that, let's talk about the here are the agents in a roll up, like who's involved in the protocol? So as you mentioned, we have sequencers and we have these provers, executors. I'll just call them executors because optimistic roll apps don't do any. Proving the sequencer is responsible for basically taking users transactions, ordering them for execution, and then passing them on. It's basically like the front end. If you're going to build like an application, it's the front end. You built this website, it can take all the transactions and then eventually send them to the back end.
00:19:10.810 - 00:19:50.674, Speaker B: This back end is either the bridge on Ethereum, or it will send it directly to the executors or the provers. Then the provers will get the transactions, execute them, then eventually propose an update to the bridge and say, bridge. Given these transactions, this is what the database looks like. So you have the front end component, you have the back end component, sequencer, executor. So in terms of being censorship resistance, or being censorship resistant, or at least protecting users when the system goes offline, the sequencer should have nothing to do with that. It's a front end component. It has absolutely nothing to do whatsoever with the system being censorship resistant.
00:19:50.674 - 00:20:34.850, Speaker B: They're just like offering the fast path, a Gucci experience for people they're willing to serve. In terms of being censorship resistant, what really matters is one a user can send their transaction directly to the bridge and they can bypass. We call that forced inclusion. As long as they can send it directly to the bridge and get it ordered for execution, then we've solved that part. The second part is we need to get that order transaction executed so how do we do that? Well, we need one honest executor. As long as there's someone out there willing to pick up the transactions, execute them and tell the bridge about it, then we get a censorship resistance system. So what you really need is force inclusion and one honest executor.
00:20:34.850 - 00:20:59.950, Speaker B: And that's very different, by the way, to like a layer one blockchain. Normally you rely on this honest majority of all the validators here. We're just relying on one party to keep the system safe. And that's really important for what it means to be decentralized. It means a sequencer could be centralized, it could be federated. The sequencer set doesn't have to be that big, because it's really just about user experience. It's the executors that have to be decentralized.
00:20:59.950 - 00:21:27.240, Speaker B: We need to think of some protocols where it's rate limited, so not everyone can do it, because otherwise you get spam. But it's easy enough for an honest party to come along and participate. And so I like to make the joke that what we really end up with is a centralized front end, but there's decentralized backend, and that's really the difference between a roll up and something like Coinbase, because Coinbase is also centralized in the back end as well, where now it's decentralized backend. And that's really cool.
00:21:27.930 - 00:22:01.714, Speaker A: Yeah, I fully agree with you. I don't think it's a corner case, because right now it's becoming more and more common. There are some native assets on the L two, and then basically, once you don't have proper execution on the L two, right. We don't really have the direct channel to bridge these kind of native assets on l two to l one. Yeah, that's something. Probably the existing bridging system for the roll up articles, they don't have, as you mentioned. Right.
00:22:01.714 - 00:22:28.534, Speaker A: If some eyesights, we sort of bridge to the l two via some, the l one contract, and later even the sequencers or executor sort of down. Right. We can still send the direct transaction on the l one ethereum to sort of exit the assets. But if it's native assets on l two, I don't think right now we have a lot of channels to exit.
00:22:28.582 - 00:23:10.234, Speaker B: There will be ways to do that. Basically with the roll ups, what they have, the guarantee is liveness such that transactions will always eventually get executed, such that you can take your funds out of a smart contract and then withdraw to the system. So if you deploy like an ERC 20 to an l two. You just need to make ERC 20 has additional functionality so that the ERC 20 contract can send an l two to an l one message to say, okay, I exist in L two. I've never been deployed on the l one before. Here's a message directly from the l two to the l one to deploy my smart contract there. Yeah, there's lots of implementation issues around that.
00:23:10.234 - 00:23:33.040, Speaker B: For example, it might be a different contract address. Maybe they're not using the deployer and it's like a different contract address. It's very awkward for nfts as well because nfts are. You'd have to physically burn the NFT on the. So there are lots of awkward things around that. But I know there's teams, they are working on that because it's a very important problem for them.
00:23:34.870 - 00:24:21.034, Speaker A: I can sense that. Yeah, sort of like beyond this general purpose l two s, right. We feel that it can rescale like l ones, for example, ethereum. Beyond that sometimes, as you also mentioned, we probably have a lot of application, like the front end stuff. Right. And then for the applications right now we have some application specific roll ups to solve the scababilities issues of these applications. And do you think this kind of application specific roll ups can be a good way to scale the Dapps in the near future? Because for the past two years we saw like x infinity, Dydx and some other upcoming games.
00:24:21.034 - 00:24:39.558, Speaker A: Right. They have million of users. Definitely if you put them on general purpose l one output, probably they will just congest the network. So that's why they either work on app chain or work on sort of roll up. But do you think the app roll up can be a better sort of solution for them in the long run?
00:24:39.724 - 00:25:17.540, Speaker B: Yeah, I think there's several reasons why. I think if you just think about were like one, roll ups were very know, ZK sync only supported payments. Starkx immutable, so rare Dydx, they're all know NFT based or trading know. So that was like, there's already evidence to say that that does work and that does get popular. I have some normie friends who aren't really in the crypto, but they went on, I think they went on immutable and they bought some fantasy football players. So clearly there's demand for that. I didn't understand why they did that, but there's demand for it.
00:25:17.540 - 00:25:49.530, Speaker B: So I think that's like empirical evidence to say this does work. So the next question is where does this fit in in the wider picture? At least in my perspective at the moment. For me, this is like the l three narrative. So the idea is that you have the l two, we can bridge ourselves onto that. And then on the l two, it's very general purpose. This could be like Coinbase, for example, uses all your assets are there, you're trading back and forth. But an l three is really where you deploy another bridge and then you can move your assets to another system.
00:25:49.530 - 00:26:16.626, Speaker B: So, for example, if I was an arbitram, I could then bridge to another off chain system that's know, run by you guys. You control the this, you have control over the user experience for your users. So I guess, actually, let me step back. There's two reasons. One, what's nice about these roll apps is that the company who's running it has control over the user experience. So maybe they just want to support nfts. That's all they care about.
00:26:16.626 - 00:26:55.662, Speaker B: They can run the sequencer, they can own that user experience. And two, they can build their software for that one specific purpose. Now, if they really want to reduce the data cost, if you're doing a roll up, they can optimize the data for that one specific application. The second one is burst traffic. If you're doing like an NFT drop and there's going to be, I don't know, 30,000 transactions within five minutes, well, you need to make sure you can handle that amount of traffic within a short period of time by offering a guisers experience. But it doesn't necessarily need to hit the blockchain yet. It doesn't need to be settled yet.
00:26:55.662 - 00:27:12.066, Speaker B: Settling could be delayed. We do this with banks already. When I transfer funds to someone, it takes two days to get settled. That's fine. They all get batched up and eventually they get settled somewhere else. See, I think there's two good reasons for that. One is owning the user experience, and two is it's handling burst traffic.
00:27:12.066 - 00:27:23.770, Speaker B: Because there's been plenty of times in Ethereum where burst traffic sort of broke some protocols, like Maker Dow back in 2020 during Black Thursday, got broken because of all the first traffic.
00:27:24.430 - 00:28:10.722, Speaker A: Yeah, that's true. Especially for the FT meme, right? Not just on Ethereum, but on all different hyperpole, probably, as you mentioned, calls like tons of thousand requests and transactions within a few seconds. Definitely we congest a network and also cause some gas wall. It definitely affect the user experience of the other applications as you just share. Right. So for all the roll ups and the different l ones you always mentioned, the bridge is a very crucial component for all these different protocols. And I also saw you did a lot of research around the bridges.
00:28:10.722 - 00:28:16.650, Speaker A: And based on your study, what are the issues of the existing bridges?
00:28:17.390 - 00:29:05.990, Speaker B: Yeah, so basically, the way we've scaled cryptocurrencies for the past ten years is via bridging. We've always been building bridges, but the question is, what type of bridges are we building? And actually, I have to thank hazard for this. I always feel the acknowledgement for it. He helped me work on the terminology for how to describe these bridges. So, basically, if you consider Coinbase, when I lock my funds in the coinbase, that's a bridge. There's a bridge under the hood that holds all the assets. Now, the question is, how is the bridge protecting these assets? What does the bridge have to trust? If I've locked in money into the bridge and into Coinbase, how do I get my money back out? And how is the bridge convinced that the money should be released back to me? So we call this the trust assumption.
00:29:05.990 - 00:29:46.546, Speaker B: Was the bridge really trusting? And of course, just to step back a bit, the bridge has all the assets, and this off chain database, like Coinbase, are the liabilities. And the bridge wants to be guaranteed that the assets can cover its liabilities, because know make sure that the system's fully collateralized. So the bridge wants to be convinced. How can I get my money from Coinbase? So there's three different historical approaches. One is a single authority. Coinbase has the sole authority to tell the bridge how to release the funds. Coinbase will say Alice can withdraw 1000 e, Coinbase will send us to the bridge, and then the bridge will send 1000 ETH to Alice.
00:29:46.546 - 00:30:28.418, Speaker B: So we're trusting one single authority with those funds. Then it sort of progressed a little bit to a multi authority, like a multi sig, maybe. There's five out of nine validators that we have to trust in order to protect the funds in the system and allow people to withdraw their funds. Then the third approach is the crypto economic bridges. And this is sort of like polygon, the proof of stake bridge. But the difference there with the crypto economic bridge is that for me to become a validator, I have to lock up coins, I have skin in the game, and then I elect myself to be a validator. And so if you look at the Polygon bridge, the last stat I had was at late 2021.
00:30:28.418 - 00:31:12.606, Speaker B: About six entities controlled about 85% of the stake in the system. I think that was about one to $2 billion worth of matic, by the way. So it's a huge amount of funds there but again, it's only six parties. And so for all three type of bridges, we had one party, a multi sig, and again, basically a multi sig with skin in the game. And in all cases, we're basically trusting less than ten people to protect billions of dollars. Now, if I were to tell you that, what would be your first thought? What do you think would be the problem if you trust, I don't know, five people with billions of dollars to protect it? The problem is, basically they keep getting hacked. Mongox lost 850,000 bitcoin.
00:31:12.606 - 00:32:03.538, Speaker B: That's 6% of all bitcoin that ever existed. And we sort of pretend that never happened. For every two to three weeks, these exchanges just kept getting hacked. And the question is why? Why do they keep getting hacked? Why is it so hard or difficult to protect billions of dollars? And the issue is really that if I'm going to cryptocurrency startup today, I have to take a set of human processes, implement those human processes, and try my best to protect the private keys and protect the servers. And we know humans don't scale, and humans aren't very good at checking, performing validity checks, or auditing, or making sure something's done right. We're not very good at that as a species. And so because of that, if you try to take these human processes and you give it the team A, team B, Team C, Team D, eventually a team is going to fail because they just can't replicate it.
00:32:03.538 - 00:32:38.782, Speaker B: Humans don't scale, so we're not very good at doing that. And so that's quite clear. It's not that the humans are at fault. They want the offer good service, they don't want to get hacked, but it's just very difficult for humans to protect billions of dollars. And so, since winding back a bit, the problem of all these bridges for the past ten years is that it relied on human trust to protect the system, where now, with the roll ups and what I would call the validating bridge, it's software that's protecting the funds. The bridge will not release the money unless it's 100% convinced that this off chain database is okay. And well.
00:32:38.782 - 00:33:16.010, Speaker B: And so we know software skills, software skills vary well, and so we can remove humans from that role of protecting the funds, then, of course we're going to be able to hopefully scale a bit better and have thousands or hundreds of thousands of off chain systems because we no longer rely on humans. So basically, that's what came out of the research. I tried to learn why all these things got hacked. And then eventually you realize, oh crap, it's just because of humans and it's not their fault. It's just they said they're just not made for doing this. Oh, I think you're muted, I can't hear you. Uhoh.
00:33:18.610 - 00:34:23.700, Speaker A: Yeah, it's always the case, right? Human always make mistakes and due to various reasons. And there's just one more thing as you just mentioned, right, the software we can use, like the rollab we can use to sort of do some sort of verification before release the funds. But how about the duration between, we sort of see the block generated by the sequencer and also the proof generated by the prover. There will be a little bit time in between, right. But if this gap is very big, for example a few days or even a few hours, right. If there are some deals made offline, for example, I transfer you like 1 million usd their bank account, but you also transfer some money to me on a roll up. But probably the sequencer misbehave and then the proof is not generated on time.
00:34:23.700 - 00:34:36.230, Speaker A: Do you feel like we need some more advanced ways to prevent this kind of stuff? I mean the instant confirmation and also proof generation.
00:34:36.650 - 00:35:03.022, Speaker B: Yeah, I guess there's a few answers to this, sort of. Empirically speaking, with these centralized exchanges, we have to trust in the settlement for as long as our funds are on that system. So this isn't a new problem in that sense. It's been around for like 1213 years. You have to trust finance for. Actually, I'll make the joke about Coinbase because Coinbase, not to lock you out of your account while you're doing this transaction and eventually getting your funds out. So it's not a new problem.
00:35:03.022 - 00:35:11.282, Speaker B: So it is always there, which is nice. Thankfully roll ups don't create a new problem around this. They just make it more explicit because we know how the system works.
00:35:11.416 - 00:35:12.100, Speaker A: Yeah.
00:35:12.550 - 00:35:48.014, Speaker B: With the current roll ups, obviously these optimistic roll ups take seven days. I think that's a bit long. They're a bit too conservative of that number. It could really be a day or two, which is probably way more reasonable. But still, training will then they should eventually fix that, the ZK roll ups. What's nice is because once you do settle on the blockchain of the proof, the funds could be released immediately. It's just a question is how long does it take the executors to pick up these transactions, execute them and produce the proof? I think the last I saw on Starknet it was like every 8 hours maybe.
00:35:48.014 - 00:37:02.194, Speaker B: I think it was around every 8 hours. They were doing it because there's sort of this trade off between the size of the proof and the gas cost and how many transactions are actually going to settle and who's paying for this. And so the longer they wait, the more transactions they can include in a batch and they can aggregate the savings for everyone. So I suspect when they get more popular and there's much more throughput or traffic on that, then it should hopefully be a bit more frequent than 8 hours. But the last part I want to mention, and this is why roll ups are also very exciting, is that because roll ups are an open platform where anyone deploy code and anyone can offer a service, then anyone can also offer a fast withdrawal service or a quick way to synchronize between different roll ups. So I was know hop protocol connects as an old startup called Mover, although I think they've pivoted now from doing know there's several different startups there that are just focused on fast withdrawals, where I have funds on arbitrum and I want to quickly withdraw back them, me and net. So there's someone on me and net who's willing to front the funds for me, they'll send me the funds on Ethereum because they know they'll eventually get paid back from Arbitrum via the bridge.
00:37:02.194 - 00:37:29.360, Speaker B: And so it's really exciting now we can have these venture funded startups that focus on the single problem to make it way better for users to quickly move between chains. And that was never possible before. As I mentioned, it's been a long standing problem and now we're actually getting better solutions for it because people are willing to take on that risk in order to earn profit. And it's a sense. So yeah, it's great to see a market actually evolve around this and hopefully solve that problem.
00:37:29.810 - 00:38:00.470, Speaker A: Yeah, basically I think they are running their own executors or verification, and then probably they have more confidence and collaborate with some liquidity providers to provide this fast withdrawal for the users. We come to the last question, as you know, right we are doing these alternative views. Do you have any sort of non mainstream advice you want to leave to our audience?
00:38:01.370 - 00:38:42.198, Speaker B: Non mainstream advice? I'm going to joke my comments here. So a lot of ethereum people, cryptocurrency people in general, they love the heat on binance, smart chain, they love the heat on it. They're like, oh, this is a fully centralized system, how dare they only have like eight validators. But actually I think binance are very ballsy for doing that. If you look at binance smart chain, it's basically working towards the goal of a roll up. They've taken their centralized exchange, basically tried to convert it into a network. It's an open network where anyone could deploy code there, give or take.
00:38:42.198 - 00:39:03.206, Speaker B: Maybe the validator will ignore it. But it's a fully auditable system. There's proof of reserves. I know my funds are in the system. If they get hacked, which happened recently by the way, if you remember with the. I forget what they lost but there was a minting issue with the bridge due to merkel trees. But the moment they do get hacked is obviously anyone that they lost funds.
00:39:03.206 - 00:39:50.902, Speaker B: And so actually binance smart chain is pretty cool because it does have proof of reserves, it does have the smart contract system that we can all deploy on and the only thing the volatile can do is go offline and I guess they could also try to fork the network but they could go offline and freeze the funds. So it's basically a side chain which is fine. Most of these systems are side chains anyway and so it's really cool. Binance smart chain actually went and did this and sort of provided this nice empirical evidence that something like this has product market fit, it's useful and people like it and people will go on at the trade because it's much more crypto native than using a centralized exchange. That's probably my non mainstream advisor. I don't know, view at the moment. I think most people hate on binance smart chain but I think it's really cool and it's sort of a step in the right direction of how I'd like to see roll ups evolve and emerge.
00:39:50.902 - 00:39:55.246, Speaker B: So yeah that's probably, I don't know, probably not expected. So I'm very happy with that.
00:39:55.348 - 00:40:37.720, Speaker A: Yeah, it's a great opinion. I mean alternative opinion. Thanks a lot for Patrick, sharing a lot of interesting insights and talking about scalability. L two rollouts and also bridges, right? Yeah and also a great thanks to all the audience who listen to our allview and all of you. As I just mentioned, we are talking to a lot of experts in the industry around l two scabilities and if you want to listen to more just subscribe to our channel. And yeah, we are signing off to the next time. Yeah, thanks everyone.

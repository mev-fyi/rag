00:00:00.280 - 00:00:09.090, Speaker A: Section of ref with ZK proofs, or I guess ZK rollups with SP one. So we should have updated the title. So, uma, take it away.
00:00:10.190 - 00:01:05.230, Speaker B: Hello, I'm Uma. I'm one of the co founders of Succinct. And yeah, today I'm going to be talking about how we built on top of the excellent work by Clavi and Andreas on top of Kona to build ZK rollups with SP one. So I think the first important thing to talk about is why do ZK Rollups matter? What problems do they solve? What actually do they help? And I think today a very common theme in the Ethereum ecosystem that we're all talking about is interoperability and unifying all these different roll ups that are spread out throughout Ethereum today. If you're a user and you want to use a roll up, it's pretty difficult if you have assets on chain a to get assets on chain b. And a lot of these teams are working on themes around interoperability, unified liquidity, better bridging, and overall just improving the UX and making it better. And I think ZK is the only way that all of these problems will actually get solved.
00:01:05.230 - 00:01:54.432, Speaker B: So today ZK rollups do exist, and there's a bunch of very smart people on some of these teams and other teams as well, that have had made ZK rollups. And what does that kind of look like today? Well, if you want to build a ZK rollup, the really critical ZK part is you have to make a zero knowledge proof of your rollup state transition function. So basically you take your old state route that's on chain, a bunch of transactions, and then you prove your new state route and you verify that proof on chain. Now, today, the ZK roll ups, the code kind of looks like that. It's not super easy to see, but you can see that people have to write circuits, they have to write their own custom assembly, they have their own dsls. It's all very complicated. And in particular, there's a lot of issues with the current approach of ZK rollups today.
00:01:54.432 - 00:02:46.208, Speaker B: All the ZK rollup teams have very large specialized teams with ZK expertise and cryptographers that have to make these state transition functions. They're very hard to customize and maintain and upgrade because if you're hand rolling your own stack and then Ethereum goes through a hard fork and you want to be compatible, you have to update all that cryptography. It's also a really large surface area for security vulnerabilities because you're handwriting everything that's going to ref and RevM. You're basically reimplementing that in ZK, which is basically ten or 100 x is hard. And then also, a lot of the ZK rollups today are not fully type one compatible. So type one means that you have the same state root computation as Ethereum, for better or for worse, including RLP, the Merkel Patricia try catch hack hash function. And so a lot of the ZK rollups, because implementing that in ZK is very difficult and is very expensive.
00:02:46.208 - 00:03:23.590, Speaker B: They're type two or type three or type four. So SP one is a ZK VM that we've been building at SysyncD. And what does it let people do? It lets any developer use ZK by just writing normal rust code. So we're at the open source rust ecosystem conference, and so when you put open source Rust plus SP one, I think it can help address a lot of the problems with the ZK rollups of today. So how does SP one work for those who are not familiar? First you write your program in normal rust code, so it looks pretty normal. It's very readable. Usually it's pretty short.
00:03:23.590 - 00:04:07.000, Speaker B: Then it gets compiled to RISC five, which is a reduced instruction set. And then we generate a proof of your RISC five execution and your RISC five program, uh, with a certain inputs to get a ZK proof that can be verified on chain. So when you have SP one, and now you can write your zkstate transition function using SP one plus Revm ref alloy, Kona, etcetera, you solve a lot of the problems with ZK rollups of today. Basically you can just write normal rust so you don't have to be a cryptographer. It's really easy to upgrade and maintain. I kind of joke it's as simple as cargo update ref. When upgrades and they're implementing all this stuff, we just get all of that for free.
00:04:07.000 - 00:04:48.840, Speaker B: The security surface area is also really nice because ref has undergone extensive audits. There's currently an effort to formally verify RevM, and we kind of get all that security work for free as well. When we use Reth and RevM in SP one, it's natively type one compatible because it's using the exact same node software and computation of the state root, and it actually ends up being not that expensive. So this is kind of the dream on why SP one will help solve a lot of problems and make ZK rollups really easy and really maintainable. And so now I'm going to talk more about how we actually go through this step by step. So step one of building a ZK rollup is we actually have to execute a block. So let's run through that.
00:04:48.840 - 00:05:36.348, Speaker B: So when we want to execute an ethereum block in SP one, we have to write an SP one program using ref to actually do this computation. But first, what we have to do is we have to fetch the witness for the computation. So this involves executing the block outside of SP one, just a normal native code. And we use the RPC, we fetch all the storage slots, we fetch all the relevant Merkle proofs, we fetch all of the data, and we do this in what we call the host program. Then we take all of that data and we construct a client input which is run in our client program, which is the SP one program. And so we have the previous block, the current block, and all the necessary merkle proofs and storage proofs and block hashes and tri nodes. And a lot of this has to deal with the complexity of the MPT.
00:05:36.348 - 00:06:10.104, Speaker B: I very much agree with Roman that MPT is the root of all evils. But yeah, we are able to easily fetch that data using rough. Then once we have that data, this is the actual SP one program to execute the block. You can see it's very short and simple. We annotate it with this SP one entry point to denote it's an SP one program. We read in the input, we deserialize it, we execute the block, we then get the new header, we hash the header and then we expose that as the public outputs of our proof. Once we have this program, we can generate the proof in SP one.
00:06:10.104 - 00:06:49.210, Speaker B: And now we have a proof for an ethereum block execution. So we actually ended up implementing this. And along the way we definitely ran into some challenges that a lot of people in this room helped us out with. So one of the challenges was that ref is a very good piece of software, it's very modular. But unfortunately at the beginning of our exploration, some of the crates did not compile within SP one. So for example, if you import crates that are making networking calls, the code is not going to compile within SP one. And we worked very closely with the rest team to power through and make those dependencies optional or feature flagged or refactored.
00:06:49.210 - 00:07:30.322, Speaker B: So that was a great help that they gave us. Another complication, as many people have mentioned at this point, is state root computation. The Merkle partition trie is very very complicated. There's a lot of edge cases and Roman in particular on the RET team helped us out a lot on actually computing the state route within our SP one program. There's also all these edge cases around the Merkle pusher trie that requires using this debug endpoint in gethse that we're trying to move away from. And the ref team has recently merged in an endpoint to help with that. Now, once we got through all those challenges, there's a bunch of reusable primitives, including an RPC DB that can be modularly used with ReVM where it fetches all the witnesses from an RPC.
00:07:30.322 - 00:08:06.966, Speaker B: And then we have a witness DB that can be used in a ZKVM context where it loads up all the state and then it can just run the block statelessly. In the end, we only have 1100 lines of code in this repo and we can now execute any Ethereum block and generate a ZK proof for it. And it also works with op stack pretty easily, thanks to op Roth. So with ZK, everyone's always super obsessed with the costs. And so I want to talk about the cost data we got from executing these programs. So I took a random range of blocks, and these were not cherry picked blocks. You can see they're just sequential.
00:08:06.966 - 00:08:45.710, Speaker B: It was a random range. Someone gave me a, you can see that the gas used, and these are real main net Ethereum blocks. You can see the gas used is some are less, some are more than this 15 million average gas target. And what we do is we take the block, we execute it with an SP one, we count the number of risk, five cycles that happen during execution. And then basically we generate the proof and we compute the total cost per transaction by multiplying the on demand cost of the GPU instance. We're running SP one on and multiplying it by the amount of time it took to generate the proof for that block. In the end, you can see the costs per transaction are actually pretty low.
00:08:45.710 - 00:09:05.614, Speaker B: It ends up being between 0.2 and 0.3 cents average. Proving cost per transaction to prove the execution of an Ethereum block. And this is actually a very pessimistic estimate. This is using on demand pricing. Usually when you go to reserved instances you can get much cheaper GPU's and there's a lot more optimizations we can do.
00:09:05.614 - 00:10:05.232, Speaker B: So even today, the costs per transaction for proving an Ethereum block are very cheap. SP one has a bunch of ZK innovations and a lot of performance engineering that we spent a lot of time on to actually enable this. So I want to talk a little bit about that one of SP one's main innovations was our precompile centric architecture. So generally even this is true, I think in ref and RevM, when you're executing an Ethereum block, even on a normal cpu, you spend a lot of time verifying signatures and verifying hash functions. In SP one we have this system of precompiles where basically you can take these very expensive cryptographic operations, and then we make a custom circuit for it in SP one that can talk to our main cpu. And usually this helps reduce the cycle count of our programs by six to ten x, which directly translates into a six to ten x reduction, improving overhead and time and costs. We also have a bunch of other precompiles for elliptic curve operations and other cryptographic operations that help a lot.
00:10:05.232 - 00:10:58.070, Speaker B: For things like KZG or bn pairing verification. We implemented an optimized GPU prover that helped a lot in terms of cost and latency over a cpu prover. And then we have a bunch of other algorithmic optimizations on the ZK side of things that really helped make sp one as cheap as possible for this Ethereum block execution use case case. So the main takeaways from doing this exercise were that the costs are already pretty cheap. And we think that with all the work we're doing and all the performance optimizations that are happening, as well as getting, you know, better reserved capacity and making our GPU's cheaper, the costs will only go down from here, maybe even by five to ten x. I think what's even cooler than the cost being cheap though is that it's super easily customizable and there's very minimal lines of code. We're super happy that we could use all of the work by the ref, then RevM and alloy and Kona team.
00:10:58.070 - 00:11:33.500, Speaker B: And in the end you have ZK verification of Ethereum blocks with only 1100 lines of code. That is super magical. And again, it's easily upgradeable. There's minimal maintenance surface area, and I think that is the very powerful developer experience of a ZK VM. So I've talked about how to verify execution of Ethereum blocks, but in a ZK rollup there's actually a lot more stuff that's going on. So I think we're only at step one. And now I'm going to dive into step two of actually building a ZK roll up.
00:11:33.500 - 00:12:16.920, Speaker B: So thankfully we are using the op stack to do kind of the rest of the complexity of a ZK roll up. Ok, so what is the op stack? I imagine most in this room are pretty familiar. And this is taken directly from one of their blog posts or their documentation, but as a modular open source set of components to build rollups in general. And I think they had a lot of foresight when they wrote this. I think it was maybe one or two years ago where they said it's not just a roll up, it's not just optimistic. And actually now that's becoming true with the work we're doing to help make their stack also support ZK. So this is kind of like a system, very simplified system diagram of all the stuff that's going on in Opstack.
00:12:16.920 - 00:13:24.564, Speaker B: You have this op batcher that's kind of like the sequencer that takes in a bunch of user transactions and is actually posting the transaction data on chain. Then you have this optimism portal where users are depositing and withdrawing. Then you have your actual node that's actually running your node software and updating the DB with the transactions and the deposits and the withdrawals. And then finally this is the current part of their stack, they have this op proposer that's washing the node, and every hour it proposes a new state route to this contract called the l two output oracle. And all the stuff in the red is all the fault proof VM stuff where basically they have the op challenger op program, canon, and a bunch of other stuff where the fault proof VM ensures that the proposer cannot propose a false route to the contract. So there's a seven day waiting period where you can run this interactive challenge game and that adjudicates whether the state route that the Op proposer proposed is actually correct or not. After seven days when the state route gets finalized, the optimism portal can use that finalized Stateroot and users can do withdrawals against that stateroot.
00:13:24.564 - 00:14:09.580, Speaker B: And one thing I want to note is this diagram is a little bit of their old system. Their new system has a more complicated dispute game contract and things like that. That clabby covered a bit, but for simplicity, this is a simplified view of their system. Now their stack is super modular, and I think the OP team deserves a lot of credit for building their stack in this very modular way where components can really be easily swapped out. And so that's exactly what we did. We decided that, ok, the l two output oracle today is adjudicated by this fault proof game. But actually it could be a ZKL two output oracle, where whenever the op proposer proposes a state route, they not only propose a state route, they also include a ZK proof that their new state route is correct.
00:14:09.580 - 00:14:46.242, Speaker B: It gets verified against an SP one verifier, and then the contract gets updated. So you can see that we are still able to leverage all the other components of their stack, like the op batcher, the op node, all that nice stuff. And the only thing we have to do is swap out the Zk l two output oracle and the op proposer. So to actually do this and dive into a little more detail, there's two components. First, we actually have to write the state transition function for the proof that gets verified in this l two output oracle. That is not a very easy task. The op state transition function is pretty complex.
00:14:46.242 - 00:15:19.570, Speaker B: It involves getting data from l one and running derivation. It involves taking the deposit transactions and making sure they're ordered properly. And then you have to recompute the new state route and make sure everything is handled correctly. Thankfully, Kona, which is the previous talk that Clabi gave, came to the rescue. So Kona is this portable modular implementation that's rust centric of the op derivation program. And we were able to just implement Kona directly in SP one. It's just a normal rust code.
00:15:19.570 - 00:16:08.320, Speaker B: We're able to write an SP one program that has the optimism state transition function and very few lines of code. As Clavi mentioned in his previous talk, our program ends up being 500 lines of code. It's very minimal modifications. It leverages all the existing work that they did, and then, boom, we get a program that can run the state transition function of optimism, generate a ZK proof of it using SP one, and then verify it on chain. Then for the op proposer, all it has to do is it runs in a loop, it watches the tip of the chain, and every so often it'll query to our prover network via one API call to actually generate the proof. So the op proposer today is a very lightweight process where it's just proposing it's getting the latest state route and it's throwing it on chain in a smart contract. This zkop proposer is still a very lightweight process.
00:16:08.320 - 00:16:40.084, Speaker B: It's not actually doing any proof generation in its own runtime. What it does is it spins in the loop and then calls to our prover network to actually generate the proofs in detail. What's actually going on is that for every range of blocks. So every so often, I think every minute, the op proposer takes that range of blocks and it requests a proof for that range, and it does it for every minute. Now, you can't actually post proofs on Ethereum every minute. That's very, very expensive. It ends up being like 280k gas per proof.
00:16:40.084 - 00:17:18.998, Speaker B: So what you have to do is you take all your proofs for each range of blocks and then you aggregate them into one megaproof, and then after that you post the megaproof on chain. And so that's actually the logic that's going on in our Zkop proposer. So with those two components, it's very easy to make an op stack chain, a fully ZK proven chain in two easy steps. You just take an existing op stack chain, or you can deploy a new one using your favorite rast. Then you deploy this ZKL two output Oracle smart contract. That's trivial. Using forge, you just run a forge script, then you spin up a docker container to run the Zkopi proposer.
00:17:18.998 - 00:18:06.460, Speaker B: It calls to a prover network, it generates proofs and then it posts them to the ZKL two output oracle. Then your time to finality goes from the seven days to 1 hour, which is pretty awesome. So we actually ended up doing this. We implemented, you can check out the repo up there. And I think the thing that was really awesome to see in a lot of the work and shows really the compounding nature of open source work is that in all the total lines of code ended up being less than 2000. Thanks to the great work of the Reth team, the RevM team alloy, and also the amazing work of Kabi on Andreas, we were able to just import Kona, write the program, use the op stack, use most of its primitives, and only modify the proposer slightly. And then we're able to have a full ZK roll up, which is super awesome.
00:18:06.460 - 00:18:42.610, Speaker B: And yeah, as I mentioned, we actually did this. It's pretty few lines of code. Getting the right lines of code was definitely difficult, but once you had it, it's actually very beautiful. And the abstractions that Clavi and Andreas have in the Kona repository were very amenable to us. There was very minimal modifications and they had really great abstractions to make it easy for us. So we're very thankful to them. So we ended up doing this for op sepolia and we're live updating with the chain.
00:18:42.610 - 00:19:32.810, Speaker B: We have a bunch of GPU's spun up in our AWS instance, and we're able to keep up with the chain and generate ZK proofs and post them every hour or so. So now, again, people's favorite question is, with ZK, okay, how much does it cost? What's the delay? So there's generally two components to any ZK system there's the on chain costs of proof verification, and then there's the off chain proving costs. So the on chain costs in our case are when the Zkop proposer proposes a state route, it has to propose a new route and verify a proof. And in all that transaction takes around 417k gas. This is actually around the same cost as proposing a new route with the fault proof game, which is around 420k gas. So the on chain costs for ZK and for the fault proof game system are actually relatively similar. You're not paying more eth to Ethereum to use ZK.
00:19:32.810 - 00:20:23.998, Speaker B: The off chain proving costs are obviously a cost that is not present in the fault proof system. And we found that in the end it ended up being zero point five to one cent per transaction proving costs. And this is a super, super rough estimate. It really depends on your workload, it really depends on how many transactions there are per block. It also really depends on your l one's throughput. So again, this is a very rough number, but we ended up with this range, and we noticed there's basically a two to three x overhead versus the proving costs of Ethereum transactions because of the other parts of the derivation pipeline where you have to scan through all the l one receipts to find all the deposit transactions and withdrawals and stuff like that. In general, we found that the derivation which involves iterating through the l one, was ten to 20% of the proving overhead, and then the block execution ends up being between 80 and 90%.
00:20:23.998 - 00:21:01.280, Speaker B: But again, all these numbers are really dependent on the load and work of your chain. Another thing that people like to talk about is latency. So, you know, how fast can we get the finality? So one common misconception is that, oh, if I generate my Zk proof every minute, I can get 1 minute finality. Well, if you want to post ZK proofs to ethereum every minute, that's extremely expensive because it ends up being 280k gas per minute. That ends up just being a very large number. So actually the bottleneck to latency is the ethereum cost of posting proofs. That's the reason why our current latency is basically we post a proof every hour.
00:21:01.280 - 00:21:35.970, Speaker B: It generally lags 20 to 30 minutes behind the tip of the chain, and we're able to do that pretty consistently. Another thing I want to highlight is that latency is not the same thing as throughput. So even though we lag behind the tip of the chain by 20 to 30 minutes, which is already pretty fine, we're still able to keep up with the chain just by having more GPU's. So if you have more transactions or more blocks in your chain, that's actually totally fine. We just increase the number of GPU's and we're able to maintain a throughput that keeps up with your chain no matter what. Another question people like to ask is security. So, you know, ZK obviously very complex.
00:21:35.970 - 00:22:29.290, Speaker B: It's kind of scary. You know, if I'm relying on a ZK proof for my whole roll up, is that okay? And I think similar to the fault proof systems of today, where you have, sometimes you have whitelisted people who can participate in the faultproof game, or you have an override security council, you can also use these same tactics with ZK to get the security that you want. So, for example, common techniques, and this is true for all the ZK rollups of today, is they have a whitelisted set of actors that can post a proof on chain. And you can also have a small challenge period. For example, a three to five hour window after your route is proposed and the proof is verified for someone to step in and you know, or for a security council to step in and act. And thankfully, the existing op stack repo conveniently already has this functionality. And so you can leverage that as well to put additional security on top of your ZK roll up.
00:22:29.290 - 00:23:33.466, Speaker B: So I think I spent a lot of time talking about current cost and latency, and a lot of people like to focus on that. But I actually think the most important question is the trajectory, where is this all going today? And I know that basically the costs are going to go down by ten x guaranteed. So there's actually two ways that the costs of all this stuff and latency can go down. One is on the SP one side, as I mentioned previously, right now we're using all these on demand GPU instances. But actually it makes a lot of sense if you have a relatively constant workload that you can start using reserved instances or dedicated instances for a really big reduction in cost. We also have a lot more optimizations we want to do to our GPU prover, and then we have a lot more optimizations to our actual circuits and algorithms on the ZK side of things that we are very optimistic will result in a five to ten x decrease in cost and latency by the end of the year. Another interesting area that costs can go down is actually protocol and software optimizations to Opstack and Kona.
00:23:33.466 - 00:24:14.960, Speaker B: So I think when Op built their program, they weren't necessarily thinking, how do we make it most efficient for a ZK, and currently they require iterating through all the l one block receipts. And I think things like this are very fixable, with minor tweaks to the protocol that can make it a lot more friendly for proving in ZK. There's also a lot of raw profiling and optimization we can do to Kona to cut cycles. I think there's a lot of table stake stuff. We only recently started looking at this code, and there's a lot more low hanging fruit to make this a lot more efficient in the context of a ZK VM. And so already today, the costs are pretty cheap, but I'm very confident that they're only going to get cheaper and cheaper from here. So, as I mentioned, we've gotten this working.
00:24:14.960 - 00:24:40.730, Speaker B: Those are the repos that I referenced. The RSP one is for Ethereum, op distinct is for the Kona sp one work. And yeah, if you're interested, you can reach out to me, you can fill out this form. And in general, we want to make every roll up, a ZK rollup and scale ethereum. And I'm very thankful and grateful to all the work that all the people in this room have done that's really compounded to finally put all the pieces together and make this possible, hopefully this year. Thank you.
00:24:47.960 - 00:25:11.020, Speaker A: Yeah, the afternoon talks are pretty epic because they're showing that, okay, now that we have the base layer, we can now start layering things on top and move really fast. Where things that people have told you maybe in the past that were really expensive or slow or expensive in dev time, well, that might be a lie. And maybe we're in this new world where things are getting done very fast, very cheap, and actually get developed very fast. Any questions for Uma?
00:25:13.080 - 00:25:24.050, Speaker C: Hey there. Great talk. I'm curious how you see ASics and FPGA's driving the costs down and the compute down. Like, what kind of improvement factors are we talking about?
00:25:24.950 - 00:25:56.818, Speaker B: Yeah, I think today we use GPU's, and that was a very big improvement over cpu. As the proof systems are still very rapidly evolving. The flexibility of a GPU is really nice, so you can iterate very quickly. But then when you have ossification, I think FPGA or custom, slick and ASIC could be a huge improvement. And maybe that's where you get the 100 x or 1000 x or something like that. There's a lot of nuance to the hardware. For example, often actually, raw computation isn't the bottleneck, it's memory bandwidth or data transfer.
00:25:56.818 - 00:26:19.260, Speaker B: And it's very hard to compete with Nvidia on those fronts. They're a very massive company with a lot of resources. So I think the equations actually end up being very complicated. Really depends on your proof system, but there's a lot of great people who are doing work on that, including irreducible with Binius. So I'm pretty excited, all that stuff. And we're actively definitely investigating it too.
00:26:19.420 - 00:26:20.280, Speaker C: Thank you.
00:26:22.060 - 00:26:29.452, Speaker A: One more question. Hello. I'm curious what you think the roadmap would be to not needing a white.
00:26:29.476 - 00:27:04.130, Speaker B: Listed set of proposers for ZK proofing? Yeah, yeah, it's a good question. I think it's probably pretty similar to op's roadmap for getting to stage two. You can have multiple different proof systems, you can maybe have formal verification. I think as these things get used in production more and more and get more Lindy or fully open source, have more people look at them, they get more secure with time. And so I think it's just a matter of time and being actually used in the wild.
00:27:04.510 - 00:27:14.518, Speaker A: Thank you. Okay, last question. Hi, I'm here, yeah.
00:27:14.654 - 00:27:20.970, Speaker C: Could you talk a little bit about how the prover network works? What are the crypto economics there and so on?
00:27:21.630 - 00:27:53.082, Speaker B: Yeah. So today our prover network is kind of a prover network of size one, I like to call it, where we're generating all the proofs. We did that just so it's very easy and fast to move in the longer term. We want to have a system where anyone in the world can just turn on their gpu and contribute to generating proofs for sp one. But yeah, today it's very simple. You just send an API call with your program, your input, we generate the proof and then we send it back to. And there's no trust assumptions on it because the proof is self verifying.
00:27:53.082 - 00:27:55.850, Speaker B: So you just verify it yourself and then you can use it.
00:27:56.010 - 00:27:56.778, Speaker A: Thank you.
00:27:56.914 - 00:28:33.860, Speaker C: One very last question. So, one thing that you mentioned that I did not appreciate in the past is that the new debug execution witness allows you to build the stateless ret node today. That would be a great hackathon project if anybody wants to do it. The question to you is how sensitive is proof generation to the state representation? And like, where do you land on the vertical debate? Because some people say it's more ZK friendly, some people say it's not, they don't believe it. Word for word, where do you land?
00:28:34.760 - 00:29:07.228, Speaker B: Yeah. First of all, Roman, thank you so much for all the work you did helping us with MPT and Stateroot you are so invaluable. Our team loves you. Yeah. With the verkle debate, I have not looked super deeply into it, although my intuition is that it's actually not that friendly to ZK. The reason is today, catch act is actually not so bad, even in our ZKVM SP one, because we have a precompile for it and we accelerate that hash function with Verkl. You have.
00:29:07.228 - 00:29:39.190, Speaker B: It's over the BLS twelve through 81, I believe, or something. So it's just a bigger field. The evolution of ZK proof systems has been smaller and smaller fields, so the vertical big field is actually not very friendly to that. I think before they do such a big upgrade to Ethereum that's so in depth, there needs to be a lot more study of how it will impact its performance in zkvms that no one's really done. So my position on it right now is I don't think we should rush it. I think we need to do a lot more investigation, and it actually might not end up being more friendly for ZK vms.
00:29:41.250 - 00:29:57.110, Speaker A: All right, so huge applause for Uma. And then we have hi from the rise team who will talk to us about PevM is high. Where is Hai?
00:29:58.250 - 00:29:59.030, Speaker B: Yeah.
00:30:05.370 - 00:30:05.810, Speaker C: Thank you.

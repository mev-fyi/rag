00:00:01.400 - 00:01:27.840, Speaker A: Thank you guys for coming. I'm Matt. I wrote a bunch of code for foundry, and now Rev and I will talk a bit about some foundry internals and how it works internally, how we interact with the EVM, how we get cheat codes working, how forking works under the hood briefly, and what are our next steps for foundry? So first of all, who has used forge or foundry or some other tools? Nice. Yeah, so for those who don't know, foundry is basically a collection of tools that you can use for developing solidity, or solidity adjacent work. You can use Anvil as a local Ethereum nodes that has a bunch of modifications that wouldn't be possible with something like geth or ref. So it's a full node from scratch. Then we have cast, which is basically just a collection of sub commands that help when you want to interact with Ethereum nodes or just to convert some ABI data, input, output function, signatures, something like that.
00:01:27.840 - 00:02:33.790, Speaker A: And our main motivation behind all of this was that we want to get to 100% solidity in your smart contracts repository. So getting rid of everything else, just solidity, and support writing tests in solidity directly, and use forge for running those tests. And it's also very easy to install. You have one bash strip that downloads the latest release, and you can use our Forge GitHub action to run it in CI. Just to give you a brief overview about the star history, because it's really nice. We hit six k a few weeks ago, but more important, we almost had 300 contributors. We try to be as open minded as possible when they are triaging new issues, feature requests, and help those to land the first pr in foundry.
00:02:33.790 - 00:03:45.370, Speaker A: But this talk is not necessarily a talk how to use foundry, because there are way better resources out there. An entire course by Patrick Collins that is multiple hours long and for free available on GitHub. Or you can have a look at our foundry book, which covers everything we have in there, references to other useful documentation, templates, things like that. I will mostly focus on some fortune tunnels, but I want to not entirely exclude some cast features. For example, there's cast run, which takes an Ethereum transaction hash and then replace that transaction locally. So it first basically forks the network at the block that this transaction was mined in, then executes all the previous transactions locally. So you get to the states, the transaction used when it was first included in the node, and then it re executes this transaction and displays all the traces.
00:03:45.370 - 00:04:52.056, Speaker A: So you can see all the calls, all the arguments, and the entire trace call, which is very useful when you need to debug a transaction or just want to get a better understanding of what is happening in there. And this basically works with standard RPC provider or URL to a node that supports regular ETH RPC methods. Another cool thing with Anvil is that you can use it programmatically, so you can use it as a library. And we see a lot of folks using that for simulations specifically. And getting it to work is super easy. You have basically just one entry point. You configure your nodes like if you want to fork some network chain id, whatever, and then you just fire it and you get API interface.
00:04:52.056 - 00:06:08.660, Speaker A: And yeah, basically a node handle that ensures that the node is not dropped. And this way you can bypass the entire RPC layer directly and speak to the node directly without going through rpcs. If you run simulations, for example, you want to evcall, you use the API object directly and you don't need to go through RPC at all. So I think this is pretty cool, but I want to focus on what happens when you run forge test under the hood. So on the left side you see the template test contract that you get when you initialize forge repository or forge project. And you see there is some test contract that inherits from the Forge STD test. And you have a bunch of test functions where this is where you write your tests and you have a bunch of assert functions that you can then use to test your contract calls.
00:06:08.660 - 00:07:25.026, Speaker A: And what you see when you run forge test is that first everything is compiled, then we run all the test functions and they either pass or fail. And if you look closely at the test fuzz function, then you see that this function takes a bunch of arguments and those are fuss by default. So these are fuzz functions where forge internally generates a bunch of random arguments and then calls this function multiple times. So you can have multiple arguments. And yeah, go wild with the fuzz logic here. But what happens internally when you call forget test is that we first prepare the Solsiqall that eventually is invoked and this includes loading all the forge CLI arguments. Like if you have a filter for specific functions that you want to run or contracts, then this is handled here.
00:07:25.026 - 00:08:46.082, Speaker A: Then we load all environment variables for, I don't know, RPC endpoints that we want to use during testing, and we also merge it with our foundry ToMl configuration file. This is where you can configure a Solseeq specific argument like optimizer settings, fuzz runs, things like that. Then we go to the preprocessing phase where we read all the project graph, all the files that are included in the in the project, and then we apply the remapping so we get the entire call that this project consists of. So this is how we check whether our file changed, if it needs to be recompiled, or it can be omitted because we already have it cached from a previous run. So this speeds up recompile time drastically. And then we populate the SOLC import via the standard JSON format, which includes all the compiler settings, the source code, whatever. What salsee then spits out is the standard JSON output.
00:08:46.082 - 00:10:37.062, Speaker A: This includes the compiled binaries, the runtime code, astrol things like that, or additional properties that you also can configure, and we write them to the output file or update no longer valid cached files. And finally we then apply the test filter. So we filter out all the test contracts from the solidity output and call all the test functions via the rust eVM that we use for running those tests. So test functions are filtered out by name, and we can see if this is a fuzz function or a regular test function. If it is a fuzz function, then we generate the arguments based on the function signature and call this function over and over again, and we see whether it reverts or succeeds as expected, a core part of forge are solidity cheat codes, which you can use during tests to manipulate the EVM or the state directly in a way that wouldn't be valid on the real chain. But it helps during testing if you want to fake the address of a caller, for example, or something simple like setting the block timestamp variable. And all of this is exposed via the VM interface.
00:10:37.062 - 00:12:48.882, Speaker A: This is where all the the cheat codes are defined, and those are then used in the forge standard test contract that you use to write your test functions, and you can call them via VM cheatcode with the write arguments and then assert for example, that the timestamp was updated as expected. So there's more code. This is basically the essential part in forge or any tool that needs to modify EVM data. And this is the interface in the Rust EVM which provides a bunch of functions that are invoked during EVM executions where we can manipulate the EVM or the state directly. For example, there are callbacks for when a call starts, when a call is ended, step functions when a new opcode was asked executed, and we can implement custom inspectors like a cheat code inspector for example, which then have mutable access to the EVM and the entire state of the EVM during VM execution so this is how you can update the block timestamp when warp is called, for example. Or you can do some more advanced things like network forking via solidity code, which will swap out the entire state during execution. So how cheat codes work under the hood is that we have a fixed cheat code address which we listen for in our cheat codes in inspector.
00:12:48.882 - 00:14:24.372, Speaker A: So every time the call function is called, which happens when a new call is about to be executed by the EVM, we check if this is a call to the cheat code address, and if so then we intercept it and apply the cheat code. Adding cheat codes is super easy. We just merge new printhead two days ago that added some missing cheat codes for working with the files, like if a file exists, if it's a directory, things like that. These are small things, but it's very easy to add them. And to add cheat codes you just need the cheat code signature, the function call that you want to add. Then we use internally Abigail, which is provided by ethos, which takes a bunch of function signatures and then generates entire rust bindings for this function signature. So what you get by invoking the arbitrary proc macro with a set of solidity functions is that you get an enum for all the cheat code calls that supports decoding encoding, things like that.
00:14:24.372 - 00:15:40.770, Speaker A: So when we have intercepted a cheat code call, then we try to decode the function input into a cheat code call. And then we can apply the cheat code based on the decoded invariant. So when warp is called, for example, then the function input should be decoded into a warp call. And we can simply mention on that decoded call and apply the g code, updates the block timestamp and return this only. But this only adds availability in foundry or forged directly. The final step would be to upstream this to forge standards by extending the solidity VM interface. Slightly more advanced feature is network forking via okay, last slide because I think Emily will focus on how to simulate EVM forking later.
00:15:40.770 - 00:16:12.940, Speaker A: But basically since you have access to the EVM data, you can also swap out the entire database under the hood and replace database lookups with something like eth getstorage add. All right. Yeah. Questions? Yeah. From Mike for.
00:16:28.650 - 00:16:29.430, Speaker B: Hey.
00:16:31.930 - 00:16:34.030, Speaker C: Arbitrage. Okay.
00:16:37.010 - 00:17:00.970, Speaker B: Curious if the build step by curious if the build step is handled all the, all the caching, all the artifacts in foundry, is that handled in foundry, is that handled by ethers, Solsi? And is there any like, do you guys have any plans on the roadmap of how that will evolve the building and the caching of the artifacts in foundry.
00:17:01.670 - 00:17:30.750, Speaker A: Yeah, so everything preprocessing is handled by ethersolsee. This includes caching as well and emitting artifacts and writing them to disk. But since we moving to alloy, eventually this should be moved to foundry directly. So this won't be a part of alloy in the future. Instead we will move it and probably foundry would be the right place for that.
00:17:35.930 - 00:18:06.920, Speaker C: What's the best way to do like integration testing, including off chain components? Because the last time that I tried to do it, I wanted to use Anvil as just purely a library. But what I found was I needed to do state setup, so I need to somehow run script. And I think for that I needed to basically have anvil running and then connect to it over the JSON RPC. So ideally I'd be able to do that all natively in rust. But yeah, what's the recommended pattern for that?
00:18:09.320 - 00:19:00.490, Speaker A: For Anvil itself we don't have something, or I think we actually do support a genesis file, which you could use to set certain account starter slots when you launch the node. So Genesis JSON file, it's a list of accounts with a list of storage keys and values which you can use for block zero basically, or for forge directly. You can set certain contract bytecodes via cheat codes, but for more advanced setup routines, probably a script or something that is invoked via an FFI cheat code or something like that.
00:19:00.990 - 00:19:01.850, Speaker C: Okay.
00:19:12.990 - 00:19:49.772, Speaker D: Checking. Okay. Hey Matt, I wanted to do a question specifically around anvil methods. For example with the JSON RPC implementations that are being rewritten in in wreath or rest, how will the future of that look like? Because I know there are some, for example debug methods, and I think it's trace methods or filter methods that are already in rest but are not an anvil yet. For example, trace filter. How will that look like in the future? Like will that also be built in Anvil, or will you share something, some component, so you can have it in both?
00:19:49.866 - 00:20:45.240, Speaker A: Thanks for asking. So all the trace implementation in ref are based on Anvil. We fixed a lot of bugs in there, and we also have standalone RPC types in rev now. So the roadmap for this is that RPC types will be a standalone component that any project can use. All of anvil defined types will be replaced by that, and also all the trace implementations will be replaced by the ref implementation as well. And this will add a bunch of missing calls, like debug call I believe is still missing. But since we have this already in ref as a separate crates, adding this will be.
00:20:47.460 - 00:20:51.668, Speaker D: I think we can catch Matt offline for any further questions, so.
00:20:51.764 - 00:20:52.940, Speaker C: Give him a round of applause.

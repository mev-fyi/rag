00:00:00.640 - 00:00:36.040, Speaker A: Awesome. Thanks everybody for having us back. It was cool to be back at the second rust Ethereum event. Last year we presented Opreth. This year we're going to be presenting Kona, which is kind of an extension of our work enabled by a lot of people in this room for continuing on op ref. So our agenda today is talk about what Kona is, a quick overview of Kona, as well as the fault proof program built on top of it. Go over a case for multiproost for stage two decentralization, a really cool project built by succinct Labs with running Kona on SP one, and then some quick talks about what's next.
00:00:36.040 - 00:01:27.790, Speaker A: So first of all, starting off with what Kona is, it is a no STD implementation of the rollup state transition as well as the derivation pipeline. And so the reason that we went and we actually re implemented the state transition and no stdin because it actually turns out to be pretty hard to run reth on top of things like ZKVMs Tees, default proof vms, given that they're kind of limited execution environments. No STD allows us to have a lot more control over that. The other thing that we have is built on top of these libraries. We have the first alternative faultproof program for the op stack, which kind of sits beside the op program. So Kona client is the faultproof program, and it's built on top of the derivation pipeline. We have a stateless l two block executor with a Merkle Patricia trie that's kind of recursive in memory.
00:01:27.790 - 00:02:41.340, Speaker A: And then we also have the hostclient I O libraries that allow for it to communicate kind of over an operating system pipe to pull in external data. To give you guys an idea of kind of where this sits inside of the faultproof stack, we'll kind of decompose the problem whenever we want to verify a claim about the state of l two on l one. The normal process for that would be to first derive the l two chain, which basically is a data transformation function between batches, which are posted down to l one by the sequencer into l two execution payloads, and then we pass it over the engine API to the execution layer, kind of standard as l one does as well, and execute the l two blocks to kind of form the output state. And normally these are in two separate processes. So we make the fault proof program, which kind of smushes the derivation, which normally sits in the Opstack's consensus layer, and then the block executor, which sits in the execution layer together into one process. And so it turns out that you actually can't execute this on chain because it's just rust or go code. And so we implemented the faultproof vms, which most of you may know canon, some may know asterisk, and they're effectively these minimal virtual machines that are implemented both natively and in solidity.
00:02:41.340 - 00:03:18.010, Speaker A: The solidity version is kind of a stateless executor of the VM. And then so we can't execute the full program on chain on those vms just because it would cost too much gas. And so we have the bisection game, which actually allows us to narrow in on the instruction step that we're looking for, and then ultimately that can decide the total dispute. And so Kona client is kind of at that very top level of the kind of smooshing together of the consensus level layer and the execution layer. There's kind of a more long winded blog post. So if anybody's kind of more interested in the technical details, there's the QR code. I'll give a second.
00:03:18.010 - 00:04:07.140, Speaker A: So kind of to demystify the process a little bit, this is all that the entry point actually is. There's a lot kind of happening under the hood here, but at a high level it's really not super complicated. So we can start off at the very top. We're pulling in the boot info, and the boot info is a couple of trusted inputs. One of these is defined in the contract, which is kind of the l one head hash. It's a commitment to the historical state that contains all of the batch data, et cetera, that we need to actually feed into the derivation pipeline to transform into payloads. It also contains a trusted l two starting commitment, which is like the previous finalized proposal, or in the case of kind of an optimized bisection game, the pre state that was agreed upon by both parties during bisection.
00:04:07.140 - 00:05:30.140, Speaker A: Then once we actually have that information, we also get like the claim, which is the user input, and then the l two block number that the claim corresponds to, we feed that into the derivation pipeline, which effectively unrolls that commitment on l one to generate all of the data fetches from blobs, etcetera, and produces the execution payload up in this function right here. And so once we have the execution payload, we can just feed it directly into the block executor, which takes in a bunch of Merkel Patricia try witnesses, and actually performs the execution of the block statelessly and ultimately recomputes the state route receipts, route transaction route, et cetera, formulates the header and we get to the very end. And so once we're here, we compute the output route. The output route is just kind of like a higher level commitment that pulls some things up to the top commits to like the block hash, the state route, and then the bridge contract storage route just for easy access. And to make the proof a bit more succinct when we need to unroll it, and then just some asserts, just to check to see that when we reproduce this state from trustlessly unrolling these commitments, that the claim was actually correct. If it's not, it'll panic, and that's kind of the end of the program's execution. So it turns out Kona client is actually pretty fast.
00:05:30.140 - 00:06:01.860, Speaker A: Not that performance really matters. In Faultproof world, this is plenty fast enough to execute within a dispute window. It's cool to see that we got a couple of optimizations and things taking advantage of policy on an optimistic path and falling back to consensus if things like batch policy isn't held. But the nice thing for this too is that with it being faster, it becomes more feasible to ZK prove. And we'll talk about that in just a couple of minutes. But the cool thing is these were both executed on a laptop. It's a pretty fast operation to do.
00:06:01.860 - 00:07:06.278, Speaker A: One note is that these are actually using cache local witnesses, so there's no network latency inside of these benchmarks, which would probably two or three x these times in practice. Normally, if you're doing a fault proof run, you wouldn't actually have the witness cached up front. So it kind of brings us into multiproofs and why we built this thing. You know, why do we have a second fault proof program when we already have one that works just fine built off of the reference? So a core requirement of l two beat, which for those unfamiliar is kind of like a roll up warden, keeps people accountable and also does a risk assessment on l two s. They have kind of this big target that everybody's trying to reach called stage two decentralization. And so in order to meet that, you actually have to have the ability for the Security Council to only be able to intervene in the event of an on chain provable bug, quote unquote. So multiple implementations of the proof, kind of like multiple implementations of l one clients offers us kind of like a sane path to getting here.
00:07:06.278 - 00:07:59.024, Speaker A: So we can do this by allowing the proofs to challenge proofs themselves inside of the dispute game, with a disagreement being considered a consensus failure, and kind of unlocking the action of allowing the Security Council to intervene. And so another cool thing is with our last year's presentation, we already have Opreth, which a lot of people in this room have worked on. Thank you, guys. You enabled this to happen, but it allows us to basically take that consensus layer and execution layer, smush them together, and have kind of a whole new fault proof program built on top of a completely different implementation. So this image is kind of a visual of what the current system looks like. And you can see that there are a lot of single points of failure. And hopefully this can give you some perspective on why the obstacle fault proofs are still on training wheels.
00:07:59.024 - 00:08:29.722, Speaker A: So any of these red boxes, if they fail and there was no human intervention or air gap, would effectively mean that the bridge's funds could get drained. And so we have the op program, which is built on top of op Geth and op node. The reference implementation, op preimage is the host client IO thing. Canon is the mips, faultproof VM. And then we have the contracts on the side. And every single one of these don't have a redundant component at play. And so if they do fail, we're kind of in a bad spot.
00:08:29.722 - 00:09:34.108, Speaker A: And that's the whole reason why there's still this big operator override in the top, right? Because if they do fail, we still need the ability to be able to recover and keep the roll up rolling. So this is a really cool graph because it shows after the introduction of Asterisk and Kona, Asterisk is a secondary fault proof VM, whereas Kona is a secondary program. We reduce our single points of failure almost to nil. With still the contracts kind of sitting in this point where they are suddenly the bottleneck. And so looking even further forward, adding multiple types of disputes, you can imagine that the handler, for once we actually discover this discrete upon block state transition, we can swap that out with something that short circuits like a ZK proof. And this would actually give us even more redundancy in that area and start looking towards turning many more boxes here gray. And so that kind of brings us to a design philosophy of Kona.
00:09:34.108 - 00:10:03.880, Speaker A: Something that we started trying to do from the get go is making sure that we could run everywhere. So Kona's components were built with alternative backend support in mind. They were starting with no STD, with alloc enabled libraries to promote portability. You can run it on pretty much anything. I actually ran it on a raspberry PI, which is pretty cool. But when boiled down, if we're just kind of thinking about fault proof VM versus ZKVM targets. There's kind of just like two small differences.
00:10:03.880 - 00:11:14.600, Speaker A: So first of all, with the host client communication, it can occur on the fly in faultproof vms, whereas ZK vms have to have that full witness up front to supply as a private input. Also with faultproof Vmsheen, the data received from the host in the native run can assume to be trusted, since the on chain implementation of the host actually verifies the data upon entry. And because we only need that small piece of data to actually perform the single instruction step, we can offload that verification to when it's actually needed, rather than having to do the full constraint inside of the proof. Whereas zkvms, during the runtime, they have to validate all of the data that comes in from the host. So for example, if I give you the preimage of a catch act hash, you actually have to rehash it inside of the ZKVM to show that it's actually the real preimage, and they have to basically just validate all of that in order to fully constrain the proof. And so the nice thing about this is really all we had to do in order to make kona run on faultproof vms and ZK vms, and even in trusted execution environments, is to abstract over the data sources. So the derivation pipeline will read over l one data, it'll read some l two data, et cetera.
00:11:14.600 - 00:11:42.124, Speaker A: And all of that is just trait bounded. You can swap them in and out and allows you to have kind of multiple backends for this piece of software. And so this is really cool. Sysync Labs Uma is going to be talking next alongside Zach O'Braunt. They finished a mvp of the SP one backend for Kona client already, which is a really, really cool thing to see. Their code base is only around like 500 lines of code. It consists primarily of those data source implementations talking about.
00:11:42.124 - 00:12:42.630, Speaker A: And then they've also got kind of like a custom entry point, and they also are able to even reuse our program for generating the witness. You just run it natively, it captures all of the data that it needs, stores it in a big directory, and then they can just feed it in whenever they actually start the run on SP one. So what's next? First of all, we got to get this software out in the wild. So we're looking to productionize Kona and asterisk soon. Kind of on the road to having this multiproof redundancy we have interop support, which is a big ongoing project which our implementation, along with a reference implementation, will have to end up supporting dispute game v two, which is a really kind of. It's an evolution of the existing dispute game that we have on chain that hopefully will mitigate some of the design failures as well as some of the implementation issues that we have around having further abstraction to nest by section, and also have these multiple handlers for the disputes. For multiproofs.
00:12:42.630 - 00:13:36.920, Speaker A: We also now have a kind of independent derivation pipeline which we're using for proofs, but because the data sources are abstracted, you can also have it run in an online context. So we hope that somebody can actually build like an execution extension for a roll up node with Kona derive. And the other thing that we're really trying to do is beef up our multi client test suites. So l one, I know Oliver talked about this, has all of these tools with kurtosis and t eight n, et cetera, to actually test cross client support. If we're going to get serious about using multiple clients in our hot path, we need to make sure that all of that is supported and well tested in a way that's maintainable. So all of these people did a wonderful job and helped contribute to this. Specifically, Andreas, up on the top, who's in the crowd, wrote almost half of Kona with me over the past few months and was a huge help.
00:13:36.920 - 00:14:25.276, Speaker A: And then some other contributors with zacobrant and succinct labs were incredibly helpful in terms of offering us a good feedback loop on our abstractions and making sure that we had it in a place where alternative back end support was a first class citizen. Justice from Torali Labs helped out with some of the ideation as well as some of the implementation. And same thing with Nicholas and hash cashier, as well as Mark Tiniway from Op Labs as well. And so if you do want to contribute, we are hiring for this team specifically. So if this kind of stuff interests you, definitely find me on the side. If you're just looking to contribute in an open source capacity, we do all of our work in the open. This is an MIT licensed code base.
00:14:25.276 - 00:14:34.480, Speaker A: We have a discord where we do protocol R and D. And if you're looking for an invite link, definitely feel free to find me in the crowd and I'll try to get you hooked up. And that's it.
00:14:41.780 - 00:15:06.170, Speaker B: All right, thank you, Ben, for the talk. Any questions from the crowd? And again, only questions. No statements. I have one. How do you relate to Kona being a piece in the multiprovered universe, especially for the stage two roll up decentralization roadmap.
00:15:06.790 - 00:15:59.210, Speaker A: Yeah, so Kona is kind of like the kind of the analog against Op program. So if we go back to this diagram where we have all of the components after the current system, Kona kind of sits beside the op program as its kind of backup redundancy piece. And so we have asterisk and canon, which are the two fault proof vms. And then we also have Kona and op program Kona specifically being implemented on top of op ref, as well as our derivation pipeline, with Op program having the op node and op geth as its execution engine and consensus logic respectively. So these separate implementations are kind of designed such that we have kind of a high probability that the same bug won't be implemented in both at the same time. Following a similar vein of l one client diversity guarantees whenever we do hard forks and implement complex features.
00:16:03.070 - 00:16:03.810, Speaker B: Mark.
00:16:14.000 - 00:16:23.820, Speaker C: So what is your biggest learning been when you're targeting writing code that runs in a fault proof vm or a zkVm?
00:16:24.400 - 00:17:15.996, Speaker A: Yeah, it's a good question. So we initially started trying to write Kona as an STD lib enabled rust library, and the really hard part about that is that faultproof vms are just a really kind of bare metal environment by definition. So it's a pretty minimal soft cpu. Sometimes they don't even support the entire instruction set, and they also support a very small subset of Linux. So I think that Kona only requires four syscalls, which is read, write, exit group, and Mmap, which is really really nice because we have that low level control. And so when we compare that with the Go programs, the Go programs actually have to statically link the go runtime, which means go routines are required. They call pretty much any syscall that they can, which I think go Lang can compile with like 52 different syscalls for the MIPS target, which, you know, not all of which are supported.
00:17:15.996 - 00:17:52.420, Speaker A: And so it's the kind of thing where having no STD code promotes portability between not only our targets, but hopefully future targets as well. Like we were kind of able to run on sp one out of the box with this kind of low level libraries, mainly because we didn't have to worry about compatibility issues with every single new backend that we added. And hopefully that'll lend us a pretty good benefit in the future, especially as we start adding more backends to things like Binius and also future tes. I know flashbots is interested in it, and that's kind of why we chose to make them more low level, no STD libraries to begin with.
00:17:53.640 - 00:17:54.420, Speaker C: Nice.
00:18:00.170 - 00:18:41.872, Speaker A: So there are a bunch of red boxes here. How do we get rid of the red boxes? Yeah, so it's a really good question. I think that there's kind of a complexity floor here that we need to think about. And we can't just like, duplicate absolutely everything here specifically. It becomes really hard in the contract side of things. So the ZK kind of handler for finding the dispute at the very end is a really good way to kind of solidify our verification function once we found the dispute. But one of the really hard things is that that whole kind of like block bisection and chain bisection layer on top are still going to be kind of the same thing, and making those redundant, it becomes pretty hard.
00:18:41.872 - 00:19:24.900, Speaker A: So really what you're kind of looking to do, in my opinion, is minimize the surface. That we actually have to kind of pull out all of the steps on formally verifying a contract that just bisects over a binary tree is really not infeasible. That's something we can do. But if we look at the system in this state, formally verifying this entire surface and, you know, fuzz testing the hell out of it basically means that every future protocol upgrade that we're going to make is going to be miserable. So it's kind of like, how far do you go? Is a good question. I think that you probably want to stop at some point in these contracts, but still probably have multiple verification functions at the end of the day.
00:19:29.600 - 00:19:34.420, Speaker B: All right, so stage two or bust, hopefully soon with Kona. One more question from Zh.
00:19:39.520 - 00:19:48.270, Speaker C: How ready is Kona and the other provers for the Pektra VM changes? Like EOF.
00:19:48.610 - 00:20:14.030, Speaker A: Yeah, so at the moment, Kona is about as ready as RevM is. There's a couple of things that we're going to have to do in our block executor code. Again, we weren't able to actually directly reuse the EVM crate from ref, but we do reuse RevM verbatim. We didn't go and write our own EVM or anything. So hopefully the upgrade will be somewhat pain free. But we don't currently have pector support within Kona at the moment.
00:20:14.740 - 00:20:19.860, Speaker C: Is the idea that that would follow at some later date on the op stack?
00:20:19.980 - 00:20:36.716, Speaker A: Yeah, definitely. The op stack tends to inherit l one hard forks pretty much verbatim. We haven't skipped one since we launched bedrock, and I can't imagine that would change. So if Pectra does include EOF, we will definitely be supporting it on the op stack as well.
00:20:36.908 - 00:20:46.158, Speaker C: Has have the, the proverbs been able to simplify a little bit in like a post self destruct era? Are there?
00:20:46.334 - 00:21:29.876, Speaker A: The provers have definitely been able to simplify in a post self destruct era. So there's this kind of interesting thing where all of this is stateless execution. So I know that you probably heard all of the ref people say that the NPT is the root of all evil, and I agree with them. So account deletions kind of being gone is just an incredible thing, but we still have things like storage slot deletions. So it actually turns out that whenever you zero out a storage slot when it was previously set, that path actually gets deleted within the try. And so deletions in the try in general are actually really, really difficult when it comes to generating execution trace witnesses, primarily because you can execute the entire block with nothing but ethget proof. So just like proving the path to each account and then proving the path to the storage slots.
00:21:29.876 - 00:22:37.522, Speaker A: But whenever you actually do a try deletion, you sometimes have to unblind the sibling, which is hashed inside of a branch node in order to collapse the branch node. And so deletions from the try in general are just a pain in the ass. And having less of those which removing self destruct helped with definitely simplified the prover. But that said, we still do have to handle tri deletions, and I think that that's kind of one of the cruxes of the things that we're going to have to get over. Like we just added a execution witness generation endpoint to retheme. And formally, the fault proofs are really heavily tied to hash scheme geth because in the Geths database they effectively key trinode RLP by its hash, and so it makes it really easy to traverse the tree regardless of where you're going. However, if you're only relying on eth get proof, you suddenly can't actually do all of the tri deletions, because sometimes you need to unblind the sibling, and that means that you have to have extra support to do historical execution and collect all of the tri preimages that are touched not only during the execution part, but actually during state root generation as well.
00:22:37.706 - 00:22:46.786, Speaker C: Is there any denial of service risk where you couldn't run bisection if there was too many of these storage deletions happening, or.
00:22:46.978 - 00:23:41.890, Speaker A: Good question. So actually no, to give kind of a perspective, and I wish I had a perfetto trace to show you guys. But the fault proof program execution is actually super cheap and we're not super worried about that. I think that if I were to say the biggest hotspot in the whole faultproof program run at the moment is derivation and specifically span batch validation. So when we, our sequencer posts down batches to l one, which is kind of all of the transactions that originate on l two, when we actually do this span batch validation, which is kind of validating the encoding and the order of all of the transactions in the batch, there's a lot of remote data fetching, which means it's a lot of communication with the host, which is over the OS pipes and actually takes 65% of the cpu cycles just to validate the span batch itself. And that turns out to be the hot spot that I think we need to address first. But in terms of tri deletions, it's kind of negligible when it comes to it.
00:23:41.890 - 00:23:53.704, Speaker A: And the cool thing about fault proofs is because it's optimistic, we kind of just need to be fast enough, not as fast as possible, but hopefully we can push the performance front for the sake of the ZK teams that also want to run Kona as well.
00:23:53.872 - 00:23:55.060, Speaker C: Great. Thank you.
00:23:58.600 - 00:23:59.460, Speaker A: I agree.
00:24:01.200 - 00:24:02.672, Speaker C: Have you tried looking into how Verkal.
00:24:02.696 - 00:24:04.448, Speaker A: Is going to impact tree deletions and.
00:24:04.464 - 00:24:06.460, Speaker C: All that in Kona?
00:24:07.080 - 00:24:33.750, Speaker A: We haven't done too much exploration in Virkal yet, but I will say is that I'm really excited. I share the opinion that Verkle is probably best placed on l two. I am very excited to have just execution or execution witnesses in the header because it makes our lives just way, way easier. But I don't think that I've done enough searching, nor have I started implementation to see concretely how it would affect our implementation.
00:24:37.770 - 00:24:51.950, Speaker B: All right, so next up today we have UMa to talk to us about SP one ref or the Internet.

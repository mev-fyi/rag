00:05:06.390 - 00:14:53.954, Speaker A: It. It. It. It. It. We're going to start in five minutes, so if people would like to take a seat, please do it earlier than later. So in five minutes we will start.
00:14:53.954 - 00:17:59.064, Speaker A: Thank you. It. Okay, so, so thank you all for coming and a ripped morning to everyone. We have gathered a lot of great people today, and it might be good to do. By show of hands, who here is an Ethereum developer? Please raise your hand. Okay. We mostly have not tourists in the room.
00:17:59.064 - 00:18:38.670, Speaker A: Great. So who here is a rust developer or has written rust in the past? Okay, amazing. Very high engagement group. So who here has deployed rust and in Ethereum in production in the past? All right, great. So we're going to have a great, very high context day with conversations where we can talk without having to talk about the minutiae. So the talk, we're calling it rust retinacence. We're making all the puns that we can.
00:18:38.670 - 00:19:03.630, Speaker A: And let's see where we are going to land today. Here you see that we have some stickers on the back. We have some new ones, some old ones. We have a Zora chain, NFT, that people are free to mint. It's an open edition, which closes on Sunday. And we also have a farcaster channel. And it's been actually had an interaction with someone today where they were like, hi, I know you from Warpcast.
00:19:03.630 - 00:19:30.690, Speaker A: And that was interesting. Maybe, maybe. Who knows? So for the next two, two and a half hours, we're slightly behind, but we have the whole day ahead. We're going to do a few talks from very high context, people from our teams that have built a lot of our open source software. We're going to have some lunch. It's going to be pizza and sandwiches. So if you want something fancier, Doordash is your friend.
00:19:30.690 - 00:20:20.216, Speaker A: And then we're going to do an hour of lightning talks. We're going to have a community showcase of five minutes each from each attendee without Q and A in the interest of time, where people will go over what they've built, and then we can all sit and chat until the end of day. We will take the chairs out, we'll put tables, and it could be a hybrid of like, a hacking socializing situation. This is an untested format, so we'll see how it goes. But overall, get the right people in the room and things happen. And the bar opens at four or five. So the takeaway, like, what am I going to sell you today? Right? What am I going to convince you of? Is that we want you to be building on Rust and Ethereum.
00:20:20.216 - 00:21:05.260, Speaker A: And we also want you to be using rest from this talk, from the other talks. They will sell you other things. So rust is a language that we want to use in production, but we don't have enough people. But it seems like small groups of people are achieving great things with it. So clearly there is something there. And on rest, using that rust foundation seemed to build something also exciting, which we also think has great potential for the future of the ecosystem. So maybe just to go back a little bit, in 2021, it was about a year in a library called Ethersrs, where we started dare to dream, where we said, ok, we have ethers, rs.
00:21:05.260 - 00:22:15.406, Speaker A: It's a good library for interacting with things. What more can we build? And we had a very simple thesis that was if you build everything to be very modular, very well tested and very well documented, then we could hopefully get to the state where the cost of deploying a new application, a new system, a new startup even would go way down. And we thought, okay, what is going to be our foundation? This guy, although these days he looks more like this. Just to be very clear, you don't fuck with. So why rust? So first and foremost, which is an underrated thing for production use, it is batteries included. You download rust, you get the compiler, you get a very annoying teacher, which is the compiler, end Clippy, the linter, you get the formatter, you get the test framework out of the box, you get so many things. And the most important thing actually for production use is a mature ecosystem of libraries.
00:22:15.406 - 00:22:54.370, Speaker A: We have asynchronous APIs, we have databases without networking implementations. Everything again built with the lens of rust, of being like this high performance thing, you get a lot of developer productivity. So there is this meme that, oh, Rust is hard, blah, blah, blah. But like every tool is a learning curve, and there is a productivity frontier that you get once you're past that learning curve. And everyone that has deployed Rust in production in this room knows that very well. If not, I think it's worth talking about and getting over that initial hump. Rust has a culture of documentation and inclusivity.
00:22:54.370 - 00:23:18.324, Speaker A: I find that to be very important. Note how we haven't talked about performance yet explicitly. The documentation is very important for onboarding people. The inclusivity is also very important for making sure we can get people on our code bases. It doesn't need to be hard, basically, it doesn't need to be complex. Everything can be simplified with the right abstractions, the right tests, the right documentation. And that's how we have approached our software.
00:23:18.324 - 00:23:49.854, Speaker A: That's how most people in the Rust community also approach their software, which is very different, let's say, to CRC community, where being able to write hyper optimized assembly that nobody can read is like considered elite. Like, I consider that to be like an anti signal. You get the obvious things that everybody has heard about. Get safety and efficient, you get performance and efficiency. Performance means I can do a lot of things. Efficiency means I can do them with little resources. You also get safety, but you also get developer productivity.
00:23:49.854 - 00:24:48.230, Speaker A: So how do you reconcile all of these? And that is where the rust language employed, modern programming language techniques, mainly the bottle checker, to give you a language that has very efficient memory allocation and very strict types and very eliminating a large class of vulnerabilities, while also giving you very high performance. It is portable, it's cross platform, which means that you can go to Linux, you can go to Windows, to arm, to whatever you want. You can even go to embedded, which is very convenient. And you also got the browser, which we'll hear some slide about from Tom and Wegman later. We did some rewriting. The big con is that you need to learn a new thing, and learning a new thing has a perceived cost, and that is a very fair critique. But take some risk and maybe you will be rewarded.
00:24:48.230 - 00:25:58.804, Speaker A: For Rust and Ethereum, the motivation is very simple. If Rust is a high performance language and Ethereum is mission critical infrastructure, which demands safety and performance, we're going to use iris based software for it. So in Rust and Ethereum, there's this big ecosystem of MEV, smart contract developers, indexers, RPC providers, a lot of things that cause big numbers. And these big numbers, one, they need to remain big because for the sake of our industry, or if there is any performance issues, we'll have trouble saturating demand. So, to the previous slide, Rust is a perfect fit almost for this kind of problem with this cost. But we're two, three and a half years in. So what have we done so far to emulate this concern? So I have put together a small timeline of what has been shipped so far, just to paint a picture or to put things into perspective.
00:25:58.804 - 00:26:35.634, Speaker A: So we started developing even before I joined paradigm Ethers Rs, which later became alloy. At the time, there were a bunch of other rust ecosystem libraries from parity, because parity was developing a party ethereum later on called open Ethereum. But there was a lot of legacy code in that, in these code bases. This was 2017 2018 roast before async await. So it was a very, very, very different world and we wanted to take a fresh perspective at it. So after ethers, we built foundry. Then we found which foundry is for testing.
00:26:35.634 - 00:27:10.900, Speaker A: Then we found dragon Rekita, who wrote RevM, which unlocked the whole simulations game. Then we put Revm in foundry. Then we're like, okay, where else should we put RevM? Let's put in a node. Basically the thesis was, if we have a very fast operating system, that is the EVM, put it everywhere and things will get better. Smooth brain approach. Then we had observed a lot of issues with and tech debt with our software that was built from 2020 did. So we did a rewrite of that and also achieved more performance.
00:27:10.900 - 00:27:51.992, Speaker A: And most of the software on the left side on the prepared M roster are semi deprecated at this point. So we're kind of looking forward and storm later today will also talk to you about Cryo, which is our approach to data. So you can see how there's sort of like a full stack infrastructure approach here, and it's unclear what's going to happen next. It's possible that we want to move up to higher abstractions, whether it is like application layer infrastructure, like a shared sequencer or anything else, we don't know. If you have ideas, please come to us. We're happy to talk and collaborate. This talk is all about Reth.
00:27:51.992 - 00:28:37.876, Speaker A: So after a ten minute intro, we'll get to the topic. So Reth is a new Ethereum execution layer. It is Apache, MIT licensed, which means that it's free for anyone to use fork. Do whatever you want with it, use it in your code bases, use it for commercial use, we don't care, just use it. The very non obvious thing about rhetoric is that we see it as an SDK for EVM infrastructure. What does this mean? It means that not only is it a node, it's a platform that you can build things, and it reduces the cost of shipping something that people would think was hard to a few days or weeks. And we will hear from people today talking about it.
00:28:37.876 - 00:29:15.360, Speaker A: We're going to hear about op ref, we're going to hear about mev ref, we're going to hear about ZK EVM using, et cetera. There seems to be something going on here. Here I have two ips hosted on the same box, by the way. So we're running an archive and a full node on the same machine, or something like 500 or $600 a month, which is pretty cheap for what you're running on it. So if people want to hit that endpoint, feel free. Maybe it will crash, maybe you will. So what? Performance is very encouraging.
00:29:15.360 - 00:30:06.588, Speaker A: Contributors are excited and we're still barely scratching the surface. And this is a slide that is two months old at this point. And we didn't do new benchmarks, but the rough trend remains the same. RET outperforms other nodes from two and a half x to I lost count, like 15 to sync and on database size. It also outperforms things that we thought were already on the efficiency frontier. And based on our most recent findings, it seems like we can do even better than that on the RPC performance, which is the read loads that many people are interested about. For example, if you're an RPC provider, if you're an indexer or anything else.
00:30:06.588 - 00:30:52.972, Speaker A: Reth also provides sustained throughput, up to 16,000 requests per second, which is a lot of queries, a high success rate, and most notably, in many cases, one or two orders of magnitude better latency. So for point queries, many times you will get a response basically instantly, whereas other times other nodes will go through long code paths for no obvious reason. So we're quite excited by that. And big kudos to the team for achieving this big feat. So we get asked all the time, is this production ready? Is production ready when Ret. Whatever. So to be clear, Reth is Alpha software.
00:30:52.972 - 00:31:24.614, Speaker A: Right now we're on the alpha seven release. We're going to have an alpha eight release soon. Sometime by Cancun we'll have a beta. And by the end of year it will be hopefully production ready. Today it's not. So here we have Raul, who will also speak to us later today about his other adventures besides risking 32 eth in alpha software. Risk reward, right? So yeah, Raul, one day he came to us and he's like, hey guys, I'm running this node, it's working great.
00:31:24.614 - 00:32:06.070, Speaker A: And we're like, Testnet? No, he was on Mainnet, but, you know, again, no warranty. If you lose your money, it's your money. Nothing. A quick case study again, we'll hear about that later. We have Opreth. Opreth is a set of patches on Reth, similar to op Geth, which is a set of patches on Geth to enable usage of Reth in L2's, specifically in optimism. Now, what's special about what happened here is that we had a chat in mid July with some people from Coinbase, Roberto, who we have here, and some people from op, which we also have here.
00:32:06.070 - 00:32:33.614, Speaker A: And basically we were like, this can't be that hard. It's a bunch of patches surely you guys can do it. Let's give it a try. And what happened? We set up a chat room and we did a weekly call, 30 minutes a week. Some effort from our team. But what was very impressive was how these people, like Roberto, I think, didn't know rust. Even when the project started, these people figured out how everything works mostly on their own.
00:32:33.614 - 00:33:21.226, Speaker A: And as of yesterday, we're almost at the tip of girly base in one month, when others would think that this would take, you know, like until December, January, February, you know, roadmap level things. Whereas this is a good example of how people are able to understand how not simple codebase works, get into it and modify it in non trivial ways while being safe, or hopefully not introducing new things. Matter of fact, we found a bug in op geth as of last night due to this small thing. Small thing. So we're building a platform, we're building an SDK. What are the uses? Multiple ones. Personally, I'm most excited about the wave of experimentation this can enable.
00:33:21.226 - 00:33:40.638, Speaker A: So it's not just that, hey, we have some existing use cases that will make better. That's great. We'll productionize them. This also enables you to dream more. And many times your imagination is bound by the tools that you have available to you. And when that is unlocked, you start thinking bigger. So what we can do, I do not know.
00:33:40.638 - 00:34:06.970, Speaker A: Novel node architecture is particularly interesting to me. And in general, the introduction of more low level cryptography primitives on ethereum. You can do this today, by the way. You can do ret equals git, whatever, and you can use reth. And I'll go over some examples. So we'll go over two examples. One is direct DB access, which means this will get a bit more technical, but people should be able to follow.
00:34:06.970 - 00:34:53.690, Speaker A: It is insane that we're querying nodes over JSON RPC. It's just insane. Like when you have an sqlite file, you don't spin up a rest API to talk to it, you talk to the damn file. So what we're going to see is that by having a good abstraction for querying the database directly, you can get a lot of efficiencies without requiring you to be an expert. And we will also see a perennial problem that exists in all node operators, which is, hey, I have a node, I want to add some functionality on it. I click fork on Go Ethereum, I add a bunch of spaghetti code. And then when Geth releases the new release, you end up like rebasing for like a week or a day wasted time.
00:34:53.690 - 00:36:07.456, Speaker A: So instead it would be nice if you can extend the node and get the CLI and everything all good without having to fork it, because that way we have some canonical implementation we can all agree on, we don't waste time rebasing, and we have a unified ecosystem in the end, and that's the goal. So I don't know if this is visible from behind. I hope to some extent. Basically just to walk you through this snippet, you import four things. You define your main and the result type doesn't matter, and you do a few very obvious things, right? You open the database, you query, you get a handle to the latest state to the database, and then you query the database, you say, I want to ask this address and this storage slot what happened? Or if you want to query the historical state of the database given just a file, right? All I'm giving it here is a path to a MDBX file, and that's it. No RPC, no nothing. I'm reading bytes and this shows a very simple example of how I can either query the latest state of Ethereum or any historical state, which is really powerful.
00:36:07.456 - 00:37:17.700, Speaker A: You see this is like what, like 24 lines total? And you already know how you can iterate through any table, right? So this is just for state. You see, I am importing state provider, an account reader. You could import transactions reader, and then you can imagine easily how you extend this to simulate, pass it to EVM build block, make one. Anyway, in practice we saw retindexer which may be not visible over here. Basically a guy that like is a VP at Aave who didn't know much rust, imported the library and in a weekend or a week had a PoC rest indexer that walks the entire logs table, skips non relevant logs based on the bloom filters, ABi decodes them, puts them into postgres, and outperform the hosted solutions by 75 x. Okay, that's money, right? People pay for this stuff. So if you can build things that outcompete or hosted things with open source code in days, that says something about how the infrastructure landscape will evolve in the next year.
00:37:17.700 - 00:38:01.702, Speaker A: For CLI extensions. I'm showing you here the trait that we have implemented that basically says if you implement any of these methods, your node will get overridden functionality. And we have two methods, one called extend RPC modules, another called spawn payload builder service. Extend RPC modules, add new rpcs. For example, let's say I want to add a paradigm RPC, I can define it and I can get it very easily on the node without forking. And I can also spawn a different payload builder. So by default, nodes usually will query the mempool for transactions to build a payload when they need to propose a block or if they're a builder.
00:38:01.702 - 00:38:39.084, Speaker A: But maybe you want to add an alternative strategy, and we'll hear from that later today. So just again, to give you an example of how simple the JSON RPC API is, on the right, you say, hey, I'm giving my API a transaction pool. I'm implementing a method that I defined. I, and I gave the whole format for that. It should be called, I define it, then I put it in my extend method, and things are working. And then now you can query txpool, the txpol API, txpoolextend API. Again, this is a powerful abstraction.
00:38:39.084 - 00:39:33.584, Speaker A: For example, you're alchemy, you're in Fuhr, and you want to add some kind of extra bespoke RPC that you sell to your customers. You can use this very easily. The other, in practice work where we have the developers off here is that basically you can build a builder and then you can shove it in the node without having to fork it. Whereas if you look at other builders, they're all forks of Geth, or the builders that are forks of Fairygon have even more edge cases in theme. So the next steps for us now are the following, and I realize this is a lot, so maybe we'll do fewer of them. But first and foremost, the goal of this event also is to foster an ecosystem. We want to talk to developers, we want to make sure that people, we're building something that people want first and foremost.
00:39:33.584 - 00:40:14.450, Speaker A: And this is useful and it's going the right way, and we're going to provide all the support needed to make this happen. We have a new release coming soon, which has the full node as part of the proper node suite, which will allow people to be running it on lower end hardware, and it allows pruning depending on whatever table you want, whatever distance you want. So the goal being that you can get a tiny, tiny node just with what you need. So if you're a map searcher, maybe you don't need all the receipts, maybe if you're, I don't know. Yeah, anything really that you want to customize on the database. Cancun is coming soon, the new big Ethereum upgrade. We're almost ready there.
00:40:14.450 - 00:41:11.704, Speaker A: We want to clean up some tech debt that the node has internally, which is just a natural outcome of building it over time. And yeah, Oprah, more performance we're exploring parquet files for our snapshots. So if you're a data person or Python rust, talk to us. And we're very excited about virus R and D that we're doing in particular three directions, one, which is a async IO database. So I O is the biggest bottleneck right now in every node, and building a database that is from the OS level async using a new kernel functionality called IOU ring is very powerful. We have good, not technical progress necessarily. We do have a proof of concept, but we have definitely understood the design space for parallel EVM, and we think we can make it happen.
00:41:11.704 - 00:41:47.310, Speaker A: And finally, we have a vision about a very, very tiny node that holds only state and proxies to other nodes for any immutable data. And that's obviously like a serverless style deployment where you can deploy multiple compute, let's say clusters on the edges, while you have all your storage in a big, like GCPDB or whatever. Yeah, that's it. Thank you for being here. This is going to be a great day. I'm very excited. I can take like a couple questions, and then we can move on to the next speaker.
00:41:47.310 - 00:42:36.748, Speaker A: Wait, do we have a mic? This one is off. Oh, that one. Share a memorable bug that you faced while building ret. And was it a result? Was it because of using, you know, like, how did rust also play into debugging or solving that bug? Yeah, of course. So one bug or ten or 100? The most memorable bug was when we were implementing the stateroot verification algorithm. So the stateroot is a thing in Ethereum, where you take the entire Ethereum state, all the keys and values, you hash them, subject to the rules of the merkel. Patricia, try.
00:42:36.748 - 00:43:19.540, Speaker A: And then you produce a Merkel root that says, this is a digest. This is a certificate of the current state of Ethereum. The hard thing there is, all your data is hashes. So anytime you have a bug, it's a Heisenberg. You don't know where it is because all hashes look the same. So the biggest issue in debugging these things always was due to mev bots and self destructs, because mev bots, basically, when you're calculating the storage route, the issue, it comes around destroyed accounts, when an account goes back to zero, etcetera. So there's a bunch of very domain specific activity which may cause edge cases that are impossible to debug.
00:43:19.540 - 00:43:56.492, Speaker A: So our approach to debugging these very crazy corner cases was we had to figure out how to run the node on slices of the chain. So instead of rerunning the entire sink, have a very fast feedback loop around snapshot run for a million. If it bugs, go block by block. We basically did like git bisect, but in the node to be able to figure out the exact block where something happens. And when you have git bisected, you usually find a problematic block. You go to the block you see, oh, Mavbot self destructed 1000 times. That's probably where a bug is.
00:43:56.492 - 00:44:35.970, Speaker A: So that would be the most memorable bug for me, at least. Now there might be others, but for me, that, like, it was a month and a half of very hard work to get over it. Let's do one more. Yeah. Hey, when you're thinking about getting rust developers, do you typically find just eager developers and get them to learn Rust, or do you find more people who already have experience in rust, contributing to things like rhetoric? Both. Right. So we have hired everyone that we work with out of the issue trackers.
00:44:35.970 - 00:44:56.050, Speaker A: So there were people that already knew both Rust and Ethereum. It is the case that many times, like very talented developers will come up to speed on Rust very fast. They can get productive. So I would say it's both. Yeah. I don't think there's any reason why you shouldn't be giving a try, though, if you care about performance. Low level.
00:44:56.050 - 00:46:30.784, Speaker A: Okay. In the interest of time, thank you all for coming. And we will hear from our next speaker, Matt Seitz, on foundry. And also, if people want to network during the talks, I would greatly appreciate if you went to the other room in order to keep the room quiet. Thank you. Yeah. So we'll have some small downtime in between talks because we have to change laptops.
00:46:30.784 - 00:48:43.690, Speaker A: So thank you for the patience. You need to also mirror, classic German. Yeah, mirror. Somewhere there should be a mirror. So our next speaker is Matt, who has been the first person I worked with on all the rust work, and he will talk to us about foundry as like, if not the most earliest, like one of the earliest contributors to it. So round of applause for Matt. Thanks, George.
00:48:43.690 - 00:49:27.060, Speaker A: And keep the microphone closed. Yeah. Thank you guys for coming. I'm Matt. I wrote a bunch of code for foundry, and now Rev and I will talk a bit about some foundry internals and how it works internally, how we interact with the EVM, how we get cheat codes working, how forking works under the hood briefly. And what are our next steps for foundry? First of all, who has used forge or foundry or some other tools? Nice. Yeah.
00:49:27.060 - 00:50:37.370, Speaker A: So for those who don't know. Foundry is basically a collection of tools that you can use for developing solidity or solidity adjacent work. You can use anvil as a local Ethereum node that has a bunch of modifications that wouldn't be possible with something like geth or ref. So it's a full node from scratch. Then we have cast, which is basically just a collection of sub commands that help when you want to interact with Ethereum nodes or just to convert some ABi data input, output function signatures, something like that. And our main motivation behind all of this was that we want to get to 100% solidity in your smart contracts repository. So getting rid of everything else, just solidity and support writing tests in solidity directly, and use forge for running those tests.
00:50:37.370 - 00:51:37.314, Speaker A: And it's also very easy to install. You have one bash strip that downloads the latest release, and you can use our forge GitHub action to run it in CI. Just to give you a brief overview about the star history, because it's really nice. We hit six k a few weeks ago, but more important, we almost had 300 contributors. We try to be as open minded as possible when they are triaging new issues, feature requests, and help those to land the first pr in foundry. But this talk is not necessarily a talk how to use foundry, because there are way better resources out there. There's an entire course by Patrick Collins that is multiple hours long and for free available on GitHub.
00:51:37.314 - 00:53:06.160, Speaker A: Or you can have a look at our foundry book which covers everything we have in there, references to other useful documentation, templates, things like that. I will mostly focus on some fortune tunnels, but I want to not entirely exclude some cast features. For example, there's cast run, which takes an Ethereum transaction hash and then replace that transaction locally. So it first basically forks the network at the block that this transaction was mined in, then executes all the previous transactions locally. So you get to the states the transaction used when it was first included in the node, and then it re executes this transaction and displays all the traces. So you can see all the calls, all the arguments, and the entire trace call, which is very useful when you need to debug transaction or just want to get a better understanding what is happening in there. And this basically works with standard RPC provider or URL to a node that supports regular ETH RPC methods.
00:53:06.160 - 00:54:20.680, Speaker A: Another cool thing with anvil is that you can use it programmatically, so you can use it as a library, and we see a lot of folks using that for simulations specifically. And getting it to work is super easy, you have basically just one entry point. You configure your nodes like if you want to fork some network chain id, whatever, and then you just fire it and you get API interface. And yeah, basically a node handle that ensures that the node is not dropped. And this way you can bypass the entire RPC layer directly and speak to the node directly without going through rpcs. If you run simulations, for example, you want to eave call, you use the API object directly and you don't need to go through RPC at all. So I think this is pretty cool, but I want to focus on what happens when you run forge test under the hood.
00:54:20.680 - 00:55:38.290, Speaker A: So on the left side you see the template test contract that you get when you initialize a forge repository or forge project. And you see there is some test contract that inherits from the Forge STD test. And you have a bunch of test functions where, this is where you write your tests and you have a bunch of assert functions that you can then use to test your contract calls. And what you see when you run forged test is that first everything is compiled, then we run all the test functions and they either pass or fail. And if you look closely at the test fuzz function, then you see that this function takes a bunch of arguments and those are fuzz by default. So these are fuzz functions where forge internally generates a bunch of random arguments and then calls this function multiple times. So you can have multiple arguments.
00:55:38.290 - 00:56:57.968, Speaker A: And yeah, go wild with the fuzz logic here. But what happens internally when you call forget is that we first prepare the scenario that eventually is invoked and this includes loading all the forge CLI arguments. Like if you have a filter for specific functions that you want to run or contracts, then this is handled here. Then we load all environment variables for, I don't know, RPC endpoints that I want to use during testing. And we also merge it with our foundry Toml configuration file. This is where you can configure a Solseeq specific argument like optimizer settings, fast runs, things like that. Then we go to the preprocessing phase where we read all the project graph, all the files that are included in the, in the project, and then we apply the remapping so we get the entire call that this project consists of.
00:56:57.968 - 00:58:03.836, Speaker A: So this is how we check whether our file changed, if it needs to be recompiled, or it can be omitted because we already have it cached from a previous run. So this speeds up recompile time drastically. And then we populate the solsee input via the standard JSON format, which then which includes all the compiler settings, the source code, whatever. What salsee then spits out is the standard JSON output. This includes the compiled binaries, the runtime code, astrol things like that, or additional properties that you also can configure. And we write them to the output file or update no longer valid cached files. And finally we then apply the test filter.
00:58:03.836 - 00:59:57.260, Speaker A: So we filter out all the test code contracts from the solidity SlC output and call all the test functions via the rust evM that we use for running those tests. So test functions are filtered out by name and we can see if this is a fuss function or a regular test function. If it is a fuzz function, then we generate the arguments based on the function signature and call this function over and over again, and we see whether it reverts or succeeds. As expected, a core part of forge are solidity cheat codes, which you can use during tests to manipulate the EVM or the state directly in a way that wouldn't be valid on the real chain. But it helps during testing if you want to fake the address of a caller, for example, or something simple like setting the block timestamp variable, and all of this is exposed via the VM interface. This is where all the the cheat codes are defined, and those are then used in the forge standard test contract that you use to write your test functions and you can call them via VM cheatcode with the write arguments and then assert for example, that the timestamp was updated as expected. So there's more code.
00:59:57.260 - 01:01:45.488, Speaker A: This is basically the essential part in forge or any tool that needs to modify EVM data. And this is the interface in the Rust EVM which provides a bunch of functions that are invoked during EVM executions where we can manipulate the EVM or the state directly. For example, there are callbacks for when a call starts, when a call is ended, step functions when a new opcode was asked executed, and we can implement custom inspectors like a cheat code inspector for example, which then have mutable access to the EVM and the entire state of the EVM during VM execution. So this is how you can update the block timestamp when warp is called, for example. Or you can do some more advanced things like network forking via solidity code, which will swap out the entire state during execution. So how cheat codes work under the hood is that we have a fixed cheat code address which we listen for in our cheat code in inspector. So every time the call function is called, which happens when a new call is about to be executed by the EVM.
01:01:45.488 - 01:02:51.612, Speaker A: We check if this is a call to the cheat code address, and if so then we intercept it and apply the cheat code. Adding cheat codes is super easy. We just merge new pieces two days ago that added some missing cheat codes for working with the files. Like if a file exists, if it's a directory, things like that. These are small things, but it's very easy to add them. And to add cheat codes you just needs the cheat code signature, the function call that you want to add. Then we use internally Abigail, which is provided by ethos, which takes a bunch of function signatures and then generates entire rust bindings for this function signature.
01:02:51.612 - 01:04:28.490, Speaker A: So what you get by invoking the arbitrant proc macro, a set of solidity functions, is that you get an enum for all the cheat code calls that supports decoding, encoding, things like that. So when we have intercepted a cheat code call, then we try to decode the function input into a cheat code call and then we can apply the cheat code based on the decoded invariant. So when warp is called, for example, then the function inputs should be decoded into a warp call. And we can simply mention on that decoded call and apply the g code, updates the block timestamp and return this only. But this only adds availability in foundry or forged directly. The final step would be to upstream this to forge standards by extending the solidity VM interface. Slightly more advanced feature is network forking via last slide because I think Emily will focus on how to simulate EVM forking later.
01:04:28.490 - 01:05:54.948, Speaker A: But basically since you have access to the EVM data, you can also swap out the entire database under the hood and replace database lookups with something like eth getstorage add. All right. Yeah. Questions? Yeah. From Mike for hey, arbitrage. Curious if the build step by curious if the build step is handled, all the caching, all the artifacts in foundry, is that handled in foundry? Is that handled by ethers, Solsi? And is there any like, do you guys have any plans on the roadmap of how that will evolve the building and the caching of the artifacts in foundry? Yeah. So everything preprocessing is handled by ethersolsee.
01:05:54.948 - 01:06:48.138, Speaker A: This includes caching as well and emitting artifacts and writing them to disk. But since we moving to alloy, eventually this should be moved to foundry directly. So this won't be a part of alloy in the future. Instead we will move it. And probably foundry would be the right place for that. What's the best way to do integration testing, including off chain components because the last time that I tried to do it, I wanted to use Anvil as just purely a library. But what I found was I needed to do state setup, so I need to somehow run script, and I think for that I needed to basically have anvil running and connect to it over the JSON RPC.
01:06:48.138 - 01:08:08.130, Speaker A: So ideally I'd be able to do that all natively in rust. What's the recommended pattern for that? For anvil itself, we don't have something, or I think we actually do support a Genesis file, which you could use to set certain account starter slots when you launch the node. So Genesis JSON file, it's a list of accounts with a list of storage keys and values which you can use for block zero basically, or for forge directly. You can set certain contract bytecodes via cheat codes, but for more advanced setup routines, probably a script or something that is invoked via an FFI cheat code or something like that. Okay, checking. Okay. Hey Matt, I wanted to a question specifically around anvil methods.
01:08:08.130 - 01:09:15.905, Speaker A: For example, with the JSON RPC implementations that are being rewritten in wreath or rest, how will the future of that look like? Because I know there are some, for example debug methods, and I think it's trace methods or filter methods that are already in rest but are not an anvil yet. For example trace filter. How will that look like in the future? Like will that also be built in Anvil, or will you share something, some component so you can have it in both? Thanks for asking. So all the trace implementation in ref are based on Anvil. We fixed a lot of bugs in there, and we also have standalone RPC types in rev now. So the roadmap for this is that RPC types will be a standalone component that any project can use, and all of anvil defined types will be replaced by that. And also all the trace implementations will be replaced by the ref implementation as well.
01:09:15.905 - 01:11:54.758, Speaker A: And this will add a bunch of missing calls, like debug call I believe is still missing, but since we have this already in ref as a separate crate, adding this will be straightforward. I think we can catch Matt offline for any further questions, so let's give him a round of applause and we can welcome our next speaker, James, who will talk to us about Alloydeh. And the overall goal of all of these libraries and long term roadmaps is that we can unify and duplicate code across the ecosystem. So the last question was spot on, on the goal it our next figure, James Prestwich will talk to us about alloy. So round of applause please. Every microphone is different everywhere you go. All right, so I'm James Prestwich.
01:11:54.758 - 01:12:53.470, Speaker A: I'm here to talk about alloy, which is the newest member of the Rust Ethereum stack. Still, I think alloy was started early this year when we decided we just wanted to trash all of ethers and rewrite everything from the ground up, eliminate all parity dependencies, and use proper modern rust to do these things. The parity libraries had the unfortunate downside that they were in in 2015, and rust as a language barely existed back then. So these days, we have async await. We have gats, we have const generics. We have all these nice features that we wanted to integrate into ethers, and we were just better rust developers than we were three years ago when we started this project. So Alloy is now a collection of the most powerful, fastest, most intuitive libraries for ethereum developers.
01:12:53.470 - 01:13:25.786, Speaker A: It is a successor to the Ethers project and will eventually cover most of the scope of ethers. Some of the things like ethers, Soulsea. We're going to punt right out of the project because I don't want to handle that. That's going to become evalir and Matt's problem, I think. Yeah, thank you, buddy. So right now, alloy is primarily me and Danny. Danny I don't think, was able to make it today, but over the last eight months, give or take, that, we've been working on this.
01:13:25.786 - 01:14:00.440, Speaker A: We've put a huge amount of effort into bringing it up to snuff. Alloy today is usable and useful. It's being integrated into places like optimism, arbitrum, risk, zero, zeth. It's making its way across the ecosystem pretty quickly, which makes us feel really good about ourselves. Alloy is a collection of libraries. We've tried to keep this to low level, useful things. In the ethereum ecosystem, we focus primarily on the interface between rust and the EVM.
01:14:00.440 - 01:14:53.228, Speaker A: That means the primitive types, solidity type representations, JSON, Abi files, Abi encoding, and decoding. We feel that we have done the best job of this out of any libraries out there in any language, no matter who that wrote them or what they do. And I'm going to talk a little bit about what the components we built are and why we think they're better than everything else by wide margin. And it's not just because of our egos. So the first thing we wanted to do was get away from parity's ethereum types. These were written again seven, eight years ago, barely updated since then. They have a number of deficiencies and cause dozens of Telegram support questions every day that we just have to answer with, use the debug formatter.
01:14:53.228 - 01:15:30.028, Speaker A: I've said use the debug formatter 50 times a week for the last three years. So we decided to start with the primitive types. This means addresses, uints, signed Int's, fixed byte arrays, and dynamic byte arrays. We based it on Remco's work ruint, which I think he's going to be talking about in a little bit. So you're kind of going down through the stack here. Start with Reth, work down through the alloy, and then into ruint. That everything's based on alloy primitives is substantially complete.
01:15:30.028 - 01:16:24.140, Speaker A: We have a lot of support for different features and is being used in RevM, ref, and other places. After alloy, we wanted to get into Abi encoding, and we decided to shave the yak first. So we want to make it really easy for rust and solidity to communicate. That means that we need an idea of what it means to communicate with solidity. And I'm going to get into why the solidity syntax parser is important in a minute. But basically Danny just went out and one man armied an entire solidity ast representation, just parsing solidity source into tokens that rust can operate on effectively. So you can actually just load your contract into rust right now.
01:16:24.140 - 01:17:00.640, Speaker A: We'll parse everything out. We won't compile it, but we will have an ast representation. Okay, we wanted to make Abi encoding easy and fast. Abi encoding is schema based, so the only way to build an encoder is if you know the types that you're encoding and decoding. So it kind of follows from there that the first thing you do is make a representation of the types that you're operating on. In practice, this is all solidity types. You know, the bytes, 32 Uint, 256 solidity structs errors events.
01:17:00.640 - 01:17:53.086, Speaker A: So we went ahead and wrote a static representation of all of those types in rust. Anything that you can represent as a solidity type, you can now represent as a rust type. All of these types are zero sized. They disappear at runtime, and we use them to make very well optimized static AbI coding routines. Rather than loading everything into some dynamic type representation, we just generate a coding routine at runtime for every type that you actually use in your program. So you are actually representing your solidity type set system that's in your contract in rust, and letting the rust compiler hyper optimize your encoding routine. This makes us two to three times faster than the next best encoding routine.
01:17:53.086 - 01:18:49.308, Speaker A: And more intuitive to use because you can actually just write solidity. As you see here on the slide. We've got that bool two, we represent that solidity in rust, and that's what we work with. So in order to make this even easier, because you don't want to be writing fixed array bool to the complex rust type name for this simple solidity bool to, you just want to copy paste solidity into your code base. So we wrote a procedural macro that lets you just copy solidity into your code base. You can copy entire interfaces, contracts, everything into your rust code base. It will automatically generate all of the soltype types, expose them to you, and let you just move them around, use them like native rust types.
01:18:49.308 - 01:19:50.940, Speaker A: And this is powered by the synsolidity ast parser that we talked about earlier. We are moving towards a world in which you just point rust at your foundry project. It automatically loads up every type that you use and has a static hyper optimized encoder for everything, and you don't even have to think or worry about it. So it allows you to embed your solidity contracts in a rust code base and not even think about encoding decoding. No more loading up JSON files to get interfaces, no more expensive runtime parsing of these things. It all happens at compile time, and it makes the fastest possible ABI encoder in case you do want to do things at runtime, because you need to do like a mevbot or you need to do EIP 712 signing or something like that. We also wrote a dynamic ABI encoder.
01:19:50.940 - 01:20:39.180, Speaker A: This means a dynamic runtime representation of slow to do's type systems and values. The purpose here is to allow for the sign typed data RPC request, which I think is also Remco's fault. Somehow you don't know when you compile your signer what you're going to sign. That's just the way it works. In order to handle that, you need to be able to represent those types at runtime. So while alloy Soltypes has no runtime overhead from the type system, Alloy Dynabi lets you be a lot more flexible, operate on runtime types, but have all the overhead that comes with that. Nevertheless, we're doing the same thing that Eth ABi did, but we're doing it significantly faster.
01:20:39.180 - 01:21:26.910, Speaker A: Danny optimizes everything just crazy, way better than I can. So even though we're not having all the benefits of static routines, it's still faster than the alternatives. Okay, so that's all of alloy that exists right now that you can go out on GitHub and use and interact with and is ready for testing consumption still, you know, early beta pre 1.0 release. The thing I'm working on right now is Alloy next. This is the part of Alloy that replaces ethers provider networking JSON RPC stack. So this is the part of alloy that's actually going to talk to the nodes.
01:21:26.910 - 01:22:05.028, Speaker A: The first component is alloy transports. This is like the HTTP, the websockets, the IPC code. The main thing we did here is we're swapping out customers custom network code for tower. Tower is a commonly used service model in rust. It lets us get a bunch of ecosystem code for free, and we no longer have to maintain things like quorum or rate limiters in house. That's going to let us cut several thousand lines of code out of the ethers project, which I love cutting code. I love it when other people maintain useful code.
01:22:05.028 - 01:22:34.200, Speaker A: Thank you. So this replaces ethers providers. The code is very generic. It involves these huge tower associated type blocks. So I'm not showing it here. The next part of the stack is alloy networks. When building ethers, these people went out and very rudely started building other blockchains chains besides Ethereum.
01:22:34.200 - 01:23:09.810, Speaker A: We have these roll ups and stuff now, and everybody who made another blockchain decided to get clever and start changing the transaction formats. And that means changing the JSON RPC responses and arguments and everything. And before you know it, you have this data type explosion where every network uses a different transaction. So you have to have a different object. And ethers is not built for that. Ethers middleware assumes every transaction is a transaction. It doesn't check that it's an optimism transaction or an arbitrum transaction.
01:23:09.810 - 01:24:00.696, Speaker A: So new in alloy is the network abstraction. A network describes the types of the JSON RPC. So the optimism network type is free at runtime, but it includes the type information for the optimism RPC. It tells you what optimism says a transaction is, or optimism says a receipt is. This lets us build alloy providers. The provider is abstract over the network and over the transport, so you can have a provider that connects to optimism via HTTP. If you look down here in the estimate gas, you can see that it uses the network's transaction request object.
01:24:00.696 - 01:25:07.446, Speaker A: So when you estimate gas, you're providing the type that optimism says is a transaction request. This lets us use the same middleware methods and code, but swap out the actual types that you're working with so that you can specialize your code for optimism if you want to or, you know, use Ethereum or provide your own network. The goal is to make the RPC commands that we must work with, because that's how nodes work more flexible in our code base. And the specific like user problem we're solving is as of today, you cannot use optimism and Ethereum in the same binary with ethers RS optimism is a feature. In order to enable optimism, you have to make it not work for Ethereum anymore. After alloy providers with the network abstraction, you can have connections to both networks in the same program at the same time. And as a bonus, the traits are now object safe.
01:25:07.446 - 01:25:45.266, Speaker A: So you can abstract over what middleware you're using and you don't have to manually manage that anymore. And every user facing part of the API gets simpler. So that's the slides for today. Does anyone have questions? That means I explained it really well, right? Yeah. Do we have microphones around? Who's carrying? I mean, if you shout at me, I can probably hear you. There we go. Hello.
01:25:45.266 - 01:26:18.320, Speaker A: Hello. Yeah, it's very impressive to get the using the procedure macro to support solidity. I cannot imagine how many dirty hacks there, but any plan to support yo or so. It's actually cleaner than you would think. It's about as clean as you can make a procedural macro. You know, due to the constraints of procedural macros, you can never make them really clean. But this one's not bad, relatively.
01:26:18.320 - 01:27:19.056, Speaker A: We don't currently have plans to support any other languages than solidity, but we have just discussed it, and the stack is designed so that you could write a syn Viper or a synneural if those languages support the rust token model as well as solidity does with Viper. It's very complex because whitespace is significant and the rust token model doesn't support that. So you would need to do a lot more of the tokenization and parsing work than you need to do do with solidity. Our long term goal is to have essentially an intermediate representation, that you build these solidity things into the intermediate representation and then expand from there so that we can be a lot more flexible and build interesting transpilers and stuff. Great, thanks. But we keep it at the code gen level. We're operating on asks.
01:27:19.056 - 01:27:57.040, Speaker A: We're not operating on bytes. Great, thanks. Where does RLP and Ssz fit into alloy, or does it? RLP is part of alloy. We have the RLP crate that we took over maintenance from Rethenne, which is a great implementation. So that is officially part of alloy as well. It's just significantly less interesting to talk about on stage. Ssz we have not in housed for alloy.
01:27:57.040 - 01:29:14.912, Speaker A: We may in the future. The focus for alloy is primitive types and interacting with the EL and SSE doesn't directly further those goals, but it is the kind of low level pure primitive that we want to eventually support. One last are you keeping the middleware structure for customization, or have you played around with any other ways of doing that? We are likely to keep it but improve the abstraction. This is another thing where we home rolled that middleware abstraction and we're not happy with it. So the idea is to have the provider's trait replace the middleware trait and to have a similar but better abstract middleware stacking system. If anyone has an alternative to that, I do not love the middleware stacks that we produce. The goal of this is to make it simpler.
01:29:14.912 - 01:29:58.200, Speaker A: So instead of a giant concrete type, we box or we type erase and make trade objects. And that makes it a lot simpler to manage the types of your middleware. We also have been experimenting with a tower like layering abstraction so you can have a layer builder that makes it easier to instantiate these things. But I don't love the core middleware abstraction. I just none of us seem to have come up with anything better. Yeah, the middleware is all tech that blame 2020. If you have a better suggestion than middleware stacking, like let me know.
01:29:58.200 - 01:31:02.296, Speaker A: Please someone please help. Round of applause for James please. Nice. Next up we'll have Remco from Worldcoin who will talk to us about Ruint, which is probably the most low level building block that we have in the stack right now. And yeah, Remco can explain it better than I can. So thank you, Ramco. How about now? Good.
01:31:02.296 - 01:31:57.580, Speaker A: So welcome to the bottom of the stack. Let's start with some existential questions. What is it? Ruint is a rust beacint library for large, fixed size unsigned integers. Fixed size here means that the size is known at compile time, unlike some other bigint libraries like GMP and num bigint, which are dynamically allocated and are therefore slightly less performant for the sizes we're using. In Ethereum, which is mostly a uint 256, rust has a bunch of built in unsigned integers just like U 32, U 64, all the way up to U 128, but unfortunately the next one is missing. This is a rush choice, actually. LLVM, the compiler backend, supports arbitrarily sized integers quite efficiently, but rust doesn't expose it, so we need to do it ourselves.
01:31:57.580 - 01:32:45.820, Speaker A: And that is what ruin does heavy emphasis on developer experience. I found that in some of the other existing libraries that are out there, the thing that annoyed me is that the function I needed wasn't implemented and I need to somehow work around it or some features weren't implemented hard to do. So I wanted a library that was just turnkey does everything you want. In particular, I made sure that it's a drop in replacement for something like U 64. All the standard library functions that you expect are there and do what you think they should be doing. It is also, unlike some other libraries, actively maintained. And a big shout out to James and Georgios for this because I got distracted trying to onboard the entire world onto blockchain somehow.
01:32:45.820 - 01:33:31.406, Speaker A: Another question, why did I end up writing it? So one of the main reasons is Rust's orphan rule. If you build a library that exposes some important type, and this type doesn't have some trait on it, let's say Certi, it is incredibly annoying to, as a consumer of this library, add this on, it's impossible. You either fork the library or you need to use a new type on some other weird construction. You don't want this. So that was the main motivation to build a library that has all the traits. Second is constgenerics. We just got const generics and I so wanted a library where I could do uint and an angle brackets and tell it how many bits I wanted, and I wanted to see if I could build something like that.
01:33:31.406 - 01:34:05.900, Speaker A: Turns out, yes, kind of. And I had some from a previous project, some really fast ports of GMP algorithms lying around that really needed a new home where people could actually use them. So that's the motivation for starting this project. Starting with all the traits, I made them all optional. They all have feature flags, so you don't blow up your compile times if you don't need it. The way dependency resolutions works is that whatever is needed in your entire project automatically gets enabled. So that's cool.
01:34:05.900 - 01:35:15.836, Speaker A: It's probably barely readable, but there's a whole list of traits it implements. Lesson learned along the way is that these traits, like let's say Serdi or ARG FF, they upgrade sometimes, and that is technically a breaking chains, which would be really annoying because it multiplies over all these dependencies that are there. So we're working on a solution there to support versioning of implemented traits. And probably all these feature tags will also have a major version associated with them so that you could implement, let's say, 32 and enable Certi three and even have both enabled concurrently, if that is what your project needs. Now, I said it was mostly compatible with STD, and indeed, if you find anything non obvious and different about these units versus the built in native ones, that's a bug and you should report it. But there are a couple of changes. The standard operators, plus, minus, multiply, etcetera, they wrap by default kind of a design choice.
01:35:15.836 - 01:35:58.512, Speaker A: The built in rust ones will panic in debug mode and then silently do undefined behavior in release mode, which is not a good idea. The other thing is that shifts in rust are a little bit awkward, because if you give it a shift amount that is larger than the type itself, it's also undefined behavior. We don't want that. And then some technical constraints, like some functions, couldn't be made constant because of technical reasons. Anyway, recommend you read this part of the doc before you really go deep into it. Now it would be disappointing some members in the audience if I didn't present a little bit of moon math. So this is the moon math section.
01:35:58.512 - 01:36:59.462, Speaker A: What this library actually implements is what in number theory is called a ring, which is the integers modulo two to the power something. This has addition, like a ring has addition, subtraction, multiplication, etcetera, as you've learned it in primary school. But it also has an inverse, which is the like anti multiplication element. It's basically a number that when multiplied like if you're given a number, you can compare its inverse, and if you multiply the two together, you get the number one, which is kind of like division, except we don't have fractions here. So what does this number look like? I have an example on the right here. Like if we take the number 57 in u and 64 in this case I can compute its ring inverse, and then the result will be this really bizarre looking 64 bit number. But if you multiply that with a wrapping, multiply with the original number.
01:36:59.462 - 01:37:41.698, Speaker A: The result is indeed one. And in fact, if you multiply by this number we just computed, it is kind of like dividing by the number 57. So I compute a number b here that is 57 times something, and if I take that result and multiply by a, I get my original number back. So yes, we've just divided by 57, doing a multiply caveat. This trick only works if the number is if this division is exact. If it is not exact, you get some really weird other number. Another caveat is that these inverses only exist if the number you're inverting is.com
01:37:41.698 - 01:38:42.202, Speaker A: prime with your modulus meaning in this case that it needs to be an odd number. So this only works for odd numbers, and only when the division is exact. But it's a really cool trick, and you can actually use it to optimize certain algorithms quite effectively, mostly because this inverse is actually also really easy to compute. So that's the moon mod section. Another highlight, kind of along the lines of James's work as well, is like how do we use the proc macros to make things easier on the developers? One of the things, and this is partially a motivation for writing this library as well, one of the things I've realized is that Rust's tokenizer actually supports arbitrarily sized integers. Like the token stream representation just has a string for the integer that is in your source code. So the unmar takes whatever rust source you give it.
01:38:42.202 - 01:39:25.440, Speaker A: It finds all the integer constants and checks if it has a suffix that starts with a capital letter. Uh, standard library types have a lowercase u. If you do an uppercase u, it will get picked up by this macro. It takes whatever is in front of it. It will parse it exactly the same way as rust would do by itself, except it will do it in an arbitrarily sized type, and it will do this. It will then produce a constant and substitute it in like the output code. So this basically allows you to just wrap a bunch of code in this unmarked, and now you can write code using the ruined integers as if it's native rust.
01:39:25.440 - 01:40:32.050, Speaker A: Another fun thing in the project is it has a little bot that I've been playing around with that automatically creates GitHub issues for any todo commands that are in the code. I'm a firm believer that you need to keep your project management as close to the source code as you can possibly do. This one allows you to just do your to do management in the code system itself. Fun little hack other fun bits of code like I mentioned, there's a couple of pretty sophisticated algorithms in there that I ported over from GMP. There's knut division, which is a efficient division algorithm, and lemur GCD, which is a greatest common divisor algorithm that is also used for modular inverses. This one is particularly fun because modular inverses are quite important in cryptographic applications, and I'm fairly sure that this one is more performant than anything that's out there right now, even in the crypto dedicated libraries. So it'll be fun to see that get a little bit more use.
01:40:32.050 - 01:42:03.650, Speaker A: Another fun bit of code if you're exploring the library, is look at the postgres integration, I went quite overboard there, and I tried to implement every single column type that could remotely be interpreted as an integer, and in particular the one that's kind of obvious, actually, the numeric type, which is the arbitrarily sized integers that postgres supports. That seemed to make sense to implement, but it turns out that the format is completely undocumented, and I had to dig through the postgres source code to figure out how that binary format actually works. That code hasn't been updated since 94, I think, and it uses binary coded decimal, so it was a good fun bit of history there. On the left you see the function to compute the root like square root, cubic roots, and higher order roots. It uses a fun trick to speed up the process where basically it takes a double precision float approximation of the biginthe uses float operations to create a first approximation of the result, and then just does a couple of quick iterations to turn it into an exact value. This is a way of designing fast algorithms, and it's enabled by having another interesting piece of code that does a very precise conversion from a f 64 double precision float to an unsigned integer. So some concrete questions.
01:42:03.650 - 01:42:57.410, Speaker A: What are the next steps here? Obvious ones are more optimizations. Right now it's, I think, entirely plain rust, so very portable, but it doesn't have specific optimizations you can do in X 8664, which has some fun opcodes like Mulx and Add x, and similarly arc 64 arm. All of them could benefit from more targeted optimizations. Interesting thing that came up recently is like, hey, maybe we should have a RISC five backend or a mips backend here, because it seems that people are now suddenly interested in compiling this thing to RISC zero and canon and other completely new architectures. More traits always welcome. If you want to implement traits, please do. Just submit a printhead, probably get included.
01:42:57.410 - 01:43:27.718, Speaker A: It's kind of zero cost, it's just an extra feature flag, and it will save people a lot of trouble because of the orphan rule. A particular one that is still open and a nice beginner's task is num traits, which has a lot of fun little traits like is zero and is one and you name it. Another thing is maybe extended with more types. Right now it's just unsigned integers. Maybe we want signed integers too. It could be interesting. Like I said, it has fast modular inversions.
01:43:27.718 - 01:44:23.084, Speaker A: Maybe we want to have a whole modular type where you have a compile time modulus and then you can just instantiate this ring and do algebra in it. Or prime fields, even a runtime sized version. Like I said, this one is compile time fixed size. Maybe we do want a version that can leverage the same algorithms that have already been implemented, but use a runtime sized type. So where this one is kind of an array of digits, that one will be a factor of digits. And right now if you peer under the hood, you'll see that it's uint bits limps, which is a restriction of what rust generic can currently do. So you need to provide the number of bits you want, but also how many 64 bit limbs that requires.
01:44:23.084 - 01:45:27.480, Speaker A: It will panic if you give the wrong impossible numbers here, and it would be nice to make it automatically compile time compute how many limbs it needs. But unfortunately this is blocked on rust upstream issues that have been open for a couple of years now, so that will not be resolved anytime soon. The other things though, contributions more than welcome. It's a fun little low stack, high impact project. Should be fairly accessible. So yeah, hope to see your prs there. Any questions? Hey, have you considered adding support for SIMD that would fall under architecture specific optimizations? Okay.
01:45:27.480 - 01:45:53.940, Speaker A: And for clarity, SIMD for parallel instructions. What was the question? I have a quick one, just shout out for the GitHub action. That's awesome. Thanks. Yeah, you should check it out. It also uses git blame to assign the GitHub issue. You love that action, man.
01:45:53.940 - 01:47:10.852, Speaker A: Next, how does world coin use the rowing library library? Sorry, how is workoin currently using this? I think we use it in some places in some of the crypto math, but the main usage will be when we move to an op stack on something like op red, and that whole thing will be built on top of all the foundations you've seen so far. Thank you. Hi, I was just wondering, well, first your blog and approximation theory changed my life, but I was just wondering, what is the most interesting or esoteric algorithm you had to implement for adding functionality to ruin? Oh, for sure, the lemur GCD. That one is a wild one. Thank you. Round of applause for Remco. Next up we have storm from the paradigm team, who has been working on rustifying the data stack with some exciting new tools and a lot of non obvious insights.
01:47:10.852 - 01:48:27.400, Speaker A: So warm applause for storm, please, and we can give him a second setup. Hello? Yes, good. So hi, I'm storm. I work on data at paradigm, and for the past few years I've been experimenting with many different approaches for analyzing crypto data and for building the surrounding crypto data infrastructure. And things are very exciting right now in the data space. And this is thanks to a bunch of new rust tools that I think will fundamentally change the way that we sort of think about crypto data. So today I want to share some of the approaches that I've been experimenting with and sort of give my take on where I think the space is going.
01:48:27.400 - 01:49:23.856, Speaker A: So a fun buzzword in the zeitgeist right now is the end game. It's the idea of what is the ultimate system that we're working toward. And so in the context of data infrastructure, what is the data endgame? There's a bunch of problems in the data space that we need to solve or that an endgame solution needs to solve. So, first of all, right, now, even though blockchains are public ledgers, actually collecting crypto data from these blockchains can take a huge amount of time and energy and expertise. Instead, we want this process to be fast and cheap and easy. And then there's also just basic data concerns. Like we want our systems to be modular, scalable, robust, so we have a pretty good idea of the properties that we want our systems to have.
01:49:23.856 - 01:50:28.470, Speaker A: The big question is how. So one of the main arguments that I want to make today is that we're not actually that far from solving these problems. So first, I'm going to talk a little bit more about the problem space, and then I'll sketch out what I think a proto endgame architecture might look like, and then I'll finish up by detailing a few tools in this architecture. So when I say data here, I'm specifically talking about the infrastructure that makes on chain data available to all the downstream research and applications. So I'm not talking about consensus or validating blocks. It's once the blocks are validated, how do we get those blocks to all the people that want it? And making this process fast and cheap and easy is just a means to an end. The real goal here is to enable all of the feature or all of the applications in this list.
01:50:28.470 - 01:51:18.558, Speaker A: So, monitoring, alerting, accounting, quantitative modeling, people need data for a lot of different things, and so there's going to be a lot of trade offs that we have to navigate for this. But at the same time, there can still be a shared set of foundations that all of these applications are built on top of. And I think this is where Russ fits in and has a really interesting role to play. So everyone knows rust is really good for building infrastructure. It's fast, it's robust, it has a lot of nice, common practices. But the thing is, most people don't want to learn rust. And this is especially true among data analyst types, people that are doing different types of research.
01:51:18.558 - 01:52:12.590, Speaker A: People often prefer to work in higher level languages like Python, like SQL. But this is actually a great arrangement for Rust because rust is good at building composable systems that these higher level languages can take advantage of. And this has already happened in the Python ecosystem. So many of the classic Python libraries now have new versions that are powered by Rust. Under the hood, these new versions are faster, they're more robust, they often have better APIs. And so even though most Python users don't know Rust, Rust is still able to elevate the python ecosystem to the point where people actually prefer it when libraries are written in rust. So I think the dynamic looks something like this.
01:52:12.590 - 01:53:11.390, Speaker A: We build the foundational data infrastructure using tools like Rust, and then once the foundation is really solid, this enables an entire ecosystem of new tools to grow on top of it. So people can use, people that are using the higher level languages can just get the data quickly, easily, without worrying about infrastructure. And this isn't just data scientists, this is anybody that needs data. And this is ultimately the purpose of the data infrastructure. So that's kind of the problem landscape. I want to go over some of the tools and concepts now that can improve the typical crypto data workflow, and I'll show how these assemble into an architecture that we use for internal data work at paradigm. And it's not quite an endgame system, but it's very flexible, and it ticks a lot of the boxes that we've discussed so far.
01:53:11.390 - 01:54:00.636, Speaker A: So this is a high level view of how data flows in the crypto ecosystem. So it all starts at the top, where EVM nodes essentially define the ground truth of what happens on chain. And then data from the EVM nodes can either go to indexers or it can go directly to the end users and the applications. And right now there are many, many, many different tools for implementing each part of this flowchart. But the really cool development in the past six months is that this process can now be performed almost entirely using tools built in rust. And it looks something like this. So it all starts with a Reth node.
01:54:00.636 - 01:54:50.580, Speaker A: We heard about this earlier today. And even though Reth is still in alpha, there's already a lot of tools for extracting the data out of Reth, either indexing it or delivering it directly to its final destination. So just to name a few of these, Rethin Dexer is a way to query ret data from postgres. We heard about that a little bit rest db py is a way to do it from Python and ethers. Reth is a way to use rest's internal database as ethers middleware. So a lot of these tools are still very new, but they already show a huge amount of promise, especially when it comes to their performance characteristics. And then in the bottom half of the diagram here, we have a bunch of tools that aren't specific to crypto.
01:54:50.580 - 01:55:41.760, Speaker A: These are just rust tools that have become really popular in the data engineering ecosystem. And to really appreciate the advantages that you get with these, I think it would be helpful to explain three modern trends in data engineering. So data engineering is something where web two companies have made really amazing progress over the years that hasn't really percolated into crypto yet. So there's a lot of low hanging fruit by just looking at what's going on in web two data engineering, and adapting those best practices over here. And each of these things I've listed can be a huge amplifier on the metrics that we care about. So starting with standardized IPC. IPC is inter process communication.
01:55:41.760 - 01:56:28.970, Speaker A: It's one of the main ways that different programs on your computer can talk to each other. And the big innovation here is a standardized IPC format called Arrow. Arrow is kind of what the data ecosystem is uniting around as its common language for data programs to talk to each other. And what you get with Arrow is the ability to share data between different libraries and processes without needing to make copies. And this is a huge unlock for efficiency and interoperability. So it means that different programs can operate on the same underlying memory. You can take a pandas data frame and convert it to a polar's data frame instantaneously without needing any serialization.
01:56:28.970 - 01:57:13.252, Speaker A: Arrow is also becoming a common way for databases to ingest their data and to expose their data to others. So when you're making new data tools, it's good to ask yourself, how can I make my tool speak Arrow? Because then you immediately get connected to this entire other ecosystem of other tools. So arrow is only for when you're operating in memory, when you're reading or writing to disk. The most common modern format is parquet. Parquet can be seen as an extreme evolution of CSV. Most of you have probably seen CSV files before. You have a file.
01:57:13.252 - 01:58:08.830, Speaker A: Every row in the file or every line in the file corresponds to a row in a table. And CSVs are all about storing tables. Well, parquet stores tables too, but it does so in a much more sophisticated way. So Parquet will break down the rows and the columns into separate chunks, and it will compress those chunks and it will index those chunks so that you get a very compact representation. And it can still be used for efficient queries that only read the parts of the file that are relevant to you. So this leads to huge benefits for storage size and for speed. But really the coolest thing about Parquet is the modern ecosystem of tools that is forming around it, which brings us to our third data engineering trend, which is the separation of storage versus compute.
01:58:08.830 - 01:59:27.000, Speaker A: So the traditional architecture for databases is that every database has its own custom storage format. So Postgres has its own format, MySQL has its own format, SQlite has its own format, and each of these databases also has its own custom query engine that's run on the same machine that stores the files. But more recently, these things have changed and the storage and the computation have been decoupled. So there are now standard storage formats like Parquet that are compatible with multiple query engines, and the data files and the query engine no longer have to live on the same machine. And this decoupling means that you can now sort of mix and match your storage versus computing solutions, and you can scale each one separately depending on your needs. And you can also seamlessly go from querying files on your laptop to querying files on s three without needing to change any code. So with this you get an easy path towards scalability, and it's also flexible for your architecture to evolve over time.
01:59:27.000 - 02:00:27.692, Speaker A: So combining all these concepts, this is the proto endgame architecture that I've been experimenting with, and this is what I use for most of my internal data work at paradigm, and it's been working pretty well. I have a rust tool called Cryo that extracts data from a reth node into parquet files. And then to analyze this data I use polars, which is a rust data frame library with a really nice query engine. And if I want to avoid this middle step and avoid touching disk, cryo can also deliver the data directly to polars using AeroIPC. So this architecture is a really good fit for crypto data in particular. Most of the time I just run things on my laptop and it executes really quickly. And then when I need more power, I can run this exact same architecture on a big cloud node.
02:00:27.692 - 02:01:12.790, Speaker A: I don't need to modify any code and it just works. And since your database here is just a bunch of immutable parquet files, it's very easy to keep data synced across multiple machines. So just a little bit more about cryo and polars Cryo is a bulk data extraction tool, so it's basically a rust rewrite of a bunch of python code I had lying around. And this was my main motivation for learning rust in the first place. I was trying really hard to optimize this python code, but Python gets really slow. It tends to be really fragile when you're doing a lot of parallelism. So yeah, I ended up with Cryo.
02:01:12.790 - 02:02:17.510, Speaker A: And the basic operation here is something like this on the command line where you specify the data set that you want to collect, the block range you want to collect it over, and you can do this either on command line or there's a python interface or a rust interface as well. So as an example of usage, you can tell Cryo collect all the contracts that have been deployed on chain. Cryo will spin up a bunch of worker tasks that collect the data in parallel and save the results as parquet files. And then you can query these parquet files by just pointing your query engine to this data directory. And Cryo gives you a huge amount of control over how the data is acquired, formatted, filtered, et cetera. So Cryo is designed to be very composable and modular so that you can combine it with other tools. So this is an example of combining it with a cron job.
02:02:17.510 - 02:03:24.730, Speaker A: You just tell Cronkite, hey, run this cryo command every ten minutes or however much you want, and this will maintain a live copy of your desired dataset in whatever data directory. And Cryo is also item potent, so it will only collect the data that is currently missing from the dataset. Cryo can collect most of the standard EVM datasets, and thanks to parquet compression, you can fit most of these data sets or even all of these datasets on just a laptop. So, for example, the dataset of all traces in Ethereum history is more than five terabytes on Google Bigquery, but it's less than 500gb when you store it using Parquet. So Cryo can also collect these data sets very quickly. For example, Bantag was able to collect this traces datasette in under 10 hours from an irgon node, and a few years ago this process would have taken weeks. So Cryo is still under active development.
02:03:24.730 - 02:04:27.000, Speaker A: We have a lot of features on the way. So first of all, Cryo is currently using RPC to collect data, and this is nice because it works with any EVM node, but the performance will get a lot better once it has a direct connection to rest's internal database. Number two, Cryo will soon be able to collect a lot more datasets. Basically, any information that you can get over RPC cryo will be able to build a dataset out of it. And number three, we're going to upload a copy of each of these cryo datasets to the paradigm data portal so that you can access this data even if you don't have access to an archive node. And then very quickly, Polars is the other tool that I'll talk a little bit about. So polars is a rust data frame library for Python, which means that it's for reading and transforming large tables of data.
02:04:27.000 - 02:05:18.210, Speaker A: When you have a directory of parquet files, polers can run complex queries on those files in a really efficient way. And something that's really cool is you can still query these files even if they're too big to fit in memory. So you can run queries on the 500 gigabyte traces data set from your laptop. I definitely recommend checking out polrs if you're doing any data work in Python. So as an example, let's say you collected the parquet data set of Ethereum contracts. Polrs can run just about any query you want on this data, and it can do it quickly. So if you wanted, you could load all the addresses of all contracts into python from the files in under a second.
02:05:18.210 - 02:06:20.310, Speaker A: You can also do things like get all the contracts deployed by an EOA, get all the contracts deployed with a certain bytecode, all these things are very quick. And it's a similar story for all the other data sets that cryo can collect. And something that I've noticed in myself and others using this style of architecture is that it really changes the way that you think about your data. When it's totally frictionless to explore your data, you tend to explore it more and you tend to gain a deeper level of understanding because you're exploring it more efficiently. So that's all I have for today. How do these things fit together into the data endgame? I still think there's a lot of work to do, but there's a huge amount of progress being made on all the important fronts. So with modern tooling, we get things that are extremely fast, extremely cheap, not quite effortless, but it's getting easier all the time.
02:06:20.310 - 02:07:09.272, Speaker A: More and more data is becoming available. You get formats that are open and interconvertible, and you can run the same architecture on your laptop or in the cloud. So I think that if this rate of progress continues, we're going to like each of these issues is going to reach a near optimal state in a short to medium term time frame. And with that, we're going to have sort of a new foundation that a rich data ecosystem can grow on top of. Thanks for your attention. We have time for two questions. Hi, I'm using Kreu and production stage.
02:07:09.272 - 02:08:11.470, Speaker A: I really thank you for your kind of these amazing repositories. And I want to ask questions like, what I found is that the current of the parquet is now representing in the binary format if it's not a big int type. So what I did on my pyspark code is to transform those binary into the hex binary format and then to decode according to the ABI files that I want to, want to decode it into. And it gives some kind of painful time to process in my spark the clusters. So is there any kind of more plans to implement those Abi or hex decoding features in the cryo? Thank you. Yeah, so this is actually something that's being worked on right now by Eric from Zora. This is definitely like a known problem that we want to tackle head on.
02:08:11.470 - 02:09:16.996, Speaker A: So we're going to get direct decoding of logs, we're going to get direct decoding of different function calls and traces. All that's on the roadmap. I've got a question. We had talked in the past about this not being well suited for, like, maintaining, like, live, like, to the tip chain sink. I was wondering if you'd figured out any solutions for, like, maintaining some kind of like, batching process that combines the data from the chunks that have had enough blocks to complete with, like, the delta at the tip of the chain that hasn't been completed yet. Yeah. So right now, cryo has an option, a command line option, where you can give it a number of blocks where it won't save any blocks that are newer than that age.
02:09:16.996 - 02:10:10.630, Speaker A: So if you give it a high number, like 1000 blocks, you basically never have to deal with reorgs or anything like that. That's easy mode. Eventually, it'd be nice to implement some direct reorg logic so that you can actually stay close to the tip without any sort of delay. That's not currently something we're working on, but it's something we're thinking about right now. Cryo is very focused on bulk historical analysis, but reaching into these more like, streaming type use cases, I think it's like a natural evolution, and it'll probably happen eventually. Lot of love for storm. And for every one of these topics, feel free to find the speakers out there.
02:10:10.630 - 02:10:45.536, Speaker A: So our last speaker before we do a quick lunch break is Tom from Wagme, who will talk to us about not rust, but maybe there is some rust. Yes, and Tom is a frontend developer. We don't hold any will towards him. It's okay. Nice. Can you hear me? Yeah. Thanks for coming everyone.
02:10:45.536 - 02:11:14.878, Speaker A: Super excited to be here. Thanks for paradigm for hosting this event. We're going to talk about two programming languages today. Any guesses which ones? What's that? Rust is one of them, not JavaScript. JavaScript is like, no one really likes it. We're actually going to talk about typescript, which is like a little different. And if you're not familiar with typescript, it's a superset of JavaScript.
02:11:14.878 - 02:12:19.670, Speaker A: It actually has a really important role in the crypto community, everything from Uniswap, Ens friend. If you've used any of these things, they have front ends, which are primary ways that people interact with protocols and other really cool stuff we build. And I just so happen to maintain a couple open source libraries. One of them is WagMe, which is a higher level react hooks library. If you've donated to the latest gitcoin round, you've used Friendtech, you've registered a domain on Ens, anything like that, you probably used Wagme, it's pretty popular throughout the space, allows you to do stuff like connect wallets, send transactions and yeah, I mean it launched fairly recently and it's sort of taken over the front end world. Me and then my co collaborator Jake, who's in Australia, so he couldn't make it, started collaborating with paradigm in November last year. And yeah, just some examples of what you can do.
02:12:19.670 - 02:13:02.790, Speaker A: Here's like really simple way to connect a walleth. You would think that this is easy, but there's so many different wallets out there, hardware like lots of other ones. And if you do a little bit of configuration, wag me and then just put this code into your editor, you end up with something that doesn't look quite as nice as that because you have to write CSS, which is kind of a disaster. But yeah, and then you can do other stuff too, like contract interaction. Here's an example from mint, fun. Just like minting nfts, pretty straightforward, not a lot of code. And so we had this higher level reactive framework to build applications, but we wanted to move a little bit further down the stack.
02:13:02.790 - 02:14:09.250, Speaker A: And so there's things like this that have existed over the years, web, three, J's, ethers, J's, and I feel like similarly to the rewrite it in rust mentality. We were sort of like rewrite it in typescript, like really really good type safety and type inference. And so VM, which is our effort for that, launched earlier this year, it's a lower level interface, does JSON RPC requests, abi encoding and decoding, signing. It's kind of a cool thing to do because Wagme was originally written in ethers, j's we wrote VM, swapped out the underlying implementation, everything kept chugging along on all like the dapps and stuff that were using it. And so VMS, you know, we rewrote it. It's pretty fast. This isn't probably what you would see if you compared rust with these different JavaScript frameworks, but in terms of like encoding, it's like the fastest out there that I'm aware of right now that's used and very popular.
02:14:09.250 - 02:15:15.028, Speaker A: And it does some cool stuff like you can interact with anvil really easily, there's wrappers for all the anvil methods you do use, and this is really popular and people using it in their front end like test suites and stuff like that, this is the part that I get really excited about. So basically everything up until this point has mostly probably just looked like JavaScript to you guys because it is. Typescript is JavaScript and there's this really cool thing that you can do. Typescript is a terrain complete language and what you can do is you can take code. So in this case here we have like an ABI fragment, which is a tuple, and then in the typescript type system you can transform it and then create static types which then, you know, add a lot of nice type safety, whereas JavaScript doesn't have any. And this is really important because you know, if you passed, you know, the wrong number value or you know, you're not passing in an address or something, people might lose money, something might break. It's not a great situation to be in.
02:15:15.028 - 02:15:54.382, Speaker A: So here's an example. We have like this Abi fragment and yeah, you see a type error here because we know we've parsed that in the type system and then pulled it out and said okay, this needs to be a big intensive. And because it's not, it's throwing an error bigints in JavaScript this would have been 420 and then an n after it. And you know, similar thing. You know, we don't just do types, we do like, you know, two fixed length tuples too. So here's one. The type system is really cool and allows us to do some like pretty complex stuff.
02:15:54.382 - 02:17:06.108, Speaker A: It's like a whole programming language in its own. And just to demonstrate something that I think is even cooler, but demonstrates the power of typescript, this is like a function we have human readable Abis. This is a function called parse Abi, which takes basically you can just copy the signatures from your contract. It has two implementations, one at runtime, which will transform those strings into like a JSON Abi, but then also a parallel implementation at the type level, which in your editor, you see I'm hovering over the symbol and it's transformed it, which is cool. So yeah, I think one thing that we've been trying to hammer on a lot is this concept of advanced developer experience, which coming from the rust world, some of these things might look pretty similar, like making sure things are strongly typed, inferring types wherever we can. It's really nice to be able to just go into your editor and write some code and autocomplete your way to success. And yeah, we support ABIs type data schemas.
02:17:06.108 - 02:17:54.679, Speaker A: The AbIs can be massive. If anyone has like a really large contract that they know of, you can tell me about it, because I'd love to like try it out. But you know, this stuff works really, really well. You can largest, you know, you can just throw massive contracts at it and the type system is able to handle it all modular architecture. So we really care about making sure that all the functions that exist in VM and Wagme, you know, are low level enough that you don't have to like do workarounds and things like that, and they're really composable and work well together. And then, because often this stuff is running in the browser, some people are building their APIs with VM and other backend related stuff. But because a lot of this often runs in the browser, making sure that it's as small as possible.
02:17:54.679 - 02:18:46.233, Speaker A: Yeah, and we try to make contributing easy. Wagner, I think, has around 150 contributors. VM has I think around like 80. And yeah, really high quality docs tests, because that's the stuff that makes, I mean, that stuff can make your day job really painful if you're using library and makes it easy for people to learn. I think reading the VM docs has been really helpful for a lot of JavaScript people because it sort of introduced them to lower level concepts in Ethereum that were abstracted away before or they didn't really understand. We tried to use the same names for stuff like RPC methods map, like those names map to exactly the same names in VM for functions and stuff like that. And so yeah, I mean, the stuff we built has been pretty popular.
02:18:46.233 - 02:19:11.750, Speaker A: Okay, so now for rust, like, you know, writing typescript, there are some things that I am very envious of. When I look at the rust world, error handling JavaScript isn't the greatest. One of my personal favorites is like pattern matching rust. It's like really nice. I wish something like that existed. There's libraries and stuff. I feel like the JavaScript community has basically built libraries that are rust language features.
02:19:11.750 - 02:19:50.738, Speaker A: Package management is another random one. Cargo is great. There's three package managers at least that are popular for JavaScript, and then obviously performance. That's something whenever you're writing something makes you feel good about it. So this is where we get to maybe combining rust and typescript together. This is kind of like, you know, a blue like, because typescript's blue like Ferrous cartoon version. And so it's something I've been thinking about is like, you know, how can you take some really great stuff, typescript types, and that's like the stuff that, you know, JavaScript developers are using in their editor and like keeping things safe.
02:19:50.738 - 02:20:51.454, Speaker A: And how can you pair it with something like using rust at runtime? Maybe there are some libraries and stuff that you're lazy and you don't want to re implement that in JavaScript. Maybe they're really solid, lots of people use them, they're extremely performant, stuff like that. So yeah, this is just an exploration into typescript and rust via webassembly. Sort of the goal here was to see if we can maintain the same developer experience, but then also maybe reduce some things like bundle size and improve performance significantly, and also give JavaScript developers access to the rust community because there's a lot of great stuff happening. Yeah, and you see the typescript logo here, it's not as great as Ferris. So unfortunate. Okay, so to set the stage, have a demo, it's going to be using ethers rs.
02:20:51.454 - 02:21:22.530, Speaker A: Unfortunately I'm not familiar enough with alloy to have implemented that. And yeah, VM, we're going to compare them together. So on the left hand side is ethers rs and this is going to be signing some data which we'll look at in a sec. And then on the right is VM. So yeah, I wonder which one's going to be faster. I mean that's pretty fast, right? You know, not perceivable, but you know, it's rust. So definitely quite a bit faster there.
02:21:22.530 - 02:22:18.216, Speaker A: So what does this look like if you wanted to do this for one of your libraries, how would you do it? So there's some imports and stuff that's not here and excuse like my rust if it's not, you know, something's a little funky with it here. So yeah, we're just signing some type data. So we're going to expose that method in a way that wasm can use. And then also we're going to be generating random wallet, so doing that as well. If you're not doing any crazy type level programming, which we are, you know, in this case we are, you can just get typescript types to automatically work with this stuff without too much overhead. But in this case we're going to like write some basic typescript using this library called AbI type, which is one that we also work on, which does a lot of the type transformations. And so, yeah, I mean, there's not much here.
02:22:18.216 - 02:22:57.614, Speaker A: It's pretty straightforward. And yeah, and then in terms of what you have now, you run WASm pack and now you have this library that you can use. This is in JavaScript now, and you get all the benefits of rust behind the scenes. And then you also get the benefits of typescript, really strong type safety inference, auto completion and yeah, works really well. So, you know, what does the future of this look like? WASm has been around for a while. No one's really used it. It's not like, I mean, it's not like a frequent thing that people are reaching for all the time.
02:22:57.614 - 02:24:14.928, Speaker A: What are some reasons for that? Well, unless you're doing something extremely computationally expensive where you're okay with having some maybe context switching between different languages, and you're okay going over the WaSm bridge and taking that hit, and then maybe loading some extra bundle size depending on what libraries you're using. Otherwise, people have sort of stayed away. But some things that I'm excited about as stuff improves is maybe we can swap out some internals in VM. We have our own ABI encoding decoding in there, which is pretty fast, like you saw, but it doesn't compare to Rust. So if that becomes a bottleneck eventually, maybe we want to swap it out. Another thing that I think is really exciting is maybe running anvil or something like it in the browser someday for simulation or other things like that. And another thing, I think it would be cool if for certain things that are applicable to a wider audience, maybe people that would use JavaScript libraries that there's implementations that already exist in rust is like adding typescript types and was unpacking your rust library because then you don't have to write that much JavaScript, you're only really writing the type level.
02:24:14.928 - 02:25:00.430, Speaker A: And yeah, I'm super down to chat about this more. I think it's exciting, and it will only get better if there's some cross pollination between communities and people are working on stuff, especially in crypto. I think there's maybe some exciting use cases. So yeah, typescript loves rust. So there's actually one more thing wanted to chat about here, which is this thing called Rivet. I'm not sure if anyone's seen this, but we announced this this morning and rivet is. So right now we find ourselves in this situation where as developers, most of us are using consumer wallets and like global test nets to write our software, which aren't really meant for this use case at this point.
02:25:00.430 - 02:25:55.590, Speaker A: You know, consumer wallets don't necessarily have features that you need to debug stuff and iterate quickly. If anyone's tried to like do stuff like run Anvil and use metamask and have to reset nonces and stuff like that, it's not very fun to do. And then global public test nets, sometimes the iteration speed is slower, you have to deploy things, you have to scrounge up some testnet ETH and things like that. So yeah, the goal of what Rivet is, is what if we built some tools for developers to use? And so that's what rivet is. It's developer wallet and devtools, sort of like react devtools. If you've used that or any other browser dev tools, it's a little bit higher level, allows you to manipulate state of anvil so you can like really shorten the feedback loop to doing stuff like send a transaction. Okay, now it's reset.
02:25:55.590 - 02:26:16.328, Speaker A: Need to like add some balance or fund an account. Just click a button to do that. And yeah, we're super excited to collaborate with paradigm on it. You can just go to this link if you want to try it out. It's in like an early alpha state and I'm going to show it to you here in this demo. So we're on Uniswap. This is Uniswap's website.
02:26:16.328 - 02:26:43.916, Speaker A: We can connect to it, we can pick some eth amount, swap to USDC. The cool thing about this is you go to any website, start interacting with it. In this case, we're not going to confirm the swap right away. We're going to change our balance so you can see how it works. We're going to auto mine manually mine here. So we switched our balance to ten and now we don't have enough. So everything's updated appropriately.
02:26:43.916 - 02:27:35.252, Speaker A: So let's add some eth back to our balance and mine that. And then let's switch to interval mining so we don't have to manual press stuff anymore. And then yeah, we can just swap and it's done once it comes up to confirm. Yeah, and so yeah, we just swapped it. You can see the nonce incremented, we can see the transaction went through. Yeah, we're super excited to keep building on this and making sure that it's really solid and something that shortens iteration time for people allows people to collaborate. One thing that we're really excited for is this notion of time travel debugging, where you can just jump back and forth on the chain to reproduce issues that users are having a and just move really quickly.
02:27:35.252 - 02:28:40.290, Speaker A: So yeah, that's rivet, and if anyone has any questions, happy to ask them. You can go to these links. If you want to learn more about our JavaScript typescript, we're going to do two questions for Tom. Maybe you can't answer this, but why do you think the Ethereum foundation isn't pushing forward a lot of these ideas? These ideas are excellent and badly needed. And how hard is it going to be to push these ideas back into the Ethereum foundation, if at all? I wonder. Maybe you can't answer that, but yeah. You mean stuff like developer tools or rast one? Yeah, I mean I think the Ethereum foundation is great.
02:28:40.290 - 02:29:15.750, Speaker A: Like they set up some roadmap and things like that. But Ethereum is like a community, so people are just working on stuff that they find cool and taking initiative. So yeah. How does it get back in there? I don't know. I feel like community already does a decent job, but I think, yeah, sometimes it is good if stuff comes from a respected and trusted source too. So I don't know, and maybe to add on that, that the EF is responsible for fostering an ecosystem, but ideally the ecosystem, it should be anti fragile. The EF should be able to disappear tomorrow and the ecosystem should still move forward.
02:29:15.750 - 02:30:04.598, Speaker A: Thanks. I was curious, what's your experience with WASm and the maturity of it in terms of adoption in the browser? A little bit more? Yeah, I haven't used it a whole lot other than just experiments around it. So yeah, I guess that's mostly it. I mean, from what I've seen, just based on diving into it really quick, quickly, it's like the developer experience of me jumping in with no knowledge. There's a little bit of learning curve to figure out how to package these things up. But once that's done, this wasm wallet package, you can go to NPM, it's available there. Or you can go to this website, Wasm dash wallet Vercel app, and just try it out.
02:30:04.598 - 02:30:55.810, Speaker A: And it works pretty well. So stuff's definitely a lot better than it was five years ago when I tried to hack on it then. And one last question from James in the same vein. Have you done any bundle size comparisons for the wasm versus veeam? Yeah. So this specific case, the bundle size has actually increased a little bit, but there's a lot that you can do to try to eliminate that. I'm asking because in the past, the reason I moved on from a lot of wasm stuff is because the bundle size blew up and like webpack and the whole pipeline was not well suited to wasm. So I have quite a bit of experience here if you need help.
02:30:55.810 - 02:31:19.308, Speaker A: Totally, yeah. Very interested. Big uploads for Tom. All right, we made it through the talks. Congrats to everyone here. Big shout out. So we're going to take a small break until 12 30, 35 or so.
02:31:19.308 - 03:10:01.964, Speaker A: There's sandwiches on the back. Thank you all for being with us here. Stay because afterwards we'll have 1 hour of lightning talks from many community members to show some exciting projects that we are not directly internally driving. So we'll be back in 30, 45 minutes or so. So please be around and feel free to network. It, it, it, it, it, it, it, it, it, it, it. Let's give it five minutes.
03:10:01.964 - 03:13:47.580, Speaker A: But if people would be coming back their seats, please. Let's do that. Okay. Kind request for everyone to get seated in this room. Or if you want to keep talking, feel free to go to the other room. We'll close the doors and so on. So if everyone would start getting seated, we would greatly appreciate it.
03:13:47.580 - 03:14:55.316, Speaker A: Can somebody close the door perhaps? Yeah. Yeah. Okay. People are coming in, but otherwise let's close it. Okay. While people are getting cd, I'll just do a quick reminder that we have this open edition NFT and the broken chair. Yeah.
03:14:55.316 - 03:15:19.858, Speaker A: So we have this open edition NFT. It gives you access to this forecaster channel. Lately we've been using it like the last week. It's been a nice community ground for the rest Ethereum groups. So, yeah, if people want to continue talking about things there, I also cast the thread about Q and a. People are welcome to join there and we can continue the conversation there. Yeah.
03:15:19.858 - 03:15:57.456, Speaker A: Next up, we'll start with our lightning talks. Our first speaker is Emily Shah, which I may be mispronounced, who will talk to us about shadow events and the lightning talks? Everybody will be switching laptops. So kind request that in between people don't get up, make noise, etcetera. Applause for Emily. That's mine. Okay. Speaker one.
03:15:57.456 - 03:17:15.748, Speaker A: Yeah, cool. Okay. Hi everyone, I am Emily. I'm the CTO of Shadow, and I'm going to be talking about shadow events today. So first, what is a shadow event? A shadow event is a gasless event logged in an isolated fork that shadows mainnet. And why are they cool? Why are they valuable? You can think of Shadow as unlocking permissionless edit mode on any contract on Mainnet. So this means that you can add custom event logic that can include and access any on state on chain state, including internal state and private variables.
03:17:15.748 - 03:18:06.960, Speaker A: And it's all gasless. And once you've written this new event logic, you can go back in time and backfill historical data that you didn't get before. So what this means is that if you need on chain data, instead of writing convoluted SQL pipelines or assembly script, you can write code close to the metal directly in the smart contract in solidity to get the exact data in the exact format that you want. Cool. So how does it all work? When you want to add a shadow event? The first step is to spin up your own shadow fork. A shadow fork listens to transactions happening on Mainnet and then executes all those transactions on your fork. And that's why we call it a shadow fork.
03:18:06.960 - 03:19:03.170, Speaker A: And this is completely isolated from Mainnet, so you can so gas costs and contract size limits are completely removed and you can go crazy here in the hosted product, your shadow fork is near real time and it has all the same exact state. Aside from the additional event logs that you added. And if you added any additional storage slots, slots, that's the big difference, but everything else exactly the same as Mainnet. Second step is to edit the source code of this contract that you want to shadow. And you can shadow any verified contract, or you can shadow unverified contracts that you have the source code for. And then the third step is to deploy your shadow contract onto your shadow fork. And then once deployed, front fills start immediately, and then we will kick off a backfill process.
03:19:03.170 - 03:19:56.620, Speaker A: And then finally you access your shadow events like you would your normal Mainnet data via JSON RPC. We support all the standard ETH RPC, JSON endpoints, and we also support other access models like GraphQL, webhooks and SQL tables and parquet tables. Cool. So using a shadow fork is pretty simple, but there's a lot going on behind the scenes and under the hood to make this really fast and really performant. And forking Mainnet is not a new idea. You might actually do this multiple times a day when you run your foundry test. So we took a lot of inspiration from foundry, and we're actually using certain crates in foundry to help us make this blazingly fast performant and paralyzable.
03:19:56.620 - 03:20:57.650, Speaker A: So if you're building crypto native infrastructure, there's actually a lot of alpha in foundry that you should consider leveraging. The one that I'm going to highlight today is called the backend handler, which is a highly multi threaded fork backend used in foundry to run multiple forks simulations. So when you do vm, create fork and run a simulation, this is what's happening under the hood. So basically what it does is when you spin up multiple forks, there is a single instance of the backend handler that is basically fulfilling all of the JSON RPC requests. And so this is doing really a lot of the heavy lifting. The backend handler uses Tokyo channels to dedupe in flight requests and then caches the previously requested results. And you can thank this module for not blowing through your alchemy compute limits every time you run your foundry tests.
03:20:57.650 - 03:21:42.588, Speaker A: So here's just a little snippet of code. In this snippet of code we are fetching for a storage slot at a particular address in the backend handler. So you can see it's pretty simple. Just first checks if the value is in the cache. If it is easy, we'll just send it right back. Otherwise it knows that we need to request this data. So once we know we need to request this data, what it does is it basically checks first if we have a pending in flight request, if we've already requested for this storage slot, and we don't need to send another request if we haven't seen it before, then we add it to the queue of pending requests to be processed.
03:21:42.588 - 03:22:29.180, Speaker A: And then finally all this is doing is just pulling for all the requests that are in flight. If it sees a request finally come back, it just sends it back to all the listeners via the Tokyo sender channel. So huge shout out to Matt on the cord foundry team for designing and building a all this code that I showed today, and I highly recommend reading through this code if you're building really complicated high I o systems. And if you need any weekend reading for this weekend this pr. I don't know if you can see it, but it's PR 1715 and foundry. It's a really good one to read if you are curious about how forking works. And also it has an example of how a VM code works from front to back.
03:22:29.180 - 03:23:12.150, Speaker A: So if there's one takeaway that I wanted to give to you guys for this talk, is that the name of the game for building an ethereum is composability and composing on top of foundry. And Reth is the new meta for building crypto native infrastructure. So if you're building infra, you should really be thinking about using foundry and rethemeral as tools in your tool belt. And if you're interested in using these tools with us in prod systems, come find me afterwards and we can chat. And there's a lot more that we could have covered here. It was only five minutes, so feel free to find me afterwards if you have any other questions. Thank you, Emily.
03:23:12.150 - 03:23:57.810, Speaker A: Shadow is an exciting new project that the way you want to see flourish. Next up, we have Ben Clavi and Andreas from op Labs who are going to talk to us about op ref. What that means we would let them go through it. All right, hey, everybody. So we're here to talk to you guys about Oprah th today. And just before we get to the slides, we just wanted to show you. This is a real node.
03:23:57.810 - 03:24:22.422, Speaker A: This is the op node driving reth to sync base Gorley. At the moment, we are at block around 5.1 million, which is past the regolith hard fork. So we have already gone. Oops. We've already gone all the way through the bedrock blocks and are well into sinking regolith. So, yeah.
03:24:22.422 - 03:25:01.540, Speaker A: So where did this project start? About last fall, I pinged Georgios because we were planning on making a patch to Akula. Obviously, Reth came in and kind of deprecated Akula and took over development of the rust client. And so Georgios was well willing to do this. Some projects came in the way of everybody, and now that Reth is coming close to being out of alpha, about a month and a half ago, Coinbase optimism and the Reth team got together and said, this patch must be pretty easy to do. And it turned out to actually be. So the op gethdif is actually really small. It only entails a couple of things.
03:25:01.540 - 03:25:44.020, Speaker A: The primary things are that we have this new deposit transaction type, which actually allows you to send deposits into the roll up, as well as some l one to l two cross chain messages. The engine, API, and payload building receive several modifications to allow us to insert transactions directly from the sequencer in order. And then there's also some state transition modifications that affect how deposit transactions are processed, the gas accounting, et cetera. And then there's also some small, less consensus critical items, like some RPC stubbing, et cetera. But that's kind of the gist of it. So when will you guys be able to run this? Hopefully pretty soon. As you guys can see, we got past the regolith hard fork on base Gourlay.
03:25:44.020 - 03:26:30.530, Speaker A: I think that the biggest hurdles next will be historical state support so we can run this on op mainnet. If any of you guys don't know, base goorly is an op stack chain that has no historical state. Opnanet is really the only one. But past that, we are pretty close to having this in your hands. And we just like to say a huge thank you to all of our contributors. We based a lot of this off of op Geth as well as op Aragon, built by testin Prod Proto helped us a ton base developers. We have Roberto at the top left there, Brian bottom right.
03:26:30.530 - 03:26:54.756, Speaker A: Killer. Killer job. And then, of course, the whole op, the whole ret team, as well as Vex and myself. And so what's next? We're going to build the op stack in rust. It is going to happen. Op Zethe is up next. We have optimism, execution changes.
03:26:54.756 - 03:27:27.210, Speaker A: We have to move them into revm. We have ref powered indexing tools. We can probably get that alongside cryo for free and off chain agents, l two blockbuilders, et cetera, et cetera. And first we need to get to tip and stay synced. And if you don't contribute to the rust opie stack, t eleven s won't follow you, so better get on it. Thanks, Sean. Thank you.
03:27:27.210 - 03:28:39.910, Speaker A: This is a particularly important project because if ethereum scaling is to work, we need performant L2 s and l one clients were not designed for that. Next up, we have Joachim, who we had the honor to work together last summer at Faridheim, who will talk to us about jit evm, whatever that means. So a lot of blows for Joachim. Please. It's really surprising. We've managed to make 15 laptops work with one cable today, but maybe this is not the time. Oh, that is your computer? Yeah, it's like the other workspace.
03:28:39.910 - 03:29:02.696, Speaker A: You need to mirror, you run arch. All right. He doesn't run arch. I should have stuck to arch. This is pop. Osdhehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehehe all right. Hi, everyone.
03:29:02.696 - 03:29:58.310, Speaker A: It's great to be here. I'll be talking for the next five minutes about jit evm. And what's this about? So the idea here is actually pretty simple. Can we have an evm that creates machine code at runtime for hot functions or contracts? This is a technique that is everywhere in other virtual machines for other programming languages, for example JavaScript or python. And why would we want to do that? Well, hopefully it's faster. Okay, so I think this pretty easy kind of straightforward idea, and what I'm going to show you is a little bit of results of kind of a proof of concept playing around with this idea that I did last year over the summer at paradigm. And since then I've gone back to kind of my day job, which is to be a PhD student here around the corner at Stanford.
03:29:58.310 - 03:30:31.322, Speaker A: And their my day job is not so much writing production rust code as it is writing papers. So, you know, this project needs a little more love than I can give it at the moment. And so, you know, if this is interesting to you, please don't hesitate to reach out. The code is on GitHub and you know, we're very helpful. We're very happy to help you get started. Cool. So why is it now the right time to do JIt EvM? So initially, you know, this idea of having a JIT EVM has been around for quite a while.
03:30:31.322 - 03:31:14.488, Speaker A: And for the most part, during that time, EVM was thought as in the context of consensus and execution. Doing a just in time compiling virtual machine in the context of consensus has certain challenges. For example, the just in time compiling pipeline is fairly complex. You might not want to have that on the critical path that is critical to consensus. There's questions around how this behaves, if somebody feeds it with maliciously created code. And so this idea has been a little bit like, not sure we want to do that, but things have changed a little bit. I think storm in the morning gave us a good idea of new use cases, essentially where we're using the VM now.
03:31:14.488 - 03:31:42.220, Speaker A: One of them is definitely testing or fuzzing. For example, right there. You're running this on your own contracts. You're not going to give it a maliciously crafted input. So if you can get performance speed up here, that would be great. The same is for me, searching for chain analytics, all this data processing, predicting the outcome of transactions in your wallets, et cetera. So this is where a faster EVM, perhaps one that uses Jit, would be useful.
03:31:42.220 - 03:32:44.466, Speaker A: How does it work? Trying to explain this in one slide, the basic idea is as follows. You start out with a contract in EVM bytecode, you do some analysis on the control flow to segment this into blocks that get executed together. And then you use in the proof of concept implementation, we use this crate called Inkwell to transform this into LLvM intermediary representation. So what happens in this process, basically is each of these blocks contains a bunch of opcodes, and each of these opcodes gets translated kind of in lnvmir. And I show here kind of the example implementation of the addition opcode, where LLVM kind of can do integer additions kind of natively. And then running such an operation basically means popping to elements of the stack, running the operation, and pushing the result back. And you can see there's proof of concept.
03:32:44.466 - 03:33:28.060, Speaker A: There is no gas accounting here. And mind you, this is all a year old code now. So with the recent new developments around Reth and RevM, et cetera, hopefully there would be a better way to implement this today with not as much code reuse as reimplementing an interpreter. But then once you have translated your EVM bytecode into this IR, you basically hand it off to the LLVM pipeline, and it basically does the whole rest for you. So it kind of optimizes the code and turns it into machine code. And the machine code can basically operate directly on memory and stack. You just point it to a region of memory that it can use for that.
03:33:28.060 - 03:34:39.750, Speaker A: And if it wants to do something a little more complicated, like accessing storage or calling other contracts, then it would probably call back into the EVM and say, hey, can you set up this other piece of code that I would like to run? And then this is my last slide is a little bit broadening the discussion a little bit. I think we should think about when and what we know about the code that we're about to execute. And there's the usual spectrum between knowing stuff only at runtime and what do we know already at compile time, and having the usual interpreter EVM basically corresponds to saying, well, at compile time we really don't know anything or don't know much about the code that we're going to execute. So we have to interpret everything. And just in time, compiling EVM kind of pushes this kind of towards compile time, not really doing it at compile time, but saying, okay, today I'm running a certain piece of a certain contract, then probably I'm going to run the same contract tomorrow. So maybe it's worth it, translating it into machine code today so that the execution tomorrow is faster. But I would argue there's a whole design space to be explored.
03:34:39.750 - 03:35:16.060, Speaker A: You can probably push this even closer, even further towards compile time. Right? You could call this ahead of time EVM. And the idea basically being that most of the. The stuff that we execute is a relatively small set of contracts and they don't change a whole lot, month to month. And so maybe we can compile them already at the time where we're creating the binary of the client. So, yeah, that's about the pitch. If any of this sounds interesting to you, or you just want to chat, you want to know more, please find me or Georgios.
03:35:16.060 - 03:35:43.970, Speaker A: Thank you. Thank you, Joachim. Again, I'm going to keep saying this, but all of this is extremely important work in the course of making the ecosystem more performant. So this. If there's anybody that knows LlvM or Enkwell, please talk to us. We want to productionize it. Ok, next up, we have Noam from alchemy, who will talk to us about the rust bundler for ERC 4337.
03:35:43.970 - 03:36:39.484, Speaker A: Could he come up on stage? Warm applause for Noam, please. Oh no, there was Jacob first. Anyway, you should go. And we will do Jacob after. I'm so sorry. Noam had asked to share some context about 437 zone. Maybe we can do the one liner, which is a new smart contract standard for building wallets.
03:36:39.484 - 03:38:02.018, Speaker A: And there's a need for a lot of off chain infrastructure to make it work. And these are called bundlers. And this is what the talk is about. If we can get the slideshow. Do you want to telegram me? The slideshow? It. It's not working for me. Oh, no.
03:38:02.018 - 03:38:23.892, Speaker A: Great. Is this on? Oh, yeah. Nice. Cool. Sweet. So, as Joe just mentioned, we're talking about our rust implementation of an ERC 4337 user operation bundler. Quick show of hands, who here is like, high level familiar with ERC 4337? Nice.
03:38:23.892 - 03:38:45.660, Speaker A: That's pretty good. I'll give a very quick primer and then we'll dive into the actual client. So, technical underpinnings of account abstraction. High level, there's two kinds of accounts. There's eoas, which are what most of you guys are familiar with in terms of how you interface with the blockchain. And then there's smart contract accounts. For a multitude of reasons, we believe that to get a billion people on chain, we'll need smart contract accounts.
03:38:45.660 - 03:39:31.630, Speaker A: This was called out in a few recent blog posts, including one from Vitalik on his three transitions. But the problem is that natively Ethereum and EVM can only handle eoas. Right? Now. So how do we provide the infrastructure off chain to safely support smart contract accounts? The full flow is something like this, where still every transaction on Ethereum is initiated by an EOA, but the entity managing that EOA is what's called a bundler, and it can accept meta transactions called user operations from a lot of users. Bundle them, post a single transaction to Ethereum or any other network, and have those proxy through what's called the entry point contract to the user's account so quickly. Runler 101 everyone before me made some really nice slides. I apologize, I did not.
03:39:31.630 - 03:40:01.130, Speaker A: So there's just a lot of text that we can parse through. Cool. So what's Rundler it's a modular implementation of the ERC 4237 bundler, drawing a lot from Rest's design principles. There's three main components. There's the RP salayer, the bundle builder, and the Mempool. The mempool stateful, the RPC layer and bundle builder can scale statelessly on top of that mempool. The default connection between these components is GRPC, but we also are building an integrated mode with zero copy.
03:40:01.130 - 03:40:41.828, Speaker A: We've built the UmM pool to handle reorgs in the underlying network. It heavily uses ethers rs, and we're going to be switching to alloy when that's already there's been an absolute truckload of headaches around gas estimation for 4337, and this is compounded by a lot of factors, including different fee markets on l two s and what's called the 164th rule. So we have a binary search implementation implemented in solidity to help streamline some of these things. And there's a four part, 15 page blog post on gas estimation if you guys are interested. More about that. It's crazy that that topic can be so deep. And then we have a pretty advanced bundle builder right now that optimizes for bundle size.
03:40:41.828 - 03:41:27.964, Speaker A: Actually, we had a recent bug last week where it was posting transactions that would use more gas than optimism would have available per block. So that's been patched, but otherwise pretty sophisticated. And it's streamlined so that we can support things like signature aggregation for BLS soon. The high level idea there is that on l two, a lot of users submit UOS signing transactions with the BLS scheme. The bundler can aggregate all those signatures into one signature that's then posted on the underlying network and can save a lot in DA costs. And then it also handles all of the ERC 4337 simulation rules, which are pretty restrictive, and we can talk a little bit more about that later. We're currently actually sprinting to open source this.
03:41:27.964 - 03:42:23.058, Speaker A: It's still not yet been open source, but it is in a private beta managing Alchemy's managed user operation endpoints on Ethereum, Arbitrum Polygon optimism and now actually base. We have this checklist for open source and you can see from some of the like we actually powered an airdrop for this team called Cyber Connect about a week ago where the rundler handled super smoothly, so it's been powering live production use cases. So how runler we're still waiting for benchmarks. Most of it is going to be just a proxy to the underlying node layer. So writes are theoretically constrained by the best based network gas limits. Reads too are constrained by fan out to things like ETH logs and underlying node layer. There are some low hanging fruits for performance optimizations that we'll get in, including things like native tracers that we want to build into ref to support user auth validation.
03:42:23.058 - 03:43:21.490, Speaker A: It's currently a current team of four alchemy engineers, but we'll have open source soon. Cool. And looking forward, we're cutting the public beta release in early to mid September. We've been working with a few folks who are writing their own bundlers and the Ethereum foundation on the P two P Mempool specs, which will be a key component of this to make it more censorship resistant. There's also general designs for what's called alt mempools to work around the restrictions in core 4337. So the idea is bundlers can subscribe to execute user operations that violate 4237 rules and in exchange for taking that risk get compensated higher fees. We want to build as I mentioned, a simulation tracer straight into the rest binary which currently we rely on the JavaScript called Tracer which is not super efficient using the latest and greatest from the EF and the IPFS team for the p two p stuff following rest lead for rundlers and SDK.
03:43:21.490 - 03:44:00.028, Speaker A: Kind of having some prototypes around AA Reth where like top of block can be the like user operation batch being posted from the UoS it receives. And yeah, a lot of other performance style improvements using like all the great tools that folks have mentioned in earlier talks today. Cool. So yeah, that's it, high level. We're really excited to get this out to the ecosystem soon. Been just load testing it and running a few experiments in production to make sure that it's all good to go and cleaning up for everyone to be able to onboard and contribute to it soon. But yeah, if you have any other questions, check out our website, alchemy.com
03:44:00.028 - 03:44:27.150, Speaker A: account dash, abstraction or. I'm happy to chat about these things at any time. Thank you. Thank you, noam. And now we'll hear from Jacob on a ret based builder, which somewhat relates to the topic that just Noam talked about. One could easily imagine the endgame that every builder for MeV is also running a bundler and is basically just making user ops a first class citizen. Almost.
03:44:27.150 - 03:45:32.014, Speaker A: All right, you should mirror, I think. How many engineers does it take to figure out the screen? Nice. Hey. Hello. Yeah, so, as Giorgio said, we have a ret based blockbuilder. I'm Jacob Kaufman. I work at the applied research group at the Ethereum foundation.
03:45:32.014 - 03:46:07.812, Speaker A: And this is something that I've been working on for the past few weeks with a teammate of mine, Alex Stokes, who's also here. And, yeah, let's get into it a few preliminaries. First, I want to say thank you to the red team for really great support. I could say a lot more, but in the interest of time, let's move forward. And then a disclaimer. This is experimental software, research purposes only, no liability, all that stuff. Quick outline.
03:46:07.812 - 03:47:27.924, Speaker A: So I'm going to talk about local block production, Mapboost block production. Why is open source block production software important? And then we're going to talk about Evangelion, or EvA, as I'm calling this block builder, and then we'll talk about some ongoing and future work. So, in Ethereum, we have this separation of concerns between the consensus layer, or the CL, and the execution layer, or the EL, and they communicate via the engine API. So the CL will periodically notify the EL about updates to its fork choice state via engine, fork choice updated. And when it's the validators turn to propose, it will also send along these payload attributes, which contain information that the EL needs to build the payload. And the EL will return an identifier, called the payload id, which the CL can use to retrieve the corresponding payload. So in Mepboost block production, validators auction their block space to this network of external builders, and relays broker this interaction between the validator and the builder.
03:47:27.924 - 03:48:27.056, Speaker A: And both the validator and the builder rely on the relay to sort of provide some guarantees about this exchange. So builders are the specialized entities that have advantages that allow them to build higher value blocks. The main sources of edge, or alpha are information or order flow and algorithms. So, for example, builders might have a vertically integrated searcher or some other exclusive agreements with searchers to get bundles or private transactions. So why block production? Open source software. This chart is from which is maintained by another teammate of ours, Tony. And you can see that essentially four or five builders have, you know, an overwhelming majority of the block share.
03:48:27.056 - 03:49:29.772, Speaker A: And so we really want to lower the barriers to entry for builders. And so what we try to do is we can't really solve the information edge, but we want to minimize the algorithmic edge as much as possible. And yeah, we want to allow builders to specialize. So instead of having to spend energy and resources maintaining a fork, we would rather allow you to spend time building more advanced algorithms. And it would also be cool to have academics or other researchers implement various algorithms. So what is evangelion or Ava? So in Reth, there's a crate called the Reth payload builder, and within there, there's a trait called the payload job generator. And essentially what this is is you call it with some payload builder attributes, and it will give you back a job.
03:49:29.772 - 03:50:29.120, Speaker A: A payload job is essentially a future that will eventually resolve to some payload. And I've omitted some details here for brevity, but you can also periodically poll the job for the best payload. This is important because transactions and bundles are always flowing in, and so over time you can assume that the more time you have to accumulate transactions in bundles, you can build more valuable payloads. So we have this implementation of this trait, and then also Giorgio has talked about CLI extensions. So we pass in this custom builder, and then that's essentially all we need to do to interface with Reth. We also configure the consensus layer to continuously trigger payload jobs. So by default it will only trigger a job when it's the validator's turn to propose.
03:50:29.120 - 03:51:22.490, Speaker A: But you can configure lighthouse to, for instance, trigger a new job for each slot. And then also the other bit is that the El and CL are not Mevboost aware by default. So we need to build some extra machinery around it so that we can, for instance, query a relay to see this proposer. Are they registered with MavBoost? And then we need to get their registration information so that we can do things like send the fees to the proper address on the execution layer. And yeah, that's really it. So with not so much code, you can have a custom builder without maintaining any forks. And this is a huge improvement over maintaining a fork of geth.
03:51:22.490 - 03:52:02.870, Speaker A: And yeah, we've built some blocks on Sepolia. Here's the link to the GitHub. And for ongoing future work, we need to build some better abstractions in the same way that RET provides these powerful abstractions. We want things like a bundle pool block packing algorithms and bidding strategies, as well as some other optimizations. And then I'll quickly say that we have this other project created by Alex Stokes that's in the same way as an open source builder. It's an open source relay also in rust. And yeah, we'd love to have more help on it.
03:52:02.870 - 03:52:48.640, Speaker A: So thank you. Thank you, Jacob. Next up we have John Becker on Heimdall. Where is John? John, the reason why the Evangelion builder is super important is because people thought of block building as a hard thing. Reality is that the bundle construction is hard, the order flow is hard, but the spinning up a node that can run a builder should not be hard. And this touches on it by letting you do builder less than 1000 lines of code, which is super powerful. Yeah, John, take it away.
03:52:48.640 - 03:54:07.510, Speaker A: When the HDMI gods let us, you can tell who uses extended monitors from the default config. I think you need to click on main display and then mirror or something. Use as main display where it says up. Yeah, mirror. Yeah. Hello, I'm John Becker and I'm going to talk about Heimdall. Yeah, it's basically an advanced bytecode analysis toolkit.
03:54:07.510 - 03:55:04.858, Speaker A: So what can it do? Well, it can decompile byte code which generate control flow graphs for bytecode, decode arbitrary call data, Dom contracts storage, and generate bytecode snapshots. I'll talk about what all those mean in a sec, but first I'm going to talk about symbolic execution. So symbolic execution is basically a complex process of finding all the possible paths that a program can take. So it's pretty blurry, but up there that's just bytecode. And then symbolic execution will run this bytecode with some call data. And then every time it encounters a jump by instruction, we'll take both paths and that allows us to trace what the actual EVM is doing. You probably can't see that either, but it's a bunch of assembly.
03:55:04.858 - 03:55:41.472, Speaker A: And then in between the assembly are lines and arrows to other blocks of assembly. And this is called the control flow graph. Basically what that means is if you start at that first block, it will follow the EVM and just continue executing things. And this basically represents all the possible steps that the EVM could take. And Heimdall is able to convert that symbolic execution into solidity code, which you also can't read. Yeah. So now let's talk about what this powers.
03:55:41.472 - 03:56:26.418, Speaker A: So this symbolic execution powers the decompile module, the CFG module, and the snapshot module. Let's talk about the decompile module. So decompilation is the process of converting machine code or byte code into a readable format like solidity. And we're able to do this from symbolic execution, like I said before. But basically you run Heimdall, put in a contract address you don't need to be verified, and it will execute that contract symbolically, and then generate an ABI and some representation of the source. It's very useful for pen testing or finding out what a contract does if it's not verified. Taking it a step back, control flow graph.
03:56:26.418 - 03:57:37.770, Speaker A: You've already seen this a few slides ago, but basically shows every possible path that the contract could take. The snapshot module is new, I added it a few weeks ago. It's similar to decompile, but takes another step back and will only show you relevant information. It'll run things and display gas consumption events, emitted custom errors, storage accesses, modifiers, access control, etcetera. And it can actually resolve signatures from the four byte directory, which is pretty cool, which is how Heimdall is able to give you the exact ABI of any contract you put in. And then another module that does not rely on symbolic execution is the dump module, which basically will fetch all the transactions a contract has made or been interacted with, and replay them, and then give you a nice TUI format and CSV format of the storage, the storage slots within the contract, including things like mapping. And if you could read that, which you probably can't, this is the wrapped ether contract.
03:57:37.770 - 03:58:18.070, Speaker A: And you can see the first three slots are wrapped ether and then the decimals and stuff, and symbol. And then the last module I'm going to talk about is decode, which basically you can put in arbitrary call data or a transaction, and it will decode the call data using the four byte directory. So the first four bytes of the actual call data will be looked up, and then it'll take all those possibilities and attempt to decode them. And whatever succeeds will be the output. So in this example, which. Oh, you can read that. This example is just a withdraw.
03:58:18.070 - 03:59:13.470, Speaker A: I think it's also from wrapped ether. But put in the transaction hash, you don't need the ABI, it will just tell you it's a withdraw of whatever the hell that UN is. And you can also explain what the call does roughly using GPT four. Ok, so what's next? I'm going to be working on a monitor module, which basically will just watch the mempool for some patterns and then call cron or whatever you want it to do whenever something happens in the mempool. And then I have some improvements, like improving symbolic execution because it's rough and loop detection is very hard. Breaking out of loops is hard. Improving the decompilation output so that you can actually recompile it or just making it better recursive call data decoding like multicall VYPR support is also going to be rough because it's different.
03:59:13.470 - 03:59:42.600, Speaker A: And then GPT four powered code cleanup is kind of on the back burner because AI is not deterministic and I don't like that. And then raw trace decoding will also be added. Eventually you can get in touch. This is very short, but it's technical. So if you want to talk to me afterwards about anything, feel free. I also like otters, so there's an otter. Thank you.
03:59:42.600 - 04:00:31.560, Speaker A: Thank you, John. Next up we have Jason Rennick who is going to talk to us about the secure designer using Intel SGX for context, what John talked about around the CFG analysis. It also has big applications in MeV where you don't know what you're searching for, but you want to make money. So when you're doing symbolic execution, you tell it, find me a path that will make me money. And the searcher, the solver then is responsible for finding a path, usually that will never terminate. So you're responsible for trimming down that statesperson space, but it is used by some top searchers successfully. So a lot of ground cover.
04:00:31.560 - 04:01:52.498, Speaker A: You should mirror or pull the window on the other workspace. Yeah, main display. That it? Okay, thank you. Yeah, as you can see by my desktop, I'm a big puffer fan. I'm CTO at Puffer Finance. So. Okay, I'm going to talk about secure signer today.
04:01:52.498 - 04:02:43.224, Speaker A: So this was the tool that we built for the validators within our pool, but it's also applicable to actually all proof of stake chains as well as like people outside of the puffer pool. So the motivation here, you can kind of think of it like a hardware wallet for your validator. And the goal here is we want to enhance the validator key management through trusted hardware. And so the goal here, there's multiple goals. One is protecting honest validators from themselves because a lot of these past slashing events have been because of user error, like running multiple validator clients and signing conflicting messages. Another thing is to provide more security in case your actual validator is corrupted or you're trying to be malicious and attack the chain. And another is to reduce the severity of these consensus client bugs.
04:02:43.224 - 04:03:31.366, Speaker A: We saw Ethereum lose finality for a little bit a couple months ago. Luckily it wasn't worse and didn't lead to slashing. But if that were the case, it's better to have these extra defenses in place. And another thing here is to help increase validator software diversity. So we're trying to just like we have lots of consensus clients and execution clients, we want to add to this like remote signing kind of class of software and have people build more diverse clients. So the outcomes if we're able to achieve all this would be to help reduce equivocation across Ethereum, which ultimately leads to a more stable chain, and then actually reduce operational risks for validators in general. And this really helps the solo stakers who have kind of less capital to play with here.
04:03:31.366 - 04:04:23.130, Speaker A: And finally, I guess for everyone here trying to help increase the design space for staking infrastructure. So yeah, having different remote signing tools in the mix really adds to this. So what is it? So right now it's developed as a SGX enclave, and we're planning to diversify that in the future. But it has like some primary responsibilities of essentially maintaining this EIP 3076 protection database, do the BLS keygen and signing, as well as being able to like speak the language of the ETH two beacon chain data types. And yeah, big shout out to the web3 signer team from consensys who really kick started all of this. They essentially have the same thing implemented as a Java program. So we were able to reuse a lot of the same APIs to speak to all these consensus clients.
04:04:23.130 - 04:05:14.026, Speaker A: So yeah, so onto some rust stuff. So we built this fully rust native. We use a warp web server and the main thing here is being able to interface with consensus clients. And we use this convenient lib osdem abstraction layer for actually building the enclave. But moving forward, we're trying to actually have a modular signing back end that allows you to interchange different types of enclaves besides SGX because we want to diversify on the hardware manufacturer and then be able to integrate with things like DVT. And actually one thing that we're really excited about is trying to break up this mono repo into lots of smaller crates that we can open source and contribute back to the community. We've been integrating a lot of lighthouses crates into our project and.
04:05:14.026 - 04:05:49.012, Speaker A: Yeah, thank you. This is Puffer's discord. So we're a new protocol getting started. Thank you, Jason. Next up we have Steven Lee from Risc Zero, who will talk to us about Zke EVM using REvM and risks zero. The work that Jason just talked about is also very impactful. Again, in Mev, where privacy is a big issue, we have devised very intricate protocols for protecting builders from protecting the order flow from getting eaten by adversaries.
04:05:49.012 - 04:07:43.870, Speaker A: And so having solid encryption schemes or secure enclaves can help on the margin. If your laptop takes direct HDMI, maybe just do the HDMI. No, not when we'll do it with one laptop next time. Kind of. Can you telegram me the presentation? Oh, yeah, no, the cable is not good. The adapter, it. Hello? Cool.
04:07:43.870 - 04:08:24.864, Speaker A: So today we're going to talk about Zethe, which is a type zero ZKE VM built by Risc Zero. So what is Zeth? Zeth is a fully open source Ethereum block prover. And what this means is you can prove all the transactions inside of an Ethereum block, as well as the block construction itself. It supports all EVM opcodes, and it's built in 100% rust on top of the RiSC zero ZkVM. So this allows you to ZK proof any sort of rust execution when it comes to performance and cost. Right now it's about twelve minutes for a proof and about $20 per proof. But we think there's a lot of good improvements by the end of the year.
04:08:24.864 - 04:09:09.750, Speaker A: And all of this is enabled by the Riscro continuation system, which allows us to parallelize the proof generation across hundreds of GPU's. So what does building a block in rust look like? Well, we can take advantage of a lot of the resources already in the Ethereum rust ecosystem. RevM allows us to easily emulate EVM and all transactions in rust on top of our ZkVM. Ethers gives us a good way to do JSON, or PC interface, which allows us to take input data from alchemy. For example, alloy gives us existing implementations of ethereum primitives and solidity types. And for catch at caching, we just use the ShA three crate and we use that implementation. We don't need to build it ourselves.
04:09:09.750 - 04:10:25.598, Speaker A: Something else that's pretty unique is instead of using the traditional MpT for ethereum, which has over 250 million unique addresses, we build a partial Merkle patricia tree. To do this, we look at the block we're proving, and we look at the transactions inside of that block, and we see what are the relevant addresses and accounts inside that block, and build a partial MBT of just that data. So this allows us to do significantly less Merkel inclusion proofs really improving our performance. So if you put this all together, you take this partial MPT and then you feed it into the Z block builder. So this verifies the partial MPT root, matches the parent blocks state route, verifies the hash chain of the predecessor blocks, applies all the EVM transactions and updates the partial MPT, and then uses the partial MPT's new root hash as a state root for the new block. So what's really key about Zeath, and what's really great about it, is how upgradable and extensible it is. Everything is built in rust traditionally, ZK programs are a bunch of polynomials or really complicated dsls, but because it's native rust, you have support for native rust crates.
04:10:25.598 - 04:11:13.900, Speaker A: And what's really amazing here is Zethe was built in two months by a team of three amazing engineers. Traditionally, ZkeVM has taken half a billion dollars of VC funding and three, four years of developments. We did it in like 1000th the time. Also, as REVM and alloy are updated, Zeth will easily support any of the new eips and EVM opcodes. And additionally, because it's built in rust, you can implement novel sequencing, larger blocks, advanced primitives, by going into the rust code base. It's about 6000 lines of code and change around parameters, implement new opcodes, etcetera. So when it comes to the future plans of Zeath, we think Zeth is a framework with limitless potential.
04:11:13.900 - 04:12:04.886, Speaker A: We really want developers to go play around with it, test it out, and build innovative projects on top of it. The easiest solution is you can build your own ZkevM rollup by inserting Zeth into a blockchain stack. Additionally, you can modify Zeth to support more novel consensus or block construction. And we're doing this right now for our op fraud proof system, where we're adding some l two to l one derivation, as well as taking some hints from op ref to basically zkify the op stack. There's also potential to add a completely different vm, such as Solana VM or moviem. Take advantage of execution level parallelization, and throw that on top of our ZKVM all in rust. This is also a great basis for ZK bridging historic state proofs, and what I'm personally really interested in is the Verge.
04:12:04.886 - 04:12:52.730, Speaker A: If you combine Zeth with proof of consensus, you can basically leapfrog the entire timeline that Vitalik introduced and finish the verge of. And what that means is next time, when you're trying to sync with Ethereum instead of downloading 400gb of blocks, you download a single quantum, secure, stark proof, verify it, and then you're instantly synced. So we're a lot closer to this than we previously thought, and I find that really exciting. So now I just need to give a shout out to Tim Carson's Rami Khalil, Wolfgang Wells, who are the core developers behind Zeath, the entire risk zero team, and the many contributors to the Ethereum rust ecosystem. I'll be here. Tim Carson's is here, so we're happy to answer any questions in the future. Thank you, Stephen.
04:12:52.730 - 04:13:52.214, Speaker A: Next up, we have Raul Jordan from off chain Labs, and Prism team lead the consensus client, who will talk to us about stylus and how we can write smart contracts in rust. In L2. Yeah, you can unplug. Also on the ZKVM point, there is a clear devex performance tradeoff, and I think people are pushing now the Devex tradeoff, others are pushing the performance, and it's going to be interesting where we land. Long term hardware acceleration will probably play a big role here. So also be on the lookout for that over under. This works nice.
04:13:52.214 - 04:14:20.638, Speaker A: That was fast. All right, testing. All right, hello, everyone. My name is Raul Jordan, and I am one of the crazy people that's staking on Mainnet with ref. And I'm here also a maintainer of the prism consensus client for Ethereum and also working now on l two technology. So really excited to talk to you guys about the arbitrum stylus and what we're cooking up. All right, so l two s on Ethereum are really awesome.
04:14:20.638 - 04:15:13.806, Speaker A: They enable things that just weren't possible before. We can do so much more if basically you can get a lot of the guarantees of Ethereum in the fact that you can bridge over and you can also bridge back with fraud proofs, and that gives us so much opportunity to explore just crazy things that otherwise would take years to do on Ethereum l one, for a good reason. Ethereum is this decentralized, kind of very secure base layer, and it cemented itself as a very strong data availability layer. If we want to keep, you know, if we want to really move and change some of its key features, that obviously takes a lot of time, and there's a lot of inertia behind it. So, NL two, we can innovate, and we can do things a lot faster and oftentimes in ways we couldn't expect before. So I'm working on currently the arbitrum l two, and at a high level, how it works is that we run go Ethereum state transition function. So this is the same thing that happens when you process an Ethereum block.
04:15:13.806 - 04:15:57.514, Speaker A: When you process an ethereum transaction, it goes through Geth. And what we do is that we compile all that code into this format called webassembly, which some might be familiar with, which then gets proven back on Ethereum with a delay of approximately seven days. So during this time, people can make claims about arbitrum state, and they can also dispute those claims. And always Ethereum will be the final arbiter of truth. So we'll figure out if somebody is lying or if a dispute was just completely incorrect. So why webassembly? What is this thing? Why are people talking about it? People also call it wasm is for short. And the idea is that it's this compact binary format that's originally designed for the web.
04:15:57.514 - 04:16:59.074, Speaker A: And the idea is that with this we can run other languages than JavaScript in the browser. So we can do things like, for example, run c code, run rust code in the browser, and it's supported heavily by web standards committees. It's become an amazing tool that is already in production at many companies, and many folks already have already had exposure to it. Coincidentally, it's also really great for l two s and for doing this kind of fraud proof verification game that we just spoke about. So originally, JavaScript was really all we had for developing web technologies, and today the ecosystem is a lot more mature. So browsers now support very robust experiences with Webassembly, and especially Rust has really awesome support, first class support, with some of the tooling that exists out there today. So something we asked ourselves is, hey, l two s, what they're actually doing is proving computation on Ethereum, right? We don't really say what kind of computation, but most of the time it's EVM computation, ethereum computation.
04:16:59.074 - 04:17:31.844, Speaker A: Right. It doesn't need to be that way, necessarily. And could we do more? Right. So actually the competition that we do is in WASM, and a lot of this comes from Go Ethereum. But a question arises, can we do fraud proofs, overdose, any kind of arbitrary user wasm? And the answer is yes. So question is, why not other binary formats, such as mips or RiS five? And really it comes to the tooling and the community support. WASM has become so supported by standards committees that the tooling is getting better and better each year.
04:17:31.844 - 04:18:11.380, Speaker A: And even the creator of Docker anticipated that WaSM on the server was going to be the future. He said that if WASM existed back when he was creating Docker, they wouldn't have even need to create Docker in the first place, so that's how big of a deal this is. So presenting arbitrum stylists. Arbitrum stylus is a next gen environment for developing smart contracts. On Arbitrum, you can write your smart contracts in rust, c, c, and really, any language that compiles to webassembly and doesn't have a runtime. Are we choosing between EvM or wasm? No, this is actually fully composable. It's one chain, multiple vms.
04:18:11.380 - 04:19:00.526, Speaker A: It's not a new l, two, and we like to call it EVM. We actually have two vms running side by side, which is the EVM and also the wasomer vm. And they can fully interact with each other, and they still go through one exact state transition function in one database. There's nothing like this that exists today. Some of the breakthroughs that are possible with stylus is that a lot of execution becomes incredibly more performant, and that also means resource efficient and cheap. So, for example, benchmarking catch hack shows a 73 x performance improvement when it comes to certain things, such as memory. We can see gains as much as 500 x on certain memory types for applications that use medium amounts of Ramirez, and the numbers are just staggering.
04:19:00.526 - 04:19:57.262, Speaker A: What does that translate to? It translates directly to transaction costs for users and things that just weren't possible before within the bounds of the EVM. So when you have access to stylus, we get things such as amazing cryptography that can be implemented on arbitrum, gaming, AI, generative art, and even precompile research. So instead of waiting years to adopt a precompile, it can be implemented as a rust program directly. Most importantly, and what I'm most excited about is that you get to write pure rust, right? There's no crazy domain specific language, no wild, crazy chimera of languages that seems like rust but isn't rust. No, you get to write pure rust, and you can use the tools you're comfortable with to interact with the EVM. We provide a very low level, syscall like API to get access to host functions. This means that you can implement really nice frameworks on top that provide nice types, use alloy, use, all kinds of things.
04:19:57.262 - 04:20:43.780, Speaker A: The community can choose any way they want to go with this, even the most minimal entry point, you have a function that just takes in some bytes and outputs some bytes. This is just pure rust. You can go wild, do anything you want here, and you're not bound by the traditional gas limits or execution costs that EVM contracts would normally have. Can we add support for other languages in Rust? If folks here are curious about Zig, it took me about 16 lines of code to add full support for zig for stylus. And if you have any other favorite programming language that you want to write smart contracts in, you can go ahead. It's all up to you. When Stylus we have fully working fraud proving for stylus programs full EVM compatibility in interop and also ABI equivalence, which is really important.
04:20:43.780 - 04:21:17.376, Speaker A: Rust is supported out of the gate, and a lot more is coming. The really cool thing is that when you interact with a stylus program, it looks just like a solidity smart program, a smart contract. You don't even need to know that it's in rust. You get an ABI interface to solidity. You call a function. You do a transaction underneath the hood. It could be written in rust, it could be written in zig, or even in c, and basically, the world is your oyster if you use stylus, if you're an l two developer, if you're interested in smart contracts, if you like writing rust, please find me after this talk and you can contact us.
04:21:17.376 - 04:22:02.780, Speaker A: I want to give a huge shout out to the team lead and the mastermind behind stylus, which is Rachel Bosfield from our team, and you can also contact me. So thank you, everyone. Here's a capybara. Thank you, Raul. Next up, we have Francois Gariotte, who's going to talk about recursive zero knowledge proof verification on Ethereum using Nova. Raoult's talk was particularly interesting because you can make the observation that for an l two, the only thing that you need is some way for your runtime to be interpretable in l one, and the moment you have that. So the moment they had a wasm verifier in Ethereum with WaSm prover, then you can make your l two runtime anything you want.
04:22:02.780 - 04:22:51.912, Speaker A: By making Wasm, you can go from any language to it. Hi, my name is Franso Garriot. I'm going to present work that's done mostly by Artem Charles Duke and Mace Penczyk, who's somewhere in the room. Okay, so Nova is the reference implementation for one of the zero knowledge proof protocols that have exploded in the last year and a half to two years, and that are mostly called folding or accumulation schemes. And the general high level idea is that they help you make proofs of stuff that you repeat over and over again. Examples include such things such as a ZkVM or executing instruction set. We've had a talk that exemplified one of those patterns today.
04:22:51.912 - 04:23:44.060, Speaker A: Guess which one it was. But decryptor is evolving very fast. That is, we have papers showing a new optimal protocol for this every three months, and that's going to come back as a problem. And all the references, the reference implementations are in rust, and we would like to have a verification on the EVM for one of those folding schemes. Sounds simple, right? It is actually not that simple, because the EVM cost pattern is one that has a big uncanny valley in the middle. You have certain Zika roll ups that are on the right here, that have, for time, adopted the approach of biting the bullet of 11 million gas paid on each verification, and then they've improved on it. Ask them.
04:23:44.060 - 04:24:34.330, Speaker A: And then you have the small ZK verification, which are the gross 16 plum class of protocols. Can you reduce something that is in the middle? Can we do something that is in the middle? Not only because we would like to, and it's an interesting research questions, but also because the traditional solution to go from the extreme right of this line to the extreme left, is to stock your verifier. That is, instead of verifying a proof, you're verifying a proof that your verifier ran and said that the proof was valid. That's cool, right? Nice idea. You put the verifier inside your verifier. There should be a min about Zipit on this slide, actually. But what if your verifier changes? I said cryptographic protocols change every three months.
04:24:34.330 - 04:24:59.976, Speaker A: That's not going to. If we have to rewrite this project every three months, this is not going to work. We're a tiny startup. We don't have enough people to do that. So we are trying to dog food our own silly ideas. That is, the Nova protocol as it stands, finishes with a stock that is not really amenable to Ethereum cost verification. We're changing that stock, we're changing the cryptography.
04:24:59.976 - 04:25:50.080, Speaker A: So we are ourselves not only receiving the work from the community of cryptographers that is improving folding schemes, but we're revising the cryptography ourselves to make it more ethereum compatible. And initial obstacles that we've encountered are things such as the Nova reference implementation requires insanely huge public parameters. It's also implemented on a different curve cycle than what we have pre compiled for on the EVM. So the crypto is wrong, then there's a polynomial commitment scheme that has its own problems, and the compiled contracts are gigantic. And so the idea is, we know we are going to change the cryptography, to make it more EVM compatible, and then solve those problems. But this talk is not about how we solve those problems. But please do ask me after.
04:25:50.080 - 04:26:51.992, Speaker A: This talk is about how do you develop a solidity program that is chasing equality and compatibility with the rust cryptographic protocol, while that rust cryptographic protocol is a moving target. And so some of those ideas are that why we are interested in this is that when it comes to recursion, of course this improves upon some of the existing cryptographic protocols that have been used for their knowledge, proof such as hello. And we're aiming to change the cryptography to make it way more compatible with where Ethereum is. So I mentioned huge public parameters. You have to pass a lot of data to your verifier. One of the things that we do with foundry is generating that data on the fly from the constants that we extract from our rest reference implementations. But that data itself is too big.
04:26:51.992 - 04:27:52.834, Speaker A: So now we create code generation that allows us to create solidity contracts, implement adding that data to the state, but in morsels, in pieces that allows us to really dockput what the deployment of our eventual contract would look like for that code generation. Even though our initial project is in rust, we're using Python because this is what has given us so far the best development speed for the generation of that contract. So you get the python on the left and solidity on the right. Sadly, I have to report it's kind of the same thing. For the part that I did mention a bit earlier in this talk, such as the crypto, you remember we were on the wrong curve cycle. So now our solidity verification has to implement operations that are, for one side, on which we're testing not using precompiles, but reimplementing curve arithmetic. And on the other side, which has precompiles, we're reusing them directly.
04:27:52.834 - 04:29:02.204, Speaker A: A little bit of a problem, but code generation in Python saved us more than the classing in solidity. That would not have exemplified the cost that we would get in the final product on the EVM, we even have some extreme data contract that access a lot of data on each iteration. The idea, though, is that the final product looks a little bit like this. We start from a rust program that generates, that has its own parameters and serializes them to JSON, and we use JSON as a data interface between the rust and the python. And all of the validity of our solidity deployment basically relies on that serialization pipeline on which we really hope there aren't any bugs and it's a little bit sad in the sense that a lot of this is not necessary. Where our sources in Rust foundry is developing. In rust, we would really like to have nicer pipelines for accessing that data without going through rust.
04:29:02.204 - 04:30:13.244, Speaker A: JSON Python Solidity, four languages most of the development for what we're doing does not happen on the setup of the protocol. It does not happen on the data itself. It happens at very specific moments where essentially what we're doing is static generation for a foundry development environment. If you are interested in extending foundry in that direction, please come call to me after so general high level summary cross testing the validity of a solidity verifier with a rust initial prover program is hard. We rely heavily on code generation, both for things like genericity generation of cryptocurrency primitives and parameter data, including some of it at testing time. And it would sure be nice to have the hooks to allow this at testing time. Finally, what we've eventually converged to is instead of having this live generation, equipping an unveiled node with custom data contracts for the purpose of that testing, anvil and foundry have helped a lot.
04:30:13.244 - 04:31:03.550, Speaker A: If you're interested in how they could help more, please contact me after. Thank you. First of all, our last speaker is Isaac Vodka, who talked to us about policy languages in Rust. I found it interesting from Francois talk that we've been talking about going from solidity to rust using JIT, or from solidity machine code for performance. Yet when you want to verify things on AVM, you actually have to go the opposite way. You have to transpile or convert your rust logic into EVM, which is just an interesting mirror, I guess. I like the wallpaper.
04:31:03.550 - 04:32:51.614, Speaker A: All right, we have a markdown presenter. Hello, everyone. I'm Isaac, and I'll be talking about how we can design various languages for how we route transactions on the node level in a modular way. So we've seen a few examples of how we can add modules as extensions to Reth today, whether that's builders, mev protection, all sorts of bundlers. But what I'm primarily talking about here is we're talking about when transactions are broadcast before mempool. What are the things that we can do about that transaction, and how can we route it? For example, you can think of how we would add various security features to a transaction broadcasting system based on the context of that transaction, and decide to not only just pass through transactions to be broadcast, but in some cases block send things for MFA, perhaps even create various complex MPC systems based on transaction context. So in order to do this in a modular way which is customizable, we don't want to have to code absolutely all of our security rules for these modules.
04:32:51.614 - 04:33:49.216, Speaker A: In rust, sometimes we want to have modular rule sets or policy statements so that we can make decisions on what transactions do. So we started building just various JSON policy documents for instructing these modules on how to route transactions and what to do. And then after making the first version, I wanted to look out into this space to see is there something that already exists here? Because these are not entirely new problems that we're solving around making decisioning based on context. So I found a really cool rust based language written by AWS called Cder. This is a language which I'm pretty sure powers a lot of how IAM handles resourcing and accessing things. It was not built for crypto applications, and so the main applications in their docs look like you're building Instagram or something, where it's like you're trying to permission users from interacting with photo albums based on who they're friends with. But there are some core concepts here which are very useful.
04:33:49.216 - 04:34:54.794, Speaker A: We're still talking about people trying to interact with resources given certain contexts. So how can we make a language like this understand crypto contexts? So we integrated cedar with ethers, rs with a to do to integrate alloy and make it so that we can help this policy engine, this general purpose like routing and policy decisioning tool, understand the context of transactions and decide when transactions should be broadcast, when they should be broadcast via alternative means, and when they should be perhaps blocked or sent for additional confirmation. So we can also add additional hooks and decorators here to tell it what to do with transactions. So we can say when there are certain transactions that are coming from wallets that are EOA transactions, contract transactions, when they have certain contexts around value or Abi, what do we do with them? So we want to trigger web hooks, we want to send things to maybe private broadcasting pools. All of that we can do in this like just declarative language. So we need a few things to make this work. We need some extensions for data types.
04:34:54.794 - 04:35:37.210, Speaker A: So this is a little snippet of an extension I wrote to add U 256 context support to the CDeR policy engine. We need to do similar things like that for ABi and transaction decoding. And we also need the schemas. So we need the policy engine to understand what the map of the space looks like for contracts. So we need to understand like how eoas interact with contracts, how they interact with them through transactions. Describe the concept of networks. And by building up all of this information about actions and schemas and policies, we can automate a lot of the routing for transactions at the node layer.
04:35:37.210 - 04:36:26.015, Speaker A: So the cool thing about this, some vision I have for how these nodes can become a lot smarter than these pass through broadcasting layers, is that nodes can understand the context of what transactions are trying to do and help people make decisions on where they should go. So I think there's a lot of automation that we can build into the core node layer by combining things like perhaps a DSL four policy with the bundling modules you saw earlier today. The MEV modules we saw earlier today. So thank you. Nice. Thank you, Isaac. This is also very important in the context of, let's say you're a custodian, let's say you're building an NPC signing service.
04:36:26.015 - 04:36:45.762, Speaker A: You always want to have an access control list in front. So this is a good modular way to do things. All right, we're done. Congrats to everyone. Like, big clap. So, yeah. Holy shit.
04:36:45.762 - 04:37:08.750, Speaker A: This is real. Right? And we have 100 and 5200 people in the room. We went through 4 hours of very technical talk. Bar is open, no? Yeah. The goal for the rest of the day is we have the venue booked for most of the day, or if not the entire day. We're going to move some chairs on the side, we're going to bring in some tables. We have three, four whiteboards.
04:37:08.750 - 04:37:35.790, Speaker A: People should feel free to sit on the chairs. Maybe if you don't want, can lie around. Ideally we can have some kind of more concentrated time where people can get to know each other. Maybe if you're working on similar projects, come talk to people. Or if you don't know someone, come talk to me and I can introduce you. Yeah, the goal is free time with good builders in the same roof. So, yeah, feel free to mingle as you wish.
04:37:35.790 - 04:38:30.620, Speaker A: Thank you all for coming. And, yeah, wish we can put this more often. And the bar might open earlier, but it might not. Also get stickers, please. It, it.

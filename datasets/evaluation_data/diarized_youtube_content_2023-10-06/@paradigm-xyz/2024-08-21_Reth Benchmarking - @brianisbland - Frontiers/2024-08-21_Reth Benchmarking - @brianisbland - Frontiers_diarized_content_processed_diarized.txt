00:00:00.160 - 00:00:56.808, Speaker A: Blood sugar and caffeine. So I'll try to take you through a nice easy journey through benchmarking. So don't need to tell all of you here, but we think that on chain is the next online and in order to achieve that goal, we practically want to vertically scale base to 1 phrase that. You heard a lot yesterday, but not yet today. So where are we today? We're at ten mega gas a second. We've gone up four times this year so far. That's pretty good, but we still have another 100 x to go, so why have we not done that yet? There's a lot of challenges along the way, which covered in detail yesterday l one data availability fault proof compatibility state growth.
00:00:56.808 - 00:01:55.850, Speaker A: But today I'm going to talk about the execution performance part of this. So it's important to recognize that, well, we're concerned the most about our scaling limits in the most adversarial conditions. So what is the worst case block or transaction pattern look like? And while we have a nice security model as a roll up of a one of NDE, it's only really useful if there's other people running nodes safely. So we want to make sure that we have a pretty good template for all of our ecosystem partners in order to run a node safely that can stay up to sync from our snapshots. Okay, so let's see. So ethereum client has a ton of moving parts. There's a lot of different opcodes, over 100 that have fairly non deterministic costs.
00:01:55.850 - 00:02:43.830, Speaker A: There's block overhead, in addition to the transactions themselves, of course. Computing the Merkel state, the merkle, sorry, computing the try route. There's also the fact that the performance will probably degrade as the state grows and the database gets larger. And then also none of this is running in a vacuum. There's of course the underlying hardware, software, file system and so forth. So how are you practically benchmarking Ethereum now? There's a lot of different transaction patterns and types from sends, transfers of tokens, swaps, non financial activities like gaming and social. And they all have very different access patterns.
00:02:43.830 - 00:03:59.240, Speaker A: And you can't really statically analyze any of these because what a transaction does is entirely determined by the EVM state and not really what's in the payload. So one of my colleagues built this tool called the replayer. It's sort of a black box tool for running through a sequence of blocks and transactions sort of acting, playing the part of a consensus client can plug into an existing ethereum node, pull down the block and transaction data, and then funnel it into a new node that you're running locally. So in addition to running through past transactions and replaying them, it can inject other additional transactions or tweak the payloads in various ways and then record timing stats at each step of the way and then perform tracing. To get us the data we actually need to do our analysis. So that means looking at the opcodes executed and checking the storage diffs. So wanted to create a standard test environment here.
00:03:59.240 - 00:05:00.350, Speaker A: We ran all these benchmarks in which I realize is a little bit behind the current version now. And this is the op version of course, and chose fairly commodity hardware that anyone can spin up today on EC two. So this is like the I three en six x large instance type which has plenty of cpu's, lots of ram. Most importantly, it has two locally mounted NVMe drives which critically are mounted in a raid zero configuration on ext four. So a very standard novorls file system. So now the other important part here is to look at the actual sample data. So we wanted to find block ranges that have a wide range of access patterns, specifically those which are very disk and storage intensive.
00:05:00.350 - 00:06:15.470, Speaker A: Settled on like a 25,000 block range on base main net, starting roughly around the 11 million point. And this notably contains a very high concentration of Zen transactions. If you run, if you operate an EVM chain, you might be aware of this storm. Actually has a great blog post detailing the impact of Xant on a variety of other EVM chains. But most importantly, this sends a ton of s loads, s stores, contract, deploys and sometimes self destructs at the chain. Okay, so let's try. So, running through these 25,000 block range on the given configuration, we can see this chart here where I took every data point which corresponds with a single block and charted like the number of gas in megagas on the x axis and the time in seconds to go through the full block execution and import process.
00:06:15.470 - 00:06:50.300, Speaker A: So if you squint really hard, you can say okay, cool. There's a linear equation here that generally maps to this and gets you around 60 mega guests a second. But it's also obviously not a linear function. Here we have the line towards the bottom. We have this cluster in the corners of the top left and top right quadrants. So this is actually very poor correlation between block gas and execution time. So obviously we need to go deeper.
00:06:50.300 - 00:07:41.938, Speaker A: We can't just model this as like a linear function of just like how much time per guess. But also there's like a ton of different opcodes, as I mentioned earlier. It doesn't make sense to benchmark them independently. So intuitively, we know that read and write ops are a lot less predictable from just adding two numbers or multiplying off a stack. So what we did here is I grouped a lot of different operations into different buckets, like storage ops, call ops, account reads and so forth. And I sort of sliced the data a lot of different ways. And sort of the best thing we came up with was a fairly simple formula.
00:07:41.938 - 00:08:47.624, Speaker A: So our variables here are like our total gas for the block and the storage related gas that's s loads, s stores, calls, anything that really needs to possibly read or write from disk, and then an assumed overhead per transaction. So running a multivariate linear regression like least squares, we were able to create a cost function here. It's better, but it tracks the bottom case here and the top corner. But it's missing what's really the most important, which is our low gas high time blocks. So this is definitely not the right solution here. So it's important to step back and ask, why is this the case? Gas is not really there to reflect execution time exactly. It's set up.
00:08:47.624 - 00:09:44.812, Speaker A: Gas prices are set up for incentives structure. So while in reth, it might be computationally equivalent to add a new storage slot, update an existing one, or delete one, they all cost very different amounts. Now, separately, there's other factors such as failed transaction, inverted contract calls, costing storage, but maybe not actually writing. And then finally, at the end of every block, we're only needing to calculate the state root changes based off the total net changes. So there's a lot of double counting depending on what transactions are the block. So putting this all together, we can kind of reduce this to a few fairly simple variables. So we model like the total gas consumed, which critically recounts any refunded gas.
00:09:44.812 - 00:10:27.810, Speaker A: Like just because some gas was returned to you for clearing out storage doesn't make it any cheaper in the short term. Then also excluding things like call data, which are there to keep the block small but don't really add any cost. And then we count the number of slots change. So that's like the number of accounts changed, as well as storage lots within individual contracts. You put this all together on a block level, you get like a two variable equation. It's very, very simple. And running the same regression pattern again, we actually get something that shockingly accurate in terms of modeling our various transaction patterns.
00:10:27.810 - 00:11:24.222, Speaker A: So what this comes down to on this specific test example is around two nanoseconds per gas, another just under a millisecond or a per slot changed with a very small overhead per block. So it tells us a good number of things here. One that we can definitely have shorter block times because the cost of overhead is very low. And it also means in practical terms that updating and deleting storage slots is really the most expensive use of gas on our commodity hardware. So after you factor in refunds it's only around 4000 gas to delete versus like 22,000 to add a slot. So that's like a five to six x difference in cost. So in the real worst case here, we're at like just under a millisecond per slot updated, which gives us just over 1000 slots per second.
00:11:24.222 - 00:12:19.980, Speaker A: Which is in the absolute pathological short term case is like just over a 4 million gas a second. Now there's a lot of silver linings here. Like every time the same storage slots accessed in the same block, those are additional ones are kind of free for us, but. Okay, so now we did our benchmarking on one specific configuration. It's important to introduce a few other variables to see how that changes things. So the next really good news here, and I'm not sure how much you can see it, but throwing hardware, the problem does work. So we bumped the instance size still far below the max available on commodity cloud hardware, which doubling an instance size on EC two gives you generally twice the cpu's, twice the ram and twice the disks.
00:12:19.980 - 00:12:58.810, Speaker A: Really all that matters here is twice the distance rate of zero. If we look at the bottom, I'm not sure if you can actually see the bottom line out in the audience, but it stays roughly the same. So non storage related execution stays very constant because there's really no parallelism. There's not much to do with other cpu's, but the IOP's more or less doubles time to perform storage operations halves. So that's great news. There's a lot of room to grow there. Now, also important to like compare this against Geth.
00:12:58.810 - 00:13:41.402, Speaker A: So we took the lightest configuration possible, which is full node path DB. And you get a much more linear representation of gas. Which is actually kind of unsurprising when you think about the fact that geth is the majority client on which all these gas prices were originally set. Now there's a few caveats here. One is I ran this on a much smaller set of blocks because the traces were like an orders of magnitude slower. And I didn't really want to wait a week for this whole thing to go through. And the other important point here is that Geth is actually very rarely actually flushing a disk.
00:13:41.402 - 00:14:39.610, Speaker A: So even though we were performing lots of storage, writes only twice did this self report as actually flushing the changes to the disk. So that also means that we can't really explain the P 95 spikes of this dataset. It all kind of shows up as noise and is not mapped to any particular pattern of opcodes or storage access. So it's kind of an interesting takeaway here. So maybe you've also, maybe you're running your own node and you've heard there's cool file systems out there that will let you have on demand or like live snapshotting and cool features like copy and write, like b tree file system or butterfs. Don't do it. If you look at this y axis, we've gone up sort of like a ten x multiple.
00:14:39.610 - 00:15:40.930, Speaker A: Like a whole order of magnitude is lower on the worst case. So just like using file systems with like smart features is really not a good way to run a database because your worst case performance just gets far far far worse. And in fact we couldn't really model this either with a similar cost function analysis as before. So where does this really. So where are we today really in wrapping this up? So we know we can get around 500 storage writes per second per NvMe drive in raid zero, which scales generally linearly. So in the absolute temporary adversarial case, when you're just deleting lots and lots and lots of slots and doing nothing else with your gas, that puts you down somewhere on the order of two mega gas a second per drive, which also will slow down a bit as state grows. But the good news here is that all other gas is like super cheap on Reth specifically.
00:15:40.930 - 00:16:33.130, Speaker A: So we're seeing somewhere on the order of 500 mega gas a second block sizes. And we know that there's a lot of things being done to get that even faster. And the other takeaway here is that geth full node on bathDB generally has an average case that maps to the middle case for reth. So that was when you have storage heavy, but not pathologically optimized storage heavy access patterns, even though it's only rarely actually flushing disk. So that tells us there's really good performance implications on Reth. And we've made huge leaps forward here. So just looking ahead, we know there's plenty of levers available for improving execution speed.
00:16:33.130 - 00:17:19.180, Speaker A: There's revmc compiled evM bytecode. We can run things in parallel and actually start to use all those extra disks or extra cpu's we have lying around idly. And really the biggest one we can have right now is optimizing our disk writes. That really is the critical path to scaling further right now, ignoring things like DA and other blockers along the way. So one takeaway here is that high throughput chains probably want to start charging more for storage access. And you can do this with just breaking EVM equivalents, you can just charge more. It's not something we want to do lightly because it's just not great for the developer experience.
00:17:19.180 - 00:17:37.769, Speaker A: So there's probably a good reason to align on like Vitalik's, like multi dimensional EIP 1559, set a number of storage lots you want to write per block and price a base on that. So thanks everyone for listening to my talk.
00:17:48.160 - 00:18:05.620, Speaker B: Thank you for your work. Amazing presentation. I wonder if you measured the difference in read and write for storage and how does the ram affect this? Because if you feed the whole database in memory, the writes are kind of the same, but reads instant from memory.
00:18:06.120 - 00:18:50.470, Speaker A: Yeah, yeah, great question. So I didn't want to bore everyone with lots and lots of slicing of data, but I did specifically test that. So when we were bucketing storage slots by category, I was trying read access versus write access. It didn't actually matter too much. So the earlier graph where we weren't looking at storage slots themselves, we didn't really get a much better model. And there's sort of an intuitive reason for that in that you already are paying a lot more in gas for writes versus reads. So I think it's actually fairly accurate right there.
00:18:50.470 - 00:19:07.030, Speaker A: Now, as for Ram, we did not try putting the entire state try in memory. I'm sure that would completely change the model here if you're no longer having IO bound operations.
00:19:12.730 - 00:19:31.470, Speaker C: If you go back to the last diagram of Re's, correlation between gas and estimation. Yeah, this one. So there still seems to be a class of outliers on the upper left corner. Are they significant or only visually significant?
00:19:32.730 - 00:20:15.390, Speaker A: That's a good question. Was generally within the margin of error. So let's see. So it's probably not, I mean, modeled perfectly as a linear equation, as was sort of covered yesterday. The overall stored or the overall trie representation is actually a tri of tries. So when we update storage slots on contracts, those are rolling up into the overarching master try. So there is like somewhat nonlinear effect here, but this is generally a good enough approximation for figuring out our upper bound of scaling.
00:20:16.930 - 00:20:21.110, Speaker C: One more question. How many rounds do you guys did for this experiment?
00:20:21.930 - 00:20:36.830, Speaker A: So this specific test here is 25,000 blocks range. And I ran this, I want to say, on the order of like five or six times since I created this model.
00:20:37.610 - 00:20:38.550, Speaker C: Thank you.
00:20:40.810 - 00:21:22.180, Speaker D: I guess this is a question about the rest design in general. So like, in order to account for like the moving parts of Ethereum and like the different chains. So we noticed there's a lot of like dynamic traits, objects being like wrapped into a box and like in futures being pulled by Tokyo runtime. So I feel like that would be like an overhead contributing to the execution because it compiles v tables instead of static jump in the binary. So I wonder, getting rid of those with getting rid of those things contributes much lower performance overhead independent of gas count or dependent depending on the gas count.
00:21:23.320 - 00:22:14.040, Speaker A: Okay, so that's a good question. Let's see. So I think we can definitely squeeze out more performance on the raw execution layer, which is sort of the low line here. I don't. So I don't think that would necessarily impact like sort of the worst case performance, which is like kind of what we've been focused on in this test, given that that's entirely bound by storage slot rights. I mean, if there's a great way to like statically analyze the transaction and understand what's going to be written to in advance, then maybe we can really start to squeeze out additional performance there.
00:22:17.540 - 00:22:51.890, Speaker E: Hey, great presentation. I'm over here in the couch. So I was wondering, caching could probably help on some of this. So I was wondering if you had done any analysis on a specific cache solution that might work, because there are obviously different algorithms, and some of them are, for example, more temporal in nature. And I would imagine for on chain activity, you would have lots of activity localized on some accounts, like uniswap or sen, in this case. Thank you.
00:22:53.310 - 00:23:45.914, Speaker A: Yeah, so there's, I guess, explicit caching, and there's also sort of the implicit caching of like what happens within the context of an overall block. So if you have, you know, if you were building the block and you could say, okay, I know there's a bunch of transactions that are going to go and use the same uniswap contract, you kind of get that extra performance for free just by charging the end user for the computation, but not really inducing any additional cost on the node. I think we can definitely improve the read performance across the board. Just, bye. Proactively populating cache. I think it was the rise team yesterday had an interesting point about hinting. Sorry.
00:23:45.914 - 00:24:23.170, Speaker A: Node providing hints to other nodes about what transactions might. Sorry, sorry. I think you can provide hints from a sequencer to additional nodes about what storage slots we read. I know that's kind of like the idea behind the access lists, but they're not really well adopted. But this, yeah, we can definitely prefetch storage slots and put them in cache to improve sort of the average case here.
00:24:23.750 - 00:24:26.090, Speaker D: Okay, we have time for one more question.
00:24:27.510 - 00:25:26.940, Speaker F: Thank you for the presentation. Do you think your findings are kind of a bear case for trying to price gas in a way that's a little bit too clever and kind of overfits the implementation? Like for example, get seems to be somewhat more aligned with the gas costs currently, while Ret doesn't fit the same way. Does that mean we should basically never try to fit that because somebody else might make a new client that's not going to fit? And a second question is, have you done any benchmarks that are a bit more about consuming data from red? So for example, if you have subscribers to web sockets and whatnot, trying to measure the latency, things that may not be about increasing the gas limit, but more like the experience of using red.
00:25:28.920 - 00:27:14.840, Speaker A: Okay, so these tests were focused on block production execution. So don't have the benchmarks on like RBC subscriptions and that kind of latency, but. Okay, so as for your first question here, I think it's important to like ask as a chain operator, what are the clients you want to support and what are sort of the price models here for each of them? So ultimately you're trying to figure out what can we squeeze in reasonably on either average or absolute worst case. So, I mean, I think at the end of the day you will have clients that are running way faster than other clients and can just, whether that means that can do more optimized block building or serve other additional RPC requests like in between execution time, you're still going to be sort of bound by your worst case. But I think the other point here is Reth is currently focused on providing a very consistent fast access archive node where we were comparing that to the path DB full node on Geth, which is really only able to serve the current state at any point in time. So I think if we were to take some of those or apply some of those changes, and only buffer writes to disk and only periodically flush them, we'll see this compress and look much, much closer to the geth side just much faster.
00:27:22.660 - 00:27:48.810, Speaker G: And this specific thing we also have observed and we have an experimental rewrite of the consensus to execution layer interface, which should help with that by removing the writes from the critical path. So this is not released yet. It's a behind an engine experimental flag. It's not recommended by any means for production use, but any people doing benchmarks should reach out to us for working on this.
00:27:50.630 - 00:27:56.010, Speaker A: Yeah, looking forward to rerunning these with those changes and really seeing the numbers go down.
00:28:00.990 - 00:28:18.990, Speaker D: Okay, so next up, we have lunch. It's going to be similar to yesterday. It's just outside. We just ask that you be back here at 1230. We have a bunch of stack talks about breath examples out in the wild, starting with Emily, CTO.

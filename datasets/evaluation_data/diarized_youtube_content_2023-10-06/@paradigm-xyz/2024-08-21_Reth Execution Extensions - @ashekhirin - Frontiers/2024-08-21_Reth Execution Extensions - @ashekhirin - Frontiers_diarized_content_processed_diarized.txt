00:00:01.120 - 00:00:31.842, Speaker A: Hi everyone, my name is Alexi. I'll be talking about execution extensions first. Wanted to ask, maybe raise your hands if you heard of execution extensions. Now, if you've built an execution extension, you played with it. Cool. So let's start with the motivation. Why do we want to do this thing? The goal is to build off chain services that benefit from real time on chain data.
00:00:31.842 - 00:01:23.520, Speaker A: And if you think about it, it's basically everything that's not on chain. This is roll ups, this is indexers, this is avss, sometimes this is MeV bots. I was going to remove this from the slide, I didn't basically, you derive the data that you need from new transactions, new headers, and you build something on top of it, how people usually do it. If you build an indexer, you want new blocks, and people usually subscribe to Websocket. There is a handy RPC called ETH subscribe. It's good, it's standardized, everyone has the same implementations. So whether you are geth, neithermind, Reth, Eragon, whatever, you will get the same response.
00:01:23.520 - 00:02:16.980, Speaker A: This is good. The downside of this approach is that you have poor performance due to serialization and deserialization of JSON, which is basically not the best format for efficient data transfer. Also, there is not enough data that's passed on on this channel. One example is the reorgs. So for example, if you have a reorg on the chain, you want to be able to receive the blocks that were reorged from the chain and also get new blocks that were committed to the chain. EtH subscribe doesn't allow you to do this. And also you need to maintain some ad hoc solutions with Python or JavaScript or rust code which is not related to the node code.
00:02:16.980 - 00:02:48.080, Speaker A: It's like live separately. So it's a separate project that you have. And here is a small example of JSON RPC. Call to Eth subscribe. What if I want more performance? Okay, you can fork the node. This is to the Times of MEV Geth and all these forks. When you have geth that everyone knows and love, and you fork it, add your own modification to it and run it as a new piece of software.
00:02:48.080 - 00:03:38.864, Speaker A: The problem with such approach is that you accept that you need to resolve conflicts from time to time, because the code bases are evolving all the time. And here's an example of our work. In one month you will basically need to rebase on top of almost 500 pull requests. Not fun. You can also accept that you will just stay behind on new features and optimizations. Which is also not cool because you want to benefit from other developers working on the client itself, which is also an important thing that you need to actually know where to look in the node code to be able to modify it. Reth is different from Geth, Geth is different from netherminden, all different languages and all different structure of the code base.
00:03:38.864 - 00:04:48.186, Speaker A: So you need to know where to plug into your indexer, your roll up, or your AV's, for example. So what addition do we think is an ideal? It was supposed to say our solution, we think that you can extend the node and plug to off chain data using the rest SDK and basically avoid the overheads on JSON and any serialization or any other data format you can avoid forking because you use Reth as a library, that method that was talking about previously, which is also we think is important. You are able to differentiate between chain commits and reorgs. So when there is a reorg, you receive a separate enam variant saying the chain reorg. This is the old chain, this is the new chain. I'll talk about it later in detail. And also execution extensions, or x axis how we call them, is a well defined framework that allows component reuse.
00:04:48.186 - 00:05:38.362, Speaker A: For example, you have the whole rest core SDK for you, so you can use anything from it, EVM executor or whatever. Yeah, so enter execution extensions. On the right there is an example of a real execution extension that you can build. It's 50 lines of code or so. I'll go through it in a short manner. So basically you get access to all node components via the context that passed as an argument. Then you consume the reorg aware stream of new notifications, and each notification is basically a chain commit or chain reorg, or also chain revert if it was just unwinded in the pipeline.
00:05:38.362 - 00:06:19.830, Speaker A: For example, you do not have any serialization deserialization, HTTP websocket data transfer. You have the same shared memory that Reth uses. So important thing about XXs is that you plug them into the same binary as ret. You compile it in one project and then you run it. So if Reth already committed a chain and it has it in memory, there is no need to copy it again for xx to use because it's read only for every xx. So we can just pass it to xxs and they can do whatever they want with it. Maybe do a clone, maybe serialize, but it's up to the xx.
00:06:19.830 - 00:07:08.760, Speaker A: And as I said, it's compiled in the same binary, so there is no overheads on any data transfer, which is also nice. Let's talk about what is an xx in detail. Basically it's just a future. We made it so that you can write an async function that accepts the context. It returns a result with an empty value and never resolves. What you should do in your xx is that you consume the stream of notifications. You mention different variants, commit, reorg, revert, and then you send an event back to the node saying hey, I processed up to this height, up to this block number.
00:07:08.760 - 00:07:56.300, Speaker A: Why is it important? Is because we have pruning. So if you think about the full node, it only has like what 10,000 blocks in the past from the chain tip. So if you have a slower xx and you are lagging behind, you need to say up to what number of blocks in the past you processed. So we don't print the data that you still need. And also it's up to you whether you want to query the transaction pool, the third party API, some other blockchains, whatever. There is only two requirements. You need to consume the notifications to drain the stream and you need to send an event back to the node.
00:07:56.300 - 00:08:39.748, Speaker A: How do you install an xx? You use the core SDK node builder and you can install however many x axis you want. They will all be running in the same binary pulled by the manager. And yeah, they can even communicate with each other. If you want, you can have some channel for passing the information from one xx to another. The manager, as I said, they are managed by the manager. And the manager is a thing that's responsible for sending notifications to Xaxis from the node. So the life cycle is the following.
00:08:39.748 - 00:09:36.442, Speaker A: You get a new payload from the consensus client, you execute, you commit to your database of main l one node and then you have a chain which is a structure that contains state divs. Try updates, blocks, headers, and you send this chain structure to x axis. Xxmanager also controls backpressure. So there's a question, what if I do not consume the stream of notifications? Basically the node will stall and say you in the warning log that hey, your xx is wrong and it's an opinionated thing to do. But we think it's right because when you write an xx in your binary you are supposed to use it. So if it doesn't work, we need to let you know about it. It also handles errors.
00:09:36.442 - 00:10:21.564, Speaker A: So if xx crashes, the whole node exits. Because again, we think that if you install an xx and it doesn't work, the whole process should abort. It also has some monitoring. For example, when you have another notification coming to Nxx, we emit a metric to prometheus and you can see in Grafana how many notifications you received, how many events you sent for every xx. Let's talk about the xx context and what's inside it. So as I said, this structure is passed inside your xx. Every xx receives context.
00:10:21.564 - 00:11:06.236, Speaker A: And the main thing here is the stream for new notifications that you need to consume. I'm not sure how to do it. Yeah, it's right here. Notifications receiver execs notification you consume this thing. It also has a bunch of other different components that are hidden in this generic components node. These components are transaction pool, EVM executor, database provider for the l one nodes and you can use all of it inside your xx. We also give access to the chain head that we started with some config and sender for the events back to the node.
00:11:06.236 - 00:12:32.542, Speaker A: But basically we think that this is all you need from the node itself, from the host node, and everything else is up to you to figure out if you want to extend it more. So on previous slide there was an exact notification receiver and this is the notification itself. There is three variants in this enum commit, Reorg and revert commit. A new chain was committed, Reorg null chain was reorged and we send both old and new chain, which is basically the same type, the same string, but the old chain contains all the state divs that happened that were reverted, and the new chain contains all state divs that are committed. So what you can do is that for example, you are building an indexer and you want to reverse the changes that were reworked and you actually have the state divs for accounts and for storage slots that you can just revert from your postgres or whatever. Yeah, the chain itself contains blocks. Obviously there are headers and transactions inside blocks, but also it contains the outcome of the execution because chain is passed to the xx when it was already executed by the main node.
00:12:32.542 - 00:13:10.040, Speaker A: What you have in the outcome is the state divs, the receipts and the requests. Requests are the thing from new hard fork that allows you to communicate with the CL. They are derived from the execution. So we also pass them and there is also try updates. They can be useful if you want to build something on the Merkel Patricia tray. You receive basically all nodes that were changed in the tray but not the full tray. So you can build your own index of the try in your own format if you need.
00:13:10.040 - 00:13:58.920, Speaker A: So what do we have implemented so far? We have the lifecycle management via the manager. As I said, we have the front fill, which is basically when your node just started from scratch, you need to sync to the tip. You use the pipeline as was said before, and during the pipeline execution you receive the committed blocks to the database into your xx. They're sent from the execution stage. So when you actually do the execution, you have all the state divs received requests and you send them. And we also have the front field during the live sync. So when you node is up to the tip and it follows the CL, we send a new notification with every new block.
00:13:58.920 - 00:14:50.990, Speaker A: So during the live sync, then the notification contains just one block. Backfill imagine you have an indexer and you are indexing some fields of transactions. Now you want to index one more field, but you have 20 million blocks in the past on Mainnet. How do you re index it? You do the backfill. Backfill is a thing that we provide. It's an abstraction over the EVM executor that allows you to say, hey, I want to execute from block zero to tip and send the results to my xx. What will happen is that the node itself will continue with live sync and following the consensus client, but the xx will backfill the data from Genesis.
00:14:50.990 - 00:15:25.088, Speaker A: This can also be exposed via RPC or CLI. So for example, I will show the example slide later. You can have an RPC that's called backfill start that accepts a range of blocks and without node restart it starts a backfill for just your execs. We also have testing utilities because you need to be able to mock the components of your node without actually running it. So you need to run unit tests, you need to run end to end tests. And we have some utils for this. Examples.
00:15:25.088 - 00:16:08.136, Speaker A: Oh my God, where is the picture? Okay, so we have a repo for examples. We implemented different source of examples from the minimal example, which is basically the one that I showed you before. Log every new notification. And we have more sophisticated ones such as backfill via RPC or clique querying the blobs from the consensus client or third party. Like blobscan. It can be useful when for example, you are a roll up and you want to query a blob for some historical block. But blobs are expired so you don't have them on the cl anymore.
00:16:08.136 - 00:17:02.610, Speaker A: And you need to have another source of data. For this there is a disk v five example. A cool thing that we are excited about is that you can connect x axis between each other via custom disk v five topics so they can communicate and utilize the same network that ETH has. We have a toy example of rollup which is basically an sqlite rollup that gets the blocks from the ethereum, Mainnet or Haleski. In our example it's Haleski. It does the execution of the batch that was submitted to the mainnet to the l one, and then it commits the execution results state. Try to escalate database also like 1000 or 2000 lines of code.
00:17:02.610 - 00:17:51.030, Speaker A: Not a lot for a working roll up, even though it's on escalate. What future work? We still have so x axis work today, people building it. There will be shadow rest execution extension as was said before, but we still have some work to do. For example, you may not need to have any other functionality except acting on unitification. What if we have a tray that has onunitification methods that actually calls every time you receive a new notification? It's simpler xx because you will not be able to act on other data sources. But it's also easier if you just need the notification from the node. We want to build a more comprehensive standard library for x axis.
00:17:51.030 - 00:18:23.600, Speaker A: Some of the things are blob utils for EIP 4844. As I said, we already have blob querying, but for example, you may want to have something else for this. Backfill extensions for PC and CLI. As I said, we have backfill as a, as an abstraction, but you need to build the RPC and CLI by yourself. So we can also provide the extension. Sorry. We can also provide the abstraction for the RPC and CLI that does the backfill for you.
00:18:23.600 - 00:19:10.418, Speaker A: And the last one is disk V five. We also want to provide you a way to expose a custom disk V five topic to communicate with x axis without diving too deep into diskvive and how it works. Another cool thing that we excited about is dynamic loading of x axis. So as I said before, x axis are compiled in the same binary. So you cannot actually have a running ret node and somehow install an xx into it. There is a cool idea with dynamic libraries like so dilip DLL on different platforms that you can install into an already running binary. There is a project, sorry, not project.
00:19:10.418 - 00:19:52.230, Speaker A: There is a part of the Solana client called Gazer. It's basically a plugin system that allows you to output the data from the chain to Kafka or whatever data source or data warehouse. And it's done without any recompilation, which is quite cool. And we think we can do something similar I have an example with WaSM, it works in a similar way. You just call NRPC with WASM bytecode and it starts running along your main node. And the last thing that we want to improve is observability. As I said, we have some basic metrics for xxs, like notifications sent, events received.
00:19:52.230 - 00:20:43.422, Speaker A: But we want to have more insight into ix access stalling, are they falling behind the mainland chain, etcetera? So a couple ideas what you can build today on this hackathon. On this small hackathon you can build an AV's that's utilizing the disk v five or IRO. Also a cool project for peer to peer connectivity. And basically it's an xx node. It's a reth node with an xx that communicates with the same piece of software over this network. There is a toy idea, but it's a cool hackathon project for a game roll up. So there is mud, but you can also do one with baby, which is the game engine in rust.
00:20:43.422 - 00:21:28.180, Speaker A: So like imagine you commit some change for your game on chain and then in your xx you actually do this action in your game engine. You will need slower than 1 second block time, but it's not a problem. You can also have stealth addresses. We also have this as an example, but it's not finished yet. Stealth addresses is an ERC that was recently approved as far as I know that allows you to. I don't remember what it does, but check it out, it's cool. And yeah, this QR code is the examples repo that you should check out because he has a lot of examples and open pull requests with more examples.
00:21:28.180 - 00:21:49.990, Speaker A: That's. I believe it. Yeah. Thank you. Any questions? Hello. Hello. Hi.
00:21:49.990 - 00:21:55.002, Speaker A: If you wanted to use an xx, would your node have to be fully.
00:21:55.026 - 00:21:59.070, Speaker B: Synced or could you just run it and follow the tip?
00:22:00.330 - 00:22:18.470, Speaker A: You can run an xx without a fully synced node. It will get the notifications from the pipeline sync. So you can start a fresh node without any data in the database. And when you do the execution for the historical data, UX will receive these changes itself.
00:22:22.770 - 00:22:31.350, Speaker C: What networks can be run with xx? Like for example, can I run it against arbitrum or what are the requirements?
00:22:32.570 - 00:22:54.200, Speaker A: So the way you think about it is that you have ret node as the guys was talking about on the previous talk, and you have for example opsecobase. That ret node can run everything, that reth node can run. Xxs can be plugged into. So we don't have support for arbitrum yet. So no, for now you cannot do this.
00:22:55.100 - 00:23:03.960, Speaker C: Ok, what should be done in order to run it on arbitrum? Is it because of different network stack or is it more deeper?
00:23:05.340 - 00:23:28.140, Speaker A: I'm not sure. I believe it's even deeper diff than opstack changes. So you will need to have lots of custom changes for your node to be able to process arbitrum blocks and peer with arbitram nodes and all this stuff. So I think it's unrelated to x axis because x axis are plugged into an already functioning node.
00:23:30.560 - 00:24:00.270, Speaker D: What's the thinking around redundancy? Especially client redundancy? If you've got an index or something that would leverage an XXD with just an RPC endpoint, it's pretty trivial to fall back to using some other client if there's an issue or yeah, what's the thinking around that? If you've got a co located xx, is there an adapter or something in the works that could wrap an RPC that you could use a fallback?
00:24:01.930 - 00:24:45.360, Speaker A: Not right now, because we're thinking about it as safe either scan you have some indexer that's built in c hash in the case and Reth is basically a basic infrastructure for this indexer. I think it's possible to build a wrapper around RPC so you have an exec similar functionality, but I'm not sure it will make sense if you still have the overhead for JSON sterilization, decerialization, the networking. But maybe the code reuse may be a good thing and you can write your xx in rust and plug it into for example nethermines or geth RPC. Yeah, we didn't explore it yet, but that may be a good idea.
00:24:46.140 - 00:24:46.920, Speaker D: Awesome.
00:24:49.820 - 00:25:18.920, Speaker C: Would it require a rather bigger machine to run RS XSS to do indexing? Because today, let's say I'm building a di for indexing NFT contract. I only would be subscribing to events related to my contract that I'm interested in violating RPC. It seems that if I want to use Xx I would need a bigger machine to sync the whole state. Is it a proper use case or are actually can be very very slim in this case?
00:25:21.020 - 00:26:08.600, Speaker A: Good question. So I think you can use the full nodes for this. It's a bit smaller than the archive node, it's 1. You will get the changes for your NFT contract from execution of new blocks, but it will still be not a lightweight node. You're right. I think in this case the subscription to just the events of your NFT contract may be a better idea to use the RPC, not the xx, because xxs assume that you have a fully synced ret node. There is a future where you have ret node running somewhere in the cloud and you can plug into your xx into it via the dynamic library or WASM.
00:26:08.600 - 00:26:15.000, Speaker A: But it's something that we are not building right now. And it's a third party service I think should be.
00:26:16.100 - 00:26:53.380, Speaker B: Yeah, I'm here Alexei, you see me? I'm here. Yeah, yeah, thanks Alexei. Great presentation. I think it's super powerful and it seems to really open a lot of new gates to be able to interact with the chain off chain. But I'm curious about. I feel the intuition and the potential of what could be open. But I'm curious like you who have worked on it, do you have like a few examples or do you have a vision for it in the future? What would be like the big unlocks that execs could bring to the blockchain or to ret in general?
00:26:55.440 - 00:27:40.660, Speaker A: Right. I think it will make building indexers easier and more performance. So as I said, you are kind of locked into the RPC subscriptions in lots of situations. It will allow you to query the database directly, get the blocks right from memory. So it's not an unlock in new use case. I think it's a performance unlock and an unlock for cost saving, I would say. Yeah, I think stuff like shadow locks can be a good use case.
00:27:40.660 - 00:28:19.330, Speaker A: You can build it on a regular node with re execution of each block. But what you will be able to do in Reth is that you are able to override the executor that main node uses and you are able to receive the block that was executed just once with all the shadow locks emitted or all the traces. It saves you, I think, on time that you need to process the blocks for shadow locks. Again, not a new use case. You can do it with RPC. I think it's mostly about performance and the convenience.
00:28:20.190 - 00:28:46.848, Speaker E: Just to offer an additional point on this is that by running exexis you can run ten roll ups on top of one node without having to run services. So why I'm really excited for it is for people to just run mini roll ups on top of their nodes without having to worry about Kubernetes cluster orchestrating everything. So it's a nice way to simplify the infrastructure.
00:28:46.864 - 00:29:06.880, Speaker D: Hi, I had a question earlier. I saw you had a node exposed into your executor context. Is that sync that node synchronized with your context? Like for example, if there's a reorg that you haven't received yet. Would that node show the pre reorg state or the post Reorg state?
00:29:07.740 - 00:29:34.570, Speaker A: Good question. Yeah, it will show the latest state that you have. So when you query the database for the latest state, it will show you the actual latest state and not the one that you're currently working on. From the notifications, you are able to get the historical state for the archive nodes via the same nodes provider. But yes, the latest state of transaction pool database payload builder will be actually the tip and not the one that you are processing.
00:29:42.990 - 00:29:54.750, Speaker D: Hi, I was wondering how the xx backfill interacts with the state pruning that you mentioned that it communicates with a full node about.
00:29:56.370 - 00:30:30.400, Speaker A: Yeah, so what backfill does is that it actually uses the blocks that you have in your database for re execution and sending new outputs to your execs. And we do not prune transactions and headers at all because transactions and headers are needed for the health of peer to peer network to be able to share it with other clients. So even on the full note you are able to send, you are able to do the backfill from the genesis.
00:30:34.180 - 00:30:39.520, Speaker E: All right, one more. Ok, let's do one more. Keep it short.
00:30:40.220 - 00:30:47.292, Speaker A: In the future, do you plan on supporting out of the box support for things like parquet files or column or.
00:30:47.316 - 00:30:51.690, Speaker B: Databases like DuckDB for storing state?
00:30:52.910 - 00:31:20.130, Speaker A: Is it about x axis or the main node? Yeah, the main node. Yeah. We have some thoughts, ideas what to do with the database? Maybe to split it into more databases? We currently have static files format and it's basically a columnar format for storing the append only data like transactions and headers. So it's a customly rolled format which is very similar to parque but more efficient for point queries. Nice.
00:31:21.110 - 00:31:24.250, Speaker E: Okay. Given this, we're sure. Do we have one last, last question?
00:31:24.990 - 00:31:32.930, Speaker C: Thank you so much. A quick question. Is it possible to build a op stack with some precompile with xx of res.
00:31:35.710 - 00:31:36.930, Speaker E: Con execs?
00:31:37.230 - 00:32:20.948, Speaker A: Yeah, I mean, is it a precompile? I think precompiles sync in the sense that you have EVM and you need to get the result from a precompile immediately and not after the block execution. But Conxx is a nice idea that the guys will talk about later I think. But yeah, I think for precompilers in the EVM on opstack, you need to modify the executor and the EVM itself and not build it as an xx. Although you can have an async precompile that says start a request and maybe then fulfill the request. And you can build the fulfillment parts of the request into the xx. So you start the request for disk reads. You read the disk in the xx.
00:32:20.948 - 00:32:24.880, Speaker A: And then you receive the result back in the fulfill part.
00:32:26.700 - 00:32:28.532, Speaker E: All right, give it up for Alexi.
00:32:28.636 - 00:32:29.440, Speaker A: Thank you.
00:32:34.940 - 00:32:35.940, Speaker E: And now we're going.

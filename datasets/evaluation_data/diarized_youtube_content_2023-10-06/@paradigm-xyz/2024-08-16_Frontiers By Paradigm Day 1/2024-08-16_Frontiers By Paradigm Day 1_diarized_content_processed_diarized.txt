00:00:00.120 - 00:06:38.900, Speaker A: Go inside. Mic check. Okay. 1234, toast sandwich, crypto. Okay, we're still gonna bug people to go inside, so we're gonna start in five to seven minutes. Good morning, everyone. All right, so our frontiers warming fm all of that stuff.
00:06:38.900 - 00:07:27.298, Speaker A: So we have gathered today to talk about a bunch of good open source software. We also have a bunch of logistics first to get through. So our event is called frontiers. Last year we hosted an event that we called Rustx Ethereum, which meant to showcase the open source stack that we built on Ethereum in the programming language of rust. Now, this year, the last year event was one day, half a day of talks. The rest of the day was spent on some mix of networking and hacking. Today and tomorrow we hope to do something that's a little more exciting with even more talks, going deeper, having more externals, having more of our internal team, but also having more time to build exciting stuff, some logistics.
00:07:27.298 - 00:07:55.102, Speaker A: So we have the talks in the morning, today and tomorrow. In the first half of the day before lunch, we have people from our internal teams. In the second half of the day, we have ecosystem builders that are building on our stack. And after 02:00 p.m. or 130, basically, depending on whenever the talks end, we're going to flip the rooms. All the chairs, as you see here, are going to be replaced by tables. And anyone that sits here is expected to cowork or hack or basically get stuff done.
00:07:55.102 - 00:08:30.990, Speaker A: And you should think of this as a very, very light networking and more. So we're trying to do things, you know, no necessarily investment talk and no talks about tokens and all of that. We're going to focus on really the building part today with regards to Saturday. At the end of day, anyone that has hacked something that they're proud of, and if they had started something before, if they had the idea before, it's okay. Like, this is meant to be a safe and friendly place. There are no rewards. If you want to come at the end of the day on Saturday, you can get here and just present for five to seven minutes.
00:08:30.990 - 00:09:02.090, Speaker A: No expectation to do that, but I think some people might enjoy that. And if you build something cool and you want to showcase it, feel free. We managed to get a live stream set up, actually. The reality is that we could have done it ahead of time, but we really wanted to make sure that we get people excited to come to fly out here. So big shout of the people that flew out, but also a big shout to the people that will be looking at things online. We have the website which has a live stream link as well. We have a telegram room where people will be chatting hopefully.
00:09:02.090 - 00:09:36.418, Speaker A: And we also have the work a warpcuts channel where the images are loading. Aha. Yeah. And we also have a warpcast channel on slash frontiers for people that want to do some more freeform content. And we like that because it groups the content so that we can then find it after the fact. All right, so everybody should have received the pouch and big shout out to our design and events team for this because it took a lot of work to be very intentional about how we want to communicate this event. And I think merch is something really cool that you can do a lot with.
00:09:36.418 - 00:10:04.546, Speaker A: And generally people give you sometimes many boring t shirts or they give you baseball hats and all of that. And no offense to anyone doing that, but this is not like what we prefer to do. And so we said, all right, given our audience as programmers and many programmers like mechanical keyboards, let's give them keycaps. And that was an idea by Tom from Wagme who is like over there on the crowd and will talk to us tomorrow. It was an amazing idea and we loved it and we instantly did it. So everyone should have a keycap. They have a bunch of rarities.
00:10:04.546 - 00:10:39.450, Speaker A: They represent some of our open source projects. Hopefully next year we'll have even more of them. And then at some point your entire keyboard can be our keycaps. All right, so we have Vivek from cursive. Where is Vivek? Vivek is right here. Okay, so everybody might have noticed that you have received an NFC card where you can tap and play a fun social game. So we collaborated with the cursive team after seeing them run an activation event in Athens in ZK Summit earlier this year where they basically facilitate fun social experiences using ZK and other cryptography.
00:10:39.450 - 00:11:15.944, Speaker A: So I will have Vivek on the stage for a couple minutes to briefly explain how this works. So big applause for Vivek to explain this. Thanks Rojos and big shout out to the paradigm team for supporting us through this activation and letting us demo at this wonderful event. So everyone at entrance should have received a NFC card on a little clip thing. If you don't, I have this bag full of more. I can walk around and give people some. And we're going to have a big bin at the entrance way, so make sure to grab one.
00:11:15.944 - 00:11:54.784, Speaker A: We have one for every single attendee. And yeah, so if you guys want to try it right now, you can go for it. If you haven't set it up, basically you have this NFC cardinal, you should be able to tap the top of your iPhone to it to be able to receive this little NFC link. It won't work if you're on airplane mode or if you have your camera open, so you can just do it from your lock screen. If you have an Android, basically the tapping is more kind of in the center of the phone, but generally sometimes you have to turn on NFC for Android, but once you do that, you're basically just good to go to use experience. So tapping your own card lets you set that up. And basically what? At a very base level, it allows you to share your socials and share different GitHub statistics really easily.
00:11:54.784 - 00:12:40.380, Speaker A: It's pretty developer focused, given the sort of themes of this event, and we hope people will just get some base utility out of that. But there's a bunch of other fun cryptographic features we've built in which we're hoping can help facilitate deeper connections in a safe, privacy preserving way. So when you actually meet someone, you can do something called a private set intersection, which essentially allows you to see different contacts you have in common and other information where essentially only what's revealed is the stuff that's in common. Everything else is sort of kept private, and you can basically see this on the main profile page for someone else. One thing is that this is a synchronous process, so you need to be on each other's page at the same time. Hit discover, and then you can see who you've met in common. And if we have time this weekend, we might add in some more fun features to that.
00:12:40.380 - 00:13:34.040, Speaker A: In addition, you can make proofs about your event experience. Right now, there's just two it's like proving you've met some set of speakers, proving you've met just some number of attendees. Here, we're also hoping to expand that list, and we're open to ideas for fun things we can do. And finally, the thing we're most excited about, which we're very grateful to the paradigm hiring team for helping us discuss and iterate on, is a private hiring matcher, which essentially allows you as a candidate to privately post that you're open to jobs, as well as a recruiter to privately post some sort of job listing. And you only get notified if there is some overlap in your preferences, whether it be sort of like the salary that I'm willing to work for as a candidate, or what the salary a recruiter is willing to give, as well as different interests and requirements. And the idea here is that privacy can sort of make this interaction basically safer. And as someone searching for a job, you don't need to necessarily post publicly or say publicly that you're looking for something.
00:13:34.040 - 00:14:03.150, Speaker A: It can just sort of be facilitated privately and notably, like as a candidate. Like, if you receive a match, you will always basically be able to consent to sharing that with the recruiter. So the recruiter will never see anything by default. It'll be up to you to basically share things. So, yeah, try that out. Even if you're not looking for a job, if you just want to put some dummy profile up just to test the technology behind this, which is some new multiparty computation tech, that would be great. But yeah, that's all from me.
00:14:03.150 - 00:14:21.726, Speaker A: Thanks so much to George Osten, to paradigm. Thank you, Vivek. And, you know, we say let's make crypto fun. Again, I think there's a textbook thing that makes crypto fun, and it's like, been a pleasure to get this done. So we basically did the dating app for founders and for talent. And I think it's pretty cool. Safety is a core component of this.
00:14:21.726 - 00:14:54.420, Speaker A: Like Vivek said, if you want to get hired or you're a founder, you necessarily don't want to leak our Yol alpha to the market. And so, yeah, I think this is really cool. And please go to Vivek and Andrew and Rachel, who were welcoming to give them feedback. So some more logistics, telegram and work passed. I'm going to leave this up for two, three, four, 5 seconds. Like, just so people that are excited that want to scan it. So I'm going to count 123123.
00:14:54.420 - 00:15:25.594, Speaker A: All right, hope this worked. And now we're going to get into my talk, which is the future of Reth. And let's maybe talk about the story so far, which is, okay, we have Reth, which is a contributing, friendly implementation of Ethereum. So the text that you see on the screens doesn't exactly matter. Just take that. You see a GitHub repo called rethemeral with 300 ish contributors, which is the important takeaway from this. So we built reth.
00:15:25.594 - 00:16:14.770, Speaker A: We started building Reth almost two years ago, or in October 2022 was when we made some of our first commits with basically four core motivations. A was the client diversity motivation, meaning that you want many different implementations of the Ethereum protocol for staking. And Reth is an ethereum node, it's an execution layer, which means that it's the one half of the ethereum node, the other half is a consensus layer. We have some people from consensus clients in the crowd. So if you have a problem with your staker, go to support for them, not to us. Now, on the client diversity front, it's not just the client implementation for the safety of the system, it's also important that you have a ton of people that have tried to learn how the system works. And when you do many reimplementations, the thing that knowledge just gets dispersed across the ecosystem and that's very valuable.
00:16:14.770 - 00:17:00.306, Speaker A: So talent resilience means that basically instead of onboarding like in months, it's very important that you're able to onboard on the end client in weeks if not days. And this is why we're so anal about contributor friendliness, because that means that we can take and train a junior and you know, we can just take a junior and put them on an Ethereum node, which is kind of a head scratcher. You know, sometimes you would think that such a junior would never be able to do that, but we have converted people to believing that they can do it, and I think that's important. Client scalability. We just think that performance matters a lot. We don't talk about performance all the time because it's part of our process. But in this day, today, you're going to hear a lot about performance because we have some exciting results to share.
00:17:00.306 - 00:17:37.780, Speaker A: And code extensibility is probably the thing that I'm the most excited about because I'm tired of people forking nodes with our principal and then having to rebase that hundred. Getfork and Matt from our team afterwards. Give us a bit more on that. So all of these motivations, they got us the online of, okay, blazing fast, modular, contributor friendly. And contributor friendly is very important because a I think you want to be doing things with friends, not on your own. It's way better when you have a bunch of people doing things with you. It's also better for moving fast because we're able to leverage the collective power of the community to move really fast.
00:17:37.780 - 00:18:14.280, Speaker A: We're actually able to hire the best people out of their code bases, which has been really impactful. And also every bug is shallow in the eyes of a thousand eyes or more, which is a classic old Linux open source code. There's many reasons on why it's contributor friendly. The issue tracker is pristine. The documentation is really good, it has a lot of tests, it has a lot of benchmarks, and most importantly, the people are there for you. So there's a chat room, there's a paradigm red chat room. We all have the foundry, the alloy, you know, we have a whole stack of chat rooms, and everybody on the team is trained to do support.
00:18:14.280 - 00:18:48.868, Speaker A: Some people like it more, some people like it less, but it's basically expected from everyone that you're in the chat rooms and you're willing to do communications with the customer, the developer and the community. Also, we have very strict rules around engagement. No ads, no job, no job listings. It's always very clear and technical and deep. And if somebody asks a newbie question, we're very welcoming to them, but also we're not afraid to tell them, hey, this is the wrong chat, you should go to there. Not our problem. So we started in 2022 and we released the client in 2023.
00:18:48.868 - 00:19:29.456, Speaker A: That was the alpha one release. That was a year and two months ago. So let's see how we've done since then. In 2024, Reth is adopted by 5% ish on Ethereum mainnet. Granted, this is not a lot, but given the client has been in production for only a few months, we think this is already very high and we hope that we can raise this even further in the coming year. Why do people do that? Well, because ret is really fast and it's really compact, so archive nodes really matter. And for an archive node to have clear integrity on what your data is and to have a lot of speed, you must be using rest.
00:19:29.456 - 00:20:11.136, Speaker A: Otherwise there is nothing that you can do a data analysis with it. And we use the power user as a feedback loop here. So syncing a ret node to date on good hardware, which is like bare metal hardware with NVMe drives, usually commercial Samsung drives, takes about 50 hours, which is huge. People used to think that an Ethereum node takes like, you know, weeks to sing, whereas ret does that in two days. On Ethereum Mainnet archive mode, the database is also basically almost ten x smaller than anything else on the geth and nethermine end. And it's actually smaller than the Aragon. There is a big caveat here that Aragon did a recent release, at least an alpha release of the Aragon three project.
00:20:11.136 - 00:21:26.126, Speaker A: So we're excited to further benchmark that and learn if there's any innovations that we could co adopt as well. On the contributor friendliness damn, this is like a bit small, but on the contributor friendliness, the thing I want to highlight is, well, a mats like insane number of prs, but also just it's 500 pull requests, 200 closed issues, 50 contributors one month, which is a lot. People don't do 500 contributions in their entire year, whereas this project is really actively contributed to which means it moves fast, but it's also, it highlights that you need to have a very good testing process about it, because otherwise it's going to be breaking all the time. Okay, so this is how we got here, but like, where are we going? So I think the three things that matter the most are feedback loops, or, well, feedback loops matter the most. And the three feedback loops that we think of the rest development are the following. So it's scalability, stability, performance, extensibility for stability, which is the most pristine area for stability. We're Ethereum L1, so by being able to meet the bar of Ethereum L1, we know that the thing that we have is stable.
00:21:26.126 - 00:22:19.678, Speaker A: Because if people are putting stake that runs on the node, that gives us some sense that, okay, people trust this to be stable and it's not going to break under their legs on performance. Of course, Ethereum l one is not a place for performance and open debate whether it's perform until one should or should not exist. We believe in the L2 vision, and as a result, we're also developing L2 support for ref and we're dumbing out the core SDK that Matt will talk about in the next talk. But basically we're supporting op stack right now and we're also seeing very exciting results there. Thirdly, we have extensibility, where again, with core SDK and with execution extensions, we're able to modify the node. So let me start going deeper into these, and then the talks will actually go really deep. Our goal is that basically every piece of crypto infra uses rest for high performance stability and extensibility.
00:22:19.678 - 00:22:42.184, Speaker A: And we hope that that's why we're calling it core SDK. We hope that Reth is like this core library that people use to build software and stability is for Ethereum mainnet. We released REt 1.0 a few months ago. It required a long security testing process. We run an audit with Sigma prime. They allocated a lot of engineers on it, and we're really thankful for them, but also for stability.
00:22:42.184 - 00:23:40.312, Speaker A: It's not about bringing on ref 1.0, it's also about being vocal in the core development process. So we hope to contribute to the core development process for the stability of Ethereum with input on which EIP should go in the next hard forks, and to weigh in on that process in a productive way for performance. We coined the term Giga gas earlier in the year as a reasonable benchmark, something which doll aspire towards. And we'll hear talks about that throughout the day where a by supporting Opstack, we're able to get a L2 network that actually has support for fault proofs, that can support decentralized sequencing, that can execute the L2 roadmap. And on the other hand, we have the Gigagas vision, which involves a lot of optimizations that we're planning to do on the client, of course all open source for the community benefit. And hopefully what we hope to do is that we can commoditize performance so we never need to talk about the marginal DP's or gas per second ever again.
00:23:40.312 - 00:24:16.626, Speaker A: And we can go build some useful things on extensibility. Reth is not just a node, it's an SDK. So you can use RET, asterisk or the specific packages that you want, and you can build a bunch of these things that you see on the right. People have been doing a lot of these things. Again, I don't want to take time from other people's talks, so stay throughout the day to see what people are doing with it. Execution extensions are the ETL moment almost for Ethereum nodes. It basically says that after every Ethereum block, do something else.
00:24:16.626 - 00:24:46.900, Speaker A: Now this is a very common pattern. You see it in MeV bots, you see it in indexers, you see it in ZK rollups, you see it in everyone that uses the ETh subscribe method. But generally people lack performance in all of these. Whereas execution extensions, they let you co locate off chain services on top of your node. And it's very exciting because you can build an indexer execution extension which shadow we'll talk about today. You can build a ZK roll up execution extension, which I guess it's a mix of the Clabi and Uma. Talk later today.
00:24:46.900 - 00:25:26.970, Speaker A: And you also build an Meve execs that gives you extra information and tightly integrates your mav bot in the node. We have a blog post on that, and Alexi from our team will talk about it soon. So all right, these are all the raw ingredients, but surely we are not building just libraries. There is some first party thing here. So we announced earlier in the year restalphanet, and the idea behind RestalPhanet is basically owning our fate and having a clear feedback loop on all of these things that we want to ship. I think if you outsource building your core parts of your ecosystem to others, you're going to fail miserably. So it's very important that we're able to develop a first party application here.
00:25:26.970 - 00:25:51.974, Speaker A: So we thought, all right, since we're building a chain SDK that hopes to be better than Cosmos or substrate SDK. Well, what could we do? Let's build a roll up. But surely we're not ready for doing anything on Mainnet. So all right, let's build a testnet roll up. And what should the Testnet roll up do? The things that we're the best at. So it should a do high performance. And we hope that REt Alphanet is the first roll up that breaks through the Gigas barrier.
00:25:51.974 - 00:26:41.360, Speaker A: And two, we want to facilitate experimentation on the node side with custom eaps, which I'll talk about in one moment. Execution extension we want to roll out on ret Alphanet and also we want to just accelerate the L2 roadmap. So we hope that ref Alpha net is also like a good carrot to go after the stage two roadmap, which involves multiple for proofs ZK proofs on the roll up. The initial release goals of Alphanet is to basically be prag the next Ethereum hard fork. But there's a L2, plus the SeC P 256 r1 curve, which is the curve that you use in the Passkey signers. So we wanted to have 1 second block time. We actually have merged some exciting performance improvements in RET recently which allow us to achieve that.
00:26:41.360 - 00:27:17.698, Speaker A: And we want to launch it initially with 30 mega gas. But hopefully we can ramp it up as we roll out optimization to one gigas. It's going to be Prague compatible, which means four eips that Oliver is going to talk about us about later. And most importantly, it's integrated with the entire stack. So foundry alloy and VM all support all of these eaps. So right now with our tools you can deploy eofden code and test it on an Alphanet version running locally. You can deploy a BLS signature verification code drive that does aggregate BLS signature verification and you can do that.
00:27:17.698 - 00:28:01.724, Speaker A: We'll share later in the day some links on how you can try this out. You can also test out 7702, which is the most exciting thing with regards to account obstruction. And yeah, like these are all integrated in the stack, which really showcases the power of the full stack deployment. Finally, we want to launch Alphanet. Alphanet stands for Alpha as an edge, but also Alpha as an alpha software, because we're really good at just doing frequent releases. So what we really want to do here is see if we can do something which frequently restarts. So can we do a devnet that basically every six weeks is in a tight sprint and launches a bunch of features from a list of features that we brainstormed.
00:28:01.724 - 00:28:32.662, Speaker A: So if people have ideas like please come to us, we're happy to deploy them. Some ideas that I want to highlight are one ZK passport for doing KYC without like any other hardware fhe precompiles for private, for private tokens. We really like the JIT revmc work that we did early in the year, and we want to deploy it. And finally, we just care a lot about the devx and UX around payments. So anything that makes that better, it's like a core goal of ours. So I think that's it. We have a lot to do today.
00:28:32.662 - 00:29:38.790, Speaker A: Let's build, let's push the Ethereum frontier forward, and we'll leave it up to Matt and Dan from our team for the next talk and have maybe a couple minutes for Q and A. Thank you. Okay, cool then thank you all. And now we'll get on. Basically everyone from the team will start doing talks on each of the things that we talked about. Good morning, everyone. I'm Matt and this is Dan.
00:29:38.790 - 00:31:31.550, Speaker A: Hello. We will talk a bit about ref SDK, the current state of it, and what we have in mind for the upcoming months, and what features we would like to implement and support. Why are we doing this in the chat room? We get a lot of questions that are when do we get support for chain x? When is this supported? Can I modify this component? Can I only use the networking stack, for example? And some of those are already possible, like most of our components are already modular. Especially networking stuff is useful on its own if you want to do some weird mev stuff. But all of this is still tied to the Ethereum mainnet, and we realized that there is demand for like an EVM centric node SDK. Because EVM is widely used, developers want to develop on the EVM and we want to provide the required building blocks so you can innovate on top of the EVM, essentially without forking the node, and then go through the troubles of rebasing it, maintaining a fork, keeping up with l one development. And ideally this should just be some kind of plug and play of supported modules, crates, and you put them together as you like, make some modifications and experiment with new features.
00:31:31.550 - 00:33:00.358, Speaker A: But if we want to come up with an SDK, we need to support a node from scratch. And there are a lot of things in a node, lots of components. There is the entire database layer where you store the state of all accounts, historical states, big one, are chain specific types. This is probably the hardest one, because every network or every roll up improvement proposal kind of requires either a new transaction type sorry, or some modifications to existing ones on some weird other transaction types that are not even signed. And then also on the EVM layer. Ideally you want to support something like custom pre compiles, custom logic eventually also ethereum object formats which Dan will talk about later a bit. And maybe your node should not use the doesn't want to use the engine API that is currently used on optimism and mainnet.
00:33:00.358 - 00:34:39.350, Speaker A: Maybe something entirely different, which is perhaps just one request that advances the chain. A big component of a node is also RPC and especially RPC issues are very annoying and it would be nice to have some very well maintained RPC crates or library where everything is already implemented, be it gas estimation, trace processing, things like that. And also p two, p and t xpool. Those are the biggest components that composer node. And it would be really nice if a user could just take some well maintained library, make some, introduce some new features and then compose them to their custom chain. Why I think this should work is because if we look at various EVM based chains, they are very similar, but there are lots of nuances. OpGAF maintains a gIF, a div and if you look at the numbers then the diff is only like 5000 lines of code, but these diffs affect the entire node.
00:34:39.350 - 00:36:03.778, Speaker A: Basically on the execution side you have a new transaction type, for example different, slightly different engine API, different RPC types, but otherwise it's fairly similar but different. So there are very very few things that are exactly the same, but all of them are very similar. So what we currently support is ethereum mainnet, testnets of course, and DoP stack because close enough to ethereum l one, we made some modifications to the engine API because on optimism it's slightly different. We made some modifications to the EVM so it can handle optimism, specific execution logic and custom types. The current drawback is that this requires a feature flag at the moment, so we don't have abstract transaction types. And ideally we want to get to a place where this is no longer the case. So you could run Opstack and Mainnet in the same binary, even in the same process.
00:36:03.778 - 00:37:11.290, Speaker A: Yeah, and what is currently supported on the SDK side of things is that you can introduce custom commands to the existing CLI extenders with new services, introduce new RPC endpoints, and also execution extension that Alexei will talk about in a bit. Cool. Yeah, there are more more talks about what is currently being built on top of rev, and I'm looking forward to the talks about Shadow Ref, the rbuilder and SP one ref and Dan will now talk about two bots and actual ref SDK. Cool. So yeah, I'm going to be talking about what we want people to be able to build in the future. So you could build a lot of different things with the rest of Reth SDK. It doesn't have to be a chain.
00:37:11.290 - 00:38:08.080, Speaker A: You can build whatever you want. Some examples up here are what we have taken a look at seeing what are the requirements for the SDK? How would you build it? We mentioned off breadth, which fits in optimistic roll ups, but beyond what you can already do, we've gotten a lot of requests for various things people would like to build. One example is transaction types. For example, the rip roll up improvement proposal on native account abstraction requires a entirely new transaction type. So it'd be great to natively support this in the ref SDK header and block types. This is pretty common actually. People will add a field, they will change a field.
00:38:08.080 - 00:38:41.220, Speaker A: So we of course want to support that. Custom consensus would be very interesting. I mean, optimism already modifies the engine API. You should be able to modify it too. New execution environments. I'll talk about that later when it comes to EOF and how that kind of enables adding very, very crazy modifications to your chains or applications execution environment. But there are a lot of very interesting things you can do there.
00:38:41.220 - 00:39:43.340, Speaker A: Finally, I'm going to talk about state commitment, which is right now the Ethereum mainnet uses Merkel Patricia's tree, but you could use other things. Regular binary tree, you could use VRKL, you could use something that has cryptography that's more friendly to your ZK proof system. So it would be cool to see what people build once we support this in the SDK. Another thing that we want to really emphasize is that everything that we allow customization for will have native support for RPC, tracing, whatever, when you actually build your node with it, which is also going to be very, very easy. Here are some other goals of the rest SDK, some of which we are actively working on and are actually pretty close being done with. For example, no standard support. This is a very common request for ZK teams.
00:39:43.340 - 00:40:33.560, Speaker A: They want to be able to run reth code in the ZKVM, which is more restrictive than a regular laptop, for example, fully modular crates. People should be able to use their stuff in a standalone component. So if you just want to run the p two p layer, you should be able to do that. If you just want to have like an RPC layer and then proxy it somewhere else, you should be able to do that with the SDK. Finally, you should be able to customize everything when it comes to execution. So if you want to do something like shadow is doing, where you run stuff kind of in between a normal transaction that should be supported. So we'll make all this very easy to configure.
00:40:33.560 - 00:41:16.380, Speaker A: So custom types are very, very interesting. I'm really looking forward to what people will build with them. But yeah, here are sort of some of the examples of what you might build. We did mention that Alphanet will have BLS and SACP 256 r one support, but right now it just has precompiles. You could also imagine being able to submit a transaction directly with that cryptography. So if you just want to sign a transaction with your passkey, you wouldn't require a 4337 wallet, for example. You could just sign transactions just like you would a normal Eoa.
00:41:16.380 - 00:42:09.140, Speaker A: And so that is at least one compelling use case for custom types of like a custom transaction type. Usually if you're modifying this in op geth, it would require you to go in, add a new transaction type and change a bunch of like switch statements that switch on the transaction type and it becomes very, very invasive. Additionally, if you were to try this with Reth right now, if you were to fork it, this would become very frustrating. Additionally, header and block fields. One example is millisecond precision block timestamps. Some chains run at lower than one block second block time, so you need more precise timestamps. Consensus is also pretty interesting.
00:42:09.140 - 00:43:00.830, Speaker A: You can build ret anvil with it. If you've ever used anvil in foundry, it'd be nice to be able to use all of the things you can use with ref. And BCI is also very, very interesting. You could do some cosmos ret type stuff. And finally, this is partially enabled by the SDK and partially enabled by Eofdemen. For a quick recap on EOF, I know Oliver will talk about this later, is that you can have custom byte code. You can basically tell it, I have this new bytecode format, it has this version, and it will sort of switch execution modes and do something different than the regular evm interpreter.
00:43:00.830 - 00:43:35.720, Speaker A: So what that would enable you to do is add 55 reals, which Leo alt built, which is very, very cool. It's a new execution environment. Check it out on GitHub. You could do just Risc V, or you could have an l two with just like x 86 native code or something. Just ideas. But this would be very interesting. I want to see people experiment with it.
00:43:35.720 - 00:44:21.800, Speaker A: Custom system calls and system transactions. This is pretty common actually, in roll ups. The new Ethereum forks are also doing it. You can basically have automatic transactions happen at the beginning or the end of every block. If you need your chain or validator to do something every block, this can be very useful. Finally, state commitment. I mentioned this before, but I think it would be really cool to see people experiment with a custom state commitment and sort of if anyone is experimenting on it, we would love to know what you're building, what you need from the SDK.
00:44:21.800 - 00:45:46.650, Speaker A: But if right now Ethereum uses mercia tree and you need, you might want to have smaller proofs, or you might want to just experiment with the width of the tree to trade off IO or compute custom hash functions. If you're running a ZK roll up or something, Virka would be very cool. Or you could just get rid of it and not have a state commitment, which would be also kind of cool. And the final thing I want to talk about is just, or really ask people is what would you want to build? If you could modify a chain, or if you are building for a chain that is kind of like modified Ethereum, or even wildly different from Ethereum, how would you build your application in rust, or how would you like to build it? The rest SDK is not limited to just building chains. It's also for whatever application that you would want to build. If you're building on Polygon, even then, it'd be interesting to see what you need from the SDK. So I think people should think about what they want to change in ethereum and let us know what you want to do, and we will build the tools that are required.
00:45:46.650 - 00:46:25.320, Speaker A: I think that's about it. All right, thank you, Matt and Dan. So Matt was actually sick last night and he still did the talk, so extra kudos to him. So we have some time for Q and A. Make sure it is a question, not a statement, not anything other than one question. It can be a spicy question, but it has to be a question. So Tony here will pass around the mic and make sure to ask one question.
00:46:25.320 - 00:47:21.540, Speaker A: Thanks for the talk, guys. You mentioned on the previous slide the idea of avoiding merkelization or the Merkel state commit entirely. Can you speak to what you're alluding to there? It's kind of interesting, really. It's just that like, I mean, if you like, the state commitment is required for mainly like clients and stateless clients, which are applications that live chains want. But if you don't want that, then you could get rid of the state commitment, or have it be something that's more efficient, like just hash the state dif, for example. So yeah, it could be. I mean, if you care about performance and that's it, and you don't want like clients, then I could see a good case for removing the state commitment.
00:47:21.540 - 00:48:11.330, Speaker A: Hey, thanks. Great talk. I'm curious how much of this exists versus future vision? I didn't quite get a feel for where this project is at, I guess. And how can people help beyond telling you what kind of modifications they'd like to make? So basically everything that I mentioned in this slide are things that are not currently supported but we would like to support in the future. And then I think Matt can expand on what you can currently do. Yeah, we are actively working on it, but it will still take some time. But we kicked it off.
00:48:11.330 - 00:49:28.122, Speaker A: But the thing that blocks all these features are essentially abstractions over all those chain specific types, be it block header or transaction. Once we have that, this will unlock a ton of features that Dan went over to give some examples of what you can currently do. Like right now, you can add new CLI arguments, you can add new RPC endpoints. There are various things you can do if you're running P two P as a standalone service, but we'd like for all of these things to be fully integrated. Do you think it's ready right now to run some private network with a consensus algorithm like QBFT, or what the lift would be for that? So right now you could hack it together. Bye. Calling into the engine API, for example, when a new block is finalized, you can just, there's basically three fields in the fork choice updated endpoint in the engine API.
00:49:28.122 - 00:50:42.846, Speaker A: You would set those all to the same thing. I think this is how some BFT projects work with Ethereum clients right now, but we are currently working on a refactor to how we handle consensus messages that would allow you to really put whatever message type you would want in there. So anything related to BFT, you could have your own custom messages depending on what the consensus protocol does. That's not ready quite yet, but you could hack something together for now and then stay tuned for the full support. Cool, thank you. Is a pipeline, a pipeline architecture supported on your roadmap, meaning like interleaving, like transaction building, execution, state commitment, storage? Yeah. Perhaps a bit more context here is that pipeline architecture takes care of historical syncing.
00:50:42.846 - 00:52:32.926, Speaker A: It downloads stuff from the network, executes, verifies hashes, and this is just one component of a node, so you could already modify it. And essentially it's just one component, which is the backfill or downloading part, and you can also switch it out to something else if you want to use something different. Say you were looking to build a sequencer that had custom logic or rules. Where in the SDK stack does that slot in? In an ideal world, I think this belongs to the payload building component, which is also used by the Opstack payload builder. If it's a sequencer, then it's supposed to include transactions from the block. And the way the payload building component is written right now is that it lets you implement anything that eventually returns a block. So as long as it can handle the NGen message, the payload builder attributes and returns a block when the consensus layer requested block, you could introduce anything that supports that and a small follow up.
00:52:32.926 - 00:54:02.990, Speaker A: How does that slot in? With decentralized sequencing and the sort of broader consensus around it, out of scope building, like as mentioned, you can plug anything in there. And if it just delegates the payload attributes to something else and then eventually retrieves it over the network and returns it to the consensus layer, this is also possible. Are there any plans to reduce the IOP's load? The Reth requires, like switching to an optional tree DB. For example, if I want to sync mainnet off a USB three drive or an underpowered Kubernetes cluster, I think that's probably, that's not super related to SDK. But we, there aren't any current plans to do that. But if you have a list of requirements or have tried it out on something that's bad hardware, then we're happy to talk about it. And I see if there's a way that you could tune your node to maybe make it work.
00:54:02.990 - 00:55:03.836, Speaker A: Yeah, hi everyone, my name is Alexi. I'll be talking about execution extensions first. Wanted to ask maybe raise your hand if you heard of execution extensions. Now, if you've built an execution extension, you played with it. Cool. So let's start with the motivation. Why do we want to do this thing? The goal is to build off chain services that benefit from real time on chain data.
00:55:03.836 - 00:55:43.070, Speaker A: And if you think about it, it's basically everything that's not on chain. This is roll ups, this is indexers, this is avss. Sometimes this is MeV bots. I was going to remove this from the slide I didn't have. Basically you derive the data that you need from new transactions, new headers, and you build something on top of it. How people usually do it. If you build an indexer, you want new blocks and people usually subscribe to WebSocket, there is a handy RPC called ETH subscribe.
00:55:43.070 - 00:56:33.520, Speaker A: It's good, it's standardized, everyone has the same implementation. So whether you are geth, neithermind, Reth, Eragon, whatever, you will get the same response. This is good. The downside of this approach is that you have poor performance due to serialization and deserialization of JSON, which is basically not the best format for efficient data transfer. Also, there is not enough data that's passed on on this channel. One example is the reorgs. So for example, if you have a reorg on the chain, you want to be able to receive the blocks that were reorged from the chain and also get new blocks that were committed to the chain.
00:56:33.520 - 00:57:20.090, Speaker A: Eth subscribed if subscribe doesn't allow you to do this. And also you need to maintain some ad hoc solutions with Python or JavaScript or rust code which is not related to the node code. It's like live separately. So it's a separate project that you have. And here is a small example of JSON RPC call to Eth subscribe what if I want more performance? Okay, you can fork the node. This is to the times of MeV Geth and all these forks. When you have Geth that everyone knows and love, and you fork it, add your own modification to it and run it as a new piece of software.
00:57:20.090 - 00:58:18.670, Speaker A: The problem with such approach is that you accept that you need to resolve conflicts from time to time, because the code bases are evolving all the time. And here's an example of our work. In one month you will basically need to rebase on top of almost 500 pull requests. Not fun. You can also accept that you will just stay behind on new features and optimizations, which is also not cool because you want to benefit from other developers working on the client itself, and which is also an important thing that you need to actually know where to look in the node code to be able to modify it. Reth is different from Geth, Geth is different from nethermind, all different languages and all different structure of the codebase. So you need to know where to plug into your indexer, your rollup, or your AV's, for example.
00:58:18.670 - 00:59:10.810, Speaker A: So what addition do we think is an ideal? It was supposed to say our solution, we think that you can extend the nodes and plug to off chain data using the rest SDK and basically avoid the overheads on JSON and any serialization or any other data format. You can avoid forking because you use as a library. That method was talking about previously which is also we think is important. You are able to differentiate between chain commits and reorgs. So when there is a reorg, you receive a separate enum variant saying the chain reorg. This is the old chain, this is the new chain. I'll talk about it later in detail.
00:59:10.810 - 01:00:17.854, Speaker A: And also execution extensions, or x axis how we call them, is a well defined framework that allows component reuse. For example, you have the whole rest core SDK for you, so you can use anything from it, EVM executor or whatever. Yeah, so enter execution extensions. On the right there is an example of a real execution extension that you can build 50 lines of code or so I will go through it in a short manner. So basically you get access to all node components via the context that passed as an argument. Then you consume the Reorg aware stream of new notifications, and each notification is basically a chain commit or chain reorg, or also chain revert if it was just unwinded in the pipeline. For example, you do not have any serialization deserialization, HTTP websocket data transfer.
01:00:17.854 - 01:00:59.110, Speaker A: You have the same shared memory that rest uses. So important thing about xxs is that you plug them into the same binary as Reth. You compile it in one project and then you run it. So if Reth already committed a chain and it has in memory, there is no need to copy it again for xx to use because it's read only for every xx. So we can just pass it to xxs and they can do whatever they want with it. Maybe do a clone, maybe serialize, but it's up to the xx. And as I said, it's compiled in the same binary, so there is no overheads on any data transfer, which is also nice.
01:00:59.110 - 01:01:52.334, Speaker A: Let's talk about what is an xx in detail. Basically it's just a feature. We made it so that you can write an async function that accepts the context. It returns a result with an empty value and never resolves. What you should do in your xx is that you consume the stream of notifications you mentioned, different variants, commits, reorg revert, and then you send an event back to the node saying hey, I processed up to this height, up to this block number. Why is it important? Is because we have pruning. So if you think about the full node, it only has like what, 10,000 blocks in the past from the chain tip.
01:01:52.334 - 01:02:46.000, Speaker A: So if you have a slower x axis and you are lagging behind, you need to say up to what number of blocks in the past you processed. So we don't print the data that you still need. And also it's up to you whether you want to query the transaction pool, the third party API, some other blockchains, whatever. There is only two requirements. You need to consume the notifications to drain the stream and you need to send an event back to the node. How do you install an xx? You use the corer SDK node builder and you can install however many x axis you want. They will all be running in the same binary pulled by the manager.
01:02:46.000 - 01:03:38.028, Speaker A: And yeah, they can even communicate with each other. If you want, you can have some channel for passing the information from one xx to another. Yeah, the manager, as I said, they're managed by the manager. And the manager is a thing that's responsible for sending notifications to xaccess from the node. So the lifecycle is the following. You get a new payload from the consensus client, you execute, you commit to your database of main l one node and then you have a chain which is a structure that contains state divs, try updates, blocks, headers, and you send this chain structure to x axis. Xxmanager also controls backpressure.
01:03:38.028 - 01:04:22.826, Speaker A: So there's a question, what if I do not consume the stream of notifications? Basically the node will stall and say you in a warning lock that hey, your xx is wrong and it's an opinionated thing to do. But we think it's right because when you write an xx in your binary you are supposed to use it. So if it doesn't work we need to let you know about it. It also handles errors. So if xx crashes, the whole node exits. Because again, we think that if you install an xx and it doesn't work, the whole process should abort. It also has some monitoring.
01:04:22.826 - 01:05:03.440, Speaker A: For example, when you have another notification coming to Nxx we emit a notification, sorry, a metric to Prometheus. And you can see in Grafana how many notifications you received, how many events you sent for every xx. Let's talk about the xx context and what's inside it. So as I said, this structure is passed inside your xx. Every xx receives context. And the main thing here is the stream for new notifications that you need to consume. I'm not sure how to do it.
01:05:03.440 - 01:05:56.480, Speaker A: Yeah, it's right here. Notifications receiver execs notification, you consume this thing. It also has a bunch of other different components that are hidden in this generic components node. These components are transaction pool, EVM executor, database provider for the l one node and you can use all of it inside your x ax. We also give access to the chain head that we started with some config and a sender for the events back to the node. But basically we think that this is all you need from the node itself, from the host node, and everything else is up to you to figure out if you want to extend it more. So on previous slide there was an exact notification receiver and this is the notification itself.
01:05:56.480 - 01:07:10.180, Speaker A: There is three variants in this enum, comed, reorgan and revert commit. A new chain was committed reorg, no chain was reorged and we send both old and new chain which is basically the same type, the same struct. But the old chain contains all the state divs that happened that were reverted and the new chain contains all state divs that are committed. So what you can do is that for example you are building an indexer and you want to reverse the changes that were reworked and you actually have the state divs for accounts and for storage slots that you can just revert from your postgres or whatever. Yeah, the chain itself contains blocks. Obviously there are headers and transactions inside blocks, but also it contains the outcome of the execution because chain is passed to the xx when it was already executed by the main node. What you have in the outcome is the state divs, the receipts and the requests.
01:07:10.180 - 01:08:00.432, Speaker A: Requests are the thing from new hard fork that allows you to communicate with the CL. They are derived from the execution, so we also pass them and there is also try updates. They can be useful if you want to build something on the Merkel Patricia try you receive basically all nodes that were changed in the try but not the full try. So you can build your own index of the try in your own format if you need. So what do we have implemented so far? We have the lifecycle management via the manager. As I said, we have the front fill which is basically when your node just started from scratch. You need to sync to the tip.
01:08:00.432 - 01:08:50.159, Speaker A: You use the pipeline as was said before and during the pipeline execution you receive the committed blocks to the database into your xx they sent from the execution stage. So when you actually do the execution you have all the state divs received requests and you send them. And we also have the front field during the live sync. So when you node is up to the tip and it follows the cl, we send a new notification with every new block. So during the live sync then the notification contains just one block backfill. Imagine you have an indexer and you are indexing some fields of transactions. Now you want to index one more field, but you have 20 million blocks in the past on mainnet.
01:08:50.159 - 01:09:42.030, Speaker A: How do you re index it? You do the backfill. Backfill is a thing that we provide. It's an abstraction over the EVM executor that allows you to say, hey, I want to execute from block zero to tip and send the results to my xx. What will happen is that the node itself will continue with livesync and following the consensus client, but the xx will backfill the data from Genesis. This can also be exposed via RPC or CLI. So for example, I will show the example slide later. You can have an RPC that's called backfill start that accepts a range of blocks and without a node restart it starts a backfill for just your execs.
01:09:42.030 - 01:10:16.028, Speaker A: We also have testing utilities because you need to be able to mock the components of your nodes without actually running it. So you need to run unit tests, you need to run end to end tests. And we have some utils for this. Examples. Oh my God, where is the picture? Okay, so we have a repo for examples. We implemented different source of examples from the minimal example, which is basically the one that I showed you before. Log every new notification.
01:10:16.028 - 01:11:01.100, Speaker A: And we have more sophisticated ones such as backfill via RPC or clique querying the blobs from the consensus client or third party. Like Blobscan. It can be useful when for example you are roll up and you want to query a blob for some historical block. But blobs are expired so you don't have them on the Cl anymore. And you need to have another source of data for this. There is a Diskv five example. A cool thing that we're excited about is that you can connect x axis between each other via custom disk v five topics so they can communicate and utilize the same network that ETH has.
01:11:01.100 - 01:12:00.122, Speaker A: We have a toy example of rollup, which is basically an sqlite rollup that gets the blocks from the Ethereum, Mainnet or Haleski. In our example it's Haleski. It does the execution of the batch that was submitted to the Mainnet, to the l one, and then it commits the execution results states try to escalate database also like 1000 or 2000 lines of code. Not a lot for a working roll up, even though it's on escalate. What future work? We still have so x axis work today, people building it. There will be shadow rest execution extension as we said before, but we still have some work to do. For example, you may not need to have any other functionality except acting on new notification.
01:12:00.122 - 01:13:10.340, Speaker A: What if we have a tray that has on younotification method that actually calls every time you receive a new notification? It's simpler xx because you will not be able to access another data sources, but it's also easier if you just need the notification from the node. We want to build a more comprehensive standard library for Xaccis. Some of the things are blob utils for EIP 4844. As I said, we already have blob querying, but for example, you may want to have something else for this backfill extensions for RPC and CLI as I said, we have backfill as an abstraction, but you need to build the RPC and CLI by yourself. So we can also provide the extension, sorry, we can also provide the abstraction for the RPC and CLI that does the backfill for you. And the last one is disk V five. We also want to provide you a way to expose a custom disk v five topic to communicate with x axis without diving too deep into DisKV five and how it works.
01:13:10.340 - 01:14:01.270, Speaker A: Another cool thing that we excite about is dynamic loading of x axis. So as I said before, xx's are compiled in the same binary, so you cannot actually have a running rest node and somehow install an xx into it. There is a cool idea with dynamic libraries like so dilip DlL on different platforms that you can install into an already running binary. There is a project, sorry, not project. There is part of the Solana client called Gazer. It's basically a plugin system that allows you to output the data from the chain to Kafka or whatever data source or data warehouse, and it's done without any recompilation, which is quite cool. And we think we can do something similar.
01:14:01.270 - 01:14:48.750, Speaker A: I have an example with WASM. It works in a similar way. You just call an RPC with WASM bytecode and it starts running along your main node. And the last thing that we want to improve is observability. As I said, we have some basic metrics for x axis, like notifications sent, events received, but we want to have more insight into ix access stalling, are they falling behind the main chain, etcetera. So a couple ideas what you can build today on this hackathon. On this small hackathon you can build an AV's that's utilizing the disk v five or IRO.
01:14:48.750 - 01:15:32.746, Speaker A: Also a cool project for peer to peer connectivity. And basically it's a ret node with an xx that communicates with the same piece of software over this network. There is a toy idea, but it's a cool hackathon project for a game roll up. So there is mud, but you can also do one with baby which is the game engine in rust. So like imagine you commit some change for your game on chain and then in your xx you actually do this action in your game engine. You will need slower than 1 second block time, but it's not a problem. You can also have stealth addresses.
01:15:32.746 - 01:16:05.016, Speaker A: We also have this as an example, but it's not finished yet. Stealth addresses is an ERC that was recently approved as far as I know that allows you to. I don't remember what it does, but check it out, it's cool. And yeah, this QR code is the examples repo that you should check out because it has a lot of examples and open pull requests with more examples. That's I believe it. Yeah. Thank you.
01:16:05.016 - 01:16:19.660, Speaker A: Any questions? Hello.
01:16:20.320 - 01:16:21.150, Speaker B: Hello.
01:16:21.320 - 01:17:19.278, Speaker A: Hi. If you wanted to use an xx, would your node have to be fully synced or could you just run it and follow the tip? You can run an xx without a fully synced node. It will get the notifications from the pipeline sync. So you can start a fresh node without any data in the database. And when you do the execution for the historical data, Uxx will receive these changes itself. What networks can be run with xx? Like for example, can I run it against arbitrum or what are the requirements? So the way you think about it is that you have ret node as the guys was talking about on the previous talk, and you have for example Opseco base. That ret node can run everything that reth node can run.
01:17:19.278 - 01:18:00.130, Speaker A: Xxs can be plugged into. So we don't have support for arbitram yet. So no, for now you cannot do this. Okay, what should be done in order to run it in arbitram? Is it because of different network stack or is it more deeper? I'm not sure. I believe it's even deeper than opstack changes. So you will need to have lots of custom changes for your node to be able to process arbitrum blocks and peer with arbitrum nodes and all this stuff. So I think it's unrelated to x axis because xss are plugged into an already functioning node.
01:18:00.130 - 01:19:17.340, Speaker A: What's the thinking around redundancy, especially client redundancy, if you've got an indexer or something that would leverage an XXD. And with just an RPC endpoint it's pretty trivial to fall back to using some other client if there's an issue or. Yeah, what's the thinking around that? If you've got a co located xx, is there an adapter or something in the works that could wrap an RPC that you could use a fallback? Not right now, because we are thinking about it as say if you are either scan, you have some indexer that's built in c hash in the case and Reth is basically a basic infrastructure for this indexer. I think it's possible to build a wrapper around RPC so you have an exact similar functionality. But I'm not sure it will make sense if you still have the overhead for JSON serialization, decentralization, the networking. But maybe the code reuse may be a good thing and you can write your xx in rust and plug it into, for example get RPC. We didn't explore it yet, but that may be a good idea.
01:19:17.340 - 01:19:53.890, Speaker A: Awesome. Would it require a rather bigger machine to run RS xss to do indexing today? Let's say I'm building a dapp for indexing NFT contract. I only would be subscribing to events related to my contract. I'm interested in violating RPC. It seems that if I want to use xx I would need a bigger machine to sync the whole state. Is it a proper use case or RS actually can be very very slim in this case. Good question.
01:19:53.890 - 01:20:40.620, Speaker A: So I think you can use the full node for this. It's a bit smaller than the archive node, it's 1. You will get the changes for your NFT contract from execution of new blocks, but it will still be not a lightweight node. You're right. I think in this case the subscription to just the events of your NFT contracts. Maybe a better idea to use the RPC, not the xx because xxs assume that you have a fully synced rethnode. There is a future where you have reth node running somewhere in the cloud and you can plug into your xx into it via the dynamic library or WaSM.
01:20:40.620 - 01:21:28.160, Speaker A: But it's something that we are not building right now and it's a third party service I think should be yeah, I'm here Alexei, you see me? I'm here. Yeah, yeah, thanks Alexei. Great presentation. I think it's super powerful and it seems to really open a lot of new gates to be able to interact with the chain off chain. But I'm curious about. I feel the intuition and the potential of what could be open. But I'm curious like you who have worked on it, do you have like a few examples or do you have a vision for it in the future, what would be like the big unlocks that execs could bring to the blockchain or to ret in general? Right.
01:21:28.160 - 01:22:18.534, Speaker A: I think it will make building indexers easier and more performance. So as I said, you are kind of locked into the RPC subscriptions in lots of situations. It will allow you to query the database directly, get the blocks right from memory. So it's not an unlock in new use case. I think it's a performance unlock and an unlock for cost saving, I would say. Yeah, I think stuff like shadow logs can be a good use case. You can build it on a regular node with re execution of each block.
01:22:18.534 - 01:23:11.514, Speaker A: But what you will be able to do in Reth is that you are able to override the executor that main node uses and you are able to receive the block that was executed just once with all the shadow locks emitted or all the traces. So it saves you, I think, on time that you need to process the blocks for shadow locks. Again, not a new use case. You can do it with RPC. I think it's mostly about performance and the convenience. Just to offer an additional point on this is that by running execs you can run ten roll ups on top of one node without having to run 40 services. So why I'm really excited for it is for people to just run mini roll ups on top of their nodes without having to worry about Kubernetes cluster orchestrating everything.
01:23:11.514 - 01:24:06.520, Speaker A: So it's a nice way to simplify the infra I had a question earlier. I saw you had a a node exposed into your executor context. Is that node synchronized with your context? For example, if there's a reorg that you haven't received yet, would that node show the pre reorg state or the post Reorg state? Good question. Yeah, it will show the latest state that you have. So when you query the database for the latest state, it will show you the actual latest state and not the one that you're currently working on. From the notifications, you are able to get the historical state for the archive nodes via the same nodes provider. But yes, the latest states of transaction pool database payload builder will be actually the tip and not the one that you are processing.
01:24:06.520 - 01:25:11.510, Speaker A: Hi, I was wondering how the xx backfill interacts with the state pruning that you mentioned that it communicates with the full node about. Yeah, so what backfill does is that it actually uses the blocks that you have in your database for re execution and sending new outputs to your execs. And we do not prune transactions and headers at all, because transactions and headers are needed for the health of peer to peer network to be able to share it with other clients. So even on the full note, you are able to send, you are able to do the backfill from the genesis. All right, one more. Okay, let's do one more. Keep it short.
01:25:11.510 - 01:25:52.966, Speaker A: In the future, do you plan on supporting out of the box support for things like parquet files or column or databases like DuckDB for storing state? Is it about x axis or the main node? Yeah, the main node. Yeah. We have some thoughts, ideas what to do with the database, maybe to split it into more databases. We currently have static files format, and it's basically a columnar format for storing the append only data like transactions and headers. So it's a custom rolled format which is very similar to parque, but more efficient for point queries. Nice. Thank you.
01:25:52.966 - 01:26:47.882, Speaker A: Okay, given this was short, we have one last, last question. Thank you so much. Quick question. Is it possible to build a op stack with some precompile with Xxdev of res Cornex? Yeah, I mean, is it a pre compile? I think precompiles sync in the sense that you have EVM and you need to get the result from a precompile immediately and not after the block execution. But Conxx is a nice idea that the guys will talk about later, I think. But yeah, I think for precompiles in the EVM on opstack, you need to modify the executor and the EVM itself and not build it as an xx. Although you can have an async precompile that says start a request and maybe then fulfill the request, and you can build the fulfillment part of the request into the execs.
01:26:47.882 - 01:27:25.502, Speaker A: So you start the request for disk reads, you read the disk in the xx, and then you receive the result back in the fulfill part. All right, give it up for Alexi. Thank you. And now we're going to talk about the Giga gas. So we have Roman and Danny walk us through a bit through how we're going to basically solve scalability, scaling, performance and all that. Give it up for Roman. And then click one, two.
01:27:25.502 - 01:27:55.318, Speaker A: Okay, this is the Giga gas talk. All right? So you'll hear us say a word, giga gas a bunch of times. Let's play a game. Like you can count it and whatever. Georges can figure out the present for you afterwards. Yeah, Giga gas. All right, what happened to all of the images? That works.
01:27:55.318 - 01:28:46.748, Speaker A: All right, so measuring chain performance obviously TPS does not represent an actual throughput of the chain, because you cannot. A single transaction does not have information about its complexity. A better metric is gas per second, for a number of reasons. You can see on the screen, I think everybody is on board with us for measuring the chain performance accurately. So where we are at now, we're currently at 100 million gas per second. Our goal is obviously, you can say it, giga gas. Right? Why? Because we want to speed up the Ethereum chain and DL two s to be able to compete with all of the other networks.
01:28:46.748 - 01:29:48.700, Speaker A: And the main bottlenecks are execution mostly in historical context, because thinking an archival node, if you look at the chart, most of the time is taken by execution. The state route, obviously we've talked about state commitment, and we will talk about state commitment a lot. The blockchain tree, this is the special abstraction in our codebase that is tracking the unfinalized blocks and database commits in hotpath. And we'll tell you later how we address that. All right, so perf, what do. And then you will talk from here. All right, I one big bottleneck in the current state of the node is that we are spending all the time in execution.
01:29:48.700 - 01:31:08.694, Speaker A: What does this mean? It means that we are no picture. Yeah, it means that we are spending a lot of time in the EVm interpreter. So how brief round down on how the EVM works is that you have some bytecode which is unstructured, a list of instructions, just raw bytes that an interpreter will load up when a transaction gets called, when a transaction gets sent. And this will step through every single instruction, execute it, evaluate it, do some bookkeeping, and then go to the next instruction or jump to somewhere else in the program. This works fine, has worked fine. Always. The problem is a lot of time is spent just bookkeeping and in the interpreter, stack manipulation, which is essentially just moving variables around to satisfy the requirements of the EVM, which is generally avoidable.
01:31:08.694 - 01:32:13.378, Speaker A: By instead of interpreting the bytecode, you compile it down to native code using an optimizer, which will essentially remove all of that overhead of the stack manipulation. So this is essentially what ReVM sees. Instead of taking a byte code and executing each instruction one by one, we first analyze it. We determine some basic structure of the program. For example, we check for static jumps so we can have a nicer control flow and some other analysis passes for more optimizations. But this is essentially what it does, is you analyze the bytecode, you emit some internal intermediate representation, which is in this case llvm. And once you optimize it.
01:32:13.378 - 01:33:14.070, Speaker A: Using LLVM, you can emit native code which can then run just normally on your cpu. The point of this is that it's a 100% replacement of the interpreter. You can essentially, the way it's implemented is you just, instead of calling the interpreter with a bytecode, you pass it onto the compiler. You can just in time compile it, or you can compile it ahead of time into an object file, which you then load at runtime. And then this just completely replaces the interpreter. So we measured this initially a few months ago when we released revency. We have great improvements up to 20 x for simple programs which are very computationally heavy, like Fibonacci in this case, but also up to two x in normal contracts, like wealth, for example.
01:33:14.070 - 01:34:37.680, Speaker A: Other ERC 20s also measure about the same. We also tried running this on a node on rest. However, the improvements weren't really that substantial, because also of all the things which Roman will talk about later, and so it might not be a very compelling use case for l one execution, but on l two, where maybe you have a lot of system contracts which run on every block, a lot of computationally heavy contracts, this could be a substantial improvement. So the EOF, which is the EVM object format, not actually ethereum, I discovered this recently. I guess it's more part of the VM, so it makes sense. But essentially this is an improvement which will be most likely included in the next artwork. This, I won't go too much into detail, this is a nice graphic, that dragon, which unfortunately could not make it today, made.
01:34:37.680 - 01:35:54.954, Speaker A: Essentially it's nice quality of life improvement for compiler developers, but also for nice performance improvement for also our use case and also the interpreter. So in general, how jumps are executed right now, which we call the legacy bytecode, compared to the EOF bytecode, which will happen. It's not live anywhere as far as I know, but essentially how jumps work is that dynamic jumps. All the jumps in the EVM bytecode are dynamic, which means it takes in a stack item and jumps the location that specified by the stack item. This is not great for static analysis tools, because you cannot determine the control flow of the program necessarily. And also it's not very performant in the compiler use case. So in revenue, because you have to generate a massive switch table over all the jump destinations, which has to be validated at runtime.
01:35:54.954 - 01:37:37.580, Speaker A: And this obviously inhibits all optimizations and makes the control flow very complicated. Another use case. So essentially what UF does is that it removes dynamic jumps, it makes all jumps static, meaning the jump destination is an offset that's encoded directly right after the instructions. So all tools analyzing the bytecode and also revmc can make use of this to have more information of the program at compile or deploy time. Another major improvement is that instead of having one big long list of instructions in the bytecode, you have code sections which essentially are their own simple functions which can call into each other and then return just as a normal program that runs on your cpu. This obviously also helps for compile time, because instead of passing one massive 100,000 lines of code to llvm, you can like split it up into multiple functions, just like, you know, just like when compiling a rust program or c program with clang, which helps a lot, helps the optimizer a lot to produce better code and also faster. And in general mostly thanks to removal of the jump desktop code, because all jumps are static, so the analysis can be done at compile time.
01:37:37.580 - 01:38:27.028, Speaker A: You have a lot less bookkeeping, a lot less instructions. I believe it was like up to 20% less code size on some popular contracts. This means that obviously compiles faster. And also this also helps the interpreter to have to be more performed because there are less instructions to execute. These are just some of the improvements that ERF brings. Won't talk about the instructions, but yeah, that's about it. So on the other side, I've talked about how ReVMC helps you achieve more performance with a single EVM.
01:38:27.028 - 01:40:13.914, Speaker A: On the other side we can execute multiple evms in parallel. So this has been in the talks for a while. For example, since a bunch of recent blockchains have been advertising this, that you can execute the EVM in parallel. The main reason this hasn't been done on EVM more recently is because there are a lot of road box to it won't go too much into detail, but essentially the main algorithm that is used and modified is called block STM. All it does is defines a set of read and write sets that are computed once executing all the transactions in parallel. And then if you have any conflicts, you have to re execute them to essentially achieve the right execution because transactions are generally thought of as sequential, but if you execute them in parallel you may get some conflicts, so you have to somehow fix them. So this has been done in DVM because also of the of the Coinbase problem, where essentially each transaction has to will send a certain value, a sent amount of eth to the block coinbase, which is a single address.
01:40:13.914 - 01:41:58.466, Speaker A: So this essentially makes all transactions depend on each other. However this has to be, yeah, this has to be handled separately as a special case which increases complexity in the whole algorithm. So not going too much into details, but there's a talk later today by the rise people which will talk about the PE VM, which is I believe mostly working EVM parallel EVM implementation using also REVM, which eventually probably make it into Reth or anyway can be used as a ref implementation of the EVM. So we've talked about EVM improvements running EVM in parallel, but one of the other half of the EVM execution is essentially spent in storage and doing I o and reading and writing to the database. So the current, this is more specific to rest, but applies to also all clients. Is that the current state the current databases have a lot of may have like some hacks or not be very optimized for the EVM use case. For example, MDBx is a general purpose database, but we used to use it for all data.
01:41:58.466 - 01:42:57.610, Speaker A: We've discovered that it's not a great use case for EVM because there's a lot of overhead for like fetching data and also there's a lot of hacks. MDbx in specific island also a big pain for us because it's written in c in one single 25k lines of code file. We have to interact with it with FFI, other generated boundings. Not a great API. And also the fact that it is Mem mapped, which has been discussed a lot recently. There's this great talk. I sure want to use mmap in your database management system, which kind of shades on it for 20 pages or something.
01:42:57.610 - 01:44:22.730, Speaker A: So yeah, so Mamp might have a lot of problems, has a lot of problems with the EVM use case where like you have a ton of data that cannot necessarily fit into memory. So that causes a lot of performance issues. Another use case for changing a database is that current implementations don't use IO uring or other types of async I o. These are future performance improvements which may look into like changing database writing our own another way, instead of replacing the entire database, we could, just as we've done with static files, is that you split the data into multiple databases, for example using a tri db only for the state, and then b three for the rest. Currently we are only using a b three MDBx for most of the data. The historical state is in static files, which has run out of performance improvement, and we might look into doing more of this. And now hand it over to Rowan.
01:44:22.730 - 01:44:49.392, Speaker A: Yeah, let me overtake the spotlight. All right. A little hint, for everybody who's been keeping track, we have like three, four gigas mentions. We'll crank it up from here. Four, four. Okay, cool. Additional bonus for a person who will take the live stream and will crop all of the gigacast mentions and do like a counter, you know, like Georges will come up with some nice present, I'm sure.
01:44:49.392 - 01:45:34.776, Speaker A: Right? And one more thing, on the parallel EVM, there is one question of how to actually execute in parallel. There was another question of how to communicate it trustlessly between your peers. And we highly recommend the blog from our teammate dragon, which is linked right here. You'll probably get the link to the slides after the presentation. And yeah, a little recap. What's keeping us from giga gas, sequester execution IO, what else? Well, interpreter. And the fourth one is state commitment.
01:45:34.776 - 01:46:39.810, Speaker A: All right. One thing that we have talked about and has been our biggest grievance is state commitment. The problem with state commitment that it is a sorted hexory try and it is very difficult to find new approaches of how to parallelize it. But we did find one recently which is actually MPT is a trial of tries. So technically what you could do is when you've gathered all of your state updates from the block, then first you can compute all of the storage routes in parallel, and only then you recompute the state route for the whole account try. And that brought us up like two, three x improvement in the stateroot computation. What is it? Yeah, this is what I just mentioned.
01:46:39.810 - 01:47:40.970, Speaker A: Another performance improvement for this is caching the intermediate nodes so when you have long in memory chains, you can preserve the intermediate nodes for the previous blocks that have not been committed to disk yet, and you can reuse them to compute the stateroom for next blocks. Some ideas, actually. Georges suggested that as you execute the block, you can stream the access list, the state access list to a stateroot computation task which preloads all of the access nodes. And then when you're done with execution, you have gathered the whole access list. Arguably it is faster. We wanted to experiment with that for a while. We have not had time yet.
01:47:40.970 - 01:48:09.904, Speaker A: And yeah, another approach is just you take the whole trie and you split the trie into sub tries and you compute like in parallel the roots for specific path in the trie. Yeah, images. They lost my meme. What happened there is my meme. Right? Hex retry is the root of all evil. I thought. No laughs in the audience.
01:48:09.904 - 01:48:44.920, Speaker A: All right. I thought really hard about this one. Yeah. Another alternative is to get rid of hex retry. I think given how often we bring up the problems that we have with MPT during these talks, you can understand how painful it is for us to interact with it. Yeah, just we mentioned already all of the pain points. Yeah.
01:48:44.920 - 01:49:48.330, Speaker A: And the fifth item that is keeping us from doing giga or potentially multiple gigs per second is the consensus engine. And this is specific for breathe. How we initially implemented the consensus engine and the initial problem was that on FCU, unfortunately update, when you actually advance the chain, we have always persisted all of the data to database and the commit added like 100, 200 millisecond additional latency that is actually unnecessary. Yeah, just quick shout out. Consensus engine revamp is a joint effort by Matt, Dan, Feda and Dai, and we'll hopefully release it in production mode really soon. It's a really great improvement. I hope people will like it and will run giga gas chains.
01:49:48.330 - 01:50:40.588, Speaker A: Another, another great improvement with the consensus engine rewrite is that we now expose a more configurable interface because consensus engine is like the main driver of the node, but the only driver that we have built in right now in ret is beacon consensus. But it doesn't have to be only that. Potentially you can swap it out for PBFT, tendermint, bft or whatever the hell you want to use. And yeah, again, they lost the numbers. Here are the numbers. On the left is the FCU latency that is currently on main without the rewrite. On the right with the consensus engine rewrite, just for you to understand.
01:50:40.588 - 01:51:31.330, Speaker A: The left one is in milliseconds, the right one is in microseconds. Yeah. Quick round of applause to the team who worked on this. This is really impressive. Yeah. And another one, like we come up with all of these ideas about performance improvements, but how do we actually experiment with them? How do we measure them? We did come up in the past with a couple of debug scripts that allow like replayer scripts that allow us rerunning certain segments of Mainnet. But this is, this like, this creates a bias towards Mainnet data and this also restricts you to Mainnet protocol.
01:51:31.330 - 01:52:21.148, Speaker A: And some of the performance improvements for your chain might not be mainnet compatible, Ethereum mainnet compatible. So yeah, now we have Alphanet, it's going to be deployed in life really soon. And we hope that with Alphanet we can experiment really fast on execution layer innovations and it will just give us a fast iteration loop. Yeah, I came up with a slogan for Alphanet. I did not run it by anybody yet, but deploy bench rinse repeat, there should be a Giga gas for it somewhere as well. Right? Thanks. Questions? Thank you, Roman and Danny.
01:52:21.148 - 01:52:36.590, Speaker A: This is a lot of work and probably the most important work because the SDK will not matter otherwise. Will start. Yeah. Thank you, guys. Super interesting work. I'm going to be this guy. I'm going to ask the same question as I did previously.
01:52:36.590 - 01:53:02.980, Speaker A: I'm very curious about what do you think the new things that this will open? Like, what are going to be some innovations that are going to be enabled by having this Giga gas. And I'm also curious about state bloats. And by the way, you say Giga gas twelve times, so you can send me like 21 million btcs and I would be okay with that. Thanks. Okay. George's will expense it. All right.
01:53:02.980 - 01:53:55.200, Speaker A: Yeah, we got a deal. Can you formulate the question a little bit more specifically? Not too broad? Yeah. Why does Giga gas matter? What is it going to enable and state load element the state load part? Just why the performance of the chain matters? First of all, it's ux. Like, you don't want to just have users sitting there and waiting for their transactions to get confirmed for forever. Second of all, the only application for blockchains that we did right now are kind of limited to financial applications. What we would be really excited to see is more gaming applications. You know, where the state has persisted to chain.
01:53:55.200 - 01:54:38.064, Speaker A: Yeah. It just, you cannot have. You cannot support, like the next billion users on a one mega gas chain. Thank you for the talk right here. Quick question on RevMC in regards to the compilation to Llvmir, does that change my debugging tool chain? Like, do I have to switch my debugger? What does that look like in terms of that support? And is there a guarantee? What guarantees are there in terms of the assembly code versus the EVM? Yeah. Right. I.
01:54:38.064 - 01:55:17.670, Speaker A: So essentially it's just a complete replacement interpreter. Do you mean debugging, like with foundry or. Yeah, we could integrate in foundry. The problem is that there are some hooks missing. Or for example, like, we internally use the ravam interpreter in foundry for doing all stuff like sheet codes. Some of that, like, you wouldn't be able to get like maybe console logs or something like that because it uses RevM on step functions. Hooks.
01:55:17.670 - 01:55:52.870, Speaker A: But essentially most of it should work. Like, for example, like calls and logs and mostly should work. Yeah. Gotcha. And then in regards to doing those, like, cheat codes, would that be on the LLVM side or would that, if I wanted to hack on that, as I said, it should mostly work. We haven't tested it. Essentially all we would have to do is replace the EVM runner with revency or with a revenue c handler that either jeets or blows it from disk.
01:55:52.870 - 01:57:07.456, Speaker A: And yeah, it should be the exact same gas cost, exact same semantics. Thank you. So for the replacement of storage, there's a bunch of ideas there. So what have been tested already and what were some preliminary results? Yeah, the thing about replacement storage, I'll say the pinpoint that we had initially, initially we had only one storage type. And what the thing that we did not realize as we were migrating to static files is now we have, now we have two different storage types. And in the past we relied too much on the atomicity of the database transaction. And whenever the node crashes, it drops, it does not commit anything.
01:57:07.456 - 01:58:03.700, Speaker A: And we did not realize, in my view, that the biggest pain point between having layered databases, layers of storage types, is synchronizing them. What we did try is, I think somebody already mentioned there was a question, like, we did try parquet. We tried other for static files, specifically for append only data, which tried different file formats, and they did not work for the things for our benchmarks. So we kind of reinvented that. We then build our own. What we're keen to keep experimenting on are different databases, like for different use cases. Like maybe in a year from now, you'll see our tree stored in like firewood or some other more appropriate database for the try.
01:58:03.700 - 01:58:38.340, Speaker A: Yeah. Thank you. Thank you, Roman and Danny. All right, so next up we'll have Oliver, who was brave enough to do this talk on core development. So give it up for Oliver and. Yeah. Hey, guys, I first of all, thanks for coming out and to people at home, thanks for tuning in.
01:58:38.340 - 02:00:03.514, Speaker A: I was asked to do this talk about core development, which is a pretty broad topic, so I wasn't entirely sure what to present about. So I think what I'll do is I'll present what is core development? What is a core developer? Then I'll go over briefly what's in Pectra and then what's in the future. Like, what are we excited for? So what is core development? It's, to me, always been a pretty nebulous term. Essentially, it's anything that improves the core protocol of ethereum. So that's the execution layer, the consensus layer, and it's very multidisciplinary, right? Like, you have researchers, you have community building ideas, you have the developers, you have an amazing testing team at the EF DevOps, you have user contributed testing and infrastructure. So there's a lot of stakeholders in this process, and by default it is essentially an open process. The idea is that this is very inclusive, so anyone can submit an idea and hopefully anyone will be able to get traction for the really good ideas and it will be implemented at some point.
02:00:03.514 - 02:01:13.130, Speaker A: I think one of the challenges here is that there are a lot of ideas, there's a lot of good ideas, but there's a pretty finite set of resources in terms of how many people can create test vectors, how many node developers are there, and things like that. So there's like a limited amount of time to actually iterate on these ideas, which is something that the rest team is working on trying to make easier with the SDK, for example. So the process simplified is you get an idea, you submit an eap, anyone can do this. Then you gather support, which arguably is one of the more tough parts of the process. Again, because there's not only limited supply of work and testing, there's also really a limited amount of mind share. So making sure that even if you have a good idea that it bubbles to the front and people are talking about it and thinking about it is pretty tough. And I think there's a bunch of different channels for this.
02:01:13.130 - 02:02:02.332, Speaker A: I think one of the most of the bigger uaps usually end up building a website and then usually also attach a meme to it of some sort, which is a really fast way to spread or to get mind share of your idea. What happens is once it gets support, usually there will be some sort of working group. For example, for Verkle there's a working group, they're building tests or building devnets. They're figuring out the details of how workload is going to work. And it was the same with EOF, and it's the same with most of the bigger eaps. Then these things are discussed on ACD, which is a biweekly call. Not biweekly as in two times a week, but as in every other week.
02:02:02.332 - 02:02:50.010, Speaker A: And there's one for El and one for Cl and they're like kind of shifted. So one week you'll have ACD for the execution layer and then you'll have one for the consensus layer on ACD. Again, this is actually open. People will usually go over ok, what are the updates? What have we done, what's interesting? And then what are our concerns regarding specific eaps? And this is also where usually we try to reach consensus on what should go in the next fork. Once the next fork is sort of settled, we build devnets. These are also publicly available and we test them. The devnets are crazy.
02:02:50.010 - 02:03:50.674, Speaker A: When I started on ref, I honestly didn't think there was as many tests and tools as there SDR actually is. I was at Interop in Kenya earlier this year and I learned so much about kurtosis, which is like, if you haven't used kurtosis and you're interested in client development, please go look at it. It is insane. And shout out to EtH panda ops for this tool. And then after the devnet and things are stabilized and fast and everyone can reach consensus on the network, you end up doing a network upgrade. So what is a Coredev? Again, pretty nebulous. If you want to be super strict, it would be anyone who contributes in some sort of fashion to client software that can sync to the latest block, but in practice is a lot more inclusive.
02:03:50.674 - 02:04:48.840, Speaker A: Right? Like researchers, in my mind at least, are core devs. But then you can ask, okay, like which researchers? Teams that produce test fixtures and infrastructure are arguably also core devs, but again, which ones? I think it's more like a social consensus thing. I think maybe at some point you just get the vibe that, oh, I think people think I'm a core dev and I think that's about it. So what's in Pectra? Pectra is a pretty big upgrade. First we have 7700 two, which I'm really interested in. It's the current account abstraction proposal, and it essentially allows you, or it adds a new transaction type that allows you to use your EUA as a smart contract so you can delegate, sort of like a delegate call. If you're familiar with the EVM, you can delegate your UA to use the bytecode of another account.
02:04:48.840 - 02:05:51.710, Speaker A: And this used to be transient, but now it's like permanent in the sense that once you delegate, it's always delegated until you explicitly decide not to delegate anymore. So why did we go for a 7702? If you've been around in space for a long time, maybe you remember account abstraction talk in 2017. It's been on everyone's mind for quite some time, and there's been a lot of proposals. Even in Petra we actually had, I think it was 3074, which was then replaced by 7702. Because it's simple. That's the key phrase is like, how do you point with this? Wow, it's simple. And I think that's pretty important, both because that means it's simpler to test, it's simpler for users to gruk about, and it's easier to implement, and it allows all the crazy things.
02:05:51.710 - 02:07:07.456, Speaker A: It allows transaction batching, account recovery, privilege, de escalation, social recovery, multisix, really anything. And I'm curious to see if, if anyone is hacking on this here, and if so, please reach out to me or anyone else who knows about this and also let me scan your card so I can win the leaderboard. And then the next thing in Petra is EUF, which is you can think of it as like a versioning for bytecodes. So it's a container format where it has a version and then it has sections much like a normal executable on an operating system. And it allows a bunch of nice things like static, it introduces static jobs, there's changes in some behaviors, it's easier to deprecate instructions, and it's easy to extend in the future. Imagine you could add a new UF version with new kinds of crazy bytecode or new kinds of instructions and things like that. And the use cases are vms better static analyzers.
02:07:07.456 - 02:07:56.840, Speaker A: Probably also easier to create debug formats for this. For dev tooling it's easier to analyze for JIT, there's no stack to deep, and we might be able to also with some additional work, remove the contract size limit and a lot more. So this is just for the execution layer. There's also a bunch for the consensus layer, but I'm not a consensus dev, so I won't pretend like I know too much about that. We're adding BLS precompiles, which is for signature aggregation and things like that. I'm not entirely sure myself, I was trying to think of okay, what are some really cool things you could hack on here? I'm simply not creative enough to know what you can use BLS for. I'm sure people are like, there's some really smart people here.
02:07:56.840 - 02:09:07.046, Speaker A: Who knows? Then we also added 29 35, which just stores a window of block hashes unchained. So this was originally going to change the block hash opcode, but that was pushed back on because it would make it more expensive and it wasn't really clear what the immediate use case was for it right now. But this is essentially preparation for Verkle, the 7605, 7002 and 7251. Or let me point with this, these are mostly in my mind like code organizational things. So we've essentially created a general way for the execution layer to talk with the consensus layer, which allows us to do consensus exits for validators on the execution layer. And it was also used in 7251, which increases the max effective balance for validators and allows you to consolidate multiple validators into one, which should be cheaper. So what's next? Or what are we excited about? So I guess you can't really see it.
02:09:07.046 - 02:09:51.670, Speaker A: Everyone knows this picture though. I think this Vitalix, nice roadmap. I would say that we're in a pretty good spot. Pretty much everything on this roadmap is being worked on in some shape or another, and there's good progress across the board. Verkle is, I think, progressing pretty nicely as well. I think in general we're in a good spot, so we might some things I'm really excited about is gas limit and repricing. We want to go really fast, which means we need more compute in the blocks, which means more gas giga gas teragas.
02:09:51.670 - 02:10:47.146, Speaker A: So we might need to increase the gas limit if it makes sense. And I think there's a really great series of blog posts here. Bye. By Georges and storm, I believe, on how to raise the gas limits. And it goes into all the limitations, like why is the gas limit as it is? It's both compute, but it's also state growth, history growth, and I highly recommend you read that if you haven't already. I also think there's a talk tomorrow called rest benchmarking, which will also go into some things about how we might be able to reprice instructions. How do we actually do that from a more data standpoint, rather than doing some benchmarks in isolation and just kind of going with it? Then there's vergil for l one.
02:10:47.146 - 02:11:28.982, Speaker A: It's a bit unclear if it's the best for statelessness, but it's definitely a candidate. Personally, I think it's very complex to swap the state commitment live, so I'm not too keen on that. And there are also interest in alternatives for l one, like alternative state commitments that might also give us statelessness and might be good for CK. But on l two, Verkle is actually super interesting because you can do something called a shorted fault prover. Imagine that you have an l two. You're going really fast, like multiples of giga gas. As a fault prover, you would need to catch up or keep up with the chain while also doing some complex computations.
02:11:28.982 - 02:12:30.030, Speaker A: If you use vertical where it's stateless, you could shard this process. So if you had a range of 100 blocks you might want to do fault proofs for, you could shard it between 100 different fault provers because it's stateless and it's possible it also helps on other things. And that's it. Yeah. All right, any questions for Oliver Eips process points. Oh, I also want to say if you have any questions on the eips, impactra or any erps in general, feel free to find me and we can talk about it. Yeah, well, Henry, thank you for the presentation.
02:12:30.030 - 02:13:17.600, Speaker A: I'm just curious about the process. From the moment you had this idea of creating wrath and then the moment is starting, getting more stable and you went to version one. I'm curious about what is this whole process of building a new ethereum client and how do you get there? Because there's so many different clients that already exist, so many different teams, their team, foundation, et cetera. How do you get there? Great question. It was actually tough, mostly because one thing I will say about this core development process is it's very distributed, which is nice, and it's very inclusive, which is also nice. But sometimes it can be hard to find specs for. Like, it's hard to find, like there's no unified spec.
02:13:17.600 - 02:13:56.748, Speaker A: Right. So if I start from scratch, where do I go? Usually you will read over the ips, but you will also reference what have other people done before me, because the specs aren't everything. There's a lot of like de facto standards as well in Ethereum. So it was tough and we had a lot of issues getting started. But you persevere and you ask questions essentially, if you're unsure, every core dev ever is super happy to explain to you how every part of the stack works. They're very passionate about it. So that was a great help.
02:13:56.748 - 02:14:41.510, Speaker A: I think. It was not only a team effort from the people who build with, it's also a team effort from the community at large, welcoming us and being willing to help us build with how long. So we started. Was it late 21 or something? Or late 22? Yeah. And in December of that year we all met up and we were like so sure that we were ready, like we were almost about to sync and they would be awesome and then we could optimize and everything. That was not the case. We had a lot of issues, stateroot issues, peering issues.
02:14:41.510 - 02:15:11.492, Speaker A: I think it took an additional six months after that to have something that actually would sync. It was, I would say for an alpha, pretty stable, but we were still learning a lot of things. So it was nothing. The most stable. And from alpha to 1.0, I think an additional six months or something like that. One year, I think one year because we did Alpha 1 June 2023, then beta February 24 maybe.
02:15:11.492 - 02:15:22.622, Speaker A: I'm thinking from alpha to beta. Yeah. And from beta to 1.0, like a few months or something. Hey, thanks for the talk. Yeah, over here. Sorry.
02:15:22.622 - 02:16:16.620, Speaker A: You mentioned there's some alternatives to verkle emerging. I was wondering what they are and do you have any hot takes? Do you think VRkL is going to get dropped and replaced with something else? I don't know exactly the details of the alternatives. I've heard that Verkle is not super good for CK and that there is been a lot of progress on CK with actually Merkle tree. So it might be that we don't do anything in terms of will Verkle get dropped? It's hard to tell. Like I'm saying there's a lot of good progress on it and there is, and there are like functioning devnets, but it's not like, it's not like it's coming out like in a few months or something. We're talking like maybe the next hard fork or hard fork after that. I'm not sure if it will be dropped.
02:16:16.620 - 02:17:03.260, Speaker A: We'll see from here to then when we're cfiing it for the next fork. Yeah. Based on your first hand experience and conversations on the ground, what do you think the readiness is right now for Pectra among the different clients and rest, specifically and particularly EOF? I'm really curious where that sits. Yeah. So right now Pectra is tested in two separate kind of loops. You have pektra without UF and then you have picture with Ef. I would say the picture without EOF.
02:17:03.260 - 02:17:35.506, Speaker A: I'm feeling pretty confident about it. It seems like for the current iteration of the Devnet, Devnet two, we did have a few issues, but they didn't seem too major and people were pretty fast to fix them. I guess we'll see on Devnet three, but generally I'm feeling pretty good about the state of Pektra without EuF. For EUF, it seems like. I know Rhett is ready. It seems like there's still some work to be done from some other teams. And I mean, it is.
02:17:35.506 - 02:18:03.560, Speaker A: I would say arguably Uf is probably the biggest part of packtrap because it is not one eip. It's like multiple. So as for the readiness of UF, I'm not too sure. And there is talk about maybe delaying it and pulling it out of pectra. Yeah, it's a story we've all been through a couple of times now. Thank you. Small follow on 7702.
02:18:03.560 - 02:19:04.564, Speaker A: I know there's been a little bit of back and forth on how the transaction noncing is going to be handled and some of the minor details around it. Happy to see something simpler getting proposed. But do you have a take on if those minor details have been worked out? It seems like generally there's consensus that the spec is in a good state. I think there's still room for discussion around how the nonce works. Not necessarily for the authorization itself, but I think personally, I'm a bit worried about the fact that currently you have this invariant where your nonce only gets bumped if you send a transaction. But with 7702, when you delegate an account for someone, the nonce is also incremented, which makes things like transaction pool design more complex. It's not like.
02:19:04.564 - 02:19:48.420, Speaker A: I wouldn't say it's a deal breaker, necessarily, but it's definitely something that I would be willing to explore a bit further. Yeah. Thank you. We have bindings for so both EOF and 7702, and all the pectoral features are already integrated in foundry and alloy, so it would be useful to get people to try them out over the weekend. And if you have questions on the mechanics of 7702 after reading a spec, please find me. And even if it's a question on how to use one of our tools for 7702, I'd be happy to help. Good.
02:19:48.420 - 03:30:25.156, Speaker A: All right, give it up for Oliver. Lunch is outside. Be back by 1230 and we'll have the external wrath builders talk soon, and we'll talk about what we're going to do after, too. Thank you all for a wonderful morning. All right, we'll be starting in two minutes with the Ben Clavi presentation and Andreas presentation. So if people would. Oh, my God.
03:30:25.156 - 03:32:01.410, Speaker A: Nobody's listening. Hello. Okay, can people start getting seated so that we can get started so that we don't run behind too much? I'm gonna start in two minutes. And will Clapby and Andreas come to the stage from the side. Should we close the in between? Okay. Okay, clabby, just come on. Okay.
03:32:01.410 - 03:32:44.554, Speaker A: Does anyone mind closing? Yeah. Great. All right, we're back for the second half of the day, where we'll have three ecosystem builders to tell us very exciting stuff that they've been building on Redstack. So part of that first up and Clavi form optimism. Awesome. Thanks, everybody, for having us back. It was cool to be back at the second rust Ethereum event.
03:32:44.554 - 03:33:43.470, Speaker A: Last year we presented Opireth. This year we're going to be presenting Kona, which is kind of an extension of our work, enabled by a lot of people in this room for continuing on op ref. So our agenda today is to talk about what Kona is, a quick overview of Kona, as well as the fault proof program built on top of it. Go over a case for multiproost for stage two decentralization, a really cool project built by succinct Labs with running Kona on SP one, and some quick talks about what's next. So first of all, starting off with what Kona is, it is a no STD implementation of the roll up state transition as well as the derivation pipeline. And so the reason that we went and we actually re implemented the state transition and no STD is because it actually turns out to be pretty hard to run ref on top of things like Zkvms tees default proof vms, given that they're kind of limited execution environments. No STD allows us to have a lot more control over that.
03:33:43.470 - 03:34:40.830, Speaker A: The other thing that we have is built on top of these libraries. We have the first alternative faultproof program for the op stack, which kind of sits beside the op program. So Kona client is the faultproof program, and it's built on top of the derivation pipeline. We have a stateless l two block executor with a Merkle patricia try that's kind of recursive in memory. And then we also have the host client I O libraries that allow for it to communicate kind of over an operating system pipe to pull in external data. To give you guys an idea of kind of where this sits inside of the fault proof stack will kind of decompose the problem. So whenever we want to verify a claim about the state of l two on l one, the normal process for that would be to first derive the l two chain, which basically is a data transformation function between batches, which were posted down to l one by the sequencer into l two execution payloads.
03:34:40.830 - 03:35:30.394, Speaker A: And then we pass it over the engine API to the execution layer kind of standard as l one does as well, and execute the l two blocks to kind of form the output state. And normally these are in two separate processes. So we make the faultproof program which kind of smushes the derivation, which normally sits in the opstacks consensus layer, and then the block executor, which sits in the execution layer together into one process. And so it turns out that you actually can't execute this on chain because it's just rust or go code. And so we implemented the faultproof vms, which most of you may know canon, some may know asterisk, and they're effectively these minimal virtual machines that are implemented both natively and in solidity. The solidity version is kind of a stateless executor of the VM. And then, so we can't execute the full program on chain on those vms just because it would cost too much gas.
03:35:30.394 - 03:36:12.260, Speaker A: And so we have the bisection game, which actually allows us to narrow in on the instruction step that we're looking for, and then ultimately that can decide the total dispute. And so Kona client is kind of at that very top level of the kind of smooshing together of the consensus layer and the execution layer. There's kind of a more long winded blog post. So if anybody's kind of more interested in the technical details, there's the QR code. I'll give second. So kind of to demystify the process a little bit, but this is all that the entry point actually is. There's a lot kind of happening under the hood here, but at a high level it's really not super complicated.
03:36:12.260 - 03:37:32.050, Speaker A: So we can start off at the very top. We're pulling in the boot info, and the boot info is a couple of trusted inputs. One of these is defined in the contract, which is kind of the l one head hash. It's a commitment to the historical state that contains all of the batch data, et cetera, that we need to actually feed into the derivation pipeline to transform into payloads. It also contains a trusted l two starting commitment, which is like the previous finalized proposal, or in the case of kind of an optimized bisection game, the pre state that was agreed upon by both parties during bisection. Then once we actually have that information, we also get like the claim, which is the user input, and then the l two block number that the claim corresponds to, we feed that into the derivation pipeline, which effectively unrolls that commitment on l one to generate all of the data fetches from blobs, etcetera, and produces the execution payload up in this function right here. And so once we have the execution payload, we can just feed it directly into the block executor, which takes in a bunch of Merkel Patricia tri witnesses, and actually performs the execution of the block statelessly and ultimately recomputes the state route receipts, route, transaction route, et cetera, formulates the header, and we get to the very end.
03:37:32.050 - 03:38:11.444, Speaker A: And so once we're here, we compute the output route. The output route is just kind of like a higher level commitment that pulls some things up to the top. It commits to like the block hash, the state route, and then the bridge contract storage route, just for easy access. And to make the proof a bit more succinct, when we need to unroll it and then just some asserts just to check to see that when we reproduce this state from trustlessly unrolling these commitments, that the claim was actually correct. If it's not, it'll panic, and that's kind of the end of the program's execution. So it turns out Kona client is actually pretty fast. Not that performance really matters.
03:38:11.444 - 03:38:52.248, Speaker A: In faultproof world, this is plenty fast enough to execute within a dispute window. It's cool to see that we got a couple of optimizations and things taking advantage of policy on an optimistic pass and falling back to consensus if things like batch of policy isn't held. But the nice thing for this too is that with it being faster, it becomes more feasible to ZK prove. And we'll talk about that in just a couple of minutes. But the cool thing is these were both executed on a laptop. It's a pretty fast operation to do. One note is that these are actually using cache local witnesses, so there's no network latency inside of these benchmarks, which would probably two or three x these times in practice.
03:38:52.248 - 03:40:07.054, Speaker A: Normally, if you're doing a fault proof run, you wouldn't actually have the witness cached up front. So it kind of brings us into multiproost and why we built this thing, you know, why do we have a second faultproof program when we already have one that works just fine built off of the reference? So a core requirement of l two beat, which for those unfamiliar is kind of like a roll up warden, keeps people accountable and also does a risk assessment on l two s. They have kind of this big target that everybody's trying to reach called stage two decentralization. And so in order to meet that, you actually have to have the ability for the Security Council to only be able to intervene in the event of an on chain provable bug, quote unquote. So multiple implementations of the proof, kind of like multiple implementations of l one clients, offers us kind of like a sane path to getting here. So we can do this by allowing the proofs to challenge proofs themselves inside of the dispute game, with a disagreement being considered a consensus failure, and kind of unlocking the action of allowing the Security Council to intervene. And so another cool thing is, with our last year's presentation, we already have Opreth, which a lot of people in this room have worked on.
03:40:07.054 - 03:40:52.480, Speaker A: Thank you guys, you enabled this to happen. But it allows us to basically take that consensus layer and execution layer, smush them together, and have kind of a whole new fault proof program built on top of a completely different implementation. So this image is kind of a visual of what the current system looks like. And you can see that there are a lot of single points of failure. And hopefully this can give you some perspective on why the obstacle fault proofs are still on training wheels. So any of these red boxes, if they fail and there was no human intervention or air gap, would effectively mean that the bridge bridges funds could get drained. And so we have the op program, which is built on top of op geth and op node.
03:40:52.480 - 03:41:33.700, Speaker A: The reference implementation op preimage is the hostclientio thing. Canon is the MIps, faultproof VM. And then we have the contracts on the side. And every single one of these don't have a redundant component at play. And so if they do fail, we're kind of in a bad spot. And that's the whole reason why there's still this big operator override the top, right? Because if they do fail, we still need the ability to be able to recover and keep the roll up rolling. So this is a really cool graph because it shows after the introduction of asterisk and Kona, asterisk is a secondary fault proof VM, whereas Kona is a secondary program.
03:41:33.700 - 03:42:27.330, Speaker A: We reduce our single points of failure almost to nil, with still the contracts kind of sitting in this point where they are suddenly the bottleneck. And so looking even further forward, adding multiple types of disputes, you can imagine that the handler, for once we actually discover this discrete upon block state transition, we can swap that out with something that short circuits like a ZK proof. And this would actually give us even more redundancy in that area and start looking towards turning many more boxes here gray. And so that kind of brings us to a design philosophy of Kona. Something that we started trying to do from the get go is making sure that we could run everywhere. So Kona's components were built with alternative backend support in mind. They were starting with no STD, with alloc enabled libraries to promote portability.
03:42:27.330 - 03:43:23.174, Speaker A: You can run it on pretty much anything. I actually ran it on a raspberry PI, which is pretty cool. But when boiled down, if we're just kind of thinking about faultproof VM versus ZKVM targets, there's kind of just like two small differences. So first of all, with the host client communication, it can occur on the fly in faultproof vms, whereas ZK vms have to have that full witness upfront to supply as a private input. Also with Faultproof Vmsheendeh, the data received from the host in the native run can assume to be trusted, since the on chain implementation of the host actually verifies the data upon entry. And because we only need that small piece of data to actually perform the single instruction step, we can offload that verification to when it's actually needed, rather than having to do the full constraint inside of the proof. Whereas zkvms, during the runtime, they have to validate all of the data that comes in from the host.
03:43:23.174 - 03:44:08.562, Speaker A: So for example, if I give you the preimage of a catch act hash, you actually have to rehash it inside of the ZKVM to show that it's actually the real preimage, and they have to basically just validate all of that in order to fully constrain the proof. And so the nice thing about this is really all we had to do in order to make Kona run on faultproof vms and ZK vms, and even in trusted execution environments, is to abstract over the data sources. So the derivation pipeline will read over l one data, it'll read some l two data, etcetera. And all of that is just trait bounded. You can swap them in and out and allows you to have kind of multiple backends for this piece of software. And so this is really cool. Sysync Labs Uma is going to be talking next alongside Zach O'Braunt.
03:44:08.562 - 03:44:53.240, Speaker A: They finished a mvp of the SP one backend for Kona client already, which is a really, really cool thing to see. Their code base is only around like 500 lines of code. It consists primarily of those data source implementations we were talking about. And then they've also got kind of like a custom entry point, and they also are able to even reuse our program for generating the witness. You just run it natively, it captures all of the data that it needs, stores it in a big directory, and then they can just feed it in whenever they actually start the run on SP one. So what's next? First of all, we got to get this software out in the wild, so we're looking to productionize Kona and asterisk soon. Kind of on the road to having this multi proof redundancy.
03:44:53.240 - 03:46:02.520, Speaker A: We have interop support, which is a big ongoing project which our implementation, along with the reference implementation, will have to end up supporting dispute game V two, which is a really kind of. It's an evolution of the existing dispute game that we have on chain that hopefully will mitigate some of the design failures as well as some of the implementation issues that we have around having further abstraction to nest by section and also have these multiple handlers for the disputes. For multiproofs, we also now have a kind of independent derivation pipeline which we're using for proofs, but because the data sources are abstracted, you can also have it run in an online context. So we hope that somebody can actually build, like, an execution extension for a roll up node with Kona derive. And the other thing that we're really trying to do is beef up our multi client test suites. So l one I know Oliver talked about this, has all of these tools with kurtosis and t eight n, et cetera, to actually test cross client support. If we're going to get serious about using multiple clients in our hot path, we need to make sure that all of that is supported and well tested in a way that's maintainable.
03:46:02.520 - 03:46:57.730, Speaker A: So all of these people did a wonderful job and helped contribute to this. Specifically, Andreas, up on the top, who's in the crowd, wrote almost half of Kona with me over the past few months and was a huge help. And then some other contributors with Zach Abrant and succinct labs were incredibly helpful in terms of terms of offering us a good feedback loop on our abstractions and making sure that we had it in a place where alternative back end support was a first class citizen. Justice from Torali Labs helped out with some of the ideation as well as some of the implementation. And same thing with Nicholas and hash cash here, as well as Mark Tinaway from Op Labs as well. And so if you do want to contribute, we are hiring for this team specifically. So if this kind of stuff interests you, definitely find me on the side.
03:46:57.730 - 03:47:27.080, Speaker A: If you're just looking to contribute in an open source capacity, we do all of our work in the open. This is an MIT licensed code base. We have a discord where we do protocol R and D. And if you're looking for an invite link, definitely feel free to find me in the crowd, and I'll try to get you hooked up. And that's it. All right, thank you, Ben, for the talk. Any questions from the crowd? And again, only questions.
03:47:27.080 - 03:48:22.626, Speaker A: No statements. I have one. How do you relate to Kona being a piece in the multiprovered universe, especially for the stage two roll up decentralization roadmap? Yeah. So Kona is kind of like the kind of the analog against Op program. So if we go back to this diagram where we have all of the components after the current system, Kona kind of sits beside the op program as its kind of backup redundancy piece. And so we have asterisk and canon, which are the two fault proof vms. And then we also have Kona and Kona specifically being implemented on top of Op ref, as well as our derivation pipeline, with Op program having the op node and op geth as its execution engine and consensus logic respectively.
03:48:22.626 - 03:49:36.334, Speaker A: So these separate implementations are kind of designed such that we have kind of a high probability that the same bug wont be implemented in both at the same time. Following a similar vein of l one client diversity guarantees whenever where we do hard forks and implement complex features. Mark so what is your biggest learning been when you're targeting writing code that runs in a fault proof vmdezenhe or a ZKVM? Yeah, it's a good question. So we initially started trying to write Kona as like an STD lib enabled rust library, and the really hard part about that is that faultproof vms are just a really kind of bare metal environment by definition. So it's a pretty minimal soft cpu. Sometimes they don't even support the entire instruction set, and they also support a very small subset of Linux. So I think that Kona only requires four syscalls, which is read, write, exit group, and mmap, which is really really nice because we have that low level control.
03:49:36.334 - 03:50:33.510, Speaker A: And so when we compare that with the Go programs, the Go programs actually have to statically link the Go runtime, which means Go routines are required. They call pretty much any syscall that they can, which I think Go Lang can compile with like 52 different syscalls for the MIPS target, which, you know, not all of which are supported. And so it's the kind of thing where having no STD code promotes portability between not only our targets, but hopefully future targets as well. Like we were kind of able to run on sp one out of the box with this kind of low level libraries, mainly because we didn't have to worry about compatibility issues with every single new backend that we added. And hopefully that'll lend us a pretty good benefit in the future, especially as we start adding more backends to things like binius and also future tes. I know flashbots is interested in it, and that's kind of why we chose to make them more low level, no STD libraries to begin with. Nice.
03:50:33.510 - 03:51:37.132, Speaker A: So there are a bunch of red boxes here. How do we get rid of the red box? Yeah, so it's a really good question. I think that there's kind of a complexity floor here that we need to think about, and we can't just like duplicate absolutely everything here specifically, it becomes really hard in the contract side of things. So the ZK kind of handler for finding the dispute at the very end is a really good way to kind of solidify our verification function once we found the dispute. But one of the really hard things is, is that whole kind of like block bisection and chain bisection layer on top are still going to be kind of the same thing, and making those redundant, it becomes pretty hard. So really what you're kind of looking to do, in my opinion, is minimize the surface that we actually have to kind of pull out all of the steps on, you know, formally verifying a contract that just bisects over a binary tree is really not infeasible. That's something we can do.
03:51:37.132 - 03:52:35.930, Speaker A: But if we look at the system in this state, formally verifying this entire surface and, you know, fuzz testing the hell out of it basically means that every future protocol upgrade that we're going to make is going to be miserable. So it's kind of like, how far do you go is a good question. I think that you probably want to stop at some point in these contracts, but still, like probably have multiple verification functions at the end of the day. All right, so stage two or bust, hopefully soon with Kona. One more question from zero. H how ready is Kona and the other provers for the Pektra vM changes like EOF? Yeah, so at the moment Kona is about as ready as Revm is. There's a couple of things that we're going to have to do in our block executor code.
03:52:35.930 - 03:53:07.158, Speaker A: Again, we weren't able to actually directly reuse the EVM crate from Reth, but we do reuse revm verbatim. We didn't go and write our own EVM or anything. So hopefully the upgrade will be somewhat pain free. But we don't currently have Pector support within Kona at the moment. Is the idea that that would follow at some later date on the op stack? Yeah, definitely. The op stack tends to inherit l one hard forks pretty much verbatim. We haven't skipped one since we launched bedrock and I can't imagine that would change.
03:53:07.158 - 03:54:04.204, Speaker A: So if Petra, Petra does include, if Pectra does include eoF, we will definitely be supporting it on the op stack as well. Has have the provers been able to simplify a little bit of like a post self destruct era? Are there? The provers have definitely been able to simplify in a post self destruct era. So there's this kind of interesting thing where all of this is stateless execution. So I know that you probably heard all of the rest people say that the NPT is the root of all evil, and I agree with them. So account deletions kind of being gone is just an incredible thing, but we still have things like storage slot deletions. So it actually turns out that whenever you zero out a storage slot when it was previously set, that path actually gets deleted within the try. And so deletions in the try in general are actually really, really difficult when it comes to generating execution trace witnesses, primarily because you can execute the entire block with nothing but ethget proof.
03:54:04.204 - 03:54:56.820, Speaker A: So just like proving the path to each account and then proving the path to the storage slots. But whenever you actually do a try deletion, you sometimes have to unblinde the sibling, which is hashed inside of a branch node in order to collapse the branch node. And so deletions from the try in general are just a pain in the ass. And having less of those which removing self destruct helped with definitely simplified the prover. But that said, we still do have to handle tri deletions, and I think that that's kind of one of the cruxes of the things that we're going to have to get over. Like we just added a execution witnessed generation endpoint to reth. And formerly the fault proofs are really heavily tied to hash scheme geth, because in the Geths database they effectively key trinode RLP by its hash, and so it makes it really easy to traverse the tree regardless of where you're going.
03:54:56.820 - 03:56:11.820, Speaker A: However, if you're only relying on eth get proof, you suddenly can't actually do all of the tri deletions, because sometimes you need to unblind the sibling, and that means that you have to have extra support to do historical execution and collect all of the tri pre images that are touched not only during the execution part, but actually during state root generation as well. Is there any denial of service risk where you couldn't run bisection if there was too many of these storage deletions happening, or. Good question. So actually no, to give kind of a perspective, and I wish I had a perfetto trace to show you guys, but the faultproof program execution is actually super cheap, and we're not super worried about that. I think that if I were to say the biggest hotspot in the whole fault proof program run at the moment is derivation and specifically span batch validation. So when we are sequencer posts down batches to l one, which is kind of all of the transactions that originate on L two. When we actually do this span batch validation, which is kind of validating the encoding and the order of all of the transactions in the batch, there's a lot of remote data fetching, which means it's a lot of communication with the host, which is over the OS pipes and actually takes 65% of the cpu cycles just to validate the span batch itself.
03:56:11.820 - 03:56:50.972, Speaker A: And that turns out to be the hotspot that I think we need to address first. But in terms of, like, tri deletions, it's kind of negligible when it comes to it. And the cool thing about fault proofs is because it's optimistic, we kind of just need to be fast enough, not as fast as possible, but hopefully we can push the performance front for the sake of the ZK teams that also want to run Kona as well. Great. Thank you. I agree. Have you tried looking at how Verkle is going to impact tree deletions and all that in Kona? We haven't done too much exploration in Virko yet, but I will say is that I'm really excited.
03:56:50.972 - 03:57:40.170, Speaker A: I share the opinion that Verkle is probably best placed on l two. I am very excited to have just execution or execution witnesses in the header because it makes our lives just way, way easier. But I don't think that I've done enough searching, nor have I started implementation, to see concretely how it would affect our implementation. All right, so next up, today we have UMa to talk to us about SP one Reth, or the intersection of Reth with ZK proofs, or I guess ZK rollups with SP one. So we should have updated the title. So who want to take it away?
03:57:41.280 - 03:58:47.384, Speaker B: Hello, I'm Uma. I'm one of the co founders of Succinct. And yeah, today I'm going to be talking about how we built on top of the excellent work by Clavi and Andreas on top of Kona to build ZK rollups with SP one. So I think the first important thing to talk about is why do ZK rollups matter? What problems do they solve? What actually do they help? And I think today, a very common theme in the Ethereum ecosystem that we're all talking about is interoperability and unifying all these different roll ups that are spread out throughout Ethereum today. If you're a user and you want to use a roll up, it's pretty difficult if you have assets on chain a to get assets on chain b, and a lot of these teams are working on themes around interoperability, unified liquidity, better bridging, and overall just improving the UX and making it better. And I think ZK is the only way that all of these problems will actually get solved. So today, ZK rollups do exist, and there's a bunch of very smart people on some of these teams and other teams as well, that have had made ZK rollups.
03:58:47.384 - 03:59:34.160, Speaker B: And what does that kind of look like today? Well, if you want to build a ZK rollup, the really critical ZK part is you have to make a zero knowledge proof of your roll up state transition function. So basically you take your old state route that's on chain, a bunch of transactions, and then you prove your new state route and you verify that proof on chain. Now, today, the ZK rollups, the code kind of looks like that. It's not super easy to see, but you can see that people have to write circuits, they have to write their own custom assembly, they have their own dsls. It's all very complicated. And in particular, there's a lot of issues with the current approach of ZK rollups today. All the ZK rollup teams have very large specialized teams with ZK expertise and cryptographers that have to make these state transition functions.
03:59:34.160 - 04:00:20.190, Speaker B: They're very hard to customize and maintain and upgrade because if you're hand rolling your own stack and then Ethereum goes through a hard fork and you want to be compatible, you have to update all that cryptography. It's also a really large surface area for security vulnerabilities because you're handwriting. Everything that's going to ref and RevM, you're basically re implementing that in ZK, which is basically ten or 100 x is hard. And then also a lot of the ZK rollups today are not fully type one compatible. So type one means that you have the same state root computation as Ethereum, for better or for worse, including RLP, the Merkle Patricia, try catch act hash function. And so a lot of the ZK rollups, because implementing that in ZK is very difficult and is very expensive. They're type two or type three or type four.
04:00:20.190 - 04:00:59.482, Speaker B: So, so sp one is a ZK VM that we've been building at Sysyncd. And what does it let people do? It lets any developer use ZK by just writing normal rust code. So we're at the open source rust ecosystem conference, and so when you put open source Rust plus sp one, I think it can help address a lot of the problems with the ZK rollups of today. So how does SP one work for those who are not familiar? First you write your program in normal rust code, so it looks pretty normal. It's very readable. Usually it's pretty short. Then it gets compiled to RISC five, which is a reduced instruction set.
04:00:59.482 - 04:01:43.602, Speaker B: And then we generate a proof of your RISC five execution and your RISC V program with a certain inputs to get a ZK proof that can be verified on chain. So when you have sp one and now you can write your ZK state transition function using SP one plus revm, ref alloy, Kona, etcetera, you solve a lot of the problems with ZK rollups of today. Basically you can just write normal rust so you don't have to be a cryptographer. It's really easy to upgrade and maintain. I kind of joke it's as simple as cargo update ref. When upgrades and they're implementing all this stuff, we just get all of that for free. The security surface area is also really nice because Ref has undergone extensive audits.
04:01:43.602 - 04:02:29.550, Speaker B: There's currently an effort to formally verify RevM, and we kind of get all that security work for free as well. When we use Ret and RevM in SP one, it's natively type one compatible because it's using the exact same node software and computation of the state root, and it actually ends up being not that expensive. So this is kind of the dream on why SP one will help solve a lot of problems and make ZK rollups really easy and really maintainable. And so now I'm going to talk more about how we actually go through this step by step. So step one of building a ZK rollup is we actually have to execute a block. So let's run through that. So when we want to execute an ethereum block in SP one, we have to write an SP one program using Ref to actually do this computation.
04:02:29.550 - 04:03:20.724, Speaker B: But first, what we have to do is we have to fetch the witness for the computation. So this involves executing the block outside of SP one, just a normal native code, and we use the RPC, we fetch all the storage slots, we fetch all the relevant Merkle proofs, we fetch all of the data, and we do this in what we call the host program. Then we take all of that data and we construct a client input which is run in our client program, which is the SP one program. And so we have the previous block, the current block, and all the necessary merkle proofs and storage proofs and block hashes and trinodes and a lot of this has to deal with the complexity of the MPT. I very much agree with Roman that MPT is the root of all evils. But yeah, we are able to easily fetch that data using ref. Then once we have that data, this is the actual SP one program to execute the block.
04:03:20.724 - 04:04:00.790, Speaker B: You can see it's very short and simple. We annotate it with this SP one entry point to denote it's an SP one program. We read in the input, we deserialize it, we execute the block, we then get the new header, we hash the header and then we expose that as the public outputs of our proof. Once we have this program, we can generate the proof in SP one. And now we have a proof for an Ethereum block execution. So we actually ended up implementing this and along the way we definitely ran into some challenges that a lot of people in this room helped us out with. So one of the challenges was that Ref is a very good piece of software, it's very modular.
04:04:00.790 - 04:04:38.796, Speaker B: But unfortunately at the beginning of our exploration, some of the crates did not compile within SP one. So for example, if you import crates that are making networking calls, the code is not going to compile with an SP one. And we worked very closely with the rest team to power through and make those dependencies optional or feature flagged or refactored. So that was a great help that they gave us. Another complication, as many people have mentioned at this point, is state root computation. The Merkel Patricia try is very very complicated. There's a lot of edge cases, and Roman in particular on the RET team helped us out a lot on actually computing the state route within our SP one program.
04:04:38.796 - 04:05:24.628, Speaker B: There's also all these edge cases around the Merkle pusher trie that requires using this debug endpoint in Geth that we're trying to move away from. And the RET team has recently merged in an endpoint to help with that. Now once we got through all those challenges, there's a bunch of reusable primitives including an RPC DB that can be modularly used with ReVM where it fetches all the witnesses from an RPC. And then we have a witness DB that can be used in a ZKVM context where it loads up all the state and then it can just run the block statelessly. In the end we only have 1100 lines of code in this repo and we can now execute any Ethereum block and generate a ZK proof for it. And it also works with op stack pretty easily, thanks to op Roth. So with ZK.
04:05:24.628 - 04:05:49.890, Speaker B: Everyone's always super obsessed with the costs. And so I want to talk about the cost data we got from executing these programs. So I took a random range of blocks, and these were not cherry picked blocks. You can see they're just sequential. It was a random range someone gave me. You can see that the gas used, and these are real main net Ethereum blocks. You can see the gas used is, you know, some are less, some are more than this 15 million average gas target.
04:05:49.890 - 04:06:19.642, Speaker B: And what we do is we take the block, we execute it with an SP one. We count the number of risk, five cycles that happen during execution. And then basically we generate the proof and we compute the total cost per transaction by multiplying the on demand cost of the GPU instance. We're running SP one on and multiplying it by the amount of time it took to generate the proof for that block. In the end, you can see the costs per transaction are actually pretty low. It ends up being between 0.2 and 0.3
04:06:19.642 - 04:06:52.160, Speaker B: cents average proving cost per transaction to prove the execution of an ethereum block. And this is actually a very pessimistic estimate. This is using on demand pricing. Usually when you go to reserved instances, you can get much cheaper GPU's and there's a lot more optimizations we can do. So even today, the costs per transaction for proving an Ethereum block are very cheap. SP one has a bunch of ZK innovations and a lot of performance engineering that we spent a lot of time on to actually enable this. So I want to talk a little bit about that.
04:06:52.160 - 04:07:57.150, Speaker B: One of SP one's main innovations was our precompile centric architecture. So generally even this is true, I think in ref and RevM, when you're executing an Ethereum block, even on a normal cpu, you spend a lot of time verifying signatures and verifying hash functions. In SP one we have this system of precompiles where basically you can take these very expensive cryptographic operations and then we make a custom circuit for it in SP one that can talk to our main cpu. And usually this helps reduce the cycle count of our programs by six to ten x, which directly translates into a six to ten x reduction, improving overhead and time and cost. We also have a bunch of other precompiles for elliptic curve operations and other cryptographic operations that help a lot for things like KZG or BN pairing verification. We implemented an optimized GPU prover that helped a lot in terms of cost and latency over a cpu prover. And then we have a bunch of other algorithmic optimizations on the ZK side of things that really helped make SP one as cheap as possible for this Ethereum block execution use case.
04:07:57.150 - 04:08:39.146, Speaker B: So the main takeaways from doing this exercise were that the costs are already pretty cheap. And we think that with all the work we're doing and all the performance optimizations that are happening, as well as getting, you know, better reserved capacity and making our GPU's cheaper, the costs will only go down from here, maybe even by five to ten x. I think what's even cooler than the cost being cheap though is that it's super easily customizable and there's very minimal lines of code. We're super happy that we could use all of the work by the ref, then RevM and alloy and Kona team. And in the end you have ZK verification of Ethereum blocks with only 1100 lines of code. That is super magical. And again, it's easily upgradable.
04:08:39.146 - 04:09:34.058, Speaker B: There's minimal maintenance surface area and I think that is the very powerful developer experience of a ZK VM. So I've talked about how to verify execution of Ethereum blocks, but in a ZK rollup there's actually a lot more stuff that's going on. So I think we're only at step one and now I'm going to dive into step two of actually building a ZK roll up. So thankfully we are using the op stack to do kind of the rest of the complexity of a ZK rollup. Okay, so what is the op stack? I imagine most in this room are pretty familiar, and this is taken directly from one of their blog posts or their documentation, but as a modular open source set of components to build rollups in general. And I think they had a lot of foresight when they wrote this. I think it was maybe one or two years ago where they said it's not just a roll up, it's not just optimistic.
04:09:34.058 - 04:10:20.600, Speaker B: And actually now that's becoming true with the work we're doing to help make their stack also support ZK. So this is kind of like a system, very simplified system diagram of all the stuff that's going on in op stack. You have this op batcher that's kind of like the sequencer that takes in a bunch of user transactions and is actually posting the transaction data on chain. Then you have this optimism portal where users are depositing and withdrawing. Then you have your actual node that's actually running your node software and updating the DB with the transactions and the deposits and the withdrawals. And then finally, this is the current part of their stack. They have this op proposer that's washing the node, and every hour it proposes a new state route to this contract called the L two output Oracle.
04:10:20.600 - 04:11:21.362, Speaker B: And all the stuff in the red is all the fault proof VM stuff where basically they have the op challenger op program, canon, and a bunch of other stuff where the fault proof VM ensures that the proposer cannot propose a false route to the contract. So there's a seven day waiting period where you can run this interactive challenge game, and that adjudicates whether the state route that the op proposer proposed is actually correct or not. After seven days, when the state route gets finalized, the optimism portal can use that finalized state route and users can do withdrawals against that stateroom. And one thing I want to note is this diagram is a little bit of their old system. Their new system has a more complicated dispute game contract and things like that. That clabby covered a bit, but for simplicity, this is a simplified view of their system. Now, their stack is super modular, and I think the OP team deserves a lot of credit for building their stack in this very modular way where components can really be easily swapped out.
04:11:21.362 - 04:12:04.856, Speaker B: And so that's exactly what we did. We decided that, okay, the L two output Oracle today is adjudicated by this fault proof game. But actually it could be a ZKL two output oracle, where whenever the op proposer proposes a state route, they not only propose a state route, they also include a Zk proof that their new state root is correct. It gets verified against an SP one verifier, and then the contract gets updated. So you can see that we are still able to leverage all the other components of their stack, like the op batcher, the op node, all that nice stuff. And the only thing we have to do is swap out the Zk l two output oracle and the op proposer. So to actually do this and dive into a little more detail, there's two components.
04:12:04.856 - 04:12:35.850, Speaker B: First, we actually have to write the state transition function for the proof that gets verified in this l two output oracle. That is not a very easy task. The op state transition function is pretty complex. It involves getting data from l one and running derivation. It involves taking the deposit transactions and making sure they're ordered properly. And then you have to recompute the new state route and make sure everything's handled correctly. Thankfully, Kona, which is the previous talk that Clabby gave, came to the rescue.
04:12:35.850 - 04:13:27.524, Speaker B: So Kona is this portable modular implementation that's rust centric of the op derivation program, and we were able to just implement Kona directly in sp one. It's just a normal rust code. So we were able to write an SP one program that has the optimism state transition function and very few lines of code. As Clavi mentioned in his previous talk, our program ends up being 500 lines of code. It's very minimal modifications. It leverages all the existing work that they did, and then boom, we get a program that can run the state transition function of optimism, generate a ZK proof of it using sp one, and then verify it on chain. Then for the op proposer, all it has to do is it runs in a loop, it watches the tip of the chain, and every so often it'll query to our prover network via one API call to actually generate the proof.
04:13:27.524 - 04:14:08.642, Speaker B: So the Op proposer today is a very lightweight process where it's just proposing it's getting the latest state route and it's throwing it on chain in a smart contract. This Zkop proposer is still a very lightweight process. It's not actually doing any proof generation in its own runtime. What it does is it spins in the loop and then calls to our prover network to actually generate the proofs in detail. What's actually going on is that for every range of blocks, so every so often, I think every minute, the op proposer takes that range of blocks and it requests a proof for that range, and it does it for every minute. Now, you can't actually post proofs on Ethereum every minute. That's very, very expensive.
04:14:08.642 - 04:14:44.002, Speaker B: It ends up being like 280k gas per proof. So what you have to do is you take all your proofs for each range of blocks, and then you aggregate them into one megaproof, and then after that you post the megaproof on chain. And so that's actually the logic that's going on in our Zkop proposer. So with those two components, it's very easy to make an op stack chain, a fully ZK proven chain, in two easy steps. You just take an existing op stack chain, or you can deploy a new one using your favorite ras. Then you deploy this ZKL two output Oracle smart contract. That's trivial.
04:14:44.002 - 04:15:18.518, Speaker B: Using forge, you just run a Forge script, then you spin up a docker container to run the zkop proposer. It calls to approver network, it generates proofs, and then it posts them to the ZKL two output oracle. Then your time to finality goes from the seven days to 1 hour, which is pretty awesome. So we actually ended up doing this. We implemented. You can check out the repo up there. And I think the thing that was really awesome to see in a lot of the work and shows really the compounding nature of open source work is that in all, the total lines of code ended up being less than 2000.
04:15:18.518 - 04:16:08.270, Speaker B: Thanks to the great work of the ref team, the RevM team alloy, and also the amazing work of Kabi on Andreas, we were able to just import Kona, write the program, use the op stack, use most of its primitives, and only modify the proposal slightly. And then we're able to have a full ZK roll up, which is super awesome. And yeah, as I mentioned, we actually did this. It's pretty few lines of code. Getting the right lines of code was definitely difficult, but once you had it, it's actually very beautiful. And the abstractions that Clavi and Andreas have in the Kona repository were very amenable to us. There was very minimal modifications and they had really great abstractions to make it easy for us.
04:16:08.270 - 04:16:45.834, Speaker B: So we're very thankful to them. So we ended up doing this for op sepolia, and we're live updating with the chain. We have a bunch of GPU's spun up in our AWS instance, and we're able to keep up with the chain and generate ZK proofs and post them every hour or so. So now again, people's favorite questions with ZK. Okay, how much does it cost and what's the delay? So there's generally two components to any ZK system. There's the on chain costs of proof verification, and then there's the off chain proving costs. So the on chain costs in our case are when the Zkop proposer proposes a state route, it has to propose a new route and verify a proof.
04:16:45.834 - 04:17:18.312, Speaker B: And in all, that transaction takes around 417k gas. This is actually around the same cost as proposing a new route with the fault proof game, which is around 420k gas. So the on chain costs for ZK and for the fault proof game system are actually relatively similar. You're not paying more eth to ethereum to use ZK. The off chain proving costs are obviously cost that is not present in the fault proof system. And we found that in the end, it ended up being zero point five to one cent per transaction proving costs. And this is a super, super rough estimate.
04:17:18.312 - 04:17:59.160, Speaker B: It really depends on your workload. It really depends on how many transactions there are per block. It also really depends on your l one's throughput. So again, this is a very rough number, but we ended up with this range and we noticed there's basically a two to three x overhead versus the proving costs of Ethereum transactions. Because of the other parts of the derivation pipeline where you have to scan through all the l one receipts to find all the deposit transactions and withdrawals and stuff like that. In general, we found that the derivation, which involves iterating through the l one, was ten to 20% of the proving overhead, and then the block execution ends up being between 80 and 90%. But again, all these numbers are really dependent on the load and work of your chain.
04:17:59.160 - 04:18:42.292, Speaker B: Another thing that people like to talk about is latency. So, you know, how fast can we get the finality? So one common misconception is that, oh, if I generate my ZK proof every minute, I can get 1 minute finality. Well, if you want to post DK proofs to Ethereum every minute, that's extremely expensive because it ends up being 280K gas per minute, that ends up just being a very large number. So actually the bottleneck to latency is the ethereum cost of posting proofs. That's the reason why our current latency is basically we post a proof every hour. It generally lags 20 to 30 minutes behind the tip of the chain, and we're able to do that pretty consistently. Another thing I want to highlight is that latency is not the same thing as throughput.
04:18:42.292 - 04:19:39.898, Speaker B: So even though we lag behind the tip of the chain by 20 to 30 minutes, which is already pretty fine, we're still able to keep up with the chain just by having more gpu's. So if you have more transactions or more blocks in your chain, that's actually totally fine. We just increase the number of GPU's and we're able to maintain a throughput that keeps up with your chain no matter what. Another question people like to ask is security. So, you know, ZK obviously very complex. It's kind of scary if I'm relying on a ZK proof for my whole roll up, is that okay? And I think similar to the fault proof systems of today, where you have, sometimes you have whitelisted people who can participate in the fault proof game, or you have an override security council, you can also use these same tactics with ZK to get the security that you want. So for example, common techniques, and this is true for all the ZK rollups of today, is they have a whitelisted set of actors that can put poster proof on chain, and you can also have a small challenge period.
04:19:39.898 - 04:20:30.100, Speaker B: For example, a three to five hour window after your route is proposed and the proof is verified for someone to step in and you know, or for a security council to step in and act. And thankfully, the existing op stack repo conveniently already has this functionality, and so you can leverage that as well to put additional security on top of your ZK roll up. So I think I spent a lot of time talking about current cost and latency, and a lot of people like to focus on that. But I actually think the most important question is the trajectory, where is this all going today? And I know that basically the costs are going to go down by ten x guaranteed. So there's actually two ways that the costs of all this stuff and latency can go down. One is on the SP one side. As I mentioned previously, right now we're using all these on demand GPU instances.
04:20:30.100 - 04:21:28.048, Speaker B: But actually it makes a lot of sense if you have a relatively constant workload that you can start using reserved instances or dedicated instances for a really big reduction in cost. We also have a lot more optimizations we want to do to our GPU prover, and then we have a lot more optimizations to our actual circuits and algorithms on the ZK side of things that we are very optimistic will result in a five to ten x decrease in cost and latency by the end of the year. Another interesting area that costs can go down is actually protocol and software optimizations to Opstack and Kona. So I think when Op built their program, they weren't necessarily thinking, how do we make it most efficient for a ZK? And currently they require iterating through all the l one block receipts. And I think things like this are very fixable with minor tweaks to the protocol that can make it a lot more friendly for proving in ZK. There's also a lot of raw profiling and optimization we can do to Kona to cut cycles. I think there's a lot of table stake stuff.
04:21:28.048 - 04:22:10.852, Speaker B: We only recently started looking at this code, and there's a lot more low hanging fruit to make this a lot more efficient in the context of a ZK VM. And so already today, the costs are pretty cheap, but I'm very confident that they're only going to get cheaper and cheaper from here. So, as I mentioned, we've gotten this working. Those are the repos that I referenced. The RSP one is for ethereum op, distinct is for the Kona sp one work. And yeah, if you're interested, you can reach out to me, you can fill out this form and in general, we want to make every roll up, a ZK rollup in scale Ethereum. And I'm very thankful and grateful to all the work that all the people in this room have done that's really compounded to finally put all the pieces together and make this possible, hopefully this year.
04:22:10.852 - 04:22:11.840, Speaker B: Thank you.
04:22:18.990 - 04:22:55.180, Speaker A: Yeah, the afternoon talks are pretty epic because they're showing that, okay, now that we have the base layer, we can now start layering things on top and move really fast where things that people have told you maybe in the past that were really expensive or slow or expensive in dev time, well, that might be a lie. And maybe we're in this new world where things are getting done very fast, very cheap, and actually get developed very fast. Any questions for Uma? Hey there. Great talk. I'm curious how you see ASICs and FPGA's driving the costs down and the compute down. Like, what kind of improvement factors are we talking about?
04:22:56.040 - 04:23:41.022, Speaker B: Yeah, I think today we use GPU's, and that was a very big improvement over CPU as the proof systems are still very rapidly evolving. The flexibility of a GPU is really nice, so you can iterate very quickly, but then when you have awesome classification, I think FPGA or custom silicon like ASIC could be a huge improvement. And maybe that's where you get the 100 x or 1000 x or something like that. There's a lot of nuance to the hardware. For example, often actually, raw computation isn't the bottleneck, it's memory bandwidth or data transfer, and it's very hard to compete with Nvidia on those fronts. They're a very massive company with a lot of resources. I think the equations actually end up being very complicated and really depends on your proof system.
04:23:41.022 - 04:23:50.350, Speaker B: But there's a lot of great people who are doing work on that, including irreducible with binius. So I'm pretty excited, all that stuff. And we're actively definitely investigating it too.
04:23:50.510 - 04:24:01.134, Speaker A: Thank you. One more question. Hello. I'm curious what you think the roadmap would be to not needing a whitelisted.
04:24:01.222 - 04:24:35.240, Speaker B: Set of proposals for ZK proofing? Yeah, yeah, it's a good question. I think it's probably pretty similar to op's roadmap for getting to stage two. You can have multiple different proof systems, you can maybe have formal verification. I think as these things get used in production more and more, and get more Lindy or fully open source, have more people look at them, they get more secure with time. And so I think it's just a matter of like, time and being actually used in the wild.
04:24:35.620 - 04:24:52.080, Speaker A: Thank you. Okay, last question. Hi, I'm here. Yeah, could you talk a little bit about how the prover network works? What are the crypto economics there? And so on.
04:24:52.780 - 04:25:24.192, Speaker B: Yeah. So today our prover network is kind of a prover network of size one, I like to call it, where we're generating all proofs. We did that just so it's very easy and fast to move in the longer term. We want to have a system where anyone in the world can just turn on their gpu and contribute to generating proofs for SP one. But yeah, today it's very simple. You just send an API call with your program, your input, we generate the proof and then we send it back to. And there's no trust assumptions on it because the proof is self verifying.
04:25:24.192 - 04:25:26.956, Speaker B: So you just verify it yourself and then you can use it.
04:25:27.108 - 04:26:04.960, Speaker A: Thank you. One very last question. So one thing that you mentioned that I did not appreciate in the past is that the new debug execution witness allows you to build the stateless ret node today. That would be a great hackathon project if anybody wants to do it. The question to you is how sensitive is proof generation to the state representation? And like, where do you land on the vertical debate? Because some people say it's more ZK friendly, some people say it's not, they don't believe it. Word for word, where do you land?
04:26:05.860 - 04:26:37.684, Speaker B: Yeah. First of all, Roman, thank you so much for all the work you did helping us with MPT and Stateroot. You are so invaluable. Our team loves you. Yeah. With the verkle debate, I have not looked super deeply into it, although my intuition is that it's actually not that friendly to ZK. The reason is today, catch act is actually not so bad, even in our ZKVM SP one, because we have a precompile for it and we accelerate that hash function with Verkl.
04:26:37.684 - 04:27:05.356, Speaker B: You have. It's over the BLS twelve, 381 I believe, or something. So it's just a bigger field. The evolution of ZK proof systems has been smaller and smaller fields. So the vertical big field is actually not very friendly to that. I think before they do such a big upgrade to ethereum that's so in depth, there needs to be a lot more study of how it will impact its performance in zkvms that no one's really done. So my position on it right now is I don't think we should rush it.
04:27:05.356 - 04:27:10.320, Speaker B: I think we need to do a lot more investigation and it actually might not end up being more friendly for zkvms.
04:27:12.340 - 04:27:42.118, Speaker A: All right, so huge applause for Uma. And then we have hi from the rise team who will talk to us about PevM is high. Where is. Hi. Yeah, thank you. Hello. Hello.
04:27:42.118 - 04:28:20.212, Speaker A: So, hello everyone. My name is Hai, I'm from rise. We are a chain l two focused on chain performance. So pushing geogast per second and transaction per second forward is our jobs. And so I'm going to spam that a lot today would definitely surpass twelve mentions of gear guests. And today I would like to talk about parallel EVM and its contributions to the quest. So essentially, parallel EVM is an execution engine for EVM blocks that maximize throughput by executing transactions in parallel.
04:28:20.212 - 04:28:59.824, Speaker A: It is not the most powerful component in our stack, but it's still a key component regardless to unlock 1 transactions per second. And so traditionally EVM executors just execute transactions one by one sequentially, regardless of how many a no test. And this is obviously like a waste of resources. And ideally we would get something like ten x speed up by executing 16 transaction at once instead. But it turns out it's not that easy. If so, everyone has done it already. And so the main problem to the is the called state conflicts.
04:28:59.824 - 04:29:37.546, Speaker A: And let's see an example to see how it works in practice. So let's say. So let's start with Alice having ten eth. Then in the first transaction he sent two eth to both, and now he has eight left. And in another chance in the next transaction he sent one eth to Carl, and now he has seven left. So this is very simple and intuitive in the sequential world, right? But when we go parallel is got a bit tricky. So if we execute these two search actions in parallel, it would read that at least have ten e both.
04:29:37.546 - 04:30:54.700, Speaker A: And the second transaction would actually think that he would have liked naive afterwards, which is obviously wrong. And the issue would arise every time two transactions try to read and write to the same state. And to solve this, we have block SDM, which is a algorithm designed by Abdos, especially for moviem and their own chain back then. And they solved this problem by adding a multi version data structure that track read and read data per transaction, and by introducing validation tests. So it scheduler scheduled both execution and validation tasks to see if transactions were executed with old data, and if so, it must be re executed with the latest data stored in the multi version memory. So if we get back to these examples, then a validation task on the second transaction will notice that, okay, it was executed with an o balance of Alice. So it would reschedule the transactions to be re executed with eight instead.
04:30:54.700 - 04:31:52.946, Speaker A: And it turns out block STM is not that applicable to EVM off the bat, because like all EVM transactions read and write to the same beneficiary for gas payment. So for example, like in this transaction, okay, sorry. So it was, we start with a beneficial balance of ten eth, and the first transactions just, you know, pay 0.2 as gas. Then it has to calculate this as okay, so after these transactions the beneficiary balance has 10.2 and to the next transaction it has to read like okay, so after the previous transactions it has 10.2 and now we pay 0.3,
04:31:52.946 - 04:32:49.958, Speaker A: now it's 10.5. And this repeats to the end of the block, making the block like fully sequential by definition. And so there's essentially no parallelism for EVM. We just stick to block STM at ease. So luckily I had some weird experience writing production Haskell for a few years, and so intuitively I came up with a very purely functional way of doing things of lazy evaluations. So the solution is like instead of eagerly calculating the beneficiary balance, at the end of each transaction, we simply lazily update restore these updates like okay, I don't care what is the current value is, I just want, oh sorry, I keep misclicking. So I don't care what the current balance is, I would just add 0.2
04:32:49.958 - 04:33:15.307, Speaker A: to it as gap payment. And for a second transaction it doesn't have to read the pre, the current balance at all, just say whatever it is, I'm just going to add 0.3 to it. So we only fully evaluate this at the end of the block or when there's an explicit read to the beneficiary balance. So the full evaluation is still sequential, but it's very simple addition. And so it's very fast. It's still very fast.
04:33:15.307 - 04:34:14.116, Speaker A: Why? With these lazy evolution techniques we can do state loads, EVM execution of co interactions, gas calculation, all of that can still be doing in parallel. And at the end of the day we look at the whole point of block execution that we only want to know like the state at the end of the block and all these intermediary state we don't really care about. And it turns out that gas payment is not the only thing that we can lazy update. And we can do the same for PE transfers or ERC 20 transfers and more. Because if we look at it then for the center of a raw transfer transactions a lazy update would be like I don't care what's the non, the current launch is, we're going to add one to that. And I don't care what the current balance is, I don't need to eagerly calculate that just yet. And I'm just going to add minus subtract by the transaction value plus the gas payment at the end of the block.
04:34:14.116 - 04:35:13.524, Speaker A: And so by that, even if the same sender, you know, have several transactions in the same block with increasing nonch it can still be paralyzed. And same for arc trade transfers which is basically just adding something to the recipient balance and subtracting something from the standard recipient. And it also turns out that EVM transactions have a long q distribution. Basically means that like a few transaction patterns make up for most transactions. So we can detect the patterns and optimize to it with lazy evaluation, lazy updates or any other techniques, techniques we can gain huge speed up. And so we also do a lot of benchmarking for any performance works is a must. And through these benchmarks we can also like detect what are the botnets, what can be improved, especially when we are building on block SDM which was originally designed for moviem which is very different from EVM.
04:35:13.524 - 04:36:31.582, Speaker A: So through this benchmark we can actually see a lot of improvement specifically can be done for EVM. And so the current status that we are two times faster on average, you know, this is like two x speed up over sequential execution for Ethereum and blocks and the max beta result four x. And interestingly we actually have little to no overhead as we fall back to sequential for small blocks and lazy updates actually remove most of the conflict. So this is an improvement over block SDM which has like 30% slow down when a block is very sequential. But if we look at this then it's not that exciting, right? I mean like if it's not ten x or 100 x and what's the point of even talking about this? So we have to move to the next benchmark, which is a giga gas benchmark because our goal at the end of day is to push through EVM throughput forward and you know, to surpass 1 transactions per second and a lot more. And this is like a lot bigger than what is the current traffic on Ethereum today. And we are, so we are benching with very large blocks with hundred thousand transactions and to see how parallel EVM can speed this up.
04:36:31.582 - 04:37:23.121, Speaker A: And it turns out the max speed up we achieved so far is actually 23 x and this is for over 6000 independent units. Twelve transactions that make up to one giga gas. And this, and another interesting number is that this is done in only 18 milliseconds. So this scales up to 55 giga gas per second. Which is not bad I guess. But when we plug this into our own, you know this is, you know this 55 gps is just raw execution speed, right? When we actually plug it into whole block building and sinking pipeline it only scale to not even half of that to only 21 giga gas per second. And this is because like execution, raw execution is still only one half of the bottleneck.
04:37:23.121 - 04:38:14.164, Speaker A: And then the other half, the actual bigger half is on state access. And we need to so that through a lot of the other techniques that hopefully we can share more about in Frontier 2025. But for now let's just bear with me that with parallel evM we can get to 21. Actually if we only apply parallel evM to vanilla Red then it's only get to around 7 GHz/second peak throughput for live blob beauty and syncing. And this 21 is with other improvements that we've done already on the pipelining improvement and also like the status as improvements and of course like okay so 21 gps is like 3000 times faster than the peak speed of average room. But if we look at the slide and there's a big red flag. It's called independent.
04:38:14.164 - 04:39:04.840, Speaker A: So is this even realistic? Like I mean like all these measurements are on independent transactions. While in practice like many uniswap transactions are dependent on the most popular pools. Right? So this is like fantasy if anything is new list. But it turns out that there are already many efforts in the ecosystem to design parallel DF's. Just like when we started to have like multi core machines, people started to design you know concurrent and multi processor algorithms. And I think we are entering the same area and Ethereum is actually lagging behind a little bit. And you can see in these kind of papers then other ecosystem already are designing parallel dapps like sharded automated market makers.
04:39:04.840 - 04:40:02.960, Speaker A: That is promised like five x throughput on SUI and 16 x throughput on Solana. And so I hope that our PvM could help bring all these innovative design and more to Ethereum and od two s to keep EVM contract design cutting edge. But also like not all usage are dependent. So there are actually many usage that are independent by nature. So we've been talking with a project called VM, that is another l two that use we as these cheap storage backend. And they also support da commit transactions for other l two s. And all of these DA commits are independent by default, and so if they plug parallel evm into their node, it would be like an instant x three for nothing.
04:40:02.960 - 04:41:08.756, Speaker A: And so we have been working to put EVM into Rath and there's been a few weeks of work already. And it's not necessarily easy because we need to make sure that parallel EVM works correctly and actually consistently perform well. And not seeing, you know, some edge cases that is much lower than sequential or it actually produce wrong results, then we actually have to fix all of them before confidently running it inside red. And my favorite as case is a block where an MVN bot interacts with contract, then self destruct it, redeploys to the same address, interact with the contract, again own the same block, and our parallel executor needs to know if a address is the contract or not to apply lazy updates rules. And the blocks surely confuse the hell out of it. And so yeah, we still need to work on a lot of testing and benchmarking before we can say that parallel EVM is ready inside Rev. But the overall aim is to at least double or triple the sync speed.
04:41:08.756 - 04:42:08.116, Speaker A: And so one day we can sync ethereum from scratch in half or just under a day. And if we look at this graph, then basically also work in progress. Integration is just slightly above 200 lines of changes because power EVM is essentially just a very simple and I clear interface. You give me a block, I give you back the state transitions and the execution result with that block. And so if we look at this, then yeah, any, also if you use, if any projects are using RevM, if they stack, can just switch Revm over to parallel Evm to get instant speed off with the same interface. And also like, yeah, anyone using red would in the future benefit from this speedup instantly for future plans. So we only started to work on product EVM, I think in early April, 4 months.
04:42:08.116 - 04:43:06.010, Speaker A: And throughout we already seen like four x seven x ten x 13 x 17 x and now it's 23 x for the peak gas buildup. And I don't think it's stopping anytime soon. And we have several ideas to keep pushing the limit. So one of it is already mentioned by several teams is to support an optional DAC, which is a dependency graph for full nodes to sync from sequential faster. So basically like, you know, Dag would say that okay, this transaction depends on this transaction. And so a syncing node with that Dag which has executed all of them in, in the right order so that there would be no conflicts and no re execution at all. And so this is also like very important work in the sense that it helps to keep the footnotes smaller than the sequencer so the sequencers can be buffed up to very performant, you know, powerful and expensive hardware, but the syncing node can stay, you know, relatively consumer friendly.
04:43:06.010 - 04:44:18.962, Speaker A: And also one personal favorite is to redesign the scheduler to minimize synchronization overhead. So I'm actually not a big fan of block SDM scheduler design because all the worker threads kind of share the same atomics, so they kind of like interact with these same atomics every worker iterations and that keep refreshing the cpu cache. So there's always some kind. It's very small, but there's constant latency per worker iterations, which is very annoying. I think ideally we would have like a dedicated scheduler thread that manage all these automates internally and going to put the tasks for each worker thread in their own dedicated memory locations, so that all these worker threads only going to work with their own allocated memory locations instead of having to share. And only in the case of state conflicts do they need to access to the schedule of memory locations to say that, okay, there's some state conflicts, pre revert to the previous transaction index. Other works included optimizing the concurrent data structures.
04:44:18.962 - 04:45:24.740, Speaker A: This includes the email recache for chain state loaded from disk, and also the multi version data structure for the parallel executor. We can also track with JaX points to re execute from instead of re executing the whole transaction when there's the conflicts. And one thing I really really want to try for months now is to try and support more different EVM executors, like just in time compiler that danny I believe, and the paradigms teams ship buyback. So we'd love to try to plug it in and see how it could speed up power EVM even more, get even more gear guests. And the last one is to do a lot of low level tuning. So like memory allocators, like when you optimize to the microsecond range, you know, even memory allocators can make a big difference. And up to now we have been trying like J Malog, Snmlog, mimalog and RP Malog, and the difference is actually very noticeable, up to like 30% to 40% in performance and this add up.
04:45:24.740 - 04:46:40.300, Speaker A: And so we are using PMLlog mainly for EVM implementation, but also we believe that in the future when the allocators API rest, mature and get stable, we benefit even more by hand rolling our own custom allocators for the concurrent data structures, and to have another good one for the global allocators, for the whole node or the program that consumes unused parallel EVM kernel configurations have a very interesting backstory. So I got two weeks ago, I got back from ad con after a week on the road, and I boot up my desktop, excited to get back to work. And it prompted me to update Ubuntu to 24.0. And I was like, I mean like, you know, a fresh start, why not? And then I updated Ubuntu, I updated the rust compiler for a fresh benchmark and out of nowhere there was a 20% regression. I didn't change any code. I mean the machine even had like a one week rest before that 16 hours day just benchmarking hardcore code. And why the 20% regression? And after looking around I found out that is insane.
04:46:40.300 - 04:47:43.206, Speaker A: I think the latest Ubuntu versions, it upgrades the Linux kernel version. It actually switched to a new Linux kernel scheduler as the default kernel scheduler, and for some reason this one is 10% better on average, but 20% worse for computing intensive use cases like parallel EVM. And so we have to roll back to the previous kernel version and I have to just alert everyone in the team to make sure that you have the right kernel version inside your machine and make sure that all the cloud instance have the right kernel version. And of course we cannot just get stuck with this kernel version. I think in the future we need to fine tune parallel evM to work well with oddity or most common kernel configurations, and especially to have the best one for our own stack. And another one is to an arm and XT six or AMD 60. This one is pretty interesting as well.
04:47:43.206 - 04:48:50.890, Speaker A: So I have so my desktop is Intel I nine overclocked at 5.9. It beats all cloud instant I could ever find easily. But for some reason spun up awn is done with graviton three recently and it's like only at 2.6. It's literally virtual cpu's versus my physical cpu's, right? And for some reason the cloud instant bit my desktop at the Giga, the Uniswap Giga gas benchmark. And that 18 milliseconds is actually from that graviton. And so I think that eventually we also need to do all of these low level tuning to make sure we know exactly what is the best configurations and what is the best setup to deploy parallel EVM on at a higher level, like to deploy all these performance nodes on. And so yeah, so we are fully open sourced and the power EVM implementation is fully in Rust MIT license.
04:48:50.890 - 04:49:42.560, Speaker A: And so, you know, let's collaborate. If you have any new ideas, feature requests, collaboration ideas, integration ideas, and or new, new parallel dapp designs, you'll feel free to hit us up. And we're actually also hiring. So if you're interested in doing hardcore low level rust performance tuning works for this and for a new database that we have been cooking on the back, then feel free to hit me up. And again, a great thanks to paradigms and the team for hosting this nice event and you know, building alloy our EVM red and a lot more that could make parallel EvM happen so quickly. Thank you Andrew. Hi, we have a question from Christianity.
04:49:42.560 - 04:50:36.440, Speaker A: Thank you for the presentation. I have two quick questions. One is, is it possible to run this optimization for a whole range of blocks so that, I don't know, you kind of have, maybe you can make the syncing faster. And what kind of gains do you think you'd see for like full ranges as opposed to parallelizing each block independently? And the second question is, I saw that you restart transaction execution from scratch upon conflicts. I was wondering if you can hold the intermediary state in some kind of immutable data structure so that you can resume basically from any program like instruction. Yes, thank you for the good question. So for the first one is definitely possible responsibility.
04:50:36.440 - 04:51:22.274, Speaker A: So I do expect that. So block SDM essentially takes in an input as a list of transactions, so it doesn't really need block headers. So block headers are only relevant in setting things like what is the beneficial account and such. And so we can definitely flatten a lot of blocks and try to run it through parallel EVM for potentially more parallelism. And especially if we look at this, then the intuition so far is that the more transaction and the more workload we have, the more parallelism we can potentially have. Because also, like, I think until now, one of the biggest bottleneck that I want to get rid of is to, is when we join threads. It actually has a pretty long latency, especially in zip rust.
04:51:22.274 - 04:52:11.444, Speaker A: And so I think that if we can do a lot of stuff before we, you know, join the trace and output a execution result, the better. And also that's also a reason why that arm thing that could beat my desktop was because I think arm is very efficient and so it has very low trace overheads and so we can spin up new worker trace and, you know, join them much faster. So definitely that's something we want to try in the future. So, you know, especially for historical things, just buff a lot of blocks together, execute them in parallel. And for the second question. Yeah, so, yeah, it's definitely the first bullet point here. So this is actually, I stole this from the original block SDM paper.
04:52:11.444 - 04:52:54.550, Speaker A: I don't think they have tried to implement that yet, but I think it makes a lot of sense because re executing from scratch is very expensive. We need to rein set up the EVM environment and all these configurations for each transaction. That is very expensive. So we just re execute from the repoi that flag a state conflict, then I assume that be much faster. Yeah. Question here. So, for these future plans, which one of you do you think will be the biggest, like, superboost for real world transactions? I mean, we saw that, like, with independent uniswap transactions of performance already, like, amazing.
04:52:54.550 - 04:53:48.430, Speaker A: Good enough. But for world war transactions, like, which one of these, like, is it a better scheduler other than block S and T SDM or some other optimizations that's gonna take us there? Yeah, that's actually a very good question. So, I actually think that the most probably promising gain of all of these is the first one is to just support, like, optional metadata for the syncing notes or whatever follows to run and execute the transactions in a way that there would be no re executions, no state conflicts, that it would actually speed things up. I think all of the others are more. It's very hard to speculate how much it would, you know, affect real transactions. It could be anything from just 20% or to 200%. So it's a lot of experimenting work required to understand that.
04:53:48.430 - 04:54:42.904, Speaker A: But also, I believe that, you know, the new parallel designs for Dapps would be also required to get the best our parallel evm, because we can only do so much to remove explicit read because lazy updates is a very powerful technique, but it cannot be generalized to arbitrary logic. And so I don't think we can just use the ad hoc techniques at the Apollo EVM level to solve all the apps, and they will actually have to design better, less app instead. Hey, great talk. Really interesting work. You didn't speak much about what? So the evm wasn't ever designed to really be parallelized. Right. I work on l two s.
04:54:42.904 - 04:55:40.530, Speaker A: I'm sure a lot of other people work on an l two would be open to adopting l two specific EVM extensions. So if you could pick one or two things that you would change in the EVM to enable more parallelism through the sorts of techniques you're using, what might they be? I know this is hard to take but I would switch to another VM incrementally. Well, it's pretty hard to say because I still believe that most state conflicts at the app level. So it depends on the application's logic. So as we can see with the previous example of we VM, they use case are all deep. You know, all transactions in the DA commitment uks are independent by nature. And so you know, we don't need to change EVM to get the max parallelism level out of it.
04:55:40.530 - 04:56:26.408, Speaker A: But yeah, I guess like a low hanging fruit would be, you know, to remove, to modify the gas payment mechanic because as you can see, this lazy technique can get that through. But there's still a cost at the end of the block to fully evaluate these sequentially. And it does add some tail latency to the block execution result, which is very undesirable. So I would change that to first, another idea is introducing increment opcode which allows you to get around the slow dad store pattern that happens. Yeah. So basically providing more opcodes for Dapps to design better or easier design parallel DF. That would be very helpful.
04:56:26.408 - 04:56:51.568, Speaker A: Yeah. Okay. Yeah, one question there, one from zero edge and we wrap. Yeah. Two quick things the system described reminds me a lot of like a lazy Mapreduce. Have you looked into doing more dag based approaches to scheduling work based on like what slots are accessed? Yes, certainly. So we are.
04:56:51.568 - 04:58:07.174, Speaker A: One of another component in our stack is a customized mempool that do some pre processing of the transactions to, you know, do statical analysis to detect dependency. But this only applies for blockbuilders. But at least for blockbuilders with this technique it definitely helps by reducing the state conflicts file at runtime, which is a lot costlier after that. Then the blockbuilders can pass on the blocks with this DAC that it already builds to the syncing nodes. Yeah, I feel like that's like a really promising avenue, but, and then the second question I had is in the, how much of a speed up do you have in blocks where you have transactions that actually end up all affecting the same contract? Like in like pragmatically you oftentimes see blocks where it's like all transactions being a swap on a uniswap pool or like a mint on an NFT. Is it, it's one x or is there like, does doing it lazily actually improve it from one x? Yeah, so lazy is not very easy to generalize. So it really depends on the actual applications.
04:58:07.174 - 04:58:52.770, Speaker A: So your ideally application would just redesign in a way that reduce share states between the transactions. So that would help a lot. But yeah. So until then, until we have that, then we are would be happy to have, I'm sorry, just you know, one giga gas per second on average. And having this 21 giga gas at the peak that we aim for and eventually we push the average towards 21. This is not like from parallel EVM alone, but from the whole ecosystem, you know, pushing these new parallel design forward, working together to achieve this. And hopefully by the time we have the average case 21 GHz/second we would start to see, see like new cases that actually reach one tera gas per second.
04:58:52.770 - 04:59:27.006, Speaker A: Speed up. Yeah. All right, last question for zero age and we can wrap. Hi. One concern. With block production being sped up, I think on the sync case it's obviously a big win across the board. But in block production, if it's faster to produce blocks then there's a danger of producers just withholding the block production to gain more mev.
04:59:27.006 - 05:00:18.370, Speaker A: How do you see the MEV issue slotting in with parallel execution and other techniques to accelerate block production or potentially even exacerbating certain issues? That's also a very good question. I think this is harder to solve for l one or existing blockchains, but I think at least for us, the more we get, the more throughput we get, the lower block time we can push down. So like, you know, of course, like you have more power to build different blocks but now you have less time to do so. We try to reduce the block time to improve the UX, but also like to, you know, make sure that the best block is built on time and no holding back there. All right. Uw. Hi.
05:00:18.370 - 05:01:08.230, Speaker A: Thank you. Okay, so this is the end of the beginning of the day or the end of the talks part of the day. What's going to happen from now is that we're going to start flipping the room. So I'm going to ask everyone in a second to stand up. We're going to start from the left side of the room to the right and replace all the chairs with tables both here and outside. And basically for the people that stay, the expectation is to enter work mode and hack. Big shout out to our events team for making this happen, our design team for giving everyone very nice flag to cursive for this nice social experience to the speakers that worked extremely hard to get this done on a very short notice.
05:01:08.230 - 05:01:23.070, Speaker A: And we hope to have a great day for the rest of today. Please feel free to hang out until I think we have it around until 08:00 p.m. and then tomorrow we will reconvene at again the same time. Please make sure to bring your cards. Thank you all.

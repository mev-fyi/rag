00:00:00.160 - 00:00:13.430, Speaker A: The previous talk and let me just try. I don't know how that works. Oh, I probably just broke something. There we go. I guess that'll do. Cool. Let's get started.
00:00:13.430 - 00:00:39.864, Speaker A: So, yeah, you pretty much saw this diagram just in the last talk. One piece that was missing, that is actually quite important is a boost here. Let's see if. Okay, there we go. Like a big spotlight, but yeah, so you have the cl over here. This is driving our view of the consensus of the chain. The execution client metboost is this multiplexer component that interfaces between the proposer and the relay.
00:00:39.864 - 00:01:06.410, Speaker A: The relay is here and then the builder is over here. Actually, this is going to be better now. Yeah, so you can see this whole pipeline. And if you're here, you probably have heard of mev. This is like a take on the infrastructure, how it looks today. We have this flavor of like off chain PBS, and these are kind of the main pieces today. Even in the last couple of years since the merge, this picture has actually gotten way more complicated.
00:01:06.410 - 00:01:39.902, Speaker A: There's searchers, there's solvers for different applications or various off chain things. With respect to the l one, there's account obstruction. So then you have the bundlers there and all the players in 437 landscape. And. Yeah, point being is, if you didn't know over 95%, you know, it fluctuates, but say over 90%, even up to like 95% of all blocks on Ethereum are built through this pipeline. So it's quite important. And let's see the next slide.
00:01:39.902 - 00:02:31.128, Speaker A: Yeah, so because of, again, how critical it is to the lock building process on Ethereum today, it's super important. We want to make sure that there's like a, a stack of software, and this infra layer is very secure, well tested and robust. So as you can probably guess from the picture you just saw, there's a lot going on, many different actors, they all have to be coordinated in exactly the right way. And importantly, if there are security issues at any point in the stack, bugs or things like this, people have a bad day. There's the builder, the relay, the validator, and by extension then users. So if there's a bug, say, in the relay, and they can't really the block, that's like a whole missed slot, we would call it for the whole chain. And what that looks like for the end user is, you know, you have to wait twice as long, let's say, to like have your transaction be confirmed.
00:02:31.128 - 00:03:15.740, Speaker A: And that's just very not nice. So what can we do about this? Given its importance, and it's like centrality to the stack. Security is like the top concern. And, you know, one sort of, you know, I'm calling it here, security posture. Like something that we usually do in Ethereum land is think about implementation diversity, or like client diversity. And the way that this whole off chain PBS with mebboost started, flashbots seeded the system, and it's very exciting that other people have joined to help build it out as well. So this is a talk on mevrs, and essentially it's a rust repo that has implementations of these three key components, the mapboost, the relay, and the builder.
00:03:15.740 - 00:04:03.310, Speaker A: So what's cool on here? Yeah, I mean, check out the repo, I guess a cool thing for us here. It's like pretty much all in rust. You'll see there's a little bit of nics that's just like a side hobby I have. I do a lot of immutable deployments and things with Nixon Nixos, which is super cool, but that's a whole different talk. So, yeah, why mevrs? So, one way to think about it, at least this is where I started working on it, was just as like very much like an experimental toolkit. So it can be useful for prototyping different ideas or features about improving or hardening this pipeline. Reason about protocol changes, something we did a few months ago, in the last year at least, was change how withdrawals should formally work.
00:04:03.310 - 00:04:37.864, Speaker A: Part of this whole process is that you have builders making blocks. They then submit some bid, which is going to be probably different than the actual value in the block. And this then interacts with the consensus layer. A big thing here is like validator withdrawals. And so something we are seeing is that if you had a payment, let's say, to the proposer, and the proposer also was like withdrawal and ETH at the consensus layer in the same block. Many of the ways that relays and builders were computing the values to bid would include these withdrawals kind of by accident. Like, the withdrawals has nothing to do with the sort of mev in the block.
00:04:37.864 - 00:05:21.536, Speaker A: So that's kind of just a bug. And, you know, having sort of this like, playground to experiment with these ideas is really helpful, because then, you know, it just provides some way to, like, ground the thinking around. Okay, if we exclude withdrawals, like, what does that look like? How does it impact things? Stuff like that. It's also helpful for, like, hard fork testing just to have, like, again, a full suite of the stack. There's many things like, as we go from like, okay, all the eips we're thinking about to actually like, deploy, deploying them in mainnet. There's a huge process to get to that final endpoint, and a big part of this is testing all the pieces together, interactions between various vip's. And then as we do change the protocol, there are direct impacts on this builder API, which is, again, this interface.
00:05:21.536 - 00:06:21.380, Speaker A: Maybe I'll just go back really quickly. This interface, I broke it interface here between the validator and the consensus node, and boost itself. There's a specification of how this should work, and basically anything we do over here that changes how the chain looks is going to impact this component and vice versa. Another thing to note is there's quite a bit of other rust software that I have, again, sort of focus on the consensus layer and things there. So one thing to point out is a lot of mavrs uses these two dependencies. I have a repo ethereum consensus, also SSD Rs. So ethereum consensus is essentially an implementation of the consensus specs and rust, and similarly useful for prototyping and reasoning about different features of the protocol.
00:06:21.380 - 00:07:04.398, Speaker A: There's also an SSD library that's a serialization format that has a mercallization scheme built in. It's sort of the core primitive when thinking about any consensus data type. So helpful for all of those reasons. Another thing was to directly address this lack of implementation diversity. So, like, kind of, as I was pointing to a minute ago, especially like in the earlier days, there was sort of just some initial implementations, at least, that were open source by flashbots, and otherwise, there wasn't anything out there, at least that was open source. So the flashbots implementations were in go. I like Rust a lot more, as many of you probably do.
00:07:04.398 - 00:07:43.100, Speaker A: And it was like a natural choice to be like, okay, yeah, we can kind of like kill two birds with 1 st by having like a nice rust stack. Rust has this tagline like performance, reliability, productivity. Pick three and you can clearly see how that plays very nicely with something like, again, securing this very critical part of the protocol today. That being said, the community has grown a lot, even since I started working on all this stuff. Ultrasound, ultrasound relay project has stepped up and been doing a lot of relay. You can go to the repo there, and you can see a lot of open source, also rust software. They have around different parts of the stack.
00:07:43.100 - 00:08:34.440, Speaker A: And we just saw this talk on our builder, which is a fairly new effort by flashbots to take a similar view with respect to the builder and importantly, open source. This was another key point was that because of the way MEV works, it's like if you have some edge or some alpha against your competitors, you're very incentivized to not talk about it. What that means then is if you're a more sophisticated actor, because say you're a hedge fund that can afford really less expensive devs, it's really hard then for new entrants to come in and enter into the fray. So the issue there then is bearish entry around this process. And yeah, open source is good. You could imagine that it would help the sort of market structure. I mean, another key point here is there's essentially only three top builders, which is like an incredibly small number.
00:08:34.440 - 00:09:10.788, Speaker A: And that's bad for other reasons that we don't have to get into now. But basically the way to think about this is the more the merrier. And one way to start to address the market composition is just by reducing bearish entry. So let's just walk through some of the components. This is just like a screen cap off GitHub. And yeah, basically there's again a matteboost implementation, which is this multiplexer I'll get into in a minute, a builder and a relay. There's this Mevrs library, which is just a catch all for various common utilities and things like that.
00:09:10.788 - 00:09:56.530, Speaker A: And then there's a binary to tie it all together. So we're going to look at each of these three in turn, but essentially they all are ready to support Deneb, which is the latest hard fork we have on Ethereum. There is some early work on Electra, so let's look at these pieces now. So the first one is Metboost. And yeah, essentially how it works is you go to buy a block from a builder and what that ends up looking like is you talk to these relays, you can generally be connected to many relays, and then you get bids. When you go to sell your block space as a proposer, you need to pick, presumably the one that pays you the most. And then what that looks like is you get, say, a set of three, four bids.
00:09:56.530 - 00:10:24.016, Speaker A: You need to pick the highest value one. So metaboost is just this component. It's pretty lightweight and essentially just performs this selection process for you. And yeah, it actually, if you look, it's really not much code. The core thing is really just getting the bids at the right time and picking the most valuable one. Okay, so next, the builder. You'll probably see a lot of overlap with the r builder here.
00:10:24.016 - 00:10:46.500, Speaker A: I mean, I think there are a few different design decisions that we've taken so far. But generally a builder with Reth and. Yeah. So let's take a look. I guess one sort of, I think from what I understand so far, the biggest difference is actually. So this builder has a node extension to Ruth. It just builds on top of Reth as this very modular, almost collection of libraries.
00:10:46.500 - 00:11:11.842, Speaker A: It just sort of extends the execution node in a way to do the MeV boost parts that a builder needs to do. So the key thing is leaning on this payload builder abstraction. That's super awesome. Shout out to the rest team for that. And the payload builder is tasked with actually crafting the blocks. Right now, the builder just uses transactions in the mempool. So you look at the mempool and just build a block from what you have there at the time.
00:11:11.842 - 00:11:58.078, Speaker A: You need to. There's this component, this notion of an auctioneer, which is doing a lot of the organization and coordination around all the different timings and when to build blocks, when to submit blocks and things like that. There's also a bidder component that. The idea at least is that you'd have this bidder that you could write your own custom bidder. How it would work is whenever there's a block made by the payload builder, the bidder would see this. Say you would see, ok, I built a block for one eth, and then the question is now, ok, when sort of how much value do I want to keep versus give to the proposer, and when do I want to make that bid? And how this kind of works is, let's say there's a new slot and now a new proposer is going to make a block. You could have many payloads.
00:11:58.078 - 00:12:44.698, Speaker A: This really should be a continuous process. Then you can in turn imagine this bidder is also this dynamic, very continuous thing as well. The bidder then can in turn, for example, look at the different relays that it's aware of, and then you see different competitive strategies between different builders, because I can actually see what other builders are bidding in real time and then use that to inform my own strategies. So, yeah, this might be a little hard to read, but going to do a bit of a code walk through the builder and just kind of demonstrate how it extends RotHdeh. So the place to start is this payload service builder, which essentially ends up building a payload service. And this is the piece of reth that handles block construction within the El. And, you know, it does this stuff.
00:12:44.698 - 00:13:17.250, Speaker A: I think there's also great examples in the ret repo itself around how to do things like this ultimately you end up with. Right. So this is essentially like the abstraction that you can sort of implement to customize this behavior. And it has a bunch of stuff, but you can't see that. Okay, sorry. Ultimately, there's a custom payload builder that this repo has that sort of. Yeah, it's the place to implement all the different, like, logic you would need for the Met boost auction itself, which I'll touch on in a minute.
00:13:17.250 - 00:13:50.820, Speaker A: Importantly, like, for example, there's a signer that's passed in because there's a way that you need to like pay the proposer in a particular format. So then the builder then has a balance they're aware of and then a way to make transactions to pay the proposer out of that balance. There's a fee recipient for the builder. So again, if you had a searcher submit a bundle, there's a way to say, hey, this is how you should pay the builder. Yeah, you can't probably, yeah, you definitely can't see that down there. I'm sorry. But there's also a reference to the bidder that gets passed in.
00:13:50.820 - 00:14:18.310, Speaker A: Okay, this should be better. So. Right. The payload service builder is the thing we're just looking at. And then ultimately it gets passed into this node builder type, which if you've extended breath at all, this is like a pretty. Yeah, you should be familiar with this. Basically, there's a way to like take the default execution clause that Reth provides and customize it.
00:14:18.310 - 00:15:02.232, Speaker A: And there's like different, I mean, it's actually very flexible, but you can have like different nodes or, sorry, different types and then different components in the thing. And in this case, we just want to customize the builder component with the payload builder. And then otherwise there's a way to like sort of asynchronously launch the other components like the auctioneer and bidder to tie everything together. And. Yeah, I was just going to highlight that this is, again, the other side of this channel to reference from the bidder to the payload builder. The code is a little split and I could just put these screenshots. So again, if you're curious, I can show you after a bit more of the structure and the code itself.
00:15:02.232 - 00:15:44.426, Speaker A: But ultimately, you could imagine setting up the payload builder with the RET extension and then going to this part where then you wire these other components together, again having a reference to the payload builder, the bidder. And yeah, there's a bitch in there. So that's a flavor for how some of the code looks just like actually extend. Ruth, let's walk through high level how this works. The first thing this is driven by is a fork choice. Updated notification from Ruth so the way that you run nodes on Ethereum today is you have a consensus node and execution node. And so when there's essentially a new block and it's part of the consensus, the consensus node knows this.
00:15:44.426 - 00:16:23.890, Speaker A: It tells ref which Reth then needs to update its head. And the way this is customized is then this notification gets dispatched to these various components within the mevrs builder. When you see you have a new head, you now need to figure out if you need to build or not. And there's information in the fork choice along with some other information you get from say your consensus node to know who the proposer is. And then more importantly if it's registered with different relays that you're connected to. So you do that. If so, there's also some preferences that validators have when they register, for example their gas limit that they would prefer for the block and then also the fence, which is how they should be paid.
00:16:23.890 - 00:17:05.240, Speaker A: And if you find some of these, you start building. If not, you can just ignore this particular update and just wait for the next one, say 12 seconds later. So if you do need a build then for each proposer, because actually you could have multiple proposers just given the way the consensus works, then you want to start building payloads. This is where the core ref machinery kicks in. You pass in this metadata around what the proposer wants the block to look like. And essentially for every block that the payload service builds, it sends to this bidder. The bidder in this way I was talking about a second ago says ok, for a given bid, how much do I actually want to pay out? When should I submit the bid? And it does all that.
00:17:05.240 - 00:18:08.400, Speaker A: The bidder then sends the notification to the builder again at the right time to say, hey, go ahead and finalize this payload with say, this value, this payment. And then that ends up getting back to this auctioneer component that then sort of puts the block in the right format and submits it via the right APIs to each relay. So the cool thing here is it's built on Roth. It's fast. I don't have benchmarks, unfortunately, but I've been using it in various devnets and testnets and it works, I think from, well, I know from the experiments I've done that there can be quite a dependence on hardware. But assuming you can toss enough hardware at the issue, it can actually handle quite a number of different auctions and parallel and you've heard this many times now, so it won't be a surprise, but the biggest bottleneck that you quickly run into is just computing the state route for the final block. It's a quite heavy computation and there were talks yesterday, if not also today, around this problem in Reth.
00:18:08.400 - 00:18:57.130, Speaker A: Quick shout out again to the Reth team. They've been super helpful around like iterating with APIs, just answering questions and being available, and also just very open to feature requests and things. Something that might not be clear, but is definitely part of this problem domain is that you might actually want to very iteratively build the block in terms of even just the APIs. So rather than saying hey ref, go build a block, you say go build enough of a block that I can see how much mev is in it. And then I want to turn around and say bid this much because that also needs to be a payment transaction in the block itself. There's things like this where you can imagine extending or hardening these ret APIs. And yeah, the Reth team has been super helpful helping me understand and also just responding to requests like this to keep the shout out going.
00:18:57.130 - 00:19:28.540, Speaker A: Yeah, all this is built on top of rhetor. This would not be possible without an execution client. And in particular the fact that Reth is so extensible and modular, it makes this like super nice and easy. It also uses ally in a few places. Like in particular, I used alloy signer just because I needed a way to sign transactions and it seemed like a really simple, nice way to do that. I've even used foundry more for just making ephemeral wallets on these different testnets and things, and using that to fund the builder, move funds around, stuff like that. So nice work.
00:19:28.540 - 00:20:08.506, Speaker A: Okay, we'll touch on the relay. This is the last big piece and the relay component, it kind of sits in between the builder and the proposer. And the idea is builders are basically spamming related blocks. They have to figure out which blocks are valid which conform to the method auction rules for those blocks. They then can expose them to the proposer via these builder APIs. Just as of today, I would say this is the least developed part of the whole suite in MevRs. The way that it works now is there is essentially this trusted builder idea where essentially it only takes block submissions from hard coded builder pub keys.
00:20:08.506 - 00:20:45.560, Speaker A: And this is basically just because I don't have to then think about implementing block validation. So in short, it means built with the MeV builders. A key piece here is like payload validation in terms of like, hardening this out into something that looks more like the production relays we see today. And like, the Roth node extension strategy went so well with the builder. I really want to do this with the relay a few months ago. That's probably changed. So if you're interested to contribute, that would be a place to start.
00:20:45.560 - 00:21:03.310, Speaker A: And yeah, status, it works. Super awesome. Here's a tweet. There's like two blocks from sepulia. And yeah, it's super cool. So that's it. There we go.
00:21:03.310 - 00:21:33.250, Speaker A: DM's are open. Here's my Twitter page. And yeah, I would love contributions. I try to mark good first issues. It's tricky sometimes because the ret APIs are, they've gotten more stable in the last couple of months, but they were also changing as I was building some of this. The foundations in terms of how I think the builder or the relay should be structured in this repo, we're also changing. But yeah, if you're interested, please reach out and we'll try to find a nice way to contribute.
00:21:33.250 - 00:21:36.770, Speaker A: And otherwise, I'll take questions. Thanks.
00:21:50.430 - 00:22:29.632, Speaker B: Hey, great stuff. So you touched on this near the end. Looking at it from the perspective of a proposer, it is kind of scary to be signing a block where you don't know what's in it. Right. If it's an invalid block or something, you're out your slot. That's bad for everybody. What do you see as ways to incentivize building new relays or what's in your view and the broader view right now, more long term solutions for that issue?
00:22:29.816 - 00:23:10.200, Speaker A: Yeah, this is tricky. And I think a lot of the pain point, I think there's many ways I tried to address this. This was one way, was just even, say, a year or two ago, just be like, hey, actually have nice software that people could use. And yeah, like what you're really getting at is the fact that these are all public goods, at least like the relay in particular, and like more the consistent software with Medboost and things like that. And funding public goods is very hard. If you have a nice silver bullet, many people in this room would love to hear it. Yeah, there's like various efforts around like making some sort of dialect structure for relays, and that's when we fund them.
00:23:10.200 - 00:23:56.050, Speaker A: Otherwise, yeah, generally how the relays work today is they don't have any profit. They essentially operate at cost, or they're just operating out of pocket. It's tricky because if you were to have a for profit relay, then you essentially be out competed by the other relays that wouldn't charge. But at the same time you could imagine value add services around a relay and there's a whole bucket of things around customizing the actual type of the block. You could say, as a proposer I want to do, maybe I want a block that I don't know. Oh, there's many things you could imagine, but there's things around customizing the actual contents of the block that the relay is positioned to implement. And this could be something to add.
00:23:56.050 - 00:24:12.110, Speaker A: I guess. To give you one example, you could imagine something almost like pre conformations or things like this, where it's not just the contents of the block, but extra semantics on top. Wherever, you know, you could imagine a relay doing this and this is now something that they could actually charge for in like a sustainable way.
00:24:16.770 - 00:24:42.550, Speaker C: What do you think of the people are usually taking relays for granted because relays is usually like one single point where people trust in Ethereum ecosystem, especially like for like pre comps and stuff like that. Like people are proposing protocol at which you like delegate, like block selling on the relay or stuff like that. What do you think of this evolves of research.
00:24:44.570 - 00:24:45.978, Speaker A: With pre comps in particular.
00:24:46.114 - 00:24:54.266, Speaker C: Or, or anything in general, just people taking relay security for granted, thinking that they run on te or whatever.
00:24:54.418 - 00:25:25.800, Speaker A: Sure. I mean, I don't know if people take it for. Okay, they do take it for granted until for some reason, you know, they, let's say they're like a solo staker, they have a few proposals a year, and suddenly they wake up one morning and they thought they had a blockland, but the relay failed for some reason and they found out they missed their proposal. Like, this happens to people naturally. They become very upset. So, yeah, it's a thing where people don't realize it's an issue until it happens to them, which is not good. And yeah, I guess more on like the precomps point.
00:25:25.800 - 00:25:43.040, Speaker A: Like, again, generally I support experimentation as long as it's sort of safe in the right way. So, yeah, I think we could see a lot of things evolve around, like things that improve ux or again, like features around like how blocks were built in Ethereum that are valuable to people. And yeah, maybe you could start to address some of these sustainability issues.
00:25:54.830 - 00:25:57.078, Speaker D: Looks like that's it. Thank you, Alex.
00:25:57.134 - 00:25:57.850, Speaker A: Thank you.
00:26:03.070 - 00:26:12.170, Speaker D: Okay, next up we have Ludwig and Will from Cirella talking about Brauntease, how chasing MeV led to a general purpose blockchain analytics engine.
00:26:14.790 - 00:27:11.650, Speaker E: Hey, Chad. Today we're going to be presenting brontes, which is basically the endeavor of us chasing systematic MEV detection. And in doing so, realizing that we ended up building somewhat of a general purpose blockchain analytics engine for Ethereum and all L2s that are based on the EVM. So why brontes? Um, we're not masochists. We have dealt with trace data in the past. Classifying it, pre processing it, normalizing it is just absolutely painful. And personally, we don't really like that step, as opposed to the interesting analysis that we far prefer, like focus our time on.
00:27:11.650 - 00:28:32.920, Speaker E: And so Bronte's really the main initiative is to reduce all of that work, ensure and streamline the entire pre processing portion of the work so that you can jump immediately into the analysis portion without having to worry about how to decode curves 56 pool implementation or how to implement discovery. For a factory that produces 15 different contracts at a time, all of that have been such a significant bottleneck. And this was really aimed to completely mitigate that. The other thing is that we're working on MeV, we're working on minimizing it. And although everyone and their mothers love to chat about MeV, unfortunately we don't have that good data today. There's great research on the validator payout side, there's great research on the research on the timing game side, but in terms of data on systematically identifying actual MEV transactions and providing accurate kind of p and l statistics, we haven't seen that much. And on top of that, there isn't really an open source place where we can all kind of participate and contribute to the discussion on how we want to classify, how we want to improve the taxonomy.
00:28:32.920 - 00:29:37.032, Speaker E: So what you end up needing to be able to do, this is basically akin to a feature complete block explorer with extra steps. This is something we didn't necessarily realize in the beginning, but we kind of pushed through painfully. So you need to be able to decode and classify these complex, defier interactions. But the very important thing here is that you have to normalize them so that you can operate on a unified type, so that when a uniswap swap or a curve swap happens, you don't have drastic different data representations. The other thing is that you don't want to lose the context that you gain from operating at the trace level, because when you're operating there, you have the core frame hierarchy, and then you can use that to infer many different things. So in this normalization and classification step, we really wanted to maintain that level of context. Then the second thing is that you're going to need a lot of off chain data for this.
00:29:37.032 - 00:31:03.280, Speaker E: So you need an efficient way to store it, an efficient way to read and write to it. One more complicated thing is you need prices for almost every single token and you need them at a transaction level granularity, because if you're looking to accurately price a sandwich, if you're looking to accurately price an atomic arbitrage, you can't depend on Coingecko's API. And trust me, like we initially tried, their rate limiting is also just not conducive to how blazingly fast brontes is. And then the last thing is you need extensive metadata on addresses, on contracts, also just more simply on builders and searchers because you can't really accurately compute the p and l because the interactions in a lot of these searchers, between the searchers and builders are quite complex and are not straightforward, where you'd basically mark out a bundle as negative in p and l. If you didn't know about the special deal that the builder and I, the top searcher had, or the fact that Manta builder, which was Jane street or another unknown builder by the name of Beaver, would actually send all of their profit directly to the builder. So the searchers would look unprofitable. You need like that global context, because otherwise you just can't have accurate numbers.
00:31:03.280 - 00:31:45.040, Speaker E: There we go. And so putting all of that together at the high level, you can think of the pipeline as we have a block, we're going to trace it, we're going to build the tree where we do the classification and normalization. And at the same time we're going to fetch the metadata. And then after all of that, we've collected the necessary data for our analysis and we can operate our inspectors. So to collect and normalize actions, basically what we use is a custom retracer that matches logs with the call frames and then a macro system that provides a really clean interface. We'll tell you more about it.
00:31:50.020 - 00:32:09.896, Speaker F: All right, so to start, what we basically do is we collect all the traces in the transaction tree or in the block, of course. And then for each call frame, for each transaction, we go through, through a process, click the next one.
00:32:10.008 - 00:32:18.288, Speaker E: Yeah, I'm going to try and point out. So here you have the individual transactions and then they get processed at that point here.
00:32:18.344 - 00:32:52.170, Speaker F: Yeah, right here. So if it's a call, it goes over to our protocol classifiers that will be on the next slide. And if it's a discovery, it goes over to the discovery classifiers. This also will trigger a pricing update which then says, hey, this call frame used. Well, if this is an ERC 20, we need pricing at this exact transaction index in the block. All right, I think we skip this one.
00:32:52.470 - 00:33:21.500, Speaker E: Yes. So this very similar. Basically, the protocol classifier is just a dispatch that you do on an address that is labeled as being part of a specific contract or slash protocol. So for example, Uniswap v three would be labeled as Uniswap v three protocol. And then we'd have the function call as the additional portion of the match key that enables us to match against the specific function and then decode and then classify the data.
00:33:22.040 - 00:34:08.242, Speaker F: Yeah. So for this, we built a macro. The goal of the macro was just to simply abstract away and give just a really clean interface for dealing with all of these unclassified types and call data. It's kind of very messy in the back end if you, for every single one, are doing all this decoding manually. So we thought it'd be nice and clean to put it in this. So basically, all you have to define is the path to the protocol module, the path to the alloy function call type, log type, and what you want your closure that actually does the logic behind it to be passed in. So here.
00:34:08.242 - 00:34:39.799, Speaker F: Oh, there we go. Okay, so here is what a uniswap v three mint call looks like. Oh, keep breaking it. All right, there we go. Yeah, so you can see here, protocol, and then the mint call, that's just the first two entries are basically how we create the key that people match on the action. Type the log that you want. And for here, we just want everything.
00:34:39.799 - 00:35:28.710, Speaker F: So with that, you can see, I mean, it's probably twelve lines of code right here, just reading from the database to grab protocol info. Take the deltas, return the mint. It's really that simple for pretty much all protocols except curve. And then on the flip side, we have the discovery. So it's another macro surprise. We have the create pair call, and then just the factory address. And I mean, this is even more simpler, right? It's just take the two kokens, name the protocol, insert into the database, and for almost all of the discovery we have out here, it's this clean, which is really nice, and it's super simple to test as well.
00:35:29.010 - 00:36:58.652, Speaker E: And the nice thing is, so as soon as a create pool is effectively discovered, that gets stored in the database, and then any time that there's a function call to that contract will then run the action dispatch, which will classify the underlying swap or mint or burn or whatever interaction. So this is really like an extremely zoomed out overview, because it would take an hour to present fully on this, but I think this is probably the most complex portion of the entire project. So basically, the main problem is that you can't afford to load all of the state of all of the pools. If you want to be as comprehensive as we were trying to be. And you need to find a solid enough proxy to be able to identify what the optimal route is so you can mark out an instantaneous price at that specific transactions index in the block. So what we did to simplify, and again, not perfect and very much room for improvement, is we use a global token graph with the connecting pools as edges for the token nodes. And we use that connectivity as a proxy for liquidity, which enables us to build subgraphs that are more focused where we can actually afford to load all of the state for each pool and then compute the optimal route and then identify the instantaneous price.
00:36:58.652 - 00:37:25.706, Speaker E: And so we're able to price basically any token that is on uniswap v two, v three swap. We started incrementing curve. We have, like, we don't have the willpower for that. So if anyone wants to take that on, that would be great. Thank you. Yeah. And then the separate portion of the data that you're actually provided is the block metadata.
00:37:25.706 - 00:38:14.298, Speaker E: And this is a really valuable portion where you store all of the data that we could possibly think of could be useful in the analysis of any financial interaction. So you have the relay data, the builders, the bids, the fee recipients, the builder metadata with connected searchers. So what searcher addresses are vertically integrated with Beaver? What searcher addresses are vertically integrated with Rsync? Basically any form of metadata that you could think of on the builders, even their ip locations, but we're not sharing that. And then you have the address metadata. So labels from various providers. Then you have the labeling from private transactions. Huge shout out to chainbound for that.
00:38:14.298 - 00:39:08.658, Speaker E: Thank you. You guys did an amazing job and made it super easy for us. And then you have the propagation time for the blocks. And the biggest portion of the data are all of the trades and quotes for 95% of the pairs across the top five crypto exchanges. So to inspect a block, now that we have all this data, now that we have this classified block, we can move to the interesting part where we provide the block tree and block metadata that I mentioned right before, and we pass it into the individual inspectors that all run in parallel. And so those individual inspectors then produce their results. And there's a final processing step where we can compute the final block P and L and also de duplicate the results.
00:39:08.658 - 00:39:59.010, Speaker E: And this is one of the surprises that we had while building this, is that if you miss out on the de duplication and filtering step, you're not going to be able to label things accurately because the MEV can look exactly like another type of MEV if you're not able to filter it out. So say, an atomic arbitrage and a sex dex trade. The atomic arbitrage is obviously getting an advantageous rate. If you aren't able to identify that as an atomic arbitrage and only run, say, a sexdex inspector, well, then now you're labeling it as Sexdex. So that is, like, super important to de duplicate. And the funner part in the processing is actually the composition where you can take JIT attack and then realize that it's actually JIT Sexdex. Or you can take a JIt and a sandwich and realize that those are actually the same bundle.
00:39:59.010 - 00:40:04.070, Speaker E: And so then you can kind of compose these more, these simpler mev types into complex types.
00:40:06.220 - 00:40:36.606, Speaker F: All right, so we started off with this whole thing as mev, mev, mev, but then we realized, as Ludwig mentioned in the start, that it kind of is applicable to anything. So to, so, like, if you wanted to build an inspector that just did something super simple, this is all you need to implement, right? It's just, you define what block window you want to look at what you're going to return as a result and then just write your code.
00:40:36.638 - 00:40:36.878, Speaker G: Right.
00:40:36.934 - 00:41:22.252, Speaker F: So no picture again. There we go. All right, so, and then at the higher level, right, we have these things called processors, which is just a collection of inspectors processing that generate the same result. So all you need to do is implement your process result function and then create your config, right. And you pretty much can do whatever inspecting you want, any analysis that you want. All of the complicated actions are just all hidden away. So it's super easy to build whatever your mind can think of really and.
00:41:22.316 - 00:42:26.820, Speaker E: Quickly to touch upon, like the block window portion. So that's a feature we actually very recently added. But to explain this basically enables you to say, okay, I want five blocks in a row directly provided as data. And so this is something that we haven't used that extensively in the code base yet, but is super useful if you're trying to build, say, ev intent inspectors that look across multiple blocks and see transactions in previous blocks that are a signal for a statistical sandwicher that is going to look at approvals on token contracts to then front run transactions. And finally, it's blazingly fast, at least kind of. Again, we don't have benchmarks, but it runs in two main modes, historical ranges, which are broken up into chunks, and then those individual range executors will all run in parallel. And then at the same time we have a tip inspector that is specialized to follow the tip of the chain.
00:42:26.820 - 00:43:36.536, Speaker E: Then in terms of futureworks, we'd really love to see support for l two s. You don't have to do that much for Opreth, for example, you have to do a tiny bit of a refactor on the discovery and just update the address book to match the latest chain. Then we'd love to improve the MEV inspector methodologies. Sextext is always going to be an estimation, but the closer we can get to that the better. And also in terms of long tail MEV inspection analysis, it's very hard to filter out a lot of false positives, but with a decent amount of work, I think we could get something really compelling. And then eV intent inspectors are really high on our roadmap cross chain MeV inspectors, although I am still strongly of the belief that this is shared sequencer Siops, but I'd love to be proven wrong. One other kind of very off topic feature that we'd really love to see is a taxes feature with brontes, because you have all the transactions, you have an ability to decode them, you have all of the prices and you know when and address traded.
00:43:36.536 - 00:44:03.980, Speaker E: So it wouldn't be too hard to actually be able to give you a almost perfect report of all of your on chain trades. Although the actual legal calculation of how much you want to pay is probably not, not that simple. But moving over that and then improving the speed and reliability of the dex pricing and extending it to support more protocols would be really amazing.
00:44:05.840 - 00:44:19.808, Speaker F: Yeah. So just shout out to everyone over this past probably eight, nine months of just constant work on brontes. I mean, Joe especially. Yeah, yeah. Went through a lot.
00:44:19.904 - 00:44:50.424, Speaker E: Yeah. Had to implement hundreds of of bespoke connections to all of the varying centralized exchange streams. So huge shout out to him because otherwise this wouldn't have been possible. Then in terms of resources, you can scan here, there's the GitHub and then the book. Leaving it up. Oh yeah. Quick acknowledgments before I'm done.
00:44:50.424 - 00:45:26.320, Speaker E: Sorry. So, huge shout out to the ref team and the alloy team for building the primitives that made this possible. Special mention to Danny Popes, because we initially tried to use the sole macro on every single verified contract on Etherscan, and I can tell you, we found a few edge cases like the. What was the keyword for Rust? A bunch of ridiculous stuff. And he patched up all of that. So huge thanks. And then big thank you to gaussian process and Kevin for reviewing our inspector methodology and kind of going through the results.
00:45:26.320 - 00:45:51.240, Speaker E: So huge thanks there as well. Contact us here. And we're also hiring for Rust devs, but, yeah, that's it for us. Thank you so much. Oh, and this is a quick sneak peek at the front end website that we're going to be spinning up very soon.
00:45:53.340 - 00:45:55.440, Speaker D: Any questions for.
00:45:55.780 - 00:45:57.400, Speaker E: Shit, I forgot the questions.
00:46:08.300 - 00:46:08.676, Speaker G: Yeah.
00:46:08.708 - 00:46:09.396, Speaker A: Thanks, guys.
00:46:09.508 - 00:46:28.804, Speaker G: Great presentation. I'm actually curious about how do you get the metadata regarding the private order flow like you said? Okay. We have metadata about the searchers and the builders and their private deals and etcetera. Considering they're private. How do you get the information regarding that?
00:46:28.932 - 00:46:55.050, Speaker E: There's a media trained answer, and then there's the real answer. The media trained answer is that we are on chain sleuths and do extreme data analysis. The real answer is that you can contact all of the competitors and get them to snitch on each other because it is in their incentive to give you information on how their competitor is operating. So that has been an extremely fruitful source of information.
00:47:02.320 - 00:47:16.780, Speaker A: Yeah, thanks. It looks super cool, and I'm excited to see this dashboard that you just had. Go live. So given all of this, the rich software you have for the analysis of things and all the analysis that you've done with it, what's one surprising thing that has come out of this?
00:47:18.720 - 00:47:52.128, Speaker E: So there are a few. There are a few. Sextext is not as competitive as people think. Builders are on paper, clean, not sandwiching. But if you mark out a lot of the sandwiches, they don't appear profitable, and that is for a simple reason that they are working together. So they are shifting the responsibility on another party. The other thing is people love to.
00:47:52.128 - 00:49:02.000, Speaker E: To make fun of. Well, at least in the very niche MEV research community, people love to make fun of just in time liquidity attacks because everyone says, oh, yeah, they're not profitable. You're basically always better off sandwiching, which is almost certainly true. But when you mark out JIT attacks, they are 99% of the time unprofitable until you mark them out against a centralized exchange and you realize that this is not a just in time liquidity attack that is trying to steal the fee from a liquidity provider, but rather this is a sextext arbitrager that is also a builder that happens to realize that you're trying to trade at a discrepant price, but that price discrepancy is within the fee bound. So they don't profit from arbitraging, from trading against the poor directly because they pay the fee. But where they do profit is if they provide the liquidity, they get paid the fee and they get to clear you with this discrepant price and have effectively swapped. But that was like a really interesting kind of point that we came to understand because you would expect sextext to really be bad for LP's.
00:49:02.000 - 00:49:16.280, Speaker E: And everyone says, oh, sextex is great for the chain in terms of getting prices in line. But it turns out when your builder is also a sextext arbitrager, you as a swapper are also getting a pretty bad deal.
00:49:24.220 - 00:49:29.600, Speaker B: What do you see as the most prevalent forms of MeV after this analysis.
00:49:32.580 - 00:49:40.310, Speaker F: There'S a lot of atomic arbitrage that we've seen, but mostly sex stats. There's sex decks almost every block.
00:49:40.430 - 00:50:03.970, Speaker E: Yeah, it's sex Dex, and I'd call it sandwiching, but it's really just Jared's trades at this point. Yeah, it is insane how much this guy trades. He's the top three counterparties on uniswap are wintermute, Beaver, and Jared.
00:50:05.460 - 00:50:06.244, Speaker H: Cool.
00:50:06.412 - 00:50:07.276, Speaker E: Really cool codebase.
00:50:07.308 - 00:50:33.720, Speaker H: I'm excited to take a dive in and see what's under the hood. One of the questions I had was, if you could elaborate a little more on the block inspector process and how you actually create this sort of compound classification between different strategies like JIt and then Sexdex as well. What is the actual control flow that's being able to classify this compound behavior?
00:50:34.140 - 00:51:14.902, Speaker F: So we kind of glossed over this a bit, but we have this tree that is just the hierarchical structure of all of these normalized and unnormalized actions. So then with these inspectors, you more or less just get passed in this tree and a bunch of metadata pricing. So with that, for example, with like a sandwich, we look, we just go through all of the traces, mark out the same addresses, take those addresses, take those possible victims, and then look at the pool overlap, say, oh, this is trading on this pool in this direction, victims in this direction. Back run in that direction. You got a sandwich and you have.
00:51:14.926 - 00:51:44.440, Speaker E: Nice utils where on the tree you can say collect, and then you pass the action type. So it's like collect swaps. And this will give you all transactions where a swap action has happened. And then you can also collect these specific actions out from each transaction in terms of the composition aspect. That happens really at the last stage. Once all individual inspectors have run, you have two things. You have the filtering deduplication, and then you have the composition step.
00:51:44.440 - 00:52:29.120, Speaker E: The filtering says, if there is this type of MeV and this type of Mev give priority to the one that you decide. So this is useful. For example, atomic arbitrage versus sextext, because atomic arbitrage will be stricter in terms of what we can classify it as. But a sextext will look like a positive p and l. And then for the composition step, again, it's just the results from the JIT inspector, for example, and the sandwich inspector, which will naturally overlap if it's a JIT sandwich. And then you can declare a specific composition function which takes these two individual bundles, at least as they're built, but are actually the same bundles, and then unifies them into a single complex mev type.
00:52:30.340 - 00:52:32.360, Speaker D: Okay, we have time for one more question.
00:52:34.420 - 00:53:00.970, Speaker I: Now that you have all of this data and you've kind of had time to process it, maybe, how does it affect your outlook on the designs that the Ethereum research community is looking at as far as, like, proposer builder separation or any of these other ideas, like what you would recommend or urge people to do? Because you mentioned, like, people wanting to talk about it, of course. But like, what, what actions or things are you guys kind of like, thinking of after doing this analysis?
00:53:02.190 - 00:53:51.988, Speaker E: I'd say, like, two things. We're, now we have the data. I don't think, like, having this data is enough for us to kind of have a super opinionated view on what is right and what is wrong in terms of the PBS roadmap, given that there's so many second order effects of possible solutions that we might imagine. So that's why I try and be very careful on giving very specific kind of guidelines there. But that's also a very boring answer and doesn't tell you anything. So the second portion, and disclaimer, I'm very much talking my bag here, because this is what we're working on. But what we saw is that this idea that there's so much like General MeV is kind of psyops in the numbers.
00:53:51.988 - 00:54:33.042, Speaker E: 99.9% of it is just all the same. Even liquidations don't matter that much. It's really just sandwiching atomic arbitrage, sex Dex, in no particular order, by the way. And from that, we know that applications that are being designed today have, or at least claim to have immediate solutions towards it. So if anything, I'd like to see less of a focus on handling the redistribution and prevention of extraction at the base layer because I think that that very quickly becomes quite opinionated and rather push it to the application layer. But that has significant kind of trade offs.
00:54:33.042 - 00:54:55.680, Speaker E: One of them for applications that control their sequencing and the other is just complexity. If you're an app dev and you're building on a financial primitive that is known to generate and produce large amounts of MeV, you now have to handle that yourself and be a big boy about it. And that is not easy. So, yeah, like a lot of trade offs.
00:54:58.260 - 00:55:16.920, Speaker D: Thanks, guys. Okay, before we move into the hacking portion of the day, we have a couple quick announcements. First, we're going to have Andrew from the cursive team who's been powering your really awesome NFC badge experience, share a bit more.
00:55:19.420 - 00:55:45.856, Speaker J: All right, hope all of you enjoyed tapping your badges and thanks for trying it out. If you're curious about any of the cryptography or NPC stuff, feel free to come find me and ask any questions. Two quick things. Number one, you've been collecting flowers for every single person that you've tapped. Every single person has a unique flower. So you can go in the app and tap your own badge and you can see a garden of all the flowers you've collected. It's pretty neat, pretty cute.
00:55:45.856 - 00:56:03.700, Speaker J: We're going to share our flowers to Twitter, so if you want to do that, feel free. And the second thing is you can make a proof that you've met 50 people at the event. And if you or Vivek, we will give you one of these exclusive NFC rings. So very special and thanks so much.
00:56:09.760 - 00:56:11.000, Speaker F: All right, I'm.

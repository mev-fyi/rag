00:00:14.650 - 00:01:40.060, Speaker A: I'm going to present you an instantization model for asymmetric football client server reliable industry, more specifically, lifeline protocols. Talking about life science, most people usually think about end user use cases and very lightweight use cases. And I believe in the near future, as we work towards scalability, even our core network protocols and systems will depend more and more on some kind of lifeline protocols or asymmetrical protocols. So having a reliable solution for incentivizing them is really important. So I've been working on a model that is capable of long term trust building clients and servers in a totally decentralized and trustless environment, and can incentivize predictably service availability and consistently response times. And I've been implementing this model in the goiterium light science protocol, also called alias, but it's also applicable in any model or for any protocol. And when this turns out to be workable, then it could also serve as a proof of concept for our future network protocol as well.
00:01:40.060 - 00:03:05.960, Speaker A: So what I have trying to realize is a truly decentralized service cloud where clients and servers can do resource allocation and load balancing based purely on market signals, and can take care of their own interest and protect themselves against attackers and fraud because no one else will do that for them. The most obvious issue such a system has to solve is that in a peer to peer network, promises are not enforceable. So anyone can get away at any point, including servers, right after receiving the payment. So we got to have some kind of a reputation mechanism. And in this case, in this model, this will look like servers have to first provide a free service, and after there's a high demand for that free service and clients just to try to trust server, they can start offering money in order to priority. I also wanted this model to have of course a low network overhead and ideally it could even be workable with any kind of payment technology, including on chain payments. But of course with a more advanced payment technology, payment churning technology.
00:03:05.960 - 00:04:56.780, Speaker A: So the best way to understand this approach is through the time factor. Timing is sticky on any market, and this one is no exception. After all, I supply clients and talk about the importance of response quick response time, but also the market mechanisms themselves are time dependent, and what works on a longer time scale might not work equally well on a short term time scale, simply because the information that actors are trying to base their decisions on might need some time to become reliable, like service policies and response time statistics and serving difficulty measurements. These are very noisy things and we just have to collect a certain amount of data in order to be able to make good decisions. And I wouldn't like to run into problems similar to high frequency trading, which I believe can really disconnect from any market fundamentals and disrupt any meaningful market activity by extreme price fluctuations. So in this model, we also like to avoid quick price fluctuations because prices, I believe are practically meaningless on a short enough time scale or price changes. And so in order to make things a bit more stable and predictable in this talk I will show you how servers can plan ahead a little bit with their allocating their serving capacity, and how clients can do load balancing based on server feedback, and also on a longer time scale, how clients can evaluate server performance and choose the best service for their money.
00:04:56.780 - 00:06:00.970, Speaker A: So for first, let's look at how the servers can manage their own serving capacity and ensure good response times. Servers oh, sorry. So servers have their own token accounting, and so they have their own service tokens, which are meant to be based on the actual physical serving difficulty of request, and they should be unrelated to any market prices or conditions. And the refresh costs are always nominated in the service tokens. And basically, usually the servers can freely decide the cost of any individual refresh. But there are previously announced maximum cost limits for each refresh type, and we also define capacity as service tokens, spendable per time units. And we assign a capacity to each client, which basically means a request rate limiting.
00:06:00.970 - 00:07:08.114, Speaker A: And we also set an upper limit on the total capacity of all connected clients. And the goal of this is to avoid trendy and overload, by which I mean a situation where we have a lot of requests in the same time and response times start to rise very quickly. And so we set up some criteria for detecting this, and we can maybe not always avoid this, but reduce its frequency of its occurrences by adjusting the total capacity allowance. So the refresh rate limiting method applied in alias is called the client side for control. And as I said, it's based on capacity to each client and also a request buffer. And the server, when receives the request, it can remove the cost of the request from the buffer and also recharge the buffer at a rate that's proportional to the capacity. And in every reply it also includes the current buffer status.
00:07:08.114 - 00:08:44.970, Speaker A: And this is what clients can use as a feedback for load balancing, because if they have multiple server connections, they can always send an extra request to the server where they have the best buffer value. And now a few words about how service tokens are being sold. Basically, we want the servers to be able to sell some of their tokens in advance, but not too many of them, because the spending rate of tokens is also limited and it is always a service interest, ensure the stability of the purchasing power of its own tokens, because as we will see later, that the clients will pay attention to this and the servers will lose their reputation if they fail to do so. So what servers should ideally do is limit the total outstanding amount of its service tokens by controlling the selling price of tokens. So there's a base price, and as it issues more and more tokens, it can rise up the token price. And if we are limiting the amount of tokens, we should also enforce spending of the tokens by setting an expiration time on them, or by making them inflationary, or some combination of these. And it's also important to mention here that whenever a currency transfer is accepted by the server, it's not automatically converted to service tokens.
00:08:44.970 - 00:09:35.880, Speaker A: That's something the client has to explicitly initiate, and this is also when the expiration starts ticking. So it's always optional to buy a significant amount of service tokens in advance. That's an option for clients that has a potential cost, but it also has a benefit. One benefit is that it avoids further price fluctuations, but even more importantly that this is a commitment to spending the tokens and using the service in the near future. And the server, this is a very valuable information for the server, and the server will reward this by granting more stable connections. And let's look at included details of how it's done. We are now looking into the client connection priority model.
00:09:35.880 - 00:10:20.500, Speaker A: Obviously the number of clients to be connected simultaneously limited. So we got to have some kind of priorities. And the priority value we are going to use in this model is token balance divided by requested capacity. And I'm not going to explain this in detail now, but the nice property of this is that it rewards commitment. Commitment. So if the client commits to use the service in the near future, then the server commits to let the client use the service in the near future. And another nice property of this is that it lets us integrate free service very nicely and smoothly into the whole model.
00:10:20.500 - 00:11:24.546, Speaker A: And this is something that already works in go ethereum light servers that even clients who don't have a token balance, they have a virtual negative balance which is associated to IP address, and also it's expired exponentially over a longer time. So this is to ensure that free clients can, the client who has used the service less recently has a higher chance to connect. So free service is also important. And the server also has to ensure that preservice is not always, but regularly available for two reasons. One of them is that this is what helps reputation building and getting new customers. And the other one is that the same condition that allows preservice to be available. It also ensures that the service events are all spendable in a limited time frame.
00:11:24.546 - 00:11:37.900, Speaker A: So there's another control mechanism here that controls the base token price based on whether the service preservice is possible or not. If it is possible, then it.
00:11:40.050 - 00:11:40.634, Speaker B: Reduces.
00:11:40.682 - 00:12:31.806, Speaker A: The price and otherwise it slowly, exponentially increases the base price. And yeah, this is about it for the server mechanism. And now quickly, let's take a look at the client side mechanism. So this is a complex topic, and also I can't go into every little detail here, but there's a subjective value measurement on the client side, which is ideally it should be a mirror of the server side token accounting. So basically the clients try to somehow put a number on how much service they received. And this is also based on served requests and guaranteed capacities. And it's also modified by a service quality factor which is based on response times.
00:12:31.806 - 00:14:13.642, Speaker A: And how response times are converted to service depends on the expectations on response times, which depends on price factors and everything. So basically it's possible to, if the client has to make a decision on who to pay for, it can map out the whole available market as a price versus average expected response time function, which is nice and intuitive and easy to understand for human users. So if we have an equilibrium and we have an expected response time, then we can convert our collective statistics into a trigger scalar value. And I like to mention here that very long response times can even map out as a negative value for clients, because we want to incentivize reliably good response times. And this service value is what the clients are trying to get for their money, basically. And finally, there's a tricky part of this, because if the client wants to make a decision about who to pay for, then what it really would like to do is to predict the service value received after making the payment and before the next payment is requested. Theoretically, if we can trust the server, this is not so hard, because we expect the service tokens purchasing power to be more or less stable, and the client has an idea of how valuable those service tokens were in the past, and there's a token price at the moment, so it should be predictable.
00:14:13.642 - 00:14:57.782, Speaker A: But of course the client cannot blindly trust any server. So this is how the reputation building mechanism works. We have three predictors. We have a base value predictor, which is very simple and paranoid, and only uses things that the client knows for sure. So it basically takes the service that you receive so far and the payment sent so far and the payment expected currently, and it just does a linear extrapolation which converges to something meaningful over the long term. It's not very good, but also not cheatable. And there's the trusted value predictor, which basically does what I already described it with the server and the token accounting and token prices and the stability of these tokens.
00:14:57.782 - 00:16:18.402, Speaker A: And to make the final judgment, there's a third ensemble predictor which initially returns the prediction of the base predictor. And over time, if the trusted predictor consistently gives the better estimates of service value received after making a payment, then it will allow more and more deviation from the base predictors value in the direction of the traffic predictors prediction. This allows deviation, this represents the reputation of the server, and this is what is going to be ruined if the server doesn't hold its promises and doesn't keep its service token value stable. Yeah, I have a little more time. So now just a few words about current state of implementation and roadmap. So as I already said, most of the components, or many of the components are already implemented in goiterium. And I so far mostly focused on implementing the server side because that's what we first need in order to even start experimenting.
00:16:18.402 - 00:17:15.366, Speaker A: And recently server API has been implemented. It's going to come out in one of the subsequent get releases. And with this you can already play with the client priorities and you can assign priorities to your own nodes or your friends or customers nodes. And there's the automatic token sale mechanism. It's work in progress, but I really hope I can finish it and we can release it by the end of this year. And this will mean that by the end of this year we are going to have payment fully working, payment enabled light servers, which anyone can start up and start earning money. And this still means that on the client side there's going to be some manual help needed, like a whitelist for servers who we can pay for.
00:17:15.366 - 00:18:26.654, Speaker A: But the client side management logic is also already partially implemented, and I really hope that by the middle of next year I'm going to be able to show some results that you can try. Of course this is going to be an ongoing longer research. Yeah. So please, if you have any feedback then contact me. I'm going to release the new document documents about the details of this model because I'm aware of that. I didn't answer every questions in this short talk, but I'm going to put up a new document to my GitHub page and I'm going to announce them on Twitter and Reddit and everywhere. And I would really like to make this model usable, both for go Ethereum and the Gaslight client, and also for our future light clients of Ethereum too.
00:18:26.654 - 00:18:40.740, Speaker A: And yeah, that was it. Thank you for your attention. Maybe there's time for one question or two. Any questions?
00:18:45.430 - 00:18:47.140, Speaker B: How do payments work?
00:18:47.670 - 00:18:48.190, Speaker A: Sorry?
00:18:48.280 - 00:18:49.720, Speaker B: How do payments work?
00:18:50.730 - 00:19:27.220, Speaker A: How do payments work? Well, so this model is so it can work with any kind of payment technologies. I was looking into using Raiden and now the Swarm team also has the swap protocol. That's also an interesting payment channel technology. But I think we can even start experimenting, as I said, with simple launching payments, which are really easy to do. The model doesn't depend on the payment technology.
00:19:28.390 - 00:19:30.978, Speaker B: Are the tokens fungible? You can pay for a token that.
00:19:30.984 - 00:19:53.080, Speaker A: Works for any server or just service to consuming? No. So every server has its own service token and they are only accounted locally on the server. And I'm not sure yet whether they should be tradable and transferable. Let's see what the future is, whether that's a good idea or not.
00:19:53.630 - 00:19:56.538, Speaker B: If you do like an on train detection, you have to free pay and.
00:19:56.544 - 00:20:19.020, Speaker A: Hope that they're like, yeah, so if you send ether to a server or die or whatever, what the server wants to accept, then you are going to have ether or die on the server. And as I said, you have to explicitly say, okay, now I have ether with you and I want to convert some of it to serving to. Hence now and my time is up and thanks very much.

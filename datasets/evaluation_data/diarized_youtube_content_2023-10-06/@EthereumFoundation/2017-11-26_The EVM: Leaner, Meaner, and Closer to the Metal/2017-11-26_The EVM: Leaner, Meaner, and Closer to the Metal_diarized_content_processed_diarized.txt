00:00:16.650 - 00:01:07.294, Speaker A: I'm Greg Covid. I spend my time for Ethereum working on the virtual machine, working on improving its performance, and working on designs for possible successors to what we have in order to solve some of the performance problems that we're running into. If this works, there will be another slide. How about that? The first problem you run into in any sort of optimization work, according to my old friend Jerry Schwartz, is one. All benchmarks are bogus. You'll never have a set of benchmarks that actually represents the real world. But if you don't have benchmarks, you will just go in circles.
00:01:07.294 - 00:02:02.370, Speaker A: You'll never make progress. So the benchmarks I'm working with are a few algorithm kernels that are relevant to what we're doing. RC five is an old and useless cipher, but it's a good example of a cipher that uses a lot of 32 and 64 bit arithmetic, a lot of complex logic, and Blake two B is still an important hash function. It's also a lot of 64 bit logic. Blum Blum shove is cryptographic random number generator. I think it's one of the slowest in the world. It operates on big registers, so we can use the 256 bit registers of the EVM effectively.
00:02:02.370 - 00:02:59.478, Speaker A: And EC mall also can use big registers effectively. And then I have a few tests of individual EVM operations, and those are small EVM assembly programs to try to isolate individual operations. And this is a graph of what I got with the whole thing. And it's a bit complex, but what you can see down along the bottom is the different benchmarks, and along the right are the first three are some major clients. EVM is our go client parity is a rust client. EthVM is the c client. The rest aren't clients yet.
00:02:59.478 - 00:03:46.150, Speaker A: But EVM to WASM is part of the WASM research. It's a program that takes EVM code, translates it into WASM code, and then I fed that to Google's V eight engine, which generates assembly code. EVM jit Pavel was just talking about. It generates assembly code directly from EVM code. And then the native c is. I rewrote the benchmark programs in c instead of solidity or EVM assembly and compiled those to assembly. So pretty clearly the C Plus plus wins the race.
00:03:46.150 - 00:04:55.260, Speaker A: And pretty clearly exponentiation is pretty hard for everybody, which isn't surprising, but it's a little concerning. There might actually be possible exploits by writing contracts that do exponentiation and get charged only a few gas, but take a whole lot of time. And RC five looks pretty hard because RC five works on dynamic shifting, and the EVM does not yet have a shift operator, and so it gets imitated with exponentiation. And in between things are relatively regular. And the speed you could actually predict by the language that the client is written in. Where did that come from? Next slide. I can't see the screen with these glasses on.
00:04:55.260 - 00:05:44.380, Speaker A: So to simplify it, this is looking at one angle. It's a harmonic mean of the performance of each client, and it shows pretty much the same thing. So clearly, the interpreters are not as fast as going straight to machine code by any route. And clearly some interpreters are better than others, but they've all been good enough so far for our purposes. And of course, I love car races. As examples, last year somebody in the audience shouted out that instead of using classic cars, burning tons of gasoline, I should be using Tesla. And Teslas are nice.
00:05:44.380 - 00:06:29.740, Speaker A: Is George Hallam here? Are you here, George? George would agree that rather than a Tesla, this would be much cooler. This is a 68 Mustang hatchback. Under the hood is actually some powerful electric motors, and the trunk is full of lithiumion batteries. And if this works, where's the button? We will see how this does against the Tesla. Is there any sound? No such luck. But there goes the Mustang. Tesla doesn't have a chance.
00:06:29.740 - 00:07:12.360, Speaker A: So it did, just missing. But after a quarter mile, it had gotten to 140 miles an hour. That's a lot. So what keeps those interpreters from reaching native speed? And the first answer is they're interpreters. So they've got that overhead. You can work hard, you can reduce the overhead, but generally you can't do better than about three or four to one. Compared to native code.
00:07:12.360 - 00:08:07.030, Speaker A: For our particular interpreter, the 256 bit registers slow us down because real hardware has 32 64 bit registers, and the unconstrained control flow hurts us a lot. And I'll get to that. The 256 hz. If you remember grade school math, adding multiplying two numbers is pretty easy. You can do it in your head. If you have four numbers, suddenly it gets a lot harder and it's quadratic, so it gets worse and worse. 256 squared is a lot control flow.
00:08:07.030 - 00:08:48.290, Speaker A: The jump operator in EVM go to are considered harmful, but at least if you say go to label, it will go to one and exactly one label. In the EVM, you say go to whatever's on the stack. So there's no way of knowing, often statically, where it's going to go. So you can have a nice little program like this. And f calls g and h and returns and it calls I and returns, et cetera. Nice clean structure. No trouble.
00:08:48.290 - 00:09:59.290, Speaker A: No trouble. To understand static analysis, anything? No trouble. What's it actually look like to the EVM? That's what it looks like to the EVM. So if you're trying to do formal analysis, if you're trying to write a compiler, if you're trying to do anything with it, again, the number of paths goes up quadratically and you're in trouble because pretty much if you can't do it in linear time, or at least analog n time on the blockchain, at deployment time or at runtime, you can't do it. So how do we do better? Well, evmjit is already doing better. I won't back up, but if you look at the slide, the evm jit is actually pretty close to the native speed. It does very well on the wide arithmetic and not so well on narrow arithmetic and complex logic, but it's a very good jet.
00:09:59.290 - 00:10:36.920, Speaker A: I've told Pavel he gets to be the electric fox. He's tired of these little three and four letter names that don't mean anything. This is a racing team out of Latvia that's a completely electric dragster. And here it is winning the european world record. There it goes. Drag races are fast. It's not impressive, is it? It's over.
00:10:36.920 - 00:11:11.010, Speaker A: Hello, 275 miles an hour. Just a few seconds. Love these things. So we've got two research programs that have been going on how to improve things. They've been nicknamed EVM 1.5 and EVM 2.0, which doesn't really mean anything except those are the nicknames.
00:11:11.010 - 00:12:09.058, Speaker A: And for 1.5, that's a suggestion to extend the current EVM by adding new opcodes and requirements. So we forbid those unconstrained jumps. We will not allow you to do that. And we then have to provide a way to do the things that you otherwise do with those jumps. So there's opcodes for subroutines, and then we've got to get away from having nothing but 256 bit registers. So we've got opcodes for native scalars and opcodes for SIMD, because real hardware has all this silicon devoted to SIMD registers.
00:12:09.058 - 00:12:47.906, Speaker A: And if you go to Google and type SIMD crypto, you get a lot of results. So it would be useful to make that hardware available. And at deployment time there's a validation phase that goes through the code and makes sure that it actually does follow the rules. What a concept. And then 2.0, well, gee, it provides opcodes for structured control flow. It's stricter than 1.5.
00:12:47.906 - 00:13:45.338, Speaker A: It actually looks like a high level language with if else and such, and it provides opcodes for native scalars. The SIMD is coming later, but there's a SIMD proposal, and it also has a validation phase where it validates control flow and stack discipline and type safety. So they're very similar at that level. So we've got some technically very similar proposals. They both provide for very fast compilation to native code. It could be done as a JIT. We've come to realize Ethereum cannot do Jits, they are actually exploitable.
00:13:45.338 - 00:14:46.262, Speaker A: That is, if you find or write a contract which takes a long time to compile with a JIT, but requires very little gas to run, and you start hammering those contracts, you can do a really nice DOS attack. So if you're going to do any compiling, you've got to do it upfront at deployment time. And Martin's notion of transpilers I think is very important here. 1.5 can be transpiled to 2.02.0 can be transpiled to 1.51.5, or 2.0
00:14:46.262 - 00:15:40.662, Speaker A: can be transpiled to 1.0, either of them can be transferred to the JVM, you can make up new ones, pretty much. You can compile any vm you wanted to some other vm. And he also has a notion of gas injection. So you put little pieces of code into the right places to count the gas. And what this means to me is it doesn't matter what execution engine a client chooses, because on the blockchain you can put a contract that translates into that execution engine. So these can be completely independent choices.
00:15:40.662 - 00:16:34.010, Speaker A: And we could actually choose to support a number of vms if we wanted to, and independent parties could decide to support a different vm. Put a transpiler on the blockchain and away they go. Two. Gee, I'm almost out of slides and there's no sound. That's really too bad. So what is the big deal about native performance? And what's the big deal about being lean and mean and close to the metal? Well, we saw the electric dragsters here is like a real top fuel dragster. They run on a mixture of diesel fuel and nitromethane.
00:16:34.010 - 00:17:39.390, Speaker A: And just about a month and a half ago, not too far from Ming's place in Michigan, this guy got the world record and it's over 338. These guys pull about five or six g's, which is about the same as an astronaut taking off in the space shuttle. But there's a problem with going fully native. In the siebe world, we call it undefined behavior. Hello. No, that's the last. Come here.
00:17:39.390 - 00:18:10.356, Speaker A: Okay, play. There it goes. What's going on? My screen. We'll try it again. Doodoodoo. The driver actually walked away unscratched. I love this guy.
00:18:10.356 - 00:18:44.170, Speaker A: We'll give you one more boom. And it turns out I'm done, so. I knew it. Audiences love explosions. I'm done.

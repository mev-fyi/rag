00:00:01.050 - 00:01:01.338, Speaker A: Great. Thank you. So a lot of the time people ask me to give presentations about things like what is the progress of Casper? Or what is the progress of sharding? Or in general, what are future versions of the ethereum protocol going to look like and when are they going to get there. So that question, the answer is to get there when they get there. But to day, what I wanted to talk about is go a bit deeper down and give a bit of an introduction to some of the kind of thinking processes, some of the reasoning that goes into the ways that we've been making some more design decisions in things like Casper so far. So we'll start off going back to the basics. Right? So I generally think of blockchain protocols in general as being a part of this category of crypto economic protocols.
00:01:01.338 - 00:02:01.358, Speaker A: And I feel like the thing that really fundamentally separates things that are done on bitcoin, bitcoin, ethereum, dogecoin, things that are done on top of any of the three from anything that happened before, basically, is this kind of crypto economic element. Right? So decentralized systems, we've had those for a while, and even just to fault tolerance, consensus, we've had that for 30 years. But the thing that's really unique about what some people call the blockchain space is that it mixes together these two ingredients. It mixes together cryptography and economic incentives. I'll describe blockchains in those terms a bit later on. So basically, I think of crypto economics as being a kind of methodology for building systems that try to guarantee certain kinds of information security properties. And the two main kinds of building blocks that we have are, first of all, cryptography.
00:02:01.358 - 00:03:24.846, Speaker A: And cryptography is about proving properties about messages that happened in the past. So if I sign a message, it proves that I created it. If I have a message that includes the hash of another message, then that proves that that second message came before the first message came after the second message, and that when I created the first message, I already knew about the second message. Now, economic incentives, where those incentives are defined inside the system and administered by the system, are used to encourage the participants in the system to work hard to make sure that certain properties continue to hold into the future. So we'll take a look at bitcoin just as a simple example. So you can just think about what bitcoin is for on multiple different levels, but you can think about it on a high level and you can say bitcoin is there to create a peer to peer digital currency, or you can think about it on this kind of very low kind of functional level, where you say, what specific things do we want the bitcoin blockchain to want? What specific behaviors do we want it to have? So, in general, we want to create a chain of blocks, and we want those blocks to contain transactions. And the bitcoin blockchain maintains some notion of state.
00:03:24.846 - 00:04:33.054, Speaker A: So we can think of state in bitcoin as being how much money everyone has. You can think of state in ethereum as being how much money everyone has. And what is the code of all the smart contracts, and what is the state of all the smart contracts? And the transactions affect the state, right? So if the state before said that I have $100 and I have 100 bitcoins, and then I send 70 bitcoins to Christian, then a new state says that I have 30 bitcoins, and Christian's balance also increases by 70, roughly. Now, one smaller functionality that bitcoin has that we don't really think about, but it's also technologically important, is the bitcoin blockchain maintains a clock, right? So, bitcoin blocks contain timestamps. And those timestamps are ideally supposed to roughly reflect reality. Now, here's some ways of thinking about what a well performing bitcoin blockchain looks like. First of all, we have a property of convergence, right? So ideal total 100% convergence would be, is if you have a chain and new blocks can get added to the chain, but blocks can never get removed.
00:04:33.054 - 00:04:57.958, Speaker A: Blocks can never get replaced. You never have reorgs, you never have 51% attacks. Every time a block comes and goes onto the chain, it stays on that chain in that exact same place forever. The next block gets added on top of that. The next block gets added on top of that validity. So we want the bitcoin blockchain to be valid. And here are some definitions of validity.
00:04:57.958 - 00:05:32.850, Speaker A: So there's lots of definitions of validity. One of them is that you want proof of work to be valid. You want blocks to contain the hashes on the previous block. You want things to be in the right format. Also, an important one from the point of view of a currency, is that you have this validity predicate. So, only transactions that satisfy some validity predicate that depends on the transaction and also depends on the current state, should be included in the block. So, for example, if the current state is that I have 100 bitcoins, then I take this transaction, sending 70 bitcoins to Christian, that transaction is valid.
00:05:32.850 - 00:06:13.070, Speaker A: Sent. Now, if I try and send another transaction after that, sending another 70 bitcoins to Christian, because the state changed the second time around, that transaction fails. Also, the clock should be roughly increasing. That's one partial condition for kind of the clock reflecting reality. It doesn't cover everything because the clock could potentially increase like ten times faster than real time. But the clock should definitely not be going backwards. Here are some more subtle properties that you might not think about, but the blockchain also has, right? So one of them is data availability.
00:06:13.070 - 00:07:02.398, Speaker A: So the chain does not just need to be valid, it also needs to be available. Everyone needs to be able to download the blockchain if or when they want to. So if you see a block header, and that block header is part of the kind of canonical chain, then you should be able to kind of go down the merkel tree and download the rest of that block. Now theoretically, you could imagine a malicious mining cartel decides to publish a chain of block headers where the blocks that those block headers points to are all valid. Everything is totally correct. But they hide the data. They don't actually distribute the data in the blocks to anyone else, they just distribute the headers.
00:07:02.398 - 00:07:42.510, Speaker A: Even though the blockchain is valid, even though they're following all the other rules, this is still bad and this is still something we want to avoid. Availability. So this is availability of the protocol. With respect to users of the protocol, if I have a transaction and that transaction has a sufficiently high fee, then I should be able to include that transaction in the blockchain. Now, of course, sufficiently high fees might end up getting pretty high, as I'm sure some of you are aware. But you don't want a system where even if you pay $100, it refuses you. Or you don't want a system that just outright discriminates against certain classes of actors.
00:07:42.510 - 00:08:16.358, Speaker A: We have blockchain blocks, transactions. So we kind of know what a well functioning blockchain looks like, right? And here are some of the cryptographic tools that it uses. Proof of work. So, proof of work allows you based participants in the network to prove that they have access to a certain amount of computing power. And this essentially gets used as part of the kind of way of assigning identities in the consensus mechanism in some sense, signatures. So a signature is proof who sent a transaction. And hashes.
00:08:16.358 - 00:09:15.950, Speaker A: And hashes have several purposes in bitcoin, right? One of them is that they establish a total ordering of the chain. So they establish that you have this chain and you have blocks, and the blocks are in this exact order. And no, you can't kind of take a block out in the middle and replace it with something else. Another function that hashes have is they enable a kind of limited light client protocol with Merkel proofs, right? So basically, if you have a bitcoin client on a phone, and you only want to check your own transactions, you don't have the resources to check the whole thing. Then you can use this protocol where you only download the block headers, only check the proof of work on the block headers, and then only verify the small portion of the blockchain that you actually personally care about. And because the blockchain is all kind of linked together through this hash based data structures, you can actually do this incentives. So the miner of a block that gets into the chain gets twelve and a half bitcoins plus.
00:09:15.950 - 00:09:56.010, Speaker A: And this is something that we think about less. But it's also important. The miner can kind of extract economic rent from being a kind of a temporary dictator over transaction inclusion. So what do I mean by dictator? Basically, if the minor of, if you send a transaction, if the miner of the next block wants it to get into the next block, it gets into the next block. And if the miner of the next block does not want it to get into the next block, then your transaction does not get into the next block. Now, it's a temporary dictator, because even if the first minor doesn't include your transaction, some future miner might. But even still, this privilege actually does end up being part of a miner's incentive.
00:09:56.010 - 00:10:44.314, Speaker A: Now then you create a block, and the block does not get into the chain, then you get nothing. And there also is this funny difficulty adjustment property that basically says rewards are marginally long run, zero sum. So basically, no matter what people do, the total sum of everyone's revenues is going to end up being roughly the same. And this is important. And particularly this actually is one of the main reasons why bitcoin has selfish mining vulnerabilities. So, cryptography, so we can think about cryptography very generally, right? So, hashes, they have several functions. One of the interesting ones is that you can use hashes to prove topological order of messages, right? So if a contains the hash of b, then a came after b.
00:10:44.314 - 00:11:35.686, Speaker A: If a contains the hash of b, and b contains the hash of c, then a came after b, b came after c. And so by transitivity, a came after c. Also, hashes can do other things. So they enable these data structures that you can kind of crawl through and verify very small portions of. They can in general allow for small pieces of data to kind of stand in for big pieces of data signatures prove the identity of the sender of a message. Zero knowledge proofs prove arbitrary, computable predicates on messages. So basically, if you have a message and you want to prove some property about it, even if that property takes a very long time to verify, if you verify it, then you can create a proof, and other people can verify your proof.
00:11:35.686 - 00:12:24.006, Speaker A: And this proof is, with the newest protocols, even potentially even much faster to verify than the original verification function itself. And the other fun part is that you can verify properties of messages that you know without revealing what those messages are, even without revealing anything about what those messages are, except for the fact that they satisfy the proof. So that's one more powerful tool in our toolbox. We also have a bunch of other tools in the toolbox, right? So we have proof of work. And proof of work is a kind of cryptographic tool for proving that you have access to a certain amount of expected computational effort. So if you make a proof of work, then on average, a certain amount of computational effort was expended in order to create it. Erasure codes.
00:12:24.006 - 00:13:17.222, Speaker A: So we'll talk about data availability later, but generally, erasure codes, one way of thinking about them is they convert 100% data availability requirement into a 50% data availability requirement. So for example, let's say I have 1gb of data, then I can use the serration coding algorithm, turn it into 2gb, and what the algorithm gives you is any 1gb out of those 2gb, even if it's like a gigabyte made up of tiny different chunks placed together from all over the file, can be used to recover the original data. So this actually is something that's going to end up being useful for us later on. Time lock crypto. So this is an interesting tool in the toolbox. Basically, it allows you to prove, first of all, prove stopological order. So if b is a time lock encrypted value on top of a, then b came after a, but it also contains a built in clock.
00:13:17.222 - 00:14:11.686, Speaker A: Right? So not only did b come after a, b came at least some number of seconds after a. Homomorphic encryption and obfuscation, you can convert functions into functions that behave similarly or do the same thing, except in forms that are more privacy preserving. So basically kind of black box computation, even if the computation itself is being done in the clear. So that's roughly kind of the kinds of properties that these cryptographic algorithms have, right. And if you think like a crypto economist, then you don't necessarily even need to care about the details of how all these properties are implemented. You just have to care about kind of what the interface of these functions are. So what are their inputs, what are their outputs? What do they do, what properties do they have? This part is in some ways a simpler task than being a cryptographer actually involved in creating these functions.
00:14:11.686 - 00:14:42.214, Speaker A: Now, economics. So this is the other half of the toolbox, and here one major part of the toolbox is incentives. And there's two kinds of incentives. Well, there's actually two ways to split incentives into two kinds. So the first way to split it up is you have tokens. Basically, tokens are when you incentivize actors by kind of assigning them units of a cryptocurrency defined inside of the protocol. So for example, the bitcoin protocol can just assign a minor 12.5
00:14:42.214 - 00:15:29.510, Speaker A: bitcoins as a reward for creating a block. The Ethereum protocol can assign you five ether. If you create a block, or if you want to penalize people, then you can delete coins that they have. The second kind of incentive, and this is once again one that's talked about much less often, but it's also still very important and interesting, is privileges. So privileges basically means you incentivize actors by giving them decision making rights, where those decision making rights can be used to extract rent. So what do I mean? Now remember thinking back to mining, right? So when you create a block, you are a temporary dictator over transaction inclusions in that block. If you want a transaction to be included, then you can include it.
00:15:29.510 - 00:16:11.998, Speaker A: If you want a transaction not to be included, you cannot include it. Now then what happens is that because you have this power, other actors in the network can basically have the incentive to bribe you to try and get you to use your power in order to help them. So other people can bribe you to use your block space to include their transaction. And this is called a transaction fee. And this is in some ways an intended part of the incentive structure behind how bitcoin works and behind how ethereum works, and behind how any blockchain in general works, you can give people privileges. You can also take privileges away as a penalty. So this is the other way of categorizing rewards or categorizing incentives.
00:16:11.998 - 00:17:14.386, Speaker A: Rewards and a reward basically means if someone does something good, then you can increase actors token balances or give them privileges, and you have penalties. If an actor does something bad, then you can reduce their balances, or unless it's actually written incorrectly, or you can take their future privileges away. So here's some other important concepts. So first of all, we often talk about crypto economic security margin. So basically, a crypto economic security margin is an amount of money where you can prove that either some protocol worked. So either some protocol satisfies some guarantee or the guarantee is broken. But some actors in the system, those malicious actors that cause g to fail, end up paying either paying an amount of money x or foregoing some amount of revenue equal to x in order to make that property not fail.
00:17:14.386 - 00:18:33.038, Speaker A: Right? So you can think about a crypto economic security margin on the protocol staying like the blockchain being convergent on some finality mechanism being broken, on any kind of mechanism that you create having the intended effect. In general, the idea basically is that you can measure security in dollars. Crypto economic proof. So this is a kind of message signed by an actor that's basically, you can interpret it as, I certify that either some claim is true or I suffer an economic loss of some size. Now, in some ways, basically what this is, it's an object that you can then use, that you can download and check. And if you verify that the cryptographic crypto economic proof is in the right format, then you know that either p is true or somebody lost some amount of money in order to trick you. So one example of this is, if you think about proof of work in the context of a like client, you can think of a block that gets created as being a crypto economic proof that the block points to something which is in the main chain and that the block itself is part of the main chain, where the predicate p basically is kind of being part of the chain.
00:18:33.038 - 00:19:23.338, Speaker A: And the economic loss of size x is basically the block reward. Now, in proof of stake, you can imagine crypto economic proofs where size x can be much larger. Because in proof of work like x is basically kind of bounded above by the rewards that you can either give miners or take away from miners. But in proof of stake, you can use deposits and you can make people put large amounts of money at stake. And if people make proofs that are false, then you could just delete their money all at once. So then another kind of set of concepts has to do with the security model that you're thinking about. So first of all, there are some security models that aren't economic, right? There are some security models that just say we expect two thirds of the participants in the network to be nice guys.
00:19:23.338 - 00:20:09.182, Speaker A: And this is called standard byzantine fault tolerance. There are models that say we expect all actors to be nice guys, but maybe some of them might have their service crash, and that's traditional fault tolerance. So there's those kinds of models as well. As far as economic models go, one of the major ones is an uncoordinated choice model. And the uncoordinated choice model assumes that all participants in the protocol do not coordinate with each other. They have separate incentives, and they're all smaller than some given size, so they're all smaller than some given percentage of the network. So, to give one simple example, the bitcoin network is secure in an honest majority model if the attacker has less than 50%.
00:20:09.182 - 00:21:06.150, Speaker A: But it's only secure in an uncoordinated choice model if an attacker has less than 25%, because 25% is the bound for salvage mining coordinated choice model. So that's a model that basically assumes that all actions in a protocol are controlled by the same agent or controlled by the same coalition driving attacker model. So this is a model where you have an uncoordinated choice assumption, but it also assumes that there is some attacker, the bribing attacker. And the bribing attacker is capable of making payments to actors conditional on those actors taking certain actions. Here, the bribing attacker model has two parameters. The first parameter is budget, which is how much is the attacker willing to pay in order to carry out an attack. And the second parameter is cost, which is if the attacker does carry out the attack and it succeeds, then how much does the attacker actually end up paying? Now, to illustrate all of these, we can think about just one simple example, shellingcoin.
00:21:06.150 - 00:21:50.750, Speaker A: So, a shelling coin protocol is this kind of simple but kind of naive way of trying to provide the true answer to some question. So, for example, who won the election? And here's the algorithm. Step one, let's say you're trying to choose between a or b, right? So everyone votes a or b. Step two, the majority answer is taken to be the correct one. Step three, everyone who voted the same answer as the majority gets a reward, and everyone who voted the same answer as the minority gets nothing. So that's the algorithm, right? Now, in an honest majority model, is this algorithm good? This is a question just to check how people are following along. In an honest majority algorithm, does this work? Yeah.
00:21:50.750 - 00:22:38.474, Speaker A: Okay. And this works basically because we expect an honest majority to vote honestly. Now, in an uncoordinated choice model, what happens? So here's where it becomes interesting, right? In an uncoordinated choice model, it also works because you have the incentive to vote the truth. And the reason why you have the incentive to vote the truth is because everyone else is going to vote the truth, and you only get a reward of p. If you agree with this majority now, then you might ask, well, why is everyone else going to vote the truth? And the answer is because they're thinking in the exact same way that you are. So it's this kind of recursive equilibrium, right? But in an uncoordinated choice model, it works. Now, it's not the only equilibrium, but it is an equilibrium.
00:22:38.474 - 00:23:37.390, Speaker A: And if the system is in this equilibrium, then it's an equilibrium, then it can stay in this equilibrium. So now let's try and think about this in. Actually, before we even get to this, we can think about this in a coordinated choice model. So, in a coordinated choice model, basically, does this work? Right. Any ideas? So, the answer actually is basically that the incentive is kind of neutral, right? So the reason basically is that if you imagine n participants, if they all vote for a, they get a reward of n times p. If they all vote for b, they get a reward of n times p. Now, what you could say is that you could say that if the participants in this network care about its kind of people trusting it in the long term, then you could imagine that they get a bit higher reward for if a wins, if a is the correct answer, than if b wins.
00:23:37.390 - 00:24:13.702, Speaker A: And this is a kind of public good that's spread across all the participants. So you could imagine that if you try to include these kind of goodwill factors, then in the coordinated choice model, it does have some security. Now, let's look at the bribing attacker model. So this is the kind of infamous people Epsilon attack that Andrew Miller came up with about two years ago. Basically, a bribing attacker can corrupt the shellingcoin game with a budget of people's Epsilon and a cost of zero. Now, what do we mean by this? So here is the default game. So, the default game, basically is if you vote zero and others vote zero, you get the reward.
00:24:13.702 - 00:24:51.434, Speaker A: If you vote one, others vote one, you get the reward. But if you disagree with the majority, you get nothing. So here you have many equilibria, but everyone telling the truth is one of those equilibria. Now, let's look at what the bribing attacker does. The bribing attacker adds this extra reward here into the matrix. Basically, what the attacker does is he says, and this could be a crypto, economically enforced, this could be a smart contract bribe. Basically, the attacker says, if to anyone who votes one, if, let's say, zero is the correct answer, the attacker wants to trick them into voting for one.
00:24:51.434 - 00:25:33.062, Speaker A: If to anyone who votes one, if the majority votes zero, then I will compensate you people's epsilon. Now, if you vote one and the majority also votes one, then I'm going to pay nothing. But if you go with me and you vote for one and you end up losing, then we'll compensate you on an, and I'm going to add a bit extra. So now let's say you are a participant in this model, and you decide, you're wondering, what are you going to do? Now, there's only one equilibrium, because no matter what your beliefs are about how others are going to vote, you voting one has a higher reward than you voting zero. And so everyone votes one. And so the attacker actually ends up in the bottom right square. So the attacker actually ends up paying nothing.
00:25:33.062 - 00:26:09.570, Speaker A: Right? So that's what I mean by a budget of people's Epsilon versus a cost of zero. You have to be willing to pay p plus epsilon, but you end up not paying anything. So that's just a bit of an example of how kind of the three models can give radically different responses to many kinds of games. Proof of work. Turns out proof of work has a lot of the same properties that shellencoin does, right? Basically because proof of work is also a game where you get more money if you're part of the majority. And so you can do people's epsilon attacks on it. Same behavior in uncoordinated choice models and same behavior in coordinated choice models.
00:26:09.570 - 00:26:43.646, Speaker A: Now let's move on a bit and look at faults. Faults basically are. And you can think of faults at several different levels. So one level where you can think about faults is you can think about faults of the protocol. So you can think about a protocol that does not satisfy some of its desired properties. So, for example, you could imagine you have a blockchain. Then at some point, instead of the blockchain adding another block, the blockchain kind of doubles back three blocks and it kind of forks off.
00:26:43.646 - 00:27:55.134, Speaker A: And those three blocks that were originally there just kind of end up disappearing off into nothing or getting included as uncles or whatever else, right? So that's a deviation from optimal behavior, because it looked like the chain was going this way, but actually it turned around and went another way. Faults of individual actors in the protocol. So individual actors might, the servers might crash, they might decide to be malicious, they might decide to do various things, they might get bribes to do various things, and faults of the network. So networks might have latency, or networks might just not let certain messages pass through, or potentially you might get a kind of worldwide partition. You could imagine if World War II starts and a bunch of undersea cables get cut, and the US and Eurasia split off into different internets. That's also a network fault categorization of faults. Right? Here's one way where we can categorize faults, at least faults of individual faults and faults on the network.
00:27:55.134 - 00:28:39.038, Speaker A: So we can think of a protocol as being a function that describes what a node is supposed to do. So we can just think of a protocol as a function that takes as inputs the set of messages you've already seen. Then some auxiliary data, and auxiliary data might include the time, it might include who actually won the election. It might include any other data that you're supposed to have. So it's a function that takes the set of messages you already saw, plus when you saw them, other than the auxiliary data, and it outputs either nothing or some message that you're supposed to send. So here's how we can categorize faults. One thing we can say is one kind of fault is invalidity.
00:28:39.038 - 00:29:40.294, Speaker A: So invalidity basically means a node sends a message where that message is not the result of executing the protocol for any subset of the messages that the node actually saw. So basically the node is just not running the program at all. Basically, in this case, the node has to have kind of stuck a wrench into the program and kind of jiggled the transistors around or done the software equivalent of that. So for kind of any reasonable aux, or for any subset of the messages that the node actually saw, the next one is equivocation. Now, we could think of equivocation as being kind of like your program forking, right? So basically, imagine you saw some message, then you saw message m one. Then you faithfully follow the protocol as if you saw message m one. Then you pretend to unsee message m one, and then you see message m two, and then you send a message as if you were faithfully following the protocol, as if you saw message m two, but as if you never saw message m one.
00:29:40.294 - 00:30:31.510, Speaker A: Right? So basically it's like when the kind of graph of what you saw doesn't look like a straight line, it looks like you kind of saw some things, but then you forgot them. So this is called a club vacation, ignoring and delaying inputs. So this is basically consistently pretending that some message that actually arrived at some time t one, did not arrive until some later time t two. And possibly you can just ignore messages completely. So that's t two equals infinity, not sending or delaying outputs. So this is when you're supposed to send a message, but you either send it later, or t two equals infinity, you never send it at all using false values of aux. So, for example, if Trump won the election, but you decide either you really don't like Trump or you want to screw around with the system, you proclaim in the schelling coin game that Hillary won the election.
00:30:31.510 - 00:31:30.438, Speaker A: Special case. Remember, part of Aux is time, right? So sending messages too early is a special case of this, and another one is now. Those are all individual faults. We also have network faults, which basically is latency or dropping messages. So fault assignment, right? So one thing that we can do is if we have a measurable protocol fault. So there are some protocol faults that you can't measure, but there's other protocol faults where you have clear cryptographic evidence that says a fault happened. So one example is that if you have a proof of work blockchain and you see two blocks that were built on top of the same parent, that is a clear, measurable, improvable network fault, right? Now, given that kind of fault, given a fault that we can unambiguously identify, we can often, inside the protocol, narrow down why the fault took place, at least within one of several scenarios.
00:31:30.438 - 00:32:02.610, Speaker A: So here's just one example. To go through a blockchain fork, right? So you have your network, the miners are just happily trudging along, and we have a happy, happy blockchain. Then you have block a. Then, uhoh, on top of block a, you have block b and c, and on top of block c, you have block d. And presumably on top of block d, char la la, happy blockchain again. But you still have this fault in the middle. So whose fault is it? We have five cases.
00:32:02.610 - 00:32:24.950, Speaker A: Case one is B ignored. CND. Right? So B saw C and D's blocks, or B saw C's block. But B said, screw you, I'm just going to build on top of a. This could be because B just really doesn't like C, or this could be part of a selfish mining attack. Or this could be because B's computer was corrupted. Lots of different reasons.
00:32:24.950 - 00:33:13.290, Speaker A: But the point is, it is a fault of pretending not to receive messages. Case two, C ignored B, right? So it's entirely possible that B made a block first, then C saw that block C could have built on top of it, but C instead said, screw you, I'm just going to build on top of a. And then D had a binary choice between B and C, and D just happened to pick C. Case three, C did not send to B, right? So C created a block, but C said, you know, what? I'm not going to send this block to these other miners. I'm just going to keep the block, and maybe I'm going to send it to D because he's my buddy. So that's also a fault case four, B did not send to C, right? So maybe B created a block, but B's are like, I'm not going to send that block. I'm going to try and selfish mine or whatever.
00:33:13.290 - 00:33:41.650, Speaker A: But B ended up not sending the block. C ended up creating a block, creating their own block. And Dn just built on top of C in case five network faults. Right? So they could have just created those blocks close to the same time. And because of network latency, they just ended up creating them on top of the same parent. So this is a fairly exhaustive categorization of what could have caused this to happen. Now, here's one thing that you might notice here.
00:33:41.650 - 00:34:28.674, Speaker A: You might notice that the false categorization here is symmetrical. All right? So for every story that blames B, you have a story that blames C. Now, what does this imply? Right? So here we're going to start looking at some of the kind of principles of crypto economic penalty assignment. So basically, if you have a fault, and that fault is, then the next question is, who can you blame for the fault? If you can blame one party unambiguously, if you can unambiguously prove that one specific party is faulty, then you should kick them and kick them again. Kick them again and kick them again until you've kicked their entire deposit down. Right. You're just trying to punish them as hard as possible.
00:34:28.674 - 00:35:20.510, Speaker A: And the reason is, well, why not? The more you can punish them, the higher your crypto economic security margin. Now, let's say you can't choose, let's say, you know, down to one of two people who's guilty, but you don't know which one. Now, one thing you could do is you could just kick both of them, right? You could just kick both, kick both, kick both, and they both lose their deposits. Now, this still has a high crypto economic security margin, but it has a flaw, right? Basically, because if in a protocol that works this way, there's a risk that innocent validators are going to wind up having to just getting completely destroyed, because they just ended up kind of falling in with the wrong crowd in some crypto economic sense. So even if it's not your fault, you could get slashed, right? Now, this is bad. Now, we still want to punish both participants. We still want to punish people who are faulty.
00:35:20.510 - 00:36:01.390, Speaker A: But there's a balance, right? Where you have to kind of trade off between having more crypto economic security margin and having a protocol that has larger griefing opportunities. So a protocol that has larger opportunities for people like actors to maliciously cause other actors to lose money. So there's a trade off. Now, third principle, pay for performance. So the total rewards paid to all actors should be an increasing function of some metric of protocol quality. The better the protocol does, the more you should pay people. So here is how you might assign penalties.
00:36:01.390 - 00:36:33.302, Speaker A: Now, you might notice that in the five stories we gave, a is exonerated, right? None of the five stories blamed A. D is exonerated. None of the five stories blames D. But B and C were each blamed equally. Right? The fault possibilities were symmetrical. For every story where B is at fault, there was a corresponding story where C is at fault. And so by the principles of crypto economic fault assignments, you would actually want to penalize B and C equally.
00:36:33.302 - 00:37:17.618, Speaker A: Now, notice this is actually a very substantial departure from the holy book of Satoshi, right. In the holy book of Satoshi, C gets a full reward because C is part of the chain, and B does not get a reward because B is not part of the chain. And that's it. But we're saying according to the crypto economic principal penalty assignment, which are better than the holy book of Satoshi, we can create a set of. Basically, they say that we should do this different thing. And if we do this different thing, then, first of all, we have more incentive compatibility. We have stronger performance under the coordinated choice model.
00:37:17.618 - 00:38:22.010, Speaker A: And as a side effects, this actually fixes selfish mining. Now, why is this better under the coordinated choice model, right? Any ideas? I'll give you a hint. Property three, pay for performance basically is like an exact synonym of working well under the coordinated choice model. Do people understand why that's the case? Okay, so basically, in the coordinated choice model, you assume that decisions are made by a coalition which is fully colluding with each other, right? And a coalition cares about its total revenues. Over here, I basically say total revenues should be an increasing function of protocol quality. So in accordance to choice model, basically the coalition is going to be incentivized to make protocol quality be as high as possible, so have as few protocol faults as possible. Now, basically, the idea benefits.
00:38:22.010 - 00:39:10.090, Speaker A: If we know someone is faulty, they'll be punished. Innocence may be punished, too, but we can kind of analyze griefing factors. We can analyze griefing bounds, and we can try and make sure this isn't too big of a problem and selfish mining issues are easier to resolve. So we can look at proof of stake in this model, right? So in proof of stake, you have a consensus algorithm where that consensus algorithm, instead of using proof of work, uses signatures that are assigned by bonded validators. Bonded validators basically means you are an actor in this network, and as part of the state, you have a deposit where the deposit is worth some amount of money, but you cannot take the deposit out. You cannot take the deposit out, at least without some kind of long time delay. And the protocol allows bonded validators to do things.
00:39:10.090 - 00:40:35.554, Speaker A: But if the bonded validators do something where they can be unambiguously attributed to be faulty, then the protocol will slash your deposit down, right? It's going to kick your deposit to death. And so properties that we want to have safety, now here we can have, unlike a blockchain, unlike a proof of work chain that only has convergence properties, basically, or that only has kind of probabilistic convergence and kind of linear economic security margin. Here we can have a notion of kind of hard finality where you can come up with a protocol where after enough validators sign enough of the right kinds of messages, you get to a situation where a block is finalized and can't get unfinalized. It just can't. Right? And we want to have a property of liveness. So basically liveness kind of as in proof of work, blocks keep getting produced and blocks keep getting finalized. One of the reasons why the crypto economic security margin of proof of work is very high, of proof of stake is very high is because in a proof of work model, because identities are anonymous, because miners are anonymous, the only way that we have to incentivize miners is by either giving them rewards or giving them privileges or taking away their rewards and privileges, right? So basically, if you want to have a crypto economic security margin of size x, you'd better be prepared to pay people x in proof of stake.
00:40:35.554 - 00:41:38.022, Speaker A: Because we have penalties, we can actually go much higher than that, right? So people are generally familiar with the notion that you can stick money into a deposit, you can earn interest on the deposit, you can take the money out, but potentially the amount that you have to pay, the mechanism has to pay people is only the value of the interest. And by the way, the interest could potentially be paid entirely in privileges, right? The interest could potentially be paid entirely in just the ability to collect transaction fees. The amount that you have to pay is only the interest, but the crypto economic security margin is the principal, and the principal is much higher. Right. So that's the basic principle here, no punishment intended. So here are some properties that we want proof of stake algorithms to have. Right? So this actually kind of follows along with traditional byzantine fault tolerance consensus theory in some ways, but there are some modifications because we're operating in this crypto economic setting.
00:41:38.022 - 00:42:37.578, Speaker A: So first of all, auditable safety, right? So auditable safety is kind of like the crypto economic version of byzantine fault tolerance safety. Now, if you look at proofs of security of traditional byzantine fault tolerance consensus algorithms, so things like PBFC, things like Paxos, all that fun academic stuff from the proofs, generally say basically this algorithm is safe because if it finalizes two incompatible values, that can only happen because at least a third of the participants in the network were dishonest. At least a third of the participants in the network acted maliciously. But here we have a stronger condition. We don't want to just have a situation where if the protocol fails, then at least a third are malicious. We want to have a situation that says if the protocol fails, then at least a third are malicious, and we know whom to blame. So that's actually slightly harder.
00:42:37.578 - 00:44:19.210, Speaker A: And in fact, if you use a synchronous BFT protocol, so if you use a protocol whose safety depends on a bound on network delays, then you actually can't unambiguously prove who is faulty. And so you can't get to kind of this auditable safety requirement. If you use algorithms that are safe under asynchrony, then it turns out there's an argument that you can basically convert any algorithms from the old model into algorithms that are secure under the new model by adding kind of the right layer, the right kinds of hashes and signatures to it. And basically the way that this works is that if you add the right kinds of hashes and signatures, you can kind of exhaustively enumerate all the kinds of faults, and you can prove that any fault is either a fault that you can unambiguously blame someone for, or it's a fault that you can kind of mathematically consider as being equivalent to network latency. So that's kind of where the reasoning comes from. Plausible liveness. So plausible liveness basically means the algorithm does not get stuck, right? So you imagine in order to satisfy the first condition, you're going to have to have some mechanism for penalizing validators for doing things that are bad, but you don't want to run into the opposite problem, where if you have an algorithm that's badly designed, then you could imagine that if this algorithm might accidentally get into a situation where it hasn't finalized anything and it can't finalize anything without some portion of the validators voluntarily violating these penalization conditions and voluntarily sacrificing their entire deposits.
00:44:19.210 - 00:45:13.310, Speaker A: So if a protocol had that property, it would also be bad. So here we have kind of plausible liveness, which means that basically the protocol can't get stuck. There always exists a path toward finalizing something there always exists a path toward kind of finalizing and agreeing on some block. So that's a bit of an introduction to kind of the latest branch of thinking about Casper. Here is a bit of an introduction to some of the latest thinking about sharding. So in a sharded blockchain, one of the most difficult problems that you have to deal with is something called the data availability problem. So basically the idea is this, if you think about a noncharted blockchain, so any blockchain that exists right now, this actually isn't an issue because full nodes can just download an entire block and they can validate themselves that a block is fully available in a shorted blockchain.
00:45:13.310 - 00:46:38.922, Speaker A: Basically the definition of a shorted blockchain is a blockchain where there is so much data in it and there is so much new data that is being constantly produced that there is no way for a single node to be able to download and verify all of it. You could imagine Etherscan having some servers that can download and verify all of it, but not regular users. So then the question is, how does a regular node actually verify data availability? Now here's one of the reasons why this is hard. If data is available, right? So if you had some magic oracle that you can use to kind of mathematically prove that some data is accessible and anyone can download it if they need to, then proving correctness. So proving validity properties is actually something that you can do with interactive protocols. So you can use various kinds of interactive verification, you can use kind of crypto economic binary research, you can use various fancy techniques where if someone does come up with something that's faulty, basically the network kind of comes together and generates a crypto economic proof that says, here is something that's worth point that everyone should look at and verify. And because of this kind of crypto economic pointer, every network sees, oh wait, there is an alarm here, I should check this thing and everyone can check for themselves.
00:46:38.922 - 00:47:16.630, Speaker A: Oh wait, there was a mistake here and the person who made the mistake gets penalized. So the problem is with data availability, you can't really do that and here's what, basically, data unavailability is not a uniquely attributable fault. So basically, if someone makes a block where the data is unavailable, you can never unambiguously prove that it was their fault. And this is the reason why. Consider two cases. Case one, node X published data d at time t three, when they were supposed to have published it at time t one. So they were supposed to have published it at time t one.
00:47:16.630 - 00:47:59.800, Speaker A: Instead, they waited until time t three and there was some node y, and that you could think of that node y as being a watchdog node, or I can gap term as a fisherman or some crypto economic policeman, whatever you analogy you want to use. And you can imagine node y correctly raised the alarm and notified you at time t two, that the data is not available. That's case one. Now here's case two. Node X correctly published the data at time t one as they were supposed to. But node y is a crooked cop. Node y published it, lied at time t two, lied and claims that the data was unavailable, even though in reality the data was there.
00:47:59.800 - 00:49:17.226, Speaker A: From the point of view of a node that looks at the situation after time t three, these two situations are completely indistinguishable. So this is the challenge, right? The reason why you can't use these kind of crypto economic techniques to zero in on data that's unavailable is because once you start zeroing in on the data, the attacker can just suddenly make the data available, and then the rest of the mechanism looks like it's trying to conduct a denial of service attack. Right? So there's this kind of, basically you're stuck with either having a mechanism that doesn't work or having a mechanism that can just give you denial, that can just be exploited over and over again as a denial of service vector. So this is a fundamentally hard problem. So one problem in a shorted blockchain is how do we finalize a state when we can't personally verify its correctness from the point of view of computation? You can use interactive games, you can use challenge response protocols, you can use crypto economic binary search, or you can just do a ZK snarp for data availability. What do we do so far? There's two major kinds of solutions that we've thought of so far. One of them is to rely on an honest minority assumption.
00:49:17.226 - 00:50:44.534, Speaker A: So what an honest minority assumption means is basically you will assume at least 15% of the network is going to be honest. Then you have a protocol that says basically 15% of some randomly selected set of validators that's responsible for some given shard can just hold it back from being finalized forever. Now if they keep doing this, they get penalized for it, right? But the kind of intention here is that we expect these 15% to be honest and we expect them to prevent any kind of bad block from being finalized. Now this has a problem, right? One of the problems is that, first of all, being part of this kind of altruistic 15% is expensive. So it's not clear exactly how sustainable this assumption is. And the second thing is that if this also opens up another kind of denial of service vulnerability where a malicious 15% can hold back finality forever, now you could argue that this actually is, well, you could actually come up with mechanisms where in order for the malicious 15% to do this, basically it becomes very expensive. And you can come up with mechanisms where this kind of attack is always more expensive and has worse trade offs for the attacker than just making easier attacks like spamming the blockchain with transactions.
00:50:44.534 - 00:51:45.230, Speaker A: But it's still kind of an issue. The second approach is to use erasure coding. So what do we do here? Basically the idea is that instead of using these kind of weird crypto economic tricks to try to make sure that data is available without people checking whether it's available, we actually have every node try to check the availability of every piece of data. Now it's a shorted blockchain, and in a shorted blockchain there's too much data for everyone to actually check and fully download directly. So instead what we do is instead of doing a full check, we do a spot check, right? So basically every node randomly selects a few branches, tries downloading the branches, and only if all of the branches pass. So if only all of the branches download correctly, is the node going to accept that block as being kind of legitimate? Basically it's a random sampling. It's a fairly kind of standard cryptographic technique used in a lot of situations.
00:51:45.230 - 00:52:51.620, Speaker A: If you do this kind of approach where for every block header, you kind of randomly poke at it in a bunch of places and all of the pokes come back with data, then you know that most of the block is almost certainly available. Now this scheme by itself has a problem, which is in a blockchain, you really want the data availability to be 100% availability, 99.99% isn't good enough, because what if the remaining 0.1% is the DAO? Right? What if you have a DAO which is one contract, and that DAO has $200 million in it, and some attacker comes along and presents a block where they suddenly make the state of the DAO unaccessible, even though that might only be 1% of the blockchain state or even 1% of the state of one shard, that's still unacceptable. So this is why we need a razor coding. So, with eraser coding, basically you can kind of expand the amount of data in a block such that as long as at least 50% of the data is present, that 50% can be used to reconstruct the entire 100%. So that's the basic idea.
00:52:51.620 - 00:53:31.578, Speaker A: So, open problems. So this is stuff that we are thinking about. One of them is optimal properties of consensus algorithms. How do we design consensus algorithms that have the best properties possible? Highest security margin, lowest cost, best performance under various economic models. Censorship resistance. So the challenge of censorship resistance is that censorship is a fault that's extremely difficult to detect, right. If you see a blockchain and someone claims that they're being censored, it's actually very hard to detect whether or not they're actually being censored.
00:53:31.578 - 00:54:29.810, Speaker A: So, for example, let's say that I send a transaction, and this transaction has a fee of one dollars. Here's how miners could potentially trick everyone else. Miners could themselves send a bunch of transactions into the blockchain, all of which have fees that are higher than $1 and make it look like my transaction never got included just because the fee wasn't high enough, even though actually they were discriminating against me. Now, even if you can't do this, one way of solving that problem is by making fees mandatory and burning part of them. Even if you do any kind of various tricks, a node that logs on later on can't tell when a transaction was published, right? So a node that logs on later on can't really tell whether or not censorship happened in the past. Now it can tell if there's censorship that's ongoing, because once a node does log on, then it can tell whether or not transactions are being included on time. But for stuff that happened in the past, you can't tell.
00:54:29.810 - 00:55:18.734, Speaker A: So this is a hard problem, maximally accurate timestamping. So, for a lot of applications, even if you look at kind of high frequency things, payments, financial applications, you want to have a clock that's as accurate as possible. Now, the Ethereum blockchain is kind of okay because you kind of have blocks every 14 seconds, and it's hard to cheat on the timestamps by more than a few minutes. But it's still not perfect. So the question is, can we have some timestamping some kind of clock that's much more accurate? So can we use things like sequential proof of work? Can we come up with some kind of much more accurate clock scale mold allegation? So this basically is how do we make shortened blockchains, and particularly how do we most optimally. And next, we solve data availability problems. So if anyone here has answers, you are welcome to join the research team.
00:55:18.734 - 00:56:20.470, Speaker A: Thank you. I would say it definitely is very new. I mean, I think with some of the work that's being done by myself and Vlad, it's definitely getting more rigorous over the last couple of years. It's not yet at the point of having kind of fancy pdf academic papers written in latex that get submitted to journals. But I think, well, okay, to some extent. To some extent it's getting there, right? So I would argue that any paper that was written about incentive analysis of blockchain protocols is crypto economics to some extent. But actually formalizing the foundation and getting everyone to agree on all these concepts is still a work in progress.
00:56:20.470 - 00:56:23.846, Speaker A: Yeah.
00:56:24.028 - 00:56:45.806, Speaker B: If we cannot mitigate between the two faulty, if we don't know who's the faulty one doesn't incentivize for centralization. Why we can create an ambiguous attack and make people who are small miners not identifiable. And as long as we punish them, they will disappear because the cost would.
00:56:45.828 - 00:57:26.842, Speaker A: Be too high for them, right? Yes. So you are correct that any kind of protocol that does try to punish actors in this way does have what's called a griefing opportunity. So basically, a griefing opportunity is when you can cause other people to lose money, but at some cost to yourself. So in any of these situations, if you create a one of two faults where you're one of the two, you lose a dollar, they lose a dollar. So we often analyze this in terms of the size of the griefing opportunity. So how much money can you make people lose? And the griefing factor. So if the griefing factor is three, that means that if you spend one dollars, you can cause other people to lose $3.
00:57:26.842 - 00:58:26.320, Speaker A: In these cases, the griefing factor is often one. Now, the question of can this be used to kind of either harm other participants or drive specific participants out or do other nasty things? The answer is yes. But as is always the case in crypto economics, you can always do bad stuff. You just pay some cost for it. So the important thing that you have to keep in mind, though, is that you want to make sure that you're not accidentally designing the protocols in such a way that kicking another actor out of the system immediately translates into a profit opportunity for you. So for example, bitcoin and ethereum, in my opinion, made these terrible mistakes in that they have this situation where the total reward paid to the miners is the same regardless of the protocol quality. And this basically means that if you can kick a small miner out, then you are directly profiting yourself.
00:58:26.320 - 00:58:47.720, Speaker A: Good crypto economic design involves making situations where even if you. Situations where you kind of maliciously act to reduce the experience for other participants in the network is not something that directly makes you money and should be something that directly costs you as much as possible.
00:58:48.890 - 00:59:04.806, Speaker B: Yes, I have a theory question in your table. How can you exactly claim that c is not at all, at all? Because D can make a very conscious choice about not sitting on top of B block.
00:59:04.918 - 00:59:53.478, Speaker A: Correct? Okay. So to some extent this does kind of depend on what the kind of implied protocol is. Because, for example, with bitcoin, the sort of theoretically correct behavior is that you're supposed to build on top of the first block that you saw in ethereum. What you're supposed to do is you're supposed to choose randomly, 50 50. And the reason why this is the case is because it was part of a recommended solution that was given to us by the academics at Cornell to reduce our vulnerability to selfish mining. Now, it definitely is the case that whatever kind of the initial rule is, you could decide, I'm not going to follow that rule, I'm going to follow my own rule. And you could call that a fault.
00:59:53.478 - 01:00:40.534, Speaker A: But at the same time, first of all, it's not really an attributable fault, because this sort of thing, it's based on private randomness. You can't prove that someone else is actually faulty if they did this. And the second thing is that just in my opinion so far, there isn't really a consensus that following some rule other than default rule actually is something that's faulty. So far I think there's a lot of people that just have the opinion that if there are multiple competing logist chains, you should just have a choice of which one you pick, and that's fine, but if we really want to kind of be a stickler for which rule you should follow, yes, you could think of it as being a fault, but it's one that's extremely difficult to attribute.
01:00:40.662 - 01:00:43.180, Speaker B: Yeah, I got a question about it.
01:00:50.610 - 01:01:34.056, Speaker A: There's not really a formula, it's more intuitive. Basically the idea is that if you choose 15%, that means that you're trusting that there's not going to be a situation where more than 85% screw you over. But at the same time you're also giving 15% in the ability to make your life moderately difficult. If you go up from 85% to 99%, then you have a much, much stronger margin on one side, but on the other side it becomes really cheap to just basically stop the blockchain from moving forward. So that's the trade off. Yeah.
01:01:34.238 - 01:01:39.640, Speaker B: Do you know whether in the near future there will be any light clients for mobile?
01:01:39.980 - 01:02:19.300, Speaker A: So in proof of work Ethereum, there already are light clients. So there is a client called left and another one called status, and they actually are light clients. And these are things that are already in their alpha stage. And if you want to, you can use them now. Then there are protocol improvements that are in the pipeline that would facilitate making better light clients. So for example, in metropolis there is a planned improvement proposal that would allow light clients to be more secure by kind of probabilistically validating the header chain instead of fully validating it. And in proof of stake, you can also do lots of various tricks to try to make the litecline protocol stronger.
01:02:19.300 - 01:02:28.344, Speaker A: But in general, I would say at this point the litecoin technology is very far along because I already used the.
01:02:28.382 - 01:02:33.948, Speaker B: Likelihood option of gap. Would be really nice to have it in. Nice application.
01:02:34.114 - 01:02:44.670, Speaker A: Totally, yeah. I would highly recommend you download status and try it out. Yes.
01:02:45.380 - 01:02:47.456, Speaker B: So the crypto economics assume just that.
01:02:47.478 - 01:03:40.400, Speaker A: Everyone is rational, or did you look into any compensating mechanisms? Yeah. So there's different kinds of models. Right. So there's some models that are kind of fully crypto economic, there's some that are partially crypto economic, there's some that kind of assert various kinds of imperfections in either people's thinking or in people's abilities to coordinate. In general, my preferred methodology is that I want to build protocols that are secure both in the crypto economic model and in a two thirds honest majority model. And there's also a lot of models that rely on kind of hybrid approaches. So like this honest minority plus kind of coordinated choice is one option that's fairly popular.
01:03:40.400 - 01:04:26.140, Speaker A: My kind of general actual beliefs on this is that reality. It definitely is in some cases approximated by honest majorities, though in some cases their honesty has limits. So, for example, if the protocol tells them to just burn all their money, then they're probably going to be dishonest fairly quickly. In some cases, though, I do think that these kind of crypto economic bribing attacks are fairly realistic. And the reason why I say this is because oftentimes the bribes don't even actually look like explicit bribes, right? No one actually says, moha, I'm going to give you $50 to wreck the protocol. Instead they say, oh, I am going to open up a new mining pool. And this mining pool is going to pay 5% more than all the other mining pools.
01:04:26.140 - 01:04:55.156, Speaker A: And I'm not going to tell you that I thought five extra 5% is a bribe for me. I'm just going to make the mining pool 5% better and I'm paying in the 5% quietly. And then when I have enough hash power, I'm going to break the network. This is a totally plausible attack vector. And you could imagine if, for example, one thing that people often like doing is coin voting, right? Where if you want decentralized governance of a blockchain, let's just have everyone vote on it. Problem is, voting works well in uncoordinated choice. It works well in coordinate choice.
01:04:55.156 - 01:05:44.090, Speaker A: It works terribly in a bribing model. And in a coin voting model is basically, you could imagine people creating either exchanges or kind of interest paying banks and incentivizing people to throw their money into them. And then these parties would just end up. There would be kind of this hidden catch that if you're using this wallet, then they would basically vote on your behalf. And what you're really doing is you're kind of selling away kind of your share and the voice in the system, because that's something that's kind of more of a public good than a private good. So, yeah, in general, I think the real world is variable enough that it's really worth looking at all the models. Yes.
01:05:45.340 - 01:05:47.464, Speaker B: Can you make these slides available?
01:05:47.662 - 01:06:15.680, Speaker A: Yes, they're actually already available. I forget the link. Yes, actually, I think if you go onto my Reddit profile and you scroll down a couple of pages, eventually you have a link, it's a PDF on Vitalik CA if anyone wants to kind of sort through it that way.
01:06:16.450 - 01:06:27.534, Speaker B: And how do you finalize the proof of stake? Because I read this paper about proof of stake is impossible, and they have this attack vector where you bribe the former.
01:06:27.582 - 01:07:35.654, Speaker A: Okay, so there is two major classes of objections to proof of stake. One of them is called nothing at stake. And this is the thing that you're talking about. There's also a second one that's called stake grinding, but that's actually an attack on specific kinds of bad random number generators. And that's, in my opinion, it's like a less fundamental and much more technical thing, and modern algorithms have already figured out how to deal with it, but with nothing at stake. The idea basically is that older proof of stake algorithms, so things like pure coin, things like most of what actually, even what most proof of stake cryptocurrencies are using now, they do not use penalties, right? They actually all only use rewards. And proof of stake without penalties doesn't really work well, because basically, if you just kind of try and naively simulate proof of work, and you just give people rewards for making a block that's on top of the chain, then if at any point there is a fork, you have the incentive to make a block on top of every possible chain at the same time, because, oh, there's always some chance that this chain wins, and I might as well try and claim a reward inside of it.
01:07:35.654 - 01:08:41.370, Speaker A: So that's roughly why the idea behind the nothing and stake attack. Now, the bribing portion of the attack basically says if you're an attacker, then you can bribe people epsilon to create blocks that extend your chain. And basically, as long as your bribe kind of exceeds how altruistic people are, then everyone's just going to make blocks on top of your chain. Your chain is going to grow to be the longest, even if it's reversing like a very long number of blocks and transactions. The way that basically these issues are all dealt with in modern proof of stake protocols, because they do rely on penalties, they do rely on basically penalizing validators for making kind of, basically for equivocating, for kind of like making blocks or making messages that are contradictory with each other. And that's what solves nothing at stake issue. Okay, any more questions?
01:08:41.440 - 01:08:42.280, Speaker B: And thanks.

00:00:01.770 - 00:00:44.534, Speaker A: Thank you. So I'm going to talk about a hybrid construction for VDF provers, a hybrid between two previous provers that were already mentioned this morning, which we'll call the Veselovsky prover and the Pierce act prover, which I'm going to present in more technical details than what was just briefly mentioned in previous talks. So first, as was already said, it's a scheme that works in a group of a known order. So we're going to fix a group g. I'm just going to write it g. But imagine an RSA group or a class group, whichever you prefer. And basically the VDF is a sequential amount of squarings.
00:00:44.534 - 00:01:54.794, Speaker A: So the input of your VDF would be an element g from the group, and then you have to square it t times until you obtain the final element g to the power two to the power t, which is the output of your VDF. So you could just pick that as your VDF. But then the problem is, can you efficiently verify that the output has been computed correctly? So say you're given a pair g and h that Alice claims h is the output of the VDF on input g. Can anyone verify this claim without having to recompute everything? So can Alice convince the entire world that she did the computation properly without having everyone recompute the whole thing? Because it takes a lot of time. So here's the problem we're trying to solve. Alice wants to prove that h is the correct output, and the way it's going to be done is thanks to some auxiliary proof. So Alice, when she's evaluating the VDF, not only she's exponentiating gt times to obtain h, she's also computing some kind of proof, which is a helper for everyone else to verify that the computation has been done properly.
00:01:54.794 - 00:02:32.666, Speaker A: We will call this PI the proof. And now, given the triple G h and PI, anyone can efficiently verify that h is g to the power two to the power t. So mostly two methods have been proposed to provide efficient proofs of the statement. One, which we'll call the Vysolovsky proverb, provides very small proofs by. So the proof is essentially one element from the group g, and the verification is very efficient. It's going to be two small exponentiations in the group. But computing the proof PI will take a little bit of time.
00:02:32.666 - 00:03:18.620, Speaker A: It's going to add some overhead to the whole VDF computation. So it's not going to be as long as the VDF computation itself. So you're going to have to do t sequential squarings to compute your VDF, and then you're going to have a little bit of extra work, which will be around maybe 10% of the time it took you to reevaluate the VDF, and 10% can be a lot. Want to maybe reduce that? The second construction proposed by Apiachak proposes proofs that are longer, around 40 times longer for reasonable parameters, and the verification is also slower by the same order of magnitude. But computing the proof by is extremely efficient. It adds pretty much no overhead. So you do your VDF computation, you do your t squarings, and then the proof comes pretty much for free with a negligible cost.
00:03:20.110 - 00:03:24.010, Speaker B: Can you compare the space requirements for generating the proof?
00:03:24.750 - 00:03:51.650, Speaker A: So for generating the Pierchak proof efficiently, you're going to need square root of t, around square root of t, or memory. And for the Viselwassi proof, it's more tricky. It depends on how fast, how optimal you want your prover to be. You can get pretty close to the best speed up also with square root of t group elements.
00:03:51.730 - 00:03:56.902, Speaker B: And you did this all at one time. You can't do it like sort of streaming, like you need square root t elements at some point.
00:03:56.956 - 00:04:39.990, Speaker A: Yeah, it's square root t pre computed values. So values that you've encountered during this computation. I'm going to say a bit more on this when we go into the technical details. So a question, and a natural question is, can we get somehow the best of both worlds? Can we combine these constructions in a way that we get small proofs, efficient verification, but also computing the proof is fast. To simplify the presentation, I'm going to present everything in an interactive approach. So originally we say we have Alice that wants to evaluate the VDF and convince the rest of the world in an interactive setting. She just wants to convince a verifier bob and they are allowed to interact.
00:04:39.990 - 00:05:11.374, Speaker A: This will be simpler to present, and then you can use some standard tricks to remove the interactivity of the scheme and get some non interactive VDF. So first the Veselovsky prover, so presented in this interactive setting. So it's a discussion between Alice and Bob. Alice claims that the spare GH satisfies h equals the correct output of the VDF. And now there's going to be an exchange between Alice and Bob. Alice tries to convince Bob. That is correct.
00:05:11.374 - 00:06:01.354, Speaker A: So it's going to be a challenge response exchange. The challenge will be random, rather large prime number l. Large means not as large as RSA parameters, but something like 100 bits or 200 bits. So Bob sends this random prime number to Alice. Now Alice is going to compute the euclidean division of two to the power t by this random prime l. So you get that two to the power t is the quotient q times the random prime l plus some remainder, and Alice sends to bob the proof PI, which is the element g, raised to the power q, the quotient. Now Bob can easily compute the remainder of this division by l, which is r, and then he's going to accept the proof if this equality is satisfied.
00:06:01.354 - 00:06:44.960, Speaker A: So the proof PI to the power l times the element g to the power, the remainder equals h. So it's very easy to see that if everything went correctly and everyone did his job honestly, then the equality is satisfied. Just have to replace PI by g to the q. And then you see that you get g to the power, the q times l plus r, which is just g to the t. So then it's correct. It's a little bit more tricky to see that it would be difficult for Alice to produce a proof that satisfies this equation if the initial statement is wrong. I'm not going to go into the security reduction, but we can say something like, if Alice is capable of producing misleading proofs, she's able to solve some supposedly difficult problems in groups of unknown order.
00:06:44.960 - 00:07:02.770, Speaker A: So this is the interactive version. You're going to make this non interactive by replacing Bob by a hash function and Alice to provide a non interactive proof which will just pick the prime l to be the next prime of some hash of everything that is in the input of the protocol.
00:07:04.970 - 00:07:07.046, Speaker B: The number of rounds will be of.
00:07:07.068 - 00:07:15.960, Speaker A: Your interactive proof will be t. No, this is the entire proof. One round. Yeah.
00:07:16.810 - 00:07:22.786, Speaker C: I think that this has good soundness. I think you're asking about the soundness in the protocol. This has good soundness.
00:07:22.898 - 00:07:23.560, Speaker A: Yeah.
00:07:24.170 - 00:07:26.454, Speaker C: Sound there is very low. They only have to repeat once.
00:07:26.492 - 00:07:52.210, Speaker A: Yeah, exactly. You have to repeat only once because the soundness is very low is very good. So just to sum up the construction in a non interactive fashion. So if Alice wants to evaluate the VDf on input g, first she's going to compute h by t. Sequential squaring. This is the slow part. Then she's going to have to compute the proof, and to do so she's generating the next prime of the hash of everything she computed.
00:07:52.210 - 00:08:07.910, Speaker A: Then she's going to compute this euclidean division and compute the proof PI, which is g to the power, the quotient, and the output of the VDf is the pair h, which is the actual output, and PI which is the proof. So only two group elements.
00:08:09.210 - 00:08:25.270, Speaker C: Yeah, practically, it might make more sense to just hash ght and the non and then send the nonce along, because then the verified only has to do one primary check. You can hash ght and anonce until you hit a prime.
00:08:25.350 - 00:08:25.786, Speaker A: Yeah.
00:08:25.888 - 00:08:26.946, Speaker C: Choose anonymous freely.
00:08:26.998 - 00:09:13.142, Speaker A: Yeah, true. The question is, you can have a nounce in the hash so that the nouns necessarily gives you a prime number. And then the verification doesn't need to compute the next prime. Yeah, so you get a small output, only two group elements, and a fast verification, because you essentially have two small exponentiations in the group. Now the big question is, how can you compute this proof efficiently? Because it's d to the power q and q has a pretty big bit length. It looks like it's going to be as expensive to compute PI as it was to compute h. You want to go a little bit faster.
00:09:13.142 - 00:09:58.700, Speaker A: So what are the main methods to compute PI? So the trivial method would be to just do a long division to compute your coefficient q, and then you compute PI, which is d to the q. But this will take essentially time and space bigger of t, because q is bigger of t bits. So it's going to take a while and a lot of memory. So first you have a no memory variant. If you observe that to compute your exponentiation PI to the q, you're going to use the bits of q one at a time. So you can just, instead of computing q at the beginning, just compute it on the fly with this formula, which gives you the bit, the binary expansion of q. So now no memory, but still time big o of t.
00:09:58.700 - 00:10:42.054, Speaker A: Now there are faster variants if you use some pre computed values. So when you're computing h, which is g to the two to the t, you encounter a lot of powers of g on the way. You encounter all the powers of the form g to the two to the I, where I is between zero and t. You can store a bunch of them and they are going to help you in computing the exponentiation by q much faster. So if you store around square root of t intermediate steps, you can compute the proof PI in time, essentially two t divided by log t. So here's the first challenge. Can you do better than that? The problem can be expressed very easily.
00:10:42.054 - 00:11:30.550, Speaker A: It's just suppose you're given a bunch of pre computed values of the form g to the two to the I, and then you're given a random number q of t bits. How fast can you compute g to the q? So with the current methods, you can go as fast as t divided by ab, where ab are any two parameters that you want. No, sorry. Using t divided by ab precomputed values, you can compute the exponentiation in time t divided by a plus b times two to the a. So then you can tune a and b to minimize this. And this is how we find this, possibly two t divided by lock t runtime. So a first question is, can you go faster? And a second, can you go, well, maybe as fast, but with less precomputed values.
00:11:30.550 - 00:12:05.018, Speaker A: This is a pretty fun, pretty fun challenge if you like all kinds of tricks to do very fast computations. So now the second prover is a phacks prover still. I'm going to present it in an interactive setup. So the idea behind the pitch proverbs, you take a recursive approach. Alice wants to prove to bob that H is the correct output for the VDF. And you observe that the output of the VDF is essentially, you take t squarings. So it's a long sequence of squarings.
00:12:05.018 - 00:13:02.246, Speaker A: You can cut this sequence in the middle, and then you have two sequences of half the length. And the idea is, can Alice prove simultaneously the two pieces of the path? Can she prove simultaneously that g prime, the value in the middle is the first value raised to the power two to the power t over two, and that h, the last value, is the middle value raised to the power two to the power t over two. Okay. And if you can prove both of them simultaneously, you can take a recursive approach and divide by two the length of what you're trying to prove at each step. And in fact you can by using some random linear combination of your two equations that you're trying to prove. So to obtain a random linear combination, we're going to let Bob choose how to combine them. So Bob chooses a random integer r.
00:13:02.246 - 00:13:48.440, Speaker A: And then we consider the two new elements, g one which is g to the power r times g prime and h one which is g prime to the power r times h. And now the statement that Alice is supposed to prove is the linear combination of these two statements, recursive things, you have to store a bunch of values. And essentially, in the end, you can see that by storing square root of t intermediate values, the whole proof can be computed in square root of t group operations. So square root of t group operations, it's totally negligible next to the big o of t cost of computing the vdf. So the proof comes almost for free. So computing the proof is very efficient. But the proofs are longer.
00:13:48.440 - 00:14:35.140, Speaker A: Why? Because each round of the, of the, of the, of the proof, every, every recursive round, you increase the length of the proof by one group element. So in the end, the proof consists in around log of t group elements. So for realistic parameters, log of t will be around 40. And if you're using an RSA group of 2000 bits, in the end you get a proof that is around 10 kb, which is a bit more than what you would like. So now you could try to combine the two approaches and get smaller proofs that are easy to compute. So the hybrid construction is pretty straightforward. It's not so difficult to figure out.
00:14:35.140 - 00:15:37.990, Speaker A: Still same problem. Alice wants to prove the statement to Bob. They can first do a few rounds of the pH act prover, and after k round they end up with proving a statement of the form h prime equals g prime to the power two to the power t divided by two to the k, because each round divides by two the length of the statement you're trying to prove. So in the end you have a length of t divided by two to the k, so each round divides by two. And at the end you have this kind of statement to prove, where h prime and g prime are not the same as the original h prime and g prime, though. But then, instead of continuing with your Phak proof until you reach a thing that is trivial to prove, you stop there and you use a Vizzolovsky prover, which can produce a proof for this statement, which is only one group element and can be computed in time bigger of the length of the statement t divided by two to the k, or faster. If you're trying to use some optimizations with using precomputed values.
00:15:37.990 - 00:16:20.530, Speaker A: Okay, so how efficient is it? So if you're using k rounds of phak and then Visilovsky, each round of phak adds one element to the proof. So in the end you have k plus one group elements. So that's the length of the proof. And now how difficult is it to compute it? So we can neglect the cost of the Phi crowns because they are very efficient. And if we look only at the cost of computing the final Wezelovsky proof, it will be bigger of t divided by two to the k. So you can tune your parameters like this, depending on how fast you want to be, you can go faster by having longer proofs. So it's a trade off.
00:16:20.530 - 00:17:15.040, Speaker A: Now you can use some optimizations using pre computed values for the Visolwski proof. And essentially, if the number of rounds you consider it a constant then the cost of computing the Visolovsky proof is essentially big o of this fraction there. When I say k, a constant, I mean that in the big o, you have some dependencies in k. There are constants in the big o. So why is that? Why having too many rounds will be a problem? It's because to compute the Viselovsky proof, say, for the statement h equals g to the two to the t as fast as possible. If you want to use all the optimizations, you need to use the pre computed values of the form g to the two to the I. And these are readily available.
00:17:15.040 - 00:17:42.890, Speaker A: You encountered them during your initial computation. But now, once you've done a few rounds of your checks, proof you don't have gnh anymore. You have h prime and g prime, which are new, so you need to update all your precomputed values. So if you have a lot of pre computed values, this will be very costly to update them all. We can do it. We can transform all the precomputed values of the form g to the two to the I into g prime to the two to the I. It comes with a cost.
00:17:42.890 - 00:18:11.748, Speaker A: Essentially, the computation that you have to do is something like this. So this is another challenge. Try to compute this as fast as possible. So you're given k integers r zero, r one up to rk minus one. These are the random numbers that are issued by Bob in the interaction. And then you're given two to the power k group elements, c zero, c one up to c. There's a typo there, c two to the power k minus one.
00:18:11.748 - 00:18:58.530, Speaker A: And then you have to compute this big products, which are product of, it's the product of all the values c n raised to the power products of r eyes, where you pick only the r eyes, where the ice bit of n is one. If you can compute this super fast, then you can update all your pre computed values super fast. So this is another challenge to do this as fast as possible. Currently, we know how to do this in time. Two to the k minus one exponentiations by ri values plus as many group multiplications. But it's not clear that this is optimal. So, can you do better, or can you prove that it's optimal somehow? That would be interesting.
00:18:58.530 - 00:19:09.572, Speaker A: That's it, yes.
00:19:09.706 - 00:19:36.830, Speaker D: So for the original Westlowski proof, not the hybrid. So you're taking two to the t, and then you're doing the remainder. Two to the t equals ql plus r, and you're worried about the bits of q, but you can control the size of q by making l, like just big enough so that Q's powers are much less than t, like square root of t. So can't you just use this to control the number of squarings you need to do?
00:19:37.840 - 00:19:38.828, Speaker A: You mean.
00:19:38.994 - 00:19:44.272, Speaker D: So here you are worried about the fact that for q, like, computing g to the q is expensive, right?
00:19:44.326 - 00:19:44.544, Speaker A: Yes.
00:19:44.582 - 00:19:48.896, Speaker D: So why don't you just control the size of q by controlling the size of l?
00:19:49.078 - 00:19:55.504, Speaker A: Okay, so the question is, if I understand properly, can you make Q smaller by choosing L bigger?
00:19:55.552 - 00:19:56.788, Speaker D: Because we know how to make a.
00:19:56.794 - 00:20:13.144, Speaker A: Prime, except they are really like different orders of magnitude. L will be. You don't want Bob to generate a prime that's pretty much as long as half the length of two to the t. That would be an enormous number.
00:20:13.342 - 00:20:16.664, Speaker C: I think it's good to give numbers. L is like a 128 bit prime.
00:20:16.712 - 00:20:17.052, Speaker D: I see.
00:20:17.106 - 00:20:17.468, Speaker A: Yeah.
00:20:17.554 - 00:20:20.190, Speaker C: Due to the t is 40 billion bits or so.
00:20:21.120 - 00:20:22.350, Speaker D: I see. Okay.
00:20:23.200 - 00:20:23.950, Speaker A: Yes.
00:20:26.560 - 00:20:40.784, Speaker C: In terms of efficiency, a similar approach would be maybe to compute the velocity proof for the first half, then from half to the three quarters and so on and forth. Because these proofs are going to finish before you finish the computation.
00:20:40.912 - 00:20:45.492, Speaker A: Yeah. This is what Justin referred to as the iterated least.
00:20:45.546 - 00:21:06.984, Speaker C: I mean, there it seems to have the same proof size, and you don't have to. Well, at least you don't get the overhead of computing. I know the overhead of computing Christopher's proof is small, but at least you don't have it at all, because most of your proof will finish before you're done with the computation.
00:21:07.032 - 00:22:05.500, Speaker A: Yeah. So the question is, can you do a Viselovsky proof for, say, the first half, and then a Viselovsky proof for half of what remains, and then something like this, using the fact that computing the proof is anyway shorter than the whole computation. I guess this is an approach that we explored. Yes. And one of the possible problems will be that it's unclear at the moment how much faster it will be to compute the proof, because here we give counts in terms of number operations in the group. But multiplications will be maybe twice as expensive as squarings. And you need to do a lot of multiplications in your proof, but you don't need to do any multiplication in the VDF evaluation, so you could get maybe a new factor two in the time it takes you to compute the proof, just from the fact that you need to do multiplications instead of squarings.
00:22:05.500 - 00:22:16.016, Speaker A: But maybe if the multiplication is fast enough compared to the squarings, maybe that's an approach that should be considered. Well, yeah.
00:22:16.038 - 00:22:31.376, Speaker C: Then I think. I'm wondering whether then you can also, once you computed the proof for the first step, you can throw away those values. But that probably doesn't throw away the intermediary values for the first time.
00:22:31.498 - 00:22:48.750, Speaker B: It's something mean. Again, I don't know much about it, but just going on what Benedict is saying, you can compute mercury trees with order log space. You keep accumulating, and you can always store just log number of values at any point of time.
00:22:49.760 - 00:22:51.756, Speaker A: Yeah, I guess possibly you could do.
00:22:51.778 - 00:23:00.632, Speaker B: This to block these things. Again, I'm just speculating here. If you had sort of some way of accumulating these proofs and discarding values that you don't need, then.
00:23:00.706 - 00:23:06.960, Speaker A: Yeah, well, I guess that's many directions that remain to be explored. Work for this afternoon.
00:23:08.180 - 00:23:10.288, Speaker C: Yes, I guess as a follow up.
00:23:10.294 - 00:23:20.432, Speaker E: To the idea of picking a bigger l, you said you don't want Bob to generate a random l, but in the non interactive form, it's really the prover. And if you use a non strip.
00:23:20.496 - 00:23:22.868, Speaker C: Trick, then all the work and the.
00:23:22.874 - 00:23:24.560, Speaker E: Verifier only has to verify.
00:23:24.720 - 00:23:49.008, Speaker A: Yeah, so the question is, it's not Bob's job to generate a random l because we are going to use a non interactive version anyway. So it will be Alice's job. But in any case, generating an enormous prime will be so costly, you cannot. And the verification becomes expensive if L is too big, because you have an exponentiation by L to do. Yeah.
00:23:49.094 - 00:23:56.820, Speaker E: I was just wondering if there's a trade off, though. If you make it a little bit bigger, does it get.
00:23:56.970 - 00:24:07.236, Speaker A: I think it gets to a really minimal advantage to pick a big L because what if you just double it?
00:24:07.258 - 00:24:08.740, Speaker E: Do you go faster or slower?
00:24:09.320 - 00:24:32.280, Speaker A: Q is two to the t bits, and then you subtract to that. The bit length of L is going to be extremely close to the t unless you pick l to be outrageously bigger.

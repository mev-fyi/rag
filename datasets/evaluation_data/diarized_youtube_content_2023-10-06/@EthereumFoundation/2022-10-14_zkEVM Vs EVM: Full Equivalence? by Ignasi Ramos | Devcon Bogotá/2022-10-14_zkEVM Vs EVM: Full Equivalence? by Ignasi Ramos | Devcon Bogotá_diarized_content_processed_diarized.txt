00:00:13.130 - 00:00:50.922, Speaker A: Hello everybody. First of all, I would like to thank you to the Depcon organizers for giving me the chance to do this talk. And also thank you all of you, for attending the talk. My name is Ignaci Ramos, I work for Polygon CKBM and I am at the protocol team. It's been a year, a year and a half that we've been working very hard to release the CKBM. And I am very happy and very proud to announce that on Monday it was announced the release of the CKBM on public Testnet. So I would ask you to do an applause for all the Polygon team that they did that effort, that it's enormous.
00:00:50.922 - 00:01:51.600, Speaker A: So thank you very much. The title of the presentation is DKVM versus EVM, full equivalence. Okay, so a little bit, what are we going to talk about? First of all, I will do like an overview to give some context about what is a CKBM, and then I will go more concrete on what is the Polygons CKBM. After that we will go to the topic of the talk, which is the difference between the CKBM, the polygons CKBM and the ABM. So what is a CKBM? Well, there are three statements that I think that they define the minimum of a CKBM, which is that it is a virtual machine that executes smart contracts in a way that is compatible with zero, no less proof computation. And why would we like to do this? Because our expertise is scale Ethereum. We want to increase, like the throughput of Ethereum, the transactions per second.
00:01:51.600 - 00:02:55.534, Speaker A: At the same time, that will lower the fees. So how can we do it? We use GKSNar technology to make cryptographic proof of execution of ethereum like transactions. In a summary now, when you process like a batch with a lot of transactions, you get a result, you get an output, you get an estate. So how can other people, how can other ones to trust you that this process, this process of the batch has been done with correctness has been done correctly, following like the EVM constraints, they have to process also those transactions and see that the output is the same. With zero knowledge proofs, we can do it easily, because we can, after processing all those transactions, create a zero knowledge proof. And if someone wants to validate that this transaction have been processed correctly, like following the constraints of the ABm of the FICABm, in this case, they only have to verify that proof. And this is faster.
00:02:55.534 - 00:03:40.782, Speaker A: Also, the verification of a proof, it's always constant, which is very interesting, actually. This is like a game changer in the ecosystem. I remember it was around the SCC that a lot of companies were doing announcements of releases of three kvms, and it created a lot of noise, especially in social media and in many places. And a lot of people was very confused because a lot of new words appeared there, like compatibility equivalence. What is the proverb? I don't know, but luckily we have like Bitalik that he did a very interesting blog. Actually, I strongly recommended to read it. When he classified the ckvms in five times, he created what I like to say like the CKVM dilemma.
00:03:40.782 - 00:04:18.030, Speaker A: Like if you have more performance, you have less compatibility, and if you try to have more compatibility, you will have less performance. Actually, at Polygon CKVM, we aim to be from type two. We are not there yet because we still have to finish the pre compiles, but we will be there very soon. Actually we are like 2.2. So the advantage of this type two is that it has a lot of compatibility. It has as much compatibility that we can talk about equivalents. The disadvantage is the performance.
00:04:18.030 - 00:05:12.622, Speaker A: In Vitalik post he said that it takes like a lot of time to generate the proof. Well, this is a bit relative. I mean, what is a lot of time? Now we are generating proof in around five minutes, but we still know how to do it, and we have a lot of ideas in mind on how to reduce this to up to five minutes. And also it's not that big problem because you also can parallelize the proofs. First of all, I would like to explain very simply, when we talk about equivalents, what are we talking about? We're talking about that putting the batch of transactions in the EVM and putting exactly the same batch of transaction or the same block or whatever to the ZKVM and get the same state. And when I say state, it's like the same state route. And when they have the same state route, it means that the storage, the state of the blockchain is exactly the same.
00:05:12.622 - 00:05:48.330, Speaker A: It means that all the accounts have the same balance with the same nodes, with the same bio code, with the same storage, with whatever. They are exactly the same. So are different black boxes, because internally they work differently. But the equivalence means that for the same input they have the same output. I could be like a lot of time explaining how we've done it, and there's people here sitting that could explain it by far better than me. So I just do some sentences just to put some context. Also, it's not the topic of the talk, but we can discuss about it later.
00:05:48.330 - 00:06:32.810, Speaker A: But at the end, what we're doing is a processor, okay? And a processor has clocks. So each clock, it's like a new state. And we are playing with these new states as steps. So as all processors, you can build an assembly at the top of them, you can build an assembly language to define these steps. And this is what we've done with a language called Gkassembly. With GK assembly, we try to replicate the behavior of the EVM in an assembly language. When this assembly language is compiled, it creates like a build, which is a big trace of all the steps that will define the processor.
00:06:32.810 - 00:07:14.950, Speaker A: On the other hand, we have the build the polynomial identity language with, it's like one or step more of circum 2.0. It's also a language done by our tech lead, Jordy Valina. And what the executor does is that he gets the ROM, which is the build of the CK assembly language that I just explained it. He also uses the pill where there are the state machines of the ethereum defined there, and he verifies the correctness of each one of the steps of the Ram while it process the transactions. So more or less, this is how it works. Like I'm just scrapping the surface. This is how it works, the CKBM.
00:07:14.950 - 00:07:49.166, Speaker A: And of course, as all other processors, we also have a ram and a storage. Now let's talk about the variances between both of the evms. As you may know, the EVM uses a patent merkel tree, while we are using a sparse emergency tree, where the leaves are indexed in each leaf of the evm we store. Well, it just stored all the information of the account. They have the nons, the balance, the store at roots, and the code hash. But we are doing it differently. We are doing it differently.
00:07:49.166 - 00:08:24.910, Speaker A: On each leaf we only store one property of the account. So this brings me to the second difference, which is the hash. For the evm. It's used the KTAC, but we are using the poseidon with the Goldilock prime number as definite field. This is for performance reasons. So when on Ethereum you want to get the key of a leaf, you have to hash the address. But as we only can retrieve like one property of the account for each leaf, we have to hash the address with a property key.
00:08:24.910 - 00:09:05.050, Speaker A: For example, if we has the Ethereum address with the property key of balance, we will get the leaf where is stored the balance. Another difference is that Ethereum uses more than one tree to define all the system. As you can see here, in one of the leaves there's the storage route. The storage route points to a different state tree where the storage is stored. We are doing it differently. We only have one tree that defines the whole system. Another difference is the memory the ABM uses for each lot of memory.
00:09:05.050 - 00:09:38.630, Speaker A: Eight bits, one byte, and we are using 256 bits. Let's like 32 bytes. So we are working with biggest memory slot. This makes that when you are querying to the memory, the information that you get, it's the same, but the way that you obtain the formation, it's a bit different. I mean, the internal logic of some of codes had to be changed a bit. I will show you an example now. For example, for the upcode m load.
00:09:38.630 - 00:10:03.094, Speaker A: With m load, you load 32 bytes from the memory. Well, there are different cases. Some are more tricky than the other ones. This is the easiest one. When you want to get just 32 bytes, you just ask for it and you have to return the fullest lot. In our case, it's the fullest lot because we have a slot of 32 bytes. The fullest lot of the memory in case of the offset is different from zero.
00:10:03.094 - 00:10:42.130, Speaker A: Well, when I say different from zero, I'm talking about mod 32. It means that the beginning of the slot is not the beginning of the memory that you want to retrieve. Maybe you will have to get like half of the memory from one slot and half of the memory of the next slot. And it gets a bit more tricky. Sorry. When you want to retrieve more than 32 bytes, in this case, for example, more or less than 32 bytes. In the first case, for example, we are only retrieving some bytes of one slot, in the second case, just the bytes in the middle of the slot.
00:10:42.130 - 00:11:42.970, Speaker A: And in the third case it's like if you want to do it with offset, different from zero, and also more than 52 bytes, then maybe you have to get some bytes from one slot, then get the whole bytes of the following three, four, five slot, whatever the length is, and some bytes from the last slot. The CK counters. Yeah, another difference, probably this is very new for a lot of you. I will say that the behavior is like gas, but it doesn't replay gas. I mean, we are computing the gas exactly the same way as Ethereum does. But as I said before, we have a limited number of step in the processor, right? So when you are processing a batch, you have a limited number of steps, and also you have a limited number of state machines that you can consume while doing an upcode or an operation. So in our implementation of the three KVM, I will show an example just after this slide.
00:11:42.970 - 00:12:32.146, Speaker A: We have to check that we have enough counters to process that opcode if we go out of context. For example, the ZigbM throws an error which is out of counters. This error is not user fault. Actually it's like a fault of the executor, but it can be solved easily, like processing this batch, but with less transactions, because it means that the number of counters to process that batch has been exceed. Here we have the name of the state machines, for example the binary one it just consumed when you compute a binary operation, or the keychain when you do a keychain hash, I will show you an example of an opcode. Well, it's a widely used upcode. It's the equal one, the equal upcode.
00:12:32.146 - 00:13:15.942, Speaker A: He compares the two last values in the stack and checks if they are equal. As you can see, this code is from TK assembly. As you can see, the first two lines here I am checking that I have enough counters to process that upcode. As you can see, the binary I'm checking I have at least one binary counter for the state machine of the one binary counter to process this disobedded. It's because here I use the equal and the equal consumes one binary. Also I check the steps. Each one of the lines of the CK assembly is a step of the processor.
00:13:15.942 - 00:14:02.706, Speaker A: Here I put 120, although the number of lines it's less. It's because I will go to read code, which means that all the process has been correctly in the best case scenario. But in the worst case scenario I may fall out to a stack underflow or maybe a rofas or a stack overflow, and I will need some more steps to handle this error. We don't use the self destruct. Actually this is a difference now, but we guess that it won't be a difference in the near future because probably Ethereum will accept the EIP 4758 where it replaces the self destruct by send all. So we are not using self destruct from the very beginning. We are using send all.
00:14:02.706 - 00:14:53.094, Speaker A: And I'm happy for it because self destruct creates a lot of problems. What does the sendal does instead of removing the bytecode and the storage of the account when you call the self destruct? What it does is to empty the account and send all the balance of the account to the account caller at the end. We're just following this EIP. This is also a difference that will disappear in the next months because we are really working hard to finish this and this is why we are not still type two but as I said before, this will be over in a few months. Actually we only support three pre compiles from the ABM. We support the C recover, the identity and the model X. And this is one of our priorities.
00:14:53.094 - 00:15:24.530, Speaker A: We are working to finish them all. Actually the SHA 2.56. It won't be that hard because we've only done the easy recover. Maybe the acpiding, it's a bit more tricky, but it's work in progress. Okay, one of them is the code of the Xcode hash. Obviously if we are using a different hash, we're using the Poseidon instead of the kitchak. This Xcode hash, it's returning the hash with Poseidon.
00:15:24.530 - 00:16:15.554, Speaker A: Also the block hash. Well, this one is not really a difference because it's not a variant, because now on the EVM you only can get the block hash of the last 256 blocks. We are supporting to get it from all the blocks in the blockchain from the very beginning. And the memory limit, we have a limited memory of around 40gb. This is different from the EVM because DBM is unlimited. The limited is settled by the gas and you can put like 50 million gas in one block. Actually this limitation makes that in a batch you can put 8.5
00:16:15.554 - 00:16:43.610, Speaker A: million for each transaction. That this is the cost of the memory expansion and we won't have any more memory. But I have to say that a transaction with 8.5 million gas should be enough to do whatever you want. It's also very easy, like to do different transactions. If you have a very big transaction, it can be like split it in different ones. And also, this is currently this last one.
00:16:43.610 - 00:17:33.098, Speaker A: It's a different now, but it won't be different anymore because we are also working on it and it's one of our priorities, which is that we are actually not supporting EIP one five five and EIP 2718 transactions. But it's a matter of time. So in conclusion, well, you all have seen the slide from before, but this is like now the most important moment of the presentation. Why is it happening now exactly? It's that we are passing the 97% of the Ethereum test suites. I think it's the best way and the most empirical way to show to the people that we are compatible. We're equivalents with the EVM. So this is the final dream art.
00:17:33.098 - 00:18:31.054, Speaker A: We are full EVM equivalent. And I also would like to send a message like this in the second point, which is that the difference that I've been explaining now, most of them are for aim to be more equivalent and with a better performance. I mean we've been building the ZKBM with a different toolkit than what was done with the EVM. So we have to take some technical decisions with different tools but to reach the equivalence also taking in account the performance. So I think that maybe also we have learned a lot from all those years of the EVM processing a lot of transactions. And actually I think that probably people from the theory foundation, if they had to do the EBM again from the very beginning, they will do some things different. And some of the things are the ones that we're trying to do.
00:18:31.054 - 00:19:12.700, Speaker A: Like we've learned from them, we learned from the EVM and we've tried to do it better. And finally to finish, just tell you that what I said at the beginning, we are on public testnet, so we really encourage everybody to try to crash it, try to test it, play with it. It will be very good for us if you crash it so we can find a bug and we can iterate and deploy again, fix the bug and all this. So just to finish, thank you very much. Thank you very much for being here. I hope you enjoyed the talk and thank you. Close.

00:00:00.330 - 00:00:34.600, Speaker A: Me being like, this meeting is being recorded. Okay, I think it's. This is a good spot to kick off. Good morning everyone. This is the eigth call. Posted the agenda in the chat here. As always, some spec updates, Devnet updates, and then we have some updates on the builder side as well today, so hopefully we can cover those to kick off.
00:00:34.600 - 00:01:06.138, Speaker A: We had this issue from the last call, Dapline's issue, around old finalized data. Whether we want to consider it available. There's been some movement on this in the past few days. I see. Danny, you're the last person here, I think, who's commented. Do you want to give a quick update on where things are at? I think Micah actually commented, I haven't read that yet. He's not here though, right.
00:01:06.138 - 00:02:22.274, Speaker A: Okay. I think there's like general directional agreement on what to do here. One would be first and foremost to not add the complexity of the unbound DA requirement. And then it's a matter of do you by default think that data is not available if you can't get it past that window, if you need to, and thus don't do reorgs, or do you by default think that it's available? There's kind of a security and UX trade off here. I think people generally want to by default assume false, but then if you're past this window, if you don't do an additional trade off at that point, you kind of have some trouble catching up. I think from a security standpoint, if you haven't been in sync for 2030 days, you actually should get a recent piece of information from the network because of the week subjectivity period. So that's not a terrible security trade off, but in most cases, you could just sync the network from there and be safe and be fine and find the head.
00:02:22.274 - 00:03:14.354, Speaker A: So it's like a bit of a trade off, although Micah jumps in and says like, well, this is exactly what it should be because of the security issue with leak subjectivity. So I can circle back on that and make sure there's no final input between now and Thursday and then try to make a microfinal call on Thursday. I think. Fortunately, this is not blocking core development. This is like more on the edge case side, and we've decided certainly to go from not in the complex direction of the unbound window. So Thursday, reasonable, unless there's comments right now where we could try to hash some stuff out. I don't know if all the relevant parties that have been on this thread are here, and if anybody has some additional information or sees the trade off differently than I.
00:03:14.354 - 00:03:41.448, Speaker A: I'd love to hear. Thanks for the update. Anyone here have some comments or. Okay, so yeah, let's try and get this resolved by the Cl call this week. Yeah, I'll ping in a public channel that pretty much want final comments on this before Thursday. Sounds good. Sweet.
00:03:41.448 - 00:04:31.000, Speaker A: The next one, also a daplian issue that I think there had been nothing since on the last call when we discussed it, and there hasn't been another update on it yet. But basically the blocks by root edge case. I know, yeah. Basically Sean was the last one to comment two weeks ago. Not sure if there's any updates there or a way to move it forward given it's been kind of stale. I saw that line actually open a pr for this. It's 31540.
00:04:31.000 - 00:04:55.260, Speaker A: You're 13 hours ago. Okay, nice. I missed that. Okay, so I guess, yeah, then we can just review this pr. I don't know if anyone has any comments on it already or if given it's pretty new. I suspect most folks have not had a chance to look into it. Okay, so people can look at that.
00:04:55.260 - 00:05:56.682, Speaker A: And then the last bit on the spec Xiaoi had some testing updates with regards to the trusted setup. I don't know. Is Xiaoi on the call? No. Yes. Hello. Yeah, so the KDG ceremony will generate the G two trustee set up with 65 elements. And previously we used 4096 elements for the many preset and four elements for the minimal preset, which is like it won't be matching to the main setup.
00:05:56.682 - 00:06:58.606, Speaker A: So now we use set it to 65 for the testing trusted setup. So I think it won't change the definite consensus, but it seems it would be helpful for the KZG library to use the 65 right now. So just need some quick reviews and I think we can merge it in the spec release this week. Yeah, and we discussed this with Donkrad and George and other people on the library side, and that's definitely what they want. And there's not really a big trade off in just keeping it to the sides of the. So if we start the devnet, we should use these new values, I guess. What's the impact of if we start Devnet three with the old size? Obviously I should be.
00:06:58.606 - 00:07:21.890, Speaker A: Breaks everything to change this value, I guess. Is that a correct assumption? This is something you need to. I thought this was just for the spec tests. Yes. Okay. Got it. Sorry, my bad.
00:07:21.890 - 00:07:35.820, Speaker A: Yeah, but Devon out. We want to use the production value. 4096. Right. That makes sense. Okay. Anything else on the specs.
00:07:35.820 - 00:08:14.664, Speaker A: Every call the specs section is getting shorter, which is a very encouraging sign. We used to spend like 50 minutes just on this. Okay, next up then Devnet three. I know over the past couple of weeks we've been trying to get it started with a minimal set of clients. I don't think that's happened yet. So I guess I'm just curious to hear from the different implementations like where things are at. Are there any blockers and yeah, we can go from there.
00:08:14.664 - 00:08:47.552, Speaker A: I don't know if anyone wants to start. Otherwise I can call people, I can give an update on prism site. So we passed all the spat test. I think I've implemented most of the sync stuff, so I'm waiting to test it. So I probably would just test it with multiple prism nodes first to see how that works. I also posted like an interrupt instruction on how to set up prism and gift, but that's just one pair. So I'm trying to do multiple pairs right now.
00:08:47.552 - 00:09:44.870, Speaker A: So yeah, if that goes well, if I can do a sync with multiple prism nodes, then I think for our end we are clear for Devnet three. Nice. Hi Bhavan from lighthouse so we are on a similar boat as prism. We managed to do local interrupt with multiple lighthouse nodes and multiple get nodes and we were able to send blobs into this local testnet and it works. But right now we are ironing out a few bugs and also we are testing sync as well locally and I think we should be in a good place to start local to start a devnet pretty soon. It's like we are just ironing out bugs right now. Thank you.
00:09:44.870 - 00:10:48.040, Speaker A: Hey everyone. From the lodestar side, we've been able to pass the alpha one hotfix two spec test. We're able to run a lodestar local only multi node devnet with like a fake el attached that can make blobs. So right now we're currently working on a Geth interop in CI right now, but we're running to some issues with that. The latest rebase Geth branch is again breaking for that interop and also the last commit that kind of worked for us with the Geth interop was the one ending in zero Charlie Bravo seven. It runs successfully Interop, but without any of the blob transactions. What else? The blob transactions generated using the CKZG library, it causes an invalid KZG commitment error in geth.
00:10:48.040 - 00:11:58.860, Speaker A: Seemingly as it might be that the KZG libraries are not interoperable right now, but we were able to actually interrupt with Ethereum js got that to work with blob transactions submitted between those do we have an example blob where we're seeing that difference? I can look into why GOkZG is not accepting it. Yeah, I can get Gajinder who's been testing this to pass on the information to you. Robert Great, thank you. Where did you get the trusted setup? Like are you maybe using different trusted setups? I don't know what the current convention is there because currently they're all like testing setups. Right? So someone I don't know where they came from. They should have all been updated to use the consensus specs one which I see, but I did hear about interoperability problems as well last week. It seems that some of the wrappers are not updated.
00:11:58.860 - 00:12:33.810, Speaker A: I tested GokZG last week and it's interoperable with a different library, the Ganarak one. So I think it's a wrapper problem. But if you can send the blob as well to me it'd be great. I can check it out. Who maintains the wrappers? Is that Dan? So it's still Dan. It's multiple people. So for node JS it's Dan.
00:12:33.810 - 00:13:29.340, Speaker A: For Nevermind, it's Alexi. Okay, so I guess we can loop them in if we get more suspicious of that mind we just trust tab different from that one from CKZG. If you use the standard one it will fail, but we can sync on that. Nevermind. Still is not syncing with gas prism network. We have some bugs, but I hope we will fix everything during the next week at the state. Thanks.
00:13:29.340 - 00:15:12.994, Speaker A: Any other? Andrew oh yeah, so for we have I've been working with of he actually is on both of our teams so he's been very helpful with getting Lodestar Ethereum JS interop working. We have at least on our setup been able to run EJs and Lodestar together and sync and send blob transaction here again, we do have a blocker with the CKZG library and I mentioned this to kev that the verify KZG proof method that's in the CKZG library is not exposed by the wrapper. So I can't fully implement the pre compile right now. So that's one blocker for us. I have it implemented as far as I can, but we can't do that last proof verification of the two points that get provided in the input I have shifted today to start kind of looking at trying to maybe do some more interop we have the same, I think Phil mentioned we have this verify KZD proof error when we try to send our we try to generate blob transactions using our code and send it to geth and it rejects them with this KCG error. So that's one that's probably, I'm assuming a KZG interop issue and I'm hoping to try to start working, maybe see if I can get Ethereum Js to hope maybe sync with prism at some point this week. Our pr to pull in timestamp based hard forks is still in flight.
00:15:12.994 - 00:15:53.560, Speaker A: Hoping that gender and I will get that merged in the next couple of days because that will hopefully allow us to start trying to go on the latest Devnet three spec. But otherwise we've made some good progress in the past week just being able to generate blobs and at least sync with Lodestar. So that's promising. Yeah, sorry, I was just going to ask. So Lodestar is using the NPM package as well? As far as I know, yeah, I think you'd have to confirm with. I mean, when I looked at it, it looked like the same one when I was doing my interop testing. Yeah, I believe that's correct.
00:15:53.560 - 00:16:51.404, Speaker A: Okay, I'll ping Dan to update the NPM version because I think that's basically the issue here, that it's using an outdated version. And if that's not the issue, then I'll just look into CKZG to see where the issues are. Beso is definitely not ready for definite three so far. What is done is parsing of the transactions from the network, the network payload, and that's basically it. So this week, hopefully we will have somebody working on a transaction pool and we will start doing the KZG proof integration with the today. I mean this week, but definitely not ready for definitely. Yeah.
00:16:51.404 - 00:17:44.254, Speaker A: Similar update for Aragon progress, but not ready yet. Okay, I think that's everyone is there. The team that has an update? Yeah, hi, yeah, sorry for Techu. We are working on storage and we have things pending on the network and syncing. So our goal is to basically start implementing the spec test, see if they pass, and hopefully sometime in January to start joining the defects. Sounds good. Any other team that I've missed? Yes, sorry from gradient team.
00:17:44.254 - 00:18:48.540, Speaker A: So we are not ready for the testing. However, we got a bit more numbers on the different elliptical backend libraries. I pasted the link in the chat and the interesting thing is that it could be something wrong with our CKCG bindings, but we got significantly better performance on verification with rust blst implementation. So I don't know, maybe somebody knows. Is there benchmarks on the CKZG without any bindings? Do you have those? I think there are such benchmarks that you can run from CKCG without any bindings. Yes. I don't know if they do the operations you want it to do, but there is a benchmark tool.
00:18:48.540 - 00:19:40.994, Speaker A: Okay, if anyone knows, please give link for that. And another interesting outcome is that, at least for proof generation, the parallelism is working pretty good with little efforts. So I think it's possible to get really good results with more efforts for approved generation for multiple blobs at once. So that's the results. Thanks. Thank you. Any other client updates? I think the only one we don't have update from is Nimbus.
00:19:40.994 - 00:20:11.042, Speaker A: Right. Oh, and Henry, I see you're on the call. Do you want to give a quick update? I saw there was like the initial pr for Nimbus. Yeah, sure. So Nimbus has basically started over the last few weeks. I've been working on it with help from the Nimbus team. Not going to be ready for Devnet for at least a few weeks, but basically the status is we've got some scaffolding in the core, Nimbus repo, a bunch of.
00:20:11.042 - 00:21:08.580, Speaker A: Basically most of the scaffolding I think is in place. I'm working on the CKZG bindings right now, as those of you on that telegram group have seen. And I think once that is done, which is basically today or latest tomorrow, I'll start wiring those calls into the call validation and gossip and take it from there. So yeah, we've gotten a late start, but it's coming along very cool. Okay, so it seems like there are definitely a couple of teams, like getting close to Devnet having some single kind of combo interop running locally. In terms of next steps, should we try and get a Devnet launched in the next week? Do people feel like we need a bit more time than that? Yeah, I guess. I'm curious.
00:21:08.580 - 00:21:48.992, Speaker A: Prism lodestar or Prism Lighthouse? You all seem like almost ready. Yeah. What do you feel is a good thing to aim for? I feel like as we get towards the holiday, there's probably less people available. So if it was just us and lighthouse launching a death net by ourself, then doesn't really make much sense. So I don't know, I feel like I would prefer until early January, but yeah, I don't really feel strongly either way. I guess it's up to others. But Terrence, if it's up and running.
00:21:48.992 - 00:22:45.040, Speaker A: Wouldn't that make it easier for other people to join in? I mean, right now it seems like testing is a little awkward. If the Devnet was running then wouldn't that make it easier? Yeah, definitely. That's a good point, right? Yeah. I was going to say I would prefer if we can get it going next week with just a couple of clients, then I think it would be worth it. Yeah. From Lighthouse, we agree right now if we have some help from the DevOps team, I think we can launch a Devnets maybe sometime early next week. There are some bugs that we are ironing out, but I think that if we have something that everybody can sort of try to connect to from their own client combinations, then it's definitely helpful.
00:22:45.040 - 00:23:55.810, Speaker A: Even if the devnet has bugs, like, it'd still be helpful. Okay, so I guess, yeah, let's try and get it running and then do people think it's possible to get this done before the next call, like before Tuesday, or are we going to need more time than that? I'd say let's shoot for it. It's not a certain thing, but it feels like we're really close. Yeah, I agree. I think it would be good to like if we can leave for the holidays and have the devnet running in the background and even if it's not everyone on it, it's just good for anyone who wants to test or whatnot that it's there. Okay, so let's try and get at least a minimal question on that. I guess just to make it a little bit more explicit, what's our sense of what the path is to get that devnet up and like, it sounds like prism, light heart, lighthouse and geth are probably the closest with maybe Nethermind and Lodestar and Ethereum js.
00:23:55.810 - 00:24:38.442, Speaker A: I mean, do we want to start with two? Do we want to start with three or four? How are people feeling about that? So prism gets has been our previous combination for Devnets, and we've only had that in the past. That seems like the reasonable pair to get started now. It would be nice to have Nethermind Lighthouse also if we can get those in, but I'd be fine setting it up with just a single pair just to again, help the others get. Oh, please. Taryn. Sorry. I do think Lighthouse is slightly more ahead of us at this point because they do tested multi nodes in terms of syncing.
00:24:38.442 - 00:25:13.660, Speaker A: We haven't tested that. So yeah, feel free to replace prism with Lighthouse to star as well. I guess it doesn't make that much difference, either one of them. But I do want to point out the fact that we haven't tested multi node syncing, which I probably can test in the next few days. Yeah, I think that's fine with us. As I said earlier, we're ironing out sync edge cases, but I think we'll be good to go. Maybe sometime early next week.
00:25:13.660 - 00:25:45.826, Speaker A: Okay, so I think, yeah, let's start. Lighthouse geth seem like the two most ready ones. Then we can add prism to that. So like Prism guest, and then we can add Nethermine and try out Nethermind Lighthouse and Nethermind Prism. I think if we have even just Lighthouse guests up and running with some infrastructure by next call, that's already a good start. And then maybe in the week after that, we can add prism and nethermine to it. I think.
00:25:45.826 - 00:26:28.640, Speaker A: Yeah, if we didn't have the four clients in the next few weeks or so, that would be. That would be really good. Yeah, I think this would be epic if we get this out before Tuesday. Huge. See, I guess. Any other questions or concerns people have about getting this out? I had one question about the CKCG library, but do we have test vectors available? Sorry, I've been out for the last week and a half, so it's already been answered. Not available.
00:26:28.640 - 00:27:20.846, Speaker A: Yeah. So there are test vectors for the blob generation, and I've just added some for the verified KZG proof. After what Ethereum js told me can link you to the test vectors, I can generate a release schedule that just changes them into JSON files. Because right now, you have to do. Go run star. Go. Yeah, that on the jskzd wrapper.
00:27:20.846 - 00:28:01.146, Speaker A: I also just pinged Dan in our company slack just to reemphasize that we want to cut a new release. Kev, you think that that's likely to fix the issue? Yeah, I think that's the main issue right now. If not, then I can go into. Because if Dan cuts a new release, I can run it against the test vectors, which work for GokzG, and I can just quickly see that something KZG. We'll get that out today. All right, thanks. Sweet.
00:28:01.146 - 00:28:57.732, Speaker A: Anything else on the devnet? Okay, let's do it. Let's try to get a couple of clients running by next call and then a couple more by the end of next week. Sweet. Okay. On the large block testing, Giorgio says he couldn't make the call, but he gave a quick update on the discord, saying that it's ready to run EF DevOps is prepared. We're trying to do this tomorrow. Anyone else have comments or thoughts about this? Okay, so hopefully we get a proper run done tomorrow and potentially some more during the week.
00:28:57.732 - 00:29:43.200, Speaker A: So then next week we can kind of review them and figure out if and how we want to approach mainnet in January. Next up, Gabby had an update on the builder spec. Yeah, and I see you posted a hackmd in the agenda. Do you want to take a minute or two to walk us through this? Yeah, sure. Hi everyone, I'm Gaui. I've been working on this builder spec changes with Shimi. We are participating on the protocol fellowship and this is our first time doing spec changes so any feedback is appreciated.
00:29:43.200 - 00:31:29.190, Speaker A: Yeah, the changes are not super big, but we need to update both the VCon API to include the types for the 44 four and we also need to do some changes on the builderive API specs. Those changes are really well summary on APR but to give a quick overview we needed to include the below KC commitments on the fork version container, the signer builder v. This is the container that is returned by the get execution payload from mvus. And then we also need to include a new endpoint that we decide to do a version two for the submit blinded block to also include the blog cycle with a new signet become block and blob cycle container. The one open question we had for that last change was if having this version two was the way to go because we get some early feedback from Metacrist that there was some preference for reusing the existing API calls instead of creating a version two. But then also Enrico suggests that he thought that having a version two in this case makes sense. So that's one thing that having some other feedback would be great.
00:31:29.190 - 00:32:26.848, Speaker A: That's for the questions. And finally to mention some action items that we were thinking to do going forward is implement these builder spec changes that are left to be done on the lighthouse code base. And then once we have that ready, generate some test vectors to share with the Boxbox team to have some le testing. Because Sean from Lighthouse shared with us that previously there was some issues with other forks, so having that kind of test early was a good thing to have. That's everything. Thank you everyone. Cool, thanks for sharing.
00:32:26.848 - 00:33:04.690, Speaker A: Alex had some comments in the chat. I don't know Alex, anything else to add? Yeah, I was just going to say that I think we can get away with the v one. I was looking at the versioning rules and basically they say we only want a new version if we basically break what's there? Which we wouldn't do, at least we wouldn't need to do because we can just add this metadata that says this is like a four. Four block versus something else. Either way, generally, from looking at this document, it generally looks good. And I'll go review the prs and. Yeah, nice work.
00:33:04.690 - 00:33:41.440, Speaker A: Awesome. Thank you. Yeah, one last thing is that unfortunately, shimi couldn't make it because of the tensions. But thank you. Of course. Anything else on the builder specs? Okay, last thing I have is basically the benchmarking stuff we talked about last week. I don't know if there's been any updates there that anyone wants to share.
00:33:41.440 - 00:34:21.882, Speaker A: Yeah, basically the pre compile gas cost benchmarking. Yeah. So I think Marius ran the benchmarks on his computer, and in the worst case we've got around sixty k. But this is like the worst case. And I'm thinking maybe we should reevaluate how we do the pre compile benchmarking. Like, maybe take 10,000 iterations of the average case. Does anyone.
00:34:21.882 - 00:34:51.960, Speaker A: So I think to add here, like, the worst case here, doesn't mean it's the worst case in terms of the data, but it's just that on the same data, it has slight distribution of runtimes. Right. Yeah. And that's because of garbage collection rather than anything to do with the actual computation. Right. So there's no way you could provoke it to do like 100 times the worst case if you include the pre compiler. 100 times.
00:34:51.960 - 00:35:45.865, Speaker A: I wish we had Maris or Martin on the call. I feel like they probably have a good intuition what's a reasonable part of the distribution? Target. But, yeah, we can have that conversation offline. Yeah, that makes sense, I guess. We're also waiting for other clients to post what their benchmarks are. I think most other languages also has a garbage collection, so it might be the same results, but from rust. And like I.
00:35:45.865 - 00:36:35.884, Speaker A: I said, was saying, nethermine has some intermediate results that they can post later. So, yeah, it'll be good to have a sanity check across at least two plants. Sweet. Anything else on that front? Okay, anything else anyone wanted to cover? Okay, well, we can wrap up here. Like we said last week, we'll have a call next week, and that'll be the last one this year, so. Yeah, thanks, everyone. And yeah, hopefully we could get this want.
00:36:35.884 - 00:37:36.304, Speaker A: I'm not going to be here next Tuesday because I'm getting surgery, but I did want to just. And Danny's going to be running the call because I think Tim's not going to be here as well. But I did want to just say that like six months ago when we started this effort, I think it felt like a long shot that this would happen in 2023. And now here we are six months later, and we have every client close to interopping sometime in January, and I think are gearing toward the place where we're all going to be in person to make that happen and then have a commitment at the core devs level to ship this as a fast follow, ideally in Q two of next year. And I just want to say I've never worked on Ethereum core development before, but that feels like an incredibly remarkable achievement for six months. And I don't think that that would have been possible without everyone in this room showing up every Tuesday for the last six months to make this happen and being super positive and super engaged. And I just want to say thank you to everyone.
00:37:36.304 - 00:38:05.522, Speaker A: I'm not going to get to say it next week, so thank you for all of your hard work. It's been an honor and a joy to get to collaborate on this, and I'm really excited about bringing it to production and scaling Ethereum together in 2023. Thank you. I don't think we can end the call on a better note than that. Thanks, Jesse, for wrapping up this way. Thanks everyone, and talk to you all in the discord. See you.
00:38:05.522 - 00:38:07.810, Speaker A: Bye. Thank you. Bye.

00:00:14.410 - 00:00:52.682, Speaker A: This came out of like a fun project. I wanted to write like a full, like an end to end symbolic execution engine in solidity, including the solver that, that we usually use in the background. And this is actually pretty fun. So I wanted to share with you what this does. So a few questions for audience adjustment. Who here was at Hari stock yesterday about symbolic computation in Yule? Okay, who knows what symbolic execution is? Okay, nice. I am prepared to tell you what it is, though, for the ones who don't know.
00:00:52.682 - 00:01:27.462, Speaker A: So I'm quickly going to go over some slides and then we're going to move to code. These expressions are thrown around a lot, like what symbol execution, what's constraints, what's SMT slover, what's all that stuff? And a lot of people know what it is, but if you don't know what it is, they kind of like you feel left out. And these words are used very trivially, even though they're not really, they're simple but not trivial. So first I want to tell you what's not symbolic execution, and that's concrete execution. So let's say you have. Oh yeah, last question. Who can read assembly like this? Nice.
00:01:27.462 - 00:01:53.166, Speaker A: Okay, that's very good. So let's say we have this assembly here from EVM and we want to run a concrete execution over it. So let's say we have this call data, it's twelve in hacks. I don't know what that is. What is that in decimal? Like 20? No, 18. Yeah, it makes sense. So if you run this program call data, what do we get? There's no return here.
00:01:53.166 - 00:02:24.666, Speaker A: So let's just consider top of the stack as sort of a return. In this case we get a twelve, we're going to push zero on the stack, we call data, load that position, we get the twelve, push three, multiply, that's going to give us 36. In hacks, we add one. So we get this number top of the stack. Right? So this concrete execution, you have a program, you have a concrete input, and then you execute the program. That input, you get an output. So now what is symbolic execution? We just said what's not.
00:02:24.666 - 00:02:52.334, Speaker A: So t eleven actually has a pretty good explanation of what it is. So it turns the program into math and then solves math formulas. That's actually a very precise, although very vague description of what it does. We have the same program here, but now instead of a concrete call data, we're going to have a symbolic call data. What does that mean? To be symbolic is that you just use a variable instead of concrete number, that's really all you do. You keep looking at variables. So our entire call data is going to be CD.
00:02:52.334 - 00:03:28.542, Speaker A: Now it's just a variable. The top of our stack is going to be a variable called top. That's all we're doing. So here we're going to collect constraints, which are things that must be true when we run the program. So when we run call data load of zero, we're basically doing CD of zero, right? And then we can also call it x, we can call it z, we can call it whatever, it's just a symbol and it happens. That thing must be greater equals zero, because we're dealing with EVM words and they're unsigned, right? The second part is that we are assigning that to x. We just make a variable out of that.
00:03:28.542 - 00:04:01.110, Speaker A: When we do the call data load, next thing we have this multiplication. We can make another variable for it called y, which is now x times three. Finally, for this add, we can make another variable for it called top. And then, which we just did the previous top of the stack, which was y plus one. So you see that for every operation we add a new variable, we add a new symbol that represents that expression, and we collect all these expressions. So we end up with what we call these constraints. And this is what is our symbolic Encoding.
00:04:01.110 - 00:04:51.286, Speaker A: So we take the program in EVM bytecode and assembly here, we transform it into a set of constraints, and that's our symbolic Encoding. There are different, there are many, many different ways to write these constraints from a program, which means we have different ways to symbolically encode your program. Why do we want to do this? So our symbolic encoding is going to turn into a system of linear inequalities. So this was our set of constraints that's going to turn into this system of linear inequalities. There are equalities here, but they can be very quickly translated into inequalities. So we just keep them as equalities for simplicity. And why do we do this? The reason why we did this, because we know how to solve these things with algorithms that you might have seen in high school or university, or you still will see it when you finish high school.
00:04:51.286 - 00:05:33.154, Speaker A: And what could we do with it? We can, for example, do the same thing we did before. We can give a concrete call data, in this case, the same call data as we had before, and run it symbolically. What does that mean in this case? A simple substitution does it. We can substitute CD by this entire call data, which then substitute CD of zero by twelve and so on. And we get that the top is going to be this number when we solve that with gal Jordan elimination or Gauss elimination, or there's tons of ways of solving it. A simple substitution here will do it not only gives us the value for top, it gives us values for every single variable in this system. We could already done it before with the concrete execution.
00:05:33.154 - 00:06:21.938, Speaker A: So the cool things we can do with this, we can ask many, many things. So you can ask, for example, can top be greater than 10,000? How do we ask that? We simply add a constraint that represents that statement in this language. So can top be greater than 10,000? Basically gives us this constraint here. And then here's the answer. It is possible, in which case such a solver, such a math solver will tell us that this system is satisfiable, meaning that there is a valuation for every single variable in this system that makes the set of constraints satisfiable. It is possible that all the constraints are true at the same time. And it also gives us what we call a model, which is the actual values that make the whole set of constraints valid.
00:06:21.938 - 00:06:45.978, Speaker A: And similar to before, we have a value for top, and we also have values for every single variable that appears in the system. We can also ask, can top be zero? What do you think? So, can represent it for these constraints? Pretty simple. By the way, all these variables are on the integers. There's no reals or rationals here. Everything's integers in this case. It's always. The system is unsatisfiable.
00:06:45.978 - 00:07:11.640, Speaker A: It's inconsistent. There's no way all these constraints can be true at the same time. They may be true in separation, but they will never be true at the same time. What we want to do is basically do exactly that in solidity. But what exactly do we want to do? You can do several things. You can try to prove that a certain assertion is true. You can prove that a certain thing always happens or never happens kind of things.
00:07:11.640 - 00:07:38.526, Speaker A: For our use case, we're going to try to find unreachable branches. So here's a piece of solidity. We're going to analyze EVM bytecode, but this is just to show an example. So, we have this function that takes an integer x. And first we require that x has to be last or equal ten. Then we have in the branches has if x last or equal, 50 does something, and then the rest does returns false. So this branch here, basically the false branch of the.
00:07:38.526 - 00:08:23.594, Speaker A: If it's unreachable, right? Because axe, we know that axe is less or equal ten from the beginning of the function, which means it's always less or equal 50, meaning that it will always enter the if and it will never come to this part of the code. If you take the true branch, this is reachable, because these constraints are satisfyable together, but these are not, right? So if x has to be less or equal ten, it cannot be greater than 50. So this branch unreachable. We can remove the whole thing. Well, not the whole thing, just the bottom. The cool thing about trying to do that stuff is that we need very little support from the EVM. Of course, if you want to write a symbolic execution engine, you need to write an interpreter in the first place.
00:08:23.594 - 00:09:20.154, Speaker A: So you need an EVM interpreter. But we don't want to deal with every upcoming code because it gets really big, really complicated, and we don't want to do things like call create and storage and all this complicated stuff, which of course you could, and a lot of tools do that. We don't want to do that in validity. The cool thing again about this encoding, we only have to care about the stack operations control flow, so jumps and upcodes that stop the execution and relation upcodes. And so basically we're going to care mostly about, as you saw before, ifs with relational operators inside, so less than, greater than and mitigation of these so that we can get less than or equal and greater than or equal. The symbolic encoding we're going to use is also pretty simple. So for every EVM expression that we saw before, we're going to transform into a math constraint of the form a minus b less or equal k, where a and b are going to be variables and k is going to be a constant.
00:09:20.154 - 00:09:53.242, Speaker A: So this is also what Harry was talking about yesterday in his talk. And we got things like this, for example, whoever was in Hari's talk together. Is this system satisfiable? Yeah. So if you sum everything on both sides, then you get basically zero last or equal minus two, which is a contradiction. So this system is impossible to be satisfiable. The reason why we like this encoding is because we can use a difference logic solver. And again, as Harry explained yesterday, a difference logic solver is very simple to write.
00:09:53.242 - 00:10:41.754, Speaker A: What does it do? It basically takes these constraints, these math constraints, and it tells you whether it's possible or not that these things are satisfyable at the same time. And if it is possible, it's going to give you values for the variables that make it satisfiable. Otherwise it just says it's not possible at all for these things to be satisfied together. The solver is much simpler than the things you need, like ILP or SMT when you need to solve it, linear combinations or even nonlinear expressions, and the sorts of things that you end up with when you start encoding arithmetic expressions and other things. And as also hire explained yesterday, this runs more time on the graph generated from the Constraints using the Belmont Ford graph algorithm. Not going to go much into that. If you want to learn more about that, please rewatch Hari's talk.
00:10:41.754 - 00:11:09.242, Speaker A: And this algorithm is super simple. This is basically almost the whole thing, and most of it is comments. So now all we need to do is put it all together. So this is the whole project. So these are two test files, one for the solver itself, just like unit tests for the solver and one for the symbol execution engine. And then you have all those files for the whole engine. So what we want to do is write interpreter.
00:11:09.242 - 00:11:38.234, Speaker A: How do we write interpreter? We need. So by the way, please, if you have questions, just like try to, you can ask questions right now just to make sure we go in a good flow. Actually, it's not here. So usually when you write this interpreter for EVM, you have this context. What is the context? You have the code that are executing, you have the program counter, like which opcode are you executing? Right now we have a stack. In our case it's going to be a symbolic stack. Don't worry about that.
00:11:38.234 - 00:12:08.710, Speaker A: Now we have a path which basically it's a path of all the program, like of the program counters that were visited in the jumps. And we're going to use this to detect loops and exit because we don't want to encode loops. We have an array of constraints. This is what I showed before. Like when you see the require, it says require, act less or equal. Ten, we go into that branch. So we keep that constraint because that thing needs to be true for the rest of the execution.
00:12:08.710 - 00:12:46.450, Speaker A: And this counter variable is just a counter to help create new variables. So when we were creating new variables for the expressions x, y and z and so on, here we're going to be expression one, expression two, expression three, and so on. And they need to be different in the branches that we execute. So that's it, we have the context, ignore the rest. For now, let's jump right into the execution engine. So we have this recursive function called run from, which takes our context. So here you see, it's basically going to traverse all the opcodes, select the opcode.
00:12:46.450 - 00:13:28.010, Speaker A: This is just a check that we just exit early on loops it becomes an under approximation, but we don't want to do loops. We extend the path with the Disney opcode. And here is the part that, the first part of what I mentioned with the interpreter. We need to care about stack upcodes because they're going to add some numbers and a bunch of different things, jump locations, jump destinations that we will need when building our constraints. So this just does the usual stack handling. So if it's a swap, you're going to go into the stack and swap the numbers. If it's a dupe, you're going to duplicate whatever it needs to be duplicated.
00:13:28.010 - 00:14:15.390, Speaker A: If it's a push, you just push that number into the stack. Here the only thing we do is apply a function on the stack arguments. So for example, if you have an ad, we're not going to encode the ad precisely here, but we do need to consume the stack slots and put a new return value there, right? So this basically just uses these handlers we have internally. It's like a bunch of function pointers if you have an ad. So this is generic for all the opcodes we don't care about. It takes the number of arguments this opcode takes, pops all of them from the stack, creates a new, what we call symbolic variable. So like a new expression 13 or whatever here, and puts that expression on the stack.
00:14:15.390 - 00:15:10.160, Speaker A: And we don't really care what it looks like right now. We don't really care what kind of constraints we have over it. Here's a part that we actually care about where we do the check. So if we have a jump, every time we see a conditional jump, we take the argument of that jump, we take the condition that makes it jump and we ask the solver, is it possible that we can jump to that location? Because as you saw before, we had this requirement and if, right, so we have require x less or x less than or equal to ten. So we have that saved, x must be less or equal to ten. And then we see if x greater than 50. And then we ask, is it possible though that x is greater than 50? So at this point, that's when we have all the math things encoded already in here.
00:15:10.160 - 00:15:38.950, Speaker A: As you'll see, this make symbol. This is like internal helpers, not really important right now. So here is where we do the check. So we check if the opcode is relational. So if you have a less than or greater than or if it's an e zero, because if you need to do greater or equal, we don't have greater or equal. In EVM. So we need to do e zero less than right, and similarly for less than or equal.
00:15:38.950 - 00:16:31.130, Speaker A: So if it's one of these, we basically take the condition which is here, we transform it into a DL expression, difference logic expression, and basically call the solver. So we have this check here, which will take all the constraints, and we'll call this little DL solver that I mentioned. And this is the check we call the silver. And if the silver says unsat, then we say this branch is unreachable. Why unsat? Because if the branch conditions are unsatisfiable together, it means that the solver will say unsatisfiable. Right. And this means that that part is not reachable because there's something in the middle that is not allowing, that will not make the code path is basically going to be inconsistent.
00:16:31.130 - 00:16:47.978, Speaker A: And what the solver looks like is. Yeah, this is the entire solver. So you take the constraints. So here we just build the graph. So this is building the graph. You just need to know how many variables you have. This is still building the graph.
00:16:47.978 - 00:17:25.850, Speaker A: And then here we run the single source for this path algorithm, which is the first part of the solver, which is a very basic graph algorithm. Then we do the negative cycle detection, and that's really all the solver does. This is 20 lines of code. It's really simple. And it's a logic that I really like because it can do a lot of things while being very simple. The last thing that I want to show is, how do you use this? So here I have this contract, unreachable, that has a bunch of functions. And that is like some unreachable branches in each of these functions.
00:17:25.850 - 00:18:09.030, Speaker A: All we need to do to test that is really just this. We call the sim run function from the library, from the symbolic execution library, with the runtime code from the contract. That's really all. And here's a simpler thing, just like manually, just a simple test with some bytecare that I know what it does. And if you run this. Yeah. So here you'll see that this is a complicated case with all the solidity high level functions, and it's not the best way to report the things, but it emits an event that's at unreachable branch with the pc to 55, this tiny example.
00:18:09.030 - 00:18:54.760, Speaker A: So this is the same as I showed in solidity, just like in, written quickly in Yule. And this is the bytecode that it generates, or that I wrote manually. So we can quickly compute this together, keeping track of the stack, and then you'll see what it actually does in execution. So push zero, we're going to push a zero, then we just call it a load of zero. It's going to give us some x. Then we push ten, we duplicate the x, we do last then. So this is going to turn into this.
00:18:54.760 - 00:19:27.122, Speaker A: This is the stack, by the way, and the top is the higher position. So now we push tag zero b, and we do like a conditional jump where the false branch stops. So we don't care about the false branch, all we do is just. So we're going to pop these first two arguments, right, because of the jump, but because we go into a branch, this condition must be true for the rest of execution, right. Set of constraints. So we keep going. In tag one jump, we duplicate x.
00:19:27.122 - 00:20:20.020, Speaker A: Again, we push 50, we do an lt now which consumes the x, and this becomes top of the stack, just a symbolic expression like y equals x, length less than 50 less than x. We push 14 and then we jump two. And then at this point when we see the jump, we're going to ask the solver, is it possible that this new condition 50 less than x is consistent with what we already have, x less than ten. And then the solver is going to say, that's not possible. And at this point here, precisely at this jump, I, that's where we basically stop and say this branch here is the true branch. Like where you're jumping next is unsatisfiable, so you can actually remove that entire branch. Right.
00:20:20.020 - 00:20:36.200, Speaker A: But, yeah, so there's a lot of code behind that, but a lot of helpers. The main intuition was basically this algorithm of just like running the interpreter, carrying about a few upcodes, not carrying about other upcodes. And. Yeah, happy to take questions.
00:20:37.210 - 00:20:47.494, Speaker B: Super cool talk. This is wild. You can do this in solidity. I'm wondering about overflow though, because your assertion at the beginning was that that one example you showed was impossible, but it is very possible in the presence of overflow.
00:20:47.542 - 00:20:52.460, Speaker A: No, that one wasn't because you need the answer to be minus one third. So it's not going to be possible.
00:20:52.910 - 00:20:53.514, Speaker B: Okay, sure.
00:20:53.552 - 00:20:53.706, Speaker A: Yeah.
00:20:53.728 - 00:20:56.254, Speaker B: But it doesn't look like you handle overflow anymore, right?
00:20:56.292 - 00:20:56.750, Speaker A: Yeah, exactly.
00:20:56.820 - 00:21:00.574, Speaker B: So that means that your results are not correct.
00:21:00.692 - 00:21:05.106, Speaker A: Yeah, exactly. There's a bunch of sound and stuff you have to add to this. All right, thank you.
00:21:05.288 - 00:21:10.338, Speaker C: Sorry, I didn't see, but is this code somewhere available to.
00:21:10.504 - 00:21:19.462, Speaker A: Yeah, this repo GitHub.com, that thing. And there's probably bugs in there though, so feel free to fix them.
00:21:19.596 - 00:21:26.310, Speaker C: So since you wrote this in solidity, do you have any thoughts on why you would want this to be executed on chain?
00:21:26.810 - 00:21:43.200, Speaker A: Not at all. Should not run this on chain. Yeah, well, actually, let me quickly just look how much gas this takes for this tiny program.
00:21:43.890 - 00:21:53.710, Speaker C: You said that for a given program, there's a lot of different encodings you could have. Can you give a few other ideas of other encodings and what would be the trade offs?
00:21:54.610 - 00:22:28.250, Speaker A: Yeah. So this encoding basically chooses, we chose difference logic because the slover is very simple. So we could write it in solidity. Right. So the encoding is tailored to become systems often equalities, that look like the constraints that a DL slover would take. But where is it now? In Hari's talk, actually, which I have here, there are different. So if you actually want to encode, add, mold, div, all these kind of things, you will need more complicated constraints like linear combinations.
00:22:28.250 - 00:23:00.580, Speaker A: Where is it, Harry? Yeah, you'll need linear combinations like this, for example, and more complicated constraints, and you'll need like a simplex or integer linear programming thing, or even a nonlinear solver, depending. And these things are a lot more complicated. So simplex is, well, it's an exponential algorithm that kind of happens to run mostly in polynomial time these days. But a nonlinear earth, if you're, if you're trying to solve nonlinear constraints, that's an undecided problem and you're going to have a hard time solving it. So. Yeah.

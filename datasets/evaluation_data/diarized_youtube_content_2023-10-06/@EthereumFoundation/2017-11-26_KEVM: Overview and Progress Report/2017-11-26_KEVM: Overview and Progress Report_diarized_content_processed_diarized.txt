00:00:13.210 - 00:00:50.554, Speaker A: Everyone test? Yeah, I'm Everett Hildenbrandt and I should have put also my group on there, but I was kind of in a rush to make the slides because it was all a little bit last minute, but that's how it goes. And the original title was overview and progress report. And then I decided yesterday that more kind of a k by example approach would go better here. So I figured I'll put that as a subtitle, but still leave the original one so I don't offend anyone or something. So we'll see. Okay, so what is k? K is this language for building programming languages in, and then you get to derive a bunch of tools from it. So essentially you give us the formal language, definition, syntax and semantics, and then we derive a bunch of tools from it.
00:00:50.554 - 00:01:40.060, Speaker A: So ones that are more in the vision phase right now are test case generation and compiler. But all of the other tools you see here, we actually derive from the one semantics. So that means that the tool that you're doing symbolic execution with, or model checking with, or deductive program verification, or you're executing the test set with use all the same semantics. There's only one semantics that all of them are using, so there's no way for them to disagree on how the execution happens, which is important when you're trying to verify that programs have the properties you think they have, the k back end. I'm not really going to go into much depth on this, but the static logic we use for matching configurations is called matching logic. There's some ongoing work on showing that this is a generalization of separation logic and the polytic modal logics and first order logic as well, and stuff like that. So, well, when I say generalization, I really just mean like there's embeddings into it.
00:01:40.060 - 00:02:22.954, Speaker A: And then also the dynamic logic is reachability logic, which is this language independent dynamic logic for reasoning about transition systems. So go ahead and ask me or the other team members, you guys raise your hands if you have any questions about these specific things, but I'm not really going to talk about that in this presentation. Instead, what I'm going to focus on is this k by example thing. So the organization we have on GitHub is this k framework organization. The KVM repository is at EVM semantics, and all of the semantics that we maintain are developed there. There are some semantics that other people maintain that aren't within our kind of organization. And then directly in this repository we have this directory which has a bunch of toy languages you can kind of play with and get familiar with k.
00:02:22.954 - 00:02:46.854, Speaker A: So that's a good place to start. Okay, so I'm going to dive right in. And basically this part of the presentation is just going to be a bunch of k. So I'm going to try to teach you guys k using an example that hopefully people are familiar with, which is EBM. So we're going to start off with some basic kind of functional style rules in K. Here we're declaring a function called chomp. It takes in an integer.
00:02:46.854 - 00:03:14.490, Speaker A: It produces an integer. So the type signature of this is int to int. We declare here that it's a function and then we give it semantics using this rule keyword. So we say rule chop of some integer goes to the Integer modulo POW 256, where this is the built in K Modulus operator. And that only happens if it's either less than zero or greater than POW 256, which is two to the 256. Otherwise it just goes to I if it's within those bounds right there. So you see that these cover all the cases.
00:03:14.490 - 00:03:41.858, Speaker A: Some other operators we define. These are just a fraction of them for demonstrating. But for example, there's this plus word operator. And notice we can define the syntax right here to be infixed directly. So we can say actually something like three plus word four instead of having to say plus word of three and four. For example, we declare that's a function. And then we give semantics to it down here just by calling the built in plus int operator and then calling chop on top of it.
00:03:41.858 - 00:04:12.460, Speaker A: Notice we also give semantics to division. This one has to be broken into two cases where you're dividing by zero, where an EvM that's defined to be zero and where you're not dividing by zero, in which case we just call chop on the normal division. And also feel free to ask any questions at any time. It's going to kind of ramp up in difficulty as we go, so it's better to ask earlier. Okay, so defining data structures in k. This is going to be a word stack for EVM, and we're going to define it as a simple cons list. So anyone in the functional programming languages will recognize this.
00:04:12.460 - 00:04:39.374, Speaker A: This is just something that, it's a hint to our SMT solver. But basically we say that we have this dot word stack right here, which serves as the empty element of the cons list. And then you can also cons an integer onto a word stack and that also produces a word stack. So this can be thought of as a singly linked list. And then here's for example, word stack append. Given two word stacks you can put plus plus in between them. That also produces a word stack and then word stack append.
00:04:39.374 - 00:05:14.426, Speaker A: Some word stack is just the word stack, and then some word appended to a consed onto a word stack append. A word stack is the word consd onto the appending of the tails. Pretty simple functional programming like stuff. Okay, so then in k we have this thing called a configuration which basically specifies the state of our system. And that lets us kind of tell k that there's a bunch of states sitting around that we don't want to have to mention all the time, but we want to be able to grab it anytime we do need to mention it. So here's just a fragment of the configuration. The actual configuration contains 60 plus cells.
00:05:14.426 - 00:05:58.766, Speaker A: A cell is one of these Xml like brackets like this. And then in the semantics when we say configuration, you also supply kind of the default value of each of the cells. So this is telling us that in the k cell the entire EVM program is loaded. That's what this dollar sign PGM, it's a special symbol, is loaded into the k cell at the beginning of execution. And then there's a subconfiguration called EVM that for example contains the VM execution state. So for example it's the current executing program which in the yellow paper is I under Barb, the current word scat which is mu s, the local memory mum and the current gas available which is mug. We don't just have the vm execution state, we also have the network state.
00:05:58.766 - 00:06:31.366, Speaker A: So we have another sub configuration. So what you saw above is where this dot dot, dot is, this is the network state. We have a map of the active accounts. Essentially that map just states whether it's an empty account or an actual non existent account. And then notice we have this account cell which is wrapping this account cell which has multiplicity star which basically says you can have as many account cells as you want. So in a realistic EVM network you can have many account cells. And then in each account you have an account id, the balance, the code, the storage and the nonce.
00:06:31.366 - 00:07:10.200, Speaker A: And these are the initial values. Down here we also have things like the transact, the current transaction set, and a couple of other little network state things, for instance. So like I said, the actual configuration contains 60 plus cells. Obviously I can't put the whole thing here. And then another thing to note, this multiplicity star here people have asked me about how can you do concurrency or parallelism or something like that? That's exactly how you do it, you essentially do a multiplicity star in a cell that's surrounding the K cell. So for example, in the C semantics we have, or in the c plus plus semantics we have, we have multithreading semantics using this multiplicity star, or in the rolling case semantics that exists. That's one we don't develop.
00:07:10.200 - 00:07:56.050, Speaker A: They also use multiplicity star for the independent processes that are evolving in parallel. Okay, any questions thus far? Okay, let's get on to EVM execution. So before what we saw were rules that were just defining functions essentially, and that's just kind of the functional subset of what you can define in K. But now we want to define generic transitions in the transition system. So first we need to say how to perform a single step. So we introduce this next operator, and in the yellow paper, basically what you do is you say okay, do a few simple checks to see if this is going to throw an exception. Like will the word stack be under or overflowed? Will the gas limit be exceeded? Some other checks like that.
00:07:56.050 - 00:08:31.822, Speaker A: And then if not, then you execute the opcode, and then afterwards you increment the program counter and then you revert the state if any of the above steps threw an exception. So here's the actual k rule right here. Notice here now we have the same keyword rule, but we have multiple cells mentioned. Back up here we have rule, but we have no case cells mentioned. And then we have this function attribute, which basically means that anywhere in the configuration this rule can apply. But this rule only can apply exactly at these parts of the configuration. So what do we do when we see the next operator? We replace it with this chunk of code.
00:08:31.822 - 00:09:14.174, Speaker A: When the program counter is pcount and in the program cell, the current program cell, that program counter is pointing to op and we don't care about the rest of the program. Note that this dot dot dot is not me aliding details. That's actually what the rule looks like. This is verbatim what the rule looks like in the semantics. So essentially we use this dot dot dot to tell k don't care, we don't care what's there, we just care about that one particular opcode in the program cell. So yeah, when we go next, we say first push the call stack, which basically saves a copy of the current execution state. Then we check, is it exceptional? Is it a bad jump operator? So is it going to jump to an invalid jump destination? Is it one of the designated invalid operators? There's one.
00:09:14.174 - 00:10:01.062, Speaker A: Oh, the stack underflow or overflow? Check if that check passes and doesn't throw an exception, then we actually execute the operator which does the memory computation, how much memory this is going to change also does the gas computation and also has the effect on the state of whatever this opcode is. And then we increment the program counter. If any of these throw an exception, that exception ends up consuming the remaining of these operators until it hits this syntax right here, which basically acts like an if then else over exceptions. So if there is no exceptions, we drop the call stack, which essentially forgets the state that we saved up here. But there is an exception. We take the false branch of this if then else, which means that we pop the call stack, reverting to the previous state and propagate the exception on. So this little squiggly arrow can be read as followed by essentially.
00:10:01.062 - 00:10:38.002, Speaker A: So if you only see a single element right here with this dot, dot, dot. So the precedence of this is that this dot, dot, dot is outside of the scope of this rewrite arrow, then that means there's only a single element and then anything else in the followed by part. But we're replacing this single element with several different computations to make. Does this make sense, people? All right. Okay, so EVM programs, let's take a look at what they look like in K evM opcodes. Here are some simple expressions. So we actually bin up the opcodes based on their arity, essentially.
00:10:38.002 - 00:11:19.502, Speaker A: So sub and div are bin stack ops. And we use somewhere else in the semantics, we will automatically load the arguments based on the arity. So all bin stack ops will get two arguments off the word stack and the word stack will have those arguments removed. So sub just goes to minus word, div goes to divide by push, divide by word, and then that's followed by this hash push, which is just an internal operator for actually moving the result over to the word stack. And then here's some local memory operators like m load, which is an unstack op. So it takes one argument. So m load at a specific index, you go and grab the local memory from the local memory cell and then you say as word the range of the local memory, starting at index and going 32 bytes.
00:11:19.502 - 00:11:54.110, Speaker A: So you take 32 bytes from a local memory, pack it together as a word, and then you push that onto the word stack. Because remember, the local memory is actually a byte sequence, it's not a word sequence. Here we have a bin stack op, m store. So m store of this value at this index. It's going to take the local memory and replace it with the local memory where at that index you write 32 words prefixed with essentially the bytes of this value. So you chop that value up into 32 different words. If it's not enough, you pad it to the width of 32, and then you write it to the local memory.
00:11:54.110 - 00:12:17.446, Speaker A: Does this make sense? Okay, so the rules are going to start getting bigger and mentioning more of the configuration. Notice this only mentions one cell. This mentions two cell. Oh, and there's one more thing. Notice here we have two rewrite arrows. This is as opposed to a lot of languages, which would require that you pull this rewrite arrow outside, copy the whole configuration above and below. But essentially k does that for you.
00:12:17.446 - 00:12:50.322, Speaker A: It pulls the rewrite arrow outside and copies. So you'll have a k and a local mem before then the rewrite arrow, then a k and a local mem with the right hand side of these. But Kay just pulls those out for you. So the rule can be a little more compact and readable. Does that make sense? So then here's some ethereum network opcodes, so s load and s store, they're the network storage analogs of the m load and m store. So when you s load at an index, there's an unstack op, and the current executing account is the one with this id. Well, first we match an account.
00:12:50.322 - 00:13:35.102, Speaker A: So remember there's many different accounts because that multiplicity star, we match the particular one that matches the account of the one that's currently executing. And then we look in its storage for this index essentially, and then we push the value up right here and the storage and the account don't change, we just push the value up there. Yeah, so it's kind of a lot going on. But once again, this dot, dot, dot is not me aliding details. This is actually verbatim the k rule for this operator. So once again, k is kind of being our friend, allowing us to align lots of details of the configuration that we don't need to mention for this particular rule. S store right here, it has once again two transition arrows, one that's going on within the account and one that's going on in the k cell.
00:13:35.102 - 00:14:13.290, Speaker A: And then we're rewriting the s store to the empty computation essentially. So we're saying that the computation is done. We once again match on the account id, grab the account, take the storage, update the index and the storage with the value. And then there's this side condition here, because there's a bunch of different semantics, whether the key is already in the storage or not in the storage, or it wasn't empty or it wasn't. Yes. Why do you use operator for memory? You use columns. So this arrow right here is actually map update and it ships with k as a built in from the prelude.
00:14:13.290 - 00:14:43.826, Speaker A: This right here is actually specific to the EVM semantics because it has to write a whole word stack at a time. So it writes the first element and then the second element. So this desugers to a sequence of 32 of the map update operations. Does that make sense? I guess I could give it some nicer syntax, but I don't know, that was an early design decision. Then it's hard to change later. Yeah. Okay, so I just wanted to show an example of a bigger network opcode.
00:14:43.826 - 00:15:16.786, Speaker A: So this is the call op code. It's running off the edge of the screen here. But basically we define a bunch of internal operators to help with the call op code and that's pretty straightforward to do. But then these internals can be reused for the delegate call op code or probably for the static call as well. But I'm not sure, it was a while since I wrote this code. Okay, so gas calculation, I'm going to run through this super quick because it looks like I'm running low on time and I want to get to the verification part, the intrinsic gas calculation. We tried to mirror as much as possible the style of the yellow paper.
00:15:16.786 - 00:15:53.580, Speaker A: So we have this function gas exec, which is parametric in the fee schedule that you are executing with. So you can specify different fee schedules, for example. I'll talk about that on the next slide. So given the schedule and the opcode, call the Cs store gas function from the yellow paper essentially. And then this we're going to declare as a function, which means we're not allowed to depend on any part of the external configuration. So this gas exec operator is going to grab all the relevant parts of the state that cs store needs to calculate its value and give cs store those values as arguments. So the definition of Cs store is right here.
00:15:53.580 - 00:16:29.320, Speaker A: Once again, it's a function takes three arguments, produces an int, and notice it doesn't depend on any part of the configuration. So you check is the value not equal to zero and the old one is not equal to zero. So this has to do with whether you're setting it or resetting it essentially. And then these are different schedule constants, so they're parametric in the particular schedule. And then these are all sorts of other cost functions that we've implemented. These mirror exactly what goes on in the yellow paper. So really you can read this instead of the yellow paper, if you don't like reading the yellow paper, and it has a lot more explanatory text around it in our repository online.
00:16:29.320 - 00:16:59.700, Speaker A: Here's how we implement the schedules. So we say that you can produce an integer if you have a schedule constant and then these brackets and a particular schedule. And then here are some examples of schedule constants once again from the yellow paper. G zero g base g very low. Here's a schedule, the default schedule. It sets g zero to zero, g base to two eip 150 schedule g balance gets changed to 400 over the schedule that come before. That was like homestead or something, I don't quite remember.
00:16:59.700 - 00:17:32.540, Speaker A: So you just update, for each new schedule change, you just update the schedule constants for that particular schedule. So it's actually a command line flag. You can give the semantics to tell it which schedule to execute with. Okay, so now I'm going to talk about a toy verification example, which is a sum to one, sum to n example. I forgot to put what the actual spec is here, but it's basically that s is equal to n times n plus one over two. Just a classical, I think it was Euler's formula for sums, or maybe Euclid or something. You say enough names, you eventually get them all.
00:17:32.540 - 00:18:08.550, Speaker A: So in no particular language, this is kind of the program that we're looking at, but in EVM, obviously it looks a little Uglier. So the proof claim, this is the main claim right here. I'm going to run through this really quickly, but basically we're saying they look like reachability. They look like the rules from the definition, and that's because they pretty much are the rules from the definition. And basically what it's going to do is it's going to start on the left hand side of the rule. Notice we have a symbolic value here for the gas and symbolic Word stack here. And it's going to symbolically execute using the inference system of reachability logic until it reaches a state that implies this right hand side of the rule, essentially.
00:18:08.550 - 00:18:59.074, Speaker A: So basically we're saying starting at any word stack, we get to the same word stack, but with the sum from one to n put on the top, and our counter gets to zero and the gas consumed is exactly this amount. And then we have some preconditions basically stating that like n is greater than zero, there isn't an integer overflow. The size of the word stack is small enough that there won't be a stack Overflow and the gas available is large enough. Basically we first write down the SPEC up here, and then we try to prove it. And then the prover tells us in a not so intuitive way that it can't prove it. And then we say, oh, what are the preconditions we have to add? The reason I'm telling you that is because, okay, so actually, with some example, there's this loop. In traditional horror logic style things, you have to provide a loop invariant.
00:18:59.074 - 00:19:58.682, Speaker A: We generalize that a little bit in reachability Logic to the Notion of a Circularity. And this basically says, if you're starting at the loop head, you can reach the end of the program and calculate the correct remaining partial sum. So, notice, in a loop invariant, if you're familiar with those, you specify the behavior of a single iteration of loop. Here, you specify the behavior from the beginning of the loop to the end of the program, which is often easier to specify than the behavior of a single iteration of the loop. Okay, so verifying ABI compliant contracts, writing these specifications is actually really hard for ABI contracts because they're huge, right? So we provided some helper functions like ABi call data, and some other little ones which will let you essentially actually pass in the name of the function you want to call, or the typed arguments that you want to pass to that function, for example, instead of having to pass in the hex encoded byte string, for example. And so here's an example usage. You can say, abi, call data transfer to this address, this transfer value.
00:19:58.682 - 00:20:21.006, Speaker A: Note that transfer here is a symbolic value, but this is actually a constant. So that's the call data cell. And then here you would use it right here. This would be that line above. Instead of having to write out the byte encoded hex values here. And then notice the balance one goes to balance one minus transfer, balance two to balance two plus transfer. And then all these preconditions right here, some of them were caught.
00:20:21.006 - 00:21:02.240, Speaker A: This example is the HKG token that had a bug in it. Some of these were caught by the HKG auditors, some weren't actually. So our prover was able to help us find some integer overflow, bugs and stuff like that. Okay, so not enough time here, but basically we passed the tests, almost passing blockchain tests with an order of magnitude of the performance of CPP Ethereum, which is pretty good for a formal verification framework. We're working on some ABI extraction stuff and not discussed here, but come and ask me about it. EVM prime, which was the IC three bootcamp project. We're extending EVM with some stuff to make it easier to give semantics to Viper via compilation to EVM, and we're getting pretty close on that.
00:21:02.240 - 00:21:16.370, Speaker A: Yeah. So this is the framework overview. It's not just for blockchain languages. And that's the end. Thank. Thanks, Everett.

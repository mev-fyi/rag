00:00:12.810 - 00:00:52.406, Speaker A: So today we're going to be talking about the staking economy and how it's moving from monolithic to modularity. We're going to introduce our speakers here. I'm the host, Victor Bunyan. Big supporters over there. I got a taste for Columbia. Anyway, so we have an amazing panel before us introduce myself, I'm protocol specialist at Coinbase Cloud. Coinbase Cloud is an infrastructure provider.
00:00:52.406 - 00:01:31.494, Speaker A: We run validators and nodes across something like 30 or 40 different blockchains. At this point, we run a good number of ETH validators. And so we're extremely invested in the success of Ethereum Ecosystem, paying a lot of attention to this transition from what is currently a validator, which is a box somewhere that has some software on it. The keys are either there or in some other box, and it's pretty vanilla. And it goes and it does its work and it performs its consensus duties. But the trend that we're seeing right now is that there's a whole host of essentially middleware solutions that are changing and modularizing the validator experience. And so they're almost kind of like plugins or extensions.
00:01:31.494 - 00:02:16.354, Speaker A: You can think of it as a very crude example. This is a fairly recent phenomenon. Flashbots and Mevboost was the first and primary example of it reaching an enormous scale within the Ethereum Ecosystem. But with the advancements coming from the teams up here and also other teams working in the space, we expect for this to be an extremely exciting and pivotal moment in the development of blockchain infrastructure on Ethereum. And so with that, I'm going to pass it over to the panelists to each introduce themselves and their projects. We're going to give them a little bit of time to not go super technical, but it's important you understand what each project is, because it's really going to inform the rest of the conversation. And these are nuanced meaty topics.
00:02:16.354 - 00:02:27.740, Speaker A: And so the directive we gave them is a VC pitch, but a VC that knows what's going. So with that, Stefan, please go.
00:02:28.510 - 00:02:29.162, Speaker B: Right. Hello.
00:02:29.216 - 00:02:29.530, Speaker C: Hello.
00:02:29.600 - 00:02:30.522, Speaker B: All right, this works.
00:02:30.576 - 00:02:30.922, Speaker D: Hey, everyone.
00:02:30.976 - 00:03:36.610, Speaker B: I'm Stefan, until recently was at Flashbots. One of the big things I've been working on there over the last year has been developing and shipping mevboost, which is often talked about these days. So I'm happy to get into it, get into discussing what it means to develop this kind of software for validators. Mevboost was developed to help solve two very specific problems with regards to validator deployments and mev. One was allowing access to solo validators to participate in the mev market, and the other one was to protect client diversity and sort of avoid a future where validators would try to fork their own code and create some technical debt in integrating new upgrades. So the way that it's architected and the way that it works today is anyone running a validator, whether it's at home or a massive node operator like Coinbase Cloud can plug in mevboost into their system. Do some minor configuration and essentially run it out of the box and get better rewards.
00:03:36.610 - 00:03:39.540, Speaker B: So, yeah, that's the intro there.
00:03:41.350 - 00:04:23.934, Speaker D: Good evening, everybody. I'm Sriram. I'm, founder of this project called Eigen Layer and also run the University of Washington Blockchain Research Lab. What we're doing at Eigen Layer is essentially enabling the sharing of decentralized trust from Ethereum staking to anybody who wants to build a new system on top. So the core idea here is staking is the root of trust. So when you're after the merge, we are in a proof of stake world where the stakers basically put down a stake and commit to block validation. And if they make an error or if they behave maliciously, they can lose the stake.
00:04:23.934 - 00:05:12.426, Speaker D: So this underwrites a certain economic security into the blockchain. What we are doing is enabling it to be flexibly shared. So for example, you put down your stake and restake. So restake is a new concept we came up with. restake is the idea that you're using the same stake, putting it at additional risk and committing to doing additional things. Maybe running a new chain, running a new service like data availability, running other middlewares on top of this common stake. So the exchange here is stakers are taking on additional responsibilities and additional risk and in exchange they are compensated with some fees or other tokens which are paid for those stakers.
00:05:12.426 - 00:06:00.266, Speaker D: Imagine you want to build a new distributed system. You have to go around and try to create a whole new validation network which is decentralized fund economic security to it, which is actually very expensive. For example, just to get a sense of numbers here, ethereum has like $20 billion worth of economic stake at risk. If you wanted to build a platform which has similar economic security, you're talking about like you have to pay the stakers an annual Apr, like 10%, right? That's like $2 billion worth of fees just for your other system to be as secure as Ethereum. It's virtually impossible. So what you can do is you can borrow this massive economic security because you're restaking it, you're using it for additional services. Anybody can come and build new services on top, thus augmenting the feature set of the Ethereum ecosystem.
00:06:00.266 - 00:06:22.390, Speaker D: We think of this as a permissionless way to do feature addition to Ethereum. So you're borrowing the Ethereum trust and now running new services. It is purely opt in from the staker side. It's not forced on anybody. But the stakers that do opt in are actually able to earn this additional risk reward dynamic. So that's what we do at Ion Layer.
00:06:23.450 - 00:06:47.498, Speaker C: Hey everyone. Colin Myers, co founder of Obel. We are focused on building what's called distributed validators. Easiest way to describe what a Distributed Validator is, is today all validators are seen as one key, one entity, one individual. It's very singular in nature. Our primary goal with DVT is to enable and change everyone's minds. That validators can become communities.
00:06:47.498 - 00:07:15.000, Speaker C: So with DVT, what you can do, you can take a regular Validator, you can use a DKG, divide up its key into different shares, and the four of us today can share a Validator together. And if Victor's House burns down, all things are fine because we use threshold signing and applied cryptography. So our node will keep going. It'll keep validating. The network will not halt. And, yeah, that's what we're focused on. It takes on the form of a middleware, and it sits on the e two side.
00:07:15.450 - 00:07:37.790, Speaker A: Awesome. And I know you folks are all starting out on Ethereum, and you talk a lot about Ethereum, but obviously it's not the only proof of stake network that's out there. There's a proliferation of them, and most networks these days are proof of stake. How do you think about the trade offs of sticking to Ethereum versus also starting to work on other layer ones or L2s and other ecosystems?
00:07:38.850 - 00:08:01.400, Speaker C: I think right now there's a huge narrative of the bizarre versus the app chain. I think they can both live and survive. I'm an American that spends half my time in Europe, and it's actually almost culturally how the world is divided. Like, Europe is kind of a bazaar. All their cities are meant to be lived in. Everything is close to each other. America is like app chains, suburbs, houses, everything's real, structured and together.
00:08:01.400 - 00:08:45.060, Speaker C: So the way that we look at that is Ethereum is the bazaar, and then who's the app chain? So for us, as we look at where to take DVT, it needs to fit technically within that network. And what's favorable for us are not too fast block times because there's rounds of communication that need to go between the individuals that are inside of a cluster. So for us, Cosmos is like another chain where that could work and is kind of the app chain model. They have five to seven second block times for us to work on other chains. DVT works best with BLS signatures. They're homomorphically additive, which enables you to split them up and then re aggregate them and broadcast in a very efficient manner. Cosmos does not have that.
00:08:45.060 - 00:09:14.954, Speaker C: Maybe they will adopt it, or maybe DVT can be fit into another chain in that sense. But today we are most focused on Ethereum. However, DVT is something that all public blockchains should use, in my opinion, to add more resiliency and add fault tolerance to the network. So it comes down to demand. It comes down to where the economic value is. It comes down to where the smartest minds are. And I do believe that outside of the bazaar, the app chain model is probably the only other layer one that would compete with Ethereum.
00:09:14.954 - 00:09:17.920, Speaker C: And that's how we currently look at the option set.
00:09:18.290 - 00:09:19.280, Speaker A: Very cool.
00:09:20.930 - 00:10:21.346, Speaker D: We are primarily ethereum centric. And the reason is, when you want to build a layer like this, you are basically looking for where is the maximum pool of decentralized trust? Because we are basically a decentralized trust marketplace. Where do you have maximum economic security? Where do you have maximum decentralization? How can we leverage this and build a whole bunch of new technologies on top of it? So our attention is actually in onboarding newer and newer modules and technologies. And one interesting thing that if you look at Ethereum versus the other blockchains, ethereum has committed itself to the modular blockchain world. And I think very few people understand the kind of scope of what a modular blockchain world is. The way to think about it is one thing we all love across all these ecosystems about blockchain is permissionless composability, right? You can build an app and I can build something on top of it and somebody else can build something on top of it. Together they stand much stronger than any one person could have ever built.
00:10:21.346 - 00:11:05.220, Speaker D: And permissionless composability is at the app layer and that's how all smart contract systems work. But we want to bring permissionless composability at the distributed system level. You build a new system, I build a data availability layer, you build a broadcast layer. Somebody else builds some other thing on top, an authentication layer. You just pack all of these together and then create a new service. So Ethereum having committed to this modular paradigm where there is going to be different things done at different modules rather than all bundled together, we're all about unbundling trust, right? So we are actually taking the trust network and letting people innovate on the different modules. So for us it is a natural fit that Ethereum is the right place to build something like this.
00:11:08.070 - 00:11:54.458, Speaker B: For mev, okay? Deciding where to build mev solutions sort of comes from the starting point of where is the biggest problem and the biggest problem is where the most usage is. So it sort of makes sense to start from that perspective with Ethereum. And it turns out that building mev solutions is kind of hard. So you kind of solve it. You build something on one layer and then you say, well, it would be nice to go build it on it everywhere else, but there's only so much time and resources to be able to do it. So the other thing is it's not a one size fits all solution. So I think there's some principles, there's some abstractions, there's some research, some ideas that can be reused across multiple different places.
00:11:54.458 - 00:13:09.210, Speaker B: But you can't just reuse the model that you deploy for a certain node architecture, for a certain client architecture and copy paste it into other chains. It's been really cool to see other teams emerge in other ecosystems that try to solve similar mev problems at the middleware layer, at the node customization layer. I know on the Solana side, the Jito team has been working on it for a little while and it's fascinating to see how different the solution space is. So sort of the solution that they are coming up with to be able to outsource the Mev extraction is actually to slow down block times. So because Solana has this main difference of being so much faster at block production than Ethereum, to do any meaningful outsourcing, you need to have slower time block times so that you can add the network latency that's required. And so it sort of highlights that even though the principle is the same, the idea of being able to outsource mev extraction from the validator level, the implementation ends up looking completely different. The other thing that I'll note is mevboost is surprisingly simple software.
00:13:09.210 - 00:14:18.138, Speaker B: Running a consensus client, doing all the peering and the networking is really difficult. Mevboost is just like a plugin that is a sidecar to the system and allows it to connect to a bunch of other resources for receiving blocks. It's just a multiplexer of an RPC call. Yet it's so hard to get adopted, right? Like such a finite, such a small change, which you'd say like, okay, anyone could implement this in like a day and ship it is not that trivial when you're deploying it to a network with 430,000 or so nodes, there's so many different stakeholders involved, so many different interests. And the hardest part of developing this kind of software is not the technology itself. It's also being embedded into the ecosystem, understanding what are the goals that are being achieved by the development of this software, what are both the technical but social goals as well as economic interests of all the parties involved. And that's where 90% of the work of developing these kinds of solutions lies.
00:14:18.138 - 00:14:20.174, Speaker B: It's not necessarily just the technical side.
00:14:20.292 - 00:15:12.240, Speaker A: Yeah, I think it's such a good point and I think it's something that unless you spend time in multiple ecosystems, it's very easy to take it for granted that people outside of your ecosystem have the same worldview about what's fair and what should happen and who should benefit or not benefit from certain activities. And what we find is that you can't copy, paste metaboost because other ecosystems don't want necessarily these characteristics. And so the software just doesn't make sense as it is. But I think Shrimp especially talked about some of the use cases kind of like off the cuff, but something that I would like to do is just make this a little bit more real of what can all of this look like longer term. And so what I'd love it is if you guys could talk about what are the most ambitious use cases that you're thinking about, that you could potentially solve or address, what does that look like?
00:15:13.570 - 00:15:55.482, Speaker C: So on our side, any type of validator can use DVT. You can be big, you can be small, whatever. It doesn't matter. What we find most interesting is that using its cryptographic properties to partner professionals with non professionals. So when it comes to how do you decentralize a liquid staking pool? Today, most of the pools are run by professional validators or they are run by the pool themselves. And over time what you must do is include other people into that validator set. And with DVT you can get the consistent uptime rewards and performance by pairing someone up with a professional in that capacity.
00:15:55.482 - 00:16:31.180, Speaker C: So today, let's say there's a four node cluster. It can be a figment, it can be a coinbase cloud and it could be two at home validators. And if applied cryptography works the way that it should, that validator should have just as much performance and it enables the small person to come in with the big person and then maybe become the big person eventually. So taking a node and mixing its constituents between professional and at home is kind of not the tail end of what we're going for. But right now it sits at the most innovative spectrum of how we're testing with people and how we're looking to push it forward.
00:16:33.790 - 00:17:13.574, Speaker D: From our end. The main thing we are quite fascinated about is the ability for the Ethereum ecosystem to become much richer. We can start listing out the top five problems in the Ethereum ecosystem and then start ticking off how we can solve all of them just by using Icalayer. I'll give some examples. Number one, the data availability bandwidth on Ethereum. So in the rollup centric roadmap, computation is offloaded, but data availability still happens on Ethereum. So the data availability bandwidth of Ethereum even with upcoming upgrades will be in say, 80 90 Kb/second.
00:17:13.574 - 00:17:48.530, Speaker D: So when you have a bandwidth like this, the roll ups are of course extremely optimized to actually take advantage of this and still pump in like tens of thousands of transactions per second. So that is awesome. But in a world where we are imagining a lot of the digital intermediation fundamentally happens through things like blockchains, we want to make sure that there is abundant bandwidth. 80 Kb/second is not enough. Ethereum itself has a roadmap with some really interesting ideas called Dong Sharding, where you can increase this up to like 1.3 megabytes per second. But even that we feel, and that's a few years out and we feel this is not enough.
00:17:48.530 - 00:18:42.050, Speaker D: There are applications which will need much, much more and we are provisioning. The first service we're building on top is a data availability solution on top of icon layer which can actually scale the throughput of data availability quite significantly. We are in our internal DevNet at 15 megabytes per second already and I think we can scale this another 100 X in the coming years. This is one example of taking one pain point in Ethereum and then figuring out how new distributed systems methods can actually come in and solve these things. We stand on the shoulder of giants. We build on top of Dunk Sharding some of the best ideas out there just good engineering and open permissionless competition. This has done a lot of good to the L2 world compared to what Sharding was, where one solution has to be enshrined and there's a lot of internal contesting on which is the right solution, whereas a permissionless competition for each of these different features actually leads to a very, very powerful world.
00:18:42.050 - 00:19:23.354, Speaker D: So another example, people think a lot about whether we'll be in a single chain world or a MultiChain world. And I think this is not a very relevant discussion for what we are doing. Why? Because even in a MultiChain world, it's very clear to us that Ethereum will be at the center of this MultiChain world. And why is that? What is the center of a multi chain world is if you think of each blockchain as like a node and it's like a graph, you see that the Hub node of this network is Ethereum. It is the most connected, it is the most liquid and the most secure. These are the three properties you need for a Hub node of a multi chain world. And we feel Ethereum is the right Hub node.
00:19:23.354 - 00:20:21.118, Speaker D: And so in this paradigm, there are some lacking things. We see a lot of bridge hacks, for example. And can we think about how we can build like very powerful bridges on top of the Ethereum landscape? So that's another thing you can do is once you restake, you can opt in and start running light client bridges for all other chains and start bringing in very powerful inputs into Ethereum. Another example, you can think of other things like mev management, right? Like you want to do mev management. When a block proposer is making a claim that I'm going to follow this ordering rule. What makes them hold to that rule if they can restake on Eigen layer and then opt in to new slashing conditions for what they have particularly agreed into? Like, I'm following this threshold encryption, I'm following this auction model. Whatever the new rules are that you opt into, you can hold by it because you can make credible commitments on Eigen layer.
00:20:21.118 - 00:20:22.786, Speaker D: Some examples of what I think we.
00:20:22.808 - 00:20:29.960, Speaker A: Can yeah, I also think we can just cancel the rest of DevCon. He got it. Eigen layer will solve everything.
00:20:31.770 - 00:20:41.986, Speaker B: I have a question about Eigen layer. How should validators think about the risks so intuitively to me, there's like, okay, I have my steak.
00:20:42.178 - 00:20:49.738, Speaker A: We're going to get to that. I'm saving the spiciest ones for the end. You want to do it now? We can do spicy ones now. All right, I'll do spicy ones now.
00:20:49.824 - 00:20:51.002, Speaker B: We can do spicy ones now.
00:20:51.056 - 00:21:06.740, Speaker A: Yeah, let's do it. But here's the condition. The spiciness actually applies to each of you, not just Eigen layer. And I want to hear about the risks associated with each project and the failure cases that are possible. Have you changed your mind?
00:21:11.430 - 00:21:12.740, Speaker B: Where do we start?
00:21:14.870 - 00:22:23.326, Speaker A: Well, I think maybe I'll give a little bit of background in that when you think about a middleware solution that does one thing right. So today a lot of people run Flashbots, right? They run mefboost as part of their validators and they're able to participate in the Flashbots software and ecosystem and all that. And the nice thing is that because it's relatively simple software that doesn't make tremendous changes from otherwise expected geth behavior, it's fairly well understood and we understand the risk parameters, we understand how it interacts with relays and the failure cases there. But you know, what we don't understand is like if you're running Flashbots and you're running Eigen layer and you're staking there and also you're part of oval, right? And so your validator key is split into four, for example. And so that actually creates a very powerful situation where you can have these incredibly robust and performant and do everything type validators. But at the same time it's also a very scary situation because of the risks involved of like okay, now you have nine client teams that are doing different things and you have three middleware solutions and you have upgrades across all of them happening all the time. And so the risk there starts to compound.
00:22:23.326 - 00:23:09.320, Speaker A: And so that's some of the background that we're thinking about. And so maybe there's going to be two questions here. One, I'd love to hear about what are the risks and failure cases associated with what you guys are building? Like what's the worst case scenarios that can happen and how are you trying to prevent it. And then second thing I'd love for us to talk about as a group is like okay, we are all marching and all kind of like making upgrades and doing all the things if I'm a validator that is going to be using all of your software. And also something else, how do we make sure I don't get slashed, how do we make sure that the Ethereum network remains performant? How do we make sure that your development processes or testing or whatnot are in sync between all of you and also the other clients are using such as execution or contestants clients. So it's a big meaty topic. Who wants to go first?
00:23:10.090 - 00:23:28.650, Speaker C: I'll start with block times. We talked about this earlier. So first and foremost, like long block times in Ethereum are super important for this entire middleware renaissance is what we're calling it. Internally you have these core client teams that have been built up over time. They're funded by the EF. It's free software. It's the MVP viable way that you access the network.
00:23:28.650 - 00:23:58.322, Speaker C: And now it's time to build enhanced functionality. On top of that, those middlewares must be designed in a credibly neutral manner. They must be designed with simple modes of failure for us on our side of the equation, the biggest mode of failure. Well, first of all, what is the number one reason why everyone's been flashed to date in the network because everyone's been running a configuration called Active Passive redundancy. It means to get more effectiveness or more uptime. You've run the same key in two places. One is online, one is offline.
00:23:58.322 - 00:24:35.620, Speaker C: This can result in lots of false positives. So you can't have a highly available validator without DVT, basically. So first and foremost, DVT addresses the number one slashable event in the network to date by being able to give you more availability. So when designing the middleware, modes of failure for us today are missing. Just miss your duties and then you take your time and you bring your machine back online. And that really only happens if you lose more than 33% of the nodes in your cluster. Right? So we're talking seven of ten, we're talking three of four and different combinations like this.
00:24:35.620 - 00:25:16.042, Speaker C: We'll be giving a talk tomorrow, Oshina and I, around how to design DVT at scale while not increasing correlation. So today, now where we're at with DBT is like correlated slashing is one of the worst things that can happen in the network. We try to avoid that at all costs. We believe that liquid staking pools in DDT will reign predominant inside of these. So it's our duty and responsibility to make sure that it's designed in a manner that doesn't increase correlation. Because the worst thing that can happen is a correlated slashing event takes place across 80% of the network. Who's running the same middleware? Obel is a security middleware.
00:25:16.042 - 00:25:40.186, Speaker C: Right? It's different than mev boost where you use mev boost to get more. With Obel you use it to protect yourself, which in theory will probably earn you more as well. So today when it comes to correlation, that's our biggest focus on testing. We think it's probably the biggest risk of the whole future of staking is making sure that correlated slashing events don't take place. And yeah, that's where we're at.
00:25:40.288 - 00:25:40.940, Speaker A: Awesome.
00:25:42.830 - 00:25:48.842, Speaker D: What's the biggest risk of using Eigen layer? There are many risks, as many as.
00:25:48.896 - 00:25:50.010, Speaker B: Things it fixes.
00:25:51.810 - 00:26:34.886, Speaker D: We'Ve tried. So there are really two kinds of major failure modes. One is you get a whole bunch of stakers collude and they're not only attacking the core protocol but also attacking all these other services. So the potential profit from actually your attack has increased because you have a much higher exposure. That's number one. I think this is even though this is somewhat significant, I think it can be addressed quite well. And the basic paradigm for why this can be addressed well is we have to compare existing systems to this new upgrade using Eigen layer.
00:26:34.886 - 00:27:31.770, Speaker D: Imagine you're running a whole bunch of DApps and all of them depend not only on Ethereum for service, but also they depend on some Oracle Bridging service and a few other things. That's exactly how the ecosystem is today. And even though Ethereum is giving you very strong security guarantees in terms of the economic security. You have all these other dependencies which do not have the same level of economic security or decentralization built in and you're only as safe the DAPs are only as safe as the weakest link. And by restaking the Yeet stakers, for example, just to give some numbers, if there is 20 billion at stake in ETH, but there are three middlewares, each of them have like 1 billion at stake. You just attack the weakest pool and you can actually potentially completely corrupt all the inputs. And the alternative universe is where each stakers all opt in to provide these services.
00:27:31.770 - 00:28:14.954, Speaker D: Especially if these services are lightweight or scaled horizontally, then it's possible that a lot of each stakers will opt in. And when you have a lot of eat stakers opting in, you are essentially to corrupt any one service, to corrupt any one DAP, you have to corrupt a majority of the ETH stakers and they are putting themselves at slashing risk. At some point, this becomes infeasible. There is a hardening of security. You want to take $20 billion of a flash loan and go and stake and get burnt for $10 billion and going to extract more than that. It's very difficult. So when you have a lot of restaking happening, actually your system's net security increases significantly relative to where we are today.
00:28:14.954 - 00:28:51.270, Speaker D: Okay? The counterpart to this is the other kind of risk, which is what happens if there are programming errors. Okay? You have a bunch of these services that are running. One of these servers has like a bug, or even worse, it's maliciously designed to break the entire network. Somebody is offering a 20% yield things we have seen before and everybody opts in. And at the end of the day, there is some massive slashing event. At the end of this thing, all eat stakers are slashed and there is mayhem. This is our worst nightmare.
00:28:51.270 - 00:29:33.522, Speaker D: Okay, how do we solve this? I think to get a good analogy, at least in the Ethereum ecosystem, there has been a lot of thought in how to create systems that are immutable and Ossified. And the right approach to this is to start with training wheels, like L2 solutions today. And you have these training wheels where you have governance mechanisms which can backstop risks. And that's the same thing we'll do. So essentially there are two grades of services on eigen layer one grade of service in which there is what we call a slashing veto. There is a committee of Ethereum community members. This is not a token dow which you can buy out.
00:29:33.522 - 00:29:46.834, Speaker D: This is reputed Ethereum community members, including people building on top in this committee. They can veto slashing events which happen illegitimately, right? So slashing happens, it doesn't get actuated. There's a gap.
00:29:46.882 - 00:30:18.754, Speaker A: And in this gap, and I'll clarify there because one thing that when we say slashing, it's not necessarily slashing on the Ethereum blockchain itself. It's slashing via. The Eigen layer protocol. And so what it does is that your ETH that you have staked, it essentially gets withdrawn to an Eigen layer smart contract, and the Eigen layer smart contract confiscates some or all of that ETH, depending on the slashing condition that you triggered as part of Eigen layer. So it's like slashing conditions on top of slashing conditions, depending on which rules of the protocol you break. And so that's what he's referring to.
00:30:18.872 - 00:31:07.374, Speaker D: Absolutely. So the governance committee can veto slashing on top of Eigen layer, and this prevents things like these risk contagions. But as these protocols evolve and they have been well tested in the wild, they can ossify themselves to another grade, which is not subject to any slashing veto. So the only thing that the governance committee can do is to veto slashing. They cannot add on new slashing. So the stakers are not taking additional risks, but people building on this middleware are taking a governance risk because whatever legitimate slashing gets illegitimately vetoed. And so as you grow in trust when you build these new services, you've been tested in the wild, you can ossify yourself to another grade where you're not subject to this slashing veto.
00:31:07.374 - 00:31:40.410, Speaker D: And so at that point, the stakers have to opt in. You have to convince them to opt in because they are losing one of their core protections either by establishing reputation and testing yourself in the wild. So that's how we mitigate some of these risks. It necessarily requires exerting subjectivity. And I think this is one thing that the whole blockchain space should take more seriously, is how do we combine subjective mechanisms with credibly neutral mechanisms so that we can get the best of both worlds?
00:31:41.550 - 00:31:42.540, Speaker A: Very good.
00:31:44.030 - 00:31:44.940, Speaker B: All right.
00:31:46.670 - 00:31:48.414, Speaker A: Back in the hasidigo. Yeah.
00:31:48.532 - 00:32:18.140, Speaker B: Before I start answering, actually, I want to get a sense of what the room is composed of. So I will ask for show of hands, and please participate. Anyone who's running solo validator at home, can you put your hand up? Okay. Anyone who works for some professional node operator validator company, put your hand up. All right. A good chunk of you. Anyone who's building, like, validator middleware, sort of what we're talking about here, you can put your hand up.
00:32:19.550 - 00:32:20.154, Speaker D: Okay.
00:32:20.272 - 00:32:22.474, Speaker B: Small group. What are you guys?
00:32:22.592 - 00:32:24.700, Speaker D: This is the oboe group. That's the whole oboe team.
00:32:26.430 - 00:32:27.082, Speaker B: Amazing.
00:32:27.216 - 00:32:28.780, Speaker C: That's the fan over there.
00:32:30.130 - 00:33:00.066, Speaker B: Anyone who's validating or staking on other networks, put your hand up. Okay, cool. All right. Mostly actually professional validators, which is interesting. Okay, so risks mev risk mevboost risks and facts. I mean, at some point, risks no longer risk, and they become actual. So in developing mevboost, I think, and maybe any software, really, it's easy to think about the first order risks.
00:33:00.066 - 00:33:41.038, Speaker B: What are the first order possible failure modes? And you can sort of create a security model that says, okay, here are all the different ways in which the software could go wrong or get abused, et cetera. For mevboost, this was threefold. Right? So from the validator perspective, you are outsourcing part of your power to these third parties that are called relayers. And there's three ways in which these relayers could start to misbehave. One of them is they produce a block that's just simply invalid, right? So you believe they're proposing a valid block to the network, but the block is invalid. The second one is that they can lie about the value of the block. So they'll say, hey, this block is worth ten ETH, but in fact it's only worth one ETH.
00:33:41.038 - 00:34:21.230, Speaker B: Second way that they can misbehave, and the third way is that they could withhold the block. So they give you a block, you sign it, you return it, and then the relay just never reveals it to the network. And so it causes you to miss the slot. So, okay, you think about, okay, these are three different things that the counterparty is trusting. What are the impact of that and then how do you start to mitigate them? Well, the validity one is if a relay continues to produce invalid blocks over time, that's publicly known. And so you can see this relayer is not behaving as it's expected to. I can simply disconnect from this.
00:34:21.230 - 00:35:10.922, Speaker B: And so the validator in this case has a power to be able to protect himself from being sort of attacked. And they can also critically notice if this happens to other parties. So this is sort of a key part of the security model. You don't want a validator who is maybe going to propose like three blocks a year or something to have to wait until the next block proposal to know that the counterparty that they're interfacing with is malicious in some way. You need to be able to see it from the state of the entire network for the third one. And the block withholding one is the most difficult because there's this problem of attribution. Like, you don't know if the relayer just revealed too slowly, if it's because the validator never submitted their block to the relayer and they only submitted it to the rest of the network.
00:35:10.922 - 00:35:50.554, Speaker B: There is a lack of attribution as to where the fault lies. And these kinds of issues are the most difficult to solve when you're building software for validators. If you don't know which actor in the system the fault originates from, you can't mitigate it as effectively. And you have to look at these wider health metrics for the system. The solution for that specific risk is looking at is the blockchain continuing to propose blocks. And so you can have this health factor for the blockchain as a whole. If there's X percentage of the last 100 slots that had a valid block proposal, that you can consider it to be good enough.
00:35:50.554 - 00:36:09.010, Speaker B: If for whatever reason, the health factor falls below some threshold, you have a circuit breaker in which it says it disconnects from all the middleware that could possibly be causing these kinds of faults and you fall back to sort of a tried and trusted operation of the system. Okay, these are the first order risks.
00:36:09.990 - 00:36:12.740, Speaker A: Everyone's the following but wait, there's more.
00:36:13.590 - 00:36:20.040, Speaker C: This is making what we do look a lot more simple. This is great. We're the most complex thing on a panel, but this is awesome.
00:36:20.490 - 00:37:16.166, Speaker B: All right, second order risk. So this is like the risks that aren't just directly from the behavior of a single node, right? But more risks are emergent from when you look at what if the entire blockchain is operating the same software, right? What are the economics incentives? What are the marketplaces that get developed on top of this? And how does that impact the expected behavior of the software? I think this is where censorship sort of comes into play, right? So you can solve all of the micro sort of risk at the individual layer while still having some bigger, broader risks that are more emergent out of the use of the entire system that can't be necessarily solved just through the initial design. They sort of become second order effects and some of them are easier to predict than others. And it's sort of a question of iterating on the ecosystem of the solution both at the technical layer but also at the industry level to try to migrate these.
00:37:16.348 - 00:37:58.174, Speaker A: Yeah, and I think that censorship is a prime concern for the whole ecosystem right now and it's been a prime topic of conversation throughout other panels and talks at DevCon. So yeah, we're all working on fixing it together. That's actually one of the things that Eigen layer is often mentioned in e three research posts about how it can support potentially solving that problem. And so you guys talked about the individual risks associated with each project. But then I want to go to the next question, which is that how do we deal with the amalgamated risk profile that results from using multiple middleware solutions? Why is that funny? Amalgamated?
00:37:58.222 - 00:38:00.230, Speaker C: That's not its word. I don't know if it's right, but it's good.
00:38:00.300 - 00:38:11.100, Speaker A: Yeah. I'm an immigrant and so we don't have preconceived notions about words. Like all words are equal to us. So I'm like all English words are nice. I like them.
00:38:11.790 - 00:38:20.700, Speaker C: So where we're at here, fact of the matter is there's really only one predominantly used middleware and it's mevboost. So there will be many more. And we made it.
00:38:21.310 - 00:38:22.878, Speaker B: He paved the way for all of.
00:38:22.884 - 00:39:01.260, Speaker C: Us to see that it's actually doable. So today there aren't combinations of middlewares happening. We actually recently integrated Caron, which is our client, into Med Boost. And now a distributed Validator can propose blinded beacon blocks, which is cool. So actually that kind of opens up this new entire landscape where a validator looking at the mempool, if there's ten people in a validator, all ten of them have a view on the mempool. And then that has like and since there's a consensus mechanism built inside of it, that opens up like a whole new paradigm of not only what mev looks like, but also what security looks like. So we have validators combined with Mev boost running on testnet today.
00:39:01.260 - 00:39:42.806, Speaker C: We don't get to propose very often but going through that process of testing it and figuring it out, fortunate for us they came first. I really don't think it would have been smooth if DVT and Mevboost launched at the same time. It was kind of the natural of getting to the merge. Let's get boost near mainnet, let's change it from a client into a middleware, let's merge and then after that now we take on the next middleware which is like DVT or others. So I think doing them in phases as a community is super important. I think the EF kind of unknowingly designed it that way and that's kind of how we interact with the client teams. For example, it's kind of like wait in line and your turn will come up.
00:39:42.806 - 00:39:57.066, Speaker C: So now that we're seeing more middlewares come out and they're getting more use yeah. What happens when they sit on top of each other? We've been looking at it less from the risk perspective and more from the opportunity perspective but through that finding we'll probably find what the risks are.
00:39:57.168 - 00:40:06.190, Speaker A: Yeah, and I'm glad you mentioned the client team angle. That's actually the next thing I want to talk about because I think it's super important. Any other takers on the amalgamated risk?
00:40:06.610 - 00:40:47.098, Speaker D: On the amalgamated opportunities? Yes. I already mentioned, for example, that you can do mev type things on top of Eigen layer. That's one set of opportunities. Another set of opportunities is can you build distributed validation for some of these other services built on top of Eigen layer? Because again, the same set of reasons why you would need DVT on top of a core layer also applies to services built on Eigen layer. So these are some of the touch points and interfaces. I think one nice thing is the core Eigen layer design is kind of as a sidecar, it's not directly touching the client. So we are basically add on.
00:40:47.098 - 00:40:55.162, Speaker D: Right? So opt in, add on, that's the two aspects. But there are some touch points between these different middlewares.
00:40:55.306 - 00:41:27.942, Speaker C: One of the other interesting things to mention about Eigen layer and Opal is for the long term goal of this cryptography project is to deal with what's called the lazy validator problem. So today it's not cryptographically possible to objectively prove who in a threshold signing scheme was not doing their job. So Eigen layer can't fix that. That's more like moon Math. They can fix that. But then it comes down to how do you solve that? Once you can identify it and that lazy person in that DVT cluster, you can disincentivize, you can punish. You can do a variety of different things.
00:41:27.942 - 00:41:57.246, Speaker C: Today, the only way that the industry has thought about punishing that actor, in our sense, would be to create a token. Make everyone bond. Oval token to the node, disincentivize, slash that token. And to your point, we would have to create our own trust network. So at the later tail of DVT, in its more mature state, the goal is to be able to use cryptography so that a group of people can run a validator together and not know each other. They don't have to know each other, they don't have to trust each other. But to get there, you have to deal with the lazy validator problem.
00:41:57.246 - 00:42:09.080, Speaker C: And today the best way to do that is to create a new trust network which is just 20, 17, 18 all over again. So there's like things that we would need for the later tail of what we're doing that Eigen layer is trying to build.
00:42:09.690 - 00:42:10.440, Speaker A: Yeah.
00:42:12.730 - 00:42:13.942, Speaker B: I have a question.
00:42:14.076 - 00:42:15.160, Speaker A: Yeah, please.
00:42:16.170 - 00:42:52.866, Speaker B: Is it better if we have a world where all the middleware solutions can sort of innovate, right, and throw new ideas at the wall, figure out what happens and what sticks if it gets adopted, then it's just all cordev's problem now and they have to deal with it? Or should it be that each of these new middleware solutions have to figure out sort of their own governance mechanism over how to continue maintaining these and shipping new features? And how does it fit with integrating into the principles of Ethereum, into all the other middleware solutions that get built? Is there like, one path that's better than the other?
00:42:53.048 - 00:42:56.920, Speaker A: By the way, I really regret showing Stefan the questions ahead of time.
00:42:59.050 - 00:43:13.500, Speaker C: So in our case so what was the question?
00:43:15.550 - 00:43:17.130, Speaker B: How do you feel about Front earning?
00:43:18.830 - 00:43:54.822, Speaker A: His question was, you guys are all building really cool stuff, but it's sidecars, it's like different clients. And so as we mentioned earlier, there's nine different clients that are either execution or consensus that are currently on the Ethereum blockchain. And now you have this slew of middleware solutions that aren't part of the all core devs, aren't part of the EIP process, they're not part of any established Rails by which the Ethereum community releases infrastructure, software and upgrades. So the question is, how do you deal with that, right? Do you just ship whatever you want and then just throw it at the core devs and be like, it's your problem now?
00:43:54.956 - 00:44:35.102, Speaker C: So ours was a reverse problem, actually. I was part of a group of people who were focused on pre genesis for E two. We spent a lot of time on enablement onboarding education. Then we began to focus on post genesis problems, and one of the first ones was Stake Centralization. And DBT started off as a research project at the EF, and then we worked with them to build a reference implementation out of it. And then we took it on and now it's basically our responsibility as a project to take that and push it forward. That's more in my opinion, how the EF is being designed today is like if you want to be a real decentralized foundation, you probably can't ship too much code when you get more mature.
00:44:35.102 - 00:45:11.920, Speaker C: So their job are to be like educators and business people and reference implement, do all the research, do the legal work, do the business work, enable a community and push out technology that other people can take and run with. It also ties to the economic scheme of how things work. Right. The fact of the matter is that the client teams are funded by the Ethereum Foundation and or in some cases Joe, and now middlewares are not anymore. Right. We have our own private funding, we're not relying on the EF. Our software doesn't need to be it has to be open source, obviously, but it doesn't need to be free.
00:45:11.920 - 00:45:39.740, Speaker C: So that fact then creates a whole new world of the economic schemes of how it works because economics, incentives and coordination will deem all relationships and at the base layer the relationships and the client layer are straightforward. It's like virally left, everyone can use it. It will be forever free. The EF has given them good chunks of money to do so and now we're at a new layer and we get to create it economically the way that we want to.
00:45:41.710 - 00:47:01.406, Speaker D: Yeah, from our end. I think one of the things that has been lacking, I think already Colin alluded to is economic models for people to build these new services and that's something we and the other issue that Victor raised is the question of whether these should be governance processes which bring on new things or should we let permissionless open competition? I'm very much on the side of open innovation. I think if you look at the rate of innovation on the various layers of the blockchain stack you would see that the rate of innovation we saw in the DAP layer is simply amazing. You can take anybody else's ideas, compose things on top and build new things. Whereas if you were a protocol dev, there were very minimal opportunities for you to express your engineering and building skills because the only way you could do it is to go and start a whole new network. And what we need is mechanisms by which we can actually massively accelerate the rate of innovation at the core protocol layers because it's entirely log jamming the rest of the applications that can be built on top. So we feel like as long as there is an attendant economic model to each of these middleware being built, for example, on top of Eigen layer, that would be collect a fraction of the fees and only the remaining fraction of the fees goes to the stakers.
00:47:01.406 - 00:47:37.680, Speaker D: It could be hey, you have a new token and you have dual staking. You stake your own token as well as you have each staked. So there could be a variety of different models in which these middlewares can become self sustaining. But I do understand that there are some examples. For example, Flashbots has done a great job in stewarding mev towards away from things like multi block mev and reorgs where things can get quite hairy. And I think the pressure on these things should be exerted socially rather than in terms of any kind of governance process.
00:47:39.330 - 00:47:40.480, Speaker A: What about you?
00:47:40.930 - 00:48:56.838, Speaker B: Yeah, I fall on that side of the camp. I think it's really tricky to design good standards, body governance bodies over anything but open source technology. In particular, I think we're very lucky that we have sort of an ethereum core development ecosystem that's so committed to transparency and openness and it has allowed for a lot of these social consensus things to get expressed directly into how the protocol gets designed. All these wars and these arguments are being had in the public can go away. If there's this formal process by which things get approved, then the question is like, what's acting and getting these things approved? And it's a completely different game that isn't necessarily about public dialogue and discourse. And that's a big part of know. Victor, you helped out a lot in the development of an mev solution, right? Like, there was this e two working group that essentially got started maybe this time last year to develop the MEB boost solution and bring all the stakeholders in house.
00:48:56.838 - 00:49:12.030, Speaker B: What do you think is the role of all these different stakeholders continuing forward? Is it like you vote with your feet, you decide which technology that you operate as a node operator, which technology that you use, or should there be some more active process for involving those views and opinions?
00:49:13.010 - 00:50:07.038, Speaker A: Yeah, that's a great question. It's hard to know. But I think that as infrastructure providers, what we want is, by and large, to be unappinionated in that we want to take open source software. We want to run it in the vanilla way in which it is designed, and we don't want to ever express opinions over the state of the network and what is allowed or not allowed or censorship or any other properties. And so when we think about the designs of these various softwares, something that we think about is as infrastructure providers, we know how to run infrastructure really well. And so the things that we focus on are performance, our security, all these components that enable us to run great infrastructure. But when it comes to the characteristics of the design or the trade offs that the design makes, I think over there it becomes much more of a conversation and a vote with your feet kind of thing.
00:50:07.038 - 00:50:24.398, Speaker A: And we did have a different mev solution come and talk to us. And they came to us and they explained their design to me and I was like, that is completely uninteresting to me. And that stumped them because they were like, well, I had 100% hit rate before I talked to you. And I'm like, yeah, well, here's why your idea is dumb and I'm not going to do it.
00:50:24.564 - 00:50:26.630, Speaker C: This is why victor makes the big bucks.
00:50:28.250 - 00:50:29.254, Speaker B: Brutally honest.
00:50:29.372 - 00:50:56.960, Speaker A: Yeah, I'm loving. But know, I think that we try to influence as much as we can in a way that still allows us, know, remain credibly neutral as infrastructure providers. But at the end of the day, we have to make decisions. And I think that the decision that we make as infrastructure providers always have to be aligned with the long term goals and health of the network. And if we're not doing that, then our business is dead and nothing matters. Okay, we're very much at time. Thank you so much.
00:50:56.960 - 00:51:13.358, Speaker A: And thank you so much for the speakers. Really appreciate you guys. All right, we'll be here if anybody wants to talk, and if not, we'll be outside. And if not, you can find us on twitter and telegram and all the things. Thank you guys.
00:51:13.444 - 00:51:15.250, Speaker C: Thanks, everyone. Bank.

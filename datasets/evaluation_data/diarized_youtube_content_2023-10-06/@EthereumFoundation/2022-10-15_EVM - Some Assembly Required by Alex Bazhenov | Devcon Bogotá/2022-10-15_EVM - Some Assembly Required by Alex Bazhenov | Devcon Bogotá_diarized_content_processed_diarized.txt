00:00:14.410 - 00:01:10.834, Speaker A: Hey guys, my name is Alex. I am a lead developer at Tallyho, and I'm here to talk to you about EVM assembly. So the two things we're going to cover in this talk is first, like what is EVM assembly? And second, how to read the opcodes, how to read opcodes and trace an EVM transaction. But I think before we jump into that, it's pretty important to tackle a question of why do we care? Why would we care about EVM assembly? I think that there's a few reasons. So any of the code that we write as developers is pretty far abstracted from the code that a machine actually interprets and executes. And the closer we get to this real code and the further we get from our abstractions, the more we can reinforce our mental model of what the machine is actually doing. And I think in general, learning from first principles is a fantastic way to progress as a programmer and to just build solid and bulletproof mental models of what your code is doing.
00:01:10.834 - 00:01:50.346, Speaker A: So what is EVM assembly? Well, let's start with what is the EVM? So you've probably heard of EVM Zke, EVM, Evmos. There's a lot of terminology out there right now, but at its core the EVM is just a stack machine. It's something that takes in instructions, builds up a stack, and then operates on that stack. Most of the operations consume values from the stack. So add takes two values from the stack, adds them, you're left with one value, multiply takes two values from the stack, adds them, you're left with one value, et cetera. But there are exceptions to this. I think the most notable one is push.
00:01:50.346 - 00:02:15.590, Speaker A: So we have push one through push 32, which pushes between one and 32 bytes onto the stack respectively. So let's go a little bit more in depth into the EVM stack machine. So, stack machine has a depth of 1024 items. Each item is a 256 bit word. If you're not sure what a word is, that's okay. And it's not really relevant for this talk. It is a slot on the stack machine.
00:02:15.590 - 00:02:52.546, Speaker A: During execution. The EVM has memory that does not persist between transactions. It also has storage that does persist between transactions. When we talk about writing to the blockchain, that's what we mean. We are storing things in the EVM and also compiled smart contract bytecode executes a number of EVM opcodes. So we have some that you might be familiar with if you've looked at x 86 assembly, like XOR and add and sub. And we also have a number of blockchain specific opcodes in the EVM, and we'll dive into more of these a little bit later.
00:02:52.546 - 00:03:53.830, Speaker A: And then I think the last important thing about the stack machine is that each operation costs a certain number of gas. So when we pay gas for our transactions, we're essentially paying a little bit or a lot of gas for every single operation that the stack machine executes. All right, so now that we have some understanding of what an EVM is, what is assembly? So, assembly is something that lives in between the code that we as developers write and between the code that a machine interprets. So, on one hand, we have solidity, which is nice, some people think, easy ish to read, easy ish to reason about. And then on the other end of the spectrum, we have bytecode, which is pretty much impossible for humans to read, but very easy and very efficient for machines to read. And then in between solidity and bytecode, we have assembly. So this is kind of what it looks like, and it is an intermediate language or an intermediate representation.
00:03:53.830 - 00:04:34.238, Speaker A: And what that means is it is something that lives in between the code that we write and bytecode, and the opcodes that you see there are what are actually running in the EVM. So the solidity or the viper that we're writing is compiled down to opcodes and then running in the EVM. And that pattern is what lets us have multiple smart contract languages that compile down to EVM and then are able to be executed, or. Sorry. That compile down to assembly and then are able to be executed. All right, so let's trace a transaction. I have a website up here, www.
00:04:34.238 - 00:05:03.774, Speaker A: Dot EVM codes. You might find it useful, you don't need it to follow along, but it's a fantastic reference that has every single opcode in the eVM, how much gas it costs, and what it does. All right, so here I've written this incredibly useful smart contract. We have one storage variable, total supply, and we have a public function that anybody can call that sets total supply to eight. So, very simple smart contract. Not much going on here. Not even sure why anybody would use it.
00:05:03.774 - 00:05:56.682, Speaker A: Right? So the opcodes representing this contract should be pretty simple, right? Well, we can take a look. So Sol C provides us with a handy little command where we can pass a contract to sol C with the opcodes flag, and it will output a opcode representation of that contract. So our simple contract becomes that which is kind of unreadable. But by the end of this presentation or this talk, you guys will be able to read some parts of it, some that are common to all transactions that we see in all transactions that we see in the EVM, and some that are specific to the contract that we wrote. So let's go ahead and trace a specific transaction. Imagine that we've deployed our contract at some address and then we are using ethers to call ultrasoundmoney set total supply. The transaction that we defined in the beginning.
00:05:56.682 - 00:06:29.414, Speaker A: Great, we submitted the transaction. It's been mined. It's part of the blockchain. Let's take a look at it. So Geth has this very handy command called debug trace transaction. If you're here for the previous call, you're probably more familiar with it than most. And what we can do is we can pass in the transaction hash where we invoke that sent total supply function and get an opcode trace as well as a historic representation of the stack of that transaction.
00:06:29.414 - 00:07:09.922, Speaker A: So basically find out everything that happened in it. So let's trace the opcodes of that transaction. You'll see here that there are some lines between these opcodes, and I've divided them into four sections. So that is more so just for clarity, because I want to focus on three parts that are common to every transaction and one part that is common to ours. And I also want to note that what I'm going to show you is not necessarily a one to one representation of what you'll see when you send debug trace transaction. For example, we're going to be converting hexadecimal numbers to decimals because hexadecimals are hard for humans to read. We're going to be showing booleans as true or false.
00:07:09.922 - 00:07:42.538, Speaker A: But that's just so that what's happening here is so it's easier to follow along with what's happening here. So let's start with the top, this little section. So we have push 10 x 80. What we're doing here is we're pushing 128 onto the stack. Zero x 80 is represented is the hexadecimal representation of 128. Then we're going to push 64 on the stack. And then we're going to call a function called mstore which is going to store the value 128 at the offset 64 in memory.
00:07:42.538 - 00:08:13.610, Speaker A: So what's going on here? We don't have 128. We don't have 64 on the stack, or we don't have 128 or 64 in our contract. So why is this happening? Well, what's happening is solidity uses the memory area between address zero and address zero x seven f or 127 for internal purposes and stores data starting at address zero x 80 or 128. So this is solidity doing some boilerplate internal memory management for us. Fantastic. We don't have to worry about this as solidity developers. This is just a straight win.
00:08:13.610 - 00:08:38.530, Speaker A: Wonderful. All right, so now we're going to jump to line 25. In our list of opcodes between line three and 25 there's some more boilerplate stuff. There's validation of message value and making sure you can't send ether to a non payable function. But that is not really relevant to us because our function isn't payable. So we're going to go ahead and skip that. Great.
00:08:38.530 - 00:09:11.014, Speaker A: So on 25 we're going to push four onto the stack. Once again, where is this four coming from? And then 26, we're going to encounter our first blockchain specific opcode. And what we're doing here is we're pushing the size of the input data onto the stack. And as you can see, we pushed four onto the stack. Now we have four on the stack again. So that means our input data size is four bytes. But where did this come from? We didn't send any ether and we didn't send any arguments along with our function call because there were no parameters.
00:09:11.014 - 00:10:01.590, Speaker A: It was just the public function that we invoke. So why is our call data size four? Well, the answer to this is that when we call, get total supply in ethers, under the hood ethers is going to hash that, get total supply function into its function signature and send that along with the input data when we send that transaction. All right, so we know that we have four and we know that our call data size is four. What's going on next? Well, Lt, as you may have guessed, checks if input data, if the input data is less than four. And what's actually happening is it's looking at the top value of the stack, looking at the second from top value of the stack and seeing if the second is less than the top value. In our case it's not because four is not less than four. So we push false onto the stack.
00:10:01.590 - 00:10:34.360, Speaker A: Remember, this would be represented as a zero or one. And then we push zero x 280 or 38 onto the stack. We'll come back to that in just a second. The next instruction that we see is jump I, and I think of that as jump. If so, what that instruction is telling us is if the second from the top value is true, jump to the program counter represented by the top value in the stack. A simple way to think about that is if the second from the top value is true. Jump to line 38.
00:10:34.360 - 00:11:26.114, Speaker A: Since the second from the top value is not true, we don't jump anywhere. And this check executes. And essentially what's happening here is that since function signatures are four bytes in length length, if the call data size is less than four bytes, we know that we can't possibly be calling a valid function. And then the function gets reverted if the call data size is less than four. So with that idea of function signatures in mind, let's take a look at the next section. So, call data load is another blockchain specific opcode, similar to call data size, except instead of pushing the size of the call data onto the stack, it pushes the actual call data onto the stack. Remember that the size of our call data was four bytes.
00:11:26.114 - 00:12:08.866, Speaker A: So here we have four byte hexadecimal value on our stack. That seems relatively arbitrary, but some of you are probably correctly guessing that we are actually pushing our function signature onto the stack. On the next line we have push four and we push that same exact function signature. What's happening here is the contract is checking. Okay, I'm being sent this function signature. Does it match this function signature? And if the answer is yes, represented by the opcode, equal. So equal takes two values from the stack and returns, sorry, the top two values from the stack and returns.
00:12:08.866 - 00:12:46.090, Speaker A: True or false? If they're equal, we get a one or a zero. And in our case, it's true. So once again, we're in that jump I situation. So we have true on the stack, we push 45 onto the stack. And now on line 36, we are, excuse me, on line 36, we're going to jump to line 45 because line 32 was equal to line 33. And hey, we know that this is the function that we wrote because it's the function that we tried to invoke. Fantastic.
00:12:46.090 - 00:13:18.246, Speaker A: And this is how the evm determines which functions to call. If you have many functions in your smart contract, you are going to have many lines of call data load. Does it equal this function signature? Does it equal this function signature? Does it equal this one? And then if it matches one, it'll jump to that line, and if it doesn't, it'll revert because you cannot call a function that doesn't exist. Awesome. Okay, so now we're finally in that very simple function that we wrote. If you recall, it was total supply equals eight. What we see on line 45 is a common command called jump deskt.
00:13:18.246 - 00:13:36.926, Speaker A: And all that does is it marks that line 45 is a valid destination to jump to. You cannot jump to any arbitrary destination. You need to jump to a valid one or you'll revert. So this just lets us know that, hey, we can jump here. What's the next thing we see? Push eight onto the stack. All right, awesome. This is definitely code that we wrote.
00:13:36.926 - 00:13:58.274, Speaker A: Total supply equals eight. I remember eight. This is us. Cool. But after that, we push zero onto the stack. So where does the zero come from? What are we talking about? Well, if you recall, in our very simple contract, we only have one storage variable. And that storage variable, because it's the only one defined, is in the first storage slot.
00:13:58.274 - 00:14:15.438, Speaker A: So the first storage slot, or the zero storage slot via array indexing. Right. So this is awesome. We have everything that we need. We have eight, we have zero. All we have to do now is save this and we're done. Right? But wait a second.
00:14:15.438 - 00:14:33.250, Speaker A: We see that in our transaction, we duplicated, we ran dupe two, so we duplicated the second from the top word of the stack. Okay. Then we swapped the first and second words on the stack. Okay, interesting. And then. All right, great. So now we ran s store.
00:14:33.250 - 00:14:58.586, Speaker A: So s store. Store and storage. We are saving eight to the zero with storage slot. That's what we initially wanted to do. But then we also have a pop after that because we have this extra eight on here. And what is this eight doing? Why is it here? This doesn't make a lot of sense. Right? Like why are we duplicating and swapping here? Why are we popping at the end? Solidity is doing extra memory management that we don't want.
00:14:58.586 - 00:15:25.742, Speaker A: Right. Because we want to be as gas efficient as possible and be as gas efficient as possible. So we should jump down into Yule and try to optimize this code. Right? Well, let's talk about gas optimization using Yule. If you're not familiar, Yule is simply a language that we use to write assembly code in solidity. It's not exactly like writing opcode. It's not exactly like writing EVM assembly.
00:15:25.742 - 00:15:41.318, Speaker A: It has for loops, if and switch statements. And it also disallows some commands like jump statements because they quickly become very difficult to reason about. And. Yeah. All right, so we added Yule. We have this optimized set total supply function. It's awesome.
00:15:41.318 - 00:16:07.822, Speaker A: We have an s store with a zero and an eight. So we're saving eight to the 0th slot. This is great. This is going to be way better. Right? Let's go ahead and measure our contract. So once again, or let's go ahead and look at the opcode representation of our contract first. So once again we take a look at the opcodes and we see that in fact optimized set total supply does have less opcodes than set total supply.
00:16:07.822 - 00:16:38.554, Speaker A: This is fantastic. We know that opcodes cost gas. We see that set total supply and optimized set total supply have the same opcodes, except set total supply has more. We just saved a lot of time and money. Right, but let's measure it to be extra. Extra, sure. So here, this is, I think, hard hat gas reporter, and we've ran the set total supply function 100 times and we see that the average gas cost is 22,599.
00:16:38.554 - 00:17:08.418, Speaker A: Cool. And then hey now we ran optimized set total supply and we see that the gas cost is 23,591. Awesome. Agas, we have just saved our users like an enormous amount of money, right? Well, not really. I kind of rugged you guys here. So if you notice, optimizer enabled is equal to false. If you're not familiar with optimizer, it's something that you can use in hard hat and in other tools when you're deploying smart contracts.
00:17:08.418 - 00:18:02.914, Speaker A: So let's go ahead and enable our optimizer in hard hat. We will set runs to 200, enable it and remeasure. And in fact, when we have the optimizer enabled, it looks like the two functions cost approximately the same amount of gas. Right? So all our time studying Yule and learning it and learning about s store was wasted, right? Well, I wouldn't argue that exactly, but I will say that optimizing smart contracts is hard, and chances are that you're not going to do a better job than the compiler unless you really know what you're doing. Contracts containing assembly are generally harder to reason about and harder to audit than contracts written in solidity and Viper. So what you might gain in gas optimization, you will probably be making a trade off in contract or user security. And the other thing that's important is if you're writing your own assembly code, always measure and make sure that your implementation is better than the compilers.
00:18:02.914 - 00:18:50.562, Speaker A: Because chances are there are some very smart people working on the compilers and optimizers that know something that you don't when it comes to memory management or safety. And I guess that's essentially my last point. Remember, a lot of the memory management stuff solidity does under the hood is there for safety reasons. And just because an opcode looks like it's unnecessary doesn't mean that it actually is. That being said, optimizing in Yule and in assembly is definitely something that is needed and useful, especially in defi and on mainnet where gas costs are lower now but quite higher than a lot of the other chains. But yeah, I guess do so at your own risk. So thank you guys once again, my name is Alex, I'm a lead developer at Tallyho and we are hiring solidity and typescript developers.
00:18:50.562 - 00:19:28.142, Speaker A: So if this kind of stuff is interesting to you and you're looking for a change, please reach out. And then finally I want to give a big thanks to Gilbert Garza. He had a lecture at Zero X Macra that inspired this talk and there are a few resources on here if you would like to dig deeper on any of the topics covered today. Thanks so much. Thank you. We would have some time for questions if you like. Why the optimizes function spend the same amount of gas if it has more sorry, less opcodes.
00:19:28.142 - 00:20:19.280, Speaker A: So the opcodes that we were looking at were for the unoptimized functions and we were looking at them because it's easier and possible to dissect them in a talk. So when we saw those two opcode, I guess of like optimized, what was it? Set total supply and set total supply. Those are the unoptimized opcodes. And then after the optimizer runs the opcode representation of those two functions actually becomes the same. What were those two opcodes, two extra opcodes doing the swaps were doing on the unoptimized compiled version. The optimized compile version was effectively the same as our opcodes. Here I can show you.
00:20:19.280 - 00:21:27.994, Speaker A: So here we have our unoptimized set total supply and our optimized set total supply like in our code where the optimizer has not run before. After the optimizer runs, both of these functions have the same exact opcode. And in fact, even though we have two functions in our contract, the optimizer is smart enough to know that they're doing basically the same thing. So when we were talking earlier about these selectors over here, right, so this selector jumps to a destination and then there would be a different function selector for another function. For the other function they would actually both jump to the same destination because effectively what they are doing is the same. What would be some good use cases for managing the assembly code within contracts? And do you recommend any good resources for learning Yule? Yeah, so I think that the best use case that I have seen is a fairly common one where if you're adding two numbers that you are 100% sure will not overflow the integer limit. Then in assembly you can add them with a.
00:21:27.994 - 00:22:18.040, Speaker A: There's an unchecked flag which basically tells the compiler to not check for integer overflow. I believe that in solidity, nine point something in some fairly recent version of solidity, safe math became, I guess, like, there are a lot of checks that run under the hood. You can turn off those checks if you're sure that you don't need them, and that'll save gas. But once again, that can be very dangerous. And as far as resources for learning Yule, I think just like reading smart contracts and trying to figure out what's going on, there is the best way to do it. There are unfortunately no good resources to learn Yule or really EVM assembly, which is that I wanted this talk just like.
00:22:20.590 - 00:22:24.890, Speaker B: Just to follow up on that. Have you heard of Trim?
00:22:25.630 - 00:22:26.426, Speaker A: Yeah.
00:22:26.608 - 00:22:49.790, Speaker B: Okay, so my question is this, right? Say, for instance, if I'm writing trim and I'm basically transpiling my smart contract into trim, what are the, I guess the pros and cons to that as opposed to doing it Yule style, like within solidity and then using Yule?
00:22:49.950 - 00:23:16.506, Speaker A: Unfortunately, I can't answer that question because I'm not familiar enough with trim. I do believe that Gilbert was the person that I mentioned in my talk was the person that developed trim or one of the developers. And I would encourage you to reach out to him on Twitter, but I'm not familiar enough with trim to answer that. Hey, thanks for the talk. I saw somebody asked about Yule today. There was an awesome workshop about that. It's like 2 hours long.
00:23:16.506 - 00:23:45.670, Speaker A: You should watch that. And then I had a question for optimizer runs. What number do you recommend? What number? I just choose 200 because it's standard. I know that there is a. Or it's not standard. It's just like standard in what I've written. I know that there's eventually a trade off size between contract size and gas efficiency that you get if you set your optimizer to, like, I don't know, 500,000, a million, or maybe less.
00:23:45.670 - 00:24:00.440, Speaker A: But I generally go with 200. I don't work in the DFI space, so I'm not too concerned with ultra, ultra ultra optimization. But 200 seems to be a good number for what I'm seeing, if that was it. Thank you so much. Thank you, guys.

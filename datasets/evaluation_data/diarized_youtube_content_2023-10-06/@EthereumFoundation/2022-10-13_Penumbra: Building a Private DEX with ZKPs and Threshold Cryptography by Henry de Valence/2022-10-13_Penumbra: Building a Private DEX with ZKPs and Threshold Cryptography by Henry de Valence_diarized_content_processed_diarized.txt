00:00:17.370 - 00:01:06.494, Speaker A: So looking forward to the next talk. Who is here for ZKPs? Who thinks ZKP are the greatest things that Blockchains ever enabled in the space in terms of getting it funded. All right, that's just my personal opinion, though. But I think ZKPs are actually the nice thing that nobody expected coming from cryptocurrencies, but they still happened. So next up, we have Henry Devalance, the founder of Penumbra, and he's going to be talking about their experience of building a privacy. This just disappeared in front of my eyes because the talk is starting now, but Henry is building a privacy preserving Dex using ZKP. So please put your hands together for Henry.
00:01:06.622 - 00:01:07.460, Speaker B: All right.
00:01:07.910 - 00:01:08.370, Speaker C: Yeah.
00:01:08.440 - 00:01:58.190, Speaker B: Well, great to see everyone. So I'm going to be giving a talk about how to build a private Dex. However, just as a kind of a pre warning, if you're really interested in all of the sort of details of ZK proofs that actually won't be covered in the talk. And the reason is that I think part of the problem with deploying ZKPs for privacy rather than just for scalability, is that there's some interesting and fundamental challenges in the state model. So that's actually sort of the whole summary of the talk. So to get started for context, so I'm working on a project called Penumbra. What that is, is private proof of stake l one, inside of that L one, we have an interchange shielded pool.
00:01:58.190 - 00:02:59.430, Speaker B: So you can take any IBC compatible asset, move it into this chain, and that's the privacy boundary. So as it moves in, it's recorded in this shielded pool. And the cool feature that we have is this private decks that's integrated with that shielded pool on top of that privacy preserving base layer. However, I'm not sort of here to just chill the project. I'm here to talk about the kind of technical aspects and specifically, what are the challenges to actually building this system. So the first challenge is oh, sorry, just as a bit of motivation, right? Why do we actually care about having a private decks in the first place? The thought is that every market is also a market in information. When we talk about price discovery, for instance, you can think of that as being a kind of decentralized computational process that, as a side effect, produces some information about prices.
00:02:59.430 - 00:04:10.614, Speaker B: But that means that information leaks are value leaks. When people talk about mev and have these dashboards of here's, how much value is extracted from people who are trying to do trading, really, that's just the sort of first order symptom of this problem. Even if you fixed mev in some way, you still have the problem that you're leaking information about what trades you're doing, what trades your account has done, your entire history of your whole trading strategy. All of that information is valuable, too. It's just harder to make a dashboard of it. So the thought here is that privacy is a really interesting thing for trading because trading is a context where having privacy allows you to unlock greater capital efficiency. And as somebody who's really interested in privacy for its own sake, as a value, as a human right, et cetera, this is a really interesting and exciting opportunity because it means that there's the potential to build a private product that can actually outcompete the non private ones because it's private.
00:04:10.614 - 00:05:05.726, Speaker B: So we get out of this mode of like, oh, well, we'll have people accept all these trade offs to use the private thing. No, we're going to build something that's better because it's private. So right, I said I was going to talk about the challenges and the first challenge, which is the most fundamental is actually the state model. So if we consider a transparent chain like ethereum, the paradigm of that state is global mutable state. There's like one big ethereum state and every transaction is applied sequentially and it can do whatever mutation to that state. And as it's doing that mutation effectively, it's taking like a global lock over the whole state, doing some changes, then you do the next transaction and so on. But in order to have a shielded chain where the user state is not public information, we have to change the state model to a model of immutable composable state.
00:05:05.726 - 00:06:00.282, Speaker B: This is actually kind of like historically speaking, this is sort of rewinding to a bitcoin style sort of UTXO model. But I think UTXO is a little bit of a loaded baggage laden term. So I prefer just having this idea of a state fragment. And instead of having one big global state, we're going to have a tree of state fragments which are immutable and each transaction is going to consume some state fragments, produce some new ones and put those append those into this tree. The reason that we want to do this is that that way we can make the state transitions private. And the move to do that is you replace all of those state fragments with cryptographic commitments to states. And then in your transaction, rather than explicitly declaring the plain text values of those state fragments, you can just have a ZK proof that the state transition was valid.
00:06:00.282 - 00:06:51.594, Speaker B: And here are the commitments to the new states that I produced. Okay, so this is all cool and that's why everybody's using private blockchains all the time. No, why is that? Because that diagram isn't quite right. In fact, what you're submitting to the chain is this ZK proof pi that represents this state transition. But what we've actually done is we've moved all of the execution off chain along with moving all the user data off chain, right? But now we don't really have any way to access any shared state because when somebody's submitting their transaction effectively, every transaction is its own little micro roll up. And what I would claim is that the key problem here is one of early versus late binding. So what we have in this sort of ZK model is early binding.
00:06:51.594 - 00:07:17.522, Speaker B: Every transaction has to have this fully sealed complete state transition. But that's not actually what we generally want, right? If you make a trade on uniswap, you're not going to sign over here's the exact state of the uni reserves of this contract here's the exact outputs that I'll get. Because the only way that you could do that is by sort of having the entire world stop while you submit your transaction.
00:07:17.666 - 00:07:18.166, Speaker C: Right.
00:07:18.268 - 00:07:32.270, Speaker B: What we want is the ability to have a partially filled transaction where we can have some placeholder values where when the transaction is executed, the shared state is going to go in that spot and then it'll determine some outputs.
00:07:33.330 - 00:07:36.334, Speaker C: So in order to make this work.
00:07:36.452 - 00:07:45.842, Speaker B: With the sort of ZK model where we're keeping all of the user data off chain, we need to have some better concurrency model for shared state.
00:07:45.976 - 00:07:46.418, Speaker C: Right.
00:07:46.504 - 00:08:20.750, Speaker B: Fundamentally the problem is that if you're doing this off chain execution, you need to have some kind of exclusive control over the data that you're executing on. And you can start with the kind of, oh, well, we'll take a big global lock and you can make the locks smaller. But the more interesting idea, I think is what if we try to model concurrency with message passing rather than locking? If you look outside of blockchains at just kind of like normal high performance, high concurrency software systems.
00:08:22.450 - 00:08:23.166, Speaker C: You can do.
00:08:23.188 - 00:08:59.786, Speaker B: Better by having finer locking. But a cleaner and more scalable approach is to have different parts of the system executing independently with their own state and passing messages back and forth to each other. So what would that look like in the context of trying to build a privacy preserving chain? Well, we could try to think of this kind of actor model for chains where a transaction, rather than synchronously doing a contract call, where it locks some state, does some execution and then finishes and releases the lock. We could say that a transaction is going to pass a message to a.
00:08:59.808 - 00:09:02.282, Speaker C: Contract and now we're going to have.
00:09:02.336 - 00:09:22.030, Speaker B: Each contract execute once per block. But as it executes, it's going to receive the set of all of the messages that any transaction passed to it and it can process those all in a batch. And depending on the specifics of that contract logic, in some cases you could combine all of those messages into one.
00:09:22.100 - 00:09:22.334, Speaker C: Right?
00:09:22.372 - 00:09:42.930, Speaker B: Like you could do a batch swap, which I'll get to later on in the talk. But also you could imagine, say, like an auction protocol that orders these messages by the bid amount. And the key thing is that you're not doing any execution at a higher time resolution than is actually provided by the underlying consensus.
00:09:43.010 - 00:09:43.254, Speaker C: Right.
00:09:43.292 - 00:11:38.086, Speaker B: When people talk about transaction ordering, a lot of the problems arise from this mismatch between the economic mechanism in the contract, which is trying to execute at this sort of faster than consensus speed and the actual consensus ordering guarantees that are provided by the blockchain, which happen block by block, right? Like if you're agreeing on transactions in batches, maybe you should also be executing them in batches. And on the other hand, our per user state, we can still have this sort of off chain execution, but now the execution is going to be asynchronous, right? When I consume my state and I pass a message to a contract, I can't compute my outputs yet because I haven't got a message back. So I need to somehow record this sort of intermediate future that represents the eventual results of the computation that I'm going to be doing. But I can do all of the computation that is only touching a particular user's state can happen off chain, privately in ZK. So the really interesting thing about this model is that it actually simultaneously unlocks both scalability and privacy because all of the data that doesn't need to be having any shared execution, that execution is happening on each individual user's client. And the on chain data is limited to the minimum shared computation and it's executing in a batch, so you can potentially have a much more efficient implementation. So to see kind of how this works in a diagram, which I think it might be a little bit more clear, we're going to start off with our first somebody's preparing a transaction.
00:11:38.086 - 00:12:39.966, Speaker B: They're going to perform a state transition and produce a ZK proof of it with their private inputs. And that transaction is going to send a message out to this contract. What it's going to record as the output of that initial transaction is actually a privately minted state NFT, which commits to the future that this computation is supposed to be representing. So now this user has this in this diagram, the diamond is this NFT that records the kind of intermediate state of their per user computation. After they send that all out to the chain, it's included in a block. The chain is going to send a message back by publishing data to the chain or the contract is going to send a message back by publishing the data to the chain. And we take that message from the contract, combine it with our intermediate execution state, we're going to burn that state.
00:12:39.966 - 00:13:24.718, Speaker B: And inside of this ZK proof, we can now prove that we've modeled the correct future with the correct same input values that we had committed to in the first transaction and now we can privately mint some outputs. So this is this sort of big picture diagram of how this sort of async ZK execution can work in principle and we'll get to a concrete example of how that works out for the case of doing batch swaps. But before that, I just want to get into this second challenge, which is once you have an idea of okay, we have maybe a workable state model but what is the privacy model?
00:13:24.804 - 00:13:25.486, Speaker C: Right?
00:13:25.668 - 00:14:29.074, Speaker B: And the claim here is that basically every useful blockchain revolves around public shared state. That's why, for instance, ethereum is valuable because it has everybody's state in it and it's all there. So the idea of like oh well, we're going to just make everything private and everything will be completely private doesn't actually work because in fact the reason that we're using the coordination tool is so that we can coordinate. Nobody wants to use a market where they have no idea what the liquidity is or what prices they might get or what the volume is. And all of the sort of big breakout successes of useful contracts have the contract's public shared state acting as this kind of universal counterparty so that you don't need to go and find some person to interact with, you can just interact with the chain. So we need to have public shared state, but maybe we want it to be private. So what does that mean?
00:14:29.112 - 00:14:29.410, Speaker C: Exactly?
00:14:29.480 - 00:15:59.470, Speaker B: Right? The question is like how do you allow private interaction with public shared state? We want to have some kind of notion where the individual users transactions have privacy but all of the aggregate state of the chain, like all of the aggregate market data is public but the individual users trades are not. So here's two basic strategies of how you could have private interaction with public state. One is splitting flows and the other is batching flows. When I say flow, the reason I use that word is that I think of value being in different sort of pieces of the chain state and as people do things you're going to have flows of value between different portions of the chain state. And we want to have some kind of system where people can have privacy about what their contribution to that specific flow is but still have a sort of overall transparent aggregate. So looking at these two in turn for splitting flows, the idea is that we're going to start off with some user's value, that maybe this is an amount that they want to trade. They can split that into randomized sub amounts and then reveal each of those sub amounts in distinct transactions and then reunify them later.
00:15:59.470 - 00:16:36.502, Speaker B: So this method only works if you have a shielded base layer. If you have a transparent base layer, then this is trivially broken because you just look at what the account was and then you can see what it did. But if everything else is private and you're only revealing like here is a specific amount that I'm sending to this part of the system. This is a public delegation amount to some validator. This is like an amount in one sort of randomized subtrade. This might be okay and it's a fairly practical and simple thing. However, it's not really ideal.
00:16:36.502 - 00:17:44.754, Speaker B: So the other strategy which is more interesting and more cool is this idea of batching flows. So if we know that we're already going to be processing the contract state in batches, it would be nice to have a way to batch up flows. We do this using a construction that we're calling flow encryption, which is effectively additively homomorphic threshold encryption with sort of end to end verifiability. Once you've tacked on six different properties, you might as well give it a distinct name. But the idea is that each individual user with their distinct contribution to this flow can encrypt an integer amount, include that in their transaction, and then the validators can sum up those encryptions and decrypt only a batch total. So that there's the batch total. And the idea is that now you can use that as the input to some public on chain computation, but still have long term privacy for individual transactions as long as the batch size is big enough.
00:17:44.754 - 00:18:52.898, Speaker B: As an example, if you're trying to have a delegated proof of stake system, you could make it so that oh, the validator weights will change in each epoch and we'll just sum up all of the delegations or undelegations in each epoch and only reveal the net change. So these are sort of the two pieces. Let's see how this kind of works out as a concrete worked example, which is doing sealed input batch swaps on Penumbra. So, looking first at the private state part, right, remember that we have this model where we explicitly segment away the per user private state from the shared public state. We're going to start off with, okay, here's the private input for this trade that a user wants to make. They're going to encrypt that input, include that in their transaction. The rest of the transaction is totally shielded because we have this shielded base layer so there's no public accounts or any other metadata in the transaction.
00:18:52.898 - 00:20:03.870, Speaker B: And what they'll mint in that swap transaction is a swap NFT where the asset ID of that NFT is a Snark friendly hash of their input trade amounts, the trading pair, the address that they're going to mint the funds to, some prepaid fees. And as this transaction that they submitted is included in a block, it gets batched together with the others decrypted. You send that into the Dex engine which resolves all of the trade intent and publishes the output data into the chain state. And now that user can consume their swap NFT, which remember is modeling this sort of future that resolves eventually to their swap outputs and produce a proof that uses these public batch swap data as a public input and their swap NFT as a private input to privately mint their correct prorata share of the batch swap.
00:20:04.370 - 00:20:08.526, Speaker C: And so that means that that individual.
00:20:08.628 - 00:20:13.620, Speaker B: User'S output can be minted completely privately and as long as you have.
00:20:15.990 - 00:20:16.622, Speaker C: Sufficient.
00:20:16.686 - 00:21:12.686, Speaker B: Volume in the batch, you can get long term privacy for individual users trade amounts now, if you're on, say, like a thinly traded pair, maybe you end up in a batch size of one. But in that case, you can use this sort of randomized splitting technique that I mentioned earlier to make effectively a kind of like randomized TWAP of your trade. So zooming out of the private state part to how this works. On the public state side, we have all of these swap transactions that have been included in the block. We have the Dex engine group, all of those inputs by pair. We do this batching and decryption. But now at this point, we don't just have a single swap, we don't just have a single swap transaction on a single pair.
00:21:12.686 - 00:22:48.078, Speaker B: We have a complete picture of here's all the trading intent for the entire chain in this block. And we also know that we only have to run the Dex engine once per block because we're in this batched computation model. So that means that we can actually be considerably more sophisticated in how we resolve these trades. We can load up the entire liquidity graph of all of the assets on the chain, sort of put the trade intent into the correct spots on that graph, and then compute some optimal resolution of all of these trades simultaneously. So you can do some kind of global resolution of the trading intent, do optimal arbitrage, and this is computationally tractable to do just like in consensus because you know that you're only doing this once per block. So you end up in a model where rather than sort of having to call each contract potentially like thousands of times a block, you just know that the chain is going to step in discrete time from one set of consistent prices to a new set of consistent prices. You can handle all of the newly added or removed liquidity also in a batched way, right? So you first add all of the newly created liquidity, then you resolve all of the trade intent, then you ARB all the prices to be consistent with each other, then you close all the closed positions.
00:22:48.078 - 00:23:29.066, Speaker B: And this also lets you, as a side effect, have like single block JIT liquidity with the kind of like batch semantics. So there's a lot of really interesting pieces of market design that get unlocked by this model. So that's basically the content of the talk. If you want to play with this, we have some weekly testnets that you can play around with. Here's a bunch of links so far. The big last sort of piece to build is the actual Dex engine. But we have a toy AMM that you can do these shielded swaps against on our testnet.
00:23:29.066 - 00:23:33.440, Speaker B: So that's the talk. If anybody has any questions, happy to get into it.
00:23:43.130 - 00:23:46.600, Speaker A: Just wait for the mic, please. I'll run to you with the mic.
00:23:50.430 - 00:24:02.826, Speaker D: Thanks for the talk. Just curious. So have you found a tight bound for how much of a loss you have when you provide batching, because if it's a constant function, market maker, a.
00:24:02.848 - 00:24:04.206, Speaker B: Loss in what sense?
00:24:04.388 - 00:24:16.306, Speaker D: So you're going to get an average. You're smoothening it out in that sense of speaking. So you can actually have a spike in a block you're just averaging. So have you done any analysis? I did some analysis. So I'm curious if you have done that.
00:24:16.408 - 00:24:21.026, Speaker B: So I guess the question that I have is like a loss relative to what? Right?
00:24:21.128 - 00:24:25.990, Speaker D: Assuming no private. So two worlds, same block, private versus non private.
00:24:30.410 - 00:24:31.254, Speaker B: No.
00:24:31.452 - 00:24:32.200, Speaker D: Okay.
00:24:36.890 - 00:24:37.930, Speaker C: Do we have more questions?
00:24:38.000 - 00:24:40.620, Speaker A: Yeah, not sure. Who was first? Sorry.
00:24:43.310 - 00:24:54.118, Speaker E: Just a quick one. Thanks very much for the talk. This is fantastic to hear and to get this content. Quick question on reverts the whole batch reverts.
00:24:54.294 - 00:24:54.714, Speaker C: All right.
00:24:54.752 - 00:24:55.606, Speaker B: Sorry, I missed that.
00:24:55.648 - 00:25:02.350, Speaker E: On reverts the whole batch reverts. If a transaction reverts transaction is not valid.
00:25:02.510 - 00:25:16.214, Speaker B: Yeah. So it's possible, for instance, that someone could submit a transaction that say they submit a trade for a trading pair that doesn't have any liquidity on it.
00:25:16.252 - 00:25:16.598, Speaker C: Right.
00:25:16.684 - 00:25:58.722, Speaker B: So one of the outcomes of the batch swap is that the trade can fail. And in that case, rather than having people privately mint their prorata share of the outputs, they privately mint their prorata share of the inputs. They get their funds back. Yeah. So the whole batch goes at once. So technically, I guess you could have some kind of griefing attack where someone is continually locking up capital in trying to prevent other people from trading by submitting a giant whale trade. But they can't actually do that without running the risk that someone will provide liquidity at a bad price.
00:25:58.722 - 00:26:00.980, Speaker B: So I think it's probably not a big deal.
00:26:03.110 - 00:26:03.570, Speaker C: Right?
00:26:03.640 - 00:26:12.590, Speaker A: The time is off. Well, one more round of applause for Henry, please. Thank you, Henry.

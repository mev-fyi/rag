00:00:03.690 - 00:00:12.640, Speaker A: Okay, let's dive in. Welcome everyone to 4844. Implementers call. Roberto just confirmed you're going to be taking notes this time. That sound good?
00:00:15.010 - 00:00:16.686, Speaker B: Yes, thank you for reminding me.
00:00:16.788 - 00:01:24.914, Speaker A: I will take notes for folks who want to follow along on the notes you can hear I, I'm going to be running this call because Kim's on a plane. Jesse, I work with Coinbase for the last six months. Before we dive into the agenda, I wanted to just quickly check and see. There's a few outstanding action items that I wasn't sure whether we followed through on, and they are these four. Let me actually just share my screen uv going to check them off, but let me know if otherwise. Okay, let's dive in. So we're going to be talking about the spec updates.
00:01:24.914 - 00:01:58.530, Speaker A: Angar, you mentioned that you had to jump on a flight, so why don't we start with your spec updates. I think the first one that's on the list is the modulus one, EIP 5864. Right. So that one, basically, I think it's just ready to match. Maybe some people would want to have just one more sanity look. It ended up being slightly modified. I'm not sure if we talked about this last week to also return the degree, polynomial degree.
00:01:58.530 - 00:02:41.150, Speaker A: And I have a personal small question mark there. Just best practices kind of concatenating the values right now that the module is showing basically an a site value right now. It's not padded. I think that makes sense. I also think it makes sense that leading and then the 32 bytes value kind of following as a small group and in case you want to use. Basically, I think we're having a hard time hearing you because of the background noise. Maybe try talking a little bit closer to mic, a little slower.
00:02:41.150 - 00:03:13.354, Speaker A: Okay, maybe someone else go ahead and I find a better location. Okay, sounds good. Let's come back to the onsguard ones. And he's going to do it. It looks like there are three specs that we merged. The first one is the get blobs v one change to the execution API. Any additional context that folks want to share on that one, I guess.
00:03:13.354 - 00:03:17.740, Speaker A: Yeah, that was a proto one. Proto. Any additional color to add there?
00:03:21.330 - 00:03:31.360, Speaker C: No additional color. I think that the execution API is updated, so please update the implementations too, if you haven't already.
00:03:33.510 - 00:03:40.740, Speaker A: Awesome. Any questions on that? Or folks have questions on the execution API do you want to be making available?
00:03:43.590 - 00:04:19.040, Speaker D: Yeah, just one question about this pre compile execution spec includes some lines about verification of values passed to this pre compile and we do not verify x and y values there. I mean, when we verify blobs, but we do verify it in this pre compile, can we delegate it to cryptography library instead of validating it on execution side, client side.
00:04:24.200 - 00:04:33.876, Speaker A: And just to make sure I understand, Alexei, I think you're asking about the execution specs rather than the execution APIs, is that right? Or the engine APIs?
00:04:34.068 - 00:04:43.870, Speaker D: Yeah, it's more about point evaluation pre compile specification. Yes.
00:04:48.160 - 00:04:48.910, Speaker A: Okay.
00:04:50.720 - 00:05:03.350, Speaker B: I think that's the intent, is that we do want to move everything into go KZG. But you're correct right now there's some implementations that are pieces of the implementation remain in the clients. That's on the to do list.
00:05:06.120 - 00:05:11.910, Speaker A: Alexei, just so we can fully understand, what's the specific thing you're asking?
00:05:12.440 - 00:05:55.380, Speaker D: Yeah, let me rephrase like that. So, point evaluation precompile is described in the specification. It includes just two lines I wanted to discuss. We are requested to verify that x and y values, inputs of this pre compile need to be verified, being less than modulus. Right. Should we move it to cryptography side and do not verify in execution client directly?
00:05:56.440 - 00:06:41.410, Speaker E: Right, I think I see what you mean. So the way I see it is that the pre compile code kind of guides you into that X and Y are scalar elements and hence need to be smaller than the modulus. But you're right that most likely in your implementation you're going to wrap it into a type that does the modulus check inside of it. Now you're saying whether we want to move this entire thing into the KZG library, as in that the library should receive like integers or bytes or something, and do the pre compile itself.
00:06:42.280 - 00:06:46.390, Speaker D: Yeah, you read my mind exactly right.
00:06:47.880 - 00:07:08.430, Speaker E: Okay. If you think that is better for you because you're managing less cryptographic burden on your side, we should consider it. You're right that there is some leaky leaks, like abstraction leaks there.
00:07:11.440 - 00:07:12.590, Speaker D: Okay, thanks.
00:07:13.600 - 00:07:17.580, Speaker E: I mean the point evaluation, sorry, the esag proof.
00:07:19.780 - 00:07:21.776, Speaker D: Pretty much takes bytes, right?
00:07:21.958 - 00:07:24.640, Speaker A: Like API.
00:07:28.660 - 00:07:29.730, Speaker E: Does it?
00:07:30.340 - 00:07:31.570, Speaker D: Does it not?
00:07:34.760 - 00:07:56.330, Speaker E: You mean the KCG? Okay, well maybe not for this call. I can make a note about this, about figuring out the interface of the precompile for client devs and work on it offline so that we don't hog the call.
00:07:57.340 - 00:07:58.510, Speaker D: Yes, thanks.
00:08:00.240 - 00:08:16.850, Speaker B: Yeah, feel free to bring this up in the execution implementation. The implementation tracker. I did have a chat with proto just yesterday in fact, about some of the stuff being moved into GokzG. So we can probably align over there.
00:08:20.580 - 00:08:36.410, Speaker A: Just to make sure I fully understand what the outcome of that back and forth was between George and Alexe. Do we think we want to make a change to the GoKCG CKCG interfaces and the interfaces that we defined in the consensus spec?
00:08:37.740 - 00:09:58.860, Speaker D: Actually it's not required because we already have byte arrays based interface there. I'm not sure that we need to additionally verify this modulus constraint for x and y, because probably it will be done on cryptography side two. I mean, cryptography library side two. So we do this twice and we need to unmarshal these values, I mean, to transform it to integers to compare with these modules. And if we could just pass bytes to the cryptography implementation so we could save some execution time, I don't know, and write less code. Yeah, it could be much more obvious if we could check this specification. It includes these checks for modulus and I just don't see we need it there.
00:09:59.630 - 00:11:04.026, Speaker F: Gotcha. Yeah, this is a fair request. Presumably specifically the verify KcG proof could just check the modulus is within bounds. The only not really a major concern is those assertions lets us bail out early if the user provides invalid points, because we do like expensive KC version hash later. If we were to move that to the KCD library, then if the user provided invalid points, then we'll end up doing the hash thing, which is not a good thing to do if you're in the. So the alternative is to move the entire function, kind of like what George was saying, have that implemented by GoKCG, then client implementers don't have to worry about all that crypto stuff. But I think we still need to keep the assertions prior to the verify KCG group so we can build early the event of an error.
00:11:04.218 - 00:11:14.020, Speaker E: I'm sorry Muffy, which hash are you talking about? The pre compiled doesn't have any hashing, does it? Or does it have.
00:11:14.790 - 00:11:18.210, Speaker F: I'm looking at the spec right now, the KCG version hash.
00:11:22.650 - 00:11:29.606, Speaker E: Okay, and you want that to fail? You want the basic assertions to trigger before the hashing happens.
00:11:29.788 - 00:11:30.520, Speaker F: Yes.
00:11:31.610 - 00:11:33.180, Speaker E: Okay, I see.
00:11:37.070 - 00:11:51.920, Speaker D: Okay, you said it may be indeed be better than just provide that heavy calculations before basic checks. That's it probably.
00:11:59.210 - 00:12:44.790, Speaker E: Right. I mean, Alexey, if you're saying that this is going to make your life easier, and since CKZG is a very tailor made library for this specific purpose, I think that's a good indicator that we should make the interface better now in terms of how the spec should look like, because it's like python, so it's not typed. I don't see how the actual assert lines can be completely removed, because that's kind of like the implicit thing that they are scalar types. I don't know how the spec will look like if we change the interface, but I agree that we should look into the interface to make it nicer for developers.
00:12:50.050 - 00:13:17.160, Speaker D: Okay. Yeah, I just found these basic checks quite useful. Maybe the interface can be proved by, but my statement was just about these two basic checks that I did not find useful previously, so it's now looks okay for me.
00:13:25.400 - 00:13:38.250, Speaker A: Okay, so I think we can resolve this is the kind of takeaway that George and Kev are going to look at whether there's an interface change we want to make here to the CKCG to add another function.
00:13:40.140 - 00:13:41.320, Speaker E: Yeah, potentially.
00:13:42.460 - 00:13:50.110, Speaker A: Okay, well, let's create an action item to do that, and if you guys decide no, I think that seems like a reasonable takeaway as well.
00:13:50.560 - 00:13:51.630, Speaker E: Sounds good.
00:13:52.800 - 00:14:05.250, Speaker A: Great. While we're on the topic of cryptography, George, the last cryptography spec API change got merged. Any other context to share there?
00:14:06.180 - 00:14:36.280, Speaker E: No, I don't think so. I think the PR got merged, the interface got simplified, apparently. Maybe not simplified enough based on Alex's comments, but yeah, all in all, I think it's like a simplification, so not much to report there. If there are any questions, we also have like a CKZG telegram group that might be a bit more specific. If you have questions of how to interface with CKC talking to the client developers.
00:14:39.660 - 00:14:49.230, Speaker A: Confirm me confirm, let me know if it's wrong. But I believe CKZG now implements these interfaces for client developers who want to be leveraging that. Is that right?
00:14:50.820 - 00:14:53.410, Speaker E: What's that? Can you say that question again?
00:14:53.940 - 00:14:59.650, Speaker A: Does CKCG implement the new interfaces from the 338 change?
00:15:01.540 - 00:15:28.196, Speaker E: So that's actually a good question. I'm not sure which. I know Ramana had the coronavirus at some point, so I don't know if the branch is fully up to date with the super. There is a branch with a new interface. I just don't know if it's like the main branch or not. I think it is Duncar, do you remember? I believe he merged it into the 4844 branch.
00:15:28.228 - 00:15:30.076, Speaker D: Now that we've merged it as far.
00:15:30.098 - 00:15:33.500, Speaker A: As I. Yeah, it's in the 4844 branch.
00:15:34.320 - 00:15:35.070, Speaker E: Okay.
00:15:41.840 - 00:15:58.000, Speaker A: Sorry, I had another question about the interface. So for the load trusted setup function, basically, is that how we are planning to load all the trusted setup values for the devnet through a file?
00:15:58.980 - 00:16:14.020, Speaker E: Yes, exactly. That function is. Suppose you pass it like the trusted setup parameters. Let that be devnet. Let that be minimal, let that be whatever main net and it loads it into the library to do the appropriate steps on the other functions.
00:16:14.840 - 00:17:05.750, Speaker A: Got you. Awesome. So I guess just a summary there for client developers who are doing implementations. The CKCG 4844 branch now supports the new cryptography interface that was just merged and so that should make implementation much easier. I also know that we now have Javascript bindings available for that, which might be useful for Ethereum js who I saw the implementation, who's starting implementation, and then I believe that there are rust bindings and Java bindings as well. But maybe someone else can chime in on that to confirm. I'm working on the rust bindings right now.
00:17:05.750 - 00:17:09.800, Speaker A: I hope to have a pr by tomorrow. End of the day.
00:17:12.990 - 00:17:46.820, Speaker G: I don't think the Java binding is up to date because there was a Java binding on the original Keyzg repo, but now it needs to be adapted with new interface. And I see also that all the bindings are in the repo itself, while the original one was a separate repo. The Java binding needs to be worked at the moment.
00:17:53.560 - 00:18:10.830, Speaker D: Yeah, and our library supports multiple ECC backends, currently have updated interface for BLCT backend, so for those who use the rust library they can use it.
00:18:16.570 - 00:18:51.710, Speaker A: Are there any clients that don't currently have clear path on a cryptography library to use for their implementation? Okay, Enrico on the Java side, is that currently blocking y'all? Do you guys have a path to update those bindings?
00:18:52.450 - 00:19:48.800, Speaker G: We were discussing with the Bezo team because actually TecW and Bezo are as far as I know, the only clients that are requiring the Java bindings. We have definitely a bunch of work before makes this binding really required. So we are kind of planning internally the timing for start working on it. But yeah, definitely if there are some help from outside will be appreciated. Otherwise at some point the taco team or the Bezo team will start working on it. Assumption is that should be an easy binding. But yeah, I'm not an expert on that, so don't have a clear idea.
00:19:56.460 - 00:20:46.804, Speaker A: Okay, sounds good. Well, I will comment an observation that two weeks ago there was uncertainty around the crypto APIs. There's uncertainty around the crypto libraries and now we have good crypto library, strong APIs and most findings on track, which seems like a lot of great. Okay, going to keep us moving. Anskar posted updates on his few things, so I'm just going to talk through what he shared in the channel. The first one is the modulus change that's ready for merge. The pre compile now returns two values, degree and modulus, and he'd love one person's eyes to double check the encoding.
00:20:46.804 - 00:21:14.070, Speaker A: Maybe doncrod. Doncrod is the right person to look at that, and otherwise we're ready to merge. Anyone have questions on that change in terms of returning the modulus in the pre compiled wrote decoding? Okay, maybe someone else.
00:21:21.790 - 00:21:23.722, Speaker E: I mean, the current encoding is literally.
00:21:23.786 - 00:21:43.698, Speaker D: Just eight bytes for the length for the number of elements and 32 bytes for the modulus. So there's no encoding. It's literally just those two values concatenated. So yeah, I don't know if anyone has an opinion on this. I don't know how these things are usually done. Right.
00:21:43.784 - 00:22:53.920, Speaker A: That was basically my only kind of question, just to make double check. We kind of keep with how pre compiled handles usually, and whether there's, for example, a preference. To me it feels like this ordering basically having the not 32 byte value first is slightly preferable because it makes loading from memory, once it's written to memory slightly more efficient, because then once you load it, you don't have to mask the leading bytes because you can just take a memory location with leading zeros anyway or something. I'm not sure if compilers are smart enough to do this anyway, and it will be a very small efficiency gain, but these kind of things just basically make sure that this is kind of the standard way we do this. But other than that, I think that. David have any perspectives on the encoding? I think it's fine, you can just go ahead with it. Great, sounds great.
00:22:53.920 - 00:23:57.520, Speaker A: So the next one, I'm just going to keep giving high level overview onscar, but let me know if you want to jump in. Reducing the throughput of blobs values right in the pr. Currently 256 target and 512 megabytes reduced down from 1 megabytes. We're going to talk about the test we're going to run later, but that's the current proposal from AnScAr. Anyone have any questions or thoughts on that? One question I had is, do we want to wait until after we run the kind of network test to merge this fully, or do you think it makes sense to kind of merge this and then we can readjust back upwards if necessary? My weak preference would be the latter, just because it seems like the same default, but I think either works. Anyone have strong opinions?
00:24:03.620 - 00:24:05.520, Speaker B: It's an easy parameter to update.
00:24:08.100 - 00:24:37.250, Speaker A: Great, well, go. I'd say let's move forward with merging that, and we can always adjust it now if we need to, adjust it later if we need to. And then the last one is the PR to set a minimum data gas price. There's been a bunch of discussion on the PR, but no consensus reach for now. This is again just a constant that we can change in the future. But anyone have any commentary or questions there?
00:24:46.810 - 00:24:51.320, Speaker B: Who is driving that investigation? Or is it just tabled for now?
00:24:52.170 - 00:25:41.210, Speaker A: I think Anskar is the running point on it. Okay, I think we will leave that one open again. It's just a config change, so shouldn't block anything on the client implementation. Two other spec updates that want to talk through, one that just got merged and this was proto one from you from a while ago to I think just bring everything in line with the new fee market update on the consensus specs. Any additional commentary to add there?
00:25:43.180 - 00:26:01.310, Speaker C: I reviewed it, but you should credit Anscar. And I think Anscar is boarding his flight so it's not able to comment. Yeah, I think the fee market changes are ready and like they're merged so you can continue with implementation there.
00:26:03.940 - 00:26:14.850, Speaker A: Great. Does anyone have any questions on the new fee market specification or is blocked on that implementation today?
00:26:25.220 - 00:26:35.280, Speaker B: We do have some tests for fee market implementation in Devnet v three, Devnet V two, as well as the Devnet v three in case anyone is implementing clients.
00:26:38.840 - 00:26:42.180, Speaker A: Are those in the interop repo? Is that what you're saying, Roberto?
00:26:42.520 - 00:26:58.168, Speaker B: Yeah, maybe Mophie could speak better to it. He's the one that implemented it. But yeah, they're spec level tests. They basically fire up the clients and upload a few blobs and check things. If your client is even graded, you.
00:26:58.174 - 00:27:28.910, Speaker A: Should be able to run those. Awesome. Okay, one last spec update that is in the agenda to discuss, I believe. Oh no, there's actually one more after this. And this is yours, Mophie, the rebase of 4844 on Capella. Can you give a quick status update on that, kind of where things are and what the next steps are?
00:27:29.600 - 00:27:56.990, Speaker F: Yeah, right. Right now it's blocked on the withdrawals pr. We're waiting to get that merged in so that I can rebase four. Four four on top of that. Yeah, that's pretty much where we at. I think we've gotten consensus of how the rebase should look like and how we want to do testing. All that's left is to update the withdrawal capella structures and update the pr.
00:27:58.160 - 00:28:01.870, Speaker D: And we should have that merged by tomorrow morning.
00:28:03.440 - 00:28:57.328, Speaker A: Splendid. Great. So this was probably the biggest open question in the last implementers call. But with this resolved, we are planning to kind of. Actually, let's talk about Devnet three in a second. But does anyone have any kind of questions on the decision around rebasing for it for on top of capella and how that will change kind of the implementation? Okay, sweet. Okay, the last perspective spec changes.
00:28:57.328 - 00:29:04.548, Speaker A: Terrence, I saw you opened up a pr to discuss a few things. Would you mind giving us a quick overview there? Yeah.
00:29:04.634 - 00:29:59.376, Speaker H: Hello, everyone. So I opened an issue this morning. There are a few more to do that from what I have observed over the last few weeks. So the first one, which is my fault, I didn't fix this, is that right now the block and blobs are gossip together, but we should probably add a note saying that, hey, the old beacon block gossip will no longer be supported because I think there's some confusions that people are assuming that we will still be supporting the block gossip topic, which we will not. So that should be easy. Just a few lines of notes in the consensus networking spec. Any questions on that? If not, the second one is that we currently do not have a way to request blob by root.
00:29:59.376 - 00:30:08.804, Speaker H: Right. Because now if a block is missing from a distinction, you can request a block by root. But we don't have a way to request the blog by root.
00:30:08.852 - 00:30:09.160, Speaker D: Right.
00:30:09.230 - 00:30:36.288, Speaker H: So there's two way to go about it. The first way is to implement a blog by root method. The second way is just implement the block and block by root method, just assuming they're coupled together. I'm leaning towards the second way just because it's just easier. You can avoid two coast and sounds like there's a few people who agree with me on the Discord channel. So I'm wondering if people have feedback on this or is there what people prefer?
00:30:36.464 - 00:30:40.550, Speaker D: So the range requests, we're going to keep them separate, right?
00:30:41.400 - 00:30:43.030, Speaker H: Sounds like hit. Yeah.
00:30:43.880 - 00:31:08.540, Speaker A: Wait, the range request. We're actually just discussing this too, but we were thinking it might be better to have a range request with both the block and blob and then just a separate block range request. Just because at no point you can't do anything if you just have a blob. So why would we be asking for a bunch of blobs?
00:31:10.560 - 00:31:23.936, Speaker G: Yeah, I tend to agree because I don't see how a client ends up having only a block at this point. If we have the main topic, that.
00:31:24.118 - 00:31:30.676, Speaker A: Gives us the coupled version only a block after.
00:31:30.778 - 00:31:35.140, Speaker D: If the blob pruning depth is less than the block pruning depth.
00:31:38.370 - 00:31:48.862, Speaker A: So that would be a reason to keep the blocks by range request, but we could just have a separate request for blob and block by range.
00:31:49.006 - 00:32:35.966, Speaker D: Yeah. My argument for keeping those separate is that historic sync, essentially you can keep historic sync and add stable and not have to think about it and add syncing the blobs rather than reworking to then have to use both of these methods. And again, my argument is in the future, assuming full sharding, you would still do full block sync and that element, and you would not do the kind of the blob sync which became additive. And so that allows us to kind of keep this core machinery totally stable. At the end of the day, I'm not engineering it, so I could be otherwise.
00:32:36.158 - 00:32:54.150, Speaker H: I think one more argument to have them separate just so you can sync both in parallel. But then you also have this implementation like complexity, like what happens if one gets here without the another. So I think it's a lot simpler to have them coupled from the implementation perspective.
00:32:56.270 - 00:33:23.474, Speaker G: Yeah, I agree. Because if you make it separate, then the handling of two different things that might be going wrong. And you start also thinking about optimistically validate the block while you are retrieving the blobs when you give up, when you go another try. So there are a lot of complexity there.
00:33:23.512 - 00:33:24.990, Speaker A: If you keep it separate.
00:33:25.150 - 00:34:10.126, Speaker D: I guess I think about it as just have the blobs as a dependency. Once I have a range of blocks, get the range of blobs rather than trying to interleave them. Because then you get your historic block thinking, you don't have to touch it all. And then you just have this kind of secondary follow process that ultimately would be pruned out of the code base. So it allows for that to remain totally separate. Whereas if, because there are going to be different pruning depths on blobs and blocks, and what you would be retrieving historically, then you now have to interweave, you have to totally change your previous sync process to now consider, am I doing this method or that method? And then once we go to full sharding, you'd have to then change it again. Again, that's my argument.
00:34:10.126 - 00:34:14.018, Speaker D: I will leave it there.
00:34:14.184 - 00:34:24.360, Speaker F: So in the event of flow sharding, can we just reuse a coupled request response rbcs and then just leave the sidecars like zeroed out?
00:34:32.570 - 00:34:51.722, Speaker D: Sure. Then you have a cludge where you're still like switching between the two, because you're still going to have to account for different printing depths or you're going to change a constant to assume the printing depths are the same, because now that they're zeroed, sure, there's plenty of ways to try to work it cleanly.
00:34:51.866 - 00:35:05.810, Speaker C: We can emulate the coupled request response method by just calling one after the other. It's not so much a consistency issue as it is with gossip sub, since we are talking to the same pair.
00:35:12.020 - 00:36:22.360, Speaker A: But we would still have to handle the failure cases. Is the thing where one peer just doesn't give us one of the two things. Yeah, and generally I feel like with the moving window for pruning, that's not too much of an issue so much as we have some margin of error past where we're pruning, where all the clients just still have blobs and yeah, generally it's like having the blob and block separately looks simpler, but I think because we have to deal with these edge cases that might not ever happen. It makes it more complex. And then just using one request at some range and a different request at another range, generally an implementation I think is actually simpler.
00:36:25.100 - 00:36:37.980, Speaker D: What happens when my clock is slightly off and I make a block and blobs by range request that is out of your pruning depth? Do I return zeros? There ends up being edge cases there as well, right?
00:36:38.050 - 00:37:40.170, Speaker A: I think that can be resolved generally by just like in implementation, we don't specifically code this to the minimum epoch depth for what you serve, but just don't request past it. If you happen to accidentally request past it, clients should have some epochs of margin of error. Yeah, and then to the point of is it more performant to download blocks and blobs in parallel as opposed to having one big request? Diva made the point that a bottleneck is actually processing, it's not download, and if you are requesting them separately, you can't process them until you have both, so it doesn't really make a difference.
00:37:52.780 - 00:38:00.250, Speaker H: I don't think we'll be able to come to a conclusion from this code. So should we just follow up on the issue itself?
00:38:03.040 - 00:38:06.430, Speaker A: Yeah, that's what I was about to suggest. That makes sense to me.
00:38:10.000 - 00:38:35.300, Speaker H: It's 30 87, but yeah, I was also discussing so my second point was basically we need blobs by root method, or we need a block and block by root method, right? So any objection for having them coupled by root?
00:38:38.300 - 00:39:23.320, Speaker C: The thing with the Byroot request response methods is that some other clients, like Nimbus have made a case in the past that sync should not rely on these by root methods as much, and maybe even only have these by root methods supported. For a recent part of the history, it's much easier to index the finalized data linearly and then store it in optimized device on disk and so on. We have whole new file formats for this and everything. And then creating this by root method just kind of ruins that by introducing an additional database index to find everything by root.
00:39:25.260 - 00:39:35.976, Speaker H: Yeah, I feel like this is more for missing block from attestation, more like from the current epoch or the last few slots, which you need to.
00:39:36.078 - 00:39:36.500, Speaker D: Right.
00:39:36.590 - 00:39:48.400, Speaker C: Let's say if we introduce it, we can limit the usage of this to the more recent part of the chain so that we don't require additional database changes in clients.
00:39:51.220 - 00:39:57.296, Speaker H: Yeah, that sounds good, but I also feel this is more like a general issue than foe for specific.
00:39:57.398 - 00:39:58.050, Speaker D: Right.
00:39:59.720 - 00:40:04.150, Speaker C: If we repeat the same issue, then we make it much harder to clean up.
00:40:07.640 - 00:40:10.152, Speaker A: Yeah. Okay.
00:40:10.206 - 00:40:16.664, Speaker H: So that's all I have. Those are the three basically questions or ongoing discussions I want to follow up.
00:40:16.702 - 00:40:17.290, Speaker D: On.
00:40:20.060 - 00:40:28.428, Speaker A: Just to confirm where we're leaving these. On the first one, it sounds like we should just open that spec change. Terrence, are you going to do that?
00:40:28.514 - 00:40:29.916, Speaker H: Yeah, happy to.
00:40:30.098 - 00:40:40.850, Speaker A: Great. On the second one, it sounds like there's more discussion that we might need to have. Or do we have a decision on the second one, or are we going to open up a new pr for that one as well?
00:40:41.860 - 00:40:51.908, Speaker H: I can open a pr, but we don't have to merge it right away and just let it marinate and discuss and just see how it goes.
00:40:51.994 - 00:40:57.830, Speaker A: Yeah. Okay. And then the third one, it sounds like there's active discussion already.
00:40:58.380 - 00:40:59.130, Speaker D: Right.
00:41:01.100 - 00:41:22.140, Speaker A: Are any of these blocking. I'm not as well versed in these domains. Are these kind of like core blocking spec changes, or would they be more kind of like things that will make the. Yeah. How important is it to drive resolution on these over the next couple of weeks, do you think, from a kind of like finalizing the spec perspective?
00:41:22.640 - 00:42:02.620, Speaker H: Well, I think the second one is definitely important for the Devnet three purpose, just because today if you're missing a block, you cannot get a blob, then you're kind of stuck there. So the second one is definitely definite three blocking, but it's not so hard for spec. And also to implement the third one, I think it's fine. We can spend a little bit more time on it just because I think for the definite three purpose, it's not super important to backtrack or bad sync. I mean, it's a nice to have, but it's not a blocker.
00:42:05.840 - 00:42:27.590, Speaker A: Got it. Okay. Well, for the second one, which seems like the more critical one. Do we think that there's a path to trying? I guess is it something we can decide today or if not, what's kind of the path to getting it decided in the next couple of days so we can continue making progress towards seven f three?
00:42:28.280 - 00:42:37.572, Speaker H: Yeah, just feedback from everyone. So I will open a pr and I will post a pr on discord link and yeah, just hoping for feedback from everyone.
00:42:37.706 - 00:42:48.536, Speaker A: Okay, sounds good. Proto it sounds like you have opinions there and so I think you weighing in there and helping us nudge that.
00:42:48.558 - 00:42:49.800, Speaker F: Along would be really helpful.
00:42:50.140 - 00:43:11.600, Speaker C: I'll review. I think there's a nice compromise here where we do support the byroot method in some form or another, but we limit the byroot usage to a time span, not as long as the full by range support, so that we don't have to create a database index to support this method.
00:43:22.460 - 00:43:52.350, Speaker A: Great. Okay. Are there any other active spec changes or spec discussions that folks want to raise before we move on to discuss the devnet three? Okay, let's move on to discuss Devnet three quickly. Want to just look at this.
00:43:54.400 - 00:43:54.908, Speaker E: Spec.
00:43:54.994 - 00:44:36.120, Speaker A: Overview that we have. Can folks see this screen now with Devnet three on it? I think, yes. Awesome. So I believe that there are no changes on the execution layer side. We are going to include the modulus change that should merge. But there's nothing else new that we need to do there on the Cl spec. We have now merged the cryptography API, we've merged the fee market changes and we have a resolution on the rebase on capella.
00:44:36.120 - 00:45:02.390, Speaker A: Let me just quickly make these changes in line for doing have so these two are merged so we can take those out because they're in the main spec. And then the 352, we plan to keep that in the devnet, is that correct?
00:45:03.560 - 00:45:04.310, Speaker B: Yes.
00:45:07.560 - 00:45:17.350, Speaker A: Okay, great. And it sounds like we can have that this week, correct?
00:45:18.760 - 00:45:19.510, Speaker D: Yes.
00:45:22.600 - 00:45:53.868, Speaker A: Eleven. And then it sounds like there's also one other, terence, the upcoming pr that you're talking about with allowing blob retrieval by to be do we have to block the Devnet or do we want to kind of put that in the critical path for the Devnet?
00:45:53.964 - 00:46:08.970, Speaker H: I think so. Just because there's no way for us to proceed if today we are missing a block and we don't have a blob. So you kind of deadlock there, but it shouldn't be that hard to make it happen.
00:46:11.180 - 00:46:40.650, Speaker A: Okay. Any other El or Cl changes that folks are expecting to be part of the Devnet? Last time we had this upcoming pr to block broadcasting blob transactions by default. Did we do that?
00:46:43.260 - 00:46:46.970, Speaker D: Is that just the gossip? Oh, no, sorry.
00:46:48.940 - 00:46:58.590, Speaker A: It was basically changed to. And I think there was debate between Ansgar and Marius about whether we actually wanted this to be encoded in the spec or not.
00:47:02.480 - 00:47:30.420, Speaker F: I think that was my understanding is it was like related to e 68 and not necessarily part of the vip. I know Maris isn't here. I remember there were two approaches to blocking broadcast. One is to do it by the transaction type, and the other is to do it by the size of the transactions. I don't know which direction.
00:47:30.760 - 00:48:00.144, Speaker A: And I think the debate was basically, do we need to actually include this in the spec or. And it looks like we had an action item for Ansgaard to update for specifying that blobs must only be announced. But maybe that didn't get done. I was premature in resolving that action. Follow. I don't think this is strictly blocking the Devnet, but we should follow up with. Oh yeah, Ansgar is on the call still.
00:48:00.144 - 00:48:06.752, Speaker A: Great. Ansgar, can you open the pr to do that? Yep. Great, thank you.
00:48:06.806 - 00:48:08.790, Speaker D: Announcing and then they can pull.
00:48:09.240 - 00:48:10.404, Speaker A: Yeah, exactly.
00:48:10.602 - 00:48:14.100, Speaker D: Okay. Because they're too large to be pushed on. Gets default.
00:48:14.680 - 00:48:57.200, Speaker A: Yeah, yeah. That was basically the compromise we came to at the Devcon workshops to make it easier for the clients to manage like Dos vectors. Okay, so we will get that in and then this engine get blobs by bundle. That one is merged so we can just have it there. This includes withdrawal field as part of the engine API. I believe that that were blocked on 352 on the CL spec to get that in there. Mophie, is that right?
00:48:57.350 - 00:49:00.108, Speaker F: Yeah, we're definitely clearing that.
00:49:00.294 - 00:49:15.400, Speaker A: Okay, so do we have a pr open for that or can you take an AI to open that pr once the CL spec change lands?
00:49:17.500 - 00:49:41.456, Speaker F: Yeah, sure. Also, relatedly, I think should we also update the EIP? Because the EIP does specify what the new header should look like because we're adding the ISIS data gas. It's not a big deal because I think most client devs should understand that we should include withdrawals, but in this interest of completeness, I think we should.
00:49:41.478 - 00:49:48.290, Speaker D: Also update the IP to just say that it has a dependency on the withdrawals. Yeah.
00:49:56.830 - 00:51:09.700, Speaker A: Okay. So are you going to take that as well? Sure. Okay. And I will make the note here upcoming PR to highlight dependency on withdrawals. Any other commentary? It looks like mostly it is the things that are actually the modules change is going to merge and then we need to get the rebase on Capella and then around blobber to go by root, but other than that, the scope is basically locked in. Any questions, thoughts, objections? Cool with that then I was wondering if it might make sense to do a quick client roll call. What clients we're expecting to have or participation as part of the devnet.
00:51:09.700 - 00:51:41.116, Speaker A: We had gas and prism existing. Do folks want to quickly check in and say whether they're interested in participating in the Devnet or not? Yeah, for lighthouse we definitely want to. We're pretty far along in implementation, but currently working on integrating KZG and fleshing out sync. So once we get that specked out.
00:51:41.138 - 00:52:10.626, Speaker D: We can implement that. Yeah, nevermind. Wants to join too. Maybe not. With everything working. Go CKZG library needs some tests and attention and other stuff not yet merged. Does that mean that you'd want like a smaller allocation of validators as a percentage of network?
00:52:10.818 - 00:52:18.386, Speaker A: Yeah, it.
00:52:18.508 - 00:52:19.350, Speaker B: Sorry, I missed.
00:52:19.430 - 00:52:19.962, Speaker A: Who is that?
00:52:20.016 - 00:52:23.058, Speaker B: Which client? Nevermind.
00:52:23.174 - 00:52:23.550, Speaker A: Yes.
00:52:23.620 - 00:52:24.240, Speaker D: Yes.
00:52:31.240 - 00:52:35.590, Speaker A: And then Roberto, how are you feeling about Aragon at this point?
00:52:39.180 - 00:52:40.760, Speaker B: Yeah, I think it's very doable.
00:52:43.980 - 00:53:00.510, Speaker A: We will do Aragon likely at this point. Any other Besu? Teku? I know Nimbus hasn't had the bandwidth to get started and I think that's the full set.
00:53:03.540 - 00:53:05.164, Speaker G: Yeah, Teku, very unlikely.
00:53:05.212 - 00:53:08.850, Speaker A: I think very unlikely for Besu as well.
00:53:10.660 - 00:53:11.650, Speaker D: All good.
00:53:16.020 - 00:53:39.930, Speaker A: Okay, well, a six client Devnet I think would be pretty awesome. So keep pushing in that direction. Do folks have a sense of a high level target for when we'd want to be Devnet ready or ready for Devnet three?
00:53:42.560 - 00:53:48.380, Speaker B: I'd like to shoot for before the Thanksgiving holiday. I think that might be realistic.
00:53:51.040 - 00:54:10.150, Speaker A: It's sort of like we need some degree of lag from after the specs completely stable. And I don't know the be nice side before Thanksgiving, but I feel like we will need at least a week more realistically, two weeks of lag after the spec stable. So.
00:54:24.620 - 00:54:37.820, Speaker F: Yeah, I think we can stabilize the spec by Monday, Tuesday, next Monday, Tuesday with that timeline, would like before Thanksgiving still be feasible?
00:54:41.120 - 00:55:14.790, Speaker A: I don't recall what Thanksgiving state is exactly, but the week after it. That seems challenging. Give us one week. Yeah, there's a coordination component that might make it difficult, but I think we could get the development done by then. Yeah. All right. Is the all core devs call this week on Thursday or is it next week? On Thursday?
00:55:16.330 - 00:55:17.320, Speaker D: This week.
00:55:18.250 - 00:55:21.830, Speaker A: This week. And then is the next one on Thanksgiving on the 24th?
00:55:32.350 - 00:55:34.320, Speaker D: Oh, sorry. I think it was muted. Yes.
00:55:35.090 - 00:56:07.330, Speaker A: Okay. It seems like we should be preliminary. Yeah, I think luckily we have a very global audience it seems like we should probably be pushing for the week after Thanksgiving to have the Devnet fully stood up. Based on what we know today, I think that'd make it more likely more teams could participate, which would be good.
00:56:09.300 - 00:56:26.600, Speaker D: Yeah, I mean, come Wednesday on that week, I think a number of us people are going to drop off for a few days. And so that means like trying to launch it on the 21st, the Monday, which given spec changes done, maybe the 14th. That's a really tight turnaround.
00:56:27.580 - 00:57:44.394, Speaker A: Yeah. Okay, well, why don't we preliminarily plan to launch on the 30 November, which will be the day after our implementers call that week, which will give us this week to basically confirm all the spec changes done next week to get implementation, the next two weeks to get implementation done and then button up any loose ends that the first half of that week and launch Devnet three. That sound reasonable to everyone? Let me just add this timing. Targeting launch on 1130. We will make it by the end of November. And I know we have all core devs on Thursday of this week now. I know.
00:57:44.394 - 00:58:21.320, Speaker A: And it seems like from a spec perspective, really the changes are the withdrawals change. And then this one conversation around the blob retrieval by root because the modulus one is going to Mophie. Terrence. Oh, I guess Terrence just left. I think the more we can kind of push to get those two spec changes, at least having a line of sight to being done. So by the time we go into all core devs, we can say, hey, we're basically finalized. From a spec perspective, I think the better.
00:58:26.200 - 00:58:28.390, Speaker F: Yeah, sounds good.
00:58:29.720 - 00:59:22.688, Speaker A: Okay. We are at time the last update that the two other items here that were prospectively on the agenda was the large block spam test and the readiness checklist. The readiness checklist. We can update async based on all of the progress here in terms of the large block spam test. Dan, is Dan Lee here from paradigm? No, it doesn't look like it. I can share an update from have. Paradigm is going to be running the first iteration of that spam test on testnets either this week or next week, and then we'll move to mainnet and that's going to start giving us data on kind of current network characteristics which we'll be able to use to finalize the blob size and to just in general build our confidence around network.
00:59:22.688 - 01:00:14.340, Speaker A: So if folks have questions or thoughts or want to be involved in those tests, there's a telegram group that we have and we can add you to it. Just let us know. Okay, I think that's all. Anyone have any final comments, questions? Thoughts? I guess last ask for me, this is my first time ever running this kind of meeting in Ethereum development. If you have feedback or thoughts about how it could have run better, please feel free to reach out. I'm Jesse Pollock on discord and telegram and Twitter and would love any thoughts on how I could better show up for ethereum. Okay, thanks everyone.
01:00:14.340 - 01:00:15.430, Speaker A: Have a great day.
01:00:16.280 - 01:00:17.140, Speaker D: Bye.
01:00:19.080 - 01:00:25.890, Speaker A: Bye everyone. Fun. Bye.

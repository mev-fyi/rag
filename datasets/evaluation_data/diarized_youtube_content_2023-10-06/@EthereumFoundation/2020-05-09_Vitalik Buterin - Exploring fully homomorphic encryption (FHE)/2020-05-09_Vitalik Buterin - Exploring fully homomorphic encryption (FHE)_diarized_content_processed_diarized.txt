00:00:00.250 - 00:01:00.186, Speaker A: Today what I wanted to do is basically kind of go through the basics of how fully homomorphic encryption works. So fully homomorphic encryption, and as I'll get into a bit later, basically is this kind of encryption that allows you to run computations on encrypted values. And there's a lot of things that are really interesting about this, like you can do privacy preserving computation really easily. It's also an important building block in some multiparty computation protocols. It's an important building block in a lot of the proposed obfuscation protocols that people are starting to come up with. And the interesting thing with fully homomorphic encryption is that it sounds scary. There's a lot of, I feel kind of impressions that it's this very complex form of cryptography.
00:01:00.186 - 00:02:05.226, Speaker A: It just got figured out only slightly a couple of years ago. And so it must be really complicated to understand. And it turns out it's completely not. It turns out that fully homomorphic encryption protocols are literally kind of simpler to fully understand, I would say, than even a lot of elliptic curve based constructions. Now, the reason we're not using fully homomorphic encryption for everything is basically because it's not very efficient and it has high overhead, it has ciphertext that are very large. And I'll get into why this is the case fairly soon as well. So to start off, let's talk about kind of what is fully homo morphic encryption, right? So the goal of fully homomorphic encryption is basically to have an encryption scheme where you can compute on encrypted data, right? So if you have an encryption of x, you want to be able to turn that into an encryption of f of x for some function f without being able to decrypt.
00:02:05.226 - 00:03:13.446, Speaker A: So without being able to determine x or determine f of x. So you can think of partially homophobic encryption protocols that we know about already. So if you think about even elliptic curve points, now, this doesn't technically fully satisfy the definition of fully homomorphic encryption because it's not an encryption scheme, it's just a group that has a homomorphism. But if you look at elliptic curve points, if you take some number x and you multiply it by some elliptic curve point, that's the generator, and then you add the generator multiplied by y, you get the generator multiplied by x plus Y. This is a really nice property of elliptic curve points, basically that they do kind of follow this and distributed property. And there's a lot of protocols that do make use of this. So in the case of blockchains, for example, there is deterministic wallets that have master public keys that they rely on these elliptic curve homomorphisms.
00:03:13.446 - 00:04:45.702, Speaker A: There's even zero knowledge proof protocols based on elliptic curves. Things like bulletproofs, even just signatures rely on this kind of additive homomorphism, so it already provides a lot of value. And if instead of adding, you want to be able to multiply, then you can just use RSA, right? If you just use kind of simple RSA encryption. So x to the power of e, then x, y to the power of e equals x to the power of e times y to the power of e. And so if you have the ciphertext for X and the ciphertext for Y, you can create the ciphertext for xy, right? So we have this kind of family of schemes that gives us additive homomorphism, and we have this family of schemes that gives us a multiplicative homomorphism. Now the question is, can we come up with a scheme that lets us do both, right? So can we come up with some way of making a ciphertext so that you can do both adding and multiplying on ciphertexts? And if you can add and multiply, then you basically have general purpose computation, right? If you restrict your ciphertext to just being zeros and ones, then you can do pretty much every logic gate, right? So if you want to do and then, and of X and Y is just x times y if you want to do or then, well, or is basically you can kind of invert x invert Y, then you do an ands and you invert again. Or you have this kind of simpler formula where you just say x plus y minus x times Y, right? So if both value inputs are zero, then this is obviously zero.
00:04:45.702 - 00:05:25.040, Speaker A: If X is one, then you have a one here, you have a zero here, and then you subtract a zero here, so you get one. If Y is one and x is zero, it's symmetric. So you also get a one. And then if x and y are both one, then you get one plus one minus one. So you also get one for Xor. You can do either just x plus y, and that's if you don't care about the numbers staying within kind of the range zero and one. If you just care about them being even and odd, or if you care about the numbers being within the range zero and one, then you can just do x plus y minus two times x times y, right? So if x and y are both one, then it's one plus one minus two, and you get to zero.
00:05:25.040 - 00:06:18.866, Speaker A: So if you can add and multiply, then you can do pretty much whatever logic gates you want. And you can do arbitrary computation. Now it's not going to be efficient arbitrary computation, because if you imagine wanting to do some math based off of numbers, then you'll pretty much have to decompose those numbers into bits, and then you'll have to turn your addition and your other operations into circuits. And then you have to evaluate the circuits. And so you can see how kind of the complexity multiplies, but you can do it. So to give the intuition around how these fhe protocols work, we'll start with a kind of toy protocol. And this is, I believe, technically secure under some kind of very unfavorable key sizes and complexity.
00:06:18.866 - 00:07:25.674, Speaker A: But this is the way that people started kind of figuring out how to be able to do addition and multiplication. Right? So imagine your private key is a big prime, and think of it as a really big prime number. Then to encrypt a message where a message is restricted to either zero or one, then what you do is basically you take a big random number, then you multiply it by p, then you add together a small random number multiplied by two, and you add your message. So what we have here is basically we have a multiple of p that's offset by some noise and a message that's hidden in the least significant bit of the noise. And if you want to decrypt, then you decrypt the ciphertext with the key by basically saying it's the ciphertext mod p in brackets, and that kind of kicks out this term, and then you just do mod two, and that kicks out this term. And so you have your m left. By the way, if people have questions at any point, please feel free to ask.
00:07:25.674 - 00:08:20.026, Speaker A: I'm happy to answer. So why is this scheme additively homomorphic? Right, so why is this kind of approach where you encrypt a message by taking a big multiple of your key, adding some noise, and then hitting your message in the least significant bit of the noise. Why is this additively homomorphic? Well, basically, if you imagine you have two ciphertexts, each one of these ciphertext is going to be a multiple of p plus some noise plus a message, multiple of p plus some noise plus a message. And these things just kind of naturally distribute. Right? So basically the ct one plus ct two actually is a ciphertext. It's a ciphertext in the correct format, because you just have a multiple of p that is k one plus k two. Then you have your noise, and the even part of the noise also adds up.
00:08:20.026 - 00:08:45.778, Speaker A: So you have two r one and two r two over here. And then it's just two of r one plus r two. And then your messages add up, right? So m one and m two. Basically you have m one plus m two over here. And note that this is addition mod two. Right? So if your message here is one and your message here is one, then this is two, but the two over here is indistinguishable from just being part of the noise. And so it just becomes the same as zero.
00:08:45.778 - 00:09:45.926, Speaker A: But if we just want to do binary circuits, then this is totally fine, right? So you can add together two ciphertext and you get a ciphertext that is of the correct format of the addition or rather of the x or of the message bits. Now why is this multiplicatively homomorphic? So let's say you multiply together your two ciphertexts. Then you have an expression of the form that your first ciphertext, k one p plus two r one plus m one multiplied by your second ciphertext, k two p plus two r two plus m two. And you basically just kind of fully expand this. And when we expand it, we're just going to say, first of all, let's figure out which terms are multiples of p, right? Because if you remember the decryption process, the decryption process starts off by just modding, which just kills all your multiples of p. So let's figure out what the multiples of p are because we don't have to care about them. Basically, you have k one p multiplied by all three of these.
00:09:45.926 - 00:10:09.230, Speaker A: Then you have k two p multiplied by all three of these. So these five terms go over here. Now you have two times. So now we have to figure out which of the remaining terms that are not multiples of p are even. And it's basically two r one multiplied by this. And you have two r two multiplied by this. So you have a bunch of terms that get multiplied by two.
00:10:09.230 - 00:10:57.070, Speaker A: And then you have this thing over here, which is not multiplied by p and not multiplied by two, which is just the product of the messages, right? So if you take this expression, and then you do a mod p and then you do a mod two, then the mod p is going to kill these five terms. The mod two is going to kill these three terms. And so you just have this one term left. So we see that this is additively homomorphic. We see that this is multiplicatively homomorphic. Now why does it have kind of any level of security? Basically, it's this approximate GCD problem, right? Basically, if you did not have noise. So if we did not have this kind of two times small random, then you have just a bunch of multiples of p plus zero or one, and then a bunch of them are going to be just multiples of p plus zero.
00:10:57.070 - 00:12:25.830, Speaker A: Then you can just use any GCD algorithm, and then you just keep just the Euclidean algorithm and you just gcd all of these multiples together and you get p, and then you can kind of break the scheme, right? But as it turns out, if you just have approximate multiples, then figuring out what p is becomes much harder, right? So the security of this cryptographic scheme is based on the hardness of computing approximate gcds, as opposed to computing kind of exact gcds, which is easy. So there is a more general principle here, which is basically that solving systems of equations becomes much more difficult when these equations have errors, or you can call them noise, right? So if you add some noise into your equations, then suddenly figuring out parameters that are parts of those equations that you can normally figure out easily just suddenly becomes much harder. And this is pretty much what the security of all of these constructions ends up being based on. So, as a side note, public key encryption. So I showed this scheme as being a secret key scheme, right? You need p to encrypt. Now, turning these schemes into public key schemes is really easy, right? You basically just provide a bunch of encryptions of zero. And then if you can public key encrypt zero by just computing a random linear combination of these, and you can add some more error.
00:12:25.830 - 00:13:14.330, Speaker A: And if you want to encrypt one, then you could just take these encryptions of zero and add one. If you want something more generic, then into your public key you could add some encryptions of one. And then to encrypt one, you add a bunch of encryptions of zero and then an OD number of encryptions of one, and you have a new encryption of one, right? So any fully or homomorphic scheme that is private key, you can turn it into a public key one pretty easily. That's not a problem. Now, why doesn't this work already? Right, so there's two problems. One of them is that multiplication just doubles the length of the ciphertext, right? So here you had k one p and k two p. And here you have k one k two p.
00:13:14.330 - 00:13:44.050, Speaker A: And actually it's k one k two p times p. So it's k one k two p squared. And so the bit length of this multiplication is just going to be the sum of the bit lengths of the ciphertext that are coming in. And so if you try to do more than a couple of multiplications, it just blows up horribly and it just becomes impractical. Right. So you can't do more than a logarithmic number of multiplications, period. But there is another problem, which is overflow of the errors.
00:13:44.050 - 00:14:35.090, Speaker A: So if you remember, the sum of the ciphertext kind of turns into a new ciphertext of this format, then the product of the ciphertext turns into a new ciphertext of this format. We can look at what happens to the even kind of error term here, right, when you add, the error roughly doubles. You take the sum of the errors when you multiply the error squares, right? So when you had r one and r two, here you have two r one, r two. And so the bit length of the error doubles. And so once again the maximum multiplicative depth is going to be the logarithm of the number of bits in p or the log of log of p, right? So you can think of the maximum multiplicative depth as being really low. Like think of it as being something like ten or even five. It's tiny.
00:14:35.090 - 00:15:33.586, Speaker A: So how do we overcome this overflow problem? So there's two general categories of solutions to this, right? The first category of solutions basically is that we do clever tricks to make multiplying only increase the error by a constant factor. And so instead of having log, log p, or log of the number of bits of p multiplicative depth, you actually do have a log p multiplicative depth. So the multiplicative depth is proportional to the number of bits in p. Right? So if you imagine we can make a protocol where every multiplication increases the error by some fixed factor, say a factor of 1000, then that's only ten bits. And so if your modulus has a bit length of, say 10,000, then your multiplicative depth goes up to 1000, which is already huge. So this is one solution. And the second kind of solution is bootstrapping.
00:15:33.586 - 00:16:39.594, Speaker A: Right? So bootstrapping basically is this kind of key switching mechanism where what we're going to do is basically imagine that you have some ciphertext that has some noise and you want to convert it into a fresh ciphertext that has less noise, right? So what we'll do is we will basically take the kind of circuit that represents decrypting X under some secret key, and we're going to evaluate it homomorphically, right? So what we're going to do is we're going to take X. So X is a ciphertext, then we're going to represent X as a bunch of bits. And what you're going to do is we're going to provide a kind of bootstrapping key. So think of this as being part of the public key of the system. First of all, you can encrypt the bits of X under some new key. So you can encrypt the bits of X here under some new key s two. But also we provide the bits of S under a key s two.
00:16:39.594 - 00:17:07.250, Speaker A: Right. So what this basically means is that for some key s two, you have the regular public key for s two. And you also have an encryption of s under s two. And so given the value of X in the clear, you convert that into its bits, then you convert that into encryptions of the bits of X. And then you have encryptions of the bits of X. You have encryptions of the bits of S. And you just compute fs homomorphically.
00:17:07.250 - 00:18:05.382, Speaker A: Basically you just compute this Decryption Process using these inputs that we have. And what this gives you is the decryption process returns one bit, and so you get one bit, which is the decryption of X. So it is the same bit that x represents, except it gets encrypted under the key s two. Right. So before we had X, which is an encryption of some bit under S, and now we have basically an encryption of X that's under the key s two. And the important thing is that x might have had a lot of error, but this Decryption, it's only going to have a fixed amount of error regardless of how much error you have over here. And the reason basically is that, well, from the kind of perspective of looking this under key s two, all of these bits start off as being a ciphertext of error, of kind of the minimum error level.
00:18:05.382 - 00:18:34.900, Speaker A: They start being kind of depth one. And then this decryption has some constant depth. And so the amount of error that's going to be in, the result is actually going to be constant even if there is a lot of error in the ciphertext here. So before I kind of continue, maybe I should offer an opportunity for some questions, because bootstrapping is kind of a little bit complicated to understand. So maybe just kind of think for a bit and make sure that you understand what's going on here.
00:18:36.950 - 00:18:44.020, Speaker B: One question I have regarding bootstrapping is, is there randomness involved and where does it come from?
00:18:45.850 - 00:19:33.860, Speaker A: So bootstrapping just basically means that you're evaluating the decryption circuit. So the place where there is a kind of error involved is basically that the process of homomorphically encrypting these x bits is going to involve basically taking values from the public key, and those values already have some noise inside of them. So the process of executing the circuit kind of after you have those values doesn't require you to have to add any extra randomness, but the bootstrapping key already has kind of randomness that got used in the process of constructing it. Right. That makes sense.
00:19:35.430 - 00:19:45.938, Speaker B: Could you describe what exactly, sorry, what's the output of the decryption function? What does that look like when it's evaluated in the circuit?
00:19:46.034 - 00:19:53.450, Speaker A: Right. So the output of the decryption function is either the bit zero or the bit one, depending on what the ciphertext x represents.
00:19:57.540 - 00:20:07.748, Speaker B: Right. Okay. So the thing I'm having trouble with is that I don't want the one evaluating the circuit to actually see those bits. Right?
00:20:07.834 - 00:20:40.652, Speaker A: Correct. Okay. So the reason why the person evaluating the circuit cannot see those bits is because that person does not have x. Right. So computing the decryption requires you to have x, and it requires you to have x now in your bootstrapping key. You're not going to give them x, you're going to give them an encryption of the bits of s under s two. And so the only thing they can do is they can evaluate the decryption circuit in a way that gives them just outputs that are encrypted under the key s two.
00:20:40.652 - 00:20:44.290, Speaker A: They have no way of kind of extracting outputs in the clear.
00:20:45.700 - 00:21:00.180, Speaker B: I see. So deck, they don't actually get deck, they get the decryption circuit. Okay. They have some representation of it. They get the bits of s encrypted using s two and they run this circuit.
00:21:00.760 - 00:21:18.296, Speaker A: Right. They run those bits. Exactly. So they have s encrypted under s two. They have x in the clear. And so they just encrypt x under s two and then deck it. And it's part of the algorithm, so everyone has it.
00:21:18.296 - 00:21:26.590, Speaker A: And so you just evaluate deck homomorphically using bits encrypted under s two. And so you get zero or one encrypted under s two.
00:21:26.960 - 00:21:36.924, Speaker B: Right. So what you write below this ANC deck, that's not actually something I have to do. I only have to run the deck and that automatically already gives me the encryption.
00:21:36.972 - 00:21:40.192, Speaker A: Okay, exactly. So this is just what it's equivalent to.
00:21:40.326 - 00:21:41.010, Speaker B: Yeah.
00:21:41.780 - 00:21:53.300, Speaker A: Right. Okay. What is k is just whatever the value is that Zed is encrypting.
00:21:54.780 - 00:21:55.690, Speaker B: Thank you.
00:21:57.660 - 00:22:27.296, Speaker A: Once you've re encrypted this, why can't you back propagate the new lower entropy or the new re encrypted format with the lower error, why can't you back propagate that lower error and gain a log factor or constant? If you do your multiplication trick through every previous multiplication, again, how would you back propagate the lower error? I don't know. I haven't tried to play with this yet. But. Right. Intuitively, it feels like there may be.
00:22:27.318 - 00:22:28.690, Speaker B: Some method of doing that.
00:22:31.540 - 00:23:04.972, Speaker A: I think the problem is lower error plus higher error equals higher error. And generally kind of any function, if you have some function and you throw in a lower error thing and a higher thing, you get a higher thing out. So because the errors are just randomly generated, you're not going to be able to make them cancel in some way. Okay. Right. So one subtle technical point. So this x is encrypted under s.
00:23:04.972 - 00:23:45.400, Speaker A: And here we're saying we encrypted under s two. Technically, you could just set s equals s equals s two. Right. So you could technically just encrypt the bits of x under s. And then you can have the bootstrapping key be the bits of s encrypted under s. And this makes things a lot easier, because instead of having lots of keys or having an entire chain of keys with a chain of bootstrapping keys, you can just have one key. So why in the standard descriptions of bootstrapping, don't people do that? Basically for weird technical reasons, you can't prove kind of a security reduction straight to the lattice assumptions.
00:23:45.400 - 00:24:12.692, Speaker A: And so there's this kind of special term. It's called circular security. And depending on whether or not you're one of these cryptographers who's like, no, you have to have proofs versus one of these cryptographers who's like, yeah, whatever, it's fine, dog. It's your choice whether or not to trust circular security. A lot of people think it's fine. I have a question. This s two is also a public key.
00:24:12.692 - 00:24:21.910, Speaker A: So the private key don't know. So just have to use several public keys of the recipient for this. Right.
00:24:25.160 - 00:24:29.400, Speaker B: What is the second depth of the decryption?
00:24:29.740 - 00:25:11.456, Speaker A: Good question. And I'm about to get to it in the next slide. So the main problem is that the multiplicative circuit depth of this decryption, it involves a modular reduction, and x mod p has a circuit depth of log log x, which is bigger than log log p. And this is higher than what fhe can support. Right. So basically, one of the reasons why nobody cares about the scheme that I just spent 10 minutes describing to you is because bootstrapping is not possible. In general, bootstrapping has a circuit depth which is logarithmic.
00:25:11.456 - 00:26:28.406, Speaker A: And so the next parts of all of this are going to be kind of how do you adjust the scheme so that you actually can bootstrap? So we're going to skip over a few things. So Craig Gentry came up with some really clever tricks in 2009 involving subset sums and other things I don't understand, to try to kind of get around this problem. So to try to reduce the circuit depth of bootstrapping to the point where you actually can bootstrap in a fairly simple fhe schemes. And Craig Gentry is great, and we love Craig Gentry, and he's going to come back in the story. He is the one that created, or one of the people who created the Matrix FHe protocol. But we're going to go straight to speaker Berkierski and Vinod Vikuntanathan's work in 2011, which is kind of the first scheme that really, I kind of managed to get around this problem, right? So the schemes that I'm going to show out from here on, they don't depend on approximate GCD, they depend on a slightly different, but kind of similar seeming assumption, which is this learning with errors assumption. Right.
00:26:28.406 - 00:27:44.830, Speaker A: And the learning of errors assumption basically says that if you have a system of equations, so if you have this kind of system of equations, you have a bunch of variables. You have a bunch of equations. Normally you can solve them using gaussian elimination, and it's fairly easy. But if you just have approximate equations, so you have a whole bunch of equations. And even if the system is really over specified that have a small additive error, then finding any of the variables becomes very hard, right? So solving systems of linear equations where the outputs have errors in them is something which is hard and is something which, as far as we know, is quantum hard. So these mechanisms also reduce to hardness of latices and the shortest vector problem and all of these other kind of problems that are fairly well studied in mathematics. So basically, the schemes that I'm going to get into from here on, they're not going to depend on approximate gcds, they're going to depend on hardness of solving approximate systems of linear equations.
00:27:44.830 - 00:28:58.786, Speaker A: So let's get to bv 2011. The key is going to be a vector, and it's going to be a vector of numbers s one s two to sn, and the ciphertext is going to be a vector a that satisfies the property that a dot product s is a message plus an even error. And this is all going to be done modular. Some OD q q doesn't have to be prime, but it has to be od. So basically you generate an a such that a one s one plus a two s two plus ansm equals m plus two times your error. So the connection between this and the learning with errors problem is basically that you can think of each of these ciphertexts as being an equation and your secret key, right? Your secret key is, I guess, one s two s three s four. The coefficients in the equation are going to be the a and the output is going to be basically some small number and it's zero or one, depending on what your message is, plus some error.
00:28:58.786 - 00:29:39.858, Speaker A: And that error basically kind of perturbs the values. And that makes it hard to extract s. So your ciphertext is just, if you're kind of comfortable thinking in terms of vectors and dot products, it's just ma such that a dot product s equals message plus two times an error. Or you can think of it as this linear equation. One optimization is that you can set the first number in your secret key to one. And that just makes it very easy to construct these a's. Basically you just generate all your other a's randomly, and then you set your sa one to kind of compensate for whatever the rest of the dot product gives.
00:29:39.858 - 00:30:52.054, Speaker A: And so whatever the rest dot product gives, basically you construct a one to be kind of the minus of that, and then the minus of that plus s one kind of adds up together with this. And then you get your zero. And if you set a one to be, to kind of subtract another m plus two e, or rather add another m plus two e, then this whole dot product just becomes m plus two e, right? So, constructing vectors that satisfy this equation is very easy. So as I mentioned, an alternative interpretation of this vector interpretation is that a ciphertext is a noisy equation where the variables are your secret key. Addition is easy, right? So addition, basically if you have al such that al s equals one m plus two e, then ar such that ar s equals another m plus two e, then dot products are additive. And so ao plus ar s is just going to be the sum of your messages plus the sum of your errors. And the way that you decrypt, obviously is just you actually compute a s and you take the last bit and so you can decrypt the addition.
00:30:52.054 - 00:31:58.766, Speaker A: And if you decrypt the addition, you get twice the even error and then you have the sum, or rather the xor of your two messages. Again, right? So addition here is simple, multiplication is harder, right? So the problem here is that in the scheme I showed you before, you're just operating with single numbers, and single numbers can be added and multiplied here you're operating over vectors. And vectors can't just be multiplied with each other. Well, they kind of can. Right? So you have this kind of notion of an exterior product, right? So basically you have kind of this concept of an exterior product where a vector multiplied by another vector is just a big vector that contains all of the products of the elements, right? So if you imagine Al is a vector with ten elements, Ar is a vector of ten elements, the exterior product is going to be this vector of 100 elements. It's like the first times the first, plus the first times the second, plus the first times the third all the way up to the first times the 10th. Then you have the second times the first all the way, blah, blah, blah, and then the 10th times the 10th.
00:31:58.766 - 00:33:01.622, Speaker A: Now you have this nice kind of algebraic identity that basically says Al exterior product Ar dot producted with s. Exterior product S equals this dot product multiplied by this dot product, right? And so remember that Al is one ciphertext, Ar is one ciphertext, and the product of the decryptions. So m one times m two is just going to be this dot product times this dot product. And so because of this algebraic identity, that equals the same thing as Al exterior product Ar dot producted with S exterior product s. So if you take two ciphertext and you just exterior product them. So basically you just turn them into this big vector that contains all possible products of their elements, then that becomes a valid ciphertext of m one times m two under the key s times s. Right.
00:33:01.622 - 00:34:04.602, Speaker A: So you can multiply, but the length of your secret key grows quadratically. And so the challenge is you need to have a way of going back to linear. So to go back to linear, what we're going to do is we're going to have this procedure that we call relinearization, right? So the procedure for linearization, it feels a bit like bootstrapping, basically, because what you do is you have kind of encryptions of s under your new key, and then you just evaluate things under your new key. So it's kind of similar to that, but it's doing something slightly different. Right? So a real linearization does not solve the error problem. It just solves the problem of taking a ciphertext under the key s times s or s exterior product s and turning it into an encryption under s. So the relinearization key is going to contain kind of encryptions of Sisj times two to the d.
00:34:04.602 - 00:35:26.594, Speaker A: So it's going to contain basically Sisj for all inj. So all elements of s exterior product s and not just those elements, it's also going to contain those elements times two, those elements times four, those elements times eight and so on and so forth, going up pretty much all the way up until for every power of D that's smaller than your modulus. And so what this lets us do is it lets us compute an encryption of the dot product of al exterior product Ar with s exterior product s as a linear combination of SisJ two to the d, right? So if you imagine this expression just as we did in bootstrapping, we're not going to kind of evaluate it in a clear because, well, you don't want the person executing the circuit to be able to figure out the output in the clear. So instead we're going to evaluate it homomorphically under either some new key or if you're willing to assume circular security, you can provide it under s. If these encryptions are under s, right? So we're going to evaluate this whole thing homomorphically just as a linear combination of all these powers, right? So for example, if you have Al as one, two and then ar as three, four. And so Al exterior Ar is going to be 3468, right? So this is one times three. Four is one times four.
00:35:26.594 - 00:36:25.238, Speaker A: Six is two times three. Eight is two times four. Then to evaluate Al exterior, the dot product of Al exterior Ar with S exterior x, basically what you're going to do is you're going to say, well, you're going to have three multiplied by s one s one, four multiplied by s one s two. Six multiplied by s two s one and then eight multiplied by s two s two. And then to avoid having to multiply ciphertext, because multiplying ciphertext makes the error blow up, you have these powers of two. And so the multiplication you could just express as a linear combination of these powers, right? So to express three times s one s one, you're going to take this encryption of s one s one times two, the zero plus the encryption of s one s one times two, the one. And so this gives us s one s one times three encrypted under your new key.
00:36:25.238 - 00:36:54.030, Speaker A: Then for four you just have s one s. So here, four is the second element in al exterior yard. So we're going to multiply it with the second element of s exterior x, which is s one s two. So we'll use the encryption of s one, s two times two squared. Then for six is two to the one plus two to the two. And so we're going to add the encryption of s two. S one times two to the one with the encryption of s two, s one times two to the two.
00:36:54.030 - 00:38:15.958, Speaker A: And then here we're going to add the encryption of s two s two times two to the three. And so basically if you add all these encryptions, then you have a vector which is the encryption of, or rather a vector which kind of, if you were to dot product it with your key, it would give you s one s one to the zero plus s one s one to the one plus blah, blah, plus some error because each of these terms are going to have some error added to them. So you're going to just add all of this error and you have these set of terms. And this is going to give you three times s one, s one four times s one s two six times s two s one eight times s two s two, which is the same thing as this term here. Right. So basically what we've done is we've created this sum of a bunch of these ciphertexts such that if you were to decrypt it, so if you were to dot product it with the new key, then you would actually get a value which equals to the evaluation of this plus some more error. And so if you were to evaluate it and you were to cancel the error out, then, because this gives you m one m two plus some error.
00:38:15.958 - 00:38:38.850, Speaker A: M one m two plus some error plus some error, cancel out the error, you would get m one m two. So this both kind of preserves the message. And because it's an addition of a bunch of linear size ciphertexts, the ciphertext size and the key size also go back to linear. So I'll stop again and kind of wait for questions because relinearization is also not very intuitive.
00:38:44.870 - 00:38:59.794, Speaker B: Wow, this is super cool. One of the questions I have is you mentioned that this helps reducing the size of the key but not helping with the error.
00:38:59.922 - 00:39:00.600, Speaker A: Correct.
00:39:01.690 - 00:39:03.570, Speaker B: Why does it not help with the error?
00:39:03.730 - 00:39:43.110, Speaker A: It does not help with the error, basically because this expression itself, right. It's going to evaluate to this multiplied by this, and al is equal to m plus two e. Ar is equal to m plus two e. And so the product of those things is going to contain a term that has four e squared. And so this thing evaluates to four e squared. And so this thing evaluates to four e squared. And so here you have four e squared plus some more error that comes from a logarithmic number of these, right? So the error still blows up from being a multiple of e to being a multiple of e squared.
00:39:43.110 - 00:40:25.218, Speaker A: Now, there is another magic trick to make the error blow up less quickly. And I'll get to this after. But first, I'll kind of wait for questions about this scheme. What does it mean to encrypt sis j two to the d? Yes, very good question. I was about to actually answer this myself. So, the encryption scheme, as I provided, it, can only encrypt zero and one, because it has some even error. So you might ask, well, what does it mean to encrypt this thing, which is obviously going to be much bigger than zero and one.
00:40:25.218 - 00:41:47.180, Speaker A: So the answer basically is that the encryption in quotes of Sisj two to the d is going to be a vector a, such that if you were to dot product it with the key, you would get sisj times two to the d plus some even error. Right? So you cannot actually extract Sisj to the d from the ciphertext, because there is the error, and the error is just going to kind of wash away everything except for. Well, it's going to wash away everything except for the really high bits and the low bit, but it's going to wash away some bits in the middle. It is basically a vector where if you dot product that vector with the key, that you get Sisj to the d plus even error. And so the reason why this is still useful is because if you add up these cybertexts, then you still get al times ar or al exterior er dot producted with s exterior x plus a whole bunch of even errors. But these even errors just kind of add together with the even errors that were already inside of here. And so whoever ends up kind of ultimately decrypting this ciphertext, the errors are all even and sold, will be able to just cancel, take them out.
00:41:47.180 - 00:42:57.070, Speaker A: Okay, I got it. So it's just kind of not encrypted properly, like parts of the final cipher text that you cleverly adapt. Right? Okay, so here is the magic trick to make your error blow up less quickly. So, first, kind of a fun fact, right? So we can switch ciphertexts between kind of what you can think of as being two perspectives, right? So one perspective is your ciphertext is a and a dot product at s equals m plus two e, where m is either zero or one. Now, if you just kind of modular divide a by two. So this is all mod q. Then a divided by modular divided by two dot producted with s gives you m becomes m over two and two e becomes e, right? And so your small even error becomes a small error that doesn't have to be even and m over two.
00:42:57.070 - 00:44:15.830, Speaker A: So zero divided by two is zero and one divided by two is ceiling of q of half your modulus, right? So if your modulus is, say, 999, then one divided by two is going to be 500, right? Because 500 times two is 1000, which modula 999 reduces to one. And so you can basically take a ciphertext that's of this form and then you divide your a by two and then you convert it into a ciphertext that has this format where instead of your message being in the lowest bit, your message becomes kind of in the high order bits. Now this perspective is better for multiplication because if your message is in low order bits, then when you multiply your two messages together, your message is still kind of preserved, right? Your message is in the field of two elements, or I guess you can't divide. So the ring of two elements might be a little more precise, right? Like basically if your message is in the low order bits, then everything that happens with the error kind of happens on top of the message and the message just kind of flies under and it doesn't get affected. But in this perspective, the message is at the top and so everything interferes with it. So in this perspective, you can't multiply. But this perspective has a key advantage, which is that it makes the noise less structured, right? So here the noise has to be even.
00:44:15.830 - 00:45:13.354, Speaker A: Here the message just becomes small. And so by cleverly switching between these perspectives, you can, without having the secret key, change the modulus of a ciphertext. So here's what we do, right? We start off with a such that a dot product s equals your zero or one plus two times the error. Then you do a perspective switch. And so you have an a prime, which is a modular divided by two, which is equal to small error plus either zero or half your modulus. Now what we're going to do is we're going to switch it from mod q to mod p, right? And so what we're going to do is we're going to take this ciphertext, we're going to take the a prime and we're going to multiply it by p, and then we're going to integer divided by q. And so if you do this, then what you're going to get is you're going to get a value, which if you then multiply it by s.
00:45:13.354 - 00:45:41.906, Speaker A: So you do rescale a but you do not rescale s, right. So this is a bit kind of important. So the rescaled a prime gives you basically, well, if you dot product it with the same thing, then the output is going to be rescaled. And so zero becomes zero. Ceiling of q over two becomes roughly ceiling of p over two. Small error becomes small error, except the error itself also gets kind of downscaled. Right.
00:45:41.906 - 00:46:08.780, Speaker A: So it gets downscaled from being something times q, some small fraction times q, to being the same small fraction times p, until the actual magnitude of the error kind of goes down. And then when you basically do a reverse perspective switch. And so you go from this perspective where it's either zero or ceiling of p over two to this perspective, you double of this and then it becomes either zero or one plus two times the air.
00:46:09.150 - 00:46:17.840, Speaker B: Now this operation, I didn't understand the previous step about. Yes.
00:46:20.530 - 00:46:24.560, Speaker A: Why this times p divided by q? Trica works.
00:46:26.210 - 00:46:32.458, Speaker B: Yeah. Why it gives you the one on the right. Why is the message zero where two?
00:46:32.484 - 00:47:39.350, Speaker A: That's not right, basically. So if you just think of this as being just a multiplication, then if it was an encryption of zero, then it's just going to give you a multiple of q. And if it was an encryption of one, then this gives you a multiple of q plus half of q, right. And so if you multiply this by p over q, then multiples of q turn into multiples of p and multiples of kind of half multiples of q turn into half multiples of p. So I guess one example was that if you imagine say q is 5000 and p is 1000, then if a prime s is, or let's say q is 10,000, p is 1000. Just for simplicity, then if a prime s here was say 50,000, or let's say 50,000 plus a bit of an error, then if you go down from q to multiply by p over q, so basically p is 1000, q is 10,000. So you divided by ten, so your 50,000 just becomes 5005 thousand.
00:47:39.350 - 00:48:04.910, Speaker A: Modulo 1000 is still zero. But if you instead had say 55,000, then 55,000 times p over q is going to be 5500. And so modulo 1000 is going to be 500. And the error that gets introduced by kind of the floor division not being perfect is still a small error. So it just kind of mixes together with the small error that already exists.
00:48:07.610 - 00:48:10.694, Speaker B: So this should really say e prime as opposed to e, right?
00:48:10.732 - 00:48:15.110, Speaker A: It's a different, correct? Yes, sorry, that's correct. This should be e prime.
00:48:22.140 - 00:48:30.090, Speaker B: And even the contribution from e, that's also going to change, right.
00:48:31.820 - 00:49:02.550, Speaker A: To just kind of go back to this example. Right. So let's say your a prime s was as an integer dot product equal to, let's say instead of 55,000, it was equal to 55,030. So your error is 30. Then if you multiply by p over q, 55,030 turns into 5503. And so Modulo 1000, it's going to be 503, 500 is p over two. And so your new error, it was 30 before, now your new error is three.
00:49:02.550 - 00:50:05.240, Speaker A: So basically the ratio between the error and the model size remains the same. Correct. And I'll explain why it seems like you're not accomplishing anything because the error ratio is the same, but you're actually accomplishing something really important, which I'll get into in the next slide. Right. Now, I guess, are people satisfied that if you have a ciphertext whose error gets bigger, you can turn it into a ciphertext whose error as a number is bounded by some constant, but it's just a modulus that keeps being reduced? Right, so this is kind of the lesson here. Yeah. Okay.
00:50:05.240 - 00:50:52.226, Speaker A: So here is why we switch. Right? So there's two reasons to switch, actually. So the first reason to switch is this makes bootstrapping actually practical. Right? So bootstrapping involves basically computing this dot product a s mod q, and computing this dot product a s mod q has a circuit depth of log lot q. And by reducing the modulus, what we can do is we can basically turn something which to a decrypt requires a circuit depth of log q to something that has a circuit depth of log log p. And p here can be very small. Right.
00:50:52.226 - 00:51:20.492, Speaker A: Once you do the modulus switch, you don't have to actually do any more computations. So P could be a pretty small constant. And so this basically means that the circuit depth of bootstrapping becomes a constant. And so you can just increase q to as much as you need in order to make the bootstrapping procedure actually possible. Cool. Yeah. So in the bootstrapping key, basically the way that we do it.
00:51:20.492 - 00:52:11.550, Speaker A: So bootstrapping is just kind of computing this dot product P or kind of as a circuit. And so to make this computable, you're going to provide Si times two to the d values in binary representation. So for every Si times two to the d and this is modulo p, then you provide a binary representation of this. And so you have n log p numbers in binary representation. So for every one of these terms, you have your sn. Basically, to compute Sn, you take for every one bit that's in an, because you have an in the clear, you multiply that by the corresponding kind of bit representation of the power of sn. And so you just have a bunch of these numbers.
00:52:11.550 - 00:53:22.870, Speaker A: And these are numbers in binary representation, right? So they're not single ciphertext, they're log p ciphertext. And then you just add a whole bunch of these numbers together. And then to take modulo, the best choice of p is going to be two to the power of n minus one. And that makes modulo really easy because you just meet your addition circuits wraparound. So how do we implement these addition circuits? Right, the addition circuit is just going to be, you have these n log p numbers and you just have to add together these n log p numbers, right? And then the modulo, basically your addition circuits, instead of carrying onto kind of even higher bits, every time you carry past the size of p, you just kind of wrap around, right? And then that just gives you modulo at two n minus one for free, right? So if your modulo says 1023, then your bits are 128, 256, 512, then 1024 is equal to one. So you just kind of wrap that around to one. So moduloing is really easy.
00:53:22.870 - 00:54:42.076, Speaker A: So your setting is you just have to add together a whole bunch of numbers, right, and the first step is that you can reduce three numbers to two numbers. So you can have a kind of three to two adder that has multiplicative depth, one, right. And the way that this works is basically that every bit of p is going to be just the xor of the corresponding bits of a and b and c. And every bit of q is going to be kind of the two of three functions of a and b and c, right? So this is zero if a plus B plus c is zero or one and one if a plus B plus C is two or three. And you can think of the SSB and carry digits, right, and the q, you also kind of multiply it by two, which basically means you just kind of left shift q by one, right? So the reason why this works is basically because every bit in a and b and c gets represented inside of p. But then in the specific case where you have kind of two bits that are turned onto one, then inside of p they get turned into zero. But you flip the corresponding q from a zero to a one and then the q gets kind of moved to the left by one.
00:54:42.076 - 00:55:23.932, Speaker A: And so that multiplies it by two. And so basically kind of every individual bit in a, b or c gets kind of correctly represented in p plus q, right? So this is a kind of three to two adder, and this has multiplicative depth. One. Adding two numbers x plus y does require logarithmic multiplicative depth, right? So if you're going from n numbers to two numbers, that requires the multiplicative depth, which is basically logarithmic in n. So logarithmic in the number of the number of numbers, and we don't care about the size. But then adding the last two does require multiplicative depth. Log log x plus y.
00:55:23.932 - 00:56:03.690, Speaker A: And here x and y are mod p. So we're basically saying log, log p, or log of the number of log of the number of digits of p, right? So if p is 1023, then p has ten digits. The log of ten is going to be four. And so your multiplicative depth is just going to be four. Now, the reason why adding circuits have this logarithmic multiplicative depth is basically because you have to worry about kind of threading the carry bits through the number. And in the code that I'll link to later, I have algorithms for doing this. So in general computing a linear combination of size n, log p is going to take size.
00:56:03.690 - 00:56:40.020, Speaker A: So first of all, you have these n numbers, and second, you have this kind of, and the n numbers together, the sum is going to be size n log p. And so it's kind of log of n, log p. And so this becomes log of log n plus log log p. Here you have another log log p. And so the total kind of o is going to be kind of log n plus log log p. And you can pretty easily just set q to be high enough that this is less than log log q. And so basically you can implement the decryption circuit and so you can bootstrap.
00:56:40.020 - 00:57:41.972, Speaker A: So here's optimization number two, right? So I mentioned back when we were over here that there's two tricks to overcome overflow, where one is bootstrapping and the other is clever tricks to make your multiplication only increase your error by a constant factor. So this is the clever tricks that I'm going to talk about, right? So basically, imagine if instead of just doing a modular switch before bootstrapping, we do a modular switch after every multiplication. So if you don't do this, so if you imagine a circuit that has some multiplicative depth, then your error is going to square every time you do a multiplication, right? So if you imagine your first ciphertext, let's say the modulus is ten to the 16 minus one. And your ciphertext has error ten squared. If you square it, the error is going to be ten to the four. Actually it'll be a ten to the four times some constant. But we'll simplify and we'll say it's ten to the four.
00:57:41.972 - 00:58:20.324, Speaker A: Then the third time you multiply the error is ten to the eight. Then the fourth time you multiply the error is ten to the 16. And then the error kind of overwhelms the ciphertext. And then here decryption starts failing. So if you just do this kind of fully homomorphic or just partially homomorphic encryption naively, then after a logarithmic multiplication depth, you're screwed. Now what happens if you do modulus reduction, right, so you have x, which has an error of ten squared, modulo ten to the 16 minus one. Then you multiply it and so you have x squared with an error of ten to the four.
00:58:20.324 - 00:58:58.656, Speaker A: Now you perform a reduction, and so here you have error ten to the four modulus, ten to the 16 minus one. We're going to basically cut the modulus by a factor of 100. And so your error gets cut from ten to the four to ten squared, and your modulus gets cut from ten to the 16 to ten to the 14. And so now you have this term over here and then you can have this term over here. And now if you square this again, then your x squared goes up to x to the four. Your error of ten squared goes back up to being an error of ten to the four. Your modulus is the same.
00:58:58.656 - 00:59:20.712, Speaker A: Then you reduce it again. And now your error goes down to ten squared. Your modulus kind of hops down again. Then you square it again. The error goes up from ten squared to ten to the four. And then you just reduce the modulus again. And so notice that instead of the error squaring every time, we have the modulus just kind of very nicely orderly, just stepping down by a constant factor every time.
00:59:20.712 - 00:59:57.170, Speaker A: Right. So the clever trick here is basically that when you multiply the ciphertexts, the errors get multiplied. And so if you just make sure that the errors as numbers stay small, then squaring the error is always just going to be a constant factor multiplication. And so instead of having a logarithmic number of steps, you can have a linear number of steps. And so your multiplicative depth goes up from log log q to a log q. Pause for questions. Again.
01:00:04.550 - 01:00:12.510, Speaker B: I didn't completely follow everything. So it's multiplicative depth of what don't we want to decrease the multiplicative depth.
01:00:12.590 - 01:00:47.214, Speaker A: Sorry, by multiplicative depth, I mean the maximum multiplicative depth that you can support. Right? So if you notice, like the example at the top and the example at the bottom here, your error blows up to the point where it overwhelms the modulus after three multiplications, because each time you're squaring here, we're keeping the error under control. Right? The error is just always ten to the four down to ten squared. Up to ten to the four down to ten squared. Up to ten to the four, down to ten squared, except every time the modulus just steps down by a constant factor of ten squared. And so here instead of doing three steps, you can do eight steps. Right.
01:00:47.214 - 01:00:50.930, Speaker A: So here you can do log log q steps. Here you could do log q steps.
01:00:52.390 - 01:00:58.722, Speaker B: And both optimizations are kind of unlocked by this context switch, right?
01:00:58.776 - 01:01:06.390, Speaker A: So both the bootstrapping and this technique that lets you basically not need bootstrapping half the time are unlocked by the module switch.
01:01:10.490 - 01:01:11.238, Speaker B: Cool.
01:01:11.404 - 01:03:00.700, Speaker A: Okay, so now we move on to what this presentation was supposed to be about, which is matrix fhe. So the problem that matrix fhe solves is basically, can we try to find something that's kind of more natural and more efficient than realinearization, right? So relinearization is expensive, basically, because relinearization requires you to just add this really huge number of ciphertexts. And if you imagine a large modulus, you're talking about hundreds of ciphertexts for each element. So can we try to make something that's kind of somewhat nicer? And can we also try to create a protocol that's somewhat simpler where adding and multiplying ciphertexts actually is done by adding and multiplying elements in some kind of naturally reasonable array. So matrices, yay. So here is kind of the context, right? So to encrypt s with, or to encrypt zero with a secret key, what we're going to do is we're going to have come up with a matrix a such that the secret key multiplied by the matrix is an error. And to encrypt one, we're going to have a matrix a such that a secret key multiplied by the a gives the secret key plus an error, right? So basically what we're doing is we're kind of hiding an approximate eigenvector where here, where the eigenvalue, if it's zero, the eigenvalue is zero, and if it's one, the eigenvalue is one, and if you really want, you can potentially encrypt other values as long as the eigenvalue kind of becomes the place where the plain text gets hidden and it's only an approximate eigenvalue and so you can't extract it using the standard techniques for the standard because learning with errors makes it hard.
01:03:00.700 - 01:04:17.314, Speaker A: So addition is easy, right? Basically addition, if you just add together two matrices, then so if you add together a matrix such that SA equals something, with a matrix where SA equals something else, then s of Al plus Ar is just going to be basically whatever the value is for the first one plus whatever the value is for the second one. Right? So s times Al, or decrypt of Al plus ar becomes decryptive al plus decrypt of ar, which is going to be your left message times s plus your left error plus your right message times s plus your right error. And so you have the sum of your messages times s plus the sum of the errors, right? It's basically kind of the same thing that we had before, except here, because instead of dealing with vectors, we're dealing with matrices. And matrices, yay, can actually be multiplied. Then the decryption of the multiplication of the matrices is going to be s multiplied by Al times er. And remember, you can think of matrices as being linear maps. And so you're going to kind of pass s through Al, then you're going to pass s through ar.
01:04:17.314 - 01:04:53.120, Speaker A: And so the eigenvalues get producted as well. And so you can kind of show that this kind of expands out. So you have first s passing through Al, then you multiply that by ar. And so s times Al is going to be a kind of MLS plus El as before, right? So here s times a is going to be whatever your message is multiplied by s, either one or zero plus your error. Except here we still have to multiply it by ar. So we have mls times ar. Then you have el times ar.
01:04:53.120 - 01:05:45.258, Speaker A: And so here, multiplying by Ar basically means your mls is going to turn into, well, mlmrs because ar times s by itself is going to give you kind of Mrs. Right? And so if s times ar gives you Mrs. Then ML times s times ar is going to give you mlMrs. So here kind of the decryption of the product is going to give you kind of the product of the messages here. And then over here you have is the two error terms, right? So one of the error terms is going to be the left error multiplied by ar. And then here you have the right error multiplied by Ar multiplied by the left message. So you can add, you can multiply.
01:05:45.258 - 01:06:38.078, Speaker A: But there is a problem, right? And the problem is that the error is not just being multiplied by the other error, you're not just having like el times ar. Instead, your error gets multiplied by the magnitude of the matrix elements. So if you start with matrices that have a fairly small magnitude, then every time you do a multiplication, the magnitude of your matrix elements just keeps on doubling. And so once again, you're limited to your depth being kind of log, log cube, by the way, just kind of. One other reason why this matrix approach is nice. Basically, from here on, we don't actually care about the modulus as being od, we don't care about them being prime, we don't care about modulus as having any kind of properties. And so to make the math easy, we're just going to set the modulus to equal some power two to the k.
01:06:38.078 - 01:07:42.562, Speaker A: And that makes them kind of math really easy. And it makes bootstrapping really easy as well, because you could just kind of forget the higher order bits. So the problem is that you have this kind of El multiplied by Ar, and these Ar values themselves kind of get big and they get bigger every time you multiply. And so how do you stop the error from just blowing up? So the fix to this problem is you have this kind of really strange and clever bit splitting trick. And the bit splitting trick basically says that if we treat x as being a vector, then we're going to define these two functions. One is called powers of two, the other is called bitify, where powers of two basically says for every element in x, you just kind of concatenate the powers of two of x, and then bitify of x just turns it into a bit representation. Then you have this identity that the dot product of powers of two of x together with bitify of Y equals to the dot product of x of Y.
01:07:42.562 - 01:08:22.226, Speaker A: And to kind of visually show this, I have an example, right? So if you have x as one, two, three, and then y is six, five, four, then powers of two of x, sub one turns into 1242 times into two times one, two, four. So two, four, eight, and then three turns into 3612 and then y turns into its bit representation. So six is 1105, is 1014, is 10 zero. And the dot product here, well, here it's one times six. And then here we're basically kind of doing powers times bit representations. And so you have two times one and then four times one. So this adds up to being six.
01:08:22.226 - 01:08:58.160, Speaker A: Then over here, two times five and basically the five turns into 10 one. And so you add two times one and then here you add two times four times one to kind of compensate for this one having a higher place value. And so two times one plus eight times one is ten, which is two times five and then three times four is twelve. And so three times, well here four, you just have like a one here. And then the white gets multiplied by three times four. So you have twelve, I guess, also pausing and just kind of stare at this, at their ads. Just kind of verify for yourselves that this works.
01:08:58.160 - 01:09:10.690, Speaker A: So basically, kind of converting X into powers of two and converting y into a bit representation is a dot product preserving operation.
01:09:16.350 - 01:09:20.454, Speaker B: It kind of feels a little bit like the relinearization trick.
01:09:20.582 - 01:09:50.646, Speaker A: Exactly. Yes. It's very similar, except this is kind of just explicitly representing real linearization using vector math. It's exactly the same sort of stuff. So the bit splitting technique also applies to matrices because matrix math is basically just batched vector math. Right. And so powers of two of s times bit of I of a equals s times a.
01:09:50.646 - 01:10:31.010, Speaker A: Actually this should be a dot. This should be just actual matrix multiplication. And so what we're going to do is we're going to basically do, instead of doing al times Ar, we're going to do al times bit of phi of Ar. And we're going to set our ciphertext instead of being n times n, we're going to set them as being kind of n times n log p. Basically, the idea is that whatever is on the left side, we're going to kind of set it as being permanently in this kind of powers of two representation. And so bitify is going to give us an n log p times n log p of matrix. And so kind of the dimensions match up.
01:10:31.010 - 01:11:53.622, Speaker A: But instead of multiplying al times ar, we're going to multiply al times bit of I of Ar. And the reason why we do this is basically because if you notice here you have these two error terms. One has Erar and one has Elar. And so if Ar elements are always going to be zero and one, then here you just have El, and then here you just have Er multiplied by the message, which is just going to be zero or one. And so the error blow up is small, right? The error blow up, it's just going to be adding a whole bunch of these terms that were proportional to the original error. So I'll admit the thing that's kind of difficult to see is why Al times bitify Ar is still kind of still eigenvector preserving the same way that Al times Ar was eigenvector preserving. Again, basically the, how do I describe this? The kind of intuitive idea, right, is that these ALS are kind of permanently in this powers of two form, and then these ars are permanently are going to be bitified.
01:11:53.622 - 01:13:00.036, Speaker A: And so their dot product is going to be the same as it was if you just had a kind of regular alt together with just a regular AR. And so the eigenvector here instead of, well, here, it's not kind of fully an eigenvector. Instead of being s, instead of turning s to s, it's actually going to turn s into powers of two of s. But this works. And you can also just experimentally verify that it works, right? And the benefit is that, as I mentioned, instead of the air blow up multiplied by big AR values, you just guarantee that these AR values are always zero and one. And so the error blow up is smaller. By the way, I have code here, and the code is actually not long.
01:13:00.036 - 01:14:09.892, Speaker A: So the homophic encryption here is about 300 lines of python. This is under 200 lines of python. So if you want to kind of see for yourself, if you want to play around with matrices for yourself and kind of verify things for yourself, I highly recommend looking through the code as well. So, optimizations, right? So there's a bunch of ways to optimize this. So, first of all, you might notice that one of the really interesting problems or properties of matrix fhe is that the error growth is asymmetric. So here you're multiplying by Ar, and here you have just El, here you have er being multiplied by a message, and you have this interesting property that if you have a ciphertext on the right that has a higher error, then the error actually barely increases at all, right? And so what this basically means is that whereas in tensor fhe, you don't really have this property, the errors kind of just multiply here. If you want to perform some kind of operation, then it actually makes sense to perform that operation kind of asymmetrically.
01:14:09.892 - 01:14:43.616, Speaker A: So say if you want to do a bunch of additions, then you just kind of fold them all into the same sum, one after the other. The error bounds criterion becomes kind of more complicated. So it's not just max multiplicative depth, it's not just max polynomial degree. It becomes this weird, complicated thing. Other optimizations. So you don't need to do things in base two, or you don't need to decompose into kind of binary n powers of two. You can also do this in base three or base four or base 16.
01:14:43.616 - 01:15:52.076, Speaker A: And this potentially lets the error kind of increase less slowly. You can pack multiple bits into a ciphertext that you can do kind of addition and multiplication on a lot of bits at the same time. There's also this thing called ring lwe, where basically, instead of just thinking about kind of a whole bunch of independent equations, you can represent those equations as being an equation in a polynomial ring. And I don't really have time to get into this, but this also lets you kind of decrease key sizes a lot. So this is still kind of basically how kind of modern, fully homomorphic encryption schemes work, except there's this kind of whole suite of optimizations that people have been totally coming up with. So the main reason why there is a big overhead is basically because the ciphertexts are matrices, right? And in order to satisfy these Lwe assumptions, the ciphertexts have to have a pretty substantial length. And so we can think of these matrices as being something like matrices of size 100 by 100 or whatever.
01:15:52.076 - 01:16:43.870, Speaker A: And then here we're going to store them in powers of two, and we're going to bitify them. And so the 100 potentially blows up into being 10,000, at least temporarily. And so matrix multiplication becomes this really big kind of multiplication procedure. And if you want to be able to process circuits of substantial size, then these numbers have to have fairly substantial bit length. So we're potentially talking over 100, potentially. So there's a bunch of factors that do end up kind of conspiring to make it fairly different or to make this kind of fairly inherent large blow up in circuit sizes. And this is the reason why this is all kind of less large and less clean than things like elliptic curve cryptography, for example.
01:16:43.870 - 01:17:02.192, Speaker A: But it is increasingly getting to the point where for at least small computations, it is completely viable, and you can do kind of individual computational steps on the order of milliseconds. So there you go. Thank you.
01:17:02.246 - 01:17:23.690, Speaker B: That was really cool. Thanks for the presentation. I have a question of what do you know what is considered the state of the art today? Like, there is all these different libraries out there, tfhe and all these kind of things. So what is Mattu method and considered the best today?
01:17:24.220 - 01:18:13.220, Speaker A: There's definitely a bunch of libraries like he lib is one of them, and there's some wonders with different names. So there is a survey by Zvika Burkirsky, the inventor of the 2011 protocol. Let's see if I can look this up right now. Here you have fundamentals of fully homomorphic encryption. And so it's basically just search fundamentals of fully homomorphic encryption with Zvika Berkowski. And then what you get, it's from 2018, basically describes similar to the matrix FPG protocol. So the state of the art is definitely you start from either the product approach or the matrix approach.
01:18:13.220 - 01:19:03.400, Speaker A: They have different pros and cons, and then you just apply a whole bunch of optimizations. Ring lwe is one of them. Another one is those various schemes for being able to kind of stuff a whole bunch of ciphertext or a whole bunch of messages into the same ciphertext. So one of the ways that you can do this is you can imagine here, instead of having a ciphertext where a just satisfies a product equals one message, you might say a product message, and a product t satisfies another message. And then you can do kind of SIMD operations. So if you add and multiply, that kind of adds and multiplies all the plain text simultaneously. And then you can do kind of rotations, you can do kind of permutations.
01:19:03.400 - 01:19:30.080, Speaker A: And so there's this kind of growing body of clever tricks, the same way that the zero knowledge proof space has a growing body of clever tricks that try to compensate for the inheritance efficiencies. So that's where we're basically at right now. We're at kind of just taking this base and incrementally building upon it. Awesome, thanks. I sent a link to the report.
01:19:30.150 - 01:19:33.190, Speaker B: That you referred to in the Telegram channel.
01:19:34.840 - 01:19:35.590, Speaker A: Great.
01:19:37.480 - 01:19:47.076, Speaker B: I just have a quick question. Sorry, finish this one first.
01:19:47.178 - 01:20:20.130, Speaker A: No, I was just going to mention that you can also look up BV 2011. There's also another protocol, BV 2012, which avoids the need to do modulo switching completely, basically by kind of pretending that the ciphertexts are fractional but still representing them as integers. So you're just going to feel free to look up the papers for all of these as well, and then hopefully they'll be more understandable after this. All right, thanks. Go ahead.
01:20:24.200 - 01:20:32.020, Speaker B: Yeah, this is like just coming back to your last thing about the switching into Al and AR matrices.
01:20:33.240 - 01:20:33.990, Speaker A: So.
01:20:37.740 - 01:21:00.130, Speaker B: So where. Yes, okay, so you can do this multiplication. So how in the, in the next step, right, you do it using the spitify, isn't that actually. Exactly. I haven't quite understood why you're not doing exactly the same operation and just computing it in a different way.
01:21:01.860 - 01:22:03.204, Speaker A: Right. So basically the idea here is that bitify is guaranteed to always contain zeros and ones. Right. I think I might have a good intuitive answer. So the intuitive answer is so first of all, powers of two and or kind of power of two reduction and bitifier kind of opposites in some sense, right? So if you bitify something, then you can multiply it by a matrix, which kind of converts it back into the pre bidified form. But if you take a matrix and multiply it by matrix, which is in this case not bidified, then the multiplication itself, when you do kind of modulo. And then what this is is you can think of it as being kind of an unbidified version of a bitified thing.
01:22:03.204 - 01:23:09.748, Speaker A: And what happens is that the kind of inverse of bitifying that's kind of inherently baked into here, it has this property that if you apply it to things that are not bits, right? So a bitified matrix multiplied by another bitified matrix is not necessarily going to contain bits. Because matrix multiplication adds a whole bunch of bits together, then you're still going to get a matrix. And because you have modular reduction, it's going to reduce to modulo, whatever your modulus is. Basically, the modular reduction just kind of magically makes the higher order terms go away. And because you're only doing the matrix multiplication while the matrices are bitified means that the process of matrix multiplication never multiplies any particular value by more than the width of the matrix. And so the error only gets multiplied by a small amount. Right? So it's actually not the same operation.
01:23:09.748 - 01:23:23.724, Speaker A: It's a different operation, but which is still guaranteed to have kind of the same consequences, specifically with respect to multiplying by basically things that of the format of.
01:23:23.922 - 01:23:46.820, Speaker B: I actually just noticed that I don't even know what this multiplication here means, because in the previous operation, okay, so we have bitify has blown up a vector into an n times log p vector, right? So what are these ar and Al objects? Are they tensors or are they still two dimensional matrices?
01:23:47.960 - 01:24:31.980, Speaker A: These are all matrices, right? So the way to intuitively think of this is, okay, so here's one way to intuitively think of this, right? So think of Al as being a bitified matrix multiplied. So Ar has size n log p times analog p, right? Bitify ar is a big square. Al has size, small times big. It's n times analog p. And think of Al as being bitified Al multiplied by the matrix. That is the inverse of the inverse bitify matrix multiplied by bitify Al multiplied by bitify ar. And then you're going to take bitify Al and bitify ar.
01:24:31.980 - 01:25:32.640, Speaker A: Then you multiply them together. And then to actually see what this means, you have your kind of inverse bitification matrix multiplied by the product of the bitifies. Right? So basically you have these kind of matrices that have the property that if you multiply them by powers of two of s, then you get powers of two of s. And so here you have kind of already washed matrices. And so if you multiply them by s, you get powers of two of s. And then if you take Al and kind of expand it out as a bitified thing, then the bitified things are kind of, well, powers of two of s is an eigenvector, basically. And so if you product together bitify al, with bitify ar, you get something where powers of two of s is also an eigenvector.
01:25:32.640 - 01:25:39.450, Speaker A: And then if you kind of squash it back, then you get a ciphertext Dolan above the same form.
01:25:40.620 - 01:25:41.370, Speaker B: Right.
01:25:42.140 - 01:25:47.496, Speaker A: As I said, if he wants to.
01:25:47.518 - 01:25:54.910, Speaker B: Kind of, I think I realized the parts that I don't understand yet. I guess I'll have to look at the source, right?
01:25:56.160 - 01:26:16.870, Speaker A: Yeah, I'd recommend not even just looking at the source, but even just kind of opening up a Python console and kind of playing around with kind of bitify and multiplying by vectors and just kind of see what properties the ciphertext and the bitified ciphertext have with respect to multiplying by s and multiplying by powers of two of s.
01:26:20.600 - 01:26:41.630, Speaker B: Okay. All right, here's the part I didn't understand. So there's no extra operation each time. Now the whole time we are computing with n times n log p matrices. Yes, I see. Okay, so we changed our protocol. This is not just like a modification of the multiplication itself.
01:26:43.280 - 01:27:29.640, Speaker A: Right. So another way to think about this, I think this approach is just an optimization. Another way of thinking about this is you can make a less efficient but easier to understand protocol if your ciphertexts are nloc b times nloc p matrices. So imagine your ciphertext just are kind of bit of five l and bit five a. So they are big matrices that contain only zeros and ones that have the property that powers of two of s is an eigenvector, right? So we agree that if you just multiply al times bit of I of ar, then powers of two is going to be of s is going to be an eigenvector of the product. Right? But then what this operation does, we want to preserve the invariance that your ciphertext are just zeros and ones. Right.
01:27:29.640 - 01:28:12.970, Speaker A: After you multiply two matrices together, they're not necessarily zeros and ones. And so what we're going to do is we're going to basically kind of do an inverse bitify operation. So squash it. And because of this, squashing preserves the eigenvector. So basically, before it turns powers s into powers of s, powers of two of s into powers of two of s, after it just turns s into powers of s, you squash it and then you vidify it again. And the squashing and the bit. And basically the squashing, it preserves the eigenvector, but it kind of forces the values in the ciphertext to just continue being zeros and ones.
01:28:31.800 - 01:28:44.330, Speaker B: And you mentioned, like, you can do operations in order of milliseconds. That's like sort of one bit, essentially like a one bit operations, like something like. And.
01:28:46.540 - 01:29:43.432, Speaker A: Right. I have a question. I'm not sure. Go ahead. First, thanks for fantastic presentation. And the question is, you have talked so far only about multiplications of plain text and ciphertext, but do you think that any of this technique translates to some more complex functions, like polynomials of ciphertext, something like, more naturally than just computing them operation by operation? Yes, it's a good question. One of the challenges is, right, so first of all, this technique, it's theoretically compatible with ciphertext being not just zeros and ones, but being arbitrary field elements.
01:29:43.432 - 01:30:40.770, Speaker A: The problem is that because you have this mlera ter term, ter, basically, if your messages are not zeros and ones, it makes the air blow up quickly. Right. So you can get some, you can potentially, instead of working in the ring modulo two, you can work in the ring modulo some small number, like maybe up to 100 or something, but working over things that are not bits, it just kind of seems intrinsically hard, because multiplying by things that are not small numbers causes error to blow up very quickly. You do pretty much, sorry, I meant differently. Not just kind of not filled elements, but instead of just multiplication, like I'd know multiple of three different elements, or I'd know some. Oh, yes. Polynomial of four elements of small degree or something.
01:30:40.770 - 01:31:12.020, Speaker A: Right. So the trivial way to do any of this is that there are mechanisms for, I think, multiplying. Sorry. So if ML, individual ML, kind of as bits, right. Is just a zero or one, then multiplying by three doesn't really have anything. Right. So if your method are zero one, that you pretty much have to do everything using binary circuits.
01:31:12.020 - 01:32:10.460, Speaker A: And the nice thing with binary circuits is that multiplication is just an addition of kind of login left shifted values. And so you can do it. And I mentioned before in the optimization section, right, that you can potentially have a ciphertext which contains multiple point text, and you can do shifts. And so you could do kind of large parts of things like addition and multiplication circuits kind of operating over many, over many bits simultaneously. But I guess in general, operating over binary circuits is the most fundamental thing that this ends up allowing. There are definitely kind of optimizations. The main challenge here, right, is that your messages have to always be zero and one.
01:32:10.460 - 01:32:41.800, Speaker A: But there are optimizations that have to do with kind of computing more complicated gates in a way that ensures that the output is still zero and one without having to do as much work as if you just kind of did it naively with simple gates. So there's nothing kind of super mathematically elegant, but there are kind of these kind of bags of tricks that let you optimize a lot sometimes. Okay, thank you.
01:32:46.250 - 01:32:57.574, Speaker B: One question I have is that people often say that functional encryption is related to fhe. Do you know how to go from fhe to functional, or how they're related?
01:32:57.702 - 01:33:35.350, Speaker A: Right. So functional encryption, in terms of the definition, basically it says instead of being able to go from n of x to n of f of x, for arbitrary f, you can go from n of x to just having f of x, but only for one specific app. So it's a kind of different and potentially more powerful primitive in terms of how these functional encryption protocols work. I'll admit I haven't kind of fully figured this out yet. They're definitely considerably more complicated than fhe.
01:33:37.710 - 01:33:48.810, Speaker B: Okay. I mean, I guess one easy way, well, quite easy conceptually, is to go through obfuscation, bootstrap with fhe, and then go back down to functional encryption.
01:33:50.830 - 01:33:58.030, Speaker A: Right, exactly. But even, well, if obfuscation protocols, often in practice, end up being built on top of functional encryption.
01:34:00.290 - 01:34:01.040, Speaker B: Okay.
01:34:04.470 - 01:34:40.802, Speaker A: There'S a lot of different paths to try to get to obfuscation, and none of them kind of fully satisfy people yet. And they do end up having overhead. One really nice thing is that if you have an obfuscator that works for circuits of constant size, then you can turn that into an obfuscator that works for kind of arbitrary size. And the way that you do that is to obfuscate a big program. You first homomorphically encrypt the input. Then you have the circuit itself provided in a homomorphically encrypted form. And so basically your function is going to be circuit evaluation.
01:34:40.802 - 01:35:16.582, Speaker A: And so you're going to evaluate the encryption of x with the encryption of the circuit. And then you get an encrypted form of the output, and you generate some proof. So think of it as being a snark or something. But you can make proofs that kind of play more nicely together with the homophobic encryption scheme, so you have less blow up. So basically then what you do is you take your encryption of f of x, and you take your proof that you actually computed f and not some different function. And then you have a fixed sized program that checks the proof and then decrypts the proof. Correct.
01:35:16.582 - 01:35:32.190, Speaker A: And then you have your f of out. Right. So that way you can kind of obfuscate programs. You create an encrypted program that lets you go from f to f of x, but this still depends on a fixed size obfuscation.
01:35:35.730 - 01:36:17.850, Speaker B: So I think pretty much the exact same technique works for something called correlation intractability hashing. And I think the idea here is that you can have a provably secure fiat mirror, as opposed to having a heuristic fiat shamir. And then if you have this hash function, which has this very special property, then you can boost it to arbitrary circuits. And I think some of the lattices people managed to build a non interactive zero knowledge proof which is secure.
01:36:21.390 - 01:36:21.706, Speaker A: In.
01:36:21.728 - 01:36:35.620, Speaker B: The standard model without, I guess, another question I have. Go ahead. What were you going to say?
01:36:36.310 - 01:36:40.900, Speaker A: No, I was just going to say, that sounds right and interesting.
01:36:44.730 - 01:37:09.500, Speaker B: The other question I have is on performance, this one guy said, roughly speaking, a decade, like fhe decade was optimized by an order of magnitude every single year. And I was wondering if you think we've hit a wall or this is going to continue to continue for four or five years and help you.
01:37:10.270 - 01:37:56.918, Speaker A: Right? Yeah, I've kind of taken you through the journey of the years of where homomorphic encryption was just getting kind of massively better with new discoveries every two years. Right. So over here you have only partial homomorphism degree, and bootstrapping is impossible. Then you have this really complicated scheme from Craig Gentry, then you have this really clever trick that allows you, finally allows you to bootstrap for the first time, but the error flows exponentially. Then suddenly, had I. The error only flows up linearly, and then now the complexity of doing a down to a matrix multiplication. So here we're seeing huge speed ups.
01:37:56.918 - 01:38:49.100, Speaker A: I think after these protocols, the speed ups have definitely started slowing down, and we expect speed ups to kind of continue slowing down over time. I don't know enough to be able to say, honestly, what a reasonable lower bound would end up looking like. I think my instinct would say at this point that we'll probably expect to see more speed ups from optimizations than we will from kind of very fundamental changes to how cybertext work. So kind of coming up with gadgets that let us operate on many bits at the same time more effectively. I don't know.
01:38:50.270 - 01:39:43.190, Speaker B: Right. Okay. Do we have more questions? One thing I'm kind of curious about is kind of the ultimate kind of cryptographic primitive for the long term future, let's say, when we have quantum computers. And it's kind of unfortunate that, from what I understand right now, we can't really do snarks with lattices. And I was wondering if you think this is, like, a fundamental thing, or we're going to need fry and latices working in parallel.
01:39:45.370 - 01:40:41.458, Speaker A: So you can do bulletproofs with lattices. Right. Because you can just use ciphertext the same way you use petters and commitments. It's very possible that someone will come up with some lattice based protocol for kind of zero knowledge proving. I don't know. I think the reason why it seems fundamentally harder in the lattice world is because you have these errors, and so you can't really do things like equality tests as easily. For example, even one of the big kind of problems or challenges in this style of cryptography is, can you even come up with a zero testing key? And because of linearity, if you have a zero testing key, you can turn that into an equality testing key, and that would just immediately give you a multilinear map.
01:40:41.458 - 01:41:26.390, Speaker A: And it turns out that all of the approaches that people have come up with for trying to test this, some cybertex equals to zero using subkey that allows you to do that without allowing you to decrypt everything else. It's inevitably weak information that kind of breaks the security proof that shows that you can't extract everything else about the message. So, yeah, we might end up coming up with something. I don't know. It definitely is possible that we'll end up needing both fry and lattices in the long term and that the two things just naturally specialize in different areas.
01:41:30.570 - 01:41:32.920, Speaker B: The zero testing is very interesting.
01:41:37.370 - 01:41:45.750, Speaker A: Yeah. It's one of, like, ten things where if we had it, then we would just solve everything. So sad.
01:41:53.130 - 01:41:55.320, Speaker B: Thank you so much. This was really interesting.
01:41:57.810 - 01:41:59.694, Speaker A: Okay, thank you.
01:41:59.812 - 01:42:00.460, Speaker B: Thanks very much.

00:00:00.330 - 00:00:51.146, Speaker A: You okay, so let's get this started. This is what now, the 6th of these 4844 calls just posted the agenda in the chat, as always, a bunch of spec updates. Then we were supposed to be launching Devnet three tomorrow, so it makes sense to chat about that where things are at there. And then we have two other updates, or at least one update on some benchmarks for the pre compile. And we can also talk about the large block spam test as well and see how things are going there. And I don't know if Xiawei is on the call, but right before she posted. Oh yes, you are here.
00:00:51.146 - 00:01:41.214, Speaker A: Shawi, do you want to just give a minute to talk about the new test vectors on the. Yeah, thanks for sharing. Terence found the issue in the test vectors that we released last week, so I cut a renewal release today here. Yes, I hope that if any of you have tested and please let me know and if there's any new issues and please pay me. Thank you. Awesome, thanks. Okay, next up, we had two specs issues open on the cl side that we didn't have much progress on last time, and I just wanted to follow up on them.
00:01:41.214 - 00:02:29.260, Speaker A: The first was, Terrence, one of your issues about adding blob availability checks for ancestors. What is the status there? Yeah, so hey everyone, I have a corresponding pr to the issue. So the pr was approved by Denny, but there was more feedback regarding that. We do not want to remove that data availability because it's nice when you go to den sharding, you still have that notion. So I made a minor update to that and the pr is ready again. So yes, feel free to take a look and further comments is welcome. Okay, and that's pr 3125, right? Yeah.
00:02:29.260 - 00:02:57.350, Speaker A: Okay, nice. And I just linked it in the issue, so if anyone was following just the issue and weren't aware, they can go there. Great. And then George, you had some updates on the crypto side of things. So 30 93 was merged and now there's another pr 31 38. Do you want to give a quick update on those two? Yeah, sure. Okay.
00:02:57.350 - 00:04:06.470, Speaker A: For a quick update, basically we settled down on how we want to handle empty blobs, empty sidecars basically, and now the correct behavior is on the spec. That's settled. So basically, now client devs can basically pass empty sidecars to the crypto library and it will handle it gracefully. So that's done. And the future things on the cryptography side is another thing raised by client devs about when we use the pre compiled and we are given scalar field elements as bytes, whether we validate them or not. Before, we were not validating them and we were just kind of using them as they were given to us. But it seems like the more correct approach is to actually validate them and error out if they're not canonical.
00:04:06.470 - 00:04:49.602, Speaker A: So this new pr 3138 basically introduces the validity condition that should have been there from the beginning. Yeah, that's also isolated on the cryptography side. So that's one nice thing from the API we have designed that kind of all these things are nicely abstracted away on the cryptography land, and it doesn't give much clutter to the rest of the client dev workflow. And another thing that's happening, I'm not sure. Kev, are you here? Let me scan. Yeah, I'm here. Right, okay.
00:04:49.602 - 00:05:07.966, Speaker A: You want to give an update on the pre compiled gas cost or where we are right now? Because I'm also not sure where we are right now. Yeah, and Martin is here as well. He ran the benchmarks originally. Right. We can maybe do that after. So we already had a note for that. Yeah.
00:05:07.966 - 00:05:40.860, Speaker A: So we can come back to the. Sounds good, sounds good. One question by infi. What is it? Does 3138 resolve the canonical encoding issue you highlighted a while back? That's a question to Kev. Yeah, it does. It causes the issue. Okay, so I guess that's it from the cryptography side.
00:05:40.860 - 00:06:44.640, Speaker A: Sweet. Any other updates or concerns about the spec? And then if not, we can cover the benchmarking of the pre compile. But anything else just at the design level or related to the spec. We had a concern on lighthouse site, so for the interop repo, we have a specific preset that has been generated where the slots per epoch is set to three. So we were wondering why that is. Because it's a bit annoying to handle it on Lighthouse, because we have to define another preset which is only valid for the purpose of the interop specs testing. So I was wondering if it's not that big of an issue, we can just change it to mainnet spec.
00:06:44.640 - 00:07:53.610, Speaker A: I'm not really sure why it exists. Yeah. Does anyone know why it was set to three? Are you talking about the minimal specs for 4844? No, in the interop EIP 4844, Interpo, we assume that that's what going to be used for the Devnet eventually. There's a different preset defined which has like the slots for epoch set to three, which is not main net, and it's not minimal either. So it's a bit hard to handle this specific case only for the testnet. I was just wondering why it exists, basically. Okay, just for.
00:07:53.610 - 00:08:39.336, Speaker A: Yeah, so Mophie answered. You just said it was easier to debug, and I guess it makes sense with the three epochs, just quicker. Yeah. Does anyone have an issue moving it to 32? Okay, it seems like we want to move it to mainnet Mophie. Is that something you can do? Okay, awesome. So Mophie will make that change. Anything else on the spec? I see that there is no lion here.
00:08:39.336 - 00:09:27.054, Speaker A: Correct me if I'm wrong. I just want to highlight one issue that he opened and he's highlighting a couple of edge cases that to me sounds reasonable to discuss. Yeah. So that's 3113 that you just posted. Yes, exactly. So if anyone has some room to have a look to that and maybe start discussing in there would be nice. Has anyone already reviewed this? So we're like looking at it in lighthouse, and these are the types of edge cases we're still trying to figure out how to handle.
00:09:27.054 - 00:10:14.834, Speaker A: So we're aware of it and we'll comment on it soon, but don't really have ideas yet. Yeah, same with prism that we are actually studying this issue. It's a tricky one, but yeah, we will review very soon. Does it make sense to chat about this on the Cl call in two days, or should we basically come back to it next week on this call? I think if we have more traction on it, it'd be worth it on the Cl call, but I'm not sure. So I'd say no for now and then just wait for it next week. Okay, sounds good. Yeah.
00:10:14.834 - 00:11:17.052, Speaker A: So if people want to have a look at that and share some thoughts on it, we'll keep an eye on it. Any other issues or spec related concerns? Okay, I guess then the next one that's kind of also part of the spec. Martin, you ran sort of an initial set of benchmarks for the pre compile on the get branch. Do you want to take a minute to kind of walk through what you did and. Yes, sure. So what I did is basically a rerun of what's been done a few times before when we added new pre compiles, Blake and the BN ad and the BN model and those a long time ago. That was at the time when the implementations were get and CPP Ethereum and parity.
00:11:17.052 - 00:11:59.232, Speaker A: So kind of the scripts that I used to take the raw data and transform it into columns. There are three formats for that, one for Geth and the other one for CPP ethereum and one for parity. So right now I only have data for get, which I ran in two different machines. And both of those kind of indicate that the proposed gas cost is not far off. But probably it would be good to bump it by a factor of 1.5 or maybe two. And that's something.
00:11:59.232 - 00:12:32.616, Speaker A: I mean, it doesn't need to be set in stone now because it's a very simple constant change. And that's also pretty nice with this pre compiled, that there is only one flat cost. It's more difficult. Last time we priced something, it was where you have a formula where the pricing depends on the complexity and or the length of the input. And of course, that makes it another dimension of difficult. Yeah. So now we got some preliminary results.
00:12:32.616 - 00:13:22.200, Speaker A: It would be nice to have the same kind of executions done on the other El clients. Nevermind. And visu. I suppose that Aragon is mostly on par with. Yeah, and at least we have a sense of whether they're on the same level as get or if something is dangerously slow. And the methodology used is to compare the new pre compile mgas per second wise with the other pre compiles. And the reference one we've used has been easy to recover and.
00:13:22.200 - 00:14:03.758, Speaker A: Yeah, that's about it. I guess I don't have much more else to say. Does anyone have any questions? I know Kev, you had some thoughts on discord. Do you want to quickly give an update? Yeah, I guess it wasn't entirely intuitive that the failure cases were taking longer or were more expensive than the correct cases. I've managed to reproduce it on my computer, so I'm just investigating why that's the issue. Yeah. And I kind of assume that that's something that can be fixed.
00:14:03.758 - 00:14:52.878, Speaker A: I don't know, but that's my instinct, at least. Yeah. And then I guess for the other El teams, how easy is it for you all to reproduce this? I assume people might not have had chance to look mean. I know that Nethermind and both Neldomind and Bisa have done benchmarks of pre compiled before that we've done some comparisons on. Okay, so I can reach out, because I don't think there's anyone from Baseu on the call. And then I think Alexai maybe from. Oh, Jiri.
00:14:52.878 - 00:15:10.520, Speaker A: Sorry. Yeah, Jiri, do you want to. We're just starting to actually implement things, so almost nothing's done yet. Right. Okay, so there's not much to benchmark. Fair enough. And then on the Nethermind side, Alexa, I see you're here.
00:15:10.520 - 00:16:37.074, Speaker A: Do you have the bandwidth or how easy is it for you to benchmark the 4844 pre compile relative to other pre compile in terms of pricing? And then there's a script. The last comment I had in the chat is Martin's results for doing this. We have quite a basic test for that pre compile on net side, and we did not run any benchmarks actually from interrepo or from any other place yet. Okay, got it. And do you think the pre compile itself would be in a spot? Where is the implementation? Far enough that it makes sense for you to benchmark it, or are you still working through it? And even if you benchmarked it now, it won't be a good benchmark because there's still stuff to optimize. Benchmarks are always good and we can compare probably implementations in the future, right? Okay. Because we do have people who might be not in fine teams who might be able to help with this stuff.
00:16:37.074 - 00:18:02.968, Speaker A: So I'll reach out after the call and check with them if they could help with at least the nethermind one in parallel. So this way if you're all still working on the implementations, you can get the benchmark set in parallel. Okay, so I'll follow up on that and then Proto has a comment about the pricing being more of an issue for ZK rollups than optimistic rollups. I don't think there's anyone here working on ZK rollups, correct? No. Okay, I can follow up offline as well and ping some ZK teams and get them to share any thoughts they have on their repricing, anything else on the pre compiles. Okay, then next is the devnet. So Devnet three was supposed to be launched tomorrow from skimming the chat.
00:18:02.968 - 00:18:36.968, Speaker A: It doesn't quite seem like we're ready. So maybe it'd be good to just get an update from the different client teams about where they're at generally and what the next steps are for. Oh, sorry, go ahead. I was going to say, Tim, I think I agree that we're not nearly ready for Wednesday. Things are coming along quite well though, so I'll delegate the individual teams. Yeah, I can give a quick update on the prism side. So thanks, Shaoi again for fixing the spat test.
00:18:36.968 - 00:19:25.428, Speaker A: So right now we have been testing the spat test. As of this morning, we found two to three test failures, and that seems like those test failures are on our end. So yes, I think we just want to fix those as soon as possible, and then after those we should be ready to begin interrupt, but no guarantee that it works right out of the gate. I kind of imagine some trial and error, but yeah, that's where we are today. Got it. Any other teams from prism? So for lighthouse we still have things to iron out with sync I think. Otherwise we're there with an implementation.
00:19:25.428 - 00:21:00.490, Speaker A: So we've been working a lot more towards trying to join the interop repo and making solid progress, but now we sort of need an execution client to test with. And then also like pon mentioned earlier, if we can make the spec use twelve or, sorry, like the main net slots per Epoch 32, that'd be helpful. And I think part of the reason it was set low was for the tests in that repo to run faster and I'd like to have us run the tests. So I was wondering, is it possible that we can just start the testnet from a later epoch so we don't have to wait a ton of epochs to run the tests? Why don't we use the minimal preset? Oh sorry, what was the question? So if I understand the suggestion is to use the main net 32, why don't we use correct preset? So if I understand the interrupt is a bit od because it has three, but we could make that eight, which would be the minimal all clients should support. Right. And I assume the minimal preset is used on existing test nets or something. Well, so the issue with the minimal spec is right now it has incorrect fields per BLS elements, I think.
00:21:00.490 - 00:22:07.530, Speaker A: And that value is hard coded in the CKZG library. So yeah, I don't think the KZG library works with the minimal spec at present. But if we update that in the spec at that point I think we could change the tests in the interop repo to use minimal. Sean, did you say update the hard coded value in the spec? So I think the field is like it's in the minimal preset, the fields per BlS element, it's lower in minimal versus main net, and that value is hard coded to the main net value in the CKZG library. Field per blob, right? Field elements per blob, yeah, I think so. It's like 496. Yeah.
00:22:07.530 - 00:22:54.720, Speaker A: This is something just to say that I want to talk to Ramana today so that we make it compile time configurable. He was amenable to it last time we talked, so I think we can now move on with that. Okay, so if that's the case, then whenever that's configurable, we can transition the interop repo tests to use the minimal aspect. So that'd be reasonable. So I don't know much about these presets, but why not just change the minimal one to use the 4096 value? We do have that, right? No, we didn't want to change that. Right, sorry. Shall we? Hello.
00:22:54.720 - 00:25:04.280, Speaker A: So the minimal preset and config are for the spectex to provide minimal test vectors with less low cost for the client teams to run in the CI daily or weekly. So we also provide the many test vectors at same time, but for the stack side, since we are using PyEcc, the Python implementation and our KCG implementation are actually from the spec lines. So that is incredibly slow compared to the C implementations. So for the spake itself, I think minimal preset with build elements per block with like four or eight is needed for the spec site. But for the definite you can free to generate to use any numbers in the configurations or in the preset, if I understand correctly. Okay, so we don't want to change the minimal preset because it'll be too burdensome on certain testing, but sounds like there's not another existing preset. Yeah, I think you can define the definite only preset, if I understand correctly that we might have used it in the previous short term Devnet before Sean, is that an issue? Just to define a Devnet specific preset with 4096? So we actually sort of have that right now because we were trying to get the test passing.
00:25:04.280 - 00:25:59.392, Speaker A: So that's not too big an issue. Yeah, I guess if we update the slots per epoch, at least to match the minimal spec. So if we just update that to eight and keep the BLS field elements high until it's configurable, that seems pretty reasonable. So the devnet has the minimal configuration, do I understand that correctly? What's there now is already a sort of custom configuration where it's main net apart from slots per epoch is three, but main net is 4096. Right. So you wouldn't have a problem with CKZG on that. Right, but the question would be if we just wanted to switch to a preset that exists, it would be minimal and that one wouldn't work.
00:25:59.392 - 00:26:40.376, Speaker A: Yeah, and why would it be minimal? Maybe you already said that, but I didn't catch it. It's to have the slots per epoch be lowered so that the tests run reasonably quickly because we have to fork through multiple epochs. Okay, got it. Okay, I see. Mike, volume. If I understand, are you able to run with the interoperab now with the current slots per epoch of three? No, we're able to run up until the withdrawals fork. And then at that point we don't really have anything to test against.
00:26:40.376 - 00:27:19.764, Speaker A: So then it breaks. But we have up to Bellatrix working and the issue is this three slots per epic. No, we have that working. It would be preferable not to have that though, because we had to. One of the assumptions we make is for example, slots per historical route being divisible by slots per epoch, which that doesn't work. When slots per epoch is three. We have an AI to change that to 32.
00:27:19.764 - 00:28:10.002, Speaker A: So let's assume that's going to happen. What else? If it's changed to 32, then we can just use the main net spec and that's great. Cool. And Mophie, you did most of the interop config stuff as I understand it. Other than the tests maybe running slower. Is there another concern with that? We may have lost Mophie. Mophie says it should be fine in the chat that complains we can add more machines.
00:28:10.002 - 00:28:28.640, Speaker A: Okay, so tentatively let's set it to 32. I'll try to make that change today. Awesome. Thank you, Roberto. Yeah, that's it from Lighthouse. We're sort of just like trudging through interop and then trying to finish up sync. Awesome.
00:28:28.640 - 00:29:44.690, Speaker A: Kind of the same issues in another mind development. We want to have someone with timestamp based forks for Shanghai and for withdrawals and for EAP 4844 to test with. So we are a bit blocked by that. Just to form the structure of docker compose with our nodes. We made a pull request, but we still don't know what Genesis will be relevant for Devnet three with timestamp based works. And we continue our testing with available tests. We hope to join the network right after or a few days after some other execution.
00:29:44.690 - 00:30:30.118, Speaker A: Client and consensus client like prism and gas will provide the community with timestamp based forks. That's the status. All right. I'm not sure we have anyone working on switching to time based forks right now, at least in a prism or terrence. Are you guys doing time based presets in prism time based forks? Yeah. So from the sales perspective, it doesn't really matter. The changes will mostly come from the El side.
00:30:30.118 - 00:31:16.754, Speaker A: So what we have been doing is that we have been testing local interrupt and there's local interrupt with withdrawal, and there's also withdrawal testnet. And then I believe that is based on the timestamp 4k mechanism. And then we have been using the like client branch. So like client Matt has a branch for that. So let me post a branch here. So maybe you guys can look at how that branch is done and because that is the branch we're using for testing withdrawal based on timestamp. Does it include AP four eight four and withdrawals both? No, it doesn't include 4844.
00:31:16.754 - 00:32:07.480, Speaker A: So someone has to basically build on top of that. Okay, it's just a special case. Never mind special case. We did not plan to have block number based forks for these two cases. Shanghai and Shardin Forks we will pass on till we'll get some other teams implementations with timestamp based forks. If I understand right, timestamp based forks are the preferred going forward fork mechanism. So it makes sense to switch to that if it's not too much trouble.
00:32:07.480 - 00:33:02.248, Speaker A: Yeah, we're going to have to do that anyways because withdrawals have to be timestamped and because the 4844 fork, even if it went live effectively at the same time, it still activates after and after the merge. So I think there's no world where we do withdrawals with timestamps and then we come back to blocks for four. Okay, so let's queue that up as an action item to get statement based forks and guests within Interop. We have a volunteer for that. If not, I'll try and get to it. I have a commit somewhere that it's just like one commit that you need to pull in. It should be really easy.
00:33:02.248 - 00:33:23.760, Speaker A: Oh, fantastic. Nice. So is prism capable of starting with a merge network? As of now? Yeah. Hey lion. So we just merged the feature like last week. So yes, as of today we are capable. Cool.
00:33:23.760 - 00:33:58.092, Speaker A: Can we update the interop repo for EIP for it to start at Capella or Benatriz and merge Capella and AIP at the same time? Yeah, we can do that. Cool. Awesome. Thank you guys. Okay, we want the interop repo to start post merge. Basically, yes. Okay.
00:33:58.092 - 00:35:13.940, Speaker A: And so I guess I can add those two changes to the Devnet three spec. So to clarify, we're using timestamps for fork and then would we want Devnet three to also start at Capella? Basically, I'm not opposed. Also not opposed to. Go ahead, Sean. I was going to say I'm also not opposed to it. Are there any drawbacks to doing that other than just perhaps not exercising more of the fork logic? I guess it doesn't matter really if we're going to go out post withdrawals anyway, right? We could start it at the Latrix as well, right? Like we could start it at the merge, go through the Capella fork, and then does anyone have a preference either side I think capella, if we're going to do not like a phase zero start, a capella start would be better. Just we don't have to deal with the terminal total difficulty logic and whatnot.
00:35:13.940 - 00:36:00.800, Speaker A: Okay. We can also do Bellatrix epoch zero, TPP zero, and then capital and eip for it to forward the same epoch. That's a good question. Yeah, I don't know, maybe this requires a bit more thought. Okay, so for sure we want to do timestamps because that's what we're doing everywhere else anyways. And then whether we start at Bellatrix or Capella TBD, but clearly not starting from phase zero. Does that make sense? Yes.
00:36:00.800 - 00:37:20.960, Speaker A: Okay, I'll add those two notes to the Devnet three spec after the call. Um, okay, anything else on the devnet? We sort of went through some client updates and technical issues, but any other client want to share updates or any other issue? Yeah, this is Andrew from Ethereum Js. I think I noted in the last call I was able to that we're going to be very late to Devnet three, if at all at this point. I have a mostly working local fork of the interop repo now, so I can at least get our client up and running. I've been able to get it partially working with Lloyd stars, having a lot of trouble getting it to interact with prism correctly for some reason, so I'm going to start working on that again today. But I do have, I think most of the spec implemented at this point on the El side. So have the new engine APIs and we're using the CKZG library and it at least works in local testing.
00:37:20.960 - 00:38:03.412, Speaker A: I don't know about interop testing yet, I haven't done there yet. But that's my goal for this week, is to try and get interop to actually kind of cross the sharding block. That's where things are breaking with Lodestar right now. So I've been looking at that and we'll be trying again with Prism just to see if I can get it to go past Capella to the shard block on the El side. So hopefully at some point, maybe in the next week or two, we'll be able to actually start really running the tests in the interop repo and then possibly join Devnet three at some point before Christmas or whatever the current Devnet is at that point. Got it. Very nice.
00:38:03.412 - 00:38:56.390, Speaker A: So we'll add EPS. We can add you to the table in that three thing as well, so you can track the progress there. Yeah, I think realistically, given all the issues that have been popping up, end of next week is probably may even be optimistic, but I think we should try and shoot for end of next week as a new deadline. Sorry, related question so prism and GEF are able to run the full EIP for eight four logic today. Both fee and Coinbase will mostly on it. I believe they have like so we have Devnet two, but that's not the latest spec so I wouldn't say we are fully functional as of today based on Devnet three. There's still more work.
00:38:56.390 - 00:39:45.216, Speaker A: I have the Prism repo in the interop. It should be abiding mostly by the new spec. I think we still are waiting for Kev to submit the zero blobs tweak, but that's under review. I imagine that's going to happen probably within a few days. So my point is, during early altar days, Adrian Sutton from Teku essentially started nets really quickly and really fast on whatever was the latest spec and the definite was only Teku and running with four nodes. But it was incredibly productive to have that Testnet as a target to testing test logic quickly when you are developing. So if that is available, it will be extremely helpful if you guys can quickly spin.
00:39:45.216 - 00:41:36.210, Speaker A: As long as that's somewhat working. A tiny desnet that we developers can use that will be very appreciated and that could be done in parallel to devnet three if Prism is ready before and I guess the prism thing, the biggest concern is that it does not rebase on capella as per the chat. So there needs to be some work done on the prism branch as what's the quickest ElCl combo? We think we can get basically rebase on capella using timestamp forks and kind of running so other teams can try to interrupt with. Yeah, so it sounds like the issue right now is a Cl client that is rebased on Candela. Yeah, we have this and we might be able to get it working if we have a local test net where we won't miss blocks. Because for us the big missing piece is sync. It's like we have sync partially implemented, but it could get messy if we're missing blocks.
00:41:36.210 - 00:42:22.930, Speaker A: So if you have a test network or a devnet where lighthouse, there's only lighthouse validators perhaps to start. Yeah, like maybe like a couple of lighthouse nodes with just lighthouse validators might work that are local to each other. Yeah. Could we use kudosis on this one? Because all it does is as long as it is just a beacon node, a validator and an El then you can set up a local testnet with that quite easily. We just need docker images. Yeah, I mean I could build a docker image with what we got. Yeah, I think that work.
00:42:22.930 - 00:42:59.710, Speaker A: I can give you the yaml file to run that then. Cool. So if I understand you cannot sync or you do not expose for others to sync. I think we'll panic if we get a blocks by range request right now for signed blocks and blobs. And then we'll sync because we have gossip implemented. So we'll just import blocks as we see them. But it's if we miss a block and have to request a block, I don't think that'll work for us.
00:42:59.710 - 00:43:31.940, Speaker A: Got it. And blocks by root. Blocks by root? Yeah, I don't think. Let me think. No, because we're trying to figure out how to handle the edge cases you pointed out where. What do we request? Pre and post fork as well as before and after the prune boundary blocks by route. I don't think we serve either.
00:43:31.940 - 00:44:31.630, Speaker A: Okay, so I guess it seems like either Lighthouse or Prism are probably the two first that are going to be ready on the Cl side. Let's try and get that and get running. And on the interop repo, hopefully it doesn't lead to lighthouse missing blocks and having to sync. And then. Roberto, you were saying before end of next week would be like an aggressive but nice target for the Devnet. Yeah, the people think basically say before all core devs next week is realistic. That's about ten days, nine days.
00:44:31.630 - 00:44:59.400, Speaker A: Yeah, it's really up to the Cl devs. I think at this point I think Geth is going to be ready. I think I'll be able to implement the ais that have come up around making the epic changes and the time based fork. But the CL stuff's a little outside my control. I don't have a good handle on that. Got it. So load stuff should be ready logic wise and needs revised.
00:44:59.400 - 00:45:23.144, Speaker A: But we have never attempted to run the full thing. So get is ready today. Geth will be ready soon. I think a few more things to be done on the execution API. I'm working on that right now. Other than that, I think it's. And the zero blob stuff for example, needs to be integrated.
00:45:23.144 - 00:45:58.660, Speaker A: All that's ready though. Just need to pull it all together. Got it. So on your repo, on Infi's repo now the CI passes for prism and GEF. So if that is the case, what is the difference between those tests and actually what we want to do in the net. I think once we've done the execution API work for withdrawals, those tests may no longer pass. I'm not sure Mophie might be able to better comment on that.
00:45:58.660 - 00:46:59.690, Speaker A: So I think that's where we start getting interoperability issues with between the interoperab repo prism and where the geth is right now. And then Mop is saying that they did Cl. Yep. So yes, it's passing now with an older version of our Geth repo that is not doing the entire expectations of the Capella rebase. That will break very soon, and we'll need that updated Cl at that point. Okay, yeah, let's try that. And anyways, we'll have the call next week, a couple of days before to review where we're at.
00:46:59.690 - 00:47:29.010, Speaker A: I agree. Before awkwardness would be amazing. Even if it's not all the clients, even if we get like three or four out of six running, the other ones can come after, and then having the whole set before the holidays would be great. So we at least know this is working on a devnet. Yeah, I think it's possible. I'll push it along best I can. Sounds great.
00:47:29.010 - 00:48:01.650, Speaker A: Anything else on Devnet three? Okay, last big thing that I wanted to make sure we cover is this big block test. I know Georgia is here. Still on the call, I think. Yes. You want to give us an update there? Yeah, quick context. So last week's progress was that we ran it on with 128 kilobyte transactions and it looked like nothing happened. Now we wanted to do it with 522, 56, 1024.
00:48:01.650 - 00:48:24.040, Speaker A: I'm connected the flashboots builder, but right now there is a cryptic RPC bug that I'm waiting to get support on. So that's the blocker, but the code is written, and once I'm unblocked on the flashboards. Mevboost girly builder. It should be good. Might even be today. So I'll let people know. Async in the chats.
00:48:24.040 - 00:49:08.428, Speaker A: Awesome. And Perry, I think you were saying that you've added support or are going to add support for Mevboost on a lot of the EF DevOps validators. Is that right? Yes, I've already done that. So now something like 30 ish percent of curly should be running map boost, and we are getting a couple of consequent proposed blocks that are all coming from map boost. Nice. Very cool. Any questions? Maybe let's coordinate after this call on maybe giving me the RPC for the EF builder and the address so that we don't have a builder.
00:49:08.428 - 00:49:25.880, Speaker A: We're just relying on the flashboards one. Okay. But the relay is plugged on the builder so we have more hash rate for inclusion of multiple blocks in a row. Yeah, we're at about a third now. Cool. No problem. Then it's even easier.
00:49:25.880 - 00:50:10.804, Speaker A: Thank you. Sweet. Anything else on that? Okay, and then the last thing, Henry I think just had to leave but he started working on a Nimbus prototype so we should start seeing more on the nimbus side in the next couple weeks. There's already an initial pr open. Yeah. Anything else anyone wanted to cover? Okay, so it's the first time we've ended these. Not over time.
00:50:10.804 - 00:50:26.420, Speaker A: So I guess that's a good sign. Yeah. Thanks everyone for joining and talk to you all on this. Y'all call in a few days. Thanks guys. Thanks everyone. Bye.
00:50:26.420 - 00:50:28.840, Speaker A: Thanks Spike. Bye.

00:09:18.600 - 00:10:08.310, Speaker A: Daniel, this is your sign to start the live stream. I will wait like few more seconds. Hello everybody. So great that so many of you are joining already for the boring opening ceremony. I hope I can make it less boring by telling you a bit about how this is all going to work in this online setup, which we certainly didn't expect when we were planning for this conference. And I will also introduce what do we hope to get out of the solidity summit, as well as who's on the team and everything you need to know to survive the next two days with us. So I think we are good to go.
00:10:08.310 - 00:10:58.204, Speaker A: That means I will share my screen with you now and we can get started. So the first life hack for everybody who will present after me is that you click share your screen and then you click on your camera again so that you can see both the speaker as well as their slides. All right. Hello everybody. I'm super happy that you are all here. My name is Francisca and I will be your host and moderator for the next two days, except for the open discussion sessions where we will have expert moderators leading you through the sessions. We're super happy to have you all here.
00:10:58.204 - 00:12:19.130, Speaker A: This is our very first solidity summit. It was expected to be an in person event in Berlin, but due to the corona crisis, which is happening right now, obviously we are not hosting an in person conference, but we switched everything to be an online conference. And yeah, we hope that this will work out fine. This is certainly new to Rome for us to be hosting an online conference, but we are super happy to do this together with the Interspace team and we hope that all of you will have a smooth experience. In order to have such a smooth experience, I already sent you some instructions, but I will also walk you through how everything will work again so that everybody knows how to get the best out of this conference. Firstly, welcome to everybody and why are we even hosting this event? So obviously, we want to get people involved and interested in the solidity language together and want them to be able to exchange about the topics that they are interested in. We certainly want to exchange experiences and discuss language design and tooling together because the developers of the solidity language certainly have some questions for you who are using the solidity language on how the language design should be moving forward.
00:12:19.130 - 00:13:20.124, Speaker A: We hope that those discussions will actually then result in improvement proposals which will definitely impact the actual implementation of the solidity language and yule. And we don't only want to foster the communication between the solidity team, so us and you guys, but we also want to foster the communication between teams that are working on maybe the same or similar topics so that you are aware of each other and maybe you can collaborate moving forward. And, yeah, ultimately, also we want to obviously identify needs for the smart contract ecosystem for Ethereum and derive steps forward together. So, yeah, first of all, meet the solidity team. Those are all the people who are officially working on the solidity language at the moment. But obviously this is an unexhaustive list. We have so many open source contributors that are either contributing by reporting bugs or by requesting features, or by just joining the conversations with us.
00:13:20.124 - 00:14:05.764, Speaker A: So this is just the official team that I'm listing here. And if there are some people from the official team in the jitsu room right now, feel free to turn on your camera really briefly so that people can see you. Also, there's the. Yeah, hey, guys. Also there's all of the GitHub handles from the team there. So in case you have questions, you can just add them in the GitHub channel and then you can discuss with them over there. So now, how to solidity summit? This conference is, as I already mentioned, powered by Interspace, which is a new open source initiative to basically bring online conferencing to the blockchain space and maybe even beyond.
00:14:05.764 - 00:14:47.640, Speaker A: Let's see, they already produced some great events in the past. For example, the Noncon, which was, I think, the first conference where interspace was used, and then also a virtual hackathon Easter Turin. And I believe there will be much more events coming up in the future. So what does this mean? This conference is facilitated by a couple of tools, which I hope will make the collaboration and interaction between all of us during the conference smooth and easy, and will almost feel as if we are all in the same room together. It's powered by Jitsi, mostly. Jitsi is this open source conferencing tool and video conferencing tool, which we are using right now. So there's one main conference room.
00:14:47.640 - 00:15:50.670, Speaker A: This is a single track event, so everything will happen in this main room. There's the lobby room, which you can use to hang out, for example, in breaks if you want to try out Jitsi, if you want to just chat casually with people who are hanging around, you can also create your own breakout rooms. So basically, if you want to take a discussion further, and it's not part of the agenda anymore, you can create your own breakout room, and then you can distribute the link of this breakout room to the people who are interested. For example, using the guitar chat. We are using YouTube for the live stream, so if you are watching via the live stream right now already, you might know that we're using the Ethereum Foundation YouTube account and you can find the live stream link also on the interspace portal. We will be using the solidity GitHub chat for the Q A sessions and for coordination. So in case you have any question for a speaker during an open discussion session or whatever, feel free to just put your question there and the moderators will relay the questions.
00:15:50.670 - 00:16:55.696, Speaker A: We have agendas in a Google sheet as well as also in a Google calendar, so if you want to create your own individual itinerary, you can do that by going to the Google Calendar entry and just copying the agenda points that you would like to see. In the open discussion sessions. We will use hackMds to take collaborative notes, and those hackMds are also always listed in the agenda points. If you're participating today or tomorrow, or even both days of the event, you are also able to claim a proof of attendance protocol token which will verify that you attended this event and for very ad hoc coordination in case all other technologies that I've just listed above fails us. We also have a telegram group for emergency coordination in case this room breaks down or whatever needs to be coordinated. I will be sure to put it in the telegram group as well as in the GitHub channel. So that's basically that.
00:16:55.696 - 00:17:55.540, Speaker A: And you might ask yourself, but where do I find all of those links? Crazy, right? So don't you worry, just go to interspace solidity summit, ethereum.org if you aren't there already and there you will really find everything you need in one place. And as I was outlining before, you, for example, find the collaborative notes in the description of the open discussion session if you click on agenda so how does this jitsi thing work? I have made a screenshot when I was doing a conference all on my own. So if in case you open the jitsi room in another browser tab, which I think is the recommended option to do so, if you are, for example, a speaker, then this might look similar to you. And Jitsu is very easy to use, actually super straightforward. There's a few features you can share your screen. Sharing your screen is on the left, in the corner on the bottom.
00:17:55.540 - 00:18:44.500, Speaker A: You can raise your hand, which might be excite surfer is raising his hand, for example. You can do that in case you want to speak, so that in an open discussion session or whatever, a moderator can see you want to say something. You have the microphone settings in the middle where you can also choose which mic you would want to be using. You can quit the meeting in the middle and you can also change your camera settings there and then on the right hand side on the bottom you have other settings, you can change the view and you can click on the eye to know which is the room URL. But you can also know that just by seeing your browser tab. Yeah, and you can also set yourself a name. And as I see, almost everybody who's in the room already did so.
00:18:44.500 - 00:18:54.970, Speaker A: So basically by clicking on your video or by clicking on the settings you can give yourself a username. But this sounds everybody already did. So.
00:18:58.140 - 00:19:02.696, Speaker B: Yeah, I wanted to mention that you can click on the help button.
00:19:02.798 - 00:19:05.224, Speaker C: In the sidebar of the interspace and.
00:19:05.262 - 00:19:07.704, Speaker B: There'S a description of the jitsi interface.
00:19:07.752 - 00:19:11.470, Speaker D: If you didn't catch everything that Francis said.
00:19:11.920 - 00:19:58.428, Speaker A: Absolutely, exactly. And then what's the recommended setup? So jitsi has this maximum participants of 75 participants per room limit. I don't think that we will reach this limit, but to ensure a smooth experience for everybody in case you don't plan on actively being involved aka speaking or discussing actively in a session, I would always recommend you to go for the live stream because it also saves your CPU. Obviously you can switch between live stream and participating in the jitsu room directly depending on the session. If you just want to listen in, you go watch the live stream. If you want to really actively participate, you join the room. So feel free to jump around and switch around between those two.
00:19:58.428 - 00:21:04.160, Speaker A: Talk to us in GitHub for Q A. And yeah, just FYI, the live stream by nature has a little delay, so if you really actively want to discuss in such an open discussion session, I would recommend you to join the gypsy meeting because otherwise you will be 1 minute late more or less to the discussion. Yeah, then how do you survive 9 hours online per day? Obviously you don't need to participate in every single session, but I would love you to do so because I think it's all really relevant and interesting content. So yeah, just a few quick reminders which you might already be aware of, but I just wanted to let you know again, please don't forget over all of this cool conferencing to drink something depending on your time of the day, coffee, tea, clubmata, beer, water, whatever you prefer. Don't forget to eat. Also, don't forget to get up and stretch your legs sometimes and also have a screen break for your eyes. So just watch out of the window or go watch your kids if they are playing around at home at the moment during corona.
00:21:04.160 - 00:21:31.124, Speaker A: And yeah, you can also open the YouTube livestream on your phone. So in case you need to go somewhere or just want to wander around a little bit, that's also an option. Okay, last but not least, let's have a quick look at what is going to happen today together at the agenda. So this is the agenda. You might be familiar already with it. We are currently here. I'm doing the opening.
00:21:31.124 - 00:22:11.776, Speaker A: Right after that Chris will present us the solidity 2020 roadmap. After this we have a nice talk coming up from Ricard and Shangwe about the K framework and K solidity. After this we will look at a source level formal verification tool together with Akosh. Then we will have a presentation on Satora. Then we will learn something about D [unk]type and chainlens, which are two tools developed by Loridana. Then we will hear about some thoughts on language design and fragmentation from Alex. And then in the afternoon we start with the open discussion sessions.
00:22:11.776 - 00:22:39.440, Speaker A: They always start in the afternoon because we want to give also the Americas a chance to participate in those. So we will start with the first discussion on Safemas by default, moderated by Chris. Then we will have a break. Then we will have a discussion on libraries 2.0, moderated by Chris again. Then we will receive a nice introduction on Yule plus from Nick Dotson. And after that we will also have a discussion on new features for Yule, moderated by Alex.
00:22:39.440 - 00:23:22.270, Speaker A: Then we will learn something about the soil compiler. Then there will be another open discussion on upgradable contracts, another short break, another discussion on fixed point types, then tracking mapping keys with a truffle debugger by Harry and consecutively also a truffle debugger demo and followed by a debugging data discussion. You might notice that one talk is missing today. Unfortunately one of our speakers fell sick so we will not hear about curiosities in solidity development from Nick. And that's why the fixed point types discussion has been moved up a little bit. Yeah, and that's almost it from my side. So long.
00:23:22.270 - 00:23:46.340, Speaker A: I hope you will have fun and enjoy the upcoming talks and discussions, and please feel free to ping me with any feedback you might have. I'm underscore Franci on Twitter and Franciehigh everywhere else, so have fun and enjoy. And with that, without further ado, I hand the mic over to Chris.
00:23:48.200 - 00:24:02.500, Speaker B: Yeah, thanks a lot for this great introduction, Francis. Let me quickly share my okay, does this work for everyone?
00:24:03.910 - 00:24:06.482, Speaker A: Yes, this works. If you now click on your camera as well.
00:24:06.536 - 00:24:07.300, Speaker C: We will.
00:24:07.850 - 00:24:08.790, Speaker B: Camera.
00:24:15.340 - 00:24:16.088, Speaker A: Perfect.
00:24:16.254 - 00:25:17.176, Speaker B: Yeah, nice. Okay, so I will talk about solidity's roadmap for 2020. Having said that, the solidity project is not a project that has fixed roadmaps, and this is also one reason why we're having this summit here, to talk about future features and agree if we want to have them and how. So there is one thing we very much focus on and that is completely set, and that is the reimplementation of the code generator. Using our intermediate language, Yule. We are currently roughly at 50% implementation of the full language features, and yeah, we'll talk more about that later. And then a second important thing is the SMT checker.
00:25:17.176 - 00:26:15.400, Speaker B: So our formal verification tool. We would also like to get almost full coverage of the whole language until the end of the year. But yeah, for both these topics we'll have to see how far we get. And then maybe more interesting for you, we plan to have at least one, maybe two breaking releases with new breaking features. Some features can of course also be introduced in non breaking releases. And yeah, I would just like to highlight some of the breaking features that I myself find interesting. And for one, this is a feature that makes the copying semantics more explicit and also makes at least reference types immutable by default.
00:26:15.400 - 00:27:11.260, Speaker B: So if you want to have a memory array where you can change values, then you have to specifically mention that at the point of declaration there will be a discussion session on that topic on day two at 07:00 p.m.. CST. And then another topic, safemath. By default this is arithmetic overflow checking at runtime, introduced automatically by the compiler. We were we did not introduce that for a long time, for two reasons. The first is that we think that the existing optimizer has a hard time dealing with that, and the second is that it can introduce new bugs. But we see that everyone is just using the Safemouth library.
00:27:11.260 - 00:27:53.036, Speaker B: And because of that we would like to have a discussion on whether we should introduce that by default or not. And that discussion will be on today at 340 p. M. Then another interesting feature is call data variables. We already have the call data location specifier for function parameters of external functions, but there's no really big reason why call data cannot be used for any other variables. So local variables and parameters and internal functions. And I think this could yield nice performance improvements because it does not.
00:27:53.036 - 00:28:56.796, Speaker B: Because when you have a memory variable and just use that for call data content, then you always need a copy to memory, which could be unnecessary. And in addition it guarantees that you can modify such the content of such variables. Then another interesting topic is language servers. So during the last, actually last weeks, few months, we noticed that people have a hard time debugging solidity code. And just in general working with in general the development process could be better. And because of that we thought about implementing a language server as part of the compiler. Language server is an initiative started by Microsoft to standardize the interface between compilers and debuggers and IDEs.
00:28:56.796 - 00:30:28.812, Speaker B: And as soon as you have a language server for a language implemented, then any IDe that also has language server support can work with that language. So this is a nice generic way to provide access to compiler features. And the cool thing about that is things like gotodefinition are probably rather easy to implement for us. And while several IDEs already might have that feature, the interesting thing about implementing it in the compiler itself is that when you use the Gotode definition feature in the ide, it uses exactly the same code that does the identifier resolution during code generation. So you're 100% sure that it goes to exactly the same definition that is referenced in the final code? Yeah, tomorrow at 04:30 p.m. And then also in the same direction we want to improve the output of the compiler that can be used for debuggers or more general, I don't know, how would you call it, code inspection routines. This is an initiative that was started by the Truffle team last year, or maybe even two years ago, and some more teams joined in in the meantime.
00:30:28.812 - 00:31:35.736, Speaker B: And yeah, the discussion about that will be today at 08:50 p.m. And yeah, two things that we always do in parallel, regardless of specific features, is improving the new Yule based optimizer and improving the webassembly output. And these two are kind of interconnected. And yeah, talking about Yule, let's go a bit more into detail about Yule, because there are still some misconceptions around about Yule. Yule is a simplistic intermediate language we have been using for quite a long time, at least for parts of the compiler. And the idea behind Yule is that it should be human readable, and not only machine readable. And we hope that we can build our Yule optimizer.
00:31:35.736 - 00:32:41.800, Speaker B: Currently. We hope that it has that feature to generate code that is still readable by humans. Even after the optimization, there will be two sessions around Yule. One of them is about Yule. Plus that is an extension of Yule developed by Nick Dotson, and that is today at 05:10 and then right after that at 540, a discussion group about new features for Yule. Our hope with Yule is that it allows people to understand much more what is happening behind the scenes in the compiler, that it allows to actually inspect the generated optimized Yule code that is then very very close to EVM bytecode. And it allows this Yule code to be fully audited.
00:32:41.800 - 00:34:19.214, Speaker B: And because of that you do not have to rely on a definition of the solidity language or absence of bugs in the compiler. Yeah, let me just quickly check the time and the nice thing about Yule is that it has very few features, but it is a structured language, so it has for loops, user defined functions and so on. And it is extensible and typed, which allows it to be used for different purposes. For example, we're thinking about adding memory allocation features to the optimizer that allows lifetime tracking of memory objects and out of bounds access and so on. And yeah, all this will hopefully be covered in the discussion later today. As far as the Yule code generation in the solidity compiler is concerned, we are pretty far ready so early. I said 50%, but yeah, 50% of the features does not mean 50% of the smart contracts out there.
00:34:19.214 - 00:35:11.470, Speaker B: So please try it out whether it already works for your smart contracts. And you can try it with salt c minus minus IR this shows you the originally generated intermediate code for the smart contract. But this is usually not something you would like to look at because we are writing the code generator in a highly modular way, which means we have many many different functions for each tiny functionality that constantly call each other. And the optimizer will inline all that. And most of these functions in the end just do nothing. So what you would like to look at is the output of salt c minus minus optimized minus minus IR minus optimized. This is a bit weird.
00:35:11.470 - 00:36:04.506, Speaker B: So if you just use minus minus IR minus optimized, it will show you the intermediate code after optimization. But if optimization means no optimization, so if you did not switch on the optimizer, then it will be the same as before optimization. So please always use these two flags together. And having said that, yule output from solidity is still experimental, so we might change any of these flags in the future. We might introduce different built in functions and so on. So this is still experimental, while Yule itself is not experimental anymore. So if you want to take Yule code and use it as input then this is pretty safe.
00:36:04.506 - 00:37:07.570, Speaker B: I never say it's foolproof because no software ever is, but it should be pretty safe and it is being used out there already. Then one last thing about the SMT checker. There is a session at day two on 06:00 p.m. About more or less formal aspects of solidity, a formal specification language. And I'm not the expert on the SMT checker in the solidity compiler, that would be Leo, but he told me that it can do already quite a lot. It does function abstraction, which is really nice. So when you call a function internally, it does not always inline it, but instead it tries to infer properties of the function and just use these functions.
00:37:07.570 - 00:37:28.620, Speaker B: And I think invariants are not yet implemented. But this is something on the roadmap and also one of the main topics of this session on day two. Okay, that was it. About the roadmap. Do we have time for questions?
00:37:30.270 - 00:38:08.670, Speaker A: Yeah, we have minimum two more minutes. So if you have questions, there are no questions on the chat. Maybe questions in the room about the solidity roadmap. Just raise your hand or shout or comment on GitHub. Okay, seems like no questions so far. But don't you worry, Chris will be around for the next two days. So whenever you have questions, just put them in the room.
00:38:08.670 - 00:38:16.380, Speaker A: Then I guess there is one question now on the chat. The presentation will also be shared later.
00:38:16.450 - 00:38:23.010, Speaker B: Yes, I totally forgot about that. Actually wanted to paste the URL in the chat. I'll do that right now.
00:38:23.860 - 00:38:39.190, Speaker A: Okay, there you go. All right then, next up we have the introduction to the K framework and K solidity with Ricard and Changwei. Are you guys there already?
00:38:40.600 - 00:38:41.350, Speaker B: Yes.
00:38:41.960 - 00:38:44.890, Speaker A: Perfect. Then I hand over the mic to you guys.
00:38:49.470 - 00:38:52.940, Speaker B: Okay, let's see. Can you see the presentation and me?
00:38:53.710 - 00:38:58.300, Speaker A: Yes, I can see both. A little blurry, but it's okay.
00:38:59.090 - 00:39:20.820, Speaker B: Okay. My neighbor also just started drilling, so we'll see if we survive that. Thanks for having us. I'm Ricard. I work for runtime verification. I usually work on Kwasum, and I'm here with Shangwei from NTu Singapore. And we want to tell you about k and how and why specifying solidity in K is a good idea.
00:39:20.820 - 00:39:58.800, Speaker B: The k semantic framework is built on the idea that every programming language should have a formal semantics. So from a formal semantics, the K framework can automatically derive all the common software tools. This includes parsers, interpreters, but also more complex tools like compilers, model checkers, deductive verifiers, and so on. So the complexity of work for generating ttools for L languages goes from T times L to t plus L k is by no means a new technology. This framework has been developed for over 15 years. We use it heavily at runtime verification. There's lots of publications surrounding it.
00:39:58.800 - 00:40:31.510, Speaker B: It has also proven very language and blockchain agnostic. So the formalism works for high level languages like solidity, C, Java, low level languages like WASM and EVM. And we worked on different blockchains like Ethereum, Algorand, Tesos and so on. I just want to show you the formalism that K is based on. It's a rewriting formalism. So I'm going to give you a short example of what that looks like. The first thing you need to define is the state that the rewrites should act on, which we call the configuration.
00:40:31.510 - 00:40:51.454, Speaker B: It's built up of what we call cells. So here we have a configuration which contains the program to run in a cell that we name K. We have an environment for the current variables, which is a key value map. And we have a local memory storage and more cells we don't really care about.
00:40:51.492 - 00:41:03.700, Speaker A: Now, Ricard, I'm sorry to be interrupting, but the slides are kind of blurry. Is there an option that you either can share them with the audience or maybe Shang Wei could share his screen instead?
00:41:05.210 - 00:41:06.966, Speaker B: Sure, let's see.
00:41:07.068 - 00:41:09.510, Speaker A: They are kind of hard to read right now.
00:41:09.660 - 00:41:11.830, Speaker B: Okay, I can share my screen, but.
00:41:11.900 - 00:41:14.470, Speaker E: Does it affect Ricard's presentation?
00:41:17.630 - 00:41:25.754, Speaker B: So we have some transitions, but we should be. Okay, I'll just say next slide or something. Okay, let me turn off my.
00:41:25.872 - 00:41:27.660, Speaker E: Let me try as well.
00:41:29.410 - 00:41:31.994, Speaker A: That would be great. Sorry for the interruption.
00:41:32.122 - 00:41:32.414, Speaker B: Yeah.
00:41:32.452 - 00:41:34.622, Speaker D: So that just means that people will.
00:41:34.676 - 00:41:35.680, Speaker E: Have to select.
00:41:37.730 - 00:41:40.074, Speaker C: Not the speaker's picture.
00:41:40.122 - 00:41:42.482, Speaker D: To see the slides because the live.
00:41:42.536 - 00:41:44.370, Speaker C: Stream follows the audio.
00:41:45.750 - 00:41:46.402, Speaker A: Yes.
00:41:46.536 - 00:41:47.220, Speaker F: Okay.
00:41:49.910 - 00:41:54.210, Speaker E: So let me share with my slides.
00:41:54.890 - 00:42:04.298, Speaker B: Great. You can click through. There's a much better quality.
00:42:04.464 - 00:42:06.858, Speaker A: Yes, this is very sharp now. Thank you.
00:42:07.024 - 00:42:37.490, Speaker B: Okay, keep going. And. Yeah, here we come to syntax. So you write your syntax in typical eBNF form, but we have these handy annotations. For example, strict two means that the second argument here is strict, so the right hand side would be evaluated first. So you can add some semantic meaning to your syntax declarations if you go to the next slide. Here's an example of what a rewriting rule looks like, and I'll just show you how it acts over a specific configuration.
00:42:37.490 - 00:43:18.338, Speaker B: So here we have a configuration with the identifier Foo, and you assign three to it and you write your semantic rules with this rule keyword. Basically what we will do here is we will look in the current environment, find the pointer and then go to the storage and modify the value at that pointer. Go back. Yeah, so the rule, it's a rule keyword, and you see these little rewrite arrows, those specify where the state is going to change. Next slide. So first the assignment is going to.
00:43:18.344 - 00:43:19.300, Speaker C: Match the.
00:43:23.750 - 00:44:01.298, Speaker B: Rewriting rules just applies to any configuration that its left hand side unifies with. So in this case the configuration matches the rule. The assignment in the rule matches Foo equals three, with Foo assigned to X and three assigned to Y I. So actually this might be a little annoying to do in this way, so let's just skip over the rewriting part and I'm happy to explain this in detail to anyone later. Or you can just look at slides yourself. Let's go to formal verification. So basically, from a semantic written in this formalism, there's a straightforward way to reason about how program execution click next.
00:44:01.298 - 00:44:37.020, Speaker B: The K framework derives a prover for free, and the basic idea is this. You treat every rule as an axiom. Next you can do next three times you write a claim as a rewrite rule. Then you start from the left hand side, apply all axioms that match branching whenever there's more than one thing that applies, and you just show that on every branch you always reach a state that matches the right hand side. So next slide. Let's see.
00:44:39.470 - 00:44:41.086, Speaker E: Maybe I showed them all.
00:44:41.268 - 00:45:28.940, Speaker B: Yeah, that's probably good. So basically, why should you bother making a formal specification or an executable formal specification? I'd say it's the best of both worlds. You get something that's readable and reasonably high level. If it's a case style, you can even write it in a literate style, inline it with your documentation. It's executable, obviously, so you get an always up to date correct by construction reference interpreter. Everyone working on the formal verification tool can now do so properly in quotation mark because you actually have a formal definition of the language. I'm very curious to see what's going on on the s t end tomorrow regarding this, but yeah, having some formalism that describes the language is usually a good idea.
00:45:28.940 - 00:46:17.210, Speaker B: I also find that it's a good prototyping tool for trying out language changes, because once you've hacked away on a language change in the compiler, for example, you need to specify it in a way that is ruthlessly unambiguous. And at least with k the semantics are even composable. So you could write a separate semantics for, say, Yule and include that in the solidity semantics. And it actually shouldn't be that intimidating, because defining a semantics is sort of on par with writing an interpreter in terms of work. So with that I want to ask you to consider this statement that solidity should have an executable formal semantics. And with that I just want to hand over to Shangh Wei, who has been working on just such a specification.
00:46:19.070 - 00:47:11.626, Speaker E: Okay, thanks Rica for the introduction of the K framework. Then I'm going to take over to introduce how we define the formal semantics of k of solidity in the K framework. To do so, actually you need to define two components. The first component is the configuration, which indicates the status or state of smart contracts. If you look into the configuration file, actually you'll find that it has two main parts. The first part mark in the red color, which is for execution of a smart contract instance, while the second part mark in the blue color is for recording the whole blockchain network status. And let's zoom into the red part and you will see that we have a dedicated cell called execution engine for execution of smart contract instance.
00:47:11.626 - 00:48:20.018, Speaker E: And inside this cell we have several important cells. For example the call stack for function calls, either external or internal. We have call state, including the iD, which is the address of the current instance, the caller ID, call value, storage, local memory, et cetera. And if we look into the blue part, you can see that we have a sale account in which we store all the contra instances that have been deployed on the blockchain, including its address, its contract name, its balance, its storage, et cetera. Now let's move on to the second component to define that is a set of semantics rule indicating how each solicit statement behaves based on a current configuration, as well as how it updates the configuration. Let me use this statement as an example. So here we have a statement to declare a variable of unsigned integer in storage whose initial value is three.
00:48:20.018 - 00:49:04.910, Speaker E: And how do we define a semantics of this statement? We need to write a semantics rule for that. For example, here in a case cell we see this statement of this syntax. We know that it's a variable declaration, so we try to rewrite this statement to allocate term in K. It looks like this, and at the same time we need to look for necessary information and put it here. So for example, here we need to know what is the current account that we are going to declare this variable. So we need to look for its account ID. So we put it here together with the variable information, for example, the name of the variable, the expression, the value, the type, the location, et cetera.
00:49:04.910 - 00:50:10.520, Speaker E: And then we move on to this allocate term. So whenever we see this allocate term in a case cell provided with the necessary information, then we are able to do the corresponding arrangement in this account, that is, to insert this variable record in this account cell. Here I omit the details, but to sum up, to develop a formal semantics of solidity in the k framework, we need to define, first the configuration second a set of semantics rules like this for each statement. Now I'm going to talk about the challenges that we face during when we develop the semantics. The first challenge is that solidity is actually changing very fast, either in syntax or semantics. Currently the latest version is 0.6, but if you look into the version history in average, almost every month will have a version change, which is quite challenging for us to run after the frequent version changes.
00:50:10.520 - 00:51:11.318, Speaker E: The second challenge is that the language description in the official document is not comprehensive. Usually complicated or corner cases are not mentioned. For example, if we are talking about function modifier, the following details are not mentioned. For example, what if the underscore statement is used for more than once? What if the modifier is inherited for more than once by a function, et cetera? And we need to figure this out by ourselves based on some experiments, which is quite time consuming and the current status of k solidity the project started in the beginning of 2018, and until now we have two versions. Version one supports solidity 0.4 and this table summarizes what are the features supported by our semantics? And as you can see that almost every core feature is supported except those that we are not able to support. For example, this inline assembly.
00:51:11.318 - 00:52:02.666, Speaker E: Basically this is EVM bytecode, and obviously it is out of the scope of solidity itself. And since solidity 0.5 was introduced, we plan to have a refactoring based on version one to version two to support solidity 0.5. And currently we have finished core expressions and statements, and we are still working on some advanced features, for example function modifiers, user defined types, inheritance, et cetera. And now you can find our version two implementation on GitHub now, and with version two, actually you can do automatic testing or proving your smart contract. Now I would like to share with you one of the interesting findings. When we developed the semantics and it was back to solidity 0.4
00:52:02.666 - 00:53:04.526, Speaker E: and here we have a very simple test case that we use to test our semantics, and you can see that it's a very simple contract test consisting of two state variables, a and b, with their initial values one and two respectively. And we have a function fool here in which we declare a local array d with two elements, and after that we try to assign seven and eight to the two elements respectively. Now the problem is what are the values of a and b after we execute the function foo? Well, based on our semantics, a is still one, b still two, but the program stuck at this statement. And this is because when we declare d we don't specify the location. So by default it will be in storage, and based on the semantics it will be a reference to storage. But we don't have its initial value, meaning that we don't know where d points to. So whenever we want to execute this statement, we don't know where to store seven.
00:53:04.526 - 00:53:46.410, Speaker E: However, if you try to execute this contra in the remix compiler, I mean 0.4 version, and you will find that the result would be a becomes zero and b becomes eight. And you may be surprised because you thought you are dealing with only local variables, but actually global variables are affected. And obviously something went wrong here. So we reported this findings in our technical report in 2018 on archive. And after our investigation we found that the solidity 0.4 compiler implemented some implicit behavior which is beyond developer's expectation.
00:53:46.410 - 00:54:21.334, Speaker E: And the problem comes from this statement. When we declare this array d, we don't specify the initial value, but for the compiler it assumes that the default value will be zero. So actually d points to slot zero in the storage. So that's why when we execute this statement, the content becomes like this. And when you execute the second assignment statement, the content becomes like this. So that's why a becomes zero and b becomes eight. And of course this behavior has been fixed since solidity 0.5.
00:54:21.334 - 00:55:17.170, Speaker E: Now you need to specify the initial reference for d, otherwise the compiler will complain about that. So from this example we can observe that the formal semantics of solidity is very important, especially for developers. Well now I would like to summarize this talk by introducing the possible application of cage solidity. First of all, our semantics is fully executable, meaning that you can execute your smart contract based on our semantics and you will have an output configuration. Actually, you can have the output configuration after each statement, and you can do formal verification. You can have some assertions in your smart contract, and our tool can help you to do symbolic execution to check whether the assertion will fail or not. Or you can even try to prove that your smart contract are correct.
00:55:17.170 - 00:55:53.300, Speaker E: But of course you need to specify the properties, and then you can even do compiler verification. This is what you can do. For example, you have a smart contract right. You can run your smart contract based on our semantics. Then you have an output configuration. In the other hand, you can compile your smart contract by a compiler, and you have your EVM bicode, and you execute your bicode and you have your real output. And after that you can compare the two outputs to do course validation if they are not consistent, meaning that something's going wrong.
00:55:53.300 - 00:56:24.240, Speaker E: And last but not least, you can even do semantics consistent checking. For example, how do you know that the behavior in the solidity level conforms to that in the EVM bico level? To do the consistent checking, actually, you need the formal semantics of EVM, which is supported by another project, KeVM from runtime verification. All right, I think that's pretty much I want to share with you today. I think Rico and I would be happy to take questions if we still have time.
00:56:26.050 - 00:56:40.580, Speaker A: Yes, you still have a couple of minutes, so feel free to ask questions in the solidity GitHub chat or right here in the room. Okay. Yeah, somebody's raising his hand. I see it already. La dio. Yes.
00:56:41.990 - 00:56:45.686, Speaker B: Hey guys, thanks for the talk. Wait, can you hear me?
00:56:45.868 - 00:56:46.550, Speaker G: Yes.
00:56:46.700 - 00:57:16.830, Speaker B: Okay, cool. Yeah, so this stack case related to KVM, of course, makes a lot of sense, and it's super nice. But suppose, let's assume that Kul exists. How much easier would case liturgy to Kul and Kul to KVM be if you want to verify the whole stack, then sort of like the single large step from case liturgy to KVM?
00:57:18.930 - 00:57:20.980, Speaker E: Ricard, are you going to answer?
00:57:21.750 - 00:58:15.250, Speaker B: Yeah, sure. So you mean for compiler verification, like verifying it in intermediate steps, right, if you have the source code and then you have the compiled bytecode and you want to check equivalents, for example. Yeah, I mean, it would be the same thing in the sense that if you have a complete semantics of Yule, you could symbolically execute your program and then you could check that. I mean, the tricky part is defining sort of equivalence, like figuring out, well, we expect this value to be output or stored somewhere, whereby EVM just correlating that to the corresponding part of the solidity configuration. It would be the same thing, I think, but it depends sort of on how the semantics are written. But in principle, it should be the same or simpler.
00:58:15.670 - 00:58:56.442, Speaker E: Actually, I have something to add up. When we try to define a formal semantics of solidity, we try to keep the configuration as much the same as EVM as possible. For example, we still keep the gas transaction number, et cetera. We try to keep it as the same as possible. This is because we want to do the consistency checking, although some of the cells we cannot use it. For example, the gas cell actually in the solidity level, you don't know actually how each statement consumes how many gas. So we just put it there and have some estimation.
00:58:56.442 - 00:59:22.840, Speaker E: One way is to you compile your solidity contract into EVM and calculate the gas and get back to solidity level and put into the gas cell. So I think if you want to do the consistent checking, that would be not difficult because 80% of the configuration are the same. I hope I have answered your question.
00:59:23.930 - 00:59:25.000, Speaker B: Yeah, thanks.
00:59:25.610 - 00:59:35.658, Speaker A: Okay, Chris, you also want to say something and then I guess we move on to the next talk. And also Shang Wei, you can stop sharing your screen. Then we will be able to see you again.
00:59:35.824 - 01:00:00.766, Speaker B: I'm sorry. Yeah, you mentioned that the documentation is lacking on some edge cases. For example, the modifiers. Are there any other cases? And if yes, it would be really great to. I don't know if you have something like that, get a list of edge cases where the documentation is lacking. It could be more descriptive.
01:00:00.958 - 01:00:14.998, Speaker E: Okay. And maybe I can collect my findings. When we develop semantics, I can share with you some lacking part that we would like to seek from you.
01:00:15.164 - 01:00:17.482, Speaker B: Cool. That would be great. Yeah. Thanks. Okay.
01:00:17.536 - 01:00:18.380, Speaker E: Thank you.
01:00:18.830 - 01:00:34.000, Speaker A: Okay. Thank you both for this very interesting talk. So then with 1 minute delay, we can move over to the next talk by Akosh who will present his first level promote verification tool. Are you there?
01:00:34.770 - 01:00:35.230, Speaker B: Yes.
01:00:35.300 - 01:00:36.382, Speaker G: Can you hear me?
01:00:36.516 - 01:00:37.806, Speaker A: Yes, I can.
01:00:37.908 - 01:00:48.434, Speaker G: Then I'll start sharing my screen first. Can you see the screen?
01:00:48.632 - 01:00:49.746, Speaker A: Yes, we can.
01:00:49.848 - 01:00:50.402, Speaker B: Cool.
01:00:50.536 - 01:00:53.460, Speaker G: Okay, now I'll start the camera as well.
01:00:54.090 - 01:00:55.240, Speaker A: Works perfect.
01:00:56.090 - 01:00:56.646, Speaker B: Cool.
01:00:56.748 - 01:02:12.766, Speaker G: Great. Okay, so yeah, thanks for the. So, today I'm going to present you soci verify, which is a source level formal verification tool for solidity. I'm actually a PhD student at the Budapest University of Technology and Economics, but this is a work that I've been doing together with some people from Sri International. So coming back to verification, there's a wide selection of verification tools available for solidity and Ethereum smart contracts ranging from testing tools and fuzzers all the way to static analyzers, symbolic executors, and also formal verification tools like you've seen K solidity. There's also going to be some more talks on this topic later, and these are all pretty good tools, I would say, and they all have their strengths and application areas. And with today's talk, I would like to convince you that our tool saucy verify also has its place in this landscape, and it can also provide you some useful features that other tools might not.
01:02:12.766 - 01:03:14.110, Speaker G: So let me start right away with a quick demo on what you should expect. So here's a really basic contract. It has two state variables, x and y, which should always be the same. The constructor sets them to a starting value, and then there's an add function which will just increment both of them with the same value. So basically when you say that these two values should always be the same, except of course during some intermediate steps within a transaction, basically by this statement you are formulating a so called invariant over the contract, and invariants basically must hold before and after every transaction. So roughly speaking, before and after the execution of every public function. Now with Saucy verify, you can actually express this as in code annotation.
01:03:14.110 - 01:03:55.326, Speaker G: You can say we use this special notice doc tag. You can say invariant x equals to y. So then you can just run saucy verify on this example and it will tell you that we found no errors. Both the constructor and both Ed satisfy the specs. But for example, if you mess something up, you forget to initialize value or you do some wrong arithmetic operations. Then we can report that there are errors. Your invariant is not satisfied by, for example, the constructor, or for example by this add function.
01:03:55.326 - 01:05:02.994, Speaker G: So. So as you've seen, Saucy verify takes smart contracts annotated with these specification exceptions, for example, invariant. But I will also show you many more in today's talk. And we are using our extended version of the compiler from which we reuse parsing, reference loadolving and type checking in order to build an ast. And then we traverse this ast and translate it into a boogie program which has formal semantics. And basically by doing this translation, this is how we give a formal meaning to the solidity language on which we actually spent a lot of time. As also highlighted by the previous talks, there are many corner cases and interesting stuff, especially going around with the storage and memory reference types and things like that.
01:05:02.994 - 01:06:11.340, Speaker G: I will have some links at the end of my presentation to some of these papers. So then this boogie program can be passed to the boogie verifier, which is a modular program verifier. It was originally built for object oriented programs, but since smart contracts are somewhat similar to classes, boogie is also a good match for smart contracts. And what boogie does is it checks the program by discharging these verification conditions to logic solvers, SMT solvers which have a sound mathematical basis, and they support various theories such as arithmetic arrays, data types and so on. And these solvers can return proofs or refutations. So boogie can tell if the boogie program is correct or not. And of course, in order to be useful for the developers, we back annotate these results to the original contract, as you've seen it in my demo.
01:06:11.340 - 01:07:17.840, Speaker G: So when we say we perform formal verification, it is important to note that we prove functional correctness with respect to the specification that you wrote. So if you don't have any specs or you have some problems in your specs, of course, then the results of the formal verification cannot be trusted. But that is how these things usually work in common, and we are also not targeting these common vulnerability patterns. Besides some examples that I will present you like overflows and reintrancy, there are many other tools for that. Our focus is really on these functional specifications. And these specifications can be implicit coming from the code, like for example checking for failing assertions or checking for overflows. But as I presented you, our main goal is to provide explicit annotation possibilities, like for example invariants and the other ones that I will present you in a moment.
01:07:17.840 - 01:08:21.214, Speaker G: And basically sOCI verify performs modular verification, which means that functions are verified independently from each other to give a better performance and scalability. And basically each function will have a precondition and a post condition which might come of course from invariants. Like for example, in the example we have a precondition that x should be equal to y, and then we execute the body and the post condition should hold. So basically this is what we want to check given the precondition. Does executing the body guarantee the post condition? And this can be done, or this is done by translating the specs and the function to SMt formulas by boogie and feeding it to two solvers. This is what boogie does in the background. So if we start with the same x and y, and then we increment both of them with one, then can we prove that they are afterwards the same end? This is what Smt solvers can basically prove.
01:08:21.214 - 01:08:35.080, Speaker G: And if interestingly, if there are other functions that call each other, like for example, here's a function g which has its own pre and post conditions, and it will call f. Then in order to be scalable and efficient, basically.
01:08:38.350 - 01:08:38.714, Speaker B: We.
01:08:38.752 - 01:09:29.654, Speaker G: Substitute the call with the specs, which basically act like a summary of what the function is doing. So just speaking a little bit about these implicit and explicit annotations, you can see a similar contract here which has x and y. And there's a function to add some integer which will just call another function to add it to x and then in a loop it will increment y. Just for illustrative purposes it does some of this stuff. And solidity provides some of these implicit specs. Like for example, you can write require and a search statement. But in order to give more flexibility, we developed our annotation language to explicitly provide specs.
01:09:29.654 - 01:10:03.542, Speaker G: And I will tell you or introduce you all these in a demo. For now, I just want to quickly summarize, what are the possibilities? So of course we support pre and post conditions. You already saw, contract level invariants like X should always be equal to Y. We also support loop invariance. This is required because of this modular and efficient reasoning. These are basically formulas that should hold on entry and on every iteration and on exit for the loop. But we also support fine grained access control.
01:10:03.542 - 01:10:41.210, Speaker G: We can, for example, specify that the function should only modify state variable x if a given condition holds. We are also working on specifying events. If I have some time and you're interested, I can show you some examples. And these annotations are essentially side effect free solidity expressions that are given in code. So this way you don't have to learn a new language to write specs. And also the specs are not separated from the code, they are strongly tied together. And we also have some extra elements to be more flexible.
01:10:41.210 - 01:11:13.338, Speaker G: For example, we can express the sum of the collections. I will show you some examples. You can refer to previous values of variables. And we are also experimenting with using quantifiers with which you can express properties like every element of an array is non negative, or for example, this array is sorted and this kind of stuff. So let me get back now to my demo to illustrate these features. Also. In the meantime, if you have questions, feel free to ask.
01:11:13.338 - 01:11:52.626, Speaker G: I will provide link also to these examples and to the slides. So let's see now a little bit more complex example. This is a typical token. It's a fixed cap token. It has some total amount, and it has a mapping that keeps track of the balance of each user by mapping the address of the user to his or her balance, which is an integer. There's a constructor which will just set which will just put all the tokens to the creator. And there's a typical transfer function which does some checks to make sure that the transfer can happen, and then it does the transfer by changing these values.
01:11:52.626 - 01:12:33.490, Speaker G: So for these kind of tokens, it's pretty obvious that you would like to have some high level functional properties. For example, with the fixed cap tokens, it makes sense to specify that the total amount equals to the sum of individual balances, this is actually an invariant. It must always hold for the token. And you can express it in a way that's saying an invariant, the total should be equal to verifier sum uint. This is a bit ugly. It's something that we are working on it. But for now you can express it with this special function so that we don't have any collisions with other already existing functions.
01:12:33.490 - 01:13:08.602, Speaker G: Balances. So the total amount should be equal to the balances. So now you can run saucy verify on this example, and it will tell you that yes, your contract is correct. But for example, if you mess up something, it can tell you that the invariant is broken. However, this is alone not enough. Like for example, I can just swap the minus and the plus, so the transfer still takes place. And actually the sum of the tokens will stay constant.
01:13:08.602 - 01:14:01.568, Speaker G: So the verifier will say that this is correct, modulo the specs that you wrote, because it still holds. In order to verify these kind of properties, we have to give some extra conditions. We actually have to state what a transfer does. And what the transfer does is basically you want to make sure that you have a post condition that after the transfer, the balance of the message sender should be equal to the old value of the sender minus the amount that was transferred. Right. And the same or similar should hold for the receiver. Let me just cheat with that.
01:14:01.568 - 01:14:35.036, Speaker G: So the balance of the receiver equals to the old balance plus the amount. So now if you run the tool on this example, which is still swept, so it's wrong. Now it will, I made a typo. It's not balance, but balances. This is the benefit of reusing the compiler. And I guess I also have to fix it here. But now saucy verify will basically report that this condition does not hold.
01:14:35.036 - 01:15:27.448, Speaker G: So then if you actually fix it, you make the transfer in the correct direction, then we will be able to prove that your specs hold. Okay, so this is one example on why these specs are important. So let me show you again a little bit more complex example. This is the same token. It's just that now I'm using this batch transfer function, which can transfer some amount of, some value of tokens to an array of receivers. It does some checks on the length of the receivers, it calculates the total amount. It checks that the sender has this amount, and then it subtracts this amount from the sender.
01:15:27.448 - 01:16:06.410, Speaker G: Then it uses a loop to transfer this amount to each receiver step by step. And for most of the operations, it is actually using this safe math library, like for example, the subtraction and for the addition. But there was this famous bug where developers forget to use it for multiplication, which could result in a potential overflow and basically a generation of tokens out of thin air. So if you run saucy verify on this example, maybe I will just.
01:16:09.200 - 01:16:09.516, Speaker B: Move.
01:16:09.538 - 01:17:11.868, Speaker G: It a little bit so that it's visible. You have to turn on overflow checking that you can do with the special flag, and it will tell you that there's a potential overflow. But if you fix it, you are using multiple from safe math, then it's no longer reporting any false overflow alarms, which many of the tools actually tend to do. But just because there's no overflow, it does not necessarily mean that the functional properties are met. So now we can, for example, just put back our invariant that the total number of tokens should be equal to the sum of the individual balances. And we might want to try to prove that this will fail because we have a loop. And in this case, the verifier actually needs some loop invariant that must hold for the loop.
01:17:11.868 - 01:17:53.640, Speaker G: This is required because of this verification approach. And one invariant that we need is that the loop counter is always less than equal to the receiver's length, which it can be equal, because when it exits the loop, it's equal. And we need also the contract level invariant, but a slightly generalized version. So when we are doing the loop, the total amount of tokens equals to the sum of the balances. But since we first subtracted the amount and we have not made all transfers yet, we have to add those transfers that we have not made yet. So we still have length minus I transfers to make. So this should be added.
01:17:53.640 - 01:18:29.450, Speaker G: And with this invariant, now we can verify this example. And this is an interesting example, because it's pretty complex from a verification point of view. There's reasoning going on over like bit precise reasoning going on over 256 bits, there's invariant. There's also some nonlinearity. So this is a pretty nice example of what we can achieve in terms of performance. Let me show you another classic example during transit here. Yes, sure.
01:18:30.060 - 01:18:47.820, Speaker B: Does it also work if you use the symbolic multiplication instead of the safe math multiplication? So does it find the error? So does it find the error if you use the asterisk for multiplication, but do not turn on overflow checking?
01:18:49.520 - 01:19:29.020, Speaker G: So this is a good question. If you do not turn on overflow checking, then it will not find the issue, because essentially, in this case, your spec holds, because if there's an overflow in the balances, then basically there will also be an overflow in the sum of the balances. And because we have this symmetry, there are two overflows, they will cancel each other. So, yes, really good question. And this also highlights why you should pay attention on what you are actually verifying and what are your specs and what's your configuration.
01:19:29.520 - 01:19:33.710, Speaker B: Yeah, thanks. Can I also ask some stuff?
01:19:34.800 - 01:19:35.950, Speaker G: Yeah, sure.
01:19:36.640 - 01:20:00.470, Speaker B: Okay. So yeah, thanks for showing this. Also, verify is really nice. And I think we're doing very similar things as everybody talks with Taeyeon. So I have actually multiple questions, so maybe we take them offline. But one question that I wanted to ask now is for the looping variants, and also maybe for the contracting variants, do you try to verify them as well, or.
01:20:02.200 - 01:20:14.410, Speaker G: Do you assume them to hold the invariant? We are verifying them, so you have to manually write them. But if you write them, then basically we are essentially verifying them.
01:20:15.340 - 01:20:16.868, Speaker B: Also the loop invariance.
01:20:16.964 - 01:20:52.790, Speaker G: Yes, also for the loop invariance. So basically we will check whether it holds on entry, and then we will use an inductive proof which says that, like, okay, if it holds on entry, then let's check if for every iteration, if we assume them before the iteration, and then we execute one step, can we prove that it will also hold after the iteration? So it's basically an inductive proof for the contract level invariance. We do the same. We prove that the constructor ensures it, and afterwards, for every function, we will assume in the beginning and assert in the end. Basically, that's the main idea.
01:20:54.200 - 01:21:17.420, Speaker B: And for these functions that you call like underscore, underscore verify something because they didn't want to potentially have conflict. One thing that I've been doing to get an interpreted function is basically to write an extra interface with names of functions, like with unimplemented functions that I want to use as an interpret functions.
01:21:18.080 - 01:21:18.830, Speaker G: Yes.
01:21:19.280 - 01:21:25.410, Speaker B: If you do that, you can also get like an ist for the function and the function call.
01:21:26.340 - 01:22:18.080, Speaker G: Yes, that's a good point. I've also seen other verifiers doing that. But I think our main decision, I mean, we were considering this method, but our argument against that was that. So in that case, I think you will have to include some other source file in your contract. So you have to actually modify your source code a little bit. And what we wanted to actually do is to have the original source code completely unmodified and just include everything in comments so basically, when you would compile this contract with the original compiler, it would still compile and produce the same binary or ast output without these verification specifications. So I guess both methods have their advantage and drawback.
01:22:18.900 - 01:22:24.870, Speaker B: Yeah, I can pause now if people have more questions, but otherwise I still have more questions.
01:22:25.880 - 01:22:34.196, Speaker G: Okay, maybe I will just continue for a while, and then in the end we can discuss, or we can also create a breakout room and take some of this stuff.
01:22:34.218 - 01:22:37.736, Speaker A: Also, just a heads up, we have like seven to eight minutes left.
01:22:37.918 - 01:23:25.376, Speaker G: Okay. Yeah, that's perfect. Okay, so let me just get back to this other classic example, the reintrancy, which is usually illustrated by these simple wallets, where you keep track of balances in terms of ether, and you have some deposit function which is payable so that users can deposit, you memorize their balance, and then you have a withdraw function where the users can specify some amount to be withdrawn. You do some checks, and then you use this call function to make the transfer. If it fails, you revert, otherwise you deduct the amount. And this is a well known bug, like for example, from the DaO for reintrancy. And many of the tools actually, like even the linter from vs code will tell you that you should not use this call because it's dangerous.
01:23:25.376 - 01:24:20.644, Speaker G: And here we also have an invariant which says that the sum of the balances should be less than equal to the balance of the contract. It's less than equal because on self destruct, this contract can receive some funds. So it's a slightly generalized invariant. But also in this case, if you run solc verify, it can tell you that, yes, this is dangerous. There are errors, because when you are making this external call, your invariant does not hold, your contract is in an inconsistent state. However, what many of the tools tend to do is just like if you have a call function, then that's dangerous and you should not use it at all. But for example here, if you actually fix the contract and you first make the deduction, and then you do the transfer, then if there's even a reentrancy, it's not an issue anymore because the check will not succeed.
01:24:20.644 - 01:25:05.860, Speaker G: So this is actually safe to do. And in this case, if you run the verifier, it will tell you that, yes, basically your contract is fine, modulo, of course, your specs. So it can check whether, when you make the external call, whether your contract is in a safe state to make this external call. Okay, so just because that there's an external call, it does not necessarily have to be dangerous. And let me just get back to the final example for this fine grained access control. So here's a contract which implements a simple storage users can store some data, and for illustrative purposes, let's assume that it is now just a simple integer. And we have a flag that indicates whether this data has been set or not.
01:25:05.860 - 01:25:52.500, Speaker G: So we have a mapping for entries. We have an owner who will have some special permissions, we have a constructor to set up the owner, and we have some other functions. So let's first start with a function for changing the owner. And here what you want to really make sure is that it will first of all not modify any of the data. And then it can only modify the owner if it was called by the actual previous owner. And you can specify it with the following tag which says modifies owner if the message sender is the owner. So you can only modify the owner if it is indeed the old owner.
01:25:52.500 - 01:26:38.256, Speaker G: Here, just for illustrative purposes, I introduced the set data private helper function, which will take an entry in storage as a storage pointer and some data. And it will set this data, and it will also set the flag. So since this is a storage pointer, it can basically modify any of the entries. So we just specify that it can modify the entries. Now you have the add function where a user can set some data by first checking that the data has not yet been set. Then it takes the pointer and calls the set data. So now you can specify it that it modifies entries, but only at the address of message sender.
01:26:38.256 - 01:27:29.340, Speaker G: So you are not allowed to modify someone else's entry. If and only if this has not yet been set, then you are allowed to do this modification and you can do similarly for update and so on. Since I'm running out of time, I will not show you that. But what's interesting is that, for example, if you specify update, it will call this set data, which modifies both the set and the data. There's syntactic assignments going on, but since the update will require the entry to be already set, you can specify that it will not actually modify this set field. Because it's true, it should be true. And when you make the call, you set it to become true.
01:27:29.340 - 01:28:17.380, Speaker G: So just because there's some syntactic assignment going on, we can still prove that it's not a real modification. But I guess I'm not going to finish this example. Let me just go back to my slides and wrap things up. You can find these examples in a complete form in the demo. In the demo repository, you can try them out. So, to summarize, I've presented Saucy verify, a source level formal verification tool for checking high level functional properties within code annotations. We have lots of supported annotations and we are using boogie modular verification and SMT solvers to achieve this task.
01:28:17.380 - 01:28:50.644, Speaker G: And you can find it online on GitHub, it's open source. We also have a docker image. You can also take a look at my website or my Twitter, and you can find these examples and some papers. So I guess I'll finish now and let me know if it's still time for a few questions. Or we can also discuss online. I've seen in the GitHub that there's some discussion going on with tags right now. We use this notice because it was the easiest, so we could not really introduce our own one.
01:28:50.644 - 01:29:05.870, Speaker G: Like we could not write, for example, at invariant or at precondition. But if there will be some support for custom text as the discussion is going on, we could also switch to that. So that would be something interesting for us as well.
01:29:07.280 - 01:29:16.940, Speaker A: Okay, thank you so much for your talk. I think we would have time for one more question, if there is any more questions in the room. Ricard.
01:29:18.240 - 01:29:38.870, Speaker B: Yeah, so it looked like when you didn't have the loop invariant, for example, that salsi verifier reported an error. Right. But I would assume that the SMT server in that case would have run up in an unknown. It didn't really disprove the claim, it just didn't manage to prove it.
01:29:39.480 - 01:30:05.420, Speaker G: Yes. Well, in this case, I think the actual report that we are getting back from Boogie is that because there's a loop, the loop will basically have all the variables. So in the end, because of the loop, the conditions will not hold. But I think we could possibly detect that there's a loop going on without some invariants. So we could give some hints to the user that, okay, we are reporting an error, but it might be because there are some loops which are not annotated.
01:30:06.080 - 01:30:22.150, Speaker B: Yeah, because it would be interesting to see when you get an error. I guess what you want is a counterexample. Here's something that violates. Right. And when it's an unknown, it's an unknown. We couldn't prove it. So you need to hint more.
01:30:22.150 - 01:30:25.750, Speaker B: Yes. Boogie doesn't support that.
01:30:27.400 - 01:31:03.810, Speaker G: Boogie has some limited support for generating error traces, but there's actually a different verifier called Corel. It consumes the same boogie language, and that's basically a bounded model checker. So I think what we could essentially do is to first run boogie, to say, to check if it reports an error, or it can prove the property. And if there's an error, then we could do a second run with Corel, which will perform a bounded model checking. But since we already know that there should be an error, it will find a trace, or if it does not find a trace, then we know that the original error should just be an unknown result.
01:31:04.980 - 01:31:05.952, Speaker B: Okay, thanks.
01:31:06.086 - 01:31:08.050, Speaker G: Yes, but, yeah, thanks for the question.
01:31:13.560 - 01:31:17.830, Speaker A: Oh, I was muted. Excuse me, do we have more questions here in the room?
01:31:20.040 - 01:31:54.412, Speaker B: I just wanted to mention all the comments, all the basically dennisations that you have for invariance, loop invariants, preconditions, post conditions, these kind of things. We also want to add, at least I do. Maybe I can convince everyone else to add support to the language, to be able to write those insularity itself. And that's mostly what my part of the session tomorrow is going to be. So it'd be nice if you can join the discussion.
01:31:54.556 - 01:32:16.390, Speaker G: Yes, I'm also aware of act looks interesting. And yes, I think if it becomes widely adopted and supported, then I don't really see any theoretical limitations of, for example, making saucy verify, able to parse, for example, act specifications and then check them.
01:32:16.760 - 01:32:45.328, Speaker B: Yeah, what I mean is, instead of act, so act is going to. Martin is going to present act, which is then an external spec. What I mean is rather the specification inside the solidity source code, for example, having the language support contract invariance loop invariant preconditions, these kind of things with a better syntax than simply just flooding requires and asserts everywhere, which is one way to do it.
01:32:45.494 - 01:32:51.920, Speaker G: Yes, that would be a good proposition, and I'm looking forward to the discussion.
01:32:52.340 - 01:33:17.130, Speaker A: Thank you very much for your presentation. If you have other comments, feel free to keep on discussing saucy verify on the GitHub chat, or also feel free to create a breakout room, and we will move on to the next talk in this room, which is by Mooli, and it will be on Satora, keeping your code secure forever. Move fast and break nothing. Mooli, are you there? Yes.
01:33:19.040 - 01:33:30.496, Speaker H: Yes. Let's see if I know how to turn on the camera. Can you see me now?
01:33:30.598 - 01:33:33.330, Speaker A: Yes, we can see you, but not the screen.
01:33:34.420 - 01:33:43.988, Speaker H: You can see me and not the screen. Now I share the screen then. Now you can see the screen.
01:33:44.154 - 01:33:49.590, Speaker A: Yes. And not me and not you. Yeah. And now click on the camera again.
01:33:50.840 - 01:33:52.150, Speaker H: Just a second.
01:33:53.240 - 01:33:55.128, Speaker A: Yes, this looks perfect.
01:33:55.214 - 01:34:13.900, Speaker H: Okay, let's see that I go to my screen. It's fine. Thank you very much. Fancy. And thank you Akush, for the first talk. Actually made my life much easier. So I want to also make your life easier for the people in the room.
01:34:13.900 - 01:34:49.172, Speaker H: We actually have also a formal verifier and actually you can try it as we speak now it's actually implemented and hosted in Amazon. So what you can do at the moment, if you're not our customer, we don't let you change your code, but you can change your spec and I encourage you to actually try that. It's actually a beautiful demo which was put by Anastasia and REIt from our team. And actually this actually shows you that you can actually, it says actually failed to access my camera. But you can see me, right Francie?
01:34:49.316 - 01:34:53.176, Speaker A: Yes, we can see you fine and hear you fine and see the slides. All good.
01:34:53.358 - 01:35:51.208, Speaker H: Wonderful. So what we are very happy in this space and we hope this will continue. We are finding terrible bugs in this space and terrible bugs in smart contract. And actually I'll give you a little bit hint of how we are doing it. Wait a second, this doesn't move now. So who are we? So we are actually a team which is located in Seattle and in Berlin, in Tel Aviv, Shelley Grossman, James Wilcox, John Toman, Noridor and Alexander Nuch, who's actually here in Berlin, Leo Oppenheim with security expert or pistener, Anastasia Fedotov and Thomas Berandi. And what we are trying to do, we are trying to formally prove like the previous talks that the code satisfied the specification.
01:35:51.208 - 01:36:26.016, Speaker H: But as I said, we are equally interested to actually find bugs. And actually that's the biggest value of our technology. As part of the Ci CD, it's actually find bugs. And just to mention we had the previous talk interactive term prover. These are very powerful tools, they are agnostic to the programming language. They have even completeness in the previous talk we had also by Christian and we hear tomorrow about SMT checker. These work at the solidity level, also the Solsi verifier and the very sold by Microsoft.
01:36:26.016 - 01:37:03.612, Speaker H: So what's interesting about our tool, it operates directly in the EBM code. We think that this is very good. And in fact I'll show you. And the second thing that we do in Sartora and I'll talk about it in the second part of the talk that we are actually implementing clever static analysis that actually can recover interesting information about EVM code. And this actually improves the utility of the SMT. So we see these as two complementary technologies that work well together. So what do we build we build this product that we call continuous code verification.
01:37:03.612 - 01:38:22.332, Speaker H: It's very similar, and you see it in the demo, it's very similar to what ankish shows in one way, in the sense that you give the customer code, but we actually write in a different file, we write a specification, we write a property that says what are the invariant, what are the rules that must be obeyed? And then we feed it to the tool which is hosted on the web. It actually either can give you a formal proof or it can actually give you a test case. And that's actually a very valuable test case that show you input that violate the specification. So the interesting thing about that, that we think that specifications are hard. But once you write the specification, once when you upgrade your contract, or you move to another version of the contract, we can check that your code satisfied specification, and we have already done it with few customers which integrate our tool into the CI CD. So there are unique aspects of that. So one of the things that we say that we decouple the specification from the code, so we don't write this loop invariant in the code, we write them outside the code, and we write them in a high level, in a sense that we want to make sure that we guarantee certain properties that outside user care about.
01:38:22.332 - 01:39:06.890, Speaker H: Like for example inverted operation, the bounded supply that I'll show you later. Maybe you want your transfer to be additive in the sense that if is transfers to D and first it transfers x and then it transfers y, then if it's transfers x plus Y, it should be the same. And interestingly, we can check these properties and either prove them or even more interesting, fine bugs. And the other aspect that is unique about our approach is that we tackle the low level EVM program. So this has some pleasant benefits. So basically we want to make sure that you don't need to change the spec when you change your code. And in fact in some cases we show that we can use the same spec for different project.
01:39:06.890 - 01:39:59.892, Speaker H: And another thing which is interesting, because we operate on the low level code, we can catch more errors. So this means that we can actually catch errors that are not actually caught on the source code and we verify the actual program which is being executed. So for example, if the solidity compiler generates a loop, if the solidity compiler generate, and in fact it does, if the solidity compiler generates tricky memory operations, we can actually check them. So we see ourself as a checker that can be executed after the compiler. So I'll give you a very simple example, and this is example which is in the demo. But there are other examples which are more tricky. So this is a very simple property that any ERC token should satisfy.
01:39:59.892 - 01:41:03.004, Speaker H: And this is actually given by Shamik Islam, which is the head of security at Coinbase. So when they list tokens, they want to make sure that nobody should be able to mint unbounded number of tokens. So formally, some kind of an environment that says that the number of minted token is less than the predefined amount. So let's see of a very nice team which is the makerdao, and this is a team which implement an inverse auction. So what is an invest auction? You start by some kind of a bid which is high, and then you have different guys, Ellis bead and Bob bead. And since Bob beat was the smallest one, then at the auction ad time, after the closing time, basically the number of bids, basically Bob will get the bid and the total number will increase by bob speed. And this is a very nice behavior, but what happened, we run the tool and we run actually the test version of the maker.
01:41:03.004 - 01:41:37.800, Speaker H: We just ran it through this abounded minting supply. And basically what it happens, it found out that if you have Mallory, and Mallory bids very close to the marks and nobody else bid it. So after the bid expiry time at the closed operation, basically the total supply is increased by Mallory bids. And this is actually something that you can execute. Now with our code, we can check it, you can write this back and check it. And in fact, it's one of the examples on the demo. So this is exactly what will happen in the demo.
01:41:37.800 - 01:42:15.984, Speaker H: It will run on each function. And you see, it operates on the EVM code. So you see some data about the EVM and what it tells you, it tells you that all the functions satisfy this rule, but the close can violate it. And it gives you the test case. In fact, it gives you the test case that actually show you that it has this violation. And once you fix the code, it will actually show you that it's actually correct. So how does it work? How does the Satura prover architecture work? So what happened is that we have, the first part is something which is very unique in this space.
01:42:15.984 - 01:42:53.936, Speaker H: We have a decompiler, we have something that takes the smart EVM code and perform clever analysis, and actually it will perform more. This is actually what John has implemented in the Seattle office of Satora. We are actually getting this high level intermediate representation. Think of something like Yule and maybe more, that you can actually extract automatically from the EVM code. This we feed to what we call verification condition generator. So, verification condition is not like the VC that you think. It's what called the VC informal method, which is basically a method that converts into a formula like we've seen in aqua stock.
01:42:53.936 - 01:43:42.428, Speaker H: And this takes the rules, which are from outside, and it takes the intermediate representation, and from both of them, it generates these constraints, it generates this verification condition, and we feed them to existing constraint solver. We are operating directly on the SMT level, so we can feed it to different constraint solver, the whole public domain and great and complementary. And this constraint solver either can give you a test case which actually show you the actual violation, or it can actually give you a formal proof of the rules that hold on all inputs. So this is a very simplistic example. I'm only showing you like kind of absurd account. You see this transfer function, and you see some rules that says that the balance before is equal to the balance after. And you see that there are this constraint.
01:43:42.428 - 01:44:39.460, Speaker H: For each statement in the code, we generate a mathematical constraint which emulates the semantic of that, and we also take the invariant or the rule, and we generate it into an equation that says that you want the Sat solver, you want the SMT, the model, to find a solution to this set of constraints. And each of the solution to this set of constraints, it represent a bug. Okay? So basically you feed it to a constraint solver, and the constraint solver actually gave you a simple but interesting bug, that if you're transferring from an Alice to itself, then in fact this invariant can be broken. So it gives you some kind of an edge case, and once you fix it, it can give you a proof. So I want to talk to you about the EVM, which is the interesting part of this talk, which is sort of what we do technically. So I took a very simple example. It's the banking example, which is also available in the demo.
01:44:39.460 - 01:45:18.044, Speaker H: And it's a very simple, think about it like ERC, or maybe even simpler than ERC. There are functions like deposit, transfer, and withdraw. And remember, you see in Anku's talk that basically he is handling the solidity, but we are not tackling the solidity, we are tackling the EVM. And this has some very interesting consequences. So what's going on in the EVM? So the EVM, you basically have a flat memory. So basically all the local variables and fields are all actually hidden, and the operations are low level operations. So even if you select a field, it becomes a bitwise operation that we know as SMT solver.
01:45:18.044 - 01:45:46.068, Speaker H: That's very difficult. So you make the task of the solver very difficult. And even worse, the control flow and the procedure are really hidden, and even the arguments are hidden. So this makes the life of the verification or even somebody who's investigating this code manually, very difficult. So this is just to show you what happened. It's an output of our tool. So this is one of the stages of this decompiler.
01:45:46.068 - 01:46:24.000, Speaker H: And I'm sure you don't understand what's going on here, right? So basically what happened is that these are nodes that represent the EVM instruction. You can't read it, and so do I, but each of these, it represents some kind of execution of the EVM. And there is an error if one instruction can be followed by another instruction. So you see that these are one thing that you can see here, which is kind of weird, that in the EVM it's all kind of spaghetti, which actually even the procedure structure is lost. So, for example, here is this deposit, if you believe me, and I will not be able to prove. But this is the deposit part. So this is a part of the EVM, which is a deposit.
01:46:24.000 - 01:46:54.876, Speaker H: Here is the risrow. So they're very, very tricky. So reading this code or running static analysis or formal verification of this is very, very tricky. And even if you take this small function, this transfer, which is part of the bank, and you even look at that at a solidity level, it's very, very clear. But look at this instruction. So basically, the access to funds message sender as part of the require. This looks very simple in solidity, but guess this is how it's generated in the EVM.
01:46:54.876 - 01:47:27.056, Speaker H: There are, in fact 21 instruction. You should ask Christian later. But there are 21 instruction here, and this 21 instruction, they manipulate the memory and the stack in a tricky way. So what actually is going on? This funds message sender is actually mapped as a hashing function, which is actually, you concate the message sender and the slot of the fund. And this is executed by means of increasing and decreasing the stack. So you see the first instruction, it puts zero in the stack. The second instruction, duplicate.
01:47:27.056 - 01:47:50.736, Speaker H: Now we put message sender. Now you put this value cleaning, you put another zero. You put the value cleaning again. You put this duplicate, you put this 20 here. So now it's 32. You put this add, you put the swap, you do this store level. And now there is this 32.
01:47:50.736 - 01:48:12.260, Speaker H: You add the 32 to get 64. You put this zero. I'm sure you lost me by now. There is this hashing thing. Now there's zero, there's dot, there's sload. Eventually, trust me or trust Christian, it actually gets you the right solution. But if you want to read it or run formal verification here, it's very, very tricky.
01:48:12.260 - 01:48:54.144, Speaker H: There are a lot of things here which makes SMT even harder than it usually is. And SMT is a very hard problem. So this makes life of people hard. And this is actually where static analysis would be useful. Okay, so what do we do? So, besides using SMT techniques, which are wonderful, we're also using other wonderful techniques and developing our own, which are called Absac interpretation. So there is a well understood theory that says, how do you automatically find environment about your program? And we do that at a low level program, but you can actually execute these kind of things at a high level program. And these prove some kind of absent silent overflow.
01:48:54.144 - 01:49:47.160, Speaker H: For example, we can actually implement something similar to safe mass, but not dynamic. We can actually automatically find something that was similar to Aquustok without even calling the SMT. And this gives you some kind of a sound and potentially incomplete reasoning. But it's not so bad for us because we can actually run the SMT. And from a computational point of view, it's actually sidestepped the problem of undecidability. So what's going on under the hood of this tool? It actually does this sidestepping of undecidability and proves properties of your program by doing this abstract interpretation. So what's going on? You take the state, you take the set of state, and you over approximate the next state, and then you over approximate the next state, and so on and so forth, until you reach what we call a fixed point, a point where the analysis stopped changing.
01:49:47.160 - 01:50:30.388, Speaker H: And at that point, if we actually separate the good state from the bad state, we will automatically be able to find environment about your program. And this happens if your program explores some kind of locality property. And if they don't, then in fact, this will give you a false alarm. But so for us, it's not so bad, because we have the SMT checker that we can run in order to check whether these are right or wrong. So what we do in this space, we are developing this framework that you can think about it like EVM, like LLVM or suit. So these are things that develop academic research project in University of Urbana champagne and also in McGill University. Suit is for Java, LLVM is for C.
01:50:30.388 - 01:51:19.088, Speaker H: So we are trying to do something similar for EVM, and we are exploring the properties which are unique in this space. And I'll be happy to say more, or you can contact John. So we are doing memory analysis, we are doing unused allocation bound checking, we are doing all kinds of analysis, and actually we are an intermediate step and we are doing more and more. One thing which is interesting, that during this process we are finding actually bugs in the solidity compiler. We just found one, and also that we can actually reconstruct a lot of the high level information from the EVM. And this could be useful by itself. So for example here I didn't show you all the code, but you see that actually these are the 21 instruction, and you see that the static analysis actually was able to eliminate the stack.
01:51:19.088 - 01:52:06.880, Speaker H: So you see there's no more memory here, and in fact you see that we are able to recover almost the information of the source. And this is useful whether you are doing static analysis or not. So basically this makes the analysis simpler. I can show you many, many examples that SMT timeout and this will terminate in few seconds. And what it does conceptually, it separates the low level operations which are executed in a bytecode from the high level operation that we are proving, and it will allow us to prove stronger invariant, and actually it makes it more, the bugs that we are producing are more understandable. So the compiler of course has many usages beside formal verification. This is known of course in the community program understanding, slicing, auditing for upgradable contract.
01:52:06.880 - 01:52:50.684, Speaker H: We can check interesting properties and other things. So that's one thing. So I'm almost close to the end of my talk, and I want to somehow say something about more high level and leave a level for other discussion. So we are this space, I've been working on this space for 30 years now. So there are actually many interesting technique in this space, and somehow I like to think about them as how expressive they are and how automatic they are. And this is a very, of course I should say this is a bit subjective, but there have been academic articles trying to compare them. So we heard this morning about tools like K or cock or TLA.
01:52:50.684 - 01:53:39.728, Speaker H: Plus they are proof assistant. They are very good, but they require lubricious effort. I'm just pointing out an academic effort, what we did something for academically in the context of IV, where we tried to compare how much effort are in these interactive term proverbs. And it's a very big effort, and it's even worse in the sense that once you change your code a little bit, you have to redo it. On the other hand, there are a lot of beautiful techniques that developed by many people, including myself, static analysis, and they are very automatic, but they are limited. And what Satora is trying to do, Satora is actually trying to be in the middle somehow. We hope, and of course, this is something that has to be judged, but we hope to be maybe not as automatic, as interactive, but is automatic enough to enable you to show everything that you want.
01:53:39.728 - 01:54:16.440, Speaker H: And even more importantly, when you change the code, find a box. And also we want it to be automatic, powerful. So we want to actually achieve both of them, maybe just sort of for you, for curiosity. Verde is a very nice project by James Wilcox, who is our CTO, is in Seattle, and basically he proved properties of consensus in cock. And every lines of code, every line of the consensus protocol, he had to write ten lines of cock. So that's very tricky. Iron fleet is a project which actually used Daphne or boogie.
01:54:16.440 - 01:54:46.120, Speaker H: And in fact, it's actually also difficult. And what we are trying to do, we are trying to make it very small. And I think we have numbers that show that we actually have very small lines, at least academically, for these protocols. And in Satora, we are trying to be even more automatic. And sometimes we sacrifice precision, but other things. And also we are leveraging a lot of interesting properties about this domain. So we are doing something which is very specific for smart contracts.
01:54:46.120 - 01:55:22.690, Speaker H: So this is my last slide. We want to make formal verification standard for software development. And the interesting thing is that we think that this domain, and I'm of course, academic, but now I'm taking a leave because I'm thinking that this is a very interesting domain for this technology. And in particular, we are interested to explore the connection between proof automation and automatic bug finding. We think that actually, there are actually two side of the same coin. So we don't want to separately look for proof and for bugs. We want to actually connect them together.
01:55:22.690 - 01:55:48.190, Speaker H: And the other thing that we are trying to do, I haven't been able to show you, but you can see our specified language. We have quantifiers, we have hyper properties. We are doing a lot of things that make actually verification at the high level good. And we love to collaborate with the Ethereum foundation and anybody else. And the sad thing is that we operate at the EVM level. Thank you very much.
01:55:50.320 - 01:56:03.970, Speaker A: Thank you. Thank you for your talk. Awesome. All right, we have a couple of minutes left again for questions. First the questions in the room, then the questions in the chat. Leo, you want to say something?
01:56:04.820 - 01:56:32.612, Speaker B: Yeah, thanks, Muli, for the talk. I think it's a very nice and special challenge to talk about high level invariance on the EVM level. And related to that, I took a very brief look at the spec language you just mentioned, and I was wondering, how do you deal, or how do you specify or how do you manage loop invariants in the context of, in the EVM context?
01:56:32.756 - 01:56:48.056, Speaker H: Beautiful question. So that's actually something we ask you. It's very difficult for us at the moment. We have a mechanism for that. I think we discussed with you. We have a mechanism for that, what we are doing, and that's their hope. And in certain cases, we can infer them automatically.
01:56:48.056 - 01:57:11.572, Speaker H: But if not, we have to say something which is specific to the code for us. Usually what happened. For example, if you have a procedure, you have pre and post condition, then it make it easier because we can specify that to the procedure boundary. But you're absolutely right. There are certain cases that actually the source level is something that is better. But remember, where we want to be. We want to be for people who change their code.
01:57:11.572 - 01:57:45.568, Speaker H: And the problem with loop invariant, it's not just a one time thing. You change your code. And as you know, every little change of your code, you change your invariant. So it's true, actually, we are at the moment we want to infer. So if you write, for example, in our specified language, you see there is this notion of set invariant, but what does invariant mean? It's a global invariant. So basically what it does, it checks that before in every procedure, it checks them at the procedure boundary. But if you want to do them at the loop boundary, you actually have to either infer them or do some other thing.
01:57:45.568 - 01:58:10.090, Speaker H: Our tool, by the way, also has the possibility of doing bound and model checking. So you can actually say explore a fixed bound of the loop and other thing. And another thing that we are doing with the static analysis, we infer, actually interesting loop invariant, and I love to elaborate about it. So we can infer quantified environment. We can infer many things which are very hard for SMT, because this is actually my research, as you probably know.
01:58:11.020 - 01:58:28.316, Speaker B: Yeah, thanks. Yeah, we talked about it some time ago, and I was just wondering how it looks right now, because it is a very hard problem and I personally haven't gotten very far. And that's something we're trying to figure how to specify for act, for example, on a lower level.
01:58:28.498 - 01:58:45.750, Speaker H: Yeah, so we should definitely talk about that. We actually have coming code which will probably contribute open source that does an interesting thing that needs this loop environment. So I would love to talk to you, and of course I will attend your session tomorrow to understand what you are heading to.
01:58:46.200 - 01:58:47.270, Speaker B: Cool, thanks.
01:58:47.640 - 01:59:04.850, Speaker A: Okay, we have one more question in the room from AP. We can't hear you in case you're trying to speak.
01:59:14.200 - 01:59:15.748, Speaker B: Sorry, can you hear me now?
01:59:15.834 - 01:59:16.964, Speaker A: Yes, now we can hear you.
01:59:17.002 - 01:59:18.244, Speaker C: Perfect. Okay, perfect.
01:59:18.442 - 01:59:38.120, Speaker B: So my question is regarding the fixed point analysis. Basically the effective smart contracts, even the simple one, have concrete domain of them. It's invisible to find a fixed point. So what are you using it for as your abstract domain when you're looking for a fixed.
01:59:38.960 - 01:59:58.076, Speaker H: Yes, yes. So this is actually a question to John, but he's sleeping, so I'll try to do a good job. So he's adding more and more things as we speak. I think the interesting thing. So you are from this domain. I just don't know how technical to get. But it's one thing that pointer analysis in this domain.
01:59:58.076 - 02:00:22.084, Speaker H: So we talked about it that there are things that llvm and others, but everybody say a lot of bad things about solidity in EVM. But we can say a lot of good things. It's much easier for static analysis than many of this domain. In particular memory allocation. Actually there are no dealocation. So basically we have points to analysis, but it's very simple and we love to say what we are doing. We have interval analysis.
02:00:22.084 - 02:00:48.224, Speaker H: We are adding, and we are adding more as we speak. The nice thing about it, we're working with customers and we see the customer code and see what is needed for this code. And we have the SMT always as a backup. So basically you run the SMT. If the SMT does a good job, we don't have to do anything. But in many cases when the SMT fails, then we actually have to develop more clever abstract domains. And we are thinking of adding more abstract domains to that.
02:00:48.224 - 02:01:04.730, Speaker H: We have basically kind of a framework that we add more and more abstract domains. I don't know if this is understood. I love to have more session and we can show you, but it probably must be later in the afternoon so that John can wake up.
02:01:05.180 - 02:01:16.116, Speaker B: So I quickly looked at the specification language and you can define their roles and actions. Right. So it's not like a predicate abstraction.
02:01:16.148 - 02:01:34.768, Speaker H: That you're doing much more. Yeah, we're doing many more and we should do more. Actually, even though smart contact is a simple domain, there's a lot of interesting properties to prove. And we need to add enough to make it possible to prove these properties. Yeah, so you're absolutely right.
02:01:34.854 - 02:01:36.690, Speaker B: Okay, thank you.
02:01:37.780 - 02:01:57.080, Speaker A: Okay, it seems as if there are no more questions currently here. In the room and also just some discussion going on over in the chat room. So what I would say is we can move over to the next talk by Laura Hana on Dtype and chain lens.
02:02:07.600 - 02:02:10.312, Speaker F: I don't know if you can see my slides.
02:02:10.456 - 02:02:14.124, Speaker A: We can see your slides and yourself. All good.
02:02:14.322 - 02:03:06.860, Speaker F: Okay, so hello all. I'm happy to be here to share with you our latest work and research on btype and chain lens. Dtype is by far the most intellectually and elegant project intellectually satisfying and elegant project that I have ever worked on because it embodies the values that I cherish the most, which are transparency and unity and unity through folding the basic building blocks of software types. So Dtype is a decentralized type system. Dtype's goal is to standardize a common type description format stored on chain so available to everyone. Types themselves are stored on chain, including custom types and this will allow a degree of interoperability that has not existed before. So these are our motivations.
02:03:06.860 - 02:04:12.972, Speaker F: Normative rules in computing must be open to everyone, and an unfortunate counterexample to this is the floating point arithmetic standard which is paywalled and it costs $100 to access it, and webassembly which is supposed to be an open standard and it is built to become the future binary language for software. Building blocks uses it. Anyone should be able to read the full open standards of such a system. Unity if we want to truly build the Babylon tower of software, a convergence to generally agreed upon types must happen. And a good side effect of having an on chain standard is that you can always use it to verify that your software follows it closely and you can use that software, in this case dtype, as a source of truth when bugs arise. So these are our motivations. What is the philosophy on which Dtype is being built? All types derive from the same prima material.
02:04:12.972 - 02:05:20.580, Speaker F: This prima material for Dtype is bit one and it is very real. It is representable on the wire, which means you can use the hardware as an ethylon to mathematics as opposed to other type systems which use abstract ideas like nuts natural numbers. But prima materia can be variable and for example, we are curious to see if dtype will be flexible enough for a parallel typing system dependent on one qubit. For Dtype, types are functions and functions are types. Specifically, all functions with the same output of the same type represent that type and we should be able to travel from the type to prima materia, and this means its input is prima materia or derived from it. Typecasting rules must be defined in the type system, so every type is generated and can be traced back to the initial untyped prima material. The type system should be flexible in terms of encoding and decoding on various hardware, at least for 32 and 64 bit systems.
02:05:20.580 - 02:06:50.900, Speaker F: So is dtype static or dynamic? And you will see it is both in the sense that it comes in two flavors. Dtype is nominative because types can have the same underlying structure but very different semantics, in the sense that you must not be able to add apples and oranges even though they are both unsigned integers. But first, our roots dtype version one was based on clike structs, and it allowed us to start thinking about how such a system could be integrated in ethereum 20 and we advocated for having a special shard for the operating system components such as types, which would effectively act as a global scope for all other shards. And all the links to this can be found in the Dtype repository. Now, Dtype version two is functional, and it is built upon the knowledge that we gathered while building pipeline, specifically the onchain pipeline graph interpreter that we now have live for testing. All types are now based on functions, so pipeline itself can be an editor for creating new types, and the new dtype engine is actually a graph interpreter for functions residing in the same contract, and both compiled functions and runtime created functions in the form of graphs. So I'm now introducing Taylor a suit of Yule Yule plus extensions for using dtype as a type system and pipeline as an interpreted language.
02:06:50.900 - 02:08:19.680, Speaker F: Our target is compatibility with WasM, with webassembly, and with any ethereum vm. Therefore we chose Yule for our tech stack and then we found about Yule plus. So our first step was to introduce our own memory struct in Yule plus with support for d type types to get a sense of what we need and what can be done. And I'm keeping in contact with Nick Dodson from fuel Labs, who will talk about Yule plus later today, and I think it's the fourth talk after mine on how we can make Yule plus support extensions for various encoding and decoding formats. The initial type bootstrap for the Yule plus extension was done with type definitions from a json file where types were defined based on other types, and you can find this in my Yule plus fork in the Taylor branch. This allowed me to more easily extend Yule plus to memory structs containing dynamic types, and we used it to start developing the on chain Taylor interpreted type system based on our pipeline model. So Taylor is functional and comes in two flavors, interpreted and compiled compiled where the Yule plus transpiler extension uses on chain d type data for encoding and decoding, and pipeline can be used to compose types, and in the future type definitions will be shadowed in multiple languages where a pipeline interpreter exists.
02:08:19.680 - 02:09:54.332, Speaker F: So presently Dtype can have support for any type of any encoding, and the EVM is not restricted to only solidity types. So what are the native tailor functions? Type creation starts by using a suite of native functions that will be used recursively, and most of them are pure functions like new identity, config, concat map, reduce curry. But state mutating functions for typed values and a pay function are part of a tailor extension where logic can be built upon the same principles of interpreting graphs. In my last article about currying, I explained how the core of the mechanism works. We currently use four byte signatures for types, and all recursive calls go through execute internal, execute internal tries to call execute native or execute curried, depending on a success variable that each of them returns, and all native functions that I previously showed you reside in execute native in a switch case statement. Virtual curried functions are handled by execute curried, which retrieves the data from a pointer in memory, and the pointer is also the current function signature. The interpreted flavor of Taylor version one is significantly more complex than my article example, and stored graphs for types are handled by the execute graph function, and we also have support for named and sized types, but a run of this system would not fit a slide and would require at least five minutes of explanation.
02:09:54.332 - 02:11:23.724, Speaker F: And if you know pipeline, you know why the execute graph part can become very complex. So these are links to my recent articles, also found on medium on how recursive apply and curing works as a prerequisite reading for this talk. Recursive apply is the engine of functional programming and we have implemented it along with currying in our onchain interpreter. So what types can be built with Taylor? From bit one to numbers to arrays, tuples, union to n dimensional arrays and trees, the types in bold do not exist in solidity and Dtype is made to be compatible with flood buffers and cbore. We are working on type formulas to define a proper set of native functions, and we currently have working implementations for bytes, unsigned integers, static arrays, static and dimensional arrays, and union, and these are based on a typed encoding format. This is one of the encoding formats that we are working on, a typed format where values always come with their type and it can act as an intermediate representation for other types of encoding. So this enables smart contracts to do runtime type checking, and values stored under this format expose their types directly in the bytecode, making raw bytecode analysis more rich in information.
02:11:23.724 - 02:12:24.640, Speaker F: And at the moment we are using a four byte signature for types, and the base types have a hard coded signature format where the last three bytes represent the size. So currently a tuple which you can see on the right starting with EE, also contains the additive sum of component sizes for ease of use. These are the current data structures that we are working with. Each type definition is an ordered array of steps, and each step contains the signature of a type, which is a function, and an array of input indexes. These input indexes are the indexes of the input arguments from the setup all graph local variables that are produced while running the graph. And on the right you can see our current n dimensional array definition using the new reduce config Gettype signature, query and concatnative functions. This is an example of a union type definition.
02:12:24.640 - 02:13:04.830, Speaker F: It only needs a selector index for the component type and the native select function. The selector runtime value is expected to be at position zero in the actual data. So when you define a type that can have sizes, for example uint, you don't need to define every size type. So you don't need to store another definition for uint 256. So you can think about the abstract type uint as a partially applied function. And we also have support for named types. As I said before, you shouldn't be able to add apples and oranges, nor the various CRC 20 tokens together.
02:13:04.830 - 02:14:04.764, Speaker F: So now for a short demo. This is a modified version of the Yule plus extension for remix, and this is the Taylor graph interpreter contract which I will be deploying. And now we are going to insert the definition for the un type and then the definition for the simple array type. And now we are going to call the function for creating a new array. So this is the signature for the execute function, which is the main entry point in the program. This is the signature for simple arrays. It starts with four, four four.
02:14:04.764 - 02:14:57.484, Speaker F: It doesn't have a size because it's the abstract type. All the inputs and outputs are wrapped in tuples. So ee is a tuple of size three, and the next three values will be the additive lengths of the components of the tuple. So our first value, or our first argument is a typed value, and the value is essentially this, which is the signature of the abstract un type, and itself is a bytes value. So that's why we have bytes of type of size four here. So we are effectively, we want an array with un items. Now the second argument is this, which is 32.
02:14:57.484 - 02:16:06.110, Speaker F: So we want an array of un sized 32 elements, which is equivalent to UWinT 156. And the last argument is four, which is the length of the array. So we call this and we get again another tuple with one element, and the typed value is this one. So this is the signature for an array with length four, which contains Uwint of size 32, so 256 in solidity. And the next is the actual value, which is initialized with zero. I don't have time to show you more examples or examples of casting, so I will go back to the presentation. So, to summarize, I have talked about the interpreted flavor of Taylor.
02:16:06.110 - 02:16:16.210, Speaker F: I'm not sure if you are seeing the correct slide, because I am not.
02:16:16.580 - 02:16:18.610, Speaker A: We are seeing further research.
02:16:19.700 - 02:17:20.110, Speaker F: Okay, there was a nice slide with a diagram here, but I don't seem to be able to show it. Maybe I'll show it later. So, to summarize, I have talked about the interpreted flavor of Taylor. The types created on chain can be used for the transpiled version. So Taylor as a U plus extension, providing type definitions, encoding and decoding rules, and type checking. Further research for the near future is an efficient set of native functions, optimizing the steps needed for building and casting types and bootstrapping the tailor interpreter. So it uses tailor produced types and parameterizing based on Vm slot size tailors native sizes and prima material.
02:17:20.110 - 02:18:18.404, Speaker F: This was the diagram that I showed you earlier, so dtype and pipeline go hand in hand. Dtype provides a minimal set of typeless functions, maintains a table of signatures, provides pipeline with input and output choices. Being able to parse the input and output pointers and pipeline helped us turn dtype into a combination of function into combinations of functions ran by an intracontract pipeline interpreter, and will also provide intercontract type processing. And this is how byte one can be represented. It receives bit one as input, which is repeated a given number of times. In this case, eight. Okay, this was the diagram.
02:18:18.404 - 02:19:23.772, Speaker F: I'm not sure if you saw it earlier. And now for the n dimensional array example. The n dimensional array can have n dimensions where n is larger than two, and on the right you can see a representation of an empty array with three dimensions. The first three four byte slots are the type IDs for each subarray with its own dimension, and the fourth fourth byte slot is the un 32 type ID, and then the values, in this case initialized with the zeros. So I showed you dtype Taylor and pipeline what is the purpose of lens? Lens is a browsable and searchable cache for onchain types and it will provide data for editor tools or input for tools like pipeline. And anyone will be able to run it at home because the main data is on chain. But as we well know, most people prefer trusted setups over running their own.
02:19:23.772 - 02:20:12.430, Speaker F: And I think the next level in providing good, common good software data is a system of decentralized governance where companies or individuals join database clusters. So having one company control all the source code is begging for problems. And I for one do not want the next Wasm package manager to follow suit. Our current version of chainlens was derived from our work on the pipeline contract finder where we needed the APIs of already deployed contracts. And if you do not know how to use chain lens with pipeline, check out my YouTube videos. But chain lens only has two types, contracts and functions. D lens will have multiple types and we have around 40,000 contracts waiting to be published on the decentralized database with better search.
02:20:12.430 - 02:21:30.866, Speaker F: So how would d lens look like? And I have a small demo here which will run on Robston. So this is how the current chain lens looks like. It has contracts. You can search through them, browse them and functions, and you can interact with those contracts and functions and then you can export them to other tools. So now let's see what types we already have inserted in the ruption deployed Taylor contract. So we have here some types and I will insert another named type which will be a uwint of size four which will name scarce token. And while we are waiting for the Robson transaction to finalize, I will show you another thing that we have, which is a prototype of a typed database on chain.
02:21:30.866 - 02:22:40.620, Speaker F: So for type u one, I'll click on this button and we'll see the values that are stored now under type u one in this small database. So we have two values, six and seven, and another value under type u two. And what we can do is select some of these values and then we can export them and apply other tools on these values. So while we are waiting for the transaction to finalize, I'm going to tell you why we are building the type length and pipeline in parallel, because the process is slower but it allows us to learn from each of them and it influences how we build them individually. So the dtype lens pipeline flow is as follows. Pipeline handles pure graphs from pure functions provided by lens and it receives input from dtype through lens. And the result is a state transformation graph applied to insert or modify the output which is a dtyped value.
02:22:40.620 - 02:24:14.260, Speaker F: And now we can see the new type that we inserted here and we can add other values to it. But I will return to my presentation now. So if you will port your project to DType, you will be able to generate types from Dtype in multiple languages, do on chain type checking and cost checking, and I don't think you can see the correct slide. Okay, this is a call to arms towards unifying types across languages and I don't think the blockchain revolution has ended and we are betting it will restart on other vectors than money. So defining types on chain guarantees that blockchain programmers will be part of the next software revolution which will come. I view blockchain as a citadel for common resources and computable standards, and many may say that this is very hard to actually achieve, which is true, but I cannot think of a higher scope and goal than this one, and this is why I donated my time to this cause. So after our work for more than a year on DType, we are in the position to launch this hypothesis.
02:24:14.260 - 02:24:29.150, Speaker F: If a decentralized blockchain based OS will ever exist, it will contain its type definitions in its on chain boot sequence and we wish you success in building. And now if you have any questions.
02:24:33.160 - 02:25:10.720, Speaker A: Wow. Thank you so much. Let's have a look. Whether there are any questions in the room, please feel free to raise your hand or just speak if you have a question in the room. Other than that, I will check on the GitHub chat. Does anybody have a question in the chat? So league commented I think this is related. I think the nothing type would have hard time.
02:25:10.720 - 02:25:23.380, Speaker A: Every type can be traced back to prima materia, but I like nothing in my type system. That said, I like the idea of dtype. I just think there should be no dogma constraining the type system.
02:25:24.310 - 02:25:29.880, Speaker F: So the non type is actually an empty tuple for us.
02:25:33.290 - 02:25:51.660, Speaker A: Okay leaky, I hope you hear this. Other than that, if there are no other questions in the room, then feel free to take the discussion onwards in the GitHub chat if anybody has a question later on. And other than that, thank you lu Dana for your talk.
02:25:52.110 - 02:26:19.240, Speaker F: Yes, and related to this, if there will be more questions or the will to collaborate Saturday the 4 May 02:00 p.m. Eastern on Jitsi I will hold a meeting and the link will be posted on the gitter chat for dtype and my twitter account. Perfect. And the slides for this presentation are also posted on my twitter account.
02:26:20.010 - 02:26:53.600, Speaker A: Awesome. Thank you we will also share everything with the solidity twitter account and keep you posted. All right then, let's have a look at the agenda. We are very good in time. We have actually three minutes left before the next presentation is scheduled from Alex. So I would like to kindly remind you that you should drink something and stretch yourself and not sit in the office chair 24/7 is Alex already in the room though?
02:26:55.250 - 02:26:57.890, Speaker B: Yeah. Hey everyone, if you can hear me.
02:26:58.040 - 02:27:34.542, Speaker A: Yes, we can. Perfect. Nice. Yeah, so basically the next presentation, but we can also wait for two more minutes if you like, is on thoughts on language, design and fragmentation from Alex, who is co leading the solidity project. See if there's any other things on the chat. No, does not seem like it. Then let's wait two more minutes in case people are tuning in only for this talk, and then we can kick it off on time.
02:27:34.542 - 02:29:09.840, Speaker A: 03:20 so in two minutes. But now it's 03:20 Berlin time, the scheduled time for the next talk from Alex. So, Alex, feel free to get started.
02:29:18.140 - 02:29:32.368, Speaker B: So we'll try to run the camera, but the computer is quite slow, so if the slides become blurry or anything, please let me know and then I will switch off the camera. Can anyone hear me?
02:29:32.534 - 02:29:40.050, Speaker A: Yes, we can hear you and see the slide, but your camera is lagging a little bit. But you can try it and if it shouldn't work, I will let you know.
02:29:40.840 - 02:30:26.012, Speaker B: All right, great. First, I'm trying to do streaming talk, so bear with me. Okay, thank you, Francis, for the introduction. So, yeah, my name is Alex, I'm part of the solidity team, and in this talk I will go through why I think solidity needs to evolve rapidly. And we'll also bring some examples to show that it did evolve rapidly in the past. And I think this is very useful and it's actually needed. But before we get into some of these details, I will provide some reasons why I think this is like a truthful statement.
02:30:26.012 - 02:31:21.664, Speaker B: But before we get into that, I brought some interesting trivia by digging through the change log, and I think this will show some interesting things at this part. Feel free to maybe interrupt me like once or twice, but there will be a longer time available at the end for a Q and A. So the main net of Ethereum kind of launched in July, August, and the first release of solidity, according to the change log, is zero 10. However, it's not even tagged in git and there's no build anywhere, so I'm not even sure if it exists. But zero one one is the first one which actually exists in terms of a git tag, and it's part of the binary releases, but it's not on the GitHub release page. It was only the next release which is present on the release page. Now going into changes in the language.
02:31:21.664 - 02:32:03.200, Speaker B: The first actual new feature introduced was in 2015, September, with the throw statement. Does anybody remember that still? Yeah, I'm glad it was gone, but you may be able to bring it back for a different reason. In the same year we had the first two breaking releases. So still in 2015 was the first which broke, I guess, the API, it broke the encoding of storage. And also this was the first version I ever used of solidity. And then 0.2 was the first one which made a break in the syntax.
02:32:03.200 - 02:32:53.040, Speaker B: The reason for this change here was because it was kind of ambiguous how to parse the old version without the parentheses. Now moving on to the next year quickly, this was just like three months after there was a new breaking release with 30, which made some preparations for assembly and also made libraries usable. And then moving on. Still in the same year, roughly another like six months later, we had another breaking release. And this had quite a few breaking changes. I didn't list them here, but I counted at least 16. And you guys can see it already had two familiar features of today, the version Pragma and the payable keyword.
02:32:53.040 - 02:33:35.848, Speaker B: Also by three, six. Does anybody remember the old formal verification back end? That's also gone for a long while? And then we had the metadata and just going on to 17. All these features are really familiar to everyone. And as you can see, we had like a really, up to this point, we had a really steady release schedule. We had major improvements every few months, and you can see a big break here. So end of like 2017, we were midway through the 0.4 series, and of course in 2017, the ecosystem exploded.
02:33:35.848 - 02:34:21.790, Speaker B: A lot of people came into the space, a lot of new projects were spawned. So at this point, we got a bit more careful about making breaking changes. And this carefulness resulted into looking back, like two slides back. September 2016 was the last breaking release. The next one was November 2018, two years after the previous one. And this was because of this carefulness that we don't wanted to make breaking changes because people would complain, people wouldn't be happy, and we didn't want it to slow down anyone. But actually what we ended up doing is slowing down people even more because the five resulted in 60 breaking changes and people didn't want it to move on.
02:34:21.790 - 02:35:11.416, Speaker B: It took quite a few releases into five until people finally started to move on. And this was also the first time we ended up releasing a four, like a previous version after five. So we had a 426 release with serious bug fixes because people were still heavily using it. And somehow we managed to repeat the same mistake with six released last December. It took a year after five and not 60, but Turkey breaking changes. So these were some interesting trivia I like, but let's go into the actual reasons. Well, I think all of these changes are actually happening, so reason number one is the goals of the language are kind of shifting.
02:35:11.416 - 02:36:00.984, Speaker B: Initially we wanted to have a really friendly language to attract a lot of people to the space, because both Ethereum as a protocol and as a system, and both solidity as a language were brand new and basically the concept of smart contracts. They did exist prior to solidity, but this was really the first language which made it usable and friendly to people. So the goal was to be friendly and to invite a lot of people. So because of that we chose a design which looked like JavaScript and did a lot of weird implicit things and was kind of easy to learn. So this is what we ended up with people doing. An example from 2015. It's such a lovely piece of code, I guess you can see my mouse.
02:36:00.984 - 02:36:37.700, Speaker B: So there's an interesting line. Because we didn't have the new keyword for bytes, there was no way to allocate bytes here. So because of that there was this nice predefined allocation in terms of spaces. So this was one of the features missing. The second feature missing is we didn't had shifts as it can be seen here. And also there was like a weird bug. The comment is wrong, but the bug was that if iterating the other way around then some fields.
02:36:37.700 - 02:37:18.020, Speaker B: The last field I believe was overwritten by the last store. So this is an example that we didn't have too many features and we were super explicit. Moving on to 2016, here's another interesting piece of code. What is this doing? It's trying to concatenate strings, and we had no such feature at all. Interestingly, we still don't have a feature for concatenating strings, but there's this side effect of Abi encode packed introduced two years after this code was written, which can be used to concatenate strings. So still at the reason one, the goals have shifted. And this is what we had in terms of language.
02:37:18.020 - 02:38:05.460, Speaker B: I think at this point we're not trying to be a super friendly language for people familiar with JavaScript. Rather we're trying to be a safer language, while at the same time also trying to stay friendly in syntax. But the goal is safety. So because of that we have a lot of verbose syntax, a lot of explicit syntax, and we really try to highlight constructs for people, which would be risky. So as an example here, anything which would cause unbounded gas usage is a huge risk because you could end up with a lockup. So for example, there will be tomorrow a session about an explicit copy syntax. So that could be one of the cases where we try to highlight all of these riskiness.
02:38:05.460 - 02:38:59.604, Speaker B: So that's like reason one. Reason two is that Ethereum is still learning the protocol and DVM is evolving the new features added. It's one example, create two was introduced quite a while back. But to fully exploit the benefits of create two, we needed language support, and that also took a while to integrate because of deciding what the syntax should be. Also, these protocol developers create lot of new restrictions every now and then, and they also reprice instructions. And all of these have a profound effect on the language because structures and features suggested prior may become unusable or may become a bit risky as those changes are enacted in the protocol. And lastly, even bigger changes are coming.
02:38:59.604 - 02:39:44.710, Speaker B: There are the new protocols being developed. One example is E 2.0 that also has like a huge effect on the language because it introduces such features which have no concepts in the language right now. Reason three is that the ecosystem, the developers, they're still really learning how to use this language and how to use the whole system, and they're doing all sorts of interesting and weird and maybe sometimes dumb things. And we have to really find a careful balance here in the language between providing them good features. So they shouldn't be just running around trying to implement everything from scratch. But we shouldn't be too restrictive, we shouldn't just tidy hands.
02:39:44.710 - 02:40:40.710, Speaker B: It's really hard to find this good balance between providing enough features but not being too restrictive. And we are constantly trying to figure out this balance, and I don't think we have found the balance yet. Reason four is that experts or auditors, they're also learning. I guess like in 20, 15, 16 when all this started, probably it would have been possible to count the number of experts in EVM or solidity in terms of capable of auditing code. I would have been able to count it by hand, maybe it was only like eight or ten of them. But today it's like quite a healthy ecosystem. We probably have a handful of companies with a lot of people in each who are experts in the complexities of Ethereum, EVM and solidity as well.
02:40:40.710 - 02:41:51.950, Speaker B: And it took quite a while for these people to build all their tools which are needed to aid their work. I want to reflect back here to the three earlier talks we had today from Ricard, Akash and Muli. These tools are really valuable and important because you guys mentioned that you have found issues in the language and issues in the compiler itself, and I think that's really important that we take all of this advice and reports from you guys seriously, and we consider the implications on the language, and we should change the language if that's the right thing to do based on those findings. And the fifth reason is that the solidity community itself is still learning a lot how to do things right. We are trying to figure out which are the features, which the language should have, and which are the features the language shouldn't have, but we should enable people to build those features on top of the language. But I don't mean here that we want everybody to re implement the same things. We want some kind of modularity, and it's really hard to figure these things out.
02:41:51.950 - 02:43:01.744, Speaker B: Also, we still don't know what are good syntactical options and what are bad syntactical options. You're trying to first choose something which looked okay at the time, but probably realized a few months in that together with some other features, it may not be the best way to do it, so it's nicer to change it. And also it's really hard to find a balance between how we're both the language should be or how implicit the language should be. And I think right now we have decided to be on the really explicit side of the spectrum, but it's still unclear whether this is the right approach to take. I think we have to experiment and find out what is the best approach. And lastly, just the way delivering these changes to the actual dev developers, that's also something which was a bumpy ride so far. So just going back to again, another reason probably took quite a bit, because developers rely on frameworks, they don't use the compiler directly and they shouldn't be using the compiler directly.
02:43:01.744 - 02:44:06.920, Speaker B: These frameworks are really useful and helpful for them, but I think at the time, like in four, so like 2018 ish, a lot of these frameworks were still early and they may not had options to rapidly deliver a new compiler versions. I think we have learned over the past like two years how to deliver new compiler versions more rapidly to developers, which also really is really important. And I guess one more note on that, which probably nobody has heard about, but we do have a tool called solidity upgrade or update. I think it's upgrade which can be used. This exists for five and six, and it can be used to automatically transform, in the case of the 50 four piece of source code, to the five syntax. Of course it cannot do everything, but it can do a lot of the manual work. So I think we learned quite a bit how to deliver these changes more quickly to developers.
02:44:06.920 - 02:45:24.850, Speaker B: So I think these five reasons show that we need all of these changes, and we need these changes to happen fast, because we're still really early in terms of the protocol, the language and the ecosystem. I think we are also quite lucky lately that it turned out that solidity is extremely popular. And this is also showed by the two new compilers which have surfaced for solidity. And we're also lucky to have these two new compilers to take part of the summit today. I think Sol will have a talk later on, and tomorrow Solange will also introduce their compilers. And I would like to take the opportunity here to reach out to you guys to say that it would be really nice to work together on the language design, because it's important to have a consistent language across all of these compilers, and it's important to have the feedback from everyone. So I guess what remains now is just to show how any of this design is happening, because probably not everybody is aware that the design process is quite open.
02:45:24.850 - 02:46:25.590, Speaker B: You may think that this is something restricted, and we are like in our dungeons and we discussed in hiding, but it's extremely not the case. All of the discussion, all of the important discussion is really happening on GitHub issues, on the ethereum, solidity, repo. Unfortunately, some of these issues go back to 2016, and it's really hard to get feedback to some of them and to engage people a lot more. But we do have, sometimes we do have ad hoc discussions of getter, or we do have in the team two weekly meetings on Monday and Wednesday. And in many cases, we do discuss some of these features in a more fluid manner on these two mediums. But in every single case, when we do that, at the end of the discussion, we do record our findings on the issues. And lastly, we do have the summit here with the main goal to discuss actual language design questions.
02:46:25.590 - 02:47:35.790, Speaker B: But let's see, how could we move on to the future? So I collected like three different options for going into the future, and the first one is we could have some kind of a focus group, which still tries to have a similar development cycle as we have today. And this practically would mean to have regular meetings to brainstorm some of these issues. So you can think about this as kind of like a mini solidity summit on a regular basis. I guess as we move much more into the future we could have more structured proposals, just like Python peps or the swift evolution. But I think this might just slow down development right now too much, but I think we can take some learnings from them. And finally, I guess in the really far future we could have some kind of a language committee, but I wouldn't advise to consider that for now. So my conclusion is that we need to keep making these changes at the current pace and maybe we should consider this focus group.
02:47:35.790 - 02:47:46.290, Speaker B: I think I don't have too much time, maybe for one question, but I will be hanging out on gitter to answer any questions. Thank you.
02:47:48.900 - 02:48:22.650, Speaker A: Thank you, Alex. All right, we have one or two minutes left if we want to answer any questions. Are there any questions here in the room for people that just joined? You can raise your hand with the raise your hand feature so that I know that you would like to speak. Other than that, I will also have a look in the GitHub chat. Some things going on here about SMT, so I don't think that there is a question from Ricard. Yes, go.
02:48:24.620 - 02:49:44.564, Speaker B: Mean. I'm obviously biased and I might sound know a parrot repeating the same thing, but I'm interested in formal verification and we talked a bit about formal semantics and there's one for salsa verify and there's one for Kay. I think there's like Isabelle semantics for Yule and any. Can you see any way in this workflow without slowing things down too much, where you can kind of integrate a formalism of the semantics or are we still at the level that we're just like all the changes that should happen are just like make changes to the compiler and write some docs or can we add some more formalism in there? I think we, looking at your talk, you highlighted that some of these things are not really well documented and we definitely don't really have too much specification for any of this. We do have some specification for Yule, but I guess that's a different topic. I think I would be really interested to have more of this specified and have a more actually specified way of making these changes. Yeah, I would like to discuss this maybe outside because we don't have too much time now.
02:49:44.564 - 02:49:46.230, Speaker B: Yeah, that'd be nice.
02:49:48.520 - 02:50:16.920, Speaker A: Okay, cool. Is there anybody else who would like to ask a question or comment here in the room does not look like it. There's also nothing in the chat. So I believe we can move forward to our next topic, which is actually the first discussion round of today. And Alex, can you stop sharing your, or just as a heads up, stop sharing your screen?
02:50:17.290 - 02:50:20.360, Speaker B: I think I did, but it just.
02:50:20.810 - 02:50:48.078, Speaker A: Okay, okay, sorry. All right. Yeah. So now we are moving over to the very first discussion round of the day, which will be about Safemas by default, moderated by Chris. And I believe, Chris, you will also give a little intro into the session just before we start for the open discussions. They will usually be introed by somebody. So explaining the problem or the thing that we would like to discuss.
02:50:48.078 - 02:51:17.320, Speaker A: And we also prepared the hackMD documents per session so that if you, for example, have an idea, proposal, or want to comment something, you can collaboratively do this in the hackmd. So let me put the hackmd that we will be using now also into the GitHub chat, and you can also find it in the Google agenda, both on the sheet as well as in the calendar entry. Have fun.
02:51:19.130 - 02:51:20.398, Speaker B: Thanks fancy.
02:51:20.594 - 02:51:30.060, Speaker A: And Chris, maybe click on your camera again, or not, however you like. Yes.
02:51:31.410 - 02:52:10.440, Speaker B: Cool. Yeah, first, I'm really happy. This was a fantastic start for the summit. It might get a little bumpy now, so let's see, because we're trying something that is very different. As Fancy said, I will introduce the discussion group with a short talk and then the ideas that we will discuss together. So if you're listening in from the YouTube livestream and want to join the discussion, then please move over to the jitsi room. But you still have some time, so I'll first do the talk.
02:52:10.440 - 02:53:38.834, Speaker B: Okay. Safemath Safemath is the name of the library by openzeppelin that implements checked arithmetics, also runtime checked arithmetics, and it is used by almost every single smart contract out there. So we thought that maybe it's time to move a feature like this into the language itself. It has not yet been part of the language for several reasons. The first reason is that the old optimizer, so the optimizer does not operate on Yule, cannot really cope well with conditionals because they involve jumps, and depending on the type of the jump, it has to clear its internal state representation. And another reason is that it's so you may have noticed that the open zeppelin implementation is only for uint and int, so only for the 256 bit types, and we would have to implement it for all the whatever, how many types. So this is a complication, and maybe at least for me, the most important reason is that it might just about create a new kind of new class of bugs in smart contracts.
02:53:38.834 - 02:54:25.822, Speaker B: Because an addition and a multiplication, if we add that, then an addition or a multiplication can always revert. And if this condition for the revert. So if you have your smart contract in a situation where it will always produce an overflow, at that point it is fully stuck and you might not get your money out or whatever. So adding runtime checks for overflow does not free you from thinking about overflows. That's maybe the takeaway here. Okay. And yeah, in this discussion session, I would like to make decisions on three things.
02:54:25.822 - 02:55:24.386, Speaker B: The first one is whether or not we want to have it at all. The second one is whether the failure will result in a revert or in an invalid opcode. And the third one, we would like to have the ability to switch off these checks. And the question there is how granular should it be possible to just switch off all the checks, or should you be able to select which checks to switch off? So, on to the first question. No, sorry. Yeah, so this is the proposal on how it would look like. Then we would switch the checks on for a breaking release, and you would have a keyword called unchecked that would disable the checks on the brace delimited region that follows.
02:55:24.386 - 02:56:47.700, Speaker B: So t equals x plus Y would not revert on overflow, but the x plus y here, that is outside of the unchecked region, that would revert on overflow or would cause an invalid opcode. And yeah, what I find really nice about checked arithmetics as part of the language is that you can write mathematical expressions just as mathematical expressions, and you do not have to write them in functional notation, which is maybe not that difficult or not that hard to read for this simple thing. But if you are thinking about more complicated, I don't know, financial constructs, then this gets complicated quickly. Okay, maybe before we talk about what we'll do on failure, should we open the discussion to whether or not to have it at all? Are there any people who think it's a bad idea to add that feature at all? Or are there people who think it's a very good idea?
02:56:53.100 - 02:56:59.420, Speaker A: Ricard wants to speak. And then after that, Mr. Chico.
02:57:01.920 - 02:57:02.284, Speaker B: If.
02:57:02.322 - 02:57:04.940, Speaker I: You might mean me, with Ricard.
02:57:05.360 - 02:57:06.280, Speaker A: Oh, yeah, Ricard.
02:57:06.360 - 02:57:06.892, Speaker F: Sorry.
02:57:07.026 - 02:57:37.972, Speaker I: No worries. It's a good idea. Because also, what we realized before was with our contracts that we updated to the 0.5 version. And now if it goes to 0.6, very similar, that open Zeppelin would first have to upgrade their library before we can actually continue using open Zeppelin. And if there is a delay, then this means we would have to wait for them or copy their classes into our repository and make the changes required to make them compatible with a new compiler if this is required.
02:57:37.972 - 02:58:07.120, Speaker I: So for the changes from 0.4 to 0.5, this was required for certain open zeppelin related classes. And this would obviously prevent this, since if it's built in, then you don't have like it's part of the compiler. So therefore I think it's a very good idea to have safe math and also to be able to deactivate it, because there are places where I personally like to use the overflow to do some magic, but I think it's good to make this explicit.
02:58:14.330 - 02:58:16.166, Speaker B: So there were other people.
02:58:16.268 - 02:58:19.558, Speaker A: Cool. Thank you, Martin. Mr. Chico, next.
02:58:19.724 - 02:59:20.970, Speaker B: Yes. Yeah, I just wanted to say about the previous comments, which I like that. I think it also highlights another issue which we're not discussing here. So I'll just make this brief, but I think there is in general a problem that arises with compiler updates where you want to rely on a contract that uses the previous version of the compiler. It gets sort of complicated to use it in the same workflow, but without opening up that can of words. I just want to say that it might be problematic that it uses the same syntax that the safe math by default as the current version, while introducing new semantics. And I was wondering whether you have considered introducing a new type that uses safe math by default.
02:59:20.970 - 02:59:39.060, Speaker B: No, not yet. Another option would be to use a different operator.
02:59:42.810 - 02:59:52.250, Speaker A: Okay. Other than that, we also have Daniel and Miguel who would like to say something.
02:59:52.320 - 02:59:56.762, Speaker B: Daniel, I just wanted to say, actually.
02:59:56.816 - 03:00:02.220, Speaker I: We do consider using different types, but in the sense of using.
03:00:04.910 - 03:01:55.550, Speaker B: Actual number range types, and not necessarily power of two integer types as usual types, because the checks for the overflows will be similar regardless of the sizes, to the ranges of the types, but that will cause other complications. So that's not the longer term goal than the checkmath we are talking about here. Just as a minor note, I mean, what would the benefit of using a different type be instead of unchecked? So the reason why we think it's, or at least I think it's better to use it on the existing type system, is that most of the people already use it anyway. Right? So use safemouth for open separate. Yeah, I think they do in a lot of cases. And I think the process of explicitly including Safemath as a library makes people aware of the fact that it overflows and exactly as you mentioned, the cases where your contract might end up being stuck as a result of this is something that is taken into account while going through the motions of including safe map. And also just with the sort of reflexive understanding that people have of how solidity operates would need to change quite a lot if people were to understand the default operation as doing this overflow check.
03:01:55.550 - 03:02:22.150, Speaker B: And that's just why I think that one can at least consider having a different type, call it integer or whatever that still has a range that it is bounded to. It only has a different semantic meaning assigned to the operators that it. Yeah, Sean says arithmetics.
03:02:23.450 - 03:02:29.080, Speaker A: Yeah. So there's Miguel, Sean and Nicholas who would like to say something just as a heads up.
03:02:31.470 - 03:03:55.962, Speaker B: Yeah, maybe we should keep it a little bit focused. So let's note down the option of having different types or different operators, maybe. And then, sorry, who was the next Miguel? Hello. I agree that it's a great idea to include Safemath by default, but I think that we should let the developer choose if he wants to use it or not. I mean, it's a good way to do it with the programming language, but I'm also thinking about the possibility to choose it in the compilation process, just using a flag or something like that. And I also wanted to say that from my developer perspective, and if we include the sitemap by default, we are going to reduce the error tracing.
03:03:56.126 - 03:03:56.454, Speaker I: Right.
03:03:56.492 - 03:04:10.440, Speaker B: Because we cannot include error messages in this way. Or am I wrong? Yeah, that will be part of my slides later. Okay, thank you so much.
03:04:11.930 - 03:04:15.518, Speaker A: Then there's also Nicolas Venturo.
03:04:15.714 - 03:04:20.700, Speaker B: Yeah, my question was actually related to the reverb reason he just mentioned, so we can carry on.
03:04:21.630 - 03:04:24.330, Speaker A: Okay, Sean, was your part covered?
03:04:24.490 - 03:04:47.480, Speaker B: One comment on the flag. The difficulty I see with the flag is that if you write a library that works with checked arithmetics but does not work with non checked, then it will break depending on how you compile it. So I think it should either be a pragma on the full file or something like this. Unchecked thing.
03:04:56.530 - 03:04:58.080, Speaker A: Yes, Sean, please.
03:04:59.970 - 03:06:05.650, Speaker B: I just want to make the same point as I made in the GitHub chat, that an unchecked region is rather not very granular and it would affect all mass operations in that. And if you would replace the arithmetic operators with simple intrinsics, then it becomes much more clear what is checked and unchecked. You mean your proposal is to have different operators for checked addition and unchecked edition? Well, what I mean is an unchecked add built in function. So as I showed in the GitHub chat, you do so a unchecked underscore add and then the other argument. But we already do have that with safemouth from Openzeppelin. So if you want to have something like that, then there's no support by the compiler needed. Okay, so why have the unchecked regions then? Sorry, did it.
03:06:05.650 - 03:06:32.990, Speaker B: So did you say a function for unchecked addition? Is that what you said? I can't find the message you're talking about. Um, well, just a point that unchecked regions are not very granular. So if we already have an unchecked ad, why would we add unchecked regions?
03:06:45.970 - 03:06:48.666, Speaker A: You're muted, Chris, in case you're talking.
03:06:48.788 - 03:07:09.710, Speaker B: Sorry, inverted button. Yeah, because operator notation is always easier on the I than function notation. That's the least. So I see there's no consensus on having checked arithmetics by default. Is that the case?
03:07:10.400 - 03:07:17.100, Speaker A: We could also do a poll if you like. A quick yes no poll.
03:07:21.920 - 03:08:47.916, Speaker B: Well, many of the concerns have been around what features would it have and how to be supported. So perhaps if we continue with the other topics I had in mind, we can then come back to this, given how you envision this feature. Yeah, I think all the options we talked about now are, as you say, can be implemented in a similar way. And it has already been mentioned that the question is what would happen? So is it possible to have an error message? So the question is, should we have an invalid opcode or a revert on failure? The problem with an invalid opcode is that it would consume all gas, but it is already used for internal checks, or at least that's the idea there. And it is kind of an internal check. So it's not something like invalid input, at least not necessarily. And the good thing, the benefit when we use an invalid opcode is that static analysis tools can check, if they can check it on the EVM bytecode level, whether such an invalid opcode is reachable or not.
03:08:47.916 - 03:10:02.912, Speaker B: And because of that they can differentiate between arithmetic overflow that is desired, because you really want to have wrapping arithmetics or overflow that is not desired. And if we use a revert, then the compiler can specify an error message. It would not consume all the gas, but it would not be distinguishable from this error case, would not be distinguishable from other revert cases or from inverted. So this is something I've talked to with some people at NCC, and if we use an invalid opcode, then this prevents you from, or this forces you to think about the overflow case because if you use these tools, then they will say, oh hey, here is an error condition. You haven't checked that. And the way to check it, of course, cannot involve wrapping arithmetics itself. It has to work differently.
03:10:02.912 - 03:10:50.500, Speaker B: And my proposal would be to do checks not based on the actual overflow, but think about sane ranges for values like, I don't know, ten to the 20 tokens, ten to the 20 units of some token. Nobody will have ever more than that. So we can just restrict the range to that and then we will not have an overflow. And this has the added benefit that it makes these failure conditions visible to people reading the source code. Okay, so opinions about embedded opcode or.
03:10:50.670 - 03:11:04.540, Speaker A: Yeah, there's lots of people who would like to say something and who raised their hand during your presentation. Nicholas was raising his hand for a while, and then after that, please, Christian. And then Lucas.
03:11:06.320 - 03:11:40.504, Speaker B: Hi, this is Nicholas from the open sapling team. I wanted to mention something about this, and it's actually two things in one. Bear with me. One thing that I wanted to mention is that not all overflows are made equal. And sometimes you may do a subtraction that goes below zero, but that is actually not an arithmetic overflow, in that values are of range. But for example, you're doing an ERC 20 transfer, and the account that is actually doing the transfer doesn't have enough tokens. So in that sense, the required statement that you would write holder must have large.
03:11:40.504 - 03:12:24.808, Speaker B: The tokens that they have must be larger than what they're trying to transfer. That is not actually an artistic overflow. And the sort of revert reason you would want for that is account doesn't have enough tokens, not just like math error. So I was wondering, in a case such as this one, where you require beforehand for the values to be in a sensible range, and therefore you know statically that the addition will never overflow. Would the compiler be able to not emit the actual runtime check because it's able to infer that condition? Or would the check be in a way performed twice, first by the range check and then at the actual moment of the addition? So I hope that the optimizer will be able to remove the check in that case. Yes. Right.
03:12:24.808 - 03:12:59.156, Speaker B: So you write the required maintenance statement and then just your own operations, but you decouple those DRs method and the actual error checking in the case of, say, not enough balance. I didn't understand, sorry. Yeah, imagine you have a near transfer and you have to check the balance of the account that is doing the transfer. Has to be larger. Has to be smaller. Larger, sorry. Yeah.
03:12:59.156 - 03:13:11.530, Speaker B: And you write the required check and then you would have exactly the same check again for the subtraction. Right? Yeah. And I hope that the optimizer can remove the second check. Correct. Awesome, thanks.
03:13:12.380 - 03:13:13.980, Speaker A: Okay. And then Christian.
03:13:14.480 - 03:13:34.496, Speaker B: Hi, Chris. Hi Christian. Actually, you said that the problem with revert is that we don't have custom error types, but this is what we wanted to implement. Right. We have at least a proposal file, then people should be able to distinguish between overflow. The compiler will emit the error. So there's no way to.
03:13:34.496 - 03:13:58.680, Speaker B: Where would you write the. Yeah, the compiler could, I mean, if you have revert, then everything's fine. Then you can specify detailed errors. Yeah. At least the compiler can specify detailed errors. Yeah, that was my thinking. The other thing, maybe I skipped it, but I don't see the negative arguments for your unchecked proposal.
03:13:58.680 - 03:14:20.690, Speaker B: Why are people against it, against this unchecked keyword? Because we have counterproposits. Just because we have other proposals and we need to decide for one. Or is stay with revert invalid for now? Okay, at least come to one decision. Revert with customer error type.
03:14:22.580 - 03:14:26.096, Speaker A: Okay, so we have Lucas in the pipeline.
03:14:26.208 - 03:14:30.436, Speaker B: Yes, hello. I just want to quickly say that I fully agree that this should be.
03:14:30.458 - 03:14:32.550, Speaker G: An invalid opcode, because.
03:14:34.360 - 03:14:53.964, Speaker B: If you run into this in a checked environment, it is something that should never be reached. And that's like an assertion. So yeah, it should be an invalid outcode. And additionally this scenario open zeppelin raised.
03:14:54.012 - 03:15:02.288, Speaker G: With this, doing balance checks in the safemath. I hated this every time I saw this.
03:15:02.374 - 03:15:18.200, Speaker B: And yeah, you need to write your own require then before this check is run by safemas. Okay, thanks.
03:15:18.650 - 03:15:21.590, Speaker A: Okay, then we have Patricio Palladino.
03:15:24.970 - 03:16:12.934, Speaker B: Yeah, hi, this is Patricia from Nami Labs. I just wanted to mention that even if these checks have an error message, it has to be pretty generic, something like mass overflow or something like that. And if that's all you get when the transaction reverse, it's not very useful. It's pretty much the same than just having an invalid code, because if you have a lot of code with a bunch of mathematic operations, you can point which of those overflow. You're saying that the user will not be able to make sense of that message. Right. It's much better if the source code has a specific message balance too low and something like that.
03:16:12.934 - 03:17:05.174, Speaker B: Right. It's pretty much the same than using Malidobco. You just get an extra video of information that tells you, okay, this error is related to math, but that's it. So to have the complete picture, an external tool should analyze the execution and point into the error, but that's already the case. So to summarize, I'd go with invalid code because having a rebar doesn't add much value to the developer. So it looks like everyone seems to be on the same page, at least with regards to that. Is that correct? Or at least most of them.
03:17:05.212 - 03:17:13.420, Speaker A: Yeah, we still have Alex and Leo in the pipeline who would like to say something. Alex, please go ahead.
03:17:17.710 - 03:19:32.940, Speaker B: Yeah, I just wanted to add a brief comment on the revert and the revert message. I think especially for this case, it would be much nicer to consider the debugging options and maybe some other ways to, you know, based on on where the invalid opcode was caused, and use debugging info to find out which operation caused it, as opposed to including a revert message. I just didn't really see this as a useful feature, but maybe wanted to get some more feedback why people would want to have a message, because that seemed to be the reason for revert. So Leo wanted to speak to yeah, I'm not saying I'm opposed, but to go for invalid with the argument that this code should never be reached in a checked environment assumes that people will put requires to prevent the overflows in the first place. And from discussions a while ago, this was the same reasoning from what I've been told, why Zeppelin started safe math with assert and then with the not entirely assumption, but with the wish people would write their own requires and the assert would then catch cases that were not caught by requires that people wrote, but then people never wrote requires because the revert effect is the same in the end. So I think this should be considered the requires people not write requires. I remember the discussion, but I think the thing is, people used safemath before, and then we were upset because you couldn't activate the SMT checker for people using safemath.
03:19:32.940 - 03:20:44.736, Speaker B: But for this the issue is different since it's an internal check and we can do whatever we want in the SMP checker. And concerning bytecode level analyzer tools, this is usually something people choose to use. So they first say okay, let's run the bytecode analyzer tool on my code, and then they are already convinced that it's a good thing, so that might motivate them to add missing require statements. Well, it's not only the synthetic checker, it's a conceptual thing, like whatever is asserted is something that should never happen and this turn instead into an input filtering. If all you care about is not overflowing, then it doesn't matter which one it is. And of course if you care about giving a nice message like you don't have balance or whatever, then of course a required is nice earlier on from whoever's writing the code, but for the effects of rewarding the effects is the same. And it's just about the conceptual idea that an assert should never be reached.
03:20:44.736 - 03:21:17.650, Speaker B: Like an assertion failure should never be reached, and in this case overflow checks are used mostly for input filtering. So to me conceptually doesn't fit as much, but I'm not going to use that as an argument to oppose it. Yeah, I think it's the difference. I mean if you want to write a quick and dirty contract then you can rely on the compiler doing the overflows. But if you want it to be nice and have nice error message, then you might want to add the requires. At least that's my hope.
03:21:19.780 - 03:21:27.120, Speaker A: Okay, so timing wise we are already in the break. I think you have a couple of questions left, right Chris?
03:21:29.160 - 03:21:32.516, Speaker B: Yeah, but we can skip them I think so.
03:21:32.538 - 03:22:04.300, Speaker A: There is also a lot of discussion going on actually in the getter chat itself, where people pointing out their points as well as on the HecMD. I hope you saw this. Anything you would like to say to wrap this up, or what? Do you have any other question left?
03:22:04.990 - 03:22:30.490, Speaker B: Yeah, I think we have to come a conclusion on the main question, what should the default be? But yeah, it looks like this discussion slot will not come to that conclusion, so maybe let's continue the discussion on the issue.
03:22:33.580 - 03:23:17.830, Speaker A: Yeah, did you put the issue links in the hackmD? Otherwise I think this would be a good idea to link all issues there. Yeah, somebody's asking already for the link to the GitHub issues so we can continue the discussion there. Thanks guys, that was really nice. So now we have a couple of minutes left for a short break where if you didn't get enough of us yet, can hang out in the lobby. But I will certainly take a break and close my eyes for a second or look somebody somewhere else. We will reconvene here at 425. So in ten minutes german time for a next discussion on libraries 2.0.
03:23:17.830 - 03:23:24.090, Speaker A: See you in a bit. Daniel Streamer if you're there we can.
03:45:00.880 - 03:45:53.508, Speaker B: Marking parts of the country to explore, but in my experience the issue most people have with it's too expensive. So why have this when I can just inline? And if by issue there are more efficient ways to split it. If you just mark parts of the contract, then calls between these parts will get rather expensive and that's not really visible. Yeah, I have no idea how that look. Hopefully you'd be able to split your contract into different modules. And perhaps what this would do is make it easier to deploy and make sense of your system as opposed to having a very complex deployment strategy where you deploy the different contracts and then link them all together. So that's an area where the language could provide help, but I don't really know what shape that would take.
03:45:53.508 - 03:46:50.392, Speaker B: So I mean that's maybe going towards the functional session I was referring to. But what about we just group functions? So we define a bunch of functions and group them and give that group a name and call it a module. And then a contract consists of multiple modules, but you have to call, and you can call functions inside the same module directly as we do it now. And if you call functions of a different module that is still part of the same contract, then you have to write module name function and it will use delegate call. Yeah, and the contract is a collection of modules. I think that's an interesting idea to explore. My main point is I don't see why anyone would nowadays use an external via delegate call unless they're hitting the byteload size.
03:46:50.392 - 03:47:04.330, Speaker B: And even then there are likely more efficient ways in terms of gas to do that split, which is why I think they're not being used. Do people hit the bytecode size? And if yes, what do they do?
03:47:12.400 - 03:48:17.696, Speaker I: So actually we hit the bytecode size with ignosa safe contracts, right? So this is a exceedingly large contract. And I know we had discussions before about this whole thing, should we enable the optimizer or not? And there was all this logic around that. And since we actively decided against the optimizer for now, and therefore we started this exactly this thing with the modules, right, where you could split out certain logic, which is very explicit, and then we use delegate calls or you have to allow them, but it's not very universal, it's very explicit and it's actually very complicated to. I do agree that if libraries with delegate calls and you can mark certain code to be excluded and maybe, or external, which can be then swapped in, would be very nice. But I think it should be a little bit more explicit than it is right now with the libraries. And this use case of going around the size limit is very special and I'm not sure how often. I think most of the people in our case would have just enabled the optimizer.
03:48:17.696 - 03:48:20.168, Speaker I: Let's say it this way, but I.
03:48:20.174 - 03:48:27.160, Speaker B: Mean, the optimizer doesn't reduce the code size too. There's always a limit.
03:48:28.140 - 03:48:29.770, Speaker I: Like a little bit actually.
03:48:31.500 - 03:48:32.056, Speaker B: Right?
03:48:32.158 - 03:48:36.590, Speaker I: Yeah, exactly. Like right around the limit. It helps. Again, for us it was not.
03:48:39.680 - 03:48:41.388, Speaker B: But what did you do in the end?
03:48:41.554 - 03:48:47.708, Speaker I: In the end, basically we tried to really, like, we had to do what you did with libraries, but we did.
03:48:47.714 - 03:48:48.108, Speaker B: It a little bit.
03:48:48.114 - 03:49:30.990, Speaker I: Like in the safe has this concept of modules, right, where you can whitelist certain other contracts to interact over the safe, kind of, or like in the name of the safe, which then is similar to what you do with the libraries. Basically you export certain code into other contracts and allow these contracts, or like call these contracts and allow these contracts to interact back with your original contract and on the save. Obviously there were other motivations too. That's why it worked out for us. But in general, this is something where I think having something that is a little bit more built in and a little bit easier to do, and in this case maybe also more secure because it's a more provided concept, might definitely be helpful, but it's still a very special.
03:49:37.160 - 03:50:21.040, Speaker B: Okay, there was. Francisco wanted to speak. Yeah. Can you hear me? Yep. Okay, so I was thinking, the problem with using libraries for splitting a contract to make it fit in a block introduces the problem that you now have to make the arguments explicit, because the library can't read them directly from the state variables. And if you want to make it as optimal as possible, you need to essentially put all of your contract state into a struct and then pass that as a storage argument to the library function. And this is very different to how people actually program solidity.
03:50:21.040 - 03:51:03.760, Speaker B: So I think that's a big barrier for using the library mechanism to split a contract across multiple blockchain contracts. So if that was the goal, to give people a tool to split a contract, I think we would have to look into better ways of sharing the storage layout. Maybe a library 2.0 could say, I'm going to use the same storage layout than this other contract. I think that would be a big issue to solve. But this modules proposal, I should have written it into the slide. That would solve it, right? Yeah, that's an alternative.
03:51:03.760 - 03:51:39.820, Speaker B: The main difference between that modules thing and the libraries is that initially we thought libraries could be reused across projects and that's why they should be separate from contracts. But that didn't turn out to be. Yeah. It's interesting to notice though that if we're talking about code splitting, it's quite orthogonal to code sharing across projects because you split a contract, you're not going to share that with anyone else because it'll be quite specific to one contract. So I think those two discussions can be separate.
03:51:54.590 - 03:52:12.680, Speaker A: Okay, we also had a couple of points in the GitHub chat. Did you see those? Chris?
03:52:15.690 - 03:52:17.910, Speaker B: Very hard for me to follow the chat.
03:52:18.490 - 03:52:47.940, Speaker A: Ok, so Patricia said, I agree with Nicolas that the only common use of libraries is because of the bytecode size limit. Nick Ward said, as another bytecode size limit data point, moloch version two is undeployable without optimizer enabled and then the link to Molok Ventures code. And Patricia says, I've seen many contracts lately enabling the optimizer with runs one just to reduce the bytecode size.
03:52:57.260 - 03:53:07.210, Speaker B: Francisco yeah, something different. Forgot what I was going to say.
03:53:10.000 - 03:53:37.478, Speaker A: No worries then. Think about it again. There's also one more comment on the GitHub chat from Volflow. I hope I'm pronouncing this right. A solution I have used personally is to break contracts up logically, not just by bytecode sections, I. E. Structured more similarly to multicolateral die, with logic split between smaller contracts and permissions enabled between them.
03:53:37.478 - 03:53:47.070, Speaker A: My main concern with the delegate call solution to bytecode size is exactly what was just said, that storage layouts are very tricky to match up and to maintain.
03:53:51.300 - 03:54:40.850, Speaker B: Yeah, I remembered. So with regards to sharing libraries across projects, I would say that the issue there is the tooling. As far as I know the way for people to do that is using for example truffle's link method. And then I don't know that there are nice tools to share these addresses. So maybe for example, that's something that ethpm can solve. But if code sharing was something that we wanted people to use, we would have to make sure that the tooling was right for that. And I don't think it's up to the task yet.
03:54:40.850 - 03:55:20.460, Speaker B: Yeah, I mean I think code sharing is secondary concern. So about this matching up the storage layout. So I mean, unless we share code between different contracts then this is not an issue, right? Because the code that is delegate called into is deployed at the same time as the main code and compiled from the same source file.
03:55:30.500 - 03:56:16.464, Speaker A: We have another comment on GitHub. Cairo says, I just hit the bytecode limit today with a factory contract that deploys other contracts, but I could work around it as I needed an efficient factory anyhow, and split up the code to deploy into a prototype contract deployed separately, and then use EIP 1167 proxying. Did you freeze Chris, or are you.
03:56:16.502 - 03:56:19.220, Speaker B: Just thinking, just thinking.
03:56:19.370 - 03:56:43.320, Speaker A: Good. And another comment on GitHub. I'm just relaying them all to here, unless you guys want to discuss further. Could it be possible for the compiler to split a large contract into small contracts itself, so that it would take care of the storage layout and the delegate call?
03:56:46.320 - 03:58:34.196, Speaker B: I mean, it would take care of the storage layout and the delegate call anyway, even if you split it up explicitly, right? I mean, splitting up is hard because you have to find two groups or multiple groups of functions that do not call each other regularly because these calls are expensive. And the problem with that is the compiler doesn't know what regular means because it doesn't know what a common use of the contract is. So just because there are many calls in the source code doesn't mean that these calls are used often. So I think if we do something like splitting, then it has to be explicit by the developer and cannot be done automatically by the compiler. But Nicholas has a different opinion. It seems truffle can do mean is that something people would use just explicit marking of functions in contracts to be split and then auto delegate call between the marked sections. I wanted to point out something, this is not an EAP yet, but there's been discussion about this on the dev ring by Vitalik.
03:58:34.196 - 04:00:37.740, Speaker B: Mainly there's been lots of discussion around increasing the gas cost for the call and static call and delegate call upcodes based, making them proportional basically to the size of the bytecode, basically favoring smaller contracts and more modular systems. I don't know what state this is in, but it had some level of support, and I believe this is a direction that the ecosystem might go forward in the future. And in that sense it does make a lot of sense for there to be better support for language to build multi contract systems. There is some now in the form that you can say new contract and deploy contract from its head and R one and get its address, but it may make sense to explore more deeply this idea of modules. What about dynamic libraries or access to delegate calling a function on a contract? Is that something people want? Okay, maybe we rather discuss that in the upgradable contract section. Yes, all the use cases that I can think of off top of my head have to do with upgradability as opposed to reducing bytecode, and it's mainly because of the increased gas cost that an external library in place. This is a sort of tangential question, but would you be able to tell us how optimal the bytecode produced by the compiler is? Just trying to get an idea of maybe before going in a direction of splitting a contract.
04:00:37.740 - 04:01:31.330, Speaker B: There is more work that can be done on optimizing the size of the bytecode. You mean how close it is to the limit? No, I mean how optimal it is. But that's a very subjective question. So what is the optimal, speaking about bytecode size specifically? So someone suggested, for example, using the optimizer with runs one, how optimal of code would that produce? So it is an undecided question to see if the generated code. How good is the optimizer at this point in time. It's just something that. I don't know if you could comment on that.
04:01:31.330 - 04:01:55.290, Speaker B: What kind of answer do you want for that question? So it has areas where it can be vastly improved. It has areas where it is good. What I can tell you is that the runs parameter only influences a very small detail of the optimizer. And this is the representation of constants, at least currently.
04:01:57.840 - 04:02:04.190, Speaker A: Chris Papat made a point in the GitHub. I guess he's talking about optimal equals small code size.
04:02:06.640 - 04:02:54.700, Speaker B: Sure, but that's still, I mean, regardless of how good the optimizer is, some people will always hit the code size limit, right? So I'm not getting too much positive feedback here. Maybe it's also just not too controversial topic as the previous one. So is these marking areas and contracts something that would be good for you or not?
04:03:00.300 - 04:03:10.428, Speaker A: Chris, we could really try out this dropholding, because I think we have 30 people in the room and we have a couple of minutes left. So for an easy yes, no question, why don't we try.
04:03:10.514 - 04:03:12.396, Speaker B: Right, I completely forgot about that.
04:03:12.498 - 04:03:23.730, Speaker A: Try this out. Let me just create it quickly. So what do we want to ask? Can you repeat the question?
04:03:25.700 - 04:03:43.680, Speaker B: Marking areas, where to split contracts. Does everyone know what I'm talking about? Maybe I'll write a small code example. Yeah, actually if you could explain a bit more thoroughly the solution, that would be wonderful.
04:03:43.840 - 04:03:44.550, Speaker C: Yes.
04:03:48.970 - 04:03:55.080, Speaker A: Okay, so you explain and I already created the poll. Then we can. Nice share this together.
04:03:55.410 - 04:04:36.220, Speaker B: It the functional all have all the same name, so you can't see my screen, right?
04:04:37.730 - 04:04:44.510, Speaker A: Yes, we can see your screenplay.
04:04:47.490 - 04:05:53.130, Speaker B: We have a contract with three modules and a state variable. Then each module, you can access the state variable directly so you don't have to pass storage pointers. And you can call other functions of the same module. This will result in just a direct jump. And if you want to call, I guess the names also have to be unique, otherwise it's too confusing. And if you want to call a function of a different module of the same contract, you do something like a f two. And this will use delegate call then, which means memory will be an independent memory, objects will be an independent copy.
04:05:53.130 - 04:05:57.150, Speaker B: But storage can still be accessed.
04:05:59.870 - 04:06:00.186, Speaker C: And.
04:06:00.208 - 04:06:14.110, Speaker B: There'S a single constructor that cannot be in the module and the dispatch will directly delegate call into the module.
04:06:16.610 - 04:06:23.790, Speaker A: Chris, can you somehow enhance the size a little bit? People ask in the chat.
04:06:35.080 - 04:06:36.470, Speaker B: Does it work like that?
04:06:37.480 - 04:06:39.350, Speaker A: Yes. They say much better.
04:06:50.750 - 04:06:53.040, Speaker B: F two shouldn't call f two, of course.
04:07:08.080 - 04:07:10.710, Speaker A: And I see Nicholas wants to say some thing.
04:07:12.200 - 04:08:04.070, Speaker B: Yes, I've explored similar solutions in the past. My understanding is this has a big limitation is that every module needs to be aware of the address of all other modules. And the only two ways that I know you can do that is either have post construction initialization or have a sort of factory contract that deploys all modules. The issue with the latter, which I think is what you're trying to describe here, is that you're still constrained by the total gas that a single transaction can take, which is again limited by block size. So there's like a second. Right, I see limitation syntactically like this. You should also be able to write something like new C two and this should deploy all the modules and the contract, of course.
04:08:04.070 - 04:08:27.762, Speaker B: But, yeah, that's a really valid concern. Yeah. No, I think this is interesting. I was just pointing out there's some limitations still on some issues. I mean, then one solution could be. Okay, you're saying modules need. Yeah, I mean they could be stored in storage, right? Yes.
04:08:27.762 - 04:08:56.210, Speaker B: You do a multi transaction initialization process, but that'd be way more complicated. I don't know, it's just something to think about. And if the addresses are stored in storage, then we could also upgrade them. So you would have an upgradable contract when everything is inside a module whose address is stored in storage and that you can change.
04:09:00.800 - 04:09:05.900, Speaker A: Cairo is asking, so modules would behind the scenes be deployed as libraries?
04:09:11.020 - 04:09:28.050, Speaker B: They would be very similar to libraries. Exactly. It's the main difference that they can access state variables directly. So Nicholas, was that currently right? Yeah.
04:09:35.700 - 04:11:11.720, Speaker A: Okay, if you already have an opinion about this, then feel free to go to the straw poll link I posted in the GitHub channel and vote. Chris, just relaying another comment from wallflow. Another possibility could be a hierarchy of modules. Module C deployed first cannot call other modules. Module B deployed second can call module C. Module A deployed last can call B and C. And Francisco says the addresses can also be deterministic somehow.
04:11:12.780 - 04:11:16.810, Speaker B: Yeah, maybe you could create two for that. Could you create two for that?
04:11:26.570 - 04:12:18.550, Speaker A: So far the results of the poll show that over 50% are for yes and then over 30% have no preferences or I don't know. And one vote so far says no on the question of marking areas where to split contracts. And on the no, Benjamin says, although it appears there is a low percentage of people voting no, I think it wouldn't hurt to inquire the reasons why people might not want it. Yes. Who doesn't want it? Anybody here on the call who doesn't want it and has an opinion on why not? Alex?
04:12:23.610 - 04:13:15.390, Speaker B: Yeah, I think it would be useful to maybe lobby for a code size increase instead, because the limit we have is quite arbitrarily decided, and I'm just really confused about splitting contracts in general. Also, I'm not clear what use cases result in super large contracts. I mean, maybe we could do the question the other way around and ask do people use libraries or do people use public functions of libraries and should we just remove them from the language?
04:13:24.200 - 04:13:26.464, Speaker A: Do you want to ask this question as a poll?
04:13:26.592 - 04:13:27.572, Speaker B: Yeah, why not?
04:13:27.706 - 04:13:35.690, Speaker A: Okay. Do you want to ask whether they use it or whether we should remove it?
04:13:38.620 - 04:14:49.760, Speaker B: Should we remove the delegate call aspect of libraries? Is that assuming there is an alternative, like contract modules without alternative, at least for now, the alternative is delegate call in an assembly or something like that. In that case I would say no because it's the only mechanism that exists today to implement this pattern which some people do find the need for. But I feel that what's missing from this conversation is how common this need actually is. And I can't answer that. I don't have the data, but it's something I also don't know. I also heard that people hit the limit, but then they find other solutions that do not involve libraries. At least that's what I gathered from the discussion earlier.
04:14:49.760 - 04:15:15.450, Speaker B: Maybe I'm wrong. It. I think that while people tend to find other solutions for this problem without using libraries, you. Am I speaking?
04:15:16.940 - 04:15:18.152, Speaker A: Yes, you are speaking.
04:15:18.286 - 04:16:31.670, Speaker B: Yeah, sorry, this UI is very confusing. So while people tend to find other solutions for this code size limit problem, when you do heat it, find one of these solutions like setting enabling the optimizer. You end up with a feeling of fear because you may hit it again and you may not find another solution except for libraries. Yeah, totally. And I would also say those workarounds can sometimes feel insecure. So it would be good to provide good alternatives. But you only really need that mechanism if you cannot also split the data, right? Yes, but if we remove libraries from the language and you have to resort to in an assembly to do these kind of things.
04:16:31.670 - 04:16:35.780, Speaker B: It will still feel very hacky.
04:17:01.680 - 04:17:03.150, Speaker D: Can you guys hear me?
04:17:04.080 - 04:17:04.830, Speaker A: Yes.
04:17:05.280 - 04:17:17.810, Speaker D: Hey, it's Nick speaking in two minutes. Allegedly. I want to express my opinion that I'm afraid of libraries. And that's it.
04:17:19.380 - 04:17:23.170, Speaker B: Yeah, that's something I can understand.
04:17:24.740 - 04:17:48.470, Speaker A: Okay, but to wrap this up, with regards to the question we just asked, should we remove the delegate call aspect of libraries? So far the majority says no. Just to give that feedback back to the room. Chris, do you need more input? Two more minutes.
04:17:52.360 - 04:18:31.710, Speaker B: I think it would be good to have distinct discussions with people who have hit the code size limit and talk to them, how they circumvented that. And what would they have done if they had some mechanism like this marking area stuff, modules. And of course if there is a way to do that, kind of find out how common the problem is. But yeah, talking to people who had that problem might be a solution to that too. If we don't find anyone, then yeah, the problem doesn't exist.
04:18:37.170 - 04:18:58.470, Speaker A: Okay, so this is a good next step then, I guess. Thanks all for discussing with us. Next up we have right on time in 1 minute, the introduction to Yule plus by Nick who just told us he's afraid of libraries. So yeah, welcome, Nick.
04:18:58.890 - 04:19:03.994, Speaker D: All right, so you guys can hear me? All right, we can hear you.
04:19:04.032 - 04:19:05.002, Speaker A: All right. Yes.
04:19:05.136 - 04:19:08.300, Speaker D: Great. So should I just share my screen?
04:19:08.990 - 04:19:10.666, Speaker A: That is a beautiful idea.
04:19:10.848 - 04:19:11.434, Speaker D: Okay.
04:19:11.552 - 04:19:12.380, Speaker B: All right.
04:19:14.830 - 04:19:21.230, Speaker A: If you also want to show yourself, you can also enable the camera and share your screen at the same time. But you don't.
04:19:22.610 - 04:19:24.000, Speaker D: We'll give it a go.
04:19:25.970 - 04:19:29.780, Speaker A: So the hack is basically to share your screen and then click on the camera again.
04:19:39.510 - 04:20:03.258, Speaker D: Damn you gypsy. Why can't you be perfect? Okay, so my screen is being shared. Great. I will present this. Okay, so let's get right into it. So I'm Nick and I've been doing Ethereum stuff for like six years.
04:20:03.344 - 04:20:05.290, Speaker A: We don't see your screen anymore.
04:20:06.510 - 04:20:08.270, Speaker D: Okay, I got it. Got to share it again.
04:20:08.420 - 04:20:19.090, Speaker A: Yeah, no, we can see the screen only if you click on present. It somehow disappeared. So in this edit Google Slides mode we could see them.
04:20:19.240 - 04:20:45.730, Speaker D: Okay, let me try this then. Try doing like a view link in Chrome because it might be the switching between browsers. What do I want to do here? Okay, 1 second. Let me try full screen share. It might just be safari full screen. You got it. Not got it.
04:20:45.820 - 04:20:50.810, Speaker A: Yeah, this works well. But now we don't see you anymore because you have to click on the camera again.
04:20:50.880 - 04:21:49.600, Speaker D: But it doesn't matter fuck it, who cares? Okay, restart. So as I said, I've been working on Ethereum far too long. I've aged significantly and it has been a wild journey. And yeah, I've been using solidity, I think since it started or since the very early, earliest versions. So it's been a very wild roller coaster of an experience in lots of different apps, lots of different stuff happened. But effectively, after a little while, getting deeper and deeper into solidity and getting deeper and deeper into how the EVM actually works, you want to go a little deeper and a little further. And.
04:21:49.600 - 04:22:43.840, Speaker D: Thanks. Know Chris and know Yule has been an interesting pathway. So yeah, today I'm going to present my extension to Yule. Plus you could call it a new language, but it's effectively mostly Yule, but with some extras. That's the way you can think about it. So for the agenda, we're just going to do a little overview of Yule. What I really like as a dev about Yule and what it is and as well the motivations for why there's justification for maybe an extension to Yule, objectives for this new language, a feature overview roadmap, and where we might want to take Yule plus.
04:22:43.840 - 04:23:37.006, Speaker D: And then lastly I have a special reveal of a project. So you guys are going to see, well, kind of the reason why I want all these things and the reason the result of doing of the agenda. So yeah, with Yule, Yule is just an intermediate language. It helps Chris and Alex and the rest of the solidity team sort of build solidity and act as a nice sort of intermediate layer between assembly and some kind of reasonable language. And the things that really stand out to me about Yule is just simplistic grammar. There really isn't a large grammar there. It's functional notation, it's low level, it manages all the stack work for you.
04:23:37.006 - 04:24:28.330, Speaker D: And if you've ever tried, I don't know, computer science class or something, managing stack, it's a goddamn nightmare. So it's great. It's easier to audit and formally verify primarily at the assembly level. So when I want to take a build that I've done and have people who do form verification work with it, I find the produced assembly is much easier to build proofs out of than solidity. So I think this is a big benefit. And I know there's tools that are on the way and that are constructed for solidity and form verification, but with Yule we can really do it right at the assembly level. And just the produce build is really clean.
04:24:28.330 - 04:25:16.794, Speaker D: So the compiler is simplistic. I love that I can open up the solidity compiler and look at the Yule section and actually understand exactly how it's breaking everything down and how it's going to ship off to EVM code. I think that that's a huge benefit for the community and the language to be able to have this really simple step. Solidity has obviously got a ton of features and it's working with a lot of different concepts. And this of course makes the compiler complexity, increases the compiler complexity significantly. Whereas with Yule you're really doing more simplistic operations. This is minus the Yule optimizer, which adds a bit more complexity.
04:25:16.794 - 04:26:12.078, Speaker D: But of course you can just turn that off and then it produces really efficient builds. So because it's just managing stack and you're effectively still using stuff, write off assembly, you get these really tiny clean builds of contracts. And I really do like that. Of course you're not going to get the safety you want, the language and compiler level safety that you get from languages like solidity, but you do get significantly increased build efficiency. So the deployment cost is very small. Shared memory and function macros, so you can actually using Yule, and I'll show cases of that. But one big aspect is just sharing the same memory across many different functions.
04:26:12.078 - 04:26:59.374, Speaker D: And I know solidity can probably and eventually do this using some macro terminology, or if it already does, I don't know. I haven't worked with solidity recently, but effectively this is one of the big reasons and you'll see why in a second. And as well just more precise stack control and management. So just being able to in a fine grained way, build applications and low level code and get a better idea as you build how the stack is actually going to be managed. Because you know, the Yule compiler is actually very dumb. It's not doing anything special. If you're loading up a huge functional statement, then you know you're going to be pushing the stack even further.
04:26:59.374 - 04:27:44.800, Speaker D: And that's basically the precision you get with Yule. So some motivations for the extension to. So I love Yule vanilla. The second I saw it and the second I started to work with it, I immediately loved it. And given that I've spent a long time with solidity, I felt like as a developer it was sort of reasonable for me to be able to extend my capacity and go further down, closer to the EVM metal for experiments and for development and everything else. And I loved Yule for various purposes. And I've built the fuel optimistic roll up, which is what I'm currently building.
04:27:44.800 - 04:28:36.810, Speaker D: Most of the contract, about 80% of it, is written in Yule. So it's one function written in Yule and then there's a few solidity functions. And in our second build, which we'll be releasing this quarter, the entire contract is built with Yule plus, effectively Yule, but Yule plus. So the lessons I've learned from that I've kind of taken into this and said, okay, well, there's definitely a few things I would love in Yule, but it may not make sense to have in Yule. So first thing is management. So building large code bases with Yule becomes very verbose and repetitive, obviously, because it's low level and it's going to not do a lot for you. So it comes with a lot of mental management, as working with memory on a low level would always come with there's not a lot of sugar.
04:28:36.810 - 04:30:00.490, Speaker D: So there's many instances where you just wish there was a little bit of syntactic sugar and adding it would not be significantly less efficient. So it's not like we're adding on these really complex statements that have big concepts around them or anything like that. They'd be simplistic concepts and they just add significant notational value without increasing build complexity as well. I think you can add sugar to something like Yule because it has such a simplistic sort of base grammar, but that doesn't mean that it should be in Yule, because the reason why I think I love it and why other people will love Yule for certain cases is going to be because of its simplistic grammar and that there isn't all these new concepts or expressions or anything on top of it's very simplistic. So this becomes kind of a motivation to say, hey, maybe there should be a little sugar or extension on top of this. That's going to pepper in little things that just make building apps with this easier. And I will say too that I don't think it was the expressed motivation that Yule would be used for application development or for things like scaling and roll ups.
04:30:00.490 - 04:31:42.810, Speaker D: But it really fits the bill in terms of what I'm looking for as a more lower level developer with Ethereum and for the express reasons. So of course, the design intention was not to put something really developer facing in front of everyone with fuel was more, how can this be a nice intermediate step between assembly and the development of solidity and or other languages? So that's just to note that. So as for safety, Yule comes with little safety nets of just, it's effectively a simplistic compiler over the assembly, over assembly, and then lastly extensibility. So making an open source layer on top of Yule that allows for a lot of custom language variants and plugins. So this you'll see is kind of something we're looking at and it's something that we're already kind of using with DType, which is an interesting new typing system. So these are the sort of motivations and as well for fuel labs and the optimistic roll up game, it's primarily about gas sensitivity and you'll see why in a second. And then as well it's better for roll up contracts because roll up contracts require significant amount of low level gas sensitive work in terms of breaking down proofs.
04:31:42.810 - 04:32:55.780, Speaker D: A lot of cases where memory would be shared and where if you're copying fresh memory every time, that's going to really significantly add up. So you want to be able to have a deeper level of control over what's happening in execution. And then lastly I'll show it's fantastic for building stateless contracts which are sort of, I don't think a concept that people are really working with yet because we're not really dealing with problems of scale just yet. But as you'll see, stateless contracts are what we believe is the future of decentralized app development and the future of, well, everything pretty important. Okay, so objectives for the new language, and we're almost through my dense point slides, so just hang in there if you're getting bored. So objectives for the new language, so philosophy, don't do too much value, just add sugar where you need it, where it's only going to add maximum value. Don't add all this fun sugar for nothing.
04:32:55.780 - 04:33:31.642, Speaker D: Yule first. So produce valid Yule builds grammar. Keep the grammar as close to Yule as possible so that we're not doing too much. Once again be extensible. So allow others to add in different layers on top. I'm not going to know every reason or feature that people want, but I do know that JavaScript is a really easy system to add and remove things, or it's a really easy language for others to contribute and socially contribute. So it comes with a lot of interesting potential experimentation and then as well influence.
04:33:31.642 - 04:34:37.410, Speaker D: So if a lot of developers are using a certain feature in Yule, plus we could see maybe can that be carried over into Yule or solidity in some format. So just being able to influence other languages. So the features of Yule plus after that huge rant are as follows. So just all existing Yule features, enums, constants and Ethereum Abi generation, the hash generation safemath. So you can basically get safe math injected for free and you can turn that off as well. Any of these things you'll be able to turn off in the production compiler injected methods, so mslice and require and memory structures which are the more sophisticated addition and will be expanded to support ABI encoding and a few other different kinds of structures, dtype structures, et cetera. So as I said before, Yule plus is just a layer on the Yule sole compiler.
04:34:37.410 - 04:35:17.354, Speaker D: So we've written Yule plus and nearly which is an e actually there, which is a nice sort of grammar parser. So the grammar is constructed in this grammar language which is sort of a hybrid between JavaScript and their own language. And then we break down the Yule code that way, add a layer of features on top that gets compiled to Yule and that's it. And we're really not doing anything more than that. So to cover some of the features. So here's what enums look like. We've kind of kept most of the notation similar to Yule, so just enum colors, et cetera.
04:35:17.354 - 04:35:53.146, Speaker D: So it'd be zero, one, two and as well constants. So just adding the const specifier. So this does two things, one with constants. If it's a literal, I. E a number, hex value, something like that, it will just do injection across the build if it's not a literal. So it needs to be run in execution, then that is going to be set as a let statement, but we'll look out for other things. Trying to reassign, that's the current way we're handling it.
04:35:53.146 - 04:36:40.122, Speaker D: I'm sure there's more that can be done there, but that's actually the basic idea. Abi signature generation and topic generation. So still all vanilla Yule, but you can do fun things like write sig and then effectively a solidity function, which is how it's getting parsed. This is thanks to ethersjs solidity function to Abi parser. So you can effectively write what you believe that function is in vanilla solidity, sort of a header, and then that's going to get compiled down to its signature and do all the checking, et cetera. Same thing for topics and topic hashes. So it'll do the topic hash generation as well.
04:36:40.122 - 04:37:22.038, Speaker D: So this just makes handling, readability, all that sort of stuff. It just cleans up a lot of jargon that you're going to get if you just tried to do it with hashes, because you'd really have to prespecify like this hash is this thing. So these are nice little generations and that's just going to do a literal injection there, which is quite nice. So save math by default. So if you're just using add, sub divide, et cetera, it's going to basically change that method name in execution and inject the save math methods above. So it'll switch add over to save add and then you're running that. However, you can turn it off and you can use features like unsafe add.
04:37:22.038 - 04:38:03.418, Speaker D: So you're just specifying in the literal sense, hey, I want unsafe here, give me unsafe. And of course you can just turn it off outright if you don't want it. So really flexible on the basic things like safe math and overflow and underflow checking. And with this addition I want it to be as hands off as possible. I don't want to be maintaining this magnificent addition to Yule. I just prefer that it gives us the flexibility to add what we need, create low level builds, and then move on with our lives. So some methods getting injected and another feature so m slice and require.
04:38:03.418 - 04:38:55.926, Speaker D: So all m slice is effectively just shifting right by a certain amount of bits. So here I'm just taking the first four byte signature, just grabbing it from the call data that's copied to memory. So doing little things like that. M slice is great for, I use it so much in my builds that it just had to go into injection. However, these methods can be changed in the compiler settings, the injection settings, and you can turn them off and you'll be able to basically specify like okay. Or you'll be able to go hey, I don't use m slice at all, so it'll never get injected. So you have many different options with what's being added onto the Yule language here and require as well.
04:38:55.926 - 04:39:46.230, Speaker D: So you'll be able to specify like hey, this statement whether it's trueish or not. And then you can specify an error message. And we've chosen a simple error system here where the error basically you put a huge string in there. It's just going to hash that string, take the first four bytes and then use the first four bytes in an injected literal in the require statement. So that's all it's doing. And then at compile it will give you all the errors and their hashes and it'll give you all the signatures and their hashes. So you still get all the sort of luxuries that you would get from a solidity like compiler environment using Sig and error and these sort of injected systems, but they just come in little clean packets out compile time.
04:39:46.230 - 04:40:42.870, Speaker D: Of course we can standardize notation there, make sure that all the builds are up to spec and they produce nice arrays and everything else of all the ABIs. But even right now just with this basic injection we've been able to do quite a bit. And then lastly the most sophisticated thing we've done and this is going to change over time. Right now you'll in the later versions of solidity compiler support types and they're basic types but they're still types. So right now Yule is just all it's typed, but at least in the builds that we're producing it's all the same type. So it's only one type. But of course as we go along we're going to add in that typing and we're going to add in as well some custom typing with the enums mstrucks and you'll be able to do some basic custom typing.
04:40:42.870 - 04:41:33.138, Speaker D: So I think that'll be a really nice addition. It's really not that hard, it's just haven't gotten the time yet to switch it. So right now this mstruck notation is sort of in a non type setting, but it will be in a type setting after. So basically what we're doing here is we're just specifying and describing an existing structure in memory or a structure that may come into existence in memory. So right here we have some complex data. Maybe that complex data has a signature, it's four bytes, maybe it's got a value that's 32 bytes, and maybe it's got an array like structure with a dynamic length and an array where you have ten bytes for each item. So this allows you to describe a lot of what structures would be popping up in ABI.
04:41:33.138 - 04:42:29.478, Speaker D: However, this doesn't have offsets yet where you can specify dynamic offsets for each property, but that will come as well. So you'll be able to get a nice sort of recursive offsetted memory structure description. And I think that that's going to add a significant amount of value to Yule. Plus right now it's more just keep it basic and just see how this can be used. And this is what we're going to build a lot of our roll up with. But in the future you're going to have full fledged Abi and not only that, you'll be able to specify your own ABI encodings and you'll be able to specify your own typing as well. So these would turn into instead of four and 32 and 32 and ten, it would go to something like a bytes four, or it would go to a U 32 and U 256, et cetera.
04:42:29.478 - 04:42:44.970, Speaker D: So that's really where the typing is going to come in. And then here we have the usage. So the usage is really cool. It's just the structure name. So complex data dot. So the dot notation is already supported in Yule. So we're not doing too much here from a sugar perspective.
04:42:44.970 - 04:43:19.014, Speaker D: And then signature, and then we're just putting in the start of where complex data as a structure begins. So this makes managing memory at a low level just really easy. You're just laying out the structure and saying, hey, here's the structure. And then you're just picking it apart and it comes with all these sort of generated functions. So you can say, give me the position of this particular value. You could say, give me, sorry, array should be r there. You can say, hey, give me this item within this array.
04:43:19.014 - 04:43:58.370, Speaker D: At this position you can say, give me the array length. You could say hash this particular value or hash the entire complex structure. It'll just do all the positioning for you and it'll inject those functions. So it's really just a function generator. And what we want is a system where you can tune that generator the way you want it because we can't expect everyone to use all of the same formatting. However, Abi encoding at present does most of what we need. Unfortunately, when you get into rollups, the Abi encoding falls short because it's not type packed.
04:43:58.370 - 04:44:15.834, Speaker D: So this is something we can go over in the discussion, but that's effectively what's up there. So roadmap and future language exploration. And by the way, how am I doing for time? Am I ranting too much?
04:44:16.032 - 04:44:21.630, Speaker A: No, you're good. You have five minutes to go and then anyways, go into the UL discussion.
04:44:22.530 - 04:44:53.198, Speaker D: Great. Okay, so I'll get through this as quick as I can. So basically we're going to add this ABI in string specifier. So this will actually generate an M struct based upon the ABI you specify. And then you'll be able to then use those structures in existing memory, which is really cool. So this is great for call data and parsing call data and doing all that sort of work as well. It's extensible, so you'll be able to plug in your own typing system like Dtype.
04:44:53.198 - 04:45:49.002, Speaker D: The objects will be extensible, so we'll introduce some basic extensibility. It'll just be copy and paste extensibility. So it'll just follow the expressed ordering and just inject it. There'll be tiny packages, so we'll do a tiny little package manager and it might support as well the etHPM package manager, because I know it can handle this sort of thing better. CLI support and low level customized version of remix. So remix is great and I like the way it's configured, but I think yet we could have yet another lower level oriented version that I think expresses what's changing in execution over time with better gas metering and so forth. And then the big thing as well.
04:45:49.002 - 04:46:20.906, Speaker D: Types, types, basic custom types and memory pointer types, which is what we're going to discuss next. So that's the roadmap. So now for a special reveal of some stuff that we're working on here at fuel Labs and we think will be a game changer. And I'll try to present it in four minutes. Here we go. So using our ule plus tech and our low level code, we were able to roll up ens. So we now have a version of an ENS registrar.
04:46:20.906 - 04:47:12.866, Speaker D: And Nick Johnson knows all about this and we'll be releasing this soon. And basically it cuts the cost of ens registration currently in half, but that will be even more as we get it, more efficient and as we kind of go further. It's a system that has got a lot of features, and this is sort of the usage of why Yule and Yule plus and these lower level languages is so important because as Ethereum scales, as we go to 2.0, as we go to a world where we're in a more stateless environment, using a lot less state rights, all of this becomes very critical. You won't be able to use state the same way, so you're going to have to get creative. Sparse ens. So what is it? Stateless, verifiable and cheap ens registrations.
04:47:12.866 - 04:47:36.170, Speaker D: So basically we've knocked the cost of registering a name down at good gas prices to about 0.1 cents per name. So ten k gas. And right now we're sitting at about 45K gas per name. So this is pretty significant savings. And name registrations can be batched.
04:47:36.670 - 04:47:39.902, Speaker C: I personally love getting face to face.
04:47:39.956 - 04:47:41.438, Speaker B: Time, if you can call this that.
04:47:41.524 - 04:47:47.326, Speaker D: But yeah, I don't think it's like the end of the world. Sorry, someone talking.
04:47:47.508 - 04:47:49.460, Speaker A: Sorry, whoever is talking.
04:47:52.710 - 04:47:55.570, Speaker B: Right now. Yes, this is the usual.
04:47:57.030 - 04:48:00.980, Speaker A: Okay, Nick, I muted everybody and now you have to unmute yourself again.
04:48:04.350 - 04:48:05.162, Speaker D: Here we go.
04:48:05.216 - 04:48:05.434, Speaker B: Great.
04:48:05.472 - 04:48:06.620, Speaker A: Then it should work.
04:48:06.990 - 04:48:09.898, Speaker D: Great. Okay, can you guys see me?
04:48:09.984 - 04:48:10.282, Speaker A: Yes.
04:48:10.336 - 04:48:36.242, Speaker D: Can you hear me? Okay, great. Still got it. Okay, great. So the way this works is using a sparse merkel tree and some kind of encoding. Well, you can get 16 characters in with compression, but you lose certain names if you do that. Tip 712 compliant and it's state optimized. So the entire thing, the entire contract uses one state mod.
04:48:36.242 - 04:49:02.822, Speaker D: So you're literally registering potentially millions of combinations of names. And we're only doing one state. Right on Ethereum. So we believe that this kind of design is the way that Ethereum apps and EVM apps should work. We shouldn't be using millions of state writes on Ethereum. It's not sustainable. And the way that the client manages state, as we've seen, is a huge bottleneck because of random access state memory.
04:49:02.822 - 04:50:31.720, Speaker D: So this sort of state optimized design, where you can have millions of Ens names being registered under a single state mod, is sort of the way we think it should go. So here you can see we have our one s store that we use for the root, and then you're deriving the names and a name is broken down by an encoding scheme to a specific number, which is going to be your number of where this is included in the sparse Merkel tree, and then that's going to resolve to your name data. So this simple use of a sparse merkel tree to increase the efficiency of things like Ens will present massive value add, I think as we move closer to scale and just making things a lot cheaper, I mean, instead of paying something like one cent per name or things like that on a bad gas day, you're paying a lot less for that. And for people like wallet developers and stuff, this is a pretty big deal. So I can go into this a little further, but effectively looking at some of the sparse cns contracts, all this will be open source soon under Apache two, and you'll just be able to really check it out. But here I'm using the enums, you can see I'm using M slice, you can see I'm using the SiG generator, and you can see I'm using that mstruct formation specifier. So all these things that we're building into language we're really using all the time.
04:50:31.720 - 04:51:08.018, Speaker D: Here's more mstruct usage. Taking in the registration and doing the batch work, and as well adding in safe math where necessary, adding in these nice little multi m store bits of sugar, and then doing the require statements and so forth. So instead of doing m store zero, m store zero plus 32 m store zero, whatever, you know how mstore is going to function. So you can just do some nice quick sugar there and it just makes the notation so much easier. We know what it's going to do. So considerations. So I'll just try to wrap this up.
04:51:08.018 - 04:51:57.650, Speaker D: So basically, as we move into what we believe is a new era of contract development, which is stateless contract development or using one to two state rights for an entire system. So imagine a Dex using only one to two state rights, something like that. We believe that scalability is going to be key. Designing for scalability is going to be key. Reducing s stores, reducing s loads, and getting to a point where the execution is very clean, it doesn't cost a lot, and it can last a long time and be formally verified. So yeah, stateless contracts and yeah, our sparse Ens system should go up in about a week or so. So you can get a demo and you can try it out on Goreley.
04:51:57.650 - 04:52:36.678, Speaker D: And I think that's really to set the bar and the reason why we're doing things like Yule plus and kind of focusing on that stuff. So if you want to use ule plus, just save, install Yulep NPM. There's a Yule plus plugin which is awesome thanks to the Dtype team and Uoplus ide, which will build eventually into a lower level system, GitHub discussion, et cetera. All the links are there. I can post these slides somewhere. So I went a little over, I went three minutes over. But yeah, that's presentation.
04:52:36.678 - 04:52:37.620, Speaker D: Thank you.
04:52:42.160 - 04:53:29.770, Speaker A: No worries. And thank you so much, especially for the info on the Ens stuff. You can stop sharing your screen now if you like. And other than that, are there any questions for Nick either? And you can post your slides, by the way, on our solidity GitHub, because we're using the GitHub chat to chat during the conference. So let's check in this room first. Any questions for Nick on your plus? For the newbies here, you can use the raise your hand feature to raise your hand so that I can see that you want to say something. And let's also look into the GitHub channel.
04:53:29.770 - 04:54:08.120, Speaker A: So there was a discussion going on in the GitHub channel about basically the problem that while U Plus is a nice project, I'm a bit worried about promoting developers to write low level code. Some of the solidities mitigations are going to be missing and people will make mistakes. In my honest opinion, this should come with huge warnings like what happens if someone is unlucky and writes two functions that generate the same function id with solidity he is going to be safe. But with Yule I suppose there will be no warning. There was already a little discussion on that, but I wanted to give you the chance to also comment.
04:54:08.460 - 04:55:14.700, Speaker D: Yeah, so I think safety is a big reason why solidity needs to exist. And the development safety that comes with having a compiler focused on new developers coming to Ethereum and new developers coming to the ecosystem. And I think that that's critical. But the thing is, as you start to build these more complex builds, and as you start doing development that requires a lot of sensitivity to gas and opcodes and exactly what you're doing. Yes, it takes expert, or what we consider to be, I think, expert knowledge to do. There's not a lot of places to go to and there's not a lot of places to find languages that will support you. We had lisp for a while and things like that, which offered some language like options for working with assembly, but Yule really stationed itself nicely as an intermediate ground.
04:55:14.700 - 04:56:02.780, Speaker D: And then Yule plus is a sort of addition to that that makes it more human to use. So I wouldn't say this is something to be promoted for general developers. I wouldn't say that at all. While we can add a lot of the same safety protections into the Yule plus compiler, just because humans are humans and even I make a ton of mistakes as I'm building, I think this is more for people who want to go a little deeper. They want to be a little more sensitive. They might really have a deeper knowledge of the EVM and they just need something with more precision. But they also don't want to be dealing with the baggage of working with just Yule that's more designed to build languages.
04:56:02.780 - 04:56:37.300, Speaker D: At least it was intended by default to be that. So I think that's my justification for this and why I think it's important. And as well as Ethereum devs move to more stateless app designs, they will need the sensitivity and the precision. And that's where I think Yule plus will really shine. So we'll hope to get enough safety in there for even more general purpose people to use it or general purpose builds. But right now it is really more specifically for scaling stateless apps and sort of deeper EVM development. So that's my rant.
04:56:37.300 - 04:56:41.064, Speaker D: So I think you're wrong, but I also think you're right.
04:56:41.182 - 04:56:41.850, Speaker B: Yeah.
04:56:44.620 - 04:56:49.468, Speaker A: Okay, we're running a bit over time, but I see that Justin might want to comment on this again.
04:56:49.634 - 04:56:52.060, Speaker B: Okay, can you hear me?
04:56:52.130 - 04:56:52.892, Speaker A: Yes, we can.
04:56:52.946 - 04:57:32.308, Speaker B: Okay, perfect. Thanks. Nix. Thanks for the presentation. Yeah. My point is that you and you, that's a great project and when you're going to use it, you know what you're doing and from your expectation only people with some expertise are going to use it. But my point is that you should kind of also when you are promoting and presenting your work and you please add some huge warning just to be sure that the people that are going to look at you and you'll please must understand that they need some level of expertise to use this language.
04:57:32.484 - 04:57:34.776, Speaker D: Yeah, I completely agree.
04:57:34.958 - 04:58:01.740, Speaker B: I know that some people are going to read your blog post or read some publication and see, oh, your place is great. I'm going to reduce the gas cost and everything and they might not understand that they need this level of expertise. So it might be just a notion of having more running or having more promoting it with this huge red flag. You need to know what you're doing when you use place. Does that make sense?
04:58:01.810 - 04:58:12.852, Speaker D: Yeah, I completely agree. I think we can slap massive warnings on everything from a developer perspective so that they know that that's the case.
04:58:12.906 - 04:58:13.076, Speaker B: Yeah.
04:58:13.098 - 04:58:42.510, Speaker D: And even Yule too in many areas says the same thing because it really is for more experienced people. Just to wrap this up, when you're starting out, even with coding, you would recommend like a python. You wouldn't give them a C plus plus right away and say like, hey, this is great. This does everything you could ever want. Use this. So I completely agree.
04:58:43.460 - 04:59:15.600, Speaker A: Okay, great. In order to not run more over time, let's move over to the next discussion, which is super connected to what we're discussing. Anyways, the next discussion will be moderated by Alex and has the title new features for Alex. You with us? No. Yes, but I can't hear you in case you're trying to speak.
04:59:19.010 - 04:59:21.470, Speaker B: It takes a while for the computer to.
04:59:21.620 - 04:59:26.500, Speaker A: Oh yeah, your computer is old. All right, I can hear you now.
04:59:29.110 - 04:59:41.400, Speaker B: Okay, maybe it's switched on the camera. Now maybe a quick question. Are we cutting the slot ten minutes short or are we running over?
04:59:42.170 - 04:59:45.880, Speaker A: I'd say let's go with the flow and see how the discussion goes.
04:59:47.690 - 05:00:07.280, Speaker B: Okay. I turned off the camera because it's dying. All right, so this is going to be a session about discussing some Yule features and it would be really nice to actually reach some decisions. It. Okay, it's working.
05:00:09.250 - 05:00:09.566, Speaker F: Well.
05:00:09.588 - 05:01:02.510, Speaker B: Thank you, Nick, for a lengthy introduction to Yule plus. But I do have a few words here regarding Yule and some of this was also mentioned by Chris earlier in the morning. But basically Yule started its life as a line assembly and it's evolved from there. But at a certain point we realized that we definitely want to have some kind of an intermediate language or intermediate representation in the compiler pipeline. And we realized that the inline assembly syntax we had with some modifications was not all that bad. So we ended up having introducing Yule, which is trying to balance the feature set between these two different distinct use cases. And also Nick, you mentioned that types for Yule has been added recently to the compiler.
05:01:02.510 - 05:02:25.660, Speaker B: Actually it was even more confusing because Yule and inline assembly there have been a various number of versions of each available in a compiler at the same time, and the pure Yule version always had types, but it was not really usable because it was just a lot of typing and it also didn't have any of the built in functions like the EVM opcodes. But what was enabled lately is a nicer version of that where we have a dialect of Yule. So we have for example an EVM dialect which defines what kind of built in functions like EVM opcodes you have and also defines the default variable size which is 256 bit for EVM, and for types which are 256 bit wide. You don't need to specify them, so it's less typing. But Yule did have types early on. Now in this session I will bring up some of the issues for the inline assembly use case, but I don't think we have time to discuss anyway. But then I have roughly four or five questions regarding the intermediate representation use case, which I hope we're actually going to reach some decisions on.
05:02:25.660 - 05:03:38.500, Speaker B: So also some more notes regarding the Yule plus. Last year with Nick we had like a lengthy discussion because Nick asked us to introduce some of these features into Yule, and I think we realized that while we liked a lot of these features, they may not be the best to be added to compiler at that point. So we kind of agreed the best way forward would be having the staging language outside which basically Yule plus became. But I think we do plan to bring in some of the features which make sense into Yule itself. Now again, in the inline assembly use case here are three features which the imports I believe is supported by U Plus. But we do have a discussion on imports and we also have two other discussions here which might be useful for people writing inline assembly or writing standalone assembly in Europe. I think I'm going to share the slides, so whoever is interested in these topics please just go to the issues.
05:03:38.500 - 05:04:14.400, Speaker B: But let's finally go to the main topic of today, which is the intermediate language use case. So here's like a simple issue we have opened for quite a while. Initially, Yule didn't have an if statement. It only had a switch statement. And therefore it made a lot of sense to have a switch statement with a single case as a replacement to an if statement. And this is still valid code today. So it's possible to have a single case with the default or a single case with an actual value.
05:04:14.400 - 05:04:47.400, Speaker B: Now, this is good for code generators, because if a code generator would not want to have a special case for if statements, it can have like a single version of code generation just using the switch statement. But the question is, is it bad for auditing? And the issue link down here tries to decide whether we should disallow this feature or whether it's good to stay. So maybe we can spend one or two minutes getting feedback on this.
05:04:54.200 - 05:05:59.032, Speaker D: Yeah, I think just to add one quick comment. So even with what's nice about this is we have the flexibility, I think, to use both. If you were to remove something like an if statement here, that could be added on top in sugar and just brought down to a switch statement. So in terms of the auditing, though, I think we would probably want to ask the formal verifiers, people doing a lot more of that work for them, their lives might not change that much because this is still a jump. So it's more, I guess, or even in this case, auditors like Openzeppelin, et cetera. I'm fine with even removing if statements and simplifying grammar more, because I know I can just add it back in in sugar if I need it, or if I feel like I really need it. But if statements are very clear, which is nice, switch is clear, but not inherently as clear, I would say.
05:05:59.032 - 05:06:05.428, Speaker D: Or at least I'm used to statements, but I do toggle between them, though.
05:06:05.534 - 05:06:15.500, Speaker B: So, I mean, it's a specific question whether we should support single case switch statements or not. The question isn't whether we should support switch statements.
05:06:17.200 - 05:06:17.816, Speaker D: I see.
05:06:17.858 - 05:06:18.450, Speaker B: Okay.
05:06:23.300 - 05:06:26.880, Speaker D: I would be for keeping even single case switch statements.
05:06:28.340 - 05:06:28.752, Speaker B: Yeah.
05:06:28.806 - 05:06:29.116, Speaker D: They don't.
05:06:29.148 - 05:06:30.690, Speaker B: Why? Any particular reason?
05:06:35.640 - 05:06:58.910, Speaker D: Well, to be honest, I just like the simplicity of knowing that I'm not demanded to have two cases, that a switch is inherently this basic mechanism. And I can use it with one, I can use it with many cases. So that's why. But it doesn't change my life significantly whether you took it away or not. I would say.
05:07:05.080 - 05:08:25.180, Speaker B: I would be interested to also maybe hear feedback, maybe from Jocelyn because you're involved with auditing or anybody else who feels like. Yeah, so what happened if the case one is not taken? It's just like a knob. So it's really like just like a heath, could you repeat? Yeah, so like this single switch statement, it's just basically like a if statement. Like if the condition is false, it's just like skipping everything, right? Yeah, you can use an if statement, which is in the language now instead of the single case switch statement. I don't see any particular difficulty for reviewing this. So it seems like there's no downsides having this, at least for auditing. And we know that for code generators it can be useful.
05:08:25.180 - 05:08:47.590, Speaker B: Usually. I think it makes sense to have always a default statement for all the switch, but that's another question. I guess some might expect like a switch statement to always have a default execution, but that's more like a language, semantic type of things that curve with you.
05:08:48.780 - 05:09:06.750, Speaker D: Yeah, I've heard that. Always have a fallback when doing expressions like by demand. Yeah, I mean those can be added in as rules, like more of a linter like sense on sugar on top. But yeah, I agree. Heard that before.
05:09:07.520 - 05:09:53.660, Speaker B: I guess it depends. Also, if this is meant to be a code that is going to be generated automatically by solidity. In that case you can have always default statements that can be added automatically, or if it's something that is written by hand. And in that case people might make mistake and forget the default statement. When you want to review your code, you have like two type of codes that you are going to review. Either it's generated by the compiler, so it's going to follow some syntax and some words, or it's going to be done manually and it's a bit more difficult. Yeah, I guess this is the case of the generated code by the intermediate representation.
05:09:53.660 - 05:11:02.060, Speaker B: Whether such constructs would be bad on auditing, I would favor to have always a default setment, but it's not like a strong requirement. Does that make sense? Oh, you mean to have multiple cases but always have a default. Yeah, as a syntax for a switched operator, I would favor at the language level to always have a default statement. Yeah, I think that's a different discussion. Yeah, maybe we can also move on to the next question because that's, I think is more interesting and maybe this one wasn't well described, but any last comments on this? All right, yeah, I think it would be nice, Jocelyn and Nick, if you guys can leave your comments on the issue and maybe we can take it from there. Cool. Thank you.
05:11:02.060 - 05:11:58.030, Speaker B: So the more interesting question with the switch statement is right now we don't have curly brackets around the cases, and there's a proposal that we should have curly brackets around the cases to group all the cases together. And I think in the team we don't really had any strong opinions. So I would be interested to hear strong opinions from people from both sides to have curly brackets around the cases or not have them. Maybe one additional comment so we can have them optional. So the expression after the switch has to be followed either by a case or by a default. So if you see a curly opening brace, then the parser would be able to distinguish both cases. So we can also have that optional.
05:11:58.030 - 05:12:05.940, Speaker B: And another important aspect to discuss here is that whether the cases should be indented or not, I think.
05:12:09.160 - 05:13:04.324, Speaker D: Yeah, so in this case I, from a guilty pleasure perspective like that, there isn't that additional set of brackets just because for me it makes the code. I just hate reading code that's like 18 depths of tabs in. And if you add these curly brackets, then you're starting to, I think, need to read it that way because you're increasing the number of tabs you're using. But from a language design perspective, I could totally see the argument why you would want the blocking of that particular code. I completely see why. But then the last thing I'd consider is it's not a normal block. So the rest of the blocks with curly brackets all express the same kind of blocking around it.
05:13:04.324 - 05:13:41.168, Speaker D: And if you put blocks around the switch, then you're changing the nature of the basic block. I think I might be wrong there. So there is that to consider. But I like that there isn't brackets around the switch because I find it to be overly verbose in one sense, but I'm kind of torn because in a language design sense it sort of makes sense. And then lastly, you're changing the nature of the block because the switch block is going to have inherently a different nature to it than the rest of the block types. So three things to consider there, I.
05:13:41.174 - 05:13:49.270, Speaker B: Think, between disallowing them, enforcing them, or making them optional, what would you choose?
05:13:51.080 - 05:14:20.910, Speaker D: For now, I like the way it is. I will put an opinion down and say I like the way that it is. And if auditors, I think, were in a position where they wanted to demand them just for clarity and readability and or consistency of some kind, then maybe making an option would be good. But I like the existing way that they are. I actually find that more clear because you're not changing the nature of what a curly bracket block is.
05:14:31.830 - 05:15:25.000, Speaker B: Nicholas? Yeah, I have a question, but when you say auditing, if you could clarify what it is you mean. Precisely. And that relates to a question about this Yule optimizer. My understanding is the optimizer outputs EVM bytecode and not more yule optimizer, goes from Yule to Yule, from yule to Yule. Would you be auditing the final optimized Yule code or just the first patch? How do you envision that working? Envision what working? Sorry, how do you envision the workflow of a Yule auditor? Will the optimized code or the original code? The code will just translate. They can choose, but the optimized code should be auditable. Okay.
05:15:25.000 - 05:16:50.530, Speaker B: Personally I do like having the Gary brace just because it helps to identify the dire block and the different cases, but it's not like strong requirement neither. I do prefer them for this visibility. So one comment brought up I think an issue or by someone that of course this example here is misleading because it's tiny. But especially in the case of the dispatcher function where you can have a lot of cases. If you do have the enclosing curly braces, then an editor can visually highlight where it starts and ends. So that was like one, I guess, opinion on helping auditing? Yeah, it's going to help editor and also like linter and stuff like that. Yeah, I think making the optional is a good resolution here and everyone seems to be happy with that.
05:16:50.530 - 05:17:02.496, Speaker B: Yeah, good. Sorry, go ahead.
05:17:02.678 - 05:17:26.410, Speaker C: Thanks. Just one thing I wanted to comment is in java it's possible to use curly braces anywhere, not just in particular semantic like an if statement or a switch. And it scopes variables to that block. So I just wanted to point that out and maybe a similar semantics might make sense here.
05:17:27.420 - 05:17:28.920, Speaker B: It's the same in Yule.
05:17:34.800 - 05:18:11.976, Speaker D: There could also be a case, Alex, where, I don't know how this looks, where you put the block around the switch to be more formal. So instead of putting it switch exprs round curly, you would just do curly, then switch express with the case one and the default. That's also I guess another way of potentially expressing this. But of course that changes the scoping. But I suppose if you're already going to try to change the scoping with this new block, then that would be, I just mean there's no way to.
05:18:11.998 - 05:18:23.180, Speaker B: Define a variable, to declare a variable inside the expression. So it doesn't change the scoping, it introduces a new scope, but the scope cannot have any variable.
05:18:23.760 - 05:18:24.750, Speaker D: I see.
05:18:25.840 - 05:18:31.724, Speaker B: If you place it around, then you would want to change the scoping rules, right? Otherwise it would be cumbersome to use it.
05:18:31.842 - 05:18:32.510, Speaker D: Yes.
05:18:34.880 - 05:19:14.592, Speaker B: Good point. I don't remember, what is the advantage to not have them? They are not needed. And Nick Dotson says, every curly brace introduces a block, which is a list of statements. And this would not be the case here. Okay. But from the moment you add them, I would just put them as mandatory. Because if you need to be able to discern this as not a block because it can append, it makes more sense to not have this as optional so that you don't have more complex words.
05:19:14.592 - 05:19:19.570, Speaker B: Just have like one word and that's it. Does that make sense?
05:19:30.630 - 05:19:47.560, Speaker A: Quick, throw in in terms of timing. Let's run ten minutes late. We can steal the ten minutes, probably from the upgradable contract discussion, which will be 1 hour. So the next talk then will start in ten minutes. And you guys still have ten minutes to discuss.
05:19:49.130 - 05:20:10.800, Speaker B: Thank you, Francis. So I guess my suggestion now just to wrap this question up, because we have more interesting ones, maybe we could take Chris's suggestion to introduce it optionally, and then we can judge whether people use it or not and make a decision on keeping one version later on.
05:20:14.470 - 05:20:15.940, Speaker D: Yeah, that sounds good.
05:20:17.910 - 05:21:10.850, Speaker B: All right, let's move on then to the really interesting part of the talk. Or the session would be user defined types. So we do have types in Yule, but they are only the basic types according to the dialect. So basically in practice with EVM, you have U 256-6432 I guess we go down to maybe eight, but that's it. There's no other typing in the language. And we want to introduce user defined types, but a simplistic version of user defined types. So where basically one could set a type, and that would be an alias to one of these basic types.
05:21:10.850 - 05:21:45.840, Speaker B: And here you can see a type definition line. There are like three different options. We're not even sure which one is like a good syntax and what this type definition line does. It actually generates conversion functions. And those conversion functions can be used to convert a given type to. I mean, it actually generates two conversion functions, converting from user type to base type and base type to user type. So why this is called conversion here? It's practically just typecasting what happens.
05:21:45.840 - 05:22:42.190, Speaker B: So on the next slide, we can talk a bit more about conversion functions. Alex, maybe to clarify. And there is no implicit conversion, there's only explicit. Yeah, yeah. So what we can discuss here is, first of all, is anybody against having user defined types because we are really strong on having them and you will see why in a minute. I think you first have to explain the use cases, right? Yeah, so maybe one example use case is we would want to have a specific type for memory pointers so that like Mstore or m load wouldn't take a U two five six for a memory offset. It would rather always require a memory pointer.
05:22:42.190 - 05:23:41.940, Speaker B: And the goal here is that it would be much easier to avoid mistakes where you would swap operands and also should aid auditing because you would be sure that one operand has to be of a certain type and that would be enforced by the type system in your would that be a user defined type or a built in types? Now I guess for like EVM memory pointer that would be a built in type, but it would still, I guess one option is that we have this user defined type syntax and this typedev line would be injected. Or I mean that would be the first line in the generated Yule file. But yeah, if you look from an inline assembly viewpoint, you wouldn't define like memory pointer yourself, it would be present.
05:23:44.870 - 05:25:06.094, Speaker D: Yeah, I'd say on the user defined type thing I would say that in one sense, of course having these sort of custom types makes a ton of sense at another side of this though, at least in the way that I'm currently using Yule more progressively, that I really only found there would be type situations such that base defined types would still solve most of my problems. So having like up to U 256 in types and then a memory pointer type would be more than enough. And I could flavor those. So I could maybe potentially flavor them with some user defining terminology such that a memory pointer might be flavored as a certain name or something like that, which has more enforcement rules. But I didn't necessarily feel the need to be building all these sorts of different custom types because still, this is still functionally very simplistic compiler, so it's not like there's a lot of deep stuff going on there. However, I'm sure there is many use cases that I didn't cover in my builds, but that's just an argument maybe against user defined types. Just to throw it out there.
05:25:06.094 - 05:25:16.478, Speaker D: Not to say I am, but I do feel just even basic typing like length and maybe memory pointer is going to be pretty sufficient for a lot of cases.
05:25:16.574 - 05:25:22.558, Speaker B: But the memory structs you define, wouldn't they be user defined types?
05:25:22.734 - 05:25:28.214, Speaker D: Yeah, so they would effectively be a flavored memory pointer is what I'm saying.
05:25:28.252 - 05:25:30.438, Speaker B: This is what we're talking here about, right, isn't it?
05:25:30.604 - 05:25:31.126, Speaker D: Yeah.
05:25:31.228 - 05:25:32.946, Speaker B: What do you mean by flavored?
05:25:33.138 - 05:25:43.046, Speaker D: I just mean that so you have user type as base types. So the base types are going to be the ones provided, right. Like length and memory pointers.
05:25:43.158 - 05:25:52.574, Speaker B: You need to specify a base type because you need to tell the assembler how it should turn that into EVM bytecode in the end. Right.
05:25:52.612 - 05:25:53.278, Speaker D: What is it?
05:25:53.364 - 05:25:55.002, Speaker B: How is the data represented?
05:25:55.146 - 05:26:22.006, Speaker D: Yes. So in the case of Yule plus, it would be something like type defined the user type in this case would be say a mem struct name. Right. And then that would be as a memory pointer. So that's how I would represent. So in Yule plus, this makes a lot of sense. And I would say, I suppose in even normal cases of using Yule for the progressive uses of stateless apps that.
05:26:22.006 - 05:26:50.800, Speaker D: Yes, a basic user defined type system, I suppose, makes a lot of sense because when I say flavoring base types, I mean literally, as you say, typedef the user type to a base type. But I've also found too, just to say, if you removed type def for a second and just said we only have these base types, you can get away with a lot with just the memory pointer type and I think a length kind of type as it's going down. That's all I'm saying. You could get away with a lot without it.
05:26:51.650 - 05:27:01.970, Speaker B: Yeah, I think we learned that maybe for this open discussion format to be. I guess we underestimated how much time we can spend on this.
05:27:02.120 - 05:27:02.820, Speaker D: Yeah.
05:27:04.070 - 05:27:54.340, Speaker B: On that note, I don't think we're going to reach like a final decision here. But I really want to put the next slide out, which is the conversion function. So basically, if we follow the thought that we don't have the syntax for defining user types, but we definitely want to introduce memory pointers, at least for EVM to take this as an example. If we do that, we still need some kind of a standardized way to convert between these memory pointers. And like u two, five, six. And this was the more questionable part to ask because we couldn't come up with any syntax people agreed on within the team. And here are just a bunch of them from the issues.
05:27:58.040 - 05:28:01.924, Speaker D: Yeah, this is where it all gets messy, I think.
05:28:02.042 - 05:28:21.720, Speaker B: Yeah, I don't think we can reach a decision here now, but I would really ask people who are interested in this topic to keep a note of this issue number and maybe think about these conversion functions. What would be a good naming structure?
05:28:23.200 - 05:29:07.130, Speaker D: I'd also say too, something to potentially think about is for each type you specify, you could specify an open Yule like function that isn't typed, that's more raw, that can do the parsing and conversion of the case to the other case, like from the type to the type. If you wanted to specify some kind of conversion system that was more the user defined, but if it was just going from one type to another. Yeah, there's a lot of philosophy, I think, that would go into that in order to determine the best path, if it was just language level.
05:29:09.660 - 05:29:45.350, Speaker B: So I just have a question, just to be sure. Like I understood it correctly. This type dev are going to be used only for type and new type of the same size, right? Yeah, I think that was the idea in the issue. So it's like an alias of a type where you are statically an alias of the type that is enforced by the type system. Basically. Perfect. So maybe one suggestion we could get around this issue by specifying the name of the conversion functions together with the typedef, maybe.
05:29:47.560 - 05:30:05.710, Speaker D: Yeah, totally. You could also do something where you specify just a really simple system where if you're going from a u, say a u eight, you specify whether it's going to convert it with trimming off one side or the other side. Is it going to trim right or trim left?
05:30:06.240 - 05:30:31.460, Speaker B: So the conversion always does nothing. It just removes the types. It just says, oh yeah, this is now the other type, but the underlying data format has to be the same anyway. Right? And you can write more complicated conversion functions that convert u and a to you in something else. But the reason why we need this specialized conversion functions is because there's no way to write them down without violating the type system.
05:30:31.610 - 05:30:35.620, Speaker D: Yeah. Okay, so this is on just the typing alone. Okay.
05:30:35.770 - 05:30:58.190, Speaker B: Makes sense. Basically, I guess the use case for this type dev is like you have a variable and you know that it's coming from block timestamp or something like that. And you want it to be a timestamp. And you use this as this type. Yeah, that could be one of the user defined ones. But as we discussed, like memory pointers, those would be given.
05:30:59.120 - 05:31:24.404, Speaker A: Alex, sorry to be jumping in again. Yeah, I know we over ten minutes are now over, and we have to move on with the agenda. And now. Okay, no, Mr. Chico doesn't want to say anything anymore. So if you want to keep this discussion going on, then you either can do so in the GitHub chat or you have to create a breakout room. But here now.
05:31:24.404 - 05:31:38.980, Speaker A: Next up would be Michael. Sorry for the slight delay, Michael. Michael is here to present the sol compiler for duel and solidity. We can't hear you right now, Michael. You're still muted, I think.
05:31:41.270 - 05:31:42.818, Speaker B: All right, can you guys hear me?
05:31:42.904 - 05:31:43.586, Speaker A: Yes.
05:31:43.768 - 05:32:13.670, Speaker B: Okay. All right, thank you. So my name is Michael Yuan. I'm part of the second state and Cybermiles team. So we started working on sol Sol compiler about a year ago and very excited to share our work with you guys here. And so let me turn on the sharing. All right, can you guys see my screen?
05:32:14.360 - 05:32:20.900, Speaker A: Yes. If you now click on the camera again, we could see you and the screen at the same time.
05:32:21.050 - 05:32:22.470, Speaker B: Okay, let me see.
05:32:29.340 - 05:32:30.650, Speaker A: Okay, perfect.
05:32:31.180 - 05:32:41.212, Speaker B: All right, let me see if I can start. Good. You can still see me, right? You can still see it, right?
05:32:41.266 - 05:32:42.796, Speaker A: Yeah, you're all set up. Perfect.
05:32:42.898 - 05:33:13.068, Speaker B: Okay, excellent. Thank you so much. Yeah, well, okay. The sole team, that's how we position it. It's an llvm based toolkit for solidity and you know, so it's solidity on know, that's where the name came from. It's not very imaginative, but anyway, so we are very distributed team. I live in Texas, but most of the engineers that work on Seoul, they live in Taipei.
05:33:13.068 - 05:33:58.580, Speaker B: And in a minute you're going to know why because a lot of this compiler talent actually come from the semiconductor industry. So that's our background. It's primarily in compilers for chips and for hardware and things like that, and also for enterprise software. Myself has a background in enterprise software. So Haidai Thai from our team would give a more in depth overview of Seoul tomorrow. He has a talk scheduled for tomorrow, so if you like what you hear today from know, make sure that you catch his talk. Oh, well, my publisher made me do it.
05:33:58.580 - 05:35:18.990, Speaker B: So this is a book I wrote last year and it has a lot of solidity and developer tools. And it's probably too much of an entry level book for this audience, but I just want to put it here. It's published by Anderson Wesley in the US. So anyway, let's get started. So first of all, the burning questions you all want to ask is why another compiler? Why do we need another compiler? What were we thinking when we started almost a year ago when we decided to write another compiler? So I want to put up the two quotes with Alec had back in 2018, and he talked about one of the major strengths of Ethereum or any decentralized ecosystem really is a diversity of tools and diversity of software, right? It's decentralization of software. So that's where we see ourselves in this ecosystem, is to provide, I wouldn't say alternative but to provide another way to do another tool chain for a prevailing language like solidity or URL, so that we can have multiple front end, multiple back ends, then to have another toolkit that provide more stability to the ecosystem. So that's where we see ourselves coming from.
05:35:18.990 - 05:36:09.660, Speaker B: So what is it? What exactly is so just that it's solidity on OVM. So at the current state, if you look at the released software of Sol on GitHub, there's three major parts. The first is we have solidity to evasm compiler. EVASM stands for ethereum flavored webassembly, but you already knew that. So it can compile solidity source code to Webassembly, ethereum flavored webassembly. And the second aspect of it, it's Yule to evasm compiler. And another interesting aspect of it is generates EVM targets, the traditional current generation EVM targets with the help of the EVM LVM project, which is project Alan Lee led.
05:36:09.660 - 05:37:16.168, Speaker B: So most importantly, our position of it is not just a compiler that you can use out of the box, it's a collection of tools and libraries to build your own language tools in the Ethereum ecosystem. That's how we see this project going in the future. So here is a GitHub link to this project. It's second state, so it's easy to remember. So before I go further, I want to take a minute to talk about why know that's Ethereum flavored Webassembly, why do we choose that as a compilation target? Why don't we just do UVM directly? First, of course, is that because there's already a solid UVM compiler and it's widely used and we don't really necessarily want to compete with that from the get go we try to choose another compiler target that is up at the coming. And also because as a team we also build our own webassembly runtime. And the mode of that Webassembly runtime is evadone.
05:37:16.168 - 05:38:17.524, Speaker B: So if you go to our other project, it's called SSVM, it's second state virtual machine. It's a fully compliant Webassembly virtual machine. It can be used on the server side and also primarily used on the server side, I would say. And it has a mode that is called evasm mode that you can actually, we have confirmed it passes all the state for evasm tests, so it passes the test suite 100%. And so with so and SSVM you can actually now start an evASm private node and use so to compile your solidity contract into webassembly and run it on that. So it's sort of like a mini testnet and or simply use our testnet. There's a test network that we had in partnership with cybermiles that use the older generation of what they call Ethermint, the ethereum on tenement.
05:38:17.524 - 05:39:08.484, Speaker B: And then we put the ssvm evosum in there to replace the guest virtual machine. So that provide a complete end to end solution that allows people to compile from UL or solidity source code to webassembly bytecode and then run this webassembly bytecode in an actual blockchain. So that's the work that we have done so far. So here is a demo. I'm glad it runs because I don't have to go to YouTube for that. But it's animated, Jeff. So it basically shows that the big chunk of text that you just saw, sorry, this goes too fast, but the big chunk of text you just saw is the compiled bytecode encoded into hex format.
05:39:08.484 - 05:40:04.840, Speaker B: And so this is your standard guest console that connects to our testnet that allows, so it goes over again, it unlock account and put that in there and deploy it as a contract. So what contract that is? That contract is the ERC 20 contract that compiled to webassembly bytecode and then run on the evolution testnet using. So there's a lot of tools, a multiple tools that we have developed so far. So it basically shows you that you can use the console to make transfers from inside the contract. So that's just the work that we have done that we can demonstrate here. So if you go to our software release page, that you can see the current status of the compiler. The current status of the compiler.
05:40:04.840 - 05:40:28.096, Speaker B: So with every release we test all the almost 500 test cases from the U library and we pass almost 80% of it. So here the text on the bottom of the page says the features that are currently supported by.
05:40:28.118 - 05:40:28.690, Speaker D: So.
05:40:31.300 - 05:41:20.610, Speaker B: There are still many features in EO that are not yet supported. We're still working on that, but as I have also heard that your language itself is evolving. So we definitely want a closer partnership with the rest of the solidity team and your team, so that we can have a really strong roadmap that we would be able to support all those features in the near future. So currently it passes over close to 80% of all the test cases of Yule. And what about the solidity front end? It's less impressive. Solidity has 80 testing contracts. Those are not unit tests, but four tests with complete contracts and we can pass 27.
05:41:20.610 - 05:42:02.912, Speaker B: There's still a lot of features that are not implemented, solidity features that are not implemented. So however, we have found some of the solidity contracts we can use. So C to compile it to yo and then use to compile it to webassembly. That path that we have walked for a couple of those contracts. But straight from solidity, we can support one of the most commonly used contracts that ERC 20 contracts. So that's where the demo that you have just saw is the ERC 20 contract written in solidity compiled by so and then deployed on evasive. So below is some of the text.
05:42:02.912 - 05:42:39.532, Speaker B: Here is some of the unimplemented language features in solidity. So as you can see, there's still a bunch of things that we are thinking about. What's the best way to implement even basic features like return multiple value. It's still our roadmap. So Hadadai from our team going to be able to talk more about this tomorrow. That's why we choose to implement some features first and why some are difficult to do well. We just talk about so as a compiler tool.
05:42:39.532 - 05:43:38.956, Speaker B: So as a compiler tool as of today I think is a prototype. So it's not yet ready for production use, obviously because it doesn't pass all the test suites. So it provides some interesting features. And however, going forward, what we really see so as a toolkit, as a library of components that other people can use to build their own languages. So for instance, because it's based on LVM, it's an intermediate language, so it can support multiple language front ends. Right now we have demonstrated partial support for solidity and UL, but it wasn't binding for rust that can compile into LVM, not through our tool, but can be mixed and matched with a rust compiler in that way. And there's more than 20 languages LVM already supports.
05:43:38.956 - 05:44:33.744, Speaker B: So by building on that framework, we thought there may be an opportunity for us to become one of the tools in the tool chain or in the tool chats that people can use. Then I put here is an article from etc course Alan Lee that he talked about. He wrote it yesterday, he talked about building domain specific languages using and then on the back end, on the front end that we are envisioning a toolkit that can support components that can support multiple programming languages. On the back end, we are envisioning the toolkit can support multiple runtime targets. So we have already shown webassembly and we have shown through EVM LVM project. We can support today's EVM. But what about, I thought more interesting use cases or not really more.
05:44:33.744 - 05:45:48.824, Speaker B: You know, one of the popular use cases is the non blockchain crypto use cases. If you look at other projects out there like Facebook, Libra, or the chinese central bank project, the digital ZMB project, those are all, I would say, projects that are rooted in crypto but not blockchain based. So they use a lot of infrastructure that come from the crypto world, like the digital wallet, the smart contracts, things of that nature, but not necessarily blockchain based. Is there a possibility to build a toolkit that makes solidity a more of a more general programming language that can be used in those kind of scenarios? So here's what we mentioned with a toolkit like so that we might be able to do so. For instance, one of the things that has going on in the academic world for a very long time is formal verification. But before blockchain come on, it's very few, very little code has been actually formally verified or have that kind of security. Even in the banks people don't bother to do that.
05:45:48.824 - 05:46:57.356, Speaker B: But solidity is probably one of the early first languages that has a lot of tools around formal verification. But is it possible that can we use formally verified solidity application in cloud computing environment instead of just in blockchain? Right. Can we set up, say, a function of service function as a service or a container service on Amazon cloud that can run solidity code, formally verified solidity code instead of having to have a blockchain on the back end, things of that nature. That is something that from our point of view, it's really interesting that we want to make soul part of the bigger story in the ethereum system as a blockchain system and also in the cloud computing system. So anyway, that's all I have. And again, the project on GitHub is GitHub secondstate Sol. And we'd love to hear your feedback and we'd love to have more collaboration with the community.
05:46:57.356 - 05:47:03.570, Speaker B: And I think I'm two minutes left, so thank you very much. And if you have questions.
05:47:04.900 - 05:47:34.452, Speaker A: Wonderful. Thank you, Michael. Yeah, if anybody in the room has questions, I also saw some people are probably joining from the Americas. We have a raise your hand feature which you can use in case you want to say something. Please raise your hand and let me know. Or also you can put your questions in the GitHub chat, which is solidity. There are still some discussions going on on Yule.
05:47:34.452 - 05:47:51.390, Speaker A: I see. So far, no question on Sol, but if you should have a question later on, please feel free to just put it in the GitHub chat. Thanks so much, Michael.
05:47:51.550 - 05:47:52.500, Speaker B: Thank you.
05:47:53.030 - 05:48:34.560, Speaker A: And yeah, as Michael said, there will also be a more in detail discussion on soil happening tomorrow. Cool. Then we can move on to slightly delayed move on to the next discussion, which will be a big one on upgradability of contracts, or how did we call it, upgradable contracts. And it's going to be moderated by Chris again. So Chris will give a little intro into the problems or the questions we have for you, and we also have hackmd prepared for collaborative notes. Again, I will share it in the GitHub chat. Chris yeah, feel free to get started.
05:48:44.090 - 05:50:19.510, Speaker B: Okay, nice on the minute. This discussion is probably similar to the ones about libraries, where it's more like a brainstorming thing, although there were some specific proposals to help upgradable contracts in the past, so maybe this can be a bit more focused. Upgradable contracts, I think, have three different aspects, or at least compiler support for upgradable contracts has three different aspects, and that is checking whether the storage structure of two contracts that are two different versions of the same deployed contract is compatible, then whether solidity should support some kind of mechanism for proxy contracts. And the third one is splitting code into multiple contracts. But I think that's what we discussed in the libraries section, so maybe we shouldn't have to discuss that anymore here. Okay, let's talk about storage compatibility first. The solidity compiler recently had an update that allowed it to output a JSON that contains the storage structure of a contract.
05:50:19.510 - 05:52:02.330, Speaker B: So in principle at least, if two contracts are compiled with a solid version that supports that, there could be tools that compare this storage layout and see whether it's compatible. The question would be, is that something that the compiler should be able to do? And the problem here, especially when. So the problem here is that we cannot really apply that to the source form of two contract versions, because this source form might be written for a different version of the compiler. So what we could do is compare the JSON. So one thing we could do is have a json file that is the storage layout of an older version of the contract as a input file for the compiler, and then the new version says contract name whatever is compatible with, and then the name of the file containing this JSON. Is that something people would be very happy about? Yeah, having storage layout in a JSON or in something would be definitely neat. If we allow at least third party tool to check different versions and stuff like that.
05:52:04.860 - 05:52:07.176, Speaker A: Santiago, you also want to say something?
05:52:07.358 - 05:53:01.130, Speaker B: Yeah, I think that just having the information, the storage layout, which is something the compiler is already outputting, is fine, and we can develop tooling to make that check. I think the most important thing to get from the compiler is the upcoming part ensuring somehow that we can have storage compatibility either by via fillers or autoplace storage, or by specifically indicating where we want each variable to be placed. That's what I would expect to be given by the compiler, not the check itself. Yeah, if we would have some way of comparing it on source level, that would be different. But maybe the check should rather be done by a different tool. I heard that Richard from gnosis is working on one. Maybe he didn't start yet, so he has to start now.
05:53:01.130 - 05:53:45.920, Speaker B: Okay, then let's talk about ensuring that source is compatible. One point we did talk about here is what about the API? Of course a new version can introduce a new function, but it should not. I mean it can also delete an existing function, but it maybe should not change the parameters. What are your thoughts on that here? That's something that needs to be checked. Does the compiler provide enough structured output that this can be checked?
05:53:50.750 - 05:53:52.118, Speaker A: Santiago?
05:53:52.294 - 05:54:12.020, Speaker B: Yeah, I think that it's same case as with storage layout. That's something that can be handled outside the compiler. Basically with the json API we have all the information we need for that. And besides different contracts, we have different expectations as to whether it's resammer or not to break the API during an upgrade. Breaking storage layout is a much much more sensitive issue.
05:54:12.950 - 05:54:15.300, Speaker A: And Jocelyn also wanted to say something.
05:54:16.470 - 05:54:27.270, Speaker B: Yes, Santago already said what I wanted to say. We already have the ABI information, so it will depend if you want to have check within the compiler or just for third party tools.
05:54:43.870 - 05:55:05.630, Speaker A: Yeah, Jocelyn again, and also I'm just quickly relaying another question from Ellen, could use sembare semantics versioning contracts. Does that mean anything to you guys? Chris, does that make sense?
05:55:09.200 - 05:55:23.780, Speaker I: So I think Ellen is talking about the thing where you using semantic versioning to say should a contract be breaking or not? Right, but I'm not sure what completely the idea here is from Alan.
05:55:30.460 - 05:56:43.320, Speaker B: Again, I think that's something that can be handled by the tooling and by each project differently. Then let's talk about the ways to ensure compatibility. I think there are kind of two ways to do that. Okay, first of all, so one thing to keep in mind is we have to do that both for the state variables, including the inherited ones, and for all structs that are used in storage. Um, yeah, and if we have a mapping obstruct, then this could get complicated. But okay, maybe, yeah, no, that's just a special, the problem is in arrays obstructs. Yeah, but if you have two structs of the same type after each other, you have the same problem, right? The same as with arrays are not a special case.
05:56:46.090 - 05:57:02.400, Speaker A: Of comments also on GitHub, again, not sure if you are monitoring those. Chris Dominic, Nicholas, Dendria and Ellen commented again. Do you see those or should I relay?
05:57:03.300 - 05:58:27.380, Speaker B: No, it's are in my opinion two ways, and I actually hope that all the issues that were referenced are covered by that. One of them is to add fillers, which are unused storage slots that just produce spacing where future storage slots so future variables can be added. And the other suggestion is to move to a completely different place, either by using hashes or by specifying the location manually. Alex is in favor of five, nine, seven. Francisco yes, so the fillers are interesting, but not enough because of inheritance. There's so there are several problems. I don't know if everybody has the context here, but it's interesting to think about the several problems that can come up.
05:58:27.380 - 06:00:11.784, Speaker B: So if there is an inheritance list and one of the contracts in the middle adds a new state variable, then the fillers there can pad things so that that doesn't cause an incompatibility problem. But if there is an inheritance reordering in the linearization, then the fillers there don't do anything. So it seems that they are not enough and that some mechanism for out of place nonlinear storage slot allocation is needed. Maybe, Chris, if you do remember the different proposals that there are to implement that in the language, you could go over that and we can discuss the fillers have to be kind of elastic and that probably just boils down to one of the other proposals. So, and yeah, I think the proposals, there is one proposal where you just specify a location for each member of a struct and for each state variable of a contract. And then the problem is that it can lead to collisions and the compiler has to check whether there are any collisions. And in the end I think collisions are exactly what we want to prevent.
06:00:11.784 - 06:01:02.750, Speaker B: Right. And if you do an update and add a new state variable, then we can move it somewhere else when we edit, but we always have to do that. So I'm not sure whether this is a good solution. And then the other solution is to provide a name or something like that, which is then hashed and produces a storage location, so you do not have too much direct control over the storage location, and the likelihood of collisions is extremely unlikely. Richard.
06:01:03.490 - 06:01:57.150, Speaker I: So why I would prefer the naming solution is also because if you just define a position, theoretically, if you don't have any context information, like what is this variable? Like, you could have two addresses, but they could be completely different, like what they do or what they mean. Obviously, if you then change the position, this would be then, or could be fatal. Why? If you use a hash, this is a little less likely, because the hash itself, if you use a proper name, should provide some context where it's a little bit less likely that you run into this issue. But I'm also not sure if I think I would. In general, this feature should be on a similar level as the ABI V two encoding was in the beginning, because it can break a lot, but it can be very useful.
06:02:00.130 - 06:02:11.358, Speaker B: Why do you think it. This would all be optional, right? So you're saying you have to use a pragma when you want to use the feature. They say Abi encoder v two.
06:02:11.544 - 06:02:48.394, Speaker I: Yes, I think so. I would make it very explicit, because if you. Maybe, I'm not sure, but right now it feels like I'm very in favor of this feature. I would really love to have this. Right. But I also feel like if having this from solidity, if you have. Normally, if you don't use too much inheritance, all those things, it's a lot nicer if it just works out of the box, and then suddenly, because you're unaware, copy code from somewhere and copy in one of these annotations.
06:02:48.394 - 06:02:53.220, Speaker I: It might have unexpected behavior, but maybe I'm a little bit paranoid on this case.
06:03:02.130 - 06:03:04.334, Speaker A: Santiago, do you want to say something?
06:03:04.452 - 06:04:04.150, Speaker B: Yeah, I'm curious about what's the expected space that we're considering for out of place storage, where we're considering on randomizing the allocation of the slots within a small range that would lead to smaller bytecode, because you need to address basically lower positions. Or we're considering using the entire storage slot space, which would make. It would ensure that there are no collisions, but may lead to slightly larger bytecode. I think the idea is to have just hashes of stuff, so 32 byte storage locations. It would increase the bytecode, but not the runtime cost. Perfect. Sorry.
06:04:04.150 - 06:05:59.636, Speaker B: Following a bit on what Richard brought up, I think it's important that whether it's activated via pragma or compiler flag or whatever, it's something that it's easy to toggle on or off, either at compilation time or at the most derived contract level, so that it's possible to share code between people who are interested in using upgradability, and they don't care about these features. One of the main problems we have in the Opensplain contract library is that we need to develop two versions of the library, one that takes care of storage, compatibility and, well, initializers. But we'll discuss that in a minute. And we have the other version that's for vanilla usage. So it would be nice if it's possible to just have one single repository of code, and then the user write at deploy time, compile time, or at the last possible minute, or even when they're on building their Mossy rev contract, then they can specify whether they want to opt in or not to this behavior. So, can imagine this to work pretty well for state variables themselves. But we also need the same mechanism for struct members, right? Would it then be assume we use hashes for all these additional offsets, then the struct would basically turn into a mapping where the offset members are looked up via their key, right? So if we have an array of structs, it has two regular integer members and a third integer member that has such an offset because it was introduced later on.
06:05:59.636 - 06:06:23.990, Speaker B: Then we apply that hash maybe as an additive offset, or maybe in a similar way to a mapping. Richard.
06:06:26.010 - 06:07:07.970, Speaker I: So why I do think maybe mixing these approaches might not be best. But as a struct is very flat and has no inheritance, I think that would be fair to basically, for me, the mapping of a mapping seems overly complex. And I also, theoretically, at least in my mind, I like that the memory of a struct is in one place. And therefore I was thinking if you could look at them separately, like how you handle this instruct looking at this very separately, how you handle this as state variables, and to even maybe start out with the state variables and not supporting it for structs in the beginning, but I'm not sure if that helps.
06:07:09.690 - 06:07:22.300, Speaker B: Apart from inheritance structs and state variables. So members and structs or apart from inheritance state variables are just members of the virtual struct that is the contract, right?
06:07:26.860 - 06:07:27.610, Speaker I: Yes.
06:07:28.140 - 06:08:29.710, Speaker B: So I think it's the same thing. I mean, of course this would only apply to storage because memory is transit anyway. Jocelyn, are you not going to miss some optimization? Because typically in a struct, like if you have two fields that are contiguous and I can fit within one word, in storage, you can have one slot and one store. And if you use a mapping, you will need multiple one, it might not be like a huge difference, but it's worth nothing. I guess if you add a single member, then you can't use that optimization because the space is just, unless we use the padding. And if you add two new members that would fit in the slot, then we could move them to the same location, maybe with the same offset.
06:08:35.980 - 06:09:13.104, Speaker I: Mayor, for the question again of the struct thing, but this is a major difference in the sense of that structs can exist in memory while normal memory, if you look at them, a normal contract, I would see it as a mapping, right? In the sense of your storage location is like the key, and then you have the value. But a normal struct, obviously, since you have the possibility to define the struct to exist in memory, you cannot really have it as a mapping, since we cannot have mappings in memory, right? Because we cannot.
06:09:13.152 - 06:09:16.660, Speaker B: I would just ignore these offsets for memory.
06:09:18.120 - 06:09:38.940, Speaker I: Okay, fair. And the other point for the optimization, if you use the hashes, it might become complicated, or you would have to make this explicit. Or you say you lose this optimization if you turn on this pragma. For me, I think that would be fair. If it's this explicitly.
06:09:45.500 - 06:11:12.738, Speaker B: Maybe about the pragma again, I mean, there will be a special keyboard for that, or symbol or whatever, and as long as you don't use that, then nothing will change. I still don't see very much why we wouldn't need the pragma. It seems like there is consensus on the ability to specify slot for a variable to be defined in the source code. There are some comments about it should be obtained, et cetera, et cetera. I think that can be discussed more in depth in an issue, but there seems to be consensus around this. Does anybody think that having this capability is not a good idea and that it shouldn't be added to the language? I think this might be better discussed. There are some subtle points, like what Santiago mentioned about opt in, that I think should be discussed more carefully.
06:11:12.738 - 06:11:43.150, Speaker B: What do you think, Chris, if we carry on to the other points that you had in mind? I'm not sure if there are so many other points. I just want to spec something out inside the hack committee. We still have half an hour, right?
06:11:46.480 - 06:12:10.440, Speaker A: Yes, we do. So in case you're wondering what Chris is doing, he is writing something down in the hackmD. The link is in GitHub.
06:12:25.410 - 06:14:02.996, Speaker B: Real nice that we have syntax highlighting, and it even knows the keyword storage offset. That's good. So in the issues, there are also proposals to provide much more fine grained access to the storage layout. I'm not sure if that's such a good idea, but this would be a simple proposal that just applies the hashes of the strings as offsets, as offsets to everything that follows. I would have to think that through if this also works for arrays and mappings and whatever, but would that be maybe a good simplistic starting point? Nicolas Anish we can foresee with that is if you want to plan for any possible upgrade, and any of those state variables might change in a way, you'd basically have to specify a search offset before each of those, which is basically equivalent to just providing the actual slot for each state variable. So I'm not sure if I see the use case in which the offset is simpler than just providing key for each state variable and being et cetera. We like to have a solution where you don't have to think about where we don't.
06:14:02.996 - 06:14:08.270, Speaker B: Basically, I would like to have a solution where you don't have to do your memory allocation yourself.
06:14:11.280 - 06:14:19.070, Speaker A: Santiago, go ahead. And also, in case we are not like speaking into each other, feel free to also just talk without raising your hand.
06:14:20.400 - 06:14:41.750, Speaker B: Sure. Basically. Sorry, Chris, I'm not sure I understood what you meant. I'm not having to deal with memory here. I want to echo what Nico said. I think that the proposal of using a fixed annotation to specify the exact slot would be much useful. I mean, not even the exact slot, just the pre image of the hash where you want the variable to land.
06:14:41.750 - 06:15:40.420, Speaker B: Especially because that will help. Yeah, something like that, or even a keyword or something like that, that it's then hashed and gets what will be the position in storage. Basically, in my mind, what we're looking for is something that allows you to give a name to that variable. That could be, for instance, c contract c variable b, or whatever it is. And that name does not change, ever. So even if you rename the variable something, that's a key that remains constant, and that key derives a position within the 32 byte space, that gives you confidence that it's not going to clash with another key derived in another contract that you may be pulling in and inheriting from both of them.
06:15:41.350 - 06:16:19.040, Speaker I: What I liked about the other storage solution, or I do like this one, what I liked about the other one, was that basically for each class, you only would have to define it once, right? Because you could set the storage offset at the very beginning. Before you define anything else and just say, okay, this is here. Like in this storage slot starts all the variables for this contract, and even if you inherit it later on, it's fine. You can handle this all yourself, and you can use all the fillers if you would want to, but you wouldn't have to think for each variable about it, but only once for a contract, right? So I found it nice. But I do get your point here.
06:16:21.170 - 06:16:33.490, Speaker B: How about allowing for the add annotation to be set at the variable level, contract level, or even struct level. It could be similar, only that I think it's a bit more declarative.
06:16:40.400 - 06:16:42.990, Speaker I: For me. That sounds fun.
06:16:45.920 - 06:17:11.170, Speaker B: Where exactly? I mean, you can edit the hacking d please feel free. I added another thing that is maybe a bit more declarative that just says, yeah, this was added later in a new contract version. Okay, but if you add it to the contract, then it will also move the old variables. Is that what you want?
06:17:14.020 - 06:17:14.992, Speaker I: Go for it.
06:17:15.126 - 06:17:21.648, Speaker B: Go ahead, Richard, delegate calling to other okay, I see, yeah, I see the.
06:17:21.654 - 06:18:01.036, Speaker I: Use case also it was a little bit talking about what you had before, right? Like now, theoretically you can only define it once and then it would apply to all of the storage locations, all of the member variables, without you having to worry about all the member variables one by one. So you could just say, okay, I apply a storage offset for this whole contract, and then everything else can be handled again by solidity. Radically. We could also allow additionally to sum, to also edit everywhere else. Just an example, I'm going to edit everywhere.
06:18:01.148 - 06:18:13.670, Speaker B: And so in this example the offset is applied to a, which is the first variable. And in the old version of the contract, the storage would start with b, right?
06:18:16.200 - 06:18:38.750, Speaker I: Yeah, probably. Then if you would have to handle this manually or add a filter filler, right, like in the old one, if you really basically just edit later on this storage ad thingy, then you should probably not do that. I do see your point. I'm not sure what the best way would be, but then I would have to. I think right now I would do this.
06:18:42.160 - 06:18:52.290, Speaker B: We're talking about two different ways to use this. I was not aware of that. So the first way would be to already move it somewhere else in the initial version, right?
06:18:54.100 - 06:19:27.740, Speaker I: Yes, I would probably define it in my contract from the get go, not for when I deploy an upgrade. But I know my contract will be upgradable in the future, so I want that even my initial deployment already is independent of these locations, so that I can upgrade and can do all the magic without having to worry about that. Suddenly they are overriding each other. So I would probably from the get go either annotate all contracts or all member variables so that this is set in stone from the very beginning.
06:19:31.120 - 06:20:03.670, Speaker B: And for this it will also be maybe useful to have a tool that allows you to automatically annotate all the variables on a contract. So you can start with a vanilla contract and make sure that you end up after a completion run with fixed locations for your variables. But I think that's nice to have. Just having the ability to specify a particular location is pretty much all the building blocks we need. Still have to say that it looks really ugly.
06:20:09.720 - 06:20:26.036, Speaker I: I'm also not sure if to me it also doesn't look nice. I'm also more used to this Java Kotlin approach where you write have the annotation above or before it. I'm just not sure how this variables.
06:20:26.068 - 06:20:35.070, Speaker B: Have names, contracts have names. Why do we have to specify this string here? Would it be okay?
06:20:35.520 - 06:21:28.510, Speaker I: So for me, coming from, I don't know why I'm scared about just using the name is I originally come from a little bit outside like the Android world where they also did something like this. And then you had optimizers which changed the name, or obfuscators which made the name smaller, or you refactor a name and then suddenly that would change your storage location just because you refactor your. I don't know, because you had a typo in a variable and you don't think about it, rename it, and then suddenly it's a different storage location. Not sure if it's that cool. And I know on a lot of javas they actually do this if they pass also json and so on. You have to annotate it to be sure that it doesn't break in the future just because of some refactorings. But yeah, I know from simplicity it would be nice if we could directly use the name or something.
06:21:35.220 - 06:22:25.920, Speaker B: Pato, I think you were first. No, my point was already mentioned, so go ahead. I wanted to add there is also an issue in that you can have contracts with the same name on different libraries. I can totally see two or three different libraries having a contract name Erc 20 and today we don't have a namespaces as a first class citizen, so it would be difficult to distinguish them. And also having an annotation like this is the immutable ID or the mutable location of this particular contract or variable makes it much more explicit. Otherwise I can totally see a user just changing an internal variable name because it looks nicer and breaking up their entire storage.
06:22:50.040 - 06:23:21.810, Speaker I: So as a language designer, as the writers of the language. This would be the first time that we would like, if we go with something like the add annotation as other languages, that would be the very first time that we have it as explicit as in the last proposal, right? I'm not sure having it something like closer to a modifier, if that would be more solidity like, but I'm also not sure if it. I'm not sure how strongly you feel about all these not introducing new syntax, kind of.
06:23:32.200 - 06:24:23.560, Speaker B: I wanted to propose, given that we've discussed many ideas around this, and there seem to be a couple of trade offs that are sort of hard to figure out at the best solution for. We could carry on this discussion on issues on the repo. There's another large topics around upgrades that I think should be touched on, which is that of constructors delegate call proxies. They cannot use the native solidity constructor because that'll happen on the implementation addresses storage and not on the proxies. So there's a need for what is sometimes called an initializer function that sort of replicates the work of the constructor, and the issues that coming up with that function is a very manual process. It's error prone. All of the niceities that certity provides around abstract contract inheritance chain, all that is lost.
06:24:23.560 - 06:25:40.042, Speaker B: So if there was support for the compiler to somehow extract the actual constructor bytecode or turn it into a function, or there's ideas that'd be extremely useful. I would make the experience much both nicer, but also safer because of the many guarantees around constructor semantics. So the constructor would only be executed for the first version of the contract, right? No, not even for the first version of the contract. Usually if you are deploying an applicable contract, you're deploying the implementation and you don't care about its state. So oftentimes you don't even run the constructor for it. You actually want an empty constructor because you don't care about initializing any state on the implementation. Is this overlapping with reusing contracts from multiple delegate call proxies or not? Because otherwise you could execute the constructor on the actual thing that will later be the delegate call proxy, then deploy the contract.
06:25:40.042 - 06:27:03.962, Speaker B: So deploy the contract that will be upgraded and so with within with create and return the delegate call proxy as the actual contract. Do you understand what I'm saying? Yeah. The thing is, in order to be able to execute the constructor code on the proxy and not on implementation, you need some way to extract all the constructor logic from the implementation to apply it on proxy, making proxies a feature of solidity. So you say contract is upgradable and what happens is that it starts executing the constructor, but instead of returning the actual runtime code, it calls create, which then deploys the runtime code at a location. And the actual contract that is deployed at the first address is the delegate call proxy with a pointer to the delegate. I think it's super interesting, but I'm not sure if there is already agreement on what flavor of proxies are mostly used. And besides that, that's also an issue.
06:27:03.962 - 06:28:13.040, Speaker B: If, as you were saying at the beginning, you want to reuse the same implementation from different proxies, you would need some way to actually get the constructor code into the proxy, into the second proxy and the next ones. Yeah, you wouldn't be able to reuse that in that case. Yeah, that proposal is very interesting. There are a couple of EIPs around proxies, and they have very different trade offs regarding execution, cost, overhead, and also in some sense security. So I don't think that'll be a straightforward decision for solidity to make regarding which flavor is supported. On the other hand, if there was a way that somehow the part of the creation code that is in charge not just of returning the actual runtime code, but of initializing state could be extracted so that different tools could create this sort of contract that in one single step does the deployment and construction for any proxy flavor that I'd like, that would be a great building block, and I think it's enough for all solutions that I know.
06:28:13.970 - 06:28:28.280, Speaker I: So would that for you only be like an additional field in the compiler output? Because right now we have the deployed bytecode, right, we have the runtime bytecode and just having another one as a constructor bytecode, basically.
06:28:30.650 - 06:28:42.614, Speaker B: Not really the constructor bytecode, because the constructor bytecode includes some bits like returning the actual runtime code, but the part of the constructor that is in charge of actual initialization of storage.
06:28:42.742 - 06:28:46.682, Speaker I: Yeah, that's what I meant with constructor bytecode. Other one is the deployment bytecode for me.
06:28:46.816 - 06:29:42.880, Speaker B: Yeah. Okay. But you would still need a mechanism that prevents the constructor from being run twice, right? Actually that could be taken care by each proxy implementation. Basically the constructor of the proxy, of the delayed call proxy can take care of running that constructor bytecode from the implementation. Yes, what I meant is if that information were to be accessible either outside of solidity or even in solidity, then you could write in current day solidity, the proxy idea that you have mentioned. You could write a contract whose body is a proxy that has a constructor that in turn executes some other contract's constructor on its own storage. And that would be basically what you've described, but it'd be a much more flexible approach, I think.
06:29:42.880 - 06:30:26.540, Speaker B: I think a problem with that approach is that you no longer have insolidity, at least a generic proxy code. You would need to extend from a base proxy for each different implementation contract. You have to hex to include the constructor code. But if we actually could get the constructor bytecode, as Richard was saying, as an output from the compiler, I think we're missing some way of combining the constructor bytecode from a contract with the deployment of a different one. So we would pick the constructor bytecode from the implementation and the deployment bytecode from a proxy. And by deployment bytecode I mean the bit that actually returns the runtime code.
06:30:33.850 - 06:31:35.530, Speaker I: It would be interesting to do this combination on chain, actually, like you said, because it's a little bit looking far in the future. I know, but I have seen these cases where there's very minimal proxy, right there is this EIp for the assembly written minimal proxy, and if you want to deploy it on chain, you basically do some shift to input the master copy address into this assembly code, more or less and similar to that. It would be interesting right now if you would try to, it's not that hard to do. You could append just to your deployment code, the constructor code, and then maybe it would be even run when you use create or something. To be fair, I didn't test it yet, but having something like a little bit more native to solidity, where you could say, okay, this is your constructor code logic, use it, which is probably also quite low level if I think about it. But having some mechanisms would be nice for factory contracts, because I think it's very common to use factory contracts also for proxies, especially with create two logic.
06:31:47.320 - 06:32:45.946, Speaker B: We'Re running into factory contracts. Alex, there's this issue you recently cited again about creating copies of contracts. Alex here. Yeah, I still don't really understand how these extracting constructors would work, and in the end, so basically today it's relatively easy to get the constructor bytecode from the output of the compiler. It's just getting a first set of bytes. The main problem we have hit with that approach is that within that bytecode it's hard coded. The position of the constructor arguments at the very, very end of the entire deployment bytecode.
06:32:45.946 - 06:33:23.390, Speaker B: So that would be one of the very few things that we would need to be able to change. Basically grabbing the constructor bytecode from a contract and modifying those small positions so that they can accommodate for a different runtime bytecode embedded into all the primate bytecode. I mean, another option would be to grab the runtime bytecode from somewhere else. That is maybe what Richard meant. Right, I was talking about.
06:33:26.080 - 06:33:54.024, Speaker I: Yeah, kind of. But this is also how it is right now. Right. And I think we actually had it once on Rinkabee where we had exactly this issue that we do a delegate call which just pulls your initializer from somewhere and then runs the initializer. Right. And the issue was that actually why ever, I'm not sure anymore why, but on Rinkerb it was pointing to the wrong storage. So it just pulled empty code and was executing the empty code.
06:33:54.024 - 06:34:22.064, Speaker I: And afterwards you had a nice uninitialized proxy, but actually on chain it looked everything. All right. So the question is how to make this a little bit more explicit. I think right now we have checks for this, that this cannot happen. But this was not sure. To have some way to support this would be really nice. But I do see your point.
06:34:22.064 - 06:34:23.810, Speaker I: Like constructors are very.
06:34:26.180 - 06:35:18.050, Speaker B: Special thingy. Yeah, this whole topic, upgradable contracts. There is a reason it's not a feature of solidity, because it's really hard to get is nice. I don't know, does anyone of you in the community have specific proposals?
06:35:20.980 - 06:35:24.736, Speaker I: I think the storage location would already be a huge step.
06:35:24.918 - 06:36:10.000, Speaker B: Sure. I mean, this is something we already discussed and said. Yeah, that's nice to have, even if it's a little bit ugly. But I think that's still fine. But it would be really nice to have some kind of nice solution to all these delegate call proxy factory contracts, making it easy to create a copy of an existing contract without having to actually copy the code, things like that. Nicholas? Yeah, this may be a bit of a stretch, but bear with me. Imagine you could extract a contract constructor as if it were a function.
06:36:10.000 - 06:36:42.244, Speaker B: Think of it as a library with an internal function, and that would allow you from a different contract that somehow imports the original one. So the proxy says, hey, in my constructor I just want to call a function. But this function turns out it's actually that other construct constructors, and I can pass arguments and whatever, and it wouldn't be the exact same bytecode. Right. It's just at the solidity level, the semantics of what that function calls are. Clear what that means. It'd be very ugly.
06:36:42.244 - 06:37:59.068, Speaker B: Perhaps, and different from what we had today. But in the whole idea of I now want to call a function and just pass arguments in whatever shape and for that to be filled in by the constructor of the other contract. That seems to be sensible. But how would it work with state variables? If you call a function of another contract as a constructor, how does it initialize the right state variables? The state variables would have to be tied to the search slots, I guess, which is how it always works. I mean, it is a very intimate detail about the contract, right, how it's initialized. So I think that makes sense. I would say that perhaps it's sort of debatable whether such a detail should be exposed, but I think there's a very legitimate use case here, and it's very difficult to otherwise extract this information and to make it usable in a safe manner and not error prone to add on that.
06:37:59.068 - 06:38:38.868, Speaker B: I think that the main point is that here you're not just pulling a function, but you are pulling a function along with all the reference to storage layout from the contract. You pulled it so you could reuse this function, whether it's in a proxy or even move it into a separate contract. You could have a standalone contract that just has the constructor, so you can delay it calling to it. But wherever you pull in this function, this function needs to remember all the storage layout mapping from the region implementation contract. So it needs to be somehow a separate construct. Yeah, that's how. I mean that it's very different from other functions and other constructs in the language.
06:38:38.868 - 06:39:28.250, Speaker B: But then again, this is something very different to what is in the language today. Sorry to add one more thing regarding something you mentioned, Chris. I personally don't think that solidity needs to provide support for. It needs to allow the user to hand upgradable contracts. It just needs to provide the building blocks so the necessary proxies or libraries or tools can be built on top of that. And in that sense I think that just by providing storage, the ability to set storage layout and something to decouple the constructor from the actual implementation, I think those are the building blocks. We need to build different approaches and not just for applicability, also for minimal proxies, for using contracts and many other things.
06:39:35.280 - 06:39:44.160, Speaker A: All right guys, looking at the time, it would now be time for another break. Christie, you want to summarize anything or any last words on upgradable contracts?
06:39:44.660 - 06:40:07.000, Speaker B: Yeah, I think it would be great to open an issue on these exporting the constructor code thing. If we don't yet have an issue on that. Otherwise. Yeah, I think that was a very useful discussion.
06:40:07.340 - 06:40:10.644, Speaker I: One question quickly. Will you open the issue? Should Santiago.
06:40:10.692 - 06:40:13.290, Speaker B: No, someone else please, because I don't really.
06:40:13.660 - 06:40:16.330, Speaker I: Okay, santiago, you or me?
06:40:17.740 - 06:40:22.910, Speaker B: It's all yours if you want to take it. Okay, I'll do it.
06:40:27.600 - 06:41:07.108, Speaker A: Okay, great. Then to wrap this up, we will have 20 minutes break now. So please use the time to stretch your legs, get a drink, relax your eyes. We are live for more than 6 hours now, so I can certainly feel it at this point. And after the break, we will have a few more cool topics. Today we will start with discussion on fixed point types and then we will go into some debugging discussions. On the one hand, we will have a talk from Harry from truffle on tracking mapping keys with the truffle debugger.
06:41:07.108 - 06:41:19.070, Speaker A: And then last but not least, for today, we will have a truffle debugger demo and discussion on debugging data. So please bear with us and see you back in 20 minutes.
06:41:19.680 - 06:41:22.624, Speaker B: Note that the fixed point type discussion was moved, right?
06:41:22.742 - 06:41:50.680, Speaker A: Yes, exactly. At ten to eight. Usually Nick would have had presented the curiosities cabinet of solidity development, but unfortunately he fell sick. So we basically moved the fixed point types discussion to an earlier slot. But you can check that also in the agenda. Everything is up to date. Cool.
06:41:50.680 - 07:00:05.962, Speaker A: Then note to the streamer, please set the stream into break mode. Also, I have received the feedback from you guys that the live stream is a little bit too low on volume. So I relate that information and let's see if we can change something about it. But the feedback has been received. Okay, let's give it a few more seconds. I see some people are joining again, so let's wait a bit. Hello to everybody who just joined us from probably the Americas.
07:00:05.962 - 07:01:04.190, Speaker A: Good morning to you. We are already almost 7 hours into the conference now let's wait until everybody has joined again. Maybe as a nice to know, not so many of you have redeemed their proof of attendance protocol tokens yet. I mean, some of you did, but not everybody. So in case you want to have such a token to testify that you attended this event, please send a direct message to me on GitHub and outlining what you liked or unliked about this event. Via this way I'm collecting a bit of feedback and then I will send you a link to redeem a proof of attendance protocol batch for the solidity summit. Obviously you can also do it tomorrow or whenever.
07:01:04.190 - 07:01:40.576, Speaker A: Okay, let me check if the live stream is back on again. Yes, it is perfect. That means we can get started with the next session. This will be another open discussion session moderated by Chris, this time on fixed point types. And we also have a collaborative hackmd notes thingy again. So in case you just joined, we're using those hackmds to basically take notes. Everybody who is assigned a user in hackmd can also collaborate on that document.
07:01:40.576 - 07:01:53.540, Speaker A: In case you want to drop thoughts in or write something down, feel free to do so on this document that I've put in the solidity guitar chat. Chris, are you there?
07:01:57.930 - 07:02:28.170, Speaker B: Yes, I am. Sorry. Problem with those breaks is that people still write messages into the chat. True. Good. So let's start with fixed point types. Great.
07:02:28.170 - 07:03:24.430, Speaker B: Fixed point types are quite old topic, so we were very close to actually releasing a version of solidity that contains fixed point types and then a community member vetoed against having them. And yeah, we were afraid we could break something or introduce something that nobody wants. And I hope that now with this summit, we are in a better position to actually decide on whether we want to have fixed points or not. And I think also the concerns that this community member had back then are not present anymore. So I'm not sure, should I explain what fixed point types are or.
07:03:29.440 - 07:03:36.770, Speaker A: Your slides seem a bit broken. Again, they are overlap or now they are fixed? This is weird. Did you change anything?
07:03:37.220 - 07:03:39.456, Speaker B: I changed full screen to non full screen.
07:03:39.558 - 07:03:40.930, Speaker A: Oh, yeah, this is better.
07:03:41.380 - 07:03:42.240, Speaker B: This is better.
07:03:42.310 - 07:03:42.992, Speaker A: This is better.
07:03:43.046 - 07:03:49.316, Speaker B: Yeah, but now I have. Now it looks weird. Okay. Looked weird on my screen. So this is better.
07:03:49.338 - 07:03:51.172, Speaker A: I say this is better.
07:03:51.226 - 07:03:51.492, Speaker F: Yeah.
07:03:51.546 - 07:04:08.330, Speaker B: Okay. Sorry. Yeah, it's quite late actually. Yeah. So how much time do we have for this? 130 minutes.
07:04:14.350 - 07:04:15.100, Speaker A: Yes.
07:04:16.910 - 07:05:30.370, Speaker B: Okay. I would like you to make four decisions here, and it worked out really well for the other discussion session. So let's see, the first decision is, should we have fixed points or not? If we want to have them, should they be binary or decimal? And then do we want to have all possible types, like for integer types, so all precisions and all bitwidths that are possible, or just a subset? And what would be the default type? So, like for. For un, so u n is equal to u into 56. Do we want to have something for fixed points like that? And what should it be? Okay, fixed points or no fixed points, we had a similar thing like that for overflows. I really think that formulas that use operators are much nicer to read than functions. So you can implement fixed points in user code, but you will not be able to use operators.
07:05:30.370 - 07:06:03.642, Speaker B: And another problem with implementing fixed points in user code is that you can't really work with literal. So something like 0.5 that just doesn't work because you have to somehow get that into an integer type and 0.5 just won't work. You can do something like here below, two fixed five divided by ten. That works, but it looks really ugly. And yeah, something like 0.12
07:06:03.642 - 07:07:08.032, Speaker B: times a. I think it's much clearer what happens there than here. A mall to fixed twelve diff 100 maybe I didn't find the nicest way to do that. The main argument against fixed points is that people have to know about the implications about precision there. I think people who write solidity code are quite aware that division is not arbitrary precision decision, arbitrary precision division, but that it does round and people have to know what happens with fixed points and what kind of rounding happens there. Yeah. Are there any general comments on fixed points for solidity? Nicholas? Yeah, I have a question.
07:07:08.032 - 07:08:29.680, Speaker B: So when you talk about fixed point, it is already supported in language, it's just not usable because they cannot be assigned to a from and they already support comparison addition subtraction. My question is, what do you see would be the overall scope of the feature insulating? Would you support complex operations like Initiation square roots, or do you think that's more libraries could serve? Yeah, I think we would support the operators and that's it. And the rest has to be done in libraries, at least for the initial version. I mean, we could extend that if that is wanted. So that's basically addition, subtraction, multiplication, division assignments and comparisons, and maybe exponentiation, because we have an operator for that. Yeah, but exponentiation is difficult, so maybe you have to skip that, at least for the initial implementation. Any comments? Does anyone want fixed point types?
07:08:38.980 - 07:08:40.610, Speaker A: Alex wants to speak.
07:08:46.890 - 07:10:22.120, Speaker B: Maybe one thing you haven't mentioned is the, I mean, you only mentioned declaration, assignment, comparison. Guess you explicitly wanted to mention ABI encoding as well, right? I mean, the ABI encoding is already. Yes, sorry. So yes, in open sabbling contracts received throughout the years, many requests for this, and recently we did some sort of community driven government for what is required, what sort of features somebody would expect from such library, and some of what part of the research revealed is that there are already a number of fixed point libraries and they make quite different trade offs regarding space exhibition cost guarantees around overflows. For example, a decision is to just use 128 bits words so that multiplication always fits inside a whole EvM word. And you don't have to worry about that sort of thing. I'm not sure to what extent solidarity could with native support account for all of those, and I'm not sure how a decision.
07:10:22.120 - 07:11:17.784, Speaker B: So what I'm saying is basically the design space is quite big, and I'm not sure if you could arrive at a design that is flexible enough to account for all use cases. And what some users and developer of this library suggested is what if solidity instead provided, as you've mentioned on this slide, a nicer way to write literals and then just left it to libraries use these literals and these new types and do their own thing. But yes, this is something that people want and use already today. Okay, so you listed quite a lot of things. Sorry. Yeah, I think most of the trade offs can be selected by the users by just choosing the right type. So if we implement multiple fixed point types, which I think is the current idea, then they can choose about overflows.
07:11:17.784 - 07:12:12.240, Speaker B: Yeah, I mean, this is what we discussed earlier today. Right? So I would go the same direction as for integers, and I think most of the trade offs with regard to speed and precision or whatever that relate to more complex functions like exponentiation and square root and things like that. And I would still sort of guess there are some certainty. So for example, some libraries use binary instead of having the unit base be a power of ten and say you have 18 decimal place on the next slide. Sorry, but that's what I mean by general, I think. Is there anything anyone opposed?
07:12:16.380 - 07:12:24.540, Speaker A: I also made a general straw poll about do you want fixed point types? If you want to answer that, it's in the GitHub chat.
07:12:27.560 - 07:13:22.324, Speaker B: So maybe then still, let's keep an eye on that poll, but already move on to the next slide. And this is the, I think, most important decision with fixed points here, whether we want to have binary or decimal fixed points. The difference is when we take the number 0.12 and encode that in binary with a precision of eight bits, then it would be encoded as 0.12. Okay, so the actual value stored in the slot in the EVM would be 30, because that's 0.12 times two to the eight. And we already see the problem with binary fixed points here.
07:13:22.324 - 07:14:03.520, Speaker B: This is not so 0.12 times two to the eight would be 30.72. So this number, it is not possible to represent this number without precision loss in binary fixed point types, while with decimal fixed point types this is of course possible. So we just represent this as 0.12 times 100, which is twelve. So even by increasing the precision in the binary encoding, it is impossible to get 0.12 encoded without precision loss.
07:14:03.520 - 07:15:31.060, Speaker B: So the point in favor of decimal representation is that it ensures that all literals, which are usually expressed as a decimal fraction, can be represented without precision loss. While binary might be easier to implement, so the binary multiplication could be easier to implement. And the reason is that when you implement x times y for fixed point types, you have to rescale after. So you do the multiplication on the actual word, and then you rescale by dividing again by ten to the k or two to the k. And if you use binary fixed points, then this rescaling is just a right shift, while for decimal fixed points is a division by a power of ten. And the other problem is if x times y does not fit the word size. So if you have fixed point types with more than 128 bits of width, then they will need another word for the actual multiplication.
07:15:31.060 - 07:16:58.010, Speaker B: And yeah, I think in binary it's a little bit easier to implement that in the end than in decimal, but I'm not 100% sure. So with the shifts, it just fits nice, more nicely. But as who was it Nicholas already mentioned, if we implement decimal or decimal fixed points of a bit width of 128 bits, they are still easy to implement because it's just a regular multiplication, which then takes 256 bits, and then we just divide by the power of ten again. So I think the main disadvantage of decimal fixed points is that they waste a little bit of space. I mentioned that the division is hard to implement, and in general, in general computing, that is true in the sense that division is often an expensive operation, whereas shifting is not. But is that also, for my understanding, if a dev upcode is extremely cheap and ten to decay is a constant, because it has to do with the type which is suddenly known. So that is division by a constant, is that also hard or expensive on the EVM? Yeah, exactly.
07:16:58.010 - 07:17:39.240, Speaker B: It's cheap. Right. So that's not a problem. Yeah, it seems to me like it'd be very similar, if not the same. I guess the only difference would be that you would be shifting by, say, eight, and that is a single, like a push one opcode, whereas if you divide to ten, to the 18, that's a larger number. But that seems to be the only difference to me. Shift is very low, while division is low.
07:17:39.240 - 07:18:45.070, Speaker B: Very low means three and low means five. But I think this is just. Yeah. So I personally would tend towards decimal because it's just easier to understand what is happening. And, I mean, I don't know if we say that the blockchain space has some kind of overlap with the financial space then? I mean, the financial space constantly works with decimal fixed point types with ten to the two precision. I also think decimals are a better choice, and that is the choice that I was going for. I worry many big libraries like ABDK, which is the biggest fixed point library and is used by many mainstream projects in production today, use binary decimals.
07:18:45.070 - 07:19:27.700, Speaker B: I don't know the exact reasons why they chose that, but I do think they have good reasons for it. I'm not aware of them now, so perhaps it'd be good to dig into why that is. I made a Twitter poll some days ago, and I don't know, one reply there was that binary. So decimal fixed points waste space in the upper bits. That was the argument against using decimal. I don't know. Are there other people who have used fixed points or people who have not used fixed points but still have an opinion?
07:19:35.500 - 07:19:43.660, Speaker A: Somebody just commented on GitHub. Agree with all the comments in the stream. I feel like binary representation would somewhat defeat the purpose of fixed point literals.
07:19:49.590 - 07:21:23.900, Speaker B: Yeah, I think that's a big disadvantage of binary, that they can't represent literals. And then the question is, is that the defining feature or not? It looks like all people present here favor decimal. Is that right? Then I would say let's go for decimal. Unless anyone comes up with a big argument against. Good. Then onto the next question. Which types do we want to support? So the current implementation has actually, let's take a quick look at the poll.
07:21:23.900 - 07:21:55.170, Speaker B: Yes, 33%? No, 22% don't care. Total number of votes nine. Oh, ten. Okay, then please vote, and we'll continue on the types we would like to support. How is it? The time?
07:21:56.820 - 07:21:58.210, Speaker A: Seven minutes left.
07:22:01.960 - 07:23:10.040, Speaker B: The current proposal has fixed Mxn, where m is a decimal, specifying the number of bits and the total number of bits, and n is the number of fractional digits or fractional bits. And, I don't know, implementing all types would allow m to have all multiples of eight. But some combinations of m and n are weird. No, actually they are. Yeah. So, for example, if we only have, I don't know, eight bits of width, but a precision of ten to the, I don't know, 20, then we would not be able to represent the number one inside that type. Actually, there's no sensible limit on n on the number of digits, unless we say something like one has to be representable.
07:23:10.040 - 07:23:15.790, Speaker B: Any opinions on that?
07:23:22.260 - 07:23:23.280, Speaker A: Nicholas?
07:23:24.580 - 07:24:18.690, Speaker B: For what it's worth, many projects, including Makerdao, would have their own custom implementation for exponentiation and some complex functions, they use multiple numbers of precision. And they just switch between those when they want to go into high precision but low value mode and then switch back to the other one. So I think there's value for all of those. And the fact that number one represented may not be relevant when you're only dealing with very small numbers. You're saying one being representable is not too important. Yeah, what I'm saying is there's use cases where that sort of thing doesn't matter. And instead of having precision for very low amounts, it's important, but it has to deal what it is, right? I mean, you can have eight bits of width and 20 million decimal points.
07:24:18.690 - 07:24:52.510, Speaker B: The thing is, if we have a gigantic precision but one cannot be represented, then multiplication doesn't make really sense. And fixed point types just with addition, that is also not really useful. Right. And also the implementation gets much much harder because you need, I don't know, ten words to do the multiplication. And the rescaling. The following rescaling. Could you just place accessible upper bound on the decimal 50? Just throwing a number out there.
07:24:52.510 - 07:25:34.800, Speaker B: I guess if somebody needs more, they'll just ask for that, right? I'm really wondering why would you need. It would be great to see an example where of a use case of fixed points where the number one is not representable and you actually need multiplication inside that same type instead of just multiplication with integers or something like that. Okay, let's say, I don't know, other opinions.
07:25:56.960 - 07:26:13.890, Speaker A: There are a few more votes on the poll now. Six voted yes, five voted no, two voted. I don't care. So it's actually 64% against 38%.
07:26:17.660 - 07:26:25.130, Speaker B: What is the last. Let me check. Yeah, I would like to know some reasons people voted no.
07:26:28.120 - 07:26:28.436, Speaker F: Yeah.
07:26:28.458 - 07:26:32.810, Speaker A: Who voted no? Okay, Harry and Alex want to say something. Harry, go ahead.
07:26:36.740 - 07:27:06.884, Speaker C: Sorry. There we to. This is maybe a minor point, but I was just wondering about the case of fixed m by zero, which is obviously not necessary, but might just be included. I was wondering if there was any idea as to what the appropriate way to handle that was, whether to disallow it or whether to allow a minor.
07:27:06.932 - 07:27:08.410, Speaker B: Thing we could discuss in the.
07:27:12.320 - 07:27:16.190, Speaker C: Understood, understood. We can be discussed later.
07:27:20.960 - 07:28:05.918, Speaker A: Alex, you wanted to say something too? Or maybe not. Maybe the cat walked over the keyboard. Okay, Chris, any final wishes or summary?
07:28:06.094 - 07:28:48.746, Speaker B: I would like to discuss the default type. My proposal would be fixed 128 times 18. And the reason is 128 bits makes multiplication easy because it still fits in one word before rescaling. And 18 digits of precision matches the multiplier of ether. So ether as a fractional number could be. I have not enough brain capacity left. And I think 18 is also a very common precision in tokens.
07:28:48.746 - 07:29:35.304, Speaker B: Is that right? It is very common. Not all tokens use 18 as an example, USDC, but indeed 128 by 18 seems to be a sensible, reasonable choice for most projects. I personally am not in favor of default types just because I think they're very implicit. And I tend to be explicit with the size of my integrals. But if you want to have a default, I think this is a simple one. Yes, it has a bit more integer integer part than fractional part, but I think that's fine. Yeah.
07:29:35.304 - 07:30:08.600, Speaker B: The only way to fix that is to have binary decimals, which we don't want. And the point about ether and most organs is a very valid one, I think. Good. I don't have any final comments, but yeah, I reiterate my question on people's reason for voting no. And I don't know, either speak up now or put something in the comments in the issue.
07:30:13.110 - 07:30:35.290, Speaker A: All right, cool. Yeah, you can always continue the discussion online, either in the issue or. Yeah, there's the issue in the GitHub channel. Cool. Next up we have Harry, who will give a little talk on tracking mapping keys with a truffle debugger.
07:30:38.850 - 07:30:39.680, Speaker C: All right.
07:30:41.970 - 07:30:43.694, Speaker A: So we can hear you fine.
07:30:43.892 - 07:30:54.660, Speaker C: Yes, but I need to actually. Hold on. Sorry. There we go.
07:30:55.270 - 07:30:55.890, Speaker B: All right.
07:30:55.960 - 07:31:15.280, Speaker C: And share screen button is. Oh, here. Sorry, just a moment. All right.
07:31:21.670 - 07:31:22.226, Speaker B: It.
07:31:22.328 - 07:32:12.002, Speaker C: And wait for that to go through. Looks like it is. Okay, so, hello, everyone. I'm going to be talking about the truffle debugger and how it keeps track of mapping keys. So this is the thing that the truffle debugger does, right? So the solidity language famously does not know what a mapping keys are. And in the debugger, when we are displaying variables at a given point in the transaction, we want to be able to show what is contained in the mappings. This requires knowing what keys are.
07:32:12.002 - 07:33:06.302, Speaker C: And, well, that's not possible in general, but we can at least keep track of the keys that were used in a given transaction. And we can even do this when we've got nested mappings. Like here, I've got this function that does a bunch of crazy things with mappings nested inside other things. But if we run this in the debugger and we get to the end, it's all there. You've got this map inside this struct inside this array, and you've got all this, but the nested mapping things, that's actually not what I want to focus on right now. Let's close that down. I want to focus on something that looks a lot simpler.
07:33:06.302 - 07:34:04.950, Speaker C: Let's look at this test. This sets up a bunch of things in mappings that look very straightforward. We've just got a boolean mapping, some bytes mappings, some integer mappings, an address mapping, and if we skip to the end just a moment there, we can see it's all there. But the surprising thing is that. Let me close this down. The surprising thing is that keeping track of all this is a bit more complicated than you might expect. Well, so I mean, the first question is, how do we do it at all? And the basic answer, which I've sort of typed up on the right, here on the left, I've got the relevant part of the code, which I'm afraid is rather opaque.
07:34:05.030 - 07:34:05.660, Speaker B: But.
07:34:08.510 - 07:35:09.754, Speaker C: You'Ll see there's. So the basic version is that the truffle debugger, in order to tell where we are in the code, right? It uses the source maps that solidity provides, right? We have the bytecode, we have the source map. We know where we are in the bytecode, we can find where we are in the source. And then the other thing it uses is the ast, the abstract syntax tree representation of the source that solidity provides. So if we have where we are in the source, we can then map that to a particular node in the abstract syntax tree, and we can therefore use various information about that node. So the basic version of how this works is that whenever we are on a node and are processing the node, and it corresponds to an expression, we store the top word of the stack as that node finishes and we associate it to that node as well as to the current stack frame and similar stuff. And I said the top word of the stack.
07:35:09.754 - 07:36:00.480, Speaker C: Some types use up more than one word on the stack. So really it's the top n word stack is appropriate, one or two. And then whenever we get to an index axis for a mapping where we're accessing one of those mappings values, right, we look at the expression that is the index and we decode it, and then we say, okay, that's our mapping key, let's associate it to that mapping. So this is pretty simple and it works fairly well. Like I said, it's a pretty good system that Nick came up with, but there are some wrinkles in it. And so, first off, what do I mean when I say associated to that mapping? Here is.
07:36:00.850 - 07:36:01.760, Speaker B: Come on.
07:36:04.050 - 07:36:46.240, Speaker C: Yeah, I have sort of text slides here. What does it mean when it's associated to that mapping? An early version associated mapping the aft node that obviously has various problems. Okay, so I mean associated to the address and the storage slot. How do we get the storage slot? Same mechanism. When we pass over the node that is the correspondence to the mapping itself that we're indexing into, we stored the top word of the stack and that's our pointer. And we actually do a bit more than that in order to keep track of some other information. But I don't want to go into that here, because then I would not have time for the rest of the talk.
07:36:46.240 - 07:37:42.762, Speaker C: Okay, so we have this basic version, and now we start getting to the wrinkles. And the reason that handling all these things is not actually so simple. Oh boy, I'm kind of about to spill the secret sauce here, I guess. But hey, our debugger is open source, so it's no secret. Anyway, so what about these string literals here? That doesn't seem like a problem. They're just string literals, right? Except thing is, think about the process I described for how we handle these things. In order to get the information for the index node, we have to step through that node.
07:37:42.762 - 07:38:23.020, Speaker C: At some point there has to be some actual EVM instruction in the bytecode, that is source math to that range of the code. And for some nodes that doesn't happen. And string literals are an example of this. I say string literals, I mean also hex literals, those are considered by polymer gig bits to be essentially the same thing. What's our solution to this? So let me actually go into the code here into the code mapping saga. Yeah, we've got this tiny bit of code here for cleaning booleans to handle out of range booleans, make sure they can treat it as true. I'm not going to go any more into that.
07:38:23.020 - 07:39:26.894, Speaker C: And oh, by the way, you may notice, why is there a loop here? We're decoding mapping keys, right? It's just like what I said, doesn't involve any sort of looping process. Why is there a loop? We're going to get to that, but one thing at a time. So in order to handle string literals, we've got this special thing where before the main case down here, this here is the main case. But before that we've got this special case to handle string literals and actually some other things. If you go ahead and read the comments I've written there, where if our index is a simple constant which includes string literals, we don't use stack at all. We just read the information straight out of the ASP. This object here is one of our internal pointer objects that we use for indicating data locations, such as a spot on the stack, a spot in memory and whatever.
07:39:26.894 - 07:40:10.362, Speaker C: And in this case it represents not a spot in memory or storage or whatever, but a spot in the ast that we are going to read the data out of. Okay, that lets us handle string literal. So here's our revised process. We're going to do what I every time we process the node, we're going to put the top word of the stack, or top two words, and then when we get to the index axis, we're going to read the data off the stack for the index, and we're going to decode that, and that's going to be our mapping key, except for string literals, but then we'll read it out of the aft itself. But the next problem is what I already said. Not all types take up just one word on the stack that's easy enough to handle. Some types take up two words on the stack.
07:40:10.362 - 07:40:11.326, Speaker C: I already mentioned that.
07:40:11.348 - 07:40:12.350, Speaker B: Let's skip it.
07:40:12.500 - 07:40:42.780, Speaker C: Okay, so we got a revised version. What I said, but there's another problem, decoding pointers. So I skipped over this before. I said, oh, let's just decode the data from the stack. Now, what if it's a pointer to memory or to storage or to call data? Well, by itself that's not a problem. Our decoder knows how to handle that. It knows to go look up the appropriate information in memory or storage or call data.
07:40:42.780 - 07:41:35.574, Speaker C: But there is a little bit of a problem with making sure it knows the right type here. So if we look at the code here, we see this crazy thing where I've got a spliced definition, sorry, some of these names are a little out of date. Misleading definition here might be better thought of as node. We've got a spliced node where we take two different Asp nodes and we kind of splice them together. And why on earth would we do that? Well, we want to decode according, so when we decode, right? Obviously solidity is a statically typed language. So if we want to decode data, we need to know in advance what type we're decoding. And if we have a mapping and its keys are strings, it will be reported as its keys being in EIT.
07:41:35.574 - 07:42:29.420, Speaker C: It will say keys are memory strings, but we might be giving it to a pointer to a story string or recall data string. Now, in general, we want to decode according to the type of the mapping keys, right? Not the type of the particular expression because there might be an implicit conversion, right? So we want to decode according to the type of the mapping keys. But if the type of the mapping key says memory string and we're actually dealing with a storage string or a call data string, we're going to get nonsense. The decoder is going to repointer as entirely the wrong type of pointer. It's going to look in entirely the wrong place. So we have to do this sort of crazy splicing thing where we take the node that defines the mapping keys and splice onto it the location of the actual index expression. That's where we've got this splice location function here.
07:42:29.420 - 07:43:14.266, Speaker C: All right, we've got that, we've got that. We've handled that. We've got a revised process here. We're going to decode the word from the stack, but for string literals we're going to read the value from the ast instead. And also we have to do the splicing thing. But what if the key is a constant state variable? Because remember what I said earlier is that in order for our process to work, the key has to be source mapped to at some point there must be some actual, right? We have to actually step through that key. And for constant state variables this doesn't happen.
07:43:14.266 - 07:44:04.246, Speaker C: Now if the constant state variable is part of a larger expression, that's the key. This is fine, but if that is the entire key, it's just going to get skipped over and it won't work. So what we have to do is here is the case for handling constant state variables. This one is kind of a nesting nightmare to some extent. If it's a constant state variable, what we have to do is we have to look up the definition of that constant state variable. We have to look at the node that, we have to look at that index node and we have to say oh, this is the constant state variable and its definition is over here. And look at that ast node and then we can read the information out of that, assuming it's a fairly simple constant.
07:44:04.246 - 07:44:26.322, Speaker C: Anyway, if you do something crazy in your constant definition, we might run into some trouble and we might fail to keep track of the key. But I'm assuming that's a fairly minor case. Regardless, I like to be comprehensive. So we can handle most constant state.
07:44:26.376 - 07:44:28.740, Speaker B: Variables, okay.
07:44:32.150 - 07:45:10.890, Speaker C: We can handle ordinary keys, handle pointers, handle string literals. We can't handle constant state variables. But what if the key is a hexadecimal literal. And the key type is a bytes end. Like what if it's being used as a bytes end rather than as an integer, which is something that I made sure. Now why would this be a problem at all? Well, here's the thing. Hexadecimal literal, from solidity's point of view, that's an integer.
07:45:10.890 - 07:45:34.402, Speaker C: So when we put the raw key data on the stack, it's going to go on the stack as an integer. Left padded. Right. It's right aligned. So if you do this with zero XFf here, it's going to go on the stack with zero XFf on the end here. But this is a byte, not an integer. And those are right padded.
07:45:34.402 - 07:46:48.990, Speaker C: Left aligned. The actual value is the mapping key that would use to fit. So if we didn't have any special handling, we would put on the wrong mapping key and we'd be looking in the wrong place. The decoder would just be like, it would just look at this first byte here and be like, oh, I guess the mapping key is zero X and that's not correct. If we go back to the code here, you may have noticed a while back when I was talking about string literals, the code here talks about it's not just for handling string literals, for handling hexadecimal literals too. And there's some special stuff in the decoder so that it knows that when it's reading a, I mean, I say hexadecimal literals, really it covers any numeric literal, but it knows when it's reading a numeric literal from the asT, both string and numeric literals will read them out of the ast instead of from the stack. And it knows when it's doing this that if it's decoding as a byte, then it has to shift it appropriately.
07:46:48.990 - 07:46:56.302, Speaker C: Okay, can I ask you a question? What?
07:46:56.436 - 07:46:57.474, Speaker B: Can I ask a question?
07:46:57.592 - 07:46:58.114, Speaker C: Yes.
07:46:58.232 - 07:47:14.594, Speaker B: Can you go back to the, back to the slide? You said that the constant is put right aligned onto the stack. Is it then discarded when the mapping location is computed?
07:47:14.722 - 07:47:19.430, Speaker C: No, of course not. Obviously it has to be left shifted in order to be used, but.
07:47:19.500 - 07:47:22.338, Speaker B: Okay, it's right aligned.
07:47:22.354 - 07:48:06.280, Speaker C: Okay, then yeah, you're right that obviously it has to be left shifted in order to be used. So obviously it goes onto the stack of that at some point. But the question is, does it go onto that at the stack at the point we can capture? This actually gets into some stuff I skipped over. So normally we assume when we get to a node that the last map structure for that node that the next thing on the stack is what we want. There's actually some cases where that's not true because it goes into unmapped code, and so we have to look ahead to the next mapped instruction. When I say mapped unmapped, I really mean like mapped to minus one solidity internal step. And so it's actually possible that this could have been handled by that system.
07:48:06.280 - 07:48:35.380, Speaker C: I haven't checked that. That system actually came later chronologically, so I never thought to check that. Regardless, in this case, reading it out of the aft is how we do handle it. It's possible we could handle it instead by looking a little bit ahead instead. But I haven't checked. Right. The problem is that it has to be at a point that we can detect and know aha, this is where it is.
07:48:35.380 - 07:49:11.226, Speaker C: So yeah, anyway, there is one remaining problem, and you'll notice I still have not explained the answer to the question why on earth is there a loop here? So let's skip down to the bottom of this loop and you will see why there is a loop here. Or a better way of saying this is the example. So here I have this address map, and for a while what would happen.
07:49:11.248 - 07:49:11.820, Speaker B: Is.
07:49:14.750 - 07:49:55.850, Speaker C: This first assignment would work fine, we'd keep track of it fine, but this second one wouldn't. My thought is there a problem with addresses? No, the problems has nothing to do with addresses. Problems has to do with certain type conversions. Address this doesn't work as a mapping key, or didn't. It does now, obviously, but it didn't work as a mapping key because the address conversion from contract at the EVM level it's a no op. There's no actual EVM instruction that corresponds to the address conversion. So there's no instruction to get source mapped to it, which means once again, no value gets stored.
07:49:55.850 - 07:50:50.714, Speaker C: And you could see this with other type conversions as well. So like byte one, that would work fine because that type conversion involves a shift. But address this or int one, those are no ops. So the problem would occur. And in sufficiently old solidity there was unary plus, which is another no op. So by the way, this is kind of the opposite problem of the hexadecimal literal problem, right? So this problem is where there is a conversion in the source code but no actual instruction in the EVM, whereas the hexadecimal literal problem was there was a conversion instruction in the EVM, but no corresponding node in the source code. Unfortunately, that's the only type conversion, type of type conversion where that happens.
07:50:50.714 - 07:51:50.346, Speaker C: But there's several sorts of type conversions, where this happens, where it's at the EVM level, it's a no op. So how do we handle this? Well, if our decoding has failed thus far and the node type for the index expression is a type conversion, we have to make sure that it has failed this far. Because if it's a type conversion that isn't a no op, then we don't want to do this. But in that case, things will have worked already. But if things have failed thus far and it's a type conversion, then we look inside of, we look inside the arguments of that type conversion and we try again. And similarly with unary plus, if you're using really old solidity, is we will look inside the unary plus, and then we will go back to the top of the loop and try the whole thing again. And that's how we're able to handle these no off type conversions.
07:51:50.346 - 07:52:23.306, Speaker C: And so with this revised, that's why there's a loop in mapping key decoding. And with this revised process, with all these wrinkles, we are able to handle and keep track of basically any mapping key you can throw at us, except maybe really complicated constant state variables. But that's not a common case. We can handle pretty much any mapping key you can throw at us, and that is how the truffle debugger does it. And thank you for listening. And I don't know if there's time for questions, but.
07:52:23.328 - 07:52:24.442, Speaker B: Yeah. Cool.
07:52:24.496 - 07:52:48.030, Speaker A: Thank you, Henry. Yes. We have a couple of minutes for questions left. If there are any questions in the room, let me check. You could raise your hand if you have a question in the room. Let's also have a look at the GitHub chat. Any questions?
07:52:54.080 - 07:52:57.710, Speaker B: I just wanted to say I'm really sorry that you had to go through this hell.
07:52:59.440 - 07:53:05.010, Speaker C: Hey, I mean, this is the job, right? If you want to.
07:53:08.900 - 07:53:41.150, Speaker A: Okay. Does not seem like it. If any questions pop up during the next minutes, feel free to just put them in the solidity GitHub chat, and then we will make sure to relay them. Yeah. And next up is our very last session for today. Are we early, by the way? Yes, we're five minutes early, but I think everybody that is needed is here already. Yes, and for the last session of the day, we have.
07:53:41.680 - 07:53:45.804, Speaker B: I would also have some questions for the trophy debugger in general.
07:53:45.922 - 07:53:47.950, Speaker A: Oh, yeah? Then go for it.
07:53:49.360 - 07:53:53.950, Speaker C: Sure. Yeah, I'm capable of talking about that, that's for sure.
07:53:57.600 - 07:54:10.310, Speaker B: How much infrastructure do you need to debug a transaction? So do you need the contract to be compiled through the truffle framework. How much do you need?
07:54:11.720 - 07:55:06.360, Speaker C: So the truffle debugger. Technically no. The truffle debugger does read everything out of the truffle artifacts. Notionally you could present things in a different way. It does sort of assume that artifact format, but the artifact is basically just storing the compilation information, right, so that the solidity compiler produces the various compilation outputs. I mean, there's some other things in there as well, but I don't think we mostly use that other than the contract name. We do store some things in there somewhat idiosyncratically in a slightly different form than the compiler produces.
07:55:06.360 - 07:55:33.150, Speaker C: But notionally, if you just stored all the compiler output in your own form directly, you could just shim that in order to make it work. I don't think there's. Obviously, it is most convenient to use it with truffle because, yeah, we have everything in the right format already. That's how it's made to work. But notionally you could ship it to work with.
07:55:39.530 - 07:55:43.560, Speaker A: I'm not sure how to pronounce your name, but feel free to jump in.
07:55:51.190 - 07:55:52.550, Speaker B: Connection lost.
07:55:53.050 - 07:55:54.280, Speaker A: Now he's gone.
07:55:54.810 - 07:56:08.170, Speaker B: My browser tab crashed, as you called on me. I was just going to say there is one other piece that is essential for the operation of the truffle debugger, and that is access to the debug trace transaction.
07:56:16.510 - 07:56:29.834, Speaker C: Chris asked specifically about compiling, and so I got maybe a little over focused on that. But Nick is absolutely correct. The debugger is only going to work if you can do a debug trace.
07:56:29.882 - 07:57:06.486, Speaker B: Transaction and do Ethereum debug trace transaction. Or more flexible. Quiet. Can you speak up? I couldn't hear that debug trace transaction from Go Ethereum. Or what can it work with Go Ethereum, Besu and Ganache. And Ganache has a forking mode which I was unable to get working last night, but I've gotten it working in the past. If you're running an archive node, you can fork or have access to an archive node.
07:57:06.486 - 07:58:05.902, Speaker B: You can fork off of that node in Ganache. Even if the underlying node doesn't provide debug trace transaction, Ganache will recreate that endpoint for you, but your mileage may vary there. Okay, nice. So I think we'll have a session that tomorrow. I think we kind of forgot how much there is to speak about that, about this postcode repository. And I would really like to get it into a state at some point where you can just tell a transaction has the debugger and the debugger will use that repository to fetch the source code, recompile it, generate all the artifacts it needs and run debug trace transactions and actually do actually debug transaction on main net or wherever. Yeah, that's in our sites as well.
07:58:05.902 - 07:58:32.600, Speaker B: Like truffle debugger could spin up ganache and do the forking for you if your node doesn't provide access. And you could go to, well, on the topic of the session tomorrow, go to the decentralized contract verification system and load the source. Or just go to etherscan which already has a repository of verified contracts. Yeah, I would like to get this on the roadmap in the next couple months. I think it would really add a lot of value.
07:58:33.690 - 07:58:45.018, Speaker A: Nice, Chris. Just as an info, your volume was like super low and it was hard to understand you. Just for the next session I just increased it.
07:58:45.104 - 07:58:46.678, Speaker B: Did that help or not?
07:58:46.864 - 07:59:05.140, Speaker A: It helped for like three words and then it was bad again. Okay, but anyways, just moving right to the next session. I think first Nick will give us a demo anyways of the truffle debugger, right?
07:59:05.990 - 07:59:09.026, Speaker B: Yes. And I have a couple of slides. Let me see if I can figure.
07:59:09.048 - 07:59:10.180, Speaker C: Out how to share.
07:59:10.790 - 07:59:18.360, Speaker A: And also before we dive into this, there's some background noise. Do you also hear this? Maybe it comes from Harry's computer again, maybe.
07:59:18.730 - 07:59:24.630, Speaker B: Sorry, my computer. If I could have 30 seconds, I can grab headphones. My computer is really slow. I apologize.
07:59:24.710 - 07:59:27.094, Speaker A: No, it's gone. I think it was Harry.
07:59:27.222 - 07:59:42.800, Speaker B: Oh, ok. Well then let me go ahead. Cool. Okay, so let me get this presentation link in the chat for you.
07:59:52.540 - 07:59:53.016, Speaker I: All right.
07:59:53.038 - 08:00:53.204, Speaker B: So I wanted to provide some background to all of the different moving parts that truffle provides for debugging and decoding. And you've already seen quite a bit of the effort involved in decoding with mapping keys. So to kind of give an overview of it, there's a number of core components involved, and the one that is perhaps most recognizable is this truffle debug command. That's a command line debugger. You give it a transaction hash and it gives you a repl where you can type step, next, step over, et cetera. But this is powered by a library truffle debugger. And the truffle debugger library just takes like a web3 provider and a list of compilations and gives an interface, a JavaScript interface for doing that stepping.
08:00:53.204 - 08:01:49.336, Speaker B: What truffle debug does is it just wraps this with a repl interpreter and a bunch of display logic. But besides that, besides our core debugger functionality, we have to decode all this data. And so we have two packages for doing decoding. Firstly, we have truffle decoder, which is a new high level package. You give it a contract instance or a project and it will let you see all of the state variables in that same level of detail that Harry showed with mapping keys like nested mappings, nested structs, arrays, et cetera. Truffle decoder gives an interface for getting a lossless representation of those. Now, both of these two packages are powered under the hood by a package called truffle codec, which handles all of that core decoding logic itself in a way that requires very few dependencies.
08:01:49.336 - 08:02:42.792, Speaker B: The only dependencies that truffle codec requires are things like BN and other data manipulation packages. But it makes no network connections of its own. It's just this standalone piece that knows how solidity organizes its storage. As part of this package, we need a way to represent these decoded values in this lossless way. And so we have a sub module codec format which provides this lossless, machine readable representation of both values and types. So you can see if you're dealing with a UN 256 or a UN 128. And then all of this stuff is used in several other places, but most notably it's used in truffle test, which today decodes events using our decoding functionality.
08:02:42.792 - 08:03:21.800, Speaker B: And as of tomorrow, when we do a release, you'll see it will report stack traces. So those are the moving parts I can now switch over to show you a demo. I'll start with the demo of the debugger, just really to increase awareness, since we think it's really quite robust these days. And so I wanted to show off some features. So rather than write some complicated solidity code myself, I decided to find a project. And so tornado cache has some pretty complicated solidity code. So I decided to use that as an example.
08:03:21.800 - 08:04:18.744, Speaker B: And you'll see, I'm going to be debugging. They have a contract ERC 20 tornado. For those of you that are not familiar, tornado cache is a privacy mixer, mixes tokens using Merkel proofs, and tornado is implemented as a base contract tornado. And then it has a derived instance for ERC 20 and then a separate derived instance for s itself. We'll be debugging ERC 20 tornado now because it's a little more interesting. So if we look at contracts tornado, we're going to be debugging the withdraw function. The withdraw function is defined in tornado, but we're going to be calling ERC 20 tornado.
08:04:18.744 - 08:04:59.440, Speaker B: And I'll show you where this starts. What are we going to debug? Well, I put this, and this is an experimental feature we have in test debugging, where you can take any truffle contract interaction. Before my change, the code looked like this. This is just a truffle test. It does a tornado withdraw. And so for this demo, I'm just going to put debug invocation here, and then we're going to do truffle test debug. And while that's going, I'll just make sure I haven't disconnected.
08:05:00.100 - 08:05:00.850, Speaker C: Cool.
08:05:05.300 - 08:05:51.284, Speaker B: Pardon my computer for being slow. Seems to slow down with screen shares. So this is starting up truffle test. It's doing a fresh compilation here to make sure it can get all of the information it needs to actually run the debugger. And this is just the tornadoes tests they're just running. So their tests print out those two addresses, and then it will proceed with the tests and you'll see shortly. That's out of order.
08:05:51.284 - 08:06:36.404, Speaker B: Okay, well, that's a preview of the next demo, but when we get to the withdrawal, you'll see that this will break and get into a debugger instance any day. Just a quick question. Hi, Victor. Here, where you're adding a weight debug into that code. So this is just adding specifically the.
08:06:36.442 - 08:06:41.728, Speaker C: Debug functionality onto tornado caches already existing truffle tests?
08:06:41.904 - 08:07:06.844, Speaker B: That's correct, yeah. So truffle gives you this. It's experimental, it doesn't work in all cases, but it gives you this global, this debug global, which wraps a truffle contract interaction. So this is like tornado is a truffle contract instance, and this is an existing line of code. And we just wrap it and truffle test then hooks into this. It's like, oh, you made a transaction. Here you go.
08:07:06.844 - 08:07:32.916, Speaker B: Let's debug it. And if you don't put the debug flag on your truffle test command, it won't run this. It'll give you a warning saying you use the debug global, but you didn't pass the debug flag. Okay, thank you. And this acts as a pass through. So if you continue the tests after the debugger, you'll still get logs, the tests will still run. So anyway, here we're into the debugger now.
08:07:32.916 - 08:07:56.444, Speaker B: So why don't I pull up that contract again, erc tornado. And we're going to go next. And immediately, the debugger knows that we're no longer in the same file. Right. Withdraw is not defined by erc 20 tornado. It's defined by the base tornado. And so we have to recognize the jump from one source file to another, and that's fine.
08:07:56.444 - 08:08:50.984, Speaker B: So I'll just hit n to step next and we find ourselves in another file. So the truffle debugger keeps track of all of this by knowing, thanks to solidity's source maps that they provide and our own logic to figure out what are the base contracts? Because if you look at tornado, tornado itself is a derived contract of a Merkel tree with history and a reentrancy guard, and it works just fine. So let's jump to somewhere deep in this transaction, there's this verifier that is stored. Well, first we're on this tornado contract, and we have to deal with this verifier. So what is that? Well, we don't know what it is. That's fine. Let's set a breakpoint.
08:08:50.984 - 08:09:15.156, Speaker B: So let's look at the verifier contract. And there's a verify function somewhere in here that takes some input. I don't know how any of this stuff works. It just looks complicated. Let's debug this. So what line is this? 192. So we'll set a breakpoint for verifier sol online.
08:09:15.156 - 08:09:37.976, Speaker B: One nine two. And let's just continue to that point. Can you move up your window a little? Because the lower half is usually blocked by all. How's this? Thanks. Yes, and I think it's a little off the screen too. Cool. So we're in this verify function, but how do we get here? Well, let's just look at the stack trace.
08:09:37.976 - 08:10:06.390, Speaker B: So, yeah, we're on verifier line one nine two. And we came from line two two four. And from there, we came from two three three. We can look at all of the variables here. So you notice that proof was passed in as a memory struct. So what does that look like? Well, it has a bunch of fields, and each of the fields have a bunch of fields. You can see that we decode those just fine if we step to the next line.
08:10:06.390 - 08:10:40.816, Speaker B: Let's step over so we can get a value for a different memory struct. See what that looks like. Well, it's a different struct. You can see this all decodes with no problem. All right, we're still coming from there, so let's just step up out. Can I ask an annoying question? Yeah, please, can I step back? No, you can't. The architecture supports it.
08:10:40.816 - 08:11:00.868, Speaker B: It's just never been implemented. Okay, well, supports the loose word, Harry. Don't correct me. So, yeah, notice now that we are on two, two, four. If we step out again, we're going to be on two, three. Three. If we step out again, we're going to get pretty close to the end of this transaction.
08:11:00.868 - 08:11:35.830, Speaker B: Right. We're on tornado soul 87. And there's more I could show, but in the effort of time, I'll just show one more thing, which is that if you want to see a list of all the variables that are available in scope at a particular point in time, you can just type V and you can see all these. This includes any decoded mapping keys that we're aware of and pretty much decodes anything we can figure out. Call data variables. Well, call data pointers, memory variables, et cetera. And all the various globals are provided as well.
08:11:35.830 - 08:12:26.260, Speaker B: So that's pretty much it for the debugger portion of this demo. Does anyone have any questions? Before I move on to show off the core decoding functionality, I have one question. Let's say I have this tornado contract and it's breaking somewhere. Let's say you just muddled in the code and you broke something and you called this debugger. How would the debugger show you what is breaking or where it's breaking? Really high level question. Yeah. So as of last week's release, Truffle debugger will print in red the stack trace when it gets to the end of the transaction, saying, this is why it failed.
08:12:26.260 - 08:13:12.016, Speaker B: But you could step through yourself manually to kind of identify the place where it failed. But hopefully the stack traces will assist that. What happens now is the stack trace is captured when there's a revert. This is all thanks to Harry's recent work. When we hit a revert, we figure out what the stack trace was, and we save that for the end so that we can report it. Does that help? I've been using Truffle here and there as a development platform for testing, and generally when something goes wrong, there's times where I feel, oh, something reverted, and then I have to go through and.
08:13:12.118 - 08:13:13.788, Speaker C: Manually try and figure it out.
08:13:13.894 - 08:13:32.424, Speaker B: I'm not very good with debugging. This is something new, right? This is a new feature. Yeah. So stack traces in the debugger itself were released last week. We're going to be putting this functionality into truffle test in this week's release. Cool. Yeah.
08:13:32.424 - 08:14:14.996, Speaker B: So stay tuned for that. I was tempted to show off that functionality, but I'll wait for the release. So as for the decoder, so I have some examples here. I have testdecoder test Js and this prescript down, it imports two packages, the decoder and the codec. It grabs the ERC 20 tornado and then it grabs all related artifacts. What do we do? Well, we get the deployed instance, then we construct a decoder, and we just want to see what all the decoder variables are. Let's see what that looks like a whole test.
08:14:14.996 - 08:16:29.960, Speaker B: And I'll just explicitly say I want decoder test Js not only what the value of each of these variables is, but which inherited contract they come from, right? Like zeros is not defined in ERC 20 tornado, it's defined inside tornado, inside Merkel tree with history. And you can get this information, and this is in a human readable format using our result inspector. But let me show you one more example, which is this decoder raw because this decoded information is represented in a machine readable format. And this is to address kind of a need that we've seen in the community where existing decoders, solidity data or ABI decoders, they just convert to the native JavaScript types like in the JavaScript ecosystem. If you use one of the existing decoders, you'll just get a string literal and you don't know if it's supposed to be a bytes array, if it's supposed to be static length bytes array, a dynamic length bytes array. And so we wanted to make sure that we could capture that information in our decoding so that we can control the presentation and you can see what that looks like. So if you look at the token state variable, token is an address.
08:16:29.960 - 08:17:14.850, Speaker B: So we know that we say oh, token is of type address and it's not payable. And here's the value. And if you want it as a string you can get it like that. But we can also look at more complex types like verifier. Verifier is a contract. So how do we represent that? Well, we have a type class contract, and so what is it? Well, it's a known contract at this address, and we even know what the name of the contract is. And so you can see this information provides this lossless representation.
08:17:14.850 - 08:17:45.230, Speaker B: So you can have this very clear window into what data is stored by your contract, but more this package, truffle codec and truffle decoder, they can be used not only to look at state variables, just for this demo I did state variables, but we also use it to decode events. We can use it to decode return values, revert strings, and inside the debugger, we use it to decode values on the stack and memory storage, et cetera.
08:17:47.190 - 08:17:49.854, Speaker A: We have a question, Mick.
08:17:49.982 - 08:17:50.994, Speaker B: Oh, please.
08:17:51.192 - 08:18:02.630, Speaker A: Alex, does the debugger support assembly blocks, e. G. Displaying variables from assembly blocks? I guess even the tornado code may have it for calling the pairing pre compile.
08:18:03.690 - 08:18:08.870, Speaker B: Harry, does the debugger. The debugger will step through assembly.
08:18:10.670 - 08:18:38.578, Speaker C: Yes. The decoder does not currently support displaying assembly variables. Yeah, I noticed that recently. I wasn't paying attention to this until recently. I noticed recently the format in the ast for assembly stuff changed. So now that might actually be possible. With the old format, that wouldn't really have been possible, but, yeah, that's something I could look into.
08:18:38.744 - 08:18:43.090, Speaker A: Yeah. And then the next question would be, any plans for supporting assembly variables?
08:18:45.590 - 08:18:54.120, Speaker C: Well, yeah, it was something I hadn't really thought about before, but, yeah, that's totally something I could look into. Absolutely.
08:18:55.370 - 08:19:07.900, Speaker B: Awesome. So any more questions? Before I wrap up this, I just have some notes to share. I have one more question.
08:19:10.030 - 08:19:11.770, Speaker C: All of these variables that you show.
08:19:11.840 - 08:19:53.980, Speaker B: The output, is this available at a specific breakpoint, or is this after the transaction occurs? For this example, this is the storage value after a transaction. So this is just, if I go back into the decoder test, I have a tornado instance. I know my related artifacts, so I just want to look at the storage at that point in time, not inside a transaction. And so this is the call that I make, because I just do say, hey, decoder, tell me all the variables you know about. Does that make sense? Yeah.
08:19:56.270 - 08:19:59.340, Speaker C: I feel like maybe I should jump in here with a more detailed answer.
08:20:00.190 - 08:20:16.660, Speaker B: Sure, maybe. We also wanted to discuss debugging data format, right? Yeah. Okay. Let's save additional questions for the end. I just want to wrap up here and I'll lead into the discussion because I think there's a natural lead in.
08:20:20.310 - 08:20:33.782, Speaker C: Could I say really briefly, truffle debugger can absolutely see variables in the middle. Truffle decoder only looks at block boundaries, but the low level interface is capable of doing more than that, which is why debugger can do more.
08:20:33.916 - 08:21:09.182, Speaker B: Okay. Yeah. So if you want to recreate this demo locally, you can check out my fork of the tornado core repo, and I made a branch demo. I don't know if anyone from tornado is on the call, but thanks for letting me unwittingly use your code in this talk. And here are the commands you can run if you want to recreate my examples. If you want docs we have this resource. This tells you how to use truffle decoder.
08:21:09.182 - 08:21:48.506, Speaker B: Truffle decoder and Truffle codec are written entirely in typescript, so you can get this information about the format and see all the different data types. So hopefully that should make it easier to integrate. And then of course, there's our normal debugger documentation. And when we released this decoder, I put together a 5.1 example box which has some more bite sized example of using the decoder. So hopefully you find this useful. I know we already have internally in truffle.
08:21:48.506 - 08:22:02.690, Speaker B: It's been a real handy thing to have, being able to decode this information like this and hope other people find it useful as well. Thank you very much. Oh, I guess I should lead in. By the way, this is all very complicated because we don't have a debugging data format.
08:22:04.070 - 08:22:10.360, Speaker A: Great. Awesome. Thank you so much. Especially also for the demo. Chris, do you want to take over?
08:22:16.730 - 08:22:26.650, Speaker B: I don't really have material on that, and I think it would also be better for the truffle team to lead that, because they know what they need.
08:22:26.800 - 08:22:34.140, Speaker A: Yeah, I mean, the general problem is already outlined, I guess, pretty well in the abstract of the session itself.
08:22:39.170 - 08:23:43.390, Speaker B: I can summarize what the problem is and, well, if it's even necessary, after looking at Harry's explanation of how we have to track mapping keys, and my explanation of how all of this gets decoded. Basically in a traditional computing environment, if you want to use a debugger, the compiler tells you where everything you, you run GCC and you give it a special flag that says, give me all the debug information. And that says, oh, this variable is here. You're going to be looking in this register at this time. Fliny doesn't do that. And so we've had to recreate tools that through empirical observation and judging from some of the earlier talks in this summit, we're not alone. Plenty of projects have to reason about how solidity does mappings, how solidity puts structs, like how things are ordered.
08:23:43.390 - 08:24:42.614, Speaker B: And so it would be really helpful if there were a way to represent this information at compile time, then trouble debugger. There's still some logic in it, but mostly we would just go and look up this debugging data format and say, oh, what are the variables I need to know about, where do I find them? And that sort of thing. And so with that, I think it would really open up the opportunity for additional tooling or easier to maintain tooling around things like stack traces, step line debuggers, decoding utilities, et cetera. Right. So I don't have stuff necessarily prepared for that. But there was a Harry put together a paper about a year and a half ago, which I'll put in the.
08:24:42.652 - 08:24:43.430, Speaker C: Chat.
08:24:46.810 - 08:25:11.390, Speaker B: Which kind of outlines how data representation is done in solidity. And I guess my hope is that we can start putting together a format, specking out what a format would look like as solidity output for use in travel debugger and remix debugger and all these other tools.
08:25:16.530 - 08:25:17.760, Speaker A: Please go ahead.
08:25:20.530 - 08:25:56.794, Speaker C: So I'm going to jump in here. One note here. So, by the way, that paper is a bit out of state at this point because it doesn't account for immutables, which were recently introduced. I mean, I originally wrote this thing largely to clarify my own thinking when I didn't really understand how things were stored yet. And now that I do, it was easier to just write the code to support immutables, rather than alter the paper first and then write the code. So it's a little out of date there. But the thing to note here about regarding making a format.
08:25:56.794 - 08:26:45.354, Speaker C: So a question that of course has to be answered is how much can be assumed, right? Because obviously in a trivial case you could say, oh, assume everything about solidity, then you don't need a format at all. Your format is no information. Figure it out, which is how things are presently. But like. So I just want to give an example. So unfortunately, I meant to come here having something more of a. Having basically the start of a format.
08:26:45.354 - 08:26:50.320, Speaker C: And unfortunately, I have not actually had time to work on that.
08:26:51.970 - 08:26:52.830, Speaker B: It's.
08:26:55.190 - 08:27:48.660, Speaker C: Pretty soon in the future, but not quite there yet, because obviously this is not a new topic. Right. So we've talked about this before. And so I started looking at dwarf, right, which is a commonly used debugging data format that is probably not what we want to use for a number of reasons that Nick can talk about. It would be inappropriate. It's this binary format that goes in the bytecode, and that's not really what we want to be using here. But it does, obviously, as an old robust thing, it does provide a lot of inspiration for the questions like how are we going to structure the data? What exactly are we going to specify? And so here's an interesting example.
08:27:48.660 - 08:29:13.260, Speaker C: Sorry, this might be a little bit off the topic I originally started talking about is, what can we assume? But I just wanted to give an interesting example of something that I noted, that dwarf, actually, that solidity does that you would have a hard time specifying in dwarf, which is the way that solidity does arrays in storage. Dwarf obviously has a number of options for specifying how arrays are stored. And it even has, God, I forget the exact name of it, the exact name of the fields, but it has like bitwidth and it has stride width. And so this allows for the option that you have an array where each item in the array takes up more space than the, like each individual item has more space allocated than the actual type for that item. And so you could have something with a bit width of eight, but stride width of 32 stride length. I don't remember the name. I was like, oh that's cool, I'm glad they thought of that.
08:29:13.260 - 08:30:14.480, Speaker C: That's helpful for arrays that are stored like that. But I couldn't find anything in there that would be good enough to cover. How solidity does arrays in storage where you might have, for instance, you know, trying to do the vision in my head, like where you might have say, well, okay, let's say where you might have say 160 bits. Well no, that one does work. Let's say we might have say 80 bits of one item, then 80 bits of another item, then 80 bits of a third item, and then 16 bits of blank space, and then 80 bits of an item. 80 bits, 80 bits, 16 bits of blank space. That sort of uneven stride is not something that dwarf accounts for.
08:30:18.630 - 08:30:22.430, Speaker B: We envision storage to be contiguous, but that's also just an abstraction.
08:30:22.510 - 08:30:30.260, Speaker C: That's true. That is absolutely correct. Is that storage I'm talking about like storage is contiguous and it's not.
08:30:32.470 - 08:31:47.310, Speaker B: But let's put work aside, right? And I think it is also reasonable, at least for now, to make some assumptions. Assume that we know at least some parts of solidity. Like how do you get from where the length of a storage array is stored and where the data is stored and stuff? The compiler recently added the storage layout dump. What at least maybe simple other things could be useful for debuggers or analysis tools, maybe more related to bytecode. So for the bytecode we only have the source reference and usually people then take the source reference and look in the ast and look what is there in the ast. This is kind of cumbersome, right? Would it be helpful for each value, for each opcode? Would it make sense to kind of list the type that this comes from, from solidity or, I don't know. You talked about the mapping key discovery.
08:31:47.310 - 08:31:54.190, Speaker B: What is a simple thing that the compiler could output that would help making that simpler?
08:31:55.430 - 08:32:13.574, Speaker C: Oh boy. Yeah, that's an interesting question, because it's funny because Nick talked about map and keys, but when we were talking about debugging data formats, I was thinking more in terms of just this more straightforward, traditional, where are the variables? Sorts of things.
08:32:13.692 - 08:32:16.920, Speaker B: Oh, yeah, that would be nice. Sure, let's talk about that.
08:32:18.970 - 08:32:22.086, Speaker C: Well, progress with the specification here.
08:32:22.108 - 08:32:23.122, Speaker B: Right. You see?
08:32:23.196 - 08:32:57.454, Speaker C: Yeah. No, when you're talking about mapping keys. Oh boy. I don't even. Yeah, I think the source maps, as they're. I don't really know that the source maps need more information other than modifier depth is kind of screwy. But that's something for another time.
08:32:57.572 - 08:33:04.562, Speaker B: Modifier depth is not what modifier depth is present now.
08:33:04.696 - 08:33:59.848, Speaker C: Yes, absolutely it is. The way it works makes it difficult to use, I mean, by the way, we do, I mean, we do use it now for discriminating between local variables in different copies of the same modifier, but it turns out to be difficult to use it for more than that, as it turns out. But that's kind of off topic. I don't think that modifier depth really has much to do with a debugging data format, but. Yeah, I don't really know that there's anything that would need to be added to the source maps. I mean, as you said, we can do that process of mapping to the individual. Sounds like Nick has something to say.
08:33:59.848 - 08:34:02.250, Speaker C: I'm just going to repeat myself, so I'll let.
08:34:04.140 - 08:34:37.764, Speaker B: Sure. Well, Harry, I concur with you that source maps are probably sufficient. Yeah, it is cumbersome to go dig through the ast, but maybe I'm just used to that being the problem. But perhaps a useful piece of information would be a listing of stack frames. Like you have a function definition. It should be able to tell us up front. Oh, these are the variables that we're going to allocate onto the stack, or maybe some way of indicating what the memory will be like.
08:34:37.764 - 08:34:54.970, Speaker B: There's the storage layout, sure, but there are a lot more variables besides the storage variables. Right. And so how could the compiler provide that when we're dealing with a stack machine? The EVM is a stack machine, so everything has to be relative. Well, this gets into.
08:34:59.020 - 08:35:55.550, Speaker C: Memory to be clear, memory we only ever access. Well, okay, that's actually not quite true anymore. Okay, memory, we mostly only ever access via pointers on the stack. So the real problem is the stack, not memory. But yes, this would be, I mean, to be clear, the reason this is a problem is because solidity doesn't have frame pointers and solidity doesn't have frame pointers because frame pointers would be useless because the EVM doesn't provide any sort of dynamic stack access. But the question then becomes, can we provide any sort of static information that would help us locate variables on the stack? I mean, the truffle debugger is pretty good already at locating variables on the stack. There are some weird cases involving modifier parameters or base constructor parameters that will screw it up, but these are weird and minor cases that you are unlikely to run into.
08:35:55.550 - 08:36:16.470, Speaker C: Ordinarily, we are fine at locating variables on the stack. That said, some sort of static information would be really useful here, because as always, we're asking the question, what if this changes in the future? Are we just going to have to check the solidity compiler version? It would be better not to have to do that.
08:36:21.660 - 08:37:06.258, Speaker A: Okay, does anybody outside of the truffle team or Chris has any opinions on the data format for debugging data? There are also some notes being added to the hackmd if you want to have a look, but it's mostly for note taking so far. Alex asks something in the chat, have you looked at how EIP 20 315 subroutines could affect this? It doesn't introduce a frame, only a separate shadow return stack, but it also means there won't be a PC on the stack pointing back to the caller to you, Nick.
08:37:06.434 - 08:37:13.370, Speaker B: Yeah, that I will have to look into. This is the first I'm hearing of it and it sounds like it puts a wrench in things.
08:37:13.520 - 08:37:15.290, Speaker C: Wait, eip which number?
08:37:15.360 - 08:37:17.420, Speaker B: Sorry, 20 315.
08:37:18.270 - 08:37:19.402, Speaker C: Okay, give me a moment.
08:37:19.456 - 08:37:31.470, Speaker B: Why? That's the subroutines thing. Jump sub return sub. That's interesting.
08:37:32.480 - 08:37:37.660, Speaker C: Is this the one that got rejected? That got withdrawn?
08:37:38.560 - 08:37:43.520, Speaker B: It's a stripped down version that does not need multi byte upcodes.
08:37:44.980 - 08:37:45.730, Speaker C: Nice.
08:37:56.390 - 08:39:27.950, Speaker B: Also, I'll second what Patricio Palladino said, that it would be useful to have some kind of indication when we're in unmapped bytecode, because if you use a trough debugger or even remix debugger, you're just going to end up in opcodes and truffle debugger just skips over them. But remix debugger, if you use it, it takes you into the EBM level, which is a bit of a jarring experience. It'd be nice if you say, hey, this block of unmapped code, is this allocation or whatever, right? Can you clarify that a little? Well, if you look at message oh, message in gitter. Yeah, sure. I can also add to this. So when you are doing anything that needs to use source maps, you always end up with chunks of white code that don't actually have a source map, they just have an index fine of minus one, if I remember correctly. How could they be described? So my understanding is that those pieces of bytecode actually correspond to internal routines that needs to add kind of runtime.
08:39:27.950 - 08:40:22.050, Speaker B: So mapping it somehow like let's say file number one, two, three corresponds to a division or things like that. Actually that is a very interesting point. For most of these routines we can actually output Yule code. It is generated code. So there's no fixed Yule source code that works for all contract. But the compiler could create another artifact that contains the full Yule code of all these helper routines. And then this could be an actual source file we reference in the source maps that is not user supplied but compiler generated.
08:40:22.050 - 08:41:12.674, Speaker B: Yeah, that would be incredibly useful for things like debugging stack traces and those kind of things. I mean, you would still not be able to do kind of debugging like you debug a solidity source code, but you could at least step through your function that have names and you would have local variables that have names and so on, right? So at least you could show to the user, I mean to the end user the name of this or a name for these chunks of bytecode. That's another idea, yeah. Right. Yeah, there's all this code. Whenever you assign a memory variable to storage, you do a copy, although I know you're working on the explicitness for that. But when that's being executed, there's no indication in the source map of that.
08:41:12.674 - 08:41:20.020, Speaker B: And that's just one example. Right. So any additional information there would make for a much better debugging experience.
08:41:23.030 - 08:42:48.100, Speaker C: Um, I just want to jump in here and make a note that this sounds like a really cool idea, but this and like, yeah, this sounds like a really cool idea, but I do want to make the note since I was just talking about math and keys. Ideally it would be nice if this could be done in a way that did not break our mapping key, our mapping key decoding, which this gets into. The stuff I didn't talk about in my talk actually, is why do you think it would. Okay, here's why. It has to do with what if you use a, okay, suppose you have a call data array, and suppose you have a mapping, and suppose you index into the call data array and then use the result as an index into the mapping. And I'm assuming that you do this without storing anything in any variables in the meantime, right? You just have mapping of call data array of index. Right.
08:42:48.100 - 08:43:54.038, Speaker C: So when you do that. So this is actually why you may remember in response to your question I talked about how, yeah, we need to look at the next thing on the stack. Except that with hexadecimal literals, that's wrong. And I brought up this actually we have the system where we look at the next thing on the stack at the, we look at the thing on the stack at the next map instruction. And that's because of this call data array access case. Because when you do a call data array access, what happens is that you end up inside a bunch of unmapped code or internally mapped code mapped to minus one. The last instruction that is mapped to the array access.
08:43:54.038 - 08:44:18.410, Speaker C: The call data array access. If you look at the next instruction and you look at what's on the stack, it's actually not the right thing because it's not until all that unmapped code is done running that the correct stuff is on the stack. And so we have this process where we look ahead to the next map instruction in order to handle call data array accesses used as mapping keys distinguish.
08:44:18.490 - 08:44:20.720, Speaker B: Mapped code and unmapped code, right?
08:44:21.570 - 08:44:44.920, Speaker C: Yeah. Well, we distinguish unmapped code by noting that unmapped code is minus one. Exactly. But in what Nick is suggesting, this unmapped code would now become mapped to Yule code rather than totally unmapped code. And not what Nick is suggesting. What you're suggesting. Sorry.
08:44:48.170 - 08:44:55.320, Speaker B: It's not a user supplied source code. Yeah, to indicate that it's kernel mode. Basically.
08:44:57.550 - 08:45:30.920, Speaker C: Just as currently this sort of thing is mapped to source minus one. We just need to make sure that there is some sort of indicator so that we would know like, oh, this is internal stuff. I mean, okay, admittedly there are other ways this could be handled. I don't want to say this is the only way to handle it because there's other ways that could be handled without breaking or mapping handling. I just do want to note that little thing. And so it would be nice at least if there was a way to tell that, oh yeah, this is a mapping into generated yule code, not a mapping into real source code.
08:45:34.790 - 08:46:17.730, Speaker A: Okay. Just looking at the time and for everyone's energy level sake for tomorrow, I would suggest that we wrap it up. Unless we have any open questions or any open topics that, Chris, you want to discuss, or if anybody else would want to leave their opinion on debugging data format, then shout out. Now that does not seem like it. Okay then. Thanks so much to both Harry and Nick. For all the insights into the traffic debugger and thank you everybody else who beared with us for such a long time.
08:46:17.730 - 08:46:52.660, Speaker A: Looking forward to tomorrow. Please have a nice day if you are in the Americas and have a good night if you are in Europe. And yeah, see you back tomorrow. The program tomorrow starts half an hour later than today, so at 130 Berlin time you can also look up every other time zone on the agenda or in the Google calendars entries. I guess that's a wrap for today. Live stream manager we can now switch the live stream.

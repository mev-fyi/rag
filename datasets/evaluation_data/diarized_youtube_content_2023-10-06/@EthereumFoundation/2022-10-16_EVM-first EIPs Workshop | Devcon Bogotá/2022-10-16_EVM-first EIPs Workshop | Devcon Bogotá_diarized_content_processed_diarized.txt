00:00:13.210 - 00:01:16.930, Speaker A: Good morning everyone. It's apparently very early for some people but we kind of imagined it to be a continuation of the ethereum addition session we had I think on the first day. But the focus for today would be EIPS related to EVM. So yeah, this possibility to take a mic and describe or pitch for EIP you are interested in and we can discuss and maybe ask questions from the audience. So if anyone wants to start if not I can take like 5 minutes, 10 minutes to talk about EOF. Like three five EIP proposals we have drafted so far. So this is a slide for my lightning talk about EOF but mostly what I wanted to have on the screen is the five EIPS.
00:01:16.930 - 00:02:44.494, Speaker A: We have two first are potentially scheduled for Shanghai which means the next execution layer upgrade ada defined kind of the basic of the EOF structure. So EOF stands for EVM Object Format and is kind of our idea to structure the EVM programs in the way that kind of behave more predictable way. So we Know where the data Is in the program, we know the code Is, and we can version programs. So that also gives us some additional backwards compatibility features. And on top of that, we can build additional features. And these three additional features are the next three IPS on the list. So firstly EOF allows us to define instructions in a bit different way so we can have some immediate values means the opcode can be followed by additional numbers that means something to the instruction that will interpret the values following that wasn't possible before because of the backwards compatibility of existing EVM.
00:02:44.494 - 00:04:54.700, Speaker A: So in the current EVM you can craft a program that will break if you interpret values following opcode in a different way so these static jumps are more efficient than current ones and also there's also easier to analyze from external tools and also from the code validation in the EVM itself. And additionally, the next one is EOF functions, which means we can additionally partition the EVM code into separate sections, meaning individual native functions in the EVM. And there are additional instructions that allows you to go between these partitions. And all combined with the static jumps and the functions we can get rid of of existing dynamic jumps in the EVM which it should improve efficiency. And most importantly, we can get rid of of jump disk analysis. So the jump disk analysis is a process that has to be performed before we can start even executing EVM programs currently and the cost of doing that is proportional to the size of the code and none of the cost of EVM execution actually reflects this analysis. And lastly we can also put additional verification in the EOF format that will allow to check statically before deploying the code if a function performs stack overflow or possibly stack underflow and we can reject such programs such programs would be by definition a bit more restrictive than the current ones.
00:04:54.700 - 00:05:49.900, Speaker A: So there are some tricks you can do in current EVM that would not be possible anymore. But I think most of the compilers that target CVM doesn't really exploit these properties. So that also brings some additional efficiencies because you can kind of check for correctness, at least in the terms of stack behavior during deploy time and you don't have to repeat these checks later during execution. Okay, so that's all I can say in 5 minutes about that. So yeah, I'm open to answer some questions and also if someone wants to join on stage and talk about some interesting EVM stuff.
00:05:51.650 - 00:06:26.440, Speaker B: Okay, I have been spending the week trying to better understand EOF and one question I have is so I understand you have different versions of EOF that you can implement, but you can also add there are additions to an EOF version that can be done without a version bump. Can you walk through what are the proposals of those five and maybe others that you have? Which one require version bump, which one don't? And how would you think about deploying the whole thing over time?
00:06:27.210 - 00:07:18.810, Speaker A: Okay, the first two kind of the basics of EOF will be introduced with version one and remaining like three additionals will require the version bump. And this is kind of the question how many features we want to pack into a single version? Originally we kind of wanted to split that and that's also reason we have like five EIPS, not like single one, because people freak out if their EP is big enough. So we kind of splitted that into multiple pieces, which also brings some inefficiencies in the design, all of that because we need to update multiple documents.
00:07:20.590 - 00:07:44.274, Speaker B: So just to be clear, 35, 40, 36, 70 obviously you're introducing UF requires V one, but then there's none in the list of like 4247 50 and the last one I can't see, but anyways, none in the last three can be added. So you could add all three together and make Eofv two.
00:07:44.312 - 00:08:25.082, Speaker A: Yes, exactly. You can combine how many features you want. Right, it's like up to kind of our what you define as a version. Multiple versions bring some new kind of complexity to the system we don't have so far. So currently when we change something to EVM, it's mostly time based. To some point EVM works this way and from some point it works differently. So I think all the code still have all of the versions, historic versions, and because people care about executing every instruction from the beginning.
00:08:25.082 - 00:09:07.226, Speaker A: But you can imagine, you can design a client that only kind of has recent two or something like that. So you can kind of scrap the code and do the full sync, which means doesn't execute the transactions, just collects the state and goes on from that. I think nobody did so far this way, but it's possible and this KOF itself will introduce kind of the new EVM that will run next to the legacy one and they will be able to communicate within the single transaction. Right? So you can have legacy contract that calls the new one and new one called the old one and nothing breaks on this level. But you will have kind of two.
00:09:07.248 - 00:09:18.270, Speaker B: Parallel AVNs just to follow up. So of say the last three, say we were to split that in like two and one or like three hard forks.
00:09:19.410 - 00:09:21.646, Speaker A: Are there any that don't require a.
00:09:21.668 - 00:09:28.850, Speaker B: Version bump or do they each, as long as they're not shipped together all the time require a version bump?
00:09:30.230 - 00:10:21.940, Speaker A: I think the static relative jump doesn't require version bump at all. So kind of the forward backward no, the forward compatibility of EOF is that you can always drop new instruction into it without version bump. So whatever you add instruction can be like of any complexity. You can always do that because we make sure the opcodes that are undefined currently are not used in the programs. So we can drop the static relative jumps like without version bump. But I don't know, my feeling is it's probably better to pack as many features as we have capacity for so we don't have multiple EOF versions later. Right?
00:10:30.410 - 00:10:51.520, Speaker C: What about the backwards compatibility of packing in new optional EOF format sections? Like if EOF functions was separate from the code section and provided data on top of it, same with the stack validation information, it had a separate section number that would go on top of it. I mean, could those be done in a forward compatible way with it doesn't break things?
00:10:54.370 - 00:11:05.630, Speaker A: Let me think. So so far we didn't actually think about this way but maybe that would be the way to design it in the way we can actually drop this feature later without the version bump.
00:11:06.370 - 00:11:09.282, Speaker C: EOF functions requires separate code block, right?
00:11:09.336 - 00:11:51.518, Speaker A: Yeah, but you can kind of so the thing is when you have something mandatory you can make it optional later, right? Because the previous deployed contracts will have this thing there but if it's optional it's still fine. So maybe there's a way to have like single code section with the information that maybe later will enable more code section. So like single code section contracts from before will still work, will just have single function there. So maybe this way to design it in the forward compatibility way so we don't have to version bump. That's I think. Nice idea. I haven't really thought about before.
00:11:51.684 - 00:12:08.262, Speaker C: Would adding a minor version in the EOF header be useful to indicate that I require these forward compatible changes but I'm compatible with a backward compatible interpreter, kind of like HDMI 1.12.1.
00:12:08.396 - 00:12:39.214, Speaker A: I'm not sure. I mean it's still like system, all the contracts have to do exactly the same things and there's not really optional thing you can perform in the sense that all the clients have to behave the same way. So I'm not sure actually having minor version will make any difference. So either it behaves differently or not. So if it's like two versions numbers, I don't think that makes any difference. Okay.
00:12:39.252 - 00:12:42.014, Speaker C: I mean, I guess I just thought that Slitic could always just pack it.
00:12:42.212 - 00:12:56.840, Speaker A: Yeah, maybe like the functions there's a way to do it. I think we will need to take a look into this. The last one probably not because it just adds additional requirements of the code structure. So the previous programs probably will not follow these.
00:13:00.810 - 00:13:13.980, Speaker D: Do I understand correctly that the last EIP doesn't require the version bump because it's just the change on the EVM side so it's not in the bytecode and you can do it whenever you want?
00:13:14.510 - 00:13:49.730, Speaker A: No, actually the last one actually requires the version bump because it puts additional restriction loose on the code. So it means we want to make sure when you load the EVM program from database and you see the version number, you know exactly what you can expect from the code. So if some rules are not there at the deploy time, it means that the program you load from that era will have different structure and you can't rely on it anymore.
00:13:49.810 - 00:13:50.486, Speaker D: Yeah, got it.
00:13:50.508 - 00:13:51.080, Speaker A: Thanks.
00:13:51.850 - 00:14:13.870, Speaker E: So unfortunately I've just come across the EOF. So I'm guessing that the intention of these changes is to make it easier to do static analysis on the EVM code, particularly computing predecessors to basic blocks, which is always a challenge with EVM at the moment. And doing static translation have become a lot easier.
00:14:15.490 - 00:14:17.390, Speaker A: You mean like external tools?
00:14:20.210 - 00:14:41.750, Speaker E: I've got sort of three main use cases. One is static symbolic execution for example. Another is translation translated to X 86 and another is doing static analysis of contracts to see if they're valid. So imagine that all these things are going to help out with that.
00:14:41.900 - 00:15:20.210, Speaker A: So I think our main goal about control flow changes is to just get rid of jump desk analysis and make it more efficient. But we kind of expect to be also like DOF programs to be much easier to be analyzed by external tools. But I think we just need actually inputs from you. You probably should take a look and see if it helps or not. How much it helps, because that's not really area of our expertise but we kind of expect it to be much easier to do it analysis externally.
00:15:20.710 - 00:15:27.590, Speaker E: Yes, certainly static jumps will help enormously. But because of the predecessor problem, essentially.
00:15:28.010 - 00:15:32.040, Speaker A: We need to talk about distribution of this.
00:15:36.010 - 00:15:36.806, Speaker E: Beautiful.
00:15:36.988 - 00:15:57.146, Speaker F: So Arm has the zero register. There's a lot of register machines out there. Push zero will also be quite convenient. Fuel also has taken the zero register from Arm in their virtual machine. The EVM currently has the gas counter and the program counter and I think they're registers when registers.
00:15:57.338 - 00:16:32.374, Speaker A: Oh, this way I thought you will start talking about poor zero IP because there's one on the list. So maybe you want to talk about it. No. Okay, let me start from the back. There's like one IAP that introduces push zero instructions. I think this is what is kind of analogous to Arm and all of that. So it's just to make sure people don't use kind of exotic way of M size or all of that to push zero on the stack.
00:16:32.374 - 00:17:13.778, Speaker A: So we just will delegate one instruction to do exactly this with the same gas cost of the kind of the hacks we currently have. And that's also scheduled from Shanghai, if I remember right. Can anyone confirm that? Okay, I think it is. So that's one thing registers in a VM probably never. So this EOF stuff looks already complex enough that I don't know what is the scale we can deploy it or maybe it will never be deployed on the main net. But the thing is it has kind of different structure. So we kind of designed the EVM loop interpreter loop differently.
00:17:13.778 - 00:18:02.710, Speaker A: But the instructions they operate on are kind of shared between legacy and the new one. And I think that's the current direction we're going with nobody proposed like radical changes. I think radical change would be just to take some other VM. I don't know. We tried with web assembly, maybe the fuel VM and put it somewhere on L two or whatever. I don't expect to see so drastic changes to EVM. It's kind of the same as the question like why do we have 256 bit size words, right? And probably there is also not like not really option to short it to something smaller.
00:18:02.710 - 00:18:04.520, Speaker A: One more question.
00:18:06.970 - 00:18:17.660, Speaker D: Hey, so Greg Colvin's got his simple subroutines EIP as well. Could you explain how that is different than these?
00:18:19.230 - 00:19:19.790, Speaker A: Yeah, I will sit down because I'm sure I can give a full picture so maybe someone will jump and help me, but I can start with that. It kind of wanted to introduce these subroutines which are kind of analogous to what our functions are to existing EVM. So there are some technical issues. Like one is about having these immediate values in the instruction which are not like fully backwards compatible. And secondly, it kind of doesn't really help with this analysis. So this was one because for the simplicity, the jumps will still work the same and they can cross the subroutines easily. So you can use the new instructions to kind of form kind of the subcodes in the code.
00:19:19.790 - 00:20:10.350, Speaker A: But jumps will go whatever they want and it doesn't really help with analysis outside of that. And it doesn't really help to do kind of fancy compilation. By fancy compilation I mean you can take subroutine and compile it to native code or something and then use the system call stack to implement subroutine calls. But because there's possibility to jump over or jump out of the subroutine and go somewhere else that doesn't fit into this model. But I'm not sure that were the reason that the chain didn't went through. Maybe there were some other reasons.
00:20:11.810 - 00:20:17.518, Speaker D: Yeah, I mean, he's updated that proposal again since it was last rejected. I don't know if you've seen those updates.
00:20:17.614 - 00:21:02.602, Speaker A: Yeah, I kind of noticed, but I'm not sure this is like the I mean, the IP is kind of being updated and I have real trouble to keep track like which version we're talking about right now. But I know there's some changes, but is this still kind of something we should consider for future upgrades or not? Because I'm not sure if that's candidate for anything. Hi. So I just have one question. Are there any technical barriers for implementing 30 74? I'm really bad at numbers. Can you tell which EIP this old school? Oh, this one? No idea. Honestly, maybe someone can help.
00:21:02.602 - 00:21:32.602, Speaker A: Okay. No, you're not helping. No, I don't know. Really? So I think on the technical level, probably not so many. I think it's mostly like social level, which is problematic, or some way you can trick people to do something and there is no way back. But I am not an expert on this one actually, so I don't think I can answer this. Go ahead.
00:21:32.656 - 00:21:46.398, Speaker F: You get to be a dictator here. If you had to dream up Mstore two, what would it be? Say like you're not changing the existing memory. You just get to do memory from scratch. How would you go about it?
00:21:46.484 - 00:21:48.798, Speaker A: But you mentioned I store, right?
00:21:48.884 - 00:21:52.638, Speaker F: M store. Just like oh, we're doing memory differently here.
00:21:52.724 - 00:22:44.802, Speaker A: Yeah, that's a good question. So we didn't put anything like any kind of draft, but we have some thought about that and there was some input from Vitalik as well recently about how to kind of model that. I think there's like multiple dimensions you can try to kind of describe it. Like one is that current memory allows you to just use whatever index you want. You will just pay more gas for it. And that we kind of calculate of the memory automatically expands to the use. And that's a kind of different way of doing that.
00:22:44.802 - 00:23:14.410, Speaker A: So you kind of have to explicitly inform the EVM upfront. Like okay, please allocate more memory for me. And if you use something that is outside of the allocation, it will just terminate execution. Right. And the second one is the model that WebAssembly uses. Right. So you need to kind of allocate memory upfront and you can't use it if it's not allocated.
00:23:14.410 - 00:23:55.880, Speaker A: This is like one way you can select from I think at least Solidity was happy with this automatic allocation, but I'm not sure I can confirm that. Is anyone from Solidity here? Okay. I mean, Solidity is kind of happy that memory automatically expands to new indexes and you don't have to maintain how much you did allocated. So it would be fine to have the EVM one, you have to kind of declare to EVM that you need more memory. That'd be good or not.
00:23:56.570 - 00:23:56.934, Speaker D: Yeah.
00:23:56.972 - 00:24:09.130, Speaker E: So statically analyzing the maximum memory size is a challenging problem at the moment. And if there was something in the EOF to specify the maximum memory size, they're probably quite useful.
00:24:10.270 - 00:24:19.534, Speaker A: Okay, if I get it right, you would prefer the system when you have to kind of explicitly say how much memory you would use or something like that.
00:24:19.652 - 00:24:28.726, Speaker E: It's not absolutely necessary because, for instance, solidity is extremely facile and very easy to analyze, but there are contracts which aren't.
00:24:28.858 - 00:25:06.830, Speaker A: Okay, got it. Yeah. So this is one aspect, and we don't have a winner here so far. And from EVM implementation, I would prefer to somehow lower the housekeeping of memory. So whenever you execute one of the memory instructions like this, like m load, m store, most of the time EVM is spending just to calculating the cost. If it's like new instruction, if the index is not absolutely huge or something like that, and just accessing the memory is like this is nowhere on the profile. Right.
00:25:06.830 - 00:25:36.262, Speaker A: So I think keeping the housekeeping lower, maybe combining the explicit allocation and do the cost by memory pages or something like that would just help. But we didn't prototype any of that so far. So they're kind of rough ideas. But you can do quite interesting stuff if you have memory pages. In VM implementation, it's a very similar.
00:25:36.316 - 00:25:53.920, Speaker E: Problem to the SPUs on the PlayStation Three, for example, the minimum register size was 128 bits. So the EVM is extremely similar to the SPU on the PlayStation, and that was an interesting challenge as well.
00:25:54.450 - 00:25:58.634, Speaker A: Okay, that means like, PlayStation runs EVM.
00:25:58.682 - 00:26:02.430, Speaker E: Now PlayStation was a bit quicker.
00:26:03.970 - 00:26:08.260, Speaker A: Definitely. I think everything is quicker than VM. Right.
00:26:10.630 - 00:26:17.666, Speaker F: Also just declaring all of my questions are the lowest. Like they're the fallback ones anyone can interrupt and take priority.
00:26:17.858 - 00:26:19.880, Speaker A: Oh, there's someone beautiful.
00:26:23.770 - 00:26:37.546, Speaker D: Are there any hardware implementation of EVM or maybe FPGA ASIC that you know of? And if there is, what were their biggest hurdle asides from Mstore? I'm guessing because that's a pain, but.
00:26:37.568 - 00:27:28.122, Speaker A: Otherwise, I mean async on like memory access level or the storage access level. Yeah, I'm not sure I can help here, but I know some people were experimenting with having Async way of accessing storage. Oh, Async. Okay. Wow. So we had a project called Evmjit, which just was compiling EVM bytecode into, let's say, x 86 like native code. And the performance was great, but the cost of compiling that was also big.
00:27:28.122 - 00:27:42.560, Speaker A: So that's kind of the trade off. And at some point we just scrap it. It's somewhere around. But I think you have difficult time to decide which contract you want to compile to native code if you don't have to.
00:27:45.430 - 00:27:56.962, Speaker D: You might have misunderstood my question. Sorry, let me restate it. So has there been anyone implementing a physical hardware machine that executes EVM. That's got nothing to do with JIT.
00:27:57.106 - 00:27:57.926, Speaker A: Okay, sorry.
00:27:58.028 - 00:28:03.640, Speaker D: Just purely you get an opcode, it decodes it, it executes the code.
00:28:04.890 - 00:28:47.734, Speaker A: Okay, yeah, I kind of wanted to put it in perspective in the sense, at least to my opinion, that seems like more advanced because I don't know about this stuff at all that doing even JIT compilation, which is already hard. It's like compilation is not hard, but it's like time consuming. So you have to just squeeze this if you have hardware. Yeah, I think even if you had a hardware like that, the gas cost nowhere reflects the performance of it. Right. So I'm not sure how much you will save. You will save your machine computational time, but I think it would not improve the network unless most of the people use it.
00:28:47.734 - 00:28:54.920, Speaker A: But I don't know if anyone tried that. I would be definitely interesting project to see how it works.
00:28:55.290 - 00:29:39.430, Speaker F: Greg COVID has infamously said that the EVM is a gas counting machine that does computation as a side effect. Do you think there could be any benefits to reducing the precision or the fidelity in terms of how gradual you're doing your gas accounting? And so like, paying for more gas things upfront or even say like the memory case would be one case where you pay for expansion or the escalation, like the curve that it follows isn't actually like a smooth, perfectly smooth curve naturally. It sort of like has a flat region or like a sort of linear region. Then it goes like jumps up and then it jumps up again. Do you think more things like that could be fine in the long run? Or do you think we should be really good at counting really small units of gas?
00:29:42.570 - 00:30:30.520, Speaker A: I think depends a bit like what kind of instruction subset you mean. I think from memory we should take a look how to improve gas housekeeping for these for purely computational ones. I think it's not so big deal right now. So the one thing is that the instructions actually do quite a lot because they are like 256 bit precision. So this is not like single CPU instruction you're doing, right? Four plus loading. So there's like 20 instructions you do like your CPU will be doing for the single instruction. It depends what instruction it is, but it's actually quite a lot.
00:30:30.520 - 00:31:11.540, Speaker A: So you kind of can hide the latency of gas computation there. So kind of the CPU is doing the computation itself and also calculates gas. So the overhead of disabled gas calculation, if you have really efficient EVM implementation, it can be like 7%, maybe 10%. So this is not like huge amount and the same for the stack checks and all of that. But yeah, I don't know. For EVM, I would keep it as it is. I think it's not so bad.
00:31:11.540 - 00:31:51.854, Speaker A: Definitely the simple gas rules will help, but I wouldn't change it to be some kind of different precision or whatever. But we also don't want complicated gas rules. That doesn't bring anything. So the memory is unfortunately example once more, which means you just compute this like 32 bit chunks of memory which you need to do some additional computation to calculate the gas cost. If it would be per byte, it would be simpler and the effect would be the same. Right. So you don't want to over design it, definitely.
00:31:51.854 - 00:31:56.030, Speaker A: But I think in general it's okay.
00:31:56.180 - 00:32:13.400, Speaker E: No, for most basic blocks you can calculate the gas costs up front and just calculate it with a whole basic block. And obviously things like S store and so on are variable. But for many basic blocks, as this guy probably tell you, you can pre compute it.
00:32:14.010 - 00:33:13.050, Speaker A: Yeah, you can do that with one comment. That it's. Like for the basic gas cost, some instruction has basic cost and then Variatic gas cost, depending on the arguments and something like that. Yeah, we did try that, even the EVM implementation and it brings, I think, some performance. But I think we kind of scrapped the idea because you need additional analysis phase to ship precalculate that quick description how it was done. In EVM one, there was like the old interpreter that was doing this and the analysis cost was really big and we kind of transitioned to simple design, but efficient design of EVM, which doesn't do that anymore. And the new one is actually faster than an old one.
00:33:13.050 - 00:33:30.958, Speaker A: But to be fair, the old one didn't get so much attention recently. So maybe there's some performance you can gain from it. But it won't be really big one if you have efficient EVM. So, like, simplicity wins so far, at least in the client perspective, right?
00:33:31.124 - 00:33:42.046, Speaker E: Yes, certainly. My experience is the EVM is a tiny part of the cost of the whole system anyway, which possibly answers the sort of why don't we have an FPGA EVM which would obviously be trivial.
00:33:42.078 - 00:34:00.700, Speaker F: To do 1153, otherwise known T store T load one by Alexey years ago. Do you have any thoughts on that? And specifically to the memory problem? Would that reduce some of these pressures on reforming memory? Because you've got this transient storage. It's not hitting disk, it's pretty cheap. How do you feel about 1153?
00:34:05.390 - 00:34:47.400, Speaker A: I'm not sure if I'm on the same page with this one, but does it have the same kind of map structure that this storage has? Right. For me, the issue is that you have this map structure there. So it's not like this is like chunk of memory. You actually have hash map or whatever the implementation is because as I remember, it was doing the same. You have unlimited number of 256 bit slots you can assign to. So the EVM has to kind of have a map of that which it can scrap at the end of the transaction. Right.
00:34:48.350 - 00:34:50.010, Speaker F: Do you want it in Shanghai?
00:34:51.310 - 00:35:36.520, Speaker A: Like, me personally, I don't like I'm kind of INAFFECTED by. So like how actually I vision EVM is kind of below that. So I kind of mostly focus on the single call. So this transient storage, it's problematic in the way that I have to kind of outsource it somewhere else. So the client has to provide some API to actually access it. Because for my EVM at least, it's that I just start the EVM context when you enter the call and I end it there. So I don't have anything that lasts above that.
00:35:36.520 - 00:35:59.840, Speaker A: But yeah, I'm kind of transitioning to the transaction level EVM execution. I think the ultimate question is like usability of that and if there's strong enough number of use cases that will make it desired. Right. And I think some people really push hard for it.
00:36:00.690 - 00:36:07.038, Speaker G: I have a follow up question on that. Do you think the cost of it?
00:36:07.204 - 00:36:11.026, Speaker A: Do you want to okay, anyway, go ahead.
00:36:11.208 - 00:36:20.390, Speaker G: Do you think the cost of all the potential cost of a T store would be that much lower than the S store?
00:36:20.540 - 00:36:34.440, Speaker A: I mean, the basic one is kind of like 100. Right. Currently for the S store, like the minimum we can get if this is like accessed slot and something, no? Yeah, maybe what are the numbers in.
00:36:35.070 - 00:36:39.500, Speaker G: The number is sure, but do you think in a machine, would it really be that different?
00:36:40.290 - 00:37:16.134, Speaker A: From my perspective, it's not any different to access S store because I kind of have a buffer of this cache of this S store. And from the core EVM side, it's not much different. So the difference is when you have to actually go to the database on disk or not. And this is guaranteed not to be the case. So you don't have to do any database lookup at all. So, yeah, probably it should be cheaper, but I don't know how much. Yeah.
00:37:16.172 - 00:37:20.086, Speaker G: Do you think an alternative solution would be to just fix the pricing of.
00:37:20.108 - 00:37:50.450, Speaker A: S store and S load? I think historically we did fix the pricing of S store in every hard fork. Right, exactly. If you see the S store implementation, it's like multiple lines of different revisions of EVM. So, I don't know, maybe we can't get it right. So we need a replacement for it. I don't know how to fix it more. It's already super complicated.
00:37:53.110 - 00:37:56.950, Speaker G: Maybe that's an argument pro geo to store.
00:37:57.100 - 00:38:16.842, Speaker A: Yeah, I can't be sure. I would be sure if there was a group that actually tried to fix the store. So it's competitive feature than the transit storage, but I think there's not such group so far. So maybe we just have to pick one option of one.
00:38:16.896 - 00:38:25.680, Speaker F: So I don't know how much easier would life be if the EVM was 64 bit? Or does it not really make much of a difference to your work?
00:38:26.130 - 00:39:20.460, Speaker A: Maybe my colleagues can be help move that. We did experiment with. WebAssembly and for some use case that EVM is used for, it really helps when it's this big word size. So all of these balance calculations, all of this fixed point arithmetic, it's really hard. If you need to emulate bigger numbers in the smaller, smaller 64 bit word size, it's really horrible. And when you have simple design like interpreter and stuff so you need to drop a lot of instructions to emulate that and it was really bad on some workloads so so we can't confirm it's like the best word size but for some use case, it really helps. It.

00:00:00.890 - 00:00:49.900, Speaker A: So my goal is to try and bring vdfs to production. So I guess the goal of today specifically is to try and tackle some of the open academic problems that we would like to make progress on before we actually build the VDF. So the academics are not completely off the hook. But I'm also going to talk about briefly the progress that we have so far. So one of the pretty amazing things when you look back is that vdfs academically are only eight months old. So there's these three papers that were all published coincidentally in the same month. And before that we didn't really know how to do efficient bdfs with an exponential speed up in the verification time.
00:00:49.900 - 00:01:47.962, Speaker A: The other pretty amazing thing is that we've had a lot of interest from various blockchain projects. So roughly, historically speaking, Chia and Salana were the first, and then Ethereum got interested, falcoin tezos, and then I made a talk at Defcon, and now we have twelve different blockchain projects that are interested in using vdfs. So I hope we're not at the peak of the hype cycle and this is actual interest and it will lead to actual utility. We shall see. One of the interesting things of vdfs is that they can be used for many different things, not just randomness, which is one of the more obvious applications, but they can be used for proof of space, proof of application, proof of space time. Sonana is using them for proof of history. We have some people here from injective protocol.
00:01:47.962 - 00:03:05.698, Speaker A: There's a decentralized exchange that wants to use them for anti front running, and you can also use them for fancy stuff like expiring zero knowledge proofs. So you provide a zero knowledge proof to someone proving a statement, and they won't be able to pass that proof to another person because it will have expired by that time. And if you use timelog puzzles, you can also make the zero knowledge part of the zero knowledge proof expire. So you give someone a statement with some private data, and then an hour later they can recover their private data and you can use them for other things. So in terms of progress that we have made, one of the big milestones is that we have a new startup called Supra national with Simon, who's working full time on the VDF project management. And this is funded 50 50 by protocol Labs and the Film foundation. So the VDF project is quite expensive, and so we're looking to set up a more formal VDF alliance.
00:03:05.698 - 00:03:59.942, Speaker A: At the moment it's mostly protocol labs and the film foundation, but hopefully other people will join. Another big effort is the RSA MPC. So we're looking to go down the route of RSA groups and for that we need an RSA MPC and we want it to be scalable to hundreds of participants. So today we have the Lijero team that will be presenting and we hope to also fund them to design an NPC that can be used to generate a 2000 bit RSA modulus. And one of the nice things is that the modulus can be used for accumulators as well. So this is a very nice piece of public good. The other interesting thing is the circuit competition.
00:03:59.942 - 00:05:06.640, Speaker A: So we want to try and crowdsource the wisdom of the crowd in terms of designing really fast modular multiplication circuits. We believe we can do 1 modular squaring and we will also produce an open source baseline. But the question is, can we do significantly faster than 1 guess? The competition will help answer that question. We have quite a bit of interest in terms of people who want to help out with the competition, in terms of the EDA tools, the cloud providers, but also in terms of prospective competitors, some of which are in this room. So, okay, today, academic VDF day, we want to try and tackle the outstanding problems. So we're going to have three themes, VDF provers, modular multipliers and RSA MPC. For each theme there will be kind of a featured talk, and then in the afternoon we will have breakout sessions to solve the problems.
00:05:06.640 - 00:05:54.058, Speaker A: So this is the rough agenda. In the morning we have the talks, then lunch, afternoon sessions, and then debrief with all the solutions to the problems at 430 and then optional dinner. Okay, so theme one, VDF provers. So eight months ago we had these two pure VDF proving schemes. By pure, I mean there's just one simple idea. And the two constructions are by were Solowski and Pietozak. And the nice thing is that you can take these pure VDF schemes and you can start building hybrid.
00:05:54.058 - 00:06:47.370, Speaker A: So a few months, well, actually during last VDF day, that's when we discussed the iterated Wisalowski, which gives a different trade off between the provers. So the Wisalowski prover has very short proofs, but it takes more time to generate them. And on the other extreme you have the piezak prover, which has much larger proofs, but they're very fast to generate. And I guess we're looking to explore the trade off space a bit more. And today Benjamin will also present another hybrid, which is the piertazak with Zelowski hybrid. And so one of the open questions is, can you come up with a new pure building block? That would be fantastic. And then maybe we could try and combine them with the other pure building blocks to build more hybrids.
00:06:47.370 - 00:08:26.230, Speaker A: Or can you build a new way of combining the existing ideas to have a new set of trade offs? So one of the goals for the VDF ASIC is to try and be relevant to as many applications as possible. We won't have many shots at building an ASIC, and so we'd like it to be relevant to many different blockchain projects and use cases. And so I guess this would be some of the ideal properties of the prover that we want. We'd want the proof size to be less than 1 kb, verification less than ten milliseconds, and we want the prover latency, which is the amount of extra time you need to build a proof after you've done the evaluation to be less than 1%. So let me just briefly give you an architecture diagram of a possible candidate for the ASIC, the VDF ASIC, so that you can get a little bit of flavor. So we have this squarer, which is going to be the repeated square, the evaluator, and it will run roughly at 1 way that the provers are built is that they collect checkpoints along the way. And these checkpoints, you have the option to store them in memory.
00:08:26.230 - 00:09:16.058, Speaker A: So we have this memory, a relatively small amount of memory, maybe 1 few megabytes. And with these checkpoints, you want to build the proof. And generally the proof involves something other than a squarer. You need to be able to multiply where the two inputs are different. And so you're going to have a performance penalty on the multiplier. Let's say that the multiplier is half the speed, and because these circuits tend to be quite large, it's possible that we can only have one single multiplier for the prover. And then we're looking to have an Arm core in the VDF ASIC.
00:09:16.058 - 00:09:31.420, Speaker A: So the nice thing here is that you'll be able to program the arm core and choose the prover scheme that you want, and the specific algorithm to do the proving. So if in the future we find better algorithms, we'll be able to make use of that.
00:09:31.950 - 00:09:38.300, Speaker B: Yeah, at some point you said you wanted to make this open source hardware. Doesn't it make sense to use risk five in that case?
00:09:41.970 - 00:10:17.590, Speaker A: Right, risk five would make more sense. Yes, absolutely. I'll edit it. And then we have a few connecting bits between the arm between the cpu and the multiplier. And one more subtle consideration when you're looking at provers is that you want to have enough parallelism in the algorithm so that you can feed the input FIFO fast enough to make full use of the multiplier.
00:10:17.670 - 00:10:18.300, Speaker C: Yes.
00:10:18.910 - 00:10:27.254, Speaker D: When you say a megabyte of storage, what's the goal in terms of how long of a proof that will suffice.
00:10:27.302 - 00:10:29.706, Speaker A: For if you want to use this.
00:10:29.728 - 00:10:35.834, Speaker D: Chip to do a one week long pdf, are you not going to be able to do it, or are you going to have to compose?
00:10:35.882 - 00:10:36.366, Speaker E: At that point?
00:10:36.388 - 00:10:38.240, Speaker D: What's the max you're hoping to support?
00:10:39.010 - 00:10:57.720, Speaker A: Right. So I guess in my mind, the parameters were about 100 minutes of evaluation time. But you're right, if you want to go to one week, then you might need to move to a different proof of scheme, which does not require as much memory. So you might move to the Piers act scheme, for example.
00:10:58.490 - 00:11:02.360, Speaker D: Okay. Yeah. So for the chip you actually want to build though.
00:11:04.970 - 00:11:05.478, Speaker A: Right?
00:11:05.564 - 00:11:07.320, Speaker D: The goal is to support 100 minutes.
00:11:07.790 - 00:11:30.046, Speaker A: Chip can natively do improve, I guess here. Yeah, 100 minutes evaluation time is one of the extra lines. But I guess, again, we want to push that as far as possible, just because we want it to be. If someone wants to make evaluations of one week, we want them to be able to do that.
00:11:30.228 - 00:11:33.620, Speaker C: Why do you want to luna to only 1 mean, the more memory you have.
00:11:35.670 - 00:11:49.142, Speaker A: Because every megabyte increases the cost of the hardware. And so basically the SRAM takes up more area, and that means that you have to pay.
00:11:49.196 - 00:11:50.994, Speaker C: This doesn't necessarily need to be very cheap hardware.
00:11:51.042 - 00:11:51.206, Speaker A: Right?
00:11:51.228 - 00:11:53.160, Speaker C: I mean, every miner just needs one of these.
00:11:53.930 - 00:12:17.438, Speaker A: So in ethereum specifically, if the evaluation time is 100 minutes, we don't want a random number every 100 minutes. We want a random number every, let's say ten minutes. So what we do is that we have ten randomness beacon in parallel, and each rig has ten asics. And so it does start becoming expensive if the chips are very big.
00:12:17.604 - 00:12:23.490, Speaker B: The latency sensitivity is such that memory hierarchy is impossible.
00:12:25.830 - 00:12:26.580, Speaker A: Right.
00:12:28.230 - 00:12:30.420, Speaker B: It would be really nice if I could just pop.
00:12:33.510 - 00:12:51.900, Speaker A: But then you might be limited on the parallelism of your algorithm. So if your memory is outside of the ASIC, it might take quite a bit of time to go fetch what you need to fill the FIFO, and then you'll end up with a multiplier being idle most of the time.
00:12:53.710 - 00:13:00.298, Speaker B: We should take this offline, but usually the problem with CRM is not the amount of data I can get out.
00:13:00.304 - 00:13:02.860, Speaker A: Of it, just the delay yeah, the latency, yes.
00:13:03.890 - 00:13:10.334, Speaker B: With caching we can sort of hide most of that latency. You pay the latency cost once, but then you can basically keep the pipeline full from there.
00:13:10.452 - 00:13:22.610, Speaker A: Okay, but we need to look at the details of the provers. But caching might not be a good strategy because it might be completely random access on the full memory.
00:13:24.550 - 00:13:50.260, Speaker D: To add in the cost analysis of this is if your protocol has a communal input and a communal output, then you really only need one honest participant. And so you don't need to have n of these, where n is the number of protocol participants. Whereas if you have protocol participants have to have a unique input, unique output relative to what they need to do, then you would different total costs.
00:13:53.340 - 00:14:50.280, Speaker A: Yeah. So the point that was being made is that with vdfs you have this really nice property of uniqueness. So if you have a unique input, you also have a unique output. And so what that means from a practical standpoint when you design the protocols is that you have a minimal honesty assumption or a minimal liveness assumption. You just need one single person in the whole world to be doing this calculation, which is one of the reasons why doing randomness with vdfs is way more energy efficient than doing randomness with proof of work. So the second theme is modular multipliers. So we're going to have a talk which will present kind of a new way to do modular multiplication, which is especially low latency with, as I understand new mathematics.
00:14:50.280 - 00:16:19.172, Speaker A: And so one of the problems will be can you take these new ideas and improve upon them? Another interesting question is can we prove lower bounds on the circuit depth of the basic operation, which is the modular squaring? It turns out if you have a model such as the two input gate model, then you can really trivially prove the circuit def flow bound of twelve. And the reason is that you have the 2000 bits for your input that you're squaring 2000 bits for the modular, so that's 4000 bits. And if you only have two input gates, the fastest way to mix in all the signals is using this binary tree, which will have depth twelve, and every single input bit can influence the most significant bit of the result of the square. And so hence you have this lower bound twelve. And the question is, can you improve upon that? One of the good news is that this lower bound of twelve is actually not too far away from what we can do in practice, but it would be nice to squeeze that as much as possible. And the third theme is going to be the RSA MPC. So here we only know of a single team who has confidence that they can satisfy the various requirements.
00:16:19.172 - 00:16:36.076, Speaker A: And so one of the goals of today is to actually go through every requirement and check that they are satisfied. So number one, we want it to be n minus one, maliciously secure. So if even is it possible, if.
00:16:36.098 - 00:16:52.230, Speaker F: You'Re passing a fair car, you need honest majority to make sure the kind is on fire. But the second is like talking a random kind, but you want fairness, right?
00:16:53.640 - 00:16:59.060, Speaker E: But the point is that if there is an abort, you restart the computation.
00:17:01.740 - 00:17:19.384, Speaker A: Take it offline. Let's take this question offline. The second requirement is that it be scalable. So of course we'll only know if it's scalable once we implement it. But is it at least plausibly scalable that it can scale to 1000 participants?
00:17:19.512 - 00:17:21.790, Speaker D: Where did 1024 come from?
00:17:22.320 - 00:17:26.876, Speaker A: So I think 1024 would be, are.
00:17:26.898 - 00:17:29.020, Speaker D: You actually going to do that or is that a goal?
00:17:29.360 - 00:17:43.556, Speaker A: I think that's more of a goal. I think there will be less than 1024 people in the whole world who even want to participate. So that gives an opportunity for everyone who does want to participate to indeed participate. But even if you advertise this to.
00:17:43.578 - 00:17:46.900, Speaker C: The world, you don't think more people will stand up saying you want to participate.
00:17:48.840 - 00:18:03.420, Speaker A: Just as a test, I advertised participation in the NPC on a telegram channel with 150 people, I think, all of which are hardcore blockchain people, and no one responded.
00:18:07.120 - 00:18:15.628, Speaker E: It's going to depend like we saw with the zcash ceremony, it really depends on what the ceremony is like. So with the first zcash ceremony, it.
00:18:15.634 - 00:18:16.876, Speaker C: Was a very small ceremony.
00:18:16.988 - 00:18:18.496, Speaker E: You needed people to be online for.
00:18:18.518 - 00:18:20.236, Speaker C: Like 12 hours continuously.
00:18:20.348 - 00:18:32.452, Speaker E: With a second zcash ceremony, the challenge was scheduling. You got scheduled like an n hour window to do your contribution, and then once you were done, that was gone. So that was also challenging for people.
00:18:32.506 - 00:18:32.820, Speaker A: Yes.
00:18:32.890 - 00:18:35.168, Speaker E: You had to schedule the time like weeks in advance.
00:18:35.264 - 00:19:03.464, Speaker A: Right. So the point that's being brought up is that the actual specific dynamics of the MPC will influence how many people will participate. For us, we have a synchronous MPC, which means that everyone needs to be online at the same point in time. The goal in terms of scalability is that we want the whole MPC to last ten minutes or less. So yeah, it will be interesting to try and get hundreds of people online at the same ten minutes time slot.
00:19:03.512 - 00:19:05.470, Speaker D: What's the smallest number you think you need?
00:19:06.080 - 00:19:26.528, Speaker A: Participants. So the zcash sapling has 88 participants. I believe the question was how many participants are required as a low bound, I'd say having at least 100 would be very nice. Anything more than that is, I guess, gravy.
00:19:26.624 - 00:19:29.060, Speaker C: Is there an answer for defeating sybils?
00:19:30.220 - 00:20:12.050, Speaker A: Defeating sybils? So one way is to put your reputation at stake. So if you look at the sapling ceremony, I think almost everyone, maybe one or two exceptions, was known people from the community. Another idea is if you want to participate anonymously, you could put down some collateral. I guess this is where the third point comes in. So the worst that you can do is that you can participate in the MPC and then halfway through you just abort. And so everyone has to restart. And so having the possibility to at least identify the aborts is a key property that we need.
00:20:15.160 - 00:20:16.352, Speaker D: Requires PKI.
00:20:16.416 - 00:20:41.170, Speaker E: So our approach to the civil thing was that everybody would participate, would have to publish, commit to a key, and put escrow behind that key. Well, that's the solution of Sibyls, right? Make it expensive. So yeah, we thought you'd have to escrow that. And then if you have identifiable gores, then you can basically punish them.
00:20:41.620 - 00:20:48.050, Speaker A: Right. So putting something at stake, either your reputation or either money, would.
00:20:50.840 - 00:20:51.396, Speaker B: Actually.
00:20:51.498 - 00:20:58.448, Speaker C: One more question here, just a generic question. Is the goal to generate a general RSA public key or a strong RSA public?
00:20:58.634 - 00:21:01.210, Speaker A: A general RSA public key.
00:21:02.300 - 00:21:04.810, Speaker C: Stronger public key has additional benefits.
00:21:07.980 - 00:21:28.530, Speaker A: Right. So the question was, do we want to generate like a normal RSA modulus or a strong one? And having a strong one would be better because it has all these additional properties. But from what I understand, the MPC also becomes much more complicated and expensive. If we could have a strong one, okay. Then we.
00:21:33.700 - 00:21:35.760, Speaker C: Sign quadratic residues and you can hash.
00:21:38.440 - 00:22:08.670, Speaker A: So my understanding is that for the two main use cases that we're looking into, RSA accumulators and RSA vdfs, a plain RSA modulus works, is that correct? It works. Okay. Yeah. So you could relax the assumption. Okay. And tomorrow, if you're interested, we're having a more non academic, more practical VDF day. So we're going to try and figure out some of the logistical issues of pulling this crazy project.
00:22:08.670 - 00:22:55.290, Speaker A: And one of them will be in the morning, the RSA ceremony, logistics. So discussing the Sibyls and how do we get enough people and how do you make sure that they decentralized enough, et cetera, et cetera. And then in the afternoon we're going to have a session on the logistics of the circuit competition. And there we'll have several talks, one from Chia that just completed their VDF competition. We'll have Simon from supreme national discuss some of plans that we have for our circuit competition. And we'll have a representative from synopsis that's one of the main tool vendors, talk about their tools and how they could be used for the competition. And they have an open source bitcoin mining implementation that they will present.
00:22:55.290 - 00:22:59.540, Speaker A: So, yeah, that's it. Happy problem solving.

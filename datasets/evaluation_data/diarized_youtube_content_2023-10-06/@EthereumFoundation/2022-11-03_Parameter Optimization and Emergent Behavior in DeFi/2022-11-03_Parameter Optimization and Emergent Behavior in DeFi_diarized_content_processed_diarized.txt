00:00:12.730 - 00:01:12.242, Speaker A: This is a workshop we'll be talking about using agent based models for analyzing DeFi protocol. And the examples we'll be using is through the Vega market. Later we do a quick introduction and then I'm going to jump to a slide which will show you where to go on GitHub so that you can hack along. I really assuming it's a workshop, right? So I'm expecting everyone to have a computer in front of them and start hacking, but if not, then know you can just stay along for the chat. So my name is David, I've been with Vega for the last four years. I mainly look after the kind of financial risk and economic design, game theory analysis and together with me is Tom who's coming from traditional finance. He's a quant with Vega, working on the research team.
00:01:12.242 - 00:01:30.890, Speaker A: And one of the speakers, Mark, isn't here but he's done a lot of the RL stuff so he's the main brain behind that. So I'm going to jump to, I think here if you want to talk.
00:01:34.540 - 00:02:15.380, Speaker B: We'Ll go back to introducing what Vega is in a minute. But given I don't know how fast the Wi Fi is going to be in here, just running through a few first setup steps that we can get going with while we're presenting. For anyone who hasn't noticed, there is WiFi specifically for the workshops called DevCon Workshop and the password is Build it 22. Give that a go if the WiFi is being slow. So this repo at the top here, Vega market SIM should be open. If you go over there, clone that, that's your first step. You're also going to need go 19.
00:02:15.380 - 00:03:14.440, Speaker B: I think it's necessary. Python ideally 310, three nine might work. And poetry, just because it's probably the better package manager. Probably there's a requirements TXT if you just need that as well, we can go through actually setting it up in a bit. Then if you want to be able to view our sort of front end console, you'll also need some UI framework, yarn and NVM for node management. And if you want to try some RL at the end then PyTorch is a good starting point to download. So broadly, if everyone can make a note of that URL before we switch back and then we will start on actually presenting everyone goodbye.
00:03:14.440 - 00:03:23.810, Speaker B: We'll have an actual break for setting everything up in a bit, but cool.
00:03:26.340 - 00:04:38.330, Speaker A: Yeah. So we're back to the introduction but it's sort of a workshop and if you need help, the person who isn't speaking can actually come and help you with whatever it is you're trying to do within this framework. And if you're not having luck then we can see if one of us will have better luck and there are not so many of us and we've got, I think, 2 hours so we've got plenty of time to actually get everyone going and hacking. So in terms of what we'll cover we'll quickly introduce Vega protocol, then I will try to make sense for agent based simulations in the context of analyzing DeFi protocols. And then we'll introduce what you already started setting up, which is the Vega market SIM which is relying on something called Vega null chain. We'll explain what that is and then once we have that we'll sort of explain how to use the market SIM, how it's set up, what environment is there, what agents are there and what you can do. And at the end we're going to show you how you can train reinforcement learning agents on top of this and why you might possibly want to do that.
00:04:38.330 - 00:05:30.404, Speaker A: So that's the plan. So we start with what is Vega protocol? So Vega protocol is a layer one blockchain for derivatives trading. It's set up from the ground up for trading margin products and the price discovery is either through limit order books or through auctions. Where do the auctions come in? Typically when you're setting up a new market you don't know what the price is. So initially it's running in an auction. The auction determines what the opening price should be and then if everything goes well, it's running as a limit order book. If there are big price moves according to the risk model, it might switch to a protective auction to make sure that the big price move is really what's happening economically.
00:05:30.404 - 00:06:18.550, Speaker A: It's not someone with a fat finger forgetting a zero on an order or adding a zero on an order and causing mayhem. Anyone can create a market. What it means is you submit a market proposal to the blockchain and then it goes through the governance and it's voted on. So that's what's meant by permissionless here. And what kind of markets at the moment it supports cash settled futures. There is roadmap for supporting any kind of derivative through a derivative payoff language which will be probably vASm based but that's just on the roadmap for now it's cash settled futures. And so basically if you can find an Oracle for the market then you can propose a market and it will run.
00:06:18.550 - 00:07:28.840, Speaker A: It's got a bespoke liquidity provision mechanism because it's not based on now ever so popular constant product markets but it's based on a limit order book. So you have to do something slightly different to bond liquidity to a limit order book. So it does that and at the moment the assets that have value that you would use as settlement asset on Vega they're bridged from Ethereum though in the future there will be other bridges but Ethereum bridge is there. You can on Vega before proposing a market, if you wanted to settle in some other asset that's not there yet, you can propose the asset. The asset will then be bridged from ethereum. So you can imagine that there will be USDC Tether, Ethereum, whatever people want to is that if you're designing something like a trading platform some of the goals that you might have in the design really sort of run at cross purposes between a general purpose blockchain and what you would ideally like for a trading platform. So the things that I picked out are a general purpose blockchain.
00:07:28.840 - 00:08:22.444, Speaker A: You need something like a gas mechanism for people to pay for the cost that whatever transaction the chain is processing for them, the cost has to be covered by the gas. And if you're trading this is really suboptimal in the sense that there are transactions that you want to include and you don't want to penalize them by charging for them. If someone wants to post a limit order, that's good, they're providing liquidity. You really don't want to discourage them. If someone cancels an order, that's good, they're providing price information, you probably don't want to discourage that either. So that's in products they're effectively promises, right? If someone doesn't look like they're going to keep their promise, you want to close them out immediately. Ideally you don't want it farmed out to some bots that are running somewhere because then you're opening yourself up to mev and whole host of other problems.
00:08:22.444 - 00:09:34.608, Speaker A: So you can have atomic closeouts again for margin. You want to do potentially quiet maths, heavy risk computations and you don't want to be paying for gas for those on a general purpose blockchain you can try to do fair ordering or as fair as your definition of fairness allows fair ordering of orders and you have one specific application in mind. So you can optimize for latency, for instance, rather than optimizing for data throughput. So you're not fighting at cross purposes with other applications that would be running on top of a general purpose blockchain which would have other design goals in mind. And one thing that I didn't put on the slide, but that's also a very good reason is that sharding is actually much easier in the context of trading because something happening on this market and something happening on that market can be completely separate apart from talking together through a treasury shard. So you have a very simple use case in the sense of what needs to know about what you can design sharding relatively easily. Okay, so that was vega.
00:09:34.608 - 00:10:31.892, Speaker A: Now sort of more general case for doing just trying to get rid of the mouse. More general case for doing agent based simulations in the context of DeFi. So we've all seen various DeFi protocols and we've seen when things go well, it's great and then when things don't go well, it's called a hack or an exploit. But quite often it's not an exploit of a code bug though that can happen, it's simply an exploit of the mechanism design. You want to design a protocol, you start, you think what incentives should I create so that I've got the desired behaviors? And you do it in isolation. You really try to think it through, right? You take the smartest people you can find. There are dozens, hundreds of incredibly smart people in DeFi.
00:10:31.892 - 00:11:13.764, Speaker A: They do their best, they do what makes sense. They think it through as much as they can. But it's really difficult to think through all the consequences, especially if you have one incentive mechanism here, another here, designed maybe in isolation, and now they're interacting, right? Yeah. Oh, Wendy is a name of Klaus's Fairness pre protocol for transaction ordering. He can tell you all about that. He's there. You can just go and show him.
00:11:13.764 - 00:11:37.772, Speaker A: No. Yeah. So you put two incentives mechanisms together. If they were designed in isolation, it's not completely clear that the combined effect is actually what you desired. And then of course, DeFi is all about composability. We love that. But once you introduce composability, you're introducing another level disprove stuff.
00:11:37.772 - 00:12:28.808, Speaker A: You set up a hypothesis which is testable. You will never prove that it's true, but you can set it up so that you run the experiments that should disprove it. If you tried your best and you've not disproved it, then you'll let the hypothesis stand till proven otherwise. And if you're wondering what this is, most of you have probably seen Game of Life. It's the idea that you can take a bunch of very simple rules and they can lead to very, very complex behavior. And sort of agent based models are one thing that will allow you to analyze this complex behavior. So definition of what an agent based model is from Wikipedia and everyone's favorite agent, and quite often you want a lot of agents or a lot of similar agents.
00:12:28.808 - 00:13:01.644, Speaker A: So Agent Smith is good. I've used this picture actually twice. When you talk about civil attacks, I like to use that picture. But here it's not about civil attacks. Here they're good agents who are stressing your protocol. So in terms of what type of agents you would find in agent based modeling, the simplest ones are what I call zero intelligence, which is a bit insulting. But what it means is that they're not learning and they're not optimizing.
00:13:01.644 - 00:13:50.028, Speaker A: You just say this is the state of the world, and if this is the state, then they're going to do this. And if the state is something different, they're going to do that. So they're agents that have hard coded actions and that's what they do. They're the simplest to set up, they're the simplest to understand. And of course, if you hard coded the optimal actions, then they're perfectly good. If you don't, then they're only as useful as the actions that you've hard coded. And so the next level you can think, okay, each agent, I'm not going to hard code the actions a priori, but I'm going to tell the agent exactly what the environment, what the rules of the environment that they're in are, exactly what the rewards are for interacting with this environment according to the rules.
00:13:50.028 - 00:14:29.308, Speaker A: And I'm going to optimize in other words I'm going to solve for the optimal actions. And that's something that comes under the name either Markov Decision Processes if you're doing discrete time steps, or control theory. Stochastic control theory. It's a reasonably well established field. And there are a bunch of algorithms I could spend hours talking about algorithms that they have for solving problems. There are a few problems that you can actually solve by hand. One of the most popular is the linear quadratic regulator, which together with the Kalman filter was one of the great successes of science of the 60s.
00:14:29.308 - 00:15:03.908, Speaker A: Landed on the moon and all that. So good stuff. And then sort of the fancy new stuff is the reinforcement learning, where you actually don't have to tell the agents what their environment is. They just repeatedly interact with it, observe the outcomes of their actions, observe the rewards and update their behaviors. So these are the type of agents you might want to run on top of your environment to see what is happening. And of course, what is appropriate and what you need will very much depend on what you're trying to simulate, what you're trying to test. But basically this is your zoo.
00:15:03.908 - 00:16:09.564, Speaker A: And then the typical setup for these things sort of you understand you have the agent. Agent takes action. It changes the environment in the sense that it moves it from the current state to the next state. So sort of new state comes out, a reward comes out, and the agent takes in the reward and the state and again chooses the next action and you repeat. And of course you can have these setups that you repeat sort of forever until infinity, maybe with some discounting or maybe you assume that there is some steady state or there will be a terminal time when the game stops or whatever problem finishes and you evaluate how everything went, whether it went well or badly. And then one thing I wanted to point out here is because it will be relevant if you're looking at any of the code that we are providing, is that the agent, as it's learning it's in a state, it takes an action, collects the reward, sees the new state and decides on the new action. And if you record this, that's sort of all the data that you need to train the agent sort of offline separate from the environment.
00:16:09.564 - 00:16:41.476, Speaker A: If you collect these Sarsa sequences, then you can train the agent separate from your environment. Okay, so that's not so important now. It will be more useful information later. Right. And I think I'll hand over to Tom now who will walk you through the vega market SIM. It's a workshop. So if you have questions, I think the gentleman there already said, yeah, you're setting a perfect example.
00:16:41.476 - 00:17:10.490, Speaker A: Keep asking questions. It oh, do we need a microphone? Can we have a microphone for the question? Just yeah. Excuse me.
00:17:11.500 - 00:17:12.200, Speaker C: Thank you.
00:17:12.270 - 00:17:21.560, Speaker A: Hello? It's hello.
00:17:22.890 - 00:17:40.874, Speaker C: Do states based approaches have any role to play in parameter optimization? Like a control theory based approach for optimizing an effective so you would set.
00:17:40.912 - 00:17:57.170, Speaker A: Up your environment, which in the case, which we will show would be the whole market. How the trades happen, how the orders are matched and then you run that whole thing through the simulation, see what happens. And then you might want to do the optimization on top of that.
00:17:57.320 - 00:18:12.310, Speaker C: Right, but that's an agent based approach, right? You could use an analytical solution. So let's call an agent based approach, a numerical approach, but a control theory approach.
00:18:12.650 - 00:18:32.458, Speaker A: Yes. If you have an environment which is sort of sufficiently simple that you can really write down all the state transition equations, then you can go and solve it through either pen and paper, if you're supremely lucky, or through something like policy iteration, value iteration.
00:18:32.634 - 00:18:36.734, Speaker C: You could use something like MATLAB. Well, that's actually numerical, but you could.
00:18:36.772 - 00:19:07.266, Speaker A: Use software, obviously, to yes, and there is software out there. Does this work for creating bots, trading bots? Yeah, I mean, like the whole framework you have. I mean, Tom will talk through that, so I'll jump a bit. But basically the environment on its own. If it's just the market, it's an empty market. It hasn't even gone out of the opening auction if no one proposes anything. So you automatically need bots.
00:19:07.266 - 00:19:32.980, Speaker A: So we will talk a bit about the bots that are provided as part of the environment. And of course, you can write your own bots that can know well whatever they want to do. We've got some basic market making bots, we've got some basic price staking bots, we've got some basic momentum traders. But Stone will talk more about that, so I'll hand over to him.
00:19:34.470 - 00:20:16.110, Speaker D: Just a quick question. So in this type of systems, do you take the code from what you are testing? For instance, for the Vega protocol, I just quickly check that it's all go code, right? Okay. So do you take this code and run it inside your simulation or do you create a model of that? Okay. And do you think that's scalable if you want to simulate thousands of millions of agents because perhaps you need that or do you think it should be more in some cases you need a model of what you are actually testing.
00:20:19.330 - 00:20:44.758, Speaker A: I'll answer with the microphone. So we're running the whole Vega stack again. Tom will show that. But you're absolutely right that in some situations, especially, we want to do reinforcement learning. Having a simplified model on which you can train before you actually go onto the full stack, which will be inevitably slower than you would like because things are never as fast as you want would be useful. But we don't have that at the moment. We're learning on the whole thing.
00:20:44.758 - 00:21:00.762, Speaker A: That's why it's important that we use an algorithm which collects the Sarsa sequences and so then can learn offline, but we don't have model. There are reinforcement learning techniques which sort of build up model from observations. And you can do a lot of clever stuff, but I'm far from being an expert on that.
00:21:00.816 - 00:21:01.754, Speaker D: Okay, thank you.
00:21:01.872 - 00:21:41.594, Speaker A: So one thing that I didn't say is one reason why DeFi is so good for agent based modeling is you can try and people have been talking about agent based modeling in the real economy, and economists would love to do that, but they don't have the environment on which to execute it. And in DeFi, we do have that because things are typically open source. I can go and take the smart contract and run things through the smart contract. I don't have to create the environment. I just say, okay, I care about how this smart contract interacts with this one. I take whatever ganache hard head, I put it there, I set it up as my environment, and I pump thousands and thousands of simulations through that. I can't do it in the real economy, but here we can.
00:21:41.594 - 00:21:44.778, Speaker A: So it's awesome. Okay, more questions.
00:21:44.944 - 00:22:04.106, Speaker E: Can you talk a little bit about the reward states more in terms of kind of what the stopping criteria might be? And I guess in the context of the derivatives market, are you really looking at things like protocol solvency or profitability of certain agents that are performing trades or kind of what are the reward metrics? Because I'm assuming they're not like bugs.
00:22:04.138 - 00:22:55.786, Speaker A: But more financial kind of outcomes for us. It's very problem specific. So, for example, if we want to test what some of the network parameters should be, we set up an environment and then we look at things like if I've got a rationally behaving market maker and the parameter is X, what is their return on capital? And I'm thinking, well, maybe this is letting them earn too much money. It doesn't make sense. But in terms of the reinforcement learning guys, you would typically look at financial rewards and then, yeah, you can either run it thinking of it, maybe you're thinking they're trading perpetual so it's just forever, or you're thinking that they are trading a settlement market and so the reward comes at settlement. But it's very much something that you have to design for the specific purpose that you have in mind. This is sort of more the toolbox.
00:22:55.786 - 00:23:07.220, Speaker A: And I'm going to wrap up the questions, hand over to Tom and then you can ask afterwards because I have a feel that with the questions, we're sort of jumping ahead a bit. So I want to hand over. Thank you.
00:23:11.190 - 00:24:13.190, Speaker B: So, discussing the micro simulator, we'll get to doing some ourselves in a minute. But first I think it's useful to go through and yeah, to cover again, slightly more technically some of the questions how we run these simulations and how we get interesting results out. So the Vega market simulator, broadly, the way that Vega itself is set up, we run with a tendermint consensus layer. For those who don't know, tendermint is a cosmos based consensus. The problem with that is that it's generally tied to our block time, which is about a second. So if you run the whole thing, you can watch the market going second by second and you can interact with it, but you can't run, as the question at the back said, thousands of scenarios, run it through a year, do all these things. So what we do, we strip that out, we run what we call a null chain entirely on one PC.
00:24:13.190 - 00:25:17.818, Speaker B: And this just broadly accepts any transactions it's sent, it still checks, they're valid, it still runs through the whole Vega core logic, but just adds them to a block, allows you to control time forwarding. So it'll just sit and do nothing until you tell it to run forwards or fill up a block. And so you can inspect at any point in time for however long you want what's going on. Then on top of this, once we've got that running, we have in Python an API layer which lets you express your trading actions, your agents behaviors in much more market primitives without having to worry about the fact that you're running on a blockchain. Occasionally it still creeps in because that's the way of the world. But you can broadly talk about an agent trading on a market without having to worry about what block it's in or whether it's been confirmed and this kind of thing. Once we've got that, we then build out our scenarios and our tests.
00:25:17.818 - 00:26:21.330, Speaker B: So I'll cover possibly next slide exactly what a scenario is. But we can with a range of composable agents, composable setups. Build out scenarios to investigate and test either certain parameters test that the market doesn't explode, test the core itself doesn't explode. Or if you're just wanting to build an agent, you can try and have a realistic market and throw yours in there. How this all works is your Python layer manages we've got two different kinds of interfaces at the moment, a Vega service null, which spins up this, as I mentioned, a service entirely on your machine or what we've recently created, which is Vega service network. And that allows you to connect to a running external network and run the same agents that you've just been running locally, but on the real network that's going on. So that can be useful in some cases too.
00:26:21.330 - 00:27:07.858, Speaker B: It allows us, for example, on our testnet, we can run agents and simulations that other real people can interact with and see how that's working. We'll demo all of that in a bit. So yeah, back to setting things up and viewing. I'll go through the viewing in a second, but yeah, I was going to break here anyway. We're back here. I don't know how many people have managed to get to the end of this, but I think we'll probably take a sort of ten minute break to catch up. Anyone who hasn't, we can wander around and see whether everyone will manage and then 1015 minutes we can come back and continue with doing something more interesting with it.
00:27:07.858 - 00:27:19.462, Speaker B: If you think you've got it set up, try and run these scripts at the bottom. We can also tell you something more interesting to run if you're stuck. I think I had a question.
00:27:19.596 - 00:27:40.426, Speaker A: Yes, we have the microphone if you think you have a loud voice. Okay, so my question is I can have a new chain on my own computer so I can more so I.
00:27:40.448 - 00:27:46.990, Speaker C: Can then more in a more real way, basically test my ideas.
00:27:47.890 - 00:28:12.610, Speaker B: It's something we're pretty much currently working on is being able to better snapshot an existing running chain and be able to totally restore from that. There's the capability currently to you can run your simulation and save that and rerun the same thing. So you can have an example that you run and then run your things after. We don't currently have a way to pull from an existing network.
00:28:12.770 - 00:28:14.280, Speaker C: Okay, thank you very much.
00:28:18.410 - 00:28:21.058, Speaker F: I'm an economics researcher and advisor and.
00:28:21.084 - 00:28:22.426, Speaker E: I field a lot of questions about.
00:28:22.448 - 00:28:53.540, Speaker F: The specific parameters that people should be using in their protocol. And I tend to tell them that they can more easily solve for tokenomics problems by including a market mechanism to optimize and let the market do those kinds of things. Like example uniswap V three solves the hard problem of how to set the curve by allowing concentrated liquidity. So my question is, do you guys have an intuition for which kind of systems require a simulation and which kind?
00:28:54.950 - 00:29:16.394, Speaker B: Oh, good question. I guess I'd go back to as David was saying earlier, it depends on how. Well, if you can solve it mathematically, that's probably always going to be optimal. But when it reaches a certain point of complexity, yeah, I don't know how you would do it without either an agent based simulation or stochastic modeling or that kind of thing.
00:29:16.512 - 00:29:28.030, Speaker F: Is there an upper limit to the kind of complexity that you can model in this? Because I'd imagine in this example of using a market mechanism that adds a lot of additional complexity. Would that be an issue in the Vega simulation?
00:29:29.730 - 00:29:32.330, Speaker B: In terms of complexity of the simulation?
00:29:32.410 - 00:29:49.670, Speaker F: Yeah, I mean, it multiplies the number of agents in the system by orders of magnitude. If you have to use a market to source lots more participants, is there an upper limit to the kind of complex system that the Vega market simulation can handle?
00:29:51.050 - 00:30:21.082, Speaker B: Well, practically, I guess there is an uplimit. The system itself, we're hoping, will be able to scale to many thousands of people. So that should also scale to the number of agents. So I guess it's a goal of both the Vega protocol itself and the market. SIM, thankfully have similar things because ultimately what we want to do is build a realistic market. So if you can build as long as we can run a realistic market on Vega protocol itself, we should be able to do it in a simulation.
00:30:21.226 - 00:30:21.582, Speaker A: Cool.
00:30:21.636 - 00:30:22.510, Speaker F: Thank you, guys.
00:30:22.660 - 00:30:54.940, Speaker A: Yeah, we should be able to thousands of parties and hundreds of transactions per second. Therefore, going back to the points that you were making, I absolutely agree that if you're designing tokenomics or protocol novel, then either you can prove that it works, or you can use this agent based simulation to sort of not prove that it works, but show that it doesn't and go back to the drawing board. Yeah.
00:30:57.710 - 00:30:59.114, Speaker F: I'm just wondering if a follow.
00:30:59.152 - 00:31:03.040, Speaker E: Up, how does the training time correlate with the number of agents?
00:31:06.450 - 00:32:04.500, Speaker A: So in terms of training, there are two questions. I can have some agents that matter. The agents take their actions quickly and get on with it. But of course, the moment you have more than one optimizing and learning agent, then it's the whole game theory, and then it's also very difficult to set up, or very difficult. You have to think carefully about how you set it up because is agent A also trying to learn the optimal response of agent B so that it can anticipate, et cetera. They can end up chasing themselves in circles and all sorts of weird and wonderful things can happen. Game theory and RL comes in, and it's very problem specific, but you can end up with situations that they don't learn, or you can end up in situations that they take a lot longer to learn because there is more than one learning.
00:32:04.500 - 00:32:19.720, Speaker A: Can I have a show of hands of the people who are actually trying to set it up on their computer? Okay, now is the time to take the break, and we're going to have a look around.
00:32:20.810 - 00:33:22.330, Speaker B: Okay, so I think a few people have it running at least. I'm going to crack on and then we'll have another break in a minute for doing the next bit. So we can keep coming around for anyone who's stuck on this bit but want to give more interesting things to do on top of that. So a quick aside, once the null chain is up and running, the microSIM is up and running. You see, anyone who got it working would have seen something like on the right here, which it's a printed output log of some stuff that's going on inside market SIM exposes various APIs for this, but often you don't want to just have to manually call python APIs for every single thing that you might want to experience. So we've got a couple of useful portals on your data. You can, if you've set up the UI components as well, change a flag.
00:33:22.330 - 00:33:56.934, Speaker B: This run with console equals true in generally wherever you happen to be running your Vega null chain. That will bring up in a web browser the nice. Console that you see at the front there, that is the same console that people use on Vega protocol itself. So that has theoretically pretty much everything you need. You can even trade manually through that as well if you want. You can log in as your agents that you've set up. We'll probably demo it a bit in a bit.
00:33:56.934 - 00:34:59.994, Speaker B: You also can is actually always launched. If you check the logs there will be this GraphQL port and if you go there and you know GraphQL you can query the entire system with fairly hopefully clear GraphQL queries there's on Docs Vega XYZ there's a link in a bit the entire sort of structure of your GraphQL queries you want as well. So for anyone who has got it running for a more interesting scenario that's something you can try out running. I'll leave it up actually let me skip to the next thing. This is what I'm going to talk through with this up so anyone can type it up. So the components that Vega itself runs on a validator node that we're also going to be running locally that the Nile service spins up. There are a few different ones.
00:34:59.994 - 00:36:05.374, Speaker B: We've got Vega which is the core process that's the Go blockchain client that does all of your transaction processing and outputs your states. That is obviously it's a point in time preceding thing. So we also want the data node which listens to external events output by the core node itself and saves those into a postgres database and allows you to query all of that historic data and that's generally what you'll be using when you're querying any data from Vega storage layer. Additionally, there's a couple of extra things. There's a console as I mentioned previously, that isn't necessary but it's a very useful front end. There's also the vega wallet. The wallet is basically signs transactions and ensures that any sort of custom signing we have some proof of work to stop spam attacks and stuff and that handles all that.
00:36:05.374 - 00:37:05.506, Speaker B: It's optional here because for the null chain what we actually do is skip all of our validation so that it will blindly accept if you send a transaction and say it's from whoever, it believes it's from whoever. So you don't necessarily need that. What it will spin up is if you spin up a console the two interact and lock together. So we use a full wallet for that. So once we've got our market SIM set up, how do we actually run our scenarios? They're set up as ideally plug and play components. The overall thing we set up is we call a scenario that consists of an environment which is your background environment and your Vega setup. So that will include things like how many steps you want to run your simulation for, how your Vega is set up and sort of what kind of logging you want, that kind of background detail.
00:37:05.506 - 00:37:46.158, Speaker B: We then plug in the various agents, some of whom will be setting prices. They could be acting randomly and each of them will have something they do, you'll see when you build one yourself in a bit, something they do at startup. Often they'll force it themselves, some tokens, that kind of thing. And then they've just got a function and each step call that function and it does whatever it wants to do. It pulls in data from the market, it trades, they do whatever. So scenario environment, you'll see that when we go in a minute to the agents themselves. So what's an agent? It's fairly simple.
00:37:46.158 - 00:38:31.114, Speaker B: Ultimately it's an initialized step where they generally force it. Sometimes they will do things. So we'll have an agent that sets up all the assets because you start with a blank blockchain, you don't have any assets, any markets, that kind of thing. So you may see if you're looking through market manager who does all this set up for you, then they'll have a function that's called every scenario step. However many steps you do generally will sort of randomly shuffle them so that you're not always getting the first agent called first in any step and then a finalized method that mostly you can ignore. But often you'll want one to sort of settle the market and things. So that's how you want to set up your agent.
00:38:31.114 - 00:39:26.320, Speaker B: There's one more thing. I mentioned earlier that sometimes the blockchain does have to bleed back in you'll see scattered throughout, occasionally a wait for total catch up function. Basically what this ensures is that you're getting a good view of the market. Currently you haven't thrown way too many transactions at it, everything's in sync, that kind of thing. So it just ensures that you're more real world modeling rather than trying to ensure that you can get everything in 1 NS through. So I'm going to now talk through building one of these agents, a really simple one. It's just going to do a bit of trading I guess and then we'll break again and hopefully you can put together your own a bit if I try and find where your SIM is.
00:39:26.320 - 00:40:16.154, Speaker B: Okay, so for anyone who has it set up, we've got this run simple agent in fake SIM reinforcement. Run simple agent. I'll put up on the screen after this the paths to these files and then in agents we have our simple agent. So what run simple agent does is it sets up a scenario. I can discuss the actual arguments with people which we call Curve Market maker and that jump into working. Basically that contains an agent who ensures that there's a nice shape to the market and a few who just sort of randomly buy and sell. So they're very dumb.
00:40:16.154 - 00:42:02.100, Speaker B: Theoretically you should be able to agent, which is what hopefully we're going to build that runs this simple agent that we've got together here. So what I've put together is a few nice template functions. That is without having to worry too much about how any of this works. You should be able to cut and paste these into our step function which is down here we've got the simple agent and you can see it's got the structure as described earlier. We've got our initialize where it's finding the market, finding the asset and minting itself an asset and then say submit a market order and it check our positions. It is currently always going to buy. So 50 50 chance of making money.
00:42:14.120 - 00:43:01.124, Speaker A: Okay, so we are down to the really just the hardcore workshop participants. You're the ones who prevailed with us despite Python and its foibles and the slow internet. So I'm going to crack on. If you're coding, keep coding. If you have questions, there'll be time to ask questions. And what we want to get to now is just to show you a little bit more of what the agents that you have there, the market maker, et cetera, that you're interacting with little bit the ideas that they're based on and then move on to the reinforcement learning know as part of the environment. As Tom was saying, if you just set it up, there is nothing.
00:43:01.124 - 00:43:55.296, Speaker A: It's the empty vega blockchain as it would be when it launches live. No assets, no markets. Everything has to be created through governance. And once the asset is created, once the market is voted through, which the Python sort of expedites for you, you will still have just an empty market, right? No liquidity on it, nothing, no activity. So effectively the code provides various versions of market makers that are based on some stochastic control problems that are presolved coded up and basically running and then some sort of hacks where the optimal solution of the stochastic control problem is used as a heuristic. And then you put something on top of that and you can have Liquidity Trader, you can have Liquidity Takers, which just means they place random market buy and sell orders. You can have informed traders.
00:43:55.296 - 00:44:20.810, Speaker A: What does it mean? Well, you just tell them what the price will be at the next step, right? Maybe they have inside information or whatever. And there are the momentum traders through a library free. So you can trade on all the patterns that these chartist people have. There are these vomiting camels and I don't know what else. You can code up agents that trade on that.

00:00:02.610 - 00:00:46.900, Speaker A: You. So like we said, we're going to talk about why all your smart contracts are vulnerable to bribery and what to do about it. And this is joint work with a number of excellent co authors. Like all good research, remember, no research is ever an island. So let's start by talking about why we're all here. And actually one of the interesting reasons we're all here is because of a Polish economist from the 1970s named John Harciani who laid the groundwork for this field of study we call mechanism design. What is mechanism design? It's a field of economics and game theory that takes an engineering based approach to trying to get users to behave a certain way using economic incentives, assuming the players in this game will act rationally and in their own self interest.
00:00:46.900 - 00:01:44.002, Speaker A: So the field started in the consists of several basic components. One of them is a mechanism which is a game that has rules a game environment and that players send messages to. That game has an outcome and that outcome has what's called a social choice function or social utility function that says how good that outcome is for all the players in the game and therefore for society at large. So what you want to do is implement some mechanism that implements some social choice function you find desirable. And the hope is that because people act rationally, they'll sort of converge on this social choice function you've chosen. So what's an example of this? Well, before DevCon, I actually found myself pretty hungry and I wanted some toast but I actually couldn't decide whether I wanted regular toast or toast with an image of Jesus on it, like you may have seen being popular on various auction sites. Obviously I went with the Jesus toast because who wouldn't? And so I headed over to Ebay and found some auctions on this sort of toast.
00:01:44.002 - 00:02:34.162, Speaker A: And you can see here, this one has a few days left in the auction and it's currently bidding at $0.01. So I was like, this is great, I put in my bid for two cent and I'm going to win this Jesus toast and sort of fill my hunger. But then sort of at the last second someone comes in and puts a bid for over $9,000 because they really wanted that piece of toast and I'm sort of left hungry and not knowing what's going on. So this sort of highlights a general problem with auctions, which is that in auctions you need to play strategically, you need to consider how other people are going to act when you choose how you're going to act yourself. And the games you sort of play with them like people play on ebay, become very complex. So one of the early things the field of mechanism design has looked at traditionally is can we improve things like auctions? And in terms of the social choice function, what our high level goals are for that function? For the seller. Their goal is to maximize their profit from selling the item, of course.
00:02:34.162 - 00:03:58.254, Speaker A: And for the buyers, they don't want to overpay over what they think the item is worth or the minimum they could be paying. They don't want to have to think about complex strategies like when should I place my bid? Do I have to wait until the last second? What are other people going to do in this auction and how can I get this item more cheaply? And the buyers also want to win the item if they value it more than any other buyer in the system. We also assume the existence of some auctioneer who's this sort of trustworthy third party that runs the mechanism, which is sort of a classic assumption in mechanism design that you have this third party that everyone who trusts that's actually running this game that we talked about. So can we improve the ebay auction? One of the proposals from sort of mechanism designers, classically, was what's called a VCG auction, or Vickory Clark's Groves auction. And the way this works is that all the buyers send a bid in a sealed envelope to the auctioneer and at the end of the auction, the auctioneer opens it and the winner of the item is the highest bidder, but he pays the second highest price for the item. This model is used very commonly in things like ad sales, and you can actually mathematically prove that given a bunch of private valuations on the buyer, the best strategy for any buyer in this game is to bid what the item is really worth for them. If they overbid, in many cases, they will lose money over bidding their real valuation, and similarly, if they underbid, they'll lose money.
00:03:58.254 - 00:05:00.500, Speaker A: So that's great, right? That's what's called a dominant strategy truthful mechanism in the classic field of mechanism design, meaning that a buyer's dominant or best strategy is always to tell the truth. And traditionally, we've wanted to build mechanisms that are DST because they minimize cognitive load and overhead for sort of the players in your system and just make things simpler to think about and reason about. And cryptocurrency has sort of continued this broad tradition of mechanism design, again by some party or principle, using incentives to drive outcomes. So this is an example from the Bitcoin white paper, Satoshi Nakamoto, who talks about how the incentives in Bitcoin may help nodes to behave honestly in the system. And smart contracts have similar overlaps and continuations of this field of study that's been going on since the 70s. For example, there's this idea that you can take any mechanism that we've been studying for decades and just make it a smart contract, get rid of your trusted third party, get rid of your auctioneer, put it on chain, and then we don't have to choose who to trust to play that role. We can just sort of converge on this code instead.
00:05:00.500 - 00:05:45.742, Speaker A: Otherwise, if you want to build something that no one's ever built before. You can use these same techniques that people have been using for decades to sort of analyze your mechanism and give users the properties they want. Unfortunately, there's some challenges in doing this that make smart contracts very different from traditional mechanisms. So again, in traditional mechanisms you have this trusted third party whereas in blockchains you're replacing it with the blockchain which has its own sort of set of gotchas including things like how the peer to peer network works or how miners choose transactions or censor transactions. Also in traditional mechanisms you often assume a permission set of players, a known fixed set of players when you analyze your games. For example, Ebay knows all of the accounts that are eligible to participate in a given auction and they have permission control over this set. So does Google when they're auctioning off ads.
00:05:45.742 - 00:06:42.050, Speaker A: And because of that you can do things like leveraging identity and there is some trust involved there, unlike in smart contracts and cryptographic systems where all you might see is someone's private key and signatures and you might not be able to leverage the shared trust. So smart contract mechanism design poses new challenges and chief among these challenges and what we're going to talk about today is the ease of coordinating bribery. So last year I wrote a blog post called The Darkdow, which if you haven't read, I highly encourage you to check out. And it described a sort of nightmare scenario where people can build bribery systems for smart contracts that operate completely in the dark. So no one can tell exactly what players are being bribed to do, how many players are being bribed, or if the attack is even succeeding at all. Not only that, but users are guaranteed that the person that's bribing them is not going to get control of their money. So the entire thing is sort of a trustless Bribing infrastructure, right? And the Dark Dao is actually a mechanism for bribing other mechanisms essentially.
00:06:42.050 - 00:07:14.302, Speaker A: And what I'm going to do today is introduce this new term for you guys that we call antimechanisms which are all mechanisms that are intended to disrupt other mechanisms. So the Dark Dao is a particular type of antimechanism. It's called the Dark Dao because it's dark or invisible. No one can tell exactly what's going on inside it. But you could also have a public bribery contract or other form of antimechanism. And what antimechanisms look like is basically this. So on the left you have what it looks like when users are playing a regular mechanism, they're sending messages to this mechanism and the mechanism is coming up with some outputs of the game.
00:07:14.302 - 00:08:24.834, Speaker A: You can see this mechanism as a smart contract on ethereum private keys there on the left sending transactions to the mechanism and some outputs occurring in the state of the system. An anti mechanism happens when you have another mechanism that users can play through instead, potentially one that can interact with the original mechanism. So you can see that there, shown on the right, m prime here is an antimechanism, and two users in this case are playing M through M Prime. So why does that matter? It matters because the existence of these antimechanisms erode a mechanism's ability to faithfully implement its social choice function. So in terms of optimizing for those goals that we talked about earlier, that mechanism design loves to optimize for, those goals are highly harmed by the existence of these antimechanisms. Not only that, but we can actually quantify the security of a given mechanism as the smallest budget antimechanism that disrupts the properties we design the original mechanism for. So I would encourage you guys to stop thinking about antimechanisms or sorry, stop thinking only about mechanisms when you design your smart contracts and your protocols and start thinking about what anti mechanisms could be possible in your system and what the sort of lowest cost of disruption is as a result.
00:08:24.834 - 00:09:25.350, Speaker A: So, for the VCG auction, the second price auction we mentioned earlier here's a very simple anti mechanism, M Prime. All M Prime does is it collects bids from its users and it forwards only the top bids to the original mechanism, M. So why is playing through M Prime always better than playing through M? Well, if the highest bidder plays through M, doesn't matter. The outcome is the exact same as before, so no one's worse off. On the other hand, if the highest bidder happens to play through M Prime, then either the second bidder plays through M Prime, in which case their bid is never forwarded and the highest bidder ends up paying less, or the second bidder plays through M and you get sort of the same outcome again. So what we say is that M Prime composed with M or playing M through M Prime, in this case dominates, in this case weekly dominates playing M directly. It's always better for players to play through M Prime and it disrupts what we talked about earlier, which is the dominant strategy truthful nature of VCG auctions, because the auction is no longer receiving the true valuations from the buyers.
00:09:25.350 - 00:09:55.150, Speaker A: So in this case, VCG, in terms of a dominant strategy truthfulness, has zero security against bribery. And bribery is a huge deal in all these systems. We're building a huge deal in smart contracts. So if you're building an oracle, you can bribe people to provide certain responses. You can bribe them to go offline, you can bribe them to choose which point in a continuous time series of data they sample and send into the blockchain. If you're running a vote or a governance system, you can buy people's votes. You can pay them to not vote.
00:09:55.150 - 00:11:01.218, Speaker A: You can otherwise influence governance. If you're building an identity system, you can build antimechanisms that lease people's identities or partition out certain capabilities of the identities as separate from others and for all mechanisms you can bribe players to take certain strategies and even to collude with each other or not participate. So the conclusion is basically this, at least for now. So what are we going to do about it? Well, first let's talk about the core problem here, which is that this darkdow or these private smart contracts that we're talking about remove a user's free will in the system. They do that by restraining the actions a user can take in this cryptographic system and basically shackling them to a certain set of strategies or shackling them to a certain collusive set. And we want to get back to sort of a state where users have free will, where we know that if they're signing a message they could have signed any other message in the system as well and they're not artificially shackled by some other piece of technology or some antimechanism. So here we define free will as the ability for a user to use their information, in this case their keys in Ethereum without any external restrictions.
00:11:01.218 - 00:12:12.970, Speaker A: And in this case we're specifically talking about remote parties, people who are trying to bribe or otherwise influence users over a network because that's most of what we're trying to secure against. So this problem actually goes beyond cryptocurrencies. This is not only a cryptocurrency problem, these two papers have pointed out similar problems in traditional cryptographic systems. So one thing you can do is you can use SGX or MPC to take a deniable communication protocol where the property is that I can't generate a transcript of the protocol and you can actually generate a transcript that's provable. Right? So I lose all my deniability? I can't tell you that, no, I didn't say this because now the MPC or SGX process is going to stamp for me that yes, I actually did say this. Or you can use it to do things like bribe people to act a certain way on Facebook or buy their votes in sort of traditional voting systems and things like that, which is what that paper on the left deals with. So how do we get back to free will? Well, our core task is ensuring that a user has unlimited knowledge or access to their private information such as their keys, and that those private information or that private information can't be stored in a secured environment that's somehow shackling the user.
00:12:12.970 - 00:13:11.870, Speaker A: And our second task is that we want to use this to make a signature scheme that's usable in things like smart contracts so we know that when a user signs the message they actually control their key. So we more generally define free will as the ability of a user to learn their own secrets. And we achieve free will by requiring that whenever a user sends a message that involves secret data, for example a private key, someone can eavesdrop on that message. And because a user won't let anyone else eavesdrop on their message that would, for example, compromise their funds. That means that essentially the user is able to eavesdrop on their own data. So what we're going to be doing is sort of designing a scheme we call Complete Knowledge and users are going to provide these Complete Knowledge proofs to the system to prove that they actually know their own secrets and that some human knows this secret and it's not somehow shared across multiple parties or otherwise constrained. So I'm going to flash a bunch of cryptography at you.
00:13:11.870 - 00:13:53.614, Speaker A: These slides are going to be on my Twitter if you want to read this in more depth. But the only important thing on this slide is sort of these last two bullet points, which is that we consider two computation environments, one being sort of an untrusted computation environment and another one being an eavesdrop environment. And we want to make sure that a user has to send their private data through this environment that they can also eavesdrop on and therefore can learn their own private data. And the way we generate these proofs is we require some proof scheme that matches these two cryptographic definitions. The two important properties here are number three and four. The first one is unforgivility. That means I can't prove to you that I know some secret data that I actually don't know.
00:13:53.614 - 00:14:55.330, Speaker A: Right? And the second one is secret eavesdropping, which says that I have the ability to eavesdrop on my own data and nobody else in the network can tell whether or not I actually did this eavesdropping or not. If they could tell whether I actually did the eavesdropping or not, they could simply require me not to do the eavesdropping when they bribe me. So it's very critical that the data is able to be eavesdropped on but sort of in the dark and in secret. And the basic solutions we use for this are actually quite surprising. So there's two possible schemes here, one of which is based on Bitcoin Asics and another one of which is based on SGX or trusted hardware. So the Bitcoin Asics solution is to basically do a proof of work on your secret key as well as some challenge, and then generate a snark that some ASIC has done this proof on a secret key that the Snark keeps secret that corresponds to a public key that the Snark makes public. So when the Snark is submitted to the network, you know that at some point someone put that secret key into an ASIC to generate the POW.
00:14:55.330 - 00:15:47.026, Speaker A: The SGX solution similarly forces you to send the secret key as input or the secret data as input raw unencrypted input into an SGX chip. So on the left, this allows users to eavesdrop on their own data. Because Asics are not secured, you don't know what firmware someone else is running on their own ASIC and whether it lets them eavesdrop on their data or not. On the right, SGX achieves this because SGX enclaves have to be communicated with through an unsecured OS and nobody sort of in the broader network can tell if the OS that was communicating with the enclave did or did not eavesdrop on its secrets. So I'm not going to go through these, but check them out later if you're interested in sort of the formal cryptographic definitions of both of those schemes. What we're actually implementing is a little bit different. So the problem with the schemes that I just mentioned is they're a little bit heavy handed and inefficient generating the snark actually takes quite some time.
00:15:47.026 - 00:16:26.042, Speaker A: So there's this cute little trick you can do for the proof of work version where you restrict the non space of the ASIC and require someone to try multiple times to sort of generate a proof such that if they try more than once, they can recover their own key, and with high probability, then they'll be able to sort of eavesdrop on themselves. So basically the math here works. So let's talk about the proof of work version. The proof of work version fails in one of several cases, so the proof of work version will fail. If you can use a CPU to generate the proof of work, then SGX can just directly make this proof. Even though the secret data is never known to the user. It also fails.
00:16:26.042 - 00:17:15.930, Speaker A: If the ASIC fails to find a proof, then a user that actually knows their own secret data won't be able to prove that to the network. Fortunately, bitcoin Asics are much, much faster than CPUs, so 100,000 times faster than state of the art CPUs at this sort of work. And you can see that given even if they're only 100 times faster, the probability that an ASIC will find a solution before a CPU is basically one. Right? So there's sort of a broad range of parameters here for which it's highly likely that an ASIC will be able to find this proof of work, but a CPU will not. And therefore no sort of SGX process or multiparty computation can also solve this proof of work. So these are the marginal CDFs of sort of the times to solve Blue. You see the probability that an ASIC has solved the puzzle, and red the probability that a CPU has solved the puzzle.
00:17:15.930 - 00:17:59.062, Speaker A: And you can see the ASIC slope is just much steeper. So you can sort of parameterize your system to make sure that an ASIC can always give you this proof, but a CPU can never give you this proof, and therefore no constrained or shackled computing environment can ever give you this proof. So what we're going to be doing is releasing this sort of system on ethereum using this kind of an architecture. So all you're going to need to do in your voting contract or anti bribery mechanism is call this single function on our registry when CK, which will tell you the last time that a complete knowledge proof was generated on some key, the last time some user proved to the system that they actually are able to learn their key. Right. And users can choose, like, several backends to do this. If they prefer to do it through SGX, they can do it through SGX.
00:17:59.062 - 00:18:59.440, Speaker A: If they prefer to do it through a Bitcoin ASIC, they can do that. And interestingly enough, this also gives us an opportunity to recycle old bitcoin Asics, because even old Asics that are no longer profitable for mining on the network, are still much, much faster than state of the art CPUs and can still be used kind of to generate these proofs. So I recommend to you that if you're designing a system where bribery is a big deal, you should use this technique to make sure users actually know their data and they're not being bribed by some sort of shackling mechanism, some antimechanism, like we described earlier. Not that CK is enough by itself, though, so you need to actually follow this more complex recipe. You need to also provide the classical notion of coercion resistance, which basically says that a user can secretly change their mind whenever they want. So if a user can secretly change their mind whenever they want, there's no point in bribing the user, because you don't know if they're just going to go and change their mind later. You can't tell if they did that or not, right? And because you're using CK, you know that there's no sort of shackles on the user that prevent them from changing their mind in this way.
00:18:59.440 - 00:19:49.962, Speaker A: And for stake based systems, we want to require this on the stake key, so we know that whoever signed the message actually has skin in the game and actually has funds at risk sort of used in the generation of this message. So the high level takeaway here, I guess, is that if you don't use this system, your protocol is vulnerable to bribery, period. No exceptions. So please don't DM me on Twitter and ask me, like, are we vulnerable to bribery and collusion? If you haven't sort of studied this kind of infrastructure and read this background material, because you 100% are, and if you're interested in learning more about the technical details or you want to sort of use this in your anti bribery systems, please feel free to reach out to me and I'm happy to chat more. It's a very complex sort of topic. I only had 20 minutes to describe it. I know I sort of flew through it, but hopefully you got some takeaways that we can sort of make sure users own their own data in these systems.
00:19:49.962 - 00:20:05.480, Speaker A: And that's very important to making sure that they're not being bribed. All right, if you'd like to contact me or learn anything further, here's my information, as well as funding and a big thanks to all our IC three partners and the ethereum Community for their support in this research. Thank you.

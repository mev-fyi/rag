00:00:00.650 - 00:00:26.150, Speaker A: Yes. Okay, so we are recording. Thanks everybody for coming. This is a call to talk about the gas API and how 1559 affects it. If we have time we can cover any other questions, concerns that folks here have. So Trent already shared the agenda in the, in the chat.
00:00:31.210 - 00:00:31.718, Speaker B: Or.
00:00:31.804 - 00:01:26.806, Speaker A: Yeah, the main topic of discussion today is what do we do to return the priority fee in the JSON RPC API? There was already some discussion about that on the issue. And before that though, I think Trent, you'd put in the agenda the presentation by gas API providers. So I don't know if there's folks here who've actually prototyped or looked at what a gas price oracle can look like post 1559, but if anybody wants to share that, it's usually pretty helpful to just start off with looking at something. Otherwise we can go right into the API. Yeah, I see there's some ether scan people here or if anybody else wants to just jump in, go ahead. Whoever was just speaking, feel free to just speak.
00:01:26.988 - 00:01:40.780, Speaker C: Yeah, hi, I'm from the guest team and well, I can talk about what we have as a guest price record. Now if someone's not familiar with that already or does already everyone know that.
00:01:41.630 - 00:01:57.380, Speaker A: I think it would be pretty valuable. It was at least valuable for me yesterday and the day before to understand it better. So yeah, I think walking through what you have now and how it's changing under 15ft. Divine. I know that you and Peter posted some comments as well, but yeah, just to make sure we're all on the same page.
00:01:57.750 - 00:02:47.314, Speaker C: Yeah. So, okay. I won't go into very fine details, but it's pretty simple actually. So what we had for a very long time for regular transactions was that basically we took the past, I don't know how many blocks. Well actually it depended on whether you were running a full node or a light node because if you were a full node, the guest price oracle took the last 20 blocks quite a lot. But if you were running a light client, maybe two and maybe now the letter will be better. And what it did is it took the few smallest gas priced transactions and basically found not the median but slightly below that.
00:02:47.314 - 00:04:07.962, Speaker C: So if we put them in descending order there may be I think, 60th percentile or something like that and just return that as a suggestion. We are currently planning at least the latest kind of team consensus is that we are going to keep this mechanism and use it for, I mean we feed the effective minor reverse into it. So that's what it will actually use. And this will be a suggestion for the tip, for the max priority fee. And for the fee cap, for the max fee per gas we suggest this tip plus twice the current base fee. And yeah, it's still a good question how many blocks we should take, and it might depend on certain situations. So I also had this proposal that I just posted like this morning that maybe we could just, so it might depend on whether there's a congestion right now or not.
00:04:07.962 - 00:04:52.700, Speaker C: So we could iterate through the recent blocks and offer different priority fees depending on how urgent it is for you. And maybe this could be also like a nice signal for the users to see if there's a congestion or not. I can dig up the link, but it's in the 1559 fee market dev channel. So this is what we want to do. We want to just use this, take the minimum or close to minimum tips of recent blocks and offer something below the median. So that's what we want.
00:05:01.360 - 00:05:41.080, Speaker A: Yeah, thanks for sharing again on the issue. I think the main concern about the current guest implementation is if there's a spike in usage, those will likely be short lived. And yeah, the 20 block is almost remembering too much like looking at too much history, whereas under 1559 things will probably happen much quicker. Like if there's a spike, it's likely that it's going to be something on the order of less than ten blocks. And if you're looking back at 20, you might have users over pace, likely.
00:05:42.140 - 00:06:09.996, Speaker C: Not so sure about that. Actually, if there's a spike, the spike is short lived. So if you take the recent block, so if you accommodate yourself to the spike, then you will pay a lot and get in earlier. And if you take longer, the longer history, then you will find a tip that has worked like in the past usually. And then what will happen is that you will wait out like the spike and get in somewhere at the descending.
00:06:10.108 - 00:06:11.440, Speaker D: Edge of the spike.
00:06:12.020 - 00:06:13.360, Speaker C: So I'm not sure.
00:06:13.430 - 00:06:15.888, Speaker A: Interesting. Yeah, that's right.
00:06:15.974 - 00:06:20.164, Speaker C: So it depends on what you want, how urgent you want to get in your transaction.
00:06:20.212 - 00:06:20.810, Speaker D: Yeah.
00:06:22.460 - 00:06:58.310, Speaker A: So basically, if I'm understanding correctly, the API would work kind of pretty well. Obviously if there's no spike at all, like if the blocks are pretty constant, it would also work pretty well if there has been a spike in the last 20 blocks, but it's kind of over and it would probably fail and there is a spike happening right now. And then that means you send your transaction and it just kind of has to wait until the spike is cleared to be included again. Is that roughly right?
00:06:59.560 - 00:07:19.690, Speaker C: Well, yeah, if we use like a constant setting, then I mean constant setting for how many blocks we look back then. Yes, that's right. And yeah, thanks for linking my proposal. So I think that kind of addresses this. But yeah, so this is just like putting up ideas right now, but. Okay, so that's what we have now.
00:07:20.060 - 00:07:23.210, Speaker A: Got it. Micah, your hand is up.
00:07:23.980 - 00:07:55.220, Speaker D: So I just want to reiterate my broken recordness. Most people here probably already know what I'm going to say, but I'm going to say it again for the new audience. I'm generally against any sort of priority fee estimation. That's not just what do we believe the miner's min value is. The reason for this is because it's kind of self reinforcing, getting people into these auction and bidding wars. And in most cases it's probably unnecessary. And in the cases that are remaining, it often can just hurt the user as much as it helps them.
00:07:55.220 - 00:08:43.990, Speaker D: And so I think it's much better that most of our oracles we're writing, unless we're writing oracles specifically for very advanced users like bot authors and stuff like that, which I don't think any of us are. I really think that for the premium we should just be saying, hey, we know that miners will accept a premium of one or two or three or whatever, and that's unlikely to be changing. And so this is what you need to set the premium to and that's it. I do not think we should be incentivizing, or incentivizing, encouraging and helping people get into these gas auctions because they're going to get themselves hurt. Things are going to go wrong for the end user. I don't think it really improves anything in a significant way. And it's a lot of work and a lot of complexity and then we have to expose this in uis and it's just a huge headache that I really don't think is going to help us down the road.
00:08:44.600 - 00:09:18.000, Speaker C: Yeah, I kind of agree. This is why I'm saying that sometimes it makes sense to look like more into the past. And okay, this is like the minimum that has ever worked and suggests that, but you are talking about using a constant basically, and enterprise is changing. So basically, I don't know, minor preferences, the technology, lot of things can change. So if these minor settings do change, how will users notice that if we don't look for the facts like the actually included transactions?
00:09:20.180 - 00:10:26.292, Speaker D: Yeah, so I think we do need to have it be dynamic, but that dynamicism should be over really long time scales. I want to be cautious here because it is possible that there is a little bit of incentive for miners to actually have dynamic premium or priority fee pricing based on current mev rewards. This is really complex, really hard to do, but it is possible and theoretically rational. So I want to be cautious with my words here, but at the same time, I also think that it's probably unlikely we're going to see miners do this anytime soon because it's a lot of work and the gains are pretty minor compared to the other engineering tasks they could be doing. And so I think that we can look kind of longitudinally and say the clients that are out there, like Geth, that miners we think miners are using, have just like a command line option for set your minimum priority fee. And we believe most miners are just setting a minimum to something. And we have seen over the last 10,000 blocks, 95% of the miners have been below two or have mined a block with a transaction below two.
00:10:26.292 - 00:10:46.460, Speaker D: So set your base or set your priority fee to two. And I want to be careful to not get into this, not trying to be too dynamic, not trying to adjust hyper fast to what we think miners might be changing, because most of the time when that changes, it's just due to a very short term congestion spike and it does not last. And so I do think it should be dynamic. We shouldn't just harp.
00:10:48.720 - 00:10:50.588, Speaker C: Yeah, I agree with that.
00:10:50.594 - 00:10:51.500, Speaker D: I'll be careful.
00:10:59.240 - 00:11:00.660, Speaker E: Can I go next?
00:11:00.730 - 00:11:02.308, Speaker A: Yes, go ahead.
00:11:02.474 - 00:11:02.948, Speaker F: Right.
00:11:03.034 - 00:12:03.880, Speaker E: So I do think also the value probably needs to be dynamic, but the issue with looking at, let's say, past records of what people have been bidding is that we might be too slow to actually catch that the spikes are happening, in which case, while the spike is happening, you're still recommending the minimum tip to users. And at the end, when the spike is over, your indicator will still be kind of trailing these high values. And it might not be that useful. But we do have an objective source that we get for free from 1559 itself. Like, we don't need to look at what users are doing, we can simply look at how full the blocks are, or maybe like the two or three recent blocks. And if we see that two or three blocks in sequence, or even the previous block was full, then we know that we are in one of these spike regimes. And we don't need to wait to see users increasing their tips because they might not do that.
00:12:03.880 - 00:12:38.880, Speaker E: First by themselves, they might rely on wallets, which would do that for them. And second, even if we wait for this, with the parameters that are set, looking back 20 blocks and looking at the percentile it's not clear that you would catch immediately that the spike is happening and you can really do get it quickly enough by looking at the gas usage in the block itself. So this is kind of what I was advocating for, and I understand that it might be very different from the current padding and then there's a bit more implementation complexity, but this is where I stand on the API.
00:12:41.800 - 00:12:49.290, Speaker C: Do you suggest that we should react quickly to the spikes with the recommendations in the end?
00:12:50.700 - 00:13:23.730, Speaker E: Well, I think if you're going to react at. So Mika recommends not reacting at all, and that's definitely a valuable position. But I do think that it might be valuable for users to have at least some kind of indication that something is going on. So if you do want this indication, I think relying on the gas used by the previous block or the previous two or three blocks would be more accurate than relying on more subjective price points, such as what the users are currently doing.
00:13:24.820 - 00:14:00.270, Speaker C: Well, yeah, so that is why I propose that we should return a series of suggestions depending on how urgent it is. And, yeah, so the users could decide whether they want to fight for priority or not. And yeah, it's also good to see whether there's actually something happening right now. But, yeah, always suggesting to jump on the spikes. I don't think that's a good idea. Offering it as an option. That might be good.
00:14:00.270 - 00:14:01.292, Speaker C: Right.
00:14:01.346 - 00:14:26.580, Speaker E: I think returning series of prices like options, it might be okay. But I would still use the gas used as a metric to check that something is happening rather than user prices because then you will have this kind of self reinforcing behavior that I think Micah is worried about. And so, Amica.
00:14:28.040 - 00:15:33.560, Speaker D: Yeah, so just to reinforce what Barnaby says, if we are going to do reactive gas pricing to congestion, we should definitely use the fullness of previous blocks to identify congestion. Similarly, when we're trying to determine what the 95th percentile minimum is, if we decide to go with that, we should use that same block fullness to filter out minimums. So, like, if we're trying to figure out, okay, what do we think 95% of miners have set their min to? We should first filter out any blocks that were full or, sorry, any blocks, yeah, so any blocks were full, filter those out and don't count them at all to get those numbers. So that way we are seeing just the minimums, we're not seeing the congestion times separately. The thing to keep in mind, I think, with this debate of should we be reactive or not, is that if everyone is reactive, it turns into a pathological scenario where kind of everyone ends up paying more. Like the reactiveness is useful as an advantage over competition. And so if you have one user competing against another user, the one that reacts wins.
00:15:33.560 - 00:16:34.124, Speaker D: If you are building an ecosystem, all your users presumably are approximately equal, like you want to serve them all. In which case, if you build in tooling for everybody competing using the same strategy, you just end up paying miners unnecessarily. And so if we do introduce these strategies kind of at a very core layer, like in geth, for example, we need to make sure that they're introduced in a way that most people don't use them. I know it sounds weird to introduce a feature that we don't want people to use, but if we introduce them in a way that everybody uses them, then they become not useful anymore. They no longer serve a purpose. We very much need to introduce this, and one way to achieve that is by having this concept of transaction priority, like kind of fast, medium slow, or whatever, where the fast is saying, yes, I want to be reactive and the slow is saying, no, I don't want to react. One caveat with that, though, is that I'm worried that compared to the base fee, if the base fee is 100 and the fast, medium slow is like one, two, and three, everybody will always choose fast.
00:16:34.124 - 00:16:56.180, Speaker D: And now we're back in that same situation where everybody is choosing fast, at which point it is no longer helping anybody, because everybody's following the same strategy. In order for this to work, we need people to be following different strategies. If everybody follows the same strategy, the strategy stops working. This is very common in game theory. And so just keep that in mind that we need ways to make sure people are not following the same strategy.
00:16:59.720 - 00:17:57.320, Speaker F: So one question I wanted to ask, a bit tangential to the discussion, is that we're kind of trying to solve the whole gas price suggestion problem before we actually see how the network behaves. And so my personal $0.02 would be that the current model that gets implemented is essentially just continuing the old algorithm. And I completely agree that this might be completely unsuitable for certain tasks or certain scenarios, but it kind of worked until now. So wouldn't it be kind of prudent to wait until mainnet actually forks over and see how the base fee fluctuates and how tips fluctuate before we try to solve this problem? The only thing I'm afraid of is that we're coming up with a solution to the wrong problem, because we don't know what the problem is until the fork.
00:17:59.660 - 00:18:13.550, Speaker C: Yeah, but the problem might depend on what we offer as a default option. I kind of agree with you, but, yeah, you should also keep in mind that what we will see in practice, that depends on what we offer as a default option now.
00:18:13.920 - 00:18:48.170, Speaker F: Yeah, of course. But essentially, if we continue our current algorithm, then at least we know how wrong it is. Whereas for example, Micah had a really nice example that if the base fee is 100 and the tips are one, two and three, then it doesn't really matter. And this is exactly the problem. We don't know how the tip will fluctuate in comparison with the base fee. So that's why I'm saying it's not super easy to solve the problem. At least for me, it's not super clear what the exact problem is or will be.
00:18:51.100 - 00:18:57.148, Speaker A: I thought, Greg, you had a comment, and I think you put your hand down.
00:18:57.234 - 00:18:59.196, Speaker C: Yeah, I mean, for me, it was.
00:18:59.218 - 00:19:21.590, Speaker A: Just kind of just coming back on Miko, but he kind of answered it. The big one for me is like, personally believe I would rather people pulling the nodes to figure out a gas price than a third party API. And in that case, we're always going to have to be competitive to some degree. So you kind of have to go back down to.
00:19:23.320 - 00:19:24.036, Speaker C: There has to be.
00:19:24.058 - 00:19:52.108, Speaker A: Some level of competitiveness there. Obviously, the issue being naturally, that we're going to run to the same problem we have now, where everybody's just competing for astronomically high prices is a problem. But in the case where we have products that we use, if we don't, we try using the node, and we actually had to switch off of geth and open Ethereum, just like we couldn't rely on the node for the gas price anymore, and now we're using a third party, which is not what I want to be.
00:19:52.274 - 00:19:52.700, Speaker D: Right.
00:19:52.770 - 00:20:07.350, Speaker A: So I think we have to do some sort of competitiveness. And like you said, you just have to be careful. But I kind of do agree with Peter in the sense that, is there something simplistic we can do and just see how it ends up playing out in the real world.
00:20:14.200 - 00:21:27.944, Speaker D: So I think there is a simple thing we can do that has a good chance of working for launch, and then we can reevaluate once we have more data. And that is to encourage the client devs to have a hard coded default for the min priority fee that miners use and a hard coded default for the priority fee that gets returned. If you ask for a gas price recommendation and make sure those two are the same thing, both of them can be overridden by command line parameters or whatever. But the idea here is that by default, if all the miners just run stock geth and all the users run stock geth, then everything will just work. Like the min priority fee that miners are accepting is exactly the same as the priority fee that users are using, and everything gets through, with an exception for drink congestion, at which point we get good data on how congestion happens and what goes on there. And then like a week or two later, we can start making alternative recommendations and then the next patch of guests can maybe include something more smart. But if we can get all the clients to kind of just agree that, hey, our miners will do this by default as the min, and our users will get this as the min, then I think we have something that can work out of the gate.
00:21:27.944 - 00:22:01.224, Speaker D: And my guess is that most miners are probably going to run stock Geth out of the gate and similarly watch and see before they crank up their numbers. So we can set that to one, we can set that to two, maybe set it to five. We believe that one or two is probably the right number. We set it to five just because around launch, that'll probably be inconsequential compared to the base fee anyways, and so people won't mind five. And it means that it's less likely that miners are going to manually adjust that. Again, that requires all the clients kind of agreeing. We're kind of agreeing, hey, this is our launch numbers, just to feel things out.
00:22:01.224 - 00:22:05.450, Speaker D: But I think it's really simple and it gets us to a point where you have more data.
00:22:06.620 - 00:22:28.800, Speaker F: So a counterargument to that would be that currently the gas prices fluctuate. I mean, I have no idea what it is currently. Last. A couple of days ago it was around 30, a week, before that it was around 100. So you have quite a large fluctuation, which means that the node has to fluctuate along with the gas price, otherwise the transaction you make will never get included.
00:22:30.740 - 00:22:39.380, Speaker D: I see, you're saying the issue here is specifically for the ETH underscore gas price needs to work for legacy transactions.
00:22:41.080 - 00:23:06.780, Speaker F: No, I talking about internal both. If you want to submit a transaction via get, then your assumption is that the transaction will go through reasonably fast. Now, if guest will always tell you that the tip is two gigaway and the base fee is whatever, then probably when others are paying 100 gigawa for the tip. Good luck with your two gigaway.
00:23:08.480 - 00:23:33.830, Speaker A: Yeah. The failure mode of basically hard coding the base fee works only when there's not a spike. Right. So the trade off you're saying there is, you're guaranteed to not overpay when there's not a spike. But if there is a spike, you'll be way underpriced, and then you need some other way to estimate what the right priority fee is.
00:23:35.000 - 00:23:55.548, Speaker D: Yeah, exactly. And the caveat there is that we expect spikes to be both rare and short lived. And so for users that are just using the default, they will probably still get through. As long as you're setting like base speed times two or whatever, it's common when people talk about you'll probably get through in almost all cases. It just might take you until at the end of the spike, and the spike is like seven blocks or whatever.
00:23:55.634 - 00:23:57.004, Speaker A: And not just the spike later.
00:23:57.042 - 00:23:57.950, Speaker D: You'll get in.
00:23:58.640 - 00:24:49.528, Speaker A: There's two cases where you won't get in. It's one if there's a spike, and two if there's a high value Mev transaction. And this is why setting a constant is a bit harder. Barnabay has made some graphs about this, but basically, if a block has a really high mev transaction, the opportunity cost of being uncooled is quite high. So it's kind of unlikely to include anything with this kind of hard coded tip. So I think when I last looked last week, if you hard code a tip of two, then I think it gets you something like 75% of the blocks. With MeV, it still makes sense to include those transactions, and the top 25% probably just won't include transactions with low tip.
00:24:49.528 - 00:25:40.670, Speaker A: So that's the other case where you're just kind of selling it out, I think. Right now, last time I checked, there's about 35 40% of blocks that have mev. So that means statistically, if you're really unlucky, you send your transaction, the block has a ton of mev in it, but then the block after probably doesn't have a ton, and you get into that block. But, yeah, it is a case where, and I don't think the current gas price oracle can really pick it up. It'll probably pick up what's the sort of longer and average? And looking at it right now, it would be like tugue would compensate for the uncle risk, accounting for something like the 75th percentile of mev. But you're not going to be included in those blocks where there's like a ten east front running opportunity.
00:25:43.120 - 00:25:54.210, Speaker D: Yeah. Again, my caveat here is that we should do this as a launch thing with plans to change it in the future. And the reason I think this is fine is because.
00:25:58.480 - 00:25:59.276, Speaker A: I think you just.
00:25:59.298 - 00:26:00.984, Speaker D: Broke are going to all of a sudden.
00:26:01.112 - 00:26:04.450, Speaker A: Have we missed the reason you think this is fine?
00:26:06.180 - 00:26:08.370, Speaker D: Can you hear me now or am I still bad?
00:26:08.900 - 00:26:09.890, Speaker A: You're good.
00:26:11.380 - 00:27:03.510, Speaker D: Okay, so the reason I think this is fine is because on launch day, I find it very unlikely that all the miners are going to all of a sudden have super advanced gas min pricing strategies already coded into a patch for GEF or whatever miner they're running, even without having any data on one five five. I just like us, remember, miners are going through this exact same process as we are where they have no data. They have no idea how things are going to work out in the wild. They don't have the geth code to work on yet, so they can't even start their patch until after we get our release candidates out. And so if we just plan on having this, this is our kind of launch thing to gain more data and in a couple of weeks we'll change it, or in a month we'll change it. I think that's safe. I don't think we have to worry too much about a large percentage of miners having hyper advanced gas pricing strategies on launch day.
00:27:06.920 - 00:28:03.530, Speaker G: So I wanted to bring up a point, which is like on launch day, on the day of the fork, most people, most clients who are sending transactions are probably going to continue sending legacy transactions until the market is stabilized or they'll gradually roll it out or something. And those folks are going to, many of them still rely on the ETH gas price API. And assuming that still exists and at least is backwards compatible and continues to return the same implementation for legacy transactions, that means that folks are essentially going to be like the majority of the market is going to be sending legacy transactions with max fees set to and max fee and max priority fees set to the same thing, which I believe means that the majority, unless we are committed to breaking ETH gas price and getting rid of that API altogether, we are de facto clients. Guess is going to be de facto making pricing recommendations anyways. Is that correct?
00:28:04.860 - 00:28:07.320, Speaker A: Yes, that's correct. Almost.
00:28:07.470 - 00:28:31.200, Speaker F: So it doesn't really matter what you have, ETH gas price or not gas price endpoint, because legacy transactions still only have one gas price field, which gets interpreted as both the tip and both fields. So as long as you're sending legacy transaction doesn't matter how you estimate the gas price, it's still going to burn, right?
00:28:31.270 - 00:28:59.140, Speaker D: I guess, yeah, I think I see the difference. So I think I see the difference here. I think Peter is talking about people who send their transactions unsigned to Geth and then Geth fills them in and signs them and submits them. I think Yuga and other people are talking about people who ask Geth for the gas price and then they fill out their own transaction in a script or an external service, sign it and then give that to guest to submit to the chain.
00:28:59.300 - 00:29:30.644, Speaker F: I was talking about that second thing. So if you just ask Geth to sign a transaction, we will never sign the legacy transaction. So get will always be pulled to 1559 transaction. I was referring to the e gas price when you sign it outside of get. So to say you just ask for the gas price and create a legacy transaction yourself. In that case, both the tip and the fee will be the same. I think that.
00:29:30.644 - 00:29:35.060, Speaker F: Wasn't that the initial problem that everybody will be using the old legacy transactions?
00:29:37.240 - 00:29:46.196, Speaker D: So maybe I don't understand. Will the return value of eth underscore gas price change with the fork?
00:29:46.388 - 00:29:48.250, Speaker F: It will be the same as before.
00:29:49.100 - 00:30:02.140, Speaker D: A single value, right? Like a single number. And that single number will be a combination of base fee times two or whatever, plus some priority fee recommendation.
00:30:05.280 - 00:30:07.870, Speaker F: It will be the priority fee plus one base.
00:30:09.920 - 00:30:12.000, Speaker D: Okay, so it'll be priority fee.
00:30:12.420 - 00:30:16.080, Speaker F: So essentially that would be retain the current behavior.
00:30:21.180 - 00:30:30.220, Speaker D: People who want to sign a non legacy transaction would probably want to use a new endpoint that gets base fee separately and priority fee separately.
00:30:31.040 - 00:31:04.340, Speaker F: Yes. For was, I think life science made the pr to the something spec, eit whatever about the new RPC endpoint. So gas did introduce that. So we do have the. I don't know what it's called. Whatever is in the ip, it's called that endpoint to actually return just the tip and then we have a separate endpoint. So if you want to submit 1559 transactions, we do have a separate endpoint to specifically give you a tip.
00:31:04.340 - 00:31:25.550, Speaker F: And we do not have an endpoint to give you a fee cap because if you don't specify it, it will just default to the tip plus two base fees. If you want more control, you can specify it's fairly reliable. So the hard thing to do is estimate the tip. So that's why we do support an API for that.
00:31:27.040 - 00:31:31.904, Speaker D: Okay, gotcha. That clears things up for me. Thank you, Yuga. I'm sorry for interrupting. I was.
00:31:32.102 - 00:32:05.550, Speaker G: No worries. At mean, I guess the only point I'm making is basically it's clear that ETH clients are going to make recommendations. There's no way around that, right? Because there are many, many people who rely on these APIs, on the ETH gas price API specifically. So the community is de facto making a recommendations about how to price 1559 transactions because legacy transactions can be interpreted as 1559 transactions. So that ship has essentially sailed, I think. So the only question is what is the type of recommendation we make?
00:32:09.040 - 00:33:20.488, Speaker F: Again, you made a nice point there that the problem here is that we don't just blindly switch over to 1559, rather we will have a mix and match. What's more, initially, most of the transactions will keep being legacy transactions. So people have an expectation of how legacy transactions work, how they are priced, how they compete with them. So I don't think we can really break that expectation. And then if you have a network with 90% legacy transactions, then you need to create your 1559 transactions in a way that they can actually compete with the legacy transactions. Because if the legacy transactions are paying ten x the tip, then it doesn't matter how nice algorithm you come up with for the 1559 transactions, they won't get included because they were just always under price compared the legacy transactions. So this was kind of where I was coming at is that I don't think it's advisable to break the current workflow for legacy transactions because we have projects, wallets and everything that kind of rely on it with all its quirks and uglinesses and some optimality.
00:33:20.488 - 00:33:37.700, Speaker F: So I don't think it's advisable to break that. And if we don't want to break that, then our hands are kind of limited into how we can implement estimations for 1559. But this is a problem. I don't have a solution.
00:33:47.930 - 00:34:58.320, Speaker A: So I guess one thing I'd be curious to hear kind of people's thoughts on is, Greg, you kind of mentioned earlier you see it as like a bad thing to query like a third party service to get more precise gas price estimates. At the same time, it kind of feels like a separation of concern issues where Geth's main functionality is not to be like a gas price oracle, right? It's to be a node and to submit some reasonable estimate for the gas price. And it does feel like 1559 has a much broader design space for gas price oracles. So I'm curious what people feel if Geth has this good enough kind of backwards compatible solution that's not optimal in all cases. Does it make sense to have folks like Eth, gas station, gas now and whatnot be the ones who kind of come up with fancier APIs that do look at the block history that do help with this use case, I guess more granular if you want use cases. I don't know if people have thoughts on that. Rick, I see your hand is.
00:34:58.320 - 00:35:32.694, Speaker A: Yeah, I mean, for me personally, I feel like Geth is the best place to put an oracle because everything already kind of needs it, and I mean itself needs it. But it's like a point I can kind of trust. If a person's trusting inferior, they're going to continue trusting inferior. It's weird that in order to do anything, I trust inferior. And now some like get gas price something something, especially when all the data is sitting in memory in Geth. It has to for other purposes anyways. And so that's kind of my hope is mean.
00:35:32.694 - 00:36:10.646, Speaker A: At some point I saw somebody else recommend it as well, even like a histogram or something of gas prices. But it seems like there should be some way to bubble up information in a call that can be used by a more clever oracle. Even if Geth doesn't want to be the final call, they can bubble up enough information that's sitting there literally in memory. It doesn't have to hit the disk or anything in my mind. So that's kind of my take on that. In ethers, when you connect to something, you connect to something. If you call get gas price, it's not going to start then trusting some other service for the gas price.
00:36:10.646 - 00:36:16.566, Speaker A: So that's my $0.02. Got it. San Diego, I see your hand is up as well.
00:36:16.668 - 00:36:44.990, Speaker C: Yeah, I agree with Rick in that it would be great if Geth could solve 95% of the cases. And we were mentioning that we still haven't figured out exactly how to solve the difficult cases like the bot writers or the traders or people who need to get in during a spike. I think that would be the place where we would rely on gas now on its gas station or more complex gas price oracles. But for the average user, I would love if gas can provide the whole solution.
00:36:49.970 - 00:36:52.320, Speaker A: Peter, I see your hand is up again.
00:36:53.430 - 00:37:43.554, Speaker F: Yeah. So an interesting question from gas perspective is essentially currently gas provides one API endpoint. Now, given that 1559 will arrive, let's say we will have two API endpoints, one for lexic transactions and one for 1559 transactions. Now, our assumption up until this point is that gap is kind of work operates in this headless mode where an external app just tells gas to submit its transaction and then gap needs to figure it out. Now, from this perspective, I don't think we can make it much smarter now. I think it was George's suggestion to maybe have an additional API endpoint. Maybe I'm adding the additional part that may be able to provide some more information.
00:37:43.554 - 00:38:32.530, Speaker F: But the problem is that yes, maybe we could be smarter and look at various metrics and try to give some options to the user. But for such an API, essentially you need something in front of guest that can actually show this to the user or make heads or tails of the recommendations or the variations and then the user or something gets to pick. But I still think that if you just have a dumb program like mining pool payout that just wants to pay irrelevant of how much it costs, then you still need a dumb API which kind of just works and doesn't give any choice. But I think an additional API endpoint that tries to be a bit smarter and tries to offer up some suggestions.
00:38:39.460 - 00:39:29.230, Speaker C: Yeah, the way I imagine my suggestion, yes. So this is why I think it's a good thing if the more flexible thing is like a generalization of the default thing and we should definitely leave the default API. And I also want it to work more or less the way it did work before because yeah, it's better to not break things that already exist. Sir, can we get a confirmation to what Bernabe asked on the chat on what exactly this gas price API would be returning? Is it going to be base fee plus the gas estimation of max priority fee?
00:39:36.930 - 00:40:12.090, Speaker F: Currently the gas price oracle within gas just looks at the past block and tried to see what was the minimum. Minimum. I think for each block, what was the minimum? Three tips actually paid to the miner. And then based on that it currently takes the 60th percentile. So it essentially tries to take not the smallest tips within the blocks, but something very close to the smallest tips.
00:40:12.430 - 00:40:22.800, Speaker C: Yeah, but I think Bernabet's question was that what will the old eight gas price API recommend? And I think what, sorry, sorry.
00:40:23.330 - 00:40:49.926, Speaker F: So essentially I was saying that internally get calculates a recommendation for that tip and then for the old ETH gas price we just add the current base fee to that tip. And essentially that way the base fee gets burned and the tip that the miner gets will be more or less what the miners were getting in the previous blocks. So the miners should be happy with that.
00:40:50.108 - 00:40:54.438, Speaker C: So basically the answer to Bernabet's question is yes, it's correct what he asked.
00:40:54.604 - 00:40:55.094, Speaker D: Thank you.
00:40:55.132 - 00:41:07.980, Speaker C: Can I ask a quick follow up on that? What is going to be get behavior? If it sees a transaction on the mempool with a base fee that's below the current block, is it going to keep it on the mempool or is it going to drop it?
00:41:09.090 - 00:41:18.640, Speaker F: Currently the implementation actually was implemented by Joan. Is that okay? You can talk about it.
00:41:19.250 - 00:42:17.746, Speaker C: Yeah, just real quickly, so I don't want to again go into details, but yes, we do keep transactions in the manpool that are currently not includable if they have a high fee cap, because then they will surely become includable really soon. So what we do is that for most of the pool, we recalculate the actual minor reward based on the current base fee, the latest base fee, and we prioritize transactions based on that. But there's like a little space reserved for those transactions that would fare very badly in this comparison, but still have a high fee cap or max fee, and therefore they are worth keeping because they will be includable in the next, I don't know, five blocks probably.
00:42:17.848 - 00:42:20.082, Speaker D: So, yeah, perfect.
00:42:20.136 - 00:42:20.610, Speaker A: Thank you.
00:42:20.680 - 00:42:57.550, Speaker F: Essentially, about previously. So currently gap transaction pool maintains 4000 transactions, and with this updated 1559 we added another 1000 transactions whose purpose is to be those transactions which cannot currently be executed because the base fee overflows or underflows or whatever, but otherwise they kind of look good. But as a disclaimer, it is a new mechanism, so we're hopeful it doesn't blow up enough pages.
00:43:01.430 - 00:44:18.380, Speaker E: The reason I was asking is because there is the intuition that legacy users who are sending the old format transaction will always be grossly overpaying because they have their max fee equal to the max priority, et cetera. But actually, if your API returns the base fee plus an estimation of the max priority fee, and if the max priority fee of this legacy user is really large over time, base fee should kind of try and compensate for that. And base fee will sort of match the price levels that these legacy users are sending initially, which means that once that happens, the actual priority fee that these legacy users are sending should be pretty small and should be once again close to the minimum that miners would accept. And so legacy users are actually a bit hampered by this because they are recommended prices which are close to base fee, which means that any small fluctuation upwards of the base fee means they are priced out. It's not like the current mechanism where, okay, there's room they can still go in. Like the base fee is really binding. So I don't think we need to be too worried about these legacy users, and I don't think we need to have necessarily this image that they will be really overpaying all the time.
00:44:21.390 - 00:44:47.090, Speaker A: I'd like to ask a follow up question to Peter's comment about mempool structure there. Currently, the mempool is divided into two parts of the queued and the pending did I understand correctly that there is now going to be a new component to the mempool that contains these high max fee, but the base fee is insufficient for the current block?
00:44:47.510 - 00:45:18.514, Speaker C: Yeah. So this is a different division. So queued and pending, that's like per account thing. And it's about the ordering of sequential transactions. There's like a big heap for all the. Or we had one big heap for all the remote transactions. That priority heap was for eviction of underpriced, very low priced transactions.
00:45:18.514 - 00:45:40.050, Speaker C: And this is what has changed. And this is now that works? That, yes, if it falls out from one queue that is based on current minor reward, then it still has a chance to stay in the second queue that is just based on fee cap, on max fee.
00:45:43.450 - 00:45:56.854, Speaker A: And is this additional queue, this new queue, does that consume additional queue? I'm sorry, sort of slots like we have 4000 now for the regular pending.
00:45:56.902 - 00:46:22.402, Speaker C: So we did not want to break the existing situation so we raised the mempool size slightly. So now we have 4000 sorted by current minor reward and an extra 1000 sorted by fee cap, which is I think affordable. And it's also guaranteed that it will not work any worse than before, at least if the code is not broken or something.
00:46:22.456 - 00:46:25.410, Speaker A: Yeah, great. Thank you for the clarification.
00:46:26.070 - 00:47:30.946, Speaker F: So one slight clarification that I wanted to make or precision, is that currently this queue split isn't really a split, isn't really introducing any new queues. Rather what it does is it just changes the eviction algorithm. So previously when the queue was full, I mean depending you had 4000 transactions queued up resolution and another one arrived, then that one actually needed to push something out. And then if there was something cheaper then it pushed that something cheaper out. And with the new algorithm we have a combination that if, let's say I have 5000 transactions because that's the new limit, then if the new transaction pushes something out tick wise from the 4000, then it gets included. And if it cannot push something out tick wise then it can try to push something out from the worst 1000 maximum cap wise. So it's just playing around with the eviction rules, but otherwise structurally the transaction pool remains.
00:47:30.946 - 00:47:31.560, Speaker F: Exactly.
00:47:44.350 - 00:47:54.750, Speaker A: Any more questions on the gas price article? There was one other thing on the agenda, so I just want to make. We have ten minutes. It feels like a natural transition.
00:47:56.450 - 00:47:57.978, Speaker D: I do have one other comment.
00:47:58.074 - 00:47:58.494, Speaker A: Go ahead.
00:47:58.532 - 00:48:38.086, Speaker D: Yeah, I've seen a lot of people comment that they want to avoid centralized oracles, which I am 100% on board with. I think the thing to keep in mind is that we need to drop our understanding of the old system and think about the new one in the old system. In order to build an oracle, you needed to basically monitor the pending pool, have access to large amounts of data and the flow of transactions. It was really complicated. These new oracles should be mostly implementable as just a JavaScript library. It'll be like three functions long, and you can just copy and paste it into any piece of code. We can have gists that have them, there'll be githubs that have them, et cetera.
00:48:38.086 - 00:49:21.222, Speaker D: You don't need this high frequency data access. The one exception of that is you do need to know what the base fee is, and so I do think the clients should return the base fee for the next block, and you do need to know what that minor estimate is. That one is like a data problem. And so I do think there's value in the clients returning data. About that. Once we return those two pieces of data, though, everything else should be calculatable with a small Javascript library, like you don't need more data than that like you used to. And so I don't think we need to worry about centralization of oracles like we see with gas now and infuro or whatever, because the oracle is simplified so much that it fits in a library as long as we have the data we need from the clients.
00:49:21.222 - 00:49:54.150, Speaker D: And so I would much rather see these endpoints and the clients return that data that we need. And this is what Rick Moo was talking about, where there is some data we do need from the clients and we need endpoints to get that, like a histogram for example, of minor priority fees. But once we have that data, we can have every wallet can use their own library, they can have their own little oracle, they can tweak it and tune it. We can have standard ones that we share and whatnot, and there won't be centralization. We don't need to worry about centralization as long as the data is available, even if geth doesn't provide any gas price estimator.
00:49:56.090 - 00:50:33.966, Speaker F: Yeah, I kind of agree that that is a nice approach, just expose the data. One thing I wanted to still highlight is that the base is exposed already because it's part of the block headers, so you can always retrieve the base of the current block. If you just retrieve the header you would have the base fee and you can see whether the block is full or not. So if you must calculate the base fee for the next block, you could, but I don't think anyone wants to estimate that close to the limit, I think some will.
00:50:34.068 - 00:50:52.822, Speaker D: It'd be nice if we could have just an endpoint because in order to calculate the base fee for the next block, it is kind of complicated and you do need the full transaction list, or you at least need the gas used for the block. If you have the gas used for the block, then end the base fee from the previous block. It's already there, but had it already.
00:50:52.876 - 00:50:54.200, Speaker F: Contained the gas used.
00:50:55.130 - 00:51:03.194, Speaker D: Okay, that can also be lived in the library. So yeah, all you need is the last block then, and the histogram of historic stuff, I think.
00:51:03.312 - 00:51:58.698, Speaker A: Yeah, I tend to agree that over time, I think because the estimation was so complicated and now it becomes simpler over time, it probably makes sense. Wallets can probably write some of it themselves. But I guess I do appreciate that this is like a transition and you want things to kind of be smooth. So yeah, I feel like that's probably something we'll kind of gradually see happen. And maybe one thing I can follow up on is how do we actually provide this kind of just base implementation in JavaScript that helps you do a good estimation and shows people that, yeah, it's not rocket science and we can do it quite easily just because we only have five minutes left though. And this is kind of related to the same topic. A few folks asked about having JSON RPC endpoint for the next blocks base feed.
00:51:58.698 - 00:52:33.590, Speaker A: I just wanted to check, I guess both from the people here and the get team how valuable and easy that is because it is easy to calculate in a way, but it's also like you do need to actually look at the spec from 1559, so it feels like it's maybe something that the client could do pretty easily and that third party libraries will have to fiddle a lot to get working. Yeah. So I'm curious, what are people's thoughts about kind of like ETH base fee for the next block?
00:52:34.270 - 00:52:36.330, Speaker F: Just retrieve the pending block.
00:52:39.870 - 00:52:46.410, Speaker A: Already and it'll basically just look at the gas use and calculate the base for the next block.
00:52:48.110 - 00:52:53.162, Speaker F: In order for us to construct a pending block, we need the base for the pending block.
00:52:53.306 - 00:52:54.878, Speaker A: Oh yeah, you can just retrieve the.
00:52:54.884 - 00:52:56.800, Speaker F: Pending block and boom, you have the base.
00:52:57.890 - 00:53:14.110, Speaker A: Okay. Does that work for people here? So you get the block with the pending tag and get the base fee per gas from there. That's the answer. Okay.
00:53:14.180 - 00:53:26.240, Speaker F: Yeah. So that would already expose it. I mean, if that's not enough we can consider exposing it another API, but kind of, I don't know, isn't that enough?
00:53:29.110 - 00:53:49.510, Speaker D: I would be happy to work with Rick Moo to just make sure that ethers JS has a calculate base fee from the pending block. The latest blocks base fee. I think it's simple enough that once Javascript has it, you can just copy that into whatever your language choice is. It shouldn't be too hard. It already exists in python.
00:53:49.930 - 00:54:18.080, Speaker A: Yeah, I mean, currently what I've been doing in my current implementation of EIP 1559 is I actually just grab I get block negative one and take the base fee of that. My one concern with is this get pending block, is that new or is that something that exactly like 1559? Because part of ethers is right now detecting whether or not the network supports EIP 1559 by checking the previous block if there is a base fee on it.
00:54:18.930 - 00:54:30.178, Speaker D: So pending has been around for a while. Caveat there. Not all clients return the same thing for pending. So for ethers, I recommend being careful of using that endpoint just because it's not consistent across clients.
00:54:30.354 - 00:54:32.680, Speaker A: I mean, I can't even imagine what the other fields would be.
00:54:33.050 - 00:54:37.766, Speaker D: So anyways, yes, neither could the clients. They all imagine something different.
00:54:37.868 - 00:54:39.320, Speaker A: Right, that's fair.
00:54:40.650 - 00:54:48.170, Speaker F: So pending block has been part of Ethereum since forever. So actually since forever.
00:54:48.910 - 00:54:55.806, Speaker A: But get blocked by hash or get blocked by block tag pending, you are.
00:54:55.828 - 00:54:57.600, Speaker F: Retrieving block minus one.
00:54:58.930 - 00:55:06.560, Speaker A: That's an ethers thing. If you pass in a negative number to ethers, it uses the most recent block number, subtracts it for you.
00:55:07.250 - 00:55:20.290, Speaker F: Yeah. So if you get at least in get minus two, that's the pending block. But I don't know if you can actually pass it. Okay, let me just check which endpoint.
00:55:21.270 - 00:55:27.240, Speaker D: Eth get block block by number pass pending the string pending as the one parameter and you'll get it.
00:55:27.610 - 00:55:28.230, Speaker F: Thank you.
00:55:28.300 - 00:55:29.446, Speaker A: I'll try that out.
00:55:29.628 - 00:55:41.290, Speaker D: It's the same thing as if you would pass the word latest in for that, just in the same spot. I think you might need a boolean as well for whether you want the receipts or the transactions.
00:55:48.060 - 00:56:01.950, Speaker A: So the only downside I see to getting the next base fee using the pending block is that you get a lot of unnecessary data. But it works from our use case, so I'm okay with that.
00:56:02.800 - 00:56:38.730, Speaker F: Well, define lots of unnecessary data. I mean, sure, the base is probably five bytes and header is 500. So yeah, from that perspective, yes, we do waste a lot of data. Question, is that too much or isn't it? It's a valid question. So I'm not saying we should not add gas based fee, I'm just saying that we can do it currently too, so might be worthwhile to see how people use it and then add the endpoint that's actually needed.
00:56:44.990 - 00:56:53.580, Speaker A: Cool. We have two minutes left. Any other quick concern that people had they wanted to bring up?
00:56:56.770 - 00:57:59.940, Speaker B: I just had a quick comment. I'm not sure what the plan is after this, but I was struggling to follow along in some parts and so if someone could give me a summary of it sounded like there are going to be certain phases. There is still a little bit of debate of exactly what the guest client will be providing. And it sounds like also that the gas station APIs will also be providing some fancy, extra fancy features, potentially or not, as a wallet. We would still rather prefer to be able to get information easily and digestively with rich content from an API, if that's possible from Geth, but without we don't want to have to constantly be polling on each of our clients for the last x number of blocks. So it'd be great if both were provided from an API standpoint as well as from the clients directly. But yeah, if you could summarize what the different phases are for rolling out, that would be great.
00:58:03.540 - 00:58:05.410, Speaker A: Sure. So right now.
00:58:07.300 - 00:58:14.550, Speaker B: It doesn't have to be right now it can be like in a summary after the meeting, just to make sure that we kind of understand what's happening.
00:58:15.000 - 00:58:22.420, Speaker A: Yeah, and I think it's still kind of in flux, but I'll try to get that and I'll share it on the discord.
00:58:25.560 - 00:59:36.680, Speaker F: So one thing that before we close, speaking of, I think Micah mentioned that it would be beneficial for gas or ethereum clients in general to expose certain past historical, I don't know, histograms of who's been paying how much for which minor, I think providing a guess oracle that works on these is kind of hard, I mean, for guests, because it's an API that we cannot just change afterwards because if somebody relies on it, we're shooting them in the group. However, if it's an API that just provides data that others can build upon, that can remain stable. So if we just provide an API that returns a histogram of priority fees paid, at worst nobody's going to use it. But we don't need to change the API. It cannot be wrong. So I think that might be actually a really good idea to expose information. Then anyone can build a gas oracle on top if they want something custom, and if something turns out to be nice and something turns out to be stable, then we can also ship that within gap.
00:59:36.680 - 01:00:15.530, Speaker F: And the reason I'm saying is that if we can figure out a reasonable data retrieval to expose from gap, then I think it would be nice to add it. But that one kind of needs an idea spectro, because ideally you want to have the same data from all. So, Micah, if you have a suggestion on what data you would like to see, I think George also has some Instagram idea approach maybe you can marry.
01:00:17.150 - 01:00:55.738, Speaker D: Yeah. This just to keep it quick and tie things up. My recommendation is that, like I said, get returns. Just some data that data would be, and some of this is already returned. So I'm just going to try to be all inclusive here. The base fee of the latest block, the base fee of the pending block, the fullness of the latest block, the fullness, the fullness of the latest block, base fee of the latest block, base fee of the pending block, and then a histogram of the lowest gas price accepted over the last n blocks. With full blocks filtered out.
01:00:55.738 - 01:01:14.154, Speaker D: I think that full blocks filtered out, I think is critical for getting the most useful data here. And I think with that anyone can build a oracle. Like, with that data, you should be able to build most of the types of oracles I've seen people propose with just like a handful of lines of code in any language.
01:01:14.282 - 01:01:25.460, Speaker A: A quick idea along with the histogram of gas prices, maybe also histogram of full blocks, if that even makes sense. So there's some way to know how blocks are.
01:01:26.230 - 01:01:46.090, Speaker D: I think that's definitely useful and interesting data. And I can imagine someone wanting to write an oracle that takes that into consideration. Like, oh, we've noticed that there's a lot of volatility in blockfulness lately, and so we're going to change our strategy and so, yeah, so let's add in a stretch goal would be a histogram of blockfulness over n blocks.
01:01:47.230 - 01:01:51.660, Speaker A: And histogram may be the wrong word. I don't know, better word to use for that purpose right now.
01:01:52.190 - 01:01:56.030, Speaker F: Yeah, but we get the idea for the concept.
01:01:57.330 - 01:01:57.694, Speaker A: Yeah.
01:01:57.732 - 01:02:20.550, Speaker F: So I think it would be super nice if we could just write up a small brain dump of what we would like to see and then we can see how we could expose the whole thing. Because I guess gathering all that data and exposing it is not particularly complicated. So it's just more like figuring out what the actual data we want to expose is and in what format.
01:02:22.170 - 01:02:27.160, Speaker D: Tim, if you give me a place to put stuff, I can start it off and then let people modify from there.
01:02:28.010 - 01:02:46.990, Speaker A: Yeah, okay. Sure. I'll do that. I'll send you something. I'll post it in the 1559 p market channel in discord if folks want to comment there. Yeah, that would be really valuable. I'll put together like a hack MD or something that anyone can edit.
01:02:46.990 - 01:03:20.306, Speaker A: Great. Yeah, this was pretty helpful. And I suspect we'll probably have another one of these calls in a few weeks. And once we actually have 1559 on a testnet, it might also make things a bit more concrete. In the meantime, if you do want to just play in a very experimental way with 1559, we do have a Devnet called calaveras that's up. So that's running. There's a spec for it in the GitHub specs repo.
01:03:20.306 - 01:03:38.590, Speaker A: Let me just link it here in the chat if anybody wants to check it out. There's very basic RPC support and whatnot, but it allows you to send the transactions and if you have your own tooling to kind of play with them. Yeah, that can be useful.
01:03:40.450 - 01:03:55.460, Speaker F: To mention it. If you download gap master build, it also has the flag for joining this calibrate tester. So with an unstable build of gap, you can join it and you can play with.
01:03:57.590 - 01:04:12.598, Speaker A: I actually had a quick question about that as well. Is there like Bycall had somebody else running an RPC node we could just connect to and also an explorer, will that be added to the new card calaveras, the Explorer is there already. I don't know about the RPC node.
01:04:12.774 - 01:04:13.546, Speaker D: Okay.
01:04:13.728 - 01:04:30.020, Speaker A: Yeah, the Explorer is linked in the spec and there's an eat stats in a faucet as well. Okay, last quick question. What's the parameter to sync get with? Oh perfect.
01:04:34.470 - 01:04:35.730, Speaker F: With the camera.
01:04:36.150 - 01:04:52.854, Speaker A: Yeah. And they answered in the chat. Yeah. Cool. Okay, well, yeah, thanks everybody and talk to you all or at least part of you in the coming weeks. Bye. Thank everybody for joining.
01:04:52.854 - 01:05:05.450, Speaker A: We'll send out an email with the link to the recording and notes if there are or a summary document. All right, bye. Thank you.
01:05:05.600 - 01:05:06.806, Speaker F: Thank you, bye.

00:00:06.510 - 00:00:55.102, Speaker A: You. Hello everyone. Welcome to the next day of the sharding status. Whatever this workshop is called, hope it will be. You'll find it as happy as the previous days. So I guess, first of all, I guess, first of all, are there many people here who were not here the previous two days, just to make sure? Okay, so about mean. Yeah, so I guess, sorry about the oppressing the minorities a bit, but I will kind of assume somewhat that people some knowledge of how the Casper and shorting design works.
00:00:55.102 - 00:02:46.370, Speaker A: But maybe since today is kind of the development day, we'll focus a bit more on details from an implementation point of view. So basically, if you're someone looking to develop a casper and sharding client, then from that standpoint, what will developing the protocol be like? What sort of demands will it end up putting on you? So I guess we'll start off with just kind of repeating a simple description of the beacon chain. First of all, there's the existing proof of work chain that we know and love. And throughout basically all but the last phase of the sharding roadmap, the existing proof of work chain is going to continue to exist, and it'll continue to be a chain as long as the cryptokitties and the gambling icos stay online. It'll continue having an uncle rate of about 20% to 25%, unless elixir's optimization work pays off really well. But at the same time, there is going to be this kind of new beacon chain that starts up right. So first of all, in the current setup, there is still going to be a smart contract that lives on the main chain, and on the main chain, basically as part of the main chain state, there will be this contract, and into this contract, users will be able to send, will be able to send deposit transactions.
00:02:46.370 - 00:03:37.800, Speaker A: Did that come out well? 32 E. Okay. Yeah. So basically, you'll be able to send your 32 Eth into the deposit contract along with two other parameters, right? So the function is going to have three parameters. First of all, any transaction that's depositing will have to actually contain 32 Eth. It will also have to specify a pub key, and it will have to specify another thing. Realistically, it will have to specify a withdrawal address as well, though.
00:03:37.800 - 00:04:51.690, Speaker A: The original spec, right, basically had this idea of validation code where you can basically specify some arbitrary program as your pub key, and you can specify some arbitrary address for the withdrawal. But especially because we want to do implement webassembly and all of this, it's probably not a good idea to bake that in, right? From the start because the vm details might change. So realistically, there's a large chance the withdrawal address is itself going to be another pub key. Right? So this pub key is the pub key that you use for staking, and then you have another pub key that you use for withdrawing. And you might have a shard id in here as well, might not be specified, but this is kind of roughly what it'll look like, right? So you specify some data and at the very least you have two pub keys. And when you deposit the transaction, the transaction, if everything is correct, will end up creating a receipt. And this receipt is.
00:04:51.690 - 00:06:16.326, Speaker A: So first of all, any client of the proof of stake beacon chain needs to have at least enough access to the proof of work chain in order to be able to, first of all, know what the block hashes are, but second, know what the deposit receipts have been between any two checkpoints. So for a proof of stake client, being a proof of work light client is actually totally sufficient. So the beacon chain is going to also exist in parallel to all of this. Because of the attest of the attestation mechanism, it'll probably have an onco rate much lower than 25%. This is still kind of in progress, but generally at least some proof of stake blocks will have these pointers that basically go back into the main point to the main chain, and later blocks in the beacon chain will points to later blocks in the proof of work chain. And the idea basically is that if you're processing this block and you see that, first of all, there's a hard consensus rule that says that the main chain reference of a child has to be either the same or a descendant of the main chain reference of an ancestor. But then when you process this block, it'll be part of the consensus rules that you also have to execute this, this and this.
00:06:16.326 - 00:07:06.642, Speaker A: So you also have to execute these three and then into this. Basically, whoever deposited here would end up adding themselves into the pending validator set that's stored over here. So inside of the beacon chain state you have some validator sets. So in the current spec you have an active validator set, a pending validator set and an exited validator set. And obviously if you deposit, then you'll basically join into the pending validator set over here. Right? As a client developer of the proof of stake chain, basically you need to have at least a light client of the proof of work chain. You need to be able to process receipts and get a complete listing of receipts.
00:07:06.642 - 00:07:27.700, Speaker A: And you would need to be able to actually process these beacon chain blocks. Right. So this is kind of fairly abstract structure. This so far doesn't really depend that much on the kind of inner details of the beacon chain. So I guess, first of all, any questions at this point?
00:07:31.290 - 00:07:59.600, Speaker B: Okay, so if we take this as you just described, could we implement it as the first stage and say that it will never change again? Not again. So what I was trying to understand is, is there any minimal set of functionality that could be useful for a main chain and be implemented within, let's say like three months or something like that? Is this the base piece or something even smaller can be done?
00:08:00.930 - 00:08:05.834, Speaker A: Okay, maybe you answer first, Chris.
00:08:05.962 - 00:08:26.680, Speaker C: I mean, one good piece I think would be the networking layer. So each shard as well as the beacon chain will have separate gossip channels and agreeing on what networking stack we'll use and have all the implementations collaborate on. That would be great.
00:08:27.690 - 00:08:32.982, Speaker B: Well, that doesn't satisfy usefulness criteria, right?
00:08:33.036 - 00:09:24.940, Speaker A: So if you want something to be useful, then I think a proof of stake chain that hooks onto the minimal and the proof of work chain basically is a minimal component. Because first of all, I do think that the sharding is somewhat more up in the air than the proof of stake side. But the proof of stake side, even without sharding, will serve the useful purpose of providing a kind of linked finality gadget, right? So the idea basically is that if, let's say inside of here, and at some point this block ends up being of the beacon chain ends up getting finalized, then because this contains this, then according to a consensus rule that is aware of the beacon chain, this being finalized is also going to end up finalizing this. Right? So that's probably the smallest components that I would say is useful. But the proof of stake chain is a significant component by itself, right?
00:09:26.430 - 00:09:28.246, Speaker D: Have no way of accessing the randomness.
00:09:28.278 - 00:10:18.266, Speaker A: From the beacon chain, right? You can't go in that direction. This depends to what extent it's actually possible to write a verifier for the beacon chain inside of the proof of work chain, especially if in the earlier versions of the spec we're using cryptography that's more kind of like RSA or up to curve based than snark than stark based, then it could be designed to be implementable with the pre compiles. Although if we go with BLS twelve 381, then no, because the main chain doesn't support BLS twelve 381, or at least definitely not efficiently. Unless you do some ugly hack where you use Bn 256 to make us narc over the BLS twelve 381. But that's like horribly ugly. If it is possible, that's a good example of usefulness, I think. Right.
00:10:18.448 - 00:10:19.180, Speaker C: Okay.
00:10:21.390 - 00:10:23.866, Speaker B: Will shards have a similar setup to.
00:10:23.888 - 00:10:26.250, Speaker D: This for like, withdrawals and composites?
00:10:26.670 - 00:10:57.160, Speaker A: Yes. So shards definitely will have a similar dependency relationship as the beacon chain to the main chain. Though, as we discussed yesterday, we are considering this plan where a shard chain is basically only dependent on the last finalized block of the beacon chain. And the purpose of that is that basically increases the stability of the mechanism, because basically there's no chance of the beacon chain reorg leading to a short chain reorg. And that also means there's a bunch of code you don't have to write.
00:11:01.280 - 00:11:25.590, Speaker B: So if you say that the group safety is the minimal usable thing we can do, the next question is maybe not to direct, but to our maybe. How close is that to what have been implemented in the Casper FG work? Could we reuse some of that work? How different is it?
00:11:29.500 - 00:11:33.080, Speaker A: Maybe. Let Danny answer somewhat.
00:11:34.540 - 00:11:36.250, Speaker B: I think bread is different.
00:11:37.980 - 00:11:39.610, Speaker E: It's entirely different.
00:11:43.360 - 00:11:47.710, Speaker B: Can you explain a bit more why is it very different? Just so people understand.
00:11:49.520 - 00:12:10.064, Speaker E: The core of Casper, what's happening inside of an EVM contract. This is moving the core of Casper to a side chain or another chain. So there's reasonable concepts in terms of validators and voting on things and finalizing things.
00:12:10.262 - 00:12:11.444, Speaker B: The way that it can be used.
00:12:11.482 - 00:12:39.470, Speaker E: To finalize the existing main chain is similar to how the contract is going to be used to finalize main chain. But other than that, in terms of the actual development, architecture and components, we all have some more knowledge and industry knowledge and things and intuitions around some of these concepts. But other than that, it's fresh. For better, of course, I think for better.
00:12:41.520 - 00:12:43.228, Speaker C: I was just going to say that.
00:12:43.394 - 00:13:06.500, Speaker E: At least from the kind of research concept perspective, it's like the same finality gadget in some ways, but exactly as you said, the contract doesn't have to be rewritten or refactored, but I think the function should be very similar. There is no Casper contract anymore. The only contract exists is that like one way burn contract.
00:13:08.920 - 00:13:09.744, Speaker C: By contract.
00:13:09.792 - 00:13:13.560, Speaker A: I just meant code, Joseph.
00:13:17.740 - 00:13:39.180, Speaker B: So in practical terms, the actors that run this system previously, they would have to trust code that is on the chain, on the main chain. And nowadays, they'll have to trust the software of every client implementation of this and choose an implementation to run auditors and blah, blah, blah.
00:13:43.760 - 00:14:13.930, Speaker E: So in that respect, one of the benefits we kind of saw about the Casper contract sign was that you have all of this heavy lifting consensus code that would only have to be written once. So you do now have all of that consensus code. It has to be replicated in each client. So we're going to have to focus more on having unified testing across clients, kind of like how we have for this new.
00:14:19.910 - 00:14:35.080, Speaker B: So if the conceptually things are very similar, but the implementation is different, can we just take that specification and just change it a little bit and issue another specification, which will be for the first thing, for the first minimal thing.
00:14:37.130 - 00:14:50.758, Speaker C: One of the depends is going to be the heartbeat and the random number generator. And this is finalized right now. So one of the things you could do, I guess, is like black boxes.
00:14:50.774 - 00:14:54.154, Speaker A: In abstract away and just use block hashes.
00:14:54.282 - 00:14:56.480, Speaker C: Block hashes or something else.
00:14:57.810 - 00:15:02.270, Speaker B: I think that might be quite useful because it kind of brings us.
00:15:02.420 - 00:15:48.314, Speaker A: Yeah, I think actually not like using block hashes as randomness for the test sets is totally fine, because realistically, if it's a test set, we don't really have to worry much about attackers. And actually, if someone does do randomness manipulation on the block hash, that would be great because we could see what the effects are. The other parts of the structure, right. The parts that have to do with maintaining the beacon chain state and producing blocks and so forth, I think are definitely implementable and useful. One other thing, the black box, by the way, is the hash function. Like use Blake for now, but it's something that might end up getting swapped.
00:15:48.442 - 00:15:59.434, Speaker B: And another crazy idea to what Danny just said. Instead of implementing those in every client, we could implement an e button or. Welcome.
00:15:59.572 - 00:16:00.900, Speaker E: I was going to say that.
00:16:03.750 - 00:16:04.740, Speaker C: But that.
00:16:07.910 - 00:16:11.842, Speaker B: Even if you do just implement a lot of them, that's one implementation.
00:16:11.906 - 00:16:32.440, Speaker E: Doesn'T really stop anyone else from implementing. We all decide, let's just have one DP chain implementation, but it's still like an open protocol anybody can implement anywhere. Whereas when it was an implementation of the EVM, it was like we just say that contract is.
00:16:35.750 - 00:17:37.042, Speaker A: I will mention that at least I personally super continue to be kind of like pro multiple implementations in the sense of multiple actual implementations of code. And I think the reason being that, first of all, we've seen other blockchains that have one implementation, and even with EOS, right, they have one implementation. There was a bug a week after and the entire thing just shut down until they had a totally decentralized phone call and got it back together again, basically. I don't think that, especially not in the short term, we're not kind of slow moving enough to be able to take the bitcoin core approach, which is basically in practice, changing very little and moving slowly. So if we want to preserve a very high degree of network up and stability, which especially as we've seen from the DOS attacks, I do think it has served us well.
00:17:37.176 - 00:18:25.700, Speaker B: I was going to say, yes, I agree with all you've both done in, but what I was going to suggest is that in order to bootstrap the process of transitioning into the new system, rather than requiring all those clients implementing this consensus logic, you can actually have data, short term solutions implemented in VASM. And we know from yesterday that kind of most of the clients will very soon have VASM engines, and so you can actually get it running very quickly, and then you just let other clients implement it the way they want in the time they want. So that means that we don't actually have dependency on everybody at the same time, so people can just do whatever they're doing now.
00:18:28.010 - 00:18:46.954, Speaker E: So that might actually be a solid solution to get existing clients ready, if existing clients want to use some sort of complementation, but there are a number of maybe more agile sharding first clients that I think are going to work on that. But I agree.
00:18:47.072 - 00:19:09.086, Speaker B: Let's pump out a lot of implementation. That's absolutely fine if other clients want to use their own implementation, but that would at least be an option for any client to not do that work. Now, if they want to do something else at the moment and rely on the one that wasn't, another thing that's.
00:19:09.118 - 00:19:48.830, Speaker A: Worth pointing out is that you can also get a lot of the benefits of this by doing basically separating the two parts of it out. So basically you have established that the proof of stake clients should basically only talk to the proof of work chain through clients, through RPC, and then theoretically they can share a lot of libraries. But the goal would be that if you want to use the python sharding clients together with a guest node or the other way around, then you should be able to, and then if one implementation comes out far ahead of the others, then they can just use that one implementation, plus using whatever other node that they use before from the main chain.
00:19:58.250 - 00:20:05.370, Speaker D: So Lexi mentioned the idea of black boxing component. So black box, the beacon chain.
00:20:07.550 - 00:20:07.914, Speaker B: Black.
00:20:07.952 - 00:20:15.050, Speaker D: Box, the hash function, could you expand on that? What is the hash function? What hash function are you talking about?
00:20:15.200 - 00:21:00.382, Speaker A: Sure. So one correction is that we're not blackboxing the beacon chain, we're blackboxing the random, or we're suggesting blackboxing the random number generator. I guess by black boxing what we mean is just like replacing it with some possibly horribly insecure component that still satisfies the same interface. And the idea would be that it can be kind of like swapped out with the real, with the real component later without changing any of the rest of the code. So for the random number generator, obviously we're thinking of five design. Well, okay, not five designs, two designs. But until those designs are perfected, you can just use hashes for the hash function.
00:21:00.382 - 00:21:36.040, Speaker A: We've been doing research on stark friendly hash functions, at least like arithmetization hash function friendly hash functions, generally recently, but even before that, basically outside of the fancy new stuff, I think we both like Blake two. And Blake two is like fairly fast, and there's a bunch of libraries for it. And we can, and it's substantially faster than shot three. And we can get rid of this stupid issue. We're using a slightly different, non standard version of shot three because that's how it historically turned out.
00:21:44.110 - 00:21:55.980, Speaker C: Another thing where there's potentially going to be some change is the VLS curve. So we haven't finalized which curve really has to do either the old dash curve or the new one.
00:22:08.750 - 00:22:09.500, Speaker F: It.
00:22:12.510 - 00:23:01.588, Speaker A: So I guess we could go through somewhat about in terms of what in the current plan as it exists now, beacon chain blocks and state are likely to contain. Now, obviously details of this change, but it's at least kind of enough to give you an idea. So this would be the. We can look at the beacon chain state structure. Oh, cool. And we can look at the beacon chain block structure. So basically the block contains.
00:23:01.588 - 00:24:01.760, Speaker A: We'll start off with the block, right? So the block, first of all, what it needs to contain is that, first of all, the block has a proposer and it needs a signature from. A signature from the proposer. Second, a block contains attestations. And because we're using aggregate signatures, you want an aggregate signature for the attesters. Now also, this second signature is an aggregate signature, which means that you also need a bit field. So you want basically a bit field of attesters. And the bit field basically is just like a list of bits, right? So if you imagine you have, say 5000 attesters per block, which could totally happen, then this bit field will basically just contain 5000 bits.
00:24:01.760 - 00:24:48.384, Speaker A: So 625 bytes, right. The signature size is going to be either 64 or 96 bytes, no matter how big it is. And one other thing that's worth pointing out is that it is theoretically possible to combine together the proposer and the attester signatures. So there's totally some opportunities for optimization here. So that's proposers attesters block, attesters. Another thing you probably want outside of this that you'd want is if it is a checkpoint block, then first of all you need a pointer to the parent. So you need a pointer to the parent.
00:24:48.384 - 00:25:24.580, Speaker A: You might also need a main chain reference. So basically this is the pointer to the parent in the beacon chain. This is the pointer to some parent in the main chain. Any other variables that I missed? Height number possibly? Yeah, height or swat number possibly. We can potentially include both there. Yes. Well, technically I think that might be the whole thing.
00:25:24.580 - 00:25:42.060, Speaker A: What else do you need? Okay, so the attestation signature in the bid field, also us at the station signature in the bid field for the FFG votes. And we're hoping for the cross links as well.
00:25:43.230 - 00:25:47.798, Speaker C: And we might need other things like transactions for slashing.
00:25:47.974 - 00:26:39.440, Speaker A: Yes, yes. So things that we haven't fully finalized yet basically are probably transactions for slashing conditions like basically validator penalization. And as far as structure goes, it might make sense to include in here basically a list of records of what validators joined. Technically that's redundant because the information is in the main chain, but it would be a good convenience feature because then you would be able to actually fully validate a beacon chain without having the main chain if that's what you want to do. So if you do that, then that would basically look like you trusting the validators in the beacon chain to say who the new validators are, which is not a perfect model, but one that you could trust if you wanted to.
00:26:41.410 - 00:26:50.240, Speaker C: There might also be some administrative transactions if you want to be registered as validator or if you want to top off your balance, if you.
00:26:53.910 - 00:27:45.666, Speaker A: Yeah. So in terms of the size of this, right, like the bulk of this, as you have about a couple hundred bytes here, maybe a couple hundred bytes altogether, the bit field could go up to something like a kilobyte in the worst case. Right. So the size of one valued or SWAd is 32 ether, and the maximum, for the maximum amount of ether that could exist, I'm using as a simplification 132,000,000, which is two to the 27. And no, this is not a statement of the exact ether hard cap that I wants to impose on everyone with an iron fist. It's like something like a number to use to kind of keep in your head and think. And what that gives you is two to the 22 validator slots, which is about 4.2
00:27:45.666 - 00:28:39.890, Speaker A: million. So with 4.2 million validator slots, and then if we assume, say 128 block epochs, then that goes down to two, to the 15. So 32,000 validators get included inside of every block, which is. And 32,000 bits basically means these block headers are going to be something like 5 that's coming in every few seconds. The chain in this particular structure, it definitely would be kind of like heavier as a way heavier than the current Ethereum header chain, which is 500 bytes every 15 seconds, though in practice it's not going to go up to 5000. Actually will be like 500 bytes every 5 seconds.
00:28:39.890 - 00:29:19.600, Speaker A: And one area of research is also thinking about is there a possibility of designing the system so that a light client can get by with some subset? And I think the answer is maybe, but it's not clear that that has to exist in the form of a header chain. That could also exist in the form of a structure where, say every checkpoint block has to point to the previous checkpoint block. So you could download just the chain of checkpoint blocks and then you would basically use just the validators at the checkpoint height as a kind of proxy for all of the validators. These are details that we're thinking about but not finalized yet.
00:29:22.750 - 00:29:34.990, Speaker C: One thing that might be obvious to be worth mentioning is that there's no gas yet, so we can just make a transaction and no worry of gas.
00:29:43.240 - 00:29:44.976, Speaker E: So that's a shard block.
00:29:45.088 - 00:29:45.750, Speaker F: Yes.
00:29:47.640 - 00:29:48.912, Speaker A: That'S the beacon chain.
00:29:48.976 - 00:29:52.484, Speaker E: You said there's a pointer to the point.
00:29:52.522 - 00:30:36.020, Speaker A: This is a pointer to the previous beacon chain block. This is a pointer to the main chain. There's no point. Well, so remember, the only case where the beacon chain contains pointers to shards is where you have a cross link. And so basically the idea is that these signatures are going to simultaneously be signatures of data, where the data can be calculated basically in the structure, you might end up wanting to explicitly include a list of what checkpoint hashes people are voting on. Right? So basically you have the salary signature, you have the bit field, and then you'll probably also want to have a list of checkpoint hashes. And the checkpoint hashes ultimately do kind of like go above and they attest to shard blocks.
00:30:37.180 - 00:30:42.360, Speaker D: Okay, if we only want to experiment with the beacon chain functionality.
00:30:46.540 - 00:30:54.780, Speaker A: Then you can basically sign the hash of 42 as a checkpoint hash. And we can keep doing that until we're ready to have real shard chains.
00:31:04.110 - 00:31:12.590, Speaker B: All right, question. Because there is no effective slide cap on the east, how does that affect the number of validators?
00:31:13.570 - 00:31:58.720, Speaker A: First of all, there is the discussion of how big are the rewards going to be. Proof of stake requires much lower rewards than proof of work. So I think the community should, as I've said before, think about eventually going down to zero issuance and having a supply cap. But even if it doesn't, right, that basically means even, let's say, worst possible case scenario, it requires 6 million ether issued every year, which it totally won't, but that's the current issuance. Then basically the amount of effort needed to process the beacon chain would only go up by 6% a year. And that's not exponential, it's linear. So Moore's law totally beats it out.
00:32:01.010 - 00:32:04.720, Speaker B: Can you go back to that whole no gas thing? What does that mean?
00:32:05.250 - 00:32:30.946, Speaker A: Basically, the idea is that there is no possibility of general purpose computation happening on the beacon chain, right? Because the beacon chain is not a chain on which activity happens in the sense of no end user activity happens. So all you have on here is hash verification, like right now, BLS signature verification and random beacon verification. Eventually stark verification. And that's it.
00:32:31.068 - 00:32:35.962, Speaker E: So there's nothing that one validator can do that can have some variable amount.
00:32:36.016 - 00:32:37.878, Speaker A: Of space on the decontaine.
00:32:37.974 - 00:32:38.620, Speaker E: Correct.
00:32:39.870 - 00:33:11.350, Speaker A: The one thing you can do is you can sign for a cross link that nobody else is signing for. And so one thing that we haven't fully figured out here is basically, do we need to, and if so, kind of how to impose the limits on the load if lots of people, pretty much everyone, is voting for a different cross link hash. But that's only possible in the worst case. And there are one thing we could do is we could just limit the number of cross link hashes per block. And so if you're really, really part of the minority, you just don't get included.
00:33:12.410 - 00:33:35.280, Speaker C: I mean, there will also be a variable number of administrative messages. And also hashing messages, you can have various sizes. So we could just tap the amount of messages about variable, or we just have some sort of very primitive pieces. Okay.
00:33:37.330 - 00:33:50.000, Speaker B: Another idea for administrative messages is simply to actually do them on the main chain and then tear them across because you don't want.
00:33:51.890 - 00:34:00.130, Speaker A: And that's possible when the main chain goes away. They have to exist somewhere anyway, that's not even implemented.
00:34:00.870 - 00:34:02.982, Speaker B: I just wanted something super minimal, right?
00:34:03.036 - 00:34:16.090, Speaker A: Yeah, sure. First of all, if we want super minimal, then we don't even need penalties, right? Because in the super minimal case, basically nobody can withdraw. And technically, you don't have to implement slashing until you allow people to start withdrawing.
00:34:19.150 - 00:34:20.186, Speaker D: Let me just make sure I got.
00:34:20.208 - 00:34:26.446, Speaker E: The whole design right. If I'm processing only the beacon chain, say it's not the main chain at all. For some reason I wouldn't know, for.
00:34:26.468 - 00:34:29.200, Speaker D: Example, what a validator's deposits are.
00:34:30.690 - 00:34:46.660, Speaker A: You would know because in the idea that I just suggested, you would know because the beacon chain would contain records of who the new depositing validators are every time the main chain reference changes. But you would have to trust that if you're not validating the main chain yourself.
00:34:47.350 - 00:34:51.414, Speaker D: Okay, so I could potentially load the beacon chain with like top ups or.
00:34:51.452 - 00:34:52.854, Speaker E: Something like that, right?
00:34:52.892 - 00:34:57.560, Speaker A: In this design, there's no top ups, there's just 32 east deposits. Okay? Yeah.
00:35:03.210 - 00:35:07.290, Speaker B: Any of you notice there are some for choice rule and block producing.
00:35:11.950 - 00:36:15.220, Speaker C: So block producing is easy. Generator full choice rule, we're concerned is we having the heaviest chain with respect to assessation. But because we're kind of thinking of merging notion of assessation of crosslink and ffg into it will also be the heaviest chain. So it would be the chain which is most likely to finalize next before which, in terms of the four choice rules for the shard, we're looking to have the shard be kind of maximally decoupled from the beacon chain. And at minimum we want the shards to respect the finality point in the beacon chain. And it's possible that we can have the fortress. We'll only look at that.
00:36:15.220 - 00:36:22.290, Speaker C: So it's just, for example, one single block per epoch.
00:36:25.590 - 00:36:39.580, Speaker F: Is there any condition to restrict that which nature has will be the structure to be content cosmic be used?
00:36:42.190 - 00:37:29.046, Speaker C: Maybe we should restrict it. For example, a height should be zero or zero, some number like 100 or ten. One reason to do that is that initially, if we don't change the forklook rule of the main chain, and the main chain does revert, then it means that the vegan chain must also revert. And so if we want to minimize forks in the second chain, then having less references to the main chain, just.
00:37:29.068 - 00:37:35.800, Speaker D: Going back to black boxing. The random number generator, if I don't see that in the block, it'd be in the state.
00:37:36.810 - 00:38:04.210, Speaker A: So there would be two parts, right? You would store a random number generator state and then in the block you would contain kind of like reveal messages. And there could be ran down reveals. That could be VDf solutions and proofs. There would be a reveal message in here. I guess I'm not drawing it now, but you can leave it kind of like empty slot as some byte field. And for now it can be empty.
00:38:06.150 - 00:38:08.850, Speaker D: If we're blackboxing the random number generator.
00:38:10.950 - 00:38:44.720, Speaker A: Right, we do the simplest black boxed random number generator that you can think of doesn't require any reveals at all. Right, well, I guess what you could do is you could just have a slot for reveals and then let block producers reveal whatever they want. That's the other stub you can make. It goes in the block. It goes in the block. And then in the state, you would have r. Sorry, and g state there.
00:38:44.720 - 00:38:51.520, Speaker A: So RNG state is definitely part of the state of the beacon chain. Right.
00:38:51.990 - 00:38:55.726, Speaker D: And that RNg number just changes every block.
00:38:55.838 - 00:38:58.210, Speaker A: It could. Or it could change every dynasty.
00:38:59.910 - 00:39:01.586, Speaker D: What else might be in the state?
00:39:01.688 - 00:40:01.298, Speaker A: Okay, so I personally like to split the state up into kind of two parts that I call, I mean, in the spec, I call it active and crystallized, but it's basically kind of quickly changing information and slowly changing information. So the quickly changing information, basically is. So, number one, you have the RNG. Number two, you have basically various different bid fields. So you would have a bid field of basically who participated at what height, and you might also have bit fields of who participated at each cross link. And you'll have a series of cross link hashes that people are trying to submit. So you'd have the bit field at different heights, which also doubles as the casper f of g bitfield.
00:40:01.298 - 00:40:32.190, Speaker A: So this is all basically storing, like who participated bit field over here. Then let's see, what else would you have? Bit fields of cross links. I remember the active state being very small, right? Yeah, you would have RNg data. So data related to records of cross links in progress.
00:40:34.450 - 00:40:35.950, Speaker C: Pending metadatas.
00:40:36.550 - 00:41:09.158, Speaker A: That's not short term, that's long term data. Yeah. Okay, so then long term data is more interesting, right? So long term data, you basically, first of all, you have validator sets. So you have active validators, you have pending validators, and then you have possibly exited validators. So exited validators are just validators awaiting withdrawal. So active validators are validators that are active right now. Pending validators are validators that have logged on, that have deposited but have not been inducted.
00:41:09.158 - 00:42:08.682, Speaker A: So you might have to wait one dynasty to get inducted, and exited validators are validators that withdrew, that are waiting, either withdrawing or getting slashed, depending on how nice they were, or possibly some combination of the two. So for each of these, basically, you have a validator record. And the validator record might contain, first of all, it contains the pub key, your pub keys, it contains your balance, and it might contain RNg private state, depending on what the RNG ends up being. Oh, yeah, that looks terrible. They really should teach mirror writing in school. More useful than cursive. What else do they have? Basically, when I did the calculation altogether.
00:42:08.682 - 00:42:12.820, Speaker A: It's something like, it's like 100 bytes per validator. So it's very little.
00:42:13.990 - 00:42:46.300, Speaker D: Okay, let's say because yesterday we talked about phase one versus phase two, they're decoupled and then you work on them independently. And you would in theory, be able to phase two execution engine. Without worrying about the details of phase one. So if one of black box phase one, then I think the only relevant stuff would be like the cross links. Anything else?
00:42:46.990 - 00:43:27.798, Speaker A: So from the point of view of the execution engine, the thing that matters is obviously, first of all, what information is a particular part of the system allowed to have information about what. So that basically is determined by the cross link structure. It would also get environment variables. So for environment variables, you have block hash timestamp. You might want to allow opcodes for random number state and all that. So basically, just for that, assume that there is environment data. And the shard is aware of the environment data from the beacon chain.
00:43:27.798 - 00:44:02.450, Speaker A: And from the last point of finality. And then the shard is obviously also aware of the environment data of itself pretty much instantly. Whatever the incentivization of the execution is, depending on, I guess, how fine grained the incentivization ends up being, it could either happen on the beacon chain. So you want like penalties on the big penalties on the beacon chain. Or you could do incentivization inside of shards. If you have penalties that have to be applied to everyone, every block or rewards.
00:44:09.540 - 00:44:12.290, Speaker C: One thing that could potentially bloat the.
00:44:20.020 - 00:44:52.460, Speaker A: What data are you thinking? Oh, yes, proof of custody challenges would actually go here, right? They to go in the block. And proof of custody itself doesn't need to have a large state size, does it? I get that in this part of the state, in the validator state, you probably want proof of custody seed commitment. So I'll just say commitment and then POC.
00:44:54.000 - 00:45:00.690, Speaker C: Do you want to store when the times periods, for example, and who made them?
00:45:01.460 - 00:45:42.104, Speaker A: Yes, you would. But that would be though challenge period expires only four bytes. I don't expect that to be a source of massive bloat. And also keep in mind that the size of the crystallized state altogether in the kind of like worst case is going to be something like 400 megabytes. And I don't expect it to be possible to make enough challenges to get anywhere close to that. The active state is somewhere in the active state is mainly a bunch of bit fields. So the active state might only go up to the 100 kilobyte range.
00:45:42.104 - 00:46:18.490, Speaker A: So basically from an implementation point, of view, all of this would just be a big long thing in ram and I don't know, like shove the active state into an l one cache or whatever. If you care about optimization, basically in terms of cost of computation and processing, you're going to have a lot of bitfield manipulation and a lot of hash checking and a lot of BLS signature verification, and a lot of randomly fetching public keys from the crystallized state. So just optimize for that.
00:46:22.540 - 00:46:27.176, Speaker C: One thing that could significantly change the size of the headers might be the.
00:46:27.198 - 00:46:31.244, Speaker A: DDF if it contains a star or.
00:46:31.282 - 00:46:35.532, Speaker C: Even like the 10 kb proofs for the VDF, right?
00:46:35.666 - 00:47:11.450, Speaker A: Yeah. Now that said, we are considering designs where like submissions only get submitted once every epoch instead of once every block, which would basically mean that sometimes you have big VDF blocks but it gets amortized. Yeah, I will add though. So if we're using even starks for the VDF, then having the starks be big doesn't matter much if we're using big constructions for the signature aggregation. That is a bit more of a problem.
00:47:20.930 - 00:47:33.078, Speaker B: Just a general maybe something to think about. So because I get a feel that we're not even quite sure what is going to go into the loss or where it's going to go into state, maybe we forgot about something.
00:47:33.244 - 00:47:35.158, Speaker D: And perhaps what we need to do.
00:47:35.164 - 00:47:48.940, Speaker B: Is that to make it a bit more generic to sort of treat the block and state as a piece of cell set of cells, and then you can reference them in some sort of state positions or whatever.
00:47:54.510 - 00:49:07.620, Speaker A: From a development point of view, there's things that are easy to change on the fly and there's things that are difficult to change on the fly. So adding parameters to header structure, especially if you just have one implementation you don't care about consensus, is fairly easy, right? So I think Danny's already implemented at least some of the changes to the specs that I made since I wrote up that proof of concept code. In general, as far as basic structure goes, I feel like yes, some parts of the active state and some parts of the crystallized state are not finalized, but that's not the sort of thing that it would take like month delays if we end up rethinking it, whereas if we end up rethinking the whole concept of the beacon chain and its particular type of relationship with the main chain, then that was the sort of thing that would cause more than a month of delay. At this point, I feel like the concepts are definitely more crystallized than the implementation details, and that's in part because we realize that crystallizing the concept is probably what matters more in terms of providing kind of development stability than crystallizing or specifying exactly what all of the 32 byte hashes look like and what the alignments are.
00:49:08.390 - 00:49:11.894, Speaker D: This block is only a header, it has no body.
00:49:12.092 - 00:49:17.042, Speaker A: The block. Correct. This does not need to have a body now transactions.
00:49:17.106 - 00:49:23.240, Speaker D: But would it make sense to redefine it and consider the signatures as part of the body?
00:49:23.710 - 00:50:14.940, Speaker A: Possibly, right. So it depends on the design. So for example, over here you basically just include the, if we're going to do the optimization where we combine together the proposer signature and the aggregate signature, then you can't verify the proposer without verifying everyone else. And so then basically you can't have a concept of header, whereas if we don't do that, then you do have a concept of a header. Another thing worth that is one trade off. And then the other question is, by having headers, who are we trying to serve anyway? Right? And my answer is we're trying to serve light clients. But there might be other ways to serve light clients, such as for example basically having a block parent structure where you can verify a subset of the chain instead of verifying the full chain if you want to.
00:50:16.670 - 00:50:21.210, Speaker F: Could you give us a quick summary before we go to the chain?
00:50:25.090 - 00:51:14.240, Speaker C: Okay, so I guess decent chain is pretty radical thing compared to the previous design. It has a bunch of core functions, hard east random number generator, which is something that developers can attract away. It has this notion of attestation, which actually does a lot of work in small things. It does help with the decent chain choice rule, but also with FFG roads and cross links. And that is going to involve DNS aggregation. And for implementers, I guess you can start looking at DLS. It's very clean design, but be wary that we haven't finalized the curve yet.
00:51:14.240 - 00:52:24.466, Speaker C: And then there's going to be a whole part of accounting. So the decent chain is going to process the registration messages and the deregistration messages, as well as all the micro rewards and penalties, as well as the larger penalties in terms of matching. I guess one thing to note as well is if the balance goes too low, then there will be forced deregistration for the validators. And in order to make sure that everyone is kind of fairly treated, then we want to incentivize balances to be as good as possible to 32 or at least 32 e. And so there might be a penalty for having your balance, but there will be some margin before you. Yeah, in terms of what developments are doing right now. I still think there is a lot of work to be done in standardizing the networking stack, and that's something that can be done completely depends on what we're doing.
00:52:24.466 - 00:52:36.326, Speaker C: But other than that, working on just the catholic RNG, I will kind of.
00:52:36.348 - 00:53:29.060, Speaker A: Reiterate that I definitely don't think that you need to standardize everything before it makes sense to start development. Right? So if, for example, your goal is to have a toy that you can run as a proof of concept and show people that your team is great and sharding is great, then first of all, you definitely don't have to worry about validator rotation. You definitely don't have to worry about penalties. You definitely don't have to worry about proof of custody challenges or even proof of custody at all. You can just implement a structure that has some static, or at least like static and only growing validator set, and you can just basically do whatever the minimal structure is for FFG messages and then limit that. And it would work. It would have a lot of the properties that we're looking for, and then the other components can be sort of added on over time and.

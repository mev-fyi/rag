00:00:07.020 - 00:00:07.570, Speaker A: You.
00:00:11.220 - 00:00:58.240, Speaker B: Okay? Proofs of custody. So, just to give a little bit of context, proofs of custody are this quite neat crypto economic construction. And the way they fit in the context of sharding is basically to do what I call enhanced voting. So sharding, or part of sharding, is about scaling up the data availability problem. So not everyone downloads every piece of data. And one of the main techniques that we have is to basically sample validators at random from a pool. And then we have an honesty assumption at the pool level, which gives us some assumption in terms of the committees.
00:00:58.240 - 00:01:56.364, Speaker B: But it'd be nice if we could go beyond just honesty and we could start using rationality, so financial incentives to make sure that people vote properly, in particular when they vote on the availability of data, it would be nice if we could have some high level of confidence that they actually have the data that they're voting on. And if they have the data, at the very least it's available for them. So that's really good. So if you have a committee of 1000 and your threshold is 500, then if you have 500 votes, then 500 people in the network have this data. So that's pretty good. I guess we could start going into the details of the construction. So the setup is that you have a secret which is unique to you as a validator, and you need to keep it secret.
00:01:56.364 - 00:02:51.008, Speaker B: Otherwise, if it leaks, there will be a slashing condition, which will allow whoever reveals the secret to take half your deposit and to slash the other half. And on chain, you have a commitment for that secret. And that commitment is fairly long lived. It could be something like a week or 30 days. It doesn't have to be recycled very often. And then the question is, given a piece of data that the validator is meant to have, and by the way, that piece of data is identified via its Merkel route. So instead of just taking the data and identifying it with its hash, which, for example, is what bitcoin does, we have the data be a power of two.
00:02:51.008 - 00:04:22.204, Speaker B: So it means that you can very nicely merklize it where each leaf is a chunk, what we call a chunk, which is 32 bytes. So this Merkel route is what identifies the data. And you want to come up with a scheme where you prove that you have custody of the data. And just in a couple of sentences, what you do is that you take your data d, for which you want to prove custody, and you split it up into 32 byte chunks. And then for every single chunk, you mix in your secrets, and then you mercurialize that and you get another route, r Tilde, which is basically a route that you and only you should be able to compute, and you should only be able to compute it if you have the data. So one of the things we want to prevent, for example, is being able to outsource the computation of this thing to other people. But because of the secret part and because of the fact that the secret is mixed in at every single piece of data and because you can't give away that secret to a third party without risking having your deposit slashed, it means that only you can make this computation.
00:04:22.204 - 00:05:17.852, Speaker B: And furthermore, obviously you need the data to be able to do this computation. So you'll have the data. So just to give a bit more context, even one of the reasons why it's nice to have this proof of custody scheme is also to prevent what's called copycat voting. So if you're a lazy validator and you don't have much bandwidth to verify the availability of blocks, then one perfectly rational strategy would be to wait some period of time and see what other people are voting on. And then if many people are saying, oh, this data is available, then you also say that it's available. But I guess the point of the scheme is that you can't do that. You can't be lazy.
00:05:17.852 - 00:06:24.728, Speaker B: You actually have to download the data and produce this thing. Now, any questions so far as to why this scheme kind of proves that you would have the data? So one thing that, sorry, I forget to mention, which is very important, is that after the 30 days or seven days, you reveal your secret. So once you've revealed your secret, then everyone else can verify the route, the proof of custody that you've submitted. And if it turns out that it's wrong, then you can start engaging in a challenge game. So something similar to Truebit. So the challenger will have, they'll have the secret, which is no longer a secret, it's a public, and they'll be able to compute a route. And if it doesn't match, engage in the game and then we can go into details of the game.
00:06:24.728 - 00:06:28.330, Speaker B: It's quite easy, but that's how it works at a high level.
00:06:36.910 - 00:06:47.260, Speaker C: You just threw out 30 days, approximately. What kind of timescales would make sense to have this cycle on, and where does that come from?
00:06:49.230 - 00:07:28.760, Speaker B: Right? So you like to be able to reuse the secret just for efficiency, but on the other hand, you don't want to use it for too longer periods. And the reason is that the proof of custody becomes verifiable only after you've revealed your secret, which means that if you start cheating, then you might as well cheat as much as you can and basically cheat during the whole 30 day period. So we want to limit the period during which bad things can happen. If they do happen.
00:07:32.250 - 00:07:34.380, Speaker D: Why not just use some sort of public.
00:07:34.750 - 00:07:35.500, Speaker B: Sorry.
00:07:36.350 - 00:07:48.240, Speaker D: Why not just use some sort of public key scheme to produce the secret per tree or whatever or per day or something like that? Wouldn't that be.
00:07:52.530 - 00:08:25.958, Speaker A: Number one, as far as security goes, like, hashes are pretty much the gold standard and you have the most guarantee you'll never have to change it again. Number two, you get much more efficiency. Number three, actually, the fact that we're using XOR to mix in the data basically means that you can use the branch challenging scheme also as a way of actually recovering particular pieces of data, because if you have the seed, then you can get the data right back. So basically between those three, this is.
00:08:25.964 - 00:08:49.266, Speaker E: Pretty much the most efficient jr. But then if anyone has a piece of the data at that chunk, they.
00:08:49.288 - 00:09:00.694, Speaker A: Can xor it with the original data and recover your key. Yes, but the point is that the challenge period only starts basically after it comes time to. Or rather, you can only period end.
00:09:00.732 - 00:09:02.150, Speaker E: When the proof is provided.
00:09:02.570 - 00:09:05.302, Speaker A: No, the challenge period keeps going for a while. But the point is.
00:09:05.356 - 00:09:06.166, Speaker F: But as soon as the proof is.
00:09:06.188 - 00:09:06.994, Speaker E: Provided, you have a leaf.
00:09:07.042 - 00:09:15.882, Speaker A: Yeah. So as soon as the proof is provided, the secret is going to be known regardless. Right. Now, granted, if you use public key cryptography, it's not, but in this case it is Baloch. That's fine.
00:09:15.936 - 00:09:19.222, Speaker E: So isn't the challenge period the period to reveal the secret?
00:09:19.366 - 00:09:22.458, Speaker A: No, the period to reveal the secret is before the challenge period.
00:09:22.554 - 00:09:24.810, Speaker E: Okay. And the period to reveal the secret.
00:09:24.890 - 00:09:50.150, Speaker A: Ends when withdrawal delay, or rather, no. So here's how it works, right? There is some point in time at which you basically have to reveal a secret. And as soon as you reveal a secret, then the clock starts ticking. And basically, if you get challenged during that time, then you have to respond to those challenges.
00:09:50.890 - 00:09:53.906, Speaker E: But as soon as you provide a branch, your secret is revealed.
00:09:53.938 - 00:09:58.658, Speaker A: No? Correct. But the point is that you're only going to be revealed. Yes. You reveal a secret before providing any branches.
00:09:58.754 - 00:09:59.400, Speaker E: Okay.
00:10:04.090 - 00:10:46.486, Speaker D: Yeah, I guess the main thing that I didn't understand. So if you're. The challenge period doesn't start for quite a long time, actually, and it seems like that makes me nervous. Who knows what the threat model is? But if you wanted a challenge period to be able to start almost immediately, then you could, say, do a diffie hellman to derive the secret or whatever. And then if the guy needs to reveal the secret for this particular tree, then he can do so. And so that way, your challenge period can start right away, which, I don't.
00:10:46.508 - 00:11:17.540, Speaker A: Know, other thing that you can do is you can say so. First of all, there's going to be a lot of. There's two reasons why you might want to start a challenge. Right? One of them is that you disagree with the commitment, and the second is that you think the data is unavailable. So what we can do is we can try to, like the first use case, we can only target it after the seat is revealed. For the second use case, we can allow challenges to happen immediately. And if a challenge does happen immediately, you can have a rule that says that you pretty much have to submit the secret and respond to that challenge before you're allowed to do anything else.
00:11:17.990 - 00:11:25.574, Speaker D: Okay. Yeah. Now I see that it's actually in the threat model that it's because you can just make the data available or whatever.
00:11:25.692 - 00:11:37.878, Speaker E: Yeah, but even there, you kind of have to commit reveal. So somehow, how do you reveal your secret before a front runner does it and take your deposit?
00:11:37.974 - 00:11:56.670, Speaker A: Well, because only you have your. Oh, I see. So, like, how do you publish the additional one answer is that the game for the place where you can be penalized for revealing your secret basically ends one dime. You wait for the end of that period to finalize before you reveal the secret.
00:11:57.490 - 00:12:00.558, Speaker E: But you said that someone could publish a challenge right away.
00:12:00.724 - 00:12:07.870, Speaker A: Oh, no, I see. So basically, the idea would be that if someone publishes a challenge right away, then you wait until that finalizes, and then you publish your secret.
00:12:08.030 - 00:12:10.994, Speaker E: So if you can't respond, you can't actually respond to the challenge right away.
00:12:11.032 - 00:12:13.418, Speaker A: You have to wait for one dynasty.
00:12:13.614 - 00:12:20.134, Speaker E: Okay, so there are delays no matter what in the scheme, right?
00:12:20.172 - 00:12:20.760, Speaker A: Yeah.
00:12:24.970 - 00:12:37.980, Speaker D: Two things they're trying to enforce. One of them is that the data is available and that they need to make sure. They need to be able to verify that quickly. And the second one, that nobody submits false challenges. They can just sort that out later, and that's okay.
00:12:39.810 - 00:12:40.560, Speaker A: Yeah.
00:12:43.250 - 00:12:47.118, Speaker E: But do we want to know that the data is available now?
00:12:47.284 - 00:12:59.986, Speaker A: Well, the point of this scheme isn't to say that the data is available now. It's to say that either the data is available now, or a whole bunch of people are putting their money at risk. It's deliberately kind of like crypto economic in that sense.
00:13:00.088 - 00:13:05.398, Speaker E: I mean, it's not clear that they're putting their money at risk if they actually have the data, right?
00:13:05.484 - 00:13:38.830, Speaker A: If they actually have the data and they're not. Yeah. So this does not guarantee that this does not provide disincentives in the case where a malicious person created the data behind a proposal, published the proposal header without the data, but does have all of the data themselves, and is willing to only give out specific branches in response to challenges. If you want a technology that does survive that threat model, then you can look at my erasure quota, data availability checking stuff.
00:13:38.980 - 00:13:48.260, Speaker E: Sure. So another question. Why did you change, so why not use digital signatures instead of xoring with? Yes.
00:13:48.630 - 00:14:02.760, Speaker A: So as I mentioned, number one, it does create the property that you can basically, from the responses, you can recover the original data. Number two is that.
00:14:05.050 - 00:14:06.850, Speaker E: Makes the proof a little bit smaller.
00:14:07.010 - 00:14:24.560, Speaker A: Number two, it makes the proof smaller. Number three, it makes the proof much lighter to verify. And number four, it gets to be pure, kind of purely hash based. So there's much less, which just makes it more possible to set the protocol in stone and not worry about changing it later.
00:14:29.250 - 00:14:32.320, Speaker D: The proof is expensive to verify anyway because you got to have the data.
00:14:33.330 - 00:14:41.186, Speaker A: Right. But it's still the case that you have a. Okay, from a computation time perspective, hashes are incredibly cheap, but you don't need.
00:14:41.208 - 00:14:44.514, Speaker E: The data to verify the proof, you just need the Merkel root and some Merkel branches.
00:14:44.562 - 00:14:44.774, Speaker B: Right?
00:14:44.812 - 00:14:48.306, Speaker A: No, I think by data he means Merkel branches.
00:14:48.498 - 00:14:57.142, Speaker E: Okay. Yeah. I guess you might get a factor of like two savings on the size of the proof. I'm not sure.
00:14:57.196 - 00:15:01.980, Speaker A: Agree. So from a data point of view, not much. From a computation point, a huge amount.
00:15:02.590 - 00:15:08.598, Speaker C: So what's the disincentive again, for revealing s to like an outsourcer or something like that? You said it was disincentivized.
00:15:08.694 - 00:15:59.660, Speaker A: Yeah. Okay, so first of all, the outsourcer can submit s ahead of time and basically claim your money. Now, if you have a model where you're outsourcing to kind of partially trusted outsourcers that have reputations, and so they won't do that, then we could introduce another kind of game, which is basically a kind of deniable challenge. So the idea basically is that we allow anyone to kind of gamble on properties of your future revealed s to some extent, and basically to the extent to which anyone has more than 50% certainty about like some about some property of your seed, then they would be able to earn money off of this, and it would be totally unknown who did this. They could do this with a totally unknown account and it would be indistinguishable from someone just doing it for fun.
00:16:01.630 - 00:16:06.986, Speaker C: Can you get around the first bonded smart contract and you burn?
00:16:07.018 - 00:16:16.850, Speaker A: Yeah, you totally could, you could get around the first issue with a bonded smart contract. You can do abundant smart contract. You can just use your reputation.
00:16:20.230 - 00:16:37.740, Speaker F: Hello. I remember in truebit, for example, at some point they've introduced like a special, so in order to incentivize people checking, they've introduced a special game where the cheating does actually happen. Yeah. Do you have that in there as well?
00:16:38.110 - 00:16:51.920, Speaker A: Not yet, but it could be added. Okay. Yeah.
00:16:55.330 - 00:17:02.082, Speaker G: On average, how many do you expect like a node to validator to have to.
00:17:02.136 - 00:17:04.126, Speaker A: You mean how many challenges?
00:17:04.318 - 00:17:13.026, Speaker G: No, just like on average they receive the actual data a month later and they want to compute if it's, the.
00:17:13.048 - 00:17:24.002, Speaker A: Computation is very trivial. Like you're basically, for 1 mb, you're essentially hashing over two megabytes of data. Okay. Or, sorry, you're x overing over a megabyte and then hashing over two megabytes.
00:17:24.066 - 00:17:25.334, Speaker G: So you expect them to do it.
00:17:25.372 - 00:17:54.098, Speaker A: For, you just expect totally random nodes to just do it. We could even shove it into the default software. It's very trivial. Okay. I think we mean like the public key based thing or something else, just taking the one. Oh, right. Yes.
00:17:54.098 - 00:18:45.540, Speaker A: So one advantage of the proof only being one bit is basically that for the purpose of BLS aggregation, if you remember BLS signatures, you can do them for multiple messages and multiple users, but for every user you're adding, you're only adding an elliptic curve addition of overhead. But for every message you're adding an extra elliptic curve pairing of overhead. And so for efficiency, you want the number of messages that people are signing over to be extremely small. And also for information theoretic reasons, you want it to be extremely small because if every single attester includes a separate proof of custody, then we're going from one bit per validator to 256 bits per validator. So with this model, basically there are only two possible proof of custody claims that any particular validator could use. Yes.
00:18:45.690 - 00:19:01.412, Speaker C: So if you're using this PlS aggregation, if you're using this PLS aggregation and you're also a proposer, could you potentially equivocate by using one signature for your aggregated total and using another one to reveal to the network?
00:19:01.556 - 00:19:16.008, Speaker A: No, because the idea is that the way that you would sign is you would basically, whatever the signature is, say, of the previous block, if you want to claim a zero, you would just sign over that plus zero. And then if you want to claim a one, you would sign over that hash plus one.
00:19:16.174 - 00:19:18.970, Speaker C: Okay, I have to think about it.
00:19:20.820 - 00:19:25.180, Speaker A: And then, like, obviously, we'd have to have two different bid fields for the zero signers and for the one signers.

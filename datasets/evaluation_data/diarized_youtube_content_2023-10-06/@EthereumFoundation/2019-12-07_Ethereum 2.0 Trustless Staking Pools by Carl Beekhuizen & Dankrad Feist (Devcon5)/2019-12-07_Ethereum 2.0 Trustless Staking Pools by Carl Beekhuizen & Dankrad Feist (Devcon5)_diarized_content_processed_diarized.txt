00:00:01.960 - 00:00:02.510, Speaker A: You.
00:00:04.480 - 00:00:44.760, Speaker B: Hello. Welcome to our presentation on trustless validator pools in east 20. I'm Dankard Feist and this is my colleague Carl Bakeriesen. We are both researchers in the east 20 research team, and we'd like to talk a bit about our efforts to make trustless staking possible in E 2.0, why we're doing this, how we design the protocol to make this possible. And then in the end, Carl will talk about the actual implementation of this, how it would work. So, yeah, this is the outline of the talk.
00:00:44.760 - 00:02:10.064, Speaker B: So, like motivation, why do we need trustless staking pools? Why we want this as a primary goal in E 2.0? Then how do you design a protocol? So, like, the technology basically that is needed to have trustless staking pool as secure multiparty computations. And then there are basically less and more advanced ways to have these trustless staking pools. You can have a basic algorithm that enables you to have a sort of trustless staking, or you can actually, if you want, extend this to also have fault attribution so that if your honest two thirds majority assumption fails, you can still with very high likelihood not lose your money if you're in such a pool. Okay, so what's so cool, why do we need trustless staking pools? So the first thing you have to know about proof of stake, like an east 2.0, we need to fix the amount that is staked by every validator to roughly the same amount. And why is that? It's very difficult to design a protocol that works in a fair way with vastly different stakes.
00:02:10.064 - 00:03:20.072, Speaker B: So, for example, when you sample people for committees, you don't make any adjustments for their stake because it would just be too complex. And so the protocol is designed so that it only really works if what everyone has staked is roughly similar. It can vary slightly, but if it varies too much, then the assumptions will fail. The amount that we agreed on is 32 E, which is like in today's price is about $5,500, but say like one ETH goes to $10,000, which is very well possible from what we know. Then once one validator would have to stake 32,022 320,000 ETH sorry, US. Dollars, which is great for security because then suddenly we would have like, our security assumption. And proof of stake, of course, depend on how much money is staked by the validators overall, but it would increase the barrier of entry to such a high amount that very few people could actually afford becoming a validator from the capital cost point of view.
00:03:20.072 - 00:04:25.440, Speaker B: And so that would not be what we're aiming for, to just make validating another easy income stream for the rich that's not accessible for everyone else. And since, as I mentioned before, it's not really an option to just make staking possible with any staking amount, the alternative is that we create staking pools where several people can come together and say, like, we want to run one validator together and everyone puts in part of the required capital. And the nice thing about when you have trust or Staking pools, as we're going to talk about in this presentation, then they can still be decentralized. So, like, having a pool doesn't mean, oh, I know Jeff is like a trustworthy guy. We'll just everyone give him their money and he'll run it. But no, we can actually do this so that everyone runs that validator together in a multiparty computation. And you don't need to fully trust that any of the guys is completely trustworthy.
00:04:27.380 - 00:04:27.936, Speaker A: Right?
00:04:28.038 - 00:05:27.120, Speaker B: And there's actually also a second very good reason to do this, which is that even if you are a single guy putting up the deposit, you might not actually want to run your validator on just one machine. Because the thing is, to run the validator, you need to have the validator secret on that machine. And that's, of course, a huge potential security risk because someone hacking that machine could just do whatever they want with that key and potentially get you slashed. So a nice thing is, if you have the technology to enable multiparty computation for validators, then that also means you can increase your security by distributing your key across, say, just three machines and say you want to run it in the cloud. You don't fully trust your cloud provider. You can have one on Azure, one on S Three, and one on the Google cloud. So you avoid having a single point of failure.
00:05:27.120 - 00:06:46.092, Speaker B: Cool. So let's come to the technology that makes this possible. So one thing is that we chose to in order to sign anything on East Two, we chose this signature scheme that's called BLS signatures. And basically the way it works is that it uses an elliptic group with a pairing. So what that means is that you have this pairing function, okay? So E, that pairs two elements from elliptic groups with this linearity relation. So, like, you can move this factor N from the first argument to the second argument, and you can also move it out of the pairing here. And so, like, a secret key is just an integer, and a public key is you multiply your generator, which is G one, by your secret key, and in order to sign a message, you multiply that message so that's a point.
00:06:46.092 - 00:07:49.272, Speaker B: You remap the message to a point in the elliptic group to your secret quee times M. And in order to check it, you use the pairing equation. So you check that the pairing of your public key and the message is the same as the generator and the signature. And the amazing thing about the signature scheme is that if you look at the signature checking equation here, it's linear in the public key and the signature. And this means that you can do something like you can add two public keys and two signatures, and that will still be a valid signature for the sum of these two public keys in that message. So basically, you can just add signatures in order to create a new aggregated signatures. And this is amazing.
00:07:49.272 - 00:08:55.620, Speaker B: And basically, it also enables kind of many things that we do in East Two in the first place. Or in a way, it enables Sharding in the first place, because it means that thousands of signatures can just be aggregated into one single signature that can be checked once using this pairing. And you know that everyone has signed this correctly. So this saves a huge amount of data and computation, but also at the same time, since it is linear, this enables something called shamir secret sharing. So the idea behind shamir secret sharing is like, let's say we have ten parties who want to share a secret. What we do is we make the secret a number, and we encode it by creating a polynomial that at zero has evaluates to that number. And we give every one of those ten parties, 1234-5678, 910, one point on that polynomial.
00:08:55.620 - 00:10:05.448, Speaker B: And now the degree of that polynomial determines how many of the parties you need in order to reconstruct the secret. So, for example, here I've chosen a polynomial of degree three, and we know that any polynomial of degree three can be reconstructed using four values. And so that means this automatically gives us a four out of ten signature scheme. That means you need four of the people and any four, no matter which four, could recreate that point at zero. And basically, due to the linearity of the BLS signature scheme, that means we automatically have the signature, the threshold signature scheme. And that means that we can design this M out of N scheme. So basically, that gives us threshold BLS signature, which is like the most important ingredient, because most of the work that you do as a validator is signing things like attesting blocks saying this was a correct block, this is the state of that Shard at that block.
00:10:05.448 - 00:11:16.832, Speaker B: And now we can do that in a decentralized way. Right? And now, coming to one point that was kind of difficult in this as we have, we have one element of the protocol that inherently needs a computation that involves your secret that cannot be solved using these aggregate signatures. And that's the so called proof of custody. What's the proof of custody? The idea behind the proof of custody is that you want to prove ownership of data. So what we want to do is that when you sign that you have seen a certain amount of shard data, that you also prove that you have seen that data, because otherwise you have this so called lazy, validator problem. That means that, oh, like, I've seen some signatures for this data, so probably it's fine, I'll just sign it without doing the work, and that's probably okay. 99% of the time.
00:11:16.832 - 00:12:09.548, Speaker B: But in the 1% of the time where you do have an attacker and who does something really evil. They could use those validators, those lazy validators to massively amplify their attack because they only need a small number of signatures of some data, for example, that's not available at all. And then all those lazy validators would sign it and suddenly you have this non available data that's signed off, which is a massive problem for the chain. So the way we avoid this is by having every validator, whenever they sign that chart data, generate one extra bit, the so called custody bit or custody root. And that's basically a mix of a secret. It's the secret here and the data at every data block. And then you basically so this is the original construction.
00:12:09.548 - 00:12:52.480, Speaker B: This is good for understanding how it works. You compute a kind of hash tree root of this whole thing and then you take the first bit of the root, okay? And basically only if you have that secret, you can compute it. If you don't have it, you can't compute it. Someone else can't easily compute it for you unless they have that secret. And if you give away that secret, then we can flash you. So that gives you a very strong incentive for actually getting the data because if you don't have it, it's very likely that your custody bit is going to be wrong. Now, the problem with this is how do you do that if you are in a validator pool, if you don't actually want anyone to have the secret that can get everyone slashed? Like it would be a massive problem if someone needs to have this whole secret.
00:12:52.480 - 00:14:07.304, Speaker B: And the way you yeah, okay, so this is summary. Yeah. The way we solved that problem is we found this new pseudorandom function that basically is very friendly to compute in a multiparty computation so that you can compute with many participants in a very efficient way as defined as using the so called legendre symbol, which is defined by so this is like the notation is a over p. It's one if a is a quadratic residue modular p. So if there's a number that squares to a modular p minus one if it's not. And then there's a special case that it's zero if p divides A. But in a way you could say that never happens because the prime we're using is so crazy big that this is like a zero hash or something.
00:14:07.304 - 00:15:06.540, Speaker B: It just doesn't happen. We normalize this to a bit because one and minus one are not really like a nice thing to work with in a protocol. And then the PRF is defined by just computing this lejonre bit of the sum of the secret and the data. And the nice thing is that this is super easy to compute in a multiparty computation. I'll not go over that in detail right now because the time for that is a bit short, but basically there's a nice way to just blind the whole thing and when it's blinded, like, you can do the actual computation in the open and then it's very easy to reconstruct the original result from that. Yeah. And then basically we can replace the proof of custody using this pseudorandom function and that gives us an NPC friendly proof of custody protocol.
00:15:06.540 - 00:15:51.604, Speaker B: Yeah. So I've been working on this Lejondre function for a while now because we really want to use it. The only problem with it at the moment is that it hasn't had a terrible amount of crypto analysis and so we're currently working on improving that. So one thing I wanted to mention here is we set those Bounties on improving the state so we have both asymptotic Bounties for finding any better algorithms and some concrete ones. There will soon be a smart contract for resolving these, so stay tuned. But you can already on Lejonderprf.org Bounties can already get those challenges.
00:15:51.604 - 00:16:25.830, Speaker B: If you find a solution, just email me and then you can also already claim them. Yeah. So basically you can win between one and 16 E for finding basically keys for Lejandre. In different instances, the smallest ones are designed so that with a few months or so of compute time you can actually solve them. So I'm expecting them to be solved, but would be really interested in how long it actually takes. The most difficult ones hopefully no one can ever solve. But yeah, we want to know if there are any algorithmic improvements that might change this.
00:16:25.830 - 00:16:30.260, Speaker B: Cool. Yeah. With this I'll hand over to Carl.
00:16:31.240 - 00:17:24.330, Speaker A: Cool. So moving on as to how we actually apply this, this is going to be a bit fast due to time constraints, but here we go. So there's a distinction to make here quickly between two ways of constructing pools. One is where you use economic incentives and custodial relationships to manage a pool, which is more like the case of rocket pool, whereas this is more designed to be run in an MPC where you want to be involved in the pooling structure. So you don't want to hand your ether over to a pool even if they are incentivized. So these are what you are required to do as a validator within E 2.0. These are the primary responsibilities with their frequencies and all of this is relatively cheap in terms of what needs to be done.
00:17:24.330 - 00:18:22.664, Speaker A: And as you can see, things like the MPC calculator lejandre shows up once in epoch and so these kinds of things are enabled by what Duncrot presented. I'm going to skip over that. So the obvious way to do this would be something like PBFT consensus for a pool because we need a system that is safe but not live. Because if you ever commit something that is not a supermajority of your nodes agree with, then you've run into the scenario where you can get your pool slashed. A relatively easy way of achieving this is actually just using the BLS signatures. So you set your threshold as two thirds of your pool size. And based on this, if you have to propose, one of the pool members proposes, but otherwise you see what your attestation duties are.
00:18:22.664 - 00:19:18.120, Speaker A: This is available if you have a view of the chain. You compute the appropriate custody bit and you sign an attestation only if this attestation you think is valid in your local view. And this is with basically the overhead of only BLS signatures plus the custody bits that Duncraud presented earlier allows you to have pooling, which is very cool. Unfortunately, that doesn't guarantee consistency because it's not a full consensus protocol. People can disagree as to the state of what the chain is at any given time. So basically you can have some structure that runs PBFT if you run into some unhappy case where the pool gets out of sync. You can also make this slightly more interesting, which is where you have some kind of metapool which exists between the pools.
00:19:18.120 - 00:20:07.310, Speaker A: So as a pool member, you don't only participate in your pool, but you participate in this larger metapool. And this allows you to use the metapool to have false attribution, where you prove to the rest of the pool that this metapool that someone did something bad in your pool. And then if one of your pool members got you slashed, got your pool slashed, because the slash is not burning all of the ether, it's only burning a portion, you can basically take all of the negative penalty and put it on that one person who is bad and give the other people their money back. And in fact, it may turn out that you can get more money out. So you may make a profit if one of your pool members gets slashed, which is pretty cool. It depends on exactly how you construct that. So yeah, that's the basic construction and how something like this would work within E 2.0.

00:00:00.410 - 00:00:00.958, Speaker A: You.
00:00:01.124 - 00:00:31.734, Speaker B: We are recording. So welcome everyone, to 1559, call number eight. Yeah, we have probably a lighter agenda than last time, so there's only been two weeks between the calls rather than a month, so we might not last the whole time. But yeah, first thing on the agenda was just status updates from the different research and implementer teams and and first one there was transaction pool management. I don't know anzgar, did you have any updates you wanted to share?
00:00:31.932 - 00:01:27.218, Speaker A: Yeah, I mean, I can give like a very brief update. So basically after this preliminary write up from last time, we kind of took a step back. I mean, of course I'm the main one in the team currently working on this, but then, for example, we had a call with Martin from Geth earlier this week and we went through some of the details of the Count Geth implementation just to check if our, like, I think I have some camera issues. Whatever. Our assumptions were basically good and it seems like we actually kind of were a little bit off on some of the small details. For example, turns out for the minor, there's actually some significant rebuilding of the sorting already ongoing after every single bug. And so seems like that's less of an issue now for one five nine to just basically also use a similar mechanism.
00:01:27.218 - 00:02:04.660, Speaker A: So it seems like basically it's a little bit probably a little bit more optimistic or a little bit simpler than it looked two weeks ago. But yeah, going forward. So the idea is if the next call only ends up being in a month or so, I would hope to basically have a full write up, including maybe some simulation work and so on done on a proposal for how to do the sorting. I think last time you were saying that, it all looks like this should be very doable, and I would preliminarily agree that seems like some details are still to be determined, but it should all be like sorting should not be an issue going forward.
00:02:06.470 - 00:02:27.450, Speaker B: That's really good news. Yeah, thanks. And it's great that the Get code base already resorts every block for miners. That's really good news. Yeah, go ahead with Eviction. So what are your current thoughts there, Angear?
00:02:27.790 - 00:02:58.390, Speaker A: Yeah, sure. So I mentioned the kind of the mining because that's where there seems like we were a little bit off on the exact details of Get. Although, to be fair, again, we talked with Martin. He's more of an expert on the mempool side of things. We also want to reach out to the people within the guest team who are more like responsible for the mining side. But I'm reasonably confident that this is actually now very correct. Yeah.
00:02:58.390 - 00:03:51.880, Speaker A: On the eviction side. I think basically the only change for now that I had so far was that I think I'm a little bit more optimistic on just basically using a very simple heuristic that might be very inaccurate, but just precise enough. Because again, for mining it's really just important that the top end of the mempool stays very precise and then if at the low end there's some Eviction, that's not ideal. Ordering wise, that doesn't really matter. So you can get away with very efficient implementations like only resorting once every so often and so on. I think the main focus on the victim side really will be testing it under a huge variety of different base fee behaviors just to make sure that under all of those it hits some minimum stability, basically.
00:03:54.010 - 00:03:56.520, Speaker B: What are some heuristics that you're thinking of?
00:03:57.550 - 00:05:15.586, Speaker A: Well, again, something basically with a very simple way of calculating some expected future effective mining tips. So for example, you take the current base fee and then you take for example, historically, maybe the mempool always keeps track of the variability there within the last, I don't know, 24 hours or something. Or there could be different approach, but then you just do like a very simple for example, you just do like 50% of the current base fee plus like 25% of one sigma above and one sigma below, basically, just to give you some idea. Right, again, that might be as simple as that sounds like that might already be good enough that it's not just the count base, but you also take into account like a higher one and a lower one or something. And then you just update that maybe even just once every so and so many blocks, as long as you can do that efficiently and as long as basically that is good enough that on the high end your sorting is never perfectly precise. But again, right now I'm not confident enough that this would work already, but that would be currently one of my candidates for a very simple heuristic that might be efficient but still good enough, if that makes sense. Thanks.
00:05:15.768 - 00:05:16.914, Speaker B: Yeah, that does make sense.
00:05:16.952 - 00:05:17.540, Speaker A: Yeah.
00:05:19.430 - 00:05:34.120, Speaker B: Cool. Anything else on the transaction pool management? Okay. Next up, Abdel. Do you want to give a quick update on the large state testnet generator and where we're at?
00:05:34.970 - 00:06:30.380, Speaker C: Okay, yes. So we currently have set up the new testnet. So this will be a proof of work testnet and the goal is to have a state comparable to mainnet. So so far we have generated 100 million accounts and we are now using a smart contract and we aim to generate 100 million entries in this smart contract. And yeah, when this will be ready, we will share the URL of the different nodes and the block explorer and the ETSAt so that other clients can think of this new testnet. And yeah, that's pretty much it. So we have four nodes running and the generator is still running and I will share everything when it will be ready.
00:06:31.870 - 00:06:32.906, Speaker B: That's it.
00:06:33.088 - 00:06:34.026, Speaker D: Cool. Yeah.
00:06:34.048 - 00:07:20.700, Speaker B: And I think for that, once we have the testnet up and running on Besu and then we get nethermine and get syncing to it. I think we should probably just schedule a time to then spam it with a ton of transactions and gather metrics from all three clients. Hopefully we can gather metrics and it doesn't just fall over, but if it fall over, we fix it, try again. But I think, yeah, if we have at least one or a few shots of saying, look, we spammed the testnet for 2 hours with transactions and the node stood up. I think that's more than the worst case we'd see on main net because in 2 hours the base would probably go up like 100,000 x or a million x, and it's just not realistic to even do such an attack. Yeah.
00:07:23.230 - 00:07:26.918, Speaker E: Hi, it's Ramil. I just joined it. Sorry for being late.
00:07:27.094 - 00:07:34.250, Speaker B: No worries. Any thoughts, comments on the testnet?
00:07:36.350 - 00:07:50.580, Speaker D: No. I think it'll be important to make sure that every single node is publishing transaction from their own respective transaction pools. So we know that we can not only consume the transaction node, but also that every single one can generate them.
00:07:51.670 - 00:07:58.610, Speaker C: Yeah, so we set a very low difficulty so everyone can be a minor on this testnet.
00:08:00.390 - 00:08:06.786, Speaker D: So minor one thing, but also that the client can be a source of broadcast for the transaction.
00:08:06.898 - 00:08:07.958, Speaker C: Yeah, that makes sense.
00:08:08.044 - 00:08:12.134, Speaker B: And I think the tool abdomen I hope I get it.
00:08:12.252 - 00:08:16.090, Speaker C: Client agnostic. Yeah, you can use it on every client.
00:08:16.430 - 00:08:20.410, Speaker B: So maybe when we schedule the things, like every client can kind of spam the network.
00:08:21.890 - 00:08:37.060, Speaker D: We've been using your tool already for spamming the network when we were working with Bezu network on this current solution. So we were pushing transactions to test that problem before and it's all fine and we can broadcast. Nice.
00:08:39.590 - 00:08:58.570, Speaker C: And yeah, I will update also the web front end to add the list of the different nodes and the type of the node. And if you give me some URL of netermind nodes, I will add them to the front end so that the user can choose to which node to send the transaction.
00:09:00.270 - 00:09:00.778, Speaker D: Perfect.
00:09:00.864 - 00:09:01.500, Speaker A: Yeah.
00:09:02.590 - 00:09:45.986, Speaker B: Cool. So yeah, I suspect we'll probably have the testnet filled up sometime over the holiday, so early January. We should be able to share the information and then it might take a week or something for people to sync to the testnet because it's big. And then yeah, sometime in January we can probably run this kind of spamming test. Cool. Any other thoughts, questions on that? Next thing on the agenda? I think I just copied this over by mistake, but like EIP 20 718. I think we should wait until after this testnet thing is done and then add 20 718 support to all the specs.
00:09:45.986 - 00:09:56.060, Speaker B: It won't change anything for performance, but at least we'll get the actual testnet data before we have everybody changing their specs. Does that still make sense for people?
00:09:58.270 - 00:10:05.550, Speaker D: Yeah, sure. We still want to run some transaction spamming after adding it, but just a formality.
00:10:09.890 - 00:10:18.260, Speaker F: Do people in here have a preference or feelings about SSD versus RLP? Since it's almost certainly going to come up again?
00:10:18.950 - 00:10:20.130, Speaker D: No preference.
00:10:28.340 - 00:10:58.652, Speaker B: Sorry, I couldn't find the mute button. The only thing I guess is on the last core devs, we talked about maybe doing SSD as the dev p to p layer first and then bringing it to consensus. So I don't have a strong opinion, but I wouldn't want to go against the rest of all core devs on having SSD in 1559 if that's going to be a blocker too, actually.
00:10:58.706 - 00:11:37.960, Speaker D: Sorry. As for EP 1559, obviously I would like to keep it as separated from other things that we are adding as possible. So generally adding to 718 and adding SSZ, adding SSD itself may add something like two months delay to EP 1559. So maybe for that reason, I have strong preference for RLP. I thought that you were talking about 2718 in general, but yeah, if 2718 is bundled with 1559, like it has to be with 1559, then I have strong preference for LP. I generally have a preference not to bundle IP 1559 with 2718.
00:11:40.700 - 00:11:45.240, Speaker F: You want 1559 without 20 718?
00:11:45.740 - 00:11:47.150, Speaker D: Ideally, yes.
00:11:48.720 - 00:11:51.660, Speaker F: Even though 20 718 was going in Berlin.
00:11:53.520 - 00:12:13.430, Speaker D: As I say, I would like to keep IP 1559 separate from the Berlin discussion. Berlin discussion can be delayed massively. I mean, it keeps being delayed. I want to keep IP 1559 totally separate if possible. I mean, obviously if you have already deployed, then it will be yeah, okay.
00:12:14.920 - 00:12:15.284, Speaker A: Yeah.
00:12:15.322 - 00:12:45.432, Speaker F: So I'm like 98% sure 20 718 is going to make it into Berlin, which means that we'll want 1559 to be 20 718. And if 1559 is 20 718, then we have to decide whether we're going to do what we said in court devs, which is talk about SSE again after Berlin. And that means that discussion is going to be around one five generally target.
00:12:45.496 - 00:13:21.288, Speaker D: IP 1559 before Berlin. And this conversation, I would keep it like we don't have to think about Berlin because Berlin might be delayed. I mean, I see what's happening there and there is every court of call. We are adding one or two issues that are highly contentious recently, like Ssdrlp. It will take time, the 2718, it will take time, and people are not on board and they don't feel like there is so much of a push on Berlin. So I would just keep it separate. I mean, on the Berlin calls, like all core devs, I'll be pushing for Berlin to happen as fast as possible.
00:13:21.288 - 00:13:37.230, Speaker D: On the IP 1559 calls, I would aim at pushing for IP 1559 to happen as fast as possible. And with both of those, they can come very happily together with everything in place, but I wouldn't like them to wait for each other.
00:13:41.860 - 00:14:28.780, Speaker B: I think that makes sense. I suspect that we're coming towards the end of Berlin and there's like a very high probability that it's ready to ship before 1559. That might be wrong, but assuming it's not, I think then the path of least resistance is adding 20 718 for 1559 because we already have 20 718 in the code basis to handle 29 30 and not doing SSZ. Because I think for SSZ, like Peter from Get Point last call was we should probably do it on dev P to P. We're going to find bugs. If we do it at the networking layer, we're going to fix those bugs. That will take six months, nine months, and then maybe once that is done, we're ready to actually move it into the protocol or consensus layer.
00:14:28.780 - 00:14:56.150, Speaker B: And I think that's fine. And if for some reason there is a decision made on all core devs that we switch everything to SSZ now, then we'll have to do it for 1559. But I don't want to take the path that's opposed to all core devs. Like if everybody's switching to SSZ, you don't want to be like RLP and then slow things down and vice versa. I don't want to slow 1559 down because we want to do.
00:14:58.360 - 00:15:27.170, Speaker D: When I say there is no preference for SSZ RLP, it's because I know that we already have it right. But I also know that implementing SSZ and understanding it and testing it took me proper time. It was not a trivial task. And I think that there is no chance it will be faster than a few weeks on GEF side to properly test it and implement it into the code base. Even if you have libraries for.
00:15:29.300 - 00:15:30.048, Speaker C: You.
00:15:30.214 - 00:15:46.100, Speaker D: Maybe I'm not thinking about the fact that Prism has the Go Library for SSD and it might be more general because our approach was a bit more optimized and make it not reusable. So it might be that the Prism library is very reusable.
00:15:49.340 - 00:16:05.470, Speaker A: Matt, I was under the impression that you were currently working with the guest team together on 20 718. Could you maybe give like a very brief summary? What your take there is? What do you think? What's the timeline there? How does that side look?
00:16:06.880 - 00:16:52.600, Speaker G: I feel like Berlin is locked in. It's just a matter of getting the client test that's tested and decide on a fork block. I really think this is going to happen in the next three months, which I believe is still going to be far ahead of 1559. I think the original point for the question though was just discussing like we decided to go with ROP over SSE for the Berlin Hard fork and this is a discussion that is going to come back up after Berlin because it is a desirable thing to have SSD in the protocol. And unfortunately, the more things that we add in that relies on RLP, the more complicated it may be to do SSD at some point.
00:16:58.610 - 00:17:18.040, Speaker A: How much of lock inward would a decision on the one five nine side for RLP versus SSC be. So let's say we go with RP for now, but then it turns out that Mainet will already want us to or will one five nine to arrive with SSE instead. How much of a delay would that cause on the one five nine side?
00:17:19.690 - 00:17:20.934, Speaker E: Yeah, I don't really have a good.
00:17:20.972 - 00:17:57.790, Speaker G: Feel for what it would take to transition 1559 from RLP to SSD. I think that generally we have complete control over these things in the protocol. The one thing that we are introducing as like an external API is how we sign 1559 transactions. So if we sign those with RLP and buy switch to SSD that means we also want to change how we sign. Then that's something that would be very difficult to change because we would already start having wallets and external providers adopting that signing mechanism.
00:18:03.060 - 00:18:09.300, Speaker D: So when you say SSD, you mean even serializing transaction objects with SSZ?
00:18:11.400 - 00:18:18.040, Speaker G: Yeah, serializing transaction objects and using the virtualization functionality to create the roots in the block.
00:18:20.220 - 00:19:06.250, Speaker D: That's a very big change. It's a big change because it is affects all the web free components, all the smart contracts. This will be like a massive delay if we go for it now. We already have a method of expressing keep 1559 transactions in a traditional sense with just like two additional fields and I feel like this change is far, far from being significant for adapting the current processes. SSD would be one thing that would probably delay EEP 1559 the most from the current state of things.
00:19:08.300 - 00:19:58.648, Speaker A: Yeah. So I think I would very much agree in the sense that I think one five nine should not try to basically be taken as an opportunity to also push ahead other changes together with it. So there's no reason why one five nine should also try to push ahead SSE. Right? If if it's ready and SSE is not, then yeah, of course that shouldn't be part of it. We are in the unfortunate kind of position of course to make basically like preliminary decisions on what we assume Mainet will expect from one five nine once it's ready. And so I don't know, I think we basically have to try to keep the effort minimal that it would kind of take either way to walk back on these decisions if it turns out that we made incorrect assumptions. So I don't know.
00:19:58.648 - 00:20:22.624, Speaker A: For example, for me right now seems like the maximum likelihood situation would be that we arrive after 2000 and 718, but before SSE. But of course could be either way. Could be like that we arrive before even 20, 718. I don't know. Seems unlikely but possible. Or even after SSC. Again in all cases of course if that delays one five nine by months that's not a good place to be.
00:20:22.624 - 00:20:30.276, Speaker A: So yeah, I unfortunately don't really have a good solution but yeah, that is important to kind of keep in mind.
00:20:30.298 - 00:21:38.260, Speaker F: So the reason this keeps coming up is because while I agree with I forget who just said it, that it's better to not bundle things like get SSD in first and then switch transactions over to it. Historically, that has never worked with Ethereum that I know of. The problem is there is a subset of the core devs who do not like including changes unless they are needed for something. And so adding SSZ before SSZ is needed, there's a good chance that means we will never get SSZ in. And SSZ by itself gives us a lot of big wins down the road, which we'd like to have, but we can't get that in until we have something to put it in with. And so no matter what, I think that if we want SSZ to go in, eventually it has to bundle with something. And to stress the point that my client made, the longer we wait, the more painful it will be to do that, because we'll have more and more stuff, particularly more and more things that are being signed by third party tools.
00:21:38.420 - 00:22:15.124, Speaker B: And I guess before that's kind of a core dev discussion, though, because there's not just 1559 involved here, right? Like, for example, there's account abstraction is the other one. Right. So there's like this meta problem of like, yeah, where's the line for SSZ? Where do we want it to be? And for sure, wherever we draw that line is going to slow down every other feature by like, I don't know, call it three months optimistically. Right. But I don't think we can do much at the 1559 level to change that. Right. We can say on the core devs call, this is the stuff we maybe want before.
00:22:15.124 - 00:22:39.550, Speaker B: Or this is the stuff we absolutely don't want before because it'll be such a big piece of technical debt to deal with that. It's not worth it because it just feels like there's so many things that are coming in that might touch that that we probably want a higher level solution than just do we do 1559 or this deep with SSD or not?
00:22:40.400 - 00:22:54.080, Speaker F: Yeah, that's fair. I'm okay with not discussing it here. The gist I got is that people are very hesitant on anything that will delay 1559. And I generally share that sentiment and definitely appreciate.
00:22:56.120 - 00:22:56.870, Speaker A: It.
00:22:58.280 - 00:23:18.250, Speaker H: Yeah. Just my perspective from trying to deal with some of these things and I know this is just coming from an opinion place, not from like a knowledge or fact place, but that there probably will be something that needs to do what you're saying, Micah? But it probably shouldn't be 1559.
00:23:21.340 - 00:23:22.730, Speaker B: To do what exactly?
00:23:23.420 - 00:23:33.388, Speaker H: To put the we need SSC for this. There'll probably be something where we kind of have to decide that we need it, even though technically we could maybe not need it.
00:23:33.554 - 00:23:35.100, Speaker B: The e two verge.
00:23:35.520 - 00:23:46.576, Speaker H: Yeah, but 50 and 59 shouldn't be the one to do that. But it is a good idea to be thinking about what should be down.
00:23:46.598 - 00:24:39.584, Speaker D: The line, but let's keep it then on the all four depths here. Our goal should be to deliver EP 1559 and I think the best thing that we can do is to ensure that it's ready and tested for any of those scenarios, like whether it's with 20 718 or without, whether it's with SSD or without. And we have one solution that we're testing without those changes and it means that we can move it all the way to the end where we have a ready testnet with all the clients saying we are capable of handing Keep 1559. And this is the spec that we are working with. So the people who build tools can already start adjusting their tools and we can show them also like two alternative paths. That here is the simple path. Now this is how you have to adjust the tools and these are the alternative paths.
00:24:39.584 - 00:24:59.640, Speaker D: Pay attention to what happens to 2718, pay attention to what happens to SSD because maybe you will have to adjust those tools a bit more depending on whether those go before. But people will be more prepared, they will already start looking at it, implementing first version and I think overall everything will go together faster.
00:25:04.960 - 00:25:21.410, Speaker B: Yeah, that makes sense. So tabling the encoding discussion for there, I guess Barnaby Thomas and anyone else, or Ramil. Do any of you have updates you wanted to share?
00:25:25.540 - 00:26:18.470, Speaker D: Because I think that we're planning the next call for 14 January. So I spoke to Mihao a lot recently and he was working on this analysis of the potential attack scenarios when you not really attack on the network in general, but just the attacks where you slightly modify the base fee. And this is because we are exploring the cost of manipulating the markets if you introduce the gas markets to the equation. And he has lots of results already calculated with various different network parameters but was not ready yet to share it today. But he's very confident about sharing it on 14th. So he'll be able to look at this jupyter notebook numbers and all these charts and show you actually how it behaves when you want to push the prices down or push the prices up.
00:26:20.040 - 00:26:23.110, Speaker B: That's really cool. Yeah, looking forward to seeing that.
00:26:26.040 - 00:26:43.980, Speaker E: I would like to share update about Pull request in the get. So we review it with the comments from Abdel Hamid and we are going to start working on it on Monday.
00:26:46.320 - 00:27:43.500, Speaker B: Cool, that's great. And I think, yeah, I guess once those are addressed, it might make sense to get a more thorough review from the guest team. I know that basically the quilt team has shared it with them, but I think once we have the code in a spot where it's up to date with the latest spec, it'll be valuable to get their thoughts. And I think one thing I believe Joseph you shared this with me was that the Get team would like to see it kind of split up between the consensus changes and everything else. Was that right? Yeah. If 1559 could be phased in two phases, one with consensus, just the consensus changes, and then the second one where the mempool changes and other non consensus changes would be that was a suggestion from Martin.
00:27:43.920 - 00:28:05.270, Speaker A: Yeah, just to clarify. Of course. Of course. That's what you were saying as well. But just to clarify, it's not, of course, about an actual two phase approach, but it really just is like a logical structural split into two PRS. So they still would have to arrive at the same time and are dependent on each other. But yeah.
00:28:07.960 - 00:28:22.890, Speaker B: I guess. Ramil, what's, like, the best does it make sense for you to do that now? Do you want to address all of the spec level comments first? Yeah, I think whatever you think is best to get to that.
00:28:29.120 - 00:28:35.870, Speaker E: So we will update to the lattice spec version again.
00:28:41.060 - 00:28:45.360, Speaker B: Okay. And then yeah, we can look at split line yet into two PRS.
00:28:45.960 - 00:28:56.820, Speaker E: Yeah, actually, it's not clear for me for now, 100% how to implement that splitting, but I think we can discuss it later on the chat.
00:28:57.480 - 00:29:05.816, Speaker B: Cool. Yeah, that makes sense. Anyone else had updates they wanted to share?
00:29:05.998 - 00:30:01.930, Speaker I: Just shared on the chat paper that my CofO has presented in a workshop recently. It's very preliminary work, but it's kind of looking at 1559 as a dynamical system. So trying to get some ideas on how fast it converges, what are the, let's say, guarantees that we can find, and perhaps using that as a springboard to look at the more controlled theoretic questions of, well, how fast should the updates happen? I know, Tim, you've sent out a call to people who might be interested, and I think this work might be interesting to them as well. And what I discussed also two weeks ago is follow up to Michelle's notebook on the transition. I have a pretty final draft. Just getting it a last review and I'll be ready to share it either end of this week or next week.
00:30:11.600 - 00:31:17.250, Speaker B: Cool. Anyone else have updates? If not, I'll just kind of share my screen real quick to go over to check this, but I think we've covered a lot of it already. So just at a high level in terms of implementations, sand teams are working on it. Open Ethereum worth noting that they have a job posting out to hire somebody full time to work on 1559. So if you're a rust developer and you're interested in working on 1559, please apply to it's a posting through Gnosis, but to work directly on Open Ethereum aside from that. So just in terms of the open issues, denial of service risk actually, I've been thinking about the Dos risk more and I suspect that 1559 might make things better and not worse. And one of the reasons for this is that today on the network, if you just spam the network, your cost is constant for doing so.
00:31:17.250 - 00:32:14.020, Speaker B: If you're like a minor deciding to dos the network, you can include your transactions kind of for free in your blocks. Whereas under 1559 what's nice is even if you were to spam the network and aim to not increase the base fee to keep blocks just 100% full, the rest of the demand for the network will mean the base fee increases. And that means your attack will get more expensive over time, which is a property we don't have today. And also it kind of blocks that hall of miners being able to dos the network for free. So coupled with stuff like 29 29 and just clients being generally more resilient towards the large states, I think it's not as big of a risk as it might have been thought to be. So yeah, that's just quick update there. It's not formalized at all, but it's just like my intuitions of how it would play out.
00:32:14.170 - 00:33:21.800, Speaker D: Yeah, so timid. So exactly what Miha was working on. He was analyzing the cost of attack when you want to spam and make the blocks filled by just publishing transactions with very expensive transactions and obviously very quickly, all the rest of the network stops, including their transactions, and you're the only one who has to pay for that. Just to share some of the results that we've seen, raising base fee from 50 to 500 required some pretty solid participation of the miners, like at levels of around 40% to 48% of total mining capacity. And it was with some ranges of success ratio, like between one and two. So 20% of success with cost of around half a million dollars for ten times increase in gas prices. So yeah, pushing it up was quite inefficient, quite expensive.
00:33:21.800 - 00:33:30.700, Speaker D: But also it would be great to see how the network behaves if miners actually did not participate in this kind of attack, but people actually push the transactions.
00:33:32.320 - 00:33:59.364, Speaker B: Yeah, looking forward to seeing that. But yeah, I think this was like, I guess for me, the biggest showstopper potentially for 1559. And I feel like we're heading to a spot where it's not a major issue anymore, which is great. So transaction pool management, we already covered this, so we're working on the solution. I think we should be good. There the base fee update rule. So, like Barnabay just said, I've been reaching out to different people to see if we can improve on it.
00:33:59.364 - 00:34:37.952, Speaker B: I don't think this is a blocker for 1559, so worst case, we just ship it with the current update rule. And if somebody takes a year for somebody to spend time to come up with something better, we'll update it in a future hard fork or when we go on e two. But it's not a blocker in terms of testing, we haven't made a ton of progress. There, but I think it'll kind of resume once 1559 kind of is in more of the all core devs process rather than this sidetrack. And we wrote Abdel, I say we, but Abdel wrote a couple of EPS for the JSON RPC spec. And there's more to do. It's not rocket science, it's just work we have to do.
00:34:37.952 - 00:35:16.590, Speaker B: But I don't think there's a ton of value in doing it now because of just how early it is. And in terms of testnets, basically, I think we're combining these last two into one. The last two things we haven't tested. So just like a multi client proof of work testnet and then a large state testnet. So if we can get the two of these done, that'll be great. And it feels like in terms of R D, there's a lot more stuff that's going to be coming. But I feel like Tim Roughgarden's analysis was like the last big blocker that we had.
00:35:16.590 - 00:36:16.800, Speaker B: And now I'm pretty confident we've done more analysis of 1559 than probably any change that's gone onto the network. And they all modular, some small issues. Everything seems pretty positive. And finally, just in terms of community outreach, we've been a bit slow of doing another kind of round of feedback. I think personally, I would do maybe a more aggressive round of reaching out to projects once we have another testnet that's more usable and that we can point people to and have some documentation for it. Yeah, because in the meantime, it feels like the main thing people were asking us on these calls was like, when can I try it out? How can I try it out? So I would just wait another few months until we have something a bit more stable that we can share. And yeah, that was the last thing on the agenda.
00:36:16.800 - 00:36:30.610, Speaker B: The next call I had tentatively put January 14 because I think we have an all core devs call on the week of the Eigth. So it's the off week from that. Does that generally make sense for people?
00:36:31.620 - 00:36:32.392, Speaker C: Yes.
00:36:32.566 - 00:36:45.718, Speaker B: It cool. Anything else anyone wanted to discuss or bring up? Okay, well, yeah, thanks for making the time, everybody.
00:36:45.884 - 00:36:46.406, Speaker D: Thanks.
00:36:46.508 - 00:36:47.270, Speaker B: Bye.
00:36:47.850 - 00:36:48.760, Speaker D: Thank you.
00:36:50.010 - 00:36:52.580, Speaker G: Cheers. Good.

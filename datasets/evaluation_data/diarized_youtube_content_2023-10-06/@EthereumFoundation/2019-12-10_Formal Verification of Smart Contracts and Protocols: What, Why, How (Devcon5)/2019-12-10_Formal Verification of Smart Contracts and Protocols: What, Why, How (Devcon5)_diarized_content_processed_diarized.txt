00:00:14.570 - 00:01:19.058, Speaker A: Thank you everybody for being here sorely and cup coffee. So this talk will be for this seminar will be given by runtime verification and Microsoft. You should benefit from Microsoft and we try to give you a broad overview of what you can do in formal verification. And then we'll dive a bit into our own techniques and approaches. But to set a mood for the seminar, let me start with a famous quote by a famous person, Daitra, who said that program testing can be used to show the presence of bugs, but never to show their absence. So what that is telling us is that while testing is very useful, we cannot rely entirely on just testing if what we want is to prove correctness of our program. To prove correctness we need formal methods, which are mathematically grounding techniques to model and reason about systems.
00:01:19.058 - 00:02:50.706, Speaker A: And before we dive deeper into formal methods, I'd like you to also see another quote by another famous person, Tony Ward, both Tony Rohr and Daisler, but during the word which is the best award we can get in computer sciences, and he said that the job of formal method is to elucidate the assumptions upon which formal correction depends. So if somebody tells you that hey, I formally verified or I formally modeled my system, what that really means, what that should mean is that they clarify all the assumptions under which the property they play. Indeed. Overview of our presentation today we are going to give an overview of formal verification, and then we'll dive deeper into our approach based on the K framework. Then we'll show you some examples of how we formally verify smart contracts, and we'll use three different approaches that we want to put together under one umbrella. And then we'll conclude. So what is formal verification? At a very high level, formal verification can be seen as taking as input a program or a system or a protocol, something that computes, something that evolves from one thing to another and does something that's called as a program p, and a property or some properties or specifications which are properties of this program p that's called as s.
00:02:50.706 - 00:03:54.310, Speaker A: And what we'd like to know as output is whether the program p indeed satisfies the specification s, meaning that no matter how the program is executed, under node, under whatever input, and under whatever environment, and under whatever node determinism that you might have in that program, the program will satisfy s no matter what. Or if you cannot prove that, then you like to have a so called counterexample. You'd like to have some run or input, some environment in which p violates s. And that's very useful, because then you can use that into the program or the specification. The typical advantages that we as a community know that formal verification has are the following. So obviously what you really want for the form of verification is to be able to play that your program is correct. But that depends a lot on many factors, on what properties, what you mean by correctness.
00:03:54.310 - 00:05:16.802, Speaker A: And in general, what you really can claim is that your program doesn't have certain vulnerabilities post deployment, and those vulnerabilities are whatever you specify in your specification, forgot to specify certain vulnerabilities, then the program may still have that problem. In the extreme case, you can prove that your program satisfies the specification, true for the empty certification, and yes, you satisfy it, but that doesn't mean much. Also, former verification helps you find very subtle bugs, bugs that you haven't thought about when you wrote your program initially, because formal verification will enforce to go through all the execution, all the behaviors of the program. And because of that you will know when. It will tell you when a certain corner case or a certain case that you forgot about still learning to your code. Also, it helps you focus testing and auditing efforts, because if you have functions in your code and you verify, formally verify 19 but you couldn't verify one of them, you know that you should look at that, you should investigate that more deeply. And also, if you use it routinely, if you use form of verification routinely, you have tools, and there are tools that you can use on a regular basis, then that can help you in your everyday development of your code.
00:05:16.802 - 00:06:02.574, Speaker A: You start thinking actually differently about your code. You think of the code through the abstract lengths of the properties that the code should satisfy, and because of that you write better code in the end. So that's probably one of the least known benefits of formal verification. What I'd like to do next is to go through the entire spectrum of formal verification or formal analysis, or not even formal analysis. Tools and technologies, techniques, methods for programs, and I would like to use a metaphor, metaphor, present them. And I warn you up front that it's going to be very rough approximation of the reality. There is an entire universe of work.
00:06:02.574 - 00:07:06.286, Speaker A: We cannot minimize all that with just a couple of slides, but I think it will give you an idea that you can go as deep as you want with formal analysis and formal verification, but at the same time you can stay very light and you have to find your right balance where you think you should stay. So at the minimum, so if you turn the dial to the left, you get very cheap methods, but at the same time very little assurance as you go to the right, you have more expensive methods, but also you get more and more assurance. So the minimum you can do, and you should do is test. Have lots of tests for your program, ideally giving you, for one contract, even complete coverage. In reality, in real life, in real software, full coverage is very rarely achievable. But in smart contract, that's not too hard because they are smaller. But keep in mind what Geistra says, that no matter how heavy you test, you are still not going to get any formal guarantees, any assurance correctness.
00:07:06.286 - 00:07:37.790, Speaker A: You have more and more confidence that your point is correct, but you don't know if it is correct indeed. So that's why we say that. I think it's a minimum. Once you have lots of tests, then you can move further and do what I call here runtime monitoring. That comes under lots of names. Some people call it runtime verification, others call it runtime assurance has lots of different names. So what runtime monitoring, really what I mean by random monitoring on this slide is that you can run the program, but now observe its execution.
00:07:37.790 - 00:08:06.998, Speaker A: Don't look just at the relationship if it passes that or not. Look at the sequence of the behavior of the program, and you can monitor actually the program as it runs. And if you see any violations, then you can report errors. An example could be division by zero. So on EVM, division by zero is fine, but you may not complete. So then you can monitor for division by zero or other properties. Could be that you want to revert before the end of a function.
00:08:06.998 - 00:09:05.306, Speaker A: If you have an overflow during the function, you have to look at the sequence of steps and you can monitor them. And I'm putting it right after testing because it's pretty easy to achieve. Once you have a running system, of course, you have to implement your program somehow to observe what's going on, but that's much lighter than the other methods later on. However, like testing, runtime monitoring does not ensure correctness unless you combine it with more complicated techniques like backups and poorly correct backups. But we don't go into that here further. You can do static analysis, static analysis. There is a large variety of static analysis techniques on there, and I strongly encourage you to use any static analysis that you can put your hands on, because they give you immediate feedback about your code, that you can use the quality of your code.
00:09:05.306 - 00:10:02.614, Speaker A: So static analyzers, typically they scan your code and they look for known patterns, bad code for bad coding practices, code that you should not write. And the advantage of such tools is that they are typically very fast. You get immediate feedback. They show you where they color your code, tell you exactly where problems might be in your code. The problem with static analysis could be that they meet certain errors that they are not trained for, or they don't implement, or they may give you false alarms because they have to make trade offs. You can never prove a program correct statically complete automatically, so you have to make some trade offs. And one of the trade offs that canalize these tools make is to give you potential errors in your, and then when you investigate them deeper, realize that's actually not a problem, because I know why there are some additions.
00:10:02.614 - 00:11:01.562, Speaker A: The static analysis tool keep the analyze the code, scan the code, but they don't go deep into the semantics of the programming language necessarily. If you want to go deeper, actually into the semantic programming language, you do what we call symbolic execution, and what symbolic execution is. You're still running the program, but you run the program with inputs which are not known. If your function has two inputs A and B, you run the program with inputs A and b without knowing exactly what inputs are. And as you execute the program, you keep track of all the logical constraints and what's going on in the running program. And the advantage of symbolic execution is that you cover a larger state based or stable behavior setting program, essentially, in theory, all possible behaviors. The problem now starts being that it doesn't scale.
00:11:01.562 - 00:12:19.020, Speaker A: At some moment it will be very slow, or at some point you have to make compromises because you don't know whether certain condition works or not. So if you want to make it automatic, then you have to again accept some trade offs. And one of the trade offs that is accepting combination with symbolic execution is what you call bounded model checking, where you explore all the program behaviors up to a certain bound, let's say up to two iterations of each loop, or up to two recursive calls for each function as normal. And once you put such limits, then you can explore exposing the state space. But the problem is that you import yourself a finite smaller state space, which means that you may lose errors. If you want to be absolutely sure that you don't lose any behavior, then you have to go into formal verification. And here I'm calling it state of the art verification, because this is what most of the people who do formal verification understand by verification, and probably most of the people also in this room, which is the fact that you have a programming language and that programming language provides some specification language, another language on top of your existing language that allows you to specify properties of interest.
00:12:19.020 - 00:13:21.260, Speaker A: And then your tool, your formal verification tool, analyzes all the behaviors of the program against those specified properties. And with some help, eventually you may be able to prove maybe some additional hints, additional demos, you may be able to prove the properties correct. So this is the conventional program verification, and I say conventional, because what you're going to see next goes beyond that. So the limitation actually of the traditional verification approach of programs is that you tend to be stuck with one particular language or version of your programming language, and more importantly, one particular version of your specification language. You think that some language constructs are really important to specify, or some specification construct, like always, eventually really important. So you add them into your language for properties. But then later on if you need something else, you're out of luck because the tool doesn't support.
00:13:21.260 - 00:14:21.678, Speaker A: You have to start going into deeper reasoning and deeper analysis of your system. Then you go to formal modeling and validation of your model, meaning that you take your program and you model it in some other system, a pure improver or interactive verification environment, where you can now reason completely mathematically about the program, forgetting any programming language, you don't care about the programming language anymore. You define a transition system in your more abstract environment, and then you can reason about it. There can prove important properties there without taking the code at all into consideration. And that's really useful because it helps you find high level errors potentially in your code that may have been hidden in the actual code. So when you are more abstract, you can see core abstract problems. For example, you can see design issues of your business logic of your entire contract at that.
00:14:21.678 - 00:15:10.794, Speaker A: So many customers we work with, we take them through the various steps, and at some point we get to this point and they say, oh, actually we really want that. So once you understand the value of modeling, then you really like to go that path. But now you have a gap between that model and the actual code that needs to be filled. And this is what takes us to the final stage, which is verification or proving your code correct using frameworks. You take a programming language, a programming in a programming language, and you have a formal mathematical model of what you meant to be implementing your code. And now you have to prove that these two are, that the programming need implements the formal model. And to do that you need another language language which can set both of these and do all the groups.
00:15:10.794 - 00:16:18.790, Speaker A: And you may have heard of system like or Isabel. And the system that we use, k, falls into the same category, right? So as we go from left to right, cheaper, less assurance spending, but more assurance, and ideally we'd like to do all this automatically, but unfortunately it is not possible. There is only that much that we can automate, and traditionally we can automate almost everything up to symbolic execution and even some part of symbolic execution. But when you try to go beyond that, a human expert tends to be needed, unless you restrict yourself to very simple properties. So there's a general picture for program analysis, you cannot have everything free or automated, but nevertheless you should use everything that is automatable in your contract. If you are trying to see high assurance, and should be, then you should use all these tools. So what we intend to do today is to show you how we approach this spectrum of common artist tools from angle.
00:16:18.790 - 00:17:02.210, Speaker A: And our angle is the K framework. The K framework is great in what regard? Expressiveness. So with putting the right hands, you can do almost everything you want with it. But on the other hand, many people find it heavy to use because of the heavy notation and lack of automation. So our challenge here is how can we automate as much as possible in what you can do with a language framework like K. And here we look at two types of automation, automation that we know about things that we have done with K, and we know that those can be done better and faster. And that's what we try to do within the Firefly tool that Everest will talk about.
00:17:02.210 - 00:17:36.910, Speaker A: So let's say Firefly tries to automate everything we know we can automate with K for smart contracts and publications. Smart contracts. And then there is a lot of automation going on in the program verification community, developed by decades of research by amazing researchers like Shubandu here. And Microsoft. Research actually is a leader in that field. And what we'd like to do is to take advantage of all this automation incorporate into the K framework. And we want to do that by connecting the K framework with a program verification tool for solidity developed by Microsoft.
00:17:36.910 - 00:18:37.326, Speaker A: I'll go into more detail how to do this before we dive into our own approach, I would like to tell you that there is a suite of tools with a high degree of automation for formal analysis of smart contracts that you should definitely look at and try, which are not developed by us. And many of them have talks actually in this dev for like Mex and Meatball. I think Bernard here will talk at ten, actually half an hour later by dresser, bit securifying, verax by chain security. All these are amazing tools and you should definitely try to use them, especially when they were out of the box. And now I'm going to go deeper into our approach based on the k framework. So why do we like k framework is mainly because it supports all languages. We designed to work with all programming languages and in particular can use all versions of a given particular language.
00:18:37.326 - 00:19:31.554, Speaker A: Takes solidity because all versions are the same way. You don't have to touch anything in K framework to switch from one version of a language to another, or from one language to another completely. And this is a philosophy or division underlying the k framework that you should define a programming language once and for all, have a formal language definition that includes syntax, semantics, everything and everything else. All the tools that you need for that language should be derived automatically or semiautomatically from that one definition of your language that includes not only parts of the interpreters, but also symbolic execution engines, module checkers, deductive program verifiers and everything. And all of these black boxes, blue boxes are separate tools, but they are all completely language agnostic. Or put it differently, when you implement a tool, form analysis tool or analysis tool for a language, you typically pick two things. You pick the language and you pick the tool.
00:19:31.554 - 00:20:11.600, Speaker A: Then you develop a system, your tool, which is hardware now to that language and to that particular analysis. So you have languages and then you have tools and many tools speak one language and one Java model, Java for example. So what the kframe proposes is actually to not do that. It proposes to encapsulate all the tools and to make them all parametric in a programming language. And the programming language then can be formalized and passed as input to take the programming language. And when you say programming language, you don't need a transition of the programming language in some other intermediate language. No, just exactly the programming language it is.
00:20:11.600 - 00:20:53.590, Speaker A: So that approach, we started working on the k framework like more than 20 years ago, and only two years ago we switched to a blockchain. And it was really easy to do because all you had to do was to plug and play blockchain languages. Everything else stays exactly the same. And for Ethereum blockchain, we immediately looked at Ethereum virtual machines. We didn't want to verify programs to the solidity level at the beginning. We wanted to start directly with the bytecode to eliminate potential errors in the compiler from the trust base. And we have given actually Everett and other students, I don't know if they should.
00:20:53.590 - 00:21:25.058, Speaker A: So there were students taking classes and they said oh, actually we can give a formal semantics to EVM and then use the keyframe of the PVM. And that class project then turned into a research project and then turned into an actual product now. So there's a complete formal semantics of the EVM in case it's open source. Anything we do is open source. It is complete in the sense that we can run any EVM programs with it. It's like a client, and actually we generate from the semantics. One of the blue boxes was an interpreter.
00:21:25.058 - 00:22:14.870, Speaker A: With that interpreter capacity we generate an actual EVM client, and it is pretty efficient, or efficient enough that you can use it for actual real work. In particular, it is a bit faster than Queen Js, which is the JavaScript emulator of EPM in trouble, and it is only a few times slower than the C implementation of Ethereum. So that really makes it usable as an implementation. But remember, it's just a mathematical model, the exact same mathematical model you use for verification without any gap between an implementation and the verification. Also, several people in the community use it. Use the KVM semantics as the canonical specification of EVM. And we have a website, yellowpaper.org,
00:22:14.870 - 00:22:46.238, Speaker A: which website was completely automatically generated from EVM semantics? And we generated, we update it each time we modify the semantics. And that's human readable. You can go and read it. It's the canonical specification of the EVM. All right. And the Firefly tool that Everett will talk about is, as I mentioned, it tries to automate what we already do in K, but in a way that other people can. Also this automation not only experts in k or foreign methods.
00:22:46.238 - 00:23:28.510, Speaker A: So it is an instance of the K framework with EVM semantics and with lots of automation in various boxes and all under the hood. So that for new users of Firefly, just a push button thing. You just push button and don't even need to see what is capacity. Firefly attempts to automate whatever is there in the K framework already, while the combination with verisol. The intention here is to build upon the legacy of successful tools developed by Microsoft Research. And many of you may have ordered C three booty coral. So all these amazing technologies are already incorporated in verisol.
00:23:28.510 - 00:24:35.720, Speaker A: The problem is that there is a gap between what very Sol does analysis at the trinity level and what we do with KVM, which analysis at the bytecode level using an actual form of semantics. So what we'd like to do now is to connect the two and to regard very solid as a user friendly lightweight front end that generates all the verification artifacts that you need down there. Then to reconstruct the proof of the byport level. And this way you achieve everything you want to achieve. Automation a very small trust base, because now we have to trust the formal thematics of the EVM and at the same time, and with that I'm going to let the actual tools talk. I will start with to give us nobody believe.
00:25:23.190 - 00:26:06.766, Speaker B: So thanks for coming. So thank you for inviting me as part of this session. I was quite honored. So I work at Microsoft and I see some familiar faces thanks to all the shout outs to the research of Microsoft research. I don't claim credit for any of them, but I've been on the engine room while these technologies like Z three, Boogie and Coral, can you hear me? Have been developed. So I've been fortunate enough to sort of be part of some of these technologies or be in the engine room while these have been developed. The goal was we had a team in Microsoft called azure blockchain and they started taking dependence on smart contracts.
00:26:06.766 - 00:27:18.834, Speaker B: So it was naturally quite interesting to us to see if we can help them. So that's how the journey got started. And then we'll be talking with Grigori about how to combine these two techniques and what's the landscape of tools and so on. So what is verisol? So the way I think of it is a formal specification and verification tool for solidity smart contracts and it's a research project in my mind. There's a GitHub page, there are lots of collaborators from Microsoft, from Austin, and a coin set of collaborators from other places in Argentina and so on. So what was the motivation for Bellysol? So to me the motivation was that we need to empower the developers who are writing smart contracts for a living because there are, as rigorous said, it's a very crucial, important set of applications that you build with lots of security goals and you would like to reason about them, not just for audit, but also while you're developing for your customer idea. And this initially started with the focus on the actual blockchain smart contracts that they were building for the infrastructure and also samples.
00:27:18.834 - 00:28:06.946, Speaker B: So we had some, that was the starting point. And also, as Rigori said, one of the goal is to expose a lot of research that has sort of matured in the research community, bring it up to developers with fairly well defined expectations. So not all of them are the most automated tools in the market, but they have sort of an expectation that exactly what is expected of many of the tools use d three for symbolic reasoning. Boogie is a state of the art intermediate verification language. Instead of k, different flavor like it's a verification language that you can map different languages. And then quoral is a push button interprocessional checker. So it's completely push button, scalable driven.
00:28:06.978 - 00:28:08.166, Speaker A: By the assertions that you want to.
00:28:08.188 - 00:28:47.074, Speaker B: Prove, not by the number of paths in the program. And there's a lightweight but very predictable inference of annotations when you don't have all the annotations. And also kind of push the envelope up on the research as we look at more contract. And as I said, these are not the most optimized for the purpose. They have a sort of well defined expectation. I've been fortunate to use some of these tools in production in windows and ie, and found lots of bugs. People have used it in the caddy driver verifier, which is shipped with the driver verifier.
00:28:47.074 - 00:29:49.474, Speaker B: So these tools have a history of being tested in production and people are taking dependencies on these tools. So I will go ahead and give a few examples as I go along. We recently released net global tool, so you can try to install at some point there could be bugs. And I have a set of examples that I'm going to walk through today just to give a flavor of what tool looks like. So we'll start with the Dow example. It's most famous and notorious. So this is the notorious Dow example, and we all know what reintrinsy buzing.
00:29:49.474 - 00:30:52.026, Speaker B: But let's say you're just rewriting the Tao example and you knew nothing about reintrincy. So what is it that you were looking for? Let's say a language that doesn't have reinterpreting? What is it that you should be thinking about? So here is one example that says that, well, there's a withdrawal method that is responsible for withdrawing funds from the balances of, I guess one of the ingrains that you want to preserve is that no matter what the, what you want to say is that if I call withdraw, then the sender should not withdraw more than they have entitled to. That seems like a natural specification. It should be equal, ideally, but I'll show you examples where it actually can. Equality is too strong because an attacker can actually go and donate something. But this says that roughly that anybody should not get more money than they want. So you write this specification.
00:30:52.026 - 00:31:55.054, Speaker B: So it uses some code contract libraries that it supports. So it uses mostly old are the new things in there. So I have the bug in there, line 27, and it's a command line tool right now. And it tries a couple of things. It tries to get a fruit first, and if it doesn't find a fruit, then it tries to look for counter example. So in this case, it sort of gives you a couple examples that says you have to call the constructor with certain arguments, then you donate because without donating you cannot withdraw. So you donate and then you withdraw all the withdrawal methods.
00:31:55.102 - 00:31:55.458, Speaker A: Right.
00:31:55.544 - 00:33:19.526, Speaker B: And then the assertion that we wrote down and for, unfortunately only for windows at this point we have a viewer that can help you debug to the trace. I'm not going to show it, but you can actually step to the trace and see values as they're, so you can see values printed around the face just to get you the better sense of what's going on. So that's experience. And so I'll go ahead and do the fix, which is you update. So basically, many people know we basically update the credit of the sender before we, before we do the. So in this case it actually found a proof, meaning that this dow will be able to satisfy the property that we wrote down. And the interesting thing is the detail is how do you model that versatility? So we have a motion called combat where that version can call into any of your functions.
00:33:19.526 - 00:33:29.902, Speaker B: So with that model we have a, so this is sort of the experience. So I'll show you this RC 20 something.
00:33:29.956 - 00:33:30.560, Speaker A: Just.
00:33:36.390 - 00:34:35.640, Speaker B: So this is sort of, I guess many people are familiar with the RC 20 token. This is the one from open zeppelin, modified a little bit. And the thing that we're trying to reason about, here's again, the question is what do you do with the token? Once you're designing the token, what do you look for? So one nice specification is that the total supply that's in the token should be the state, the sum of all the balances of all the addresses. And that will sort of get a good mental model of what an internal invariant is. And if you show this to a customer, they might say, okay, this looks reasonable. If you can show this, maybe I'll trust you. And so the thing I'm going to show is up here.
00:34:35.640 - 00:35:57.482, Speaker B: So this is the method called transfer. And interestingly, Copenzeppelin doesn't check for when you send an amount, the vendors have to have that much amount. And the reason it does is because it relies on the underfloor semantics of the safe math. So the safe math sort of makes it safe because if you don't have enough money, the safe math will fail and then you'll abort the. So how do you find that without knowing the internal substance math? So the invasion that I wrote down, if you change the safe math to a regular subtraction, then it's, again, it refuses to find a proof and it calls you, it shows a counterexample where you're trying to drain an amount, one from somebody who did not have any credit in them. And this is interesting because it requires you to reason about the underlying semantics of arithmetic. If you don't, if you're not careful and don't use modular arithmetics, you might see a proof where it does not exist.
00:35:57.482 - 00:36:42.986, Speaker B: So this shows basically various levels of abstraction you can reason and the kind of guarantees you can get. The modular arithmetic is not a very scalable solution. So if you try to use it for causal line programs with lots of deep ingrained and not scalable. So you have to choose, but you sort of set up an expectation of where you want to invest. Okay, I just want to show one more example, which is an example from this tool called azure blockchain. Microsoft was one of the products that Microsoft shipped about a year back from, and it had a very nice way to decompose a workflow policy. They realized many smart contracts implement some kind of workflows.
00:36:42.986 - 00:37:33.310, Speaker B: They're getting very, very popular in the enterprise scenario. So they provided a nice language, a JSON based language, clear semantics of what a workflow looks like. And then the question is, does the polytree program implement the workflow? Can you make it full screen so people can see? Yes, thank you. Right, so here is think of this specification language with a bunch of state machines and actions and some access control, and then facility smart contract. And the question is whether the smart contract refines the state machine. So in this case, it turns out there was a discrepancy. It turns out it wasn't a specification, but nevertheless there was something that was different in the two versions.
00:37:33.310 - 00:38:04.966, Speaker B: And so this requires sort of a very deep analysis because it will take up to seven steps to get through the state. Right. So shallow execution will not be able to get to this part. So this is, I'm going to show this example. In this case, it did not find.
00:38:04.988 - 00:38:06.454, Speaker C: The proof, but it takes a little.
00:38:06.492 - 00:38:26.000, Speaker B: While to actually find the counterexample. But still it's reasonable. It's a few seconds, but it just shows you the complexity of the search space. So since this is assertion guide, it can be a little better. But of course it hasn't limited. You can see you have to issue 123-4567 transactions to reach this. So people in testing might have missed this.
00:38:26.000 - 00:39:10.762, Speaker B: Okay, so getting back seven minutes. Okay, so it shows you the flavor of verification. So for this one, for example, if you just want to do a push button verification, you have access to this coral. If you want to do proofs, you can write ingredients and interact with the tool. But the nice thing we observed is that doing a smart contract is kind of nice, in that the open environment of adversary makes it easier for the verification to go through in many cases. So that is actually a lifesaver. So the infrastructure for verison looks like this.
00:39:10.762 - 00:39:54.746, Speaker B: So we have a solution program with specifications. For specifications, if you include this cold contract library that is available, and I call it cold contract because it's sort of the solidity syntax. You get the resolution from solidity, you can get syntax errors in the specification directly from the compiler. And then we are working on translating the subset of solidity to bookie that is reasonably high level. So we're not going to try to do deep verification about how data is layout by the Pytorch compiler. That's something that Kate does very well, and that's something that is very hard to automate at the bias source code level. And you're also sort of trying to.
00:39:54.768 - 00:39:56.026, Speaker A: Do what the compilers do.
00:39:56.048 - 00:41:44.400, Speaker B: So theater reasoning is much more abstract level, which I think is good for business logics that we see in enterprises, and then the host of tools that we rely on, which are being extended by us, by the community as they feel the need. And so the outcome has three outcomes. It has proof, or you can have a trace, or in the middle near something like, well, I've not been able to verify it fully or find a trace, but I have this guarantee that any transaction of debt case, any set of transactions, if you issue up to K transactions, then I'm going to give you some sharing. So this gives you a reasonable guarantee to maybe stop testing and focus on verification at this point. Okay, so the way it works is it takes a contract for think of this one contract with a constructor and a bunch of arguments, and then creates this driver, or the hardness that sort of in an infinite loop calls any of the vector with arbitrary arguments. So you can imagine if you can verify something on this program, you've verified it for all executions, right? So the capabilities at this point is old contract library, and we've consciously taken the decision to start with a known language so developers can understand them without needing a whole bunch of sophisticated semantics of languages. Our initial customer was the folks in Azure blockchain who were systems developers, but they sort of understood the specification, at least to some level.
00:41:44.400 - 00:42:46.174, Speaker B: We have some scalable push button validation violations and highly automated two season pobi. And by highly automated I don't mean completely automated. You can might have to support some extra tracks on the side. So that's sort of the research problem is how do you lower the pathway? And so we talked about some of the study on how do you check workflow policies. The example that I showed and also checked some critical infrastructure that were built using smart contracts in some of the products they have services they have shared, and this is sort of the governance protocols that underlying Ethereum and Azure or Azure blockchain service. So basically they have implemented some of the governance and smart contracts and solidity. And so it's very crucial because any bugs there might just compromise the entire infrastructure.
00:42:46.174 - 00:44:00.390, Speaker B: And so you have to ask questions, can I get into a deadlock? Like can I remove the last administrator? So that now run that issue? And usually the work happened as like it happens, okay, you consult with the designer and you come with a specification, do boundary checking and then help them with invasions and you repeat them while the code is being developed. So we were very fortunate that we could actually do this while the program was being developed and tested in pound bugs, seven bugs. So that was a very nice experience and I think that would be nice to scale out such kind of experience. So that's sort of the goal of the very solid tool. If we take it from research prototype where we have a few customers to it, help more people, try to get a sense of the technology and enable the community, either directly or by collaboration with folks at RV, mostly gloss over the specifications that we've been adding to the contract language evolving. So we need to check back in two months. But essentially these are sort of well known facts that are necessary for doing any program verification.
00:44:00.390 - 00:44:43.366, Speaker B: These may not be sufficient to pre post conditions. Contracting training, Google training contracting data can mean various things to various people. So you have to, irrespective of what it. So it's a library and then you have stuff for conditions. So for example you can follow Venetol or contract invaders required ensures invaders. I know there's work in the solidity compiler on supporting some of these specification primitives, so we are sort of waiting and watching to see once they come up we can sort of leverage some of that. So it's not tied to this language in any way.
00:44:43.366 - 00:45:28.034, Speaker B: This is just a way to expose the facilities to developers. And then again, once you search the language, you need to read about the old value and mapping. So the example I showed in ERC currently, where you need to say that total choice, total supply is equal to the sum of all the balances. It's very hard to do in code because you cannot even write such a specification because mappings don't allow iterating over all the indices and so on. There are some things that really get a lot of value just specifying it and even doing boundary checking. And then we're working on other extensions. Part of the talk that we have in this RVs what kind of stuff.
00:45:28.034 - 00:46:20.790, Speaker B: So they have a lot of experience in the contract or those are not specifications. So what are good high level experience. So next three to six months we have a bunch of perfect coverage of solidity. So the reason I say high level reasoning, I don't think we are going to go the parts of solidity that require low level reasoning that is known not to scale at the FMT level. So if you want automation then you have to sort of carve out sort of high level land. And what I've seen in the enterprise, people don't really care about generalized. They are happy to live with a fragment that they can be more sure of rather than getting optimized gas.
00:46:20.790 - 00:46:28.886, Speaker B: So there is a hope that a lot of the reasons can be reason to high level we're going to work.
00:46:28.908 - 00:46:31.062, Speaker A: On a vs code extension to make it easier.
00:46:31.206 - 00:46:59.950, Speaker B: And then going forward the discussion we are having is what kind of can we add beyond assertions, temporal logics. And there are a lot of research in the community also how to improve the invading inference, how to give users more control up, how to do invading inference and through the grand challenge, how do we push these tools all the way down to bipolar? I think that's a very interesting problem. So with that I'll conclude.
00:47:19.050 - 00:47:20.130, Speaker A: Yes, so.
00:47:20.220 - 00:47:23.706, Speaker D: I'm sorry, did what you just described use K as the back end?
00:47:23.808 - 00:47:38.670, Speaker B: No, that's the future plan. Once it has proved at the very salt level, we'd like to convince K that it actually holds at the bytecode level. Right. That is a long term.
00:47:42.370 - 00:47:44.340, Speaker C: I'll talk about how to do it as well.
00:47:47.190 - 00:48:15.530, Speaker B: Are you considering to have a Linux version for the. There is both Linux and a Mac version of the tool. The visualizer? No, somebody has to build a visualizer, but the rest of the tool. Yeah, there's a new package you can just. Yes, hello, I'm going to work on formal verification of consensus algorithms.
00:48:15.950 - 00:48:17.418, Speaker A: Formation of what?
00:48:17.504 - 00:48:18.662, Speaker B: Consensus algorithms.
00:48:18.726 - 00:48:22.480, Speaker A: Consensus algorithms? Yes, we are going to talk a bit about that at the end actually.
00:48:24.930 - 00:49:03.210, Speaker D: All right, get started. So, hi, my name is Adrian park. Going to talk about verification of the code with more focus on the case study of each 2.0 deposit contract we recently verified. The title contains verification, but I'm not talking about the verification too much because already we talk about verification. I talk about more about the bytecode. For those of you don't know about bytecode will learn something about bytecode.
00:49:03.210 - 00:49:44.760, Speaker D: Bytecode will find this interesting. So before going to that, let me give a quick overview of our bytecode verification tool. So we have the EDM bicecode verification tool that builds on top of the K framework and the KDM that we describe. And this tool has two inputs, program bytecode and the specification. And it checks that the program satisfies the specification or not. This is very similar to very slow at the high level. The main difference is that it works as the bytecode level.
00:49:44.760 - 00:51:13.138, Speaker D: Why the map? Why the bicep code better? I will talk about it a little bit later, but let me give you a quick example how this tool works. So this is the program, very simple program that similar like ERP 20 transfer types of program. And we have the receiver address from n two and value and update balances of these from n two using this net map. So if there's any underflow or overflow it can be. So given this program, you first compile down into the bicycle, you put in the bicode into our tool and then you have to write down the specification which specify what the behavior that this program should have. So here we are described here, the behavior of the program in the success case, which means that if the balance is enough, I mean standard balance enough and there's no overflow happen, then the balances will be updated as proper way. I'm not going to too details about how these specifications details, but the thing is you have to write down the specification at the bicycle level in this way.
00:51:13.138 - 00:51:17.800, Speaker D: And some people say that wow, specification is longer than program.
00:51:20.810 - 00:51:21.494, Speaker B: And this is.
00:51:21.532 - 00:52:27.590, Speaker D: Why what mentioned it requires the whole network to write down this specification and also working at level. Our future goal is to let you just write down the specification as annotation language like insured and required for PN post condition saying that okay, this transfer function, if these two preconditions satisfied like balance, this is enough and no overflow happens, then the post condition means that whenever these transfers return safely, I mean returns true whatever or not, these balances should be updated as effective. So if you write down this specification at a high level, the source code level, our goal is to automatically generate this bicycle level specification. So you don't need to work on this level. But that's the future work. We are still working on that, but we're hoping that provides this feature. So using our this tool, we verified some high profile smart contracts.
00:52:27.590 - 00:53:03.826, Speaker D: So very recently we verified ebook 2.0 departure contract that I guess you will learn more about this in the later this E 2.0 talk. But the main thing is that this contract is really important contract when you want to be a validator of E 2.0 because you need to deposit your some eater to be a validator. Sending your departure into this contract at the east one point X and then this contract is one eight function. So you can deposit something but we cannot withdraw.
00:53:03.826 - 00:53:29.534, Speaker D: But the deposit whatever made here will be claimed in the east 2.0 network. So it's really important, first make sure that it's not withdrawal. The second, whatever you depart here will be available in the interpreto network. This is really important contract that needs to be correct. So we need to verify this. And this is our case study.
00:53:29.534 - 00:53:36.100, Speaker D: I will show you what we found wired by this contract. And we have other contracts like.
00:53:45.750 - 00:53:46.066, Speaker C: The.
00:53:46.088 - 00:54:44.514, Speaker D: Maker Dow coin was specified in our verification tool, but not by us by default guy. So we are very happy that our tool is used by another to verify their system. So we are hoping to more people using our verifier to verify their system and then that's why we are working really hard push ourselves to much more easier to use our tool. And that's more or less the Firefly talk needs the final talk. And then here are some other bunch of the smart contracts. And now I'm going to explain why we are really obsessed in this bytecode level verification. The first reason is the bytecode is what really runs on the blockchain, not the source code, right? And then compilers, believe it or not, have bops.
00:54:44.514 - 00:55:41.034, Speaker D: I'm not talking about this or this compiler, just usually compiler, even the C compiler like GCC or LSVM which is very mature and developed long period of time as box new bugs reported even now today and some bugs actually hidden in for 20 years. Simply some guys unlucky to hit trigger the box hidden the 20 years and they report it. So compilers box actually more than you expected. So the thing is, even if you verify your source code is correct, if compiler has a problem then that doesn't mean using very so verified things. It just assume that compiler is correct. If not in the case then your verification does not actually guarantee what you want. So this is really important.
00:55:41.034 - 00:56:33.020, Speaker D: That's why we are actually working at the bicycle level. And indeed we found some issues in e two device contract while we verify the bicycle level that I'm going to talk about. So before explaining what box we found let me give a very quick background how to read the bicycle arrays. Okay, suppose you have a byte array like bank, two words, 32 33, how that represented at the EVM level. The single byte is not represented as a single byte. It represents as two words, essentially six four bytes. Essentially each line is 32 bytes line.
00:56:33.020 - 00:57:32.922, Speaker D: The very 1st 32 bytes denotes what's the size of this byte, which is one. And then you have an actual byte, the data one byte and then followed by zero bytes, so 31 zeros. If you have a byte of two, then gain size two there, and then two bytes here, and then zero bytes and so, and so forth. If you have a 32 bytes, no, it's already online, so you don't have any zero bytes. That's how byte rates are represented in the ABBM level. And if you have a tuple of byte arrays like arguments, or if you return something, then they store as a triple of divide. And then if you for example two triple of two bytes array, then simply put this, like this guy, put this two, and then you put on top of these simply offset.
00:57:32.922 - 00:58:35.154, Speaker D: So this offset points where each element starts. So since the offset is simply fixed. So if you want to find some first element or next element, you find that, you go to the object, find it by where it starts, and you read the size, and then read from here, hit the size. That's how you decode or encode this bytes ray that you all need to know to understand how this box, okay, so first what we found the deposit contract. So this is one of the functions, the deposit contract called get deposit count function, which simply the futon, oh by the way, this is a viper. Those of you not familiar with this viper is similar to solidity, but simply python each syntax so you can read. So it returns this departure count, this storage value, but in the real indian form.
00:58:35.154 - 00:58:42.980, Speaker D: So simply a reverse divided. Just assume that it's true, little indian, simply correct.
00:58:43.590 - 00:58:44.340, Speaker A: Then.
00:58:47.350 - 00:59:52.170, Speaker D: Those of you think that any problem it is simply two life code. How could it be wrong, right? I mean, assume that this is correct, right? Assume that these two religions correct. Can you think about something wrong with this code? Yes, when you flip it around and then you cut off to get the right case, you might cut off the wrong data. That's very good guess, but that's somehow handled by very well in two living. Yes, but yeah, very good. I'm sorry, actually I, fortunately, because you cannot get this because in the compiler, by the compiler, so return the value when you call this function. If this contract compiled by Viper version 1.0
00:59:52.170 - 01:00:05.280, Speaker D: beta eleven, which is the latest project at the time we started. Can you see any problem with this? If you follow me, the previous preliminary. Yeah.
01:00:07.650 - 01:00:13.246, Speaker B: It'S 20, right.
01:00:13.428 - 01:00:51.334, Speaker D: It needs it all zero. But here, see something is nonzero there. What happens, what will happen is that compiler, first of all, don't worry about it, it's already big compiler. What compiler does is that when they become this, they need to prepare this data in the local memory and then they return, they first write down offset, this is correct. And write down this size. And then they copy this. And then they need to put all the zero like this is eight bytes.
01:00:51.334 - 01:01:33.946, Speaker D: So 24 bytes of zero there. But somehow comparative bulk, they only put the zero, only eight bytes, then leave whatever these 16 bytes there. And the problem is these 16 bytes of the local memory garbage came from this function side effect. So there is just garbage there, which is nonzero. This is the example of the compiler bug. And then you cannot find this unless you work at the fiscal level. Ethereum foundation writes on this code.
01:01:33.946 - 01:02:35.310, Speaker D: There's good job and no problem, but just deploy this without this verification, right? And then you have these non incorrect zero bytes and then somehow another contract that assume that expected may be exploited by some other cycle. This is really thing, that's why we really think that the bicycle verification is important. I have another bulb which is more interesting. Okay, let me very quick. So this is a main function departure. The departure function takes now three arguments, all the bytes array, and then they check that the length is whatever expected. Now this is the tuple of three elements like offset and the three arguments.
01:02:35.310 - 01:03:15.674, Speaker D: Now what if this polar input is not valid? For example, by mistake world maliciously cracked. For example, there's no actual bytes, only this six word. This is the correct 112 war. What if you provide six words? You might think that, oh, there's no bytes, right? No extra data. So data length is zero. But now we have a length check, so it may debug, right? Right. But what will happen is this is a counting example.
01:03:15.674 - 01:03:49.438, Speaker D: Simply six bytes offset 961-2816 and the three sides like 48, 32, 90 from this side. Then no bytes. This is all. And then even this, the divided function simply goes through. Doesn't it work? Let me explain why. First you try to read pop cubes as first argument. You first go to the offset because this is necessary startup data.
01:03:49.438 - 01:04:21.022, Speaker D: So if you read the size or size is 48, so you read 48 pipes simply starting from here. So they simply decode. Consider this garbage as a top key. Move on. Next you go to second offset and its size is 36 32. And then simply read this guy which is actually another size, another guy even more now third one, you go third offset. It points.
01:04:21.022 - 01:05:22.322, Speaker D: This is a size which is 96 and try to read beyond the core data, this 96. And what will happen is the yellow paper of Ethereum virtual machine said that if you want to read something beyond core data, you read that as is infinite zero. Are there already means that simply when we read this out of bounded set, simply return all zero. This is what happened. Given this index called data, the decoding process simply reads three arguments already garbage which for example signature power zero you cannot claim later in e 3.0 chain whenever you are deposited. So if you make any mistake or somehow manifest user somehow flip the bit in your core data, then you have it.
01:05:22.322 - 01:06:15.810, Speaker D: So this shouldn't happen but previously simply then go through and deposit this wrong information and then you simply lost your so again, the story is it's really important to work at the bicycle level if you want your full assurance of your smart punch when it grows. And then so far we are using our KBE tool which requires some expert and then some really effort. So far actually the large group like foundation or some who can afford this large effort can use our tool to verify that. But we are really hoping that even small startups can use our tool to full guarantee of their smart contract. And that's why we are working on this next of pipeline.
01:06:19.590 - 01:06:23.170, Speaker A: Any questions while I see the slides for the journey?
01:06:24.890 - 01:06:32.220, Speaker C: So concerning the first issue, yes, so the non zero bytes, did they affect the correctness of.
01:06:34.350 - 01:06:39.146, Speaker D: That call? Specifically because it sounds like did they.
01:06:39.168 - 01:06:40.502, Speaker C: Affect the correctness of that call?
01:06:40.576 - 01:07:25.980, Speaker D: Yeah, first of all, there's not ABI standard return value. The ABI standard basically says that if you have non aligned return value, you need to have a full zero bytes, and then that ABI is simply like protocol, right? So whoever who called this contract would assume that they're going to be a zero bytes. If somehow they float that back, just copy those into another local memory, assuming that was a zero, may have different behavior. So this is a promise, right? I mean, you need to return something, you need to follow some rules. So yeah, that's the problem.
01:07:27.070 - 01:08:14.986, Speaker C: Thanks Adrian. Adrian had some more interesting slides after that, which I'm bummed we didn't get to, but you should ask him about it afterwards on some equivalents checking and stuff that we can do. Okay, so I'm here to talk about Firefly, and this is our attempt to take KVM, which is kind of hard to use and wrap it up into an easy to use tool that kind of just works in the background and does everything in an automated fashion, as opposed to now where you basically need RT to use the K tool at all. So this is an overview of my talk. First, I'm just going to talk briefly about the motivation of why we want something like this. Show you our roadmap. It's stretched out over about two years, and then I'm going to talk about the individual tools that are on our roadmap, which we have prototypes for all the tools except this last one.
01:08:14.986 - 01:09:00.054, Speaker C: But the roadmap is still spread out over some time to do testing and internal stuff like that. As a motivation, we have tools like verisol that are easy to use, they're high level, they're at the solidity source code level, and developers can just basically use them out of the box. But the problem is, as Dejane pointed out, you don't get the guarantees that you would want at the EVM bytecode level. But then we have KVM, which is a low level EVM bytecode verification tool, which really takes an expert to use. And somehow there's not something bridging the gap between these two. So that's what we're trying to do. So the ideal scenario for Firefly is that it's going to be a drop in testing client replacement for whatever you use as your testing framework.
01:09:00.054 - 01:09:28.702, Speaker C: Right now we're kind of targeting truffle. So basically just replace ganache with Firefly and then you're off to the races. And just a couple more bullet points. But yeah, one goal, no user intervention required. It should be that you just run the tool instead of your normal testing tool, and it does the extra analysis and reports the results back to you. Another goal, easy for us to roll out more features and reporting over time. And then another goal is easy to dispatch large jobs in parallel to a service somewhere.
01:09:28.702 - 01:10:11.710, Speaker C: So these are kind of some long term goals of the project, not specifically tied to any of the actual tools we're developing, but we'll develop the tools with this in mind. Here's the long term roadmap. You can see it goes out to December 2020. I'll talk about these ones, which are part of the Firefly suite a little bit more, but then they're on the right hand side beyond Fireflyer, where we get back into where you need a formal methods expert present again. And we are doing some kind of prototyping of these tools out here. So specification generation, instead of having to write down a specification and verify your contract, we will generate it for you. And proof object generation is basically the highest level of assurance that you can get with anything.
01:10:11.710 - 01:10:55.950, Speaker C: Formal methods usually not done except in the most safety critical sorts of systems. But we're toying with the idea of moving in that direction. This is our more specific Firefly roadmap. We have K is set up so that we have like a front end, which basically takes the K specification and translates it into multiple backends. The llvm back end is our fast interpreter. So whenever we talk about the performance of K compared to other things, we're talking about the llvm generated interpreter for the K specification. And then whenever we talk about symbolic execution approving, we're talking about the Haskell backend, which is the one that actually does the proof steps needed to do symbolic execution.
01:10:55.950 - 01:11:49.406, Speaker C: I'm going to talk about each of these tools in a little more detail, but we're starting off with just a test runner. You just basically replace Ethereum JSDM with KVM, and then everything looks the same as normal from the perspective of running truffle tests. Test case coverage reporting is next. That's what we're working on right now is kind of integrating that coverage report data back to the truffle runtime monitoring, which is like bounded model checking V one, and then assertion violation checker, which is where we're going to actually integrate with the verasol tool to get kind of an assist from them. Bounded model checker V two, which is where we're going to do it symbolically and exhaustively, as opposed to here, which is going to be concrete and only on the test cases that your actual tests exercise. And then finally at the end is test case generation. That's the one tool we don't have a prototype for yet, but we'll get there.
01:11:49.406 - 01:12:44.510, Speaker C: I'll explain why that's important, or why it's nice, maybe it's not important, I don't know, it's probably important. Okay, so the test runner, basically what we're doing is we're taking KVM, we're making it into a full client, having full client functionality so that you can just use it anywhere where you would use a full client for doing testing. So we're just going to support the web3 JSON RPC and we already have it to where you can basically just run truffle tests, but where you're running the KVM server in the background instead of running, or the Firefly server in the background instead of running ganache and it just works. Benefit of that is you get kind of more confidence in the test results because KVM is kind of regarded as a canonical spec of the EVM. That's one of the canonical mean. Some people like that take it a lead and then performance is comparable to ethereum JSPM. But we actually have several performance enhancements coming out that are going to make us fashion theorem JSPM.
01:12:44.510 - 01:13:28.526, Speaker C: And then we have just kind of special purpose Firefly underbard web3 JSON RPC commands for getting back, reporting data from KVM about coverage or analysis, like the runtime monitoring, stuff like that. This is just like the bare functionality you need. This exists right now, but then everything is going to build on the fact that, okay, now this is just a drop in replacement, you can switch over to using it, not really notice any change. And then we start rolling out features. So the first feature we roll out is just test coverage. We're specifically going to measure off code coverage. So here's an example report that the prototype stood out.
01:13:28.526 - 01:14:00.470, Speaker C: And you can see there's kind of this place after this jump by that's not tested by any of the things. Everything else is tested by 73 different tests, but these are tested by zero tests. That's a hole in the coverage data. And so as a developer, if you were to see this report, what you'd want to do is you'd want to say, okay, where is this code coming from? So use a source map back to solidity and write a test in whatever testing harness you're using. Solidity tests or not. Firefly blanking on trouble tests. I swear I know the word trouble.
01:14:00.470 - 01:14:57.466, Speaker C: Yeah. So write a test that targets these lines, and then you would add that to your test set, and then the coverage report would come back free and saying, okay, every opcode at least is covered, which there's a lot of literature about whether opcode coverage or branch coverage or path coverage or something is the correct thing to do, but at least this is something, right? By the way, there are tools that will do coverage already. So if you look at Brownie, that's an existing tool that will do coverage already. So common pitfalls in tests are you might not test something like the default or fallback function. You might only write tests for the positive cases of your contract where things are going smoothly. So you don't write tests for the revert cases, you might not write tests that actually exercise the underflow overflow. And then you might not even test the ABI decoding, because at the solidity level, the ABI decoding is not apparent or obvious at all, because the compiler takes care of that for you.
01:14:57.466 - 01:15:57.178, Speaker C: But as Dejun pointed out, if you assume that the compiler is doing it correctly, you could lose all the ETH one funds when you're trying to move over ETH two, which kind of sucks. Okay, so then the next tool on the roadmap is a runtime monitor. So basically what the runtime monitor is, is we instrument the semantics with specific events which basically can fire on any particular data from any particular points of execution during running. The events that I have here, as example, are overflow and revert in this example. So overflow we just detect, are we doing an addition and the addition overflows, or are we doing a subtraction? And the subtraction underflows and revert is just that, the revert off code fires. And then I made like a little state machine dish thing here, saying if we're doing execution and neither of these events are firing, we're just in this normal mode. If execution ends, we go to this no violation found mode.
01:15:57.178 - 01:16:43.722, Speaker C: But if an overflow event fires, then we know that we have to revert, and if we end without reverting, then it's a violation. But if we end with revert right here, then there's no violation because the overflow was followed by a revert. So these properties are temporal in nature. So it's not enough to just say there are no overflows, because it's pretty common that you will have an overflow during execution, but you have to instead say temporarily. Every overflow is eventually followed by a revert before the end of the contract. So we're just going to build these events directly into the semantics, and users can supply more if they like, but then the semantics has to be recompiled. But the properties themselves to check, like this formula right here, can be specified on the command line at runtime.
01:16:43.722 - 01:17:34.160, Speaker C: So we'll provide a preset bag of properties. Users can write their own properties, and then basically we're just going to run the user's normal test sets. You still just run trouble tests, but it runs it with this instrumented mode where it will check, are these properties violated on these test runs? And then if it finds a violation of one of these properties on this test run, the user can inspect that violation and write an actual truffle test that would have caused that violation anyway, so that you don't have to rerun this tool to get the same guarantee. So you can kind of add tests that target these properties to your own test set. So that's bound to model checking. V. One assertion violation checker from our roadmap is where we would get into looking at the pre and post conditions that Dejun is talking about, or that verisol will look at.
01:17:34.160 - 01:18:42.514, Speaker C: And so verisol checks this property at the solidity level, and there's lots of tools that do this, right? There's like the solidity SMT checker, there's Varx, I have like an incomplete list somewhere. There's lots of tools that will do this, but we're going to do it at the EVM bytecode level instead of at solidity level for the higher guarantees to get there. And basically because of the way EVM is structured, the way that solidity compels EVM, all we have to ask is, is it possible to ever reach the invalid opcode because the assertions, the post conditions at the end of the functions are translated to the invalid opcode. And if you don't find that it's possible, then likely the user stated pre post conditions hold. If you do, then we can provide a counterexample, and once again that counterexample can turn into an actual truffle test so that it's quicker to catch next time without having to rerun this tool. So then we are planning on getting an assist from Verisol. So Verisol will first check it at the solidity level, and it's much quicker to run verasolidity, so it'll check at the solidity level.
01:18:42.514 - 01:19:01.930, Speaker C: If it finds a violation, then you can just work with that directly. But then if Verisol gives you the green check mark, then we run KDM and double check it at the pipe code level, and that'll guard against bugs in compiler and bugs and Verasol. Yeah, so that's kind of the plan for this assertion violation checker.
01:19:04.030 - 01:19:04.954, Speaker D: Okay, fine.
01:19:05.072 - 01:20:08.718, Speaker C: Next is the bounded model checker, which is basically the symbolic version of this runtime monitor. So this runtime monitor only exercises checks for violations in the runs of your tests, which are run on specific concrete inputs. But you might want to know, is it possible there's violations in any runs of the program? And so to do that we basically will just run the same test, but now on symbolic inputs instead, and then run the bounded model checker out to some specific depth and see if we can find a violation there. So it could be this example I have here is it could be that the test only exercises cases where X is less than three, in which case you go directly from this exact state that no violation state because no overflow ever happens. But when X is greater than or equal to three, you get this overflow and then you get this end without a revert, which is a violation of this property. And so this wouldn't be caught by the runtime monitor because it only exercises the cases that are in your test set. But then here we would catch it and provide a counterexample saying oh, try X is seven or something like that.
01:20:08.718 - 01:20:16.114, Speaker C: And then you would add that back to your test set and you wouldn't have to rerun this tool to find that violation the next time you would just be part of your test set.
01:20:16.152 - 01:20:16.740, Speaker B: Now.
01:20:17.670 - 01:21:08.354, Speaker C: Okay, sorry I'm going so fast through this. Finally, the last tool that we're thinking of, this is for each of these. I said, so once you find the violation, add a test back to your test set that would catch it without having to rerun the tool. And that's to kind of speed up your later development process and to guard against other issues. But the very last tool we're planning on putting in Firefly is where we'll just generate that test for you. So in the case of here we'll add for opcodes 1214 and 15, we'll do some analysis and find a test that will actually exercise those particular opcodes basically. Or here in the case where X greater than or equal to three, we can ask the Microsoft tools, hey, give us an example of an X that's greater than or equal to three.
01:21:08.354 - 01:21:33.354, Speaker C: I know that's really easy to do, like seven or something. And sometimes it's harder. And then the tools can say okay, here's an assignment variable that will exercise that particular execution panel. So that's the overall roadmap for Firefly at the moment. I'm going to put up this roadmap again. You can see it kind of extends out of ways. We are in this phase right now.
01:21:33.354 - 01:21:56.066, Speaker C: Like I said, we have prototypes of all the tools going on here. Not a test case generation, but we've given ourselves some time to really make sure that everything's ironed out and works well. We just want it to be basically drop in. That's one of the goals, is users don't have to know that they're using the tool until it tells them, hey, here's a problem.
01:21:56.248 - 01:21:56.594, Speaker D: Okay.
01:21:56.632 - 01:21:58.834, Speaker C: Gregory is going to wrap up any.
01:21:58.872 - 01:22:00.850, Speaker A: Questions for leverage in the meanwhile.
01:22:01.830 - 01:22:14.882, Speaker B: Yeah, you mentioned for the test, you mentioned in case of the ABI and then you could go back in general, if there's missing test coverage, you can go back with the source mapping.
01:22:14.946 - 01:22:24.202, Speaker C: Yeah, it may not be possible in all like that. You might have to actually craft some specific transaction with call data, like exercise, like incorrect API encoding or something.
01:22:24.256 - 01:22:34.290, Speaker B: Yeah, no, but I'm also saying how are you experienced? Because often source mapping for this kind of generated code doesn't give you any meaningful.
01:22:34.390 - 01:22:47.458, Speaker C: Yeah, so the source mapping would be more just to assist the developer. It wouldn't be used probably in the automated test generation, because there we can just generate exactly the call data we need to feed in to exercise that case.
01:22:47.544 - 01:22:59.126, Speaker B: And for overflows in our experiences, lots of overflows because the compiler likes to use them in all kinds of cases. Do you have any filtering for that already?
01:22:59.308 - 01:23:01.206, Speaker D: Well, so that's why you need the.
01:23:01.228 - 01:23:10.054, Speaker C: Temporal property which says overflows are okay as long as they're followed by a revert in some case. Obviously that's like a little too broad scope of a property, but you'd have.
01:23:10.092 - 01:23:16.700, Speaker B: I meant because sometimes the subtraction is optimized into an addition on overflow and stuff like that.
01:23:17.390 - 01:23:20.618, Speaker C: But yeah, we can figure it out.
01:23:20.784 - 01:23:22.810, Speaker B: You're going to have two back ends.
01:23:25.570 - 01:23:33.570, Speaker C: Those already exist. Actually that's just part of the case goal right now. I was just showing that's how the tooling is made right now diagram.
01:23:38.390 - 01:23:42.930, Speaker B: So I wanted to ask you about the two back ends after December 2020.
01:23:43.000 - 01:23:47.662, Speaker D: Why would you use the llvm back end rather than the other one? Because of the speed.
01:23:47.806 - 01:24:09.100, Speaker C: Yeah, the LVM back end is basically you take the semantics and generate LVM bitcode that directly implements an interpreter for that language. But it can't do any symbolic execution. But there's a lot of overhead in doing symbolic execution that slows it down too much for actually making a reference interpreter or something like that. 1 minute left.
01:24:09.470 - 01:24:12.940, Speaker A: We have about you five. Yeah.
01:24:13.950 - 01:24:14.700, Speaker D: Okay.
01:24:15.490 - 01:24:27.482, Speaker B: I was just going to say, I think it's important to note that the technology is available, it works, we use it internally, it's simply actually modified, extending it out to make it further.
01:24:27.546 - 01:25:07.214, Speaker A: So please note this is not paperware by any means. Internally we already use a k framework for all these different variants, use these formal methods, formal verification, formal analysis, each other. The tools require experts, require us or others who have expertise in formal methods. What we want to do, literally, is to leverage the capabilities of the tool through automation and make them available to everybody. And automation comes from what we already do in our own audits when we analyze them. When analyze people don't we know that certain things can be automated. We already do that.
01:25:07.214 - 01:25:28.370, Speaker A: And guess what, Firefly. Now, as much as we can and others come from the entire community and especially from all these amazing tools that Microsoft has and are under the hood in Verizon. So the key word here is automation. And once the tools work, then we make them available to you as push button analysis tools.
01:25:29.210 - 01:25:42.342, Speaker C: I also wanted to add, we are looking for people who are interested in conversing with us and being kind of alpha users in like a closed alpha sort of thing. So grab at the conference if you want to do part of that.
01:25:42.396 - 01:26:35.386, Speaker A: Come to all good stuff. All right, so again, I want to remind you that the K framework is language parametric or language agnostic. But none of the tools in the K framework care about what programming language you plug and play in this tool. And that gives us opportunities to do the same with many other languages. And we're already defining semantics for several other languages, which will all take advantage of the tools that we support and we improve right now as part of filesfly and its integration with vestor, among others. Besides what we are working on, several other languages maybe only float based on linear types and ecosystem like boom. And then you have out of the world formalized tools for these languages, once you define them, to incentivize people to formalize their languages in K.
01:26:35.386 - 01:27:22.070, Speaker A: And thanks to the LSM interpretation, which is pretty fast, you can think of it as you implement your language in K. And if you are happy with the speed, then you might not even need another implementation. Maybe some customers who say that hey, I think that speed is good enough actually for us, you would need to implement several hours of implementation of the language. Also, somebody asked about protocols if you want to formalize and analyze specific protocols. Yes, this is another advantage of the K framework, that it doesn't even care whether what you are defining is a programming language or not, or is confused. You have a notion of transition from one state to another, and once you formalize that, and that can be in particular a protocol or token specification. Once you do that, then you can use again all the tools of the framework to analyze your protocol.
01:27:22.070 - 01:28:20.890, Speaker A: And we're already doing this commercially. We have formalized and analyzed several protocols. Actually right now we are working with plants, yes, and also the beacon chain. And all of this becomes you can think of K at that moment as a programming language, say, hey, I'm implementing my protocols in K, and then you can execute and run things the same as you would implement them and run them with Python or both. But at the same time you can also formally analyze them exactly as they are without any gap between what you run and what you verify. And with this we'd like to conclude, and if you like that what we saw, we strongly encourage you to attend the three other events that I'm aware of that mentioned k in f one five, come to our booth downstairs, get a t shirt, speakers, go to the K website, kframel.org and GitHub.
01:28:20.890 - 01:28:43.346, Speaker A: K framework. There are lots of languages defined, for example, not only EVM, several others. The Firefly tool is available for download, download languages and become an alpha tester. Very sole also feed for download. And if you really like to have a very formal verification, but you do not want to do it yourself, we.
01:28:43.368 - 01:28:44.466, Speaker B: Are here to help.
01:28:44.648 - 01:28:58.630, Speaker A: Contact us with our views and we'll help you formally verify your contract or tokens or protocols. And we have a few minutes for questions. 1 minute left. Now a real 1 minute. Yes.
01:28:58.700 - 01:28:59.986, Speaker B: What about Rust?
01:29:00.178 - 01:29:16.590, Speaker A: Rust is a programming language. If we have a formal semantics, there are two formal semantics defined by other groups, not by us, and we don't know how good they are. We haven't played with them, we haven't looked at them, but there are two semantics. One of them for sure defines the entire state fragment.
01:29:18.370 - 01:29:25.200, Speaker C: But we are working on verifying some walls and code that was generated from rust, for instance. So that's also worth.
01:29:27.590 - 01:29:47.880, Speaker A: And you can define your language yourself. There are lots of examples and we believe that all the tools that K provides incentivize people to formalize. Yes.
01:29:48.350 - 01:30:00.860, Speaker B: If we don't have access to the formal verification, for me, I'm just like what kind of practice we can apply now.
01:30:01.490 - 01:30:17.380, Speaker A: So that's why Firefly is supposed to be. Firefly will be a tool that captures the whole audio information for the gateway. But then you need to formally specify the properties, and that's unavoidable. That's either you need to learn or work with other people.
01:30:18.710 - 01:30:19.458, Speaker B: That's what we do.
01:30:19.464 - 01:30:30.374, Speaker A: Actually part of our audit. More than half the time in an audit we spend with the customer understanding their properties to help them formalize specifications of their properties. Yeah.
01:30:30.412 - 01:30:31.606, Speaker B: But I want to know what are.
01:30:31.628 - 01:30:33.542, Speaker A: Some low hack tools we can become.
01:30:33.676 - 01:30:37.126, Speaker B: For example, nowadays, I guess a lot.
01:30:37.148 - 01:30:47.450, Speaker A: Of programmers use, especially like property checking. Yes. Can we use some of the tools?
01:30:49.790 - 01:30:51.902, Speaker B: We don't need to spend too much.
01:30:51.956 - 01:30:54.560, Speaker A: Time to change the way.
01:30:56.050 - 01:30:56.510, Speaker D: Exactly.
01:30:56.580 - 01:31:05.566, Speaker A: That's why we wanted to have Firefly. Exactly. Doesn't mean that because you say that the testing will be automatic, we don't.
01:31:05.598 - 01:31:08.386, Speaker B: Really need to write, you still need.
01:31:08.408 - 01:31:28.550, Speaker C: To write tests to get execution basis for Firefly. But the point is that now you can get more out of writing your tests would be the idea. There's some work that's unavoidable, you need to somehow tell it. This is what I want my contract to do, either in the form of tests or in the form of a formal specification, which is more exhaustive.
01:31:29.790 - 01:31:35.980, Speaker B: For example, if you're working with solidity, if you are assertion solidity right by yourself.
01:31:40.990 - 01:31:42.860, Speaker A: I'm definitely tell the tool what?
01:31:44.290 - 01:31:47.260, Speaker B: Yeah, definitely. I just want to get.

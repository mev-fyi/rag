00:00:00.320 - 00:01:12.594, Speaker A: Method. But in the context of smart contracts, maybe you could use it to detect if some transaction reverts. But it's not the bugs that we want to find. Mainly we want to find when some properties or some specification will not be, will be falsified. So it's more interesting to detect when some property which is supposed to be true according to specification is actually false. This is why we add a property which is a generalization of a unit test, which must be true always in every situation. So a typical example taken from Echindal's workshop is the balance of the sender, actually of the balance of any user must be always smaller than total supply if it's a token with a fixed supply.
00:01:13.414 - 00:01:20.550, Speaker B: And so this is what Echina calls.
00:01:20.582 - 00:01:30.034, Speaker A: Fuzzing, but it can also be called poverty based testing in general. So in addition to the smart contract, you add some invariants that you want to test.
00:01:30.574 - 00:01:35.114, Speaker B: And in this case, echinnor or foundry.
00:01:36.254 - 00:01:43.354, Speaker A: Will generate many transactions on the smart contract. And at every transaction, after every transaction.
00:01:44.534 - 00:01:48.270, Speaker B: Will verify if the property holds, and.
00:01:48.342 - 00:01:56.504, Speaker A: If not it will, we will know in this case that the property is actually false. There's a bug in the spot contract.
00:01:58.564 - 00:02:02.820, Speaker B: So it's not free automated in this.
00:02:02.852 - 00:03:12.616, Speaker A: Case, but it's semi automated because the developer must, or the editor must implement some property in addition to the smart contract. Echinza's workshop was very good to understand what kind of properties we how we must find properties to use echina and to detect bugs. But it did not go deep into how this Echina software was able to generate in a smart way those sequences of transactions to be able to detect sometimes that some properties were falsified were actually false. So I tried to dig in Echidna's code, but it's written in Haskell. For me, it's quite obscure, honestly. And by chance I stumbled upon fuzzing like a djan, which was written in.
00:03:12.640 - 00:03:20.894, Speaker B: Python using hypothesis, which is a famous.
00:03:21.314 - 00:03:51.254, Speaker A: Library in Python, specialized for property based testing. And I tried to improve on what Xerox Alphaosh did and added some missing features. Shrinking was added automatically when you use hypothesis library. Actually, whenever it detects some assertion was falsified.
00:03:53.994 - 00:03:59.090, Speaker B: So the problem is that sometimes the.
00:03:59.122 - 00:05:10.598, Speaker A: Generated counterexample is very complicated, so there is a phase afterwards where it tries to minimize the complexity of the generated tests. For example, if, let's say we generated counter example containing up to 100 transactions, the developer is at first happy. He sees, oh, nice. I was able to find a bug, but actually it's very complicated to understand why, because if you have 100 transaction, you must read one by one, try to understand what sequence of transaction was responsible of this bug. So this is what shrinking is supposed to do, is to find the smaller subset of transaction triggering the bug, and the simplest. So it's, it also simplifies inputs. So for example, if a very big inside integer triggered the bug, maybe you could find a very small integer triggering the same bug.
00:05:10.598 - 00:05:12.294, Speaker A: So it's also part of shrinking.
00:05:12.334 - 00:05:18.358, Speaker B: So both simplifying the inputs of each.
00:05:18.406 - 00:05:53.176, Speaker A: Cause and restricting the size of the counter example of the sequence of transaction. The second feature was swarm testing. So to understand it, I really recommend reading Alex Gorst's blog. It's very well written. The idea is that diversity is really important in practice.
00:05:53.280 - 00:05:56.366, Speaker B: When you do fuzzing, like in machine.
00:05:56.390 - 00:06:38.854, Speaker A: Learning, in general optimization, it's really helpful to use a diverse set of fuzzers or diverse set of configuration of fuzzers, because. So this is a bit subtle maybe, but in general, you cannot find one single configuration or one single algorithm, which can be optimal for any possible problem or any possible optimization problem. So usually if you want to find.
00:06:39.874 - 00:06:44.186, Speaker B: Maximal amount of bugs, it's a waste.
00:06:44.210 - 00:06:52.880, Speaker A: Of time to, let's say, use only one configuration. So let's say you fix all those.
00:06:52.912 - 00:06:56.768, Speaker B: Parameters and you put all your energy.
00:06:56.856 - 00:07:13.360, Speaker A: So all your fuzz runs on one single configuration. It's not optimal. Why? Because it happened that some configuration, some like, let's say here you have a simplified example with two configuration, algorithm a and algorithm b.
00:07:13.552 - 00:07:18.386, Speaker B: On some problems, algorithm a will be.
00:07:18.410 - 00:07:39.294, Speaker A: More efficient than algorithm b and be able to find more bugs. But on other cases, algorithm B will dominate algorithm a. So the idea of some testing is very general, and it tells you just use many configurations and try to distribute.
00:07:39.834 - 00:07:43.574, Speaker B: Your first runs your number of, of.
00:07:43.614 - 00:07:46.750, Speaker A: Fuzzing steps on different configurations.
00:07:46.862 - 00:07:49.854, Speaker B: And a simple way to do it.
00:07:49.894 - 00:09:01.174, Speaker A: Could be easier to, for example, run if you have 1001st ones in total, you could, for example, run 100 of them with very small sequence length. So this parameter is the maximum length of transactions that you want to send. And other configuration could be the same, but with a very big length sequence. But here shrinking is even simpler. In this case, it's just so if this parameter is true, you can, it tells the fuzzer actually to sample a subset of functions that you are, that you are allowed to call before constructing each sequence of transactions. So here I did, I showed a simple example.
00:09:02.994 - 00:09:06.898, Speaker B: With a contract with just.
00:09:06.946 - 00:10:23.802, Speaker A: Two functions, one reset function, one set function. The reset function puts some counter state variable to zero, and the set function just increments these counter variables. And the invariant that you want to check is flag one. Flag one is initialized to true, but you notice here in this code that you are obliged to call set for 50 times in a row without calling the result one in the middle, to be able to break this invariant. So a naive approach where you would sample randomly just between reset and sets would be very bad, because you will almost always interleave some calls to the set function by some reset call. So what swarm testing will do is that sometimes it will choose a configuration where only one of those functions will.
00:10:23.818 - 00:10:27.602, Speaker B: Be called and then put all its.
00:10:27.698 - 00:10:59.218, Speaker A: Energy on coding 100 times only one of those functions. And this is why, in this case, it's working. I don't know if it's clear, but it's sound testing is a way to, in a nutshell, have diversity of different configurations to sample from, and it leads to a more diverse set of generated tests. And so this way, it's able to.
00:10:59.226 - 00:11:04.382, Speaker B: Catch more bugs and then coverage.
00:11:04.478 - 00:11:05.326, Speaker A: Guideline.
00:11:05.510 - 00:11:06.274, Speaker B: Yes.
00:11:11.294 - 00:11:58.874, Speaker A: Yes, this one. Okay, so maybe I missed something. So how fuzzing like a smarter design works is that it will be able to detect that one of your contracts contains a setup function. So in this case, we have two contracts. We have environ breaker and environtest. And environtest contains a setup function. It's similar to how foundry works for environ testing.
00:11:58.874 - 00:12:19.830, Speaker A: So it will know that environ test is the contract which is responsible for your setup. And it will, at the very beginning, before generating sequences of transaction, it will call once setup function. So this will deploy your environ breaker.
00:12:19.862 - 00:12:31.274, Speaker B: Contracts, and then the fuzzing campaign will begin, and it will know that all.
00:12:31.314 - 00:12:41.374, Speaker A: The fuzzing candidates or all the functions that the fuzzer allowed to call are in this environment, breaker, which was deployed inside the setup function.
00:12:41.834 - 00:12:42.574, Speaker B: And.
00:12:45.034 - 00:12:55.904, Speaker A: There'S maybe a small subjectivity. It's that if, let's say, your parameter sequence length is equal to 100.
00:12:59.324 - 00:13:04.144, Speaker B: What will happen is that hypothesis will generate.
00:13:04.484 - 00:13:09.924, Speaker A: 100, a sequence of 100 at most.
00:13:10.004 - 00:13:13.864, Speaker B: Or sometimes less 100 transactions.
00:13:14.294 - 00:13:16.742, Speaker A: Then each transaction will be sent one.
00:13:16.758 - 00:13:21.566, Speaker B: By one to a local node, and.
00:13:21.670 - 00:14:20.284, Speaker A: After each of the transactions, the environs will be checked because it's not at the end of the sequence, it's really at every transaction in the sequence. Because sometimes if you are unlucky and you call 50 times the set function without checking the invariant, but then you call reset and you only check at the end of the sequence, you will not be able to detect that at some point the sequence of transaction was able to break the environ. So it's really checked after each transaction inside the sequence. And when this sequence of transaction is completed and all checks after each transaction actually true here, then the state of the blockchain is reset to the deployment state.
00:14:20.784 - 00:14:21.524, Speaker B: So.
00:14:23.264 - 00:14:45.754, Speaker A: We go back at the same state just after the setup call and another sequence of transaction will be generated again and the same loop continue for amount of sequence of transaction.
00:14:47.374 - 00:14:52.646, Speaker B: Okay then, so constant mining.
00:14:52.710 - 00:15:38.308, Speaker A: It's easy to understand, it's that sometimes if you generate random inputs, you could never detect, like here I put a small example, you will never be able to detect or to reach this kind of branch. For example, if x equals equals very weird and big constant by chance. Of course fuzzing will not reach it if it's free random. So this is why I use slitter. Actually Echina is doing exactly the same thing.
00:15:38.476 - 00:15:40.184, Speaker B: So I.
00:15:42.404 - 00:15:44.380, Speaker A: If you go to slitter.
00:15:44.492 - 00:15:50.292, Speaker B: I think printers guidance, echidna here you.
00:15:50.308 - 00:16:00.594, Speaker A: Will see that slitter is extracting with some function like extract constant functions.
00:16:02.414 - 00:16:03.174, Speaker B: Yes.
00:16:03.334 - 00:16:05.430, Speaker A: You can zoom it a little bit.
00:16:05.622 - 00:16:08.114, Speaker B: Yes, thank you.
00:16:08.774 - 00:17:01.934, Speaker A: So here I will not go too deep into the details, but the idea is very simple. It's that slitter is able to detect from the abstract syntax tree of the smart contracts each hard coded literal type inside your solidity file. And this is how it's able to detect that. For example, we have this hard coded constant inside our solidity file and we want the fuzzer to be able to sample directly sometimes from those hard coded constants. So sometimes it's random and sometimes it will sample among all those constants. Actually maybe a small technical detail. At first I didn't want to use slitter, I really wanted to do it all by myself.
00:17:01.934 - 00:17:05.734, Speaker A: So what I did was just to.
00:17:07.994 - 00:17:11.254, Speaker B: Detect all arguments from.
00:17:13.514 - 00:17:24.478, Speaker A: All the push opcodes in the bytecode. Because of course on the bicode level those concerns will appear after push arguments.
00:17:24.646 - 00:17:27.926, Speaker B: But actually this was not very smart.
00:17:27.990 - 00:18:25.292, Speaker A: Because when you do this you lose information because you are merging all types together. And also you will get some special constants like the free memory pointer location for solidity you will get finally a very big set of constants which are just too much and will waste the waste energy for the fossil. So it was really more interesting to do like slitter and for example to say, okay, in this, in this abstract, abstract syntax tree, I know that some integer is hard coded, so I want all function having integer as arguments.
00:18:25.468 - 00:18:29.396, Speaker B: To focus on this constant, etcetera.
00:18:29.460 - 00:19:18.828, Speaker A: Same for addresses and for other types. It's smarter and easier to do it like this. And of course it works also with strings. Here I did an example where my invariant flag zero will be broken only if this long string for zing like collision will be generated, which will never be the case if the fuzzer was generating simply random strings. But when adding hard coded constants, it detects it immediately. And finally, coverage guided fuzzing. So this is very interesting.
00:19:18.828 - 00:19:29.264, Speaker A: And most of modern fuzzers actually focus on coverage guided fuzzing. There are many ways to do it.
00:19:31.264 - 00:19:34.968, Speaker B: So actually I had a hard time.
00:19:35.016 - 00:19:55.528, Speaker A: Implementing this feature because hypothesis was not compatible. Actually a part of this not compatible with what they call targeted property, targeted example generation.
00:19:55.576 - 00:20:06.618, Speaker B: So what this means is that when using hypothesis, you can add search components.
00:20:06.706 - 00:20:17.094, Speaker A: Which would optimize some target function. But at first I wanted to use, I explained it in my article.
00:20:17.514 - 00:20:22.574, Speaker B: I wanted to use this feature which.
00:20:23.354 - 00:20:55.444, Speaker A: Allows to optimize some targets together with what they call stateful testing. But it didn't, it didn't work. It was not compatible. So I had to refactor all my code without use, without using the stateful testing feature. So it's based on what they call based machine. Anyways, you can also see my legacy code using this feature. This was.
00:20:57.704 - 00:21:00.284, Speaker B: The first blocking point, but.
00:21:05.744 - 00:21:58.114, Speaker A: The second difficulty was that even this feature, when it works without using the rule based machine, is not very optimized. So I'm still working on it. But you can already test it. I added yesterday, on Monday I think a test where it works well. Let's go on my repo what I did is simple test coverage test. So in this case there is only one function in my environ breaker contract. The fourth function taking small un eight.
00:21:58.114 - 00:22:06.434, Speaker A: And you will notice that the only way to break the invariant fact zero is to first.
00:22:08.254 - 00:22:15.384, Speaker B: Call fuzzing with some value between 40 and 60, then call.
00:22:15.424 - 00:22:36.084, Speaker A: It immediately to not reset the counter with another value between four and 60, and a third time with a value between 210 and 230. This way your flag will be set to false and the invariant will be falsified. So it works how I did to.
00:22:37.424 - 00:22:43.384, Speaker B: Make sure that it was working. This is also.
00:22:45.764 - 00:23:24.284, Speaker A: One of the things that make developing fuzzing software is that each time you do a fuzzing campaign, your results will be non deterministic. So you have to run it many times. So what I did is that I run it with a small sequence length parameter, like five maybe, and up to 1000 fuzzing runs. So with this configuration, I run it for 30 times with, with coverage.
00:23:25.064 - 00:23:25.952, Speaker B: How is it called?
00:23:26.048 - 00:24:29.810, Speaker A: With coverage guidance set to true and 30 times set to false. I noticed that only three times when it set to false, it was able to break the invariant, but almost 20 times, uh, among 30 when coverage is true. So it actually works. I did the statistical tests to me to be sure it was very significant, it works. But unfortunately, on more complicated cases, like I tried several bunches more complicated tests, like many functions, each of them is a lot of branches. It's not working extremely well, unfortunately, because they say it in their documentation, they consider that targeted example generation is still experimental for them, so they not focus too much on it. And I try to dig in their.
00:24:29.842 - 00:24:34.292, Speaker B: Code and they are saying that they.
00:24:34.308 - 00:25:10.404, Speaker A: Are trying to optimize this feature, but it's based on a simple heat climbing algorithm, which gets stuck easily in local ultima. So it's not perfect, but at least in simple cases, it can help to uncover deeper bugs. But of course, I added here some, some slides to talk about how we could improve this feature later, which I did not talk about in very briefly.
00:25:11.624 - 00:25:14.204, Speaker B: In the journal article.
00:25:15.104 - 00:26:48.160, Speaker A: What you must maybe some of you are aware of what's really becoming popular nowadays in fuzzing software, what is called concordic fuzzing. Almost all modern fuzzers, best performing ones, are using concolic fuzzing. So it's a mix of symbolic execution and fuzzing. But it's not directly symbolic execution on the invariant, because when you hear about symbolic execution, most of the times it's applied to formal verification. And how it works is that you give the same inputs to a symbolic execution engine. And so you give the smart contract code, your property environment and the symbolic execution engine will convert both smart contract code and property environment into a logic formula, and use an automated terrain prover like z three or other kind of solvers to be able to prove that in all cases, your invariants will be.
00:26:48.192 - 00:26:50.880, Speaker B: Either prove to be true in all.
00:26:50.912 - 00:27:15.200, Speaker A: Cases or false, and it's able to generate a counterexample. So at first you could say, oh great. Contrary to fuzzing, with symbolic execution, this way you're able to prove that the property will always be verified. So it's more powerful than fuzzing, because when you do fuzzing, okay, you generate.
00:27:15.312 - 00:27:24.876, Speaker B: Sometimes 1 million example, you didn't stumble upon some bugs, but if you are.
00:27:24.900 - 00:27:36.464, Speaker A: Unlucky, maybe it's a false positive. You don't have this problem with symbolic execution, because symbolic execution is able, using an automated terrain prover, to.
00:27:38.644 - 00:27:42.564, Speaker B: Somehow prove.
00:27:42.604 - 00:28:39.296, Speaker A: That the environment is true. In any case, it's as if it was able to cover all unsigned integer. You have the same guarantee. But of course, when you use fuzzing because it's generating test examples one by one in the concrete way, you will never be able to generate two to the power of 256 integers. It's totally impossible. But the problem of symbolic execution used in formal verification is that it only works in simple cases, because especially if you have four loops, you can get very poor performance and you get some path exposure and it will just time out because you will have to wait maybe for billions of years to be.
00:28:39.320 - 00:28:44.448, Speaker B: Able to to execute symbolically all possible paths.
00:28:44.576 - 00:29:10.544, Speaker A: So concordic fuzzing is like how to say it's a middle point between pure dynamic fuzzing and pure symbolic execution. So how it works is that first you run your fuzzer. Like usually you generate a lot of test cases and.
00:29:12.244 - 00:29:23.544, Speaker B: You track all generated paths which were generated by fuzzing, but after some.
00:29:25.284 - 00:29:42.872, Speaker A: So it's after some number of steps, let's say 1000 fuzzing steps, you analyze your control flow graph and you will see that some, if branches were never.
00:29:42.928 - 00:29:47.804, Speaker B: Reached, maybe typically it could be some.
00:29:48.824 - 00:30:37.654, Speaker A: Like in the example I showed you before, some very hard to reach if branches with some stuff like if x equals equals some constant. But even harder than this because here in this case, it's very easy to tell to the fuzzer, okay, generate me x equals to this hard coded constant. But what if instead of x equals some constant, you add x equals some complicated function of x and y and other inputs. So in this case, the only hope is to use symbolic execution by telling your symbolic execution engine to find a path which will negate.
00:30:39.474 - 00:30:40.574, Speaker B: This branch.
00:30:43.074 - 00:31:02.490, Speaker A: Which was never been able to be covered by the initial. Further, if you're lucky, because this problem is easier than just letting the symbolic execution join just reach all paths. Here, you tell it, okay, I know.
00:31:02.562 - 00:31:06.818, Speaker B: This branch is hard to reach, so.
00:31:06.986 - 00:31:21.722, Speaker A: Let'S do some symbolic execution to solve specifically to this branch that I was not able to discover before. And like this, you are able to.
00:31:21.778 - 00:31:28.722, Speaker B: Discover a new path using symbolic execution. Then you do again some fuzzing and.
00:31:28.738 - 00:32:04.502, Speaker A: You notice that this other path was never reached after some fuzzing steps. So you call again your symbolic execution engine. You tell it okay, this match branch was never reached. Could you find me a path by doing symbolic execution? Can you find me some inputs which be able to cover this much branch? Then it's able to reach it. And like this, you can find deeper bugs. I don't know if it's clear or.
00:32:04.518 - 00:32:08.710, Speaker B: Not, but the idea is that instead.
00:32:08.742 - 00:33:48.276, Speaker A: Of letting assembly execution randomly explore all your, all your paths, you are able, by leveraging fuzzing in a kind of outer loop, to focus on only the hard branch, using symbolic execution this way. So in cocolic fuzzing, fuzzing and symbolic execution are complementary. Actually, I think it was mainly curiosity on the fact that it's when you read like popular documentation, like echinacea documentation or fundraise documentation, you don't know how they are working. And I feel by knowing exactly how it works under hood, you might understand in which cases, what are the limitations, and in which cases you could use other techniques like symbolic execution, to go even deeper by using this kind of automated tools. And if you're interested in this topic, there's an excellent reference. It's the fuzzing book. It's really, really cool, because first of.
00:33:48.300 - 00:33:51.724, Speaker B: All, it's in Python.
00:33:51.884 - 00:34:01.822, Speaker A: You have some video tutorials, and even if you don't know, even if you're not familiar with Python, although it's a very simple language, they even teach you.
00:34:01.958 - 00:34:05.238, Speaker B: The basics of python and they go.
00:34:05.326 - 00:34:16.894, Speaker A: Really far, so they even explain concolic fuzzing and symbolic fuzzing and the latest advances in modern fuzzing.
00:34:17.054 - 00:34:22.046, Speaker B: And each time you have detailed hands.
00:34:22.070 - 00:34:32.612, Speaker A: On tutorials on how to implement them. And I found it really helpful, because if you, if you read echina or.
00:34:32.748 - 00:34:36.220, Speaker B: Foundry documentation, they are very good to.
00:34:36.372 - 00:34:41.564, Speaker A: Tell you how to use their tool, but they never tell you what's going on on the hood.
00:34:41.604 - 00:34:42.184, Speaker B: So.
00:34:43.884 - 00:35:29.404, Speaker A: This is very good reference. Understand? I'm gonna make a question, then I'm gonna open for questions and then you guys can finish. Thank you. Question. So my question is, what is the performance cost of fuzzing? And is that even relevant? You mean what's the performance cost of fuzzing? Like a smart addition or. No, it's a good question.
00:35:31.024 - 00:35:31.804, Speaker B: Yes.
00:35:36.024 - 00:35:47.916, Speaker A: Yes, yes, it's a very interesting question. And because of course, fuzzing, like a smart edition, is not a very serious fuzzer.
00:35:47.940 - 00:35:50.340, Speaker B: So it's in python, it's using an.
00:35:50.372 - 00:35:56.924, Speaker A: External node, it's way slower than.

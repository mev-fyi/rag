00:00:05.320 - 00:00:26.891, Speaker A: Oh great. Okay. So the point of my research is to understand and to increase the appreciation of Forza in the whole space, right? And that's why I termed it philosophy of Fuzzing. Because I'm aiming to capture not just the, the practice of the how tools of fuzzing, but the concept and the theories behind this technique in itself.
00:00:26.963 - 00:00:27.651, Speaker B: Right.
00:00:27.843 - 00:00:54.975, Speaker A: And, but today's presentation is going to focus mainly on the efficacy of fuzzing, right. I feel this is the, this is the best place to start before. Because before doing anything you have to answer the why part of it, right? You have to know why you're doing this or whoever you're pushing this technique to have to know why it's so effective, why it's so good and compared to other approaches out there, how does it perform?
00:00:55.055 - 00:00:55.559, Speaker B: Right?
00:00:55.687 - 00:01:19.813, Speaker A: So that's what this part of my research, right? It's a three part research and this is just a part one, right. And there's. I will touch a little on the part two and then show you what I'm currently working on with my team to kind of push the space for them. So. All right, so a little background about myself. I've been in the Web3 space for quite some time, I think approaching five years now.
00:01:19.869 - 00:01:20.325, Speaker B: Right.
00:01:20.445 - 00:01:51.011, Speaker A: So I have worked with M as a contract research analyst. I've been in, I've been an active member of the Token J Academy. Well, no, not recently although. But as of a year back I was pretty active there. And my main tool back then was machination. So I was one of the leading users of this tool. And till today, if you go on the dashboard, you see my name up there as a top designer on the platform.
00:01:51.011 - 00:02:27.535, Speaker A: So. And again, this, this is why I actually fell in love with. Was in the moment I came into Web3 Security Research, right. Because I've been into, I've been in this simulation space and Fuzen in, in the recent is basically simulation, right? So machination is a simulation tool and it made. It kind of gave me that background to transcend into this new space of Fuzen. So now entering the space and hearing about forcing and all that, I knew I wanted to know more about this and I started asking questions, but I wasn't getting good enough. Like I was getting good answers, right.
00:02:27.535 - 00:03:02.619, Speaker A: But I just weren't scratching the edge for me, right. And so I realized, okay, I have to do some research myself to figure things out and then maybe kind of build this couples of research for myself and those in the space right now. So just starting this research, I. I Didn't study head out to do a research on fuzzing. I just was studying research report previous audit reports from platforms like Shellocks and Code arena. And I built a digest sheet which I will show you in a moment.
00:03:02.667 - 00:03:02.947, Speaker B: Right.
00:03:03.011 - 00:03:53.647, Speaker A: I built a digest sheet as a way to effectively study audit report because you can read report just like any other book, right? You need a strategy, a way to read the report, read the findings, such that you can miss it next time. And that way I find the best way I find to do that is to extract a heuristic from every finding I read such that I can apply that heuristic to any code base I see in the future. And this also ties to the tool we are building which I will show at the end of this. I can't wait to show you that which I will show at the end of this presentation. So from the motivation of trying to understand how to motivation of trying to read report more effectively, I then saw opportunity. Okay, let me not just do this about myself or reading person, let me make this a broader scheme and start. And actually start doing the research on forzing.
00:03:53.647 - 00:04:24.563, Speaker A: And so I expanded it, right? So it didn't just become a research on forzing. I actually want to know, okay, now this is forzing. How good is frozen? Then let me compare it to mama review and see how it performs. And from a personal research I then say, okay, after sharing this with a couple people in the space and they were like, wow, this is good. I think this would be very beneficial for the space. I then said, okay, maybe it's best I package this as something that other people can consume. And that was how the research was built.
00:04:24.619 - 00:04:24.979, Speaker B: Right?
00:04:25.067 - 00:04:28.107, Speaker A: So I believe that's enough intro.
00:04:28.211 - 00:04:28.855, Speaker B: Right.
00:04:29.845 - 00:05:02.611, Speaker A: So thank you. So now I'm going to. We're going to go through the first walkthrough of the, of the spreadsheets which contains the like the raw data of this research. So okay, before that I would like to share something with you. So in case anyone is here, I'm following the two links that I'm going to share. Here are the links to the spreadsheet and the links to the. And the links to the presentation I'm currently going through right now.
00:05:02.611 - 00:06:07.445, Speaker A: So feel free to perish through and follow along. But I encourage you to follow the presentation and go through the document on your on your own time and feel free to DM if you have any question. Okay. Okay, so the first walkthrough just, I'm just going to show you how to utilize this and basically what everything what, what every here is doing and how to understand it so that when, when you jump on it on your own time you have better understanding of what to do. So the intro sheet here basically just give, tells you what, what, what I just say right now the motivation for this research and the report guide is what I'm, I'm about to do now like helping you understand the, this sheet, the whole spreadsheet and expansion idea I just follow up research. Like I said, this is the part one, right? The efficacy of force and it's just the part one. So expansion research are other ideas that were popping into my head while I was doing this, right.
00:06:07.445 - 00:07:01.869, Speaker A: So I've talked of, okay after this will I just go be on all of solo this finding and do like largest key analysis of those findings there or I should just do maybe a focus research on the top auditors in the space, right. Kind of get a glimpse. So maybe let me remove this strike so we see what I'm talking about. So these are all just research ideas right that I've been concerned. But right now I think this is the best one I have right now to follow up to follow up this research with the part two which is going to focus on environment formulation. And I will tell you, I will tell you why this is the best, the best next step for me now and when we're done with this. So then the legend sheet is where is where it's critical for understanding the whole shape because this is where I labeled all these shots from.
00:07:01.869 - 00:07:52.663, Speaker A: So if you go through data analysis you see most of these things here I used shorthands for them, right? Abbreviations and the label sheath is where you get to see the full meaning of all of those shorthands and also where I define the constraint of this research and the rules and assumptions that I've made in this research. Because I can't just leave it open ended because you know we are in a very subjective space and certain things can mean different things for certain people. So I have to make everything clear that okay, these are the assumptions I'm working with and based on these assumptions these are my findings. So that's what the ship does. Now the two things I just need you guys to focus on here. The main things I just need you guys to focus on here. Is this the meaning of fz, right? NFC and checklist Bulk and unique bug, right.
00:07:52.663 - 00:08:25.469, Speaker A: So hate here just mean high finance. NPM means medium finance. FZ means forcible bugs. Now forcible bugs here are defined as any bug that can be Caught with a basic forzing setup. That's the typical setup you find in any code base that considers fuzzing as part of their security approach. So now I have to study a long list of public fuzzing campaigns to get a sense of how most people design their frozen suit.
00:08:25.517 - 00:08:25.989, Speaker B: Right.
00:08:26.117 - 00:08:36.933, Speaker A: So there are other approaches that can be, that can be used to enhance what most people do. Right, but that's not the purpose here. You know, when you're doing research like you have to take the median approach.
00:08:36.989 - 00:08:37.469, Speaker B: Right.
00:08:37.597 - 00:08:49.483, Speaker A: So that's what I've done here and now nfz, right? NFZ just means non fable bugs. These are bugs that as defined in my research, these are bugs that cannot be caught with frozen.
00:08:49.539 - 00:08:49.971, Speaker B: Right.
00:08:50.083 - 00:08:59.115, Speaker A: Again, there are certain assumptions here, right. Typically these are bugs like. These are bugs that typically generate from the design of the EVM machine.
00:08:59.155 - 00:08:59.619, Speaker B: Right?
00:08:59.747 - 00:09:04.747, Speaker A: So things like front running, things like block reogs.
00:09:04.811 - 00:09:05.299, Speaker B: Right.
00:09:05.427 - 00:09:09.955, Speaker A: Things like Sandwich attack, I just term them as non phuzzle bugs in a recent.
00:09:10.035 - 00:09:10.419, Speaker B: Right.
00:09:10.507 - 00:09:43.013, Speaker A: There are ways you can. So this, I'm just saying this as a session. There are ways you can design your forzing suit to test for this type of bugs, right? But that's not the average. That's not what average Forza suit looks like. So I don't consider them as fossil bug for this research right now. Checklist bugs are bugs that you can catch by simply using public checklists like solidit and Owen Terms checklist. I believe everyone here is familiar with these two checklists and that's why I went with them.
00:09:43.069 - 00:09:43.759, Speaker B: Right.
00:09:43.957 - 00:09:46.539, Speaker A: And the last one, unique bugs.
00:09:46.587 - 00:09:46.819, Speaker B: Right.
00:09:46.867 - 00:10:06.579, Speaker A: So unique bugs are bugs that don't fall under. They are not for they are non faucetable bugs that don't fall under the checklist category. So by now you understand that these two bugs are basically subcategories of the NFZ bug.
00:10:06.627 - 00:10:06.763, Speaker B: Right?
00:10:06.779 - 00:10:23.689, Speaker A: So there are two main categories in my research, the FZ bug and the NFZ bug. That's fuzzy bugs and non fuzzy bugs. Under fossil bugs we have checklist bugs which are bugs that can be caught with checklist loaded and unique bugs. That typically comes from understanding the code base in depth.
00:10:23.737 - 00:10:24.257, Speaker B: Right.
00:10:24.401 - 00:10:31.865, Speaker A: And you won't find leads or heuristics on public checklists to catch such. To catch such bugs.
00:10:31.905 - 00:10:32.465, Speaker B: Right.
00:10:32.625 - 00:11:13.963, Speaker A: And you can't really define these kind of bugs because they depend on the code base. So actually then the next sheet, data entry. So data entry is where I entered all the data that I extracted from the research. So what this looks like is I would let's say we pick one research, one report here. Let's use the first one. So this is Midas content contest, right? And I'll go to the contest reports and I will work through every finding here, right? I pick, I'll pick one of them, then I will read the finding, I'll redefining, then I'll categorize them. Okay.
00:11:13.963 - 00:11:59.847, Speaker A: This, this part here, let me, let me skip this for now. So I'll read the finding. First of all, if you say hi, I, I'll place it under one of this category here. Is he a high fable bulb or a high non fable? Is he a medium fable or a non or medium non fable? And I can only do that by reading this report, right? And also I read it and I judge it based on the constraints I've set in the, in the legend, right? Based on my assumptions and constraints. So I'm going to, that's, I'm going to categorize. That's, that's the rule I use for categorizing this, this reports. So, so now let's let me walk you through this, the first part that I just closed here or.
00:11:59.847 - 00:13:17.445, Speaker A: So this is just the general details of every contest, right? How much is the contest pool? I typically remove the amount that is given to the lead Watson, only factor the parts that is open for context. So in this case the total reward is US$13,500, right? But the context pool is US$8,000. So this is what I, this is what I consider in my research, right? Because I don't want something. I don't want anything that will skew the results, right? Then the N SLOC number of line, the dates of the contest, the total finding, everything here you can get from the contest page, right? Total finding, the total solo finding, the total high finding, the total medium finding, and another reason I wanted to provide as much detail as possible in this, in this data is because I may use this table to get my, to do my own analysis and answer my question, right? But someone else can take this same data, right? And extract different information from it, right? Someone can decide to say, okay, I want to study only the solo bugs here and see what really makes a solo bug. This is something I actually plan on doing later, right? To see if there's any trend between what usually ends up as solo bugs or low finding bugs.
00:13:17.485 - 00:13:17.805, Speaker B: Right?
00:13:17.885 - 00:13:56.525, Speaker A: So the point is. Sorry, come on. Yeah. Can you come again please? No, no, no. I was reading manually, so just a manual approach. So to give you a sense of how much work went in Here I started this research somewhere March or April this year and we are in October now, right?
00:13:56.865 - 00:13:57.645, Speaker B: Yeah.
00:13:58.105 - 00:14:19.015, Speaker A: So that's how long it took me. That's how long it took me to put this together. So although I. I wasn't just doing this, I was combining other things because I had to participate in contest. If I see a pattern here or I discover some techniques that I can apply, I take that and apply that to some contests and see how the result turns out and come back.
00:14:19.055 - 00:14:19.423, Speaker B: Right.
00:14:19.519 - 00:14:49.559, Speaker A: Because most of my contest so far has been trying out different techniques. Right. So. And most of the techniques were born out of patterns that I recognize from this research. Can I can. All right, so the first category here is basically just putting the finance and the different groups is either a high fable. High non fable medium fuzzing.
00:14:49.559 - 00:15:34.461, Speaker A: Then the next category is something that is the. So this part, this category here, the whole idea of making switches as extensive as I possibly could is what led me to include this category. Because no, I didn't just want to know about the Forza nonfuzzle. Also wanted to break down the non fossil books into tech list and unique and unique book because I don't know how good really are this or how effective are this public. What's it called again? Public checklist that we use, like how effective are they really? In contest they might be pretty effective for private audit because you're not competing with anybody and almost everything you say goes.
00:15:34.533 - 00:15:34.861, Speaker B: Right.
00:15:34.933 - 00:15:42.989, Speaker A: Because you all know. Right. But in contest the game really kind of changed.
00:15:43.037 - 00:15:43.245, Speaker B: Right.
00:15:43.285 - 00:16:06.755, Speaker A: So you want to know if this checklist are effective for competent researchers now. Sorry, come again? Okay, so one good example is in private audits you might get by with the finding like zero address check. No, zero address check.
00:16:07.055 - 00:16:07.795, Speaker B: Right.
00:16:08.175 - 00:16:16.063, Speaker A: And in context, most contest platform won't give you that as a finding if they give you probably information. So that's one example.
00:16:16.199 - 00:16:16.751, Speaker B: Yeah.
00:16:16.863 - 00:16:21.955, Speaker A: So and something like zero address check is something you find on public checklist.
00:16:22.795 - 00:16:23.347, Speaker B: Right.
00:16:23.451 - 00:16:35.451, Speaker A: So if you're doing the private audit and you're using a platform like Solidit, kudos, you need platforms like that because they'll help you check, right. Kind of check everything that needs to be checked.
00:16:35.483 - 00:16:35.627, Speaker B: Right.
00:16:35.651 - 00:17:12.053, Speaker A: At most things that needs to be checked based on the average understanding of security in the space. But in context that might not be enough. Does answer your question. All right, so now with the solo findings, like remember we have solo findings here which I group. So total solos and all of that. So with solo findings I also group them the solo finance forcible or non fossible Bugs, right? Because I don't know which approach leads to more solo finance also.
00:17:12.149 - 00:17:12.645, Speaker B: Right.
00:17:12.765 - 00:17:31.385, Speaker A: So similar thing here and for the reward aspect. So this what I do with reward. So if, let's say I have. So let me use something here. So if we go to, if we go to this finding, for instance, go to this report, for instance. Every, every.
00:17:34.205 - 00:17:34.885, Speaker B: All right.
00:17:35.005 - 00:18:57.181, Speaker A: So every report have different reward, right? All right, they have different reward for every report. So and when I categorize after placing these guys this findings in their respective category, I also want to know how much reward those findings yield. And if the frozen bugs are getting more reward than the non frozen bugs. And also down to if the checklist bugs are leading more are yielding more reward than unique bugs, right? So that's how detailed I wanted to go, right? So and if, when, when you're going through this, I want you to understand that the reason I broke this down is so you understand which, so, so it's easier to know which finding. So okay, let me put it this way. I know this is manually done, so there's room for errors, right? And some people might not agree with some bugs at I classify as forcible or non forceable or checklist or non checklist, right? So and instead of just giving them my own understanding or my truth as the final truth, right. I want, I wanted to give room for change so someone can come now and say, okay, he classified from this reward here, he can tell which finding, right? I've classified as high or sorry as fossible or non fable.
00:18:57.181 - 00:20:09.633, Speaker A: And then he goes back and change and change it as he sees fit and runs his own analysis again. Was that clear? All right, so the same thing here, right? So I just, I make sure to break every reward, right? Submission to get to differentiate which worth finding, right? But so then one more thing I did was to see, so this path here, it's mostly hypothetical, right? Because there's no real way I can. And there's margin for error here because it's not going perfect. So what I'm trying to do here is I take the reward that a Forza would have received if he has participated in a contest, right? And then take on the table like on the rank. So if you go to this rank and check the leaderboard, right? So you see how they rank based on rewards. So this guy here, I think this guy was the winner. But usually what I do, I actually take account of the actual reward they get.
00:20:09.633 - 00:20:33.695, Speaker A: Not their bonus, not their bonus reward, right? And then what I do here is I take, okay The Forza, if the father and got 2,500 and you place him in this chart here, where will he rank? So that's what I was doing here, right. So I used the percentile approach to say, okay, if in this case the Fosa, we rank and the 93rd percentile.
00:20:33.735 - 00:20:33.959, Speaker B: Right.
00:20:34.007 - 00:20:47.471, Speaker A: So this is going to perform better than 93% of the people who participated in this contest. I also added an adjustment here for er because most of the time this leaderboard don't truly reflect everyone that participated in this contest.
00:20:47.543 - 00:20:47.943, Speaker B: Right.
00:20:48.039 - 00:21:09.679, Speaker A: Because there might end up being 20 people here, sometimes even 10 people here. But in the real. In the real result, there are over. There could be over 100 people. Just that most people end up with zero reward and so they know they don't add into the leaderboard. So to factor that result. So I just added extra 10.
00:21:09.807 - 00:21:10.191, Speaker B: Right.
00:21:10.263 - 00:21:12.865, Speaker A: For to every leaderboard.
00:21:12.945 - 00:21:13.569, Speaker B: Right.
00:21:13.737 - 00:21:24.289, Speaker A: And then I check how the. How the Fosa will perform. Like Forza indices here I'm referring to the person, like a person who uses a for.
00:21:24.457 - 00:21:24.785, Speaker B: Right.
00:21:24.825 - 00:21:43.935, Speaker A: So how the FOS will perform in this context. So this is the analysis. So that's the. No, it means that he outperformed 93% of the people in the contest.
00:21:46.035 - 00:21:46.855, Speaker B: Yeah.
00:21:47.195 - 00:21:57.019, Speaker A: So let's go back to the. Oh, sorry. So if that was the first walkthrough.
00:21:57.067 - 00:21:57.563, Speaker B: Right.
00:21:57.699 - 00:22:25.833, Speaker A: So, and I believe we've gone through this. This is basically. So this just talks about the approach I took, right. So first thing I did was to collect a time period of six months for Sherlock data, right. And I selected Shell because of two main reasons. One, one, the focus on just medium and high findings. And we all agree those are the findings that really matters the most.
00:22:25.889 - 00:22:26.489, Speaker B: Right.
00:22:26.657 - 00:22:43.735, Speaker A: And the second approach, the second reason is the reward distribution. So with platforms like Code Hub, I don't know much about Code arena, right. So the two contest platform that I'm familiar with is Sherlock and CodeHub.
00:22:43.775 - 00:22:44.215, Speaker B: Right.
00:22:44.335 - 00:23:15.011, Speaker A: So with platform like Code, why couldn't use the data is because of their reward distribution. So if someone finds. If two people find the same high finding, right. One person end up getting significantly more reward than the other because of something called define report Bonus. So you're defining which was selected for the report receives about 30% more than the other person. So that kind of skews the results even if one provides. So we are pretty much providing the same value to the client, but the representative is getting more.
00:23:15.011 - 00:23:22.211, Speaker A: So I couldn't use a reward system like that for the analysis because you can tell how that will Skew this result.
00:23:22.323 - 00:23:22.931, Speaker B: Right.
00:23:23.083 - 00:24:00.615, Speaker A: So that's why I decided to stick with Sherlock. And we've gone through this key definitions, right. So once you understand these key things, most of the, most of the things are just self explanatory then assumptions. You can also read this, read the legend sheet. So to understand the shape detail, I'll just indulge you to just take your time to read the shape first before going into the rest of the. Of the spreadsheet. And I believe that will do you more good than just jumping into it.
00:24:00.615 - 00:24:52.695, Speaker A: So now for the second walkthrough, right. I wanted to show you the next side of things. So here is the analysis, right, so sorry, analysis. So after inserting all of this data, right. I did a new sheet to visualize if there are any trend or anything to notice from analyzing data or they just got pretty random or any. Is there any information that can be extracted from this? Right, because the whole point of this is to understand how good for us are and if there are any other or how good fossils are and if there any advantage to using fossils, right. And also if there's any other thing that I could find so maybe like a certain pictures adventure, like something finding something great that I didn't know I was looking for.
00:24:52.765 - 00:24:53.259, Speaker B: Right.
00:24:53.387 - 00:25:00.219, Speaker A: And so after doing the analysis. Oh my. Sorry.
00:25:00.267 - 00:25:00.907, Speaker B: I.
00:25:01.091 - 00:25:02.375, Speaker A: Let me go from this.
00:25:06.435 - 00:25:07.163, Speaker B: All right.
00:25:07.299 - 00:26:15.995, Speaker A: So after doing the analysis, right, there are some findings, right, that's that some findings that kind of stuck out to me. And these are, these are the findings I'm going to talk on here in this presentation. So for the first one, the first thing I noticed was okay, more than 55% of the bugs in the average code base are forceable, right? So this means that you can outperform 87% of the industry just by using forcers alone, right? So you don't have to stress over doing certain manual takes or cracking your brain over the edge cases that you can only get from manual analysis, right? So by using fuzzers alone you can outperform 80% of the industry. And this, this is this. I'm saying this because I'm talking about the most basic forzing setups here, right? So you're not doing any special tweaks. You're just using the most basic standard for setup. And I want things opportunity to put.
00:26:15.995 - 00:27:14.269, Speaker A: To recommend it to like recon, right? So this guy's recon. So in the part three of my, of my research, I'll be focusing on them and like showing, like put, showing how you can use this to Your advantage as a, as a, for. As a force engineer, right? Because one of the things I struggled with when coming to this space was setting up a force suit in the middle of contest. By the time you are done forcing upset force suits and implementing your environmental test, you are halfway into the contest. And then you have to run your code and catch bug and then debug before, you know, like the contest over and you had done nothing. And then you feel like you're not growing with context or you're not growing with every. You're not growing with the space, right? So it can be frustrating.
00:27:14.269 - 00:27:53.265, Speaker A: Now work tools that we can do is you can literally do weeks of work or. Okay, let me not be too generous, right? Let me know. Make it sound too sweet, right? You can do at least three days worth of work in an hour setting up that. What's it called, setting up the. Your force suits. Aside from that, with the pro version, right. You can run your force campaigns in the cloud, right? So you don't have to monitor your local system for when it runs, right? So you can just run your force in the cloud and make sure.
00:27:53.265 - 00:28:17.473, Speaker A: And whenever. Sorry. And make sure. Whenever you catch bugs in the cloud, you kind of get a lot on things, right? So. And anytime you update your suits, anytime you want to update your suit, you update and keeps on running distance for you. So I, you should, you should check it out, go to your community, ask questions and just do, do, do your research on them. Like, it's fantastic too.
00:28:17.473 - 00:28:19.465, Speaker A: So now back to my analysis.
00:28:19.505 - 00:28:19.969, Speaker B: Right?
00:28:20.097 - 00:28:24.703, Speaker A: So now. Sorry, go on.
00:28:24.849 - 00:28:25.535, Speaker B: Yeah.
00:28:36.475 - 00:29:07.085, Speaker A: Yes. Sorry, I'm losing you. Can you guys still hear me, please? Okay, go. Yes. So that's what, that's actually one of the reasons why I pointed you to recon. So it shrinked that time so much for you that you. Okay, let me.
00:29:07.085 - 00:29:35.143, Speaker A: Let's break down the process of fuzzing, right? So one of the most time consuming aspect of fuzzy is setting up the suits, building up the setup, right. Putting the right parameters and all of that and implementing your invariant. That's the most time consuming part of fuzzing. The other aspect of fuzzing that is time consuming isn't up to you. It's just about how long the fuzzup takes to catch a bulb. So that's not within your control. Now the part that is within your control is putting your suit together.
00:29:35.143 - 00:29:48.927, Speaker A: And that's what. That's one thing that recon can really help you with. And another challenge, again with fuzziness. A lot of people get stuck with selecting which Fuzzer to use. Should I use Medusa? Should I use Echidna? Should I use Foundry?
00:29:49.031 - 00:29:49.675, Speaker B: Right?
00:29:50.375 - 00:31:27.875, Speaker A: All of those fuzzers are great for their different users, right? And what Recon does is it kind of allocates like dedicate this for us to what they are best at, right? So you can use Medusa, you can use Echina for your environment for install and there are ways you can also use foundries in that same suit and they'll all give you the best of the, of their, of their capabilities, right? Most recently they are now introducing format verification, right. I don't want this to sound so much like a Recon promo seminar, right? So I just want to say that time, the time you're talking about will be shrink down a lot by using tools like that does answer your question. All right. So to the. So in Summit to if I'm going to summarize my analysis in four points, right. So the first thing I'm going to just say is okay, pausing bugs makes up over 50% of the bugs in the average code base, right? So it makes no sense why someone will be avoiding fuzzing in this space, right? Especially if you are a private practice in context I might understand, right? Because there are certain constraints with context with respect to time or you want to focus on certain things or you want some edge. Especially because contest kind of gears towards uniqueness over coverage.
00:31:27.875 - 00:32:27.011, Speaker A: So I could understand why you might not want force for every contest, but in private audits it's kind of. It should be a base level you should always force your suit, right? Because then you can have guarantee that at least, at least if you have a good suit, you have decent suit, right? At least let me, let me just shut it down. So at least 30% of the bugs, right, Are covered. So now in the case of contest, right after my analysis I realized, okay, manual review actually capture more reward Manual finding bugs that. That can be copied. Manual reviews actually captures more of the reward parts than frozen bugs, right? So the reason why I can say without speculation and I don't want to work with speculations here, right. So but it's just what I I realized from the finding, right from the, from the analysis.
00:32:27.011 - 00:32:53.333, Speaker A: So. And I believe it's because my. This is now my own on my own my own speculation, right? So I don't. It's not. And it doesn't mean to do with facts, right. I just believe it's because of the nature of manual box is they can be so. What was the word? It can be so esoteric that people only certain people will agree that this is a bug.
00:32:53.333 - 00:33:28.875, Speaker A: People appreciate it as a bug or only certain people will recognize it. Now for instance there are certain bugs that have to do with like the EVM like reorgs or certain kind of EVM tweak quick and quirks that can cause like a disagreement between different security researchers because not everyone is going to agree on that. But if the moment that boss gets validated in a contest yeah you can. You can guarantee that most people will miss it.
00:33:29.255 - 00:33:29.639, Speaker B: Right.
00:33:29.687 - 00:33:32.995, Speaker A: So bugs like that will end up racking up most of the ports.
00:33:33.295 - 00:33:33.799, Speaker B: Right.
00:33:33.887 - 00:33:53.721, Speaker A: So that's why manner if you kind of end up capturing more reward than frozen because frozen is frozen bugs are kind of objectives because we can the book the code is to try telling you that hey run this and you catch this bug. Hey, this environment is broken. So it's as objective as a bug can be.
00:33:53.873 - 00:33:54.353, Speaker B: Right.
00:33:54.449 - 00:34:03.705, Speaker A: So compared to the other one and you know those bugs that are kind of obvious that everyone can see and agree it also implies that most people can see it.
00:34:03.865 - 00:34:04.401, Speaker B: Right.
00:34:04.513 - 00:34:31.814, Speaker A: So but not every fuzzing bug is like that. No. Because I want to dunk on forzing in this process. Now another thing you can just know that Phoenix isn't. Thank you. So let me try to speed run speak through some things because I still run out of time. So again fozen is.
00:34:31.814 - 00:34:37.374, Speaker A: Oh really?
00:34:37.874 - 00:34:38.610, Speaker B: Oh my.
00:34:38.722 - 00:35:02.722, Speaker A: Thank you. So again fuzzing isn't a silver bullet, right. But it's sure enough is a good way to set you among the top researchers in this space. I don't need to mention names but you can. You can tell by just studying the the industry that okay some people are able to catch certain things they do because they are discord and frozen.
00:35:02.778 - 00:35:03.306, Speaker B: Right.
00:35:03.450 - 00:35:38.933, Speaker A: And there are examples of books that kind of difficult to catch with naked eyes. If you go to. I think Patrick Collins had a good example on one of his videos, right. And there are several examples of why you frozen can just set you apart with ace. And in a sense it's kind of an easy easier route to the top because it has. It has more of a defined part or measurable achievements if when you're for so if you're a fossil now.
00:35:38.989 - 00:35:39.517, Speaker B: Right.
00:35:39.661 - 00:35:53.485, Speaker A: Let me try to digest that now. So if you want to learn how to force right. If you want to become a force or top guy in space I want to focus on Forza, right. So you learn the tools that you need learn the tools that need to be. That need to be learned. Right. And there's so many, that's so many terrors for that echidna and all of that.
00:35:53.525 - 00:35:54.037, Speaker B: Right?
00:35:54.181 - 00:36:51.615, Speaker A: Now you then start, you then focus on invariance, right? The invariant formulation. Because your frozen suit is just one part of it. What in my perspective, the most important thing is how good you are at formulating invariance. Because you could have the best well put tool suit in the space. But if you miss certain invariants, you won't catch the bug, right? Because invariance is what tells you which bug is present, right? So now you focus on that. And if you can master these two things, especially with, if you can master these two things, then you are sure on your way there, like at least you are 70% there, right? The rest, the other part is just sharply your edge on how to perfect these two things. And that's one of the things, that's one of the challenges or one of the problems we're coming to solve with the tool we are working on, right guys, I'm going to share a little about it at the end of the end of this talk.
00:36:51.615 - 00:37:22.807, Speaker A: So again, another thing, another thing I observed from analyzing. The result is most performers, right? Most researchers. Most researchers are currently underperforming in the space. I'm not gonna say average. I'm saying most because looking at top performance in the space because every leaderboard is pretty much the top performer, right? Top performance in the space. So like I said, there are over 100 people who contest the little body end up with like 20 people. Like which.
00:37:22.807 - 00:38:55.795, Speaker A: Who are the 20 top guys? And if a basic Forza setup can get you in the top 10 almost every time, right? Tells you that most of the industry is currently like. So if they can add this tool to the repertoire, right? Then the baseline displays like the average auditor or the skill level industry skyrocket. So that's something that we have to like consider, we have to think about as an industry. And also if any contest platform is listening to this now again, once more, I've cried about this several times, right? The time constraints of this contest don't really encourage the use of these tools because you can imagine a security researcher trying to force, trying to do manual review, trying to do formal verification, right? In the span of one week or two weeks contest, right? With a code base of over 2K or 1,5, right? This guy's the beauty code base took months to build this. Now we have to understand this in three days. Look for these bugs that I can only catch manually with for how many days and then try to use for that I mean you begin to see why the industry is performing. We're constrained by so by time.
00:38:55.795 - 00:39:29.025, Speaker A: Meanwhile, black hats have no time constraint. The people who are punishing us in this space, they have no time constraints. So we should really think about that. So now with a secondary analysis, right. This is basically. This part here is basically checking how effective public checklists are, right? Things like solidate and the O. I think Solidit kind of incorporates Owen's checklist and other checklist.
00:39:29.025 - 00:39:39.529, Speaker A: So from now I will just be mentioning solo but for my research I actually make sure I went through both checklist. So things like solidity checklist.
00:39:39.577 - 00:39:39.809, Speaker B: Right.
00:39:39.857 - 00:40:04.035, Speaker A: If you break down the non fossil bugs again I want to give like. Like an assumption here. Non fuzzy bugs. Yeah, it's just bugs that can only be caught with. With manual review. There's no frozen. It doesn't mean that you can catch those frozen bugs by manual review.
00:40:04.035 - 00:40:40.429, Speaker A: So you should know, you should. I would like to make that clear. So you can catch some of the bugs that you catch with fuzzers with manual review. But for the purpose of this research I was coming from the perspective of a fuzzer before taking everything outside the scope of fuzzing as manual of as non physical bugs. So in the manual review aspect. So I hope that aspect is clear. Now if we break down the non feasible box right into the checklist bugs and the unique bugs again.
00:40:40.429 - 00:40:59.197, Speaker A: Checklist bugs are bugs that can be caught with checklists like SolidIT. Unit bugs are bugs that you can catch with checklists like solidit. Basically that's just what it means. So you have to find them by understanding the context of the code and the external context like the EVM or whatever environment is built in.
00:40:59.261 - 00:40:59.725, Speaker B: Right.
00:40:59.845 - 00:41:16.279, Speaker A: So checklist bugs make of 22% of such bugs of such books. 22% of such bugs, right in the code base and for unique bugs make up 40%.
00:41:16.407 - 00:41:17.007, Speaker B: Right.
00:41:17.151 - 00:42:08.741, Speaker A: So also on average, right for reward for the reward claim, right? Secret box only claim can only claim 12% of the claimable reward. So let me explain what I mean by claimable reward, right? So if you go to the. If you go to the entry data, right and go to the reward aspect, right. So the reward, the total reward for every bulb I sum to calculate the claimable reward for any category here what I do is I sum all of the reward for each category to get the total claim reward, right? No, the total claim reward is not the total port. It's just the total reward for each. If you add the reward amount for each findings add all of them together.
00:42:08.813 - 00:42:09.165, Speaker B: Right?
00:42:09.245 - 00:43:07.375, Speaker A: So now in a particular case that someone found all of those bugs, the person will have, will have 100 of claimable reward. Yeah. So checklist bulk. Now to calculate the claim reward for any of these guys here, which just be the percentage of the this their own reward divided by the total reward here, which is basically the percentage of that total reward that was captured, right. Please can someone confirm if that was clear enough or after retry. Hello? Are you still with me? All right, so claimable rewards are the rewards that a particular category claim out of the total reward that was given for each, for each bugs. So if we go, so if we take a finding here, take a report here.
00:43:07.375 - 00:44:20.105, Speaker A: Oh, this job, I want something that has more finance. That's weird. So the total reward here will be summing each of this reward, right? So if you are, if you somehow claim you somehow found this toolbox, right? And you got 7,200 out of the total reward, out of the summation of all this reward, your claim would be the this reward, the sum of these two divided by the total, whatever percentage that is. So you end up with say you, if you claim you got 80 of the claimable reward. So that's how I calculate claim.
00:44:21.325 - 00:44:22.037, Speaker B: Yeah.
00:44:22.181 - 00:45:07.507, Speaker A: So, so back to Mr. Nice. So now Kepler on average, right. Only captures 12% of the claimable reward while unique bugs capture capture 53% of the claimable reward. So you can see there's a clear difference here, right, that this checklist kind of lags behind trying to understand the code base. And if you think about it, right, logically those researchers who take their time to understand the code base, right. We naturally perform those who rely on the checklist or who, especially if the checklist is a general checklist, right.
00:45:07.507 - 00:45:25.611, Speaker A: And one of the reasons this checklist will perform as such is because they get a lot of duplicates, right? Because you are using the checklist that almost everyone is using. So if you find a bug using that checklist, the chances are someone else found similar bugs is also high. It's very high because they are using that same checklist.
00:45:25.643 - 00:45:27.203, Speaker B: You are right.
00:45:27.379 - 00:46:15.005, Speaker A: So that's one big reason why the, that's one reason I think why the checklist reward is like so, so much lower than the unique, the unique approach. So within this, the next analysis I wanted to do was to only analyze code is to only analyze the code base with solid with a code with an n slock of 1000 and below and also do something similar for 3000. Right. So I was going for 3000 but after grouping them and I realized this wasn't enough data to spend time analyzing. So it's similar thing for 1000, but at least it's better.
00:46:15.085 - 00:46:15.301, Speaker B: Right?
00:46:15.333 - 00:46:16.749, Speaker A: It's better than the 3000 case.
00:46:16.797 - 00:46:17.221, Speaker B: Right.
00:46:17.333 - 00:46:38.555, Speaker A: So I can't make any conclusion based on this analysis. I can just analyze five, six contests and make a statement. So it's, it won't be rich enough data for that. So with the 1000. Right. It's still not rich enough data like. Well, it.
00:46:38.555 - 00:46:47.235, Speaker A: I mean for the purpose of this, I guess it will pass for I trust web3 someone can take this and build upon it and make it so much richer.
00:46:47.275 - 00:46:47.709, Speaker B: Right.
00:46:47.827 - 00:46:48.845, Speaker A: So let's.
00:46:49.225 - 00:46:50.005, Speaker B: Yeah.
00:46:50.465 - 00:47:13.529, Speaker A: So from this analysis, right. War with the code base. Code base under 1000, 1000 slot, as it kind of evens out with the average bugs, is kind of balanced between non fuzzable and non fuzzable bugs.
00:47:13.577 - 00:47:14.127, Speaker B: Right.
00:47:14.281 - 00:47:23.675, Speaker A: So it's a 50, 50 case of the type of bugs you find in the average code base.
00:47:23.715 - 00:47:24.203, Speaker B: Right.
00:47:24.339 - 00:47:46.671, Speaker A: So compared to the whole coding, like the wider scope, like the general analysis where non fuzzy bugs kind of edge over where fuzz bugs kind of edge over non fuzzy bulb here it's, it's more balanced and this whole balance thing kind of plays out most of the time.
00:47:46.743 - 00:47:47.143, Speaker B: Right.
00:47:47.239 - 00:48:01.399, Speaker A: So here we have payout contents. So also another analysis. I kind of glossed over this for the first time. I forgot it. Right. So again I'll miss some of this because I'm trying to go. I'm trying to freestyle this here.
00:48:01.399 - 00:48:35.661, Speaker A: I don't want to be reading from my script. So you can always go back to the analysis sheet and go through all of these analysis. So there's so much more analysis there. And you can also build your own analysis from the data here. So this coming in. Yeah, So I thought about that. Well, I believe what I'm working on.
00:48:35.733 - 00:48:36.013, Speaker B: Right.
00:48:36.069 - 00:48:41.457, Speaker A: Which is also inspired from this research. It's. It's higher on the scale of priority.
00:48:41.521 - 00:48:41.745, Speaker B: Right.
00:48:41.785 - 00:48:48.965, Speaker A: So it's. Maybe we can. I can work on this after doing what I'm working on right now.
00:48:51.705 - 00:48:53.929, Speaker B: Yeah. Yeah.
00:48:53.977 - 00:49:03.713, Speaker A: Thank you. So just going down to the general conclusion from this for analyzing the 1000s log.
00:49:03.769 - 00:49:04.327, Speaker B: Right.
00:49:04.481 - 00:49:05.579, Speaker A: So on average.
00:49:05.667 - 00:49:06.295, Speaker B: Right.
00:49:07.355 - 00:49:49.567, Speaker A: Checklist bugs make up. Sorry, checklist bug capture. 60% of the claimable reward in this kind of contest. In contest with 1000 or low end slug. Again, this makes sense if you think about it logically. This is a small code base we're talking about here. So if there's any bug that can be found, you can bet your ass that more people will find it, right now if that bug is even a bug that's so easy that it could be touched with a public, with a public checklist, right? There will be, there'll be more people who found it as such, it will have high duplicates and the reward will be less and the claimable reward will be less.
00:49:49.567 - 00:51:24.725, Speaker A: So that adds up, right? Compared to that, the unique reward, right? Thing holds up, right? Stay high 44%, right? So comparing the first, the general analysis, right, to this, to the 1000 and slock analysis, there's a significant drop, right? In the first case, the ratio was 1 is to 1.5. Now it's 1 is to 7.5. This ratio here just means it's the ratio of the claimable reward for checklist bug versus unique bugs. So in the first case it was bad, right, for checklist bug, but it's not as bad as this for lower code bases. So what this basically means is if you are auditing, if you are participating the contest with low N slog, right, you are better off trying to find the. We are better off trying to find this bugs with unique like try and find bugs that are so unique that you won't like be able to catch them with the public checklist. So think about things like how the Ethereum, how the EVM can affect this code base, how the external factors that are not, that may not be part of the code line, things that you don't, you don't see in the code itself, right? How certain those kind of things can affect the code, right? Because those are the things that end up as unique bugs and kind of stand out at the end of the day.
00:51:24.725 - 00:51:48.941, Speaker A: So that's it for the analysis. Sorry. Yes, exactly. Exactly. Yes. So that's it for the analysis for now. So the rest of the analysis you can get here, you can study.
00:51:48.941 - 00:52:30.811, Speaker A: Feel free to shoot me DM anytime you want. Why did I make this choice? Why did I classify this as that? Whatever. I'm ready for whatever questions you have, right? Because I don't think I have all the answers. I may want to have some mistakes in there, here and there. So I want this to be as accurate as possible. So if you can even point out an error I've done, I'll be happy to change it and fix that, right? So I'm counting on you guys for that, to hold me accountable to this research, right? So the next part, right, so here's the thing. Since the start of this research, I've been saying the fuzzer can set you apart by building a basic suit, right? But we all know your frozen suit.
00:52:30.811 - 00:53:44.077, Speaker A: Like everyone, if you give Temple to be the frozen suit, they might not end up with the same results, right? Because it still depends on the quality of the suit. So after, even if you give them the base setup of the suit, they might still not end up with same result because why they, they don't have the right environment or the right things to check. So this is one thing. This, this is why I've made this the part two of the research. Because your first suit, right, Is only as good. Can you see my screen please? Right, so your false suit, right, Is only as good as the invariance, right? So if you have a staking platform, right, you can build like the best suits possible and say, okay, yeah, I've set up the whole test code and all that, but if you don't know the things to test about that, about that contract you've built, right, you might have, you might still have bug missing in that contract. So that's why I wanted to make, that's why I decided to make this the part two of this research, right? So I have like, like I said, I started to say a long time ago.
00:53:44.077 - 00:54:39.793, Speaker A: So I've been scraping the web for everything I find about environment formulation and forcing and reset and coverage and all that when asking some of the guys in the space for advice and research and all that. So what I kind of did was. So yeah, so special here, this part is just special thanks to some of the guys that reach out that were very helpful, right? So, and some of them there is like trail of bits. They have a lot of resources that I found really helpful in my research, so. Oh, really? That's great, man. Wow, thank, thank you so much. So this are really great guys and I recommend you guys to consume their resources, man.
00:54:39.793 - 00:55:38.407, Speaker A: Like they have so much to offer to this space and I can't thank them enough. So, all right, so after, so this part two, right? So this is the part two of the research. We are kind of partly done with the part one. So I kind of squeezed them into because I wanted to touch on this part two a little, right? So the part two here just going to go like at a high level over what I'm trying to do here with this particular research, right? So right now in this space, I don't know of a single resource, tutorial, document or whatever that gives you a really good content or really good tutelage on how to formulate invariants, right? So there are People there are resources out there. So 12 bit has something, right? And it's really good. Yeah. But I, I make like, like a lot of juxtapose between that and other researchers.
00:55:38.407 - 00:56:01.213, Speaker A: I say okay, is there no one who is accumulating all of this and getting like one global, one like encompassing content or resource that can just be like the holy grail for us? Who wants to learn about environ formulation? Because I believe in round formulation is the key to being a good force engineer.
00:56:01.309 - 00:56:02.021, Speaker B: Right.
00:56:02.213 - 00:56:41.351, Speaker A: Because I believe in no time there will be a tool that make you set up your at least someone with some one day build. Like not one day like very soon. There a lot of tools that are kind of approaching that someone will be the tool that can set up your suit easily. And in no time now the tool will only be able to give you the base level where you set, where you stand about is the environment. You test those environments. How do you know what's a good environment to test? How do you know what makes a good environment and all of that. So this part of the research is just a high level to take you over what I'm like where I'm headed towards where I'm headed with this research.
00:56:41.423 - 00:56:41.967, Speaker B: Right.
00:56:42.111 - 00:56:53.143, Speaker A: So first thing is to understand what invariants are and it's quite simple and to define, right. There are properties or conditions that must hold constantly throughout the execution of a contract.
00:56:53.239 - 00:56:53.543, Speaker B: Right.
00:56:53.599 - 00:57:18.787, Speaker A: So this is something every forcer knows, right. If you ask it to define invoice they shouldn't break. And particularly has this famous video where he is trying to break a balloon jumping on it using the couch and all of that. So yeah, we get a concept of inference. But now how do you formulate this inference? It's now a big. It's where. It's where the big deal is.
00:57:18.787 - 00:57:37.797, Speaker A: So what makes a good environment? Yeah, we can. You can read through this at your own time. So this is just. I'll just call it file. What really matters is you understand the concept of this environment and the techniques to formulate this. So here let me give you a good example. And I've seen this a lot.
00:57:37.797 - 00:57:48.381, Speaker A: Like I said, I study a lot of code bases, right? To able to have like a solid opinion on this on the frozen topic. So I've seen this mistake a lot.
00:57:48.453 - 00:57:48.997, Speaker B: Right.
00:57:49.141 - 00:58:34.679, Speaker A: So people, most people now in space. Well, let me not say most. The average fuzzer in the space now formulates environment just from the literal code they see. And it's misleading, right? Because let me give you, using this example we have Here. Now, if you read this code, this function, the deposit function, right? There's a requirement here that says the amount must be greater than the minimum deposit. Before. Sorry, before you can successfully call this function, right? But if you want to test this function and you decide to formulate an invariant like the LP should not be able to deposit less than minimal deposit, it's going to be a useless environment.
00:58:34.679 - 00:59:21.865, Speaker A: Why? Because if you test, if you write invent and you try to test, you're basically saying, you're basically trying to break like a hard rooted constraint of solidity here. So you are reading this literally. Let's say you write a test and say, okay, try to deposit. And the test goes something like try to deposit one or something below minimum deposit. It will consistently fail because this is the required statement literally sitting here in this code line. And you are building your formula run from the literal definition of this function. Now the right way to do this, right, Would be to understand what this code line is trying to achieve, right? And then, yeah, do a kind of work around, test the pimples.
00:59:21.865 - 01:00:15.309, Speaker A: Are you with me? Yeah, yeah, exactly. So the first one is kind of trying to break a wall by planking your head on the wall. It will never break, right? Which you end up hurting yourself. So you just break your banging your head on a rock because you're trying to force something that's as a constraint on the programming language, trying to make zero accepted when the require statement is literally sitting there. And then this won't work. Now if you are trying to understand what the line there is trying to do, like the people. So your invoice should be formulated on the purpose or intention of the code line.
01:00:15.309 - 01:01:00.339, Speaker A: So now you know what you have to do is to ask yourself why is this code line there? What is this code line preventing? And then formulate an environment that checks if that states that the code line is trying to prevent will ever happen. Because now there might be other ways. There might be a withdrawal function where you can deposit higher than you can pass this test by depositing higher than the minimum deposit and then withdraw some is all part of that deposit. And then you end up with a balance that's lower than a minimum deposit. Yeah, so it's just a switch in mind. Well, so that's why I say we don't have good enough resources that, that, that teaches. That touches on this topic.
01:01:00.387 - 01:01:01.051, Speaker B: Right.
01:01:01.243 - 01:02:14.495, Speaker A: So a bad way, again to reiterate about one, a bad way to formulate environment is simply defining it from the literal definition of the code line. A good way would be to formulate it, to extract it from the purpose or intentions of the code line. What was, was that clear? So now with invariant classification, right? So there are two main groups of invent. So this particular, this, the, the two group, the term, the term and the classification here credit goes to Dev Desha, right? He was the one that I first saw categorizing variants in this way. Black box and white box. So what this just basically means, black box are invariants that you get from the docs, from the white paper, yellow paper, the duck of the project. By reading them you get to understand how this, how these protocols are supposed to work and what are the constraints of these protocols, right? And then you can extract your invent from them.
01:02:14.495 - 01:03:13.765, Speaker A: And there's this rule of thumb that I saw from who was it? Was it byte, byte 32 I think so. And it basically says anywhere in the dock you see a phrase like this should do this, you should highlight it as an invariant. So the should statement is typically used to define what a constraint in the code base, which mostly most often translates to invariants. Now on the other hand, white box invariants are invariants that you get from studying the code, right? Like the example we just showed now. So the invariant formula from there would be term as white box, right? Now the next part here, the types of environment, the function level environment and system level environment is a combination of everything I've studied. So up to this point, right? All the resources and environments I've studied up to this point. So it boils down to two things.
01:03:13.765 - 01:04:31.999, Speaker A: There are function level invariants that invariants the things conditions that you hold true in the lifetime of the function, right? And the system level environment, these are usually state changing environment, right? You have to do with the state, the state of the contract. So what conditions should hold you in the existence of the contract? Now to go to function level invariant, they are usually stateless. And one good example would be like maths functions, right? So let's say you have a division function, right? You want to know that the division has odd properties of a math, the mathematical of a mathematical division, right? So you want to test that division function for that. So that's one example. So that test now or that function might not affect the state of the contract, right? But it still has some conditions that it should hold. So that's where stateless, stateless fuzzing shines, right? So those kind of invent typically comes from functional invent. Now on the other hand we have system level invariant, right? So system level INV Comes from thinking of the system comes from thinking of the contract as a state machine.
01:04:31.999 - 01:05:39.051, Speaker A: So state machine here basically a good way to. I think this guy had a brilliant trick on it. Journey from New York, journey from nyc, right? He has a billion trade of thinking of smart contract statements. So statements are systems that can be one thing or the other at any, at any moment, right? I don't want to say point in time because I don't define it in time state, so they just say moments, right? So however you decide to define moments, so let's use a turn style machine for instance, or let's just use a whiteboard, right? So if you have a whiteboard with nothing written on it, the state at that point now is clean, right? White the moment you write on it, right? It has a new state, right? So now there's, there are scriptures on it on the board. So that's the new state of that board. Smart, smart contracts are just like that. With every transaction you make your with every state changing transaction you make of the contract of that smart contract, you change the state, you change the variable.
01:05:39.051 - 01:06:10.505, Speaker A: So it looks different than the previous state, right? So all of those states. Now the fact that it changes the way it looks or the way it appears is what defines as a state machine. Now the inference here comes in as thinking of this state machine, okay? As it changes, what should it change into or what shouldn't it change it into, right? So that's basically what you're doing here with the inference. So what are the constraints, what are the bounds for which this contrast is allowed to change?
01:06:10.805 - 01:06:11.477, Speaker B: Right?
01:06:11.621 - 01:06:57.473, Speaker A: Now so there are subgroups of this, right? So I'm breaking down the system invariant now into subgroup. So they are non state based system level invariant and they are state based system level invariant. So I will explain that. Okay, let me explain that first before going to the next part. So actually let me explain the shape this ship here before explaining this non state based environment. So like I said, smart contracts, right? Are systems, right? And they are complex systems. And in every complex systems there are different things.
01:06:57.473 - 01:07:09.433, Speaker A: There can be different, so many processes going on at the same time. So let's use an NFT market for instance, like a protocol like what is it called again? NFT auction protocol. Is it now down or something like that?
01:07:09.489 - 01:07:09.873, Speaker B: Right?
01:07:09.969 - 01:07:36.237, Speaker A: So let's use an NFT protocol like that now so you can see there are several processes going on in a protocol like that. There's a curation process, there's an auction process. Let's use this to example. Now these two Processes now are two different processes, but they all fall under one system. Now the processes also have their own phases. So how the market works. Now, let's say you want to auction an ad.
01:07:36.237 - 01:08:33.481, Speaker A: First thing you do is you curate that ad. So the process of creation now could have its own step. Let's give for example, the step could be people, you bring artists on board, right? The process of inviting the face of artists signing up, right? Then the question phase, artists to create the art and then submission phase, right? So after the submission phase, then you can then start the auction phase. Or maybe you have like a lottery system for which ads you want to auction. So after all of that phase phase is done, you can then start the auction phase. So sometimes this phase, these processes can run simultaneously, right? It doesn't really matter the point of joining drive. They are different processes in assist, they can be different processes in the system, right? So now with the auction phase now it could be, okay, you list the act you want to auction off, right? And then you have people make bids.
01:08:33.481 - 01:09:45.366, Speaker A: Then the next phase will be you select the winning bid and then you transfer the winning bid to the user and whatnot, right? So you can see how this can be broken down. A system can be broken down into processes and processes into phases, right? Now, and if you want to be general, right? Most people can just generalize environment formulation as a condition that should hold true throughout the state of the contract, right? But that isn't always the case, right? There are some conditions that just need to hold true during a certain process, right? So for instance, in the auction process, you want to know that the act, the NFT which you are moving shouldn't miss, shouldn't be transferable, right? Or should always be present. That could be an event, right? That NF should always be present so that whenever, whenever a winner is decided, it wouldn't be decided. You can easily transfer it. So that could be an event that NFT should not be transferred. We should not, should always be present. Now that event doesn't necessarily have to hold true in the curation phase, because in the cursor phase, there's no bidding going on.
01:09:45.366 - 01:10:19.567, Speaker A: You get, especially when they are not running simultaneously. So that invariant doesn't really matter. So if you check for invariant and that kind of phase, your contract might fail. Like your test might fail, but it would be a false positive. You get. So it's be a false positive because you are not checking it under the right process. So by the time you begin to divide, you break down your contract into this different into the different level, right? They're just treatment three levels, right? The, the system, the process and the phases.
01:10:19.567 - 01:11:28.689, Speaker A: Then you begin to say, okay, you categorize your events in this certain ways. Then you kind of reduce the number of force positive. You reduce, you get by a significant degree. So now let's go to the non state based system environment, right? So, so these are systems, these are conditions, right, that should hold true for all phases of, for like throughout the existence of the contract, right? So for all the phases, it doesn't matter what process is going on or what not like it should hold true. So this is not state based, right? It just by non state based, I mean no matter what the contract changes to whatever state it changes to, this environment should always hold true. So no matter the process that is currently being run, the invariant should hold true. So one example could be like the constant product formula for an AMM machine, right? For AM index.
01:11:28.689 - 01:12:43.157, Speaker A: So no matter what's going on, an AMM that constant product formula should hold true. And usually this kind of inverse environment that define how the protocol works, right? So if you deposit at any point in the contract, your balance will increase, if you withdraw, your balance to decrease, right? So those, or if you define a learning protocol, I mean just think of invariants that define the, that define how a protocol works. So that's usually where most of this kind of environment falls under. And if you have taken the time to break down your environment into processes and phases, you know, break down your system into processes and phases, it becomes easier for you to see this different type of environment. So now with state based invariants, right, there are invariants that hold true for particular system processes and phases. Now there are three main states here to consider. There's the initial state, there's an active state, and there's a final state.
01:12:43.157 - 01:13:47.981, Speaker A: Now the state initial state is the state is a starting state of a process. So an example here could be the nft. Let's use our NFT market again, for example. So the NFT you want to auction, right? It should be the initial stage should be this NFT should be present, right? You want to make sure that this NFT is available. So as a contract run, if there's any point whereby we get to the auction phase and we still don't have an NFT to auction, there's a broken environment there, right? Maybe you have mistakenly transferred the NFT to someone else, right? So this is just an example. Now the active state will be so out of state could be anything, right? So anything that should any condition that that could, that should hold true during voted during the bidding process of this nft, right? Another, it could also be the same thing. The event could also maintain for the initial state.
01:13:47.981 - 01:15:01.535, Speaker A: It could be, okay, the NF should be present also during the bidding process because you don't want to lose it or the bidders. The winning bit should be selected A higher B should be selected over the lower bid. That's another invariant to check during the state, right? Then the final state could be something. Okay, what should this contract look like after all of this process is over? At the end of the process. Now at the end of the process, we want to check whether an example of inventory will be. We want to check whether the invariant that the NFT that we auction is transferred to the right person does the ownership of this NFT change, right? That could be another check, another environment that we check at the end of the final state. So if you break distance down and if you break down your system into break it down as a state machine, right? Break it down into function levels to system level, break it down, break the system level down to assist state machine, the non base, the non state based and the state based and then break the state base into initial, active and final.
01:15:01.535 - 01:15:24.169, Speaker A: Then the invariants kind of pop out to you. It kind of becomes obvious, especially when you apply certain techniques that I'm going, that we're going to discuss now and formulation of inv. So now we now know how to categorize invariants, like how to check invariance. So the categorization, the classification, right, Helps a lot for reducing false positives.
01:15:24.217 - 01:15:24.761, Speaker B: Right.
01:15:24.913 - 01:15:48.761, Speaker A: Now the formulation helps you in digging out the actual invariance for function level. A good technique again. Not again. Sorry. This particular sheet is not exhaustive. It's just how much I've uncovered from the research so far. It can grow and it might.
01:15:48.761 - 01:16:53.473, Speaker A: Well, I'm hoping it grows, right, because this space constantly evolves. So now for function level environments, one good technique I found, right? And thanks to is it. I've tried to remind the people that made this technique popular, right? Well, I can't remember them right now, but basically what they do with this technique is they take a function, right? And then they walk through every code part of the function and define what should happen for every code path, right? And then you can formulate your invariance from this code part. And if anything other than expected happens, you can then you trigger, you trigger your test as a fade invariance. So when we get to this next part, you kind of see what that looks like. So the way this is usually represented is in three formats, right? So you start with a function with the first code path. Let's say there's a condition of yes or yes or true.
01:16:53.473 - 01:18:26.769, Speaker A: If it's true, you go into a certain path. If it's false, you go into next part and then you map out every part, every possible state that that function can head into, right? So from there you can easily then formulate your invariant form, these functions, right? Again, the BTT is just going to help you give you your code path. But also remember that you are trying to formulate your environment from the intention of the code lines, not the literal string of the code lines. We can refer back to the example we gave, the example of good and bad invariance that we just spoke about copyright meaning to understand what that means. So now with the system level, right? This is kind of tricky, right? I haven't found like a defined technique such as BTT for system leveling around. Instead what I've come to realize is it's more of mind conditioning, right? So you think about your system in certain, with certain perspective, right? Or let's, let's just for lack of better word, heuristics, right? You take certain heuristics to think about your system and then formulate conditions or formulate constraints that should hold true as the system runs. So you think about protocol specs, what are the specs? Like for instance, a constant product formula, right? Is one condition.
01:18:26.769 - 01:19:10.339, Speaker A: This is specification that should always hold you in an amm, right? And amm. Now standard conformance, right? There are certain projects that the certain standard, the setting project is certain protocols should obey, right? So if it's an optional market, there are certain things that auction market should do. You check for those influence are those environments being held, right? If it's a perpetual market, there are certain things that perpetual market should should hold true. Similar thing for value flow. So, but value flow, how the money moves around and where the money should go or shouldn't go, how the inflow and outflow. So you think about this for about the system and then you begin to formulate inverse around that. So you go through this list thinking about your system, right? The relationship between the functions.
01:19:10.339 - 01:20:00.837, Speaker A: Are there similar functions? What, what, what's the relationship between these functions? Are there similar variables? What are the relationship between these variables? And how are the actors interacting with each other? What are the relationship, what are the constraints between this? So those, that's how you begin to form invent. By the end of this exercise, you Realize you have over 100 invariants, right? You'll be the one who can get tired of formulating this environment. So I see, I see. I've seen some like so many code bases from developers where they only have like 20 inverse or 10 inverse. And you ask them why don't they have more events? They'd be like, these are the main events they can't think of. I mean it's, it's rare, it's. Yeah, yeah, it's kind of not quite obvious, right.
01:20:00.837 - 01:20:37.467, Speaker A: And that's, that's one thing we're trying to solve. So we're trying to enhance this process for you to make it easier for you. So now to. So speaking about the difficulty of formulating environment from thinkers perspective, one thing you can also do is kind of lean on not so much, right. But can lean on AI to help you with certain things, right? So for instance, with the 4, with the BTT approach, right. When this was proposed, it was proposed as something, as a manual exercise that you need to do. So it helps you understand the code base and formulate this yourself and all of that, right.
01:20:37.467 - 01:21:37.649, Speaker A: But I felt it was a tiring exercise. So you don't expect me to start mapping out every code part for every function in the code with some function, some code has over 50 functions. I can't do that for every function. So what I did was I took the spec, right, the document that was shared for the btc, right, and then formulated a query for it. So this query, so if you go to this tweet, so if you go to this tweet, right, you, you will see the tweets where I tweeted about it. So I formulated a query and then run it over and tested it over a code base, one of the code base that Cypher Cypher shared for one of their first flights, right? So and it produced a pretty good result because it was kind of a very straightforward exercise. And since I've provided all the context it needed and it had the context in the tool, I used to test it, right? I used to test it.
01:21:37.649 - 01:22:27.825, Speaker A: So it kind of gave me a job of an hour's worth of work in just a few seconds, right? So these are ways that you can utilize AI to simplify the process, right? So again, similar thing can be done for this practices here, right? And it's also, it's part of the thing, the part of tool we are building. So we're kind of refining this tool so that we, it just, it doesn't just give you generic invariance Right. It also takes its understanding of the code base and formulates the invent from its understanding and not its translation of the code lines. So yeah, so this is the last thing I delinquent to invent. So why does all of this matter?
01:22:27.905 - 01:22:28.525, Speaker B: Right?
01:22:29.025 - 01:23:41.727, Speaker A: So going back to the part one, the efficacy of fuzzing, why does it matter? So I'm the kind of person that if you tell me that this is a good way to do something and you don't give me a reason why, I won't really place more value to that thing until like get my reason why, understand. So if you like. Yeah, exactly. So I need proof, I need to verify. So I wanted to provide a way to show people with empirical data that hey, frozen is the way to go. Not or it's not everything, but it makes no sense why you are not trying to learn it, right? And also I wanted to also provide a data that people can use at least to make educated guesses or educated decision making on when to force and when not to force. So personally, right now, after doing this research, I won't approach every contest with intention to force because I know there are certain kind of code bases that are just best for you to just do go manually.
01:23:41.727 - 01:24:11.675, Speaker A: So and that certain kind of business is just based on understanding, it's not an objective thing. So when you read this report or you go through the analysis, you also come up with your own understanding, right? And also, also it also helped me know how to prioritize which techniques or which approach I use when I audit. So and right now I don't use public checklist until the end of the contest, like where I know as I actually have the time to do to do it.
01:24:11.795 - 01:24:12.147, Speaker B: Why?
01:24:12.211 - 01:25:10.051, Speaker A: Because even if I find a bug with this public checklist, it wouldn't be rewarding. But if it's a private audit, you bet your ass I'm using it from the jump, so I'm using it from the job. Sorry for swearing on your plan. On your plan. So, so if this is a public, if it's a private contest, a private audit, I'm going to use everything at my disposal. But if it's a contest, right, I now know what to use, what to set aside or what to prioritize, right? So also based off this research, you can begin to think of, okay, what kind of research can I put out there to help people understand certain things? So this is the part about people who want to build upon this, right? What kind of research, what kind of resources can I put out there? There are a Lot of people who are creating content on forcing. But so far, what I've seen, most people just create a new way, a new, like a new format of what's already out there.
01:25:10.051 - 01:25:32.749, Speaker A: So how to use Echidna, how to use Medusa, how to use Foundry. I mean there are so many tools out there, there's so many tutorials out there showing you that, right? So you can take a different approach to teaching things like are there any philosophy, are there any strategy, are there any tricks or tips or tricks that can set you apart from just from, just from the average force engineer.
01:25:32.797 - 01:25:33.269, Speaker B: Right.
01:25:33.397 - 01:27:03.655, Speaker A: Because I don't think forcing is hard. Sorry, sorry, come again? Can you repeat the question again? I didn't get it. So I really can't draw relationship between board raising and fuzzing. And if I understand bot raising, well, correct me if I'm wrong. Is it the thing that code Rena does where before every contest you run your bot over the code to find kind of like static analysis on the code to be audited. So I really, I really don't have a strong opinion on that question right now. But maybe you can hit me up in the DM and I can look into it.
01:27:03.655 - 01:28:04.315, Speaker A: Right now I don't have a strong opinion on that. So one more thing, another thing, another thing, another takeaway here, which is something a lot more tangible than what than the other points here would be the digest tab, right? So what I did for everything, for every finding, for every audit report I analyzed, right? So if I take this finding report now, remember I said I studied this as a way to study audit report and read them. And my approach to reading distance is try to extract at least one heuristic from every finding I read. So that's what I've been doing here, right? So if I take this finding now and I try to add, what I do is I extract one heuristic, at least one heuristic from the finding so that next time if I come across search finding or search pattern, imagine I can easily detect search bug. Or at least I have.
01:28:06.125 - 01:28:06.805, Speaker B: Sorry.
01:28:06.925 - 01:28:30.309, Speaker A: Or at least I have a reference to that to compare to see if this way of thinking can apply to this, apply to the code base I'm analyzing. So I've formulated over 400 new heuristics. So new heuristics that you can use here.
01:28:30.357 - 01:28:30.949, Speaker B: Right.
01:28:31.117 - 01:28:56.945, Speaker A: So this is also public, right. But the point of this year, this, this like my biggest point with this is to show you that, okay, as you read in audit reports, with every new finding you see you can get new heuristics from them. And you shouldn't rely on just the public heuristic you see, because as we've seen, the public heuristics don't take you so far.
01:28:57.275 - 01:28:57.683, Speaker B: Right.
01:28:57.739 - 01:29:32.501, Speaker A: So you want to build your own heuristic. Personally, I have like a very rich. So this is what my own heuristics look like, what I use for my own lenses, sorry, Japanese. So you can see I have heuristics for almost every web tree topic or niche you can think of.
01:29:32.573 - 01:29:33.093, Speaker B: Right.
01:29:33.229 - 01:29:50.665, Speaker A: So the purpose of creating this heuristic is so I don't rely on the same heuristic everyone is relying on. And it gives me more chance of finding unique box than what I would get if I use what everyone is using.
01:29:51.325 - 01:29:51.925, Speaker B: Right?
01:29:52.045 - 01:30:02.909, Speaker A: So you can study this digest tab here for new ways to think about smart contract or new heuristics to add to your library and whatnot.
01:30:02.957 - 01:30:03.573, Speaker B: Right?
01:30:03.749 - 01:30:58.585, Speaker A: And I mean it's, it's, it's good that you want to use it, but this is the public because you're not the only one who's going to be using it. But I, I think the better, the better thing to take away from here would be start building your own heuristic read library of heuristics, right? And over the future, like over time in the future you have something richer than what we have here, what's in the public. And that's one, that's that. This, that also ties to what we are doing right now at Odix. So let me just talk a little bit, Let me kind of. What's the word again? To sell, to sell ourselves here, right? So Audix, we are building the automate or the auditors toolbox, right? I know every project comes and says there are tools automate this and that, right? But we're trying to build here with magic. Trust me.
01:30:58.585 - 01:31:34.785, Speaker A: I'm going to go here, we're going to go to Zeke on this. So now, yeah, so now we have. Let's imagine you start building a heuristic, right? And then you build something richer than this. You have over 2,000 heuristics on your, on your, on your, jumping on your notepad. Now if you want to audit a code base, any code base at all, do you think it's reasonable for you to go through all of those 2000 heuristic manually to see if they apply to the code base you are auditing?
01:31:35.775 - 01:31:36.447, Speaker B: Right.
01:31:36.591 - 01:32:26.287, Speaker A: That will be tiring because you can't do that manually. Now what we're doing here is we're building a Platform where you can build your heuristic, your own personal heuristic. So you have your own solo date to yourself, right? Not just having your own personal solo date. You also have the ability to run your thousand of heuristics over any code base you insert. And it filters out the heuristics that fits the code base you're analyzing, right? So to shrink down your thousand, your list of thousand heuristics to say 100 or 200 heuristics, that applies to what you are analyzing. And then from that short list, you can then begin to analyze your code base as you would do with Solidate. The other end of that is the invariant generation.
01:32:26.287 - 01:33:05.681, Speaker A: So remember the whole thing about thinking formulating environment being a challenge, right? So we want to use, we're building a tool that you give with your code base, right? It understands the code base, the purpose of that code and then formulates environment, function level, environment and system level events for you, right? And then it gives you those events. So it gives you a long list of events. You can filter through them. You can. Like there will, there'll be a lot of flexibility for you. And the last thing which is down the line, it's nowhere, we're nowhere close to that yet. Is going to be an auditing canvas.
01:33:05.681 - 01:34:37.487, Speaker A: So it's basically an ide, right, where you open your code base. So instead of auditing on IDs like VS code or what's it called, Intellij, right? How about we have like Illustrator looking canvas, like where you spread your code across, right? You can connect your code with mind maps and all that, right? And within that map you highlight the code and it shoots heuristics for the highlighted for the relevant code that you've cut out though it. I don't know if. So let me see if I can draw. I can go to mirror and show you example of what this would feel like. So, so let's say you have your contract. Let me, let me copy something here.
01:34:37.487 - 01:35:11.005, Speaker A: I think I've already written. Let's say you have your contract, right? And you open your contract and your ide, right? It's all text and everything, but you have the ability to pull, to pull a function right from it. Oh, good. Okay. I think I need to ungroup this.
01:35:11.585 - 01:35:12.217, Speaker B: All right.
01:35:12.321 - 01:35:42.815, Speaker A: So you have the ability to pull a function from the contract and it ties to this, right? Or you pull, you pull a code line within the function, right? You pull a code line within the function and you kind of. You can spread your contract on an interface that Looks just like this, right? And what you can also do is let's say you have that function. You click at the click of a button, it prints out some heuristics that applies to that function.
01:35:43.435 - 01:35:44.175, Speaker B: Right.
01:35:44.795 - 01:36:24.957, Speaker A: So it gives you this bad eye view of the whole code base. And not just that, it's also shooting you with perspective to look at this code base from different persons to look for this, to look at this code base from a list that you have built for yourself. So that's our end goal. Does our angle. And while we. Sorry, so we have. You can join our discord.
01:36:25.021 - 01:36:25.269, Speaker B: Right.
01:36:25.317 - 01:36:37.973, Speaker A: So we have, we will be launching maybe the V1. So the V1, the first versions wouldn't have this feature yet. We're just going. We want to perfect our heuristic engine and environment engine first.
01:36:38.109 - 01:36:38.645, Speaker B: Right.
01:36:38.765 - 01:36:47.917, Speaker A: So when we're done with that then we can incorporate this. So you can join the discord channel.
01:36:48.021 - 01:36:48.333, Speaker B: Right.
01:36:48.389 - 01:37:27.251, Speaker A: And when you come there just hollow at me or anyone there, then we'll get talking. And one reason we decided to take this approach is we notice a trend in AI the growth like everyone else notice it. So not we notice. So everyone AI is taking all everything and all that. I, I mean still the fear mongering. And then we thought about it, okay. Rather than saying we're building it to an AI tool that's going to find bugs for you because then you won't be raising as much curiosity as you'd be raising fear and doubt within the space.
01:37:27.323 - 01:37:27.935, Speaker B: Right.
01:37:29.075 - 01:37:35.859, Speaker A: How about you focus on optimizing the security researchers process or approach.
01:37:35.947 - 01:37:36.459, Speaker B: Right.
01:37:36.587 - 01:38:06.781, Speaker A: So instead of giving a tool that an AI tool and say just give your code base, don't shoot box at you. How about we give you a tool that, okay, with the help of AI is going to help you think about this code base in certain way. You still have to do the work of finding the bulb. It's going to give you different perspective which is the heuristics. It's going to give you your invariant. But you still have to do the job of right of implementing this environment in your first suit. It's going to give you, we're going to spread like going to give you a platform whereby you can like utilize all of this tool with ease.
01:38:06.781 - 01:38:15.637, Speaker A: So basically that's why I like, I like to think of it as the auditors toolbox. So that's where we're headed.
01:38:15.741 - 01:38:16.197, Speaker B: Right.
01:38:16.301 - 01:38:22.225, Speaker A: And if that's something that interests you, I would like to see you on our discord.
01:38:30.525 - 01:38:30.973, Speaker B: Thank you.
01:38:30.989 - 01:38:47.545, Speaker A: Thanks a lot. No, that's not here. That's not me. That's not. I'm happy to be here, man. Thank you. Thanks for the opportunity.
01:38:47.545 - 01:38:58.765, Speaker A: Thank you so much. Bye.

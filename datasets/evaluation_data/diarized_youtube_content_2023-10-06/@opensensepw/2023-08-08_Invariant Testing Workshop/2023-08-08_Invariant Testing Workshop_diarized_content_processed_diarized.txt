00:00:01.960 - 00:00:02.994, Speaker A: Can you guys see it?
00:00:03.894 - 00:00:05.354, Speaker B: Yes, we can see.
00:00:05.974 - 00:00:09.190, Speaker A: Okay. Yeah. So sorry for the delay.
00:00:09.262 - 00:00:09.750, Speaker B: No problem.
00:00:09.822 - 00:00:54.994, Speaker A: Thank you for everyone who's here. So, today I'm gonna do a little presentation about environment testing. So, first of all, my name is Antonio. I'm an independent security researcher, and I'm also building a fuzz testing platform called Fuzzy. FYI, I've also been working on some fuzz testing search. I just did a presentation at the DeFi security summit, basically comparing foundry and echidna in terms of speed. And I've also been working together with some DeFi protocols, basically improving their test suites and implementing fuzz testing best practices.
00:00:54.994 - 00:02:00.004, Speaker A: And the idea of this talk is to basically present some of the tips and, like, suggestions that I learned throughout these. These engagements and some of the things that work and things that don't work quite well that I have learned basically just doing my research and also from others in the field. So I also have a bunch of references in the end, so those who are interested in learning more about fuss testing can research further if they're interested. Yeah. So here, there's a bunch of stuff. I'll go one by one, just like, straight out, giving you the kind of recommendation and discussing some of these tips. And if anybody has any questions, please feel free to chime in, and I'm happy to answer or to discuss them.
00:02:00.004 - 00:03:12.102, Speaker A: Yeah. So, first of all, this is my number one tip of writing better invariants. So, it's usually, I don't know, it's something that I haven't seen anywhere else, but sounds like a very basic idea of where, like, how do you define your invariants? Like, where do they come from? And one thing that worked best for me was starting from the white paper or from your documentation. So, if you are either auditing a defi protocol, or if you are building a protocol, you are a developer. Sometimes, most of the times, your business team or maybe your management team, you will have very clear what are your properties? Like, what are the properties of your system? And this will most likely be written in some form, like, some way or the other. Maybe you have a white paper, maybe you have just a very simple documentation, maybe some flowcharts. And these are very useful when you are defining your invariants.
00:03:12.102 - 00:03:54.532, Speaker A: So, for example, this one here is from pods finance. They are an options and vault protocol. They're building some vaults on Ethereum, and when I started working together with them, most of the environments, they came directly from their white paper. So here I just highlighted some of those from one of their vaults. And this is something that you should do when you are starting with your environments. So for example, here in tu, this light blue here, you can see that they're, let me get the laser pointer. Yeah.
00:03:54.532 - 00:04:35.658, Speaker A: So this could be like one of the invariants of the system. So they are building a state vault where basically it's a strategy that they protect the principle. So for example, if you deposit one stick at ETH, it will accrue interest and you shouldn't lose any of your one staked it. You should always be able to reclaim it later. And only the, the yield of the staked ETH will be used for this strategy. So for example, here, so take it east is a principle protected strategy. So this allows us to like think about one of the properties of the system.
00:04:35.658 - 00:05:16.442, Speaker A: So basically, if a user deposits an amount of token, they should never have less than that amount. This is one of the basic properties of the system. So there's also this one here in green. This one is more related to the strategy itself. So basically they are using the yield of stake to buy options. So basically they buy one option, one put and one and one call option. So it's a prereq, like it's an assumption of their strategy that regardless of the direction of the market, you should earn some money, basically.
00:05:16.442 - 00:06:01.994, Speaker A: So this can be translated in another invariant, and this is a third one, the dark blue here. So the yield is used to buy derivative structure. So basically we can write invariants saying that only the yield of state ETH will be withdrawn from the vault. It's a bit similar from this one, but this one is more generic, that the principle is protected. And this one is more specific, that the yield would be used to leave the vault. Basically the yield leaves the vault and then it goes back once the options strike, basically. So, yeah, so basically, like, this is the general idea.
00:06:01.994 - 00:06:13.894, Speaker A: So if you're starting, you don't have any invariant tests, or maybe you're auditing a project, maybe it's a good idea to read their white paper or documentation and think about the invariants from the white paper.
00:06:14.354 - 00:06:29.814, Speaker B: This is really interesting. You know, this is really interesting. I mean, you got, you got, you got a few variants right from the, you know, first lines from the white paper. This is quite interesting, you know, way to approach, you know, like the main concepts should never change.
00:06:31.474 - 00:07:19.288, Speaker A: Exactly. And this is like where the projects, they get very excited, but it's really their work. So, for example, in case of pods here, I basically read their whole white paper and I just noted like a bunch of invariants, like maybe 1020 invariants. And they were like, oh, we didn't even know that we had those invariants. So it's like the project, they already have these assumptions, but they sometimes they don't, like, take the time to write them in plain English. And this is like where the second point comes that basically you should be able to summarize the properties in plain English before going to any code. So this is like a pattern that some audit companies do.
00:07:19.288 - 00:07:59.514, Speaker A: So basically you can just write a markdown format, a markdown file with all the properties. And those should be like, initially you should be able to extract them directly from the white paper. So, for example, in the case of pods, I started reading their white paper. I wrote a bunch of invariants extracted directly from the white paper. And some of those were already tested in unit tests. So some were already tested in some fuzz tests, and they didn't have any environment tests at the time. So that's, that's something that we worked together.
00:07:59.514 - 00:08:38.784, Speaker A: And, yeah, so this is a good idea. And it's also a good idea that because you can talk like, basically, like have the same language between the whole team. So sometimes, like your business folks, they won't be as technically as tech savvy as your developers, and they won't be able maybe to read solidity code. But if you have, if you have a list of all the properties, that's a good idea. So that all of you can kind of discuss. And maybe, oh, no, this shouldn't hold true. And oh, this won't hold true if there's no liquidations or whatever.
00:08:38.784 - 00:09:10.673, Speaker A: So if that happens again, I can share it through the Discord app. Maybe I'll have more options there. Yeah, but, okay, so here's the point, number two. So write your properties in like a markdown file, and you can discuss it with the rest of the team or anybody. Okay, so this is the third one. That's also interesting. I took this suggestion from Sir Thoras.
00:09:10.673 - 00:10:15.314, Speaker A: They have like a course on GitHub. It's basically focused on formal verification, but most of the learnings there, they also apply to fuzz testing and environment testing. And one of the good suggestions that they give is to categorize your properties. And they give basically some categories and also explain what are the differences between these categories, and also how you can leverage this categorization to think about additional properties. So let's assume that you started an engagement. Maybe you are auditing a project, maybe you are developing a protocol, and you have your white paper, you have written down all your properties in plain English from your white paper. And now you are thinking, okay, so how can I improve this? Maybe, are there any other properties that are missing? And this, I think this is like one of the ideas that can help you.
00:10:15.314 - 00:11:09.388, Speaker A: So they have five categories on their, like that they kind of suggest. So one of them is valid states. So sometimes your system will have maybe like let's think about like a stable coin, like over collateralized stablecoin, for example, liquidity's LUSD. So in liquidity you have some states of your system. So one of the states is like normal mode, another state is recovery mode. And then you have like. Yeah, so basically depending on the collateralization ratio of the system and some thresholds your system will enter in one state or the other, I don't remember like by heart, but basically you have some states.
00:11:09.388 - 00:11:48.996, Speaker A: And, and the point is like depending on the state, some of your variables need to be like in, in a certain, in a certain configuration. So for example, in liquity, if you are in recovery mode, then all borrowing operations are paused. I'm not sure if it's that. I'm just like, like that's just an example. But basically, depending on the state, some variables must hold true. Some actions are paused, some actions are not paused. And this is something that you can, you can leverage to basically extend the number of properties.
00:11:48.996 - 00:12:34.364, Speaker A: Maybe those properties aren't written on your white paper, maybe it's not explicit, but you can think about those states and you can like add additional properties. So another idea is the state transitions. So this is when you are going from one state to the other state. So for example, like let's say only Qt again. So if you go from normal mode to recovery mode, then borrowing must be paused or something like that. So basically some variables, they change only when the state changes. So this is also a good idea to think about how the state variables will change based on the state of the system.
00:12:34.364 - 00:13:20.604, Speaker A: So this one is more about variable transitions. So it's a bit similar to the state transitions, but on a variable individual level. So like thinking about how each of your state variables of your contract should change. Another good example is about like how if one of your variables are monotonic or not. So let's say like total supply always increase, increases under normal conditions. Or maybe like whenever you burn, your total supply decreases. So this is one of the ways to think about how your variable always increase or maybe always decreases.
00:13:20.604 - 00:14:05.092, Speaker A: So there's this one here which are kind of unit tests. They are similar when you are writing foundry tests and basically, you can have an arbitrary parameter for your foundry tests. And this is what they call fuzz tests. So it's more like a unit test basic approach. So for example, let's say you are testing an ERC 20 token, and basically instead of like, hard coding the sender or the recipient, maybe you receive those parameters from the test and you use them. So basically the fuzzer will try any different value. So basically you'll be testing more values than just hard coding them.
00:14:05.092 - 00:14:28.114, Speaker A: So these are kind of analogous to a unit test. And finally are the high level properties. So these ones are the most generic ones. So, like, the system should always be over collateralized. So, for example. So this is what should be, like one of the high level properties of your system. And, yeah, so I really recommend this document from Sertora here.
00:14:28.114 - 00:15:10.808, Speaker A: I'll share later on the references. But it's very good to like a framework to think about extending the number of invariants that you have. And, yeah, so this also is related to my next tip. So they also suggest kind of prioritizing your environments. So, yeah, so maybe, like, you start by writing your invariants and you eventually, like, have, like, I don't know, like 20 or 30. And that's a good thing. Like, that's a sign that you have a lot of work to do and hopefully you will, like, maybe like writing variants for all of those.
00:15:10.808 - 00:15:55.040, Speaker A: And, yeah, and your protocol will be secure. But, like, realistically, you don't have a lot of time and you must prioritize and start with, and start with the most important ones. And this is like my suggestion, like, start with the high level first. So, for example, here they say, like, high level properties, they don't cover any specific part of the system, but they cover like, the whole system from, like, the user's point of view. So, for example, like, if you have, have a bank and like, if the client makes any operation in the bank, then the total balance should remain the same. Like, no money is printed out of thin air. So, like, no assets are disappearing or being created.
00:15:55.040 - 00:16:57.464, Speaker A: So this is like really, really important. If your bank allows double spending, then eventually, like, it'll be like a very bad situation. So if you start with the high level first, you are most likely targeting the most important features first. So this is like a good idea in terms of prioritization. I also added here, I think the Fryp, not sure if you guys saw that on Twitter, but the guys from the team from nascent, they are a team of builders building some interesting projects on Webtree. And they just released, like, a new framework of thinking about the checks effects, interactions pattern that they called frypy, like, function requirements effects, interactions and protocol invariants. So there's some discussion on Twitter whether this is really different from checks effects, interactions or not.
00:16:57.464 - 00:17:37.248, Speaker A: But the point is, like, the PI part is really important here. So the protocol invariants. So this is something that if you're building a protocol or if you're auditing a protocol, it should be really easy to understand what's, like a very, like, the most important thing that should always hold true. Like, your bank should never print money out of thin air and that kind of stuff. So think of the protocol invariants first. Start with them first, and later go to the, like, less important, like the unit tests and all of those other types of categories. So high level properties, these are definitely the most important ones.
00:17:37.248 - 00:18:06.872, Speaker A: And later, you can move on to these other ones. Okay, so, yeah, so I think those are, like, the most generic ones. And. Yeah, so right now. So this is how you started. So you started from the white paper, you lay down all your properties in plain English. Then you extended those properties using sertora's framework, and now you prioritize your properties, and you started with the high level ones.
00:18:06.872 - 00:18:59.384, Speaker A: So now how you write your code, now you get to the solidity code, and here is a suggestion. So this one I've taken from trade off bits fuzzing series, they kind of have some very good source of examples and code to follow for invariant testing. And they always do those preconditions, actions and postconditions way of structuring their code. It makes it really easy to understand and maintain and also to kind of reveal, like, what should go through before and after. How do you compare your before and after statements? Yeah, so this is a good just idea to make your cold cleaner. This is a.
00:19:01.364 - 00:19:27.264, Speaker B: When we start talking about these properties, extending them, seems to me like that's a lot of work, given that I have some complex code base, you know, usually how long does it take? Because looks like a month long process or even more, you know? And what is the main objective here is making sure the code is acting according to the rules in all expectations.
00:19:28.964 - 00:20:17.816, Speaker A: Yeah, yeah. So I'm not gonna lie like, it's not as straightforward as unit testing, definitely, because you first need to think about what you're actually trying to test here. So what are your system invariants? Maybe most projects, they don't know them. Maybe you don't have enough time, like during an audit. Maybe some audits, they don't even like test system invariants, because that takes extra time. Also, the system setup is not very straightforward because for echidna, for example, you need to set up your handler contract, your entry point, kind of. And also for foundry, maybe you need to do some optimizations because the fuzzer can take a lot of time if you are not doing that properly.
00:20:17.816 - 00:21:30.052, Speaker A: So I'm not like, I'm not gonna lie, this is an extra effort, but in my opinion, it's worth it because this is where you will find the critical vulnerabilities or the things that really break your system. But usually, if you're only doing unit tests, you won't find them, because first of all, your unit tests, they aren't generally stateful. So that's a huge drawback of only doing unit tests, because when you're doing variant tests, you are most likely doing them on a stateful way. So basically, all the transactions, they are being kind of recorded and they are changing the state of your system, and they will be dependent on the previous state. So this is why you usually find more complex bugs by doing invariant tests. But, like, thinking about how long that should take, I think like a whole week should be enough to have the basic, like the basic structure for your invariant tests. So maybe on the first day you think about all the invariants that you want to test, you maybe prioritize them.
00:21:30.052 - 00:22:42.808, Speaker A: Then on the second day, you probably work on the setup of your tests, maybe writing your echidna contracts, writing your foundry invariant tests, and maybe you have like three additional days just to kind of fine tune it. Maybe do some optimizations that I'll teach here, maybe like, think about all the different scenarios that you want to test. And ideally you should just plug it on your CI if you are like a protocol, or maybe like, you already have found some interesting vulnerabilities if you're auditing a project. But if you have less than five days, I think that's like a bit too short. Maybe like you could do fuzzing for math library, maybe some like, like components that are, that do not have that many external dependencies, but you have a lot of the external dependencies, then it takes some time to set everything up. So, yeah, so maybe like five games, you have some, a good, good enough structure, and maybe you can kind of keep improving it and over time. Oh, sure.
00:22:42.808 - 00:23:17.094, Speaker A: So Echidna is a fuzz testing tool by twelve bits. I believe it was one of the first fuzzers for solidity and EVM. So it has a lot of different features. And Foundry just released their first invariant tests support recently. So the two tools, they are very good. Like some features, like I believe, like Echidna is more feature rich. So it should have more features than foundry.
00:23:17.094 - 00:24:06.908, Speaker A: For example, you can fuzz mainnet contracts. That's a good thing. Like, like they have used it to find some like real vulnerabilities on Mainnet and, but foundry, like I have, like on my tests, I saw it being faster. So, so yeah, so basically you should try experimenting with both. And here I'll give some examples about like both tools. So, yeah, so here, preconditions, actions, both conditions, they'll just make your code cleaner. This is one important one that's more talking about DevOps doing a recap.
00:24:06.908 - 00:25:08.684, Speaker A: So you have now all your invariant tests written. So how can you get the most out of them? So make sure to kind of bound your values or clamp them so that you are not wasting some fuzz runs. So for example, here I'm testing a deposit and I'm receiving an arbitrary amount value from my fuzzer. And basically that only makes sense if I'm trying to deposit and I have enough balance on my contract. So otherwise I know that this will revert and I don't want it to revert because I'm only testing here for when the, like when the deposit happens. And, yeah, so one way to do this would be just to kind of take this random value and do a modulo operation and make it fit into this range. That's what this bound value will do in foundry.
00:25:08.684 - 00:25:46.494, Speaker A: Echidna has some similar function as well. But yeah, basically you just fit into this range. And here is like something that most people do, especially when you're starting, when you're starting out because you have some sheet codes on foundry and also like you can just do like a nif else. But that's a maybe a bad idea because basically when, yeah, so if the fuzzer just throws the value zero here, it won't pass into this cheat code. Assume here. And basically you kind of wasted that value. It will try a new value another time.
00:25:46.494 - 00:26:41.516, Speaker A: And when you're starting your fuzzing campaign, you have to determine the number of runs that you're going to try. So for example, 10 00, 10,000 or 100,000. And that's basically just one run wasted if you are doing a bunch of assumes. So you should like always try to bound the input value into the, into reasonable values that we're trying to test. Yeah. So here's another tip. Like these, basically, like sometimes you have your smart contracts that they have some, basically they have some like state variables that are tracking some like deposits or maybe some withdrawals, maybe like the supply or something like that.
00:26:41.516 - 00:27:33.472, Speaker A: And you want, you want to check like against a different variable that is doing the same thing. So it's doing the same, same action, but like it's a different variable, and that's what they call ghost variable. So for example here, like, you're depositing in a vault and you're just like summing all your shares into a different value. And then you're comparing if the deposit is working as intended. So basically later you can have an invariant that sum balance off equals total supply or total shares, for example. Yeah. So this one here, it's a bit similar to the other one, but sometimes so, but this one, I think the other one is more obvious.
00:27:33.472 - 00:28:35.876, Speaker A: Like. Oh yeah, that's obvious. But this one, I think it's more important. Sometimes you're writing variant tests and you see yourself kind of checking your protocol functions, sometimes against their own functions. But what if, like, there is an issue with the implementation of one function and the other function kind of has the same issue, you know what I mean? So the idea here is to test the logic against different implementations or maybe some very dumb sum of total position variations, but it doesn't matter. I'll just sum everything and I'll kind of guarantee that the sum is equal to the state variable. So this is very common in math.
00:28:35.876 - 00:29:19.024, Speaker A: Like, it's very common to do this mistake, like to not do this when you're testing math libraries. So sometimes you are testing maybe like if the square root function is working, I don't know. And then you are just using the same square root function from the, from the library. So you're not really testing anything. So always try to create a different implementation and. Yeah, and like check it against that different implementation. Okay, so this one here is also interesting.
00:29:19.024 - 00:30:18.846, Speaker A: This is like, it's not really like advanced, but I would say that like, when you're starting out, you're not usually writing this handler based testing, but it is worth it. And what this means is that, so the thing is, when you are writing your invariance, you can either call your protocol, like call the protocol that you're testing directly. So for example, adding liquidity to uniswap. So you can just call the function directly. But the problem is that you won't be testing, you won't be separating the state of that actor in a different. Very well, because basically all the function calls from your fuzzers. They will go through the same address, all the same address will be calling the protocol that you have deployed.
00:30:18.846 - 00:30:39.714, Speaker A: And the problem is that sometimes bugs, they appear when you have more than one user, or sometimes they appear when you have, like when you started with an empty balance, which maybe is not the case when you have a single contract that is both deploying your target contract and that is receiving, depositing.
00:30:41.794 - 00:30:42.106, Speaker C: The.
00:30:42.130 - 00:31:58.328, Speaker A: Fuzzing like input from the fuzzer, basically. So the idea here, like. Yeah, exactly. And like this, this is why I think, like, as I mentioned, like this is not really advanced, but like when you're, when you're starting out, sometimes you don't do this just because this requires some extra effort. And in here, what I did like in the same ad liquidity function for uniswap is that I created a user contract and that contract is basically just a proxy that is sending arbitrary function calls to arbitrary addresses. So here I'm calling add liquidity and I'm passing in like all the variables in, into this encode with selector. And basically what this is doing is that I have like my echidna contract here that is receiving the inputs from my fuzzer and this is calling another contract that this second contract is the one interacting with the protocol.
00:31:58.328 - 00:32:48.298, Speaker A: So basically this will make, make like, make sure that this user is the one that is holding all the uniswap liquidity, all the Uniswap tokens and so on and so forth. So I can also test like different users here. Yeah, so this is called handler based testing or sometimes actor based testing, but it's the same thing. And this is also related with using multiple actors or multiple handlers. Handlers. So in this example I'm using the same user, but that's maybe not ideal because here I'm kind of testing a single user interacting with Uniswap. But sometimes your protocol requires many different actors or many different users.
00:32:48.298 - 00:34:02.820, Speaker A: So you can kind of create a very simple modifier. Maybe if you're using foundry, maybe you kind of have different actors and you randomly choose one of those and you do all the actions, like simulating one of those using a prank cheat code from foundry, for example. And the benefit here is that I'll be testing different actors. Echidna also has that. It's a bit different for echidna because Echidna will test three different actors and by default, so you don't have to, like, you test some three different hard coded addresses and foundry, I believe, tests more than that, but it's like the same concept they won't add recom as far as I know. Maybe I'm mistaken, but they don't add precompiles as descender addresses, but they do add the precompiles as variables. So for example, if here, like, let's say instead of being amount would be like address, I don't know, like recipient, maybe recipient would be a precompiled.
00:34:02.820 - 00:35:16.854, Speaker A: So like one of the random inputs would be like those special cases or maybe like dead or dead beef or whatever. They'll try those values. Yeah. So this is also one suggestion more on the lines of optimization. So here with foundry, you usually start with founder by default, will try to fuzz all the functions, all the public functions of your contract and all the deployed contracts. But that's not usually what you want. Sometimes you just want to test some very specific contracts, especially if you have lots of contracts and some very specific functions.
00:35:16.854 - 00:36:16.624, Speaker A: And basically that will make your tests run faster, basically. And you have some additional work that you have to do here with foundry. But basically for echidna, you just use internal for your functions and for your public variables. Like a common mistake is like having public function, sorry, public state variables that like, the downside is that echidna will try to fuzz those, those state variables as well. And that, like, that's kind of useless because those state variables, they, they won't, like, do any logic because they are just kind of read only variables. So you should also try to make them internal in the case of echidna. Can you hear me?
00:36:19.444 - 00:36:44.854, Speaker C: All right, guys. Okay, so, yeah, so this one here is more on the optimization side. If you're using echidna, make sure your state variables are internal. If you're using foundry, make sure you manually select the selectors that you want to test. Also the contracts. Yeah. So this one here is also interesting.
00:36:44.854 - 00:38:00.656, Speaker C: That's not advanced, but that's something that most protocols are not doing, which is make sure that you are testing your invariants both on success and on failure. So what does that mean? So, for example, if I'm adding liquidity to uniswap, I know that k must increase, but that's only true if the call succeeds. If the call does not succeed, then the k should not change. So k before equals k after. And this is really important because basically this means that you are testing all different kind of branches of your fuzzing campaign, not only the success case, and sometimes you will find bugs on your failure case, like most times, actually. So it's really important that you have kind of this if else, or maybe a try catch when you're calling a function and making sure that you are testing variants both on success and on failures. And like, sometimes you have like different invariants, either if it's success, maybe to increase.
00:38:00.656 - 00:38:36.162, Speaker C: If it's failure, it should not change. So, yeah, so you should have like different properties here. Yeah. This one here is also interesting. Like this is not really like something you, you kind of need to do like actively, but this is something that will like inevitably happen as you write your invariance. So sometimes, like what will usually happen is that you write your invariance, you run the fuzzer and something will break. Like it will fail and you kind of have to debug what happened.
00:38:36.162 - 00:39:51.380, Speaker C: And maybe there's a real bug and maybe there is not, there is no, there are no bugs, but just your invariants. They aren't as strict as you thought they were. So this is why sometimes you start with, with an invariant and then you kind of have to improve it over time. So what I mean by that is, for example, on uniswap, a very simple invariant is that when you remove liquidity, you burn DLP tokens. So basically the total supply should decrease, but that's only true if there is no uniswap fees. So like the uniswap fees that go to the protocol that right now are turned off, but that the governance can turn on if they choose. And this is something that, it's not evident at the first glance, but this happens because if the fee is on, then you can also mint new fees, sorry, mint new LP tokens even if you are removing liquidity.
00:39:51.380 - 00:40:36.496, Speaker C: So that can increase the total supply. And this is not like evident at a first glance. So this is why sometimes you need to kind of have also some if else cases, depending on some configurations of your system, like on the state of your system, basically. And, yeah, and basically you can kind of also increase the coverage by having variants for all of those cases. Number 14, this one kind of, I think this one is the most important one. Like if you, if you, if you retain anything from this presentation, please be this part here. This is the most important part.
00:40:36.496 - 00:41:57.844, Speaker C: The first parts are also important, but this is very important, which is like making sure that you are checking the code coverage. So with echidna, for example, you can turn on the coverage report, which will basically generate an HTML file that you can later analyze and see what parts were hit by the fuzzer. And basically it will show in green the parts that were hit, it will show in yellow, a part that only I don't remember exactly what the yellow means, but yellow is also bad and red is very bad. Basically, red is when the fuzzer did not hit those lines. So for example, here I have one function that basically like I'm swapping some tokens, and here I have a condition that the reserve should be at least one so that I can make a swap. And here I can see that all this path here, all these lines of codes, they weren't even executed. So maybe your fuzzer will end in success and kind of, you are not testing anything because, because like those, all those lines, they aren't hit.
00:41:57.844 - 00:42:49.694, Speaker C: And that's really, really misleading. This is why I think this is one of the most important parts. And like one of the suggestions of Sartora for example, which is like a bit, I don't know, like not ideal, but that's how they do it, is like manually introducing bugs to make sure, like. So one of the other ways of mitigating this problem is manually introducing bugs and making sure that the certor approver will catch those bugs. So that's usually how you work with formal verification. So you kind of introduce a bug and you create a rule, and then you make sure that the rule will catch that bug. But here we have an easier way to find that, which is basically just making sure that the environment that I'm trying to test, it's being hit by the fuzzer.
00:42:49.694 - 00:43:47.676, Speaker C: Otherwise all those invariants that might be here, like beneath, on my post condition, they aren't being checked. So I will have like a false, false impression that I have a good fuzzer, a good fuzzing campaign, but maybe that's not really testing anything. So, yeah, so here, what should I do when I see this case, I'll try to understand why these lines are never like being hit. Maybe. Yeah, maybe like the reserves, they are always zero because, I don't know, like maybe adding liquidity is not working properly, or maybe like, I'm wasting a lot of runs in another part of the code. So this may also reach to a point where, where the fuzzer won't take test as many variables as the others. This is also related to the optimizations that I mentioned previously.
00:43:47.676 - 00:44:55.404, Speaker C: So sometimes you have a bunch of requires, if you're using echidna or a bunch of vm, assume if you're using foundry and maybe you're wasting a bunch of runs and you are not hitting those important lines. So this is where optimization is important. You want to make sure that your code coverage is 100%. Otherwise you are not testing anything. Yeah, so I think the reports, they are generated automatically by the tools because they need to. So basically they will try like 1000 or one or 10,000 runs, and out of those runs they would generate a report of how many of those lines were hit. I think that foundry also gives an estimate of like the percentage of times that those lines were hit.
00:44:55.404 - 00:45:48.046, Speaker C: Yeah, but the point is that you should make sure that you are hitting all the lines in order to test your invariance. So this one is important. This one is also related to the previous one, like trying to reduce or optimize your fuzzer, kind of how you can. Like you need to be conscious about the input space of your, of your, of your functions. So for example here, like this is like a bad kind of approach. Maybe you are, you're testing a withdraw function and you're using the number of assets and you're not even kind of, maybe this is like an ERC 46 26 volts and you're not even testing the addresses that you are withdrawing to. So there is really no need to have these additional parameters here.
00:45:48.046 - 00:46:33.362, Speaker C: They are just kind of wasting some campaigns because basically the fuzzer will try different values, but you only care about the first one. So. Yeah, like make sure to remove unnecessary parameters so that the fuzzer will run more efficiently. Another like kind of bad, but sometimes unavoidable situation is where you have too many parameters. So maybe you have like a deposit, you have like amount from, to recipient, like in, I don't know, six different parameters. So that's bad because you have too many inputs for your fuzzer. And, and basically this means that you will end up testing fewer scenarios and you want to make the fuzzer more efficient.
00:46:33.362 - 00:47:32.136, Speaker C: So if you can kind of refactor it to receive fewer parameters, that's better. But you should also be conscious because sometimes you can also accidentally introduce, kind of not introduce new bugs, but you can accidentally miss some bugs if you're removing important parameters. So make sure to kind of think well before optimizing. This is not the case where kind of optimization, not really. Sometimes optimization is good because if you optimize your input space, you will test more scenarios. But you should also be conscious. Like if you are by mistake, removing some possible paths from your system, then you kind of made a mistake.
00:47:32.136 - 00:48:26.080, Speaker C: So be conscious about your optimizations. But if you can optimize, then that will be definitely better because you'll test more scenarios. Yeah, so this one here is like just also kind of maybe, I don't know, maybe an advanced or footnote suggestion here that you should try multiple runs in a large sequence in different seeds. I also see lots and lots of people not doing this. Maybe you have your fuzzer set up and you just test the default values, which are quite low. They run like, the pro is that they run fast, and the con is that they don't. They sometimes won't find very deep bugs.
00:48:26.080 - 00:49:21.116, Speaker C: So you should like, really try to have the fuzzer run for as long as possible. So this is like a comparison that I made using different injected bugs on uniswap. And like the, like, long story short, like the large bars here, they just mean the kind of this how spread out is the time to break those invariants. And as you can see, sometimes you can find invariants, like in, I don't know, 10 seconds you can break those invariants and sometimes in like a whole day. So you should really like, try to increase the number of runs and the depth of your tests to make sure that you are catching all of those bugs. It's not all fuzz runs that will just instantly catch your bug. So you might be getting false negatives if you have a very small number.
00:49:21.116 - 00:50:03.292, Speaker C: Here. This one here I took from cyphering. They had a good video where they explained how they did invariant tests for their beanstalk audit. And a good suggestion was to curate a unit test for all your fade runs, because this will make it easier to debug. It will also make it easier to review. Like sometimes the fuzz output is not very clear. Maybe it's, maybe it requires a lot of transactions, so it maybe won't shrink very well.
00:50:03.292 - 00:51:03.696, Speaker C: Like Echidna would try to simplify the number of transactions, but maybe on foundry you can have, like, I don't know, ten different transactions until you find a bug. So it's a good idea to try to replicate that bug in a new unit test so that all your, like, whenever you fix the bug, you can also run those, your unit tests and have a more simplified version of the fuzz campaign that caught the bug. And I think this is the last one. So finally, this is the last one. More generic, but try to help the fuzzer be conscious about what functions you are including. Like, maybe some functions, they are good, maybe they are not good, maybe they are. Like, for example, here I have, let's say, a borrowing and lending protocol.
00:51:03.696 - 00:51:59.706, Speaker C: And then I added a new function to transfer some tokens. And should you really be transferring tokens or approving to any address. Like maybe or maybe not. And should you be trying to kind of test this function at all? Like, maybe, maybe not. So, like, it's not obvious that as, like, if you add more functions, the results of your invariant test will be better. That's obvious because every time you add an additional kind of feature, you will be kind of wasting or spending more runs. So you should be conscious, like, every time you add a new input variable, you are also spending more fuzz runs, because the fuzzer is just throwing random values at your tests.
00:51:59.706 - 00:53:04.494, Speaker C: So you should be conscious about how many functions you add. Maybe you should remove some, maybe you should optimize some. And this is, like, where it will take more time to optimize it. So, for example, here, for the first example that I gave for the pods finance engagement that I worked with them, we did an initial suite of invariant tests, and we were happily achieving 100% coverage with, I believe, a couple of hours of fuzz campaign. But then we kind of analyzed that we could improve the tests by adding some other edge cases. So we added some additional functions. And the downside is that we eventually ran out of, we kind of reduced our coverage so we wouldn't be hitting 100% anymore.
00:53:04.494 - 00:53:57.024, Speaker C: We would, because we kind of had new functions for the fuzzer to test. So what we had to do is we had to kind of increase the time of our tests, and they would have to run for much, much longer. So maybe you shouldn't add all functions. Maybe you can try to have more contained versions of your campaign and to run on, like, on a very, like, quick test, and you should have, like, a full fledged fuzzing campaign that will run for maybe days, weeks, and catch those very deep, weird bugs. And I think that's it. So, yeah. So please, if you have any questions.
00:53:57.024 - 00:53:59.954, Speaker C: Glad to answer. And.
00:54:33.474 - 00:55:03.514, Speaker D: Hi, thank you very much for the presentation. I would ask in which moment we should jump for a formal verification and maybe even writing the model in. Daphne, if you don't want to spend a lot of money with Sartora, if you think that is a good approach also.
00:55:05.934 - 00:55:53.040, Speaker C: Yeah, that's a good question. Thanks for the question. I think that will maybe depend on who you're asking. So, at the DeFi security summit, there were very mixed recommendations on when to start doing formal verification. So from my impression, and this is really like a personal opinion, big projects, they will say, you should start as soon as possible, because the system is very, very complex. So, for example, Aave, they were really defending form of verification because they had, like, such huge, such huge system with many different states. And like, fuzzing wasn't enough.
00:55:53.040 - 00:57:03.818, Speaker C: So that was their point. But I've also like, but also like Jocelyn from trough beats, he also gives a good like counter argument that fuzzing maybe be the best kind of bang for your buck in terms of kind of cost effectiveness. So with fuzzing, you can get a very good level of confidence with a much lower effort. I have never participated myself in a very big formal verification effort, but from what I know, this can take maybe months to have a good suite of invariants and properties formally verified. As of with fuzzing, maybe you can just with a week, you can already have your invariants, as I mentioned here. So if I were on the side of a protocol, what I would do would be to start with this part here. So this will be useful for both.
00:57:03.818 - 00:57:41.194, Speaker C: So write your system properties, then, like have them in English, have them categorized, like start with the most important ones, and then after this part, everything that you do with invariant testing will be applied also to formal verification, because you will try to verify the same invariant, right? Either with fuzzing or with, or with formal verification. So it would be probably a matter of choice, like of how much time you want to invest on it.
00:57:43.894 - 00:57:45.154, Speaker D: Thank you very much.
00:58:29.774 - 00:58:30.438, Speaker A: Hello.
00:58:30.566 - 00:58:48.174, Speaker C: Thank you for the opportunity and thanks for everybody who joined. I'll be sharing this presentation and also the resources here. And if anyone has any questions, please reach out. I'd be happy to help and I hope it was useful.

00:00:03.210 - 00:00:36.520, Speaker A: Okay, great everyone, let's see. This is Mevooz community call number eight. I'll drop the agenda here in the chat. And yeah, let's just jump into things. So first we'll start with the NEB. On the spec front there's version four of the builder specs, which should cover all the genev changes and should be ready to go for that. I think at least the flashbot software is ready and implements that.
00:00:36.520 - 00:00:49.370, Speaker A: With MevoOs relay, that's version 29. There might be a version two nine one. Let's see. Chris, do you mind giving an update on the status of the flashbot software for Denab?
00:00:50.270 - 00:01:34.330, Speaker B: Yeah, for sure. Map boost is then up, ready with the V one seven alpha one release. Let me post a link here. It's an alpha release because we did want to get Kiln or Lido to test it on mainet before taking a proper release. But this alpha release has been running through the last couple of test nets, and this week there is another shadow fork. And once that is all successfully concluded, we are going to cut a one seven release of Mav boost end of this week or early next week. The relay is ready with the V 29 one release.
00:01:34.330 - 00:01:56.530, Speaker B: Oh, okay. It's broken. That is correct. It's a draft release, but you can find the docker images and everything. Let me find here because I think, yes, one issue that has all the links but releases here on map boost.
00:01:59.030 - 00:02:02.340, Speaker A: Yeah, it works for me.
00:02:07.370 - 00:02:08.440, Speaker B: Let's see.
00:02:09.610 - 00:02:11.480, Speaker A: Okay, maybe this is the right one.
00:02:12.490 - 00:02:13.240, Speaker C: Yeah.
00:02:15.050 - 00:03:05.960, Speaker B: Thanks Sarah posted the wrong thing. I think so, yeah. Mefboost Alpha released stable and going to cut a full release probably early next week. And on the relay we are on the V 29 one release, the latest proper release. We did release V 29 recently, and shout out to Alex from Ultrasound, noticed an issue with the publish endpoint version one versus version two, an environment variable that was wrongly used. So we did this patch release 29, one that fixes that, and this is the release we are expecting to keep around for the whole Denp merge. There is no changes necessary at this point from our end.
00:03:09.610 - 00:03:39.700, Speaker A: Okay, great. So if you're listening and you run Web boost, you'll need to update to this new release. It'll be version one seven, it sounds like. I think that'll be ready, it sounds like within the next seven days, at least by the end of next week. So that's great. And also if you're listening and run a relay, you probably in some way use this Memphis relay software. So definitely be aware of that and go ahead and make the changes you need to make.
00:03:41.910 - 00:04:13.280, Speaker B: Danab has been maybe one more addition. Yeah, sorry, one more addition was that the builder is running. Our reference builder is running on the demo branch with the latest tag being. With the latest release being this one. So if anybody's interested in the builder code, this is the one that we've been using. There is still a small issue about calculating an invalid mercury route in some situation we are investigating that's not yet fully fleshed out.
00:04:16.370 - 00:04:19.680, Speaker A: Okay, is that related to blobs or something else?
00:04:20.210 - 00:04:20.910, Speaker D: Yeah, exactly.
00:04:20.980 - 00:04:22.750, Speaker B: That has the DNF changes as well.
00:04:22.900 - 00:04:31.860, Speaker A: And the submission, the mercurialization bug that you were just mentioning, is that with blobs or some other change?
00:04:34.550 - 00:04:38.680, Speaker B: Let me ask sarah, do you have a bit more details here?
00:04:41.210 - 00:05:13.150, Speaker A: I'm not sure if it's related to blobs. I definitely related to Dankune. So after the Dankune fork, sometimes in the testnet, it will see this error, and then basically sometimes in the testnets, we see, like, the beacon getting out of sync. Not sure if it's like blob related, but it's definitely like Denkoon related, because I only see this after the Denkoon fork. Yeah. Okay, cool. Great.
00:05:13.150 - 00:05:51.420, Speaker A: So, yeah, I think even if you don't directly use the boost relay software, you probably use flashbots builder to validate your payloads. So thanks for bringing that up. Another piece of software to keep track of. And what I was just saying, the main net Dinkun fork has been scheduled. I believe it's March 13. So, yeah, now is the time to start getting ready, and hopefully it all goes smoothly and great. Okay, let's see.
00:05:51.420 - 00:06:41.070, Speaker A: We could touch on testing. I don't know if anyone here has been looking at that lately, but, yeah, I know that we've been testing on the Shadow forks and things, versions of mobus like Chris mentioned. So, yeah, hopefully that shall be ready to go, and definitely in the next few weeks is something we can drill into. So, cool. Anyone have any questions on that stuff? Right, okay, yeah, good. Good idea. Chris, any relays other than flashbots want to give an update? Maybe just act that you're aware this is happening and you need to update your software.
00:06:41.070 - 00:06:55.690, Speaker A: Okay, we got acknowledgement from boxroute and ultrasound in the chat.
00:06:57.470 - 00:07:01.930, Speaker E: Quick question. Do we know when Gorely is going offline?
00:07:05.110 - 00:07:23.960, Speaker A: Yeah, I don't know if there's necessarily an official deprecation date, but I know, like, Lido has started even telling people to spin things down. I can go find if there is anything, but ultimately I think it's up to you if you want to drop support.
00:07:24.490 - 00:07:33.946, Speaker E: Well, yeah, we have so many validators that are only using Gorli. No one's on Heleski yet. So we're trying to encourage people to switch to using our Heleski relay instead.
00:07:33.968 - 00:07:35.210, Speaker C: Of our gorli relay.
00:07:36.350 - 00:08:12.646, Speaker A: Yes, definitely stop doing that. Sorry. Start doing that April 13. But generally the idea is like, Gorley is deprecating or has been deprecated, so people can keep running gorely as long as they want. I think a lot of the stake will go offline in the next couple of months, and that will be that. So definitely push people to use Heleski would be, I think, the right testnet and everything to start doing. And Chris has an ask.
00:08:12.646 - 00:08:42.080, Speaker A: Very good. Just have people online and watching. This is a good question. I think generally the consensus clients will not use Medboost like an epoch or so around the fork. That's something I can double check. But that all being said, if something is an issue and goes wrong, it might be the case that we need to turn your relay off to sort of limit bugs and or damage. So please be handy for that.
00:08:42.080 - 00:09:26.212, Speaker A: Okay. Are we all ready for Dinkin? Hopefully we will be. Cool. So another thing I wanted to bring up was a number of different discussion points. The first one, hopefully, is pretty straightforward. I put together this proposal to change how we do block scoring. So maybe I'll even actually share my screen and just run through this.
00:09:26.212 - 00:09:31.910, Speaker A: Let me try this. Can everyone see this?
00:09:33.260 - 00:09:34.010, Speaker D: Yes.
00:09:34.460 - 00:10:28.372, Speaker A: Okay, thanks. Right, so, pretty straightforward. The proposal is to make sure that when a builder submission comes to the relay, it's not including withdrawals. Yeah, I mean, just to give some quick context. Essentially, one way that many relays are computing a block's value is by just looking at the fee recipient's e balance before and after the payload. Pretty straightforward the way that withdrawals are processed. It turns out that basically, especially when they're like large withdrawals to the same fee recipient as the one the builder intends to pay, you can get to a place where this withdrawal amount is counted towards the MEV in the block, which I think this is essentially just a quirk of the way these things are handled.
00:10:28.372 - 00:11:11.312, Speaker A: And ultimately it causes some issues. So I called them out here. I mean, one thing is just like, it complicates people watching the system because, okay, does this builder have this much MeV or this builder have that much? When the builder can include the withdrawals, it really distorts how much. Again, MEV is really in the block. And this has nothing to do really with the execution layer. This is like the fact that there are withdrawals coming from existence layer is just this other thing that's happening and is really distinct from any of this Meb stuff. One thing that happens because of this is that it kind of can mask the actual bids that builders are sending.
00:11:11.312 - 00:11:58.464, Speaker A: So like for example, if I send a payload for one ETH, then another builder could send a payload for half an ETH, right? So it shouldn't win the auction. But if it includes withdrawals for like say 32 ETH, because Valder is withdrawing in the same slot, then this bid is basically masked. And there's actually been some analysis, I'd call it the student dashboard here. You can take a look at the doc if you'd like. But essentially there have been cases where proposers have missed out on maybe they could have gotten because of this withdrawals thing. Another big thing is actually weakened signature resistance. So there's this min bid flag which basically says if I get a map boost sort of bid or payload, it should clear some floor, otherwise I'm going to build locally.
00:11:58.464 - 00:12:22.584, Speaker A: Right. And again, this is meant to say, okay, if I have a more valuable block and from the public mint pool, I have to use that over medboost. Again, when you have withdrawals distorting these bid values, this makes this whole thing far more brittle. So generally there's big open issues with this. It's pretty easy to fix. We just take the withdrawals out. They're deterministic.
00:12:22.584 - 00:13:04.224, Speaker A: So it's very clear to everyone what they are and how they should be removed. And that's essentially what this proposal is saying to do. So the way I framed it here is add some epoch which we could figure out. Essentially you would just remove what I'm calling excluded amount, which is just taking this withdrawals to the same recipient that the builder intends to pay. Yeah, so pretty much that's it. Simple change. I also, let's see, I don't have the link, but someone at hotspots actually already implemented this in the relay.
00:13:04.224 - 00:13:16.990, Speaker A: So yeah, few lines change and I think generally it's like a pretty strong improvement to boost itself. Yeah, Chris, go ahead.
00:13:19.200 - 00:14:01.660, Speaker B: Yeah, thanks for putting this together, Alex. Nice write up and summary of the whole context. The only change that is needed is a change in the validation code. So there really is none of the really code or deployments would need to change. It's just the validation nodes that would need to account for the withdrawals. And we made a pr that I put in the side chat that does execute the withdrawals from the block scoring and flashbots is supportive, and we would like to find agreement on a given epoch where all the relays start executing the withdrawals from the bit value calculation.
00:14:06.120 - 00:14:20.410, Speaker A: Great. Yeah, and thanks for putting this pr together. That's super helpful. Does anyone think we should not do this? Let's start there. This is your time to pipe up.
00:14:31.620 - 00:14:36.550, Speaker D: Let me ask you the question. Is there any good reason not to do it?
00:14:38.360 - 00:15:21.450, Speaker A: I don't think so. I think I laid out a pretty good argument in the proposal, which, again, it addresses all of these downsides. We see pretty simple change and. Yeah, that's pretty much it. I mean, I think it's pretty clear that the withdrawals really have nothing to do with Mev, so they just shouldn't be there. I think there are more complicated things we can think about with block scoring, but they have more edge cases. And as proposers sitting themselves and all this stuff, that stuff is outside the scope of this pretty straightforward change, I think, and I think pretty clear that it would improve things.
00:15:24.400 - 00:15:29.432, Speaker D: It does require a little bit of social coordination.
00:15:29.496 - 00:15:29.916, Speaker A: Right.
00:15:30.018 - 00:16:00.968, Speaker D: Because if one relay chooses not to adopt this new scoring rule, then their bids look like they're way higher than everyone else's and they win all those blocks. I guess the coordination mechanism here is like, you have to basically have all the proposers agree that that relay kind of lied to them about the true bid value because it included the withdrawals. But, yeah, it would play out nicely by itself.
00:16:01.054 - 00:16:01.352, Speaker A: Right.
00:16:01.406 - 00:16:19.790, Speaker D: Somebody doesn't do it, we're terrible. We don't do it, and then everybody get ours, and then all the validator will be really mad at us and say we're going to disconnect unless you fix it, and then we fix it. So even if somebody doesn't play well, all the validators will be very mad very fast. But are the validators actually going to disconnect? That's the question.
00:16:21.060 - 00:16:22.896, Speaker A: Asus has already had some pressure from.
00:16:22.918 - 00:16:31.910, Speaker B: Builders to police this, and we've been doing a certain amount of social enforcement. Anyway, I'm not sure how much of a problem this is currently.
00:16:34.120 - 00:16:34.532, Speaker A: Easy.
00:16:34.586 - 00:16:39.430, Speaker D: From Lido will come and kick our ass. That will be fine. That's all.
00:16:40.360 - 00:16:56.970, Speaker E: Yeah, it seems like this is a problem that comes with every new builder until a bunch of relays tell them, hey, stop including those. But if we all just set it hard by Denku and just have the new simulation code updated for this, we could probably all on top of it.
00:16:57.340 - 00:16:58.650, Speaker B: Yeah, sounds good.
00:16:59.100 - 00:17:24.820, Speaker A: Yeah, exactly. So the withdrawals are deterministic. So it's very clear if this is happening, the bids are all public. So it's very clear, again, if a builder is doing this and or a relay is letting it happen. So I don't really see any issues there. Yeah, so that's actually a good suggestion, Ben, to focus on the Dinkun epoch. Do people feel okay about that, timing wise, that they can get this change implemented in their relay?
00:17:27.640 - 00:17:44.330, Speaker C: Yeah, that sounds fine to me. Maybe because now, you said, Stokes, that relays are just letting this happen. I do think it's nice to at least project a feeling of relays will not let this kind of thing happen. At some point we do do something.
00:17:48.060 - 00:18:07.280, Speaker A: Right. I think this is the place to do it right, because regardless of what the builders are doing, the relays are kind of this validation piece that should be supporting a variance of met boost. So that, again, the model makes sense, we can minimize trust guarantees where we have them. And, yeah, again, I think this is a pretty clear improvement.
00:18:09.540 - 00:18:11.010, Speaker C: I can agree to that.
00:18:16.410 - 00:18:48.222, Speaker A: Yeah, there's some discussion in the chat around how many blocks there are. Yeah. Terrence linked this analysis by data always. So again, I would point, you know, this isn't like every block coming through has this issue, but it actually is more frequent than you think. And yeah, some builders. So here it says we have penguin submitting some that, again, we're just using withdrawals. I assume that's from withdrawals, but it sounds kind of high.
00:18:48.222 - 00:18:57.460, Speaker A: But either way. Yeah, again, this seems like the right place to do it in terms of how we implement it, and seems like a strict benefit to me.
00:19:01.160 - 00:19:20.408, Speaker E: Can I quickly make a suggestion that we have a builder fork or some sort of gist out there for builders to see how to exclude these on their end too, just for these smaller builders, because I feel like sometimes when you bring this up to people, they have no idea what you're talking about. So if we could just quickly, everyone direct them to the same link, that.
00:19:20.494 - 00:19:21.388, Speaker C: This is what they need to do.
00:19:21.394 - 00:19:23.630, Speaker E: From now on, I think that would help things too.
00:19:24.560 - 00:19:40.400, Speaker A: Okay, yeah, that's a good point. So there's like pseudocode in the proposal. If that's not clear enough, is there a place you have in mind? Like, I would maybe even point them to the flashbots pr that Chris linked here in their builder repo.
00:19:42.180 - 00:19:46.390, Speaker E: Does that change in the builder code or is it just in the block validation code?
00:19:48.120 - 00:19:49.380, Speaker A: It's the validation.
00:19:50.040 - 00:20:18.366, Speaker B: The builder code base. What was that? Sorry, let me repeat, it's a change to the validation code, but the validation code leaves you the builder code base. So if you're using the builder code base for validation, but this is the change on the pr specifically for the validation. And we will put out like a patch or a pr for just the changes to the block scoring in the building process. Okay, cool.
00:20:18.468 - 00:20:21.626, Speaker E: Yeah, because I know that the validation code sits outside of the builder logic.
00:20:21.658 - 00:20:21.854, Speaker A: Right.
00:20:21.892 - 00:20:29.060, Speaker E: I mean, it's in the same repo, but as you're building a block and you're calculating the actual value of the block that's separate from validation code.
00:20:30.390 - 00:20:30.898, Speaker A: Yeah.
00:20:30.984 - 00:20:36.898, Speaker C: If a large part of this is just that, that is the default, it'd be really nice to just change the default that everybody's copying.
00:20:36.994 - 00:20:39.190, Speaker E: Yeah, everyone's using the flashbot builder.
00:20:52.260 - 00:21:22.440, Speaker A: Okay, cool. So let's go ahead intentionally know. We'll have this rolled up by Dan Koon. I can update this document that I put together and I'll follow up to the extent that I can with everyone to make sure we're ready. Great. Okay, 1 second. I'm just finding the agenda.
00:21:22.440 - 00:22:22.296, Speaker A: Cool. The next one I wanted to bring up, well, the next two really are around changes to optimistic relaying. And the context for this was that there were a number of, well, so at least two events, I think, where essentially, again, cordevs are watching the protocol. One of the biggest red flags I think that can happen in terms of security and operation of running this stuff is seeing what we're going to call bad block. So basically, if I have a node in the network, if I get a block from a peer, if the block is bad in some sense, which again essentially means invalid, then yeah, this is not good. It usually raises a lot of big flags in the logs, and I think all the client teams have alerting and stuff in place for this. So it becomes very clear to them very quickly when this happens.
00:22:22.296 - 00:23:03.050, Speaker A: And ultimately the reason this is bad is if there was a block that got into the chain that was invalid, especially for example, with the geth dominance we have, if there's a geth bug that accepts this block when it should not be the validators, then finalize it. We now have basically finalized a valid chain. And this is very bad. It's very bad because we'd essentially need to either agree that this is now the protocol, which is not a road we want to go down, or we would have to roll back the block somehow. Right. This would be like a dow hack level scenario. So generally when this happens, it's not good.
00:23:03.050 - 00:23:13.470, Speaker A: And luckily in both these cases, the clients all found these blocks as bad or invalid, so they're working as they expect.
00:23:13.920 - 00:23:14.670, Speaker C: However.
00:23:16.880 - 00:23:52.868, Speaker A: Ideally everyone's a good citizen on the peer to peer network and this is not even happening in the first place, it being the fact that these blocks should never even be gossiped. Right. And as far as I can tell, at least in one case what happened was essentially with optimistic relay, there was a bug in the validation code. So I think in one case what happened was basically the builder should have been demoted, but it wasn't. And then the first block got through. In the optistic relaying model, this can happen. Once the builder is demoted, the slot would be.
00:23:52.868 - 00:24:38.230, Speaker A: It's a missed slot, the block is invalid. Okay. The proposal should be compensated from the builder's collateral. Everything's good. In this case there was a bug and so we actually got multiple of these bad blocks through and yeah, that's not great. What can we do about this? One thing we can start to do, and this is again more of a discussion point, but the suggestion is essentially, if you're in optimistic mode, essentially don't release the payload until you validated it locally. As far as I understand, relays today, they will eventually validate the block, but it might not be before they release the payload, for example, to their local consensus clients even.
00:24:38.230 - 00:24:58.510, Speaker A: And so the change here would be to basically say, okay, regardless of all optimistic bid serving and all of this, you actually block on payload release until you know it's valid. I'll stop there, I guess. Does everyone understand what I mean, or should I go into this a little bit more?
00:25:02.970 - 00:25:22.620, Speaker C: I understand that. Seems like you could then spam the relay with a bunch of blocks to basically enforce a missed slot. If you're a builder, you just send a bunch of fill up the validation queue with whatever, and then that's going to delay the block publish, for example.
00:25:23.890 - 00:25:56.280, Speaker A: I don't even think this was sort of a malicious scenario. It was just like a bug because there was an accident and so we still got to the same outcome. And like, in either case, I think it makes sense to actually block payload release and this slot could still be missed. Even if there is a bug for at least one slot, you could still have a missed slot and builders demoted all this. However, this is more of like a network health thing where the relay should be a good actor here and they shouldn't even be putting bad blocks out in the first place.
00:25:58.890 - 00:26:36.734, Speaker C: Yeah, maybe. Also if people are worried about the scenario where we get maliciously attacked in such a way where we sort of overflow and the relay just can't handle it anymore, and that's why we're not publishing. I did a quick look for Alex Stokes at how often it is the case that our ultrasound relay still has time. I think it was something like 8.3% of blocks. We would not have time to simulate a block before we need to publish it, but all the rest we do. So you could even see this as an optimistic scenario where in, I guess that is then 92% of cases, you are able to simulate that block.
00:26:36.734 - 00:26:46.470, Speaker C: You are able to see that it's invalid. You are able to then decide not to publish it because you know this block is invalid already. So that could be a pretty nice way, really, to improve their safety.
00:26:51.550 - 00:27:31.638, Speaker D: It's not that I disagree, but I want to offer a counterargument, which is I think we're going to cause more missed blocks by simulating the block. So, like, just using Alex's numbers in 8% of the cases, you're not going to make it in time. So you don't have enough time. And if some blocks actually sometimes take longer to simulate, then potentially we're going to induce more missed blocks by holding it off and not releasing the payload. So I'm not saying not to. I'm just like. There is also the downside of it.
00:27:31.638 - 00:27:40.982, Speaker D: So it's going to increase the latency, and so therefore it's going to affect that potentially. Yeah.
00:27:41.116 - 00:27:42.200, Speaker C: Stopping here.
00:27:45.200 - 00:28:02.470, Speaker A: Kubi, you add your hand raised for a bit. Yeah, just a bit of a clarification. So it was my understanding that the error was in the validation code itself. So in this case it wasn't. I'm just seeing Nicholas shaking his head.
00:28:03.580 - 00:28:05.690, Speaker C: I thought it was the demotions, but.
00:28:07.420 - 00:28:35.472, Speaker E: I can clarify really quick. The error was in the demotion logic. So the validation code was returning an error, but the demotion logic, there's a couple of scenarios where there's like a false positive. That doesn't necessarily mean it was bad. It was just. It could have been chain state issues with one of the simulation nodes that was simulated in the block. In this case, we were treating something that was a true error as a false positive, which was working fine for months.
00:28:35.472 - 00:29:13.176, Speaker E: And then this one came through and it caused a lot of issues. Anyway, the bug was in the demotion logic. We've since went a lot more strict into motion logic, and I'm constantly clearing out false positives every, like 30 minutes right now. But it's just an issue on the demotion logic in terms of actually simulating the block before you return the payload. There is some benefit to that. And I think we could actually do that. Right after returning a header you have some latency between the time you've returned a header to the time you get a get payload request anyways.
00:29:13.176 - 00:29:39.620, Speaker E: And there is some ways you can make sure that that request is from the validator so you're not just simulating 1000 blocks because I mean, we get like 1000 get header requests every slot. But there are some ways to identify the validator with that. And it's also another good reason why we might want to consider having validators sign get header requests so we can know that there was them and then allocate resources for those more intentionally.
00:29:41.160 - 00:30:14.832, Speaker A: Okay, thanks. Yeah, so I guess my initial thinking was if there was a problem with the validation logic then this obviously wouldn't solve it. But that's fine. Then I would still have similar concerns to Yuri. So this will probably lead to us or general there being more missed slots than before. Yeah, that would be my take or my fear. Missed slots just because the block is instant out on time? Yeah.
00:30:14.832 - 00:30:16.400, Speaker A: Because of additional latency.
00:30:17.380 - 00:30:36.404, Speaker D: Yeah. I think Ben can add more insight to it. The reason the bug in the demotion was the simulation takes a lot of time. Okay. We think it's okay. So you think the bug was in seeing a timeout and. Well, the timeout doesn't mean that it's invalid.
00:30:36.404 - 00:30:51.420, Speaker D: Well, it actually was invalid. So the problem is that if a block takes a long time to simulate and we don't know in advance how long, maybe it will be a long block, maybe it will be a short block, then we'll have more missed slots.
00:30:55.120 - 00:31:40.676, Speaker C: Yeah, I don't know. But there's a general agreement that it maybe doesn't make that much sense for a relay to block and to go simulate to block and then not publish until it has simulated. I totally agree there. I think for me at least more of the observation was that relays often, as Ben just suggested, do have time from the point that they serve the header to the proposer, which they know is likely to be picked, to then just go simulate the block. And if you then notice that it is improper before you get the signature from the proposer, you do have the ability to just say, okay, let's not even try. And then in this case, again, if it's a demotion bug, there's no help there. But there may be cases where a builder submits an invalid block that turns out to be a wrong block and now the relay just has time to notice that it's a wrong block.
00:31:40.676 - 00:31:47.450, Speaker C: And then by the time it gets the signature, it says, oh, wait a minute, the header I served, I can never publish this. I'm not even going to try.
00:31:52.930 - 00:31:53.678, Speaker A: Right.
00:31:53.844 - 00:32:31.200, Speaker F: Would it be appropriate to suggest an alternative for the solution? So instead of withholding the payload, the relay could encrypt the payload and as it does today, but send over the decryption key when it's validated. And this could alleviate some of the latency problems as the payload size is much lower. So I just wanted to kind of pose that I guess the proposer would. Right, so that's also an operation, but that might be much faster than waiting for the payload.
00:32:34.730 - 00:32:43.798, Speaker A: So the relay also gossips the block and it needs to do the same thing. So, yeah, I don't exactly see how encryption helps much there.
00:32:43.964 - 00:33:02.430, Speaker F: Well, the payload would be there, right? Basically, we reduce the latency surface to decrypting the payload rather than sending over the payload, or I guess sending over the decryption key and decrypting the payload rather than sending over the payload, it should shave off latency. Theoretically.
00:33:06.620 - 00:33:28.450, Speaker D: It kind of resembles the original architecture of block start, et cetera, where we were like, this was my original idea regarding scale or not, et cetera. In reality, it adds a lot of complexity of this, kind of, okay, let's send it that and then decrypt it afterwards. The complexity around it is very high, the latency savings probably not as high.
00:33:29.460 - 00:33:44.436, Speaker A: I see there also is latency to this encryption decryption process. Right. So I think relays and builders are generally optimizing for things about on the timeline of the encryption. So, yeah, I don't see how this helps too much.
00:33:44.618 - 00:33:46.150, Speaker F: Well, it would be much.
00:33:47.960 - 00:34:04.380, Speaker B: Also, keep in mind that block is actually usually published through the relay and not through the proposer. So the latency of sending the payload to the proposer is not impacting their proposal time because it's already going out through the relay and their well peered CR clients.
00:34:05.200 - 00:34:10.076, Speaker F: So the largest latency impact is between the builder and the relay is what you're pointing out.
00:34:10.098 - 00:34:10.670, Speaker A: Okay.
00:34:11.840 - 00:34:12.460, Speaker D: Yeah, exactly.
00:34:12.530 - 00:34:30.756, Speaker B: And the get header and get payload request latency between proposer and relay, but not the response from get payload that is already irrelevant at that point because concurrently the block is already getting proposed and getting.
00:34:30.938 - 00:34:31.812, Speaker F: Makes sense.
00:34:31.946 - 00:34:32.900, Speaker B: Published.
00:34:35.400 - 00:34:38.644, Speaker A: Yeah, Mike. Yeah.
00:34:38.682 - 00:35:24.928, Speaker D: I guess my main thing that I feel now is that we're kind of getting into the nitty gritty of how an optimistic relay is implemented, and we can talk about what went wrong and stuff, but these things are going to be continually evolving and I think bugs will continue to happen. And it just almost feels inevitable that when there's a small set of people producing all the blocks and a small set of relays publishing those blocks, bad blocks are going to hit. If these norms that we're trying to codify, add latency, then the relay or builder that violates that norm is going to have a latency advantage.
00:35:25.024 - 00:35:25.380, Speaker A: Right.
00:35:25.450 - 00:35:35.290, Speaker D: So I don't know. I don't know exactly what the point I'm trying to make here is beyond. Like, I think these problems will probably continue.
00:35:37.660 - 00:36:08.240, Speaker A: Right. And so I think this proposal was kind of like defense in depth from my end, where it's like saying, hey, there will be bugs, and we should make sure there are not bugs, but that can happen in parallel to checking where we can. Okay. I was actually about to circle around to Alex's point, but there's a message here. So you think that that was not a helpful suggestion.
00:36:09.540 - 00:36:50.912, Speaker C: Yeah, I don't think it helps that much. As I say in the message, if it's the same slot, I really may notice, and by the time it gets the signature, refused to publish, which could be helpful in some cases, but we're missing the slot anyway at that point. And for the next slot, a demotion should happen. And then if the demotion has happened, then again, it's not a risk anymore. So it's really only that very first slot where you notice a builder has made a mistake, give you an invalid block and you've already served the header for it, and then noticing that block is invalid. I only see that you can keep the network from forking by some clients still accepting that publish and others rejecting it. But there, I feel like we're going a bit far.
00:36:50.912 - 00:37:01.860, Speaker C: Like, could be an interesting conversation, but I think we're pretty far beyond what a relay is trying to do and much more deeper into a client consensus, client execution, client responsibilities.
00:37:03.240 - 00:37:10.890, Speaker A: Sure. But what happens when there's a bug in the demotion logic? And this is now like nine slots, which is where this came from.
00:37:12.140 - 00:37:28.190, Speaker C: Yeah, but then I think, isn't it the demotion logic? Yeah. Okay. But then you would miss still every slot, right? Like every slot. The relay might notice that, hey, this is a block. I cannot publish it. Wouldn't publish it. But how would the relay know in time?
00:37:29.520 - 00:37:37.600, Speaker A: Right, because if we're assuming there's a bug in the demotion logic, then you're kind of screwed, Ben.
00:37:38.740 - 00:37:39.056, Speaker D: Yeah.
00:37:39.078 - 00:37:54.112, Speaker E: So basically, if we try to simulate the block before responding or publishing with the payload, we could still miss the slot. Because of the delay on that. But also, if it's an invalid block, we'd miss the slot anyway, whereas assuming demotion logic is correct, we'd miss one slot regardless.
00:37:54.176 - 00:37:54.356, Speaker A: Right.
00:37:54.378 - 00:38:40.420, Speaker E: So we wouldn't really save anything if we're simulating beforehand. But a couple of ideas about improving demotion, because right now the risk is per optimistic builder pub key per relay. So we could be publishing a block ultrasound, then publishes a block for the same builder that has the same bug, and then that's two, and then it's like there's six pub keys across there. So one idea that I think would be nice is for optimistic relays to expose some sort of endpoint or service or websocket or something where they are informing the other relay that they're demoting a builder. Something along those lines, so we can kind of have better protection.
00:38:43.420 - 00:38:49.210, Speaker C: Yeah, I'd love to add to that if I can. I don't know, Terrence, if you. That's okay.
00:38:50.940 - 00:38:51.352, Speaker A: Sure.
00:38:51.406 - 00:39:19.140, Speaker C: No worries. So what we're working on also is in block the motion right now. So we're trying to make it possible for a relay to notice, just as the submissions are happening, that one is invalid, and immediately the motor builders, so that they may not even get to be the top bid that we serve. So we could potentially even help also other relays to then never serve a header if they quickly enough get the message from us that we're noticing in this slot that this builder is doing invalid stuff and they should be getting demoted.
00:39:23.960 - 00:39:51.790, Speaker E: Yeah, the other theme too is grouping builder pub keys, because most builders have sets of builders that are running the same version across different regions where maybe builder one and builder two are completely different builders. So a bug that's affecting builder one wouldn't affect builder two. So I've talked to a couple of builder sets about this and they're wanting to do groupings for demotion to limit their risk as. Yeah, there's a. There's a lot to improve on that.
00:39:55.800 - 00:39:57.880, Speaker A: Terrence, you've had your Henry's for a minute?
00:39:58.620 - 00:40:40.064, Speaker D: Yeah, sure. So I guess from my perspective, from the client dev, I think missing one block due to optimism, relaying is fine, but the issue is that we're missing multiple blocks. And I guess that typically happens because of the demotion logic fails. Has anyone thought about solving this issue from mvv boost or the client implementations perspective? For example, some idea I can throw out is that we can have a relayer monitoring system that is just centralized, but then as long as there's one relayer that has an issue that relays the invalid block. We just shut off that relayer.
00:40:40.112 - 00:40:40.420, Speaker A: Right.
00:40:40.490 - 00:41:13.570, Speaker D: And that's probably not a good idea because it's that we are trusting someone else for something. Again, I guess like a trustless solution of that would be like a p two p gossip network that if today there is like a relayer, sorry, there's a relayer that is relaying invalid block. You have like a p two p prop style thing that it goes into rest of the proposer and then the proposal disconnect with that relayer. I guess these are some other solution space, but they are mostly on the proposal side.
00:41:16.710 - 00:41:58.814, Speaker A: Right? Yeah. So Francesco actually had a really nice proposal to basically add something like a bedmin pool that starts to get at this. I don't know if anyone's had the chance to look at it here, but essentially, yeah, it would start to help us have this more decentralized observability around what the relays are doing. And that could definitely help. So there's that. This is maybe slightly out of scope for this call, but the idea also came up on one of the all core devs calls to basically say, so clients today do have circuit breakers for various conditions to just not use web boost at all. And this could be one as well.
00:41:58.814 - 00:42:49.680, Speaker A: If they see a bunch of bad blocks, just stop for some time. Yeah, this kind of takes me to the next point, which is just like increasing legibility, I suppose, around optimistic relay in generally. Even right now, I think it's very hard for people to know which relays are optimistic, which builders are registered, and all of this stuff. I think ultimately, one really nice solution here is basically moving everything on chain. I don't know how people feel about that. It probably needs a little more specification, sorry. But yeah, this is something to start getting on our radars.
00:42:49.680 - 00:43:03.630, Speaker A: I don't know if any relays have thoughts about that, like essentially making optimistic relaying more transparent.
00:43:05.890 - 00:43:47.990, Speaker G: I mean, as far as I can tell, optimistic relaying, at least for the oxygen relay, is maximally transparent in the sense that for every single block we'll tell you whether or not it was processed optimistically. There's optimistic flag. I think that's part of the default flashbot implementation as well. So I expect the other optimistic relays to also support this API endpoint. And this API endpoint, for example, is used to power some dashboards. So if you go to it will, it will tell you high level stats like what percentage of blocks are optimistic, which builders are using, optimistic, blah, blah, blah.
00:43:50.670 - 00:44:40.970, Speaker A: Great. So yeah, maybe it's just leveraging that information a bit better. Okay, so to summarize a bit, there is this proposal to essentially block payload release. It sounds like we generally don't like that here. Am I reading the room correctly? Getting some nods and thumbs up? Yeah. The implications on timing games and then also the converse of having more miss slots is not great. So I think it's definitely a little more complicated than just withholding payloads until they're validated.
00:44:40.970 - 00:44:52.320, Speaker A: Maybe the next bit was just around transparency in general. Someone has something to say.
00:44:53.170 - 00:45:37.294, Speaker D: Yeah, I wanted to ask, and maybe it's a stupid thought, but does it make sense that in addition to the simulation of a block, I'm very much against doing a block while simulating, et cetera. But does it make sense to make it more robust? All the relays run blocks. Sorry, validators. Anyway, if we see kind of like, yeah, we're going to do the simulation and everything, et cetera, but have another source of truth. If any of our valid of our nodes see the block and reject it, okay, tell it to demote. So basically making the demotion mechanism more robust. So it both checks it internally with all the checks that we want to do, et cetera, but also a bit of a black box.
00:45:37.294 - 00:45:56.466, Speaker D: Use our nodes out there. If the node says it's wrong, then we have an issue and it might cause some false positives of kind of like, okay, like demoting, et cetera. That seems like a small chance and a low risk. Maybe it's stupid, maybe it doesn't make sense. I'm kind of just jamming or people.
00:45:56.648 - 00:45:58.340, Speaker A: Which other nodes do you mean?
00:45:59.270 - 00:46:30.286, Speaker D: We run multiple nodes and we use them for a bunch of stuff, including simulation. These nodes not only help with the simulation, will also literally, eventually they'll get the block and try to include them. If they reject the block, then it's kind of like it's another source of truth. And we have a bunch of them, and obviously we give them the new blocks anyway. So just get another read from them that they accepted the blocks. But maybe again, Ben, do you have any insight on mean?
00:46:30.308 - 00:46:53.270, Speaker E: It's the same. I mean, ideally the demotion logic works at that point. So as long as the demotion logic is good, any point of failure along publishing a block will have issues. We'll take care of it. So really the only major issue of this was demotion logic. Not so much a protocol issue or an optimistic issue. It was more just that demotion logic wasn't working properly.
00:46:55.290 - 00:47:06.620, Speaker A: Right. Which also kind of brings up the next suggestion, which is in some sense having almost like fraud proofs gossip amongst relays. Seems like there is more appetite for this. Do we like this?
00:47:07.950 - 00:47:28.098, Speaker E: Yeah, I mean, I'd love to have more cross relay communication going on. I think I suggested something a long time ago about some relay p to p going on, but it was just back then there was really kind of no reason to do it. Now we're getting to more use cases of why that would make sense, right?
00:47:28.184 - 00:47:29.330, Speaker A: Yeah, Alex?
00:47:30.230 - 00:48:22.660, Speaker C: Yeah, pretty strongly in favor for the good of all the out of protocol block building ecosystem. Also maybe in general to add, we already in our really have several actually circuit breakers and they also have tripped at times. I do again agree with Ben that you want to be very wary of just make this core the motion thing work, because that's very critical. I think that's a first. But I do think for relays in general, it makes sense to have, as Yuri suggested, sometimes a mechanism that says, well, if this really strange thing goes wrong, like I've served three headers and I expected them to go on chain because I was publishing blocks for them, but then none of them appeared to have at least in lured. And we have various phone calls and various circuit breakers where our auction will just stop serving headers to try and make sure it doesn't do any more damage, something like that. And then this really is working together to make that even more effective, I think is a great idea.
00:48:26.070 - 00:48:27.700, Speaker A: Yeah, definitely agree.
00:48:30.550 - 00:49:05.150, Speaker C: I guess when we're on that topic. Anyway, I have been working on demotions recently and changing some things also from we had a very close copy of the flashbot code and then now we've changed it a little bit, especially in scenarios where there was many, many submissions which were invalid. We saw some strangeness happening. So I guess if you're working on the motions in general, then happy to talk about making that more robust or something like that. I did already check the flashboards code and that I am pretty sure has all the changes sort of that I made on our side too to make it more robust.
00:49:09.030 - 00:49:27.960, Speaker A: Just one quick side comment on sharing potentially demotions across different relays. This also means if one relay has a bug and wrongly demotes a builder. And this has happened, for example, when we have tested stuff on testnets and other kinds of scenarios who are basically just demoting that builder across the board.
00:49:31.130 - 00:49:52.670, Speaker E: Yeah, I think we'll have to figure it out. But what I feel like would be a good solution is not just gossiping like a builder pub key, but also the payload. So that a relay could simulate that payload themselves to verify that that payload was improperly built so they can do their own checks on there to decide to demote that builder. Not just spamming, demote every builder.
00:49:55.170 - 00:50:14.470, Speaker A: Yeah. I think the builder would kind of have to opt into this, though, because I know we are builders as well, but we don't submit to every relay because there are obviously some trust assumptions there. So if you're actually gossiping the payload, that has to be okayed by the builder.
00:50:19.970 - 00:50:31.246, Speaker D: Aaron, wouldn't it make sense to have the validator also monitor this p two p network because the builder's public key is known to the header's bid.
00:50:31.278 - 00:50:31.426, Speaker A: Right.
00:50:31.448 - 00:50:57.094, Speaker D: So if a validator I monitor this network, I see this builder's bid, or this builder's key is getting gossip among the relayer that it may be demoted from my end, the validator side. I could also kind of just make my own action and make my own decision such that I don't have to relate on what the relayer does. I think it may be more trustless.
00:50:57.142 - 00:51:09.360, Speaker A: This, like Medboost, only sees the relay's pub key and not the builder's pub key, which is something we could change, but you wouldn't be able to do that.
00:51:15.710 - 00:51:41.860, Speaker E: Really quick because Kubi brought up that we would be gossiping payloads from builders. Those payloads would already be attempted to be published anyways. So there's not really any privacy guarantees of any transactions in a published payload anyway. So if we were doing demotion logic. So after a block had been attempted to be published, we found that it was a bad block that really demoted them. There's no guarantees of privacy for any transactions in there because they've already been attempted to be gossiped across the network anyway.
00:51:46.520 - 00:51:47.990, Speaker A: Yeah, that's a good point.
00:51:50.830 - 00:52:13.274, Speaker B: But couldn't you just then unbundle the block and no one knows which relay it was? What was that? Wouldn't it then be possible to just unbundle the block and no one knows which relay's fault it was, but allegedly.
00:52:13.322 - 00:52:22.660, Speaker A: The block's already out. Right. Like, this would be the scenario where it's like I'm trying to publish and then there's some failure. So this is Ben's point, that the blocks already out there.
00:52:23.430 - 00:52:26.260, Speaker B: I see. Makes sense.
00:52:29.950 - 00:53:27.210, Speaker A: Yeah. Terrence, just to close the loop there, that's actually the relay is pub key, and the specs are a little confusing here. The way the specs are written is that essentially when it says builder, it's like, abstractly a builder, just with respect to Metboost. But yeah, this is actually confusion that keeps coming up and honestly, me or someone should go change the specs so it's more clear what's happening. But this is my other point, is that in this builder bit, even the spec thing that you put in the chat. So the pub key, there is a relay pub key, but you could very easily also have the builder's pub key if we need it for this reason. Any more to say on this topic?
00:53:38.190 - 00:53:51.120, Speaker F: If people want to do a POC with us on this relay gossiping, please reach out. This is very interesting for us and we'll probably quickly enable this on Holski next week or something just to see what it looks like.
00:53:56.040 - 00:54:21.326, Speaker E: My one last point is I know that some people are running ref block validation code. I think there's an open source fork out there somewhere. Does anyone have any performance metrics on that to see how fast that is? I'm sure it's faster than go, but want to see some data if that's available. Don't say that one more time.
00:54:21.348 - 00:54:23.360, Speaker C: Performance metrics on what exactly?
00:54:23.730 - 00:54:28.030, Speaker E: If the rest block validated code outperforms gas.
00:54:30.710 - 00:54:38.920, Speaker B: Tried it out and in our experiments, the gaff validation code base was faster than the ref one.
00:54:39.370 - 00:54:44.920, Speaker E: Oh man. Someone needs to post that in the ref telegram group and they'll fix it.
00:54:45.850 - 00:55:02.266, Speaker C: We've already talked to them about it. They've done a few iterations on staging. It's about the same. So we kind of put it. It's not important, not a priority currently. Was hoping to get some easy games but nowhere to be had.
00:55:02.448 - 00:55:06.080, Speaker E: I know, simulation time. That'd be great.
00:55:07.730 - 00:55:08.142, Speaker A: Right?
00:55:08.196 - 00:55:19.202, Speaker C: We have a public repo for that as well. And I think last I checked our conversation with the rest team, we gave them some frame graphs, but I don't think we continued after that. Like Nicholas said, it wasn't a priority for us.
00:55:19.336 - 00:55:23.118, Speaker D: I am more than happy to reinvigorate the conversation.
00:55:23.214 - 00:55:24.180, Speaker C: There we go.
00:55:24.950 - 00:55:27.090, Speaker E: I mean, I'm here listening.
00:55:29.910 - 00:55:30.980, Speaker C: Love it.
00:55:46.580 - 00:55:52.250, Speaker A: Cool. Chris, you have some questions in the chat. I don't know if you wanted to run through those.
00:55:53.580 - 00:56:18.220, Speaker B: Yeah, sure. One question was about the optimistic relay code path in the mafboost relay code base. Flashback is not maintaining that code path and I just wanted to double check whether there's any changes expected for Dennis or is it basically like Dennib ready as is? Because some release. I think Asters and agnostic are using that if I'm not mistaken.
00:56:24.520 - 00:56:25.124, Speaker A: I don't know.
00:56:25.162 - 00:57:00.056, Speaker B: Mike or Alex, you have any insights? All right, Max, you're here from Astos, right? Have you used with optimistic relay? We do, with some changes. I need to go and have a look at it. I'll come back to you on that. Okay. We've done a bunch of testing on Gali and on Holshki, so I think.
00:57:00.078 - 00:57:00.616, Speaker A: We'Re good to go.
00:57:00.638 - 00:57:04.444, Speaker B: But let me come back to you. Okay, that sounds good.
00:57:04.482 - 00:57:04.636, Speaker A: Yeah.
00:57:04.658 - 00:57:26.210, Speaker B: Please post a note in the relays group somewhere or in a forum. Somebody tell agnostic that they should also double check. Flashboards does not provide any guarantees about the optimistic code path. We are not running it and we are not. Just to be clear, we are not maintaining that code path. Just a regular non optimistic one. That was one.
00:57:26.210 - 00:57:43.210, Speaker B: Thanks. Then I heard that ultrasound, you guys saw some two errors from the CL client when publishing blogs and would be really curious about a little bit more details and if there was any insights you had.
00:57:44.780 - 00:58:28.140, Speaker C: Sure, yeah. I'm afraid I'll have to disappoint. But just what I noticed is that sometimes when we try and publish blocks with Lighthouse at four 60 and the latest version of the flashboards map boost relay, the payload API that's in there, sometimes both nodes would indicate the 202 status code, and then that's seen as a failure, and the relay breaches as a failure. Scenario logs an error and also doesn't progress on the success path where it would reveal the payload. Right. And then when I started digging into it, I noticed that Lighthouse gives a 202 also when it sees that the block is already known to it, it's already a part of the chain, and therefore it cannot publish it. So initially I suggested maybe we could just make that a warning.
00:58:28.140 - 00:58:58.050, Speaker C: Scary error goes way, and also our errors become a high signal. Again, the difficulty there is, the more I was reading about it, the more I started noticing that I think there's also a scenario here where the blog is invalid. I found a buried issue somewhere. If somebody goes to look into that, you need to be very careful that. I think the 202 can be a hacking scenario where the blog is judged to be invalid but recognized, but I'm not sure. And then this was costing a lot of time. So then I said, okay, I'm going to leave it for now.
00:58:58.050 - 00:59:07.810, Speaker C: So, yeah, I'm not sure there, but if somebody wants to collaborate on it, maybe or something, I'm happy to provide more context and collaborate. Does that answer your question?
00:59:10.930 - 00:59:11.294, Speaker A: Yeah.
00:59:11.332 - 00:59:14.894, Speaker B: Thanks for your insight so far. Ben, you have something to add here?
00:59:15.012 - 00:59:47.130, Speaker E: Yeah, we see 202 a lot with publishing blocks the way we publish blocks. We do it to a couple of different things. Like we push to our BDN alongside a couple of Cl nodes as well, and we see that pretty much the first server that sees it will get a 200 code response, then everything else will probably be a 202. So it's basically after it's seen it from another p to P, I guess, channel on there, then it doesn't necessarily mean you're going to get a 200 response.
00:59:57.170 - 01:00:12.980, Speaker B: All right, thanks. I think that clears it up so far. The last point that I was wondering about is does the ultrasound really add delays to push get header responses until, to postpone that until a certain point in time?
01:00:15.910 - 01:00:49.870, Speaker C: Yeah. So what we do is we do try to use the time that we think is available to try and get the highest possible bid to give to the proposer. But of course also respecting the delays that we see. So there's the delays client side that we have to take into account and then there's further delays where it just gets dangerous and the block might not make it anymore. So we might not give you a header at all anymore if we see that there's very little time. But there's basically where we give no header anymore, where we're almost immediately replying and where there's still a lot of time, we think. So we wait a little bit longer to try and get you a better bid.
01:00:55.120 - 01:01:04.160, Speaker B: And is that in a public code base or is that in a, that's like get header changes. Right. Like are you running a customized.
01:01:05.380 - 01:01:34.170, Speaker C: Yeah, the logic for that is generally private. And also I think some of that will be what gives us an advantage which may make us help make the relay as sustainable. But we are generally open to questions. And although the specific timings of course, might be sensitive and we might not want to reveal generally what we're doing, we're happy to be open about and give some insights into. So do feel free to ask more specific questions and I'll just try to answer.
01:01:36.460 - 01:01:43.870, Speaker D: Yeah, I wanted to say if they didn't, our percent of winning would be even higher.
01:01:46.750 - 01:01:47.660, Speaker A: For real.
01:01:52.450 - 01:02:11.080, Speaker G: Right. There is a race to zero and in some sense we're kind of following what blocks route possibly started. And now basically the game is to delay as much as possible with whatever budget Metro gives us.
01:02:12.970 - 01:02:59.234, Speaker D: Maybe worth mentioning here what we're doing with our validator gateway. I don't know if we started the game. I think it was p to p who started the game, but I don't think we started it. But from our perspective with our validator gateway, for those who aren't familiar. Basically we take a note, it sits really close to the validator. And instead of playing the best effort game in which the validator asks all the relay but have like a threshold, okay, I'll wait up until, let's say 900 millisecond, then we tell the validator, tell us exactly when you define it to be a good time for your perspective. We'll give you a block exactly at that time.
01:02:59.234 - 01:03:28.478, Speaker D: And so this isn't timing in this like if you're waiting for others. Anyway, we'll wait to that. If you want to get that at time zero, we'll give it to you at time zero. If you want it at 100 milliseconds, we'll give it 100 milliseconds. If you want it at a second and a half, 1500 millisecond, it is the validator decision. But the idea is that currently if you just send it to all the relays, we found that we underperform because we're faster. So somebody asks us for a result, we immediately give it back.
01:03:28.478 - 01:04:00.438, Speaker D: Avoila ultrasound, if it's a validator in the US, ultrasound has like 100 milliseconds. Just until they hear the request, they'll beat us and provide a better header. Well, we could have waited 200 milliseconds. We should have had an advantage in waiting until ultrasound have responded. So we see the validator gateway as a way to get around it. And instead of being like best effort, just everybody tried to be as fast as possible. But here's the threshold that we consider safe.
01:04:00.438 - 01:04:05.420, Speaker D: Just tell us exactly when you want the header. We'll give you the header at that time.
01:04:08.350 - 01:04:58.700, Speaker E: I'd like to also mention one point of the validator gateway is to not encourage colocation with relays. We set it up in a way that it runs near validators where they want to run. And we're actually working with validators that are in low performing regions that have stakeholders almost demanding them to move to either the US or the EU so that they can have better performance. And we are seeing a really good increase in their performance for their consensus layer rewards, alongside with the relay proxy, seeing some good performance with them, with githeaders, because historically they time out at 950 milliseconds because of this latency from people like in Africa trying to make a request to a node over in the US. It's a long time, so it's been really good to see that we're fighting colocation with this.
01:05:08.130 - 01:05:17.380, Speaker A: Matt, do you have anything to say? Maybe not.
01:05:21.590 - 01:05:59.360, Speaker F: Could there be an avenue for other improvement proposals. And this goes back to this kind of Mevboost modules concept that I had pitched in the first meeting at Devcon Bogota. And because lots of folks are working on stuff like this, and you see validators saying, look, we're not that technically sophisticated to do all sorts of things, so if there could be an easy way to modify or create modules for Mevboost that can add some logic to the commitment, I believe it would unlock a big design space for lots of people.
01:06:07.040 - 01:06:33.610, Speaker E: Yeah, we do see that most validators don't want to modify movie boost. Everyone wants to be vanilla because no one wants to maintain a fork of a constantly updated code base. So yeah, there's something that could be more modular. I feel like validators would love that. But validators see the APY improvements for kiln or p to p or any of these people that are waiting, massive delays, and they want that. So the market's pushing for it.
01:06:36.660 - 01:06:56.100, Speaker F: Would the group be open to working on a proposal where we can have a framework that, I don't want to name it an App Store, but you could have a thing inside Mevboost, and people can plug and play and build things there. So that could be a major feature for this piece of software, in my opinion.
01:06:58.440 - 01:07:00.164, Speaker D: I guess you could think about doing.
01:07:00.202 - 01:07:42.870, Speaker B: Like an experimental release map boost version. I don't think we will implement that complexity in the stock map boost software, because on my experience working on it, it's just really tough hardening the software, and it's immediately shipped out to hundreds of thousands of validators that lose money on bugs. And it's really scary. And every bit of complexity is already big hassle. I don't see that type of complexity making its way into the regular stockmap boost release, but I guess we could brainstorm on how to enable like an experimental branch or fork or something else. That's my intuitive take.
01:07:43.640 - 01:08:00.040, Speaker F: I appreciate that, Chris. And maybe this goes into the design of it, right? Maybe it's better that the relays absorb this complexity or something, but this general idea of kind of mev boost modules, wherever it sits, I do believe would unlock many things for the ecosystem.
01:08:02.220 - 01:08:05.160, Speaker A: Do you have some examples of these modules?
01:08:05.240 - 01:08:26.088, Speaker F: Yeah, so there's a Tyco pre confirmation proposal, and we're doing pre confirmations on Mevcommit as well. So we're looking to have validators opt into this. Now, there's many methods where you can do this. They can use some staking token, or they could say, hey, look, relay, you take care of this and I'll pay you a fee, or they can modify Mevboost.
01:08:26.124 - 01:08:26.276, Speaker A: Right.
01:08:26.298 - 01:09:20.260, Speaker F: So the logic would be that basically I have some pre confirmations as a PBS actor, whether you're builder, relay, or validator. And I'd like this game to be played in the set of bids that are coming to my validator. Right. So the validator makes some preference that, hey, this is the type of game that I want to be played, and presumably the relay or the builder is playing that game and that there can be some harmony across the pipeline on whatever that game is. Right. And I'm kind of putting out this module store as a place where you can kind of pick and choose your games. Maybe there are timing games, maybe there are other new games, but that's kind of how I imagine the validator would kind of communicate with the rest of the pipeline when it comes to their preferences on the games.
01:09:23.090 - 01:09:38.900, Speaker A: Yeah, I mean, it sounds like something that relays would offer. Right? You could imagine different relays have these value added services, for example, that could do that there. I generally agree with Chris and others that metboost itself should be as simple as possible.
01:09:39.910 - 01:10:19.950, Speaker F: Yeah. Then the question becomes, how do we kind of link that to the protocol? Right. We can have the validator kind of opt in in some other method. What I'm seeing in the community, particularly when it comes to some of the proposals open with Tyco, et cetera, is that people are suggesting that they build a new meb, boost fork, et cetera. So it's more of an observation that the ecosystem is doing these things, and it looks like this group has some insights that we shouldn't do that because it adds complexity, it's difficult, et cetera. So maybe this is just a starting point on thinking about this, and we'll arrive at something more concrete.
01:10:21.650 - 01:10:25.730, Speaker A: Yeah. Do you have a link to the teco discussions, like if they have a forum or something?
01:10:25.880 - 01:11:05.760, Speaker F: Yes. Well, there's a proposal by Nethermind, I believe, and they talk about this. I will link it right now. I saw this from DVT tech, like oball, et cetera, where they have some logic that they want to put. I'm not particularly suggesting that that goes into Mevboost as well, but it seems like the ecosystem is, there's emerging many, many different types of commitment logic for proposers, and this could be an avenue where that can surface.
01:11:15.580 - 01:12:10.700, Speaker A: Yeah. Thanks for sharing. Anything else anyone wants to discuss? Okay, sounds like that's that. Hopefully this was a helpful call for everyone. If you are listening or here, go get ready for Dinkun. It is happening very soon and that should be your top priority. And, yeah, otherwise, thanks for joining, everyone, and I'll see you later.
01:12:10.700 - 01:12:13.020, Speaker A: Thank you, everybody.
01:12:17.030 - 01:12:17.600, Speaker B: Hi, everyone.

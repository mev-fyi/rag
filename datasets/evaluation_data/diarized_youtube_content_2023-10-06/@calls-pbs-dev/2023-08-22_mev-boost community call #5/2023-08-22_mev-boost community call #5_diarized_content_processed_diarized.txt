00:00:03.810 - 00:00:48.274, Speaker A: Okay, we'll go ahead and get started. Hey everyone, this is mevboost, community call number five. It's been a little while since we had the last one but yeah, hopefully there have been some pretty exciting updates for Daneb and the upcoming hard fork there. So I have an agenda that I've assembled, I dropped it in the chat and yeah, I think we can go ahead and get started. The main thing I want to do with this call today is just get everyone on the same page with Daneb. There's a hard fork coming up very soon and a key part of that will be updating maboost, all of the relays and any builders who are listening. So, yeah, mainly I just want to call some things and get us all on the same page there.
00:00:48.274 - 00:01:31.042, Speaker A: We can discuss implementation and any testing efforts that we want to and yeah, there's a few other things I put on the agenda just to call out. Otherwise if there's other stuff people want to talk about, if there's time at the end, then we can move to more of an open discussion. So to get started, we'll start with spec updates. So the first one is on the builder specs. These are mainly in place for Daneb already. There was this one RFC to consider changing this constant. It's not super material but in the sense that it'll probably even be the same number in the actual code.
00:01:31.042 - 00:01:47.894, Speaker A: But that being said, this is more about parity with the contingency specs, which I think is pretty important. I'm just coming back from a break so I haven't had time to look at this in much more depth beyond that, but I do want to call it out. Yeah.
00:01:47.932 - 00:01:48.514, Speaker B: Thanks, Chris.
00:01:48.562 - 00:02:42.086, Speaker A: It's this 187 that he dropped in the chat and yeah, if you're interested please take a look. And yeah, so there's that. There are a few things on the relay specs so we can move to those. These are the relay specs that Flashboss has and the idea is that if you're like a nice conformant relay, you should implement these specs. Like, a cool thing you get right is supporting this data API, which people use all over the place for all sorts of visualizations. So I think it's actually been quite helpful. There were a few things I'll get to this a bit later, but I was working on some builder software and I was trying to go off the specs to implement various pieces and ran into some things that didn't quite match at least the Flossbots implementation, so we worked on some of those.
00:02:42.086 - 00:03:15.380, Speaker A: So there's this one here, number 26. This was just when you actually submit a block as a builder before I had basically said you give back some signed receipt. I don't think any relay does this right now and yeah, it doesn't really seem needed. You're welcome Chris. But yeah, this PR just updates it to the 200 response code that matches the implementation today. So that was pretty cool. And then there's another one around.
00:03:15.380 - 00:03:31.766, Speaker A: This might have even just been something with, like, the API docs, but there was issue 24. There was just a field missing around the proposer public key. Yeah. Chris, did you want to say something? Your hand was up. Oh.
00:03:31.788 - 00:04:06.180, Speaker C: I just wanted to note that historically, for the first issue, the block submissions only returning 200. It was when we designed the really APIs. We thought it would be nice to return a signed receipt for builders to attribute like misbehavior. But then we didn't get around to implementing it before the merge and there was never any appetite or asked for it, so it never got done. And this is just like an historically artifact from the design period. And I think it's all right to thanks for splitting this out. And it seems that just returning 200 is good enough for now.
00:04:07.110 - 00:04:56.640, Speaker A: Yeah, I completely agree. I mean, no one's really complained, and it doesn't seem I don't feel like we're in a place yet where there's these semiannimous relays where they could do more dangerous things. So not that we always want to be in this regime where the system is very reputation based, but for now, it doesn't seem like we necessarily need these super accountable responses and we can always add it down the line. Let's see. So, yeah, just some spec things. I think that was everything there. Okay, next up, I did want to chat about implementation readiness for Dneb, so I at least definitely want to call out the core flashbot software we have so that's Webboost relay and the Flashbots Builder.
00:04:56.640 - 00:05:07.764, Speaker A: Chris or I don't know if Sarah's here, but if one of you would like to give just a short update, if possible. Otherwise I can just call out. Okay, not sure.
00:05:07.802 - 00:05:42.530, Speaker C: I don't think Sarah made it. But you can find the tracking issues for both Mafboost, the relay and the builder linked in the community call agenda. This outlines, like, all the pieces that were needed. It's all mostly wrapped up on Mafboost and the relay. We have the final pieces as last PRS open for review and testing. Anyone with expertise in relays is welcome to take a look there too. And it would be appreciated to get a bit of more feedback and input, if you would have any.
00:05:42.530 - 00:06:25.340, Speaker C: On the builder side, until just recently, we were not able to work with Gaff because of some missing functionality, and that's been, I think, implemented now. And we are starting to rebase the builder and then get that piece done too. I think the question here for us is when do we participate in the DevNet? And it may be next week or two weeks later. Because of occasions in between. The goal is to wrap up all the code changes until next week, and then it's basically untested in testnet. So the next stage here is then proper testing in live networks.
00:06:28.560 - 00:06:51.060, Speaker A: Cool. Very exciting. Yeah, thanks. I dropped the tracking issues in the chat for my boost and the relay. So basically, I see your names here on the call. Like, most of you should go review these PRS. That would be very yeah, yeah, Perry, that'd be great if you want to chat about testing.
00:06:53.240 - 00:07:33.772, Speaker D: Yeah, I can go about testing. So, yeah, we would definitely love to have you guys on the testnets already. But I want to showcase this one tool from Kurtosis, and I think Gani is on here also with a video. So the reason I wanted to showcase this is at the bottom, you can see a mock mev example. I'll be updating this to also show a full mev example. So there's two modes. The first mode will spin up Mario's mock mev relay endpoint, and that would allow the client teams to test the builder workflow with a mock relay.
00:07:33.772 - 00:08:25.908, Speaker D: And the mock relay also has the ability to generate invalid payloads, et cetera, so you can assert that valid payloads get delivered as well as invalid payloads get rejected. On the other side, you can have mev type full, and the kertosis team has essentially got the entire builder relay infrastructure. It'll also use Mev Flood to generate transaction loads so that you can actually have the builder build blocks that would be valid. And the idea is that once the first half is working, the second half can use that to test the entire relay builder update workflow. And the best case scenario, at least the way I'm approaching it, is all of this is local. So it would be perfect to have this working locally before we hit devnets. If you guys prefer to still take part in devnets, that's fine by me.
00:08:25.908 - 00:08:33.220, Speaker D: But we found that this local testing approach has been really beneficial for DevNet Eight because you can just do way faster iterations.
00:08:40.070 - 00:08:50.120, Speaker C: Just wanted to give a real high level shout out here. It's amazing that's invaluable to be able to start testing this in a more localized but holistic fashion. Great job.
00:08:52.170 - 00:08:52.582, Speaker A: Yeah.
00:08:52.636 - 00:08:59.500, Speaker D: Huge shout out to Gani and the Kadosis team. I just let Gani say something or add something if he wants to.
00:09:00.190 - 00:09:01.450, Speaker A: Yeah, thank you so much.
00:09:01.520 - 00:09:19.490, Speaker B: And people can start using it. This is the East To package, and as Paris said, if you pass in the right parameter, you'll have your own testnet. And if you want to scale it up, you can run the same thing against Kubernetes as well if you wanted to. You have to wait for four epochs to see payloads getting delivered on the network.
00:09:21.590 - 00:09:37.510, Speaker D: And also, just a point to mention, we've just used the Flashbots map, boost relay, et cetera, as defaults. It's a completely overridable default in case someone wants to test any other relay or any other builder or anything else. It's a generic piece of infrastructure.
00:09:40.560 - 00:09:57.830, Speaker A: Yeah, this is awesome. This might be a longer term project. But at some point it would be nice to have something that looks kind of like Hive and we get all of the relays into this sort of framework and then we could actually test them in this way. So this is like a huge foundational piece. So really good.
00:09:58.200 - 00:10:14.570, Speaker D: There's a really nice fun fact with Petosis, there's also a Go SDK built in, so you can actually have Go tests. And that's not the same as Hive, but it's kind of mostly there. So you can have a testnet spin up in the background, have GOtest assert, a pre state and a post state.
00:10:16.540 - 00:10:27.324, Speaker A: Sweet. And there is the one caveat, I think. Did we say four epochs until basically there are blocks flowing through it? Yes.
00:10:27.362 - 00:10:39.120, Speaker B: So after the first epoch, the Mev Flot component will start running and the Mev components will be spun up because it waits for capillar. And then after the fourth epoch, you should see payloads being delivered to the Mev relay.
00:10:39.860 - 00:10:48.470, Speaker A: Okay, so it's not so much the Mev software, it's more like fork timings and things that put these delays in place. Yes.
00:10:50.120 - 00:11:09.804, Speaker D: All the CLS don't have support for Capella Genesis yet. We're testing it and once that's clean, then we'll be switching over and you'll save an ebook at least. But there is a tiny hack here as well. You can change the slot time, so you can put slot times as 6 seconds instead of 12 seconds and still make it fast.
00:11:09.842 - 00:11:16.830, Speaker A: Oh, nice. Okay, cool. Have you tried this is an aside, but have you tried dropping the slot times really short?
00:11:17.680 - 00:11:24.690, Speaker D: We normally did 3 seconds lot times to just test stuff out. But you are hitting limits for sure because it's the main net spec in the end.
00:11:25.620 - 00:11:43.764, Speaker A: Right, cool. Yeah. Excellent. Thanks for sharing. I'll add these links to the agenda and I was even just talking to some people yesterday about testing relays and stuff and yeah, I think this will be really helpful to a lot of people. So again, excellent work. Yeah.
00:11:43.764 - 00:11:45.744, Speaker A: Chris, did you want to say something?
00:11:45.882 - 00:11:46.664, Speaker C: One question.
00:11:46.782 - 00:11:47.450, Speaker A: Yes.
00:11:48.220 - 00:11:53.560, Speaker C: How much of four, like data types and flows is already testable in this Kudosis setup?
00:11:55.180 - 00:12:22.560, Speaker D: I don't know if Mario okay. Mario doesn't look to be on this call, but I had a call with him, we spoke about it to get the mock MEB stuff up and running ASAP. The types have already been updated yesterday and I think he needs to integrate it into the mock MEB middleware software, whatever that we're using. And the aim is to have that done sometime next week and then all client teams can ensure that it works with the mocks.
00:12:27.110 - 00:13:07.132, Speaker A: Thank you. Yeah, I think that'll be really helpful because it's essentially unit test for these different pieces and there's probably going to be around a bug fixing just for those things. Then we can move to more full fledged integration environments as we get closer to Mainnet. Okay, so back to implementation. Let me just see where we're at in the agenda here. We covered most of this stuff about DNAV readiness. So great work, everyone.
00:13:07.132 - 00:13:40.920, Speaker A: I did want to call out the other relay implementations. I know that we have block native with dreamboat. I believe blocks route has an implementation. I at least see some of those representatives from those teams here. So just FYI, this is also something that your teams need to be aware of, is that the hard fork is happening. So definitely stay on top of this stuff and don't delay. I don't know if either of you want to give short updates on progress, and if you haven't looked at this yet, that's also fine.
00:13:40.920 - 00:13:44.490, Speaker A: But this is a chance if you'd want to chat about anything.
00:13:55.800 - 00:14:22.360, Speaker C: Come on, worry. For instance, what's the status of your Foil Four Air Force? You're looking into it, right? Are you playing with it? Are you researching it? Are you just waiting for it more? The reason I'm not giving an update is because I've been busy with other stuff and Ayali is leading that with the Dev team. So the reason I'm not giving an update is not because I'm withholding the information. Rather, I know we're working on it, but I really don't know the details because I've been working on multiple different initiatives.
00:14:22.520 - 00:14:25.116, Speaker A: So I can tell you for sure.
00:14:25.138 - 00:14:29.650, Speaker C: We are working on it. I don't have you the specifics because I'm not leading the charge on it.
00:14:30.580 - 00:14:45.428, Speaker A: Yeah, I'm not trying to put anyone on the spot. If anything, I just wanted to call it out just to make sure that everyone's on the same page and again, understand if people are just getting up around to things. Now, I think I can repeat what.
00:14:45.514 - 00:15:23.116, Speaker E: Uri just said that we are also looking at many different initiatives, and I was able to actually browse the PRS that you've prepared, but so far I haven't got any big contribution that I agree or disagree with something. We will be bringing those changes to Dreamboat as well, definitely. But no particular notes for this particular implementation that you've done in the Mev.
00:15:23.148 - 00:15:26.050, Speaker A: Boost relay so far.
00:15:27.380 - 00:15:28.188, Speaker F: Okay?
00:15:28.374 - 00:16:10.976, Speaker A: Yeah. And I'll just say I will be knocking on your doors as we get closer to bigger testnets like Sepholia Gorli, especially Mainnet. To the extent that we can help test these relays and the interactions with and with clients, I think that'd be super valuable both for your teams but also for everyone using your relays. So, yeah, just keep it in mind. Again, that was kind of why I wanted to have this call, was just to get this on everyone's radar so that we can all move forward together. So I think that is good for Janab. I did want to call this out.
00:16:10.976 - 00:17:09.540, Speaker A: I was working on some builder software, so I've been talking with the Rest Devs, and we've essentially have this project to have a nice open source builder there's like the Flashbots Builder. There might be other builder projects, but I'm not aware of an open source one other than the Flashbots one. And the idea here is just to increase essentially implementation diversity and just have, in the long run, a very nice high quality implementation. I just started with this last week or so and it's still kind of in a draft PR, but I was able to land blocks on Sepolia, which was fun. And yeah, just going to call it out, especially if anyone's listening. If there's any rust devs out in the audience and you want to contribute, please reach out. And I think it'd be really good to have this effort here to have a really nice open source builder.
00:17:09.540 - 00:17:49.090, Speaker A: Yeah, so just wanted to call it out. And what else? Okay, so from here I had some, like I said, open questions or proposals. There's some things I've been thinking about doing, some of them we've talked about on the call before at various I guess how do we want to do this? I guess before we jump into that part of the call, I see Justin and Mike are here. Are there any optimistic relay updates worth giving? Just want to check in on that.
00:17:52.100 - 00:18:29.420, Speaker B: Not too much, I would say. We've been doing a few small refactors on the Flashbot's handle, submit new block handler because the V two version reuses a lot of that code. But since it's running in a different code path, like refactoring some of those functions out so they can be used both in both places, makes them more testable and just like more modular. So that's very much like small code PR cleanup stuff, code health cleanup. Other than that, I think nothing too major to update, honestly.
00:18:30.800 - 00:18:31.500, Speaker A: Cool.
00:18:31.650 - 00:18:51.060, Speaker G: I guess one big development has been that Agnostic has turned on optimistic relaying. I haven't talked to the team recently, but if anyone here from Agnostic wants to talk about their experience, that'd be good. Otherwise I guess we can talk about it offline.
00:18:56.020 - 00:19:11.110, Speaker A: Yeah, I'm not sure if anyone from Agnostic is here, but yeah, that's exciting. And definitely the more that we could build sort of, let's say, community knowledge around operating optimistic mode, I think that be a super helpful for people.
00:19:15.740 - 00:20:01.700, Speaker G: I mean, one thing I guess worth noting is that there was a bug in the Prism client which meant that the requested gas limit was incorrectly set to zero or something. And this was creating all sorts of false positives for the optimistic relaying whereby the relay for the block was invalid. And so we demoted the builders. And so I think we kind of implemented a hot patch for that and we're kind of waiting for all these buggy Prism clients to upgrade before removing the hot patch.
00:20:03.960 - 00:20:35.730, Speaker B: Yeah, that was weird. That one was a little weird because the validator registrations basically said set the gas limit to zero and then builders were still sending blocks with like 30 million gas limit. So the blocks were still valid and were still landing on chain. But because they were in optimistic mode, we processed them async and then thought that they would have failed. But yeah, it ended up not causing any missed slots, but it caused a lot of noise on the relay end, I guess.
00:20:38.100 - 00:20:49.924, Speaker A: Right? I mean, yeah, that's an interesting question. This is almost certainly a bug with preparing these registrations and the question is do we just ignore it even though.
00:20:49.962 - 00:21:07.290, Speaker B: Yeah, it kind of implies that the builders aren't actually looking at the gas limit that's set. Do any validators actually set a 25 million gas limit and then do the builders actually respect that? Has anyone actually looked at that data?
00:21:07.900 - 00:21:16.556, Speaker A: Yeah, really? A little bit when we had this issue and they do to some extent. I talked to some builders as well and I think they mentioned that some of them at least, they look at.
00:21:16.578 - 00:21:18.840, Speaker D: The biggest relay and ask those relays.
00:21:18.920 - 00:21:41.220, Speaker A: For their registrations and we'll use those gas limits to set it. And then there were differences between relays as well in what they reported for these validators. So definitely some builders are looking at it. Yeah, I'm pretty sure the relays validate this as well. Right, that was where the issue came up. So even if builders aren't, it should still be respected.
00:21:42.200 - 00:22:26.100, Speaker E: My question is, should we broadcast this to the wider community of Validators because we are still getting those errors and some clients apparently are not re registering with us every time and we have some failures from the blocks not really passing through that through our validation because the gas amount is wrong. So shouldn't we just inform that more broadly that, hey, look at your prison notes code basis because maybe it would be good time to enforce the registrations.
00:22:32.820 - 00:22:42.150, Speaker A: Right? I mean, if this was a Prism issue, then yeah, it sounds like we should have them fix the issue. I don't know if anyone from Prism is here. Let's see.
00:22:43.400 - 00:22:45.270, Speaker B: Parents said he wasn't able to make.
00:22:46.120 - 00:23:10.300, Speaker A: Yeah, yeah, that's okay. We can follow up offline but yeah, I mean, definitely the bug should just be fixed in the client and then yeah, it is definitely an interesting question about how to handle in the meantime, but it sounds like there's a patch to just ignore it anyway. And we just assume that the Validator wants 30 million gas.
00:23:10.800 - 00:23:14.140, Speaker B: What's the point of allowing them to set different limits?
00:23:15.280 - 00:24:26.150, Speaker A: Well, this is something that the protocol supported since the beginning and at various times we've gone back and forth around like, okay, should this still be configurable? I think the rationale in the early days was like, oh, if we get to 15 mil and suddenly that opens up some Dos vector, then allegedly the minor community get together and try to change the SCAS limit in a more sort of decentralized online way. So there's at least a reason that it's configurable in the first place. There's actually even an EIP at one point to basically hard code it to 30 mil and just take this parameter away from anyone. So you could imagine going either way. And I think while it's a configurable parameter, it's very important that Validators retain control because otherwise we're going to hand a small number of builders this number and their interests are not necessarily as aligned as the Validators are. So I think it's important to provide the facility as long as it is. Yeah, I mean, it's just unfortunate that there's a bug, but it kind of suggests that we can probably think about better testing for these things.
00:24:26.150 - 00:24:33.690, Speaker A: So that's something I can circle back around to Terrence or someone on the Prism team and the other clos as well and see what we can do there.
00:24:42.480 - 00:24:56.476, Speaker B: But I guess they're still not seeing the collusion vector from the builders. Like, assuming they want to lower the base fee by underfilling blocks, giving the proposers ability to control the max gas doesn't prevent that collusion.
00:24:56.508 - 00:24:56.704, Speaker A: Right?
00:24:56.742 - 00:25:01.840, Speaker B: Like the builders can all still say, okay, we're only going to fill blocks to ten mil to lower the base fee.
00:25:02.740 - 00:25:13.590, Speaker A: It's not really about the base fee. It's more if the gas limit is like, if we want it to be max 30, they could collude to make it max 60 and then suddenly the blocks are too big for people to process.
00:25:14.680 - 00:25:27.836, Speaker C: Not only that, you could imagine that they would like to increase the max gas. So base fees lower the lower the base fee, the better it is, the more money to be had all around. And as somebody who was in the eye of the storm in a lot.
00:25:27.858 - 00:25:32.712, Speaker A: Of the gas discussions, the eventual takeaway.
00:25:32.776 - 00:26:05.268, Speaker C: From most core devs was, let's continue, let the community and the ecosystem decide on that. We always have the new option of like, okay, we hard coded limited into the protocol. Having that already at the hands of the core devs means that nobody would probably take advantage of it because if they would, it would be undone anyway. And so leaving it to the Validators and back in the day to the miners to decide how big is too big for them or how big is not too big for them to process.
00:26:05.354 - 00:26:06.724, Speaker A: They would like to make it as.
00:26:06.762 - 00:26:21.164, Speaker C: Big as possible, but not to increase the state by too much blah, blah, blah. So that's kind of like where things stand with an equilibrium. That core devs could always hard code it if needed. And that ability by itself removes most.
00:26:21.202 - 00:26:22.620, Speaker A: Of the attack vectors.
00:26:27.150 - 00:26:32.140, Speaker B: Is it not set to 30 million now? You can't put a 60 million it is not.
00:26:32.510 - 00:26:56.210, Speaker C: You could change it and it changes by increment of up to, I think, 0.1% per block. So if you're a major Validator and you have a lot of stake or nowadays, if you're a builder and you're willing to pay to win the block and for the blocks to do what you want, then you could increase it over time by 0.1 increments. 0.1% increments.
00:27:06.320 - 00:27:46.604, Speaker A: Yeah. So there's like many security reasons why it's important to have this and have it be respected. And again, I'm almost certain at least the Flashbots relay software will verify this limit. Like, it gets the preference and then it makes sure that it matches. So it's something that should be done. And then if builders are ignoring it, if anything, they should at least get the signal that the relay endpoint fails when they go to submit a block and there's a mismatch for some reason. Okay, yeah, thanks for those updates.
00:27:46.604 - 00:28:14.380, Speaker A: And yeah, this was actually an interesting one. It sounds like this is something we should look into a bit more just to harden this registration flow. So let's see here. 30 minutes left in the call, or no, when is this going to it's going to eleven. Plenty of time. Sure. So let me call this out.
00:28:14.380 - 00:29:01.900, Speaker A: I'll just put this in the chat. So there's like a draft here of this proposal. The proposal is essentially refactoring out this bit to validate payloads. When a builder goes to submit a block to a relay, generally they make sure it's valid either synchronously or asynchronously. And right now, at least with the Flashbust software, there's like a fork of guests that they use and it would be nice to have more client diversity here. And so one way to do this is to have an RPC endpoint that we add into all of the various clients to just actually validate the payload. Essentially, I put together a little proposal for how this could look.
00:29:01.900 - 00:29:39.846, Speaker A: One thing here that we came to was I essentially only bothered with supporting this payment style of end a block transaction. So, like, the idea is that the builder attaches a transaction at the very end of the block that does the payments. And I think there's some more general payment schemes you want to support, like, for example, using Coinbase to pay the proposer. So that might change some of this. But I did want to call this out. It ultimately will require support from the execution clients. So we're kind of blocked on that process and could take some time.
00:29:39.846 - 00:30:14.500, Speaker A: But I guess I'll just call this out, take a look if you're interested. And from there it'll just be working with the Els to get this supported. From conversations so far, people generally, at least, the high level idea they think makes sense with this validate payload endpoint. And then from there, we just have to figure out how to make the rest of the payment parts work. Yeah. So if there's any questions, I could take them now, otherwise we'll move on to the next thing.
00:30:16.470 - 00:30:37.750, Speaker H: So is the goal here that for relays to have different el implementations they can use for validating blocks coming in from the builders? Or is the goal for there to be different builder implementations? For example, the work that you're doing on the ref implementation for a builder?
00:30:38.090 - 00:31:31.160, Speaker A: Yeah, the first one. So this is just about this part of the Relay stack. So right now, I'm not sure how, I guess Dreamboat does this, but with the Flashbot software today, when they get a block, they basically have a builder software that you run and it's like dry run or there's some validation mode that you run that software in and then that then does all of the payload validation. But it's just a fork of gaff. And it's like a little funny because we put a lot of energy and effort into client diversity, both of the CL and El layers. And then now with Netboost today, you know, it's what, 98% of blocks are coming through this one software stack that kind of makes that pointless. So I think this is very important as sort of a values thing.
00:31:31.160 - 00:31:39.260, Speaker A: The more that we can push this effort forward, I think would be really valuable. Chris, do you want to say something?
00:31:40.190 - 00:32:21.962, Speaker C: Yeah, I think this is super valuable effort. The less custom modifications we need, the better. The more standardized APIs and client diversity we can achieve, the better. Block validation is a big one. Would be nice to switch over, switch away from any custom patches related to this. Is also work on using the new block submission of the CL clients. So sorry for switching a little bit, but Relays needed custom CL clients that were patched with custom code that validate blocks before they're getting broadcast and do an equivocation check.
00:32:21.962 - 00:33:02.230, Speaker C: Also so supported were Lighthouse and Prism that needed these custom patches that when they really send the block for propagation, it does some double checking. The CL clients now implemented a standard API. This means we wouldn't need any custom patches anymore. We can confirm that this generally works with Prism and Lighthouse and the Flashboard's. Really main branch is already switched to the new APIs. So just a heads up here. You cannot use the main branch of the Flashbots relay with the old patched CL clients.
00:33:02.230 - 00:33:12.860, Speaker C: So you should also update your CL clients. It's not yet production tested, so use at your own risk. But on the testnets, this seems to be all good.
00:33:13.870 - 00:34:19.886, Speaker E: Lucas yeah, so for that, I implemented that on Dreamboat two weeks ago. So there are another endpoints that are called B two. And in the alignment of those particular standards, I haven't seen that it's actually ready in both Prism and Lighthouse and the documentation states actually otherwise. But the problem is that SSD and other pieces of that software are not yet supported. So I wouldn't be so sure that it's actually 100% ready to be using. We are using the mixture like we are publishing two different versions of Prism and Lighthouse. I don't remember for which one, but for some you still need to use it's probably three of them that you still need to use the V one.
00:34:19.886 - 00:35:28.790, Speaker E: So the old way of block submission process and on the Lighthouse you may safely use the V Two process. However, Lighthouse is starting to return some different warnings that it wasn't returned before that would cause your relays to actually return some warnings. So keep that in mind if you plan to use that. I've seen that after the version that is stabilized and after the version that released that there are some changes being made in both Lighthouse and Prism. For this particular changes, I wouldn't be so sure that we should be using that. I would give it some time to actually use it at production. We've tested that and one of those it's not yet ready to use definitely, but it's a very nice addition and I'm totally up for using the V Two, especially that it allows you to publish directly by using SSD.
00:35:28.790 - 00:36:12.450, Speaker E: So you don't need to do the JSON Marshalling at all. You can just supply like eventually you'd be able to just supply the SSD format directly to the beacon node on the publish. Also, if you haven't seen that, it has few different kind of deepness in the test. So you can either do some pre flight check for blocks and if you're interested in some more checks, there is another level of security there and I think we all need to run the deepest one, which is an Equivocation attack checks for those particular blocks.
00:36:13.350 - 00:36:20.318, Speaker A: Cool. Yeah, that's all, thanks. Okay, cool.
00:36:20.344 - 00:36:31.500, Speaker C: This is super important input. Thanks for sharing. Maybe we can follow this up. Maybe you can write up this into an issue on Dreamboard or Mapboost or somewhere, then we might be able to.
00:36:32.350 - 00:36:33.660, Speaker A: Work on this together.
00:36:34.350 - 00:36:51.200, Speaker E: Yeah, sure, definitely. I'm just saying that I see the PR so that Prism is still working on that. That's why I'm saying that maybe it would be better to wait like a week or so to see.
00:36:53.570 - 00:36:56.080, Speaker C: Thanks for commenting. That's super valuable information.
00:37:01.290 - 00:37:12.000, Speaker I: Just chiming in here to say we value diversity in the code base of the CL client and the El client and it's a good opportunity for us to begin to value diversity in the relay software itself.
00:37:15.800 - 00:38:17.620, Speaker A: Yeah, definitely. And this is why I started with the doc that I dropped for the El because I kind of had seen some of these efforts at the CL. So I think this might take care of everything we want at the CL with this publishing point and these different broadcast modes. But yeah, I was thinking if it would be worthwhile to if we need to somehow synchronize the route of this and I suppose it doesn't really matter, but definitely for security, I think you'll find that it's better to have these additional checks. So if you are operating a relay, definitely be following this. And once there's well tested cross client support, definitely you're going to want to be using this, the V two endpoint. So that's one thing.
00:38:17.620 - 00:39:01.944, Speaker A: Let's see. Okay. Another thing I add on here was another proposal and I think some of you have seen this already. Essentially the idea is moving the validator proposals or sorry, the validator registrations on chain in some way. And I think the thing for here so some of this is the design I think is a little bit early. There's like some feedback I got and other channels that I still need to update here. I guess one question is just like does anyone feel this is high priority or that valuable? I do think ultimately there are benefits in the long run.
00:39:01.944 - 00:40:12.712, Speaker A: Part of this is understanding if we want to coordinate as a group to have this ready for Daneb, if not, not a big deal. But if we do, then that kind of puts us down a quite different path. So yeah, I don't know if anyone has had a chance. I guess I'll just summarize briefly the idea. So the idea is today when you make valid registrations, I think they're even made in the CL, then they're sent every epoch or every two epochs quite frequently and they're just sent as like ephemeral messages to the different relays via Http APIs and that works. This would say instead rather than use this sort of like off chain transport, we put them on chain, perhaps even using the Blob space of four, four, four coming up in this fork. A big thing here is it's nice to have the consensus really on who has which registration at which time because right now there's no global view and so it can lead to weird situations, especially with staking pools where you can try to play tricks as a validator.
00:40:12.712 - 00:41:05.392, Speaker A: And if there's some huge mev block then you could try to steal the opportunity yourself and just sort of quote, run with the money. And making this having a synchronized global view by putting them on chain, you then can start to implement different accountability schemes which I think is pretty important down the line. Well, yeah, I'll just leave it there again. That being said, I just kind of wanted to get a temperature check here. If this is something we're like, oh yeah, we should definitely do this ASAP, then that kind of implies doing all of work quickly. And just after some of the more recent updates on the hard fork timing, I'm not sure we have time to also squeeze this in but yeah, I was just curious to hear anyone's thoughts. Yeah.
00:41:05.392 - 00:41:08.576, Speaker A: Chris, do you want to say something? Yeah.
00:41:08.758 - 00:41:21.750, Speaker H: What is the motivation for doing this as part of the hard fork? Right, so deneb will enable doing this.
00:41:22.120 - 00:41:22.870, Speaker A: But.
00:41:25.880 - 00:41:52.136, Speaker H: Why would relay work need to be tied to that? We can let the hard fork happen and all the relays can do all the lift that they have to do in order to have a successful, smooth, hard fork for Daneb. And then after that, that capability now exists so that we could sort of design this well in a more sort of calm environment, because we're not sort of a little bit panicked about the hard fork and then roll.
00:41:52.168 - 00:42:34.856, Speaker A: That right. Yeah. No, I mean, that's a great point. My only very small counterpoint that I don't even really believe at this point is just urgency is good for driving things but I totally hear you and yeah, I think the rest of us here today we don't want a bunch of more rush work that we have to do. So yeah, I don't think at this point it's going to make sense to try to drive for any hard fork timeline and we don't really need to. The only real consideration is you could even imagine a regime where relays are taking both methods, like they're taking the existing registrations in that flow. And then you could also somehow look for more recent registrations.
00:42:34.856 - 00:43:30.620, Speaker A: And then you need some conflict resolution. And there's a question of if I look in the wrong place for a validator what happens? But yeah, that being said those are all things we can work through and yeah, I think at this point then this is an idea. If it sounds interesting to you and you have any feedback, let's chat. One thing if we don't have to rush to ship it with the hard fork is we can actually sort of quote test on mainnet which is actually nice, it's just more convenient. So that's like another small thing in that direction. I have one thing here. So during ECC some of us were there and I think we had a lot of really nice conversations.
00:43:30.620 - 00:44:40.370, Speaker A: One of them was actually some chats and builders I had and they were very keen on this idea that I think we've discussed here in the past as well around having essentially some kind of WebSocket support or like some streaming notion for the bids. Right now the relays are like maybe we won't use the word DOST but they have a huge load of calls for the bid in every slot because validators want this but also I believe builders use it to bid strategically. You can imagine you essentially have like a stream that anyone could subscribe to that's essentially here's the top bid and then you don't have to have everyone constantly hitting these endpoints. Yeah I guess the question for the crowd is do we think this is worthwhile? If so I can make a pass at again some sort of proposal and then we can kind of iterate from there. Does anyone feel it's a problem with the current regime? I guess that's a good starting point in terms of load on the relay.
00:44:41.670 - 00:45:22.978, Speaker C: Yeah, I think load on the relays is a concern, I think it's a manageable concern but it's infrastructure mostly. Like, imagine 700,000 Validators always keep the WebSocket connection open where most of them don't need it at all. Like only one at a particular point in time. If you would want to make it so only the proposer connects with WebSocket beforehand, then this would require a builder spec change and a CL change to tell mavboost soon is your turn and start connecting. So this is something to consider. I think it sounds pretty wasteful to have all proposers connect. So, like, a smart solution here would probably also include some CL changes.
00:45:22.978 - 00:45:26.180, Speaker C: Just roughing out the scope here.
00:45:29.670 - 00:45:49.160, Speaker B: I thought the point was the validator end stays the same. They still call githeader once using mevboost, but it's more that the builders would consume the WebSocket like stream. So there may only be like 20 builders that need to be hooked up to the stream. And then the proposers still only call githeader the one time.
00:45:51.290 - 00:46:22.222, Speaker A: Well, but do they only call it once? At least in general? Validators could call multiple times. Well, I don't know if they do today, but they very easily could because you could imagine, I think they're conflating. Well, there's two things here. There's just two different concerns. And so, yeah, we could do it either way. We could say, hey, this is an endpoint just for builders. I mean, one concern here in the past was essentially like transparency of this endpoint.
00:46:22.222 - 00:47:10.514, Speaker A: So if we said, oh, as a relay only builders can connect, then it's like, okay, does that lead to weird changes to market structure or have some information differential that builders have that everyone else does not have? And then even if it's like, oh, if the builders have this, but then also maybe the single proposer, you may be in the same situation. And then, yeah, I agree with Chris that we shouldn't just have a million validators just like, taking up these resources. But you could do something where it's in the middle, where you say, okay, maybe the proposal schedule that the relay has you allow, say, those, what, 64 Validators to connect? And there's some rolling window. Yeah, there's some design space here.
00:47:10.712 - 00:48:53.650, Speaker H: There are like two separate problems, right? Do we make changes that allow us to differentiate between someone who should be able to get this data or someone who's just doing it for some kind of advantage, like a builder spamming us on Get payload? I mean, I'm sorry get header. And it would require a pretty interesting change, like the ability to verify or sign somehow in order to differentiate between the two. So that's like a big change, right? If adding a WebSocket to receive the Get header data, if that improves the performance of Get header data because you already have a connection and you don't need to go through the full HTP handshake that's going to improve the performance of that. And then anybody that wants to operate efficiently in the ecosystem, including validators is going to use that like I would as a validator because I'm going to get faster payloads, I'm sorry, headers. And so it seems natural then that everyone would start to use the WebSockets because it's more efficient, faster, lower, latency to get the data. And speaking from our experience at Block native where we run a very large number of WebSockets using our Mempool API and Mempool Explorer, that is a much, much more difficult problem to manage in terms of Dos protection and just overall infrastructure management because of stateful connections versus just Http. So yes, Http is not as efficient, but it's much easier.
00:48:53.650 - 00:49:00.150, Speaker H: The worst case scenario is sort of easier to manage than the worst case scenario with WebSockets.
00:49:05.000 - 00:49:27.756, Speaker A: Yeah, it's a good point, but I do feel like at some point a relay will offer this and if it is better for the user, then it will end up with this almost centralizing vector where people will use that relay over others and then in the end, all relays will kind of ultimately have to support this feature. But yeah, definitely something to keep in mind to one more point I want.
00:49:27.778 - 00:50:04.168, Speaker C: To bring up here, I think as a super interesting topic. Thanks for bringing this up too. We should separate SIM to two use cases for the proposals and for the builders. What I do know is that relays are already collaborating with builders to improve their latencies and to provide more performance submission methods. This includes like open TCP connections, this includes gRPC, this includes SSC and GCIP submissions. Also through opentcp sockets possibly that could lead to a significant or like some performance improvement. And so some of this effort is already happening anyway.
00:50:04.168 - 00:50:18.060, Speaker C: I think maybe a question here is do we as a really community want to standardize and work together on what APIs and mechanics to provide to builders or do we just try out different things and see if they converge?
00:50:22.340 - 00:51:51.500, Speaker A: Yeah, it's an important question. I mean, I think to the extent that we have power as community here, we can bias towards things that we think are good, if we can all agree on what that means. But yeah, otherwise definitely we want to support experimentation. This is kind of the point of the builder specs and really specs and that's also a good sort of jumping off point for discussing these things. Yeah, I don't know if there are any other views on the call, perhaps not right now. Let's see, there was one more thing I have been wondering, and perhaps I'll use this time to at least revisit the topic. During the time of the low carb crusader attacks, I think in various channels, some of us have discussed basically changing the builder API so that the proposer actually never gets the block and it's now a responsibility of the relay to disseminate the full signed block and that kind of just clearly eliminates these unbundling possibilities.
00:51:51.500 - 00:52:53.564, Speaker A: I don't know if anyone yeah, I'll open it there. Does anyone feel strongly either way about this? There's like the one side where, yeah, you would just eliminate unbundling. The other side of the coin is that it's very much putting essentially the entire block flow of the whole network in the hands of, again, what, seven actors, which feels weird and again takes autonomy away from the validator, even if only marginally. But yeah, I think it's an idea worth exploring. Right. There's a question in the chat, do relays want more responsibility? And that's like another consideration here as well, is that, yeah, you'd kind of have even more to do and there might even be more pressure on you to not mess up and the consequences could be even greater. Something to ponder.
00:52:53.692 - 00:53:34.300, Speaker B: It's worth mentioning that we already have a 1 second delay in there. So functionally, if the proposer calls get payload past like, T equals 2.5 or T equals three, the relay still is the sole entity able to get that block published on time. Because with the 1 second delay and then the payload being sent to the proposer and then the proposer gossiping it, if they're late at all, they're going to get reorbed out. So it kind of already feels like the relay has that responsibility. It's also worth mentioning that the low carb crusader is like reloading they're deploying new validators.
00:53:34.800 - 00:53:44.876, Speaker A: Right. Anyway, sorry, the 1 second delay, you mean in between? Like, if I call Git payload, it waits 1 second before serving the response.
00:53:44.988 - 00:54:00.630, Speaker B: So it goes through all the checks and then it tries to publish the block through the beacon node. If that works, then it waits one full second before sending the block back to the at least that's what we implemented in the flashblood Three relate pro.
00:54:03.260 - 00:54:55.850, Speaker E: Everyone done exactly the same. However, that's pretty bold assumption about a gossip layer performance and ability to actually transmit this block over the network. And as we were talking with Prism and other consensus player clients, it's not that easy. And like, this 1 second is a fairly random number, so it may not be enough at some point. So as much as I am not sure that we should go in that path right now, that we should all just publish blocks and never return that to the proposer, I'm also not sure that 1 second is a good idea for that particular one on the very long run.
00:54:58.380 - 00:55:37.590, Speaker A: Yeah, I think the 1 second was more of like sort of hot fix. Like, let's make sure that this isn't going to be a disaster while the attack was ongoing. And yeah, it could be the case that the number could be tuned for. I mean, it doesn't sound like there's super strong consensus that we need to change this API today and perhaps we'll just keep an eye on these different latencies. I mean, one thing we can't say about the 1 second is that it seems to be working right because that's what I think most of the relays, if not all of them run and the system works.
00:55:40.200 - 00:55:58.940, Speaker H: Is there any opinion from the Ethereum Foundation on this? Because it just seems pretty dramatic to say that we're just going to give up entirely on decentralization of Block proposal and we're just going to go full on centralization to the relay community.
00:55:59.090 - 00:56:50.156, Speaker A: It seems a rather I don't think that's what this is signaling. So you can still as a validator always build locally. I think this is like the argument would be okay given almost regardless of adoption, although the adoption of that boost does motivate sort of the gravity of the security concerns. But given the security of the system just on its own, this could make it more secure. Yeah, I don't know if we're going to get like a EF official statement just because there are many different views at the like. Personally, I do think it feels very wrong to me to take this degree of freedom away from the validators. So when I first heard the idea I was like no, that's not probably the right direction, but it does really cleanly solve the unbundling attack.
00:56:50.156 - 00:57:01.010, Speaker A: And to the extent that we also want boost to have integrity so that this PBS construction is used and trusted, then that could be an argument for this change.
00:57:03.220 - 00:58:25.456, Speaker I: Yeah, here's my view fundamentally from the PO, by the way, Matt, from Blockman of your POV from the perspective of the Validator is they really want the relay network to operate like a utility. They don't really care where the oil comes out of the ground, how it gets moved across an ocean, which refining planet goes to, how the electricity gets to the house. All they want to do is turn on the lights and have lights go on and we as relay operators are increasingly incentivized to operate as a utility where we back each other up and things like that. And so this is really a question of do we put another task on the relay utility in the interest of increasing security. And I understand some of the philosophical things here, but let's be honest again, this is one of these things where I keep talking about this, which is the relays already do much of the heavy lifting and another piece of heavy lifting doesn't really change the state of affairs from an external perspective. And two, at the end of the day the relays doing their job is critical to the orderly operation of the network and that's going to be true for the foreseeable future. I think one of the other questions about this is does it further enshrine the relays? And my comment is the relays are already pretty damn enshrined.
00:58:25.456 - 00:58:56.390, Speaker I: So if we were to view the relay network as a utility that needs to operate as utility, I think this is a very fair question, but insofar as we try to play it both ways like we are right now, it feels very uncomfortable. So my view is anything we can do to secure the network and make it more reliable is a really good thing, as long as it's something that people opt into, which is what's happening right now. So, anyways, food for.
00:58:58.360 - 00:59:00.660, Speaker A: Yeah. Yeah. Thanks for adding that perspective.
00:59:01.640 - 00:59:03.408, Speaker C: Wait, Matt, what do you mean by.
00:59:03.434 - 00:59:06.170, Speaker A: Playing it both ways right now?
00:59:08.060 - 00:59:50.692, Speaker I: That we treat the relays as individuals that are, quote unquote, competing with each other, but there's no economic you guys know this for me and that we back each other up, right? Really, what the network wants, what the validators want, is a monolithic service that they just address. Now, maybe they opt into certain parts of it because they care about these values and those values, but at the end of the day, there's this fundamental disparity between having it both ways is how the network views the relays and how the network wants to interface with the relays. By network, I mean the validators. Again, this is where miss slot insurance or when we have to reimburse for miss slots and things like that, like do your job, and if you don't do your job, pay us back.
00:59:50.746 - 00:59:51.444, Speaker A: Right?
00:59:51.642 - 01:00:55.844, Speaker I: And how we as the relay operators, the small set of actors that carry the network on our shoulders, quite literally view ourselves. And I think, and again, I don't want to derail this conversation, but that at least a majority of the current relays recognize that we have more in common than we have in opposition to each other. And the point of competition is kind of pointless because what are we competing for but a leaderboard on relay scan, which is easily gamed. So my view is we should acknowledge the utility nature of what we do. We should acknowledge that we are all contributing to a consistent service and we should approach it as such. And anyways, it's my POV, having talked to a lot of validators, having talked to a lot of relay operators, having spent a lot of time in these conversations at, you know, we want to encourage, again, more participation. We want to encourage more diversity.
01:00:55.844 - 01:01:03.820, Speaker I: We want more members of our supply chain, not fewer. So anyways, I'll stop. Does that answer your question? Uri.
01:01:06.320 - 01:01:06.972, Speaker A: It does.
01:01:07.026 - 01:01:10.448, Speaker C: Thanks. I was kind of like I wasn't sure, and I agree with you for the record.
01:01:10.534 - 01:01:11.410, Speaker A: But yes.
01:01:16.070 - 01:01:41.786, Speaker C: Also on the previous point about the Get header, and it seems to be also relevant there to the previous topic that we discussed about, okay, the burden of being hammered by all the builders. And we're kind of, well, let's open it up for everybody because we want to allow for transparency, et cetera. But kind of like everything else burden falls on us. Edward is like, okay, fine, we want transparency as a service provider, let's make.
01:01:41.808 - 01:01:42.700, Speaker A: The service.
01:01:44.750 - 01:01:51.390, Speaker C: Or monolithic service and let's make it available for everybody, so everybody could see. But yes, there is still this mismatch.
01:01:52.050 - 01:02:09.890, Speaker A: So generally agree with you. Okay, yeah, thanks for those perspectives. That does, I think, probably tee us up for this next point because I know Tina is here. I think she wanted to say some words. Chris or Tina? Did you guys want to chime?
01:02:14.730 - 01:02:15.800, Speaker F: Hello, friends.
01:02:16.330 - 01:02:17.080, Speaker A: Hello.
01:02:20.010 - 01:02:21.480, Speaker F: Can you guys hear me?
01:02:22.890 - 01:02:23.542, Speaker A: I can.
01:02:23.596 - 01:02:24.600, Speaker C: Loud and clear.
01:02:25.370 - 01:03:09.602, Speaker F: Amazing. Awesome. Welcome back. Stokes. We've dearly missed you. But well, in the past couple of weeks, I know there's a lot of actual movement on the R D front, so which is super exciting. At the same time, since our last metboost community call and our gathering in Paris, I basically pushed forward quite a bit and have communicated with many in this current call about the next steps on PBS Guild or PBS Fund or PBS Foundation.
01:03:09.602 - 01:04:03.778, Speaker F: There are many names floating around and I think it's at a stage where we have a clear timeline and a next step. So happy to share a little bit with everyone. I may have just also posted this V three of the proposal for PBS Guild on the collective Flashbust net, but I'm happy to share the link. Hopefully this time is public and feel free to comment. I tried my best to incorporate. I think there was like 50 to 70 comments across the page. Oh, no forum setting.
01:04:03.778 - 01:05:37.898, Speaker F: My apologies. Yeah, that will get fixed, but high level TLDR. Sorry if I'm repeating myself a little bit for those who may have less context on this. So basically, I think when we speak about relay economic viability and we know this is an urgent problem, at the same time it's a very, very hard problem to solve in a sustainable way. And the irony is sustainability is in the name of the problem that we're trying to solve. And so while in Paris, I think I have felt the need and having met everyone, I truly have felt that there's something that we got to be able to do to move things forward. But what is it that doesn't basically put us into rushing into a position that we will regret or essentially that could have irreversible consequences for our ecosystem? So in reaction, basically, in the past two weeks, I think there is a lot of excitement and momentum that gather around the community about wanting to contribute, to help out, whether it's the relays or solving the relay.
01:05:37.898 - 01:06:59.662, Speaker F: Economic. Sustainability problems or the harder trade off space along the design space of PBS R D. So basically, PBS Guild is this vehicle that's a Grants program should start out simple and lightweight and start out with a minimum of $1 million in grants funding as a threshold to kick it off and have 50% of the initial funding that can be set aside to ensure the independent relays as well as research and data relays that can actually help us understand and be more accountable to the ecosystem as a whole. So that part I would say is almost there from legal set up. Also, in terms of securing the funding, I would say we're probably 1.5 weeks.
01:06:59.716 - 01:07:00.320, Speaker A: Away.
01:07:02.130 - 01:09:08.874, Speaker F: And the other half of the initial funding for this grants giving vehicle is set aside for some of the backlog but thorny issues that we probably want to essentially incentivize the researchers who have more time and bandwidth on their hands to tackle. So in the proposal, I have updated a new list based on the previous two weeks feedback that I have collected from those within the community who have seen and commented on the proposal as a suggested list of research, grant directions. And all in all, putting everything together. I want to say that I feel like I can finally take a deep breath and actually say that I think at least for the next half year, I think we will be able to support at least five relays. Within the ecosystem and that hopefully can get us more time and also just more mind share to think about how to actually solve it and hack on some solutions together. Yeah, I think that's it. If you're interested in any of the more boring operational details on how this is going to be set up, I'm very happy to share, to the best of my knowledge, in terms of how this vehicle could work and also clarify questions I think I have received also in the past two weeks as well.
01:09:08.874 - 01:09:59.320, Speaker F: But it's also explained in the latest proposal in terms of how to structure and how we think about governance and what is Flashpot's role in this. But happy to answer any questions or share any of the points. I thought I wanted to be blunt and say the most important things is that I think timeline wise, end of this month will be a good starting point and I think it's likely that we can aim for the grants to be ready to deploy by the one year anniversary of the merge. There's a lot of work to do, so let's go.
01:10:04.040 - 01:10:25.940, Speaker C: Just briefly looking into it, we're talking about up to five relays which are not integrated with any builder or relay. I assume it's not integrated with any builder or searcher. And when you say advancing infrastructure, resiliency and neutrality, are we talking about like, okay ofex transaction censorship?
01:10:26.100 - 01:10:29.596, Speaker A: Get a book, we're not in there.
01:10:29.618 - 01:10:39.760, Speaker C: Anyway because we run a block builder. But are this limited still to only those who do not censor OFAC transaction?
01:10:41.060 - 01:11:54.096, Speaker F: So I think this is a really good and important point I definitely agree with. I think there are some comments and feedback from the previous version that we do not want to politicize unnecessarily. I think there's a lot of problems to solve and I think we're all in it together. Credible neutrality entails us not coercing each other to make decisions that they are not comfortable with and. We as an ecosystem can only do our best to diversify geographically as well as incentivize people who have different interpretations. That said, I think that this is something that is not a hard line, but it will be a strong discretion in the sense of like it will be very difficult to actually this is a public goods funding and decentralization. While we're all working towards decentralization, we should also do our best operationally to maintain the decentralization of ethereum.
01:11:54.096 - 01:13:04.796, Speaker F: I think when we put out a grant, there is a mission there. So if we can choose the ones, the relays who are genuinely and naturally in the position to do so, I think it will be really for the best. I don't know if everyone here has checked the recent OFAC kind of dashboards. It's not looking very so I think there is something that, from my personal perspective as well as from Flashbots, we're doing our best to dispel Misinformation and I think that especially the recent inclusion list proposal and we should really make sure that it can have the resource and mindshare to focus on it as well as we should involve some of the people within the policy scene to help explain and help us get out of this current quackmire soon.
01:13:04.978 - 01:13:35.250, Speaker A: Yeah, cool. Very exciting. Thank you for all the work you put in this, Tina. The proposal is pretty long, so I don't know, people probably want some time to digest, but yeah, very exciting to see this and to take the next step forward.
01:13:36.500 - 01:15:10.144, Speaker F: Yeah. So related to this? Well, I guess it's not directly related, but I thought the timing will be really nice. SPC is coming up. One of the reasons I really wanted to hopefully get everything set up before SBC Mev workshop is also to be able to I know some of you may plan on going there and also there are quite a few pretty plugged in academia friends who will be also speaking at a muu workshop there. So I think it'll be really good to either do like a researchathon where we actually this time have something more practical. Like I think Terence has some idea in terms of wanting to move forward, accelerate the progress of the prototyping and I think there's a couple problems that we also identified and also I think maybe we can do a workshop on the trade offs of the various essentially cr designs. So I don't know if this is something that anyone's of interest and I think this can be a good opportunity and we can basically refine further what problem we actually really need to solve and who can actually commit to solving it.
01:15:10.144 - 01:15:23.680, Speaker F: Like form the core, be the champion of these particular problems that may be more or less on the backlog of the main researchers from the EF.
01:15:28.080 - 01:15:30.844, Speaker I: I'll be at SPC and looking forward to having that conversation.
01:15:30.892 - 01:17:05.070, Speaker F: That's for yes, yes. Data transparency is another dimension. I have a ton to chat with you, Matt, and anyone who is interested on that, because that's another dimension of PBS Guilds, I think, principle or that. And on that front, there's actually some groundwork I'm starting to do communicating with the best data scientists that I can find who's deep in the PBS land to unfog the map, to map out, I would say, an extended order flow supply map and also to hone in on and also to solve some of the data sharing problem. And data essentially public goods data relay is one of the things that I recently added on the latest version of the PBS Guild proposal. So happy to also move that initiative forward but there's too much going on on that proposal so please comment or just leave a message. Happy to follow up and ping me on Telegram if you're interested to do a researchathon or a workshop on any of the topic I mentioned or something that you want to bring up.
01:17:10.370 - 01:17:18.900, Speaker A: Cool. Yeah, I'll be SPC. So looking forward to see you all there and yeah, if anyone is around and wants to join us, reach out.
01:17:20.970 - 01:17:30.310, Speaker C: Tina, can I just going briefly over that. What's the high level TLDR vehicle of who decides who gets the funding?
01:17:31.870 - 01:17:33.034, Speaker F: Great question.
01:17:33.232 - 01:17:35.500, Speaker C: Who's in charge of where the money goes?
01:17:36.030 - 01:18:57.778, Speaker F: Yeah so high level setup, it's a caveman memberless foundation that's essentially the legal setup. We did basically a bunch of research and just luckily I think this is the playbook that Protocol Guild also have explored quite far. So it become quite easy for and also I'm relatively familiar with the setup and in fact it's really friendly for Dows as well as has flexibility. So what you see on paper basically is like there will be a non executive independent director who's probably going to be a good accountant. Hopefully they can count the money correctly in addition to operating a multi SIG. And then there are two paths in terms of best practice when it comes to these foundation setup is one is a council base which is committee of some sort and the other is to delegate it to quote unquote, a community of decision makers. So this latter is very friendly for Dows and the former is more suitable for something that is still highly uncertain and exploratory and kind of needs to put in the early work which is the path that we're most likely to take.
01:18:57.778 - 01:20:03.100, Speaker F: So it's actually quite convenient because we need a grant committee anyways so the council can be the grant council. How I'm taking the current approach is like a faced approach. So starting when we announce hopefully, hopefully we make the timeline of September 14, that'll be a good memorable day and going forward for six months, that will be the pilot phase. And during this pilot phase I think that we want to have three to five grants reviewers basically who sit on the council. I think what you see in the proposal is clearly not very fleshed out in terms of the heart criteria. And I think it's also not in my place to actually set in, like I would say, excruciating detail on how the grants should be done. So I think one of the first things that grants committee need to do is to actually flesh it out or reduce or adjust it as needed.
01:20:03.100 - 01:21:09.582, Speaker F: And then I think at this current stage, I kind of, in my latest proposal, provide an explanation because there's a lot of discussion around PBS Guild versus PBS fund. But in my mind, ideally, if we can move towards a guild but the first step is to actually figure out who else from Stokes and Neuter are doing the work on PBS. Right? So I would say this is the first step, in fact, mapping out the key research areas. We should be able to know within the ecosystem who is doing what work on. So the first pilot phase is to find the high priority ones. The high priority problems may not be the highest priority on the Epps roadmap, but it may be something that's more ecosystem oriented because that's the whole point, is to have an ecosystem grants vehicle. So that's I think, the gist of it.
01:21:09.582 - 01:21:32.680, Speaker F: And I think we should evaluate at the end of six months and in terms of whether to scale up or down the effort and we can go from there. And during the whole time, I think the funding just like protocol guild can continue to stream in and I think we will just keep a door open and see how it goes.
01:21:36.250 - 01:21:37.800, Speaker A: Thanks, appreciate that.
01:21:39.370 - 01:21:40.310, Speaker F: Anytime.
01:21:49.270 - 01:22:09.640, Speaker A: Cool. I think that might be a good stopping point. We have a few minutes. If anyone has any other questions or any other things they'd like to discuss. But otherwise, thank you again, Tina. And yeah, I think we're all excited to move forward and figure know how to make this work.
01:22:13.770 - 01:22:18.310, Speaker F: Thank you everyone. Have a good evening.
01:22:21.730 - 01:22:26.690, Speaker A: Okay, yeah, then I'll call that. Thanks everyone. Bye.

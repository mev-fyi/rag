00:00:03.680 - 00:00:23.170, Speaker A: Okay, great. So, yeah. Everyone, this is Mev community call number ten. Let me grab the agenda here. We have quite a few things to get through, so let's just hop in. So first up, I did want to quickly call out an upcoming map boost release. This is version 1.8.
00:00:23.170 - 00:00:42.430, Speaker A: There's an issue here and. Yeah, I think there's a few. It looks like it's mainly cleanups and things. I don't know if we have a sense of timelines yet. I don't know. Chris, if you have any thoughts on that. Yeah, sure.
00:00:42.430 - 00:01:31.300, Speaker A: We tagged the release candidate with all the expected changes two days ago and asked a few sticking pools to help us test this on testnets. Looks like everything is good. It looks like either later this week or beginning of next week would be the proper release. It's mostly minor changes. I think it's mostly cleanups and some refactoring, some simplifications. The only notoriety change is adding the request start time to the request header so realists can get a sense of when the rigos have started and how long it has been in flight. Let me link the pr here.
00:01:31.300 - 00:01:58.850, Speaker A: This is from Blocksroad, contributed this feature and otherwise I think we're looking good. So far, no expected further changes and proper release end of this week or beginning of next. Okay, cool. So, yeah. Anyone listening, be on the lookout. Yeah, and thanks to Chris and everyone else who is helping with the release there. Cool.
00:01:58.850 - 00:02:09.398, Speaker A: If there's nothing else there. Next up, I think Shay wanted to talk about tboost. I think I'll just turn it over to her. Yeah. There you are.
00:02:09.574 - 00:02:49.610, Speaker B: Yeah. Hey, everybody. Okay, so let's talk about the relay for a bit, because that's really what ta boost is about. I think that at a high level, there are probably two things that most of us hear and in the broader PBS community can probably agree on. Which is like, first of all, relays are obviously essential to PBS today. Make it possible to facilitate a fair exchange between builders and validators. But at the same time, one thing I think also many of us have struggled with is that we really wish we did not need centralized relays to perform such an important function.
00:02:49.610 - 00:03:29.162, Speaker B: And I think, I'm not saying anything new here when I mentioned that for basically two years we have been searching for a different way. So what I wanted to talk about with Teboost is a promising design that we think could be maybe a first step to solve this problem. Not the entire solution, but an interesting way to tackle part of it. So with that in mind, I might just share my screen so you can. I'll kind of just scroll briefly through the kind of post here on the flashbots forum. Can alex. Okay, I see a thumbs up.
00:03:29.162 - 00:03:30.274, Speaker B: Looks like people can see this.
00:03:30.322 - 00:03:32.082, Speaker A: Cool. Yeah, I see the screen. Yeah.
00:03:32.266 - 00:04:35.288, Speaker B: Okay, great. So essentially, Teuboost is a realization we had at flashbots a handful of months ago, that you actually don't need another party to revalidate a block, if that block was created in a trusted execution environment. And actually, it's not just that you don't need to do this, but it might actually be more secure and more private than if we rely on another centralized party, like a relay. And that's like a fairly bold claim. So I will not go through all the details here, but I just wanted to kind of briefly explain what the design is, why we think it can provide those types of guarantees, and also what it isn't. And I especially wanted to kind of focus on the last part, the open questions here, because personally, I think there's some very cool research questions that we'd love to work with people on, maybe see some grants for, make prototypes together, because this stuff is actually quite fun. There are some really gnarly questions here that I personally would be very excited to dig into with people at a high level.
00:04:35.288 - 00:05:33.600, Speaker B: What is te boost? I will jump here. I think of basically as having three pieces, multiplexing, so facilitating good counterparty discovery, keeping people safe from dos and that type of thing, the auction itself. So sharing bids with validators in a way that ensures that bids are valid, but also preserves privacy for builders, and then data availability, making sure validators get the payload. To be clear, tee boost is really about the auction piece. So basically what we're interested in is this core insight that Tees trusted execution environments could provide the privacy and integrity guarantees that we need to run a good auction. And this might actually be enough, because you don't need a relay. So I said, you get, you get two things and I'll explain what they are.
00:05:33.600 - 00:06:28.902, Speaker B: So first you get integrity, which is that you can basically get an attestation from a trusted execution environment, which confirms exactly what code was running in a TE. You can look it up and audit it, confirm it produces valid blocks, and, you know, also that tees will prevent the builders from tampering with this. So you can do this once, or we're suggesting kind of infrequently at the start, save every epoch, you can confirm what code is being run by a certain builder in a tee. And then you know that like every block bid header produced is good, it's a valid block. And then what we've suggested here is if you, you have this guarantee, validator can actually, if they're comfortable, connect directly to these tee builders. They don't need a relay to provide them that like integrity guarantee. Again, because they kind of know that the Te is producing validity blocks.
00:06:28.902 - 00:07:19.316, Speaker B: And again, I'm going through this at a high level. I'm sure if people have questions we can dive into the details later. But that's just like one of the really core principles of the design. The other principle that's quite interesting here, privacy. So tes are designed to prevent anyone from extracting data from them, so not even the operator and let alone a third party like the relay. So basically what this means is we could have a design where you don't need a relay to validate blocks, and you also don't need a relay to preserve privacy for builders. And I think the interesting consequence here is that this would let you build an auction that is more secure than Mev boost, even if the tes break, which is called out here, because I think a lot of people have this question.
00:07:19.316 - 00:08:19.422, Speaker B: Um, basically blocks aren't shared in the clear with anybody in teboost because we don't need this relay to validate them, so we don't actually have to pass the blocks to a separate third party. And that's really handy. So even if you know, the Te's privacy is compromised, we're just in the status quo today, where builders can already see all the contents of blocks. So privacy actually is a bit better. And also I would argue that while anything can have a bug in it, what's very interesting about relying on Tes rather than centralized relays is that it's a lot harder to break a tee's integrity because this is hardware. So you need the hardware manufacturer to collude with, say, the cloud provider who's hosting the tee, which is a lot more steps and a lot more parties that have different incentives than just one party running a relay today. There are lots of, I think, obvious benefits of something like this.
00:08:19.422 - 00:09:08.327, Speaker B: There's less centralization if you don't have a relay, and also there's potentially faster and more valuable blocks, because if you skip validation or not only do you skip validation, you don't have that extra hop to a relay at all. I've gone through this really quickly because I'm assuming some people have already read it, and I don't want to bore you with all the details, but I thought at a high level just be interesting to kind of call this out, explain why we're excited about it. And what I wanted to highlight at the kind of, the very end here is what happens next. So I think this is a pretty ambitious project. It definitely needs more work to bring it to life. And so I just wanted to prompt a few things that we are kind of excited about looking at next. So as I mentioned briefly earlier, we're really concerned with this like auction phase.
00:09:08.327 - 00:09:43.050, Speaker B: That's what Teboost is trying to improve. But there are obviously other things that relays provide inboost. So one thing obviously is multiplexing. If you don't have a relay, how do you make it easy for validators and builders to discover each other? How do you also prevent some validators don't want to leak their ips, people don't want to get dosed. How do you work around those concerns? Maybe there's a gossip layer in between. Maybe there's a lightweight aggregator service. We've thought about a few options here, but I think this is something that would be really interesting if people want to take a closer look at.
00:09:43.050 - 00:10:08.542, Speaker B: Another thing is data availability. So obviously right now relays do this. It's really important. How do we provide data availability if we don't have a relay in the loop? And I think this is another interesting question. We've thought about two approaches here. There might be others. One is using just a separate DA layer and another is actually using tees.
00:10:08.542 - 00:10:55.040, Speaker B: You could potentially have an escrow, um, that, you know, stores the block and make sure it releases it only when it gets a valid header from the relay or, sorry, the validator. And the final thing I would just say here is, is also, you know, prototyping this, this like auction piece. We've, we've put out like a somewhat detailed spec in this post. I think it'd be super interesting to test the core components of it, especially the way we're thinking about te proofs. Okay, so that was the sort of lightning fast version of te boost. I know I glossed over a lot of the details, but I just wanted to give you a taste of like what's happening here, why we're excited about it, what the areas for research are, and I'm happy to open it up also for questions if there's particular parts that would be useful for this group to dive in. But I figure you're already fairly up to speed on the details.
00:10:59.100 - 00:11:24.830, Speaker A: Cool, thanks. Yeah, no, this is super cool research. I have one question. So it's around, I guess, the mechanics of how a Ydezenhe validator proposer would know that a builder is actually using the te for building. Because it sounds like if you have the setup where, you know, let's say the builder test wants an epoch that they're using, you know, a te to produce the block. How do you know then when you later call them that they're still using the te?
00:11:25.210 - 00:12:14.052, Speaker B: Yeah, it's a great question. So we originally, the original design here was actually that they would confirm the attestation every time they got a block. But we realized that Washington, that would add a ton of latency to the hot path. So we have this sort of two part design right now, and it's in the te proove section here where basically first you would attest, you get this attestation that proves that a certain builder is running certain software. But then every time the builder submits a block, they could pass with it in much simpler proof. And this is one way we have thought about doing this. There might be another one that's better, but one way we're working model right now is that you could actually have a special key in the te and they just sign the bid with this key.
00:12:14.052 - 00:12:32.280, Speaker B: So you kind of know it's coming from somebody who's generated the key that, you know, you can only be generating if you run a tested or a Te that you have the attestation for. So we have this like two step process right now. There might be other ways here. We just thought this was actually a lot faster than having to re verify those attestations every time.
00:12:35.350 - 00:12:47.330, Speaker A: Gotcha. Yeah, that's cool. Another question that I also had that was in the chat, just generally, do you have a sense of performance overhead or maybe we haven't gotten to like a prototyping stage yet.
00:12:47.870 - 00:13:24.720, Speaker B: Yeah, so this is in the design phase, I think. It's not in the prototyping phase yet. We're really conscious of latency, which is why we're working on things like, okay, how do we make the, the recalling the proof process as fast as possible? But that's something that I think, honestly, we need a lot more data on when it comes to the actual te latency of building blocks in tes. We do have data on this. It is fast enough in performance. We've been running builders and tes for months at this point at flashbots, and they look pretty good. But it's all these auxiliary elements.
00:13:24.720 - 00:13:49.080, Speaker B: So the overhead, especially when you try to add DA or do multiplexing in a way that doesn't use a relay, those are things that are open, research questions. And I think, yeah, we need to collect a lot more information to make smart choices with those designs, which is also why we didn't really want to prescribe one upfront because I think this is something, they're also very very smart people who we'd love to work with to help us make the right choices there.
00:13:51.990 - 00:14:52.800, Speaker A: Cool. Yeah, no, I mean, I think, I think this is super cool. Assuming best case and that it all works, then it does seem to be like a nice way to get rid of the relay, which as you called out would solve many problems. Many of us on this call have. So that would be super cool, I guess just from my perspective. And this is probably all different can of worms, but just generally the use of like Tes and SGX and things, you know, there are known issues with SGX at least I think there's a website like SGX fail or something. I saw a talk at some point that was like, I think looking at the secret network and basically something that scared me a bit, there was just like the, at least what they were claiming is that in practice if there's like a bug in SGX, then it takes like a year plus to patch, basically because you have to like patch hardware and there's like a whole huge like you know, physical and software pipeline that has to be updated.
00:14:52.800 - 00:15:03.800, Speaker A: I don't know if you've thought any about that and like maybe mitigations or things you could do to still go with this design but mitigate those downsides.
00:15:04.500 - 00:15:48.370, Speaker B: Yeah, I think it's a great question and there's obviously lots of, there's lots of good arguments for why tes don't work in certain use cases. Right. Um, and I think we have thought about this kind of like I mentioned for the context of like mevboost and using Tes to replace the relay. One meta point that I would make is that it is at least better than what we have today. Even if you lose the privacy guarantees or um, you know, the integrity guarantees are likely to be harder to break than, than breaking like a relay or something today. So um, at a minimum we think it's like better than the status quo. Is it perfect? No, um, but it's a step forward.
00:15:48.370 - 00:16:57.624, Speaker B: And I think the, the other, you know, kind of if you want to get into like specific concerns with um, with Tes, I think one common reason why there have been concerns like this is the way people are using them. So we want to kind of be you know, rotating the, the, the keys that are used for these, these proofs once in epoch, other people have used tees for long term storage. And so obviously if you break a tee, the implications of this depend on okay, what's the time horizon? You're relying on it for security. What's the nature of the use case? What's the fallback that you have? So there's a lot more detail here that we can maybe get into at some point, but from the perspective of using these in Movboost, so far, our perspective is that hey, this is better than what we've got today. And we're kind of using them in a way that's much safer than other ways people have used Tes in the past because we're only really relying on them for this short runtime. Privacy and integrity. We can rotate keys, we can obviously have mitigations if there's an exploit that gets revealed.
00:16:57.624 - 00:17:08.970, Speaker B: So it should make them a lot safer, not perfect, but definitely better than other ways tes have been used and also better hopefully than the status quo and boost where everybody just sees everything and trusts each other.
00:17:09.870 - 00:17:48.140, Speaker A: Right? Yeah, I feel like on this type of design, like people think about multi proofs, you know, for example having like TD proof, but also like some kind of zero knowledge proof or like some like cryptographic guarantee. I don't think it quite works here because I think there's going to be latency and performance issues that we run into. But yeah, it's definitely a very interesting research problem. Anyone else? Questions they'd like to raise maybe small ad, really cool to see. I'm also very curious about it. Shay, you already asked me also for comments.
00:17:48.640 - 00:17:49.336, Speaker C: I'll do that soon.
00:17:49.368 - 00:18:43.976, Speaker A: I have a ton of questions now about the block validation part. I think that's the tricky part here. Yeah, I first have a lot of questions and then hopefully I can help a little bit and see if, you know, there's good solutions to that. Another path forward is to basically not require blocks to have the post date route in them, basically delay the post date route to the next slot. And this has all sorts of advantages. One is that relays don't need to do the block validation. Optimistic relaying becomes trivial, but it also lowers the barrier to entry, to becoming a builder because now a big part of the computer, the latency of building is just calculating the state route which would no longer be in the critical path.
00:18:43.976 - 00:19:09.610, Speaker A: And it will also make a testing much more lightweight. So the attesters, they need to download the block and do minimal validity checks, but they don't need to recompute the state route in the critical path. So if anyone wants to help write an EIP for that, that could be a big win, I guess.
00:19:14.320 - 00:19:20.460, Speaker B: In this model, would builders still have to hop? Like, would there still be that extra hop through a relay?
00:19:25.840 - 00:20:41.880, Speaker A: Well, for the parts that. Yeah, the other parts of the data availability and the multiplexing, as you put it. But the part that you're trying to address here, the auction part, and validity, that would no longer need either SGX or relay. I mean, one other comment on this is like, you know, it sounds like you're going for this very ambitious thing where you want to completely get rid of the relays, but as you pointed out, like the thing that the SGX is good at is specifically the fully deterministic computation. And so what about just having this intermediate step where the relays only see encrypted blocks, so there isn't a data valid problem, and they know for sure that the block is valid. So effectively it's optimistic relaying out of the box. So you don't need to have builders post collateral.
00:20:41.880 - 00:20:52.960, Speaker A: As you said, it's a strict improvement over, over the status quo other than the latency overhead.
00:20:54.340 - 00:21:56.382, Speaker B: Yeah, I think so. Also, as I think hopefully is clear, we haven't solved things like, like data availability or multiplexing yet. And so I think one like baby step to test something like this out would be to keep relays around for those steps and see what we can do to remove, like reduce the latency and reduce the requirement for relays to help with validation and that type of thing. So yeah, I think keeping relays in the loop at the start is probably the most like tenable path to test this thing out. And I wouldn't expect we want to like remove them all entirely. Like start with maybe the auction piece piece, see if we can reduce their dependencies there, and then move on. I do think it is desirable to not even have to go through the relay, like, not even to have to make that networking hop, which is one reason I might prefer something like the full t boost proposal to sending stuff to a relay, even if it's encrypted, just because you still have to go through a relay.
00:21:56.382 - 00:22:01.960, Speaker B: But yeah, I think anything in this direction is, you know, a good first step to test out.
00:22:05.060 - 00:23:02.276, Speaker A: So there are some advantages of going through like relay from a networking perspective, and one of them is that it significantly reduces the barrier to entry to becoming a builder. And the reason is, as a builder, you basically need two instances. You need a Europe instance for the european relays, and you need a us instance for the us relays. But if we have kind of a more direct connection, kind of the end game is that builders collocate whenever there's a significant amount of validators. And so we could end up with, I know, 20 different geographies where it makes sense to collocate as opposed to just two. And so now your cloud build has increased ten x in this world. The other thing is that relays put in significant efforts to optimize their networking stack and whatnot.
00:23:02.276 - 00:23:27.290, Speaker A: And so this would be effort that every single builder would have to do, as opposed to relying on the relays to do on their behalf. So again, let's assume that there's 20 builders that all need to do this work, as opposed to whatever it is, like four or five relays that have to do this work.
00:23:29.310 - 00:24:02.280, Speaker B: Yeah, I think it depends how easy you make it to operate a builder and what it even means to operate a builder in this context. If we have a bunch of te builders that are kind of part of a network, maybe it's actually much simpler than having to spin up your instances. Maybe you can just kind of start participating in this network. But yeah, I don't know. I think somebody's going to have to do this work. This co location piece. It's just naturally incentivized by the network.
00:24:02.280 - 00:24:17.560, Speaker B: And so whether we have a trusted third party who's responsible for doing this, or we allow other people to take on this role, I think it's just more a question of where in the network that happens. And I think there are pros and cons to each one, to relying on somebody else to handle colocation too.
00:24:22.380 - 00:24:30.840, Speaker A: Yeah, that makes sense. Is there a place we should go to continue the discussion?
00:24:31.940 - 00:24:51.550, Speaker B: Yeah, so obviously the post on the forum would love to hear people's thoughts. You also feel. Feel free if you don't want to talk about it publicly yet, you can just send me messages. But yeah, the forum is a good place. Flashbots, discord also we have that. I think there's a relays channel. If people want to talk in there, sometimes it's easier than the forum.
00:24:56.850 - 00:25:17.548, Speaker A: Cool. Yeah, thanks. Any other questions on that? Okay, thanks, Shay. Yeah, super exciting to see. Next up, Solius. I see here. See you here on the call.
00:25:17.548 - 00:25:51.404, Speaker A: I think you wanted to give an announcement on your work with Grandina. I'm not sure how you pronounce it, but the new sale client you have. Yeah. Hey guys. So I'm new to this call. Pleasure to see a lot of people here. So we are working on intense player client for quite a long time, and recently we started to check a bit more on optimizations that are important for me.
00:25:51.404 - 00:26:49.730, Speaker A: And essentially we recently were mainly working on things like speeding up production and transition. So generally there is someone on the, on the call or if you know, someone who would be interested to collaborate with conference lawyer client on, you know, getting a really fast client for any related stuff, then let us know. So yeah, if you have any questions then you can ask now or reach us later. It's that small nonsense. Maybe there was a couple parts I missed. Maybe in one sense, summarize something collaborating with a consensus layer client. Maybe one sentence, summarize what collaboration you're seeking exactly from that side.
00:26:49.730 - 00:27:46.512, Speaker A: Oh yes. So essentially we want to optimize the client and there are some ideas that we already know. For example, we think that fast block construction and fast data transition is something that would help people. However, there could be some other angles that we are not that familiar, we are not running really, we are not builders and so on. And so sorry. So if there are some folks that would like to collaborate with us on getting clients faster in terms of specifying what exactly need to be faster than that would be very helpful for us. Yeah.
00:27:46.512 - 00:28:29.720, Speaker A: And I think concretely one interesting use case at least to explore would be running grandina like in your relay infrastructure. I think the idea is to have a super optimized Cl client. Obviously you all care about super optimized el clients. And then the question is, would you see benefits from having similar performance games with the Cl part of the pipeline? If any relays are here and are interested to experiment, please reach out to Soleus. Sounds good. How can I do that? You can go to. Just go either to your.
00:28:29.720 - 00:29:06.010, Speaker A: Maybe can you put it in the chat? I noticed your mic is cutting out a little bit. It would be really helpful to have it in the chat as well. Yeah, I'll make it just after I complete my talk, because I'm on phone. Okay, I'll try to put in the chat. Cool, thanks. Let's see. So next up we have an issue a pull request on the builder specs repo.
00:29:06.010 - 00:29:11.930, Speaker A: There we go. Great. Yeah. And flake, do you want to give us an overview then, since you're.
00:29:12.430 - 00:29:54.304, Speaker D: Yeah, sure. Thanks for having me. So I put this pr a while ago. It's nothing new. So there were already proposals two years ago to add SSC support to the builder API. But I kind of wanted to revive that because at this point it's kind of established on the beacon API already that we use SSC for the block proposal APIs to reduce the latency there. And this basically is a proposal to add this to the builder APIs in a backward compatible way where this can be rolled out incrementally.
00:29:54.304 - 00:31:00.606, Speaker D: So not every relay or mev boost even needs to support this right away or every client. And yeah, the benefits here are, should be pretty obvious. So there are some benchmarks in the other existing pr for SSE serialization and also just latency improvements. This gives and then other potential improvements in terms of performance from a client point of view. Because we published a blinded blog as a YDE encoded and basically right now we have to serialize it again when we pass it or when we call submit blinded block on mevboost because it only accepts JSON. So this is unnecessary step basically. And also like so Mevboost is one of the only components really in terms of API did connects over an external network.
00:31:00.606 - 00:31:31.260, Speaker D: So I think just there in terms of reducing the payload size would be a huge improvement as well. So the PR basically describes what a good server behavior should be and how clients should work. This should be self explanatory. I outlined more details in the PR itself, so please take a look there. I would assume most relay software and mevboost already supports this behavior.
00:31:32.760 - 00:31:33.672, Speaker C: Yeah.
00:31:33.856 - 00:32:25.600, Speaker D: So how to roll this out backwards compatibility, or in a way that it's backwards compatible is basically you would call the get header with an Q weighted accept header or even just accept header that wants an SSE response. And if the get header API supports SSE, you can basically assume that the blinded block can be submitted is SSC encoded as well. So that way this can be rolled out. So basically it would be good to get feedback from real layers builders on this because I think from a client point of view this is trivial to implement since we already have SSE on the Beacon API anyways.
00:32:30.700 - 00:33:25.270, Speaker A: Right, cool, thanks. Yeah, I think various combinations of the builder APIs and the relay APIs between relays and builders have some SSD support. So yeah, we'd want to do something that reflects what's already out there. But yeah, I think having the specs would be super helpful and yeah, thanks for the PR. Yeah. Everyone please take a look and chime in if we need to reflect your current behavior in any way. Okay, any questions on the PR? I think the PR is probably a good place to follow up and otherwise we can go to the next item, which is EIP 7732.
00:33:25.270 - 00:33:48.870, Speaker A: So let's see Barnabas here. I think post is here. I think they're both authors on the EIP. I think they wanted to give an overview. Again, EPBS has been a very longstanding research arc that we've all been playing a part in. And yeah, they originally put together zip. Super exciting to see it at that stage of the pipeline.
00:33:48.870 - 00:33:53.270, Speaker A: Yeah. Would one of you like to say more?
00:33:55.090 - 00:34:04.670, Speaker C: Yeah, I'll go, I'll go ahead. Thanks for the invite. I have a couple of slides, not too many. Can you hear me well?
00:34:06.850 - 00:34:08.924, Speaker A: Yep, we can see the screen.
00:34:09.082 - 00:34:09.944, Speaker C: Can you see your screen?
00:34:09.992 - 00:34:10.820, Speaker A: Okay, cool.
00:34:12.400 - 00:34:36.790, Speaker C: All right. So, yeah, I think it's exciting. It's indeed, as Alex pointed out, been a long time coming. So we have an EIP finally. Props to POTUS and Terence, I think, for really doing this last night work of getting it past the line. Francesco and Mike for all of the work they did on PBS and have been around as well. And I'm happy to presented today.
00:34:36.790 - 00:35:31.410, Speaker C: So the design in the EIP is the one that's known as the payload timeliness committee, or PTC. It's basically a design that splits the proposal of a beacon block from the delivery of the execution payload, which is delivered by the builder. It's four easy steps. First, the beacon proposer makes a Cl block, so consensus layer block that commits to a builder bid. The attesters, which are validators sampled from the set, vote on the existence of this Cl block. So we try to make the commitment to the bid canonical. If the builder is satisfied with, let's say, permanence of the CL block, the builder will then release the execution payload that they committed to in their bid.
00:35:31.410 - 00:36:12.276, Speaker C: And in the fourth step, the payload timeliness committee votes on the timeliness and availability of the execution payload. So more details about this in the if research post. I'll put a link to the slides in the chat after. So, yeah, since we now have like this two step process, there's of course some choice considerations. In particular, there are issues regarding builder safety. So the builder needs to be convinced that when they propose their payload or when they deliver it, they're not going to be reopened. Like, they have to know that it's safe to propose it.
00:36:12.276 - 00:36:53.464, Speaker C: Nothing is certain, but I think the parameters in the EIP strike a good trade off. In particular, the actions of a builder are two of them. They can decide to reveal the payload, or they can decide to claim that in the current circumstances, they should withhold it. So if they are not confident enough that the commitment to the bid will be safe, they can claim. Okay, I would rather withhold it. But of course, if they decide to withhold in a case where they should have rebuild, that can be defeated as well. So when the builder delivers the payload, there is a choice.
00:36:53.464 - 00:37:19.786, Speaker C: Boost. Payload boost 40%. That makes the so called ex ante riogs harder. But it's a bit of a zero sum game between these two. So if one gets harder, the other one gets easier. So ex ante is the types of reorg where the previous proposal is kind of setting you up for reorganio. And the exposed reorgs are, let's say, classic rehogs of the next proposal, trying to kick you out.
00:37:19.786 - 00:38:28.380, Speaker C: And POtuS has a post about this. I think one thing that we all seem to think is pretty cool with epbs eap, is this idea of pipelining the PTC committee only verifies the time limits around here. Here you have beacon proposer of slot n releasing their block. The beacon attesters verify the availability and validity of the beacon block, after which the builder is expected to deliver the payload. Then the PTC checks the timeliness, and then later on, the proposal of n one builds on the payload and the attesters finally validate. And so what happens in this design is since the PTC testers are not checking the validity, they're only checking the availability and timeliness. You actually have 12 seconds between, at best, let's say, between the delivery of the payload and the attesters here at n plus one, checking the validity, which if you contrast this with today.
00:38:28.380 - 00:39:12.042, Speaker C: So today the payload of block n is delivered at the same time as the block n. And so the attesters have, let's say, at best, 12 seconds to check the validity before they release their votes. Terrence has a post with more details. Okay, this is a Mav boost call, so some stuff relevant to the builders. One other nice thing you get from EPBS is since the protocol is now the one doing the fair exchange, so ensuring that this contract between the builder and the validator goes through. And yeah, both parties get what they need. The builders don't need to connect to the relays, they can connect to validators directly.
00:39:12.042 - 00:39:53.178, Speaker C: And that seems to be at least a qualitative improvement in terms of their action set. Let's say another thing that's notable in this design, the builder needs to be staked. So you need a balance on the consensus layer to pay out the bids that you're making. And that also means the bids are bounded by your balance. So your balance is 32, can only be up to 32. So the reason for this is in epbs, the funds. So the funds needed to pay your bid, they have to be available in the payload pre state, because if you don't deliver your payload, we still need the payment to be processed.
00:39:53.178 - 00:40:13.830, Speaker C: And so the protocol needs to know that the funds are available so you can't fund the payment of your bid from, let's say, actions you take in your block, as you would in the, in the current mev boost. Why is this on the cl? In theory, you could do this on the execution layer, it's just more complexity.
00:40:17.690 - 00:40:18.026, Speaker A: Yeah.
00:40:18.058 - 00:40:54.260, Speaker C: One thing that's well known about epbs is that it's nothing mandating the fair exchange to go through the protocol. It's really just adding this option to the builders and the validators. The proposal can still use mev boost. There are some reason why they might not use mev boost. For instance, the direct connection does give you faster bits or lower latency. There are reasons why they might. For instance, keeping the balance on the, the consensus layer is a small cost of capital, let's say.
00:40:54.260 - 00:41:06.100, Speaker C: Yeah, and there's a, I would say, like very active debate around the cancellations and what they mean and do they work in the. In both cases, but maybe we can touch upon that later.
00:41:08.680 - 00:41:09.416, Speaker A: So, yeah.
00:41:09.448 - 00:42:13.720, Speaker C: Finally, I want to mention that the EIP implements the design that's known as block auction, which is that when the builder makes a bid, they commit to the contents of their payload by committing to the transaction route, which is what they do in Mevboost as well. In theory, you could do in protocol what's known as slot auctions, which is that the builder bid does not commit them to payload contents. So once the proposal commits to a builder, the proposal essentially just says, I expect this builder to deliver a payload timely and a valid payload, but there is no commitment to what the payload will contain. There are arguments again for both sides, like block options start options. On the one hand, it feels like a more flexible design. It also kind of reduces the lag so the payload can be built as it is delivered. So the builder doesn't need to commit like a long time in advance to what they are eventually delivering a few seconds later.
00:42:13.720 - 00:42:51.198, Speaker C: But it is a form of early options. You commit to a bid and then there's a few seconds more, during which you can accumulate more information in the form of transactions. Early auction sounds scary, usually because people think of multi block mev, but it's not early enough to have these concerns. Like the auction still happens within the span of a block. So, yeah, you're not doing the auction knowing that you won the previous one. These types of arguments. Yeah, I want to mention that we just opened an EPBS tracker.
00:42:51.198 - 00:43:18.162, Speaker C: We try to keep it alive. It's kind of recent and there's a lot more stuff to add, but we also want to make it iteratively as the discussion goes on. Open issues faqs. Feel free to ping us if something is missing. And yeah, that's it. A few more call to actions, especially I guess for the builders or the infra. Think about how this affects you.
00:43:18.162 - 00:43:41.280, Speaker C: Or maybe it doesn't. Take a look at the tracker. There are also the CL specs available. You can review them, provide possible attacks or blockers if you go into that. The ETH RND Discord channel. EPBS is also quite active, and there are bi weekly breakout calls that you can join too. Yeah, that's it for me.
00:43:41.280 - 00:43:46.160, Speaker C: I'm seeing some comments.
00:43:47.060 - 00:44:13.190, Speaker A: Yeah, awesome work I did have. There's one question, probably many, but not to get ahead of ourselves, but I wonder if you could speak to like how this would interact with like different AP's designs we've been talking about as well, or if there's any relation, like, you know, maybe they're just compatible in a sort of forwards compatible way. I don't know if you have any thoughts around that.
00:44:14.210 - 00:44:51.460, Speaker C: Yeah, well, I guess I could link to his post. I'm sure most people in this room have already seen it. AP's is in a sense an even more like profound separation of the rows. You could actually do both Ap's and PBS. It's not probably the thing that's worth doing. The way I describe it, I guess, is PBS separates out the building role of a validator, so they have to decide on the contents of a block payload. AP's separates out the proposing one, so you have to propose the block itself.
00:44:51.460 - 00:45:36.470, Speaker C: It looks a bit like the start option, in fact. So you allow the builder to essentially have full agency over the block they propose. In particular, they can make commitments like I will include this transaction in this block, known as preconce. It's a role that's a little bit more powerful than what the builder can do in block options, for instance. I would say the main difference is also the fact that in AP's, at least how it's discussed, you mandate that the fair exchange goes through the protocol. So there is this maximization tool somewhere, or tickets. That's another design that ensures that the protocol is the one that's going to be allocating the role of the proposal.
00:45:36.470 - 00:45:45.910, Speaker C: And no bypassability. Yeah, I think that's. Feel free to add anything.
00:45:49.370 - 00:46:16.490, Speaker E: I have a question. Have you already given some thoughts about what happens at the boundary condition with like heavy lottery blocks, for instance, where stakes 32 eat? Maybe not enough for the builder? Like, have you already given some thought about how that could play with people falling back to me booths or stuff like that?
00:46:18.430 - 00:46:18.766, Speaker A: Right.
00:46:18.798 - 00:46:56.780, Speaker C: I guess we have a couple of arguments. So one of them is these things are rare, but even if they're rare, you don't know when they're happening. So you might still want to kind of prepare for it. One thing is 32 is not the maximum you can put on the Cl. You can actually stake more than 32 if it's just effectively your balance that is at stake will be maximally 32. This will change with Max EB, but even today, which maybe makes no sense because epbs obviously would go in after epbs. After Max Ebb happens.
00:46:56.780 - 00:47:09.390, Speaker C: Yeah. Even today you could actually just top up beyond 32, even though only 32 would be at stake. Okay.
00:47:26.060 - 00:47:50.160, Speaker A: Cool. Assuming there are other questions. Thank you, Barbie. Yeah, excited to see the progress. Otherwise we'll move to the next agenda item. So there is a proposal, let's see. I think it was just in the forum post here, spam on the call.
00:47:50.160 - 00:48:44.430, Speaker A: I don't see him. Okay. I thought he was going to be here, but yeah. So essentially he has this proposal for some sort of privileged relay, which I think would basically let you say in the boost you want to work with maybe a particular set of relays over others. This would just kind of be like a policy decision on top of even just the sort of revenue maximizing auction that's in meth boost today. I think there are quite a number of questions to this. Like, just at first pass, it doesn't seem like something I necessarily want to put into, like boost the protocol, just because it seems like it complicates all kinds of things around, you know, relay adoption, relay usage, and then also perhaps bidding strategies and then which builders are using, which relays and.
00:48:44.430 - 00:48:50.760, Speaker A: Yeah, I think even just going through the list, it sounds like there's quite a lot here.
00:48:52.500 - 00:50:07.440, Speaker E: But yeah, I guess I can comment on it a bit because I spoke with some. I think that the main idea there, at least as a principle, is that especially when it comes around integrating stuff like reconfirmations or for instance, the kind of stuff that XGA is doing by merging an alpha and a beta block and stuff like that. Basically, sometimes to do these things, especially in the beginning, to test them, you need basically to strike deals with validators. For instance, in the case of XGA, at the very beginning, SGA had to strike deals with validators, for instance, fracs validators, and they had to run those relay exclusively. So they had to exclusively listen to FGA relay for a lot of reasons. But then the problem with that is that that eliminates the possibility for a validator to fall back to an alternative. I think that is the main rationale.
00:50:07.440 - 00:50:54.950, Speaker E: The main rationale is probably when you have a validator set that is willing to try something new, some new way of doing block building, but you want to do it in a safe way so that, you know, if it doesn't work, you just don't just like miss the slots, but you have a full bet. Usually these deals between, you know, relay and validators, or validators and builders, whatever, they take a long time to, to develop. There's a kind of like link of trust that usually can be broken pretty easily. So I guess that the proposition was basically centered around this, at least with a motivating rationale for it, not the details are something else.
00:50:56.090 - 00:51:08.240, Speaker A: Yeah, yeah, that makes a lot more sense, at least, you know, in terms of motivating the idea. Yeah, I probably wait to have Sam come to flesh things out fully.
00:51:09.420 - 00:51:10.940, Speaker E: Probably easy in the call.
00:51:11.100 - 00:52:04.976, Speaker A: No, but I'm in the call. Oh, hey, sorry. Yeah, yeah, yeah. So building on what Patrizia was saying, you know, there's a few other reasons. Another reason is for validators to provide a way to favor relays that are not doing any sort of censoring at the relay level, for example, with OfaC and stuff like that. So there's another reason right there for having this privileged relay set up. And then also, you know, what Fabrizio was talking about regarding development and stuff, that's also, I think, a pretty credible reason for having this set up.
00:52:04.976 - 00:52:57.480, Speaker A: And at the end of the day, the setting is already implemented in the sense that validators can do local block building, which is already sort of favoring their own builder versus the market for builders. So it's really extending an already encoded. Privileged. Yeah, so privileged was, you know, you know, it's better than saying exclusive. So that's the reason why we went with the, with the nomenclature proof or like maybe just like preferred or, I don't know, like this is more about like. Yeah, more logic than just Max Rev. Right.
00:52:57.480 - 00:53:26.768, Speaker A: And preferred would obviously then there are like implications for market structure that need to be thought through. But yeah, yeah, preferred would be more accurate because it's nothing privileged in the sense that it's exclusive. Like Fabrizio had mentioned that it is a fallback mechanism, it's not an exclusivity mechanism. So preferred would be more. Would be more accurate semantics.
00:53:26.944 - 00:54:15.060, Speaker E: Yeah. Just to give like an example, imagine that you run a relay that uses a different bidding logic. So for instance, you want to try out a, I don't know, sealed bid, second price auctions or stuff like that. If you try to do it at the moment, the problem that you have is that the validators will listen probably to your relay, but they will also listen to a bunch of other relays that will submit bids that are basically sorted out in different ways. Like maybe what I mean is that maybe your relay is doing some free sorting of the headers, receives and stuff like that. So the problem is that then the data becomes rather murky to navigate. Whereas you know, the kind of idea is.
00:54:15.060 - 00:54:46.720, Speaker E: Yeah, if your validator run that relay exclusively, would listen to that relay exclusively, then you could have thinner data. But you know, that introduces all sorts of problems, is not really something that can be asked. So I guess that, yeah, the idea of this is that it may help relays to experiment with different biz structures, different auction structures, whatever, in a way that doesn't necessarily hurt the validation. So.
00:54:48.220 - 00:55:30.380, Speaker A: Yeah, and just to make another note that we've already implemented this in vouch, and there is a pr open in the Mavboost repository. The link is in the Mavboost repository. Pr. I'll make sure to link it in chat as well. So this has been running on Testnet and on main net for the last two months and testnet since late April. And we've successfully validated that this works. And we have fixed a few bugs regarding some implementation details.
00:55:30.380 - 00:56:35.236, Speaker A: Ideally none. We would ideally expect that there would be no difference between the relays at worst, you know, depending on the setup, you know, it shouldn't be any different than local block building and the relay. Right. So it's really, it's really dependent upon if the relay is also running its own block. Sorry, I don't really like to get it, but what have you implemented in vouch? Just that the bit value of specific relays can be amplified or something else. There's a preference for connectivity, for favoring the results of a certain relay above others. So.
00:56:35.236 - 00:56:58.302, Speaker A: Yeah, but it's just based on the bit value, right? Like you boost certain real estate value by constant. That's what botch is doing. Yeah, check. You can check the implementation. I mean that's what I can read from the docs. That you link, but maybe you have more information to pick a link. It's a bit confusing to me also.
00:56:58.302 - 00:57:25.396, Speaker A: Like why wouldn't you just connect to a single relay if you want to prefer a single relay? Because if you connect to a single relay, you now have the problem of what if the relay doesn't provide a response or a valid block. Right. That's. That's what we're wanting to prevent. There still needs to be a failover method. Does that make sense?
00:57:25.548 - 00:57:59.820, Speaker E: Yeah, that was also what I was mentioning before. If you connect to just one relay, basically as a validator, you have a single point of failure. If whatever experimental feature this rally is running doesn't work, then you miss the slot and obviously that's going to be a problem. And most likely it's also going to tell that validator to never, you know, listen to that relay exclusively again. So, yeah, that is the main idea is essentially to implement a sort of full death mechanism.
00:58:02.050 - 00:58:25.178, Speaker A: Right. And then, for example, you know, there could be a situation in the future in which all relays are potentially optimistic. Right. And you're wanting to connect to a non optimistic relay. That could be one a little bit more contrived example of a use case. Right. Because we're already seeing, you know, different flavors of relays.
00:58:25.178 - 00:58:58.980, Speaker A: In a sense, you already have optimistic and non optimistic and then filtering. And non filtering. Right. So, yeah, I'll let you. Yeah. Two things I'm curious about. The first is, just from glancing, I'm not entirely clear on if this is purely a math boost side change, or if there's also some kind of changes on the relay side required, because then I really want to read it more carefully.
00:58:58.980 - 00:59:41.182, Speaker A: If it's just a mapboost thing, then it doesn't matter that much for relays. I guess there doesn't necessarily need to be changes on the relay level. We have another agenda item regarding updating some of the relay API endpoints for providing clarification as to how the relay is currently configured and operated. Right. So that would probably be an appropriate change for a relay. Like a relay should probably provide that information to builders and validators when registering or just as a query as to how it's configured. Right.
00:59:41.182 - 00:59:56.882, Speaker A: If it's doing filtering, it's doing optimistic. What version? That sort of thing. Yeah. So just to be super clear, like the PR as it stands in the mafboost, repo does not require relates to make any changes. No. Okay.
00:59:56.906 - 00:59:57.346, Speaker C: Yeah.
00:59:57.458 - 01:00:40.986, Speaker A: Okay. And then the second thing I was really curious about is just if you've pulled proposers on like I imagine you could already, it sounds like you already forked vouch to an extent, right, and implemented it somewhat. And if it's only a proposal side change, and it can be nice to have proposers sort of do it first before it ends up as like a spec level change. So I'm just curious if you have any rough indication of how many proposers you already know would love this feature. So we've already been testing this on Mainnet Ethereum for almost the last 60 days. We have like around 250 validators as part of the minimal set for testing purposes. So there's that.
01:00:40.986 - 01:01:16.780, Speaker A: So we've spoken to other lsts and some other staking services about implementing this, and they're excited. They just want to see some progress on getting more community consensus around this, because obviously the concern is whether or not we're going to have to maintain the maintenance overhead of maintaining these separate ports. Right. Which is not something we think is appropriate considering the minimum amount of changes that are required to implement the future. Yeah.
01:01:16.940 - 01:01:17.276, Speaker D: Yeah.
01:01:17.308 - 01:01:53.682, Speaker A: Makes sense. Yeah. Would also be really cool if that could be surfaced somewhere or something. I don't know how others feel about that, but for me at least, and I think also for our team, it would make it like a big difference if there's big parties, you know, tens of thousands of proposers that are saying like, okay, yeah, we want to prefer a relay or something like that, then it becomes a strong incentive, just as a general note. Yeah, we can do that. Cool, thank you. Are there any other, any other questions? Produce, how does hand up.
01:01:53.682 - 01:01:54.618, Speaker A: I don't know.
01:01:54.754 - 01:01:57.270, Speaker F: Yeah, but I'm not sure if I'm muted.
01:01:58.050 - 01:02:00.156, Speaker A: I can hear you. Good.
01:02:00.308 - 01:02:39.052, Speaker F: So, yeah, so two comments. There's something, one that I'm not buying, which is this failure mechanism, and the other one is the difference with what we already implement. So first of all, there are two ways of failing for a relay. One way that creates an empty block is if the failure happens after we've signed something. And then there's the other failure mode in which we can still build locally. So for the second type of failure modes, we can always build locally. So there's always that part, and there's never a single point of failure.
01:02:39.052 - 01:03:43.220, Speaker F: For the first type of failures, having preferred one or the other one, it's not going to change anything, because when one relay fails, then the whole relay mechanism fails. For the proposer, it doesn't matter if there are other functioning relays. We've seen this when certain relays were adding a lot of delay, for example. I don't see how this mechanism is better than just connecting to one or whitelisting some finite set of relays from all possible relays. From the description that you're giving, it seems to me that the difference between what we currently have, which is you can whitelist a bunch of relays, or one relay if you connect directly to it, and this preferred relay is that you're going to boost. But keep this possibility that if this guy doesn't give you enough money because it seems like the only failure mode actually, then you're going to take the second bit from a different relay. I don't expect this to cause a lot of change.
01:03:46.090 - 01:03:59.738, Speaker A: Okay, so for the second point that you made, you know, there's a presumption there that you are in fact locally blocked only, which is not always the case. Right. So that's an implicit assumption in the second.
01:03:59.794 - 01:04:08.354, Speaker F: Oh, that's an implicit assumption in the spec. If validators are not following the spec, they're malicious validators. I'm not proposing anything for malicious validators.
01:04:08.522 - 01:04:22.188, Speaker A: Yeah, well, I mean, uh, it has happened on Mainnet. I wouldn't necessarily consider them malicious, just, you know, lazy, potentially. Uh, but you know, that's a distinction without a difference.
01:04:22.284 - 01:04:29.652, Speaker F: No, no, it's malicious. They cannot validate to a test. Validators that do not build locally, that they're not running any, are malicious validators.
01:04:29.836 - 01:04:54.088, Speaker A: Yeah. Well, I mean there's, there's, there's. So in the, in the case even then. Right. You still need, you know, I don't see the point in the, in that argument, to be honest with you. In the first point, I forgot what you were trying to get at. Like at the end of the day, right.
01:04:54.088 - 01:05:26.290, Speaker A: The having whitelisted relays, you know. Okay, so a relay not providing a response is a different failure mode than a relay providing a response with the zero amount. Right. So in that case, we want to differentiate between those failure boundaries. I think maybe Fabrizio can speak more onto those points.
01:05:28.910 - 01:06:32.992, Speaker E: Well, yeah, for local block building, I agree. That's an alternative. Again, that basically means telling validation to almost forego all math unless, you know, they, they run some sort of like strategically relevant block buildings, which usually they don't. So, I mean, it is a, yeah, you say, okay, there is a fall back, but it's a full back in the sense that the validator will include some transaction, not in the sense of, oh yeah, validator is still getting Mav out of this lock. In that sense. I don't think local block building helps you in basically any way, or if it does, it helps you very little. So basically, the way I see it from a market point of view is really, you are a validator, and you are, you know, opening yourself to the services of third parties that are better than you are at destruction map.
01:06:32.992 - 01:06:57.310, Speaker E: And, you know, from the point of view of the validator is literally like choosing between different car brands or stuff like that. And the idea is of a fall back is if your car doesn't work, then you can get another car. And your objection seems to be, you don't need another car because you can always walk. And while I agree with you, I think that very different kind of fall back.
01:07:08.730 - 01:07:47.390, Speaker A: So, yeah, I think to move forward, I'll echo what Chris is saying here. Like, I think we should take a step back and think about the different types of things we're trying to do. Like, one point I heard that I think is compelling is like essentially like, if you want to test a new relay, it's tricky because at least on Mainnet, then you have to go all in. So there's something there. If we're more in the bucket of things of like, yeah, let's just say the malicious validator use case that POTUS is talking about. I think that's definitely not something that at least I wouldn't see in red boost. So, yeah, perhaps move forward.
01:07:47.390 - 01:07:51.550, Speaker A: Can we open an issue or something to kind of lay out the different use cases?
01:07:52.690 - 01:08:08.230, Speaker F: Yeah, Alex, if you're testing a relay, even so, the point is that if you have a validator that connects to a relay, it doesn't matter if it privileges or not. As long as you connect to a relay, then you're already going Olin. It doesn't matter if you connect to other relays as well.
01:08:08.610 - 01:08:14.242, Speaker A: That's the whole point that I'm trying to local. I mean, yeah, I agree. Yeah.
01:08:14.306 - 01:08:37.669, Speaker F: No, not even relative to local building. It can screw even your local building. So as soon as you're connected to a relay, a bug in that relay, it doesn't matter if you're connected to many relays, and if you're local, building a bug in that relay can cause you to lose your block. Okay, that's a rainy testing. It doesn't matter with this feature or not. You're always going all in if you're testing on Mainnet.
01:08:39.569 - 01:08:55.705, Speaker E: Well, yeah, I agree with you on this, but the point is having refining the boundaries where things can fail. Like, I totally agree with you that you are thrusting relays and every single relay can break your.
01:08:55.857 - 01:08:59.709, Speaker F: This wasn't an argument against you. It was just an argument against the testing thing.
01:09:02.329 - 01:09:37.410, Speaker E: Well, I don't think it's necessarily an argument against the testing thing. It's just like that, you know, having a more refined and structured way to be able to explain, express what is going wrong at the level of mav boost, allows you to protect yourself better in some circumstances. And I totally agree with you that if, you know, a relay gives you a payload that is super nice, and then there is nothing there and you miss the block, that will always, can always happen, and this thing won't save you from that. On this, I agree 100%. But that wasn't the intent of the proposal, I think.
01:09:45.210 - 01:10:02.672, Speaker A: Right. Where would you like to create the issue for further discussion? I think the mobile super works great. Okay, perfect. We can do that. Okay. Okay, thanks. And, yeah, maybe we just continue the conversation there.
01:10:02.672 - 01:10:19.440, Speaker A: Perfect. Appreciate it. Okay. Yeah, thanks. So I think Matt had something, and I think that was everything on the agenda for today.
01:10:20.740 - 01:11:01.886, Speaker G: Awesome. Hey, everyone, real quick. A few weeks ago, we published some data about private transactions growing over 30%, and we're about to publish an update to that. And I just want to let this community know, the prior research was done on transaction count, so 30% of transactions themselves are transmitted privately. We subsequently went back and reviewed that data and realized it would probably be clear, more accurate, if instead of doing that on transaction count, we did it on percent of gas used in the block. And it turns out when you do it that way, it's greater than 50% of the gas used in blocks is transmitted privately. So that's going to be the update.
01:11:01.886 - 01:11:37.412, Speaker G: The part that's more relevant here is different builders basically have greater amounts of private gas used. And in particular, the tier one builders, which we define as Titan, beaver, flashbots, and Rsync, not just have a lot more private gas, but are growing faster than everybody else. And then even within that category, Titan and Beaver have more private gas. And so this is, of course, the definition of a centralizing force. This. The data is pretty crisp here. We're writing this up.
01:11:37.412 - 01:11:48.080, Speaker G: If anybody on this call would like access to that write up, which is still in draft mode, just let me know over DM. I just want to let everyone know that this is a finding that we have, and we'll be sharing that probably early next week.
01:11:54.340 - 01:12:53.650, Speaker A: Cool, thanks. Okay. Any follow ups to Matt or anything else? Otherwise we could wrap up a little bit early. One minor update is that possibly next week or, you know, in the coming weeks, the ultrasound relay will spin up a new instance in the US, specifically vent hill, which is I believe, three milliseconds away from AWS east one. And it's on OVH. And OVH Us is segregated from the other OVH data centers. So you have to go through KYC again if you want to co locate as a builder.
01:12:53.650 - 01:13:22.920, Speaker A: Cool. Yeah, maybe. Also good to add that it's very interesting for builders and for proposers. If anybody's listening to this call, you shouldn't have to worry about anything. Everything will be kind of automatic for that side in particular. All the data endpoints should just work. So hopefully relay, scan and whatnot will not break.
01:13:22.920 - 01:13:43.250, Speaker A: Yes, if something does break, please message us, but nothing should break. Okay. Yeah, thanks for the update. Shawna had a chat comment to give a quick extra update. Was there something in particular you wanted to discuss?
01:13:45.030 - 01:14:32.960, Speaker H: Hello? Yeah, no, I think it's just quick update on kind of where the map boost, kind of all the services like where they are in terms of the petrol upgrade. So I think map boost and the boost relay is ready for testing. So it's just kind of missing the block validation piece which we're like working on right now. I think there are some changes to upcoming changes to Ngin API. So I think we were able to test the kind of build a workflow around like Devnet four or five. So right now I think it's on Devnet two. So that's kind of like the estimate of when we plan to kind of test this like PBS flow.
01:14:35.860 - 01:15:05.012, Speaker A: Okay, awesome. Yeah, there's Perry on the team. Was actually asking the other day about uh, builder specs and this generally. Um, and yeah, I think there might be some changes still to like the engine API and like that part of the flow which I think would impact the builder specs. Um, but yeah, definitely very soon I think it'll be time to, uh, start testing. So. Yeah.
01:15:05.012 - 01:15:36.740, Speaker A: Exciting to hear that that's moving along. And yeah, Petra is on the way. Okay. Anything else? Cool. Okay, thanks everyone. I will see you next time you.
01:15:38.360 - 01:15:39.380, Speaker D: Bye, everyone.
01:15:43.480 - 01:15:44.320, Speaker A: Hi. Thank you.

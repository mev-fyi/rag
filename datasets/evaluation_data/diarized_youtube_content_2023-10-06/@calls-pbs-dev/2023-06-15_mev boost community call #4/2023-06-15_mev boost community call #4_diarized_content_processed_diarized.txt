00:00:04.210 - 00:00:29.120, Speaker A: Okay. Should be ready to go with the recording. Hi everyone, this is mevboost, community call number four. And yeah, the agenda is quite packed. I posted in the chat. So I think we'll just go ahead and dive in there's a lot today. So, Reeve, I wanted to touch on 4844.
00:00:29.120 - 00:01:04.490, Speaker A: The main thing is that in terms of maboost and the Builder spec, there's an update here, PR 61. You can see it linked from the agenda there. And essentially it's just changing the types of the APIs for the mapboost flow such that they can support Blobs. That's sort of the flagship feature of Four Four. Four is adding these data Blobs, and there's a few different pieces we need to coordinate so that the current flow still works and also supports the construction of these blocks with Blobs. And that's what this PR does. Otherwise, it's pretty straightforward.
00:01:04.490 - 00:01:56.040, Speaker A: One thing just to call out is that now with these blocks with Blobs, relays may see this regime where you're passing back much more data per API call than you were. And I don't think anyone's expecting any issues, but definitely just something to keep an eye on, know, especially as we move towards testnets and things. If you see that latencies for some of your API calls are spiking, it might be because there's just a lot more data to send and we might need to think about optimizations there. Not expecting anything priori, but just worth calling out as we start to move that direction. Otherwise, let's see. Chris, do you want to walk through some updates on the flashbots code? I think there are some for.
00:01:57.870 - 00:01:58.858, Speaker B: Yeah, sure.
00:01:58.944 - 00:02:27.810, Speaker C: There is code on Mavboost in this branch that is linked. There is some exploratory code on the relay and in the Go boost Utils and in the block builder. I can't find the links right now, but yeah, there's like work in progress. I think within maybe two weeks we can be at a point where we can participate in a testnet. Generally speaking, I think like, the end to end flow within two weeks is reasonable.
00:02:29.270 - 00:03:04.320, Speaker A: Okay, cool. And I don't know if anyone else on the call with different relay implementations or builder implementations, if you've been able to look at this stuff, but please do so. Moving on, let's see. Yeah, I think Metacrist, you had some updates for us on relay performance. I know you've been doing a lot of work there and have some pretty exciting improvements. Did you want to walk through those?
00:03:04.770 - 00:03:49.218, Speaker C: Yeah, just real quick. In the past month or so, we had a ton of performance improvements. I think we plucked most of the low hanging fruits here. They were mostly related to not simulating as many submissions as possible. Like one chunk of the improvements, which is mostly outlined in the first link and then redis improvements on the other hand, which is in the critical path in a bunch of points during block submissions, and also during storage, which put quite a strain on the redis clusters too. And the recent changes brought resource usage down to like 10% of previous and it's pretty good, pretty fast. I think we are validating non optimistic block submissions.
00:03:49.218 - 00:04:50.750, Speaker C: The whole submission latency is about 200 milliseconds right now with kind of like stock EC, two instances and the stock code. Yeah, I don't expect big jumps very soon anymore, but I think this should reduce the operating costs and effort from other relays by quite a bit too. I think that's all I want to share. Maybe if there's any questions, maybe a few more details about canceling and non canceling bits that is alluded to in the first link, block validations are skipped for there's two types of block submissions. One is non cancellable, the default submission, and one is a cancelable submission where you add a specific URL query argument that this is a cancellable bit. Cancelable bits can lower the top bit. So even because non cancellable bits, you can all discard if they are below the current best bit of a block.
00:04:50.750 - 00:05:24.540, Speaker C: But the highest non cancellable bit provides a bit floor and even cancellable bits that are below this bit floor cannot lower the top bit value of the slot. So they can also be discarded and not validated. And I posted a table here. I think we are skipping about two thirds of all submissions now and sometimes even more. Yeah, that's it for that.
00:05:25.870 - 00:05:40.400, Speaker A: Okay, great. Yeah, that's really exciting to see. So if I'm a relay and I'm running the relay code here that you're referring to, are there any things I need to be aware of around deployments or upgrading or anything like that?
00:05:41.970 - 00:06:47.062, Speaker C: Only the single thing that is outlined in the release details that if you upgrade from a previous version that you update both the Block Builder API and the Proposer API simultaneously. If you run them as like separated API instances because they depend on a certain radis key that is used for delivering payloads from biller submissions to the proposal. And in this release it changed the key so they have both to be updated, otherwise it would still fall back to the secondary payload storage, which can be memcache and which can be the database. So it should not be like catastrophic, depending on your configuration. Otherwise I think it's pretty straightforward. Rollout no database migrations into latest releases. Oh, one more interesting thing about this is we've been doing a really big database migrations from like a ten terabyte postgres instance down to like 1.
00:06:47.062 - 00:07:15.520, Speaker C: This was pretty much a hassle. And we put together a quick migration guide, if any, of other relays need to downscale their database, because in the cloud managed databases like Amazon or Google, you cannot downscale an upsized database anymore. You need to create a new database and migrate all the data there and here in this guide, there should be some helpers if you want to embark on this, feel free to also reach out. We are happy to support.
00:07:22.160 - 00:07:22.620, Speaker D: Thanks.
00:07:22.690 - 00:07:26.350, Speaker A: Yeah. Justin, you have something to say?
00:07:27.780 - 00:07:35.890, Speaker B: I think we also went through this very painful database migration, and so if you need any help, nicholas might have some tips as well.
00:07:41.850 - 00:07:54.800, Speaker A: Okay, great. So yeah, just be aware that there's maybe this caveat here. And then also yeah, if you need to do any migrations. Sounds like there's some helpful tips in this PR. So.
00:07:57.250 - 00:07:58.000, Speaker E: Great.
00:07:59.010 - 00:08:11.380, Speaker A: I think we'll move along then. The next thing, I believe there's some updates from Optimistic Relay. So Justin or Mike, I think maybe one or both of you had some things to share.
00:08:13.590 - 00:08:59.140, Speaker B: Yeah, I just wanted to share a quick update on the progress of Optimistic Relaying. Some of the good news. So we have very good adoption from the builders. Now, we've had 21 builders make a deposit of one e and that's almost all the winning bit flow. Only one of the 21 builders asked for refund and we gave them the refund of one e because they were basically shutting down as a builder. So far we haven't had any optimistic blocks that were invalid and signed by the proposer. So the proposers haven't needed any kind of refund, we haven't had issues there.
00:08:59.140 - 00:09:51.154, Speaker B: And we're also making significant progress with optimistic reading v two. And Mike can talk about that, I guess, right after me. I guess one of the things that I wanted to give a heads up about is the possibility of increasing our collateral limit from one e to ten e. And there's a couple of reasons here. One is that some builders have asked us for higher limits. And the reason is that a lot of the mev opportunities for them are when there's these big mev blocks and they don't benefit from optimistic relaying. And we provide a more consistent service, I guess, than the other relays when we're under one EF and they want the same kind of service up to ten E.
00:09:51.154 - 00:11:06.566, Speaker B: And I guess the other reason is that in the spirit of moving towards enshrine PBS. We need to find some sort of amount which will disincentivize basically builders putting in bad blocks basically to cause one missed lot. So the current design of Antrim PBS that we have, there's a maximum amount of collateral, for example, 32 e, and you're allowed to submit bids above the 32 e, but if you make an invalid block, then that leads to a missed lot. And so basically we want the cost to the blockchain for censoring one block to be under this magic number. And 32 e, one e just seems way too small. And so ten e is kind of a way to move towards this maybe more appropriate number. And I guess a couple of things on the bad news side for Optimistic Relaying.
00:11:06.566 - 00:12:13.822, Speaker B: One is that right now we're the only relay that's running optimistic Relaying, despite the fact that the code base has now been merged upstream. And I guess the second piece of bad news is that it has been quite a bit more effort than we anticipated. I think a lot of this effort onboarding and educating the builders, getting them to fix all their simulation errors, just going through all the process of setting up the deposit address, et cetera, is kind of this one time thing. And we've done most of the heavy lifting, but even after that, there is some amount of maintenance because, for example, every time a builder has a new key, they might want that key to be promoted to optimistic relaying. And so every other day or so, there's just stuff to be done to maintain optimistic relaying. So that's it from the sync up. Happy to answer any questions.
00:12:13.822 - 00:12:17.700, Speaker B: Otherwise, I guess Mike could talk about optimistic relaying v two.
00:12:18.870 - 00:12:48.620, Speaker A: I guess I'd be curious to hear if you thought about so one thing I was kind of thinking about is moving validator registrations on chain in some way and if there's time, we can get into that. But I wonder if there's a way with optimistic relaying where you could do something similar, where more things are automated so builders can kind of deposit withdrawal and do all this kind of on their own. And so then in terms of operators, you just have to sync the chain, so to speak. Maybe it would reduce some of the ops overhead there.
00:12:52.270 - 00:14:02.594, Speaker B: Yeah, that's interesting. Maybe we could have some sort of shared database where the builders can say, I want this to be optimistic. I mean, another use case, for example, is the builder is going through some sort of overhaul of their infrastructure and they want to temporarily disable optimistic relaying. And so they could just do that with this kind of this shared channel, I guess, and then we could automatically demote them. But I guess there's also other things that we've noticed. Like one is that every time there's a timeout, so if there's a huge spike of activity and there's timeouts, then we take the very conservative approach, which was we demote blocks that timed out and that we were not able to simulate. And also there's this edge case when there's reorgs and basically there's this unability to basically simulate the block because the parent block kind of changed under you and the consensus client moved on.
00:14:02.594 - 00:14:31.740, Speaker B: And so in both of these edge cases, we take the conservative approach and we had to build kind of custom infrastructure to make the maintenance burden lower. But yeah, if someone wants to do optimistic relaying, we can kind of give you a heads up as to all the maintenance burdens that there are. I think we've reduced it to a good amount. But I just want to give you a heads up that it's still definitely there.
00:14:35.650 - 00:15:01.670, Speaker D: If the optimistic relay demotes due to a timeout on the relay side, like the SIM is overloaded or whatever it is, then how is the builder sort of promoted? Again, that sort of automated or does that require some kind of intervention? Is there any kind of signal that the builder can get that that occurred?
00:15:04.410 - 00:16:03.980, Speaker B: Right, so the way we used to do it is manually. So we have this telegram bot which tells us that there's been a timeout and then some minutes or hours later we see the notification and we manually review it. And the review process basically involves looking at whether or not there was a missed slot in that case. And if there was no miss slot, then we kind of assumed that everything is fine and we repromote. What we ended up doing is basically automating this manual process. So like a few minutes after there's a demotion, specifically due to a timeout, we look back whether or not there was a missed lot, and if there was no missed lot, we automatically repromote. So we wrote this custom piece of logic, which I guess sits outside of the go code base.
00:16:03.980 - 00:16:11.420, Speaker B: And that's something that we'd be more than happy to, I guess, open source. It's probably already open sourced, if you're interested.
00:16:14.430 - 00:16:38.130, Speaker D: Yeah, that would be interesting if you're only looking at miss slots. What about the case where is there a risk that a builder misrepresents the bid so the slot would not be missed, but the validator would have been received a different value than the bid, which the SIM would normally have caught?
00:16:41.690 - 00:17:01.820, Speaker B: Right, that is an excellent point. What we should be doing is basically looking at the block that won, and if it was one of our blocks, then verifying the payment. And that is a great point. Thank you so much for that.
00:17:03.470 - 00:17:06.218, Speaker A: I will say okay, go ahead, Mike.
00:17:06.314 - 00:17:35.430, Speaker E: I was just going to say a lot of the timeouts come from some of the builders that have less winning blocks, but very often send a ton of blocks. So usually if there's a demotion, that builder didn't end up winning the slot. So one of the if the winning block did come through our relay, we probably did get it simulated. That's the point I'm trying to make. But yeah, go ahead, Stokes.
00:17:36.730 - 00:18:01.950, Speaker A: I was just going to say, just like a remark, I'm very surprised. I don't think anyone's really misrepresented the value of bits. We spent a lot of time thinking about payment proofs and we could still introduce them, especially if it becomes a problem. But yeah, that doesn't really seem to be a place where people are trying to grieve the whole system. But that being said, it's definitely worth keeping an eye on as an operator.
00:18:05.600 - 00:19:08.924, Speaker B: I mean, on the topic of these builders, which internally we call spammy builders, our definition of spammy builder is if you have less than one inclusion for every 100,000 submissions, then we qualify you as spammy. And I guess there's like three or four of them. And one of the things that we've noticed is that they put quite a bit of burden on our infrastructure and that has real DevOps cost in terms of cloud bills and they provide some of the least value to the ecosystem, I guess. And not only that yeah, one in 100,000 Chris. Not only that, but they actually consume simulation resources. So if we were to ban all those spammers then we'd we'd have a greater win rate. So I'm not sure what kind of discussion we need to have here, but we want to be credibly neutral.
00:19:08.924 - 00:19:17.300, Speaker B: We don't want to be censoring anybody, but there are some builders out there that are providing extremely little value and consuming a ton of resources.
00:19:20.520 - 00:19:29.210, Speaker D: Is this not handled via rate limits? I know some relays like ours does have rate limits to mitigate this.
00:19:32.380 - 00:20:32.940, Speaker B: So we've taken the decision to not have rate limits. We could have rate limits. That is correct above and beyond providing the relay service. One of the things that we kind of are doing right now, kind of as a public good is basically keeping a full archive of every single submission that we receive. And the idea here is to provide a huge database for researchers down the line, maybe a few years down the line, to do whatever research they need. And so we are actually keen to keep this information and not rate limit too much. And another thing with rate limiting, so initially we had the cloudflare, but one of the problems with cloudflare is that it adds ten milliseconds of latency and so kind of shaving that off kind of makes you more competitive.
00:20:32.940 - 00:21:04.630, Speaker B: And I guess as Max said, the rate limiting is kind of easy to get around if you really want to get around it anyway. I mean, one of the things we are considering is doing rate limiting based on deposits. So if a builder has collateral then that's a form of anti civil infrastructure that we can reuse for rate limiting.
00:21:07.370 - 00:21:22.330, Speaker E: Yeah, this is kind of thinking out loud here, but we could say you get like x amount of optimistic blocks per one ETH collateral or something per slot. We haven't thought too much about it, but seems potentially useful.
00:21:26.220 - 00:21:35.930, Speaker C: I have one similar related question. How often do you get block submissions that result in a demotion or have a problem?
00:21:38.800 - 00:22:31.916, Speaker B: So there's kind of two types of blocks that lead to a demotion. Like there's the false positives where there's been either a spike of activity which leads to timeouts, or some sort of reorg that happens, I don't know, maybe twice a day or maybe even more now a handful of times a day, but that's okay because of the automatic repromotion. And then there's like the more serious problems where the block was actually invalid. That used to happen quite a bit when we got started. And the reason is that builders has had all sorts of bugs which they were not even aware of because they didn't get this feedback loop. But optimistic reading it was a forcing function for us to report every single builder bug. And I'd say nowadays we get one a week, one every couple of weeks.
00:22:31.916 - 00:22:34.030, Speaker B: It's relatively rare now.
00:22:38.720 - 00:22:39.180, Speaker E: Thanks.
00:22:39.250 - 00:22:41.120, Speaker C: Yeah, a lot of education effort.
00:22:51.900 - 00:22:59.672, Speaker A: Okay, I think. Mike, did you have some updates on optimistic relay and V Two or I feel like we've covered them. Okay.
00:22:59.726 - 00:23:46.964, Speaker E: No, I'd like to give a couple minutes of chat. Can you guys see my screen? Yes. Cool. So, yeah, just to kind of remind everyone what optimistic relaying V Two actually looks like, I thought it'd be useful to kind of revisit this optimistic relay roadmap. So this is kind of the schematic we use to describe optimistic V One, which is the builder submits the bid. We have this block thing here to represent that the whole payload is decoded by the relay before the bid is marked as eligible. So when we're looking at kind of the performance of submissions, we see that, for example, the decode duration for different builders can be like ten milliseconds.
00:23:46.964 - 00:24:48.056, Speaker E: For some builders it can be like 100 milliseconds. And that's kind of this first part of the submission that is kind of the latency bottleneck once we remove the simulation from the submission pipeline. So optimistic relaying V Two is something we call header only parsing. And the idea here is that the builder sends the bid with a new message type, and the message includes the full execution payload header, along with the list of transactions and withdrawals separately. So this is slightly different than the current submission process, but what it allows us to do is we can mark the bid as eligible and we can say the get header response is constructed before we actually receive the full contents of the block. So the block might be a few hundred kilobytes up to a few megabytes. And so the download speed of that is no longer part of the hot path for a builder submission.
00:24:48.056 - 00:25:27.690, Speaker E: So that's kind of the goal of optimistic V Two at a high level. We have some yeah, I put a link to the PR in let's see, I can't find the chat. Oh, here it is. Okay, here's a link to the PR. I opened up this against the flashbots repo, just kind of for visibility. It's sort of work in progress still, but we've done a little testing that I thought it would be interesting to share. So I guess the TLDR is we're working with Rsync to kind of demo this.
00:25:27.690 - 00:26:16.436, Speaker E: The decode durations for V Two with SSZ and header only parsing are really fast. So this is the decode duration in microseconds, and we're getting around like 40 microsecond median. There's a little bit of a longer tail because just, I think go garbage collection, go runtime stuff. But yeah, I guess the TLDR is this is about two orders of magnitude faster than decoding the full payload. So the average 10,000 microseconds is for the full V One decode versus the V Two decode is closer to like 50 microseconds. So that's pretty encouraging. The other interesting number, I would say is what I'm calling the time to save payload.
00:26:16.436 - 00:26:58.304, Speaker E: So the important thing about V Two is there's now kind of a new state for the bid, and that is the bid could be eligible to win the auction, but it could not be available. So a proposer can call get header. They'll get the header because that's available. But when they call Get Payload, the relay might not have downloaded the whole block yet from the builder. So this box and Whisker plot shows the difference between when the payload is received and when the bid is marked as eligible. So generally speaking, it's quite low. But there's a long tail up to around like 800 milliseconds.
00:26:58.304 - 00:27:37.170, Speaker E: This is 800,000 microseconds. So that's like almost a full second at the long tail. So this means that the bids could be in a state where they could win the auction, but the block isn't available yet for a full second. And that's potentially problematic, especially if someone calls Get Header near the end of a slot because let's say they call Githeader at T equals 2.5 or something, then they might call Get Payload, but we have to wait a full second for the payload to be downloaded. Suddenly we're like, really butting up against the end of the Attestation deadline. So these are kind of like some of the concerns around V Two.
00:27:37.170 - 00:28:06.380, Speaker E: This right hand one is the Received At. So this Received At is not when the bit is marked eligible, but it's when the first packet is received from the builder. So this is like a little bit longer, up to 1.5 seconds. But really the left hand plot is the critical data point. And again, this is from a builder that's pretty well colocated with ultrasound relay. It's in Europe.
00:28:06.380 - 00:28:41.640, Speaker E: I don't think it's in the same data center, but still, the fact that the long tail is that long is pretty concerning. So just a few quick takeaways. The single packet decode durations are really fast. The way the SSD encoding works, we can be guaranteed essentially, that the full header fits in one packet, so it's like 900 bytes. The MTU of an Ethernet packet is 1500. So they send us one packet and we can mark the bid as eligible. But as I mentioned before, there's like this new status where a bid is eligible to win the auction but isn't available.
00:28:41.640 - 00:29:20.870, Speaker E: That's kind of this gray area that we need to be careful with. I would say the current retry logic for Get Payload is we retry once after 100 milliseconds. So when the proposer calls Get Payload, we try to read it from Redis, we try to read it from the database. If both of those fail, then we sleep for 100 milliseconds and then we retry. But as we've seen, they could call get payload before the block is downloaded. So we might need to retry up to 1 second or retry like five times or something. That's part of the logic that we need to demo and kind of harden a little bit.
00:29:20.870 - 00:30:24.440, Speaker E: The fourth point here is that the time to save payloads is the real critical metric because it's eligible, it's not available. Kind of reiterating the same point. Our test builder that we've been running this with, we've seen that they can get demoted just from the timeout. So what this means is there's kind of a new demodable event where if the full payload isn't received in time or like whatever, there's some networking issue, blah blah, blah that is actually demodable because now we can't publish the get payload response at all because we don't have it. And I think this kind of leads nicely into my .6, which is that the V two failure mode is actually way worse than the V One failure mode. So this was coming up when we were talking about different demotions that are happening in V One, and most of the time a demotion in V One isn't actually that big of a deal because very likely, if the demotion was just from a timeout or something, even if the block ended up winning the auction, it was probably valid.
00:30:24.440 - 00:31:33.644, Speaker E: However, the V Two failure mode is like, we didn't actually receive the block, so it's like guaranteed we're going to miss the slot if someone signs that header. So I think we're approaching this with a lot more caution because the situation, even if the builder wasn't intentionally misbehaving, if there's a network issue that will guarantee a missed slot, which is not ideal. A few ideas that this kind of brought to mind for me was like, maybe we should just go straight to builderside. Publishing this is maybe a little more controversial because it takes away some of the power from the relay and it makes it so that the relay wouldn't have access to the contents of the block ever. But the idea here would be that the builders just send the headers to the relay. The relay still executes the auction, but it doesn't download the payload and then the winning bid, the relay sends a request to the builder to tell the builder to publish the block and the builder is responsible for getting it published in time. The relays would still hold collateral and say like, hey, we told the builder to publish the block on time.
00:31:33.644 - 00:32:42.352, Speaker E: They didn't get it published on time, so they either have to refund the proposal or we slash their collateral. But that's kind of the idea. I think in some ways this is a little less brittle because we don't have this intermediate state of bids, but in other ways it's kind of changing the data model more because the relay won't have the full payload and the relay won't be able to return the payload to the validator when they call get payload. Another idea to kind of harden this would be we could have an early cut off for V Two submissions. So we could say like V Two submissions have to arrive before T equals two into the slot because we're worried about this delta between when the bid is available and when it's eligible. I'm not sure this is the right approach either because then it just kind of moves the latency games slightly earlier, but it could potentially cover for the networking latency issues. And then the third thing I'm just kind of throwing out there is we could have some stricter qualification for V Two optimistic relaying.
00:32:42.352 - 00:33:20.784, Speaker E: For V one. We basically said anyone who sends us one ETH, we'll let them do it. And that's been great. We have a ton of builders running optimistic, but we could have some stricter performance requirements. Like we monitor the average time to download the block from builders and we say that your P 99 or your P nine nine has to be within 1 second for 24 hours in order for us to activate you for V Two. So these are just kind of some ideas to make V Two safer. We haven't activated it in prod yet.
00:33:20.784 - 00:33:37.700, Speaker E: These are all just tests where we're kind of like simulating it, but all the code is written it's in that PR and yeah, I think that's kind of what I wanted to say. Happy to continue discussion here and offline too. Yeah. Chris.
00:33:39.580 - 00:34:06.370, Speaker C: Thank you. This was a really interesting overview and very nuanced summary of the different perspectives. My understanding was that the performance improvements by header on the parsing is in itself only like on the order of microseconds. So like zero one five milliseconds. How does that impact the missed slot chance that much? Why is the overall latency lower?
00:34:08.740 - 00:34:31.764, Speaker E: So the decode time without header only parsing ranges from ten milliseconds up to like 100 to 200 milliseconds. And if we do header only parsing, then we cut that down to around 50 microseconds. So that's like the two orders of magnitude in the lower bounds that I was okay.
00:34:31.802 - 00:34:33.670, Speaker C: Yeah, I see.
00:34:34.300 - 00:34:50.856, Speaker E: If you look at the actual total durations, like you were talking earlier about how the total duration might be like 200 milliseconds now for a good block, if 100 milliseconds of that are the simulation then probably the other 100 milliseconds are from the decode.
00:34:51.048 - 00:34:53.256, Speaker C: No, they are mostly redis otherwise.
00:34:53.448 - 00:34:54.190, Speaker B: Really?
00:34:55.200 - 00:35:00.304, Speaker E: Do you see what the decode is? Is it usually like ten milliseconds or what is it on your end?
00:35:00.502 - 00:35:12.308, Speaker C: I can look into data. I don't have a link right now. Maybe I can get something up because we do log the decode time. So it should be pretty easy to find it out in a few minutes.
00:35:12.474 - 00:35:32.440, Speaker E: Yeah, I guess as the redis. Stuff gets optimized more, though. Basically, the bottleneck becomes the decode. At least that's what we saw in our data. So it does shave off another important set of milliseconds.
00:35:33.180 - 00:35:53.170, Speaker C: Okay, I understand. But in a more optimistic case, let's say decoding takes only, like, ten milliseconds on average, so you kind of save ten milliseconds of the overall flow. Is it worth the added complexity on both the code and the wider implications with higher misplots chances? And are these ten milliseconds worth this type of change?
00:35:54.740 - 00:36:04.080, Speaker B: I mean, Mike, would it be fair to say it's not about the decoding, it's about the downloading of the block? The downloading itself can take hundreds of milliseconds.
00:36:04.240 - 00:36:14.712, Speaker E: Yeah. Well, when we talk about decode time in the context of V One, we mean download and then parse, basically. So I think we're talking about the same thing.
00:36:14.766 - 00:36:15.848, Speaker C: Yeah, I see.
00:36:15.934 - 00:36:37.730, Speaker E: It's just the long tail is long, basically. That's the problem. On average, we might only save ten milliseconds, but for some blocks, we might save like, 100 to 200 milliseconds. And those are the ones that would really benefit from V Two parsing. But those are the ones that are also, I guess, higher risk for missed slot candidates, if that makes sense.
00:36:38.180 - 00:36:43.232, Speaker B: But the reason why the average was so low is because R Sync is located with us.
00:36:43.286 - 00:36:43.696, Speaker E: Right.
00:36:43.798 - 00:36:48.752, Speaker B: But many builders are not colocated and so they'll have a much larger decode time.
00:36:48.806 - 00:37:02.180, Speaker E: No? Yeah, I think 100 milliseconds is what I haven't looked at the aggregate data in a while because we've mostly been focused on Rsync and they're pretty well colocated. But, yeah, I think 100 milliseconds is what we saw generally.
00:37:02.260 - 00:37:08.520, Speaker C: For also creates another incentive for colocation. Right. Which is like one way of centralization.
00:37:08.860 - 00:37:23.944, Speaker E: Well, it kind of decreases the need for colocation. Right. Because if you just have to get one packet there, then in some ways the download speed is no longer the bottleneck.
00:37:23.992 - 00:37:35.328, Speaker C: Like the bottleneck of the risk for builders decreases when they are colocated much more in V Two submissions than in V One, because in V One, either they make it or they don't. But in V Two, there's this large gap in between.
00:37:35.494 - 00:37:37.312, Speaker E: Yeah. The risk is high.
00:37:37.366 - 00:37:43.190, Speaker C: Location is forced towards collocation here. I do think there is.
00:37:44.680 - 00:37:48.900, Speaker E: I guess the question is, is there already a strong colocation force?
00:37:50.440 - 00:38:07.500, Speaker B: I mean, the other thing is that this is where we're heading towards with Enshrine PBS, there will be this bid pool where only the headers and then if there's some sort of Internet issue between when the proposer signs a header and when the builder is meant to release the payload, then it's tough luck on the builder.
00:38:11.280 - 00:38:22.480, Speaker E: Yeah. In terms of code complexity, I think that's one of my points that I was making, is, like, maybe we should just go straight to builder publications. I don't know. Did you have a thought on that, Chris or Justin?
00:38:26.100 - 00:38:59.500, Speaker C: I just took a quick look at the code. It's reasonably complex, it's not like totally overwhelming, but it adds like two big chunks of duplicated functionality that can be refactored over time, but it's nontrivial, I would say, and it needs to be highly maintained by optimistic relayers because Flashbots does not run this code branch then. So this leads to further operational complexity and overhead, maybe. By the way, Chris, Michael has his hand up for real long, so maybe after Mike.
00:39:01.920 - 00:39:30.730, Speaker D: Thanks, Chris. Yeah, I was wondering, Mike, if you had, in your analysis, if you had correlated those sort of long tail latency to the block size, because obviously the larger the block then the longer it's going to take to get the rest of it. And I'm wondering if this sort of plan creates an interesting new dependency with the block size.
00:39:32.140 - 00:40:35.070, Speaker E: Yeah, so it definitely is correlated to the block size. For example, the first iteration of V Two, we weren't using the SSZ encoded bids and then the headers might have been split, like they could be split over two packets if it's unlucky, and that took away basically all the benefit from the header only parsing, so it definitely is correlated to size. And this kind of does also speak to Jacob's Chat, which is that the decode will be more meaningful with 4844 and the relationship there feels very important. But if that means that the decode time is longer, then yeah, I guess potentially the time between when a bit is eligible and when it's available might even be longer. I don't have the data plotted of just like decode time against payload size. I can try and figure out if I have that in the log somewhere, but I think it's worth studying, for sure.
00:40:37.200 - 00:41:19.320, Speaker D: Yeah, I was thinking about that in terms of risk to the builder, because a small block is lower risk to the builder and a large block is higher risk, and that puts the builder in a situation where they might have a strong internet connection to the relay. They may be colocated, but if the block gets big enough, especially with some of the future changes to blocks, then is that going to create more complexity for the builder to sort of make a decision on the block that they deliver because of the increased risk of a timeout on the full block versus the header?
00:41:20.140 - 00:41:44.050, Speaker E: Yeah, just thinking ahead on that, I think the Http request has the content length thing, so maybe we could have a check for V Two that says if the block is really big, then don't do it. But yeah, these edge cases are hard to necessarily code around, I would say.
00:41:45.480 - 00:42:17.550, Speaker D: Yeah, I just had this I imagine this future world where builders start to optimize on block size due to this latency more than they do on packing the block appropriately based on gas. Because winning a smaller block might be better because you actually win it versus delivering a bigger block that has more value, but you can't win it because of the latency that it induces. So it kind of distorts the market a bit, maybe.
00:42:17.920 - 00:42:18.670, Speaker B: Yeah.
00:42:20.400 - 00:43:04.030, Speaker E: Responding to your second comment there, Jacob, initially we're talking about censorship resistance as some kind of nice benefit of this, but it kind of can immediately be defeated by if a relay just still wants to censor. With optimistic, they can just say like, another demodable builder event is publishing a block that touches an OFAC band transaction and then slash the builder for that too. So even though the relay would end up publishing one OFAC block, they would never publish another one because they would not let that builder submit anymore. So the censorship resistance capabilities of optimistic relaying aren't like the guarantees don't feel that strong to me.
00:43:05.680 - 00:43:07.150, Speaker A: Gotcha that makes sense.
00:43:14.180 - 00:43:28.804, Speaker E: Reading Lucas's message here. Yeah. I think colocations generally regarded as not great, but seems kind of inevitable, especially with relays. Yeah.
00:43:28.842 - 00:44:09.220, Speaker A: But should we actually do that on the cost of entire network integrity? I would prefer to have network integrity and Ethereum working regardless of natural disasters, wars, et cetera, et cetera, and not have mev at the same time. This kind of trumps the idea that this impact of that should be a bit more like mev is not something that I would trade for network integrity personally.
00:44:09.560 - 00:44:30.890, Speaker E: Well, I guess I don't see how optimistic V Two necessarily changes this significantly because the most that could happen is 20 missed slots, one from each builder. It just doesn't seem like V Two moves the needle on that compared to just having relays in general, I would say.
00:44:32.380 - 00:44:58.900, Speaker A: Yeah, I mean, that was my general comments to everything that we're talking about here because I've heard that mev and yes, it drives Collocations, et cetera, et cetera, and it's actually true. But at the same time, I think that network integrity is something that we should also think about, especially if suddenly everyone decides to run their nodes in EWS and EWS will actually own Ethereum.
00:45:01.400 - 00:45:26.970, Speaker E: Yeah, I guess one nice thing is there's like this relay circuit breaker thing, so the clients implement, they stop using the relays if there's a lot of missed slots. I don't remember the exact criterion, but yeah, I think there is some protection against it in general, but overall latency games definitely are centralizing.
00:45:49.560 - 00:46:00.010, Speaker A: Okay, so sounds like there's still some open questions. Do you feel like you have enough direction, Mike, to move ahead with what you want to do here?
00:46:00.940 - 00:46:38.210, Speaker E: Yeah, I mean, the point of this presentation was kind of just get everyone up to speed and kind of solicit opinions. Generally the code is all open source and I'll probably talk with Chris a little bit about it over the coming days and yeah, if anyone has anything to add, definitely jump in. Otherwise we'll probably keep running tests and eventually turn it on. Okay.
00:46:41.440 - 00:47:06.310, Speaker C: For the record, I just think that I see the appeal or to shave off ten to 50 more milliseconds. I am not convinced that at the current time it's worth the trade off of the additional complexity everywhere. I just want to record that I'm open to further discussions, but just saying.
00:47:13.530 - 00:47:38.170, Speaker B: Yeah, I think that's fair. I mean you did mention that there is this opportunity to refactor some of the code because it's mostly just duplicated code with a few of the checks, the pre checks that are removed, as I understand. And so maybe there is a PR that could be done which significantly reduces the maintenance burden.
00:47:42.850 - 00:48:03.800, Speaker C: That could be, yeah, sure. One part of the plan, I think for me it's most clarity about the incentives this creates, whether this is acceptable, additional incentives to collocate. Maybe it is. I just want to think a little bit more before making up my mind on this.
00:48:08.250 - 00:48:42.138, Speaker B: Yeah, that's fair. I think we'll move slowly, we'll be conservative, we'll do lots of tests. But I think my intuition is it actually removes the incentives for colocation because as Mike said, you don't need a fat pipe between the builder and the relay. And the reason is that the only thing you need to communicate is 1000 bytes. Whereas if you need to be communicating very large blocks, especially after 4844, then you want to want a ten gigabit connection colocated. Anything other than that is going to be non competitive.
00:48:42.314 - 00:49:03.266, Speaker C: But I think it's on the contrary because in V two, if you take too long to deliver the payload you have a massively increased risk of missed slots versus in V one you have a general incentive to get blocks there fast. But there is not this additional risk which is like very real straight stay motion and losing your collateral if you go too slow.
00:49:03.378 - 00:49:03.654, Speaker A: Right.
00:49:03.692 - 00:49:10.650, Speaker C: Like this is a much stronger force towards collocating, I think, at least intuitively.
00:49:13.150 - 00:49:18.970, Speaker B: Right. You're right. There's a trade off. There's these two conflicting forces and we need to study it forever.
00:49:29.160 - 00:49:29.620, Speaker E: Okay.
00:49:29.690 - 00:49:56.510, Speaker A: So yeah, looking forward to further research here and please keep everyone updated. As that evolves there's a sort of meddling of more open ended or more miscellaneous questions. Were there any closing thoughts on optimistic relaying or anything we've talked about so far? Otherwise we'll kind of move into the next portion of the call.
00:49:58.800 - 00:50:18.370, Speaker C: I have one closing call I totally forgot to shout out blocksroute and also ben from blocksroute particularly for working more in the open and giving a couple of ideas for just cross pollinating improvement ideas for the relay. It's really great also seeing you guys work more in the open now.
00:50:25.460 - 00:50:26.016, Speaker E: Great.
00:50:26.118 - 00:50:26.864, Speaker C: Yeah, definitely.
00:50:26.902 - 00:51:45.940, Speaker A: It's good to see collaboration with the relays. Okay, so we'll move on to the next section. So there's a few here that Chris brought up and yeah, maybe we'll just kind of go through them. They're all kind of unrelated so we'll just kind of go in turn, the first one was considering this change in web boost to essentially have the Get payload call go to all relays rather than just the relays that serve the winning bed. And the reason we wanted this is I think we saw some issues with some miss slots where basically for whatever reason if those sort of winning relay can't return the payload in time then the Medboos client gets kind of upset and ultimately leads to a mislap. So the suggestion is instead to say okay, maybe other relays that maybe didn't win the auction but could still have that block why not give them a chance for data availability as well? And so that's what the suggestion is. Has anyone had time to consider this? Do they feel strongly we should do it or should not do it?
00:51:49.510 - 00:52:02.518, Speaker D: How do we identify sorry, how do we identify win Attribution to the relay if it might be delivered by a different relay than one?
00:52:02.684 - 00:52:33.060, Speaker C: I think it would be just the same as it is now that multiple relays can be the winner because from their point of view dr already because they delivered a block by the proposal call. For instance, on really scan IO the number of included blocks is much higher than the total number of blocks on a day because it just overcounts. Because you cannot attribute a single slot to a single relay it can always have multiple winners. So I don't think this would actually change that, would it?
00:52:34.150 - 00:52:39.570, Speaker A: When would you record the Get payload then, into the Data API?
00:52:40.870 - 00:53:05.290, Speaker C: I mean, currently all of them do every relay that delivers a payload which currently already is usually two or three relays. Like there's high overlap between flashboards agnostic blocks, route, ultrasound. Usually it's free relays very often that have this in the Data API and that believe for a good reason that they delivered a payload which I think is fair. I think there doesn't need to be a single Attributable relay.
00:53:06.270 - 00:53:33.810, Speaker A: Yeah, but if you get the header from, let's say, relay A and then suddenly you request only the relay B that also had that dog, how would you know that the relay A actually served? That as I understand, the win rates are actually by the Get payloads and not necessarily by the block submissions.
00:53:36.870 - 00:54:06.938, Speaker C: I don't quite understand what you mean. I explanation MAV boost currently concurrently tries at all the relays that serve the speed and the first relay that responds will be then the others will be canceled and the block sent to the proposer the Silk client. But still all relays receive the request and prepare the response and probably send the response already on the way. Why would you need to attribute a single relay as a winner?
00:54:07.114 - 00:54:26.450, Speaker A: Yeah, I'm just asking because maybe there is a lack of my understanding here. So relay scan operates on which part of the Data API the submission block submitted or the payload returned?
00:54:28.870 - 00:54:38.060, Speaker E: If they returned the Get payload, then they had to have the block submission. That's the point. Like if they responded with the full payload, that means the builder sent it to them too.
00:54:39.550 - 00:54:54.106, Speaker A: Yes, but right now we're talking about the slightly different scenario when you may get header from relay A and ask only relay B, let's say, right, maybe I'm not getting that.
00:54:54.208 - 00:55:19.720, Speaker C: No, let's say you have relay A and B, and relay serves speed with one if and relay B serve speed with two if. Currently, Mafboost only sends Get payload to relay B, and the proposal is to send it also to relay A and relay B because in the meantime, relay A could also have received the payload and could have it now even if it didn't serve the bid. So the proposal is just sent to all of them.
00:55:23.210 - 00:55:46.202, Speaker B: Yeah, but Chris, this have a significant impact on the statistics. Imagine a Builder is connected to every relay, then more likely than not, every relay is going to think that they won. Whereas currently it's about winning the Get header race. Whereas with this change, it's about just winning the submission race. Which relay?
00:55:46.266 - 00:55:46.880, Speaker A: Yes.
00:55:47.650 - 00:56:28.650, Speaker C: I think the question is, what is a notion of winning? Because right now, only the relay and the proposal knows that when Get header was actually only the proposer knows this. Like tools like Reliscan or the Data API, they do not expose who was actually the winning Get header response. Get header calls are not signed, so they really doesn't even know which Get header call was from the proposal. So the game is won with Get header, but realists only know if Get payload was called for them. Really? That is what they can expose in the Data API.
00:56:33.080 - 00:56:48.360, Speaker B: Right, but with the current setup where we assume the relays are being honest and reporting the data, then the signed Get payload request our proxy for when you won the Get header race.
00:56:56.920 - 00:57:04.650, Speaker C: Yeah, possibly. What's the point? Why do you want to attribute a winner? Like, what's the use of that?
00:57:07.180 - 00:57:10.760, Speaker B: I don't know. I guess it's a vanity metric to an extent.
00:57:13.980 - 00:57:30.850, Speaker A: Right, so I think the suggestion was to help availability and by extension, security. So this seems more like, can we make Medboost more secure? And then if there's something with the APIs we can adjust, we can do so I don't really see that being a fundamental blocker here.
00:57:34.420 - 00:57:50.870, Speaker F: Today. As a relay, you could just spoof that you delivered a payload. If you knew that you had the block hash, you saw the payload was delivered, you could track that. That was a delivered payload already. Even if you didn't have the block hash, you could just see that another relay has a delivered payload and just say you did it too.
00:57:57.340 - 00:58:06.220, Speaker G: Would this be an incentive for Validators to connect to more relays? Because it would increase redundancy and reduce missed slots in the scenario?
00:58:09.520 - 00:58:37.220, Speaker B: I think there's two types of connections that the proposers can have. I think it's net beneficial for them to connect to every single relay. Forget payload, but for Get header that's a different story. They should only connect to those that they trust. So there could be an advanced version of mefboost where you have two lists of relays, one for Get header that are trusted and one for Get payload which are not trusted.
00:58:42.150 - 00:58:44.034, Speaker G: That seems a bit of have your.
00:58:44.072 - 00:58:46.600, Speaker E: Cake and eat it too just food for thought.
00:58:49.130 - 00:58:50.630, Speaker A: From whose perspective?
00:58:52.090 - 00:58:54.758, Speaker G: Look, we don't like Block native for whatever reason.
00:58:54.924 - 00:58:56.086, Speaker E: Screw you guys.
00:58:56.268 - 00:58:59.660, Speaker G: Oh, but we're in a bind. Hey block native, come save us.
00:59:03.230 - 00:59:20.714, Speaker A: Yeah, I don't really follow as in I don't think that's the right way to look at it because in that case it's like relays are just helping this security of the network. It's not like I don't know, I mean like relays if you're worried about that as a relay operator you could also just ignore these requests.
00:59:20.762 - 00:59:23.006, Speaker E: Right? Yeah.
00:59:23.108 - 00:59:36.600, Speaker G: Again, we want to make sure that the ecosystem is resilient as possible but it creates very weird incentives and very weird optics about who's perceived to be important and who's actually doing the work.
00:59:37.130 - 00:59:44.006, Speaker C: Yeah, I would also prefer to keep it simple and proposal just choose whatever realist they want and not have like.
00:59:44.028 - 00:59:47.834, Speaker E: A two tier system that will more.
00:59:47.872 - 00:59:54.140, Speaker C: Easily also lead to some lists and some operators. I don't know, I rather keep it simple, I think.
00:59:59.070 - 01:00:18.690, Speaker A: Okay, so then the proposal would be there's the one list of configuration of relays that you start medboost with you would call githeader for all of them and then regardless of who can serve you the winning bid, you call Get payload for all of them. That's what I'm hearing.
01:00:22.050 - 01:00:44.558, Speaker E: One thing from the relay side, this would introduce a lot of error logs because basically every the relay will very often just not have the payload and then it'll like those those already exist to some extent but it'll increase the number of those. I don't think it's a deal breaker but worth mentioning.
01:00:44.734 - 01:01:04.298, Speaker C: Yeah, that's a good point and it's also something we should look at the code base that if the check is that we do not have a bit for it then we should just not log this as an error and if we did have a bit then it should have been fine anyway. I think that should be like relatively easy to mitigate the excessive logging here.
01:01:04.464 - 01:01:11.040, Speaker A: Yeah, we've actually seen that someone started doing that yesterday already.
01:01:13.650 - 01:01:15.006, Speaker E: Doing what? Sorry?
01:01:15.188 - 01:01:31.330, Speaker A: Exactly what we've just talking about. We started receiving those errors messages since yesterday about bits that we don't have. So I think someone may just read the agenda of that meeting and tried that ourselves.
01:01:35.500 - 01:01:51.070, Speaker F: Yeah, we've also seen some validators requesting payloads that we don't have but we do see that they get delivered from another relay anyways. So any of these validators could be running a modified movie based client, but I think this is just more bringing it into the vanilla code base.
01:02:00.010 - 01:02:41.240, Speaker A: Okay, so, yeah, I mean, it sounds like we can think about this change. There might be implications for the logging and just how we think about errors on the relays. And then also we should investigate the data APIs in case there's something there and there's some downstream effect we don't want. I can move all of this forward. Seems pretty straightforward, so I'll do that and perhaps we'll have another call in a couple of weeks and circle back to this. I would imagine before anything, there'll be like a PR to my boost that people can agree to right before this is just sort of upstream. Done, everyone.
01:02:45.130 - 01:02:45.494, Speaker E: Yeah.
01:02:45.532 - 01:02:53.110, Speaker F: I think if relayers are concerned about this too, you can also track which headers you've returned. And if you didn't return a header for a requested payload.
01:02:55.050 - 01:02:55.558, Speaker E: You don't have.
01:02:55.564 - 01:02:56.950, Speaker F: To publish the payload.
01:03:05.780 - 01:03:06.144, Speaker E: Okay.
01:03:06.182 - 01:03:23.336, Speaker A: In the interest of time, I think we'll move on. There's still quite a number of things here. Maybe we can move them kind of quickly. Chris, another one that you brought up was this proposal payment methods allowing go ahead.
01:03:23.438 - 01:04:14.920, Speaker C: I will try to keep it really quick. It's about different relays implement different payment methods. Some really allow payments to the proposal by setting the proposal fee recipient to block coinbase, and some have a payment transaction at the end of the block. The flashbots really requires a payment transaction at the end of the block, but ultrasound enabled coinbase payments and some other relays work that way too. I think we are starting to consider opening up the Coinbase payments as well. In particular, for most blocks, the gas fee for the last transaction can be as much as 5% of the block value that could be captured by the proposer through a Coinbase payment. And payment transactions are only really useful if you want to take a profit.
01:04:14.920 - 01:04:29.520, Speaker C: Otherwise there is no reason to have a payment transaction. Don't know if any of the other release here have any opinions about their payment methods, but I think the flashboards really will start just allowing both ways of payments.
01:04:32.500 - 01:05:00.490, Speaker B: I think that'd be good because we'd get standardization, I guess. Another advantage of allowing payments to the coinbase is that in the case of a reorg, it protects the payment. So there are instances where the block was made public, the last transaction was made public, the block got reorganized, and then the transaction still goes through because it's unprotected, because it's a simple payment.
01:05:01.020 - 01:05:05.390, Speaker C: Yes, absolutely. We've seen that too. Like this just happens. This is not good too.
01:05:06.000 - 01:05:06.750, Speaker E: Yeah.
01:05:11.120 - 01:06:05.390, Speaker D: So on the block native side, we actually started that way. Just a little history. The first few months that we operated, we were only doing public blocks using our Memphis infrastructure. And so we did everything with coinbase, and then when we started running private blocks with mev. We had a pretty big support burden with validator pools, trying to understand whether they were getting paid because they weren't checking coinbase changes, they were only looking at the payment transaction. So I think if we were the more that this becomes sort of standard that there may be some education or tooling required to make it clear to validators that they are actually getting the value, it's just not as obvious to sort of piece that together in either scan or whatever.
01:06:09.640 - 01:06:17.750, Speaker C: Ultrasound. Justin, have you guys seen mike, have you guys seen that, like, issues with sticking pools with coinbase payments? Did you get any reports about problems?
01:06:22.580 - 01:06:29.890, Speaker B: We haven't had reports of problems, but we are aware of the possibility of a problem.
01:06:32.180 - 01:07:01.820, Speaker F: So we do coinbase payments as well. At blocksroute, we do get people who are confused where they say they see the bid is one ETH, right? But they only saw that they produced a block for say, 0.9 e, but there was an internal transaction, so they can maybe tip that transferred that extra .1 to them. So the full payout for those blocks ends up being spread across either produced blocks and internal transactions. So it can be kind of confusing to validators.
01:07:05.680 - 01:07:28.900, Speaker B: Yeah, same here. We get confusion because they don't see it as an internal payment or as a transfer. So they're just wondering. And what we do is basically we show them a screenshot of the historical balance. So if you go to Ether scan and go to ETH balance, you can graph it over time and then you can look at the delta of the balance.
01:07:36.090 - 01:07:38.360, Speaker D: There's also exactly what we've been doing.
01:07:40.330 - 01:08:19.450, Speaker F: There's also the case where they have an incoming or outgoing transaction within the same block. So showing the full balance difference doesn't reflect what the actual bid value talking. We're working with ultrasound right now about implementing that on their end. We check all transactions inside of a block during validation for those to validate that the payout is accurate with that because there's like the gas that they're using for their own transactions along with the balance leaving their wallet or going to their wallet. So those need to be considered. You can't just do a full balance difference, but it's more of an edge case and it doesn't happen often.
01:08:19.540 - 01:08:58.370, Speaker C: Well, yeah, I mean, transfers in and out. Yeah, this is an important case to consider. And right now on the ultrasound code base, I think it's just the flat balance difference. I think what should be easy to discount would be the withdrawals from the address, but you need a tracer to trace through all smart contract interactions and instead of just filtering out the transactions. But do you think you can accurately collect all incoming transactions that shouldn't be counted? Because for us, we have been thinking about that now, and it seems that you just have to count all the incoing transfers no matter what, because any of these could be from searches or bundles.
01:09:04.200 - 01:09:27.640, Speaker F: Yeah, I'll have to double check about the traces. We do modify our validator geth nodes to add on all the receipts, the from and to addresses for them while we're applying the state transitions, so we'll know how they're involved with each transaction. But I guess I'll have to double check about the traces as well for internal transactions.
01:09:28.460 - 01:09:38.210, Speaker C: All right, but we'll be good to collaborate on this together, and then we basically have a reference implementation that does exactly what it should and that everybody can implement. That would be great, I think.
01:09:39.860 - 01:09:40.668, Speaker E: Yep, agreed.
01:09:40.684 - 01:09:45.890, Speaker F: I'll share the gist I have written up right now that I sent to ultrasound to you, Chris, later today.
01:09:56.830 - 01:09:57.386, Speaker A: Amazing.
01:09:57.488 - 01:10:32.840, Speaker C: That's it, I think, for this topic. Don't want to poke up too much space. I think just one thing we are taking a look at, like early investigation is Map boost could work even without showing the bid value, maybe even to the proposer. There could be a way with zero knowledge proofs that the proposer can compare and find the highest bid without knowing the values. And this could be an interesting avenue to explore further. This was the other topic I wanted to add. I don't know if anybody has thoughts on this, but this is an idea.
01:10:33.850 - 01:11:23.110, Speaker B: Yes, this is something I mentioned in the Mev Burn post. You can use Fhe, as you said, to encrypt the bids and then compare them. So you have two input bids, both encrypted, and then you have one output bid, which is also encrypted, which is the max of the two, and you don't know which one it is. And so what we could do is we could have the relays return encrypted bids, and then locally, the proposer just runs this max function on encrypted payloads. But then we need kind of this extra step to force the decryption. And this is very natural to do with entry and PBS because you have these two steps going on, but it's less clear how to do it with mevboost.
01:11:25.290 - 01:11:27.660, Speaker A: So wait, why do we want this in the first place?
01:11:32.030 - 01:11:54.900, Speaker C: It will remove strategic biding, which is a bit part of the biding strategy that builders repo each other's data APIs and get header calls, and then they just up their own bids a little bit to outcompete the other best bid just in time. We're doing a lot of data analysis right now and are probably showing something a bit more publicly, but there's a lot of strategic bidding going on.
01:11:57.190 - 01:12:16.390, Speaker B: Another thing that you can do, which is kind of cool, is second price auctions. So if you do them in public, they're kind of completely broken. But if with Fhe, you can salvage them and they're kind of, from an auction theory standpoint, maybe better than first price auctions.
01:12:18.650 - 01:12:36.602, Speaker A: Right. I mean, this all sounds very cool. I mean, definitely, I think around. The strategic biding issue. That'd be nice to have something sooner rather than later. It'd be cool to see especially if anyone's listening and wants to work on this stuff. It'd be cool to see sort of prototypes maybe that don't involve Fhe.
01:12:36.602 - 01:13:01.160, Speaker A: My understanding is that that's not quite ready for Primetime, but I'm not quite sure from there if there's, like, maybe some PC construction or something like this where we could have these properties, where, like, let's see you at. Least want the bid values encrypted. But maybe just for simplicity, the entire bid encrypted and then have some way still run the auction in zero knowledge. That would be super cool.
01:13:07.550 - 01:13:23.300, Speaker D: So the objective then is just to prevent bid competition outside of sort of inherent block value by the sort of game that builders do of incrementing their big in order to just win out.
01:13:23.830 - 01:13:24.580, Speaker A: Right?
01:13:30.950 - 01:14:18.210, Speaker D: Is that a goal that we want to achieve? And I kind of asked that in the sense of builders are definitely operating in a way where they want to try to generate some revenue. And if they have the opportunity to build an excellent block that outperforms everyone else, then that's their opportunity also to generate a little revenue for themselves using the payment transaction. Like we talked before with builder margin. But this would make that it would be very difficult for a builder to be able to compute what kind of margin they can have because they don't know what the competitive landscape looks. So it's like a sealed auction at that point. Is that like an objective that we want to have? I'm asking openly, not no agenda.
01:14:21.030 - 01:15:53.402, Speaker B: Right? So I think the game theory is that every builder just ends up bidding the fair value from their perspective and then they make kind of the optimal reward from their perspective, which is the delta between them and the second price. So you don't need to be guessing anymore, you just get the fair profit when you do win. I guess two other advantages. One is that it will just dramatically reduce the amount of bidding because right now we're getting on the order of 1000 bids per slot but really we should be having just way fewer. And part of the reason why we have so many bids is because as you said, they do these micro incremental increases to these bid values which creates a lot of spam. And then the other advantage is that we wouldn't have to put so much effort necessarily in having low latency Get header stream because right now the Get header API endpoint is really heavily spammed almost by the builders. So it would make being a relay so much easier and it would also make building a builder so much easier because right now every builder needs to be aware of all the other builders.
01:15:53.402 - 01:16:03.270, Speaker B: Whereas with a sealed second price auction you can just bid independently in isolation and you know that you'll get the fair outcome.
01:16:16.940 - 01:16:31.224, Speaker D: So do you mean like a sealed second price? Do you mean that the winning builder would get the delta between that, between their bid and the I'm not quite sure how that yeah, for the builder.
01:16:31.272 - 01:16:35.710, Speaker B: The winning builder is the top bid, but they only pay the second bid value.
01:16:38.480 - 01:16:39.230, Speaker E: Okay.
01:16:42.100 - 01:17:14.250, Speaker D: Then there'll be some validator education that the winning bid that you get is not what you get. You get the second price and then there's some yes. I don't quite see how that I'm just trying to map out the changes required to do that because then would some kind of block have to be reconstructed? The second bid block would have to be delivered, but it's the content of the first block. I'm not quite sure how that works.
01:17:14.700 - 01:17:21.070, Speaker B: Right. It would have to be a hard fork in the context of yeah, got it.
01:17:24.080 - 01:17:25.150, Speaker D: Cool, thanks.
01:17:37.470 - 01:17:47.114, Speaker C: Since you're in the last ten minutes now, maybe really funding would be one topic to still spend a little bit of time on or to get payload.
01:17:47.162 - 01:18:00.340, Speaker A: Not yeah, I'm happy to get into it. I was even thinking we just defer to the next call because I don't know if ten minutes is really enough to get into it, but yeah, let's take the ten minutes now.
01:18:03.430 - 01:18:08.870, Speaker G: Let's start it. These calls are too far apart. This is too important of an issue to delay.
01:18:11.770 - 01:18:12.182, Speaker E: Okay.
01:18:12.236 - 01:18:56.322, Speaker A: Yeah. I mean, I was thinking we even have like a funding breakout call. We could do that in the next week or two, but yeah, let's see with our ten minutes here. Yeah, I think there is a lot to say here. I mean, it's definitely a very important topic. I think there have been a lot of proposals kind of discussed here and there asynchronously yeah. I think the first starting point is just recognizing, like, yes, relays are providing this very important service and it's important for that to be acknowledged, meaning that it probably makes sense to seek public goods funding for these relays and yeah.
01:18:56.322 - 01:19:00.200, Speaker A: The question then, I think is how to structure that and how to go about it.
01:19:06.400 - 01:19:26.340, Speaker G: Okay. So I've been quite vocal on this point. I don't think it's anyone's surprise. I just want to make sure that we're all on the same pages. One, we are aligned that we are going to move forward with some form of funding for the relays. There's not a question of yes or no or now or later. We are all agreeing that we're going to pursue this now.
01:19:26.340 - 01:19:31.750, Speaker G: Is that a fair assumption? I see Max has a thumbs up.
01:19:33.160 - 01:19:54.780, Speaker A: Yeah, I mean, I don't see why you wouldn't there's no guarantee that again, it's like, what does this mean? It's like, do we go to different Dows and ask for grants and things? And that's a viable strategy. And then so if you do that, then there's no guarantee that capital is out there. But certainly there's no reason for that avenue not to be pursued.
01:19:56.480 - 01:20:17.330, Speaker G: I have heard murmurings there's conversations with the EF, there's conversations with Protocol Guild, there's other entities that are interested, but I haven't heard anything concrete that says this group is willing to do this thing. Does anybody have anything like that? Are there even conversations? I have personally not pursued this at all. We've been pursuing other stuff.
01:20:18.900 - 01:21:06.956, Speaker A: Yeah, I mean, I don't think the EF would directly be involved. And also the Protocol Guild is not really set up to hand out grants like that either. The Protocol Guild could be an inspiration for what this looks like. But yeah, I mean, part of it is like, this is just kind of a big there's like a huge design space here and so a lot of different things could happen. Personally, I think keeping something very focused is very important in terms of it just being successful. So then I'd rather think about more of this grant route and just be really targeted with grant funding and trying to connect Relays with the right people who can supply funding in lieu of some much bigger Protocol Guild style structure. Chris, you had your hand up briefly.
01:21:06.956 - 01:21:08.992, Speaker A: Do you have something to say or was that unrelated?
01:21:09.056 - 01:22:09.560, Speaker C: Yeah, I think these were all good points at Flashbuds. We have been a little bit quiet on this topic because we are also working on thinking through Relay funding. We are pro release, finding ways to finance themselves. We are working on a broader funding vehicle, as explained before in certain conversations too. I think we will have some proposal ready around EFCC and we'll host a roundtable there where there will be a more concrete proposal how a broader funding vehicle could look like, how it could get funded, and how it might work on also funding, really operations in addition to research and development on a bunch of different fronts. Yeah, I'm not sure this answers like, any questions right now, but just the perspective of what Flashbot is up to here while we have been relatively quiet on this topic.
01:22:16.310 - 01:22:19.906, Speaker E: Okay, one, I'm happy to hear that.
01:22:19.928 - 01:23:16.546, Speaker G: Two, I'll reach out to you one on one to see if there's a little more we could learn there. To me, there's sort of two very obvious pathways. One is we pass the hat and try to get grants, but I think we've heard well, the two obvious sources aren't that interested, even though we quite clearly are critical to the orderly operation of the chain. Being out of protocol again, it feels like we're in this bizarre never neverland. And so there's path A, which feels better but is highly indeterminate, or path B, which is, hey, we're handling all this value, the validators receive all the benefit, and we not only incur the cost and the sort of mental overhead, but we're expected to refund on the slots. So it's like 100% risk 0% reward versus 100% reward 0%. That's not an aligned economic incentive.
01:23:16.546 - 01:24:01.570, Speaker G: And I've heard the arguments which are well, on a long enough timeline. The game theoretic outcome is the relays. If they get some piece of the validator action they just give it back. But I don't really subscribe to that line of reasoning because this is not an ideal scenario. There's just a few relay operators, we're all here on this call and there's a limited timeline for all of this because EPBs is coming. And so the long term game theoretic outcome I would say is highly improbable in this scenario. And so the second way we could pursue this would be hey look, there's some slice of value that the relays themselves capture as a result of the benefit that they're delivering to their primary customer set of validators.
01:24:01.570 - 01:24:55.850, Speaker G: And we all know by the way, in this ecosystem, the entire block building ecosystem is sort of economically broken. The only piece elements that make money in this really are the trader searchers and the validators. Everybody in the middle basically has really crappy economics and those builders that are making money are basically trader searcher, vertically integrated. So the actual state of the market is to incentivize vertical integration which is kind of the whole thing we're trying to avoid. And so this is an attempt or this proposal, this suggestion is an attempt to counteract in an admittedly sort of a coarse fashion but it doesn't need to be perfect given the current state of the market. So again, we've talked about this but I feel like there are two avenues that we should be pursuing. One is grants, the other is performance based.
01:25:00.340 - 01:25:07.284, Speaker A: What exactly do you mean performance based? Like having realistic cut of the block value?
01:25:07.482 - 01:25:07.940, Speaker E: Yeah.
01:25:08.010 - 01:25:18.120, Speaker G: The simplest thing would be 1% of block value goes to the relay guild. Then the relay guild basically redistributes that on an equitable prorata basis to the relay operators.
01:25:21.110 - 01:25:21.860, Speaker E: Okay.
01:25:25.910 - 01:25:33.458, Speaker G: And by the way, the justification for this is just look at rated network and you say relay handled bids are three to 400% more valuable than vanilla.
01:25:33.474 - 01:25:33.826, Speaker D: Bids.
01:25:33.858 - 01:25:48.134, Speaker G: Bids. So hey, the validators still have plenty of value. And the idea by the way, the 1%, it's an arbitrary figure, is intended to be a small enough slice that the validators are not incentivized to then subvert the relay network.
01:25:48.182 - 01:25:48.394, Speaker D: Right.
01:25:48.432 - 01:25:53.310, Speaker G: Like, hey, we don't really like having to pay this fee but it's way cheaper than if we try to do this ourselves.
01:25:54.050 - 01:26:03.440, Speaker A: Sure. Are you worried about relays defecting? Because basically we're saying we're going to unionize and then someone could just sidestep this.
01:26:03.830 - 01:26:32.218, Speaker G: Well absolutely, I mean they have free will, right? But again, the economics are such that they're disincentivized to do so. So the converse is hey look, you guys do all this work for us for free or we're going to go elsewhere. You're like, fine, go elsewhere. We don't get any value for this. And again the thesis of all of this is to disincentivize vertical integration and that vertical integration is already becoming enshrined in this model. Right. So these theoretical downsides again, I don't really understand.
01:26:32.304 - 01:26:33.670, Speaker E: Like, oh gosh.
01:26:33.750 - 01:26:38.220, Speaker G: So staking pool X decides to do Y like okay, fine.
01:26:42.950 - 01:26:45.522, Speaker A: Okay, you can hear my for a oh, sorry.
01:26:45.576 - 01:26:47.206, Speaker G: Go justin, I might mean to talk.
01:26:47.228 - 01:26:50.680, Speaker A: Over to I didn't mean to cut you was just I thought you were.
01:26:54.730 - 01:27:25.700, Speaker B: I mean I agree. There's these two experiments that we can do. They could both fail what could succeed or both could succeed. And it's worth trying both in parallel. On the first experiment where we basically just ask for donations, there has been some amount of success. So Nounsdao just made this proposal to give the ultrasound relay 100 E. The proposal hasn't passed yet, but it's expected to pass in the following hours or days.
01:27:25.700 - 01:28:05.982, Speaker B: Huge thank you to the Nalsdao for doing this, but I think if we were to set up some sort of relay guild, they'd be maybe willing to make a larger donation. I also know that the optimism retroactive public goods funding was very successful. We're talking about tens of millions of dollars and there were some large recipients for that. And the relay guild could be successful in terms of the 1% kind of flat fee that we impose. I agree. It's unionizing. It's like the relay as a cabal kind of all need to do this.
01:28:05.982 - 01:28:25.990, Speaker B: And if one of us defects, then it doesn't really work. And I think, partially speaking on behalf of the ultrasound relay team, we'd be happy to at least try out the experiment and not defect, at least not at the beginning.
01:28:36.040 - 01:28:37.990, Speaker A: And T, you had your hand up.
01:28:40.520 - 01:28:42.996, Speaker H: Hey, it's Tina from Flashbots here.
01:28:43.098 - 01:28:43.990, Speaker A: Hi friends.
01:28:44.940 - 01:29:34.260, Speaker H: So yeah, I definitely want to say that take off my flashpots hat. I think that public goods funding. And actually, I think all of the efforts that has been put into public goods funding, all of the great experiments we will fail if we couldn't even figure out a way to how to fund really great work into relay into the actual necessary operational component like that to maintain until we get to EPBs. And that said, I want to be kind of constructive here because I see there are essentially two approaches that can be run in parallel, but there may be certain dependencies. So the grants approach is no strings attached. Sorry. There is no downside.
01:29:34.260 - 01:30:31.092, Speaker H: We can already do it today. It's about us banding together and it's not in the form of a cartel but in the form of a shared vision and a shared interest for what we believe in. And I think everyone here is here for a reason and doing what we're doing for a reason. And second, which is experiments, really fun economic experiments. I think the entire MEB space is a sandbox for mechanism design experiments. So I think I'm all for it. That said, putting back on my flashbox hat as a research organization, one of the things that I think we would like to bring forth is more community involvement in actually providing the measurable outcome accountability to these experiments and reason through through sound research.
01:30:31.092 - 01:32:42.020, Speaker H: There are quite a few of researchers who've been doing great work on TBS simulation and there should be more and much, much more. So this way on these polls or in the various forums, we will be showing our stats, we'll be showing let the data speak and we will be reasoning not only based on intuition and this way it can provide an actually more positive feedback loop for us to either the former path, which is the grant's approach. We could actually establish benchmark and let the various community who are experimenting on retroactive public goods mechanism and they would love to have us to be able to be beneficiary from this, but we can also put something more meaningful in front of the community in terms of okay, so how do we evaluate what is a good design versus what is suboptimal? That's the whole point of experiment and that's the whole point of research. So to I guess sum up my rent here is that I think the urgency is here. I think that from the flashbust point of view, we would like to bring together more of a research focused and data driven approach to this effort such that whether it's the grant effort or the experiment economic experiment effort can be sustainable and we could have something more, I would say, meaningful to chew on and be, I think, a support for all the great work that the EF research team, the new formed Arc group and the super always super busy barnaby's Rig. We want to be able to be complementary to all of those effort. So yeah, maybe let's get together at East CC.
01:32:42.020 - 01:33:13.500, Speaker H: Happy to host all of you at our Hacker Health and let's jam on this idea in person for coming. And if there is in between, there is a call specific on relay funding. Happy to share more thoughts on how to make this results oriented and can actually provide sustainability and a positive feedback loop between community oriented research and development of this middleware.
01:33:20.860 - 01:33:48.780, Speaker A: Yeah, thanks, that was really nice. Yeah, definitely. I think some of us will be at ACC so we can continue the conversation there. But that's not the only place these conversations will be happening. I think certainly in the meantime, we'll have plenty more conversations around the path forward here. Max, you had your hands, so yeah, if you'd like to say hi everyone, max from Asus. I appreciate we're running really short on time, so I'll try and be brief.
01:33:48.780 - 01:34:14.910, Speaker A: I agreed with almost everything that Matt said and to keep it short, I think we've reached consensus. I'm hoping we have to form a guild to relay funding. And what I'd suggest as a kind of positive action out of this is that each relay effectively elects somebody to form a kind of working group that we can continue this discussion in, in a focused way in telegram or discord and feedback to their respective teams because.
01:34:15.520 - 01:34:16.396, Speaker G: There'S going to be quite a bit.
01:34:16.418 - 01:34:20.620, Speaker A: Of organization to get it going. I'm happy to be involved.
01:34:25.780 - 01:34:27.010, Speaker E: Okay, great.
01:34:36.490 - 01:35:25.400, Speaker A: So yeah, I do think there's a lot more to say. I think we're just getting started. Thank you everyone for your thoughts. So far, it sounds like we have two very concrete, promising directions to at least further sort of spec out and consider. One being just more of like this Grant's arm and then the other idea being some sort of like I'll call it like a protocol Guild style situation where the expectation is that somehow there's contribution from the validators back into this thing to recognize the value relays provide. So yeah, I mean there's a lot of really compelling ideas and I think to the extent that we can, we should explore them all in parallel. We are over time.
01:35:25.400 - 01:35:28.760, Speaker A: So I'll say that.
01:35:30.970 - 01:35:31.686, Speaker E: Perhaps the best.
01:35:31.708 - 01:36:06.020, Speaker A: Way forward now so we can definitely have another call to talk about funding if we'd like and it can happen soon. So that's not really a blocker. So if someone would like that, please speak up or let me know some other way. I'm happy to schedule another call and yeah, otherwise anything else anyone sees, I don't know exactly where to go from here, especially given the fact that we're over time and I don't want to take up any more of anyone's time than we need to right now.
01:36:07.110 - 01:36:14.514, Speaker C: Thank you Alex, for setting up the community call and keep this going and for the moderation, appreciate it a lot.
01:36:14.712 - 01:36:15.074, Speaker E: Yeah.
01:36:15.112 - 01:36:15.690, Speaker B: Thanks, Ale.
01:36:15.710 - 01:36:18.040, Speaker A: Yeah, for sure. This is the easy part.
01:36:20.410 - 01:36:21.330, Speaker G: Much appreciated.
01:36:21.410 - 01:36:22.294, Speaker E: Thank you.
01:36:22.492 - 01:36:26.070, Speaker B: And plus one on having a call dedicated to funding.
01:36:27.690 - 01:36:40.720, Speaker A: Okay, yeah, I mean what I would probably like to do then is just actually formally write down the ideas we've just been talking about and then that kind of serves as a coordination point and then we can have a call to just keep pushing things forward.
01:36:44.240 - 01:37:16.760, Speaker B: I just want to kind of make public the fact that there is also a third option to relay monetization which is basically the most competitive, the one with a latency edge over all the other relays can basically just extract value from the edge that they have. But the big downside here is that one is the race to zero and two, only one relay wins or wins most of it. So it doesn't really solve the public goods funding.
01:37:19.020 - 01:37:38.060, Speaker G: So again, my proposal here is 1%. Again, whatever the percentage goes to the Wheelay dow which I think we just agreed on, and then it gets redistributed on a prorata basis that may or may not have anything to do with win rate. So it doesn't necessarily advantage the number one or number two relay.
01:37:54.060 - 01:37:54.810, Speaker E: Okay.
01:37:55.740 - 01:38:01.144, Speaker A: Should we close the call? I think that's yes.
01:38:01.262 - 01:38:02.520, Speaker C: Yes, please.
01:38:02.670 - 01:38:22.690, Speaker A: Yeah, it's okay. Thank you, everyone, for your contributions. We're just starting this conversation. There's plenty more to say, and yeah, otherwise it'll be exciting to see developments on more immediate term things with four four four and all the changes there. So I'll see everyone soon.
01:38:24.100 - 01:38:24.668, Speaker E: Thanks, Alex.
01:38:24.684 - 01:38:25.536, Speaker C: Thanks, everyone.
01:38:25.718 - 01:38:26.736, Speaker A: Bye, everyone.
01:38:26.918 - 01:38:28.940, Speaker E: Thank you. Bye.

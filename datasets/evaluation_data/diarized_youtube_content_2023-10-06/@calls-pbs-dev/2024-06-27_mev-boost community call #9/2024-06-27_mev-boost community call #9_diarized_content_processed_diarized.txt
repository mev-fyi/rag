00:00:03.640 - 00:00:22.570, Speaker A: Great. Let me grab a link to the agenda. There we go. I put it in the zoom chat. So, yeah, hi everyone, this is Medboost community call number nine. It's been a little while since the last call, but here we are. And yeah, good to see everyone.
00:00:22.570 - 00:01:01.180, Speaker A: So, yeah, we'll go ahead and jump into it very briefly to kick us off. I was just going to discuss Electra. This is the next Ethereum hard fork schedule. And yeah, there was some initial prototyping work around the builder APIs to support the hard work. I think I mainly just wanted to call out. There will be some changes, I think, even as we're working through the different devnets, as we iterate towards what the hard work ultimately looks like we're already seeing there's some things we need to change. Nothing too crazy, but yeah, just wanted to call it out.
00:01:01.180 - 00:01:10.060, Speaker A: Next up, I think we have a bit of an announcement. Chris, did you want to say something about the relay scan bit archive?
00:01:12.080 - 00:01:57.442, Speaker B: Yeah, my pleasure. We finally got around to publishing this bit archive as part of Relayscan, which collects bits in a bunch of ways. There is a documentation link that goes into more detail, but it does, it collects bits with get header polling, data API polling and the ultrasound of bit websocket stream. And this archive is based on a nightly upload. So basically every day, I think at UTC two. Amen. I the archive from the last days uploaded, it's all data transaction hash and some metadata.
00:01:57.442 - 00:02:15.670, Speaker B: No raw transaction obviously, because the bits, they are still private. But we hope that this facilitates more exploration and data analysis. And we have heard that this would have already been useful to a bunch of people looking into this, curious to see what's coming out of that.
00:02:19.310 - 00:03:00.108, Speaker A: Yeah, this sounds super awesome. I haven't had a chance to play with it myself, but thanks for putting it together. And yeah, I know this data is definitely super valuable, so hopefully. Yeah, let's do some really cool analyses. Great. Next up, there was a disclosure, hot off the presses, that I think many of you here are aware of, but just for austerity sake, there was a underflow bug found in the med boost relay. I believe it's been patched in the required places, but yeah, just wanted to call it out.
00:03:00.108 - 00:03:08.180, Speaker A: Essentially the issue was actually. Let's see, does someone want to give a summary of the issue?
00:03:08.340 - 00:03:08.796, Speaker B: Let's see.
00:03:08.828 - 00:03:09.808, Speaker A: Shay's here.
00:03:09.964 - 00:04:09.280, Speaker C: Yeah, yeah, I'm happy to give a quick overview. Basically, ultrasound got a report from some builders that they were posting a bid value that is impossibly high. It's like more eth than exists on Ethereum or something crazy like that. Looked into it and found that that there was a bug in the reference implementation for payload validation that relays use. We actually think on reflecting a bit more, this may have been related to some upgrades from Den Kun, where we changed from using bigints to I think you went 256 and we lost some built in underflow checking. That's our hypothesis as to why it became an issue recently. But we were able to find the bug.
00:04:09.280 - 00:04:56.230, Speaker C: We posted a patch, got it audited and shipped out to all relays in a couple of hours. Unfortunately, because the builders disclosed this kind of discreetly and directly to the relays, we don't think we have any evidence that somebody exploited it. Because there is a way you might be able to use a bug like this to basically host a bid that seems really, really high, win the auction, but actually not pay the proposer very much. So we're just a shout out to the people who reported it, so we could limit the impact pretty much to just one block. There's more about it in the post on the forum, but I think that's the TLDR.
00:05:01.810 - 00:05:08.270, Speaker A: Great, thanks. Yeah. Alex, was there any color you wanted to add or did that pretty much cover it?
00:05:09.810 - 00:05:34.220, Speaker D: No, I think that covers it. Maybe the only interesting thing that I still noted in this was that we accepted a really high biddeh and it's like it was only this combination of a builder submitting an impossibly high bid and it then somehow passing simulation that alerted us to something being off. But yeah, really, like thanks for everyone involved in a quick turnaround and Shaya on the disclosure stuff.
00:05:36.800 - 00:06:08.522, Speaker A: Yeah, thanks for putting this together. It's really nice to see 1 second my cat is attacking. Okay, sorry about that. I'm back. Um, cool. Yeah, thanks for putting this together and yeah, it's nice to see the disclosure just for posterity's sake. So we see what's happening and.
00:06:08.522 - 00:06:11.030, Speaker A: Yeah, good to see.
00:06:12.250 - 00:06:21.590, Speaker D: Maybe for completeness sake, like, this can definitely be exploited. If you haven't patched, you need to immediately do it. But I think everybody is in the shared security group and everybody is aware.
00:06:22.330 - 00:06:44.276, Speaker A: Great. Yeah, definitely. If you don't know what we're talking about, please take a look. My understanding is that everyone is aware, that it needs to be aware, but at this point it's public. So there you go. Great. Usually in the past we've had time for updates around optimistic relaying.
00:06:44.276 - 00:07:10.050, Speaker A: I don't know if anyone here has anything to share there. I think it's kind of just been moving along swimmingly over the last couple months. Is there anything worth discussing? Okay, sounds like no. Great.
00:07:12.630 - 00:07:13.222, Speaker E: Yeah.
00:07:13.326 - 00:07:59.646, Speaker A: Next up, let's see, is Drew here? I don't see him. So I was going to have drew on to give an update around commitboost. I think many of you have heard of Commitboost, but if not, I'll just give like a quick tldrhiche. So essentially, it's an effort that has come up quite recently, basically, to have an extensible platform for all these different types of browser commitments, essentially. So one way to think about this is that Metboost provides this PBS protocol. There's netboost to software, there's also netboost to protocol. And so Metboost to protocol gives you a way to make commitments around, right.
00:07:59.646 - 00:08:48.640, Speaker A: You know, selling your block as a proposer builder. And we're seeing a lot of research efforts around new types of commitments. So, for example, like pre confirmations, people have talked about inclusion lists and like, all sorts of things, so that's long. Good. But you can imagine that, you know, if we have these different pre confirmation ideas, people go, they fork about boost in the limit. There's now all these forks in MetBoost, which is a huge pain to keep track of just in terms of testing and security. One idea with CommitBoost is to basically have a platform that is extensible in a way that NetBoost is currently not today, metaboos the software, and can basically serve as this foundation layer for all these different types of commitment protocols people are looking into.
00:08:48.640 - 00:09:04.810, Speaker A: So, yeah, that's quick TLDR and yeah, I guess Drew's not on the call. I don't know if anyone here wants to say anything else about Commitboost, otherwise we might just save it for a future call.
00:09:12.070 - 00:10:06.826, Speaker F: Maybe I can make a comment on the preconfirmation part real quick. As you guys know, I'd started Primev and MeV commit out of the first meeting of the Mevboost stewards call. We've oriented around being 100% compatible with mevboost, where relays are the ones doing the filtering that's required to make sure the pre confirmations are adhered to. The commit boost is a separate effort, and it seems compatible with this, and Mav commit is compatible with either. But it's not a requirement that we fork Mav boost. In fact, we have pre conformations working on the whole ski testnet for five months now without a Mavboost fork. So I just want to set that so that everybody is on the same page around MavBoost being compatible with pre conformations as is.
00:10:06.826 - 00:10:13.330, Speaker F: But we can do upgrades and do all sorts of other modules as well with something like Commitboost.
00:10:16.950 - 00:10:23.462, Speaker A: Nice. So with pre MeV, is there any changes to how proposers sign things to support the confirmations or.
00:10:23.486 - 00:10:54.720, Speaker F: No, not for Mev boost. What we've positioned relays to do is basically be able to claim or ask for a Rev share because of this filtration additional work that they're doing, which you know we have an ongoing grant proposal with the PBS Guild on and you know, hope to present some of the results of this experiment to the folks here. And I've appreciate some of the folks who have given some comments on this from this group as well.
00:10:59.460 - 00:11:16.700, Speaker A: Cool, thanks. I do know from talking to Drew who's kind of spearheading the commit boost effort, I think that they are looking to have something ready for an upcoming testnet at ECC. So yeah, we will check back in after that, see how it goes.
00:11:20.160 - 00:12:09.410, Speaker G: So I'm actually curious to see like I've been asked recently quite a lot and also at the method at city like research event there's still amongst the researchers that quite some concerns with centralizing impact of precomps. So in general, so I think I'm trying to like what is everyone's thoughts on seeing like commit boost more so of a you know modular rust implementation upgrade on the software side or like are we seeing it much more so closely related to precomps? And how does, you know, how do we think about precomps from a map boost community met boost maintainer perspective?
00:12:15.750 - 00:13:18.306, Speaker A: Yeah, I mean just to chime in, I think there's two things here. So one is like again like the software of things that's implementing these various protocols and then also there's the layer of the protocols themselves. So yeah, I mean I think there's all sorts of things people on this call in other places have like wanted to change around like the software. So I think there's like a conversation that we had there around. Okay, are there like features to boost the software we want to implement? Are there like learnings from this like a sense like extensibility, sort of framing of things that would be helpful separately? Yeah, I think it's super early with the pre conformations themselves. That's, I mean yeah, like that's my concern as well around like the centralization of things here because it does seem like all the pre conformation protocols today have this like centralized gateway node that's much like a relay. The concern then is if you have similar issues that we've seen with Netboost, the protocol sort of be reinforced with the pre conformation protocols as they come online.
00:13:18.306 - 00:13:22.240, Speaker A: So that's kind of where I'm at.
00:13:26.420 - 00:13:29.440, Speaker G: Thanks for sharing. I think that Ju just joined, right?
00:13:30.940 - 00:13:36.280, Speaker E: Yeah, an hour off in my time change. So I apologize.
00:13:37.420 - 00:13:49.770, Speaker A: It's all good. We were just talking about commit boost. I gave a quick overview. I don't know if you wanted to say anything around some of the recent progress or how you guys are thinking about next steps there.
00:13:50.350 - 00:14:41.190, Speaker E: Yeah, definitely. And I don't know who on this call doesn't, doesn't have context, so maybe I can start a bit with that. Commitboost is an effort to, as Alex was saying, you know, the idea is to create a platform for validators, to make safely make commitments. And what we're working on is a standardization effort for that and to reduce the risk of a bunch of sidecars being out there. And the idea commit boost is less about run a sidecar and more about run one sidecar and opt into these different commitments. How this interacts, because a lot of people on this call are familiar with Medboost is Metboost would be a module or an opt in option for this. Sorry, my cat is also attacking me.
00:14:41.190 - 00:15:34.534, Speaker E: Would be an opt in module as one example. So it would be a module will be enabled, 100% backwards compatibility. But then there's now this whole effort outside of Metboost, whether forks or completely different designs of new sidecars that enable things like pre comps, as an example. And this would also allow validators to opt into those things. And the idea behind cope boost is to streamline that so people like homestakers can participate in those markets and potentially delegate some of those tasks away. So no matter what we see in PBS, but also sophisticated actors not having to run five to six different sidecars, and the fragmentation and risks that can come from that. The other benefit of boost, or at least how we see it, is around hard forks and core developers.
00:15:34.534 - 00:16:36.084, Speaker E: If we can, as a community, unify behind one standard, when those hard forks take place, we're only worrying about one sort of sidecar. And the vision, longer term of commit boost is it'll be a not for profit entity that will develop open source software for Ethereum with the focus on this software, commit boost, there'll be a team of a couple people sort of dedicated to this just for sustainability. But when things go wrong, they're there for coverage, and then also they're there interacting with core devs around hard forks, all these coordination mechanisms is kind of the idea. The entity itself will be funded through grants is the mission and goal here. And there's no intentions for Commitboost, the entity to be sold or bought or start side hustles. It's purely a not for profit and helping push forward. Eric Lee sustained core parts of Ethereum infrastructure that isn't part of the protocol itself.
00:16:36.084 - 00:17:23.854, Speaker E: That's kind of the context and mission around it where we're at to date. This started just a couple months ago due to some of the things that were happening in the market and the fragmentation we started to see. We had a Devnet at Zuberlin, this was bigger than Commitboost. There were a lot of teams working on pre comps and base sequencing, but Commitboost module is used throughout that and then ECC. There's a testnet called Helder which Helder is somewhat separate from Commitboost, but we're operating within there. Helder is really a persistent testnet for all teams building in proposal commitments, base sequencing and precomps to have an iterative place to work through that. So we're or help coordinating that, but it's not specific to commit boost and then post that, we should have an mvp of commit boost.
00:17:23.854 - 00:18:26.416, Speaker E: We're going to start running this in Aleski with teams or asking teams to help us with this to start out some testing and then audited code by Nsummer. The repo is open source and I think previously at Zoo we just really had one team developing this and now we have multiple teams and should have even more before, before ACC submitting code and helping with us. And then yeah, I think longer term governance wise, still working with Alex on how best to have that happen, but really see this as something similar to ACDC where the stakeholders get on a call, or even similar to this call people get on. We talk about changes that need to be made. There's consensus and either there's a team that develops that themselves, or we can leverage the devs that sit within the commit boost entity to help with that. The idea is before ECc to also have somewhat of a roadmap towards what the initial governance structure would look like for that and gather feedback and get others to provide insight based on what we've learned in the past. So pause there.
00:18:26.416 - 00:18:44.400, Speaker E: Hopefully that gives some context on where we're at, what it is, the mission and some of the risks we're trying to mitigate. Or at least we see this as a solution to mitigate that. Thanks, Alex, for the opportunity to come on and shock and. Sorry again, I was late, everyone just off an hour, so.
00:18:47.060 - 00:19:20.326, Speaker A: It'S all good. Yeah, thanks for your update. Yeah, I mean, what I like the most is just reducing fragmentation. Like you called out again, even just now we have this disclosure about this bug and the validation node. And imagine if there's like 20 pre confirmation protocols now there's like 20 times overhead in terms of tracking bugs and disclosures and all of this thing. So, you know, I greatly prefer a world where there's like one sort of middleware sidecar software that we all standardize around. Yeah.
00:19:20.326 - 00:19:30.900, Speaker A: If that then leads to new experimentation with all these different reconfirmation ideas or inclusion list ideas or things like that, that's also super cool. Yeah.
00:19:35.160 - 00:19:51.140, Speaker B: Chris, I was curious if there is some documentation out there already about these like proposal signature collection and like penalties for breaking their commitments.
00:19:54.770 - 00:20:38.690, Speaker E: Yeah, I think there's teams that have developed docs around this. Commit boost is somewhat agnostic to these things. That is all we're trying to do is standardize how a signature is requested. What people do with that signature is somewhat, I'll say up to the precomp teams building their protocols and how that's handled. Mip boost doesn't limit, for instance, the platforms that are used, which I guess is good and bad. So you could use slashing mechanisms via eigen layer, you could use slashing mechanisms being symbiotic, or you could use cryptographic, or maybe you could run this through swab, things like that. So there isn't opinions about the slashing mechanisms that commitboost is making or enforcing on the market.
00:20:38.690 - 00:21:19.740, Speaker E: It's really an open design space. How signatures are provided via commit boost, that is an open question, which we probably won't even get to before ECC, but keen to engage with folks, you know, if they have ideas and we're trying to come up at least with like an initial concept that people can start reacting to and, you know, tell us we're dumb and are down the right path or down the right path, but it's. It's one of those open things that we. We still haven't largely figured out. And as you know, there's different dynamics because there's things like Dirk and web3 signer, there's some clients that don't allow for remote signing, there's teams that use proxy signatures. There's a whole host of things. And you were just still somewhat figuring that out.
00:21:21.160 - 00:21:30.656, Speaker B: Okay. Also kind of like, can we expect some write up exploring this problem space. I would be very curious to get a little bit more of a context there.
00:21:30.808 - 00:21:46.402, Speaker E: Yeah, definitely. I think that's. Yeah, we're probably not going to get there before ECC, but post that, I'm happy to have a call and go through those things. And yeah, we've started. I think we've started to put prs into the repo. People will see this. It just took us a little bit to get going.
00:21:46.402 - 00:22:21.930, Speaker E: So I think some people have been critical of the open source nature of this. It wasn't intended, it was just getting things going. But yeah, the repo is fully public and we're trying to get prs into that and track all these things and keen to get people's feedback around it. I think at ECC one will present the updated design specs for people to react to. I don't think it will have too much to do with signatures, but if it does, Chris, we can flag that to you. And in addition to the updated specs and how we're thinking about things, also talking about the governance. So we're presenting that at base sequencing day, hosted by Espresso and cake in the morning.
00:22:25.550 - 00:22:27.770, Speaker B: All right, thanks for the update.
00:22:29.630 - 00:23:18.690, Speaker F: Can we double click on this pre confirmation sidecar thing, maybe because Drew's here. It's a good opportunity. As far as I'm aware, Mev IO is on mainnet with their pre conformation thing, which again leverages relays, does not use a sidecar as I understand. Whenever we talk to validators, the only sidecar they mention is the blocks route sidecar, which is not necessarily for pre conformations. And then Mav commit also does not require a sidecar other than Mav boost. Maybe we can elaborate why sidecars required in the first place. And then like are others like blocks route, like trying to use this instead of their sidecar? Or like how should validators kind of think about this? Like this would be helpful to like, know as we're talking to them.
00:23:22.670 - 00:23:47.600, Speaker A: Yeah. So I think what would help everyone is like having an open source example of basically an integration, right? I believe there's a commitboost module for Metaboost protocol, but yeah, I haven't seen anything for one of these pre conformation projects using commitboost in this way. It sounds like it might just be a bit early. Yeah, I think that would help.
00:23:47.720 - 00:24:07.450, Speaker E: Yeah, there are a couple. GMat is probably the most popular one. It's a fork of Met boost and integrates quite a bit. It would require sidecore, I think the bolt implementation too. At least the initial one required a sidecar. They've shifted a bit. I can't speak on behalf of these teams, but I know there's at least two examples are out there.
00:24:08.470 - 00:24:13.970, Speaker F: I just pasted the docs in how we leverage Mavboost to do it so people can look at that.
00:24:15.950 - 00:25:00.040, Speaker E: Yeah, I just want to talk about too commit boost isn't just about pre comps, it's about other commitments. So even in Helder we're working with some folks in the community that have just volunteered time to work on inclusion lists, for instance. And so there will be some, ideally some home stickers kind of interacting with these modules that allow for inclusion list. Again, the inclusion list design people are using it's streamlines just to get some concepts out there to get iterating on things. And I don't think it's the end design people go with. And some of this reprioritization is just because inclusion lists aren't in the next hard fork. And so I think some people are excited to think of ways in the near term that we could potentially get some form of inclusion lists onto mainnet.
00:25:01.780 - 00:25:14.160, Speaker F: Yeah, I think running with that and the initial pitch where you guys highlighted like support for Grafana or Prometheus and stuff would make the conversations with validators easier.
00:25:14.740 - 00:26:04.440, Speaker E: Yeah, and that's so. Yeah. The focus of commit boost is both standardization to reduce fragmentation, but also a lot around giving validators the tools, particularly around telemetry. So if we can get teams to build to the standard, they then unlock a whole suite of things and we give them the standardized toolset to do things like limit cpu usage per module, just so if something goes out of whack, it doesn't crash their whole box. A lot of the data throughout the supply chain themselves will have telemetry defined, so you could build Grafana dashboard on top so they can have insight into their box. It's ideas like that, and I can't talk through personally all the technical details, but that's like a core focus too, is understanding from validators maybe what toolsets they develop, proprietary ways that they'd be willing to somewhat give insight to, so that we can build this in an open source tool that all validators can leverage.
00:26:07.940 - 00:26:39.560, Speaker D: Yeah, maybe I can add to that. I see this as how can we do responsible experimentation with what proposers are committing to, and then what is actually the things that they want to experiment is kind of like the neutral thing and what other people can come up with. And then from a relay perspective, it would be really nice to not have to worry about all these different forks and just have one standard way to deal with it and to agree on the how and to also make sure that we don't become gatekeepers for what proposers are allowed to do with their right to propose.
00:26:49.070 - 00:27:20.780, Speaker A: Yeah, I think that's an important sort of framing, like separating out this again, like foundational software layer from all these different protocols. I think even with some of the conversation I've seen in other places, these things kind of get mixed together and. Yeah, it complicates the conversation. Yeah.
00:27:22.880 - 00:28:13.730, Speaker G: Oh, I actually think that Stefan may have had a really good, interesting point, but I was going to ask in terms of, more concretely, from a map boost community perspective, like, how do we, what is the timeline and how do we think about like, forward looking technical changes, roadmap to the map boost protocol, as well as sidecars. And so I think the commit boost conversation is a great step that like, I think accelerated kind of the discourse around how do we think about the design space. So, like, maybe it's more also just hearing your thoughts, Stokes, and from everyone else, like, you know, what's been contributing to the Muppet ecosystem.
00:28:17.470 - 00:29:32.450, Speaker A: Yeah, I mean, just my take is kind of what I said a minute ago, like, I really don't want to have, you know, in different forks in that boost, having to track them all. If there's like security issues, it just becomes a mess to like track down who is, you know, relevant to fix it. How do we fix it and all of this stuff. So, yeah, I think it's like you're saying like having, having some way to avoid different fragmentation. And again, like thinking about how do we evolve this like sidecar software that we have today is super helpful and very valuable. So that I think is really exciting and, but yeah, otherwise we just have to see, I think, how these different things stack up in terms of the ways in which people want to use these different commitment protocols. Are we imagining a kind of world where a solo staker might be able to download, I don't know, like, or look at a kind of marketplace of plugins which all do different kind of proposer commitment type things and give some kind of assurance of their kind of security properties and whether they've been ordered or.
00:29:32.450 - 00:29:40.570, Speaker A: Drew, do you think commitboost would look to try and audit everything that became a plugin for commitboost?
00:29:41.910 - 00:30:13.080, Speaker E: Yeah, I don't think, I mean, I strongly feel commitboost should not be limiting modules that are added to in any way, governance over those types of things. Validators will still need to do their diligence around what they're committing to and not being the arbiter of how to police that, I think is a very bad idea. That's my personal opinion. What I very strongly believe.
00:30:15.750 - 00:31:10.070, Speaker A: Yeah, the idea of commit boost is that it is this neutral, again, foundational layer for all those different things, at least as I understand it. So that would be the way to approach it. That being said, it does open this question of module governance and it's like, ok, do validators just pick any modules from this app store and everything's good? Do we just have software hardware constraints around the modules and call it a day? I think that part's a little under specified at the moment. And yeah, having more modules to like make it more concrete I think will help there. Yeah, you can imagine there's like commit boost core maintainers, and like, they have a view on like, what are good modules and what aren't. But yeah, at least my personal approach is to be as governance minimized as possible. Yeah, I think that makes sense, Alex.
00:31:11.330 - 00:31:19.910, Speaker E: But I imagine there'd be teams, like, some of what we see in abs is, I guess I'm sure there were teams that do this analysis for validators, you know, whoever else.
00:31:25.250 - 00:32:24.836, Speaker A: Right. But then you have this question, like, does this come up in like for example, like core development with like ethereum consensus clients? It's like the clients could take more opinionated views and sometimes they do, but then it definitely takes on more risk for them and definitely constrains what's possible. So, yeah, it's tricky. Governance is always the hard part. Okay, there was a question Steph had in the chat, essentially, around using commit boost for fork coordination. This is a volcano worms, but you can imagine the limits like this is even people using stuff like, you know, a module for like a market for your, which is very dangerous. So, yeah, I hear you on this.
00:32:24.836 - 00:32:38.280, Speaker A: Um, I don't know if he had more to say on that stuff, but my response is essentially that, I hear you, but you could also for commit boost today and do the same thing. I don't think commit boost itself really changes sort of the consideration there.
00:32:38.740 - 00:33:47.970, Speaker H: I can jump on and just say a few words. Um, I remember like in the early days of mevgeth, there was kind of like this whole debit cult around reorgs because people got sort of excited about riding sidecars that would allow for minors that coordinate around doing like Reorg Mev. And then there was like a huge community wide sort of immune system response saying like, no, this is like really bad idea and, like, zero something. And, like, we shouldn't, we shouldn't do it. And so it seems like somewhat that, like, the Overton window has shifted and that people are a little bit more comfortable with validators running all kinds of different rules. And, like, the conversation here is actually like, how do we reduce the level of friction to running new sidecars to make it as seamless as possible? So there's a question of, like, how do we do it? And there's a question of, should we do it? I just wonder if there's been some discussion around this. I'm not involved enough in here to really have much of an opinion, but I assume that there's people that have explored the pros and cons of introducing this kind of software to the stack.
00:33:53.430 - 00:34:22.770, Speaker A: Yeah, I mean, I think my take is just what I said, like it. I hear you. That it, like, lowers bearish entry. Perhaps some, but it's really not that different, as I see it, to just having a fork in med boost that does the same thing. And separately, then that also ties back to the previous point around governance. Like, that's the whole point of any sort of governance around this thing is to say, okay, you know, there are some things that are bad. You know, tm, there's like a hard red line in the sand, and these things are not okay to run.
00:34:28.670 - 00:34:29.530, Speaker H: Fair enough.
00:34:31.710 - 00:34:32.570, Speaker A: Terrence?
00:34:33.950 - 00:34:54.690, Speaker I: I think it's also, like, important to separate validators, the proposals into like, different bug and tag and like category. Right. For example, you have your solo validators, which is bye. Kind of the 10%, which is what we deal with this core. They are kind of more naive. They just follow like, whatever. They kind of just chase whatever is the highest apy.
00:34:54.690 - 00:34:58.754, Speaker I: And some of them are more like altruistic. They basically rather sell build.
00:34:58.802 - 00:34:58.986, Speaker A: Right.
00:34:59.018 - 00:35:13.354, Speaker I: But they are on the other spectrum, there are more advanced validators, like Lido, for example. Right, but those have to go to the Lido governance. For example. For example, for running lido validator, I cannot even choose what relayer I can use.
00:35:13.402 - 00:35:13.754, Speaker A: Right.
00:35:13.842 - 00:35:29.410, Speaker I: I have to use a relayer. I have to opt into specific strategy. So for that, it's kind of a different beast as well. So, yeah, so we may look at it from like a deep. So I think it might be worth analyzing it from like a different perspective.
00:35:32.190 - 00:36:13.910, Speaker A: Yeah, I think that's a good analogy. Like, it's the same thing here where it's like, okay, if there are like three, four, you know, imagine a world where there's like ten different boost relays and it's kind of the same thing where like, if one relays being like, shady, somehow we kind of have settled on pushing those concerns into the social layer where we say, okay, you know, there's like some kind of policing where we say, if this relays acting bad or harmful, essentially, you know, we just tell everyone not to use them, which again, comes around to governance and all this sort of thing. So I agree. It's like an important thing to consider. I don't think commitboost itself, like, really changes the game there.
00:36:26.770 - 00:36:35.670, Speaker F: You do the same with the Mav boost forks. If somebody forked it, it's a reorg marketplace and we don't approve. Could socially shut it down, too.
00:36:38.300 - 00:37:02.000, Speaker A: Yeah, exactly. Yeah. It's the same thing where it's like, okay, if there was like a malicious med boost fork, we could all take to Twitter and be like, hey, this is bad. In the limit. You have like social slashing and all this as like a sort of ultimate or maybe like a, you know, let's say a more concrete or more sort of hard solution.
00:37:14.830 - 00:37:21.330, Speaker G: So I'm curious for the commitment contributors like Drew and Kubi and co.
00:37:28.310 - 00:37:28.694, Speaker E: Tina.
00:37:28.742 - 00:37:29.970, Speaker A: You cut out for me.
00:37:32.010 - 00:37:36.350, Speaker E: Yeah, there's more contributors than that too, now, so.
00:37:38.050 - 00:38:08.840, Speaker G: Right. Sorry, I just couldn't name all of the, like, you know, I know there's quite a few teams there, so congratulations on the growth. What would be a good, like, what would be a really great outcome from your perspective? Whether it's the commit, I would say commit boost contributors as well as the pre conf. Researcher, like, community perspective. Like, what would be like if you have a magic wand, what would be an ask for the mapboost community?
00:38:13.140 - 00:39:00.072, Speaker E: Yeah, I don't know. The precomp things, it's just a module similar to inclusion list or map boost. So while that's a kind of the first use case that has the most excitement, we expect others to be on board. So less. Less of an opinion, I guess. On the research side, for precomps with the meth boost community, I think there's been a lot of ideas over time and challenges that people have faced. And if the community's bought into this, having those people help be part of this, I think we're open to a lot of that and I think it'd be the biggest thing is just get involved, provide ideas, feedback.
00:39:00.072 - 00:39:54.908, Speaker E: If you want to sit down and code read specs. I mean, we want the feedback, so super excited about that. I think there's just been some practical things where we had the idea and now it's putting the idea into actual specs and then iterating with people across the community on that is where we're at now. Ideally in the end this has reduced fragmentation. It gives proposers a safe platform to make commitments and it doesn't cause some social drift to ruin Ethereum, I think. But an envision would be that, yeah, we're unifying across the whole Ethereum community towards a standard and allow for safe commitments to be made. Then beyond that, getting something like this into the CL, eventually things like ets happen.
00:39:54.908 - 00:40:02.360, Speaker E: It's not really relevant software anymore, but I think that's quite a way to weighs and we just have a bunch of people sprinting in the near term that we need to mitigate this risk around.
00:40:05.500 - 00:40:39.506, Speaker A: Yeah, I think that's an interesting point. You can imagine the goal commit boost is maybe the same as the gold med boost, at least on paper, which is to get rid of it. That being said, like, at least I feel like the longer we have net boost, net boost relays and the whole ecosystem, it just gets enshrined more over time. So definitely something to think through with commit boost. Is that a realistic goal? Which I think is a worthwhile goal we're striving for. But yeah, it's tricky. There are these different protocol proposals we could imagine.
00:40:39.506 - 00:41:03.240, Speaker A: I think it'll be years before we see them. And then the question is like, yeah, is this something that will actually happen? Tina.
00:41:04.980 - 00:41:23.000, Speaker G: What is thinking around timeline in terms of adoption? Because I think, is it pegged to the pre conf timeline or is it going to be more independent of it?
00:41:29.190 - 00:41:32.326, Speaker E: Sorry, I missed that. Is that a commit boost question or a Met boost question?
00:41:32.438 - 00:41:36.370, Speaker G: Sorry, commit boost question in terms of timeline.
00:41:37.550 - 00:42:26.292, Speaker E: Yeah, we're trying to have audited code by the end of the summer with this running and being fully backwards compatible. So having a Met boost plain vanilla module going so validators can day one have this running. There is some urgency because there are precomps teams pushing things and so having this as an option for validators and also coordinating across those teams, building precomp protocols to help build modules, build modules, be part of this, which we're on that active path of. But that's, I guess the goal is end of summer. These things can always slip. We are trying to do some leski testing with an MVP. It's not a final product.
00:42:26.292 - 00:43:03.370, Speaker E: There's still some core decisions that have to be made, like the signer side of things and working through that, like Chris said. And it's mostly to start gathering feedback, seeing it in real time. Is it fully backwards compatible, things like that? And I guess governance perspective. The hope is to have grants start coming in just before ACC or around ECC getting the entities stood up and really publishing a roadmap around how that will, you know how this will work. That will probably take, you know, into the end of summer too.
00:43:08.310 - 00:45:05.190, Speaker G: Right? That's exciting. So perhaps on this note, this is, I think an invitation also for everyone on this call that we are hosting by we event. More on my PBS foundation contributors head in the sense that we're hosting a salon discussion that focuses on the tech tree of like within the broader PBS EPBS AP's space as well as there's an afternoon we'll be having a discussion about auto protocol technical governance. And I think this is like, I think MetBoost was the first out of protocol development that needs to be like, I would say that's actually like closely coordinated across many different entities. And now with the various, whether it's precom for other modules that are potentially sidecars considered, I think all will have the same set of challenges in terms of the social layer and in terms of technical decision making. I'll leave it as that because I think I definitely welcome anyone who's interested in posting relevant questions on how to think about minimal technical governance that's still sound and, and has a security first outcome. So yeah, we can chat, I think for anyone who's interested in technical governance.
00:45:08.290 - 00:45:33.360, Speaker A: Cool. And there is a link to the event in the chat. Just calling that out. Okay. Yeah, thanks, Drew. Anything else on commit boost? Otherwise we will go back to the protocol.
00:45:34.820 - 00:45:41.052, Speaker E: Well, that's it. Sorry again, I was late. Glad you all got to meet my cat. It's good. Thank you for having us. Having me.
00:45:41.076 - 00:46:04.410, Speaker A: Okay. Yeah, thanks for coming on. Cool. So the next thing I had on the agenda was to discuss blobs. Let me go find the agenda. I'll drop this post here. I think people are aware there was some turbulence in the blobfeed market.
00:46:04.410 - 00:46:44.100, Speaker A: I think last week I was actually on holiday, so I kind of missed exactly what happened. But I've been catching up and I. Yeah, it sounds like basically, I think there are a number of things just around l two s and blob consumers being immature, possibly now questions of like, do l one clients handle bulbs in like the most optimal way for the people here today. I did want to talk about like how this impacts the MEP supply chain. So, you know. Yeah, first of all, I'll just call out this link that I dropped in the chat. I think there's a pretty good summary here, again from Shaydeh.
00:46:44.100 - 00:47:09.060, Speaker A: And, yeah, so maybe to kick us off, like, I think there's a number of things that we could do. I think the first big question is, like, do builders include blobs? And if not, why? I'm not sure if anyone here who's a builder or maybe some relays who have insight into this. Can you? Yeah. Is there any context anyone could add here?
00:47:10.090 - 00:48:10.850, Speaker B: I can add some context. So I guess initially, when blobs first came to Mainnet, we actually just naively included every blog and then we saw actually a significant drop in our market share as compared to some of our other competitors. And so what we essentially did, like a couple of months ago or weeks ago, was we basically built two templates of blocks that we submit to the relay. So for every block candidate, we include blobs in one version, and in one version we don't, and we just shoot them to the relays no matter what. And whoever wins, wins. What tends to happen in practice is when the fees are super low on the blobs. Plus, obviously the latency concerns.
00:48:10.850 - 00:49:22.900, Speaker B: Usually the latency is that much higher that if the fees are so low, that blocks with blobs don't win as much. But then you can see once block fees go higher, actually, those blocks actually become valuable enough that even though that they are slower, they then get included. Another thing that we implemented, like on our relay, which a bunch of you may know is optimistic v two, which is essentially separating the header from the payload, which includes also the blobs. And that has a nice side effect that the size of the block doesn't matter at all. So it naturally will affect proposers who play timing games, but otherwise it has no impact on the sort of get header call, then you sign and actually commit to a specific block. And so with optimistic V two, actually we don't have any latency impact at all, but that will naturally require more relays to adopt. Optimistic, too.
00:49:26.640 - 00:49:31.100, Speaker A: Cool, thanks. Yeah, so that's, that's a good point, Terrence.
00:49:32.200 - 00:50:05.058, Speaker I: Good questions. So one question to the builder is that, do you guys simulate the total tips? For example, like the current problem across different routes, is that some rops process blobs are just peer batch, like a single EOA transactions, 22,000 gas. Some robs post blobs, but with some extra guest usage. For example, they need to update some micro accumulator for frog poop, blah, blah, blah. So that causes more gas.
00:50:05.114 - 00:50:05.450, Speaker A: Right.
00:50:05.530 - 00:50:51.484, Speaker I: So we have kind of this weird problem that like sometimes we only want to post blob, but we want the tips to be blobs only. But the tips also affect something else. So the question is, I wonder if builders stimulate the total tip versus just looking at tip like a single value and compare them across transactions. I guess that's one question for the builder. The second question to the relayer is that why don't we broadcast the blobs earlier than the block? I think that's relatively safe. For example, that I understand we want to wait for the block for a little bit to essentially prevent unbundling attack of the same slot. But I think the blobs could be like broadcast slightly earlier.
00:50:51.484 - 00:50:53.320, Speaker I: So I wonder if we do this today.
00:50:55.620 - 00:51:51.800, Speaker B: Yeah, so first question. So the consideration is basically what's the total contribution to block value? So yeah, we do the simulation, and if overall it's more valuable, it will be prioritized more in terms of the propagation of the blobs ahead of time or separately. I think if I remember correctly, the Bloxroot team was experimenting with that, and there were some issues. I don't know if anyone's on the call, but I think that mitigates the timing games issue. But there's still the issue of the submission of the blocks from the builder to the relay in the first place, which is the biggest part of the latest or where most of the optimizations at least happen today. But of course, there's also timing games and propagating the blobs from the relay ahead of time would mitigate that.
00:51:55.300 - 00:52:34.188, Speaker A: Yeah, I guess one caveat there is that you like the way blobs are propagated on the p two p layer is that they essentially need to be signed over by the proposer. So with the design today, this is like kind of all tightly coupled together. So it's not like, you know, the builder could send the blobs, they really could, like optimistically start gossiping blobs, they have to wait for that opposer signature. So, yeah, that part's kind of tricky. Um, but yeah, that was a question. Yeah. So then going up the stack now between builder and relay, that was a question I was going to have is like, yeah, is there something with the APIs or things we could change? It sounds like with optimistic relaying it's not really an issue.
00:52:34.188 - 00:52:51.920, Speaker A: Um, I don't know if other relays on the call have seen similar things to Titan in terms of blobs and latency and submission and all this.
00:52:55.420 - 00:53:35.936, Speaker C: Yeah, I don't have the exact figures, but we when there are blocks that are full of blobs, just everything takes a longer at our replay. Also, like, it's not just. It's not like there's one specific part, really. Just like we've upgraded some of our machines recently, which helped a little bit, but it was just kind of like an overall slowdown. I think v two specifically is what Kubi is calling out. Not just optimistic mode in general, but v two. We did see the Titan has some nice open source metrics about this, and it looks like that is faster for blobs, which is nice.
00:53:35.936 - 00:53:41.580, Speaker C: But we have not implemented v two at our relay yet, so mostly just corroborating.
00:53:44.560 - 00:54:19.580, Speaker A: Oh, thanks. Yeah, I mean, I think there's just like many things going on and it just points, I think the immaturity of blobs and the protocol. I think there's like economic issues, like, yeah, can I express my priority? And then does that allow builder to pack blobs in a nice way? For me as a blob user, that really sounds like there are infra things that could be done at least around the standard APIs, but if we all move to optimistic v two, sounds like that's less of an issue. That's good.
00:54:21.800 - 00:54:22.580, Speaker B: Yeah.
00:54:24.650 - 00:54:44.270, Speaker A: Steph had a question. Have we seen side payment makers markets emerge for Bob inclusion? I'm not sure. I guess. Steph, are you talking about like bespoke deals between like roll ups and builders or something like this?
00:54:45.370 - 00:55:12.000, Speaker H: Yeah, exactly. Because to me, blob inclusion also felt like a very natural place for pre commits to initially emerge, pre commits being sort of also just like a block based futures market implementation. And there's multiple different ways that you can package this up as a product. It can be done transparently using some kind of protocol. It can just be done as.
00:55:14.060 - 00:55:14.372, Speaker A: Some.
00:55:14.396 - 00:55:53.590, Speaker H: Legal agreements where you say, I'm going to include your blobs within x window of time from your submission with x percentage reliability. And then that's something that either a blockbuilder or a relay can offer to l two s to be able to get order flow. So I'm wondering if that's something that's been emerging, because the more difficulty that l two s have to get their things included, the more demand there is for this kinds of deals to take place.
00:55:59.530 - 00:56:33.040, Speaker F: We built a solution on this at east London that won a prize. We actually leveraged both map commit and suave swab would run the auction as to who gets to pre confirm the blobs. And then we thought relays would participate in that. But anyone could really. And then the rest of the network would coordinate to make sure the blocks deliver that. We've been talking to roll ups and they seem to be waking up to the need for this. Whereas originally the blob market wasn't too contentious for them to want it.
00:56:33.040 - 00:56:38.330, Speaker F: So, yeah, we'll continue those efforts and keep people updated.
00:56:48.550 - 00:57:16.780, Speaker A: Yeah, it's a good question. I mean, obviously there's now a spectrum of like, is this legal contracts or is there a somehow more trustless infrastructure for these types of agreements? And obviously, I think we'd all prefer more trustless solutions, but yeah, it could look like. Yeah, again, bespoke deals between different roll ups and different builders to ensure inclusion and also relays too. So I guess there's like a bit of a design space as well.
00:57:21.080 - 00:58:27.282, Speaker C: I can't help but wonder, though, if it's. I mean, it really is a pricing question, at least in part. Right. Even if it doesn't matter how you structure a deal, if the blobs aren't priced in a way that makes it worthwhile for a builder to include them, then it doesn't really matter if you have like a special side channel deal or if you submit them to a more permissionless set of builders. So I think I would be pretty interested, especially because Titan is basically, if I understand, running an A B test on this. One thing I wonder if we could do to help a little bit is getting data just so rollups understand the pricing piece of the equation. How much do you actually have to pay for inclusion? Because I think there's a pricing component and then there's actually just performance latency component in other pieces, not just in block building, but also in the way these things are gossiped.
00:58:27.282 - 00:58:52.460, Speaker C: But one thing I feel like we don't have a ton of really clear data on is how these things should be priced and how people should think about how much do I have to pay in order to get the kind of inclusion guarantees I would want. So before we move to something where there are bespoke deals, I feel like just getting a little bit more data out there so people can understand the pricing would probably be pretty helpful.
00:58:55.240 - 00:59:22.060, Speaker A: Yeah, I completely agree. And I think it's just a complicated problem because, like, at least with respect to a builder, it's like now you're. You need to somehow consider, okay, like given the ambient MEV at any one point in time, like, the blob needs to somehow clear that price. So, yeah, I think it just is tricky and then definitely, yeah, having data. So any builders or relays listening. If you'd like to share data on this, that'd be super, super helpful. Terrence and Emirat.
00:59:24.240 - 00:59:40.024, Speaker I: So I think the pricing problem is definitely one of it. But I think the main problem is that we have a clearing problem. And the clearing problem is that the current meant the block man pool rule is too strict.
00:59:40.112 - 00:59:40.290, Speaker B: I.
00:59:40.320 - 00:59:41.974, Speaker I: So I can give you an example.
00:59:42.022 - 00:59:42.230, Speaker A: Right.
00:59:42.270 - 01:00:00.918, Speaker I: There are two rules in the current block man pool. The first rule is that the tip replacement is very, very high. If you want to replace your tip, you have to pay like a significant, like a double amount. The second problem is that we only allow one sender per transaction, pronounced.
01:00:00.974 - 01:00:01.310, Speaker A: Right.
01:00:01.390 - 01:00:18.910, Speaker I: So what that means is that I only have one shot as a roll up. I can either choose six blobs, five blobs, four blobs, and three blobs, right? So the Nash equilibrium is that every rob come together and they look at how many blobs they are posting and figure out their best strategy.
01:00:18.950 - 01:00:19.366, Speaker A: Right.
01:00:19.478 - 01:00:24.342, Speaker I: For example, today, Heico is always posting one blobs, and Heiko posts a lot more often.
01:00:24.406 - 01:00:24.750, Speaker A: Right?
01:00:24.830 - 01:00:31.182, Speaker I: So, as a result, base and optimism and everyone else are posting five blobs to basically match that behavior.
01:00:31.246 - 01:00:31.644, Speaker A: Right?
01:00:31.742 - 01:00:48.504, Speaker I: So we have this kind of weird problem that if I roll up today, I send six blobs in my transaction. I pay a very high tip, but someone come later and send only one blob and pay a higher tip, the builder will include that one blob transaction.
01:00:48.552 - 01:00:48.760, Speaker A: Right?
01:00:48.800 - 01:01:17.372, Speaker I: But then the six blob is basically stuck. But if that sender had known if someone is going to send a one blob, so that sender will send five blobs instead. So we have this weird matching problem, and because of that, we include one blob, but then the guest. But then the base fee actually went down, but then the tip is going up, so it kind of revert back to this first price ultra mechanism. So this is kind of weird. So I will label the current problem. It's more like the current man pool.
01:01:17.372 - 01:01:23.560, Speaker I: It's not very friendly to allow this mix match blob transactions.
01:01:27.420 - 01:01:52.180, Speaker A: Yeah, definitely. Yeah, yeah. There's a lot here. One thing I've, like, kind of been toying with over the last days, like, having a more flexible way to include blobs, because, like, right now, it's actually quite rigid. Like, they're attached to transactions and there's, like, synchronous execution attached and, like, all of this. And. Yeah, like, to your point, given the midpool today, it's, like, even more rigid beyond that.
01:01:52.180 - 01:02:23.720, Speaker A: So I would do wonder if there's some way to, like, have roll ups, for example, more flexibly, say, hey, here's just some blobs that should be included, and then let builders have more flexibility to say, these blobs go in these blocks, and how not necessarily attach them to transactions. Yeah, I guess one way to think about it is more like a block level blob quote transaction than the transaction level blobs we have today. Yeah, Mara.
01:02:25.660 - 01:03:25.498, Speaker F: I definitely like to second Terence's point there, but regarding pricing, the two kind of aspects we hear are, one, you do have to send the whole blob when you're updating your price. Or because transferring the blob itself is slow, you have to kind of predict what the marketable price will be before you send it over, gets over there. So that's one area that roll ups are struggling with, and that their rate of update is bottlenecked by the size of the blob, so they can't update their payment in real time, et cetera, which we're telling them, hey, you can use Mav commit to do this, but it would be good for Ethereum itself to support something there. And the other thing is the lack of a high correlation between your blob priority fee and your inclusion rate. So we've created a dashboard on this post here. You guys can see the basically, priority fees are all over the place. You can have the highest priority fee, and you can wait for inclusion for a while.
01:03:25.498 - 01:03:48.520, Speaker F: You can have the lowest priority fee, and you can get included fairly quickly. And there's a lot of dynamics that come into play here, and variables, whether it's a one blob or six blobs, etcetera, but there's just multiple facets into the pricing problem. It's not just that they're contending with Mav or they have to pay a certain amount, it's just too many variables to consider there.
01:04:05.460 - 01:04:21.610, Speaker A: Yeah. So hopefully things harden over time and it becomes clear. Just from what I'm hearing, this sounds like it's not so much like a net supply chain infrastructure problem today and more just, yeah, like fee economics issue.
01:04:23.790 - 01:06:10.732, Speaker C: It might be that we can do things to help. I think the decision point, especially with what Terrence was saying, which I agree with, I think that's definitely worth digging into more, is just if we can better measure how, for example, the mempool ejection rules in El clients are actually working in practice for blobs, or looking at, okay, if it's really so rigid as to how you can update blob tips and do the things that you would need to do as a roll up. I think the question becomes, is it possible to make these things more flexible in the actual client implementations? My sense is that might be difficult, but I think it is worth us at least bringing it to their attention and trying to get some concrete data to show why this is impacting roll ups negatively. I know that client teams have fairly complicated formulas for choosing how they include blobs, so it's not as though this hasn't been given thought, but I just don't know that it's been fully evaluated given the market conditions we're seeing in practice. And so one route is to try to, like, bring more clarity to that and see if we can get useful changes shipped on that layer. If that's not the case or that doesn't happen at the speed that we need, I think there are ways that you could use, like, things we have built for MeV infra to help here. Terrence and I were chatting a little bit about this yesterday, but maybe we can, uh, use private mempools that have much more generous, um, policies about how they keep transactions around than memful, uh, client and clients do in their mempools.
01:06:10.732 - 01:06:20.320, Speaker C: I think that's like a road we don't want to go down if there's an even more permissionless option. But that might be a fallback that we could think about exploring a bit more.
01:06:31.390 - 01:07:35.790, Speaker A: Yeah, definitely. My understanding, at least with the blob and pull rules, is like, I think they were picked pretty conservatively. And, yeah, this would kind of be exactly the plan is to see things on Mainnet, and if there's issues or if it's possible to, like, relax the constraints, definitely that would be the preferred option. Okay, anything else on Bob's? Sounds like we just need to do more analysis and keep chugging along. I doubt to share data. That would be super helpful to inform. Yeah, all the different things that we're thinking through.
01:07:35.790 - 01:08:10.300, Speaker A: Okay. Otherwise, anything else? If not, we can go ahead and wrap up today. Okay, sounds like that. Thanks, everyone, for joining. And, yeah, hopefully this was helpful. A couple different exciting things of development going along and. Yeah, I'll see you on the next call you.
01:08:13.880 - 01:08:16.120, Speaker B: Bye, everyone. Thanks. Bye.

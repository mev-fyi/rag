00:00:07.050 - 00:00:20.414, Speaker A: Now I'm here with the first speaker, Shahar Papini from Starquare and he will be talking about Cairo. So I'm very excited to hear your talk. Take it away.
00:00:20.612 - 00:01:28.162, Speaker B: I'm Shahar Shah Papini, I'm an engineer at Starquare and I'm the co creator of Cairo, which you will soon see what it is all about. So I'm going to talk about our journey in Starquare from ASIC to CPU. In the stark world at least. I'll start by presenting what are Starks? Very generally I'll show the early stages in Starper of how we develop Stark's and how we progressed and how we ended up at last at the so called holy grail. Currently the universal machine written in Stark, which we call it Cairo. So what do I mean when I say ASIC to well, ASICs are application specific integrated circuits. There are specialized hardware written for some specific goal.
00:01:28.162 - 00:02:35.930, Speaker B: They're usually very fast, they are also expensive to make and they are notoriously hard to design for. On the other hand, we have cpus central processing unit. They are some specific chips, specific ASIC. They support general computation, they are usually a lot slower, they are cheaper to make, they are very easy to program for, at least compared to ASICs. This tradeoff between ASICS CPU is one of efficiency versus flexibility. CPU is very flexible, but it is usually less efficient than asics. Okay, so this analogy fits very well for our journey in starkware, and I'll share it in a minute, but first I'll give you a brief overview of starks.
00:02:35.930 - 00:03:37.774, Speaker B: What are Starks? Stark is a family of cryptographic proof systems that can be used for both privacy and scalability. Stark proves statements these statements are about some computation that a computation was executed correctly. A few examples of statements we can prove. For example, the 1000th number in the Fibonacci sequence is some specific number. Or another statement could be I have these 100 signed bank transactions and when I apply them one after the other on some specific state, they all turn out to be valid and I get some other state at the end. At Starkware we chose to focus on the scalability part of starks. A major reason for this is, first of all, starks are very efficient to verify their verification.
00:03:37.774 - 00:04:51.210, Speaker B: Time is exponentially smaller than naive computation of the same computation problem. And this fits very well to applications like the blockchain, where it's very costly to run something on the blockchain because everyone on the blockchain needs to verify it. So if we can take this huge computation of tens of thousands transactions and compress them to a small proof with very small verification time. Then the blockchain needs to work a lot less, and it's a lot cheaper to use this. So this is mainly what we do today, though starks have the capability of being zero knowledge and preserve privacy as well. All right, so a bird's eye on how stocks work. You have this statement, the program we want to verify, like the Fibonacci or the bank transactions.
00:04:51.210 - 00:05:52.510, Speaker B: The first step is to translate them to some algebraic representation. We call it air. After we did this transformation to an air, we can throw this on a bunch of algorithms. Fry, LD, Merkel, all of the stark protocol, and basically on the other end, we will have this short, succinct proof. So how does this representation look like this error? Well, to represent our statement, we use a table we call a trace. This table has some constant number of columns, and the number of rows is some power of two. And each cell in this table, in this trace, is a field element in some finite field, and it has some meaning regarding the statement we want to prove.
00:05:52.510 - 00:07:13.586, Speaker B: For example, if we wanted to prove the Fibonacci statement, then probably the row would correspond to the ith Fibonacci number, or something like that. Together with the trace, we have constraints on these cells. These are polynomial constraints that act in the field on these trace cells. So again, in the Fibonacci example, the constraint would probably be some cell equals to the sum of the two cells above it, like in the Fibonacci recursion. If this was a bank transaction, that, again, each cell would probably correspond to something, the statement, like the balance of the user, the amount in the transaction, and the constraints would be something relevant to the statement, like the new balance is the old balance, plus the amount of the transaction, things like that. All right, so now we can start the journey we had from ASIC version to cpu. So how did we build starks? At the beginning, we built them pretty much from scratch.
00:07:13.586 - 00:07:46.420, Speaker B: We needed to design the trace. We think about how many columns we needed, assign some meaning to each tracer, what it represents. Then we need to add constraints. We can only use constraints which are polynomial of low degree. If we had higher degree, we needed to break this up, perhaps with auxiliary phase cells. And maybe we need to change the number of columns in response. And this is like a very manual process.
00:07:46.420 - 00:08:42.180, Speaker B: Also, if you want to optimize it, it's all done manually. The way we measure efficiency in starks is the size of the strays, the number of cells in this table. This trace space directly affect prover time and the memory. The other way we can measure efficiency is the size of the constraints, which corresponds to the verification time. So the main thing we want to optimize for is the trace space, and the secondary is the constraint size. Usually. Well, this manual process is nice for very small problems, but when the problem gets more complex, this process gets very complex very fast, and it's hard to do very big projects in this way.
00:08:42.180 - 00:09:29.410, Speaker B: All right, so the next stage is developing tools and frameworks to help us. Stopper we developed multiple tools and things that can help us, and these are a few examples. What you see in front of you is the visualizer. You can see the columns of trace of some problems. Each cell has some text on it, some meaning, and you can see the constraints that apply on it. There's also some verifications. Another thing we developed is some framework for errors, which gives us a way to deal with abstraction.
00:09:29.410 - 00:10:32.082, Speaker B: For example, if we have some repeating logic in air that we want to use in multiple places or in specific error, multiple times with multiple sizes, different parameters, obviously we don't want to write the same thing manually over and over, so we need some framework to help us do that. So this is another thing we did. Another thing is automatically placing the cells with meanings onto this trace without need to do it manually. Just find the empty places of trace and puts things on it. So all of this helped us a lot. And actually the first product we used, Starkx version one, used these kinds of tools to create. Okay, so this is nice, but it's still not ideal.
00:10:32.082 - 00:11:49.214, Speaker B: What we would like is probably something that resembles more programming language. So the next step we could take is writing some domain specific language for errors. Now, we eventually didn't do this step, actually we had a few designs for it, but ultimately we decided to move on to the final step, which you will soon see. So this stayed in the design phase. But what does it mean? Language for errors? Well, we can think of this imaginary language that has some logic in it, and we can take this code, something that looks like code, and translate it to a trace, and constraints for some problem. This seems nice, but there are a few problems that rise from this. For example, if we have some branch, some if we always have to pay for both branches, we don't know at compile time which branch we will take.
00:11:49.214 - 00:12:34.320, Speaker B: So we need to allocate some trace space for one branch and some trace space for another, and write the constraints for both. So we pay for both. Another thing is loops. The loops are always of constant size because they are basically unrolled to have like 16 repeating the code block inside. And that means we need to pay for all the iterations. This means we can't really implement general logic with this. Can do calls, or recursive calls, or similar things.
00:12:34.320 - 00:13:21.434, Speaker B: So I'll summarize. And the reason we wanted to do something like this is to have a flexible way to program this stuff. More like programming language in a higher level. But some of the drawbacks, no memory branching is expensive, no recursion, it's not complete. Everything takes space. And also, one specific for starks. A cool feature of Starks is if you design your constraints and trace, for example for eight transactions, then you can later take the same error deployed contract, whatever, and put 16 transactions or 32 transactions.
00:13:21.434 - 00:14:17.226, Speaker B: You can put repetitions of this problem instance and verify it in the same stark. It's a very nice property of Starks, which help it scale somewhat. But the downside is that if the program is not repetitive in nature, then this doesn't really help us. For example, if we wanted to first execute a lot of transactions and then to compress, then we don't get this feature of stocks, which is a shame, at least in the DCL way. We wanted to solve all these issues. It's something really flexible, so called the holy grail. This is why we developed Cairo.
00:14:17.226 - 00:15:02.282, Speaker B: Now, what is Cairo? Cairo is specific air, specific cpu air. It can verify general computation. It's efficient. It's a Turco complete universal machine. If one human machine, we have a single error, single verifier to verify every kind of program we can think about it that is written in error. These are a few snippets of the Cairo language that ultimately compiles to these Cairo instructions that our error can verify. These are examples for library functions.
00:15:02.282 - 00:15:33.542, Speaker B: It's a developing language. We are expanding it all the time. Our new version of Stockx is written with Cairo, and all the new projects are written using it. What you get in Cairo, first of all, you only pay so called with the trace cells. What the efficiency measurement of errors. You pay only for what you actually run. If you have a branch, you only pay for the branch you've been in.
00:15:33.542 - 00:16:39.834, Speaker B: If you have a loop that only goes five times, that's what you pay for. It can support very complex, non repetitive logic. You have recursion, various conditionals, and it is very efficient. For example, we took some real world application that we had an error for it, a handwritten error. We written the same logic in the Cairo language, this yielded something that is about 20% to 30% more expensive, which when you keep in mind the ASIC analogy, it's very good because cpus are usually a lot more expensive, a lot slower. I mean compared to ASICs, then 20 30% is pretty good. However, when we use the power of Cairo and implemented some logical optimizations that are really easy with code, but very hard when you write the error in hand.
00:16:39.834 - 00:17:23.250, Speaker B: Then with these logical optimizations, the Cairo version was actually a lot cheaper, which is maybe surprising, but it's a very cool property of Cairo. We got flexibility and we got efficiency, in this case at least. So like I said, we are developing Cairo all the time. We have a lot of tools for it. Obviously the compiler, we have virtual machine, we have the solidity verifier. It's already deployed to mainet. In the diversify setup, you can look at it today we have integration with idEs, Vo, studio code and Vim.
00:17:23.250 - 00:17:52.980, Speaker B: They have auto formatter, language server. We have a tracer which is similar to debugger. You can see it up here. We also have the playground which we plan to release in the next few weeks. So you can play with, you can see it in the image down below. All right, so I want to share with you a few considerations we had while designing this cpu. Air.
00:17:52.980 - 00:18:52.706, Speaker B: This comparison also shows why it is not a very good idea to just take some existing architecture for physical cpus like x 86 and just writing an air for it. If you do that, you'll get something that is not efficient because it really doesn't fit to the, I would say, physical aspects of air. So first of all, how do we measure efficiency in physical cpus? It's execution speed. Whatever runs faster is better. In air, the efficiency is mostly the tray size, the number of tray cells. This also means that it is easier to do optimizations for the execution time. In physical cpu, you can usually add more hardware like branch prediction or out of order execution.
00:18:52.706 - 00:19:49.946, Speaker B: This is more hardware, but it makes execution faster, so it pays off. In air, it's usually a lot harder, because if you add logic, if you add trace cells for some hardware, you by definition get something that is a lot less efficient. So although you can do things sometimes, usually it's better to just keep it simple, keep it lean, keep it fast, less trace sales regarding the registers, usually physical cpus have multiple registers. They are relatively cheap in a physical cpu. In air they are more expensive. They make your constraints be a lot bigger, because you need to choose from a lot of registers. So if you remember bigger constraints means bigger verification time.
00:19:49.946 - 00:20:38.994, Speaker B: So the verify side will pay if we have a lot of registers. Another difference, the native word. Usually in physical cpus we work with bits, usually 32 or 64 bits in air, the basic word is finite field element, because this is how the trace works. This also means that while bitwise operations in physical cpus are relatively cheap, it is very hard to do bitwise operations and more expensive in error. A cool feature we have in errors is the nondeterminism. In physical cpus it's deterministic. You have some computation values before you know what you get at the end in errors.
00:20:38.994 - 00:21:15.090, Speaker B: You can use a non determinism if you know the class NP, for example. This is what I mean by non determinism. You can guess things and then prove them. For example, if I would like to search an element in a list of size n in a physical cpu, I will have to go over this list. It is n steps in the CPR. I can just guess where this element is at what position, and just show it's there. Hey, see the element 100 is what I want, so it's of one iterations.
00:21:15.090 - 00:21:54.094, Speaker B: Another aspect is the memory. Memory is also very different. Memory access is usually expensive in cpus. It has a large delay with respect to other operations in error. It turns out it's relatively cheap to access memory. It's not that expensive, and freeing memory is beneficial. Physical cpus, for example, if you have this constant size of ram and used it up, then you can free memory and then use it to allocate other stuff in errors.
00:21:54.094 - 00:22:39.550, Speaker B: It doesn't really work that way because once you used some memory, some information, it stays in the trace because it needs to get in the proof. You need to prove that this computation actually happened and was correct. So there is no meaning to freeing this memory. You still need to prove things about it. All right, so Cairo now in the future, like I said, we use Cairo today in Starkx version two. Stark is live on minute with diversify soon with immutable as well. We have the upcoming perpetual contracts project with DYDX.
00:22:39.550 - 00:23:16.714, Speaker B: Soon we will release the white paper of Cairo so you can see all the details inside. Like I said, we will plan to release the playground and sometime after it maybe some developer tools so you can use it at home. We also plan to promote community projects regarding Cairo. For example, compiling from high level languages. So it will be easy programming your favorite language and it will be translated to Cairo and be able to prove it. All right, so thank you very much. That was me.
00:23:16.714 - 00:23:21.310, Speaker B: That was my lecture. I hope you enjoyed.
00:23:24.270 - 00:23:29.580, Speaker A: I think now there would be clapping, so I'll do it for you.
00:23:31.390 - 00:23:32.140, Speaker B: Thanks.
00:23:32.830 - 00:23:50.160, Speaker A: So there are some really great questions in the chat, and I just want to pull some of those out. Let's see. Let's start with. Oh yeah, Dara, I was hoping you could actually elaborate a little bit on yours, because I was.
00:23:51.750 - 00:23:53.300, Speaker B: Elaborate on what?
00:23:54.310 - 00:24:08.710, Speaker A: So there we go. So Dara just elaborated a question. Have you considered a hybrid of specialized non turing complete circuit blocks and cpu blocks and a cpu style block?
00:24:10.490 - 00:24:31.150, Speaker B: Yes, we did. And we do not everything is actually implemented in Cairo. When we need to do something very fast, we have some more specialized error component that runs alongside it, just so we can get very efficient programs.
00:24:34.050 - 00:24:39.330, Speaker A: I think two people were asking if the code is open sourced, if it's available publicly.
00:24:40.390 - 00:25:06.540, Speaker B: I see. So some of it might get open sourced. We are not sure yet exactly what we want to open or not, but some of it will remain closed. But we hope to give enough tools for everybody to use it, even if they don't use software. But like I said, we don't know yet what we want to open source or not.
00:25:07.630 - 00:25:13.050, Speaker A: Okay, one more question was, how do you choose the finite fields used in Cairo?
00:25:13.970 - 00:25:41.750, Speaker B: Okay, so we have this specific primary use because it's efficient to do computations with. We have some architectural limitations. It needs to be big enough to contain the instruction coding, but other than that, it can be a lot of things. And there are no very hard limitations other than at least 60 bit and efficient.
00:25:43.530 - 00:25:46.550, Speaker A: Isaac asked, what is the concrete efficiency?
00:25:49.450 - 00:26:13.630, Speaker B: Like I said, it's hard to measure apples to apples. But in the real world application, in Starkx version one, when we moved from the handwritten, which was very efficient, to the Cairo version with optimizations, it actually became faster. So I would say very good overall.
00:26:15.490 - 00:26:24.130, Speaker A: Bobbin was asking, how cheap is memory access in Cairo, for example, how many cpu cycles does it take to read write from two memory?
00:26:24.870 - 00:26:55.040, Speaker B: Actually, it doesn't take multiple cpu cycles. Every cycle has a few memory accesses and it just repeats this way. The efficiency is measured by the number of trace cells, and it's not big, I don't know exactly how much, but maybe five, six, seven trace cells, something like this.
00:26:57.890 - 00:27:05.200, Speaker A: Isaac was asking, can you explain the arithmetization specifically, how do you iterate over VM instructions and memory access?
00:27:07.750 - 00:27:52.320, Speaker B: It's very similar to, I would say, transactions, if you know, general starks, like Fibonacci does this logic that repeats all the time. The one element is the sum of the previous two. So we have just a lot more complex logic about these cpu iterations that needs to decode the instruction to understand what it tries to do and to update the registers and access the memory for the next cycle. When the white paper is released, you will see all these details a lot better than what I can explain to you right now. In a few minutes.
00:27:54.770 - 00:27:56.640, Speaker A: Sergey asked, what is the.
00:27:58.770 - 00:28:12.280, Speaker B: It? I think someone asked similar question. We use a specific prime defined field is multiplication modulus and big prime. About 250 bit.
00:28:15.770 - 00:28:19.830, Speaker A: Alan was asking, does Cairo relate at all to tiny Ram?
00:28:22.810 - 00:28:38.160, Speaker B: It doesn't really relate to tiny Ram, no. Tiny Ram was some, I would say, version of a computation model that can run a general computation, but it's not related at all. I would say.
00:28:41.410 - 00:28:51.620, Speaker A: Isaac or Kev asked again, I know that you probably don't want to hear this, but will it all be eventually open sourced? It seems to be a lot of questions about this.
00:28:53.350 - 00:29:37.026, Speaker B: Yeah, some of this will be open source as far as okay, I don't want to commit already. Okay, if I commit then people will hit me. But I think the VM part and the compiler and things that can run to a place and obviously the verifier is open because you can see it on the blockchain right now. So you can see the verifier and all the air. The mathematical constraints are there in the blockchain. So you can see right now. My colleagues shouldn't hit me.
00:29:37.026 - 00:29:45.570, Speaker B: Yeah, but they do. I hope in the near future you can give some more.
00:29:45.720 - 00:29:51.830, Speaker A: You can clarify. Cool. Should it be efficient in solidity?
00:29:55.930 - 00:30:30.530, Speaker B: Do you mean the verification in solidity? Because the verification solidity is similar to other errors, because the constraints of carbon are actually quite simple. So it's not very expensive to verify in solidity. If you mean to run the virtual machine command in solidity, then it might get more expensive. Yes, I think the idea is just to verify the proofs in solidity and not just run the instruction directly.
00:30:31.350 - 00:30:39.670, Speaker A: Yeah, that's actually a question I would have. Is this sort of built for one particular network in mind, or is it really built as an all purpose?
00:30:40.010 - 00:31:10.830, Speaker B: No, Cairo in its core is general. It doesn't know Ethereum. It's just general framework to proof general computation things get some succinct proofs for it. For example, we also would like to everything you can do in the computer, you can use it to just create a proof. But we have also some layers on top of it that help it interact with the blockchain.
00:31:12.370 - 00:31:33.560, Speaker A: There's some continuation about the solidity question. Sergey said it was about the field selection and solidity, I believe. Hope, I'm understanding that. Yeah, it was. Should it be efficient in solidity? It was about the field selection, maybe. Actually, Sergey, if you want to rewrite that question maybe fully, then I'll ask it in a.
00:31:36.170 - 00:31:43.500, Speaker B: Oh, I see. Bob asked a question I want to answer. Two. Maximum degree of constraint is. Okay.
00:31:45.870 - 00:31:48.970, Speaker A: What is the maximum degree of constraints in Cairo?
00:31:49.550 - 00:31:51.802, Speaker B: Yeah, two. Exactly two.
00:31:51.856 - 00:31:58.510, Speaker A: Okay, got it. There was this interesting question. Are there any use cases where I should not use Cairo?
00:32:00.290 - 00:32:40.780, Speaker B: If you don't want to create proofs for general computations, don't use Cairo. If you have some tasks that is important for it to be very efficient, and it is repetitive in nature, and it's not very complex, doesn't have very complex logic. For example, maybe just verifying these stupid computations done a lot of times, maybe some hashing, lots of hashes, and that's it. Then maybe you should use the handwritten air version. Probably better. Cavalier is more for complex logic things.
00:32:42.910 - 00:32:49.870, Speaker A: Ivan was asking, could you expand on non determinism? What does it mean in practice to guess the position of some element in memory?
00:32:51.970 - 00:33:40.880, Speaker B: It's hard to explain it right now, but generally it means that you won't need a lot of instructions to search for an element in a list. The proverb would have to do this work, obviously, because we can't ask God or something like that. But the proverb will search for it, and the instruction that will actually enter the proof will just be like very few. It guessed the position and that's it. So, in terms of the algorithms of the OD we talked about, which are the major time things, it won't go into them and it won't go into the proof size.
00:33:42.450 - 00:33:49.650, Speaker A: Darryl is asking, is the cpu design parameterized? I think I said that, right? So that it can be specialized for the circuit.
00:33:51.350 - 00:34:22.330, Speaker B: It is parameterized, yes, a cool feature. We also have. I didn't mention that we can take a bunch of programs, maybe even unrelated, and put them in the same proof. So we have like one program, 2nd, 3rd, even if they are totally unrelated, like one is transaction, the other is Fibonacci, and then after a trend, we can choose the right parameters to do all of this very efficiently.
00:34:23.570 - 00:34:30.910, Speaker A: Isaac was asking, can we swap out the prime for another one with a sufficiently large binary root of unity?
00:34:33.970 - 00:34:38.638, Speaker B: Generally, yes, you can, Bob and had.
00:34:38.644 - 00:34:48.546, Speaker A: Another question about field. Was it 256 bit prime or is it smaller? And then a bunch of people guessed. So what is it?
00:34:48.728 - 00:34:51.182, Speaker B: 252 bits.
00:34:51.246 - 00:35:02.010, Speaker A: 252 Dara is asking, would it be possible to use prime fields that match those used in other proof systems so that it's efficient to use the same embedded curves?
00:35:03.470 - 00:35:20.080, Speaker B: Well, prime, like someone said, has it needs unity root of a very large power of two orders. So, no.
00:35:22.290 - 00:35:40.486, Speaker A: Isaac, you just added, but in your code. But I don't know if that was referencing your previous question. If you want to write. If it is, maybe just write out that question again, because I'm trying to link them together. Anyway, Darryl is asking, would it be possible to use prime seals that match those used. Oh, yeah, that. We just did this one right.
00:35:40.486 - 00:36:23.700, Speaker A: Bobbin, actually, where are we? Let's check. Keep the questions coming. If I've missed your question by chance, just put it again because I'm trying to follow this as well as question. Okay, so Isaac said that the question about in your code had something to do with Dara's question, but I'm not exactly sure what that would mean. So. Yeah. Are there any other questions about Cairo? I was kind of curious when you were talking about the use.
00:36:23.700 - 00:36:33.862, Speaker A: Is it already being used in diversify or is this like a test realm? I couldn't quite figure out how right.
00:36:33.916 - 00:36:59.134, Speaker B: Now in production, it is not used. It is v one, but in all test environments, it's currently v two. And we are planning an update very soon to use this kybo. But the contracts are, as far as I know, already in minutes. But I can check. They're in Robson, definitely. So you can check it out there.
00:36:59.332 - 00:37:09.220, Speaker A: You might have actually mentioned this earlier in your presentation, but if you were to just list quick benefits, why would they start to use this?
00:37:10.710 - 00:37:44.590, Speaker B: Well, like I said, it's very hard to do some complex logic in an efficient way in current solutions. This is the main benefit you would get. You get something that is very much like programming in any other thing you don't have to think about. Oh, wait. This is only a constant number of loops. I can't do this recursion. My program will blow up in Cairo.
00:37:44.590 - 00:38:26.540, Speaker B: It's just like a very simple programming language. Don't have to think a lot more different. Maybe just the fact that there is a prime field except for native words, but it's very similar to programming languages. And if you want another benefit that we plan to maybe have some service that you can all just play with, and it should be very easy to just experiment with ZKA proofs yourselves. Just write some code in the playground and press enter. You get your proof, something like that.
00:38:27.790 - 00:38:40.240, Speaker A: Kev asked, this is kind of related. If I'm using a snark currently to do a big circuit. Should I switch to Cairo? Maybe I'm doing ZK roll ups, but there, wouldn't it be switching to starks as well? But maybe you can answer that.
00:38:42.450 - 00:39:29.310, Speaker B: Okay, so some of the drawbacks I mentioned in the dsls also apply for your starks, especially if you're working with some of the existing frameworks that look like code. You get same drawbacks of not able to do true and complete computations and paying a lot for things you don't actually use. And another major drawback that you get in a lot of them is that you write your circuit for a certain size of program. You can't put large instances of the program in this area. You need to write a new one. All these are drawbacks that exist in some of these current tools and don't exist in Cairo.
00:39:29.810 - 00:39:35.600, Speaker A: Bobbin is asking, what is the reason for not using smaller primes? 64 bit, 128 bit?
00:39:36.550 - 00:40:07.210, Speaker B: Well, 64 exactly. I think it's just less than what we need for Cairo. We could use 128, but we use bigger primes. It lets us do more easily our hashes that are 250 something bits. It can be done, but currently we just do that. It's not a lot worse.
00:40:08.750 - 00:40:18.270, Speaker A: Isaac, I think, is joking when he says, would you consider switching to this prime two? 8948-022-3093 you smash.
00:40:22.530 - 00:40:24.720, Speaker B: I promise I will consider it.
00:40:28.710 - 00:40:48.120, Speaker A: He says, this prime has, I think, two to the 32 root of unity. Not joking. Okay. He wasn't joking. Sorry. Okay, so these are great questions. I'm trying to think if there's anything else that we could talk about since we have Shahar here with.
00:40:48.120 - 00:41:03.900, Speaker A: I mean, I'd be a little bit curious to hear about you getting involved in this project. What were you doing before that got you working on this particularly? This is such a podcast, by the way. I'm sorry.
00:41:04.750 - 00:41:40.806, Speaker B: Like I said at the beginning, we did everything manually. We worked a lot to develop our framework and do things. And it's a thought that we all had at the time that things are very hard to create right now, and we need something better. We need to do some these complex logics that it's just near impossible without. No, it's an idea. I'm not the only one doing Cairo. Leo Goldilk did a lot of work and a lot of other people in Stockwell, and we had a lot of design.
00:41:40.806 - 00:42:13.140, Speaker B: This table showed before what the consideration. These are all things that we had a lot of meetings about and trying to think what is the most efficient thing we can do in Cairo. It was sort of a passion. It was fun, very fun to create something like this. And it obviously paid off. We were working on it a lot of times over a year we are working on this project, maybe even more, and we see the fruits now.
00:42:13.990 - 00:42:26.120, Speaker A: That's amazing. So if there aren't any more questions, which I don't think there are, then I guess we can wrap up the session. Unless you wanted to say anything else?
00:42:26.570 - 00:42:30.386, Speaker B: No. Thank you all for listening. You've been a great crowd.
00:42:30.578 - 00:42:48.506, Speaker A: Yeah, thanks so much for all these questions. It was really great. Then we got a few more. Okay, we got two more. And Isaac asked us again, and this is a question that is again about the open source. How can we verify what we're proving if it's not open source?
00:42:48.618 - 00:43:18.230, Speaker B: Well, first of all, like I said, the verifier is open. You can see exactly what it does and the logic, the equation, it verifies, you will have the compiler and the run, so you can see exactly the instructions that come out of your program when you are approving it. And if the verifier works, then mathematically this verifies your statement.
00:43:20.010 - 00:43:34.646, Speaker A: Cool. And Kev, Kev has one here. Yeah, this is kind of related, right? So if I were to make my program using Cairo, would there be parts of a compilation project, a process where I inherently need to trust Starquare?
00:43:34.838 - 00:44:17.050, Speaker B: No, you don't need to trust Starquare at any point. First of all, the part that will generate the instructions, like I said, it will probably be open source. You can most likely be open source. You can see the instructions of your program, you can see the verifier, so you don't need to trust anything. Yeah, the compiler will be open source. You need to compile your programs, and the VM will also be open source, so you can generate the instruction list and the trace of your programs.
00:44:17.390 - 00:44:47.860, Speaker A: Very cool. By the way, Shahar, I don't know, will you be sticking around the event for a little while? Yeah, where you are. But later on today we're actually doing something called on gather town where we can go up and meet other people. And I feel like there's quite a bit of dialogue still happening here. And so if you can stay up. I know it's a little bit late, but it would be great because I think people have more questions, but a lot of these seem like they're kind of deeper conversation and maybe.
00:44:48.230 - 00:44:51.540, Speaker B: Sure, sounds cool.
00:44:51.910 - 00:45:13.100, Speaker A: Okay, very good. Well, thank you again, everyone. I think we're going to wrap up here and yeah, we'll be back on this stage in about like twelve minutes with John Adler. And we're going to be talking about ZK roll ups and optimistic roll ups. Very cool.
00:45:13.950 - 00:45:14.940, Speaker B: Thank you.

00:00:05.450 - 00:00:38.790, Speaker A: Welcome to zero knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero Knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online. You in this week's episode. I check in with the folks at Aztec. Aztec is a ZK based Privacy l Two project. The team has a track record of delivering some of the most important ZK research and implementations.
00:00:38.790 - 00:01:08.354, Speaker A: One big highlight here would be the original plank paper. In this interview, I chat with Joe and Charlie from the team. We talk about Aztec connect and how this relates to ZK money. We talk about how the team has evolved, what future projects they are working on, such as the DSL Noir and Aztec Three. We also talk about what stopped their recently planned launch at the very last minute. We do kind of a quick postmortem on that and what's next for the project. But before we kick off, I just want to remind you to check out the ZK Jobs Board.
00:01:08.354 - 00:01:31.126, Speaker A: If you're looking to work in ZK professionally, this is a great place for you to find your next gig. You can find job postings from some of the top teams working in ZK. Also, if you are a team looking to recruit, this would be a great place for you to let technical people know that you're looking to hire. I've added the link in the show notes. Now, Tanya from the ZK podcast team will be sharing a little bit about this week's sponsor.
00:01:31.318 - 00:02:07.762, Speaker B: Today's episode is sponsored by Alio. Alio is a new layer one blockchain that achieves a programmability of ethereum privacy of Zcash and the scalability of a rollup. If you're interested in building private applications, then check out Alio's programming language called Leo, which enables noncryptographers to harness the power of ZKPs to deploy decentralized exchanges, hidden information, games, regulated stablecoins, and more. Visit Leo lang.org to start building that's Leo la n g.org. You can also participate in Alio's incentivized testnet three by downloading and running a snark OS node. No signup is necessary to participate.
00:02:07.762 - 00:02:15.910, Speaker B: For questions, join their discord@alio.org slash discord. So thanks again, Alio. Now here is Anna's interview with Aztec.
00:02:19.850 - 00:02:30.874, Speaker A: Today I'm here in person with Joe and Charlie from Aztec. We're going to be talking about Aztec, the trusted setup they did, ZK Money and Aztec Connect. Welcome to the show, both of you.
00:02:31.072 - 00:02:32.298, Speaker C: Thanks for having us.
00:02:32.384 - 00:02:33.422, Speaker D: Great to be here.
00:02:33.556 - 00:02:55.246, Speaker A: I am very excited to hear about the latest on the project. Quick disclosure, the ZK Validator is a small investor in the project as been on. This is your second time on, and I think last time we were talking primarily about ZK Money. I'll add a link to that in the show notes. But maybe do you want to just let people know a little bit about yourself?
00:02:55.368 - 00:03:22.054, Speaker C: Yeah, so normally my role is kind of focused on product, helping take everything that Zach and the crypto team build and Charlie and the engineering team build, making it into something that people can click on and play with. But more recently, it's kind of more encompassing fundraising regulation, a lot more boring things, but they're also very important. So, yeah, do a lot of different hats here at Aztec.
00:03:22.102 - 00:03:23.710, Speaker A: Would you say you work on product?
00:03:23.860 - 00:03:34.046, Speaker C: Yeah, technically that's my full title, but yeah, at the moment it's been a few other things have crept into that remit as it is in a fast growing company.
00:03:34.148 - 00:03:39.090, Speaker A: Cool. And Charlie, this is the first time we meet. Tell me a little bit about what you do at Aztec.
00:03:39.590 - 00:04:06.506, Speaker D: Yeah, well, I'm the lead engineer here at Aztec, and I've been here about three years so far. And I've been involved in almost everything since the trusted setup. But I define a lot of the tech stack that we use and the process. And I've just been very heavily involved in engineering Aztec too, and our new product that we'll be launching soon, Aztec Connect.
00:04:06.608 - 00:04:20.506, Speaker A: Very cool. So you just mentioned the trusted setup. Years ago. I did. I think now we're talking. Two years ago, I did a series on trusted setups. And I think we had Tom, who was at Aztec at the time, on the show talking about Ignition.
00:04:20.506 - 00:04:21.726, Speaker A: That was the name, right?
00:04:21.828 - 00:04:23.402, Speaker D: Yeah. We go to Aztec. Ignition.
00:04:23.466 - 00:04:47.960, Speaker A: Aztec ignition. And so that episode will link in the show notes. That was a multi interview episode. I interviewed a number of people doing trusted setups. I remember being really impressed with the Aztec Ignition ceremony and actually later doing I helped Kobe do the Plumo ceremony. And that was one of the ones we were really looking at as like a guide. Tell me a little bit about what it was like to build it.
00:04:49.770 - 00:05:27.566, Speaker D: It was fun to build it. It was the first thing that I was actually doing when I joined Aztec. I think our trusted setup was they're all quite different. Like, people have these different algorithms, and ours just was this process of doing huge numbers of elliptic point scalar multiplications, like 100 million of them, I think. And it was done sequentially by, I think, over 173 people around the world. So the actual effort of process of doing this elliptic curve scalar multiplication was fairly simple. So that was kind of already done.
00:05:27.566 - 00:06:10.126, Speaker D: I just needed to make it extremely performant, like parallelize it over many cores. It was about 6GB of data that needed to be shifted from participant to participant. So I built a coordination server, just a centralized thing that basically and these Docker images, which meant that there was a very low barrier to entry to run it. It's like if you had Docker, you could just run this thing and it would connect to this server. It would put you in the queue, and when your turn came around, it would just stream the data down, perform these elliptic curve scale modifications, and sort of stream the data back up again, ready for the next candidate to pick it up. And we visualized this all on like a pretty globe that I think is still visible.
00:06:10.238 - 00:06:31.674, Speaker A: Yeah, I remember that. Was it a mean this was your first project, maybe actually Joe is more on the coordination side. Was it a fun activity? Was it something that brought your team together? Or would you say it was also kind of like a burden? Like trusted setups kind of get they get, kind know, a bad rep. Yeah.
00:06:31.712 - 00:07:16.886, Speaker C: I think there's a lot of coordination between kind of people we wanted to run it who were not members of the public but had specific requirements. They wanted to run it at certain times or something because they were an institution. So that was definitely a headache. I remember Tom spent a lot of time kind of coordinating that. But I think the one thing that saved us compared to some of the more recent trusted setups is you could run this very quickly. I remember Charlie rented out an AWS machine and I think had the record of, what, five minutes or something for running the whole ceremony. So, yeah, the coordination wasn't that bad because we could kind of chunk the day into like hour slots and get quite a lot of people doing this.
00:07:16.886 - 00:08:02.290, Speaker C: So there was a lot of kind of updates for people to see the graph evolving, see who was doing it, whereas some of the more recent trusted setups have been like eight hour affairs or longer. Very painful because you're just like, oh, wait, someone's still running the same thing two days later. And I think that did help us a little bit because a failed participant wasn't that much of an issue because we had this coordination server, someone else could just jump back in and we got a lot of participants. I think at the time it was after Zcash. It was the largest trusted setup that had been done. And most of the, I think Plonc implementations still use the CRS that was output from that. It's now kind of a public good that anyone can use, which is, I think, a pretty cool legacy.
00:08:02.370 - 00:08:14.026, Speaker A: Cool. And that CRS common reference string. This is the thing that sort of unlocks a snark. This is the thing that you need to start a system. Is that the wrong way to say it?
00:08:14.208 - 00:08:19.658, Speaker C: I'll take a stab and then Charlie can correct me, but I view it.
00:08:19.664 - 00:08:22.870, Speaker A: As kind of maybe unlock sounds more like you're revealing.
00:08:23.030 - 00:08:54.214, Speaker C: Yeah, I think you feed it in in order to kind of obscure all the gates in your program. So for each gate in your program, you need a point from the common reference string. And that's kind of how we use it in Blanc. And the assumption there is that if that point was generated in a trusted setup, then there's no other way for you to kind of back out what happened or how that point was generated so it can be used in the program to gain privacy would be my.
00:08:54.252 - 00:08:58.940, Speaker A: And that was the piece that used to be called the toxic waste. Right.
00:08:59.630 - 00:09:45.734, Speaker D: There's this secret number, which is basically the combination of all the randomness of all 173 participants, and that is called the toxic waste. And I think nobody knows what that is because if you assume that one participant was honest and threw away their part of the randomness, then it's impossible to know what it is. And that randomness is then used as the multiplier for these elliptic curve points. So they all have this sort of same relationship to one another in terms of how they've been exponentiated, but you don't know by how far. And then you can use those elliptic curve points within the mathematics of the proving system to make a Snark basically work.
00:09:45.852 - 00:10:00.546, Speaker A: I did do that episode a year ago, but I can tell like I am actually rusty because I have a question that I feel I probably already asked before at some point. But the common reference string, is that actually secret, or is that viewable?
00:10:00.678 - 00:10:12.730, Speaker D: No, that is public information, and it is a set of about 100 million elliptic curve points on a particular elliptic curve.
00:10:12.890 - 00:10:28.280, Speaker A: But how could that be public and yet somehow it's still securing the Snark's privacy like it's keeping the Snark. If you know that, why are you not able then to discover how the Snark works or undermine it?
00:10:28.890 - 00:11:07.774, Speaker D: This elliptic curve multiplication that we do, you can take an elliptic curve point, and then there's a sequence of operations. If you want to sort of exponentiate it by ten. Say you go through this sequence and you end up with a resulting elliptic curve point, but you can't back out the fact that it was exponentiated by 1010 in this case, is the toxic waste that I'm talking about. So we have all of these elliptic curve points that sort of have these relationships to one another in the way that two four, 6816 have a relationship to one another, but you just don't know by the magnetic scalar value by which they've been exponentiated.
00:11:07.902 - 00:11:08.386, Speaker A: Okay.
00:11:08.488 - 00:11:25.510, Speaker D: Because every one of the 173 participants did it by their own random number and then took I took your result, exponentiated it, passed it on to Joe he took it, exponentiated it by a random number. So good luck trying to figure out what the combination of all those random numbers is.
00:11:25.580 - 00:11:25.862, Speaker A: Interesting.
00:11:25.916 - 00:11:31.510, Speaker D: But that sort of relationship two, four, 6816 continues to exist.
00:11:31.670 - 00:11:52.046, Speaker A: Cool. I feel like every time I talk about trusted setups, I get a little bit closer to understanding what's actually happening under the hood. Nice. Okay, so I want to keep going on kind of learning a bit about your role at Aztec, and you worked on the trusted setup, but nowadays. What kind of role do you take.
00:11:52.148 - 00:12:29.820, Speaker D: In the yeah, so after the ignition ceremony, I was then sort of started working on the actual circuits themselves for what is currently our production, aztec Two, as it's sometimes referred to system. And yeah, I mean, I sort of just laid the foundation, the architectural foundation of that system and wrote some of the initial circuits. And then as the rest of the team became free after moving on from our original Aztec One, everybody else sort of started contributing and we've taken that on to the current live system as UK money.
00:12:31.950 - 00:13:32.922, Speaker C: Yeah, I mean, I think Charlie's probably underselling himself a bit there. Charlie's really responsible for everything from past the cryptography. As soon as that's been put into kind of a workable cryptography production piece of software, charlie and the rest of the engineering team takes that and kind of builds it into kind of a usable kind of engineering piece. Of software that's everything from our client SDK, which kind of acts a bit like a full node in the browser, to our roll up software, which actually aggregates thousands of transactions together and posts them to Ethereum and yeah, as a result, post launch, we're actually moving Charlie up to CTO. He's been with us for three years now, and I think his previous work has secured all of the circuits that people are using. So we think it's a worthy title to give him to help bring Aztec to the next level as we scale towards kind of decentralization.
00:13:33.066 - 00:13:42.180, Speaker A: Very cool. I want to talk a little bit more about the structure of Aztec. So you'd sort of mentioned this research side and engineering side. How do they work?
00:13:42.950 - 00:14:24.080, Speaker C: Mean, we have a cryptography library called Bessenberg, which I think is kind of the main interface between the two. And I think that's where engineering and crypto meet. And it's probably one of the most interesting roles we're actually hiring for at Aztec is people in that library because you kind of have to have a maths knowledge. But also, I hope the cryptography team won't mind me saying this, but sometimes cryptographers don't write the nicest code. So kind of being able to kind of take cryptography, put it into code and then make it production ready is, I think, the interface. And Charlie can talk a bit more about how the team's structured around that.
00:14:24.790 - 00:15:21.502, Speaker D: Yeah, so I think Joe's described it quite well as there's this interface between the cryptographers and the larger engineering team which who sort of operate at a higher level. Like, I myself, for example, am not a cryptographer. I'm sort of like, trying to learn as much as possible as I go along. And it's a slow process because it's quite complicated. But, yeah, our cryptographers, they're largely working on proving system related things. And I guess where we sort of meet in the middle is the circuits themselves, because writing the Snark circuits, we currently write that all in C plus plus using sort of a custom standard library, our representation of a Bool, our representation of an integer, and normal engineers can understand those concepts. The cryptographers kind of build these little components, these little bools and int components that work in the proving system and so that normal engineers can then start building circuits.
00:15:21.502 - 00:16:08.354, Speaker D: There's still some sort of nuance to writing circuits. You need to get your head into a certain sort of way of thinking. Like certain things don't exist at the moment, like easy branching logic, if statements, things like that need to be done in sort of clever ways. But there's definitely things that engineers can pick up. I mean, I picked it up and I sort of wrote the initial circuits, so that's kind of like the meeting point. And then, of course, taking that and actually turning that into a real, viable, functioning product that works in the real world is just a whole nother sort of leap like the theoretics and sort of like getting something theoretically sort of working. And like a little green tick in a test is like one thing, but being able to make that operate at scale, reliably and stably is a whole nother thing.
00:16:08.392 - 00:16:15.810, Speaker A: Wow. This actually makes me a bit more curious, Charlie, to your background before that, what were you doing that sort of led you to this role?
00:16:17.030 - 00:17:00.878, Speaker D: Well, I've just always been a huge computer geek. I started programming when I was about ten years old and I just sort of fell in love with it immediately. And, yeah, I originally wanted to be a games developer. It was that sort of formative gaming time back in the 90s where games like Doom and things were coming out. That industry exploded into hundreds of thousands of people, like sized teams, and that kind of put me off a little bit. I liked the idea of the small team creating something big, and I went through various sort of big companies. I worked toshiba Betfair, Bloomberg, and then I didn't like the big companies, so I moved to the startup space, worked for a couple of small startups.
00:17:00.878 - 00:17:32.202, Speaker D: And in 2016, I got into crypto like so many did, and sort of thought, wow, the flavor of this is much like those sort of formative gaming years back where you've got constrained environments and you're sort of changing the world at the same time by sort of building in them. And small teams of people can really make a difference. And that's when I sort of knew I wanted to get into crypto. I sort of started working on personal crypto projects, client libraries and the like. And eventually I discovered Aztec. And I'm very glad I did.
00:17:32.336 - 00:17:33.114, Speaker A: So cool.
00:17:33.232 - 00:17:36.830, Speaker C: I think we found well, you found us in the dark depths of Reddit.
00:17:37.810 - 00:17:49.554, Speaker D: I discovered Aztec and reddit. I think I originally sent an email, got no response. I think it just got lost in the ether, but I was not put off. And I tried again a few months later and yeah, it all worked out.
00:17:49.672 - 00:18:04.040, Speaker A: But, I mean, working with Aztec, it's not just kind of blockchain zero knowledge. What was the connection there? Do you feel like it's not straight up crypto? How does ZK add to that?
00:18:04.570 - 00:18:39.730, Speaker D: Well, I think the privacy aspect of what we're doing sort of sits with me ideologically. Personally, I'm big on protecting user data and privacy and things like that. I think we're in a bit of a dark time of users having their data mined and being controlled by their data. And I think it's really important that we protect what we have by having effectively private forms of cash and things like this. And also, I think there's just huge business gains to be had for this, for parts of the world that are economically developing, et cetera.
00:18:40.230 - 00:19:19.040, Speaker C: I was just going to say, I think on premise, mine and Charlie's kind of not differences, but how we view what can be built with Aztec are most emphasized by kind of Zkmoney and Charlie's interpretation, which is a command line interface which he built around our kind of very kind of like hackerish and maybe taking you back to those doom days. But, yeah, I think it just shows that there's a lot of different flavors to kind of privacy and what can be built on the network and a scale of privacy as well, which people will find their level on.
00:19:19.490 - 00:19:31.662, Speaker A: You just mentioned, actually, I mean, I think I am very curious about what that connection is between Zkmoney and Aztec Connect. So, yeah, tell me. Well, actually, maybe let's start with introducing Zkmoney.
00:19:31.806 - 00:20:54.218, Speaker C: Yeah, so Zkmoney is our kind of example application of what can be built on top of Aztec. We first shipped the first version of it, actually, for Aztec One. It was very clunky, enabled confidential payments, and its goal was to show what's possible with the Aztec SDK. It got a massive kind of upgrade and revamp in March 2021, which is, I think, what I spoke about on the last episode, enabling these fully private payments for cheaper than a normal ethereum transaction, really showing kind of that privacy was no longer a UX burden. And what we've done kind of with the new version of Zkmoney, which is kind of coming out with the Aztec Connect launch, is we've upgraded it to have all the new functionality of the Aztec SDK that's been added by Aztec Connect. So you can think of Zkmoney as kind of a showcase of what's possible to build with our SDK now that the Aztec Connect functionality has been added to it. And as a reminder of Aztec Connect, it's a kind of set of tools to enable people to interact with layer one, DFI contracts completely privately from inside Aztec, and with ten to 30 times gas savings for a process called DFI patching.
00:20:54.314 - 00:21:10.018, Speaker A: So the roll up I mean the ZK money is still going to be ZK money. I thought Aztec Connect was kind of taking it over. Aztec Connect is the suite of tools which actually allows you to do stuff on the kind of main chain across to the L Two.
00:21:10.184 - 00:21:58.050, Speaker C: Correct? Yes. So we have kind of a solidity contract interface, which is the Aztec Connect bridge interface, which enables the roll up contract to talk to any DeFi protocol. It effectively models the DeFi protocol asynchronous token swap. So you take two tokens, put them in, and sometime later you get two tokens back and you can model most of DeFi like that, which is kind of cool. And then we have the Aztec SDK, which enables you to construct zero knowledge proofs to interact with these kind of contracts. So the way you do that is you have shielded funds on Aztec. And instead of sending them to another user, like you could do kind of with the original SDK, you can now send them to what's called a bridge ID.
00:21:58.050 - 00:22:35.498, Speaker C: And a bridge ID is kind of this encoded set of instructions which tells the roll up contract, which layer one smart contract to call and with kind of what funds. And if that proof is valid, it could have come from anyone inside Aztec. And it's kind of how we get privacy. And then I guess the really cool part is you can actually batch these together. So if we all do the same transaction, we can be bundled together in a giant kind of aggregated roll up proof, and we all share the gas costs. So we can kind of do the same uniswap transaction for a 10th of the price or 100th of the price, depending on how many people are in the batch.
00:22:35.594 - 00:22:38.826, Speaker A: Does the batching in this case contribute at all to privacy?
00:22:39.018 - 00:23:07.654, Speaker C: No, it's actually just gas savings. The batching, the privacy set is kind of quite hard to define. But our best effort at the moment is the set of depositors that a given public kind of bridge interaction could have come from, plus the set of bridge interactions, which also brought that asset in. So if you think about kind of I'll try again. But if you think about I'm making.
00:23:07.692 - 00:23:09.446, Speaker A: A bit of a confused face here.
00:23:09.548 - 00:23:35.882, Speaker C: Yeah. If you think about ETH as a privacy set, there's kind of deposits into the system from l One, and let's say we have 100 of those. So in a simple system, the privacy set would be 100 users, kind of for a given asset. But with Aztec Connect, ETH can come into the system through two ways. One, through a deposit, and secondly, through a DeFi bridge interaction through Aztec Connect. So you could swap on uniswap.
00:23:35.946 - 00:23:42.894, Speaker A: You could kind of oh, yeah, I see what you're saying. Okay. Because there is just the deposit swell. There's, like people just using it in sort of its vanilla.
00:23:42.942 - 00:23:55.362, Speaker C: So this privacy actually can grow pretty exponentially because there's multiple ways now for kind of ETH to get into the system, and we're excited about that growing.
00:23:55.506 - 00:24:03.770, Speaker A: Can you, though, go in through the DeFi way and then out in the vanilla way? Not really. Right. Doesn't the contract sort of cause both actions?
00:24:04.350 - 00:24:26.942, Speaker C: You can deposit, do DeFi interactions and then exit with those funds, so it's kind of fully composable. But you have to start with funds in Aztec, so either via kind of a deposit or we're working on various on and off ramps to kind of have other ways to get funds into Aztec from centralized exchanges.
00:24:27.086 - 00:24:29.330, Speaker A: Cool. Oh, wow. Like potentially directly there.
00:24:29.400 - 00:24:30.020, Speaker C: Yeah.
00:24:30.870 - 00:25:01.610, Speaker A: The reason I was asking if the batching had anything to do with privacy was that, you know, I think also last year we did something called ZK Sessions, focused on privacy and DeFi. And Zach had talked about a way to make a private dex using batching. And that was when you said that term, I thought, oh, maybe it was related. But what you just kind of suggested is you're actually going to do the DeFi in the roll up in private.
00:25:02.110 - 00:25:05.274, Speaker C: So actually the DeFi stays public in Aztec Connect.
00:25:05.312 - 00:25:06.478, Speaker A: Oh, it does? Oh, really?
00:25:06.564 - 00:25:24.740, Speaker C: So if you think about, we've got all these building blocks on layer one, so we've got uniswap, we've got Aave, we've got all of these kind of, I guess, battle tested, more like institutions now in DeFi that have survived a few kind of market crashes like yesterday and the day before.
00:25:26.250 - 00:25:29.030, Speaker A: By the time this airs, hopefully.
00:25:30.490 - 00:26:48.926, Speaker C: And what Aztec Connect enables is kind of instead of having to move those to a new execution environment like Aztec, we actually just keep them where they are and we move the users to Aztec, make the users private, and let them then interact with these public protocols. I think what Zach was maybe talking about previously is it's actually quite hard to make a private uniswap because by definition it's the ratio of two public pools, so it's actually quite difficult. So with Aztec Connect, we took the approach that giving users privacy around kind of which user was interacting with a given D Five protocol and also what a user's holdings were with sufficient privacy. Rather than kind of reinventing the wheel, having to move liquidity to the L Two and kind of rebuild everything from scratch on the L Two. And that's definitely been one of the main selling points of Aztec Connect. There's a lot of protocols that I call them second order protocols, but they're not just dependent on their own smart contracts. So something like an element, even something like a lido, it can't really move to a traditional L Two as a different execution environment because it relies on something else being on L One.
00:26:48.926 - 00:27:22.620, Speaker C: So with lido, you need the deposit contract for the beacon chain to be able to actually use lido. And that's not going to move to an L Two or with element, you need kind of balancer and curve and loads of other protocols to actually exist for their protocol to function. So there's this unsolved question with traditional L Two s around, kind of breaking composability and liquidity fragmentation that we didn't really want to have to try and solve. So we just made the users private and gave them a way to cheaply and privately access what they already loved on L One.
00:27:23.710 - 00:27:36.894, Speaker A: This makes me curious. Can you use assets on CK money as collateral in other things? Do you have that use case or is that like is there yeah, definitely.
00:27:37.092 - 00:28:33.530, Speaker C: So all an asset is on Aztec, and All ZK money is just like a viewport to show you what assets you have on Aztec. But let's take a really simple case of ETH. All Zke ETH is which is kind of our name for assets inside Aztec. It's ETH that's owned by the Aztec Roll up contract. So you send your ETH to the Aztec roll up contract on layer one, and in return you get a claim on that ETH in the form of a UTXO note, because Aztec works on UTXOs under the hood, and you can do that for any asset. And then to go back to the question on can you use that for collateral? If there's something on l One that kind of accepts the assets you have as collateral, you can construct a zero knowledge proof that instructs the roll up contract to send it to that l One smart contract via Aztec Connect as a bridge.
00:28:33.610 - 00:28:34.142, Speaker A: Wow.
00:28:34.276 - 00:29:00.418, Speaker C: So any kind of like, collateral is possible to kind of deposit. And that's exactly where we're starting with that step Connect, actually, as well. So kind of staking all these kind of low immediacy use cases, like lending staking kind of yield use cases. We'll start with just Ethan Dai, but we'll be very quickly adding in most, ERC, 20 tokens and expanding kind of the places you can deposit assets as collateral and earn a yield.
00:29:00.514 - 00:29:20.320, Speaker A: Wow, that's exciting. Do you feel like Aztec Connect is the piece that makes I mean, it sounds like it's the thing that really opens up ZK money to be much more usable than what it is right now. Which is mean, actually. Yeah. This is a question. How do people use Zkmoney without it?
00:29:20.690 - 00:29:57.786, Speaker C: Yes, it's a great question, actually. So, two ways. So you can either use it for just paying friends, dao contributors, just paying people privately on chain. Most people do that with Dai because it's dollar stable. Or you can use it a bit like a mixer at the moment and withdraw your funds back to L One. And then you have a form of privacy on L One to go and interact with the D Five protocol, but you don't get gas savings. And what Aztec Connect enables is kind of all of the things that people used to leave to go.
00:29:57.786 - 00:30:17.120, Speaker C: And do, they can now stay in Aztec and access them through ZK Money. So it's just a much better kind of user experience. You don't have to keep track of multiple wallets on chain to work out. Hey, did I withdraw to this address previously? You just do everything from inside Aztec and you have this privacy. By.
00:30:19.410 - 00:30:44.300, Speaker A: Mean, I wonder how much can you see as the engineers building this of the activity inside? Since it's private, I'm almost like curious what behavior I guess you haven't seen Aztec connect behavior yet because it's not launched as we're recording it. But even in just kind of generally maybe in testnets or like, how much can you see into what is actually happening inside?
00:30:45.070 - 00:32:00.130, Speaker C: Yeah, I can take a stab at the on chain and maybe Charlie can talk a bit more about SDKs and kind of what's technically possible for people to decipher. So on chain, because DeFi protocols that we're interacting with are public, we can see which DeFi protocol a given set of transactions is trying to interact with, because you're going to see it on Etherscan and you can also see the total amount that a group of users want to send to that protocol. But what you can't see is what users on Aztec that came from, what their total balance is on Aztec. But you can see kind of the public kind of transaction that results from the correct verification of ZK roll up on Ethereum. So another way of thinking about it is kind of the Aztec roll up contracts like this puppet. And if people pull the strings in a certain way with a zero knowledge proof, then it will make a transaction with a DeFi protocol. So if you looked at Etherscan, you just see this roll up contract interacting with various protocols instead of users interacting.
00:32:00.130 - 00:32:06.690, Speaker C: So you can still see some stuff, but you can't see who which is, I guess, the big breakthrough.
00:32:07.830 - 00:32:15.990, Speaker A: And what can people see under the hood, like in Zkmoney? Or what can you see actually as engineers or somebody who's observing what's going on?
00:32:16.140 - 00:32:55.486, Speaker D: Well, the SDK, what we call the SDK runs on the front end. On the back end, we receive these joint split proofs from every user which is generated inside that SDK, which runs in the client's browser. And we don't see I mean, this is the same as ZK Money right now. We don't see anything like the values that come through are encrypted. We can see an IP address sent this proof, but we don't know the values or who sent that proof. Like we can't identify them within the system. The SDK which runs in the client well, that only has a view of specifically your account notes.
00:32:55.486 - 00:33:20.220, Speaker D: It downloads actually, all of the data that's taken place, it downloads. There are these things that we currently call viewing keys. There are these encrypted pieces of information for every single note in the system. But they're encrypted. And we actually, at the moment, have to do a brute force decryption over all of those to find out which ones yours belong to you. So you can only see what obviously you're allowed to see.
00:33:21.870 - 00:33:29.040, Speaker A: Can you see volume, or would you calculate volume more from the bridge part? Like, do you know how much activity is happening?
00:33:29.650 - 00:33:58.086, Speaker D: Yes. Well, we can see sort of transaction throughput, so we can see how many proofs were being sent. We can see we have graphs, these pretty little graphs where we can see, oh, gosh, it was a really busy few hours or a really busy day, or it's a bit quieter now. But it is quite mysterious to have a system running in which you've got a bunch of people using it and you don't really have any insight as to actually what they're doing. It's quite different to anything that obviously I've worked on before.
00:33:58.268 - 00:34:08.860, Speaker A: As a user, do you have the ability to create, like, a viewing key? Is that what they call it? If they wanted to show that something has happened, can they do that?
00:34:10.510 - 00:34:36.130, Speaker D: If you wanted to reveal your you can obviously share your keys with people. I'm not sure if you'd want to do that, but if you want to share your privacy key with someone that can obviously reveal your balances and your notes, that does not give people the ability to then spend them. That's handled separately by something called spending keys. Okay, so you can control who can view and who can spend as two separate things.
00:34:36.200 - 00:34:43.174, Speaker A: But you call it like privacy key, not private key. You're not sharing your private key, are you?
00:34:43.292 - 00:34:58.054, Speaker D: So there's all sorts of terrible terminologies that get conflated with one another. When we say privacy key here, it's also you can be thought of as like your privacy key has two aspects to it has both a public and private key aspect.
00:34:58.182 - 00:35:28.722, Speaker C: Yeah, it's just not used. So they're both private keys. But the use of the private key, it has a different outcome. So the privacy key is purely used for encryption and decryption of notes. It can never spend notes, and the spending keys can spend notes. So we separated it for regulatory reasons. Also just because if you have multiple devices, sharing spending keys across devices is really difficult with, like, hardware wallets.
00:35:28.722 - 00:36:17.974, Speaker C: But something like a privacy key could have slightly different security assumptions and could be shared across multiple kind of devices. It's a different set of trust assumptions. Basically. You can also do kind of more interesting things like proof of transaction logs. So if you give someone your kind of privacy key and a set of transactions, it effectively acts as a compliance log. You can say, okay, in Aztec, I only transacted with these four individuals, and I then did these ten DFI interactions with myself. So all the funds I have in Aztec, which total one ETH came from these events, which is really useful for kind of off ramping to centralized exchanges or just doing tax returns and things like that.
00:36:18.012 - 00:36:36.886, Speaker A: So you were saying, though, that you're now opening it up to have centralized exchanges potentially connect directly to the L Two without, I guess, going through kind of ethereum. Do you have the vision as well to have other L Two S connect directly into Aztec?
00:36:37.078 - 00:36:51.614, Speaker C: Yeah, it's definitely something that's on the roadmap, but it's a little bit further away because what you need is kind of a version of Aztec on the L Two, and then you need full.
00:36:51.652 - 00:36:53.566, Speaker A: EVM compatibility on the L Two, then.
00:36:53.588 - 00:37:42.398, Speaker C: Yeah, and you need to be able to pass messages between them. So if you had kind of Aztec running as an l two on ethereum and then Aztec running on another EVM compatible chain l two or kind of other layer one, if you had a very good way of passaging messages between them. You could kind of effectively represent all transfers between these two Aztec instances as, like, a state hash of a merkel tree. And then on the new environment, you could kind of unwind that and say, okay, well, I've destroyed funds on the kind of canonical Aztec L Two instance, so I'm going to be able to create funds on the new kind of Aztec polygon or Aztec optimism. But it's a bit of work.
00:37:42.564 - 00:37:49.954, Speaker A: It also sounds like that bridge needs to would you almost be sending a Snark promising that something's happened on one side to the other?
00:37:50.152 - 00:38:27.840, Speaker C: You're just sending a hash, and then you kind of would kind of unpack the hash on the other side. So there'd be kind of like two roll ups. But I'm definitely oversimplifying. And the kind of security of that messaging bridge is there's a lot of posts by kind of vitalik on the security of bridges. And it's just not something we're thinking about in the immediate term because with the current design, we can actually achieve a lot of the scaling kind of benefits of other L Two S directly inside Aztec. So there hasn't been a need yet. But if one of these environments actually takes off, I think we would strongly start to consider it.
00:38:28.850 - 00:38:34.340, Speaker A: No one can deploy a smart contract within ZK money, though, right?
00:38:34.790 - 00:38:58.200, Speaker C: Not yet. It's a misconception, actually. So we have programmable circuits, and we've had them since we launched Aztec Two. Charlie just had to write them. So we have an account circuit. Charlie and the whole team had to write them. We have an account circuit and a payment circuit in the currently live system with Aztec Connect.
00:38:58.200 - 00:39:43.762, Speaker C: We spent over a year adding two circuits, a DeFi deposit circuit and a DeFi claim circuit. So these are kind of programs that the Aztec team has written. We've had to kind of use the whole cryptography team to audit these. It's a lot of work to kind of write these programs, but we do have programmability. We are working, though, on a way to kind of have general purpose programmability where you don't have to be kind of working for Aztec to write circuits in Aztec. And that's where kind of Noir fits into the puzzle. Yeah, we have this open source project, Noir, which is led by Kev, and it's a DSL for Snarks, specifically Planck based Snarks.
00:39:43.762 - 00:40:09.566, Speaker C: And it enables you to kind of very easily write Snark programs without having to be a cryptographer. And that's kind of what Noir does internally. We also have a project called Aztec Three, which kind of enables the roll up to consume Noir circuits. So it's like the missing piece to have, like, a fully programmable, private smart contract platform running on ethereum as an.
00:40:09.588 - 00:40:31.958, Speaker A: Lt cool when you say I sort of want to tease that out of what you can actually build. It almost sounds like you're hard coding. It's not a platform to just deploy contracts. So when you talk about a smart contract, I'm assuming you're actually touching the actual construction of this roll up.
00:40:32.124 - 00:40:51.198, Speaker C: Yeah, I think at a high level, the current state of things is all the programs that we write, or circuits that we write, act on shared state, so that's the main complication is there's one merkel tree which has all the data in it, and any program that we deploy into our roll up can modify that state.
00:40:51.284 - 00:40:51.534, Speaker A: Okay.
00:40:51.572 - 00:41:39.980, Speaker C: So we have to be very careful about kind of what those programs do, because they could inadvertently, if there's a bug, you could think you're spending funds, but you could delete someone's account, or, like, you could do some pretty serious stuff. So we can't open that up to the public at the moment. So what Noir basically enables is it wraps those programs in a virtual machine, which kind of enforces some smart contract like semantics. So state variables have owners. You can't destroy state unless you own it or you have permission to destroy it, and you can call other contracts within the system, much like you can on Ethereum. So that's kind of what Aztec Three and Noir kind of enables, which is missing from the current system.
00:41:40.430 - 00:41:54.558, Speaker A: I see. What would it mean for someone to use this? When you talk about I'm trying to sort of picture an engineer coming, maybe you can just tell me, what could they design, what would they design, and how would they actually interact?
00:41:54.734 - 00:42:56.786, Speaker C: I think the place to start is if you imagine Aztec Connect as these programs we've written, we've tried to make a generic interface for all of DFI, and we think it probably captures 80% to 90% of protocols, but there's probably some protocols where it doesn't sufficiently kind of capture the needs. So the first sort of use case would be just modifying Aztec Connect, but doing it in a kind of maybe adding three asset types in instead of two, or adding kind of NFTs or some kind of different mechanic by modifying kind of our existing programs. And then from there, you kind of start to think about kind of more interesting use cases like coding up a dow where the voting mechanics are private or the rules that govern the dao are actually written and in. An Aztec contract and are hidden or kind of moving all the way up to kind of Zkit games which is a bit further in the future but something that we're super excited to kind of work on once it's ready.
00:42:56.888 - 00:43:01.366, Speaker A: How do you interface with Noor? Is it part of Aztec's company that's doing it?
00:43:01.388 - 00:43:34.446, Speaker D: Yeah, we have a small crack team of compiler experts that are currently working specifically on Noir still. It's still sort of in development. The syntax is still being figured out. It's very rust like in sort of its syntax. There's a specific team working on that and then obviously the Aztec Three team which has to write all the supporting smart contracts to enable that full programmability. They're a slightly separate team. Yeah, that's currently how they're interfacing, but they're still sort of in their research and early prototyping phases.
00:43:34.558 - 00:43:53.702, Speaker A: Cool. How does noir compare to things like Leo or Snarky JS? There's other basically ZK languages. We've done a few sessions, actually at Zkhack and AZK sessions, where we had Alex Osdmere do a survey of these different languages. Where does Noir fit in?
00:43:53.836 - 00:44:52.374, Speaker C: I guess the reason we set out to build kind of a new one when there was already so many is at the time, there wasn't a Plonc specific kind of DSL. And that's really what Noir is kind of designed to enable. Some of the kind of CircleMan artworks now support Planck based kind of proving systems, but they kind of were originally written for kind of multiple different proving systems, and Noir can support multiple ones, but it's specifically designed for kind of the optimizations around Planck based proving systems. So that's kind of why it exists. And we kind of wanted to make it a much higher level language than some of the existing Snark based languages. Something like a Circum doesn't really have like a standard library. You have to kind of implement everything from scratch and really be a cryptographer.
00:44:52.374 - 00:45:29.110, Speaker C: So if you want to be doing like a merkel proof or a range constraint, you'd probably have to write that or maybe use one that someone else has written, but it's not supported in the language itself. Something like Noir exposes kind of all of Aztec's standard library through its programs. So you get kind of the benefit of the Aztec cryptography team if you're just a small kind of two person startup building something in Noir, you can rely on kind of our cryptography and really not have to worry about being a cryptographer. Just work on program features and what you want to build.
00:45:29.260 - 00:45:42.860, Speaker A: How do you think the different languages play out down the line? Will there be ways for these languages to sort of interact with each other. And maybe that's not like, the problem you need to solve, but could that happen?
00:45:43.470 - 00:46:28.440, Speaker C: I think technically I'm a little bit out of my depth here. I know that one thing that we're working on with Noir is enabling kind of you to take a Noir program and compile it to different kind of back ends, as we call it. And we have, like, an intermediate representation in between, kind of the front end of the language, like what you see when you're a developer writing the program and actually the proving system. So I think kind of if you can compile down to the same intermediate representation, there'll be a way for you to kind of potentially use different languages in different settings. But these are all quite experimental at the moment.
00:46:28.810 - 00:46:36.940, Speaker D: It would require a lot of standardization from various teams to agree on what you agree to and what you settle on.
00:46:38.110 - 00:46:48.170, Speaker A: I do want to talk a little bit about Plonk. I mean, Plonk was a creation of the Aztec folks. It was Zach and Ariel. Was there any other authors on the original?
00:46:48.330 - 00:46:52.750, Speaker C: Yes, we had Wanner as well who worked on some of the security proofs, I believe.
00:46:52.820 - 00:47:15.718, Speaker A: Cool. I mean, Plonk's been an incredibly powerful concept, I feel like, in the ZK space. Tell me a little bit about how much more development has happened internally. What is the roadmap for Plank? I know there's other teams who've also been running with, like, how do you kind of interact with that whole thing? And I know neither of you are necessarily the folks that do this directly, but yeah, if you can just speak.
00:47:15.804 - 00:48:16.822, Speaker C: On behalf of yeah, I think what both mine and Charlie's take here is around what a different proving system enables. So our current system is still being written in Turboplanc, which is probably two and a half years old now. I think the paper and we think about it in terms of how many gates does it kind of take to prove or write a program that does kind of a ZK Money or Aztec Connect transaction, and how long does it take to prove that? Because that's what the end user sees and that's the world we work in. It's kind of like, am I waiting 30 seconds or 10 seconds to do a transaction when I generate this actual proof? So at the moment, we're still using Turboplunk. Transactions on the client take around 10 seconds, and our kind of largest roll ups take about seven minutes. We are upgrading to Ultraplonk in summer.
00:48:16.886 - 00:48:20.422, Speaker A: I love these names, Turboplunk and Octoplanc.
00:48:20.486 - 00:49:20.378, Speaker D: Correct me if I'm right if I'm wrong, but like Turboplank made range constraints particularly cheap. So if you consider proving time is directly proportional to the number of gates in your circuit, like in Planck, to do a range constraint requires is this number, for example, between these two values required a huge number of gates. Turboplonk reduced that down to just like a handful of gates for a range constraint, and thus it reduced proving time. And Ultraplonk makes sort of a similar leap for certain things like complicated bitwise operations. We can use many, many less gates to do, like right shifts and ands and things like that, like bitwise ands which makes certain algorithms that exist in the real world, such as Shah Two, Five, Six, cheaper. It will enable things like signatures to be done on curves that are not sort of native Snark curves. And it sort of opens up a world of opportunities there because you can do them so much faster.
00:49:20.474 - 00:49:25.634, Speaker A: You called it Ultraplunk, but I think I had heard Octoplanc, but that isn't what you said.
00:49:25.672 - 00:49:30.100, Speaker C: Was it Octoplanc? I think was shelved in favor of a slightly better name?
00:49:30.790 - 00:49:34.402, Speaker D: I like Octo to go through the full list.
00:49:34.456 - 00:49:51.610, Speaker C: I think we have standard plank, turboplank and Ultraplonk. Ultraplonk, the ones which are kind of immediately being deployed. And then the cryptography team to support Aztec Three is working on something which has been called Megaplanc Octoplanc, but I think is now called Honk.
00:49:52.110 - 00:49:52.860, Speaker A: No.
00:49:54.670 - 00:50:15.766, Speaker C: That is the latest of the cutting edge, but we haven't published that yet. But it's kind of work in progress that supports kind of a further increase in or reduction, improving time needed for Aztec Three because you have kind of these much more complicated programs you need to run with Aztec Three and NOAA.
00:50:15.818 - 00:50:19.058, Speaker D: I should add that Honk has an exclamation mark at the end.
00:50:19.144 - 00:50:38.470, Speaker A: Yes. Oh, my God. That's amazing. Just a question, I had Mary Mallor on the show just recently talking about a lot of the work that she's been doing, and one of them was on lookup tables. Does one of those incorporate lookup tables? Does Turboplanc do it?
00:50:38.540 - 00:50:41.274, Speaker D: Ultraplunk has I see. Lookup tables, yes.
00:50:41.312 - 00:50:41.978, Speaker A: Okay, cool.
00:50:42.064 - 00:50:44.966, Speaker D: That is what enables these efficient bitwise operations.
00:50:45.158 - 00:51:00.030, Speaker A: Got it. If anyone's curious, I can link to the Mary episode where we explain a little bit deeper what a lookup table is. There's also a part of your stack that we found called Falafel. What is falafel?
00:51:01.010 - 00:51:28.760, Speaker D: Yeah, we have a lot of food related names. Falafel. I don't know who started it. It definitely wasn't me, although I did start them at the Middle Eastern trend in some of our services. And Falafel is the name of what many teams probably call their sequencer or their coordinator. It's just the server that we run that the browser sends proofs to and it sends you data effectively. It's just like sort of an internal code name.
00:51:29.790 - 00:52:00.814, Speaker A: Actually, let's talk a little bit about the roll up build. You mentioned a sequencer. Is there a plan to have sort of a decentralized sequencer community at some point? This is sort of I'm going to just for the listener. The roll ups have sometimes different names. There's committees, sequencers, there's agents, and almost every system that bridges between two networks will have names for the thing that does it. In your case it's sequencer falafel. Falafel.
00:52:00.814 - 00:52:07.270, Speaker A: In your case it's Falafel. Is this the agent that also is making a Snark?
00:52:09.210 - 00:52:16.630, Speaker D: It's coordinating the creation of the Snark. We actually have another service that runs behind falafel called Halumi and that produces.
00:52:17.210 - 00:52:19.466, Speaker A: It'S almost a sandwich amazing.
00:52:19.568 - 00:52:45.146, Speaker D: That actually produces the Snark itself. That is a service that specifically runs this highly optimized C code and it runs on huge, great big machines in AWS at the moment and that generates the Snark itself. And philanthrop just asks Halumi to produce that proof and it kind of collects these things together and then it publishes them to mainnet. So you can actually have many, many Halumis, but you can only have one falafel.
00:52:45.258 - 00:52:49.770, Speaker A: Oh, okay. So what many Snark at the moment?
00:52:49.940 - 00:52:57.426, Speaker D: I mean, you specifically asked about decentralization. Of course we want to as time goes on, we want to decentralize. So there would be many falafels as well.
00:52:57.528 - 00:53:09.398, Speaker A: Very cool. The Halumi, the ones that are making the Snarks, who are what are they? Team members right now? Who's? The Snark creators.
00:53:09.494 - 00:53:32.806, Speaker D: Well, that's just a piece of software that is running like in AWS and it takes quite a huge amount of compute power to produce these things. So it's a large parallelized system that basically they just do jobs. Like there's a whole bunch of jobs that need doing and they pick them up and those jobs are producing proofs.
00:53:32.858 - 00:53:36.500, Speaker A: Okay, cool. But anyone could do it.
00:53:38.470 - 00:54:11.110, Speaker D: They are part of a system as a whole and in theory, down the line, anyone can run the system as a whole. So it wouldn't be like an individual who will run a Halumi. You would run flathle and halumi together. But really as time goes on, we want to actually move out of the data center as well. Like much, much longer term. We don't want you to have to be running an expensive machine in a data center that's not very decentralized either. So ultimately some of these services will probably condense down into single little things that people can hopefully run on commodity hardware.
00:54:11.190 - 00:54:11.434, Speaker A: Cool.
00:54:11.472 - 00:54:14.654, Speaker D: But we are looking like many years down the line for that, I think.
00:54:14.772 - 00:54:24.530, Speaker A: What do you think needs to happen kind of in the Snark world for that? Is it the Snark? That is the constraint here for being able to run on a device.
00:54:25.190 - 00:54:33.778, Speaker D: It will require next generation proving systems, which has been alluded to we're working on and just a very large engineering effort, I think.
00:54:33.864 - 00:55:04.442, Speaker C: Okay, yeah, I think it's technically possible today. It's just a lot of engineering and you would have a throughput reduction as a result. So it's the same kind of Snarks that we run in the browser. So they already run on commodity hardware, but the gates in the browser to kind of prove like the inner tiny Snark is about 65,000 gates, I think the largest roll up, what is it, close to 32 million? Gates?
00:55:04.506 - 00:55:05.854, Speaker D: Yes. 32 million, yeah.
00:55:05.892 - 00:55:44.570, Speaker C: So it's a lot more complicated when you're aggregating lots of transactions together. You could do a smaller roll up and maybe get it to run on a MacBook Pro right now, like a two x two roll up, but you would have a throughput sacrifice. So I think over the next year or two, with some kind of optimizations on the cryptography and a large engineering effort, it's all feasible. It's just kind of us charting our path towards progressive decentralization. And for now it makes more sense for us to kind of be a bit more centralized so we can update things more quickly.
00:55:44.720 - 00:55:55.338, Speaker A: Cool. But going back to that question about decentralizing Falafel, Halumi, creating this landscape, how do you do it and maybe what's the timeline?
00:55:55.434 - 00:56:57.518, Speaker C: Yeah, I think the current plan is something we call a Federated prover, and it's a model I think that Mina have pioneered actually. So you have kind of two roles. Like we have already a coordinator which we call Falafel, which basically picks which transactions go in a block, and then you have a set of workers. Currently those are all controlled by us on AWS, and we call them Halumi, but those could be decentralized and you can decentralize both parts. So our timeline to kind of working towards that end goal actually looks a bit different though. We would take the current system, which is one entity running Falafel and Halumi, and get a few other people to actually run the system as is. So we'd have some kind of trusted investors, kind of more large institutions, to kind of run clones of the current system to give redundancy and then that gives like a level of decentralization.
00:56:57.518 - 00:57:49.860, Speaker C: And in the background, then we'd work on kind of improving the engineering tech stack. To have a transaction pool which is missing from the current system at the moment, you have to pick your Falafel effectively. You don't kind of have a network like Ethereum does and have a transaction pool. So once we've built a transaction pool, it will enable kind of coordination of these roll up providers a bit more easily. And that's where kind of token economics can come in and full decentralization can occur. And I think we're actively starting to work on that over the next year. We don't have a date yet because putting dates is bad, as we've seen recently with our launch, but it's definitely something that the team is starting to work on post Aztec Connect.
00:57:49.860 - 00:58:00.790, Speaker C: And it's a priority for the company because we just believe that a fully decentralized privacy network is very important. It needs to be censorship resistant.
00:58:01.370 - 00:58:19.020, Speaker A: Got it. You just mentioned the launch. I know, we want to talk about that. So we're recording this mid June. There was a launch planned for last week and it sounds almost like at sort of the very last minute there was, like, a decision not to go ahead. Tell us what happened.
00:58:19.870 - 00:59:34.466, Speaker C: Yeah, we have a public Twitter thread on, I guess, the full post mortem, but I think the things that went wrong, we kind of ran out of road for testing very large roll ups on mainnet. We've done a lot of testing on kind of forked blockchains and the Ethereum testnets, and we'd expected those to behave like mainnet because they're a testnet and in some cases they're a copy. They actually didn't end up behaving as anticipated. So what happened on launch day? Everything had been deployed. We were sending roll ups. Falafel and Halumi were working kind of as intended and we had a final kind of load test that we were kind of planning on just running to sanity check that we could construct the largest roll up that we could currently create, which is 896 transactions in a batch. And when we constructed that roll up and tried to send it out to the ethereum main net, it wasn't mined by any of the nodes or any.
00:59:34.488 - 00:59:45.030, Speaker D: Of the guest nodes would not propagate it because there's this upper limit on the size of the transaction that you can actually send to the network, which is, I think it's 128 KB.
00:59:45.450 - 01:00:27.742, Speaker C: So it's a valid Ethereum transaction. The largest kind of Ethereum transaction by gas limit is close to a megabyte. But certain Ethereum client software imposes limits on the transaction pool to help transaction propagation. And we anticipated that not being an issue, but it ended up being an issue. So we decided to delay the launch whilst we worked on a few different solutions. The easiest one is just constraining the kind of batch size. I guess the batch size it only is really an issue for deposits into Aztec.
01:00:27.742 - 01:01:16.546, Speaker C: We'd have to constrain it from around 896 to around 400 transactions, which it does increase costs for users, but it's actually not too much because you're only amortizing the verification cost of the Snark and you've already amortized it by several orders of magnitude at 400 transactions compared to the current system. So it's not too big a deal. And the other kind of option we've been trying is Flashbots. You can actually send large transactions directly to Flashbots, bypass the Ethereum transaction pool and kind of get these large transactions mined by going directly to the miner. And you get the added perk that you kind of get mev protection by doing that. So it's something we're considering as well.
01:01:16.648 - 01:01:23.174, Speaker A: Interesting. Tell me a little bit about the moment, though, when you decided not to do it. Were you guys together here?
01:01:23.212 - 01:01:23.926, Speaker C: Yeah, we were here.
01:01:23.948 - 01:01:28.534, Speaker A: Right. Because when you launch updates and upgrades, it's a group effort.
01:01:28.582 - 01:02:16.310, Speaker D: Yeah, I think that basically we were obviously fully intending on testing this on Main net before launch. But it just so happens that that testing on Mainnet came down to, like, several hours before launch just because we had. Got delayed for various other reasons during this launch period. So we had obviously got everything out on Mainnet and we were together trying to well, together we work slightly remote, but we were all communicating very closely, generating these deposit proofs that we anticipated could be a problem. We did anticipate there could be an issue here. We needed to see that this roll up would propagate throughout the network. And it just came down to the line and when it was published and it didn't go out as anticipated.
01:02:16.310 - 01:02:27.642, Speaker D: Rather than just continuing to try and force things through, we just said we need to take a step back and we need to get this working stable before we set another launch date.
01:02:27.696 - 01:02:33.598, Speaker A: In a way, it sounds kind of lucky. Like, I'm glad that you were able to sort of stop it before.
01:02:33.764 - 01:02:45.460, Speaker D: Exactly. Because going out well, actually, because you don't want that to that to happen after launch, for sure. So our testing did work. It's just unfortunate that it was just so close to the line.
01:02:46.630 - 01:03:11.562, Speaker A: But when I saw that it wasn't happening, I also was kind of like, I think it's timing. Wise. Much, much better to have caught it and to be able to explore it and not be struggling. I think there's been other examples of networks launching maybe a little bit ahead of when they should have not. So much roll ups, but other things. And it's a lot harder, I think, to walk it back once it's out. So I think it's really good that you caught it.
01:03:11.562 - 01:03:25.818, Speaker A: What's the next stage, then? What comes next after that? The launch, I'm sure is still planned but I guess there's going to be you're evaluating these different options but in the meantime are you also then running extra tests?
01:03:25.994 - 01:03:52.966, Speaker D: We have the various teams, the cryptography team, engineering team, front end team and we've effectively reset this process whereby we all want to green light before we set like another launch date. So whereas previously we had sort of green lighted various things on the assumption that certain things were going to go well, we're being more strict this time around. So once we have those green lights from the various teams, then you'll hear more about another launch date.
01:03:53.068 - 01:04:11.006, Speaker A: I also wonder I don't know if this even factors into your decision, but right now markets are looking really rough. People are kind of, like, sad, and things are kind of unwinding. Is it a strange time to launch? Would it be a strange time to launch right now? Would it be better? Would it actually affect it at all?
01:04:11.108 - 01:05:18.930, Speaker C: I don't think it would affect the launch. One thing we have considered as part of kind of the post mortem, though, is with DeFi there's kind of a new type of denial of service that can happen in adverse market conditions. So if this were to happen and we kind of had launched and we couldn't suddenly produce roll up blocks with the launch kind of DeFi bridges. It wouldn't really be an issue because they're not borrowing based bridges. But a lot of the market kind of drama at the moment is around kind of underclaterized or heavily leveraged kind of debt positions. And Aztec Connect does eventually support debt positions. So I think one thing we're sanity checking is kind of are those kind of good Launch bridges and when should we put those in place to ensure that users can always exit from the system and they don't get kind of timed out in kind of highly volatile market periods?
01:05:19.350 - 01:05:26.630, Speaker A: So are there other kind of, I don't know, updates or research? Anything that folks should look out for kind of in the Aztec world?
01:05:26.780 - 01:05:50.620, Speaker C: Yeah, we have an update planned at some point in Q Three, Q Four, where there's a few things we're looking to achieve. The main one is upgrading to Ultraplonk, which enables Ethereum signatures. So currently you have to sign using a Grumpkin private key, which is something a name of the elliptic curve we use.
01:05:51.470 - 01:05:52.354, Speaker A: Grumpkin?
01:05:52.422 - 01:05:53.040, Speaker C: Yeah.
01:05:53.730 - 01:05:55.630, Speaker A: Where does that come from? Is that a name?
01:05:55.780 - 01:05:58.974, Speaker C: It's like Grumpkin and Hunting of the Snark, isn't it?
01:05:59.012 - 01:06:03.134, Speaker D: I think was it not Lord of the Rings? Was it what's that?
01:06:03.172 - 01:06:04.062, Speaker A: Alice in Wonderland?
01:06:04.126 - 01:06:18.980, Speaker D: No Game of Thrones. There were grumpkins and there were Snarks, and it was grumpkins without a P, but they were called Grumpkin because I think Zach named it Grumpkin and he didn't realize the P shouldn't be there. But it stuck. So now we have.
01:06:21.030 - 01:07:18.540, Speaker C: Obviously, we're upgrading to enable you to have better security, basically, in Aztec, so you can sign with your traditional Ethereum wallet. And around the same time, we're planning on seeing if we can move some data off chain. And it's linked to kind of large transactions, actually, and what went wrong with Launch. Aztec roll ups are quite large, and there's a few kind of parts to that. There's the actual proof, which is tiny, and then there's on chain data, which is the leaves of the merkel tree. And we believe that should kind of always stay on chain for the foreseeable future, unless something like, EIP, 4844 Blob transactions comes along. But then there's kind of what we term off chain data, which is viewing keys and stuff where the security assumptions are slightly different.
01:07:18.540 - 01:07:49.550, Speaker C: It's not a system liveness issue if you don't have this data. It's more a user can't access their specific funds, so it's still quite serious, but the system can keep functioning. So we are looking at ways of moving that data to kind of other data availability layers around the time of Ultraplonc. But so stay tuned for more on that because it has some pretty significant gas cost savings for users.
01:07:49.710 - 01:08:05.302, Speaker A: Well, thanks so much for coming on the show and sharing with us an update about Aztec CK money. Aztec Connect giving us a little recap on a almost launch and what we can expect soon. But yeah, thanks so much.
01:08:05.436 - 01:08:06.566, Speaker D: Thanks for having me.
01:08:06.668 - 01:08:07.990, Speaker C: Yeah, thanks a lot for having us.
01:08:08.060 - 01:08:15.410, Speaker A: I want to say a big thank you to the podcast producer, Tanya podcast editor Henrik Chris on research. And to our listeners. Thanks for listening.

00:00:09.290 - 00:01:37.450, Speaker A: Banks and I are going to talk today about the evolution of the MASP and some extensions that we've developed on top of the MASP for some interesting applications which I think have not been explored before, at least maybe not in this context. So first question probably is what is MASP? And it's certainly not an upside down Wasp if you're afraid of getting stung by a flying insect. No, it's not that. Even though the characters look similar, MASP actually stands for a Multi asset shielded pool. And what is a multi asset shielded pool? Well, maybe being a little bit reductionist, a multi asset shielded pool is a shielded pool with more than one asset type in it. Now was a shielded pool. Well, the sort of most famous and perhaps original example of the shielded pool is provided by Zcash.
00:01:37.450 - 00:03:30.110, Speaker A: The idea of the shielded pool is that you can use cryptography and zero knowledge proofs to encode transactions that happen. And because you are using zero knowledge proofs and cryptography to encode and to verify these transactions, they're so called shielded, they're not cryptographically linkable in the way that most transparent transactions are, where transactions that involve various addresses are cryptographically linked to those addresses. And we know by checking signatures which addresses are involved in which transactions. We want to start from the existing examples again, most notably Zcash, which support really one asset type. In the case of Zcash, it supports the native Zcash token, in other cases may support whatever native token there is for the pool. But we're interested specifically in shielded pools that contain more than one asset type, which means that the asset type that's involved in each transaction is also cryptographically encoded in some way. And so the properties of the asset are checked inside of a zero knowledge proof.
00:03:30.110 - 00:04:29.870, Speaker A: And so you don't have external or transparent knowledge of which asset type what was involved in each transaction. So we have to start with the Zcash shielded pools, of which there have been three so far. And I'll use Zcash's own description of what it is. It's an implementation of the original paper called Zero Cash, the original academic research paper. And this is a little understatement improvements to performance and functionality. In fact, over the last eight Ish years, there have been incredible improvements to performance and functionality. It's not just some smaller incremental or evolutionary improvement.
00:04:29.870 - 00:06:37.850, Speaker A: It's actually been quite substantial. And the general idea is that we want to accomplish things that you can do using the existing transparent systems, but use zero knowledge proofs or more accurately, zero knowledge succinct non interactive arguments of knowledge, which is a technical distinction. But we want to use these DK snarks to prove that the various properties of the shielded pool are satisfied, such as you cannot in general just create value out of nowhere, so on, so and so on. You cannot spend other people's value all these important properties we prove using these zero knowledge terms and the best place to learn about shielded pools. Most specifically are Zcash protocol specification and the issues on the Live Rest Zcash repository on GitHub. And these are really the two most comprehensive resources for understanding how shielded pools work and how the modern evolution of the shielded pool has come about. Of course, there's many other resources out there as well, but these are certainly very comprehensive and very well written resources for understanding the Zcash shielded pool and all of the research that's gone into the Zcash shielded pools.
00:06:37.850 - 00:08:01.240, Speaker A: And they are certainly not light reading. The Zcash protocol specification is not necessarily intended, at least as far as I know, to be read linearly as a textbook. It can be somewhat technical in some places. Certainly GitHub issues are also not necessarily supposed to be read linearly. However, I've found that it's an incredible educational resource and oftentimes the discussions there really give an incredible amount of context for why certain decisions were made in the way that they were. And we also have in the Anoma MISP repository some documentation about the multi asset shield pool specifically, which assumes generally that you're familiar with the Zcash shielded pools to begin with and doesn't repeat very much. So these resources are primarily where we draw from for the MXP and where we're going to draw from today.
00:08:01.240 - 00:10:49.180, Speaker A: So where do we start? Well, we're going to start our discussion with Zcash Sapling, which was the shielded pool upgrade that came out a few years ago. We now have Zcash orchard, but we're going to be talking about Zcash Sapling, which is still an incredibly good technology, which is still very much relevant today because it was such a massive improvement in efficiency and other benefits. And so we're going to use Zcash Sapling as our starting point of the discussion, which is quite an important starting point because of the fundamental changes that were made with Zcash Sapling and the fundamental improvements over the previous shielded pool sprout. And so I took this equation from the Zcash protocol specification and I wanted to share it first because this is probably the most significant change in the Sapling upgrade for our context, which is using this notion of a homomorphic value commitment. If we recall from our cryptography background, commitment in cryptography is a way of sort of locking some information into a box, kind of a cryptographic box, such that it has two properties that are important hiding and binding. Hiding meaning that once you lock this information in the box, it's not sort of readily apparent from the outside what information that you've locked inside and binding in the sense that when you unlock the box and reveal the secret information that was inside, you can only ever reveal what was originally locked inside of the box. There's no feasible way to take something out of the box that you didn't put into the box.
00:10:49.180 - 00:13:26.990, Speaker A: And so this use of this particular value commitment, which is a Pedersen commitment in Sapling, works as follows. They derived two fixed elliptic curve points, which call capital v and capital R here, and to encode an integer value of some kind, some amount of Zcash, which is represented by little v, you first compute some randomness, just some random bits, which we're going to call RCV. And then we're going to compute this value on the jubjub elliptic curve, where we take the value and multiply it, do a scalar multiplication of the elliptic curve point capital v and a scalar multiplication of our randomness RCV times the R point on the elliptic curve. And by adding them together, we're going to get this other point on the elliptic curve that we're going to call the value commitment of V. And the claim is that by the way that Pedersen commitments work and the way that we derive the values, the two curve points, v and R, that this commitment should have the hiding and binding properties that we discussed earlier. And this is actually really important for the way that the Sapling Shielded Pool gains real performance advantage because of the model of transactions that they use, which is somewhat different than the previous Sprout Shielded Pool and the zero coin Papers Shielded Pool. And the reason is that Zcash Sapling uses a note based transaction model, which means that value is encoded into things that are called notes.
00:13:26.990 - 00:15:50.490, Speaker A: They're a little bit like UTXOs, but generally because of zero knowledge, it's not clear from the outside what notes are spent or not spent. But the general idea is that with this note based transaction model, you can either spend or output notes. And so, in a Sapling transaction, and again, this is just you can find this in the CCASH Protocol spec. Sapling transaction looks like N spends of notes with value commitments CV old one through N, which again commit to specific values which represent amounts of ZEC. And then you create from this output m output notes which have value commitments CV new one through M, which encode some amounts of ZEC that are output. And then you have this balancing value, which is sort of the net sum of this transaction, which is used to represent how much ZC is added or removed from the shared Pool. And so the reason that this is important in Sapling is because by breaking each spend or output of a note into its individual value commitments, by using the properties of this value commitment, you can actually efficiently compute 10 knowledge proof per spend or per output.
00:15:50.490 - 00:17:05.782, Speaker A: And you don't have to encode the entire transaction in 10 knowledge group, which is actually a nice gain of efficiency and other benefits as well. And so, to ensure that transactions don't create or destroy value, again, you can find this in the Cash Protocol Spec. The important property of this value commitment is that it's homomorphic, meaning that if you add or subtract value commitments from each other to or from each other. That is effectively the same as adding or subtracting values inside the commitment. And so this means that you don't actually need to know what value is locked inside of the box. You can do this add or subtract of two value commitments and you get a value commitment that commits to the sum or different. And so this is great.
00:17:05.782 - 00:18:43.060, Speaker A: This means that we can, in Sapling consider each note individually and not have to consider the entire transaction. We can just compute for each note each value commitment corresponding to that note, sum the value commitments up outside of the circuit, not in zero knowledge, because the value commitment is hiding, so it already doesn't reveal what's inside. So we can, outside of the circuit, sum up all the value commitments and obtain the net value change of the transaction, whether it's added or removed any value from the shielded pool. And then that compares against the balancing value. Okay, so the Sapling design works really well, and the technical details that the gross 16 proof system still very efficient and practical today. It stood the test of time very well. So what can we do to add multiple asset support to this? Because this Sapling design for the most part, only supports an implied asset which would be or a single asset of some kind.
00:18:43.060 - 00:20:44.940, Speaker A: Well, I traced it back to this comment from DIRA quite a long time ago, still during the development of Sapling, which describes the really elegant, in my humble opinion. I also agree it's really elegant, really elegant way to do this without changing the Sapling design very significantly. Of course, there's several different ways that you could do this, but if we're starting from the Sapling design, which is very good, and we don't want to change it too much, the most elegant way of doing this is by realizing that you can use these homomorphic value commitments to not just sum over a single asset type, but instead over many asset types at the same time. And the way that we're going to do this is by using a different elliptic curve point for each asset type. So if we go back and look at this value commitment, we have this capital V elliptic curve point that we use to multiply our scalar value by to lock our value inside of this commitment. And the claim is that we can use a different value V, a capital V different O at the curve point for each separate asset type. And that's going to cause the value commitment to behave independently for each asset type.
00:20:44.940 - 00:22:12.150, Speaker A: So this is, again, one reason why it's very much worth, for educational purposes, understanding the GitHub issues. So let's diverge from Sapling for a second and just discuss what is an asset type? What are we formally trying to do here? Well, an asset type is an abstract property added to a note in addition to its value. So if a note doesn't have any asset type, then implicitly all notes must have the same asset type. The asset type is implicit and it's shared across the entire shielded pool. But if you add this notion of asset type to a note, then we start to understand what properties we need from notes that are now types that have this asset type. Notes should have only one asset type. I mean, this is not, you know, that we, we impose this requirement to help us.
00:22:12.150 - 00:23:34.660, Speaker A: There's no reason why notes need to have more than one asset type. And we importantly have this rule that all transactions are balanced independently across all asset types. Meaning that in a transaction, no matter what asset types are used, an asset should balance by itself for that asset type. By itself, the amount of that asset input into a transaction or spend should equal the amount output maybe adjusted by the amount that's added or removed from the shielded pool. And the idea of this is, of course, that you don't want necessarily to start with different asset types messing with each other. You don't want a transaction which has one type of asset to change its properties. When you add a second type of asset to the same transaction, it shouldn't affect asset one at all.
00:23:34.660 - 00:25:00.410, Speaker A: Now this is great, this notion of asset type, but we have to have, unfortunately, different mathematical and computational representations of what an asset type is at different points because they're used in different ways. So I'm going to somewhat arbitrarily, but very specifically use certain terms to refer to representations of different asset types. So I'm going to start by just saying, well, the name of an asset is just application defined in some way. It's some byte string of arbitrary length that uniquely represents a given asset type. And the reason this is so generic is because there's actually this incredible variation among different standards for how you might define what an asset like, specifically what kind of asset is. So you have ERC standards, you have the most common ERC 20 fungible token. You also have ERC non fungible tokens.
00:25:00.410 - 00:26:19.350, Speaker A: You have cosmos interchange representations of different tokens. You've got an incredible variety of different ways that this asset type can be viewed from an application layer. We're just going to call the name of the asset some generic thing that uniquely refers to the asset which might come from some token derivation or token address or something like that. You can also include other things. You can include some salts, you can include a random beacon. There's reasons to do this. If you want to kind of prove maybe that you didn't construct your assets before a certain point in time, maybe you include a random beacon.
00:26:19.350 - 00:28:10.700, Speaker A: There's different things you can add and it's fundamentally not part of the shielded pool specification. What information goes into this representation of an asset type? So inside of the shielded pool, we're going to get much more specific because the shielded pool has to know what an asset type is in a very concrete way, as opposed to the very generic way we just defined it in the previous slide, which maybe use outside of the shielded pool. Inside of the shielded pool, it has to be very concrete and the shielded pool has to know what an asset type is. And so there's two different representations inside of the shielded pool which for the extensions, the mask that is built on ZCache Sapling takes two forms. An asset type can be represented by an Identifier. An asset Identifier is just a 32 byte string, which the only requirement is that is derived from the asset name in a deterministic way, so that each asset type still has a unique Identifier. Two assets with different Identifiers are distinct and two assets with the same Identifier are the same.
00:28:10.700 - 00:29:41.830, Speaker A: And we're going to impose some really strict requirements on the asset Identifier for some technical reasons. Namely, we're not expecting this asset Identifier will be like a token address or anything like that, because the asset Identifier is specifically 32 bytes and it's compressed representation. It's not going to include all this arbitrary data, it's just going to be this 256 bits. And this can give very strong hint as to how you should derive the asset Identifier. Certainly you can just hash the asset name as long as you still maintain the uniqueness properties, you can use whatever kind of hash or compression you want generally. But just taking a hash of the asset name to get this asset Identifier is not a bad way to start. However, we do have this second and third requirement which are related, which is not every 32 byte string will be a valid asset Identifier.
00:29:41.830 - 00:31:27.430, Speaker A: And this is for a sort of technical reason, it doesn't have to necessarily be this way, but we do this on purpose. And this is because of the third requirement, which is that if you take the Blake two S hash of the asset Identifier, you get the asset generator, which is going to be the elliptic curve point that we're going to use in our value commitment. And so the reason that we have this construction then, and this sort of strict requirement on the asset Identifier is so that we can efficiently handle all of this inside of the zero knowledge circuits. So computation in our zero knowledge circuits is very precious, it's not free. It's certainly rather expensive for the prover to do extra work if our circuits are very complicated, it imposes a cost of not just CPU, but memory usage. And if you're concerned about your proving performance on say, mobile devices, you really want to make sure that your performance in the circuit is really good. And so we just impose by fiat this requirement that you take a Blake two S hash of this asset Identifier and you get the asset generator.
00:31:27.430 - 00:32:46.510, Speaker A: And this is why the asset identifier is 32 bytes, because that way you can take the Blake two S hash in the circuit, and you only need to do one block of the Blake two S hash. You don't have to do many Blake two S blocks in the circuit, which would be very expensive. And also, by restricting that, the hash always has to work. So not every output of a Blake two S hash is a valid curve point on the jub jub curve. And so this is why not every asset identifier is going to work. Some asset identifiers are just not valid, because when you take the hash the Blake two S hash of them, you don't get a good message generator. And we don't want to do extra work in the circuit to handle these invalid cases.
00:32:46.510 - 00:34:45.960, Speaker A: We just want to reject them. And so it's the responsibility outside of the circuit to ensure that only good asset identifiers are used. This can prevent you from just straight directly using the hash of the asset name, because you might get an invalid asset identifier that when you hash the asset identifier gives you an invalid curve point. There's some subtleties. Okay, so what does a spend look like in the MASP? So, in order to spend a note that now has this asset type, well, all we need to do is make the notes typed. Now, if a note has in it the asset generator that represents the value or the base that you should multiply the value by the elliptic curve point for your value commitment, all you need to do is add this value base as a witness to the spend circuit. So if you're familiar with the Sapling circuit and how it works sapling circuits and how they work, if you look at the spend circuit, this should be extremely familiar, because for the most part, things are not very different.
00:34:45.960 - 00:36:33.386, Speaker A: All that's been added is that we add this private input of the asset generator, which I've used VB to represent for value base. We just add this asset generator as a private input, and we want to say that the circuit is satisfied if all the usual Sapling spend requirements are satisfied. With the exceptions that we have added. Now this asset generator to each note, we can, for the most part, ignore almost everything I've highlighted in kind of this purplish color what has changed. All we have to do is add this asset generator to each note, and it becomes now a typed note. It doesn't just represent value in some implied single asset, but notes can actually have value and a type, and then not much else really changes. Except that when we look at the value commitment, instead of using this fixed elliptic curve point in our commitment, we still use a fixed elliptic curve point to multiply our randomness by.
00:36:33.386 - 00:38:00.870, Speaker A: Because the randomness does not depend on the asset type, we can just use a single elliptic curve point, which we get from this group hash for our randomness base. But the asset generator. The value base in the Pederson commitment now comes from our private input and comes from our Note commitment. And so as long as our private input matches what was committed to in the Note and we use that asset generator in our value commitment computation, we can now be confident that the value commitment matches not just the value that's contained in the note, but also the asset type. And from this side, from the spend circuit. As complex as the spend circuit is, this is the only change that is really necessary. We have some extra fine details about checking that these points are not small order and clearing cofactors.
00:38:00.870 - 00:39:32.290, Speaker A: This has to do with the fact that the Jebjeb curve is an Edwards curve and has a cofactor which you can read the details about this in both the Zcash specification and the MISB specification. Okay, so spending a note is actually not very different at all. How does creating a note look like? And this is actually a lot more subtle. So when you create a note, what does the circuit have to check? Circuit has to check the things that it checked in Sapling before, namely, you're given some public inputs about note that you're creating note commitment and the value commitment and so on. And the private input is going to have the private inputs that the Sapling output circuit had before. But we're going to add not just the asset generator to the private input, but also the asset identifier. And we'll see in a second why this is important, why we cannot just add the asset generator like we did in the spend circuit.
00:39:32.290 - 00:41:07.412, Speaker A: And if we look at what the output circuit has to do now, well, it has to do all of the things that the spend circuit changed. So when we compute the note commitment, for example, we have to now compute a typed note commitment so it doesn't just have a value with an implied asset, it now has a value and an asset generator and you put that into the note commitment. So that's the same as in the spend circuit. The value commitment has also the exact same change where you use the asset generator. Now to compute your value commitment, not some constant curve point, you use the asset generator that you've put into the note. However, there's no place in the output circuit to check that the value base is correct in the same way that there was in the spend circuit. If you recall in the spend circuit, this value VB, although you're giving it as a private input, it's ultimately compared to the Note commitment.
00:41:07.412 - 00:42:38.468, Speaker A: And the Note commitment came from the Note commitment tree comes from notes that already exist. And so once a note is typed with a certain type with a certain asset generator in it, you can assume it's good. You cannot change the asset generator later because the asset generator did not come from the user, it came from a note that already exists. And that's not true in the output circuit. As here, the user, whoever the prover is of the output circuit, whoever's creating the new note is actually creating a new note. And they can otherwise put any value, any elliptic curve point they want in VP, and they can create crazy asset types, any elliptical curve point that they want, they can type in the asset type. And this can be destructive because, for example, suppose that the value of VB that they use the asset generator is the negation of some other asset type.
00:42:38.468 - 00:44:27.000, Speaker A: So they take some existing asset type and they say I'd like to create notes which have the exact opposite asset type, the same curve point, except that multiplied by minus one. And so then by creating new notes of this negated assets type, you can create unlimited amount of the other asset type by sort of in a kind of almost quantum foam type of way. If any of you like theoretical physics, if you are allowed to have negated asset generators, you can spontaneously in the shielded pool create an asset and it's negation. And because it will still balance to zero, it would otherwise check out just fine, even though this is obviously something that you don't want and you want to prohibit. So how do we prohibit this? We say you cannot witness the prover cannot witness an arbitrary asset generator. It has to actually witness that this asset generator came from an asset identifier. And this is why the proverb has to witness this 32 byte asset Identifier and compute in the circuit this blake two S hash.
00:44:27.000 - 00:46:09.922, Speaker A: One block of the blake two S hash to derive this value base, this asset generator, and verify that, in fact, that you did not just make up some asset generator you did not just negate some asset generator that already exists. And so we should note now, having observed that this is necessary in the output circuit, we should note that this is not necessary in the spend circuit because you can only create notes with correct asset generators. The output circuit enforces that only valid asset generators can be used to create notes. And so we can assume that when the notes are spent that their asset generators were already checked to be acceptable. So 1 may wonder if it's necessary. The answer is kind of yes and no. The answer is yes.
00:46:09.922 - 00:48:32.590, Speaker A: In the construction that we just described, for the reason that I just described, if someone witnesses the negation of an asset generator and produces notes with negative value of some actual asset, they can create notes of arbitrarily positive value homomorphic imbalance. Now, that being said, there were other proposals which you can read about in the GitHub Zcash repository, in the GitHub issues which include one way of avoiding this entirely and avoiding this Blake two S hash, which is certainly more efficient from a circuit perspective. Anytime you can avoid having to do an expensive hash operation in the circuit, you can save a lot of computation time. But in the specific construction that we've described, you have to verify that your asset generator is good in some way. And so we just accept in this construction the cost of the Blake two S hash, even though there's potentially alternative ways to do this. So then one of the other most common questions I get is, why does it need to be a Blake two S hash? Why can't we just use a Pederson hash? Because it's much more efficient to compute in the circuit than a pseudorandom function such as the Blake two S hash. And the answer is that you cannot use this Pederson hash to verify or just to drive the Acid generator.
00:48:32.590 - 00:50:10.670, Speaker A: And this is because while Peterson Hash offers collision resistance, it is possible. In fact, it's actually downright easy to find related pre images to each other because the Pederson hash generators are publicly known. Suppose we used Pedersen Hash to derive our asset generator from asset Identifier. You can very easily, starting from an existing asset an existing asset Identifier, an existing asset generator, you can very easily derive a new asset Identifier, a new asset generator that has some known relationship to the existing generator. This is just generically a problem. It's not so easy to get around. You have to have unlinkability at some point, just for security purposes, to allow people to prevent people from mixing different assets types together and potentially violating the rules that we require for balances between asset types.
00:50:10.670 - 00:50:57.752, Speaker A: Now, this doesn't mean that all conversions between asset types are unwanted. In fact, this just may allow unwanted conversions. We may actually want some conversions, which will be the next part of the top. Okay, I think we're at the breakpoint. Yeah. But before we do that, there was one person in the Q A chat who was asking some questions, and I wasn't exactly sure what he meant, but you might want to give it a read and see if you can answer it and then hold on to the break. Okay.
00:50:57.752 - 00:51:13.668, Speaker A: Yeah. Let me see. Okay. Basic principle we can't hear you, Anna. I'm not muted. No, you're not. Could you hear me there? Yes.
00:51:13.668 - 00:51:46.780, Speaker A: Okay. Yeah. So just one thing. If you want to read questions from the Q A, just be sure to repeat the question for the video. If you can just read it out, that would be like there's basically only one question. All right, so Hakan asked the basic principle behind Zero Knowledge is that there's always a simulator capable of performing fraudulent proofs. You learn nothing from false evidence.
00:51:46.780 - 00:53:14.520, Speaker A: So if they're just indistinguishable from real evidence, you cannot learn anything from real evidence. Are you aiming to hide real data by using fake. Data with zero knowledge is the purpose here to hide the source rather than the information. Okay, so five minute recap of what zero knowledge is and how it works. So the fundamental idea of zero knowledge is that you want to convince the verifier of some fact in such a way that anything the verifier learns through the entire procedure, the verifier could have figured out themselves anyway, so the verifier might get convinced of some truth, but they don't learn anything else besides this fact. And so I always use the example of soda flavors. Th if you imagine that there's some people who don't believe that two different brands of soda taste differently.
00:53:14.520 - 00:54:46.490, Speaker A: Suppose suppose I don't believe that brand A and brand B taste any different, but other people do believe that they taste different. They know they taste different, then you can use a proof of some kind to essentially prove this fact to me, namely, someone who can actually taste the difference between the two different brands of soda. I can challenge that person by saying, take a sip of cup one or take a sip of cup two, and I can randomize which brand of soda or which cup of soda I challenge the prover with at every step. Basically, I, behind my back, choose one of the cups of soda, and I challenge you to taste the difference. Tell me which soda brand of soda is. And the idea is that if someone guesses 100 times in a row what the brand of soda is, then that could not have happened by chance. I've become convinced of what brand of soda that the brands of soda are different.
00:54:46.490 - 00:57:32.536, Speaker A: And the idea of zero knowledge and the idea of using a simulator here is, suppose that you want to do the same kind of proof that the brands of soda tastes different, but you don't actually want to reveal which brand is which. Well, the idea is that by, in some sense, hiding the source of hiding the way that each cup is chosen so that's so that you don't imagine you cover the labels of the cup, so you don't actually know which cup is which, then you don't actually learn any information this way. So the reason this is formalized in the notion of the simulator is that you imagine that suppose that you set up some cameras, a TV studio or something, where you're filming the prover and the verifier doing this interaction with each other, and the verifier concluding that, yes, in fact, the cups of soda are different. The way that you prove it's your own knowledge is that you argue that imagine that the verifier in the television studio is colluding in some way with the proverb. Imagine that instead of being like a real Verifier, it's a simulator of some kind, which is trying to simulate what they're not actually trying to verify the cups of soda taste different. They're just trying to simulate what it would look like if the prover were successfully convincing them that the cups of soda tasted differently. And so you have the two cups of soda, which are they have the labels covered and the Verifiers challenging the prover with the cups of soda.
00:57:32.536 - 00:58:52.550, Speaker A: Well, imagine that there actually was no difference in the taste and the Verifier being the simulator is in on the scam, right, that the simulator is trying to simulate what it would look like if there was a difference. Well, the Verifier simulator, the simulator and the prover just just need to use the same randomness for choosing the cups. The simulator chooses some pattern for how it chooses the cups. And the prover knows the same pattern, like it's going to be cup one and then cup two and then cup two, again cup one. And the idea is that in this TV studio, it looks exactly the same. Like, you cannot tell from the outside that instead of a real Verifier, it's this simulator. And yet, although it looks exactly the same from the outside, there's actually no transfer of knowledge going on.
00:58:52.550 - 01:00:05.324, Speaker A: There's nothing being proven because it's a fake proof. It's a simulator that's just not acting as a true Verifier. It's just simulating what a correct interaction would look like. And so zero knowledge proofs fundamentally kind of work in this way, where if you argue that there's always a simulator which can look exactly the same as a real Verifier, then in fact there must have not been any information gained because there's never information gained by approver and a simulator talking. Because there's no information. There's nothing real about approver and a simulator talking. It's just all sort of put on for TV, put on for show.
01:00:05.324 - 01:00:58.700, Speaker A: And so as long as there exists the simulator which can look exactly the same as a real Verifier doing the real verification, once you plug in the real Verifier, you can conclude that the real interaction between the proverb and Verifier also does not exchange any knowledge, if that makes sense. And so that's why we have this proof, this notion, not in the actual code or anything, but in the theorems and the math papers. We use this notion of a simulator that does false proofs. And that's how we argue that actually no information is revealed. Subscribe.

00:00:00.410 - 00:00:49.260, Speaker A: Welcome to anyone who's just arrived, and I think we're going to be telling folks to head over to the sessions tab. Just so you know the way that hopin works. I think actually, I need to point this way, but you have two chats. You have the event chat and the sessions chat, and we're going to be using the sessions chat when you're talking about anything related to what's going on on the screen and the events is maybe more for, like, before and after, and when people first arrive, we're going to be basically asking them to join the session. So, yeah, you should open up the sessions tab. I believe it's this way. I always am pointing the wrong is this right? Does that look right to you? No, this way?
00:00:50.110 - 00:00:50.858, Speaker B: Okay.
00:00:51.024 - 00:01:18.280, Speaker A: Oh, man. Anyway okay, so, yeah, open up the chat, say hi so that we know you're here and that you can see us and that we're coming in clear. Yeah, we need to hear from you if there's any audio problems or anything like that. And we usually want to wait just a few minutes for people to arrive, so I think we'll give them a little bit longer. Agneska, is there anything else that we should think about?
00:01:22.650 - 00:01:23.878, Speaker C: Press the blue button.
00:01:23.964 - 00:01:46.062, Speaker A: Oh, yeah, don't press the blue button. But Magnus, just FYI, you're in the events chat. So if you look there's event and sessions, click on the sessions chat. That's where we want to talk to you or want to hear from you. And yeah, there's a blue button up at the top. People click it. But what that actually means is you're asking to come on stage, and so if you're not a speaker, there's no need to touch that button.
00:01:46.062 - 00:01:47.840, Speaker A: Only the speakers should.
00:01:49.090 - 00:01:50.000, Speaker C: All right.
00:01:51.810 - 00:02:19.718, Speaker A: So I think if there's a good it seems like a good group of people, these intros oh, there. Okay, we see some people arriving. Good. Okay, let's kick off. So we are going to be doing like we're here for the Lab unplugged event. We're looking at interchain mev. This is the first time that we're doing an event that's focused more on the Osmosis ecosystem.
00:02:19.718 - 00:02:59.560, Speaker A: We've done a number focused on cosmos, but, yeah, we wanted to sort of start to explore this ecosystem deeper. We do these events, we've done quite a few of them now, kind of online, short form, but like, getting to the crux of a matter, really trying to understand a topic, and so we're very excited to, in this particular one, cover the topic of mev. This is brought to you by the ZK Validator. Agni and I are both part of that group. We are a validator we're running on a number of different networks. I'm going to tell you in a moment. And yeah, we are kind of putting on this event.
00:02:59.560 - 00:03:32.830, Speaker A: So what ZK Validator does is it aims to support privacy in ZK tech across multiple blockchain networks, and we do this through a number of ways. The networks that we're focused on are the networks that we're validators on, and we actually are quite present in the Cosmos ecosystem. We're now live on Osmosis as well as the Cosmos Hub, Evmos and Agoric, as well as a batch of other networks. We're also on a number of testnets. Yeah, the has grown a lot. We've gotten to explore a lot. So it's been a good journey.
00:03:32.830 - 00:03:47.506, Speaker A: So here's our team today. So we're nine. Wow. I think this is this every time we do it, it's a little bit bigger. It's very cool. But yeah. So what we tend to do at the ZK Validator is we run validators.
00:03:47.506 - 00:04:24.820, Speaker A: We choose networks that we feel strategically aligned with. We act as advocates for privacy in ZK Tech. We participate in governance, we support emerging teams in those networks, and we also aim to launch initiatives to promote and fund ZK Tech. Now, this particular event isn't so much focused on ZK Tech. I'm going to go into a little bit of our initiatives. So we often do these event series that are like Privacy in Cosmos, privacy in XYZ or ZK something. Now, when we started building up this event, we realized that the Osmosis ZK community was pretty small, hard to find.
00:04:24.820 - 00:04:47.782, Speaker A: And so we instead decided to focus on a topic that we thought was really interesting for Osmosis today, something that we could also learn from. But just back on zkv. What we also do as an.org is we've incubated something called Zkhack, which is a learning hub. There we do events and content. If you haven't heard of it, it's called Zkhack. Like, check out Zkhack Dev.
00:04:47.782 - 00:05:21.938, Speaker A: We're doing an IRL ZK hackathon at the end of March. We also have done things like the Open Legal Report Working Group. So what that is all about is bringing together people across the industry working in ZK Tech to try to understand what are the regulatory questions, what are the opportunities, what can we do? Oh, people are asking, is the event recorded? Indeed it is. It will be recorded, and it will be on the Zero Knowledge YouTube channel. Zero knowledge podcast. YouTube channel. But anyway, I'll continue.
00:05:21.938 - 00:05:45.210, Speaker A: So other things that ZK Validator does is early stage funding. We do this through investment and grants. We were one of the organizers of the ZK Tech side round of recent Gitcoin grants. So, yeah, I don't know if you saw us there, but we're always trying to find innovative ways to get funding into the hands of really good builders. And we also do some of the building ourselves.
00:05:46.110 - 00:05:46.860, Speaker C: Yeah.
00:05:47.390 - 00:05:50.960, Speaker A: So I think I'm going to invite Agneska to tell us a little bit about this event.
00:05:51.810 - 00:06:13.042, Speaker C: Yes. Hi, everybody. I'm so excited to see you over here. So except for all the goals that we have written down over here, we also, like Anna mentioned, want to reach out to the Osmosis community. We want to hear from you. We want your feedback. So if after this event there's anything that comes into your mind and you want to share with us, please do.
00:06:13.042 - 00:06:43.690, Speaker C: You're going to have an email address that you can reach us and just tell us what you need. We want to meet you. We want to really do more things for Osmosis as well. Goals for this event. We want to introduce ourselves as well to the Osmosis community. We want to show you who we are, what we are doing, how amazing the things are that we can do together. We also want to explore the topics of the Ned on Osmosis and within the larger community context.
00:06:43.690 - 00:07:22.934, Speaker C: This is something that is really new and exciting. I know I'm going to learn a lot today, so very, very happy to be here and participate in it. And we also want to allow the participant to gain a deeper understanding of the current state of the amed and what it means for the future of the Cosmos ecosystem because I'm pretty sure it's going to be one of the most interesting topics for the next month. Yes. What is the event schedule? I'm pretty sure you already saw it when you were registering, but let's go through it once again. So now we are at the introduction. We have four amazing talks.
00:07:22.934 - 00:07:40.462, Speaker C: We have four different teams that are going to present today. Informal systems. Skip protocol. Mechatech, osmosis lab. And at the end we're going to have a panel. Somebody just called for Zaki and Zaki appeared. Yes, Zaki is going to be one of our panelists today.
00:07:40.462 - 00:08:23.678, Speaker C: So stay with us till the end. And our media partner is ZK podcast waving here to Anna. Somebody was asking about it if it's going to be recorded. Yes, thanks to ZK podcast and thanks to the YouTube channel that ZK podcast has, everything is going to be recorded and after that put into the YouTube channel. So you're going to see a link in a second and things to look out for. Like Anna mentioned, we do a lot of initiatives that are around events as well. So somewhere in June, look out for privacy in Cosmos in real life event too.
00:08:23.764 - 00:08:26.218, Speaker A: Yes, you should have put that actually.
00:08:26.404 - 00:08:49.598, Speaker C: Yeah, it's the second one that we are doing. The first one we did last year in Amsterdam and was amazing. So we want to do something again that it's going to be maybe even better. I hope it's going to be better. And of course, sign up to our Cosmos newsletter. We hear a lot of feedback about it. It's amazing newsletter.
00:08:49.598 - 00:09:19.714, Speaker C: Hector, who's responsible for it, is here with us as well. So sign up for it. You're going to see the link in a second in the chat as well. And yes, thank you for participating. If you want to learn a little bit more about Ziki, validator who we are, what we are doing this is our website. We also have a Twitter, like I mentioned. If you want to give any feedback to us, if you want us to do another amazing event about different topics, write to us at events@zkvalarad.com.
00:09:19.714 - 00:09:27.174, Speaker C: And this is our YouTube channel that you will see this recording and you can also see the previous events that we've done.
00:09:27.292 - 00:09:32.406, Speaker A: Yeah, the playlist is called Zkv Presents and we have a lot of our previous ones there.
00:09:32.508 - 00:09:55.614, Speaker C: Yes, exactly. And now I would like to introduce to the stage Joseph. Joseph, if you could. Yes, I can see Joseph already from informal. Okay, let's go. Informal systems. Yosef as a first.
00:09:55.614 - 00:10:05.330, Speaker C: There we are. Fantastic. Okay, the stage is there. Are we doing yes, yes, we're doing slides.
00:10:05.750 - 00:10:08.494, Speaker A: Let's get them set up then. I'm going to bounce.
00:10:08.622 - 00:10:15.080, Speaker D: See you soon then. Let me find what I'm going to show you.
00:10:16.410 - 00:10:17.062, Speaker B: Yes.
00:10:17.196 - 00:10:17.926, Speaker D: Good.
00:10:18.108 - 00:10:18.840, Speaker C: Perfect.
00:10:24.010 - 00:10:24.760, Speaker B: Good.
00:10:26.570 - 00:10:59.570, Speaker D: Is it the presentation? I guess. Thanks for the invitation. So I'm here to talk about ABCI 2.0 because it opens up a couple of opportunities for me. But before that, I need to do a couple of logistic remarks around Comet PFT. So as you might know, Tendermint Core will soon be archived. And so the team that was behind Tendermint Core is now behind Comet PFT.
00:10:59.570 - 00:11:34.126, Speaker D: We have here our new Github.org and our new GitHub repo. So the reason I tell this here because all the work that I'm going to talk about here, you're going to find also on this repository. So, Comet BFT is a fork of tendermint core. It's built around Tendermint consensus algorithm. And we try to have maximum compatibility so the version numbers are compatible and we are also allowing mixed networks. So this is the current setup, that's the current situation.
00:11:34.126 - 00:12:14.540, Speaker D: And this is where you're going to find all the work I'm going to talk about today. So I'm going to talk about ABCI 2.0, give you a little bit of idea what it is, how you can use it, how you should not use it, and then wrap it up. I guess I only have like ten minutes and I started a little bit late, but we'll manage to get there. So ABCI stands for Application Blockchain Interface. That's the way how in Cosmos the application is working, coordinating with consensus. It's built around a very standard state machine replication idea.
00:12:14.540 - 00:13:05.642, Speaker D: In principle, what we have here, the transactions go into the mempool. We are proposed proposal put into a block, they go through consensus and then once the validators have decided on the next block, the block is sort of passed to the application. And then we have here begin block that delivers transactions, end block and commit. So here, wherever this happens, this is what happens. So at the end, there's not much sort of interaction. The application just takes the transactions that are generated by consensus, which also means that there's not much that the application designers can do to control consensus and control the outcome of consensus. And this is what ABCI 2.0
00:13:05.642 - 00:14:10.590, Speaker D: is trying to address. So that's basically the new workflow that we are having. So the whole thing starts with Prepare Proposal where Consensus gives a list of transactions to the application and the application can then decide for example to reorder these transactions or to get rid of some of those. So this is opening up of course a lot of new application and use cases. Then within Consentus, the validators are going to look at these proposals that have been compiled by the application more closely and if they do so, they call Process Proposal and at this point the application can validate the block, it can make sure that the block has been in fact compiled according to the application rules. So there is some application specific availability checks that could be done here that were not possible before. So you can have guarantees for example that only valid transactions make it into the block.
00:14:10.590 - 00:15:19.880, Speaker D: Then Gonzenzos keeps up unrolling the voting is going on and when the validators are about to send out their votes, they are going to call extend Vote and ask the application for some data to piggyback on the vote message. So that's a new way to get data more quickly onto the chain. And again this information is verified by the validator. So if a validator receives the vote from someone else, they call Verify Vote Extension. It again goes to the application and the application can do some consistency checks there. And then at the end we again have finalized block and commit. So what we see here is that there was a very much more detailed and fine grained control that the application has over consensus, which means that the application can use consensus in much more ways but it can also misuse the consensus in much more ways and the application designer needs to be aware of that.
00:15:19.880 - 00:16:24.742, Speaker D: And of course there's more to ABCI but I don't want to talk about that today, I want to focus on these features here. So why is it useful? So for Repair proposal since this is Mev conference here, what actually Process Proposal does is dealing with by team proposals. So if the proposals are behaving badly according against the application, what we can do here is with Process Proposal we can check whether the proposal is bad, but this also means we can deal with rational proposals. So in some sense Process Proposal will allow to regulate MAV. For example, if the application decided to auction away a block space, process Proposal can check can make sure that the winner of the action actually got their spot in the block. So there are certain things that can be done here. Another use case is that we find in Celestia where basically the transactions are reformed.
00:16:24.742 - 00:17:31.658, Speaker D: So where the transactions with Control and data come from the Mempool and then in Process Proposal they are separated the control data and the block data, the control and the data is separated and you can use process proposal to have some optimistic execution because the transactions are valid at this point. And you can start executing for vote extensions. As I said before, the use cases are Oracles, so you can get information quicker on the chain. So for example, you can use it for price Oracles and other Oracles, or you can use it for threshold descriptions. So the extensions that you piggyback on the votes are key shares and they are spread over the network here. The point here is it's an alternative to the sort of more standard way of transactions where you put transaction into mempool and they go through consensus. So which means vote extensions are faster, vote extensions are simpler, but they have bigger guarantees.
00:17:31.658 - 00:18:24.194, Speaker D: They don't go through the whole consensus. So the only property, roughly speaking, that you have is that you get two third majority of the votes have verified extensions. So there is no guarantees about agreement. Things like this you don't have, but you have this property that two thirds of the extensions are verified and have been checked by the application. As I said, with power comes responsibility. So the problem here is that in order to allow application specific validity checks, for example, and process proposal, this has influence on consensus. If the application says that this current proposal is not well formed, then consensus is not going to vote on this proposal or voting against it.
00:18:24.194 - 00:19:35.510, Speaker D: So this means that the application has the power to stop consensus, has some power of influencing liveness, which means that, and we have formalized this here, that if a correct proposer proposes a block, then process proposal must actually accept the block. So what this means, roughly speaking, is don't use it to say I don't like transaction ordering. So use it to say, okay, this transaction ordering is against the application. This was this behavior on the proposal side, but sort of just trying to change this in our own sort of like what we like might have influenced some consensus likeness. So this you should not do. Similarly for extend vote and verified vote extensions, we have similar properties. So we cannot use it to say we don't like the data in the extension because again, this will also potentially have will induce life properties problems and consensus.
00:19:35.510 - 00:20:15.730, Speaker D: So there are new powers that are given, but use them with care. That's the message here. So, to summarize, ABCI plus plus enables flexibility, concurrency, performance, new ways how the application can use consensus and interfere with it. We can make sure that all transactions that make it on the chain are valid. It has a couple of new use cases and I have only sketched two here in this talk, or a couple of them. It requires that the application is well behaved. So already in the original ABCI, we required the application to be deterministic.
00:20:15.730 - 00:20:54.370, Speaker D: And we also have seen problems with applications that have no deterministic in practice, but now we have more properties on the application, so make sure that this is satisfied. So regarding our roadmap, so we are going to bring APCI 2.0 to commit PFT. Prepare and Process Proposal is in the upcoming version 37. And this is APCI 1.0. This is what just contains prepare and process proposal. Why the vote extensions and finalized block are coming into version eight.
00:20:54.370 - 00:21:31.070, Speaker D: Also pretty soon. Here you have to link to the specification if you want to have a little bit more detail just at the end. I would like to acknowledge that this is a big effort by a quite sizable group of people, by Osmosis own Dave and Sunny, who proposed this idea. CI here, myself and Callum were working on the specification. William, Dane and CI were working on the implementation, and there's a huge list of people who contributed in many bi weekly discussions over the past year. And I think I'll stop my presentation.
00:21:32.850 - 00:21:49.250, Speaker C: Perfect, perfect. On time. Thank you very much, Joseph. It was very nice presentation. Okay, next on stage, I would like to invite Magnus from Skip Protocol.
00:21:53.510 - 00:21:54.660, Speaker E: How do I look?
00:21:55.190 - 00:21:59.650, Speaker C: Hey there, you can share your screen and let's start your presentation.
00:21:59.810 - 00:22:07.740, Speaker E: All right, so cool.
00:22:09.710 - 00:22:10.170, Speaker F: Awesome.
00:22:10.240 - 00:22:57.698, Speaker E: Everything look good. Great. Hi, everybody. I'm Magnus, one of the co founders of Skip protocol. And today I want to chat a little bit about one of these new modules that is coming out in Osmosis in the next upgrade called Protorev, and then also talking about some of the future potential directions for protorev, and also following that wonderful presentation earlier, how a lot of the new features of the SDK can be applied. So just to give a little bit of a background on mev and Osmosis, a while ago, one of our first things that we built as a team was mebsatellite, which is a dashboard to examine cyclical Arbitrage mev on Osmosis. So it measures basically transactions where the transaction ended up with more of the original asset that it started with.
00:22:57.698 - 00:24:17.374, Speaker E: We found out that as of a couple of days ago, total extracted mev via this method, hit over $7 million at current Osmo prices for Osmosis. Worth noting that there is a wide amount of mev that is not captured here, specifically centralized exchange to decentralized exchange arbitrage, which anecdotally we know is quite large, but this is sort of what on chain we were able to capture. So as we sort of talked to the Osmosis team and tried to understand what kind of solution would make sense, we found out that they were very strongly demanding an on chain MEV solution. So here are two pieces that were written by Sunny and also dev in terms of really wanting to opt for in protocol solutions that essentially diverge from things like PBS or off chain builders and seeing how far we could push this idea of, okay, well, what can we do on every validator in consensus? So introducing protorev, which was the outcome of those conversations, it is an in protocol block building solution. So it in houses the backRunning mev capture. So going back to that graph before it captures all the cyclical arbitrage itself within the protocol on every validator in consensus. One thing that's really cool is it has zero cost of capital.
00:24:17.374 - 00:25:32.982, Speaker E: It can borrow an infinite amount of capital to execute backRunning, unlike any searcher or off chain builder could. The reason it can do that is because it's actually built into the application and therefore has access to the modules to mint and burn capital. It's also fully open source. As I said, it runs on each validator in consensus, which means it has the property of a proposer can't sort of do their own thing, right? Every validator has to agree in terms of how the transactions are processed, which means that no validator can sort of go behind anyone else's back and try to get a better deal or anything like that. The last thing is it's fully governance controlled because it's a module, it has parameters, and because all the logic is on chain, the entire chain itself can sort of vote in terms of how distribution works, how the actual logic works, et cetera. So this is just a little bit more detail in terms of how it works in practice. So after every transaction is received and processed in the application, so like every transaction, the mempool that is there's an in protocol arbitrage that checks a bunch of routes after that transaction and sees sort of what are the most profitable backruns they can do to balance out the pools after that transaction.
00:25:32.982 - 00:26:29.626, Speaker E: Worth noting that all of this mev revenue was previously going back to searchers. So that graph I showed you before, that was all to searchers, none of that was captured by the protocol. So this actually in houses, according to our test, 80% to 90% of that cyclical back running arbitrage and gives it back to the protocol in the way that they choose. So what is our goal more generally? At Skip well, our goal is always to make mev fully sovereign. And what that means is give chains the maximum amount of choice they have in choosing their mev solutions that work with their protocol. This has been our fundamental thesis in the app chain world in terms of building out solutions that can be customized and basically tailored to an individual application, which usually involves not building out for a generalized L1 and solutions that apply there. So in that case, it means basically full block building control.
00:26:29.626 - 00:27:11.514, Speaker E: So governance can decide exactly how blocks are built and how mev is captured fully decentralized, meaning there's no one single party we're building towards this. It's definitely a goal that we're working very hard on. It's fully transparent, so you can see exactly what's going on. So the code eventually should be open source and then it's also compatible with some kind of cross domain mev. Worth noting that most cross domain mev is between decentralized and centralized exchanges. But in the future we think this might change. And in order to solve sort of the crisis we have of fractured liquidity, we believe the solutions should basically enable cross domain mev and atomicity and things like that.
00:27:11.514 - 00:28:01.310, Speaker E: Though that's a big research question that everybody's working towards. So this is sort of a summary of the previous presentation, but Cosmos is about to change for the better, right? The application now has a much bigger say in terms of what proposals are valid and how blocks are built. So to note, in ABCI, non proposing validators can verify block construction. There's much deeper expressivity for fee and mev markets. Because of that, you can sort of encode more of this logic inside the chain. And then there's also data availability with vote extensions, which actually has far reaching impacts in terms of how you could run something like an auction. So what is our goal over the next, let's say, couple months? It's to generalize Protorev to become the first protocol owned builder.
00:28:01.310 - 00:29:07.342, Speaker E: So right now all that Protorev does is backrun. But what if it could run an auction or a generalized auction? What kinds of properties could it have that would rival a centralized builder or an off chain builder? And how close can we get to that with the different pieces of ABCI that are coming out? This is really the focus of Skip on Osmosis and sort of our collaboration going forward. So just to compare the attributes of an off chain system for capturing mev versus a protocol owned builder, and this is not to say that off chain systems can't get better, and I believe they will. I think there might be a presentation here that talks a lot about that, but this is generally some things that we've seen in terms of how off chain mechanisms have played out in Ethereum and how we think protocol owned builders can fix some of those things. So in an off chain system, you have builder centralization, right? Even in a system like PBS, a really good builder will capture more and more of the block space. And because of that, they start to capture more of the order flow and it becomes a self reinforcing cycle that essentially makes them become dominant. You saw this with Flashbots early.
00:29:07.342 - 00:29:37.138, Speaker E: Now I think you're seeing it like Beaver build, but there's a reinforcing cycle for an off chain actor to become more entrenched. In a protocol owned builder, there are no off chain builders. It's fully invalidator. And so there's not even a question of who can become centralized or who can't. The entire protocol itself comes to consensus on how a block should be built and how mev should be captured. And all the logic for doing that is in the protocol itself. Another property of off chain systems is they're generally not OCA resistant.
00:29:37.138 - 00:30:39.690, Speaker E: So you saw this with PBS when, you know, fully went down during the FTX collapse. It's very hard to construct systems where there's not a better deal that can be had by working with an off chain provider. Whereas in a protocol owned builder it's enforced OCA resistance, which means that it's impossible to sort of create a proposal that is not according to the rules of the protocol. Off chain systems have opaque functionality, of course, right? This is one of the hallmarks of an off chain builder where they have better functionality than someone else or some sort of private IP that they're monetizing. Whereas in protocol owned builder, everything is open source, it's fully observable and inside the repo of the actual chain, there's some censorship concerns on off chain systems, right? So we've seen this extensively with PBS where a dominant builder can also choose to censor, which can be a difficult decision for a decentralized network. Whereas in protocol owned builders there's BFT enforced inclusion. So with vote extensions you can actually make sure that enough information is passed through.
00:30:39.690 - 00:32:00.338, Speaker E: And this applies not only to sort of like OFAC, but also applies to including bits, which I think we'll talk about a little bit later, outsourced logic for off chain systems. Whereas full app dev expressivity for protocol owned builders, app chains can fully determine their mempools and exactly how they want their blocks to be built. But one thing to note is off chain systems do have specialized actors, right? So these are builders become very good at doing what they do and a generalized system is sort of up in the air whether it can even compete, right? So there may be a sacrifice in terms of how much maximal mev can be extracted. But because of the benefits of protocol owned builder, there may be situations, especially for app chains, where it's very defined functionality, where it might make sense. So what are some of the new primitives that we need on chain to enable such a system? Well, at a minimum, we need an on chain bundle type. So in a protocol owned builder, you still have searchers, they're still submitting bundles and they want atomic execution. Therefore you need some way in the SDK to acknowledge that as a native bundle type on chain, we can leverage, prepare and process proposal for the auction mechanism, meaning we can sort of define the rules of how the bundles should be ordered or merged or sort of put together with other transactions in prepare and process proposal.
00:32:00.338 - 00:32:54.822, Speaker E: And then the big thing is we can leverage vote extensions for privacy and credible auctions. So with threshold encryption you can have one of the first real commit reveal schemes to create a credible auction and then you also have the data availability from vote extensions to make sure that there's at least BFT resistant. Censorship guarantee around people participating in the auctions. You'll still have off chain actors, right? There might be searchers, there might be simulators as a service in the future. There might be some kind of bundling off chain system, but because they don't decide the final ordering, it's a much lower risk that they'll ever become entrenched. So just to sort of round it out, we believe that Mev should fit in sort of this Cosmos feedback loop where validators respect chain founders who optimize for the user experience of users who keep validators accountable. Right.
00:32:54.822 - 00:33:26.450, Speaker E: This is a very unique feedback loop that we don't see in Ethereum, where validators are commoditized and relatively anonymous and don't really care about their users. And chain founders have a much smaller say in terms of the overall experience. Mev should sit in this. It should be fully controlled, fully sovereign, and sovereignty means choice. So giving sort of appchain developers the maximum amount of choice they have in their MVP markets. So just to round it off, if you're a chain developer or want to build onchain MVB solutions in Cosmos, this space is very early. Please reach out.
00:33:26.450 - 00:33:33.140, Speaker E: My telegram is madware 100, but we're also skip protocol on Twitter. Hope that was at least interesting.
00:33:33.990 - 00:33:42.920, Speaker C: That was very interesting. And there's three questions in the Q and A session if you would like to address them.
00:33:43.690 - 00:34:27.474, Speaker E: Yeah, so first one I see is, any plans to expand into generalized strategies rather than specifically back burning ARBs? Hopefully that was answered by the presentation. Yes. This is a very early and difficult space, but we're trying to sort of move protorev in this direction, and that's what we consider to be a protocol or protocol owned builder. Curious how the backRunning algorithm is updated through governance and the frequency of updates Magnus expects. So the back running algorithm, of course, the logic can be updated whenever needed, but the most commonly updated thing would be the routes that it uses. Because it is an in protocol builder and this is a limitation, it can't consider every single route. Right.
00:34:27.474 - 00:34:56.146, Speaker E: Therefore, it has some heuristics in terms of what routes it considers, but those can be updated anytime. And I expect that to be updated relatively frequently based off of feedback. The seven M you mentioned at the beginning, what is the time frame? That was since Osmosis's founding. So we started that sort of at the beginning of Osmosis's producing blocks, and then we've measured that sort of on every block since in terms of only cyclical arbitrage. Great.
00:34:56.248 - 00:34:57.998, Speaker C: Thank you very much, Magnus.
00:34:58.174 - 00:34:58.770, Speaker E: Of course.
00:34:58.840 - 00:34:59.620, Speaker G: Thank you.
00:35:00.790 - 00:35:05.670, Speaker C: And next on the stage, I would like to introduce Sean from Mechatech.
00:35:10.210 - 00:35:10.960, Speaker F: Hi.
00:35:11.570 - 00:35:12.320, Speaker C: Hey.
00:35:13.570 - 00:35:15.680, Speaker F: How do I share my screen? Hold on.
00:35:16.210 - 00:35:21.938, Speaker C: Window share menu? Yeah, open share menu. Exactly. That's it. Perfect.
00:35:22.104 - 00:35:22.722, Speaker F: Okay.
00:35:22.856 - 00:35:24.530, Speaker C: How's that yours?
00:35:25.350 - 00:36:05.338, Speaker F: Okay. I don't have any as many as the last couple presentation, so we'll keep it short and sweet. So hello, my name is braps. I'm the co founder of Mechatech. We are the builders of Zenith, which is an off chain builder that is currently live on Osmosis, Evmos, Juno and some other chains. And we want to talk about the potential for builders or block builders to become citizens. So, as we've heard in the past, talk and beyond, builders are a thing today which essentially optimize the construction of blocks.
00:36:05.338 - 00:37:22.966, Speaker F: And in particular, off chain builders are essential to capture crosschain mev. So anything that requires information that is off chain, like sex, dex or from other chains, can be seen within this sort of umbrella of crosschain mev, which has to sort of be off chain. So this, especially in the internet of blockchains, where we're living in this world of interoperability, we believe that a lot of the revenue that's going to be used to secure chains is going to be coming from caution MEV, so it needs to be integrated in some way. Right now, the way it's done is with off chain builders. The problem with off chain builders right now is that it requires sort of custom, unaudited software, right? So everyone who wants to either run Skip or Mechatech runs a patch version of tendermint, which needs to stay up to date with every chain in which you operate. Another problem with off chain builders is it's never clear who is running them and what those builders are contributing to the block. So whether they're front running, whether they're censoring or doing any kind of nefarious operation, it's impossible to know and it's possible to know what validator is working with them.
00:37:22.966 - 00:38:27.550, Speaker F: So in this way, block builders are unaccountable and we believe that to be a problem. So what do builders look tomorrow look like tomorrow? So what Mechatech is working on, in collaboration with a bunch of other parties, with input from many different chains, is a builder module. And the builder module is going to provide sort of a core API defined between every builder and every chain. It's going to allow partial block construction, which is going to be chain governed, where a builder is going to contribute probably a subset of the block and not the entire one. And it's going to pay for that right through a chain governed account. So the distribution of the proceeds of off chain block construction is going to go not between the builder and the proposer, but instead the builder and the chain. And this could be used in many ways of which we're going to talk about very briefly.
00:38:27.550 - 00:39:52.710, Speaker F: The most important contribution of the builder module is that builders are going to be accountable for actually the transactions that they contribute to the chain. So the entire bundle, whether it's three transactions, whether it's top a block, or whether it's the entire block, is going to be sort of signed by the builder and controlled by the state machine. So that means that chains are going to be able to outsource a specification of the kind of block that they want constructed by builders and be able to accept or reject that block construction in consensus. So if a chain only wants OFAC blocks or non OFAC blocks, it will be able to both specify and assert that preference at the consensus level. So in this way, block builders are essentially going to evolve into this role of just optimizing specific parts of the block within the chain specifications and be part of the overall Mev landscape, probably in composition with other on chain solutions. So of course this is an ongoing process that we're doing in collaboration with the Cosmos SDK. We are building upon the work that Joseph mentioned with ABCI.
00:39:52.710 - 00:41:08.590, Speaker F: So obviously it's going to be integrated with Prepare proposal and Process proposal. So there's some questions there, but there are other more important questions that I think we should answer as a community. And those questions are what is the shape of the block that we want people to build? How should the builder be punished if they build blocks outside that specification besides just missing the proposal? And then how should payments be distributed? So payment distribution is something that is particularly interest to mechatech as sort of contributors to public goods. The goal has always been to sort of fund core infrastructure, but there's many other options, right? So one idea of how the proceeds for Mev should be used could be just to burn it. So all the auctions, the proceeds of every auction goes into the zero address and becomes essentially like a subsidy to every Osmo holder or whatever chain it operates on. Another option is for it to go to the community pool. A third option is for it to follow the exact same distribution and commission that stakers and validators share.
00:41:08.590 - 00:41:36.540, Speaker F: So it would essentially mean all of mev that's captured from cross chain would be just part of the security budget. I don't think this is a question that Mechatech can answer alone. So we want to put that question to you and that's why my presentation is so short. Thank you very much. If you want to contact me directly, I'm very interested in your thoughts, perhaps at mechatech. Otherwise, I think we have some time for q a.
00:41:38.350 - 00:41:44.890, Speaker C: We do indeed. We have three minutes for the Q A. So if there is any questions, you can put them in the chat.
00:41:53.270 - 00:41:55.330, Speaker F: Everyone is in ferocious agreement.
00:41:59.350 - 00:42:05.890, Speaker C: There is one question. I see. And Magnus is also writing.
00:42:23.670 - 00:43:04.494, Speaker F: Oh, how should it be distributed? According to you, Sean? I like the dumbest solutions. So the dumbest solution would be just to follow the staking rewards for now. I don't think the revenue is that significant and that it's probably better to sort of develop the ecosystem as a whole. As wouldn't see any value, right? It would just make the chain more secure. That's the dumbest solution. Another solution which is like the protorev module, they're saying they should actually just pool the money and then decide how to spend it later. That's another idea.
00:43:04.494 - 00:43:59.630, Speaker F: I don't know how effective community pools are at spending money, so I'm kind of open to that. So the way it's going to work in the builder module is that the payment distribution is going to be a callback that is defined by the chain. The chain is going to implement a payment distribution function that is going to decide. The builder module is not going to decide. Define crosschain mev. So crosschain mev is like if transactions that originate on the Cosmos hub sort of expose some alpha which could be captured on Osmosis, or say someone buys a million atoms on Crescent Dex, and we expect that that's going to move the price, and that price is eventually going to move on Osmosis. So that would be crosschain mev.
00:43:59.630 - 00:44:14.380, Speaker F: I'm missing a question. Am I missing a question?
00:44:15.070 - 00:44:19.260, Speaker C: Yes. Still a few more in Q and A. Oh, sorry.
00:44:21.170 - 00:44:31.480, Speaker F: Any plan to expand general strategy? That's not for me. I don't see any questions in the Q a.
00:44:32.570 - 00:44:47.870, Speaker C: My questions how do off chain builders capture cross chain mev in an as chronicus environment in Cosmos, is there a liquidity risk they have to take on? Mostly coordination.
00:44:49.570 - 00:45:27.354, Speaker F: So the way they capture it is off chain builders can essentially synchronize the block space to buy on multiple chains so they could coordinate because they're kind of like relayers. Right. And they do take on liquidity risk or inventory risk if they need to maintain sort of liquidity positions on multiple chains to do some kind of like if they're just market makers. So when you say cross chain mev, if we simplify just say they're market makers, then they have to maintain liquidity on multiple chains to do that, and that means risk. Where are these questions coming?
00:45:27.392 - 00:45:30.730, Speaker C: And the last one, what is the adoption of Zenith?
00:45:32.830 - 00:45:54.450, Speaker F: Well, we're moving everything behind the builder module, so Zenith is live on a couple of chains with a bunch of different validators, but what we really want is the representation of Zenith to be available on chain. So it's not like us declaring who uses Zenith. It's that Zenith will sign every single bundle that it contributes to the chain.
00:46:00.560 - 00:46:04.910, Speaker C: Okay, let me check if there's any other I think that's it.
00:46:05.840 - 00:46:07.324, Speaker F: Cool. Thank you very much.
00:46:07.362 - 00:46:17.440, Speaker C: No more questions. Thank you, too. Okay, so the next person that I'm introducing to the stage is Alpin from Osmosis.
00:46:24.940 - 00:46:26.010, Speaker G: Hello. Hello.
00:46:28.780 - 00:46:31.860, Speaker A: Okay, I'll just share your presentation.
00:46:31.940 - 00:46:32.570, Speaker C: Yeah.
00:46:34.880 - 00:47:13.284, Speaker G: Awesome. All right, perfect. I'm going to present, over the next ten minutes or so, an alternative model to thinking about mechanism design. For mev, that's focused on execution risk. So my name is Alpin. I'm a protocol engineer at Osmosis. Put a lot of mental cycles into this, and what's mainly motivated this topic is just seeing people time and time again speak past each other for not having sort of common ground to speak on.
00:47:13.284 - 00:48:11.140, Speaker G: And my hope is that the sort of execution risk based model can bring people together and be a useful way to reason about mev. So before we dive into that, there are a bunch of existing ways of framing mev, especially for protocol design. The two sort of main ones in the Cosmos ecosystem are this atomicity focused one and this good versus bad. Both of them are actually, albeit like a bit of a meme, but I think to their merit, I think they're quite good, but they're insufficient in some key areas. The atomic versus non atomic one kind of misses the point of mev because it keeps the focus on a characteristic of mev as opposed to its emergent impact on participants such as the users. Protocol searchers. The good versus bad mev is a good abstraction, but it obviously suffers from being a bit too vague.
00:48:11.140 - 00:49:18.940, Speaker G: It has this vague notion of mitigating bad mev that doesn't really mean anything to anyone and makes it hard to serve design mechanisms around mev. So start with what are the properties of a useful framework for mev? I'll stand by. I think it's important that it's not prescriptive about what is desirable or undesirable in terms of types of mev, for the sake of being portable and also for the sake of sort of avoiding this extremely frustrating rabbit hole. Of debating what this desirable form of MV is at the expense of what a good mechanism designed for harnessing or controlling MEV might be. Another one is that it should be focused on at least some participant in the system, as opposed to some technical characteristic of the mev, which is largely just not useful. And then, perhaps most importantly, needs to be easy to reason about the trade offs. We can't shove under the rug this notion of mitigation.
00:49:18.940 - 00:50:28.372, Speaker G: It's critical that we actually can sort of understand what the impacts of our design decisions are. It would be nice, of course, as well if we can capture existing systems in this new framework just for the sake of making it easier for people to digest. So the question that people always ask when trying to reason about mev is what is mev? My claim is that this is actually the wrong question. The pertinent question is not sort of one of classification around mev, but rather it's a control system view on mev. How do we harness this value that sort of flows through our system? And then we can treat mev as an abstraction in the same way that we might treat sort of good or bad as an abstraction for the sake of reasoning about trade offs. My proposal is that execution risk is the sort of fundamental axis along which we can reason about these systems. And I would like to make a sort of side note here that this is not necessarily a profound point.
00:50:28.372 - 00:51:38.860, Speaker G: I think we all intuitively think about mev in this way, except making it explicit has some great benefits that I'll touch on in a second. So first of all, what is execution risk? I define execution risk in this context as the risk of an attempt at sort of mev extraction that fails, of course, with some cost. And there's some amazing properties of this sort of framing of execution risk. One is that this sort of hints at how it might be useful for mechanism design, but it has this great correlation between the increasing of execution risk and the increasing of cost for the searcher. It also sort of sidesteps the super annoying question of like, is mev ever truly removed from the system or is it just shoved into some probabilistic stat? ARB I think it's all captured by this model. It kind of avoids that whole rabbit hole. And of course, it puts the focus on searchers instead of the mev.
00:51:38.860 - 00:53:04.250, Speaker G: Ethcore developer might say that bad mev is reorg based mev calls one sort of app chain dex developer might say it's sandwiches. We don't really care, right? We care about how it affects the searcher, which is really the sort of primal participant of these systems. I'd also like to highlight that if you really dig into what have been the key innovations around mev mechanisms, and you'll find very quickly that actually almost all of them fall on this axis of execution risk, pushing it one way or the other. For example, Flashpot's primary innovation was reducing execution risk for their definition of good mev, which was sort of non reorg mev. To take a more graphical point on this, if we were to plot out this axis low to high execution risk, where might some of the things that we're familiar with fall? I would say, for example, we can throw priority gas auctions somewhere along the sort of high execution risk on the axis you really need to span. There's a good chance that your transactions will fail. Flashbots bundles, of course, have pushed execution risk down for the types of transactions that they support.
00:53:04.250 - 00:53:51.220, Speaker G: And then a great example of bad mev being mitigated is reorg mev on ethereum. It's v one where essentially whether you're a searcher, whether you are a miner or validator, it's all but impossible to land any mev that's related to reworks. And this is by design. So the emergent design goal of this system or this framing is basically these two points. It's to decrease execution risk for good mev and increase execution risk for bad mev. This will make some people scream, I'm keeping the abstractions of good and bad. I actually think that they are useful for us to keep the focus on the mechanism.
00:53:51.220 - 00:55:02.968, Speaker G: So if we were to sort of plot out all of these sort of good and bad mev types on this axis, you can throw sandwiches, liquidations. ARBs whatnot in there then? The goal is essentially to make our mechanism design be this sort of polarizing force where we push the good mev towards being super low execution risk and push the bad mev towards super high execution risk. And in some sense, this is how we sort of achieve incentive compatibility in our protocols. Of course, the question then is how? Very briefly, there are a lot of ways to do this, but an example of decreasing execution risk would of course be the flashbots bundle auctions, something like what Skip is working on, or I guess we'll be working on after ABCI Plus plus with these topple block transaction auctions. This notion of synchronous block space for cross chain mev and in general, any transition towards atomicity for transactions decreases execution risk. And we should be encouraging this and designing this into our systems for the desirable forms of mev. The sort of positive someones increasing execution risk includes all these privacy solutions such as threshold decryption.
00:55:02.968 - 00:55:57.452, Speaker G: Some of the work that Penumbra is working on falls under this category. In general, this shift from atomic to non atomic mev actually tremendously increases execution risk because now you have to take on the sort of volatility exposure that makes it very hard to remain profitable in the same way that you might with Tommy transactions. And then of course, you have all these batching and randomization based options as well. We'll find that sort of like the properties of the execution risk model for mev actually are that it is not prescriptive about what's good or bad. You might recall this from earlier, it is focused on the participants and not the mev, and it is quite easy to reason about the trade offs and importantly their impact. It also does encapsulate these good, bad and atomic non atomic notions quite cleanly. So thanks, I'll stop there.
00:55:57.452 - 00:56:13.360, Speaker G: I do have some extra slides if needed if we have time, but I hope this is a sort of useful framing that will help us get on common ground when we're discussing this important topic of mechanism design around Map.
00:56:14.040 - 00:56:38.060, Speaker C: We are perfectly on time, so thank you very much. Alpen. I'm going to leave you on the stage and I'm going to introduce our next speakers panelists. So. Yes, Anna is here. Welcome Zkv and Zaki. I think Zaki needs no introduction, so yeah, guys, the stage is yours.
00:56:42.960 - 00:56:48.720, Speaker A: Zach, is he joining?
00:56:50.100 - 00:57:01.776, Speaker C: Is he here? He was here just a second ago. I added him, so hopefully everything works.
00:57:01.958 - 00:57:22.190, Speaker A: Okay, we'll give him a minute to get back here. Alpin, I had as one of my first questions, what is mev but is now crossed out from our notes? I have a better question. Hey, Zucky. There you are.
00:57:22.720 - 00:57:24.188, Speaker B: How late am I?
00:57:24.354 - 00:57:25.516, Speaker A: Not late at all.
00:57:25.618 - 00:57:26.232, Speaker B: Perfect.
00:57:26.386 - 00:57:43.668, Speaker A: You're just on time. Okay, so I think we're going to kick off our panel. I think we probably don't need intros. Alpin, we just met, you and Zucky. Well, actually Zucky, you just arrived. Maybe do let us know who you are.
00:57:43.834 - 00:57:55.000, Speaker B: I'm Zucky, longtime builder in the Cosmos ecosystem. I've been working on this stuff since 2014. So, yeah, that's basically me, co founder of Sommelier.
00:57:55.820 - 00:57:56.280, Speaker C: Nice.
00:57:56.350 - 00:57:57.530, Speaker G: Various other things.
00:57:58.540 - 00:58:14.380, Speaker A: Cool. And Will and I are co founders of a ZK Validator, and as well as other things as well, I do a podcast called Zero Knowledge. I do zkhack ZK summit. Things that start with ZK. Will, I don't know if you want to say yeah.
00:58:14.450 - 00:58:26.850, Speaker H: And ZK Validator also runs validators across quite a few of the Cosmos chains evmos, Agoric, cosmos, Osmosis, and lots more coming in the future.
00:58:28.420 - 00:58:57.150, Speaker A: So instead of my what is mev? Question to kick us off, I sort of want to take sean somewhat answered that, which was, like, when you talk about a cross chain environment or a multi chain environment, but I do want to start with this sort of framing. It's like, how is mev unique when you start to add these different chains and different networks, is it different? And, Alton, maybe this is a bit to you, because you had rejected my first question.
00:58:59.280 - 00:59:56.972, Speaker G: So the question is about when we have app chains in general, cross chain environment, how does the nature of mev change? I mean, fundamentally, it's still the same thing, right? We're just introducing more potential sources of, I guess, non atomic mev until we have some solutions for that. And I think it gets much harder to track. It becomes this sort of nebulous notion of what actually is the value flowing through these systems. But I think one thing that was mentioned in Magnus's skip talk that I really agree with is it finally opens the door for this sort of category of mev that is analogous to decentralized exchange. Decentralized exchange ARB. But now it's across chains, and now we can actually sort of keep it internal within our ecosystem. We can harness it.
00:59:56.972 - 01:00:13.830, Speaker G: It lets us reason about these systems in a way that's much more positive sum for protocols. I know Zakia has some interesting takes on this as well. He's done a lot of work with the scheduler stuff. So zaki, go ahead with this.
01:00:14.360 - 01:00:17.510, Speaker B: Okay, I kind of lost what the question was.
01:00:19.240 - 01:00:24.200, Speaker A: How is mev unique in an IBC enabled network when you start to go cross chain?
01:00:24.700 - 01:01:50.852, Speaker B: Well, so right now, IBC is, to the best of my knowledge, the only Bridging protocol that has permissionless relayers at scale. Right now, lots of people are working on this axilar hyperlane, like lots of other people are working on this, so it will expand the cross chain MEB. So the biggest thing, right, is in a world where you have permissioned relayers, the permissioned relayer has a lot of control over capital movement and all of this stuff, and so the MEB just floats up into that layer, right? In a world where you have permissionless layers, now you kind of start imagining you end up with a cross chain mev supply chain that starts to feel like the cross chain mev supply chain in a single blockchain, where you have many different actors who can potentially and you get this evolving marketplace of things. And so I guess one kind of mev that we basically see a lot of today doesn't actually require any cross chain messaging. It's just about time synchronization. It's like, oh, the price of, let's say most of the liquidity for an asset is on binance. The price of the asset moved now, moved on binance now.
01:01:50.852 - 01:02:46.852, Speaker B: Everything needs to be synchronized against that. And so my mental model is always like, you can think of cross chain mev as like, ripples in a pond. My more nerdy mental model is always like light cones and special relativity, but no one will know what I'm talking about. So ripples in a pond, a pebble gets dropped into a pond, these ripples travel outward, and the energy of the ripple is like the mev, right? It's like the cost of synchronization because of an event. And so IBC to a certain extent makes this more interesting because now you can pair. So you have forms of this, which is just synchronization. But now if you have capital moving between chains or information about capital, so I locked funds on this chain that has market impact as well.
01:02:46.852 - 01:02:51.430, Speaker B: And so there's also that synchronization cost. And so IBC really opens that up.
01:02:54.380 - 01:03:55.880, Speaker H: I think it's quite interesting also if you look at the context of, let's say, the interchange ecosystem compared to Ethereum, actually we're super early on, let's say in terms of actual mev that can be captured in the interchange. But equally, there seems like a much richer array of solutions already starting to develop. I don't think that's not just because of IBC. It's also because of the way that app chains can give a lot more flexibility around how these solutions can exist. Whereas in ethereum, just because of the slightly more monolithic nature, it is a little bit more prescriptive. And therefore most of the designs have settled into one way. So the fact that things like interchange scheduler versus the protocol revenue in Osmosis and other things are all being, at this quite early stage being considered, I think probably is due to some of the intrinsic natures of what this ecosystem is, which is, I think, probably going to lead to ultimately better solutions for every ecosystem.
01:03:55.960 - 01:05:10.464, Speaker B: Well, can I just expand off of that a little bit? I think the scheduler frequently gets misunderstood in a lot of way as like a capture mechanism for mev. Whereas my read on what the scheduler is, is the creation of a new kind of commodity block space that doesn't exist today. Right now you have commodity block space on individual chains, and there's a defined way of buying commodity block space on an individual chain, which one way of doing it is just like, have a bunch of stake. And then the other way is some sort of API like flashbots, where you have flashbots or like Skips Mev Tendermint or Zneth or all of these things are like, hey, you can get this, you can buy this commodity. But there is no commodity of MultiChain block space, right? That commodity doesn't exist. Certainly it exists sort of coincidentally, you might be like, oh, I'm the same validator on these three chains. So I have created it, but in no formal mechanism to create that commodity of multi chain block space exists.
01:05:10.464 - 01:05:45.036, Speaker B: And the whole point of the scheduler was to create that commodity, which you need something like IBC to be able to do that, right? Because you need to have a common multi chain protocol that can then be fed into the block production mechanics that come. And so in Cosmos, we have everything with Comet. BFT will be able to support the scheduler very easily. And so many applications can then opt into supporting the creation of this new commodity block space.
01:05:45.218 - 01:06:07.350, Speaker H: So maybe, leading on from that, maybe this is the outfit to start with. Why would a chain like Osmosis choose to opt into the scheduler as opposed to developing? I mean, as is already happening, like other ways of maybe auctioning box space or capturing revenue for itself.
01:06:08.360 - 01:06:21.576, Speaker G: My understanding of the schedulersaki, correct me if I'm wrong, is that it's mainly for these sort of ICS supported chains where Osmosis would not really be in scope for that, right?
01:06:21.678 - 01:07:26.784, Speaker B: No, that's not my perspective, at least. My perspective is there's two hypotheses about this. One is this is a conversation I have a lot. The core thing is no one is trying to take away osmosis's sovereign ability to own its own block space. Osmosis can choose to sell what it wants to sell into the scheduler, right. But let's say that Osmosis's block space and priority in that block space as a non atomic unit like individual to Osmosis is worth X. My argument is that if you can compose some fraction of Osmosis block space with arbitrary other chains, so, like Osmosis, Crescent injective the list goes on.
01:07:26.784 - 01:07:58.570, Speaker B: Right. And they were all offered into this one auction, the value just to Osmosis of that space would be like 1.5 X. Right? That's the argument. And so no one is suggesting that the scheduler needs to decrease the sovereignty of any chain. It's more that it's the opportunity for chain to participate in the creation of this more valuable commodity that no chain can create by itself.
01:07:59.420 - 01:09:03.144, Speaker G: Yeah, this is a very interesting topic, especially around is there real value for sort of synchronizing and selling this block space across these different markets? I think the end state of this will be something like that. Just because I can't see a scenario where just from a general protocol design standpoint, we want to push this Mev towards being in the way that you described zaki more atomic, sort of atomic. Mev has this amazing property that it's really easy to capture. Value from it. It's very clear what the bounds of the mev is, where it starts, where it ends, and it's very easy to create competitive markets around it. I think this is one thing that the scheduler is doing really well for Osmosis right now. I think the focus is very much on is very much on one, what's going to happen on the Osmosis chain on its own.
01:09:03.144 - 01:10:02.210, Speaker G: I think Osmosis is already going to be generating very large portion of mev prior to crosschain mev being sort of a large market. And then second, I do have this sort of inkling that these top of block flashbot style auctions will actually capture a very large portion of this crosschain mev, albeit not atomically. Right. But for instance, I think things that are in scope for that will also be things like centralized exchange to Osmosis ARBs where we're like that, that sort of top of block transaction will have some value that can be captured by Osmosis Arbitrarily due to sort of that priority. I'm not sure if sort of integrating directly with the schedulers this is not something that I've put too much mental thought into, but I'm sure it'll be on the horizon if it makes sense for Osmosis. Yeah.
01:10:04.340 - 01:10:33.930, Speaker A: I want to do a little bit of a throwback to an earlier mitigation proposal. I actually don't know if this is still on the roadmap, if it's interesting, but a year ago, or more than a year ago, we had a conversation on the show with Sonny and Dave and we talked about sort of mitigation threshold decryption using still. Is it happening or is it not?
01:10:35.420 - 01:11:27.470, Speaker G: Of course of course it is. I think the primary blocker for it has been sort of ABCI plus plus. Other than that, I think it's very well specked out. We're ready and kicking to get it through and I think it will be actually cited specifically Threshold encryption as one of the primary use cases or utilities of building on app specific infrastructure. This is truly something that's not feasible to do in a general purpose environment. I think actually a lot of really interesting app chain based innovations have been blocked on this ABCI level iteration. Top of block MC auctions is another one.
01:11:27.470 - 01:11:41.410, Speaker G: But in the meantime, in the interim, we have been sort of working on a number of other sort of mitigation strategies. But yeah, I mean that's very high on the priority list. As soon as it's possible.
01:11:42.260 - 01:11:51.988, Speaker A: Do you think that there is also any sort of social or governance block to this though? Do you feel like there could be pushback you sort of say it's specked out, but do people want to do this?
01:11:52.074 - 01:12:41.910, Speaker G: Is there groups that don't threshold decryption? There are very few user level downsides to threshold decryption. I think it's very unlikely that there will be sort of tremendous governance pushback towards this. It's actually a protection mechanism for users. What we've actually observed is the exact opposite that people really want this to get through so that they don't have to worry about things like as much about some types of sort of exploited or extractive mev. Of course, there's always some sort of base layer risk of implementing, I guess, such major changes. But at the end of the day, I think this is something that users want.
01:12:44.040 - 01:13:10.380, Speaker H: So it sounds like pretty soon we're going to have the protocol revenue module implemented and live. And initially, revenue won't be basically just be paused and put into like a pot, waiting to see how much it is before it's distributed in some way. In kind of your views. What do you think are going to be the best ways to use that for the Osmosis ecosystem?
01:13:13.200 - 01:14:00.076, Speaker G: I don't have too strong of an opinion on this. Other than that I think, given that the revenue will likely be quite small if it's distributed to everyone, I do think that there is some merit in sort of directing it to the community pool, maybe to some sort of feed into things like our grants program or other sort of public good type funding on Osmosis. I think my sort of hunch is that this will be the most positive sum approach for this, although I do see the point for just distributing prorata to stakers as well, although my soft vote would be to community pool it. Yeah.
01:14:00.098 - 01:14:14.530, Speaker H: I guess if you think about it as a tax on traders, essentially something that kind of creates value back for them seems to make most sense as opposed to stakers in some arguments, but yeah, I guess it's a relatively small amount.
01:14:15.940 - 01:14:41.130, Speaker G: Yeah. And also this is a very common I think demonstrating that it's possible to distribute that value to stakers is almost as good as actually distributing it to stakers. Right. Just as something completely even unrelated to crypto Berkshire Hathaway is like, I don't think they've ever distributed a dividend. Right. But they're valued as though they could. Right.
01:14:41.130 - 01:15:03.104, Speaker G: The capacity to distribute dividends is actually and the reason I say it's more positive sum is because when you keep that value in the ecosystem, to your point, will it actually grows the ecosystem and you can sort of get these positive feedback cycles rolling. Now there's a question of governance around. How is that distributed? That's a separate discussion, though.
01:15:03.142 - 01:15:14.660, Speaker A: But yeah, I kind of want to ask so Sean asked in the chat. I want to kind of bring this up. I think it's a bit related to my earlier one, but it's how much front running happens on Osmosis.
01:15:19.560 - 01:16:17.850, Speaker G: If you go block by block and look, it's actually shockingly little, I think, for now. And this is not actually just for Osmosis. Right. Even in general, I think if you look at Ethereum, for example, small swaps and trades tend to not really get front run because it's not worth it. I think on Osmosis, what we have seen is that sort of the exploitative mev or say like negative sum mev like sandwiches and front runs in general are proportional with volume. So as volume goes down, roughly goes down as well. I do think that we will see sort of an uptick as more volatile assets are sort of launched and traded on osmosis because it's usually like the volatility that forces people to increase their slippage sort of bounds and also as a result, get front.
01:16:20.860 - 01:16:21.610, Speaker B: Awesome.
01:16:22.220 - 01:16:54.310, Speaker H: So, wanted to ask a little bit more around ABCI and I think multiple presentations earlier mentioned using aspects of it prepare proposal, for example. But it would be useful to have kind of a big picture sense for how you imagine this changing the way that the mev ecosystem evolves in different app chains kind of longer term and maybe what some of the implications are.
01:16:56.680 - 01:16:58.932, Speaker G: Zuckay answered a couple. You want to go?
01:16:59.066 - 01:18:45.604, Speaker B: Yeah, I could absolutely take why ABCI Plus Plus is perhaps the most important innovation and consensus going on right now. What has been most interesting to me has been the number of different papers that have come out after ABCI that have proposed mev mitigations that can be implemented within the framework of ABCI. So my favorite one has been Elijah and a bunch of other people who I don't know personally, so I can't remember who they are posed this whole thing about, oh, if you want censorship resistant auctions, you need to have blocks in which no single proposer controlled the block, right? And that is an entire family of consensus algorithms, but none of them have been very successful. Some of them have actually been implemented in the blockchain context, but none of them have been very successful in the blockchain context. And it turns out you can get most of the properties, most, if not all of the properties of such a system by using vote extensions, which is an ABCI mechanism. It has been a long, frustrating wait, getting ABCI Plus Plus into the world and talk about team turnover and all of the challenges and having to rename the consensus engine. And it seems like every force in the universe has been arrayed against getting this out the door.
01:18:45.604 - 01:19:24.550, Speaker B: But it is imminent and it's amazing. I mean, it's useful for stuff. The other thing that's worth mentioning is it just has utility beyond mev mitigation. But it just turns out, like so many things, you're like, oh, I want to have IBC packets that can control whether or not you need a signature from a certain party on your top of block. Oh, I can do that in ABCI Plus Plus. Oh, I want to have auctions, but I don't want the proposer to be able to censor more than one third of the voting power's contribution to the auction. Right.
01:19:24.550 - 01:19:41.320, Speaker B: I can do that with ABCI Plus Plus. And we just keep finding more and more ways of building a lot of the stuff that people are coming out with as research proposals, but practically implementing it on a production ready piece of software.
01:19:42.940 - 01:20:01.490, Speaker H: So there are a few questions in the chat, just following on from that about sort of how imminent it is now to be released and what might be like the remaining blockers, if there are any, or if it's now just like the way has been cleared and it's just a matter of time.
01:20:05.620 - 01:20:45.452, Speaker B: It'S been implemented. Yeah. ABCI is it's right now we're doing the great Comet BFT release rename and integration of the rename of Comet BFT into the Cosmos SDK, which everyone is finding extremely emotional. And then after that, you will see the first Comet BFT release with pieces of ABC I plus plus, and then subsequent. That the full. But all of these things are actually like trains that are running in parallel rather than sequencing things because the code is all written. It's actually been written for a while.
01:20:45.452 - 01:20:59.990, Speaker B: But release management is hard. And as anyone who's been watching outside of the development of tendermint, the release train got broken last year and still not unbroken yet, but we're working on it.
01:21:01.320 - 01:22:08.840, Speaker H: Fair enough. So I think wanted to ask another question more around mev in general, in the ecosystem we know, like rough size now of, let's say, $7 million we can see was captured on Osmosis, and hopefully that's growing. There's this hypothesis that there will be a lot more interchange mev as more chains, more DeFi emerges. But it's still pretty early. And I guess in some way a lot of these solutions are kind of experimental. Now, assuming that there will be a lot more defactivity and other sources of mev emerging in the future, do you already have a sense of what the future sources and they're going to be most important will be and maybe over the next year, will there be any things that are going to really change that or bring a lot more mev to the ecosystem?
01:22:12.380 - 01:23:04.410, Speaker B: So things like lending protocols and stablecoins should result in a large increase in the amount of mev period and cross chain mev in addition to just increases in transaction volume. These are probably the biggest potential sources. So I said this on Zero Knowledge podcasts, and I'll say it again. The Cosmos ecosystem has not remotely recovered yet in terms of liquidity from the Terraco apps. We still have a long way to go. But assuming that we are able to recover and get back to something like what we were and then hopefully exceed the volumes that we saw during the sort of anchor carry trade era, the amount of mev in the ecosystem actually will likely become quite large.
01:23:05.360 - 01:23:57.900, Speaker G: An important sort of additional point to this is that mev that's generated is extremely nonlinear. Right. You can't say, as we might be able to with swap fees, for example, like, hey, x percent increase in volume leads to x percent increase in mev. What we've seen time and time again is that mev is stagnant, and then it explosively grows, and then it crashes, and then it grows and it crashes and it grows. And it's also notoriously hard to track. So we have to be thinking about designing systems that keep this in mind. And if we don't, we might end up there's so many examples in sort of other ecosystems where they've finally hit some stage a period of volatility or growth and just have been hemorrhaging cash to independent searchers.
01:23:57.900 - 01:24:39.512, Speaker G: The famous example of this is what happened sort of in avalanche when they had their sort of summer of growth with DFI. And for a very long time, I think it was like the avalanche foundation just straight up denied the existence of mev in their ecosystem. And something on the order of, like, $200 to $300 million of MV was extracted by, I believe, less than 20 entities. I would speculate that it's probably single digit number of entities. It's very much like in a sort of unsupervised environment, it's winner takes all. It's extractive and exploitative to users. So we have to think about these things.
01:24:39.512 - 01:25:05.810, Speaker G: And even the 7 million mev actually is not a very large amount. But if you look at the inconsistency of it, like, a very massive portion of it happened during the Terra crash. And I think any sort of bet on sort of the growth of mev in the cosmos ecosystem is essentially going to be a bet on the volatility of the cosmos ecosystem, volatility of crypto as a space. It's a pretty obvious bet to make. We have to keep these systems in mind.
01:25:07.220 - 01:25:46.430, Speaker A: Cool. So I think we're getting close to time. I do want to say to anyone listening, if you have questions that you still want to ask, put them in the chat, because we're going to wrap up pretty soon. Can you hear me okay? Am I coming in? All right, you all froze, so I just want to make sure. But I think I kind of wanted to wrap on the topic of what else is new generally in Osmosis. Since this is the ZK validator putting on our first Osmosis event, what else should we be looking out for? Just generally, what's the topics? What are the themes that you see for the coming year?
01:25:47.140 - 01:25:50.416, Speaker G: For the coming year? Wow. Give you a little bit shorter term than that.
01:25:50.438 - 01:25:50.816, Speaker E: Okay.
01:25:50.918 - 01:25:51.980, Speaker A: Coming quarter.
01:25:52.140 - 01:26:58.260, Speaker G: Yeah. We're going to be rolling out our implementation of concentrated liquidity very soon. We have a number of, I think, very amazing innovations on top of it and a few that will come after the initial launch that will align finally, some of the properties that traders and market makers expect from centralized exchanges in the UX of DEXes. I think there are a few sort know it's not surprising that some of these mechanisms weren't sort of they're very sort of easy to I think, you know, Osmosis team has done really good jobs for bringing together the next step of concentrated liquidity, and hopefully it will bring better prices higher, and in general, a bit more trading stability to the cosmos ecosystem. After that, hopefully we can take a proper crack at threshold decryption. Although right now, we're all hands on deck focused on concentrated liquidity.
01:26:59.320 - 01:27:05.690, Speaker A: And what about you, Zucky? What do you see in the future of the Osmosis? The future quarter, we're not going to go.
01:27:08.620 - 01:28:34.740, Speaker B: Mean. The similia team has put so much r D effort into understanding God's trade liquidity, so we're very excited to see it coming to the cosmos. Though psalm vaults for psalm strategies for IBC ecosystem is still a ways away from when we'll be ready to support that. I think that's pretty exciting in general, and I think really is going to I mean, people are underestimating just like, how much just like reducing the amount of idle liquidity means. Because right now, Osmosis token holders are just paying through the nose for liquidity right now, and I think that'll be important. What are the other things that I think in this quarter? I think are particularly I mean, the other thing is with Mars and the outposts and stuff like that, right now, Osmosis has just meant one thing, right? It's just meant Lping and swapping, right? And largely DeFi on Cosmos has meant Lping and swapping. And this quarter is already and in 2023, we're really starting to shift to new behaviors and new user experiences.
01:28:37.320 - 01:28:57.130, Speaker A: Nice. Well, I think that's a great wrap up for our event. There's no questions in the chat. So, I think. Yeah. That brings us to the end of our mev focused, first Osmosis focused event. Thanks so much to both of you for coming on this panel, and thanks will for co hosting it with me.
01:28:57.130 - 01:29:02.250, Speaker A: Co moderating. I don't know what this is, but yeah, thank you.
01:29:02.940 - 01:29:04.570, Speaker G: So thanks for having us.
01:29:05.100 - 01:29:09.036, Speaker A: Yeah, thanks, guys. See you later. Bye.

00:00:05.450 - 00:00:51.670, Speaker A: Welcome to Zero Knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online. This week I chat with Alex Glukowski, CEO of Matterlabs and one of the creators of the Zksync network. In this episode, we catch up about all things ZK sync. The last time he was on the show was over two years ago, and so there was a lot to talk about. We cover the ZK Stack framework hyperchains, the ZK Credo mission statement, and the Bujam proof system upgrade planned for Zksync era.
00:00:51.670 - 00:00:58.590, Speaker A: We also chat about the future of the project and more. Now, before we kick off, Tanya will share a little bit about this week's sponsor.
00:01:00.050 - 00:01:55.462, Speaker B: Launching soon, Namada is a proof of stake l one blockchain focused on multichain asset agnostic privacy via a unified set. Namada is natively interoperable with fast finality chains via IBC and with Ethereum using a trust minimized bridge. Any compatible assets from these ecosystems, whether fungible or non fungible, can join Namada's unified shielded set, effectively erasing the fragmentation of privacy sets that has limited multi chain privacy guarantees in the past. By remaining within the shielded set, users can utilize shielded actions to engage privately with applications on various chains, including Ethereum, osmosis, and celestia, that are not natively private. Namada's unique incentivization is embodied in its shielded set rewards. These rewards function as a bootstrapping tool, rewarding multi chain users who enhance the overall privacy of Namada participants. Follow Namada on Twitter at Namada for more information, and join the community on Slash Namada.
00:01:55.462 - 00:01:57.250, Speaker B: And now here's our episode.
00:02:01.110 - 00:02:10.466, Speaker A: Today. I'm here with Alex Glukowski, the CEO and one of the co founders of Matterlabs, as well as the creator of the Zksync network. Welcome back, Alex.
00:02:10.578 - 00:02:13.510, Speaker C: Hi Anna. It's an honor and a pleasure to be here again.
00:02:13.660 - 00:02:48.590, Speaker A: Now, Alex, this is the fourth time you're on the show, and I'm going to be adding links to the previous episodes. I'm also going to be referencing them quite a bit because I had a chance to listen back. One quick disclosure. The ZK validator is an investor in Zksync. I think this was actually one of our first investments. We mentioned it on our last episode because I think we had done it around that time, but I'm very excited to learn about what's happened since? So that earlier episode was from April 2021. At the time, I was very excited to be using Zksync because it was the first time that I got to use a rollup.
00:02:48.590 - 00:03:21.018, Speaker A: It was through the Gitcoin grants where they had actually just enabled the option to use Zksync instead of mainnet to do your donations. And as a recipient of these grants, I also was getting grants on ZK sync. And yeah, I just remember being so excited about having a chance to use a roll up at all. But I know that since then, so much has happened. Can you share? I know there's a lot to cover, but can you share in a nutshell, what's happened in the last two years with Zksync?
00:03:21.114 - 00:03:57.714, Speaker C: Absolutely. With pleasure. So the Zksync network that you've been using back then is now known as Zksync Lite. It was the first protocol that we developed and launched on the mainnet. It was a simple protocol for sending tokens, and later token swap were added to this. And that you used it at Gitcoin grants also captures a very important aspect of what Zksync is all about. Zksync is not really a specific network or just the name of the protocol.
00:03:57.714 - 00:05:03.866, Speaker C: It's the name of the project. It's the name of a bigger vision. And this has been the vision of the project since the very beginning, since the inception, we've always been very deeply focused on this core mission, and we've been very consistent about it. And it's all about scaling crypto to everyone in the world without losing the properties that make crypto valuable in the first place. The decentralization, self custody, security, permissionlessness, this inclusiveness where anyone can participate no matter what, without asking anyone for permission to join. So we had that in the beginning, and it was also very clear that in order to fulfill this mission, we have to make it very nice and user friendly and convenient. And I think this was the experience that was very impressive back then with Gitcoin grants, because you could do just one click in metamask and the system would process dozens of transactions to different recipients of the grants, and it felt like magic.
00:05:03.866 - 00:05:12.446, Speaker C: This is part and part what ZK is all about. It's the magic moon math, which adds magic to blockchain applications and scales it too.
00:05:12.548 - 00:05:57.262, Speaker A: It is funny, though, that back then that was very user friendly, but it was such a novel way of think like metamask. Before that point, you would never choose networks, you wouldn't actually make distinction. I mean, there was only one network you were usually working on, and I remember there was a learning curve even back then. Nowadays, though, I feel like a lot of that has become. People are quite used to it. And actually I think that conversation about usability, I want to come back to that later on, because as much as I feel like the goal is usability, getting there still is at times very challenging. I feel a lot of users, even today, even with easier tools, are still having a hard time getting into it.
00:05:57.262 - 00:06:42.060, Speaker A: So let's come back to that. I do want to say you mentioned that from the very start you were focused on the scaling of blockchains. And in I think, our first interview, we talked about how a lot of your team and a lot of the founders of Zksync were coming from the plasma world, had moved over into roll ups. At what point did the idea of the ZKE EVM really come into your mind? Was it already back then that that was the goal of using ZK? Or was it like, instead of plasma we're going to use ZK rollups? And then eventually this idea dawned on you that you could actually create an environment where people could deploy apps the way they do on Mainnet, Ethereum, on an actual ZK roll up.
00:06:42.430 - 00:06:49.658, Speaker C: This vision was there from the very beginning. It was very obvious, really, that the end game has to be full scalability.
00:06:49.754 - 00:06:51.578, Speaker A: You knew it was going to be Zke EVM.
00:06:51.674 - 00:08:00.866, Speaker C: If you read the very first blog post introducing Zk sync, where we mentioned Zksync for the very first time, and it was close to five years ago, it's called the introduction of Zksync. One of the points that we make there is that eventually we envision full EVM bytecodes being executable and provable internal knowledge proofs. The distinction from where we are today and where we were back then is it became feasible. It was not feasible five years ago, and it was not really clear how specifically we're going to manage that. It was clear that eventually it will come. We needed breakthroughs in the protocol development in the fundamental crypto primitives of zero knowledge proofs. And those breakthroughs eventually came in the form of plonk recursive plonk redshift, and then the systems that Cambrian exploded after that, so that we can finally have performance high enough to process essentially easy KVM level computation.
00:08:00.866 - 00:08:34.450, Speaker C: And this is what happened since the last time we spoke. We launched the easy kvms on Ethereum, and they are now life and flourishing in Zksync era. Was the first blockchain l two, where you could deploy Ethereum contracts without modifications and just let them work in exactly the same way the users interact with Ethereum, mainet, or with optimistic roll ups which were lived earlier. And now we're still at the beginning of a long journey to make it universally available and universally usable.
00:08:35.110 - 00:08:55.926, Speaker A: I want to ask you about, given that, I feel like the audience now knows much more about the ZkeVM space and the different kinds of zkvms. I know a few years ago, or maybe a year ago, Vitalik published this Zkevm landscape with these different types. I'm curious, where does ZK sync fall?
00:08:56.028 - 00:09:48.822, Speaker C: Yes, Zk sync era and Zk stack. The technology that we currently have still falls under type four, meaning you have to compile your contracts and deploy them in this network. But these borders are blurring. Eventually, I think we will have systems that will support different types of virtual machines in the near future, where it will not really matter. You will be able to execute any types of programming environments, from EVM native bytecode, to something that is natively compiled for this system for maximum performance, to something like RISC five or VASM or other types of virtual machines, different bytecodes. All of that will live together and will cooperate with different trade offs for different purposes. That is definitely where Zksync is heading and everyone is.
00:09:48.876 - 00:10:02.206, Speaker A: Yeah, yeah. Let's talk about the launch of the ZKe EVM. This was the second network ZK era. What was that like? And actually, when did it launch? Was it a year ago?
00:10:02.308 - 00:10:48.726, Speaker C: That was in February this year. It was very exciting. It was the first time that you could deploy EVM contracts with exact same invariants, exact same interfaces, same user experience on EZT roll up. So it was obviously very moment of high responsibility because we were thinking a lot about security, about different ways the system can break. We were putting a lot of precaution measures in there. And so it was a mix of this responsibility and alertness and actual excitement for going live. And we absolutely did not anticipate such a fast pace of onboarding users and capital and applications.
00:10:48.726 - 00:11:01.198, Speaker C: We thought it's going to be a lot smoother and a lot longer for people to gain trust in the system. Gradually, over time, things will start moving. But it was like a snowball. It was really, really fast.
00:11:01.284 - 00:11:27.262, Speaker A: I want to ask you, though, because I remember this was Lisbon 2021. Do you remember this? We, like, caught a cab to a dinner. We happened to be in the same place, and I got a chance to talk to you then about this launch and you had set like a date, you'd put a line in the sand in the future, and you're like, we will be launching there. And I remember it being very ambitious. What was that like behind the scenes?
00:11:27.426 - 00:12:16.882, Speaker C: We've set the dates a couple of times. We had to postpone it because you're building something completely new and you cannot be focusing on several different conflicting priorities all at the same time. For us, security was paramount. We knew we're not going to launch something that is not meeting the standards that we expected in terms of security and diligence and code quality. But the moment we solved all of these issues and we actually had a live testnet going on in a very stable way, with partners launching things working properly, we gained more and more confidence. And then we just put a line saying, like, specifically by this date we will feel that the system is bottle tested enough and mature enough to be launched.
00:12:16.946 - 00:12:17.414, Speaker A: Yeah.
00:12:17.532 - 00:12:32.790, Speaker C: And so it was a gradual improvement from that point. We were just very conservative. We really did not want to rush. So the final line we've said was actually from a point where we were very, very confident that the system is functional.
00:12:32.870 - 00:12:43.040, Speaker A: And maybe this is why I confused it a little. I think back then you might have said something like, it's coming sooner, like around November, and then I guess, is it possible that then you pushed it to.
00:12:43.410 - 00:13:03.106, Speaker C: No, no. I think the initial estimates for building Zikavm were, I think from the point where we started working on it, we thought it could be completed in one year. It took us closer to two years. And so within this time period, I think there were a couple of points where we had to postpone.
00:13:03.138 - 00:13:21.642, Speaker A: I see. It's very common to all projects. I feel like we do hear that often. That idea of predicting how long it's going to take. What do you think took longer? Was it because of needing to do more audits? Maybe. Can you point to any of the most complicated or challenging parts of building this?
00:13:21.776 - 00:13:57.862, Speaker C: I think it was just a combination of things. They cannot single out a specific one thing. You start building stuff and then you do it iteratively and you discover challenges on the way. You cannot just foresee all of them completely imaginary and saying, oh, here is the perfect system. All of the best world's products that are being shipped fast are being shipped in a cyclic way where you make an iteration, you build, you launch your mvp, you get the feedback, you see what works, what doesn't work, what you have not thought about. And then you work over and over with further iterations too.
00:13:57.996 - 00:14:11.550, Speaker A: In that time too, though. Did you change the ZK under the hood at all? Was there any sort of adaptivity on the ZK part? Or would you say like you already locked that in kind of the beginning of that two year process?
00:14:11.700 - 00:15:08.094, Speaker C: The primitives were locked. What changed were the circuits. We discovered more ways to make things more efficient, and so some of them were rewritten, but mostly it was just iterative work of building the complete body of all components required to make a complete ZKVM. But we now have a really good sense of all these components. It turned out that a lot of complexity was not in the ZK circuits itself, and people overemphasize the complexity of zero knowledge pool. Specifically, there is a lot of complexity in roll ups, in just the platform side of things, in your core node, in scaling the storage and scaling the transaction processing and scaling the APIs for querying transactions. So that required a lot of work.
00:15:08.094 - 00:15:56.174, Speaker C: And luckily we have a very, very talented team, and we made some right choices from the beginning, doing everything in rust and using best practices from engineering to make sure that we can eventually scale with the demand, not putting any artificial limits, where we say, oh, ten transactions per second is going to be enough, and then all of a sudden you hit this wall of ten transactions per second, and then what? Are you going to shut down your chain and invest time in making the system more scalable? That's not how you build in a sustainable way. You have to anticipate spikes in demand, you have to anticipate growth, and you have to put in a lot of buffer, actually orders of magnitude of buffer, in order to be able to accommodate unexpected black swans. And this is what the work was all about.
00:15:56.292 - 00:16:28.550, Speaker A: That's fascinating. I was just in prep for this. I was actually listening to our first interview together with Alex V, who is also on that. And I think you actually mentioned that thought. I think he said something along the lines of, like, plasma was built for this kind of capacity. With ZK roll ups, it will be a lower capacity, but these are the trade ups that are made. But what you're describing is like, as you went on, you realized actually those spikes of usage, you can't actually have a chain halt or not be able to use it.
00:16:28.550 - 00:16:46.414, Speaker A: It may not need to maintain that capacity all the time, but it has to be able to maintain that upper boundary. So this sounds like real learning, even from that episode, what exists today? Like, what is the ZK system in ZK era today? Because I know there's something coming, but I'm curious what it is right now.
00:16:46.532 - 00:17:07.126, Speaker C: As of today on Mainet, we use plonk with recursion. What we're switching to now is the proof system called boojam, or implementation called boojam. This is now live on Testnet, and we're making full switch on Mainet in a couple of weeks.
00:17:07.228 - 00:17:07.750, Speaker A: Oh, wow.
00:17:07.820 - 00:17:33.246, Speaker C: And boojam is the implementation of a construction we called redshift originally. Alex V published it together with Constantine and Aki very shortly after plonk was announced. It was an extension of plonk, which enabled fry to be used as polynomial commitments and essentially turning plonk into a.
00:17:33.268 - 00:17:57.738, Speaker A: Transparent proof system, which then, I mean, this idea was very influential in general because we've seen lots of systems since then go with that idea. We actually covered redshift on one of the episodes we did together as well. But I remember last time we spoke, you had actually talked about shelving it, and now it sounds like you brought it back in action. What did you need to do to redshift to get it into the state that it would be bojump?
00:17:57.854 - 00:18:29.546, Speaker C: So we postponed the redshift implementation back then because it was not very efficient with the primitives which were available at the time when redshift appeared. This has changed since then with a couple of breakthroughs. An important one came from the Plunkey two team. They came up with an idea to use a shorter field in a really cool way, which boosted the performance of the hashing. And also there were a couple of other insights. I'm not the right person to answer this question. You should talk to Alex fee.
00:18:29.546 - 00:18:47.886, Speaker C: But there was something with some research on better cached quotients and multivariate lookups from Ariel Gabison and a couple of other guys. Those things combined gave boojom the performance necessary to be able to be used in production.
00:18:47.998 - 00:18:54.022, Speaker A: And you mentioned that it's coming in a few weeks. What does it mean to change out the proving system?
00:18:54.076 - 00:18:54.706, Speaker C: This is what we're.
00:18:54.738 - 00:18:58.202, Speaker A: You're changing the full ZK proving system under the hood, right?
00:18:58.336 - 00:19:32.018, Speaker C: Yes, we're changing the proverb behind the roll up system, but it's actually relatively easy for us to do because the new prover just follows one to one, the block structure. So we are actually running it now in parallel for all the blocks that are being produced on the system that we proved with plonk. In parallel. We're also proving that with Pujan. And what we're going to do is we're going to just shift to the new prover and just drop the old one. So it's a very smooth transition in.
00:19:32.024 - 00:19:39.474, Speaker A: The case of a roll up and sort of making that change. Does the change just happen in a smart contract? Like do you just upgrade a smart contract?
00:19:39.522 - 00:20:29.762, Speaker C: Basically you essentially upgrade the verifier and you upgrade the proverb that produces the new proofs. So one thing to mention here is it was very important to keep the proof system agnostic. So what we did is we on purpose used shuttle 56 hash function for the Merkel trees in the storage, so that we can change the like we did not use Poseidon, that would be depending on the field. And whenever you change the field, whenever you change the proof system, you would have to rehash and do regenesis of the entire system, which would have to be a trusted operation. We do not want that. So we built the system from the beginning, slightly less efficient, but with more future proofness, if you want. And this is how we always approach things.
00:20:29.762 - 00:20:50.438, Speaker C: So this is why it's so easy for us to make this complete switch, and this is why it's going to be easy for us to switch in the future to any new innovation that might be coming in the world, definitely becoming in the years ahead of us, while preserving the system and keeping it intact. With all the value and all the contracts, all the state that is being.
00:20:50.464 - 00:21:03.406, Speaker A: Accumulated there, what does it actually do? What does the upgrade actually do? Does it make it faster? Does it make the proofs smaller? Is it cheaper? What's the actual benefit?
00:21:03.598 - 00:22:00.770, Speaker C: It's going to make the proofs more efficient, meaning for the end user that the proof generation is going to be cheaper and the overall throughput of the system is going to be higher. Although throughput is not really a constraint here, because your knowledge proof generation is really well parallelizable, you can go and add more and more machines. We are running GPU provers. We have optimized the boojam GPU prover to be consumer friendly, with the aim of future decentralization of the proving space. You only need under 16gb of ram and a decent gaming GPU to be able to generate the proofs for Bujal. And so eventually, yes, it boils down to the cost. So now this is interesting, because the cost is invisible, the cost of the proof generation, it's negligible compared to the cost of data availability.
00:22:00.770 - 00:22:30.938, Speaker C: This is going to change with the usage of validia or hybrid systems like volutions, like ZK Porter there it will make a big difference. Like today on Ethereum, the users are paying 1020 cents per transaction on average. So they don't really notice the cost because they're tiny and booja makes it. Orders are cheaper, so you will eventually be able to have very cheap transactions on validiums.
00:22:31.034 - 00:23:14.506, Speaker A: Interesting. You just sort of talked about the prover and the actual proof creation potentially being decentralized. This is a space that I've at least heard people talking about publicly for a few years. I know, like Mina and Alio have always talked about these snark marketplaces, like proving marketplaces somehow. I've heard of a few projects doing just that, where that's their entire business at the moment is like developing these marketplaces for proof generation. What's your vision for that? Do you eventually see other teams or some third party creating the proofs actually in Zksync like networks? Or would it need to come from.
00:23:14.528 - 00:23:48.854, Speaker C: Your so let's start with the basics. We see the decentralization of all aspects, all components of the system, as an absolute, non negotiable requirement. Remember, the mission of Zksync is to scale blockchains with preserving these core values, the core philosophy, the core valuable properties that we have there. These properties include decentralization. They include resilience. The only way to become resilient is to decentralize. Decentralization, paradoxically, is actually not a value itself.
00:23:48.854 - 00:24:32.158, Speaker C: It's a means to enable several important values. And it's a means to give your systems, your blockchain networks, credible neutrality. Like if all of the proof generation is happening on one cloud provider, or just on a few big cloud providers that completely control it, then they have this soft power of being able. They can just always threaten to switch off your proof generation, your system, and then your blockchain just shuts down. So you will be forced to follow whatever orders, whatever subtle requirements they impose on you. And we want to oppose that. We want to build truly resilient systems.
00:24:32.158 - 00:25:00.662, Speaker C: So you have to decentralize the sequencer, you have to decentralize the prover, and you have to decentralize also the development process and the community that watches over the system and stewards the development and points in which direction system should be developed further. And all of that brings us to the idea or the document called ZK Credo, which we also published this summer.
00:25:00.806 - 00:25:21.090, Speaker A: Yeah, I want to talk about ZK Credo, but right before that, I just want to ask you what your thoughts are on the decentralized sequencer space, or maybe even the shared sequencers as a major ZK rollup at this point. Do you see yourselves working with one of those shared sequencers, or do you imagine actually a decentralized sequencer on your side?
00:25:21.240 - 00:26:01.594, Speaker C: So, as I said, we definitely will have a decentralized sequencer in some form. We will have many chains as a part of the bigger Zksync ecosystem. We call them hyperchains. The priority for us in building the ZK stack that powers the hyperchains is the sovereignty of the chains, giving maximum freedom to all of these chains to decide their parameters, to decide their structure, configuration and so on. And this includes the sequencing. So they will be able to choose the same decentralized sequencing approach as Zksync era. They will be able to use centralized sequencing.
00:26:01.594 - 00:26:27.174, Speaker C: They will be able to use to opt in into shared sequencing schemes to go for other providers. There are a number of talented teams working on the shared sequencer design space. So I think we'll see a lot of experimentation, and we'll definitely see different chains pursuing different strategies. And it's not going to be one size fits all, it's going to be some variety, some different tradeoff space.
00:26:27.372 - 00:26:42.298, Speaker A: Makes sense. Let's talk about ZK credo. I actually found this. I wasn't sure what it was. I actually asked you before the interview, is this a mission statement? Is this a kind of guiding document? So, yeah, what is ZK Credo?
00:26:42.394 - 00:27:25.094, Speaker C: So ZK Credo is a statement. It is a statement about our mission, philosophy and values of ZK sync project. It's not bringing in something new. Those are the values. Whatever we articulated in the first draft of the Ziki credit, I don't think it's going to be the last draft. We have community discussing it, getting involved, and it will be an evolving process. But what we set out to do is to articulate those principles in a very specific way, which can serve as the basis of the formation of community, of ZK sync governance.
00:27:25.094 - 00:28:14.678, Speaker C: Because we're building systems that have to be credibly neutral. We are striving for using math instead of relying on humans, on validators, on some centralized authorities, or even on decentralized groups of people, because there will inevitably be some forms of politics, some slight decision making changes. So we want to make them as neutral, as transparent, as immutable as possible. And this actually works for blockchain systems? It doesn't really work well for evolving those blockchain systems. We are not yet at a point where the code can write of its own. These systems do not evolve by their own. We don't have yet artificial general intelligence.
00:28:14.678 - 00:29:00.700, Speaker C: They are being evolved and developed by people. And those people make subtle choices which might affect entire ecosystems, that might affect specific applications, they might affect specific groups of people. And so it's really, really important to have some guiding principles and a strong, decentralized community that enforces those principles. So I think of blockchains. I think we have a really nice analogy. In the real world, which is called charter cities, it's this idea that you can go and create a new territory where no one lives, and you just write new rules of the game. And then whoever likes those rules can join, move in and start living and working there and build something interesting.
00:29:00.700 - 00:29:35.266, Speaker C: And if you don't like them, you leave. And those rules can also define how the rules can be changed. And so this enables you to experiment to go and create a lot of different communities with these different approaches to different lifestyles, different values, different governance systems. And we see this in the world of blockchains. It's a little harder to do in l two world than in the l one world, because in l ones, you can easily fork a system. Always in l two s. The forkability is not really possible.
00:29:35.266 - 00:29:42.454, Speaker C: Like you can migrate, but you cannot really fork the assets. If you have some ether, it's locked in one contract, it's going to stay.
00:29:42.492 - 00:29:46.402, Speaker A: There unless the base chain is forked, which is a much bigger.
00:29:46.466 - 00:29:48.918, Speaker C: Unless the base chain is forked. But then everything is being forked.
00:29:48.934 - 00:29:49.450, Speaker A: Right.
00:29:49.600 - 00:31:09.300, Speaker C: But even layer one forkability has its limits. So ideally, we want to come up with a system which is having some minimum common ground, because blockchains are for universal coordination. So we're going to have a lot of wildly different people participating in those systems, and they don't have to agree on everything, right? We only have to agree on the consensus of the blockchain state that I own so much eth. You own so much if I send some transaction to you, it's objective. You can believe in completely different ideologies or economic systems or whatever, but we all agree on this objective consensus state. So we want to come together with this minimum form of governance that will enable us to move on to iterate on the system design into the future, while not scaring off some groups of these people or enabling them to fork away and have their lives if they want to. And so the ZK credo is this foundational, like if you want a declaration of independence or declaration of values for this digital community that will form around Ziki sync idea.
00:31:10.390 - 00:31:27.806, Speaker A: In this case, though, using the term fork kind of is confusing because you wouldn't actually be forking any particular l two or Zke EVM, you could create a new one, I guess is what you sort of mean, right? Like using the ZK stack framework. And you could create a new chain.
00:31:27.938 - 00:32:24.186, Speaker C: Correct. The word itself is a little ambiguous, but let's illustrate this. So we're starting off with a single deployment of zksync. Let's say Zksync error is the first hyperchain in this universe of interconnected hyperchains. We should talk about that separately. Now, if you like the rules of the system, you can just move in and participate. The rules are built in a way that give you sovereignty, like the validators, the proof generators, whatever stakeholders are in the system that are necessary for operation of the system, cannot mess with your assets, cannot change the rules, they cannot rewrite contracts, rewrite, state, or even prevent you from withdrawing your assets back to Ethereum or to some other l two.
00:32:24.186 - 00:33:08.210, Speaker C: Right. So the upgradability of the systems is going to be done in a way that is giving users a lot of time to withdraw if they don't like any new upgrade. But if an upgrade is coming that is changing the rules of the system in a way that you don't like, there must be a way for you to withdraw. You will probably not want to withdraw to layer one because the costs of using the layer one will become prohibitively expensive with time. So everyone will be living in l two cell freeze, some kind of scalability systems. That's Ethereum's vision of the future. So you will want to withdraw to a different L2.
00:33:08.210 - 00:33:46.174, Speaker C: And if you don't have any L2 that you see that is fulfilling the promise that you want, you can just take the code, fork the code, deploy an instance of this new L2, and then invite your fellow citizens of this network state, whoever we're using the first l two in the first place, to join you and say, look, there is new change that is coming. It's actually contradicting the values we stand for. It's our obligation to prevent that. So we should all just vote with our feet and migrate to this new fork.
00:33:46.222 - 00:34:00.762, Speaker A: Yeah. So it's not forking in the way that we've understood blockchains in the past, but it is still forking in a way. Right. Because would you be able to also maintain the state of what's like, the existing balances on that l two? If you did that?
00:34:00.816 - 00:34:03.258, Speaker C: Well, at the very least, you fork the code.
00:34:03.344 - 00:34:03.690, Speaker A: Yeah.
00:34:03.760 - 00:34:30.242, Speaker C: The forkability of the code is the very essence of open source movement. Everything we do for ZK sync is obviously full free open source for this very reason, in order to enable this forkability and then forking the state. Yeah, you cannot fork the state, but you can migrate. And it serves the same purpose. Kind of like you move away, you create your own version of this universe, which you like more, and you just walk there.
00:34:30.376 - 00:34:58.278, Speaker A: Let's actually dive into the ZK stack, the hyperchains, because I want to understand how these chains interface and interact with one another. When you talk about walking away, I want to understand a little more what that means. Or if you were to migrate. So, zkstack, you sort of mentioned it a few times. Is it the cosmos SDK equivalent? The op stack equivalent? This is the builder library that anyone can use to deploy another ZKe EVM Zk sync.
00:34:58.374 - 00:35:49.402, Speaker C: This is correct. I would call it a framework, which is a ready to use system complex of code that you can deploy and start your own hyperchain. We call it hyperchains for a specific reason. The difference of a hyperchain and some random roll up is that hyperchains are hyperlinkable. Okay, we're using a technology called the hyper bridges to connect hyperchains in a very interesting way, which enables what we call surprise, hyperscalability, the ability of the system to grow indefinitely large, accumulating or absorbing as many users, as many transactions as will be necessary for the growth of Ethereum. You want 1 million users, sure, you want 10 million users. You can do that.
00:35:49.402 - 00:36:28.678, Speaker C: You just keep adding blockchains, keep adding the systems, and it just grows. And hyper bridges are using the zero knowledge proofs and a specific architecture, which is a little hard to illustrate without video, but it enables you to move assets from any hyperchain to any other hyperchain without friction, like not adding security assumptions or trust assumptions, and not adding any capital cost, and doing all of that very fast, not adding any footprint on the underlying layers.
00:36:28.774 - 00:36:48.160, Speaker A: On Ethereum, for example, is it similar at all to some of the other ZK bridge kind of technologies, like having a very compressed light client on one side, basically communicating across these two hyperchains. Is it similar to anything maybe we've already heard about on the show?
00:36:49.010 - 00:37:30.706, Speaker C: This is similar, but it has a very, very big and important distinction. So let's try to illustrate it. Imagine that you have two systems, two roll ups on Ethereum for simplicity, and you want to move assets, you want to move native assets minted on Ethereum from one of this roll up to another. Let's call them roll up A and roll up B. Okay, so roll up a has, let's say 100 ETH locked into it. What does it mean? It means that there is a contract on layer one that governs the treasury of roll up a and it has a balance of 100 e. And there is a similar contract for roll up b, also on Ethereum, which does not have this balance.
00:37:30.838 - 00:37:31.774, Speaker A: Yeah, right.
00:37:31.892 - 00:38:24.094, Speaker C: So now if you want to use zero knowledge bridging to move these assets from roll up a to roller b, you first need some way to pass a message from roll up a to roller b in a trustless way. And you can use those ZK bridges to do this. What you do is you make some commitment in roll up a. This commitment is being propagated through Merkel trees down to Ethereum, and then it can be read by a roll up b. So all of that works. So one contract from one roll up can talk to some other contract on the other roll up completely, trustlessly. So that's all good and great, but how do we actually get the 100 eth to move from the treasury contract a to the treasury contract b? There's no way to do it.
00:38:24.094 - 00:39:10.006, Speaker C: You cannot just burn and mint it there because those are separate contracts. You have to move this ether on Ethereum itself. You cannot have the treasury contract of roller b. Go to Ethereum and tell Ethereum, mint me 100 e. Where from? Are you a minor? Yeah, you need to somehow, and this is a fundamental problem. So what you have to do in order to enable hyper bridging is you have to have all of these chains have a shared single contract on layer one that manages treasury of all of them in a single place. And then you can use this magic ZK bridging to pass arbitrary messages between system contracts.
00:39:10.006 - 00:39:38.042, Speaker C: And then the system contracts can trust each other because all of these hyperchains have to run the exact same circuits, at least for the system contracts. So some minimum viable shared state of the circuits, and then they can instruct the treasury to release certain amount of assets because it's coming from the system. So it's a consensus of all of this hyperchain that this actually happened, secured by math and cryptography.
00:39:38.126 - 00:39:55.958, Speaker A: I want to just clarify to see if I understand this, but so you have the two contracts that represent the two roll ups. That's the original case. In this new case, is there like a third contract that manages the treasury of everyone or is there a joint contract that manages both of those roll ups?
00:39:56.134 - 00:39:58.854, Speaker C: There is a joint contract that manages both roll ups.
00:39:58.902 - 00:39:59.210, Speaker A: Really?
00:39:59.280 - 00:39:59.706, Speaker C: Yes.
00:39:59.808 - 00:40:10.042, Speaker A: Okay. But do they also. So just to check though, does roll up a still have its own contract? Or is it just attached to this joint contract?
00:40:10.186 - 00:40:20.542, Speaker C: It can have its own contract for managing the state or maybe for some other activities, but all of the assets have to be in one shared contract.
00:40:20.686 - 00:40:28.022, Speaker A: Got it. I don't know how some of the other ecosystems have developed, but does the op stack do something like that too?
00:40:28.156 - 00:40:38.550, Speaker C: They do exactly the same thing. So we pioneered this with our hyperchain vision a year ago, and since then we saw the op stack and the Polygon CDK embracing the same approach.
00:40:38.630 - 00:40:39.082, Speaker A: I see.
00:40:39.136 - 00:41:09.186, Speaker C: So there will be a few of these big ecosystems that are perfectly seamless inside, like the Zksyncs hyperchains, the op super chain, something from Polygon, maybe something from others, that will be this big super networks of roll ups that are easily talkable to each other, but it's much more expensive and requires more time and cost and trust assumptions to talk between those different.
00:41:09.288 - 00:41:21.074, Speaker A: Yeah, interesting. I mean, there are a lot of bridge projects, like there's axilar and hyperlane, who are doing kind of that interfacing between these different ecosystems.
00:41:21.202 - 00:41:55.754, Speaker C: They will still remain, they will fulfill their role. They will be connecting these completely separate ecosystems. Like, you can think of these ecosystems as countries. You have a country, maybe on an island, then you have different cities in that country. Each city is a roll up, and you have a network of high speed railways that connects them. And you can move goods and people really fast inside, or maybe even you can think of one city, right. You can move things really seamlessly inside.
00:41:55.754 - 00:42:33.030, Speaker C: But if you want to go to a different continent, to a country overseas, you have to take a plane, and the plane is going to be necessarily more expensive, and it will take you longer to get there. So you're not going to be using planes, hopefully, just to get the dinner in someplace and then come back. Right. But you will be using it when you have to move, like once, while something big, but in planes are still important, we'll still have these big continents, countries connected via planes. And I see those bridge systems, more like this alternative for airports.
00:42:33.190 - 00:42:56.398, Speaker A: I'm trying to figure out what it is. In the case of the ZK sync universe, there's a lot of small roll ups all on Ethereum, but in this case, a lot of the value will just be moving in between these chains and not really touching the main chain. Even though, yes, the original funds might be locked and held in that smart contract. It's all kind of happening under the hood.
00:42:56.494 - 00:42:57.042, Speaker C: Exactly.
00:42:57.176 - 00:43:03.366, Speaker A: Is there a moment where actually you start minting native tokens on the l two that aren't on the l one.
00:43:03.468 - 00:43:05.746, Speaker C: Of course you will have a lot of native tokens.
00:43:05.858 - 00:43:21.206, Speaker A: Yeah. And then I have a question about like, so in that case then, are you just using the Ethereum blockchain as your data availability space? Because at that point you're not even using it for the financial, it's not holding the original funds or the original tokens.
00:43:21.318 - 00:44:10.726, Speaker C: Yes, all roll ups and validiums are going to be using Ethereum for a couple of functions. Number one is consensus on the state, so all of them will agree on what is the final state, what is the sequence of transactions that have been executed, and that's going to be final. Then you're going to be using Ethereum as the source of security, of the validity of your computations. All of the ZK systems are eventually verified by every single validator on the Ethereum network, by every single full node of the Ethereum network. So this is how you ensure that the math is actually correct. Someone needs to verify it, and it's going to be Ethereum. And in addition to that, roll ups are going to use Ethereum for data availability.
00:44:10.726 - 00:45:26.258, Speaker C: That's going to be the most censorship resistant source of data availability out there. You might have seen Vitalik's recent post about ltus, and he points out to this specifically, that for high value transactions, for high value interactions, for example, for your most valuable tokens, but also for things like your account, private keys, you will be using Ethereum. You want this data to be completely censorship resistant and unlousable. But then in addition to that, Ethereum's data availability bandwidth is going to remain limited, no matter how performant. Even if we get to full sharding, it's still going to have some limits, and we'll still need systems that can go without limits, and those systems will be validiums. You will be able to extend it. Some of the hyperchains will be using at least part of their state, stored or made available through some external data availability solutions, either managed by them or managed by external providers, or managed by decentralized systems like Celestia.
00:45:26.258 - 00:45:35.346, Speaker C: There will be some way for them to offload data off chain, growing indefinitely, absorbing arbitrary demand for Ethereum.
00:45:35.458 - 00:46:22.866, Speaker A: Wild, you sort of mentioned that these hyperchains can be any system, so you could have kind of like any language, it could be rust based system, it could be, I don't know, basically the app developers, if there's all these hyperchains with these different language requirements, they can actually deploy in native languages on these hyperchains, not always using solidity and sort of that EVM basis. That's correct. Right. These hyperchains could be anything. I kind of want to bring the conversation a little bit back to languages to ask you about a language that was created by matterlabs a long while ago called zinc. Right. Is that ever going to make a reappearance, do you think? That was also something around the time of redshift? You were doing redshift and you were doing zinc.
00:46:22.866 - 00:46:29.930, Speaker A: Yeah. I'm just curious if you see any further development on that, and if you could imagine a hyperchain that actually uses it. Potentially.
00:46:30.430 - 00:47:04.114, Speaker C: No, we abandoned zinc. It's not going to be developed further. It lost its justification. The original reason we were creating zinc was that we needed a language for non Turing complete computation. And since we now can do full Turing complete stuff with Zkavm, with RiSC or WASM or other virtual machines, why would you use something rust? Like, if you can just use rust with all the tooling of rust? It just doesn't make any sense.
00:47:04.312 - 00:47:12.162, Speaker A: Do you imagine, though, maybe like Matterlabs itself, deploying a hyperchain with a different base language ourselves?
00:47:12.226 - 00:48:15.642, Speaker C: We're focusing on the core protocol, but I think that some hyperchains could be launching with languages that are better suited for smart contracts. I can think of move, for example, the development from Facebook libre deem that was a language that was inspired by Rust, but was actually optimized for making smart contracts more secure and easier to develop. If that takes off, I can totally imagine a hyperchain using move or something else entirely. Sure, like existing languages such as Rust were created for specific purposes, like system programming, making sure that you have safe memory space, using it for parallelism, and so on. All of that does not really matter in the world of smart contracts. You want different elements of the language to support your development, to make it more expressive. So I can totally imagine that in the future we'll see that coming.
00:48:15.776 - 00:48:30.682, Speaker A: Interesting. I know you sort of mentioned that when you launched the Zkevm February 2023, that you were surprised at how quickly it was adopted. Do you have any theories as to why you did see so much adoption?
00:48:30.746 - 00:49:20.894, Speaker C: Now, looking back, we still have not just a lot of adoption. We are the most actively used l two on Ethereum today. If you go to l twobid info, just switch to activity. So we're number four by TVL, but we are consistently number one by far. With 24 million average monthly transactions. Ethereum stands at 30 million, and all the other chains are starting with like 16 14 million and below. So there is a lot of growth happening also in terms of protocols adopting ZK sync and building new stuff and completely entirely new stuff that was not done before, going in the direction also of native account abstraction, which we haven't covered yet.
00:49:20.894 - 00:50:32.774, Speaker C: But it's an important aspect of making blockchains usable by mainstream audience. And we see a lot of projects that are expanding in this mainstream audience space. So we see things like Paji penguins launching their NFT campaigns with Walmart corporations where millions of users will be able to just scan a QR code and get their nfts and connect the physical world with the virtual space. With the metaverse. We see projects like the city government of Buenos Aires, Argentina is using Zksync for the ID system for the citizens, where they will be using blockchain to connect to goods and services and providers. We're seeing hyperchains being used for interesting mainstream audience bases. So I think what contributed to this popularity of Ziki sync is, on the one hand, this focus on technological innovation being future proof, building systems for the future, like not focusing so much on being backwards compatible, but focusing on being future compatible and building for the end consumer in mind.
00:50:32.774 - 00:51:14.738, Speaker C: And on the other hand, just this consistency with the mission, with the values. Like people know that they can rely on us, people know that when we say decentralization, we actually mean it. It's not a project that was created just to pump and dump, promote some idea and burn it in one year. We are here for a very long future. We are really well funded. We as Matterlabs, we will be able to build everything we need for the final vision to make this reality of anyone in the world can access Ethereum in an affordable way, fully preserving the properties of Ethereum. And all of that is owned by the community.
00:51:14.738 - 00:51:28.360, Speaker C: All this network governance, the direction in which it's going, it's all controlled not by a single party, by the broad community. So we've been very consistent with this messaging and I think it also contributed to where we are today.
00:51:29.210 - 00:51:48.794, Speaker A: Do you think there is a moat? This is something I've sort of been curious about with a lot of the l two projects. What do you think will keep people on Zksync? Because if it's EVM compatible, they can deploy elsewhere, right? They can do it on optimism. They could do it on the new Zke evms that are coming out. Yeah. What's the moat?
00:51:48.922 - 00:52:22.086, Speaker C: First of all, I don't care that much about the moat. I care about the mission. And we have a very specific criteria of where the mission is. Complete and what we need to do for this mission. If you ask me what I think the development is going to be on Ethereum in terms of how things will play out, I think that you will see network effects accruing to this big hyperchain, super chain ecosystems. And that is going to be what matters. They will not be bound to individual chains, but to this big ecosystem.
00:52:22.086 - 00:53:02.658, Speaker C: But I mean, individual chains also have their network effects, obviously for instant composability with synchronous transactions and so on. But this access to users and liquidity from one hyperchain to all the other hyperchains at just one click, without any capital or trust or security friction is what's going to matter. So you will be measuring not just the TVL or transactions or users, active daily users, all the parameters by which we shine at Ziki Sincara today, you will not be measuring that on individual chains, but in these chain ecosystems.
00:53:02.754 - 00:53:29.658, Speaker A: That's cool. What's your vision then for the future of this space? One of the big questions, and I kind of hinted at it before, but it was this idea of like, if you have the native assets on the block, on the l two s themselves in your vision of the future, is Ethereum still at the center? Or does it look more like a mesh or a net where more interconnection and actually value has shifted a little bit further up the l two stack?
00:53:29.754 - 00:54:03.846, Speaker C: Ethereum is definitely going to be at the center as the backbone connecting all the l two s. I believe that the Internet of value, the eventual form of the web3, that embraces all forms of value transactions in the world, will be in Ethereum. L two s, l three s. Okay. It will be in these networks. I don't think they're going to be far outside of Ethereum. You will have a couple of projects outside of Ethereum, a couple of blockchains still doing some things and being used for different purposes.
00:54:03.846 - 00:54:25.690, Speaker C: But I believe that the bulk of this world value transactions will be happening on Ethereum networks, not on layer one itself, as it is Ethereum's vision to use layer one as the fundament, the connection layer. It's not where the actual end user transactions will happen, except for maybe like some super, super high value transactions.
00:54:25.770 - 00:54:47.078, Speaker A: Yeah. In the ZK credo, there is one term which is privacy, and it's something when we first met, we talked a lot about. And then I know that there was more of a focus on scaling. Do you see privacy kind of coming back for ZKsync? Maybe it's always been there and sorry if I but at least in the messaging, it hasn't been as much of a focus.
00:54:47.244 - 00:55:25.890, Speaker C: Sure, it's not been at the forefront, but it's always been there. If you read the same introductory post about DK sync five years ago, one of the key points there is privacy. Because you can't be using blockchains as Twitter for your bank account. You cannot be having transactions where everyone in the world can see all the assets you have and all the people you interact with. In order to enter mainstream adoption, you have to implement privacy. The reason we've not been focused on privacy is two things. One, scalability is a prerequisite for privacy.
00:55:25.890 - 00:56:20.338, Speaker C: Specifically, the way Zksync and ZK stack is architected is going to make privacy preserving transactions recursive. Zero knowledge proof verification on these chains super cheap. Because we will not need to use data availability from Ethereum even on roll ups, to verify zero knowledge proofs. It's all going to be embedded. You will be just paying a fraction of a cent for this verification, and this paves the path for privacy preserving applications. But the second reason is that we are as an organization, as Matterlabs is one of the contributors to the ZK stack, and there are now more, and there will be more and more and more organizations, individuals who are contributing to this open source code base of Zkstack. We are embracing Ethereum's philosophy of subtraction.
00:56:20.338 - 00:56:54.426, Speaker C: We don't want to become an empire like Google or Facebook or whatnot, with thousands of employees doing all kinds of different things. We want to focus on one problem, which is the scalability, and do it really, really well. Okay, so what we're building is this Internet protocol for this Internet of chains. The rest should be done by other people. We don't want to be building wallets. We don't want to be building privacy extensions. We don't want to be building individual dapps, any kind of defi nfts, whatever on top of Ziki sync.
00:56:54.426 - 00:56:58.018, Speaker C: That is all for others to be built and we want to support them.
00:56:58.104 - 00:57:13.590, Speaker A: Okay, so it's in the credo more as like guidance, but not as something that you're building currently. Like you're not going to build the privacy modules or the privacy hyperchains, but someone else could build, I guess, a potentially private hyperchain.
00:57:14.010 - 00:58:02.470, Speaker C: I don't see it coming for now, unless no one really builds it for a long period of time, in which case we will have to intervene. So eventually I want to see all the points from ZK Credo being built like actually life being used by millions of people. That is success for us. I believe that other people will do it. But if no one builds, I don't know, like a fantastic wallet or a point of sale system or something else, we will have to help this happen. Maybe not in a way that labs builds it, maybe in a way that Dicky sync ecosystem supports some teams with grants and funds the development and just helps these systems to be created. But eventually all of that is going to be built.
00:58:02.470 - 00:58:03.926, Speaker C: I can promise you this.
00:58:04.028 - 00:58:24.686, Speaker A: That's cool. Are you also paying attention to some of the kind of coprocessor or like this other way that chains and off chain computation is happening? Not really the traditional l two s, and I'm curious if you'll be interacting with any of that.
00:58:24.868 - 00:58:55.880, Speaker C: Sure. I think eventually we will see the coprocessing being natively, seamlessly integrated into blockchain systems. So you will be able to just make a call to a smart contract and then execute arbitrary complex function on some public data set, plugging in external oracles that will provide access to this data and relying on some networks to the coprocessing. That is going to be very easy from the programmability point of view.
00:58:56.330 - 00:59:07.900, Speaker A: Can you imagine building something like that within the ZK stack? Or would you imagine that living somewhere else, being kind of the third party groups that are putting it together?
00:59:08.670 - 00:59:55.126, Speaker C: For now we're focusing on making ZK stack come to life with all the promises of ZK stack with hyperscalability, connection between the hyperchains, with hyperbridges, data availability, different data availability modes like validium, ZK Porter, all of that has to work in a very smooth way and with fantastic user experience. All the extensions, like adding rust programs, coprocessing, whatever, that is not in the primary focus. The primary focus is to make the foundation work. Meanwhile, as we're approaching the completion of the foundation, we'll probably have a lot of projects working on those things, and we'll be happy to support them and integrate.
00:59:55.238 - 01:00:10.590, Speaker A: Cool. Is there actually a foundation for Zksync? Like who gives the grants? Is it a treasury that's part of the governance of the actual network, or is it some sort of existing organization?
01:00:11.170 - 01:00:38.198, Speaker C: It must be rooted in the governance system of the chain, if you want. Okay, so obviously as long as metalabs is a centralized organization, it's just a private company. So we can give grants at our own discretion to whoever we want. And we are supporting some teams and we're doing some partnerships to accelerate the development. But I think you're asking about this.
01:00:38.284 - 01:01:04.270, Speaker A: Network community governance, like exactly. Following that question on privacy, I don't really imagine matter going and funding a privacy project given that it's not in the exact sort of, like you just said, in the exact space that you're working. But yeah. Is there going to be some larger treasury pool or something that the community can actually make decisions on what gets funded?
01:01:04.430 - 01:01:37.946, Speaker C: Yeah, I think that every big protocol has to come up with some form of governance that can also be sustainable financially over a long period of time. And this is a big challenge that we see a lot of experiments, but we don't see final system that is perfect yet. No one has come up with anything that I believe is yet sustainable. So this is a big research challenge that we're still in.
01:01:38.048 - 01:01:53.438, Speaker A: Interesting. Alex, thank you so much for coming on the show and sharing with us all of the updates on ZK sync. I feel like this was a very overdue episode. Hopefully it won't take another two years for us to get on one of these again.
01:01:53.604 - 01:01:58.078, Speaker C: Thank you, Anna. I really enjoyed the questions and it's always fun to be here.
01:01:58.244 - 01:02:06.530, Speaker A: Thanks. I want to say thank you to the podcast team, Henrik, Jonas, Rachel and Tanya, and to our listeners. Thanks for listening.

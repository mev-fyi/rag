00:00:05.450 - 00:01:00.858, Speaker A: Welcome to Zero Knowledge. I'm your host Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online. This week I catch up with Jordy Byline and David Schwartz from Hermes to talk about Zke EVM. They share an update about Hermes since their launch on Mainet earlier this year. We talk about the l two landscape ZK rollups and how different teams are approaching EVM compatibility on their respective chains. We then dig into ZK EVM, a model where they are using zero knowledge proofs throughout the architecture to give it the characteristics of a rollup that is cheap and fast, while still allowing for this EVM to run and compile in the same way as the Ethereum EVM.
00:01:00.858 - 00:01:37.114, Speaker A: And this episode was also recorded just days before the team made a massive announcement about the Polygon Hermes merger. So do stick around. To the end of the episode, we recorded a little bonus bit about this and what this would mean for the zero knowledge ecosystem. Quick note before we start, if you haven't already seen it, the Zero Knowledge podcast website was recently updated. There's all sorts of new ways to engage. You can check out the blog, you can actually post on the community forum, get in touch with us, sign up for newsletters, check out the YouTube videos. They're all there and I'm really excited that it's kind of come together in one place.
00:01:37.114 - 00:02:02.722, Speaker A: Do check out the new jobs board as well. You can actually post your jobs there yourself now as a hiring team. And if you're someone looking for a job, there's much better ways to kind of sort and filter now. So yeah, hope to see you over there. One more point before we start in on this episode, I want to thank this week's sponsor, Mina Protocol. Mina is the world's lightest blockchain powered by participants. It's a layer one protocol working to connect crypto to the real world.
00:02:02.722 - 00:02:40.106, Speaker A: This means developers can leverage private, verified real world data from any website to build decentralized apps. Mina's decentralized apps, which are called snaps, also allow users to access onchain services without sacrificing personal data privacy. And Mina is a unique blockchain. It's replaced the traditional blockchain with a zero knowledge proof, ensuring a super light chain that stays around 22 allows every participant to act as a full node. Mina's main net has been live for a few months and the ecosystem is growing fast. So join the community and find out more by visiting minaprotocol.com. Quick side note.
00:02:40.106 - 00:02:59.906, Speaker A: I am both an advisor to the project. And a validator with the ZK validator. So that's also another reason why you should go check it out. So thank you again, Mina, for sponsoring the show. Now, here is my interview about Zke EvM with Jordy and David. Today. I'm here with Jordy by Lina and David Schwartz.
00:02:59.906 - 00:03:02.614, Speaker A: From Hermes and Iden three. Hi, guys.
00:03:02.732 - 00:03:03.110, Speaker B: Hi.
00:03:03.180 - 00:03:04.866, Speaker C: Hello, Jordy.
00:03:04.898 - 00:03:23.610, Speaker A: You were on the show pretty recently, actually. You came on to talk to us about Hermes. But today's episode, what we want to do. Is actually dig into Zke EvM. Something that a lot of us learned about only at EFCC about a month ago. So, yeah, I'm really excited to learn more about this. David, this is the first time we're meeting.
00:03:23.610 - 00:03:27.898, Speaker A: Maybe you could quickly introduce yourself. And tell us what you're working on at Hermes.
00:03:27.994 - 00:03:43.090, Speaker B: Sure. Thanks. Well, my role at Hermes is the project lead. I'm trying to push the project forward. And to coordinate the activities. And also working very hard. On the product side of the technology we are developing.
00:03:43.090 - 00:03:50.038, Speaker B: So, yeah, this is an amazing moment. Especially for Hermes. And probably we can discuss a little more today.
00:03:50.124 - 00:03:50.518, Speaker A: Yeah.
00:03:50.604 - 00:03:52.422, Speaker B: But, yeah, amazing time. Yeah.
00:03:52.556 - 00:04:03.802, Speaker A: I mean, we did do an entire episode on Hermes. And so I will link to that in the show notes. Hermes, an l two. That is, as far as I understand, it's live, right? It's been live for some time?
00:04:03.936 - 00:04:16.318, Speaker C: Absolutely. It's in production right now. It's forging a block every ten minutes. And many transactions. And it's service that anybody can use it there.
00:04:16.484 - 00:04:30.980, Speaker A: Maybe. Before we dig into the ZKe EVM. The kind of topic of this show. I do want to hear what's new. I think our interview is, like, back in January. So this was before the launch. I'd love to hear what's happened since then.
00:04:30.980 - 00:04:39.462, Speaker A: And maybe what's potentially coming up. I don't know how much you can divulge, but yes.
00:04:39.516 - 00:04:41.640, Speaker C: Well, David, maybe you can answer.
00:04:42.890 - 00:05:06.746, Speaker B: Yeah, from the last interview, I was not there. But I guess you were discussing about the launch of the Hermes network. At this point, we were launching the first release of the Hermes. Where we were focused basically on payments. And, yeah, we became live. We are on Mainnet. We started the initial steps towards network stability.
00:05:06.746 - 00:05:35.094, Speaker B: And we started then to do some promotions of the network. To launch some activities. In order to test that the system was stable, was secure. And from here, we have been building the next steps. Or working behind the scenes. To launch the next features. We also shared the public roadmap a couple of months ago where we just announced the whole activities and features for the whole next year.
00:05:35.094 - 00:06:10.274, Speaker B: And yes, this is basically what we have been doing. We went to Paris at CC Jordy, introduced the CKBM at this point because we want to share with the community the work we are doing in order to just to get contributors or just provide new ideas and also get new ideas from the community. And at this point we are very focused on this project of the CKBM. On the other hand, we continue developing the product features for the first version based on crypto payments. So this is the current situation maybe.
00:06:10.312 - 00:06:19.362, Speaker A: We should define, even though we do have an entire episode on Hermes. Maybe you can tell us a little bit about what makes Hermes unique in the l two landscape.
00:06:19.506 - 00:06:52.126, Speaker C: Well, Hermes is decentralized. And the protocol of Hermes is designed to be decentralized. That means that the coordinator of a roll up, anybody can be a coordinator. It's true that right now it's not worthy to be a coordinator because there are not so many transactions there. And being a coordinator is a little bit expensive. But once we reach this breakeven, which is in the case of Hermes, is the lowest breakeven. So right now, the Hermes is the roll up that has most cheap transactions in cost terms.
00:06:52.126 - 00:07:16.242, Speaker C: So we are very close to get this breakeven. Then new coordinators will become. We will start to bidding for slots and start forging batches. And this will give the decentralization all. The protocol is designed to be fully decentralized. And this is quite unique. I would say that this is mainly the two big differences.
00:07:16.242 - 00:07:36.654, Speaker C: A protocol that is decentralized by design. It's governance less. The idea is that at some point there is no governance. It's just a product that's working there. And the cost of the verification, the cost of batching batch is the lowest in the space right now.
00:07:36.772 - 00:07:47.534, Speaker A: Would you say privacy? It doesn't sound like it's one of your current unique propositions. But is that something that you do see as part of the roadmap?
00:07:47.662 - 00:08:04.098, Speaker C: It is. But right now we are more focused in the ZKVM. So. ZKVM. Zkvm. In some way it includes privacy, because you can do whatever you. So here we are more focusing the ZKVM.
00:08:04.098 - 00:08:07.798, Speaker C: Let's say that with private payments in some way.
00:08:07.884 - 00:08:20.482, Speaker A: Got it. So when we talk about this EVM and like EVM compatibility, ZKE, EVM. In the current l two landscape, are there any l two s that are already like EVM compatible.
00:08:20.566 - 00:08:52.726, Speaker C: Would you say there are projects that's working in EVM compatible? And here again we are talking about two big groups. One is optimistic groups. For them I would say that the EVM part is easy. They have the problem of this challenge game that they have behind. But including the ABM is a challenge. But it's not such a big challenge as is for the ZKBM. And in this I know that, for example, optimistic is working on this way.
00:08:52.726 - 00:09:32.046, Speaker C: And there are other optimistic projects that are working in that direction. In the ZK site there are different projects that some way or the other is working on that ZK. Sigmatter labs for sure, Star wars is working also in that direction. I know that bluebring is also starting to do something in that direction, or at least thinking on that. Of course, aztec people, they are also doing a great job in that direction. Even the theorem foundation is working maybe more in the research side, but it's also working in that direction because it's important. At the end we are talking about scaling smart contracts.
00:09:32.046 - 00:09:45.266, Speaker C: So this is an important piece. And there are many groups and many people that some way or the other, maybe with different approaches, with different things, but they are working in this path.
00:09:45.378 - 00:09:50.714, Speaker A: Got it. Where do you want to start to explain what Zke EVM really means right now?
00:09:50.832 - 00:10:20.414, Speaker C: In the current Hermes that's in production right now, you can do payments, you can do transfers. It's like a little bit like bitcoin. You can do just transfers in there with ZKVM, actually you can run the smart contracts. Data is having a roll up exactly the same as roll up. But instead of doing a payment, you can deploy a smart contract and execute a transaction in a smart contract. And this is the big difference. It's a roll up that's executing smart contracts.
00:10:20.414 - 00:10:49.158, Speaker C: That's mainly what it is. And in the case of ZkEvM, just to be clear, it's Zkedm. It's zero knowledge Ethereum virtual machine. So the Ethereum virtual machine, the EVM is actually the virtual machine that's running in Ethereum. Smart contracts are executed in this vm. And ZKVM is just having a roll up that's executing exactly the same smart contracts that are currently running in Ethereum. That's what means ZKVM.
00:10:49.334 - 00:11:07.166, Speaker A: I watched actually that presentation that you gave at ECC and in it you talked a lot about opcodes, opcodes that would normally be in, I guess, running on the EVM. I don't know if that's how you say it. But what do you mean when you use that term opcodes? What do those look like? Or maybe what are some examples?
00:11:07.278 - 00:11:48.602, Speaker C: Yeah, opcode is instructions. So when you do a smart contract in solidity, this is compiled, this is compiled to a machine language. This machine language is assembly, if you want. This machine language is composed of executing different opcodes that is executing. And these are the instructions that the final instructions that actually is running vm. These instructions include for example doing an addition, pushing a value to the stack, setting a value to memory, recovering a value from the storage. These are these very small instructions that virtual machine is processing every time you execute a smart contract.
00:11:48.602 - 00:12:13.014, Speaker C: So the idea of the compatibility when we are talking about compatible means that we are able to get this compiled program with all these instructions, with all these opcodes and you just can take it and run it in ZKVM without transpiling or without doing anything. It's just fully compatibility in this time.
00:12:13.132 - 00:12:26.438, Speaker A: On the developer side I'm guessing they could use the same tooling. But on that compiling part is it actually compiling into something different or is it actually following the same thing that you'd see on an EVM?
00:12:26.534 - 00:13:10.310, Speaker C: This is the difference on the approaches when you are doing opcode compatible, actually you can use exactly the same compiler and you get the result. And instead of it's like having a side chain, but in the case it's a roller. But you just take this transaction, you just run it and you don't need to do anything else, just get this code. This is a smart contract, you deploy, you use the same tooling, no other stuff. There are other approaches, they change the compiler. So instead of compiling to these EVM opcodes we are compiling to another set that are more, maybe more ZK optimal opcodes. And you're just executing this different virtual machine that's not compatible.
00:13:10.310 - 00:13:19.590, Speaker C: But maybe the solidity program, you can compile it into different machines. These are the two approaches.
00:13:19.750 - 00:13:34.414, Speaker A: Got it. So what you're saying is from the developer side they would still be potentially just writing a solidity contract deploying it. But what's happening under the hood with Zke EVM, it's actually following the same path that it would on the original EVM.
00:13:34.462 - 00:13:49.106, Speaker C: Yeah, for at least very similar. You don't need a different compiler, you don't need a different tool set, you don't need to care about special things, just do the same. Just having like a side chain. Side chain is rollout.
00:13:49.218 - 00:14:38.434, Speaker B: We are bringing the opcode concept to the table because when you go into the details on what a CKVM implementation means. You need to go into this level of details to go down and say, look, implementation of this EVM means that we need to be compatible for the same set of operational codes that this virtual machine supports. So the challenge is to analyze every single code that ethereum virtual machine supports and figure out how to implement that. Jodie was saying the same. I mean, we have two options. We can just build a new virtual machine with a different setup of codes and compile solidity programs into this virtual machine. Or we can figure out how to build from bottom to top code and a system that is the same set of codes under the Ethereum virtual machine.
00:14:38.434 - 00:14:52.310, Speaker B: So you can be able to port existing solidity or existing smart contracts code directly to this new system. So this is why we are bringing this opcode to the set and discussion to the table.
00:14:52.390 - 00:15:03.806, Speaker A: Would that mean like you kind of talked about each opcode, but are you forced to go into each particular opcode and re implement it? Or is it more like a general reimplementation that's happening?
00:15:03.908 - 00:15:23.054, Speaker C: No, it's very detailed. You have to go each one and try to keep the compatibility as much as you can there. It's not a general thing. It's opcode by opcode and structure by structure, and trying to be as close as possible to the current Ethereum machine.
00:15:23.182 - 00:15:25.298, Speaker A: How many opcodes are there?
00:15:25.384 - 00:15:32.614, Speaker C: Actually, I need to check it, but roughly it's about maybe, I don't know, 50. I need to check.
00:15:32.652 - 00:15:35.542, Speaker A: Okay, I was thinking you were going to say something like thousand.
00:15:35.596 - 00:15:35.958, Speaker C: No.
00:15:36.044 - 00:15:37.880, Speaker A: Okay, it's like 50 under.
00:15:39.930 - 00:15:58.938, Speaker C: A lot of them are like repeating ones. For example, if I push one byte, push two bytes, push three bytes, push four bytes. Okay, these are 32 opcodes, but actually the same. But it's like around 50, maybe 70 altogether, but so just these few tens of codes.
00:15:59.034 - 00:16:16.050, Speaker A: I want to hear a little bit about the ZK part of this. So what you've described is sort of like the rebuilding of an EVM from the opcodes individually, kind of rebuilding them. But where does the zero knowledge come in? Because when you're saying you'rebuilding it, it sounds like that's maybe what you have to incorporate somewhere.
00:16:16.470 - 00:16:52.590, Speaker C: Well, at the end it's like roll ups. You have a set of transactions that execute smart contracts, like Ethereum transactions, but necessary transactions. And you are aggregating and you are processing all of them transactions. And at the end computing a proof that all these transactions are well computed. And this is where the zero knowledge comes. The thing is that verifying that a payment is valid is quite easy. Verifying that a transaction that needs to be executed with all these opcodes and memory and all that stuff is valid is much harder.
00:16:52.590 - 00:17:40.654, Speaker C: But at the end the idea is exactly the same, that standard roll up, you need to verify that a set of transactions. So you go from state a to a state b when you execute these 100 transactions. So you need the proof that state B is correct without having to compute everything and you verify that. So the idea is exactly the same that a normal wall up here, probably the word zero knowledge is not the right one. It's more the verification of a computation. Actually zero knowledge, it goes very close because this succeed verification is a property that share and we are sharing. It's the same technology in some way, but they are used for very different things.
00:17:40.654 - 00:18:03.554, Speaker C: Zero knowledge is to hide some inputs or to have some kind of privacy in general. And the other part of this zero knowledge technology is more for succeeding computation or for verifying computations in a succeed manner and in a roll up. In the case of the roll ups we are using very much the second property. It's the most important for roll ups.
00:18:03.682 - 00:18:11.062, Speaker A: This is the like going back to that optimistic versus ek roll up. It's like the fraud proofs versus the validity proofs I guess you could call it exactly.
00:18:11.196 - 00:18:21.946, Speaker C: The validity proofs is what we are building here. We're building a validity proof that a set of transactions, creating smart contracts or executing smart contracts are valid. This is actually what we are doing.
00:18:22.048 - 00:18:51.800, Speaker A: So the Xeronov proof in this case is not a privacy proof. You can actually see both sides of this action. I guess the question here is does all of the EVM in the ZKe EVM, does all of the action just sort of happen within a bubble and then every once in a while with a zero knowledge proof get re kind of checked to the main chain or is it like each transaction or each change? I'm just sort of curious, at what point are these zero knowledge proofs actually being used?
00:18:53.290 - 00:19:11.618, Speaker C: In the case of the way that we are building the CKVN? Actually we are embedding like two proofs, two proof systems in there. So mainly we are generating a stark and then we are verifying a stark with plonk or grove 16. So we are like a proof of approve.
00:19:11.654 - 00:19:12.302, Speaker A: Okay, wow.
00:19:12.356 - 00:20:02.862, Speaker C: And the idea is that we are combining two proof systems to get the best of each one. So starks are very good, but they have a problem that the proof size is huge. Well you can verify it on chain but it's very expensive. So what we are doing is we are building like a growth 16 or plunk proof that actually verifies the stark, because the stark proof just become a private input of the next. The size of the stark doesn't matter anymore. And we can use all the advantages of the stark and get also all the advantages of gross 16 and plum, which is a very cheap verification on time and very small size proof. So combining these two things is very good for this.
00:20:02.862 - 00:20:42.970, Speaker C: And actually, stars, they have. Another important advantage is that the verifier. It's quite easy to build a verifier in growth 16 circuit, because the verifier of a stark is just using just a single field element, sort of a single field. So if you are using the same field as the growth 16, then the verifier is very cheap and very easy. So the growth 16 is going to be proof, but the number of constraints is going to be quite small in compared with real Proof. That's going to be in the Starks some way. So it's just we're combining these two technologies.
00:20:42.970 - 00:20:55.642, Speaker C: We're combining plonk, we're combining block app, we're combining a start. We're combining row 16, we're putting everything together, and we are building the CKVM. That's very much the challenge that we have in France.
00:20:55.786 - 00:21:22.466, Speaker A: So is it sort of like the first proof would be a stark, which ends up resulting in a very large proof, but before you're actually like this, all remains within the ZkevM, still in that sort of space. But then, because you have this large proof, are you then using plonk almost as like a compression to then prove that large proof? You use plonk to create a small proof, and that's what you have to verify. And that is why it's cheap.
00:21:22.578 - 00:21:26.598, Speaker C: Exactly. Perfect. You get it, you explain it. Perfect.
00:21:26.764 - 00:21:41.454, Speaker A: Cool. Okay. But the one part I still don't understand, though, is like, where are the Starks starting? Every time anything occurs? Is there a stark attached to it? I'm just kind of curious, where did those come from? Where are they living in this process?
00:21:41.652 - 00:22:10.962, Speaker C: I'm not sure if I'm using here the word stark correctly, but the idea is that we are using the fry proof, like the engine of Starks, to verify polynomial commitments. Altogether, this is what we call it, the stark. Probably it's not a stark. This is another thing, but we are using the same technology as Starks. This pride to verify all the polynomial commitments. All these polynomial. We have a lot of polynomial relationships.
00:22:10.962 - 00:22:46.146, Speaker C: BBM has hundreds of polynomials relationships because BBM is complex. Okay, but all these proofs are together with the Starks. All this proof is verified inside a gross 16 circuit or gross 16 or plunk circuit if it's more or less the same, depending if you want trusted set up or not. Plonk is a little bit more expensive, but don't have trusted set up. 16 is cheaper, but it requires the trusted setup ceremony. So we probably will start with plonk. And maybe at some point, if this goes, maybe we do a grow 16 just with a ceremony and so on, just to stabilize that.
00:22:46.146 - 00:23:06.450, Speaker C: But that's the long term. But the circuit is the same, or it's very easy. So you can reduce the circuit in growth 16 and plunk. Actually, for example, in snark js, we updated the snark js some months ago. That supports. Right now it supports gross 16 and plunk with the same. With circum.
00:23:06.450 - 00:23:23.490, Speaker C: So all the programs brightened in circum can be now verified. You can convert it to a gross 16 proof system or to a plunge system. So everything is more the same. Thorx is friar. It's like a different world. It's a little bit different altogether.
00:23:23.670 - 00:23:47.554, Speaker A: I think the question that I still have, though, is kind of going back to just like the opcodes. You sort of mentioned the polynomial commitments. But is it like, on the execution of an opcode? And I might be mixing up some things here, by the way. It might be like, state transition is actually what I'm trying to say. It's like, you're going to be using fry. You're going to be basically generating one of these proofs. At some point in the process.
00:23:47.554 - 00:24:05.260, Speaker A: And I'm not clear. Is it on an execution of something like, is it when there's been a state change that you would prepare one of these things? Or is it like, after a batch of activity like activities have basically happened. And then you just sort of clump it together into a polynomial? And then.
00:24:06.590 - 00:24:22.522, Speaker C: Let me try to explain a little bit. It's a little bit more complex than that. But just to be. We have different opcodes. So the idea is to have. We have many state machines that execute opcodes. We have, for example, a state machine that executes modular multiplications.
00:24:22.522 - 00:24:55.706, Speaker C: Another state machines that's doing binary operations. Another state machine that's doing memory operations, another that's doing storage. We have, like, different state machines, each one very specific for specific opcodes, very specialized for doing specific opcodes. And we use polynomial commitments to verify this state transition in each of state machines. Okay, so we have this. Okay, now we need to link them all together. So the codes that we are verifying in this state machine should be the ones that are executing in the main program.
00:24:55.706 - 00:25:13.646, Speaker C: And the same with the memories and the hashes that we are computing. And actually, the same that we are computing when we are doing a storage. And the storage needs to be computed. So we need to link all these state machines. And here the key is the plock up data. We have, like, different polynomials, and we are just relating one each other at the end. Pluck up.
00:25:13.646 - 00:25:33.686, Speaker C: What you are doing is. Okay, this polynomial is included in this other polynomial. That means that the codes that I'm integrating in this specific state machine is actually the ones that I'm creating here. And for this, the key is plock up. But plock up at the end is done with polynomial commitments. So you have the polynomial commitments you had before. We have the new polynomial commitments that we have pluck up.
00:25:33.686 - 00:25:53.502, Speaker C: So we end up, like, a full set of polynomials. Polynomials everywhere. Polynomials, commitments everywhere. And a lot of relationships that the verifier needs to check about these polynomials. So this is what we have. And so all these polynomials commitments at the end is our polynomials openings. All this is.
00:25:53.502 - 00:26:05.194, Speaker C: We use fry to open all these, to do all the openings of these polynomial commitments that we make. We do all the verifications and all that. We do it in a circuit, in a growth 16 or a plonk circuit.
00:26:05.242 - 00:26:05.838, Speaker A: I see.
00:26:05.924 - 00:26:12.622, Speaker C: And the result of this plonk sync is actually what goes to the blockchain and verified on chain. This is a little bit discovery.
00:26:12.686 - 00:26:24.598, Speaker A: Yeah. Okay. So, I mean, you've touched. There's two things that you just brought up that we might want to clarify a little bit. One is pluckup. So this is plonk up. Kind of pluck up.
00:26:24.598 - 00:26:28.102, Speaker A: I know that this is also from aztec, I believe.
00:26:28.236 - 00:26:54.346, Speaker C: Yeah, it's. They came up with this construction. It's a very cool construction, and it's very powerful. It's used in many things, and it's a very powerful piece for building these systems, because the glue is what allows to connect different virtual machines, to glue them together in a single proofs.
00:26:54.378 - 00:26:59.982, Speaker A: Are they being created after every transaction, or are they being done, like, after a batch of transactions?
00:27:00.126 - 00:27:40.542, Speaker B: Yes. These proofs, it's the same concept as the current secret roll up. We are creating these validity proofs in the form of a batch. So we have a queue, and these queues receive the transactions from the users. And then the Hermes node just selected the title or the best transactions to process, and they do this processing off chain layer two, where you just change the states and so on. You execute all this processing off chain. And the interesting thing here is that once in a batch, you just create a validity proof of all the set of changes in the system at the same time.
00:27:40.542 - 00:27:59.846, Speaker B: So the prover we are building is the same concept at the secret roll up of transactions. It's one proof every whatever number of seconds with a maximal number of transactions in the same batch to be more efficient. But it will be one proof in improving a lot of transactions at the same time.
00:27:59.948 - 00:28:16.986, Speaker A: You had sort of mentioned that storage, there is a method that you're using, and maybe I didn't understand this, but are you also using these polynomial commitments and that structure to manage storage? Or is there another way that you need to think about that?
00:28:17.168 - 00:29:29.294, Speaker C: Well, if we want to maintain fully compatibility with the current ZKVM, we need to use the current patrifia trees. It's a kind of a mercury trees that is using right now the Ethereum virtual machine. There are new ideas for replacing these patricia trees waste, maybe using some binary trees or other different trees, or even polynomial commitments, and there are different or even Berkeley trees that was talking Vitalik at some point, and there are different ideas there, I would say, in the ZK site, and then even in the Ethereum site. So Ethereum is probably, they will upgrade at some point and remove the patricia trees and goes to a different structure for storage. This is something that's open, but opening, I would say in both sides, in our case, the days to be compatible with all these patricia trees. But it's possible that maybe we go with an easier, maybe with a normal tree, easier trees, and maybe we just break this compatibility because this is not an opcode. So the program should still work and this will be more efficient, and this is something that we need to consider and to evaluate.
00:29:29.294 - 00:29:31.154, Speaker C: But these are different options there.
00:29:31.272 - 00:30:04.878, Speaker A: I want to understand maybe what you had described going back to those earlier ideas of other ZK rollups looking to do EVM implementations. So you had mentioned Starkware, ZK sync, and that loop ring might be thinking about it. Lots of people, I guess. How are they approaching this? You described sort of using the stark and then using the snark, but in the case of starkware, would they also be doing something like that? Or do you think that they're approaching this in a different way?
00:30:05.044 - 00:30:48.922, Speaker C: It's different because we are different engineers and we have different ways of thinking and different tools. And things I'm not going to say even which is good or bad. I think it's good to have many projects, each one trying their best way. This will help a lot and if there is communication we should learn from one each other. And this is something that some way we are promoting and it's quite happening I would say in the space for this knowledge sharing and understanding what's doing each one just to learn. But it's not clear what's the best at this point is just try do it and then we'll see. That's a cool thing here.
00:30:48.922 - 00:31:16.834, Speaker C: It's like there is no good approach or bad approaches at this point. I would say that all approaches are good at this point. And maybe at some point some of them will maybe us. We just say okay, this is a bad approach, we're wrong and this is not good because this or that. And then we just explain, we say we try to learn and work around and whatever. And this can happen to us, it can happen to any of the projects. But that's cool at the end.
00:31:16.834 - 00:31:21.254, Speaker C: Important is to scale smart contracts. That's what we are, committed projects and.
00:31:21.292 - 00:31:33.610, Speaker A: Everybody'S trying to do that. But actually my question is more like do you know what they have planned and how does it compare? Not which one's better, but just like is it a very different approach? I'm kind of trying to understand how they look at it.
00:31:33.680 - 00:31:47.550, Speaker C: For what I have read and what I have listened. There are different approaches in some way, but that doesn't mean that those approaches are wrong. They are just those approaches.
00:31:48.130 - 00:31:52.558, Speaker A: But can you speak about them? I'm mostly curious if you know what they are.
00:31:52.644 - 00:32:21.322, Speaker C: Yeah, I think we explained for example matterlapse is going more in this recompiling, having their own opcode so their own virtual machine and compiling solidity to this optimal virtual machine. Starks, they also have their own virtual machine. They have a project also to port the VM to these virtual machines some way. I'm not sure about the details. You should ask them and how they are doing that.
00:32:21.376 - 00:32:23.818, Speaker A: Totally, but sounds like I should have.
00:32:23.824 - 00:32:58.166, Speaker C: Them on the show. It's in their plan too. But they are working also in that direction. As far as I know the stadium people is thinking very much in Halo for example. Or they are considering Halo in hello or some techniques that use it in hello. The approach is more similar to us in the be more ZKBM so fully VM compatible. Of course we are talking with lots of these projects and in the technical side we are just sharing a lot of information and it's like we are.
00:32:58.188 - 00:33:16.250, Speaker A: Learning every day that's awesome yeah going back to what you've actually. Or what the designs for ZKE EVM are. Is the idea here that it will support all opcodes? It will be actually one to one? Or are there some limitations that you could foresee here?
00:33:16.320 - 00:35:56.318, Speaker C: Definitely there are opcodes that are more difficult to implement to the others and it's possible that maybe the first version does not include like the full opcodes or the full precompiled smart contracts but what's cool is at this point I don't see any stopper on any opcode to be implemented even the most complex opcodes or even in this case they are not opcodes but they are precompiled smart contracts that are important like paddings or big numbers smart contract or HeCAC hash function all those looks like they are doable and they are just a matter of building. And need to see the efficiency and we need to see how it matches altogether but I don't see a priority stopper for any opcode there are opcodes yes true that there are opcodes that are like very specific layer one opcodes. That they will have to have some special treatment for example, difficulty there is nothing similar to difficulty in layer two okay, but what happened with this opcode? Well, maybe it gives her code a value or something like that or block there is no block maybe it's equivalent to batch maybe the CKVM have some extra opcodes that are more layer two related so it can be some, I would say, adjustment because it's different it's not layer one and layer two and there are some opcodes that you need to find for example, the optimistic people they already did a good work in adapting these specific opcodes but this is something very concrete and very specific to that the important ones like the opcodes that are maybe complex but they are doable. Like create an opcode that can create another smart contract that's a heart or calls or delegate calls or of course storage or even these precompiled smart contracts they are like signature verification or pilings or all these things that those are doable at least in the project that we're building we know how to build them we need to see how efficient and how they fit and altogether. But at least from the theoretical perspective they are achievable that's why we want to at some point build all of them they have to be as much compatible as we can there are things. The gas things for example what happened with the gas. They have to try to be as compatible as possible.
00:35:56.318 - 00:36:22.760, Speaker C: But there are going to be difference between layer two and layer one. And maybe there are some adjustments that need to be done in the future. But when you are doing this, it's like you are finding a lot of things. What happened with this and what happened with that and this what? And you are solving this or maybe having a workaround or some solution. And the goal is to be as compatible as possible.
00:36:23.610 - 00:36:44.990, Speaker A: Do you imagine actually in these environments that it could go even further? That it could become a realm of experimentation because you don't have the same constraints as the l one? I know. Maybe it's a ways off because you're saying the first release probably won't have all of them. So once you get to all of them, could you go further?
00:36:47.010 - 00:36:47.758, Speaker C: Yeah.
00:36:47.924 - 00:36:49.710, Speaker A: Is it too far in advance?
00:36:50.290 - 00:36:51.360, Speaker C: I don't know.
00:36:52.470 - 00:36:54.100, Speaker A: Come on Jordy, do more.
00:36:55.350 - 00:37:32.682, Speaker C: I would be happy right now if we have like a small set of opcodes working. But yeah, we'll see. This is a first approach. There are things that this work just talking like the long future. If you are talking this area fiction things. But one interesting thing of doing this opcode compatible approach is that a lot of the work can be used for verifying l one blocks. And this is for example something like protocols, like Mina protocol, things like that.
00:37:32.682 - 00:38:14.294, Speaker C: I think Stello is doing something similar that's like especially for like clients. So each block has a proof that verifies that the last block is valid and you have this kind of recursion. If you have all this proof that actually verifies all the transactions that are processed in this case of arch, you can have like a verification that all the transactions that you process are included in this block. Maybe you should add the consensus verification proof of work, proof of stake or whatever there. And then you could have a recursive verification there. So that's something that. Okay, this is not like our main goal.
00:38:14.294 - 00:38:57.266, Speaker C: Main goal is to build a ZKVM roll up. But all the work that we are doing could be used in this verification. And this would be good for like clients, maybe for using these blockchains in mobile and having a client that like client in mobile. This is something that's good evolution for Ethereum. But again, this is like long run future. But it gives you an idea of the importance of the work that we nervous. But also all the projects that are working in the ZKVM or ZKVM at least projects.
00:38:57.266 - 00:39:00.490, Speaker C: Because this will help a lot to go in that direction.
00:39:01.550 - 00:39:16.560, Speaker A: Jordy, you just mentioned gas, and I'm actually curious, what is the strategy for that? Do the l two s in this EVM compatible? Does it have to have the equal gas model? Can you get rid of gas completely?
00:39:17.890 - 00:40:20.210, Speaker C: It's a hard topic, David. It's a problem of the gas is that a lot of the security of the smart contracts of the security model is based on the gas. So if you want to have a compatible EVM, you cannot change, at least in an initial version, this gas model. So the idea is to keep this gas model as compatible as we can. So that's the idea is to keep the same gas model altogether, but said that the gas was designed to be for l one, was not designed for l two. So probably in the future you can think maybe changing some gas costs and even some gas, the gas model in the ZKVM in a different way, that makes more sense. But this is something that needs to be studied, and our goal, at least in this moment, is to be as much compatible as we can to the current.
00:40:20.210 - 00:40:29.414, Speaker C: We want that the developers that are building smart contracts in l one, they can use the same tooling, and we'll go to l two and works.
00:40:29.612 - 00:40:41.726, Speaker A: What would the base gas token be denominated in though? Like, is it denominated in the native Hermes token? Oh, it's still in Ethereum. Okay. Even though it's within the ZKe evm?
00:40:41.778 - 00:40:48.918, Speaker C: Yeah, you can choose whatever you want. But I think that the ones that make sense is Ethereum.
00:40:49.014 - 00:40:57.118, Speaker A: Is it sort of like a synthetic ethereum, though? Is it like Ethereum locked on the l one, moved over to the l two, that's then used for gas? Or is it.
00:40:57.204 - 00:41:04.318, Speaker C: Yeah, it's like a roll up. You probably have to deposit and then have some smart contract to get that Ethereum from there.
00:41:04.404 - 00:41:04.862, Speaker A: Got it.
00:41:04.916 - 00:41:09.790, Speaker C: It can be any, it can be any, it could be any, but it has to be Ethereum.
00:41:09.870 - 00:41:43.440, Speaker A: Cool. I have a kind of a higher level question about EVM compatibility in general. We've talked very much about the different solutions, the ways that Zke EVM aims to allow for this compatibility. Like almost a one to one in terms of compiling and it's sort of this equal system. But why do you even want the EVM compatibility? Like, why would we want an exact EVM copy? Is it because it's such a fantastic system or is there some other reasons that you see.
00:41:43.810 - 00:42:37.230, Speaker B: Well, I can provide my comments here. I think we were trying to solve from the beginning the scalability problem of Ethereum in the first place. So we want Ethereum to be able to support more transactions. So of course we can build different systems, but this will be a different project. I think what Jordi just said regarding the gas and the security model is very important because there's a lot of smart contracts developed, there's a lot of audits done on existing smart contracts, and the security model needs to be respected in order to manage the change to a CKBM. So if you build a different system, all this technology needs to be analyzed to see what's the impact on that. And the CKBM tries to be compatible and to respect the gas model in order to behave the same as the EVM.
00:42:37.230 - 00:42:58.518, Speaker B: So this will be very easy for developers to just migrate contracts to this system and this will allow existing projects to migrate. You don't need to recompile, ideally you just move contracts. So this would be a huge benefit in terms of adoption, because if you do different things, probably you will face friction in some way.
00:42:58.604 - 00:43:20.700, Speaker A: The setup that you described though, could you ever use that to build out a different kind of VM? Do you know what I mean? If you didn't only want EVM compatibility, but rather like another VM compatibility, would you be able to actually plug that in? Or is this so deeply built together that it wouldn't be unextractable from one another?
00:43:21.790 - 00:44:22.334, Speaker C: We need to think a little bit, but the idea is that, so if you keep the backwards compatibility, that's very much what we are doing. You can always extend the AVM and do maybe different opcodes or different even different structures, just maybe for new smart contracts that are more, maybe with a different gas model and with different things. And this is actually doable. And we may think to go in that direction, but the idea is to keep all the work that has been done in development terms, in auditing terms, in understanding that has been done. For that we need to warranty this backwards some way, this backwards compatibility or if you want this compatibility at this point. So the strategy, I think that goes more in that direction. First try to keep the backwards compatibility as much as we can and from there maybe extend the ZKBM or maybe just to do it better and just having a smooth transition in some way.
00:44:22.334 - 00:44:26.160, Speaker C: This is perfectly doable, but we are a little bit far from there.
00:44:27.430 - 00:44:49.542, Speaker A: So a few months ago, when we did a bunch of episodes on l two s, one of the questions that we kept asking everyone was how do you imagine interacting with one another? How would someone using working in the ZKe EVM space actually potentially have a bridge or communicate with another, like an optimistic EVM compatible l two.
00:44:49.676 - 00:45:21.698, Speaker C: Yeah. This is something that, for example, in Hermit we developed, although what we call massive migrations. And the idea is pretty much about that. It's just packing a lot of exits to a single exit that goes to another smart contract. So it's like with a single lo one transaction, you are like packing many transactions from one to the other. This is something that we have been working a lot in the last month. We have a full team right now working on that.
00:45:21.698 - 00:45:53.950, Speaker C: And I think we made some improvements, very good improvements, just to optimize these transitions. We are working this in the context of the payments of version one of Hermes. But all this work can be applied and all the learnings can be applied also to the CK EVM. But this is something that we are working a lot because we know that massive migrations are going to be important at some point. And work is there.
00:45:54.100 - 00:46:26.310, Speaker A: Got it. This is kind of a bit of an off topic point, but something like binance chain in this. Like, I know that there was an article that came out by Haseeb a few months ago and what it suggested was like, we're building all of this amazing ZK constructions and they're so much more safe and secure. But then there's chains where they kind of did a much lazier connection point to the l one. Yeah. How do you sort of address that? What do you think about those kinds of chains?
00:46:27.290 - 00:46:49.598, Speaker C: Look, for me, there are different things. We are building decentralized systems and permissionless systems. If you want to build centralized systems, seriously, don't go to a blockchain. Just use normal servers and normal databases. They work great. You will have much less overhead. Overhead things work very good in that space.
00:46:49.598 - 00:46:54.130, Speaker C: But this is not what we are building here at all.
00:46:54.200 - 00:47:41.678, Speaker B: Yeah, in my opinion, there's the fact that there are different needs for different use cases. And some of the applications or use cases are willing to sacrifice some of the properties in order to achieve others. So I think it's a clear example of what will happen in the end, that there will be probably different tires of different solutions for different applications. And depending on the requirements, it could be fine. So it's a combination of different technologies in order to build a different solution. And it's clear that it's going to be okay depending on your use case. The problem is that someday something happened that this will not be good for the space.
00:47:41.678 - 00:47:57.030, Speaker B: But yes, up to this point we're trying to build the best solution we can with the existing tools we have today. And from here you're always capable of reducing some of the requirements by combining other stuff.
00:47:57.180 - 00:48:19.450, Speaker A: Totally. I also liked what you were saying before, Jordy, with the differing approaches. And this is sort of, what is it like testing live? These things are live, or some of these things are live, and we're going to see how they play out which ones work, if there are actually vulnerabilities with some of these more centralized systems that maybe aren't quite obvious right off the bat.
00:48:19.520 - 00:48:48.902, Speaker C: Yeah, but it's important, Anna, the people understand the differences that's between a binance chain and an ethereum chain. I think that if you don't understand the difference, then it's problematic. I'm not saying that binance chains is not great. It could be very great for some applications, as it says. But there are different things. We are trying to build a decentralized system, permissionless and social resistant. And it's important that we understand each system that we are building.
00:48:48.902 - 00:49:10.860, Speaker C: What are the properties and the things and even the stage we are. For example, we enmes right now it's quite centralized. Right now there is a single operator. Right now we need transactions to start decentralization. We explained that. We are saying that we are not lying anybody. This is what it is.
00:49:10.860 - 00:49:57.994, Speaker C: The same happened with, well, ethereum is what it is, bitcoin is what it is. The idea is understand each chain, each system, what's doing, and if you are transparent on what you are doing, what you are achieving, that's fine. The thing is that if you think that federated blockchain is the same, that a decentralized blockchain, then okay, maybe you need to understand that what happened when a government or specific governments have threatened the validators or threats, the binance itself or binance blocks, what will happen with the chain. So these are questions that we need to understand now, the networks, I don't know, like the Facebook one, Facebook, create a blockchain, it's okay. If you're explaining why you are creating. It's good, it's approval, authority. It's what it is.
00:49:57.994 - 00:50:18.402, Speaker C: But this is what it is. You need to understand what it is. This may be very good, which was great. I'm not against this. This is good, but it's important that the people, so that users. Yeah, that the users and the people understand what each chain does and what each chain doesn't. And this is very important for the space.
00:50:18.536 - 00:50:24.878, Speaker A: Basically the trade offs that may not be explicit, but are kind of built into the way that they're thought up and the transparency.
00:50:24.974 - 00:50:53.150, Speaker C: Just to the transparency of what is each thing. So what exactly are you building? What kind of consensus are you building? What kind of properties are you achieving? What are the threats? What are the risks? What actually you are doing? If you are transparent, and that's fine. But if you are trying to sell a blockchain as a fully decentralized. And it's just a server running in AWS with some software, well, then I think this is not ethical. Correct?
00:50:53.300 - 00:51:02.702, Speaker A: Yeah. Fair. I want to hear a little bit about the timeline and the plan for ZkevM. What stage is it at?
00:51:02.836 - 00:51:07.234, Speaker C: We are running as much as we can. The current stage is.
00:51:07.272 - 00:51:08.900, Speaker A: I keep putting pressure on you.
00:51:10.310 - 00:51:31.514, Speaker C: This is the current stage. We have. We have an internal roadmap that maybe can share with you a little bit of what we are planning. But take it as an internal roadmap. Things may accelerate, may go slower. There are things that we may find, maybe some stoppers that we need to fix. There are a lot of things to do.
00:51:31.514 - 00:51:48.414, Speaker C: So do not take it as at this date, we will have it not. We are not at this stage. Maybe you can share that a little bit. So in a year, to have this in production in a year, more or less. That's the idea, yeah.
00:51:48.452 - 00:52:22.570, Speaker B: As I was saying, we have the idea to develop as fast as we can. Of course, we also assume that some issues will happen during the way Jordy is working. Now, the first proof concept with the rest of the team. And we expect to have this initial proof concept by the third quarter. Probably the beginning of the fourth quarter. And we expect to share an internal testnet with some reference projects by the end of this year. From here, we'll continue developing and getting some feedback to start getting the matility as possible.
00:52:22.570 - 00:52:49.860, Speaker B: And developing the opcodes by batches until we finish expected one year. Just assume it's half next year. We will try to do it the fastest way as we can. We'll see how far we can move at this speed. But yes, we also want to be realistic, because this is a very complex engineering project, as you can see. And a lot of things will happen during the wait.
00:52:50.310 - 00:53:03.960, Speaker A: Can you imagine? I mean, once this is finished, does it just merge into, like, would it just sort of be in the same Hermes roll up setup? Or would that kind of alter the way that you think about Hermes as well?
00:53:04.570 - 00:53:40.470, Speaker C: We don't know it yet, but will depends very much how Hermes, the current Hermes evolves. If Hermes is used a lot, that means that getting more decentralized, that means getting more fixed. Then probably this will be like a new roll up. It will be a new Hermes, maybe with some migration from one to the other. But Hermes one will go forever. And then it's going to be a Hermes two. If in the other side, Hermes just is less used, maybe then it would be possible to evolve to upgrade Hermes somewhere.
00:53:40.470 - 00:53:54.950, Speaker C: It's still not fully centralized, so we can upgrade. And maybe we can upgrade Hermes to a new roll up. Both options are open, and it will depend very much on many things, but mainly in how Hermes one evolves.
00:53:55.370 - 00:54:15.274, Speaker A: Cool. Well, it sounds like there's a lot in the coming months, weeks, years for Hermes. And I'm so glad that you came on the show to share with us the Zke EVM, how you're planning on building this out. And, yeah, why an EVM compatible ZK rollup could be really useful.
00:54:15.402 - 00:54:15.982, Speaker B: Sounds great.
00:54:16.036 - 00:54:21.040, Speaker C: Perfect. Thank you, Anna. We are open. We are here.
00:54:22.050 - 00:54:23.562, Speaker B: Very happy to be here.
00:54:23.716 - 00:54:51.578, Speaker A: Cool. All right, so I want to say thank you to the podcast producer, Andre, the podcast editor, Henrik. And to our listeners. Thanks for listening. So soon after we did this interview, there was a huge announcement. And so I'm so glad that you've come back for this little extra bonus piece of the episode to tell us a little bit about what we just learned about in the press. Actually, a huge merger is happening.
00:54:51.578 - 00:54:53.146, Speaker A: Tell us what it's all about.
00:54:53.248 - 00:55:24.318, Speaker B: Thanks, Anna. We are very happy to join forces with Polygon team. After some discussions during the last months even. We find that this makes a lot of sense for us because I think we have an amazing technology. But we need adoption. And for us, after we launched the first release of the Hermes network, we faced this issue of the adoption. And for us, this agreement is creating a lot of value for both parties.
00:55:24.318 - 00:55:38.726, Speaker B: And we are very excited about this merger, both for the project, both for the teams, and also because we think we provide a lot of value, or we'll try to do this for the Ethereum community and for the objective of scaling Ethereum. Finally.
00:55:38.828 - 00:56:06.970, Speaker A: Yeah. So two weeks ago, you had actually announced an announcement. You had said, like, something is in the pipeline. And I did notice a lot of polygon folks coming around the zero knowledge chats. I don't know if you notice them, too. Asking some questions, learning a little bit around it. What are they saying to you? What do you feel like this merger is actually going to look like? Are you going to be their technologies provider? In a way, is the roll up going to take over what they have right now?
00:56:07.140 - 00:56:34.330, Speaker C: No. We continue to be like an independent team and we have a main goal. The main goal is to bring ZKVM in production. I would say it was before the merge, it was like my focus and now is continue to be the focus. And I would say with maximum intense. This is actually my. It's a project of my life.
00:56:34.330 - 00:57:01.010, Speaker C: This is what I'm committed to. And yeah, that's just after this interview. I just arrived now to Switzerland after this interview. I just continue working on this and very excited to do. Of course, as I mentioned, there are a lot of unknowns. We are doing this new technology and there are a lot of unknowns and a lot of stoppers that maybe we don't know yet. And there is always a huge risk in there.
00:57:01.010 - 00:57:51.314, Speaker C: But we are convinced, I'm personally convinced that this will happen also, I'm convinced that the bet that Polygon made in Nermes concretely, but I would say in the ZK roll ups, more generic, is going to have their fruits in some months. There is a lot of work to do for the space. This is the most important thing is that ZK roll ups are under ZK technology. I think that at this point nobody have any doubt. It's a way to scale the blockchain technology. This is the bet and very excited to be here and personally it's an honor to lead this and push this.
00:57:51.512 - 00:58:26.240, Speaker A: I think you're totally right on where you say it's a massive kind of reinforcement or thumbs up or it sort of shows that the ZK roll ups, we talked a little earlier in this earlier episode all about the different kinds of roll ups and how they are. Also sometimes I think I mentioned this where there's some talk like maybe ZK is too complicated, maybe it won't be the winner in some way. But I think this is definitely a sign that it could be. If it can get the volume that polygon has been able to generate, then it could really show its.
00:58:28.050 - 00:59:21.322, Speaker C: You know, the technology is, well, you know, better, you know, even better than me. It's a very young technology and it's a technology that at this point is growing a lot and growing when I'm saying growing, growing in the number of researchers, knowers of the people that's working on that, knowing on the people that's understanding on that, growing the people that's building on top of this technology. Well, just look at your podcast. You have been there for a couple of years, maybe three years, just comparing three years ago. This is this amazing technology that allows many things, but scaling blockchains is one of those things that this technology allows and we will see, but still young and it's still a lot of work to do and yeah, that's what we want to do and that's why we are so excited.
00:59:21.466 - 00:59:35.118, Speaker A: It sounds like a call to action a little bit to the listeners, people looking to jump into ZK. Now would be an amazing time to do it because the momentum is very strong and it doesn't seem to be slowing down at all.
00:59:35.304 - 01:00:24.814, Speaker C: Yeah, and this is very important. Especially we have this technology that has been created for many researchers for the last many years, because even all the researchers don't know the research and it's like many years. But the zero knowledge problem, the non interactive zero knowledge comes from the ten years ago, a lot of groups that make a huge impact in the research, but it has been a humanity effort and time from researchers. Researchers have been working a lot. Of course, they continue working, but now it's time of engineers, now it's time of implementers and really taking profit and bringing this technology to final users. And here is where engineers we come to rescue. We are more pragmatic.
01:00:24.814 - 01:00:31.474, Speaker C: And sometimes between mathematicians, pure people and engineers, you have this kind of discrepancy.
01:00:31.522 - 01:00:32.210, Speaker A: Trade offs.
01:00:32.290 - 01:00:52.666, Speaker C: Trade offs, yeah. You are good in words. That's a good word. But we're bringing this to the final users. We are solving real people problems. And this step is very important. It's not a step that can be done for a single person or for a single team.
01:00:52.666 - 01:01:48.734, Speaker C: It's an effort that needs to be done from a whole community. When I announced in Paris how we are going to build the ZKBM, this is the plan. We are going to use Star wars technology, we are going to use aztec technology, we are going to use ZK sync technology, too. So it's a community effort and it's important that each person, even each individual, each individual team, just study and works on this technology and try to add value to this technology because it's very easy to add value because everything needs to be done yet. So right now, for an engineer, sometimes a blue ocean, it's a place where you can find your spot as an engineer can find your spot in something that you can build. This is the current moment that we are living and it's a call for action. Yes.
01:01:48.734 - 01:02:28.070, Speaker C: It's just people that really wants to build things, new things for the humanity. Getting to this technology, understanding this technology, and trying to think what's the best way to apply this technology to the world is something that you can find a place and you can add a lot of value. And as I told you in your podcast, you have been talking a lot about that. It's not only about scaling blockchains. This technology is amazing for privacy. It's amazing for all the multiparty computations. There's a lot of things where this technology can be applied.
01:02:28.070 - 01:02:50.850, Speaker C: And it's important that we as a community, if you want, as a humans, we add value together. We help one each other to make humanity better in some way. And this generosity of the technical people, which used to be in general, this is very important when we have this new technology, because if we do this way, we can go much faster.
01:02:51.270 - 01:03:10.898, Speaker A: Cool. Well, I want to say congrats again to both of you, and I can't wait to see how this merge works and what that means. But we'll be watching this really closely. It is a call out to everyone. Amazing. Time to jump into the ZK space, head over to the channels. There's lots of people there who will help you get onboarded.
01:03:10.898 - 01:03:12.818, Speaker A: And yeah, thanks so much for the interview.
01:03:12.914 - 01:03:13.890, Speaker C: Thank you very much, Anna.

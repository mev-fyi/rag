00:00:05.530 - 00:00:21.360, Speaker A: Welcome to Zero Knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online.
00:00:26.890 - 00:01:00.702, Speaker B: This week I catch up with Ye and Sandy from scroll. We check back in on the ZKE EVM L two project and find out how it's developed over the last year. We talk about the founding of a fully remote organization, the technical evolution of the project, the ecosystem, and more. A quick disclosure, I am through the ZK validator and investor in the project and it's been fun to learn about their progress. Now, before we kick off, I do want to direct you to the ZK Jobs board. There you'll find jobs from top teams working in ZK. So if you're looking for your next job opportunity, be sure to check it out.
00:01:00.702 - 00:01:09.266, Speaker B: And if you're a team looking to find great talent, be sure to add your jobs to the jobs board as well. I've added the link in the show notes. Now Tanya will share a little bit.
00:01:09.288 - 00:01:12.354, Speaker A: About this week's sponsor ever feel like.
00:01:12.392 - 00:01:53.870, Speaker C: Developing zero knowledge proofs is a daunting task? Well, the team at Risc Zero is here to remind you that it doesn't have to be that way. Their out of the box tooling allows developers to access the magic of ZK proofs from any chain without needing to learn custom languages or build custom ZK circuits. Bonsai, RisC Zero's most anticipated product is a proving marketplace that enables any protocol or application to leverage fast ZK proofs in languages like Rust. Go and C visit rzero link zkpodcast to learn more and sign up for the Bonsai waitlist. You can also find the link in our show notes. And now here's our episode.
00:01:56.850 - 00:02:02.386, Speaker A: So today I'm here with two of the co founders of Scroll, Ye and Sandy. Welcome to the show.
00:02:02.488 - 00:02:05.266, Speaker D: Thanks for having us Anna. Very excited to be here.
00:02:05.368 - 00:02:06.994, Speaker E: Yes, thanks for having us.
00:02:07.112 - 00:02:25.978, Speaker A: Ye, you were on last year in I think June 2022. We did an interview with yourself and your third co founder, Hai Chin. So that was like our introduction to the project on the show. And yeah, something that I'd like to do with this episode is definitely do a catch up. Before we do that though, ye, why don't you quickly introduce yourself?
00:02:26.144 - 00:02:36.174, Speaker E: Sure. Hi everyone, my name is Ye. I'm the co founder of Scroll. I work on Ziki research hard work solution for their own proof, some algorithm side and some application side.
00:02:36.292 - 00:02:48.402, Speaker A: Nice. And Sandy this is the first time you're on the show, so why don't you tell us a little bit about yourself? What got you interested in this space? And kind of where was your sort of journey to scroll? Where did that start?
00:02:48.536 - 00:03:40.686, Speaker D: Yeah, no, thanks for having me. So my crypto journey started a long time ago, around 2013 and 14. That's when I first read the bitcoin white paper and had that aha moment and just been kind of researching and dabbling and socializing in the space. My first kind of full time crypto job started in about 2017 when I became a crypto investor full time. And the journey for scroll started when I was getting deeper and deeper into protocol level research. And it became very clear to me at the time that ethereum was gaining traction, both as a protocol and also on the social layer. There were just that the amount of talent and creativity surrounding the main protocol was astonishing.
00:03:40.686 - 00:04:00.330, Speaker D: And I kind of came to this realization that this was the future of the crypto space, and I wanted to see whether there are any kind of major open problems I could contribute to. And that's when I met ye and Haichen. We met online, and we didn't actually meet in person for the entire first year of working together on scroll.
00:04:01.550 - 00:04:05.866, Speaker A: But you were not anons, you knew each like you were guess.
00:04:06.048 - 00:04:31.090, Speaker D: Yes. Well, yeah, it couldn't have been an anon, because when we met, he had a paper pending publication on prover acceleration, and that's how we originally found him. And Haitian was working at Amazon at the time as a system architect, and he worked on a lot of the stuff that we're currently using for scroll.
00:04:31.990 - 00:04:43.590, Speaker A: This is actually interesting, the co founding online. Where were you chatting? How would you have met and almost vetted each other? Just online?
00:04:43.740 - 00:05:28.598, Speaker D: Yeah, I think with every kind of meeting, there's always a little bit of serendipity involved. How does anyone meet anyone in this day and age? So it starts with an online conversation, and then there are some offline connectivities and personal relationships. And so initially I was connected to ye through one of our mutual friends and started talking online for a really long time and then decided to kind of go for it. What was the scroll project at the time? Almost very quickly, but it was a research project, and then it just kind of continued to snowball from there, really.
00:05:28.764 - 00:05:41.100, Speaker A: So I really liked that idea of founding a company purely online, where you don't. I mean, I guess it's like, what year was this that you were starting to look at this project?
00:05:41.790 - 00:06:45.242, Speaker D: It was during the peak of COVID So it was about 2021, and it's the same process for most of the people on the team. I think there are at least half the people on the team whom none of the co founders have met in person in the first. And it's still very common for us to not meet someone in person until three or six months after they've been working with us. We're very decentralized as a result of this kind of type of origin. And we have members from every continent apart from the Antarctica spanning. Very keen on taking over that piece of. Yes, essentially I think that's part of our founding DNA and that's resulted to scroll core contributors being all over the world.
00:06:45.242 - 00:06:46.460, Speaker D: Really cool.
00:06:47.010 - 00:07:04.994, Speaker A: So you sort of mentioned that you were excited about, like, the project is kind of coming out of the ethereum ecosystem, but had there already been proposals for zkevms at the time or things like scroll that you were playing on or kind of being inspired by?
00:07:05.112 - 00:07:38.238, Speaker D: I can talk about it from my perspective. I think there's already been a few l two s that are ongoing. When we started, we were inspired by a lot of years research and a lot of the research that were coming out of academia at the time. And we thought there was something that we could offer both by means of outsourcing proofs offline and also this way of organizing a completely open source kind of effort. So maybe ye can talk about his experience as.
00:07:38.324 - 00:08:21.290, Speaker E: Yeah, yeah. I think by the time when we started, as Sandy mentioned, there are several layer two efforts, but I think none of them are really building EVM by code level Ziki VM. So some, I think the closest one is building a language compatible. But I think we are targeting a deeper level of compatibility, which means we will suffer from a larger pumi overhead and much more engineering work. And we kind of make sure that we can, through hardware accelerations through this crypto, like advanced crypto algorithms, can make the efficiency become order of magnitude better than before. So that's why we start this. And with the deepest level of compatibility.
00:08:21.450 - 00:08:48.594, Speaker A: Had things like Jordy and the Hermes ZkevM proposal already come out when you guys started? Or was it happening at the same, like, I know that there was like the sort of. I think. I don't know if Starquare proposed something, but it was like, I know Zksync had proposed something, but there was all these different types of zkvms. But I do wonder, was there anything like yours, or was your research kind of like really this new direction?
00:08:48.722 - 00:09:37.938, Speaker E: Yeah, that's a great question. So I think the very original story that we start with something, our own version of how we build a virtual machine, maybe the key VM or the key virtual machine, and we can make this really efficient through hardware. So that's our initial version. And then I talked with Barry Whitehead at ECM foundation, and he's thinking of exactly the same idea of building the KVM for ECM layer one. And I think our idea overlap a lot for why we think supporting a virtual machine is possible. And then so our collaboration start very organically with Barry and with ECM foundation. And I think there are some nice idea for using lookup tables to handle the virtual machine main memory part of the KVM.
00:09:37.938 - 00:09:42.360, Speaker E: I think the same idea also inspired Jordy to start the.
00:09:43.450 - 00:10:28.882, Speaker A: That's kind of how it comes from, same original source, but kind of happening at the same. I should, you know, we will add a link to the previous episode. What I wanted to actually do, at least with the first part of this, was do a little bit of a check in on some of the decisions that were kind of being discussed back then. I wasn't sure if those were finalized or if they were still in the works or if things had maybe changed. So just a quick throwback. A year ago when we talked about kind of what was the underlying ZK stuff, it was like plonkish arithmetization and Halo two. Is that still what scroll is based on or has it brought in, I don't know, some new techniques or other proving systems?
00:10:29.026 - 00:11:11.122, Speaker E: Yeah, I think the tech stack is still remain the same. Like we are still using plunkage for writing our circuits and using KDJi at the back end using halo two to write our circuits. But huge improvement have been made on the completeness, performance and the robustness. So for example, on the circuit side, I think when we talk, we implement the majority of the circuits, but there will still be some circuit left. And by now we have already implemented all the opcodes, all the arrow cases, and they have already been sent to the auditors to audit. And on the prover side, I think we make extremely fast GPU implementation, to make proverbs really fast. And also we publish our paper.
00:11:11.122 - 00:11:44.286, Speaker E: So I think by the time we talk, we only have one paper talking about how you use IPG and ASIC to make pro faster. Now we have published another paper talking about how you use GPU to make poorer faster. And also we've done a bunch of Ziki research, reducing the memory consumption and also recursive cost. So basically, I think day one where we are running our Ziki VM, a full version. We require like 1 cpu memory to run such a large gigantic circuit. But now we reduce that to only like hundreds of gigabytes. And we are still keep improving on that.
00:11:44.286 - 00:12:23.050, Speaker E: And as for the toolings, I think we are using some derivative of halo two, which is called halo two ce. It's CE referred to a community edition. So it's a derivative version from the cache branch. Because we make many changes to this library and also because it aligned with our philosophy to always develop with the community and sharing all this pruning stack and all the toolings with the community. So it's a community effort to own this pruning stack. And we are leading some discussion to add more components into this library. I think a lot of projects actually reusing the same proving stack.
00:12:23.050 - 00:12:41.870, Speaker E: People are contributing to that. Even for some new optimizations from Fry, it's totally different. But people are still implementing like Godilogs field fry gadgets to this community owned library. So yeah, that's like align with our philosophy a lot. Yeah, that's on the key side.
00:12:41.940 - 00:12:45.822, Speaker A: Cool. I want to check the naming really quickly. Halo two ce?
00:12:45.966 - 00:12:46.226, Speaker E: Yes.
00:12:46.248 - 00:12:48.818, Speaker A: Is that what you said? What does that stand for? Community?
00:12:48.984 - 00:12:49.742, Speaker E: Addition.
00:12:49.886 - 00:12:50.478, Speaker A: Addition.
00:12:50.574 - 00:12:51.122, Speaker D: Okay.
00:12:51.256 - 00:13:08.810, Speaker A: And is this the work that PSE, what is it? Privacy and scaling explorations group from the EF and Xerox park had been kind of like championing or is there one track? Is it yours? Did it also branch out into other ones?
00:13:08.960 - 00:13:46.862, Speaker E: So originally we are using a fork of hello tool and the upstream is in the PSE's GitHub library. And we just change the panomic commitment part from the inner product argument to KDG. But then we want to make this more modular and shared by even more projects. So there depends a separate organization called Halosutce. And there will be more projects contributing to this library. Like freedom Axiom and some other projects are contributing to this. And we are leading some kind of more open discussions about how we can improve this library.
00:13:46.862 - 00:13:58.886, Speaker E: So initially it starts with, we want to build the KVM, we want to use KDG. So we use this fork and then we want to make this more modular and more people can use that. So that's how it's branch out.
00:13:58.988 - 00:14:21.630, Speaker A: How do you sort of split your time in that regard? You're developing something, you have a goal, but at the same time there's a lot of research and work that could potentially contribute to other projects. Would you say you as a research team are super focused just on the things that you need or do you think it's a little bit more fluid? It sounds like you're also contributing just kind of more generally.
00:14:21.970 - 00:15:04.670, Speaker E: Yeah, I think our philosophy is like trying to support open source and more community driven and a shared tooling stack. So we are happy to kind of either contribute to this shared infrastructure and even upstream to the hello to upstream, which is initially developed by Zcash. So yeah, we definitely spend a lot of effort on how we can maximum different projects like progress, compatibility, and also because it also enhance our security. Right. Because if many people are reusing the same pooling stack, there will be more people, more eyes looking to your code base and review, and you also get to share. So that's our philosophy.
00:15:05.010 - 00:15:37.042, Speaker A: That's actually an interesting incentive there. The idea that you may actually just want to make something more general to be used by more people so that people try to break it early. Right, exactly. I feel like there's been some chats actually in the ZK channels right now about security of some of the systems that a lot of things are being built on. And I do think if you can have more eyes on it, obviously that's a really good way to hopefully spot bugs early. You talked a little bit about the GPU implementation. This is for the verifier or the prover.
00:15:37.106 - 00:15:41.814, Speaker E: Oh, this is for the prover. How you can make prover general proof faster.
00:15:41.942 - 00:16:05.642, Speaker A: And when you talk about a GPU implementation, is this different from the rest of your tech stack? Is this like some lower level how to better interact with a GPU? And I guess the second question to this is, do most roll ups and ZK EVM teams need to do that? Because I don't think I've really heard about the teams themselves working on the hardware.
00:16:05.786 - 00:16:56.538, Speaker E: So you can imagine that when you are running algorithm initially on CPU, for example, it takes like 1 hour to generate the proof and you think it's too slow, and you want to utilize the polygam inside your proving algorithm. So you incorporate the GPU into your CPU device and it's just connected, and then you will outsource some very expensive computation to the GPU. And GPU is very good for doing some parallelization work, and it can do that very well. And the most computational heavy part inside prover is parallelizable. So it's very easy to carry that on GPU. It can make become like ten times faster. So you are basically, the high level idea is that you move the most computational intensive part to GPU and the GPU can make that faster.
00:16:56.714 - 00:17:06.754, Speaker A: That's what you're doing. Like on the software side, you've made the decision what needs to be used by GPU and what isn't. But are you actually dealing with how the GPU processes it as well?
00:17:06.792 - 00:17:14.070, Speaker E: Yes, we also need to implement how you kind of run this on GPU. You need to design the kernel implement using CUDA.
00:17:14.650 - 00:17:29.690, Speaker A: Oh, wow. And yeah, then I guess the second part of that question is, is that something that a lot of ZKVM teams need to be doing, or is it because you had this background in hardware that we talked about in the last episode that you were like, oh, we're going to also do this hardware part?
00:17:29.840 - 00:18:05.714, Speaker E: Yeah, I think for GPU, it can make all the ZQM become faster. But I think currently, from what I know, most ZQM teams are using gpus, but some don't need because it depends on your proven algorithm. If you heavily rely on some kind of ethereum curve based operation, which can be massively paralyzable and can be considered really fast on GPU, but if you are relying on more like smaller field hash function, then maybe you can run that on cpu efficiently. But I think overall, if you have GPU, it can always be faster in most cases.
00:18:05.842 - 00:18:22.710, Speaker A: Okay, so I guess most of the Zkavm teams, if not building it themselves, will be using some sort of open source version of this, because it's kind of an inevitable thing. Do you feel like this is just part of the engineering challenge in general, this is where you can get some improvements, so you will inevitably want to go for it?
00:18:22.800 - 00:18:58.142, Speaker E: Yeah, I think it's definitely part of the engineering effort, but also one direction we are working on this, which also align with our decentralization philosophy that we want to reduce the requirement, for example, the memory requirement for GPU. And we are trying to lower that requirement, for example, like maybe miners, because people believe that you will move from proof of work, you will have a bunch of gpus. And one direction might be how we can adapt our algorithm and generalize this algorithm of b ten to adapt to other cheaper gpus so they can still reuse their machines to run our proven algorithm.
00:18:58.306 - 00:19:16.702, Speaker A: Like I've done a few episodes recently on hardware, kind of looking through the lens of the zprize efforts. Do you expect sort of just like a standard for how gpus and zkps are going to be used, or do you think that there's still a lot of room to develop unique solutions there?
00:19:16.836 - 00:19:56.714, Speaker E: Yeah, that's a great question. So it depends on the algorithm. I think eventually it will become a problem which involves software and hardware code design. So, for example, recently, people are really crazy about Nova, and you might need some special components for making Nova faster. So because the proving algorithm keep evolving. So it's very hard to say that, oh, this is your final version of GPU. But I think most algorithms are reusing almost the same primitives like FFT multi exponentiation and some vector level computation, maybe some hash function.
00:19:56.714 - 00:20:12.606, Speaker E: So I think the large modules are fixed, but if you really want good performance, you need to tune the workflow and for your proof system. So I think that haven't been fixed. It depends on your software stack. So eventually it will become, I think, a software and a hardware code design problem.
00:20:12.708 - 00:20:27.638, Speaker A: But then do you think it won't be GPU and you'll just move towards FPGA? And then just if it becomes a little bit more, if even you can figure out which things you need to focus on, could you start to go in that?
00:20:27.804 - 00:21:10.654, Speaker E: Yeah, yeah, definitely. But I think in our current version, we are still more bullish on using GPU for short term, because firstly, people have more general purpose gpus in house and they can run proverbs without buying expensive FPG and ASIC. And also, one interesting from our conversation with different hardware company, that single board FPG is very hard to beat GPU performance. You have to connect many FPG boards together to beat one GPU performance. And ASIC might be better. So long term it might be ASIC. If you are kind of having one protocol become dominant ziggy protocol, and there are ASIC for this protocol, then that might be a best combination.
00:21:10.654 - 00:21:20.086, Speaker E: But now, because algorithm hasn't been fixed and GPO is still general purpose, people can buy that. And so I think short term we are still more cool.
00:21:20.268 - 00:21:40.490, Speaker A: Sandy, I want to sort of ask you a little bit about the kind of ecosystem and scroll world, since, I mean, you weren't on the last episode, but since maybe you started when you first founded the company, was it just the three of you or was there already a team? And yeah, how has kind of the world around scroll evolved?
00:21:41.010 - 00:22:43.870, Speaker D: I would say day one, it was just the three of us. But the snowball effect happened very quickly. And I think the first turning point was when I think, as yev mentioned, that when PSE team, when Barry started supporting the project, and we very much became a global community effort overnight. And having that very strong partnership meant that we're able to scale and gather resources in a way that wouldn't be possible otherwise. And then I think the second turning point was when we started having an MVP and when our vision started become clearer. And the vision was to build a product that mirrors the developer experience on Ethereum, layer one as much as technically feasible. And once that positioning is clear, it started attracting more and more talents who are like minded and who also sees the same vision.
00:22:43.870 - 00:23:47.074, Speaker D: I think the wider vision is that we're in the first of nine innings of the global if we think blockchain will be the value layer of the Internet, then we're in the first of nine innings. And if we're able to kind of have the leg up of inheriting all the tooling and all the great things that have been built on Ethereum over the last few years, then we're off to a good start. But it's still a start. So I think once that vision is well articulated and shared within the wider Ethereum researcher and developer community, we started to see a effect where people are applying to scroll and people are reaching out to us on Twitter. And I think from early on we had this policy to hire the best talent globally. So you're not restricted by where you live and you're not restricted by your identity. And obviously we do KyC on anyone that joins us full time.
00:23:47.074 - 00:24:55.740, Speaker D: But essentially we started building this culture of hiring straight from Twitter and hiring straight from discord. And that was very energizing for a lot of our community members who can see people who actively contributed to open source research. I think one thing I often explain to web two people how scroll has grown so quickly in head of headcount is that the great companies from ten years ago all built from a very kind of employee corporate structure. But now we're very much a kind of, we need to articulate our vision and set up in a way that anyone can see what we're building kind of week to week, and anyone can catch up and contribute as they wish. And if someone does have value add to the process, then we'll bring them onto the core team and train them and equip them with whatever they need to succeed in this endeavor. So I think that's how we quickly scaled and we have a 40 plus engineering team now. And I think it's very difficult to find ZK engineers and especially ones with prior experience.
00:24:55.740 - 00:25:21.586, Speaker D: And I think that's very much due to one is the division and the architecture that has so well articulated. Another thing goes to kind of heightened's ability to run an agile process, run a global development engineering team, and making sure everyone is well supported to work on this. Really?
00:25:21.688 - 00:25:25.326, Speaker A: Yeah. How do you do? Like, especially if you're.
00:25:25.518 - 00:25:25.874, Speaker D: Because.
00:25:25.912 - 00:25:29.766, Speaker A: Yeah, I think of you a little bit more on the research side.
00:25:29.868 - 00:25:30.326, Speaker E: Yes.
00:25:30.428 - 00:25:33.558, Speaker A: Is Hai Chen more on the engineering side?
00:25:33.644 - 00:25:40.086, Speaker E: Yes, exactly. Hai Chen is leading our engineering team and I'm more on the research side, both CK and protocol research.
00:25:40.188 - 00:25:52.470, Speaker A: If you're like getting kind of contributors in, are you growing in a very flat way or is it sort of like you're starting to create these structures? Yeah, I'm just curious how you do it because I guess. How big were you last year?
00:25:52.560 - 00:26:01.022, Speaker E: I think last year when we talk, it's around, like, it's still like 30 or something. Researcher, engineer, but you've grown by ten.
00:26:01.076 - 00:26:02.846, Speaker A: Okay. So it's not too much, too crazy.
00:26:02.948 - 00:26:04.682, Speaker E: Yeah, but that's only on the technical.
00:26:04.746 - 00:26:24.600, Speaker A: But maybe just from that starting point to that. Yeah, like from that starting point of just like a very small team to the 30 or to the 40. Actually, I think there's a lot of teams out there who could really, potentially really want to know how you did that because I think there's. Sometimes it's hard to maybe create those structures on the fly as you're going really quickly.
00:26:25.130 - 00:27:04.158, Speaker D: We have lots of mini teams. It's not know. There's the ZKE EVM team that collaborates with the PSE very closely, and then there's the infra team. And then the hardware team is part of the infra team that talks very closely to them. And we try not to have teams that are across more than two time zones in order to make sure everyone has a good work life balance. We're also starting to have some kind of regional kind of city offices. So we don't have any city where there are more than three scrollers right now, but we have three in New York and we have three in San Francisco.
00:27:04.158 - 00:27:20.962, Speaker D: So we're in the process of setting up like mini kind of co work offices. And we're know, at least a New York one has proven to be a reasonable kind of hub for ZK researchers to stop by and hang out. And we're hoping to have more of these types of kind of pop up offices everywhere.
00:27:21.106 - 00:27:51.470, Speaker A: Nice ye on that research front that you're kind of more in, would you say? Like you have your inner team, the folks that are on the scroll team, but I feel like you must. I mean, I've seen you actually collaborating with lots of different groups. How does that all work? And. Yeah, I'm kind of curious. How much of the new research are you letting in? Is there a point where you have to kind of cap it and say, we can't do any more changes, we can't add any more of the cool new stuff, or do you feel like it's still very fluid?
00:27:51.550 - 00:27:52.690, Speaker E: Yeah, that's a great question.
00:27:52.760 - 00:28:00.726, Speaker A: I feel like there was two questions in there. Sorry. There was like, what's it like working with other researchers outside and inside? And then there's how are you incorporating new research?
00:28:00.828 - 00:28:48.782, Speaker E: Yeah, that makes sense. Yes. So the way we are operating on the research team is that we define some larger scopes. For example, there are Ziki research working on more efficient prover, more efficient aggregation, and we are definitely looking into new constructions. Like recently people get Nova appealed and thinking about how we can move some primitives to Nova and combine integrity in our current system. So that's on the research side, on the protocol research side, we are looking to, for example, decentralization of prover and sequencer, the mechanism design between and how we handle mev, and also how we use multi prover to include the security. And maybe eventually when ECM moved to dank sharding, we will be bottomnecked by this execution.
00:28:48.782 - 00:29:23.710, Speaker E: We are looking to evmpization and more efficient client actually, and also some resource pricing for layer two. So there are some large scopes there. We are always looking to what's a problem we are going to solve in one years or two years. So we are actively working on that. But you also mentioned there is a product going on. You always need to launch some stable version, you need audit, you need stable. So we will have multiple versions and in this recent version you have stable branch which engineers are mostly working on.
00:29:23.710 - 00:30:14.030, Speaker E: And they are looking to more stabilize and battle tested, well audited as our version one. And then in the next version we will think about how we can kind of merge those different research result into our current version, and how they can integrate with our system and what they kind of change a part we need to audit and how we kind of coordinate across different teams. So it's more like even for ECM, it has Eips, it has small changes to make that works in the next version. So we will also have versioning. And so it's like version one, it will be very stable sound and complete the KVM. But the next version might be like we make some tricks, we change the pruning algorithm a little bit and then make that even faster.
00:30:14.790 - 00:30:51.290, Speaker A: Cool. I want to talk about. So this sort of speaks also to the sharing of research, but like the competitive landscape last summer, I think at eachcc there was all the announcements of zkevms, right? It was like the week of zkevms. And I remember that at least the scroll Zkevm announcement. I think you kind of put yourselves on the stage with that. I think a lot of people didn't really know about what you were doing and I feel like this was kind of like an opener. How has that changed? Tell me a little bit about what you're seeing on the competitive landscape.
00:30:51.790 - 00:31:32.122, Speaker D: I think I would probably challenge the framing that all l two s are competing in some fundamental sense. I don't think this is a productive way to think about the space. We were never thinking about the competition when we did the initial testnet launch, and we're not thinking about it now. What has changed is that we're more and more confident with our testnet results. Our testnet with proofs have been running for a few months and we can talk more about the roadmap and what we've learned since the Paris announcement. But taking a step back, I think the fundamental view is that there are still very few users in the space. So there are like 2.5
00:31:32.122 - 00:32:43.314, Speaker D: billion monthly active users on Instagram, for example, and that's just one single app, and there are 5 billion active Internet users in the world. So I think crypto as a whole probably has about like a million active users. And even that's being very generous with what we believe to be users in terms of definition. So if we believe in a future that has potentially 1000 x users, then does it really make sense to think about competition endlessly? I think we're all just kind of in the first of nine innings. I think the real landscape is that the space to be gained is so large and the design space for infrastructure to tackle is also incredibly large. Like, the feedback we've had are from a very, very small subset of the Internet population, and whether that's real or true, and whether that's enough for a real world testing, that still can be somewhat called into question. And also another thing that's changing, that's not related to the l two space in particular, but in the wider Internet space is just that.
00:32:43.314 - 00:33:27.022, Speaker D: The definition of user and developer have been framed very differently so far. In the crypto teapot, in the crypto bubble, these two categories are framed very differently. But in the real world, every user in the world will eventually become a developer because of natural language that can be used to produce functional programmatic instructions. So the line between these two are blurring. And the number of active developers like Dapps and infrast and so on is about one hundred k in the space. And once again, that can easily double or ten x because of this particular change that's parallel to the crypto like universe. And so we don't believe we're in competition with anyone.
00:33:27.022 - 00:34:52.890, Speaker D: I think the landscape is still evolving very rapidly, and we care about our users, and we're set up for longevity and for impact, and we actually pay very little attention to what the next l two us are doing. But overall, I think having more participants in the space is very bullish for Ethereum, and it allows for more experimentation, and that's a good lesson for all of us. And I think one thing that even if there are like hundreds of roll ups when we go on the call again, is that I think amongst all the roll ups, I think legitimacy is the only thing that truly matters when you're thinking about trusting your life savings or trusting your assets or value to a network. At the end of the day, I think the sense of security and trust and legitimacy, although these are like very ambiguous terms, but what you trust a network to kind of put your life savings to, it's a very nuanced and multifaceted thing. It has a lot to do with the development strategy and the trust you can build and maintain and the systematic things you set up. And I think it ties a lot into the core values like decentralization, security, and well thought out design principles, et cetera. So I think we're in the process of figuring out what that is exactly.
00:34:53.040 - 00:35:20.850, Speaker A: I really like what you just said and the sort of focus more on the collaborative part or growing the pie instead of trying to split the pie. I still think in the space there is a competitive nature. Some teams, I think, are already at least competing on the marketing front. Do you see any benefit in that? It sounds like your strategy is to definitely focus on collaboration, but do you think it also brings a bit of attention? That might actually be good.
00:35:21.000 - 00:35:58.602, Speaker D: I think any attention to the l two space is net good for the world as a whole. I think the fact that we're seeing centralized exchanges now, issuing l two s rather than their own l ones, is a move in the positive direction. It's a sign of the wider crypto ecosystem. Adapting to the mindset that l two is the way forward, is the way for scaling. And so anything that moves people away from the alt one rotation trap, I think is a good step forward. And I think any kind of marketing in that sense is positive.
00:35:58.746 - 00:36:24.070, Speaker A: That's interesting. I have a question. I feel like the scroll project is born so deeply and within Ethereum, but have you as a team paid any attention to Cosmos or the Polkadot models like any of these other sort of networks where they have the connectivity through different ways? I mean, I know the project is very ethereum. Is there any cross pollination of ideas between those ecosystems and ethereum?
00:36:24.490 - 00:37:10.070, Speaker D: I would say I learned a lot from the Polkadot ecosystem in the sense that I think there is a culture of putting developer first, and I think that's also part of the Ethereum culture as well. And the things that made Polkadot so successful. We're also keen to kind of learn from those lessons and do the same for scroll. Just putting developer first and being steadfast and being a kind of friend on the developer to founder journey as well. From the Polkadot ecosystem, I think there's also a lot to learn. I think the lesson there is that certain projects have specific needs and sometimes they would like to share economics at the protocol level. And I think these narratives are yet to be played out.
00:37:10.070 - 00:38:05.922, Speaker D: But one thing that keeps me building in the ethereum ecosystem is that if I have to spend a day figuring out how to bridge stablecoins into any new l ones, then I'm going to give up. And I think that applies to both of these things, both of these ecosystems. That's my test on how long or whether I should kind of consider seriously spending a significant amount of time or resources on any ecosystem. So that ties into the second point. I think it's a value that we try to kind of prioritize at scroll, which is just putting developer and also user experience first and making it as accessible as possible. So hopefully the process of bridging stablecoins onto scroll will be a lot easier than you would for Polkadot. And interesting cosmos.
00:38:06.066 - 00:38:33.726, Speaker A: I kind of want to ask a bit about how you envision the scroll roll up looking. Do you actually imagine it as a single instantiation? Or could it be that there's multiples of it for different uses? I don't know if that's like a roadmap thing or if that's even something that's been thought of currently. Are you just thinking about it as like a single version, that that's where you want all of the Dapps to live?
00:38:33.828 - 00:39:11.054, Speaker E: Okay, I can talk a little bit more from the technical perspective. So I think we start with solving the problem of ECM, because ECM is congested expensive. So that's why we want to build a platform that can solve this problem. Like all the transactions, all the applications can deploy here cheaper, faster throughput and enhance the security. So that's the starting point. And I believe that layer. So imagine that in five years, because layer one will be even more expensive and all the interactions with the ECM application will be moved to layer two.
00:39:11.054 - 00:39:55.706, Speaker E: And because layer two as a network has this strong network effect for application have this dependency and how many users you have. So I think there will be like very few layer twos who will be general purpose and lying on Ethereum directly. And then there might be some other chances to kind of build their protocols on top of layer two, either at layer three or some more creative form. We don't commit to any future because even layer three is a new concept proposed by people we are not making any choice among. We have to think future is like one layer two, multiple layer threes. But we are thinking something like more creative. Maybe there are some other form can also extend our layer two.
00:39:55.706 - 00:40:47.260, Speaker E: But we believe that as a layer two we should firstly inhard all the kind of, not only from the technical perspective, we inheart the security, we are cheaper with a higher throughput, but we also want to inhale this kind of legitimacy, this branding of ECU, because all the users will interact through there too. We want to kind of keep this spirit to be the same. And then more people can build more creative stuff on top of scroll. Like cheaper, minor, but still different teams are betting on different future. But we are still looking towards a. Because also, again, many futures are like people are talking about this future, but they are handwriving about the technical details. We are thinking more in the long term that we propose something which is technically feasible and also it's good for building.
00:40:47.260 - 00:40:56.294, Speaker E: It's almost like an entire country. And then people can build their own island cities on top of scroll on top of it.
00:40:56.432 - 00:41:10.834, Speaker A: But you don't imagine deploying two scrolls. That was kind of what I'm wondering is just generally once you build the stack you could, right, like you have all the software, but I guess there's no real use case for that right now.
00:41:11.032 - 00:41:59.310, Speaker E: People can still fork our code base for fork Ziki VM and launch their new Zikirap. But again, back to the question, like when Sandy mentioned when there are hundreds of rock, including all the folks and legitimacy and the trust you build for certain layer two will be the biggest issue. Like biggest reason why people choose you. And then there will be a massive network effect why people will choose build on you. And also because we are building a Ziki VM which are general purpose Ziki ROI platform. So we are not targeting at specific use cases. So all the applications we are deploying on us, and also specifically for some defi, they need this compatibility, which means it's hard to kind of launch many app chains and having the same compatibility, same UI and ux for users.
00:41:59.310 - 00:42:15.458, Speaker E: So that's why we believe that there will be some dominant layer two with strong network effect. And then even if other people are working, they need to have their own feature, maybe tailored for specific applications. But we believe that's part of scroll family instead of something in parallel.
00:42:15.554 - 00:42:46.578, Speaker A: Got it. And that's actually sort of what I'm trying to sort of envision. This is like a very general roll up future kind of vision. But do you sort of picture these large generalized l two s being few and far between, but then smaller l two s still attached potentially to the main chain, the l one that are specialized. And then obviously on these larger l two s you could also have that l three in certain cases. But I wonder, is that sort of what you envision? Have people talked about that?
00:42:46.664 - 00:43:31.482, Speaker E: I think all the people are envisioning a similar future either like multiple layer two, multiple layer three build on top of each other. But again, I think our point is that we are still doing more technical assessment for how practical this is. And what's the interoperability, for example between layer three and what's the benefits you get from there. And so we think there might be even be some more creative format, even like not layer three, not layer two, but maybe some more creative thing like in between, to build a future. I think no one can 100% that the future look like this. But there are some reasoning behind having layer three on top of layer two. For example, imagine that if all the activities are happening on layer three, people need to deposit and withdraw.
00:43:31.482 - 00:44:02.220, Speaker E: They also want to do this cheaply on their base chain, right? If you do this, for example, if you build some special application as a layer two, and then your deposit and withdraw is also, unless you have some way to have this kind of user want to leave, put all their money on your platform. So unless you are very attractive, that user want to kind of deposit and withdraw very frequently, then most application will do this still. And if you are building on layer two, then this will be very expensive. And if you are layer two, then.
00:44:02.670 - 00:44:05.882, Speaker A: You'Re saying if you build on l one, it would be very expensive, right?
00:44:05.936 - 00:44:56.006, Speaker E: Yes. And if you are building your layer three on layer two, then your deposit and withdrawal will become much more cheaper. And also because people have the reason to put their money on layer two. But for your own application, people are just interacting and playing with that for a while and then they still need to do this interaction with the base chain very frequently, which will become problematic. Yeah. And also I think if you imagine the future to be all the applications on layer two, then it's beneficial for layer three to launch on layer two to kind of directly get the users, get the liquidities on layer two and build some featured applications. There are already been some experimental layer three deploying on scroll.
00:44:56.006 - 00:45:05.470, Speaker E: And also that's what we plan to support, like adding more verification algorithm, supporting that on our layer two to support more creative experiment.
00:45:06.930 - 00:45:18.082, Speaker A: Do you ever look into things like eigen layer or sort of the DA levels? Is that something, because that is sort of being built for the EVM, the l two s, right?
00:45:18.216 - 00:45:28.470, Speaker E: In a way, yeah. In a way that technically if you use other DA solutions, it can be cheaper in some sense. But there are still.
00:45:28.540 - 00:45:33.698, Speaker A: Oh, by the way, by DA we mean data availability. Should have said data availability da.
00:45:33.794 - 00:46:45.406, Speaker E: Okay, thanks for, so I think for us, for our own purpose, because we believe that as a layer two platform, we want to inherit all the security properties of ECM. So that's why we decided to post our data onto layer one, to maintain the same security. Because whatever the DA solution you are using, there will always be trade off. For example, if you become a validator and you restake across different platforms, there might be some risk for kind of. If one platform has some problem, then it brings some systematic security issues. So I think for us, we just want to stick to this very traditional model to inhibit all the security models and become like by definition a row up, because there are some interesting debates also around what's your definition for row up? And I think a more popular opinion is that you post your data onto ECM and let ECM decide which is your canonic chain. And so that's the reason why posting this data on chain will always bring your highly security.
00:46:45.406 - 00:47:03.220, Speaker E: And maybe for some other applications depend on scroll. They can decide by their own community, either they want to have their own DA solution or running their own sequencer. So that's another reason why people want to launch their lift suite. They want to have some kind of governance over this process.
00:47:03.750 - 00:47:32.522, Speaker A: As you describe all this, though, all I can think of is like the bridging between the different l two s. And I think when we were first talking about this, I always imagined almost like a one to one, like these little bridges. But I feel like there are newer solutions now kind of emerging. Can you talk a little bit about that? Like how you picture, do you still imagine people actually using the l one as the transaction layer, or do you actually imagine the l two s kind of speaking more to each other?
00:47:32.656 - 00:48:39.202, Speaker E: Yeah, I expect layer two speaking to each other, but I think it's almost the same hard to build bridges between different layer ones even if you are sharing the same. I think people had the impression that if you are building a bridge between two different layer ones, and that's one kind of bridge, and if you are building bridges between, like if you are sharing one layer one, you build multiple layer twos, and layer twos bridging might be easier, but in fact it's still very hard to kind of bridge between layer two. I think my prediction is that because all the transaction, all the activities will move to layer two. So that's the reason why I think bridging between layer two will be more frequent, but it's still almost the same hard to build bridges between different layer two. Because still, even if you lie, there are some ideas like where because all your state route will be posted on the same layer one. There might be some way that you can read data from state route and prove that, but it still either takes a longer time to generate proof or you don't have very great kind of atomic interoperability. So I think it's still hard.
00:48:39.202 - 00:48:45.746, Speaker E: I think it's still unexplored space, so people are still doing more experimentations there.
00:48:45.848 - 00:48:52.294, Speaker A: What about bridging? That isn't token bridging, but rather just like message passing? Because I know there's some really interesting things around that.
00:48:52.332 - 00:49:21.120, Speaker E: Yeah, I think my own prediction for this is that because arbitrary messaging is even harder than just token bridging. Because you can make your kind of token transfer, because there's more. Because you can make your token transfer become part of your arbitrary message, right? Like if you want to kind of token to another layer two, it's kind of part of your message, right? So I think it's even harder, especially if it's like a smart contract function call or whatever.
00:49:22.450 - 00:49:57.222, Speaker A: That's interesting. I want to talk a little bit about, I kind of want to revisit the ecosystem topic and the connection. Now that scroll is a standalone project with a team. It was grown out of the PSE group, or like it was connected to the Ethereum foundation and stuff like that. But what is the rapport? What's the like? Does Ethereum support anything in scroll? And then I also kind of want to ask about Xerox park if there's anything, because I know that at least in terms of the libraries, there's a lot of overlap. Are there any sort of clear collaborations between those three groups yourselves and PSE.
00:49:57.286 - 00:50:56.878, Speaker E: And Xerox park yeah, I think because part of our philosophy is developing the open source way and we are really grateful all the contributions from this community, and there are several open source collaborators we have been working with, as you mentioned, like there is PSE team, and we have been co building the Ziki VM over the same code base for nearly two years. And we derive into our layer two Ziki Vm, but we are also helping them to build ECM equivalent, the key vm for ECM. So the relationship is pure, like, we are in the same community, pushing the same. That's, that's the relationship. And we start together and we have been like long term collaboration. And I think for Xerox Park, I think we hosted many workshops around our toolings. So that's why you see a lot of overlaps and why people are reusing the same tooling, because we have done a lot of workshops with them teaching people how to write halo two circuits since early last year.
00:50:56.878 - 00:51:44.494, Speaker E: And also we gave lectures about proving cost and the key member. So it has some impact for the candidates there, why they choose this library. And I think education is definitely super important for why people are using this tooling, instead of because you just get more tutorials and more help, like when you bootstrap this. Yeah, I think our relationship is more like we believe in the same goal, we are value aligned and we believe in this open source. And so that's why we came together and sharing some educational resources and discuss. And most recently, there have been a lot of discussions about new pruning systems, like folding, supernova, paranoia, hypernova. We find something put together and then we are excited to see how far it can go.
00:51:44.494 - 00:51:53.602, Speaker E: And we also want to support this ecosystem and this community grow as much as we can, like how people are using this and how it can intervene into our system.
00:51:53.736 - 00:52:49.202, Speaker A: I personally just really love watching and seeing how these ideas are developed, like how some very compelling proving system or new research is introduced, and then you see a tutorial or someone wants to teach about it. And I think the Nova example is a great one because it was almost a year ago that Justin Drake was like he wanted to do a whiteboard session about Nova, and I didn't know what that was at all. But now you can see at least in the sort of pse Xericx park. And you guys, you see this sort of like, there's a lot of people who are really excited about it. And now you see that also spreading too. I know Ariel got Nova pilled recently and there's people who are getting introduced to these ideas and then it's interesting to watch that happen and the material that gets created. But it's also sort of interesting to see why are there proving systems that also might be really compelling, aren't quite getting the mind.
00:52:49.202 - 00:53:15.418, Speaker A: And as there are more groups popping up because I don't know if you've noticed, but there's new ZK everything. Every time, every week there's like a news EK newsletter, a new ZK event. And that's awesome. And I do wonder if we're going to see sort of these areas of research, these sort of clusters almost of shared research. I think this is one. And it's really fascinating and kind of amazing to see it in action. That was my little community take there.
00:53:15.504 - 00:53:34.702, Speaker E: Yes. I think part of our philosophy is know we want to geographically extend this Ziki community to everywhere. I think Sandy had more to say about how we build this kind of Ziki community around every corner of the world and how we spread this kind of information through education, through some other local events.
00:53:34.846 - 00:54:40.502, Speaker D: Yeah, no, I was going to add to that and say, I think any team essentially that is aligned with the open source culture and focused on public education can join part of this development process. It's not, definitely not exclusive to scroll PSE and Xerox park. And you can see a lot of amazing ZK researchers as a part of this group that are expanding, whether it's new folding schemes or Nova. But I think the starting point is that there is a critical mass of projects and researchers and engineers who subscribe to this way of thinking. And we're hoping we're one of the factors that makes this kind of philosophy more widespread amongst the wider ecosystem. So the idea that you have to build everything yourself or hold it back from other people, keep it to yourself, I think that sort of mindset is slightly outdated and we want it to be outdated for the ZK world as a whole.
00:54:40.636 - 00:55:04.558, Speaker A: Tell me a little bit about the roadmap for Scroll. I think we've done a really good job of catching us up to hear what's happened in the last year. And I think, yeah, you did tease sort of what was coming and stuff like that. But tell us a little bit about the roadmap. Where is scroll at? You said there's testnets. Is there a launch date. Are you going to be careful actually like announcing launch dates? Yeah, tell me what's up?
00:55:04.644 - 00:55:51.870, Speaker E: Yeah, I can talk more on the technical roadmap and Sandy can talk a little bit more about our ecosystem building. So on the technical side, I think currently our first priority is that we are launch manifest soon. Like everyone is talking about it soon. So the first priority is that we want to build a complete and sound the key vm with a robust infrastructure, which means test of time and battle tested by all the community members. For example, our current testnet have been like there are over 20 million transactions, it's a very large number and over 1.5 blocks and I think it run like 4 million addresses or something. A lot of people are actually playing with our testnet, so making that more robust, providing feedback.
00:55:51.870 - 00:56:28.150, Speaker E: And also we already send our circuit to the auditor. So that's our first priority, building something complete. And then next step will be decentralized approver. So the point of decentralized approver is actually different from the traditional point of decentralization, which is censorship resistant. But building a decentralized pro net actually has two biggest purpose. One is that make your network more resilient because proof needs a larger cost to run, right? Like people need to buy special hardware maybe. And if our proverb goes down then other people there will be a bunch of backup who can still generally prove for you.
00:56:28.150 - 00:57:28.710, Speaker E: And also it can incentivize people to build better and better hardware. Like if you are incentivized to run approver, you are incentivized to make that more efficient to save your own money, right? Like it can make our network this kind of finalization time on layer one proof generation time becomes smaller and the next step will be designed sequencer. So even if as a layer two, even if you are running a centralized sequencer, you still have some way to avoid kind of censorship resistance. For example, you can enforce some transaction on layer one to enforce that execution on layer two. But it's still good to have decent sequencer because there are some problem of real time censorship. Like for example, you are going to be liquidating in 1 second and then I reject you and then I will include this China king in 1 hour, which is still bad. So that's why you want to have this and also some regulation and also depends on your philosophy for how you capture mu value and what this kind of value and mechanism, how that flow to different roles.
00:57:28.710 - 00:57:33.934, Speaker E: I think that's the three biggest thing our roadmap on the technical side.
00:57:34.052 - 00:57:47.678, Speaker A: Yeah. With a very quick side question here, with a non decentralized sequencer, does that sequencer collect all the mev? Pretty much. Is it sort of like an unfair advantage to that sequencer?
00:57:47.774 - 00:57:50.162, Speaker E: Yeah, it has this power, maybe not.
00:57:50.216 - 00:57:52.306, Speaker A: All mev, but like a lot of it.
00:57:52.328 - 00:58:44.302, Speaker E: Yeah, it has power to kind of collect all the MEv fees. It depends on whether you believe this layer two will kind of operate how you define, badly or not. But yeah, currently I don't think any layer twos are purposely leveraging this unique advantage to run mev, to run some bad things. But there are also good mevs, like arbitrage to kind of make balance your price and something like that. But I think eventually all the layer twos are committed to decentralized in some sense. But it's just a very complicated design problem because you need to consider the value and how that flow. And there will be a lot more things happening, like not only decentralized pool and sequencer, but a lot more things also happening, like in our roadmap, which will happen in parallel, including some efficient client implementation.
00:58:44.302 - 00:59:52.246, Speaker E: Like for example, we will think about having multiple clients and having EVM pilotation having that more efficient. And also we want to enhance our security through multi prover. And also because EVM also evolving, we are part of this large ecosystem we need to think about like after they have for example in protocol PBS, which is short for proposal builder separation, if they have this infrastructure for conception, which is four, three, seven, and how we can engage and how we can maybe even overlap with this infrastructure. So that's a large problem, like how we can coordinate changes with EFm layer one, because one important thing which differentiates from other layer ones is that layer two can actually drive the changes of EFM layer one, because we have the same goal to scale. So that's something like we are also thinking the talking with the ECM ecosystem and talking with the thought leaders, and how we can collaborate in a more open way and generalize our research, post our research and having more open discussion, and even maybe in the future form some standards for all layer twos.
00:59:52.358 - 01:00:46.410, Speaker D: We're really excited by how much interest we've gathered in the permissionless testnet that we've been running for the last few months. As ye said, we have more than 4 million unique wallet addresses on Guerley, which I think is a meaningful number. And it's very interesting. And that there's so much interest in a testnet. And also it gives us confidence that we're processing over half a million transactions on a daily basis. It means our code base has been battle tested for about more than four months now with no critical failures, and there's still a ton of optimization to be done. But I think this is a very good basis and it gives us the confidence to start talking to protocols and ecosystem partners and gearing up for a mainet, as he has said.
01:00:46.410 - 01:01:35.340, Speaker D: So on one part, we're trying really hard to onboard all of the tooling and infrastructure providers that are existing on ethereum. So for them, the integration process should be no more than a day. There's no difference from deploying on Ethereum layer one other than RPC. So it's a very quick process, but there is a conversation to be had and we're very actively having those conversations on the other side. We've recently launched a permissionless kind of page for ecosystem projects to register themselves so that they can find each other. And where any prep work is required to collaborate, they can use that as a forum. And within the first week, we've had over 100 projects kind of submit their information through this site.
01:01:35.340 - 01:02:05.154, Speaker D: And we're in the process of thinking about how to organize it a little bit better and to provide collaboration between various protocols and just bring a little bit of transparency. And on day one, I think users will be very interested in what are the things that they could play with, what are the things they could interact with. And we're trying to build a very good kind of streamlined user experience so that traffic can be directed to whatever kind of fun rides they want to play with, so to speak.
01:02:05.272 - 01:02:06.806, Speaker A: What's the name of that website, by.
01:02:06.828 - 01:02:36.366, Speaker D: The way, so you can find it through the. I think the easiest way is to find the build with scroll handle on Twitter. It's tagged on the main Twitter account and there's a form which you could kind of go into, and then I think it's linked to the main website. And I think over the last few months we've been hosting a lot of kind of local hackathons and also local meetups and hacker houses. Yeah.
01:02:36.388 - 01:02:37.994, Speaker A: You guys were also at ZK Hacklist?
01:02:38.042 - 01:02:39.200, Speaker D: Yes, we were.
01:02:41.250 - 01:02:48.706, Speaker A: And there was a few projects built on Squirrel. I think there was a ZK, ZK roll up. This is, I guess, an l two, yes.
01:02:48.888 - 01:03:38.882, Speaker D: Privacy l three, I think using a lot of the aztec tool stack. So that's very exciting. I would say one thing that surprised me in this ecosystem building process is that there's a lot of organic ZK Dapps and ZK implementations. And I think partly that's because of our team's dna in ZK research. And so that's kind of through osmosis, inspired a lot of ZK engineers to build things that are adjacent to scroll. And also on the other side, we have a very active group of grassroots developers, and they're just hacking away and thinking of new things to be built. And there's almost like one or two games popping up every other week.
01:03:38.882 - 01:04:20.638, Speaker D: And I try to stay on top of what's happening and playing with them, but there's a lot of interesting native things that are being built and preparing for our main net launch. And also I think that there's a team that's working really hard on kind of bringing on the existing more well known protocols onto scroll. The idea is that we want Ethereum users who are familiar with certain brands and certain protocols to find things that they're familiar with and they already know how to use. So there's a sense of familiarity, and then they can also find new adventures, like new protocols to play with and new games to interact with.
01:04:20.724 - 01:04:33.842, Speaker A: Do you see gaming as one of the key spaces that you want to sort of develop in terms of like just. Yeah. Do you want more games, more blockchain games on there? Is that a focus category in terms of product?
01:04:33.896 - 01:05:07.070, Speaker D: We're building a generalized DKE EBM, so we don't have to choose. So we support everything. And the pros is that that means we offer something that's interoperable and something that can interact. If someone were to build a GameFi project on scroll, it's more interoperable with the Defi stack and vice versa. So I think that's the interesting thing. So we are seeing games as a whole. It's easier to build in a silo and it has less dependencies.
01:05:07.070 - 01:05:35.880, Speaker D: And I can see that being very popular amongst more isolated kind of devs or studios that are more organized around a single game type or processes. I think that I can see a lot of games happening organically as a platform. We're just focused on building exactly the same platform infrastructure experience as ethereum layer one, which a lot of games have been known to thrive in.
01:05:38.090 - 01:05:41.594, Speaker A: Fair. Got it. Cool.
01:05:41.712 - 01:06:04.910, Speaker D: Maybe we could talk about hardware just very quickly. I think in terms of ecosystem building, I think we're quite unique in the sense that there are more than ten hardware companies building solutions for scroll. And I think that's one example of open source collaboration that's reaped or energized the whole adjacent industry.
01:06:05.970 - 01:06:17.890, Speaker A: Well, I want to say a big thank you to both of you for coming back on. Well, ta to coming back on the show. Sandy, for joining us on the show. It was really great to get a chance to find out what's been happening in scroll this past year.
01:06:17.960 - 01:06:19.878, Speaker D: Pleasure to be here. Thanks for having us.
01:06:19.964 - 01:06:22.470, Speaker E: Yes, thanks. Nice to meet you again, Anna.
01:06:23.370 - 01:06:33.890, Speaker A: Cool. And I want to say a big thank you to the podcast team, Henrik Jonas, who's editing this episode, Rachel and Tanya. And to our listeners, thanks for listening.

00:00:00.330 - 00:00:28.594, Speaker A: So welcome. Or hello, everyone. My name is John. I'm here to talk about an introduction to modular blockchains and the modular blockchain architecture. This will be a very brief introduction, but if you haven't heard of this before, well, first of all, you've probably been living under a rock, but also there's a huge amount of writing out there over the past few months on this topic. But okay, let's start a bit about me. I'm John Adler.
00:00:28.594 - 00:01:08.980, Speaker A: I'm one of the co founders of Celestia Labs, and we are developing the Celestia blockchain. Previously to this, I was a scalability researcher at consensus, where I created the optimistic role of design paradigm. And my interests in the space are primarily focused on blockchain, scalability and especially roll up constructions of various flavors and varieties and techniques. All right, a little bit about Celestia. Celestia was previously known as laser ledger until we rebranded a few months back. And it was the first blockchain specifically designed with a modular architecture in mind. And we'll cover in a bit what this modular architecture means.
00:01:08.980 - 00:02:24.054, Speaker A: And in this modular architecture stack, Celestia is a general purpose data availability layer, which we'll also cover a bit what each of these words mean. Okay? So first of all, what is data availability before we cover what is a general purpose data availability layer? What is data availability period? And this is actually a topic that confuses a lot of people because it sounds like it could be something intuitively, but it's not. So what is it? Data availability, or unavailability, is not uniquely attributable. So you can't really say that, say some piece of data is not available because one particular party individually is at fault. You could say that a group of people potentially is at fault, but you can't really say one particular party is at fault. And there's kind of two properties that it has. So data availability, is that the claim or the property that some data has been published to the Internet? And if we assume that the Internet never forgets about interesting data, then the data will never be erased.
00:02:24.054 - 00:03:10.474, Speaker A: You could recover it later or so on, but there's no person who is responsible for storing that data. It simply hasn't been published to the Internet at some point in time. And as it's applied in consensus protocols, it's if the data has not been published, we have this nice security guarantee that a huge bond will be slashed. So there will be a penalty that can be applied. And this penalty is potentially enormous if the data has not been published and we can verify it hasn't been published. So what isn't data availability? It isn't data retrievability, and isn't data storage. So once something has been published to the Internet, we assume the Internet never forgets, and you can retrieve it even if it's very cumbersome, but we don't provide any mechanism enshrine to retrieve it.
00:03:10.474 - 00:03:57.814, Speaker A: It's also not data storage. And this is important because there's a variety of data storage protocols. Like there's, sayacoin, there's Rweave, there's filecoin, there's other variety of things. There's also timestamping protocols like alma timestamps, I don't know, there's a whole bunch of these. But these things aren't fundamentally data availability because they do not give you the guarantee that if, say, some file is not available or some piece of data is not available, there will be a huge penalty. Just as an example, let's consider file storage protocols. Not every filecoin user or every person who runs a filecoin full node downloads every single file that's available on filecoin, right? They only download some subset of files they're interested in.
00:03:57.814 - 00:05:07.898, Speaker A: If they're providing a storage, they only provide some small amount of storage that they themselves provide, but no one actually downloads all the data. That is what data availability is. Okay, now let's kind of do a case study in a hypothetical o of one blockchain, some constant cost to verify a blockchain and see why is data availability even important? Okay, so let's consider a blockchain with recursive zero knowledge proofs for state validity. So each proof attests or proves rather that some block is valid. And more importantly, if you do this recursively, that means by induction, it's building upon a valid block so the whole history is valid. If you do this with certain nice techniques, you can get it that the entire blockchain history can be verified in constant time with a single proof that proves things recursively. But there's a problem with this hypothetical construction, which is, well, what happens if, let's say, using proof of stake two thirds of validators, or if using proof of work 51% of the miners, they decide to finalize a block, but they don't reveal the data that went into creating the ZK proof.
00:05:07.898 - 00:05:48.854, Speaker A: They don't reveal the transactions for all intents and purposes. In that case, no one actually knows what the state is. So you can't produce a new block. Now, because data withholding or data unavailability isn't a uniquely attributable fault, you can't really tell or warn nodes, hey, these validators produced a block and it's unavailable because the only way to check that a block is unavailable. In the naive case, we'll cover some more advanced techniques there. But the only way in the naive case is, well, the node that has been warned of this event just has to try to download the block. And if it tries to download the block, congratulations, you don't have an o of one blockchain.
00:05:48.854 - 00:06:23.666, Speaker A: You have a blockchain that requires you to download all its blocks. So data availability is key for all blockchains. If you want a system that is fundamentally permissionless and not permissioned like channels, for instance, are permissioned. You don't need data availability for channels. But if you want a system that is permissionless that anyone can enter or leave at any time, and that provides the guarantees of decentralized blockchain, you need all the block data that goes into the state. Essentially all the state transitions need to be available. How can we do with this without downloading all the bluffs? Because that's a naive technique.
00:06:23.666 - 00:07:08.900, Speaker A: It's not exactly very good. There's a paper on this fraud and data availability proofs. It was co authored by Mustaf Al Basam, one of my co founders at Celestial Labs and also Vitaliputerin back a few years ago. It essentially uses erasure coding and random sampling. Razor coding is used in error correction and so on quite often. And random sampling essentially allows you to instead of trying to download the whole block, you download specific chunks of the block, and then you use this erasure coding to try and error correct or to try and reconstruct the entire block. So it transforms a problem of having to download an entire block to having to randomly sample some constant number of shares or little pieces here in the square.
00:07:08.900 - 00:07:47.346, Speaker A: And it's secure under an honest minority assumption, which means you don't need, say, two thirds of validators, to be honest, to always commit to a valid block for the scheme to work, because that would kind of defeat the purpose. This scheme is secure if you have like a handful, a few dozen, maybe a few hundred nodes. Not validators, but a few hundred nodes in the system that are performing these checks. And most importantly, it requires sublinear work with respect to the block size as opposed to linear work. So if the block is, let's say, 10,000 bytes, it would only require 100 on the order of 100 bytes, as opposed to all 10,000. So this is sublinear in particular. The cost is the square root of the block size.
00:07:47.346 - 00:08:23.846, Speaker A: So it's a very powerful scaling technique. We know what data availability is. What is a data availability layer? It's a blockchain that only orders data and makes it available. It does not execute this data. And for how this works intuitively, we actually go back to the original Bitcoin design paper by Satoshi Nakamoto where he says right here in the first page, I think no, maybe the first page. Maybe the second page. Very early on in the paper, he describes how to solve the double spending problem, which is we need a way for the payee to know that the previous owners did not sign any earlier transactions.
00:08:23.846 - 00:09:06.166, Speaker A: We need to see there's no double spending for our purposes. The earlier transaction is the one that counts, so we don't care about later attempts to double spend. The only way to confirm the absence of a transaction is to be aware of all transactions. So this is where Bitcoin's implementation is an artifact, or sorry, the way people currently do blockchains, where they tie together execution and data availability into one layer, is an artifact of Bitcoin's implementation. But what Satoshi here describes is actually the minimum requirement to solve the double spending problem, which is you just need to know all the transactions take the first one, ignore the rest. He describes it right here, plainly. Bitcoin, however, does not tell you all the transactions.
00:09:06.166 - 00:09:33.854, Speaker A: It only tells you all the valid transactions. So it doesn't do this. Bitcoin actually does not allow future attempts at double spending into the Bitcoin blockchain. They're invalid transactions. But even if they were in a hypothetical blockchain, like Bitcoin, users could just run a note and discard those transactions even if they were invalid. And this is the fundamental thing that a data availability layer does. It allows data in without executing it so that data could be invalid.
00:09:33.854 - 00:10:11.034, Speaker A: It doesn't care. And the nice thing about this is that blocks are valid if and only if they are available. Since there's no execution here, there's no state root or anything. And we just saw in the previous slide, you can verify the availability of a block with sublinear work as opposed to linear work. And even zero knowledge proofs do not give you this property, right? A zero knowledge proof, like we saw in the example before, you still have to download, in the worst case, all the blocks. So, I mean, this can be combined with zero knowledge proof so that the execution on top of a data layer can be made cheaper. But you still need a data layer.
00:10:11.034 - 00:10:43.254, Speaker A: You cannot have a blockchain without this and have that blockchain be permissionless. Now, what is the general purpose data layer? How does it interact with this thing notion of sovereign roll ups? Roll ups, as Zaki just said not too long ago and wait, I tweeted about jokingly. Roll ups are just blockchains. They're blockchains like any other. They need a data availability solution and roll ups on Ethereum, roll ups on a world computer. A lot of people think that's the only way to have roll ups. And they have certain restrictions, but they don't.
00:10:43.254 - 00:11:19.314, Speaker A: Roll ups have certain properties, but there's a lot of things in the design space that don't have to be the way they are in Ethereum. And on Ethereum, you implement a roll up with a smart contract bridge and this roll up cannot. The logic execution of the roll up and its consensus rules can't be upgraded without a multisig or an on chain vote. So there's no soft fork, there's no hard fork. You have to do something like an on chain vote and that could potentially be captured by plutocracy. Roll ups on Celestia are different. You can have a native bridge where the logic to verify a zero knowledge proof or the logic to do a fraud proof, for instance, is done natively.
00:11:19.314 - 00:12:06.466, Speaker A: You have native rust code, go code, whatever you use to code your node. And that is the thing that adjudicates, that is the thing that verifies that the execution was done correctly. And you can upgrade these roll ups with soft and hard forks without affecting the data availability layer. So this is where the notion of sovereignty comes in this ability to hard fork without requiring permission, without requiring patocracy, where users can go just the node runners can go overrule rich whales, they can overrule them and do whatever they want to the chain. And this is fundamentally what all layer, one blockchains give you. And this is what cosmo zones give you. The reason Cosmos owns the sovereign is because you can hard fork them without having to hard fork every other zone simultaneously because they're not in a world computer model.
00:12:06.466 - 00:12:39.866, Speaker A: But if you took a Cosmos zone and posted this data on top of Celestia, you could get shared security. So this is what you get. The good thing you get out of Sharding, but without all the complexity of Sharding and these zones will still remain sovereign because there would be a roll up on top of Celestia. And this gives you certain things like IBC without an honest majority assumption, which is very powerful. Okay? So to stay up to date, here are some links. So first one's me. The second one is the Celestia Labs official Twitter account, then our website, and finally a GitHub organization.
00:12:39.866 - 00:13:33.780, Speaker A: All our code is free and open source. Both the Celestia full node, various data availability, sampling libraries and oracle tree libraries and so on. It's all available on GitHub. Okay, so I see one question, which I guess I'll try to answer, but then not go over time too much. Can you explain why a DA layer makes data available, but a DA layer does not make data retrieval? Okay, so a DA layer, what will provide you is there will be an attestation by two thirds of validators, potentially billions of dollars of stake that this data is available. You can then go and perform data availability, sampling and verify yourself. And everyone in the world can do this for very cheaply to see is this data available or not? And if it's not available, you and everyone else in the world can get together and a hard fork to slash those Validators and potentially burn billions of dollars.
00:13:33.780 - 00:14:22.990, Speaker A: But outside of this, the validators themselves and the nodes in the network do not provide any guarantees that you can go, for instance, to this particular Validator and say, give me this block in its entirety. They might serve you individual shares, they might serve those requests, but there's no guarantee that you can go to any particular node and say, give me the entire block in its entirety and I'll give it to you. If that makes sense. Yeah, I think it does make sense. It's it's a, it's a super subtle it's a super subtle topic. So we there's, you know, there's there's definitely more room for discussing this particular topic, you know, at a later time. But it's, it's a very subtle, it's a very subtle and non obvious topic.
00:14:22.990 - 00:14:29.180, Speaker A: Well, maybe it can be discussed a bit further in the panel that's coming up just now.

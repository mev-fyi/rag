00:00:07.210 - 00:00:57.886, Speaker A: Now we're going to learn a little bit about fuzzy knowledge, which is fuzzing snark circuit primitives by inokenty from aztec. Right. All right, let's do it. So, yeah, hi, my name is Nakensei, I work at Adstack, and I'm going to be talking about how we added fuzzing to our circuits so that they became a little bit more secure. Before I start, I'd like to thank Jirov Rankin for helping me with this project. So, to start with, let's look at what security of circuits is. To me it's like this hellish tower of complexity which can tumble from the smallest touch.
00:00:57.886 - 00:01:52.830, Speaker A: At the bottom we have the basic base field primitives, which for example in our code base are implemented with Montgomery. Then on top of that we have all kinds of stuff, such as elliptic curves, multiscale multiplication, ffts. On top of that we have scalar fields where we actually start implementing the circuit logic with various gates. For example, we use plunkish arithmetization, obviously. And on top of the gates we can finally build some of the basic primitives which the application developers that are using our systems to create final proofs will actually use. So this whole tower complexity, very easy to break one thing. And if you break even one small thing, then you can disrupt the correctness of the whole agreement, the whole proving system.
00:01:52.830 - 00:02:38.590, Speaker A: So let's see what we can do with circuit security. So one of the traditional ways to kind of COVID the security is to do unit tests. It's the most basic thing, you should always do it. For example, our code base is simply covered with them, and they do ensure that you do just the most basic security. It means that your circuits will not suddenly fail on the most basic of functions. So for example, you know that addition works the way you intended, that no new changes to the code base, especially if you are actively developing on top of it, no new changes actually break all of the old stuff. So yes, it's a nice place to start.
00:02:38.590 - 00:03:12.060, Speaker A: Obviously not enough. Then we have the end to end tests, which kind of help you cover the base, that the whole system works as intended, at least for the thing when you are trying to ship. So for example, we added it to our code base when I understood that, yeah, unit tests are definitely not enough. Sometimes there are still small things that fail. So an answer tests help you see that what you are deploying is actually working. But then we actually want to improve on the security. We don't simply want to check that our code base is working.
00:03:12.060 - 00:04:21.086, Speaker A: So the first thing that most people do is, and internal audits, that means that either the person who implemented the classes, implemented the code base, or somebody else, for example, somebody who wrote similar primitive, different part of the code base, comes and looks into what you've developed, suffers a lot, takes a lot of time to look into this stuff, but kind of holistically checks that there are no strange assumptions, no weirdness that another person implemented. And usually it is quite an in depth check, but obviously this never covers anything. So what do we do? We go to external auditors. And one of the issues is that with external auditors, you always have a very limited time frame, which means that even the best teams, of which. Well, there are some, but I think there are more projects than there are auditing teams that can actually check those projects nowadays. So those teams have only a very limited time. So they can look at a small primitive and maybe ensure that it's correct.
00:04:21.086 - 00:04:54.506, Speaker A: But that's the limit of it. Obviously, they can't cover the whole code base, especially such a huge one as our Bressenberg library. So even after all this, the thing that we have is this, which is not enough. We simply like to check our code base even more, especially the core primitives that we're using. So for example, we have several core circuit primitives which are very important to us. So what do we do in this case? Well, we need something automatic. That's a very important thing.
00:04:54.506 - 00:05:39.910, Speaker A: We can't simply delegate to various auditors, internal or external, because that means that we spend more and more time on human resources. Our code base grows. We need to spend even more. And any small change to any part of this code base after the audit can completely just write away all the money that we spent before that, because a new buck is going to be introduced. And now all of those checks are useless. So what do we do? Well, in the last ten years, apart from the ZK Cambrian blow up, there has also been a cambrian explosion in gray box fuzzing. So you can look at it this way.
00:05:39.910 - 00:06:23.750, Speaker A: Originally you have this very simple way of testing, which is called a unit test. We are testing a very small primitive. We're checking that it simply works. Then we have black box fuzzing, which we'll go into detail a bit later. But the idea is you stress test a small part of your code base, you do a lot of computation on it with different random data to check that it is operating correctly. And what you do next is, at least to me, when I started learning a bit more about it seemed like magic, because now you have some sort of algorithm that learns itself, what it should research and how it should test your code base. So let's start with the basic black box fuzzing harness to see how the system actually works.
00:06:23.750 - 00:07:06.040, Speaker A: So let's say we have this very small program which simply checks that a particular string is being encountered in an input. If a particular string is being encountered, then it triggers an abort. So this would be something like a bug in our code base. Basic black box fuzzer would fuzz this function in a very simple way. It would generate some random data. For example, we are taking this random data from the system randomness. Or if we are more efficient, we are using pseudorandom number generator, and then we are sending this new created input data to the program under test this function.
00:07:06.040 - 00:07:52.654, Speaker A: Then we see if this has triggered some sort of bug in the function. And obviously if we've triggered the bug, we found something new great for the fuzzer. If not, we go on to the next iteration and we continue doing this. The problem with this approach, with the black box fuzzing approach is that especially for this letter like style of code, however good your generator is, there's always a very low probability of the black box fuzzer reaching somewhere deep inside your code base. Like for example, with this function, the first step takes around one divided by 256 probability. The next one is even less than that. It's one divided by two to the power of 16.
00:07:52.654 - 00:08:24.686, Speaker A: And so it continues. So if you had eight steps in this code, then you'd never reach them on a single core, on a single machine in your lifetime. It would simply be impossible. So obviously this has a serious drawback. So what do we do? Well, with gray box fuzzing, there's a small change. Instead of simply generating the inputs to the function, we now use mutation. So let's say we start with no information about the process and about the program.
00:08:24.686 - 00:08:53.766, Speaker A: Initially, we have what's called an empty corpus, and the corpus is just a collection of interesting test cases for us. We take something from this corpus. Right now, it's just a simple zero length test case, zero length input. We mutate it. So that means that we are changing it such ways that at least some part of the original test case of the original input is left. So it doesn't completely generate something in you. It updates something that was before.
00:08:53.766 - 00:09:41.334, Speaker A: Then we send it to the program under test, and this mutated test case operates just as any other input would. Then if a bug is triggered, we do just as in the black box. Further we just output the bug. Finally, we've found something. If not, then instead of just repeating the loop like we did before, we send the coverage data for analysis. And coverage data here means that either we collect the information about various branches being taken, or maybe various comparisons being taken, then we look if any particular branch on this new execution has never been taken before. So for example, in this case, if we are starting from scratch, we see that, oh, the first if has actually been passed through.
00:09:41.334 - 00:10:34.166, Speaker A: So we found a test case that starts with an a, and we save that test case. So now we've actually changed our probability distribution, because in our corpus we have a new test case which has already found the first symbol. So to find the next one. Now if we pick this test case from the corpus would have the probability that originally for the black box father and for this father was to find the first symbol a. So we continue like this, and after several steps we trigger the abort. So the basic info is we have an algorithm that remembers where it stepped. If it steps somewhere new, it also remembers that, and then it tries all of those different test cases that it found and updates them instead of just forgetting about them and running along with something new.
00:10:34.166 - 00:11:26.822, Speaker A: And this is a very powerful technique. Since 2014, when AFL american fuzzy lob was published, it was kind of the first open source. I'm not sure about 100% that it was the first, but it was the most popularized at the time, Fuzzer, that used this mechanic with coverage. There has been just an explosion in various vulnerabilities found in open source projects. Just because people started using this technique and applying it everywhere to each project that there was. Now, about the primitives, I'd like to introduce Bigfield as an example of a primitive that we'd really like to fuzz. So today on this stage, there has already been a talk about this field arithmetics that is non native to the scalar field that we are operating on.
00:11:26.822 - 00:12:20.170, Speaker A: It is a big headache for us, at least it has been for some time. And though we're using it kind of in a different way to Mina, we're using it for the roll up. The base principles are the same, so we are trying to emulate this base field element on top of scalar field. For that we need actually five elements. That's because we're using the CRT's formulas, which I'm not going to go into detail here about, but we're using one scalar field just for the scalar field modulus, and four for two to the power of 272 modulus we also have tracking units which are used to optimize constraints in our circuits. Because if we just do it straightforward in our code base, without trying to optimize this a lot along the way, it will just cause an explosion in the number of gates. So we need to optimize this quite a lot.
00:12:20.170 - 00:12:52.546, Speaker A: So yeah, constant source of headaches, tons of bugs found at various stages there. So how do we bigfield? Well, let's start with a simple stupid black box fuzzer. Let's pick a function. For example, here we see a basic addition function. We take two random elements, convert them to the big field elements, add them and check by creating the proof and verifying it seems pretty straightforward. So this is the simplest thing you can do. This is something that you can start with.
00:12:52.546 - 00:13:31.450, Speaker A: You just run this function in a loop, and you have a basic black box father. But obviously there's lots of room for optimization. The first thing is, well, creating the whole proof each time you want to check a simple circuit primitives is way too much effort. So, for example, if we were to use the plunk proven system, it would mean that we'd have to commit to stuff. So that's multiscaler multiplication. Then we'd also have to spend a lot of time on ffts. We'd have to do fiat shimir to just check a few, like maybe less than a hundred gates.
00:13:31.450 - 00:14:10.026, Speaker A: Well, in plonk, maybe a thousand. But yeah, that's just a lot of effort to check a very simple primitive. So instead of that, we do the simulation. In our case, it's just going through various gates, looking up the values of variable, substituting the witness values there, and checking that all of the gates hold concretely for our witness. Having done that, we've already increased the speed of our fuzzing a lot. I think when we did this, the speed went up by a factor of 100. So what do we do next? In our c plus plus code base, we use the function LvM fuzzer test.
00:14:10.026 - 00:14:39.294, Speaker A: One input, which is something that's provided by clang. There's this very nice library, lip fuzzer. It is very simple to add fuzzing to your project. If you are doing rust. There's lipfossesys cargo package, which basically does the same thing. So you can do absolutely the same stuff. So what we do here is we receive some data from the Lipfazer backend.
00:14:39.294 - 00:15:32.066, Speaker A: So our fuzzer is already supplying to us mutated data. This way, we check that the size of the buffer is enough for us to take two elements in the base field. We deserialize them into the base field elements, set big field elements from that, and after that, we add the values, check the circuit. Also, one of the nice features of the fuzzer is that you can simply return minus one if there's some sort of problem on which you want to trigger the fuzzer to say, okay, some assumption has been broken, something's bad here, and you simply return zero if there are no issues. So that's already pretty good. Now, we've added very simple gray box fuzzing to our code base. We are checking.
00:15:32.066 - 00:16:10.002, Speaker A: It automatically creates coverage. So the only thing is you have to compile with particular flags. Now you have coverage. Now you have an automatic fuzzer that checks that your circuit is correct and goes through all the various stages to look for the correctness of a very simple function in your circuit. So what's next? Well, there's this concept of oracle in gray box fuzzing. It's quite different from the oracles that we encounter in crypto. The basic idea is this, you have some sort of security policy you'd like to adhere to.
00:16:10.002 - 00:16:58.470, Speaker A: For example, in binary fuzzing, you'd like to check that you haven't read any uninitialized memory or you don't have any undefined behavior. Once again, I know for rust people, it's not as important, but for us, it is. So there are these oracles, but we can also add cryptographic oracles and oracles specific to our code base. So in this particular case, we not only check that the circuit holds, but also that the value produced during this simulation is also the correct value. So we choose to check that the value produced in the big field class is the same as the base field element. That is also done through the summation of the original elements. So now we have already gray box fuzzing.
00:16:58.470 - 00:17:39.854, Speaker A: We have a simple oracle. This is probably the most you can do with one function by just using Lipfaza. But one of the problems with Lipfaza and one of these greatest features for binary mutation is that Lipfaza has very binary specific mutations. So there are three classes of mutations in Lipfaza. On the left here, we can see the individual value mutations. So, for example, when you take a particular test case, in this case, it's coffee, that's one of the few words you can write in hacks. So there are several things that you can do.
00:17:39.854 - 00:18:17.818, Speaker A: One, you can flip a single bit. In the test case, you can flip a sequence of bytes. You can substitute a particular one, two, four byte chunk by special value. For example, there are values like Oxff or values like ox two, which are special because there are lots of constants like that. Because there are lots of underflows that can happen like that. Then you can also treat some part of the test case as a uint of size four. You can do small additions and small additions and subtractions on that.
00:18:17.818 - 00:19:05.402, Speaker A: And that's basically what the value mutations are. Then you can also do structure mutations on the test case. You can insert bytes, you can duplicate bytes, you can shuffle some bytes in the test case. And the final and one of the most important mutations in Lipfazer is splicing, where you take two test cases, and you start picking sequences of bytes from one of them and from the other. So you're kind of mixing them in together. This is done so that you can take features from both of them and maybe find some new code paths inside a class by getting information from some other code path. So this is very powerful, but this is not very efficient for the cases that we are talking about.
00:19:05.402 - 00:19:46.246, Speaker A: So we are working in field elements, so we want field elements. So one of the first things we did was introduce specialized mutations. And here there are several things that we can do. The first one is we treat the values as field elements. Then, depending then we choose whether we want to treat them as something that needs be converted to Montgomery form first or not. The point here is, a lot of the time when we are doing this fuzzing stuff, we do comparisons somewhere in between. Libfuzza can do that.
00:19:46.246 - 00:20:32.834, Speaker A: So, for example, it can look at these comparisons somewhere in the code and check, oh, this is a nice value. If I can substitute this value somewhere in the test case, then I will probably pass this if statement, and that's really powerful. But not when you have Montgomery form in your code base, when you have some sort of form, which is very nice for addition multiplication, very nice for actual arithmetic, but that is not the actual value that you are outputting, not the actual value that is present in the test case. So, to use this powerful feature, like half of the time when we are mutating a particular field element, we first convert it to Montgomery. Then we apply the mutation. Then we convert it back to plain to save it in a test case. And then we have three choices.
00:20:32.834 - 00:21:16.966, Speaker A: One is to delegate, to lift fuzzy mutations, to use those powerful features. The second is to use additions and subtractions with small values, but modular our base field prime, because we know that the arithmetic is different here. And the final one is to substitute special values, but special values that are special for the base field, because obviously they are different from the binary ones. So here, these are various roots of unity to the scalar field that we are working on, because that is a very special value that can also break some stuff. So just various special values. And, yeah, then we either convert back to the plain form or continue. And this already has produced some very.
00:21:16.966 - 00:22:14.722, Speaker A: So this already produces some very powerful mutations. We apply several of them at the time. So both in lip fuzzer and in special mutations, not just one mutation is applied every time there are several mutations, usually applied in a sequence. So, for example, in the fuzzer, it's five. So now we have a very specialized fuzzer, which for one function, we have an oracle, we have coverage, and we have specialized mutations, and now there's really nothing that we can do for just one function. So what did we do next? Well, one of the problems with Bigfield is that it has an internal state. So that means that if we take two values of our base field and we construct a bigfield element from them, we might never reach some of the internal states in Bigfield by just doing one addition.
00:22:14.722 - 00:23:40.082, Speaker A: So obviously, we are not checking for all the cases, all the problems that could arise there. So the next thing that we have to do is basically substitute this one function, fuzzing with fuzzing the whole system of the big field. So instead of fuzzing just two field elements, which you see on the right, we create this instruction vector, and the instructions there are pretty simple. So we can store a witness or a constant value in big field to a particular stack that we are using just as an intermediate. So, for example, here the stack is of four elements, and then we have different, basically all the various methods and operators that we have in the big field class, multiplication, addition, division, assertions that something is equal to a different value. And by using this instruction vector, we are basically manipulating the different interactions that can happen within the big field class between all the different methods that can happen. So, for example, here on this slide, we see an instruction vector where we first store a witness into the 0th position, store a constant in the first, multiply them together, store the result into the second position on the stack, add the results from the zero and the second, and store it back to the second, and then divide the second position by itself and store it in the third.
00:23:40.082 - 00:24:31.150, Speaker A: So just using this instruction vector and mutating it, we can explore all the various different states that can happen in Bigfield and at the same time coverage. And Lipfazer is guiding us. So obviously, mutating it is a bit different to mutating just the big field element. So what we have to do here is once again reintroduce value structure and splicing mutation. The splicing mutation works in the same way, only it operates on instructions instead of bytes. So for example, you take the first instruction from one test case and the first instruction for the other. You can just go like checkers, you can take different sequences with the value mutations.
00:24:31.150 - 00:25:21.010, Speaker A: We mutate either a particular index on the stack that an instruction is taking inputs and outputs into. So for example, we can substitute the index from zero to one. If it's a storing instruction, then we can change the value from witness to a constant and back, or change the value and there we delegate the value, changing to the thing that we saw before, that the way we mutate the field elements. And with structural mutations, yes, they're kind of the same. We can swap two different instructions together. In the test case, we can duplicate instructions, delete instructions, and this way we are exploring everything that can happen in Bigfield. Obviously, it's not formal verification, but it is very efficient in practice.
00:25:21.010 - 00:26:36.700, Speaker A: So yeah, one of the last things is we have to update the bug oracle, because we don't just have one function here. Because in the big field, we are tracking the maximum value of limbs, because we are tracking the maximum value of the whole bigfield element. And since we are checking that the value of the big field is equal to the value of the base, these are the checks that we're implementing that no limbs ever overflow the maximum value, that there are no overflows to the whole maximum value, and that it's always equal to what we're actually trying to simulate. Apart from that, one of the things that we introduced is a random seed instruction. So apart from storing and all the instructions in the various methods, this is a very simple instruction that allows us to cycle through various constructors through Bigfield. There are various ways to initialize a bigfield element. This allows us by changing one value, to switch between them so that we can holistically check all the states.
00:26:36.700 - 00:27:26.534, Speaker A: Then we also implemented instruction weights at some point, because multiplication is obviously much harder than addition. And we don't want to use tons of multiplications at once because it will degrade the speed of the fuzzer. And one of the cool features that we used in LipfAza is the length control. Because if you limit the size of the length of the instruction vector initially and you allow it to grow slowly instead of just quickly explode. It means that your father has more time to explore individual cases before it degrades speed and reaches more complex situations before going through all the easier ones. And I'd like to finish with what kind of bugs we found with this. So, even though we had an audit for our base arithmetic before that, we found actually Montgomery squaring bugs.
00:27:26.534 - 00:28:15.522, Speaker A: That's why it was that plank in the beginning, that's why it was that problem. We actually saw that our basic big field formula is not always correct. We found a case where it was broken. It was a very low probability edge case, like astronomically improbable, but somebody with a particular mindset could have used it for something bad. Then some of the infield assertions have been broken. We had several range constraint overflows, sackfolds, because our code base is in C and Winston, constant inconsistencies. So this is a case where a lot of the time, when we are building circuits, we are writing the circuit primitives for a very particular use case, and we are not checking that the witness and constant stuff is actually 100% identical in logic.
00:28:15.522 - 00:28:32.700, Speaker A: So, because here we are cycling through whether values are witness or constant, we are kind of ensuring that they are identical in logic. So, yeah, and that's it. Thank you for listening to me close.

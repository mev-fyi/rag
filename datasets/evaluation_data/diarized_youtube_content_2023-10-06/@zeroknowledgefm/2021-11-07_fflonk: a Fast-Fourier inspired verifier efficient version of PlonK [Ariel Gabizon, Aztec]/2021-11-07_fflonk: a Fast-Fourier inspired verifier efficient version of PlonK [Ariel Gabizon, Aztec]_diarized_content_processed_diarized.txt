00:00:03.920 - 00:00:04.548, Speaker A: Hello, everyone.
00:00:04.634 - 00:00:31.950, Speaker B: Welcome to this week's edition of ZK Study club. This week we're really excited to welcome back Ariel Gabazon, who's going to be presenting his work on fflanc. I'm not actually sure what's the canonical way to say it, but I'll maybe let Ariel say it in a minute. But anyway, he's here to present new work on opening many polynomials using the fast furrier equation, work that he co authored with Zach williamson. So again, really happy to have you here and Ariel, over to you.
00:00:32.800 - 00:00:38.030, Speaker A: Thanks. Yeah, I guess just flonk is fine.
00:00:39.460 - 00:00:41.264, Speaker B: I probably should have asked about that, but.
00:00:41.302 - 00:00:53.830, Speaker A: Yeah. Flunk. No, it's long f. Okay, I guess slightly long f. Yeah. Flonk. Yeah, it doesn't matter too much.
00:00:53.830 - 00:01:27.740, Speaker A: Yeah. So thanks for coming. These slides are pretty fresh from the oven, so if there are no very embarrassing type, God exists. Yeah. So to get started, wait, I got. Oh, and by the way, please, if you have questions, please just ask with your voice, because it's always hard on zoom to find chat, and then you find it. It's not a question, it's just a discussion.
00:01:27.740 - 00:02:08.990, Speaker A: Please, if you have a question, please just ask. Right. Let me just move these zoom controls out of the way. All right. So yeah, the motivation for our work on this was basically save gas on ethereum. So the recent snarks we have, which are what people called polynomial IOP based several papers kind of made almost equivalent terms. We called it polynomial protocol in plonk, but polynomial IoP is what people have been using.
00:02:08.990 - 00:03:00.856, Speaker A: So basically the verification cost is usually two pairings and some number t of scalar multiplications. Now how expensive, say, on ethereum is a g one scalar multiplication? Well, it's 6000 gas. That's roughly $5 right now. So say you have some L2 and you're doing some proof on the main chain every half hour. So that's going to be like $77,000 per year per scalar multiplication. So this is what gives motivation to minimize. Here's someone Zach just joined.
00:03:00.856 - 00:03:47.032, Speaker A: Sorry. No problem. Good to have you here. That's going to be roughly $77,000 per scalar multiplication per year if you want to do a proof every half hour. So this gives a lot of motivation to really bring this number down. And the bottom line of our work for plonk is that this number of scalar multiplication goes down from 16 to five with the cost of tripling prover time. So this is really good for the sort of, if you're doing some recursive proof with many layers.
00:03:47.032 - 00:04:38.252, Speaker A: This is really good for that final layer of what goes on chain. All right, so, yeah, please ask questions, because I'm going to assume some level of familiarity here. So please interrupt me with questions. But as we know, snark verification in these polynomial to opening a polynomial commitment scheme. So that's what we're going to concentrate on. And, yeah, let me just give a reminder on the KZG polynomial commitment scheme that we all know and love. Commitment scheme, probably for the 50th time, for most of you.
00:04:38.252 - 00:05:48.640, Speaker A: So the prover sends some short commitment to a polynomial. Later, the verifier chooses some value s in the field, and then the prover sends the value f of s. Or sometimes we can think of that value being known in advance or being sent before. It doesn't matter too much. But then the important thing is that the prover sends a proof that really, yes, z is f of s were the f I had in mind during commitment time. I'm not changing my polynomial after you chose s. And of course, the really cool thing about KZG is that it gives us polynomial commitment schemes where these commitments and openings are only 32 bytes, or if you're more number fields, you've paranoid, maybe 48 bytes.
00:05:48.640 - 00:07:10.234, Speaker A: So let's really quickly remind ourselves what the KZG scheme looks like. And, yeah, let's just use this notation that x in brackets is just x times g for some public randomly chosen generator g of an elliptic curve group, or like the g one, the first source group of some elliptic curve with a pairing. Right? So with this notation, let's quickly remind ourselves of KZG. So we have some setup where for a secret x, we have the encodings of the powers of x. And now what is the commitment to a polynomial f? It is just the encoding of f at this secret x. And of course, the point is that since this is just going to be a linear combination of Srf elements, so we can compute this without knowing x just from what we got from the setup. And right in the opening, this is the main part.
00:07:10.234 - 00:08:08.938, Speaker A: So how do I want to prove that? What is the correct value f of s? So, right. And the important point, this divisibility thing that we're using all over the place, that we'll suppose if I look at the polynomial f of x minus f of s. So obviously this polynomial is going to be zero at s, and therefore it's going to be divisible by x minus s. So therefore, this rational expression f of x minus f of s divided by x minus s. It's not just a rational function, it's an actual polynomial. The prover can compute it. This will be the opening proof, right.
00:08:08.938 - 00:09:04.674, Speaker A: The encoding of this polynomial, h. And now. Well, so how does the verification work? Say I want to check that z is really f of s. So basically, I'm just using the pairing to check that really h is of this form, which will correspond to. Is the commitment minus z encoded? Is it the same as the pairing of PI and the encoding of x minus s? Right. This is this pairing thing, right? It's just checking that, really, if I multiply the denominator in this equation, I defined x that really f of x minus f of s is equal to h of x times x minus s. Right.
00:09:04.674 - 00:09:25.960, Speaker A: So this is the KzG scheme. And using this algebraic group model that makes our life very easy, we can actually prove this is sound. And the prover can't cheat if z is not f of. So, everything good so far?
00:09:29.690 - 00:09:41.998, Speaker B: Yeah, this is great. So, Ariel, just one quick note. There's a couple spots where you're cutting out a little bit. It's only happened a couple of times, but I just wanted to give you a heads up on that. I'll let you know if it gets too much worse, but I think we're fine to continue.
00:09:42.164 - 00:09:49.440, Speaker A: Yeah, let me know. So I'm in this room where it's quieter, but maybe the Internet. Yeah.
00:09:53.730 - 00:09:57.330, Speaker B: If it becomes problematic, I will let you know, but I think it's probably fine for now.
00:09:57.400 - 00:10:18.874, Speaker A: All right. I can move to a room where the Internet is better, but there's like a. Actually, let me move. There's like a 5% chance it'll be noisier, but let me just move. Okay, cool. Yeah, I see the bars going up, so that's probably a good sign.
00:10:18.992 - 00:10:29.100, Speaker B: The future viewers of this YouTube video will thank you. So when you're explaining the key thing of the flanck scheme, they're going to be like, I missed it.
00:10:30.190 - 00:10:35.100, Speaker A: Thanks. The crucial point is that.
00:10:35.470 - 00:10:40.846, Speaker B: Yeah, exactly. All right. It sounds a lot better.
00:10:41.028 - 00:11:25.040, Speaker A: Yeah, I see all the bars now. Okay. Right. So, all right, so that was a basic KZG scheme. And now what makes us have a lot of scalar multiplications in these snarks? It usually has to do with the fact that we're not just opening one polynomial, we're opening many polynomials. So let's now look a little at this problem of opening many polynomials for simplicity, just all at the same point. S for this talk.
00:11:25.040 - 00:12:29.730, Speaker A: So we're thinking of a scenario where we have now these polynomials f zero to f, d minus one. And we have the alleged evaluations, z zero to z, d minus one. And now the verifier has commitments to these polynomials and wants to check that all these z's are. So what is the naive solution? Well, let's just use this KCG scheme for each fi. And what will be the cost of that? Well, we're going to have a proof of length d, because every polynomial will have some opening proof, and we're going to have d pairings to check these proofs. Or I guess, 100% naive thing. It'll be 2d pairings, because each KZG check is two pairings.
00:12:29.730 - 00:13:54.750, Speaker A: Right? So that's a super naive thing. And the less naive thing that has been used a lot in these last few years is this following scheme for batch opening. So here the verifier will send some random gamma, and now the prover will compute this random combination of the polynomials. So f is now the polynomial, that is some gamma to the I fi. And now the point is the verifier can independently compute a commitment to f, right, because KZG is additive as similarly as some gamma to the icmI. Now the proven verifier can run kzg just once to check if f of s is equal to z for z. That is the analogous random combination some gamma to the I zi.
00:13:54.750 - 00:14:53.520, Speaker A: And you can easily prove in the algebraic group model that if any of these values, zi was not the correct value, then the verifier will reject with very high probability. And now, again, in our context, the main question is, well, what is the verifier cost here? And the verifier cost here is d minus one scalar multiplications. Why? Because in this phase of computing, the commitment to f, the verifier needs to take this random combination of the commitments and the fis. Is that clear so far? Any questions?
00:15:04.130 - 00:15:08.786, Speaker B: By the way, I'll be watching the chat and I'll vocalize anything that comes through. But yeah, I think everyone's good so far.
00:15:08.968 - 00:15:47.840, Speaker A: Okay, great. Yeah. Like I said, I personally prefer just audio questions, unless that interferes with a recording too much. Yeah, okay. Yeah, please feel free to just ask. Anyway, the punchline of this work is that we can get rid of this d. We can get, or more precisely, we can get rid of this dependence on d when the opening point s is a d power.
00:15:47.840 - 00:17:45.960, Speaker A: One important tool for our work is this theorem from this work with Drake and fish that evolved into this paper called Halo infinite, that says basically if, say we want to open a polynomial f at at some d points, so one polynomial at many points. The result also works for many polynomials. But for simplicity, let's say one polynomial. So we can do it with two verifier scalar multiplications. So when we open one polynomial at many points, we can do it in a way that the number of verifier scalar multiplications does not grow with the number of points. So naturally this suggests the following routes. So if we can reduce opening many polynomials at some point s, which is what our goal is, to opening one polynomial at many points, then we can use this Bdfg theorem to get our desired result, which again is being able to open many polynomials without the verifier group operations cost depending on the number of polynomials.
00:17:45.960 - 00:19:20.310, Speaker A: So if we'll have time, I'll go back to Bdfg and show you how this component we're using works. But without much ado, let me show you the main idea of this work, Flanck, which is to reduce opening many polynomials to opening one using the well known fft identity. So for simplicity, let's think of just having two polynomials, f zero and f one, and say that their values at s are a and b. So we want to convince the verifier of this sort of by opening only one polynomial. So let's make a first attempt. Let's say we try to only open the sum. So we define capital f to be the polynomial f zero plus f one.
00:19:20.310 - 00:21:07.770, Speaker A: And note that if the verifier had commitments to f zero and f, one can compute the commitment to f by just elliptic curve addition, which is of course much cheaper than the scalar multiplication. So suppose we did that, and now we used Kzg to prove that f of s is equal to a plus b. So, is this good? Well, obviously this is not good enough, because it doesn't constrain a and b individually. Right? For any a prime, I could take a prime and then c minus a prime as my b prime. And if this is my verification procedure, also a prime b prime will pass the procedure. So I need sort of a way of generating two independent linear constraints on these values, a and b, without resorting to using two polynomials. So the solution is to use the f of t equation in reverse direction.
00:21:07.770 - 00:22:37.734, Speaker A: So we'll define now this capital f to be the polynomial f zero of x squared plus x times f one of x squared. Right? So reverse direction, because usually we start from f and decompose it down to this f zero and f one and here we're doing the other thing. And to commit to f zero and f one, we will just send the kcg commitment to this capital f. And now let's assume our opening point s is a square. So to open f zero of s, or to sort of verify f zero of s and f one of s, we will open f at the points t and minus t. Now, why does this work? Well, again, the point is just that. Let's see what we get.
00:22:37.734 - 00:22:59.370, Speaker A: Say so. F f zero. Sorry, there's. Sorry, let me make a slight correction here's.
00:23:00.030 - 00:23:05.018, Speaker B: You might be actually making this correction, but there's a question in the chat.
00:23:05.194 - 00:23:07.694, Speaker A: Why is it not t equals s.
00:23:07.732 - 00:23:09.520, Speaker B: Squared or s squared equals t?
00:23:12.050 - 00:23:13.646, Speaker A: Why is it not squared?
00:23:13.678 - 00:23:16.500, Speaker B: I think they're asking why is it not s squared equals t?
00:23:19.830 - 00:23:38.300, Speaker A: So s is the point where I want to open f zero and f one. I'm assuming it's a square. It has a root t.
00:23:42.670 - 00:23:43.754, Speaker B: Got it.
00:23:43.952 - 00:23:44.598, Speaker A: Kay.
00:23:44.694 - 00:23:48.490, Speaker B: I'm assuming that answered your question. If not, just chime into the chat.
00:23:54.510 - 00:25:02.696, Speaker A: Yeah, sorry, one more second. It okay? Yeah, just fixed some confusing typos. Right. Why does this work? Well, f of t is f zero of t squared, which is f zero of s plus t times f one of t squared, which is, again, just s. Right. So this is if we call f zero of s and f one of s a and b. So this is a plus tb, and now f of minus t, it's again, because of the squares.
00:25:02.696 - 00:26:22.300, Speaker A: F zero of s minus t times f one of s, f one of minus t squared, which is f one of s, which is a minus tb. So the point is that if we verify that b zero and b one are correct, it imposes two linear constraints on a and b. It proves that a and b are correct. Or to be more precise, like, what will the verifier do? The verifier will. The prover claims these are the right values, a and b of f zero at s and f one at s. So, using these a and b, the verifier will compute a unique b zero and b one from these equations. And now the verifier will check, using the openings of capital f, that the unique b zero and b one they derived from the alleged a and b values la and b are correct.
00:26:22.300 - 00:26:46.240, Speaker A: So let me maybe pause here for half a minute to see if there are questions, because this is really the central thing. Maybe I will look at the chat.
00:26:52.460 - 00:27:01.610, Speaker C: Maybe we can see this, actually. So Guillermo just wrote, I guess the Tldr is that bo and b, one are the injective functions of ab.
00:27:02.480 - 00:27:03.550, Speaker A: Yeah, exactly.
00:27:05.440 - 00:27:07.790, Speaker C: Guillermo, you also could have said that, actually.
00:27:09.600 - 00:27:27.570, Speaker A: But, you know, I'm going to break my anon voice or. Yeah, yeah, you can use the chat if you prefer, also. Right. So, yeah, that's the basic idea.
00:27:36.440 - 00:27:47.610, Speaker C: Ariel, do you know if there's any questions that you would kind of expect people to ask around this? Were there things that you were thinking of when you did it?
00:27:50.380 - 00:29:13.730, Speaker A: Well, there are some questions that come to mind when you see this that I'll get to soon. One question is why, instead of opening many polynomials, maybe change your snork to use less polynomials. And the answer there, briefly, is that that does almost work as well, but it creates an even higher prover cost by a significant factor to achieve the same result. But anyway, sorry. So that you can see in the paper, it's, it's sort of the, the natural, the natural generalization. And an important point is. Right, we want to use this for snarks.
00:29:13.730 - 00:29:48.246, Speaker A: And the point is that polynomial, Iot based snarks, they usually work fine with a polynomial commitment scheme that can only open def powers for some small dur.
00:29:48.298 - 00:30:02.390, Speaker C: Just the beginning of your sentence when you just said this, at least for me, I didn't capture it. I think your audio dropped off for a moment there. Sorry to do that, but do you mind actually just sharing again what you just said about this slide?
00:30:03.130 - 00:30:48.710, Speaker A: Yeah, again, two points. One is that sort of a straightforward generalization of this allows you to open D polynomials at any point. That is a deep power. So here we open two polynomials using one polynomial. If you want to open d polynomials at some point s, using also just one polynomial, you can do it using a point that is a D power. And the second thing is that, well, we want to use this for snarks. And now we have a polynomial commitment scheme where we can only open points that are deep powers.
00:30:48.710 - 00:31:04.090, Speaker A: And usually, at least plonk. We saw that it can easily be sort of massaged so that your opening points are always deep powers.
00:31:11.900 - 00:31:12.650, Speaker C: Cool.
00:31:18.940 - 00:32:11.356, Speaker A: Okay, so now I want to. So that, that was really, again, that was a central thing in the paper. So again, please ask if something that was not 100% clear. But now I want to explain a little about this component we use, which is. Okay, so how do you cheaply open one polynomial at D points? Right? Because we reduce to this. So we need to do this cheaply. So here we're in a situation where we have a commitment to one polynomial f, and we have these d points, s zero to s d minus one.
00:32:11.356 - 00:34:26.340, Speaker A: And we have the alleged values of f at all these d points, call them z zero to z, d minus one. So how do we verify all these values cheaply? So let's define a polynomial r of degrees smaller than d, that agrees with f on all these points. So r of Si is going to be zi. And now let's define a polynomial z, which is the zero polynomial of this set of evaluation points. And the important point is that z divides f minus r, right? Because at all of these points si, you'll have f of Si, minus r of Si, which is zero. So f minus r will divide x minus si, and so it will divide z, which is the product of these terms. So, okay, so this suggests the following thing that in fact was in the original Kzg paper, that, okay, so let's, similarly to standard Kzg, let's now compute this quotient f of x minus r of x divided by z of x, and call this h, this quotient h, and let the prover send the encoding of H.
00:34:26.340 - 00:34:42.920, Speaker A: And. Sorry, I think a line here got cut from the. Important line got cut from the.
00:34:45.930 - 00:34:51.020, Speaker C: Well, this is what study club is all about. It's proofing the.
00:34:51.390 - 00:34:59.580, Speaker A: Yeah, should it should appear now.
00:35:02.690 - 00:35:08.240, Speaker C: Looks the same, I think. Do you have to refresh it?
00:35:08.610 - 00:35:10.880, Speaker A: Yeah, just a compilation takes.
00:35:12.550 - 00:35:13.474, Speaker C: There we go.
00:35:13.592 - 00:37:02.450, Speaker A: Right. So the prover sends the encoding of h, and now the verifier can check that, sort of check that really z times h is really f minus r, which, right in the pairing, it corresponds to the commitment, the original commitment to f minus, this commitment to r. The pairing of that with one is going to be the same as the pairing of PI with the encoding in the second group of z. But of course, this is pretty expensive for the verifier because they need to compute this commitment to r, which is going to be dg, one scalar multiplications, and also this encoding z of x in the second group, second source group, where we know, of course, operations are more expensive. So this is going to be pretty expensive for the verifier. And sort of what happens in BdfG is that we trade these scalar multiplications for an extra group element in the proof. So how do we do this? Well, the verifier chooses a random alpha in sense, the prover, and now you look at the polynomial.
00:37:02.450 - 00:38:11.290, Speaker A: So sort of these polynomials that before the verifier had to encode them in g one and g two, we sort of just randomly fixed them. And so we look at this polynomial l of x, which is equal to f of x minus r alpha minus z alpha times h of x. And so. Right, so we, this, so we know right before these x's change to alpha, we knew that this was just a polynomial identity. This was just supposed to be identically zero. So when we fix r and z to alpha, so we know that l of x should be zero at alpha, right? Because if we set, we also put an alpha in f and h, it's just this identity evaluated at alpha, so it's always zero. So anyway, l of x should be zero at alpha.
00:38:11.290 - 00:39:49.370, Speaker A: And also the important point is that computing the commitment to L, the verifier, can do with only two scalar multiplications, right? The commitment of L is just the original commitment to f minus r of alpha encoded in the first group minus z of the PI multiplied by z of alpha. Right? So you have your two scalar multiplications. So the verifier can compute cm of l with only two scalar multiplications. Now, sort of our original claim about all these evaluations of f, right, just to remind you, sort of original claim was that the values z zero to z d minus one are really the values of f at the points s zero to s d minus one. So our original claim for this random reduction, it now reduces to just checking that l is zero at alpha. So now basically the proverb and verifier are just doing a Kzg check that l of alpha is zero on one polynomial. At one point, we've only in total needed two scalar multiplications.
00:39:49.370 - 00:40:08.130, Speaker A: So, any more questions about this or about the thing before?
00:40:12.470 - 00:40:15.300, Speaker B: Looks like still no questions.
00:40:17.430 - 00:42:10.280, Speaker A: Cool. All right, I want to end by addressing a question that, like I sort of mentioned before, it comes to mind when seeing this work, which is, can you write everything? We did? We wanted to reduce everything to one polynomial, so we will have less scalar multiplications. But can you just reduce the number of sort of to less polynomials without this thing, by just in advance having the snark use less polynomials? And in fact, there's these very nice slides to exemplify these. There's a very nice slide of don bone on Planck. And in his version of Planck, he really does something like this. So, for example, if people are familiar with Planck, you'll know that we have these three polynomials, flfrfo, where fl is like the left wires, the right wires, the output wires, and we have them in three separate polynomials. So you could say, well, why? So if you want less polynomials, why not just encode all these values in one polynomial of degree three n instead of three polynomials of degree n.
00:42:10.280 - 00:43:03.826, Speaker A: Really here. These are very nice slides. He does something like this. This works almost as well when you compile it into plonk in terms of verifier complexity, except a small caveat, which I'll show in a second. But you pay much more in the prover because the degrees of your equations blow up much more. And to exemplify this, let me briefly show you this sort of directly on the flonk paper, and at the same time, give you a little show you how we use this scheme to get our final snark. Verifier.
00:43:03.826 - 00:43:30.270, Speaker A: Efficient snark. And if you're familiar with plonk, it looks almost the same, but I'll sort of highlight the differences. So. Right. So. And at the same time, I will sort of explain, again, exemplify the disadvantage of just directly using less polynomials.
00:43:32.630 - 00:43:36.978, Speaker B: Actually, Ariel, there are actually a couple of questions.
00:43:37.144 - 00:43:37.742, Speaker A: Excellent.
00:43:37.806 - 00:43:56.746, Speaker B: Getting past excellent context where they were asked. So I think if you go back. Yeah. Okay, so I might have to have you rewind a little bit here. So, back to your original slides. On the last slide, I think, Simon, check out Simon's. Do you have the chat up or do you want me to read it?
00:43:56.848 - 00:43:57.500, Speaker A: Yeah.
00:43:59.390 - 00:44:00.842, Speaker C: So that we have it for the video, actually.
00:44:00.896 - 00:44:01.594, Speaker B: Yeah, that's right.
00:44:01.632 - 00:44:30.450, Speaker A: Yeah. People can't see. Okay, so I see from Simon, commitments correspond to evaluation at X using the trusted setup. And PI is an evaluation at another point. So maybe Simon can say what PI he was referring to. Exactly. I'm not totally.
00:44:31.910 - 00:44:37.800, Speaker B: I. Yeah, I think it was the last of your slides. But, Simon, you can chime in on the chat, if that's right.
00:44:39.370 - 00:44:54.890, Speaker A: Yeah, I'm just trying to get back to my slides. I believe it's a commitment to H of X. Wait, is this from Simon?
00:44:58.370 - 00:45:08.460, Speaker C: Maybe referring to something else? Simon, if you are there, do you mind maybe just weighing in? You're muted right now.
00:45:09.310 - 00:45:10.202, Speaker A: Yeah, sorry.
00:45:10.256 - 00:45:30.740, Speaker D: I was referring to this equation. The commitment of L is equal to the commitment of s minus, and PI is the proof. So it corresponds to the opening of H. And to me, it was kind of an evaluation at another point, but maybe I'm wrong.
00:45:38.070 - 00:45:50.460, Speaker A: So, h. Yeah, I mean, h is the evaluation of this quotient at the secret SRSX. Secret it.
00:45:58.830 - 00:46:06.814, Speaker D: Okay, I think I'm mixing everything, but, yeah, at the end, you display the h, you evaluate it at the same x.
00:46:06.932 - 00:46:34.920, Speaker A: Okay. Yeah. At the end, we sort of. We know that this L. If there were x's here, that this should be just identically zero. And it means that this l, if we evaluate it at alpha, it should also be zero. Is it clear?
00:46:37.610 - 00:46:49.114, Speaker D: Yeah, it's clear. I think I was just mixing the s that is needed to do this evaluation of the polynomial. Okay, thanks.
00:46:49.312 - 00:46:54.460, Speaker A: Cool. Yeah.
00:46:56.590 - 00:47:39.210, Speaker B: So there's still a couple other, I think, Kay, I don't know if you ever had your question answered. So Kay asks, doesn't that require an srs of size three? And I actually don't know where that was back. So Kay, if you want to clarify where that was referring to, that would be great. And then also just in Dan slides, I think going back to Dan slides also, I am happy to read the chat, but it might be easier if people just pipe in if they want to ask the question directly, because I'm trying to infer context that I may not have. So I'm happy to read the slides or read the questions, but if you guys want to just chime in, don't be shy. So, yeah, back in dan slides.
00:47:41.950 - 00:47:42.358, Speaker A: Doesn'T.
00:47:42.374 - 00:47:48.158, Speaker B: That require an srs of size three n? So the Dan Bonet plonk slides I.
00:47:48.164 - 00:48:37.200, Speaker A: Think he's referring to. Yeah. The way, by the way, to get to these slides, maybe someone can write the actual link. But if you go to his 2021 fall course syllabus, and then it's there in one of the lectures. Yeah, and by the way, about K's, which question? So I think if I understand correctly, the question, yeah, basically every time the degree blow ups, you suffer from them both. You'll suffer from both improver computation and in srs. Yeah.
00:48:37.200 - 00:49:18.300, Speaker A: So basically here, if we look at the flunk version of plonk, how does the high level protocol go? So the one sort of difference, main difference from. Yeah, but about this work, by the way, with, with the, the vectors, I have, I have to say I didn't understand it fully, but it seems the bottom line is that still the number of scalar multiplications there, they get it to twelve, and here we get it down to five.
00:49:22.910 - 00:49:24.894, Speaker C: Which work are you referring to? Is it the one?
00:49:24.932 - 00:49:30.330, Speaker A: Oh yeah, someone put it in the chat. I think it's called VC proof.
00:49:30.490 - 00:49:31.594, Speaker C: V o proof.
00:49:31.642 - 00:49:35.114, Speaker A: Yeah, I think vo proof.
00:49:35.162 - 00:49:37.394, Speaker B: I think it's, maybe they changed it.
00:49:37.432 - 00:49:48.354, Speaker C: At least the link here says that we can add this link. Also in the video vector oracles, we can add this link. So watching can actually follow along.
00:49:48.472 - 00:51:13.390, Speaker A: Yeah, actually maybe that's a good talk for a study club, because I never understood it fully and would be nice maybe to have a talk will save me some time because I feel maybe there's a trick or two there that I didn't fully understand yet. Yeah, so the main difference between sort of the high level protocol here in plonk is that in plonk we have sort of the round at the end we sent this quotient which is sort of a random combination of different quotients of the different equations. But sort of when we're really trying to shoot for best verifier efficiency, this extra round, basically we're going to pay for rounds because every round of the protocol we're just going to send this one commitment to all the polynomials of that round, like this capital f, it's committed to f zero and f one like we saw. So we really want to minimize the number and we're going to have a scalar multiplication per one of these polynomials. So we really want to minimize the number of rounds. So this is why here, as you see in this flank protocol, we send actually a few quotations. Like we send here one quotient that sort of proves the arithmetic equation.
00:51:13.390 - 00:52:23.298, Speaker A: And then in the subsequent rounds we will send two other quotients that sort of verify the permutation. As opposed to original plonk rules, we just send sort of a randomized one, randomized t, because again that costs us another round. Because before we send the one randomized quotient, the verifier needs to send us some alpha to allow to combine of. Right now here I want to exemplify the. So you could say, okay, you want less polynomials. So sort of like in Dan Buen's slides, why not instead of flfrfo have one f that includes all the three n values and you could say the same thing of the selectors, right? Why instead of having these five selectors, why not just have one q of degree five n? So you could do that. But then what you'll pay improver complexity will be very high because then really in Planck you have sort of eight selectors, because you have the permutation selectors and these sort of these q's.
00:52:23.298 - 00:53:02.660, Speaker A: So you'll have suddenly an equation where. Yeah, where this q will be of degree eight n and now this f will be of degree three n. So this equation degree, you've got it up to eleven n. And that'll sort of mean when these quotients, you'll need to compute similarly, their degree will blow up. Yeah, that was mostly what I wanted to say.
00:53:11.900 - 00:53:17.950, Speaker B: Awesome. Anybody else have any questions?
00:53:23.900 - 00:53:33.070, Speaker A: Yeah, these are exactly the slides in the chat. Are the ones I was referring to.
00:53:39.120 - 00:53:51.320, Speaker B: Okay, awesome. Well, thanks very much for sharing this work, Ariel. And if no one else has any questions, we can call it. Thanks again for coming on Zk study club.

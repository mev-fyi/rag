00:00:06.410 - 00:00:23.630, Speaker A: Hey, next up we have Alex from Matterlabs who's going to be talking about bringing EVM smart contracts to ZK rollup with ZK sync. Please leave your questions in the stage chat and we're going to do A-Q-A after the talk, but take it away, Alex.
00:00:24.130 - 00:01:00.080, Speaker B: Thank you Anna, thank you for having me. And hi everyone. Welcome to the talk about ZK roll ups, optimistic roll ups and EVM smart contracts, and how this all can work together. And we will start with the intros into roll ups. I'm sure that most of the audience is familiar with it and know what roll ups are and the differences between optimistic and ZK roll up. In principle, very high levels. I'm not going to repeat it because there's been a lot of content on this topic over the past two years.
00:01:00.080 - 00:01:46.942, Speaker B: If you're interested, I can send links after the session to deep dives and comparisons, but roll ups on the rise Ethereum is now officially a roll up centric platform. The Vitalikutarian recently announced the adjustments in ETH two roadmap and ETH one roadmap to focus on the roll ups and make sure that they are first class citizens. And essentially it's now kind of official that roll up is scaling. Sorry, Ethereum is scaling with roll ups. Everything else has way inferior security and decentralization properties. So roll ups are the kings. Interestingly, there are two flavors of roll ups and we're going to compare them.
00:01:46.942 - 00:03:12.234, Speaker B: They share the common basis in both types. You have one contract on the mainnet which holds all the assets and a single cryptographic fingerprint of a state, for example, a root hash of a Merkel tree. And for every new block which happens off chain, which contains a lot of transactions, only this one hash is changed on the mainnet contract. Now for ZK roll ups as an operator. So whoever submits this block, they have to provide a zero knowledge proof of validity of that block, testifying that the new hash was correctly derived from the previous one. In optimistic roll ups, no modern cryptography is used and instead you rely on game theory and someone has to monitor all the transactions in the roll up and has to submit a fraud proof to Ethereum within a predefined period of time to challenge the fraudulent transactions. And in order to be able to do so for both types of roll ups, in order to be able to reconstruct the state and be able to prove that you still have some ownership, the data for every transaction is posted through Ethereum as call data.
00:03:12.234 - 00:04:22.910, Speaker B: So for each transaction we post either the input which everybody can take and re execute by applying it to their previously known state, or maybe just the delta of the state. What changed in the state, like which slots get what new value? These are the technical differences which, as I said, you can check extra. Let's focus on the properties like what is different between the two types of rollups. And just to mention, ZK rollups are currently in production. So we are for example, authors of ZK sync, which can be used for payments and not only for payments, for transfers of value of any kind, with received many fungible tokens, for example for airdrops for different payments as a checkout in applications. For example, we use it with kitcoin grants of the last round. I'm going to use it with round seven in December.
00:04:22.910 - 00:05:15.870, Speaker B: We natively support multisig, so you can implement some multisig based applications. With multisig you can actually do very interesting things such as atomic swaps, payment links and some basic contracts. And you can also send payments to any Ethereum address. So for example, you could send payments to a smart contract, and then this smart contract can request from the mainnet to get the funks back to mainet from the roll up. So there is a lot of flexibility, but it's not a fully functional smart contract platform. And this is what everybody needs because we all want to scale Ethereum in general with Defi, with all the cool things which smart contracts were invented for. So for that, let's see how this so optimistic versus Zkollab.
00:05:15.870 - 00:06:03.442, Speaker B: There are a couple of differences which in my opinion clearly benefit ZK rollups. And I think it's very important to understand these differences in order to see the importance of porting existing contracts to these systems and specifically to ZK roll up. So number one, the most crucial distinguishing factor between the two roll ups is the security model. In optimistic roll up you rely on one of an honest validator's assumption. In ZK roll up you rely on pure math and cryptography. So ZK roll up is as safe as the underlying layer. One.
00:06:03.442 - 00:07:03.540, Speaker B: If the cryptography is correct, with optimistic roll up, you're supposed to be safe. If at least one of the validators is correct, is not compromised, which per se is a reasonable assumption, but people often ignore that. It's not the only assumption of optimistic roll up. There is another one, and it's a lot nastier. You also rely on the mainnet Ethereum to be enough censorship resistant so that any fraud proof transaction reaches the optimistic roll up contract. And that is actually pretty problematic. Because there are attack vectors where you can deploy 51% attack on Ethereum manned and sender a specific smart contract for a week, which costs not a lot like the brute force cost of this attack is something like $20 million.
00:07:03.540 - 00:08:23.326, Speaker B: And if it's successful, you can just grab all the assets from the optimistic roll up. And interestingly, the actual cost of this attack is a lot lower than $20 million, because it's enough for you as an attacker to just make a plausible commitment to the threat to override other blocks from other miners who are not complying with you. You run the attack for a short period of time and you communicate to everyone that, hey, guys, you should be censoring this contract. If you don't do this, I'm going to override your blocks and you're going to lose money. And rational miners being anonymous and being able to shift hash power flexibly from one mining pool to another, they don't have anything to lose if they comply with you, but they have a lot of to lose if they don't comply. So what's likely to happen is that a large fraction of the power will move towards the mining pools controlled by the attacker, and then the cost of the attack will be negligible. It will be just like, I don't know, in the range of one, 2 million.
00:08:23.326 - 00:09:27.586, Speaker B: So if you put a lot of value in a single instance of an optimistic roll up, it's an invitation for this attack to happen. So it's probably not secure to put more than a certain amount. Let's say $50 million is an absolute maximum of what I would kind of think is not likely to happen in this attack. If you put more money, if you put 100,000,200, $501 billion, it's almost a guarantee that this will happen. And unfortunately, this type of attack cannot be mitigated as long as Ethereum remains a proof of work chain. So once ethereum moves to proof of stake and everybody migrates, then you could have some mitigation strategies. Then it would be possible for the community, for example, to arrange to have an agreement up front saying that if this type of censorship happens, then we will consider it illegitimate situation.
00:09:27.586 - 00:10:07.898, Speaker B: It's not just code is low. We have some values beyond that, and we can see which miners were or which stakers were validators were participating in this attack. We can target them and slash them. But this is only once ethereum is proof of stake. This is probably several years away, and we need to scale ethereum today because everybody is, of course, familiar with the gas prices rising astronomically this summer. So this is one big, huge problem. The second biggest problem is that optimistic roll ups have a very long objective finality.
00:10:07.898 - 00:10:56.686, Speaker B: So time for layer one to understand that a certain block is final on an optimistic roll up so that you can process exits from the optimistic roll up is equal to the fraud proof delay. So this is a security parameter which is equal to one or two weeks. Let's say it's one week. So any native withdrawal from an optimistic roll up will take one week. All the nfts will take one week. Fungible tokens could be accelerated if you use some external liquidity which is available on the main net. So you can ask somebody who is on mainet to give you immediate liquidity and then wait for this one week to withdraw it from the roll up and you're going to pay for it.
00:10:56.686 - 00:11:57.986, Speaker B: So of course it's going to be expensive and it's going to be complicated. In terms of coordination. Maybe this will work with some smaller amounts of fungible tokens or of liquid tokens, sorry. But for some less liquid tokens and for very large amounts, if we're talking about moving half of some DFI protocol on a layer two and back to layer one, this might be really problematic. All of this, of course you don't have with ZK roll ups, because in ZK roll ups the time of exit is equal to the time of finality, which is just a couple of minutes, which are necessary to construct a zero knowledge proof. And finally, you have certain types of transactions, most specifically transactions involving privacy, which are going to be a lot more expensive on optimistic roll ups than on Zik roll ups. So for example, for privacy, you have to publish all the zero knowledge proofs, which can be pretty large.
00:11:57.986 - 00:12:47.726, Speaker B: So a plumb proof, for example, is 1 kb on the optimistic roll up, and you can completely omit them in the ZK roll up, which supports recursive zero knowledge for verification. So the cost of a private transaction in ZK roll up will be something like two times normal transaction. For an optimistic roll up, it's more in the range of like 20 5000 x. So from this comparison, we can see that it would be absolutely awesome if we could just put existing contracts on ZK roll up. And many people consider, have considered it a very difficult task. That's why we had a lot of attention to optimistic roll ups over the past year. But this is actually not true anymore.
00:12:47.726 - 00:13:41.678, Speaker B: It is possible to port existing contracts to ZKE roll up and let's see how we can do this. So let's go through a migration roadmap which we in the metal apps are following, and we're planning to process to get all the legacy contracts on ZK sync. Specifically, we start with just supporting contracts which are zero knowledge proof friendly. And to be zero knowledge proof friendly, the most obvious approach is to have a non Turing compute contract support, which we did this year with zinc. What is zinc? It's a language for constructing smart contracts and also doing generic computation, like producing zero knowledge proofs based on rust. So this is an example of the code of zinc. It follows the rust syntax.
00:13:41.678 - 00:14:30.610, Speaker B: It borrows these smart contracts elements from solidity. But apart from that, everything is like pure rust, except for we eliminated all the complex elements which people normally hate in rust. And zinc comes with some nice features, so it's completely type safe. You can define custom types, you don't have to bother with all this mass insolidity where you use the same uint eight for a number and for some option and for some amount. You can define types for every single thing separately and make sure that you don't mix them up. It has type inference, which makes the syntax a lot nicer. So we have some syntactic sugar built in the language.
00:14:30.610 - 00:15:03.550, Speaker B: It's immutable by default, and it supports safe math, which the newest version of solidity also supports. But we were there a year ahead of solidity. So natively with operators, all operators are safe. You cannot have an overflow in the operations of simple math. Immutability is really important. So rust is a functional language and it allows you to have a lot less side effects and make the code a lot cleaner and a lot less buggy. And for smart contracts this is very important.
00:15:03.550 - 00:16:04.866, Speaker B: You can check it out at zinc zksync IO. A nice thing is that zinc comes with a packet manager called zargo on the analogy to cargo in rust, which gives you lots of options. So you can go and have, you can create projects, you can build them, you can manage your files, you can have a project consisting of multiple modules broken down in several files. You can run tests, you can do benchmarks and so on and so on, like lots of useful functionality, all from command line following a nice command line syntax. You will also be able to generate documentation and format the source codes. But testing is really important. You can write your tests also directly in zync and have a really nice unit testing experience.
00:16:04.866 - 00:16:45.806, Speaker B: A lot nicer than in solidity. Essentially, I'm of course biased, but every single aspect of the language is better than solidity in my opinion. I would encourage you to check it out and experiment yourself. So we have zinc and you can do contract. Zinc is not your incomplete, so it doesn't contain unbounded loops and recursion, like recursion in a single function call. You can have recursion by calling the contract itself, but it's going to cost you like an external call. A really nice property of zinc is that you can do.
00:16:45.806 - 00:17:47.266, Speaker B: We paid a lot of attention to debugging and you have for example console log traces which can be run on transactions which are running on testnet or mainnet. So you can have a smart contract call which does something and fails. And in solidity it's totally difficult to understand what happened. In zinc you can just add more debug points with console traces and just rerun, so you can modify the code and rerun the same transaction on the exact same block in the exact same spot with extended locks, and actually see what's going to happen and why the transaction is failing. It's really a lot simpler to debug with this kind of approach. Okay, we have that and it actually works. So you can take existing smart contracts and just manually rewrite them into zinc today.
00:17:47.266 - 00:18:28.750, Speaker B: And this is what we did with curve. The original curve is written in Viper, which is also a non turing complete language. It doesn't allow unbounded loops and recursion. So what we did, we just took the code and rewrote it line by line into zinc. Say the code is public, you can go to exchange and see how it looks. It's almost exactly like line to line translation of the original contracts. If you go to the curve home page, you will see, oh, sorry, you probably don't see my screen.
00:18:28.750 - 00:19:17.406, Speaker B: I want to show this one. Okay, so let me just go back here. Here is the contract code and underlaps curvezink in GitHub. This is how it looks, this is how the tests look like and the code itself. And if you go to the curve homepage, you will find a link to the Zksync testnet right there, which is also hosted by curve. And you can just try it out. So you can go and connect your wallet which will open a separate tab so you won't see it now if I do it.
00:19:17.406 - 00:20:11.882, Speaker B: But you're welcome to experiment. You will get some test stable coins on the Rinkabee testnet to play with. And you can just do a swap and see how this works with any wallet which supports web3. So with metamask wallet connect, or even with a burner wallet which will live inside your browser. So this works, you can do this now. Okay, so this was the second step. Now the third step is we can automatically convert legacy code into zinc even if it's written in solidity, since zinc and solidity are structurally isomorphic.
00:20:11.882 - 00:21:10.530, Speaker B: Except for the Turing complete part, every aspect of the language is like, though they are following different syntax styles, they are the same. So you just define your contract, you define your state, you define your public private methods, and we actually implement this. Okay, let me just share my full screen. Think I can do this. We have an experimental transpiler from solidity into zinc, just called Sol Z. And this is how it works. So I just transpiled the Uniswap code and produced a uniswap ZM.
00:21:10.530 - 00:22:45.300, Speaker B: And here is how this code looks like it's almost complete in terms of it compiles. Some lines of code are still commented out because they are unsupported, but we are almost there with the full support of solidities using transpiler, and it will be possible to compile anything except for the Turing complete parts, which you will have to rewrite. The good thing is most defi contracts do not require Turing completeness, so uniswap is non Turing complete. Most other things, even if they have some loops, mostly what you need is just to iterate through a couple of things. Most of defi protocols, like if you look at the top ten from the capitalization standpoint, they only trade through some fixed number of items and maybe number of pairs in a trading loop for curve or something like that. Most of the time you can just easily convert it with minimum modifications and it will just work. Okay, and finally, this is how the uniswap code looks here again.
00:22:45.300 - 00:23:39.860, Speaker B: And finally, we are currently working on adding Turing completeness. Once we can add Turing completeness, the transpiler will of course easily support transpolation of any code, and it will not be required to do manual changes at all. It will just work. So it will be possible to just take any existing solidity code and deploy it to zksync without need of modifications. And what made this possible were two things. Number one is recursion, which we implemented for Ethereum with plonk in summer for the Reddit challenge. So if you go to Reddit Zkscan IO, you will see the block explorer with the recursive blocks, and they are coming to mainnet actually next month.
00:23:39.860 - 00:24:52.090, Speaker B: So this is fully functional with ethereum verifier on Rigapi Testnet. And this allows you not only to have arbitrarily many blocks verified with a single proof, but also to have separate runs for every contract verified in one big block. So a block can contain multiple transactions, and each transaction will have its own smart contract call with a separate proof, and you can aggregate all of them together. So this is one approach. Another approach would be to build one generic circuit, which I think Cairo is following. But we think that what we're doing with recursion is a lot more flexible because it gives us ability to have contracts which are using some very advanced crypto, like using some non ZK friendly crypto, like shuttle 56 hashes or ketchup hashes, or ethereum signatures. And we still are able to efficiently verify them because they will run in these separate circuits written in zinc.
00:24:52.090 - 00:25:44.086, Speaker B: This is one breakthrough which made it possible. And the second is. The second thing is Turing completeness is very expensive. It adds a lot of overhead on top of the lots of overhead that zero knowledge proofs in general are adding. So we need a lot faster prover, and we are achieving this with fpgas. So we have an FPGA solution which are now being adjusted for bn two five six, and is Zillink and AWS f one compatible. And we're going to bring it live probably by the end of this year, with the lot faster proofs accelerated by fpgas.
00:25:44.086 - 00:26:21.000, Speaker B: So the cost is actually not reduced by a large factor compared to cpus, but the speed, so latency of the acceleration and accordingly the ability to produce proofs for large number of contracts and support high throughput is increased massively. And we're going to publish the benchmarks soon. But this is the final element which gives us this ability to build trinomplete contracts. And that's it. From my side, we reserved a large fraction of the stock for questions, because we suppose there to are going be a lot of questions. So Anna, I'm giving it over to you.
00:26:22.010 - 00:26:38.090, Speaker A: Great, thanks for inviting me back. So there's a number of questions. I had a question as well. But let's start from the top, where Kev asked, is this an alternative to solidity or an alternative to something like circom?
00:26:39.550 - 00:27:26.854, Speaker B: Zinc is of course an alternative to something like circum or socrates, where you can just write your circuits and produce proofs and verify proofs for these circuits. It's written in rust, so you can embed it into any application. So if you want to use it for zero knowledge proof generation, for circuits building, you can do that. It doesn't require any specific zero knowledge proof skills. So any programmer who is capable of writing solidity code or rough code or python code will be able to write zinc code. So you don't have to understand math behind that, you don't have to understand fields overflow. You're not going to make any mistake.
00:27:26.854 - 00:27:58.306, Speaker B: If the code is readable you can be sure that all the constraints are there. It's completely deterministic on purpose. We did not allow any nondeterminism. You cannot have external witness. We have a rich library of gadgets which you can use which are efficient, for example sorting and other things, and crypto primitives, signature verifications. But yeah, you can use it for that. But if you want to use it for contracts, we have a separate flavor of the language which is just supporting smart contract features.
00:27:58.306 - 00:28:05.560, Speaker B: And then you just describe smart contracts in a normal way and we do all the work in the back.
00:28:06.730 - 00:28:20.490, Speaker A: I actually want to ask my question as a follow up here because in the curve example that you shared, I was curious if curve itself is running on a ZK roll up on Testnet or if it's like the code was rewritten in zinc because it wasn't completely.
00:28:20.560 - 00:28:24.798, Speaker B: Clear as the code was rewritten in zinc and then we're on it on.
00:28:24.804 - 00:28:31.598, Speaker A: Our testnet and it would be on once it's in production. Once it's out there it would be on a ZK roll up.
00:28:31.764 - 00:29:41.800, Speaker B: Yeah. With any layer two solution you will have to deploy a new instance inside this layer two and you will have to move your funds from layer one into this layer two through some asynchronous process so it won't be smooth. You cannot just put existing code on layer two and make it interact the same way with layer ones smart contracts as you did before. What you can do though is you can gradually migrate from layer one to layer two. So curve balancer and other protocols could just deploy another instance in the layer two in ZK sync with just a small amount of liquidity. And then gradually with the increased demand in layer two, they can move funds from layer one to layer two, gradually shifting the balance towards more allocation in layer two, but always having an option to go back. Should there be something like if you need this money back on the main net because there is some hot project going live and you want to participate there and do your liquidity mining you can always do.
00:29:41.800 - 00:29:52.490, Speaker B: Don't you have full optionality? You don't have the fear that you won't be able to move them back for one week like it's going to be the case with optimistic collapse.
00:29:53.870 - 00:29:57.210, Speaker A: Weijay asked, which proof system does zinc target?
00:29:58.430 - 00:30:54.590, Speaker B: We have backend in plonk, which will automatically work with redshift once Redshift is complete. Redshift is our proof system, which is based on the plonk arithmetization, but uses fry for polynomial commitments instead of kate commitments. So it means the redshift is transparent, it doesn't require trust setup. Plonk requires the universal trust setup, which we reuse from the ignition ceremony from last year. So yeah, it's like plonk arithmetization. So anything which is based on plonk arithmetization, you will be able to extend zinc to produce proofs for that system. Why is that important? Because we're going to use some specific things from plonk, like some custom gates and lookup tables, which are making certain things very efficient.
00:30:57.650 - 00:31:06.770, Speaker A: Vasob asked, I wonder how zinc handles 256 bit numbers and the arithmetic like long arithmetics.
00:31:09.190 - 00:31:41.920, Speaker B: Just like no processor has 256 bits native words, you have 64 bit words, and then you have some number of limbs in your number, which is being multiplied with long arithmetics. The same thing happens here. We can natively support 64 bit numbers because they are not going to overflow even if you multiply two numbers in the field. But yeah, then we have four limps in the representation of a single u, two, five, six.
00:31:43.170 - 00:31:54.974, Speaker A: Isaac was asking, how are non snark friendly things like I don't know how to pronounce this kick hack or whatever kick with custom gates. It's handled in the trench file.
00:31:55.022 - 00:32:25.290, Speaker B: Custom gates in plonk we managed to bring down the shuttle five, six constraints from 25,000 in 25,000 r one cs constraints down to 5000 gates in plonk. Just one example. So you can do a lot of nice things there with like plonk allows you to construct something like starks for certain elements and use them as like the single custom gate.
00:32:27.150 - 00:32:38.590, Speaker A: Star had a question about recursive ZK snarks, but I'm not sure I understand this. It's is recursive ZK snark used to support smart contracts, and I don't know if you understand that.
00:32:38.740 - 00:33:34.850, Speaker B: Well, yeah, this is what support. So we aggregate multiple proofs recursively into one, and we can have it in a tree like structure, can have arbitrarily many proofs being aggregated into single one, and each of them can represent a smart contract call, for example. And without that it would be really difficult. Then you have to construct one single huge circuit which does everything which might work with starks, but will have other problems. So I think with starks you won't be able to as flexibly have the Ethereum constructs like Chuck and shut of s six. But on the other hand, you can have one single block which contains lots of transactions. With plonk it won't work because we have a trusted setup of a fixed size, so we can only fit as many constraints in one single proof.
00:33:34.850 - 00:33:47.240, Speaker B: But having recursion allows us to combine these proofs arbitrarily many times. So we can have as many contract calls or execution trace as we need.
00:33:48.410 - 00:33:52.242, Speaker A: Sergey asked, does it support Ethereum pre compiles like BN?
00:33:52.386 - 00:34:16.960, Speaker B: It doesn't, no, we exclude it. So Ethereum pre compiles like shutterf six? Yes. So the basic ones, not the bn or this modern crypto like AP 1962. No, we don't support that. So contracts that rely on this will have to be rewritten using the crypto primitives from zinc terrac. This is one exception. Yes.
00:34:17.330 - 00:34:20.346, Speaker A: Lasso was asking, is the recursion unbounded?
00:34:20.538 - 00:34:52.634, Speaker B: Recursion on the level of calling, the contract itself is unbounded. So you can just schedule many calls of the contract in solidity. You can do message, what's it called? Message sender? Callback. Right. But you cannot have it inside the function of zinc. It's slightly more expensive, but yeah, you can have it in unbounded way. You can structure it this way.
00:34:52.634 - 00:34:53.530, Speaker B: Cool.
00:34:53.680 - 00:34:59.130, Speaker A: Hang was asking, are the common ZK friendly crypto primitives already built into sync?
00:34:59.890 - 00:35:45.690, Speaker B: We do have a number of common crypto primitives such as hashes signature verifications. We support musig, which is a very popular signature scheme based on schnarz signatures which allows multisig and just generally is nice to work with hashes. That merkel trees. I don't have it out of top of my head, but we have a really nice documentation. If you go to zinc Zikistinc IO, you will find a complete zinc book with the standard library and all the constructs, contracts, non contracts, circuit operations, everything is explained.
00:35:47.150 - 00:35:50.720, Speaker A: I just tried to put it at the bottom there. I hope I got it right.
00:35:52.610 - 00:35:57.054, Speaker B: I'll send this link to the stage to the chat chat, right?
00:35:57.092 - 00:36:07.070, Speaker A: Yeah, that'd be awesome. Great. So Kev asked, does this use r one cs flavored versions of plonk or is it standard plonk with custom gates?
00:36:07.150 - 00:36:09.026, Speaker B: It's standard plonk with custom gates and.
00:36:09.048 - 00:36:12.610, Speaker A: Lookup tables and soon redshift.
00:36:13.830 - 00:36:42.094, Speaker B: Redshift is work in progress. It would work now. We tested recursion as well. It supports recursion the same way k based block supports recursion, but it's just not as efficient with regard to hashes. So once we can bring down the cost for hashes for recursion, it will work. If you don't need hashes, if you don't need recursion, you could use redshift. Today.
00:36:42.094 - 00:37:08.120, Speaker B: If you have applications which require transparent proof system, you can write proofs in zinc, compile them into our intermediate representation, and then it will be possible to have redshift. I'm not sure how code is already public or not for redshift, but it's certainly possible. You can talk to us if you need that, just talk to us and we'll figure out.
00:37:09.370 - 00:37:17.942, Speaker A: Darryl is asking, did redshift always use plonk arithmetization, or is that new? But then, following up, it did use plonk already.
00:37:18.076 - 00:37:31.050, Speaker B: Yeah, we used to use pure roncs based on Belmont and used to use Belmont gadgets, and now we created a bunch of our own gadgets because we needed to bring the cost down. So now we're switching to the block based organization.
00:37:31.410 - 00:37:38.990, Speaker A: Okay. Isaac asked, do you have custom gates for all non snark friendly EtH opcodes?
00:37:42.870 - 00:37:44.290, Speaker B: Can you repeat the question?
00:37:44.440 - 00:37:51.490, Speaker A: Oh, sorry. Isaac asked, do you have custom gates for all non snark friendly eth op codes?
00:37:52.230 - 00:38:31.162, Speaker B: No, it doesn't work this way. It's slightly more complicated than that. We don't do EVM. So this is the thing I missed, probably in my talk. When we talk about bringing EVM smart contracts to ZK rollup, it does not literally mean bringing evm to zk rollup. This is not what people need. What people need is to bring the legacy code, which now compiles into EVM, which is written in solidity, or viper, or partly in assembly, or u take this code and make it work in Zikarola.
00:38:31.162 - 00:38:41.410, Speaker B: This is the demand, not just, like, specifically EVM. And we accomplished that by recompiling the codes into zinc vm.
00:38:42.710 - 00:38:46.434, Speaker A: I see there is a new vm. Okay. Just not evm.
00:38:46.562 - 00:38:49.320, Speaker B: Yeah, got it.
00:38:50.330 - 00:38:56.402, Speaker A: Brendan asked, what's the constraint cost for recursively verifying a redshift proof in circuit?
00:38:56.546 - 00:39:27.102, Speaker B: I don't remember. It depends on the hashes. So the bulk of computation of verification, recursive verification of redshift goes towards hashes. So you have to see how many hashes you have. It's comparable to Starks. You can just look at Starks, see how many hashes you have, and then pick your hash which has to be super efficient, very snark friendly. It can be a non binary tree.
00:39:27.102 - 00:39:49.066, Speaker B: It can be a tree of something because you have some hashes like Poseidon which take more than two inputs and then you just multiply by the number of constraints. But I don't have these numbers off the top of my head. Alex Philosoph would be able to answer this question better. If you just drop a line to.
00:39:49.088 - 00:39:54.902, Speaker A: Us, we'll reply is zinc stack fully open source?
00:39:55.046 - 00:40:20.050, Speaker B: It is open source. We are opening the code once we complete the milestone and we have a stable version. We work on things, we polish things internally before we open them so that people who, whenever we open something it should be very smooth and functional. But yeah, everything will be eventually open source completely, 100%, including hardware.
00:40:21.830 - 00:40:32.226, Speaker A: Ronald was asking, is there a difference in syntax between the standalone version of zinc, like the previous zero point 15 version and the new smart contract version of zinc?
00:40:32.338 - 00:41:08.420, Speaker B: No differences in the syntax of the language itself. We just added features required by smart contracts. We added keyword contract and the syntax for storage definition for public methods, private methods. But inside the methods they look exactly the same as normal zinc, like previous version of zinc. So zinc is evolving, we're adding some new features, so obviously the language just supports them. But they are going both into the smart contracts and into the circuit modes. Cool.
00:41:08.790 - 00:41:13.220, Speaker A: Darryl's asking, can redshift be combined with the accumulation scheme idea?
00:41:15.130 - 00:41:17.110, Speaker B: I'm not familiar with the scheme.
00:41:20.410 - 00:41:41.470, Speaker A: VK study clubs. It's the third one from the bottom, but Dara, do you want to give a bit of context to the question maybe and we can come back to it? I'll ask the next one. Okay. Kev asked, is the one k proof size for all custom gates plus lookup with KZG.
00:41:45.490 - 00:42:08.134, Speaker B: I think the question I don't want to. I think it's like 1 something like that. So I'm not exactly sure, but it's on the order of magnetic of 1 everything. Cool.
00:42:08.332 - 00:42:16.070, Speaker A: Jekyck asked, what's the outlook to disassemble EVM bytecode and recompile for Zksync?
00:42:16.650 - 00:43:18.326, Speaker B: It doesn't make sense. You're going to lose a lot of important information. For example, if you're using imagine you have a hash map in Ethereum, right? This hash map has very specific sequence of derivation of the way you address your storage. You take the slot number, you take the key of your mapping, you make a ketchup hash out of it, and you use this hash as the key for the storage slot, like the index of the storage slot in EVM. So if you just take this natively, this code, written the bytecodes from EVM. For this part of code, you will construct a very expensive operation. Whereas if you know that you're dealing with a hash map, you can do things slightly differently and way more efficient.
00:43:18.326 - 00:43:35.010, Speaker B: So it's a lot better to work with the original source code because you can derive a lot of information from the source code from the context there. It's possible to do EVM transpiration directly, but it's just not going to be as efficient as working with source.
00:43:36.070 - 00:43:42.290, Speaker A: Ronald was asking, is the default access scope of functions the same as in solidity public by default?
00:43:45.370 - 00:44:15.134, Speaker B: I can't answer this immediately. I think in rust we have explicit modifiers for each function, so you cannot have. I think it's the other way around. You have to do pub. Let's see. Let's just look at the code and functions. You have to do pub for a function which is public.
00:44:15.134 - 00:44:51.450, Speaker B: So by default it's private. So as I said, every element of the language is better from the security perspective than solidity. Every single thing you look into is most likely better because rust is now lingua franca of all secure. If you look around Facebook, Libra is based on Rust. Alio is based on Rust. Polkadot chose rust. Lots of new things are being based on rust because it turned out to be a very good design of a secure language with all the elements which are necessary to prevent common mistakes.
00:44:51.450 - 00:44:55.900, Speaker B: That's why it was a choice for us.
00:44:56.670 - 00:45:15.966, Speaker A: There was a little bit of conversation about Fry and this accumulation schemes, but I think I'm going to let you check that out after. But Dara did have a follow up, which is more about redshift here. So what's the concrete efficiency proof size proverb speed verifier speed of redshift relative to Halo?
00:45:16.158 - 00:45:21.220, Speaker B: I'm not able to answer this question referred to Alex V. OK.
00:45:22.390 - 00:45:24.594, Speaker A: He's the person who designed it, or.
00:45:24.632 - 00:45:32.646, Speaker B: Has really, he's our chief scientist. We have multiple people working on this stuff, but he will be able to answer the question. So Tara, I encourage you to just.
00:45:32.668 - 00:45:38.762, Speaker A: Ask him, is he here? Is he in the chat or can we get him to come into gather town later?
00:45:38.816 - 00:45:41.514, Speaker B: Maybe we can try. Yes.
00:45:41.712 - 00:46:03.380, Speaker A: Okay. I think that would be awesome. Martin was asking, apart from implementing migrating from smart contracts to zinc, what else would be required to run a solution end to end locally or on a testnet example of zinc VM and layer two operator code available for local operation? Is it available?
00:46:04.550 - 00:46:44.960, Speaker B: So for local operation. You just need to run a node on the testnet. We will support deployment for multiple public testnets, so you don't have to worry about that. And I'm not sure I understand what specifically question is all about. So you just have to run a node. You can do it with Geth locally, and if you want to have it on your own ethereum testnet, you can just have a local testnet and a local installment of ZK sync and then it will work.
00:46:47.010 - 00:46:52.320, Speaker A: Cool. Kev asks, did you also copy Rust's demand driven compilation process?
00:46:57.350 - 00:46:59.940, Speaker B: What is demand driven compilation process?
00:47:01.190 - 00:47:42.480, Speaker A: Maybe if you can clarify. Also, I'll say it now, if there are any last questions, we should probably put them in the chat now. I think we have a few more minutes to take some there's some really good conversation happening here and I like know Isaac and you're answering questions. This is fantastic. I'm wondering if there's a way for me to export this after I'm going to have to check it out. Yeah, Kev, if you want to maybe just give a bit of context on that rust demand driven compilation process you mentioned. Also, Alex, you know that there's a 32nd delay, so we have to wait for a moment.
00:47:43.250 - 00:47:44.000, Speaker B: Sure.
00:47:48.550 - 00:48:01.094, Speaker A: Actually, I had a little in between question maybe, which is about the Gitcoin project that you did with that. Was there a zinc VM running? Is that also smart contract enabled or was that.
00:48:01.132 - 00:48:03.298, Speaker B: No, it's very simple. It's just payments.
00:48:03.474 - 00:48:03.910, Speaker A: Okay?
00:48:03.980 - 00:48:20.650, Speaker B: Payments are very stable now. They can be used with wallets. We're integrating them into smart wallets. They are simple, running for a long time and have proven themselves robust. Contracts are more experimental.
00:48:21.010 - 00:48:31.578, Speaker A: Okay, Ethereum working, asked Alex, could you explain more how the permissionless network of Zksync operators working together to ensure the surface availability?
00:48:31.754 - 00:49:10.410, Speaker B: Sure. We'll have a consensus in layer two with validators requiring like, they will have to put some education tokens at stake to become a validator and produce blocks. And so the way they produce blocks is similar to a normal side chain, with the only exception that once they produce a block, in order for this block to be actually happening on Ethereum, they also have like the block producer who is elected to produce this block will have to generate zero knowledge proof and submit it to ethereum. But the coordination will happen in this off chain consensus. Cool.
00:49:10.480 - 00:49:28.660, Speaker A: So Kev came back with some clarification on that earlier question. Is the new architecture that Rust is employing where compilation is no longer multi pass when you need to type check an expression for example, you query for the expression type and there's a document that is linked there.
00:49:30.310 - 00:50:18.610, Speaker B: I'm not the expert on compilers, so I said that exactly. But we simplified Rust. I'm not sure if it's multipass. It's probably multipass, but we don't do a complex type inference. And the reason for this is that a lot of people are having difficulty with rust because of unreadable error messages. They do something and then the compiler is so smart that it thinks that it should do some very complex type inference with templates, and it's probably some difficult construct which it doesn't understand, and it outputs a compiler error which is absolutely uncomprehendable. So we wanted to avoid that.
00:50:18.610 - 00:50:42.730, Speaker B: We definitely wanted people not to have this experience, and b that every error message is very helpful and helps you understand immediately what's going on. Because of that we have to simplify something. So the type inference is very simple and that's why we don't have full templates. Also, you don't need them in the smart contract.
00:50:45.710 - 00:50:56.830, Speaker A: Wej going back to the custom gates, just to clarify, does zinc have custom gates for Shaw 256? Is there a full list of operations with such custom gates?
00:50:57.890 - 00:51:09.166, Speaker B: We will publish it with the release of the next version of Zinc, but shot of s six k Chuck we do have custom gates for them.
00:51:09.348 - 00:51:26.886, Speaker A: Cool. Well, I'm going to assume that there's no more questions because it's been a moment since we've seen one. If there's any missed, I'm really sorry. We're going to head to gather town just after this, so maybe Alex, if I can get you over there too, we can continue the conversation there.
00:51:26.988 - 00:51:27.640, Speaker B: Sure.
00:51:28.170 - 00:51:29.480, Speaker A: So thanks again.
00:51:30.890 - 00:51:33.700, Speaker B: Thank you guys for listening. See you soon.

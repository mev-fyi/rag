00:00:00.320 - 00:00:04.140, Speaker A: Welcome to Goodgame. Your no BS insights for crypto founders.
00:00:07.520 - 00:00:13.480, Speaker B: Can I get a quick gauge of sentiment? Bullish neutral or bearish Cosmos? Because I'm hearing conflicting things.
00:00:13.520 - 00:00:17.060, Speaker C: Again, bearish short term, neutral long term.
00:00:17.600 - 00:00:18.456, Speaker A: I'm neutral.
00:00:18.568 - 00:00:33.902, Speaker B: Well can you actually be bearish short term than neutral long term? Because I kind of agree with Zaki that they have a 12 month window of opportunity. So if they don't succeed within the next 12 months, quote unquote succeed, do they really have another shot at dethroning Ethereum?
00:00:33.966 - 00:00:49.774, Speaker C: Yeah, I guess I'm slightly optimistic of them executing something interesting, but still not fully convinced that even if they execute it's going to be powerful enough to actually have some particularly like long standing ecosystem or value prop.
00:00:49.862 - 00:01:23.870, Speaker A: Looking for your next startup idea in crypto? Check out our Request for Startups list and get inspired at Alliance XYZ Forward slash ideas. Welcome to Good Game. This topic is going to be a very interesting topic around the modular thesis and more or less to understand how that's going to affect the Ethereum ecosystem, how it's going to affect founders users and then more importantly how is it going to affect its other blockchain networks like Cosmos? But before we get started we have a new guest. His name is Dimitri. Dimitri, do you want to give a quick background?
00:01:23.950 - 00:02:00.430, Speaker C: Yeah, sure. Happy to be on yeah Research partner at one kx generally focused on research, do a lot of writing in space across a number of topics. I've been more towards the infrastructure side of things. App chains, interop portfolio support, things around token design, go to market strategies, BDM partnerships and general investment. DD before that led investments in research at a crypto family office called Bollinger Investment Group. Did around 25 investments with a firm there and before that spend a year with a phone call coin fund for a year also doing research and didi. So overall investing in crypto since 2017 life pre crypto, much more boring.
00:02:00.430 - 00:02:04.798, Speaker C: Spent six years working at a bank across some growth strategy and innovation roles.
00:02:04.974 - 00:02:19.128, Speaker A: And Dimitri, like you know when people said they've been around since 2017, you've actually been around since 2017. I remember reading your articles back in the day. I think you were still at Berkeley from what I remember. Yeah. You went to Berkeley, right?
00:02:19.264 - 00:02:46.588, Speaker C: Yeah, yeah. First piece was on token standards. Yes, around when 1155s are coming out just after cryptokitties other standards that are coming out like998. And interestingly now we are seeing a reemergence. I think it's almost like a token standard summer between 4, 3, 3, 7. Some cool ones like 6551. Turns out this is actually an interesting go to market for teams as well.
00:02:46.588 - 00:02:51.564, Speaker C: It's your crypto equivalent of regulatory capture.6551.
00:02:51.572 - 00:03:26.744, Speaker A: Is interesting, but let's not go off on tangents because it's so easy to join crypto. But let's talk about the modular thesis. There's been a lot of content around the modular thesis and there's this new narrative of why we need to have our own data availability layer, our own roll ups, et cetera. But it could be pretty much broken down to a few functions, right? Consensus, data availability, execution, and maybe even system of bridges or bridges are like the three to four that I think are like the most important when we think about like modularity. So maybe diving deep, maybe Fuda or Dimitri, do you want to talk about what is the modular thesis?
00:03:26.872 - 00:04:00.894, Speaker D: Yeah, sure. Like I will start but I will let you, Dimitri, also add your thoughts. So modularity is a kind of a new thought in the our space because monolithic chains are suffering now. So like each chain, when, when Ethereum started, no one would speak about modularity. What modularity are you speaking about? Like everyone is trying to capture users. So all chains started at monolithic. The chain does everything possible, right? Like it does execution, it does consensus, it does data, data availability or data storage, it does settlement of the transaction.
00:04:00.894 - 00:04:41.888, Speaker D: So all the four main functions of a blockachain have been in one monolithic block. And there was actually this actually led to. It was a good design choice at this point because you cannot just build five pieces in parallel. So as Ethereum started to get users and the network started to get crowded, people started to think, okay, we need to actually start unbundling these pieces to achieve better throughput. And we saw this unbundling actually at a very interesting level. The first modularity happened at the node level. Like some protocols like Flow, for example, said we can actually unbundle these four pieces into different kind of nodes, but all of them are in the same network.
00:04:41.888 - 00:05:22.356, Speaker D: So the Flow network has four different kind of nodes, all using the same token, but still four different functionalities. It was recently when Ethereum changed the roadmap to rollup centric vision that we started actually having discussions about, oh, we can actually have these four different pieces as four different chains. And we are seeing actually some chains like Celestia coming to fill only one of these pieces, like data availability and consensus. And we are seeing rollups coming to fill the part at the top, which is execution. Roll ups will do execution. We can do everything else on the L1. So of course there is so many designs of rollups.
00:05:22.356 - 00:05:32.194, Speaker D: So I will let Dmitri take it from there if you have any thoughts or like you also Dmitry can walk us through like what kind of, what different kinds of rollups or like modular designs that you can see.
00:05:32.362 - 00:06:20.402, Speaker C: Yeah, no, I think that makes a lot of sense. I agree with you. It came from a need of scalability. I don't think that you could fit, you know, the entire, you know, global economy on top of one monolithic infrastructure. I also think about it as blockchains are fundamentally software controlling hardware. And so as you scale, I think what helps as a mental model is how do you create more specialized hardware that does a specific thing and the kinds of hardware requirements that you might need for DA is very different than what you might need for execution or in the flavor of a ZK roll up. If you have approver that hardware looks very different than if you have a normal or like a regular ETH to consensus client.
00:06:20.402 - 00:06:57.958, Speaker C: So a lot of the work around modularity I think also revolves around how do you start to specialize your hardware to actually achieve more scalability. And yeah, I think there's a lot of interesting flavors. I think we are seeing it mostly around DA and execution. I think there's a lot of very interesting experiments that we'll see around da da layers being live between celestia, polygon, avail, eigen, da. All very cool ideas. 4844 dank sharding. I think in practice we're seeing the most traction right now with the ones that are actually live between Optimistic and ZK rollups.
00:06:57.958 - 00:07:00.646, Speaker C: A question of whether you use crypto.
00:07:00.678 - 00:07:11.016, Speaker A: Economic versus cryptographic security before we dive deeper. Ciao. Any questions that we want to answer by the end of the episode that we're looking to learn more about?
00:07:11.168 - 00:07:41.806, Speaker B: The main question that bugs me, that has been bugging me for a while, is how much complexity is too much. Because on our last episode we talked about Solana, which is the antithesis of modular architecture. And obviously there are trade offs. But the nice thing about Solana is that at least conceptually it's simple. It's not easy, but it's simple. Consensus, execution, data availability layer, they're all done at the same layer. There's only one layer, one blockchain.
00:07:41.806 - 00:08:16.474, Speaker B: Ethereum started this way, but Ethereum is moving to more modular and with all these different layers unbundled, is this too complex from an engineering perspective and also from the perspective of builders? Picture yourself As a builder who's new to this space and you see a bunch of names, Arbitrum, Optimism, Ethereum, Polygon, Eigenlayer, Celestia, what the hell do you do with all these things? Right? So the question is, is this too much complexity? That's the main question I want to answer.
00:08:16.602 - 00:08:53.928, Speaker A: Got it. So maybe for some of our audience members that don't know what the modular thesis is, maybe we should talk a bit about what is consensus and what does that mean for Ethereum, like ordering of blocks 2 is data availability, where does the transactions get stored and is that transparent execution environment like with EVMs? And then I also like to touch on bridges, because I think bridges will become an important part of our conversation towards the end. So maybe talking about each of these Lego blocks and what are the startups that are building in these Lego blocks and then maybe we can dive deeper from there.
00:08:54.064 - 00:09:31.180, Speaker D: So I can take the first step at that because it can go along. Let's start from the application layer, because application layer is very obvious. Let's say that you are trading on a unit. In Uniswap, for example, you are actually changing bib token for USDC or something, right? So you as a user emit a transaction, you create a transaction. I want to sell this token, right? Someone else will come and buy this token or the liquidity provider position will change, right? So this is a transaction. This transaction affected your balance only, right? So it affected your individual state. We call this state like your balance on the chain.
00:09:31.180 - 00:09:55.938, Speaker D: Your what you hold is just called a state. So when you emit a transaction, you change your own state, but at the same exact block. Imran Chow dimension, All of you are emitting transactions, right? So we need to kind of settle all this transaction. So after execution comes settlement. We need to update execute these transactions and update everyone state. We call this settlement. So everyone knows their new state after that.
00:09:55.938 - 00:10:28.432, Speaker D: But do we agree on that? We have to agree on that. The network as a whole have to agree on that. That's why validators, each validator in the network have to re execute the transaction and all of us have to agree on the new state. And once we agree on the new state, we call this consensus. So we achieved consensus on the new state. So the new state now has to be stored somewhere because any newcomer to the network or any new transaction need to know what is the state of the wallet before it starts. So now we need to store this state somewhere for other people to be able to read it.
00:10:28.432 - 00:10:31.152, Speaker D: And this is the data availability where this data exists.
00:10:31.216 - 00:10:33.008, Speaker A: And right now, where does it get stored?
00:10:33.184 - 00:11:11.080, Speaker D: Yeah, like now everything is stored in the Ethereum. It is stored in the main blockchain. We have something called cold data, which is kinda, let's consider the state as a memory, your computer memory, your hard disk. You throw your data on your hard disk and now the data stays there for any people to come and read from it. Right. So at a higher level, modularity means that you have execution layer to execute transactions, you have settlement to know each one's balance, every individual balance. After this execution, then you have consensus that we already have to agree on the new state and that availability at the bottom, which is like we need to store this data somewhere to be able to retrieve it and know what the state of the blockchain at.
00:11:11.080 - 00:11:14.472, Speaker D: So this is a very quick description of the four layers.
00:11:14.616 - 00:11:41.360, Speaker A: Got it. Let's talk about like we touched on this a bit, which is data availability, right? Which is we have a couple things happening on the macro side, right? You have like Deng Sharding from the Ethereum side. You also have like Egan layer and others that are like building within the data availability layer. So maybe let's talk about what that means for founders. I know there's a concept of restaking as well, but what does it mean for the end rollups and people that are building this space?
00:11:41.460 - 00:13:19.886, Speaker C: For me, I think it's a matter of cost structure. Like the interesting part is for every dollar and we're finding this out in real time, for every dollar that is spent on gas, when you split that out, what proportion goes to da? What proportion goes to execution and settlement? And so the economics here are very interesting to observe in real time. And, and what we don't know that again we'll find out is, is it, you know, 80 cents on the dollar that is going to be paid for for DA for actually storing this? Or is it 20 cents or is it less? In my perspective, it's primarily a cost and security question. Where for example, you have one construction called a validium where DA is stored amongst a separate set of nodes and it's usually a smaller subset, it's usually cheaper to store for a lot of teams, you know, do they need E L1 equivalent DA security? If so, there's going to be a higher willingness to pay. But if they're fine with it being stored somewhere cheaper, then maybe it's a cost question for them. Maybe they could reduce the overall transaction costs for those application developers. My sense is for defi protocols on eth L2, you know, often your DA is your weakest link because you, you need them, for example for fraud proofs.
00:13:19.886 - 00:13:47.588, Speaker C: So if it's the weakest link and you want ETH L1 equivalent security, then a defi protocol might say I need eth L1 equivalent DA as well. So then maybe they might be more willing to pay the cost for 4844 but for a game maybe they're fine with a lydium construction and so for them they might use a cheaper DA option.
00:13:47.684 - 00:14:34.654, Speaker B: I have an anecdotal data point related to what you just said about cost structure. So I talked to a very specialized ZK rollup project recently and they told me that the DA, the data availability accounts for about 80%, very roughly 80% of the cost. And the remaining 20% is everything else, like execution, consensus, blah blah, blah. And the reason why he came up with this number is because the alternative of putting DA on Ethereum is to put the DA on, let's say at the extreme put it on AWS. And if you put the DA on AWS, you can basically save 80% of the cost of ultimately settling on Ethereum. So just a interesting data point.
00:14:34.742 - 00:14:36.398, Speaker D: Was this an optimistic roll up?
00:14:36.534 - 00:14:54.984, Speaker B: Just no, it's ZK. So the remaining 20%, a big chunk of it is actually the ZK Prover. So it's a combination of ZK proving and consensus. But you know, the exact breakdown is very hard to estimate. This is more of a intuition based estimate.
00:14:55.112 - 00:15:20.984, Speaker C: That's interesting. That's very surprising for me actually. I thought it was going to be the other way around. I thought that DA might actually end up being relatively commoditized outside of ETH L1 equivalent DA because as more of these solutions come up, you know, it, it feels like a more commoditized product to me than having globally secure settlement layer that could secure trillions of tvl.
00:15:21.032 - 00:15:45.336, Speaker B: That's really interesting, but you're talking about the future. In the future this stuff will be very commoditized. What I'm talking about is the current state of things. So today to settle the data from a roll up onto Ethereum layer one, 80% of that is DA. Our views are incompatible with each other. But also EIP4844 will reduce the 80% of DA down by an order of magnitude. One or two orders of magnitude.
00:15:45.336 - 00:15:47.520, Speaker B: At least that's what they think will happen.
00:15:47.600 - 00:15:48.496, Speaker A: Why is that right?
00:15:48.568 - 00:15:55.376, Speaker B: I mean that's the goal of EIP 4844. I mean Fudai, you probably know this better Than I. Yeah, okay.
00:15:55.408 - 00:16:31.060, Speaker D: Like as exactly what you mentioned Chad, the cost of storing that data of transaction from a rollup TO Ethereum is 80% of the cost. Right. So what if you can somehow take this data and store it somewhere else and keep save this 80%. So this is the whole philosophy not just behind EIB 4448 like it's also Eigen DA and Celestia, all of them have the same exact goal. Let's put this data somewhere else. And the design choices are different. So eignda says you can do this today through EIGNDA and do use restaking.
00:16:31.060 - 00:17:14.420, Speaker D: So the same iteration you're using for staking will be used to secure the data. So this one design, the other design Celestia says no, no, you can give us this data for you to skip and you will pay us our using our own token. So crypto economic security. So that's one the third way that as Dimitri mentioned that you can just store it in aws like who cares right? Like put it in a validium, put the data on aws. Ethereum like data blocks concept is that you will create this data space as a separate or a side blockchain to Ethereum that only focuses in data. It will not do execution, it will just do that. So it is the same concept as Eigenda but it's a kind of Ethereum foundation sponsored.
00:17:14.420 - 00:17:16.612, Speaker D: It's part of the, part of the.
00:17:16.636 - 00:17:28.772, Speaker A: Process here I thought Deng Sharding was more for like temporary memory or temporary data. Whereas like eganda and others are more long term data. Is that true or no?
00:17:28.876 - 00:17:33.694, Speaker D: Okay, so what do you mean by timber that like a ram like you.
00:17:33.702 - 00:17:42.638, Speaker A: Know, like it will flush out and you know at a certain time period it will flush out and people can continue storing data within Ethereum to some extent.
00:17:42.734 - 00:17:49.278, Speaker D: Yes. Dimetric, you can add more color into that. But we have two concepts of memory on any node.
00:17:49.374 - 00:17:50.110, Speaker A: Yeah.
00:17:50.270 - 00:18:30.500, Speaker D: Which is like the active data, your account balance, my account balance at the exact moment and your historical data. Let's put historical data to the side. The idea of data blocks is that when you transact on a rollup after a bit, after two weeks or so, your state doesn't matter anymore. You don't need to keep the data availability anymore because the data probably has progressed and you can go to archiver nodes to get this data. So yes, the data blocks concept that you will save the data for some time and then after two weeks or a month or whatever amount you decide on, the older state will disappear. But you're still keeping the current state. Dimitri, do you agree?
00:18:30.620 - 00:19:27.724, Speaker C: I think that conceptually makes sense. I think also just goes back to Chao's question around complexity, where there's different flavors of doing this. I think it ultimately comes down to to what extent does this benefit end users or application developers. It's largely a question of cost. From one perspective, if it is significantly cheaper for devs or users, then it might be worth actually going through and implementing this design pattern. I kind of think about it as, you know, if you want to build a car, like the usual analogy when building a startup, like you don't do like the wheels and then the chassis and then the steering wheel, you start with a scooter and then a bicycle and then a car. And I think these DA constructions are finding ways to potentially reduce transaction costs.
00:19:27.724 - 00:20:00.546, Speaker C: I don't know which flavor is going to be preferred, but I like the idea of for a startup or like an application developer, when thinking about which DA solution to choose from, what pain points are they trying to solve for and then what additional complexity are they taking on? And if the cost benefit or the security benefit is worth it. Yeah, maybe you, you should opt in for the complexity.
00:20:00.658 - 00:20:56.366, Speaker B: It almost feels like at some point there needs to be a AWS type of product for developers where you have a nice front end that gives you a few options to choose from. As a developer, you can choose which da, for example, the Ethereum foundation version of DA or the Celestia or Eagle layer, et cetera. And then there's another option for another drop down, literally a drop down on the UX for which roll up. Is it optimistic roll up or ZK rollup or something else? And that's the whole idea behind Caldera, for example, that you guys invested also went through our program. So moving from data availability to the roll up side of things, what is the current landscape that you're seeing? Because there's obviously Arbitrum optimism, a bunch of app chain rollups and then there's shared sequencer, A lot of complexity, a lot of names. What's the landscape?
00:20:56.478 - 00:21:39.606, Speaker C: I think in general we're kind of seeing the usual suspects around arbitrum, optimism, zksync, starkware that have their flavors of either optimistic or zk. I think there is some interesting ideas around how L3s might look like both on starkware and the hyper chains that zk sync is working on. You can conceptually do an L3 on top of an optimistic roll up. I think Arbitrum has been working on that. I believe they Call it Orbit. I think these are very cool constructions. I like the idea of giving developers the opportunity to have their own block space.
00:21:39.606 - 00:22:34.782, Speaker C: It feels like a lot of applications are exploring that right now. Most are probably still on a lot of these monolithic L2s I'll call them because of user eyeballs, effectively liquidity. I think to have a vibrant application specific L2 ecosystem or L3 ecosystem, you probably need to solve for things like bridging and cross rollup. Atomistic city. And that's where a lot of the ideas around shared sequencers come in. Most of these roll ups today, I mean, I think all of them today is single sequencer. And part of the exploration that's happened in, in the last year is well, what if we decentralize this or, or what are even the issues here? And, and a lot of folks are saying okay, well censorship, resistance is an issue, liveness is an issue.
00:22:34.782 - 00:23:57.524, Speaker C: What if someone finds where Arbitrum's single node is and they blow up the data center? People would not be happy. So do you need to build in some redundancy in the system? And then I think a lot of the thought evolved and said okay, well is there really a benefit to decentralizing a single roll up? Maybe you could have some very vanilla flavor of like round robin where you have, I don't know, like some, I don't even know if you need it to, to be stake weight, but having multiple options to actually sell to L1. But you don't solve a lot of the issues around bridging and cross roll up communication. And the notion of shared sequencers is probably relatively more novel. It's, it's, it's the idea of can you split, I suppose transaction ordering from transaction execution. So introducing another layer of modularity with the benefit of if you do have a shared sequencer set that is providing ordering for multiple roll ups, what can you do there? The cool benefit there it might be the most clear benefit is that bridging and atomic composability become slightly easier. It, it almost comes for free if you have a fully overlapping shared sequencer set.
00:23:57.524 - 00:24:04.324, Speaker C: So I, I think it's a very interesting direction like things that Astria Espresso Radius are working on.
00:24:04.412 - 00:24:38.950, Speaker B: Dimitri, I probably have like 10 questions from the last two minutes and some of them are for my, some of them are for myself and others are for the audience. I think this requires going back to the basics of defining what is for example L3, L2, what is atomicity at atomic composability and bridging et cetera. But let's start with the first one. You mentioned L3 and an L2. What is exactly an L3? This is actually a question for me. What is exactly L3 and why would you as a developer do an L3 versus doing a L2 app chain?
00:24:39.110 - 00:25:03.344, Speaker C: Yeah. So that is still up in the air. I think all layers are blockchains. They're just blockchains with two way trust Minimized bridges is the way I frame it. And what L2s do is they post their. Their state, you know, like their settlement transaction to L1, the L3 design pattern. Post that to the L2.
00:25:03.344 - 00:26:01.912, Speaker C: For the ZK variant you would have the L3 post the validity proof to the L2 and then that is recursed into the validity proof down to L1. For optimistic it's a bit cloudier where I suppose you. You have the state route posted to L2 and then that's posted to L1. I see a bit less of a benefit there because the L3 security on an optimistic roll up still falls back to the fraud proof window for the L2 going back to L1. So I'm not sure you get much of a security benefit there. I think the ZK variant with recursion is a bit more interesting why someone would do it. I think ultimately it's around customizability and somewhat business model potentially to have their own token for example use as the GAS token.
00:26:01.912 - 00:26:25.574, Speaker C: I think that's often interesting for teams. I think this is also a good opportunity for the reemergence of enterprise blockchain. But they could actually be their own L2s or L3s. It gives you access to the L2 liquidity and end user base and it makes bridging easier Amongst the different L3s.
00:26:25.662 - 00:26:45.366, Speaker A: Is it like a similar thesis to base where base is developing their own chain within the optimistic bedrock framework and they're bringing their own users into this kind of permission KYC chain. But that's ultimately bringing in a whole new set of users that wouldn't have been able to come before. Is that how you're thinking about it?
00:26:45.438 - 00:26:48.694, Speaker D: But basis are still an L2.
00:26:48.862 - 00:26:50.742, Speaker A: Say it again. Basis and L2.
00:26:50.766 - 00:27:15.184, Speaker D: That's right. I think LS3 is more complex kind of. It's a kind of replicating what is happening between L2 and L1 another level up. So L3 to L2. But there's actually a very nice distinction here that was actually commented really well or captured really well by Vitalik himself when he said like actually LS3 currently feels like a marketing term. Everyone is saying I'm building as an LS3, which is.
00:27:15.272 - 00:27:16.928, Speaker B: That's what I feel too same.
00:27:16.984 - 00:27:59.066, Speaker D: You know why? You know why? Because the data availability, like it's a funny. The funny thing that it's a marketing term because exactly the terms that we have been discussing since the beginning, which is that availability, right? If you are rolling the data from the L3 to the L2 and then the L2 is rolling its data back to the L1, then the L3 data is rolled back all the way to the L1. So you are paying the exact same cost. So you cannot have actually like any saving or any advantage actually of building an L3. So I define L3 in a funny way. I call it, I think Achao had I had discussion with you before. The true L3 and the fake L3, the true L3 that ends its relation with life to the L2 like the data availability is only posted to the L2 end of the story.
00:27:59.066 - 00:28:27.060, Speaker D: It's not all down to the L1 then yes, it depends on the security assumption of the L2 to live. So it's a layer on top of L2, the fake L3 which actually what people say right now that yeah, we just build on top of Starkware or maybe Zksync or Arbitrum as an LS3 but essentially our data still will live on the L1. So it's actually an L2 that is market as L3 for the community to give them some grant or something.
00:28:27.680 - 00:29:18.030, Speaker C: Yeah, it's interesting there might be some cases where it makes sense. If you have for example an application specific L2 that is a certain gaming ecosystem, then what you might have is potentially L3s with their own games that potentially leverage the IP of the L2 and those games can have their own economies. But then they use that L2 as some like connectivity back down. That is largely theoretical. Like a communications layer, communications layer, shared liquidity and interop layer. But yeah, it's definitely still in the idea maze to actually figure out like where this makes most sense to your question on atomicity, it's an all or none transaction. So either you execute both things or multiple things.
00:29:18.030 - 00:30:04.426, Speaker C: It could be a chain and if any one of those fail, then everything reverts. This is particularly important in defi, particularly around liquidations. Atomic what? Flash loans are a feature that you get from atomicity. It's fascinating because you can effectively have infinite leverage with zero credit risk. I suppose so. So it's a really important concept around keeping the defi ecosystem kind of balanced across different rollups. You can have composability, meaning you can interact with different L2s, but you might need either a bridge that goes between the L2s or you go back down to L1 and read one L2 reads the state that was posted from another L2 to that L1 and then they take an action.
00:30:04.426 - 00:30:14.394, Speaker C: But if you wanted to say, do a flash loan across two different L2s, that's where the notion of atomic composability would be particularly important.
00:30:14.482 - 00:30:19.946, Speaker B: Dimitri, can you define atomic composability in the context of rollups?
00:30:20.058 - 00:30:52.078, Speaker C: Yeah. So if you have, say you have in the world where you have uni chain and maker chain, and maker is not a cosmos chain, it's an L2 and there's a liquidation on maker chain. You would want some actor, some liquidation bottom to take the collateral, take it to unichain, swap it and then deposit it back to maker chain. And so that all needs to happen atomically.
00:30:52.174 - 00:30:58.078, Speaker B: But what does atomically mean exactly? Because on the layer one it means. Typically means within the same block.
00:30:58.174 - 00:31:15.562, Speaker C: Within the same block. Yeah, yeah, you're. I suppose you're assuming that the different L2s had some alignment between their block times. It's an alignment, I suppose within the same blocks that are mined, I suppose on each of the different lts.
00:31:15.706 - 00:31:28.890, Speaker B: And today they're not synced. Right. But something like a shared sequencer might potentially enable the syncing or you're skeptical.
00:31:29.050 - 00:32:04.018, Speaker D: That's what I was going to say. Even if they are synced, atomic composability is not possible simply because you need to kind of transfer an asset from the roll up one to roll up to do an action and transfer the asset back in to the one in one chain, in one block, in one second, in one fight, whatever, whatever time period. This is not going to happen. The security guarantees gets broken. Once you move from one chain to the other, security guarantees is broken, done. What you can do actually using shared sequencer is ordering transaction. And this has different use cases.
00:32:04.018 - 00:32:10.018, Speaker D: It's not liquidations, it's not flash loans, maybe arbitrage. And I think we discussed this before.
00:32:10.154 - 00:32:12.882, Speaker A: Would this be considered like asynchronous composability?
00:32:13.026 - 00:32:30.026, Speaker D: Yes. It's not atomic, like we can call it non atomic. We can create a new term. Now, given that we are all here, we can say non atomic composability. Right. Like so it's a composability in something that you can force some order of transactions to be run on different machines, but they are not atomic. You don't.
00:32:30.026 - 00:32:54.752, Speaker D: You cannot move assets between these two chains unless you have pools of capital sitting. Let's say that you are liquidating something in here and on. I will use the same examples that Dimitri gave. Like you are, you have the maker roll up and you have the mini swap roll up. If you have infinite pools of capital composite chains, then you can kind of use this liquidity. But moving the same asset back and forth breaks atomic composability for sure.
00:32:54.856 - 00:33:05.264, Speaker B: Okay, so for audience, how does a shared sequencer work? Okay, actually what is the goal of it? So first of all, what is the problem that is trying to solve? And two, how does it solve it?
00:33:05.352 - 00:33:46.810, Speaker C: Liveness and censorship resistance is what I hear about the most around. Again, if you have a single sequencer, it is fairly non trivial for that sequencer to censor your transactions. That sequencer can go offline. And so then all the users on the L2 are forced to do a manual exit back to L1. They could do it, but I can imagine the UX for that is probably pretty awful. So ideally you want to reduce, I suppose, the possibility of that happening. There can be other ways of doing it.
00:33:46.810 - 00:34:33.300, Speaker C: I suppose. For a given L2 you can always checkpoint back to the last commitment to L1. So maybe you can have another L2 sequencer that is spun up that effectively like restart state from the last checkpoint. But the sequencer bridge, admin keys or like multisig keys are probably still going to be controlled by a single entity. So that still gets difficult, I suppose. Yeah, the idea of a shared sequencer is to split the notion of ordering and execution. You can still have a single roll up operator, do the state transition and then post that state transition down to L1.
00:34:33.300 - 00:35:05.592, Speaker C: But it's not focused on the actual transaction ordering. That can be a separate group of nodes effectively that do it. And yeah, I think like I mentioned before, like the nice thing that you get for free is because that ordering layer can touch multiple roll ups, it can give soft guarantees of inclusion across different roll ups and it could also effectively act as a bridging mechanism between those different roll ups. Curious.
00:35:05.656 - 00:35:48.098, Speaker D: Yeah, like actually like when you were talking, I remember the recent tweet from Kyle Samani when he was actually speaking about a different kind of shared sequencers, which he called it centralized short sequencer, which is like exactly that. It's like you have a single sequencer, but instead of this single centralized sequencer and. But instead of it operating only on one roll up, it's Operating on multiple roll ups. And, and this is. I would. The discussion was around how would we progress to the things that you were describing, Dimitri, which is decentralized shared sequencer, something like Astrea or Espresso or Radius when you have actually a network operating as a sequencer. Right.
00:35:48.098 - 00:36:30.990, Speaker D: So this can be a decentralized shared sequencer. But there is actually people now actually thinking of can we actually to enable composability between some kind of composability obviously between different genes by just making it a shared sequencer that is centralized and everything. But it's like shared. So this is what came into my head and made me laugh because people are trying to go for the easiest solution possible to solve the problem which is like oh, we are breaking composability by having multiple roll ups. So let's solve it by having a sequencer layer that is shared but it's still centralized. So we didn't like. It's just they are not focused on decentralization anymore.
00:36:30.990 - 00:36:33.310, Speaker D: So this is just kind of funny.
00:36:33.390 - 00:37:15.256, Speaker B: Okay, but. But from my understanding of what you guys described, Dimitri and Futa, there's actually two problems. One is breaking the composability of having too many rollups and the other one is decentralization, which currently is not the case because they all use one centralized sequencer. So these are two distinct problems that may be solved with a decentralized shared sequencer network. But the problem of decentralization isn't conceptually the easiest solution, that the rollup just recruits more sequencers rather than talking to a decentralized sequencer network. Like why can't Arbitrum just recruit their own sequencers as opposed to creating a new Astria or Express or whatever.
00:37:15.368 - 00:37:24.662, Speaker D: It will not solve the composability. Essentially like Z can have. Z can decentralize, sequential and be happy. But they will not solve the composability issue.
00:37:24.766 - 00:37:40.854, Speaker B: Correct. But if I were Arbitrum, my incentive, my goal is to be the only roll up that wins everything. I don't care about composability. I actually want optimism to lose so that they become irrelevant and then composability doesn't matter in the first place.
00:37:41.022 - 00:38:16.732, Speaker D: Yes, but they will still need. They will need a shared sequencers for all the roll ups that use their tech stack. That's what the optimism super exchange is all about. Optimism now is not a single chain and Arbitrum is actually moving in the same direction. They said we will open our tech stack for anyone to use and you know what? We will give you even ARP tokens as a grant to build another etho in our ecosystem. So Arbitrum and optimism now is moving in some direction. They want to have many roll ups within their ecosystem and for the.
00:38:16.732 - 00:38:23.640, Speaker D: For compatibility between this sub roll ups or whatever, you still need a short sequencer. It's a must.
00:38:23.940 - 00:39:10.048, Speaker C: But the difference is it's the RB for example, like shared sequencer or the OP labs one that is operating across all of the roll ups that are building within their ecosystems. Exactly. Ciao. What you're referring to is an incentive misalignment problem or an incentive alignment problem where the walled gardens are being recreated, not full walled gardens. But it seems like there's not an incentive to actually achieve atomic composability between different roll ups because you actually want, you know. Well, you know, keep DeFi on RB because you're. You're able to have.
00:39:10.048 - 00:39:28.928, Speaker C: Yeah, yeah, for sure, for sure. That's why I'm a bit torn on the. I don't want to say like viability, but go to market I think is going to be interesting on this. And again this goes back to complexity. Like to what extent do you need to decentralize everything? Like go back to your, your. Your end users. Like.
00:39:28.928 - 00:40:30.040, Speaker C: Like which Persona actually needs these properties today? Maybe there's enough of an ecosystem within a certain roll up that they have less of a need for that. So are you creating a solution for a problem that doesn't exist there today? I think applications are probably more concerned with low fees, higher throughput, predictable gas cost costs. Interesting. Like business model ideas around introducing pre compiles that have not been included in ETH L1 yet that enables their user base or use cases to do novel things. I feel like that's more important today than actually figuring out a way to solve for the theoretical of liveness and censorship resistance. That's probably more of a contentious statement that I might get some DMs on later, but I think it's in order.
00:40:30.080 - 00:41:11.094, Speaker B: Of operations follow up question. I feel like the two of you send me various mixed signals and in fact Fuda, you said a couple of things earlier that are seemingly conflicting and it's probably me misunderstanding you guys, but it seems to me that Dimitri, you think atomic composability is possible and Fuda, you think that it's not possible. But my understanding of what you just described as shared sequencer, if you have a shared sequencer node that is used by both arbitrum and optimism that handles the consensus and transaction ordering of both, why is atomic composability not possible. I'm probably just misunderstanding this, but I want to get to the bottom.
00:41:11.142 - 00:41:16.852, Speaker D: Let's clarify first your statement. Dmitry, do you believe that atomic composability is possible using shared sequences?
00:41:17.006 - 00:41:17.768, Speaker C: Yes.
00:41:17.944 - 00:42:07.134, Speaker D: Okay, I am the opposite scam then. Like I don't believe that atomic composability is possible. So you got this right way. Chao, I can explain my reasoning, and I kind of did. But atomic compatibility for me means that you can take a flash loan from an application, move this flash loan, take a million USDC from one chain, move this 1 million USDC to another chain, do something with this 1 million USDC, then get whatever, do arbitrage, move back the one USDC to the first application. So you can do this now on Ethereum L1 and you can do it in one transaction, not even one transaction. You run a smart contract that has all these transactions and all of this happens and done.
00:42:07.134 - 00:42:25.130, Speaker D: Voila. Right? So this is possible because of two things. Because you have the ability to order transactions. This is the fact that you have a smart contract that contains these transactions in order. This is one. The second one is that you have liquidity. You can move this liquidity within the same blockchain.
00:42:25.130 - 00:43:11.726, Speaker D: Your state is known to every player, to every validator. Maybe we can add a third one that watch the definition of atomic. If any of this transaction fail, then all of the smart contracts will revert and you don't lose any money. So let's take these three properties and examine them again in the case of two different roll ups with a short sequencer. So we're assuming they have a short sequencer so you can take flash loan from a roll up. One, you want to move this liquidity to the rollup. Two, can you do this in the same clock, in the same transaction as executing the transaction? I don't think it's possible today that you do a transfer of assay between DOFLA and do things in that and go back.
00:43:11.726 - 00:43:39.382, Speaker D: So today, for the foreseeable future, I don't think it's possible. The other part that is breaking the atomic composability for me is that you can do some of that, but if the last step failed, you have no guarantee whatsoever to revert everything whatever has happened, has happened. You need just a week. So can the short sequencer guarantee that? I doubt it. Yes, like they can order transaction, but who knows, right?
00:43:39.486 - 00:43:55.286, Speaker C: So it's interesting, can you do that if for example, you have two different roll ups which share the same sequencer set with a rule base that each so they all have access to the same mempool, they all have their own.
00:43:55.438 - 00:43:55.846, Speaker D: They.
00:43:55.918 - 00:44:12.994, Speaker C: They have each other's state transition function in the logic and there is inclusion criteria there meaning you need to have one to go through in order for the other to execute within the shared sequencer logic.
00:44:13.042 - 00:45:02.986, Speaker D: Yeah but now you recoupled like the shared sequencer we started by this is that shared sequencer separates execution from ordering. Right? Now what you said now is exactly recoupling both recovering consensus to execution that if this doesn't execute then consensus have to fail kind of right or like you cannot proceed. So the idea of shared sequencer that you take this ordering piece, put it aside and separate it from consensus, we don't need or settle. Yes, it can. In, in the way I describe it, it can, it's possible but you kind of walk, walk back on the first assumption which is like now you cannot, you cannot progress in the chain unless you do what the search sequencer told you to do. So so something like that. So it's kind of tricky I'm sure like there is people in this space way smarter than me and they will figure out how to do it.
00:45:02.986 - 00:45:08.298, Speaker D: But as of now with my limited knowledge I don't see it happening in the next couple of years.
00:45:08.434 - 00:45:13.990, Speaker A: Maybe talking more about the shared sequencers unless. Is there any follow up to this?
00:45:14.930 - 00:45:17.430, Speaker D: I think Icha was enjoying like.
00:45:19.410 - 00:45:19.994, Speaker A: The debate.
00:45:20.042 - 00:45:22.670, Speaker D: What do you mean? Conflict with debate. Go ahead Icha.
00:45:23.970 - 00:46:00.476, Speaker B: I do have a follow up question which is a direct result of your disagreement which is bridging. So you two disagree on whether or not atomic composability is possible today. So then the natural question is what is the ideal bridge across rollups in several dimensions in terms of composability, in terms of fees, in terms of latency. These are the things I think are the most important factors for the end users. This is a question I have not been able to answer myself. What is the future of cross roll.
00:46:00.508 - 00:46:45.822, Speaker C: Up bridges to your point on atomic composability? Also like I don't think it's possible today. I guess I was more saying there might be ways to do it in the future but I think these constructions are still in progress. So still TBD for. For quite some time. I've been thinking about bridging in the context of L2s for, for quite some time. I think within a given L2 ecosystem there might be less of a need for a third party bridge. I think a lot of these L2 ecosystems, between their roll ups and potentially L3s they will probably, probably use homegrown messaging systems.
00:46:45.822 - 00:47:55.114, Speaker C: I think that's probably the safest for them. We've seen this in other areas like Avalanche, like rolled out their own messaging system obviously like IBC. I think you can have ways to use AL2. Say different L2s can read from the fraud proof or validity proof that's post to the L1 and then use the DA as the bridging mechanism where one L2 can check the fraud proof against the state route on some DA and say okay, this is valid and so that L2 takes an action on their side. So two different L2s can use L1 to bridge and then different L3s can use the L2 as effectively the the summit layer. Where it becomes harder is if you're going across different L2 or L3 ecosystems or if you're going across chains I think you for sure need a third party bridge. If you are going like off Ethel 1 that's unavoidable for anything else.
00:47:55.114 - 00:48:29.222, Speaker C: And then you have all of your flavors of transport verification layers that do that. But I think AE realization for me relatively recently is that within a certain L2 ecosystem you probably might not need a third party bridge as as much as we thought there can be use cases where you can have operators front liquidity between two different L2s on the liquidity layer. But on the transport and verification layer I think that could happen without a third party bridge.
00:48:29.346 - 00:48:44.606, Speaker D: I will have a follow up question to this one. So like do you think the IBC style bridges is like. Is a way to go for like inter roll up bridges or like what would be the ideal bridge between different roll ups? Let's say Ethereum roll ups.
00:48:44.718 - 00:49:15.514, Speaker C: You need finality for ibc so. So it's hard on. I mean like you'll have a finality gadget but that'll give you know, that'll give you some baseline. Was it like every 50 blocks or something? So that's like the fastest. I suppose that in IBC type construction would work. I guess that's like to Imran's point in the beginning like what did Cosmos do better? It baked in interop from day one. I don't think that EF has any roadmap to think about ecosystem wide interop.
00:49:15.514 - 00:49:36.416, Speaker C: Ideally there would be standards on this but I think they've just kind of left it to roll up teams to figure it out by themselves. And I think that's why you have this mush of dozens of projects that are trying to do it on their own. I think that's still an ethereum problem that has not been solved.
00:49:36.528 - 00:50:11.264, Speaker A: Okay, I want to go back to the shared sequencer topic. Specifically around right now you have centralized sequencers that are ran by layer 2s. Arbitrum runs one, optimism runs one. What is a path to decentralization? So an example is like you mentioned Austria and Nespresso, right? Are the two decentralized sequencer networks. What do you think is their go to market strategy? How do you think they're going to one get alignment with those L2s? And then how do you think about deploying additional sequencers in a way that's composable with all the L2s that are out there?
00:50:11.352 - 00:50:17.150, Speaker C: I think it's hard. I think if Arbitrum wants to decentralized, I think they.
00:50:17.270 - 00:50:23.470, Speaker A: Sorry, is it opt in as well or is it something that they can do on their own or do they have to, do they have to get alignment with those L2s?
00:50:23.550 - 00:51:22.836, Speaker C: I assume it would be opt in. You know I think the thing that would push them, like really push them is some regulatory pushback. You know I think like, like that's going to be a concern. You know, like are you considered a money transmitter if you're running a single sequence? I'm not a lawyer. How does the CFTC look at you? If you are app specific L2 that's running perp dex, should you be sharding the order book amongst a sequencer set? That's basically it is a benefit to DYBX on Cosmos that order book is distributed. You can't do that on an E L2 unless you decentralize the sequencer, which is I guess different from having a shared sequencer. But I think that that would be in my opinion the thing that leads them to want to do this sooner rather than later.
00:51:22.836 - 00:51:57.668, Speaker C: So within a given ecosystem I can imagine RVs like working on this. I presented this last year on some like preliminary ideas. I don't think you, you need it to be stake weight. I think just like simple round robin around who, who gets the post L1 they capture MEV fees, there's some business model there. It becomes harder. If you're trying to say hey RB sequencer, go also order transactions from optimism roll ups. I don't know how they make friends with each other there.
00:51:57.774 - 00:52:43.676, Speaker A: So primarily you think it's going to be a regulatory push. It could also be community push. I know right now Arbitrum makes quite a lot of money from running a centralized sequencer whereby they give that back to the community or some portion of the fees back to the community or they put in a dao where they reinvest back into the community. I'll be very curious to see how that actually plays out in the long run. Especially if you have these shared centralized sequencers. They have to one, try to get opt in from those Networks or those layer 2s, and then over time they have to decentralize in a way that it forces some sort of composability or asynchronous composability between the different layer 2 networks. So let's say Austria and the others were able to get opt in from let's say Optimism, Arbitrum and others and they run these decentralized sequencers.
00:52:43.676 - 00:53:09.682, Speaker A: The question that I would have is like one who's running the centralized sequencers or decentralized sequencers within Austria and Espresso? Like how does that look like and how does that work? Are they really decentralized or are they running in the back end? Like I'm curious on like how are they doing that today? And then if that was to happen, that would this create this like kind of shared composability network where they're able to like do maybe not composable transactions, but some sort of asynchronous composability?
00:53:09.826 - 00:54:01.870, Speaker C: Yeah, I mean like that feels nice to think about from an ecosystem perspective. I have not dug into ASTRIA or Espresso enough to understand implementation wise who runs it, whether it's like a permission set or whitelisted set or if it's fully permissionless. I can imagine it's probably easier to just have whitelisted parties in the beginning and minimum viable, you know, like start with 5 to 30 and then see how, how far you get there. You, you, you probably need to offer some benefit to, you know, if it's like RB foundation and OP foundation that are, you know, running for each other, like why would they participate? I can imagine the, the community argument, but I don't know. Like, I have not spoken to anyone there, so I don't want to speak at it.
00:54:01.910 - 00:54:40.914, Speaker D: I read a little bit about Astria and Espresso and I think it's a kind of, they have a network of consequences and they kind of randomly select which sequencer will sequence the next block over different chains. So it depends on VDFs, verifiable delay functions that you have to stake the token of the network and then based on how much you stake, you will get a number of slots, but you don't know which slots you will get beforehand. You will have to run VDFs to know the slot and VDFs are. Yeah, it's a consensus problem, as any concept problem. The advantage is that it's a simpler one. You just need to pick one from a pool. So you don't execute anything.
00:54:40.914 - 00:54:55.954, Speaker D: You don't get consensus on execution. You just. Okay, I have 10, I want to pick one of 10 randomly. So this shared sequencers network actually do consensus. There is no way around it. But it's a random one and a similar one.
00:54:56.042 - 00:54:56.290, Speaker A: Right.
00:54:56.330 - 00:55:08.202, Speaker C: Because Espresso has a variant of Hot stuff. So yes, they use that and then the VDF is for the selection of who executes it at the end. Or is that VDF based to select.
00:55:08.266 - 00:55:30.538, Speaker D: Like if we are 10 sequencers who are participating, like who us will be doing the next block or next order, this is where the VDFs come in to select one of us to take this slot. Gotcha. We have done a lot of discussion in short sequencer, so it's a very interesting topic. We focused on this one a lot.
00:55:30.594 - 00:55:33.924, Speaker A: So I think we can touch on.
00:55:34.012 - 00:56:02.940, Speaker B: Well, yeah, sorry, I was going to say we have three options now. At least three. We can either branch from a shared sequencer into MEV on L2, which is a whole interesting topic of its own, or we can talk about Eigenlayer, which may be related to everything we've talked about so far. Or we can also talk about Cosmos. I know Dimitri has a lot of thoughts and strong opinions about Cosmos and so do we.
00:56:04.120 - 00:56:04.816, Speaker A: We do, yeah.
00:56:04.848 - 00:56:06.000, Speaker B: What do you guys want to talk about?
00:56:06.120 - 00:56:12.336, Speaker A: I mean Cosmos makes the most sense, but yeah, I think. Yeah, yeah.
00:56:12.368 - 00:57:03.374, Speaker C: For Cosmos, I suppose the. You know, I've been trying to figure out where you compete as like a Cosmos chain. And if you're trying to be a sediment layer for Defi, it's really tough to compete with ETH as a sentiment layer. And if you're trying to be a gaming chain, it's really tough to compete with the culture or like maybe the BD rather on like Polygon. And then if you're trying to do like art and NFTs and it's really hard to compete with the culture on eth. And so I feel like a lot of that. And if you're trying to do interesting things at the base layer side, you know, at most had this really cool like flavor of 1559 where a portion of the gas fees burned would go to the.
00:57:03.374 - 00:57:46.200, Speaker C: The developers. Canto has some interesting like public good stuff there. I would argue a lot of that can be Pre compiled on L2s. So a lot of the features which you're building an entire chain for and paying a ton for security can just be a feature on. Ideally an L2 with a decentralized sequencer set like that probably gets you very close to Cosmos, but you still get the benefits of having ecosystem, cultural alignment, liquidity alignment. I think where it probably does make sense is if you truly need a very high degree of customization that you cannot get. I mean again, like we don't have decentralized sequencer sets or sequence or shared signatures live.
00:57:46.200 - 00:58:17.684, Speaker C: This is like all conceptual, you know, but you can bake that into like the Tendermint SDK support set out of the box. So if you actually need that today, that's probably a good option for you. So I almost view it as an order of operations around where teams launch. And historically They've launched on L1. I think now we're seeing that flip a bit. And teams are launching on L2s first as a go to market. I've seen them launch on other EVMs in some cases like GMX actually started on BSC.
00:58:17.684 - 00:59:00.080, Speaker C: I didn't know that until very recently. So you can have migrations and I think once you get to a place where maybe you've outgrown the capabilities, but you need these capabilities for a better experience for your end users, then maybe it makes sense to have your own Cosmos chain. So I think it will make sense potentially for more teams over time, assuming those applications grow to scale where they need it. But there's a tension there between having that ability on a Cosmos chain and potentially L2s having that ability through pre compiles and decentralized.
00:59:00.660 - 00:59:47.080, Speaker B: Dimitri, I want to touch on the three verticals that you talked about at the beginning. How does Cosmos compete with in Defi, in gaming and in NFTs? So NFTs, I strongly agree with you. The Culture is something that Cosmos simply cannot compete with. Ethereum, Culture wise or even Solana. Solana and Ethereum both have a very strong NFT culture and Culture itself has very strong network effect that's very hard to Cosmos to overcome. Defi, I think for the most part I agree with you. We know for a fact that many blue chip Defi protocols are looking to launch their own app chain and they want to do so on an Ethereum roll up as their own app chain as opposed to a Cosmos zone.
00:59:47.080 - 01:00:24.782, Speaker B: This is the thing that really pushed me to change my mind on Cosmos in the last six months. Over the last six months, Cosmos is the only thing That I had a.186 months ago we did an episode where we. That was when they published the Cosmos 2.0 Vision. You might remember that we're extremely bullish. And then recently the move of Ethereum blue chip defi protocols onto their roll up app chains is causing me to not feel bearish on Cosmos, but certainly feel that Cosmos is feeling a huge threat.
01:00:24.782 - 01:00:27.934, Speaker B: It's facing a huge threat from Ethereum in Defi.
01:00:28.062 - 01:00:29.838, Speaker A: Could we dive a little bit deeper on the Defi side?
01:00:29.894 - 01:00:31.630, Speaker B: I can't share the names, but.
01:00:31.750 - 01:00:59.362, Speaker A: No, what I mean is there's some comments that I have specifically regarding Defi. Yeah, go ahead. There's a set of pros and cons, right. For Cosmos and Ethereum. Right. Dimitri mentioned pre compile. So some subsidized smart contract computation and then being able to allow some sort of apps being able to run that's cheaply ran versus let's say on a layer one.
01:00:59.362 - 01:01:40.110, Speaker A: Similarly with Cosmos you could kind of do the same thing, right? There are some advantages to running on Cosmos, such as if you think about threshold encryption or if you think about dydx order matching engine that's on the validator set and then using its own currency as a way to find value in the sense of what the token can do. And so I do think there's some advantages like if you look at what DX is doing, there's a reason why they moved from. They could have done an app chain but they ended up doing their own Cosmos chain. So I guess what I'm curious more about is what, like push them to do that move.
01:01:40.230 - 01:01:45.230, Speaker B: Imran, you tried DYDX after they moved to Cosmos, right? You tried the product?
01:01:45.350 - 01:01:49.090, Speaker A: I have not, no. I've only used it on starkware.
01:01:49.590 - 01:01:50.462, Speaker B: Okay.
01:01:50.606 - 01:01:54.558, Speaker A: But I have not used it because I think they're curious.
01:01:54.734 - 01:02:25.622, Speaker B: I'm just curious what wallets do you actually need to use DYDX on Cosmos? Do you have to use Kepler or can you use Metamask? Because the thing that really boggles my mind about this DYDX decision is once they've moved to Cosmos, they basically have a much smaller user base that already have a wallet installed. Assuming you have to use a Cosmos first wallet like Kepler instead of Metamask. But I haven't tried the product either, so I don't know.
01:02:25.726 - 01:02:37.340, Speaker A: Yeah, I'm just curious. Roll ups people generally use L2 and L3s or whatever you want to call it as a way to scale. But. But then if you want more customizability, then you want to do your own zone. Right.
01:02:38.440 - 01:03:39.024, Speaker C: For now, like my understanding, they move for three reasons, maybe two One, I think it was difficult for them to build in Cairo pre people. The second is that potentially a regulatory thing around sharding the order book. And then a third I think is a pretty natural business model for the market makers who each run that order book where you kind of get like round robin mev where I think those market makers can potentially have a more like crypto native business model through transaction ordering and. And you can potentially keep. You potentially don't need to ever even turn on a fee switch if you're able to capture fees through mev. So those are in my head what the three reasons are. And I think again today they did need to do that because you cannot do that on any eth L2 because we still have no idea how to fully decentralize the sequencer on ETH L2.
01:03:39.024 - 01:03:42.848, Speaker C: But maybe that will change within the next year or two.
01:03:42.904 - 01:03:57.520, Speaker A: I also thought that the reason why DYDX moved was because of the open source nature of the Cosmos SDK. There's just a lot of flexibility and ways to kind of communicate with the rest of the open source community around how they should be building their product.
01:03:57.820 - 01:05:06.180, Speaker D: Yeah, I think the DYDX decision actually came at a timing that at this exact moment of time when they launched it, when they announced this a year ago, roughly like yes, Cosmos Zoom gave you a lot of customizability that is not also impossible as an L2 and to some extent not possible today still on L2 but a year after that actually many of the options that we were that forced DYDX to do this transition, maybe except for the MEV round robin part that Dimitri was speaking, are actually happening on the L2. And let me tackle that because this is some of the interesting stuff that is happening due to modularity so far. Like either you on L2 either use EVM and you write solidity code or you have to go and to start where and write Kyle. Right, so this was your options a year back. Actually now I am seeing so many projects using an L2 with a custom execution environment. You can write wasm, you can write trust, you can write whatever language you can want and compile it to and use it as an L2. So this wasn't possible before.
01:05:06.180 - 01:05:40.940, Speaker D: So the developer experience that was impossible before as an L2 can be possible now. What enables this fura the separation between execution and consensus that was enabled by Optimism tweaking their bedrock infrastructure to separate execution from consensus. So you don't need the evm. You separate go geth like or geth the execution engine from the consensus so you can replace geth with anything else you can replace. So you can use any state machine essentially. And we are seeing many projects.
01:05:42.240 - 01:05:45.820, Speaker C: It compiles down to MIPS or wasm.
01:05:46.720 - 01:06:08.084, Speaker D: It can compile up to anything. Once you have a state you just push the state on the L1 done. It's like you can do whatever. We are seeing people trying to bring Solana virtual machine on top of ethereum as an L2. I am seeing so many teams building wasm. I'm seeing even projects that say we you can build build a state machine using any language. So this flexibility is interesting.
01:06:08.212 - 01:06:21.316, Speaker B: And actually these are not production ready. Right. Most of these are still work in progress. Are there actually any developers who's actually writing non solidity on top? Well, aside from Carol, but Cosmos wasn't.
01:06:21.348 - 01:06:28.800, Speaker D: Ready also to run arbitrary code like Cosmos Wasm is very new unless you.
01:06:29.180 - 01:06:33.086, Speaker B: Cosmos wasm was two years ago, right? It was not that new.
01:06:33.188 - 01:06:34.922, Speaker A: About a year ago. I think it was a year ago.
01:06:35.026 - 01:06:39.510, Speaker D: Came into production ready environment. It was under development for the last two years.
01:06:39.890 - 01:06:40.618, Speaker B: Okay.
01:06:40.714 - 01:07:07.376, Speaker D: So I think DYDX moved because they would intended to bake their code in the. In the node validator code. So like as a pre combine like you don't need to write a smart contract, you just write your code as part of the node code. So that was possible before in Cosmos. That was impossible in an end to. But I foresee that within a year or so this will be possible. You can write whatever code you want as an L2 and you can run it.
01:07:07.376 - 01:07:14.064, Speaker D: And this will take one big advantage from the Cosmos ecosystem back to the L2 and I think many people which.
01:07:14.072 - 01:07:16.064, Speaker A: Is what Cosmos has as an advantage, right?
01:07:16.232 - 01:07:22.336, Speaker D: Yeah. And Imran, I think you mentioned that the Cosmos people are seeing that as well, right?
01:07:22.408 - 01:07:30.446, Speaker A: Yeah, yeah. There was a tweet Zakim tweeted a couple where weeks ago. I don't have it in front of me but pretty much said that they have about 12 months.
01:07:30.518 - 01:07:31.006, Speaker B: I have it.
01:07:31.078 - 01:07:31.278, Speaker D: Yeah.
01:07:31.294 - 01:07:32.190, Speaker A: Why don't you read it?
01:07:32.310 - 01:07:53.050, Speaker B: Here's Zaki's tweet. I think Cosmos social Capital has about 12 months to do something unique and differentiated. Otherwise we get swallowed by Eth flavored variants of Cosmos originated ideas like rollups and Eigen layer. I feel intense urgency. The hour is late.
01:07:54.010 - 01:07:55.858, Speaker A: It sounds kind of scary, man.
01:07:55.994 - 01:08:03.250, Speaker B: When I saw this I was really shocked because Zaki is like what top three at least top ten people in Cosmos.
01:08:03.330 - 01:08:04.882, Speaker A: He's one of the co founders of Cosmos.
01:08:04.946 - 01:08:06.258, Speaker B: Is he a co founder or.
01:08:06.394 - 01:08:07.682, Speaker A: I thought he was, yeah, he was.
01:08:07.706 - 01:08:11.570, Speaker D: One of the lead developers in the Cosmos today.
01:08:11.610 - 01:08:51.580, Speaker B: He's certainly the top five people in the Cosmos ecosystem. And when I saw this I was pretty shocked. But the funny thing is we actually independently came to this conclusion before he tweeted this from our last few episodes. We talked about this several times already that Cosmos is facing a huge threat from Ethereum. But interestingly, also interestingly, this is a bit of history, but it seems like arguably Cosmos is the OG or really the creator, the inventor of modular architecture with all these various independent Cosmos zones. Of course, I mean, I know you're rolling your eyes already, but no.
01:08:54.280 - 01:09:19.810, Speaker D: It'S a different kind of modularity. Like if you ask any developer why do they love Cosmos SDK, it's because the modularity of the SDK, the Tendermint consensus engine, is separate from the IPC consensus engine. It's separate from the execution engine. So the modularity was actually baked in the SDK. So you can take the SDK and build whatever with it. So it's a different kind of modularity. It's not just taking modularity, but modularity within the SDK.
01:09:19.810 - 01:09:23.910, Speaker D: It was great actually. And yeah, I agree, they are the OGs.
01:09:24.250 - 01:09:27.362, Speaker C: It's like vertical modularity instead of like horizontal.
01:09:27.506 - 01:09:27.970, Speaker D: Yes.
01:09:28.050 - 01:09:59.276, Speaker B: Yeah, that really begs the question because of like, does the first mover advantage really? Well, I guess, okay, it's very arguable who's the first mover, but Cosmo is certainly the first mover in the modular architecture. Cosmos and Polkadot, both of them actually started in, in the 201718 bear market. And then Ethereum later on converged. The vision of Ethereum converged to Cosmos, not the other way around. Arguably again, but Ethereum's network effect is so strong.
01:09:59.428 - 01:10:00.076, Speaker A: Yeah.
01:10:00.188 - 01:10:02.252, Speaker B: That all the developers went to Ethereum.
01:10:02.316 - 01:10:28.164, Speaker D: Actually, I will argue against that. It's actually Cosmos that is moving to the shared security platform that that Ethereum was believing in from day one. Like Ethereum, Cosmos started with the segregated security. Everyone is responsible. Everyone is responsible for own security. Right. And I would say the most interesting piece of Atom V2 Vision was the Interchange security and now the Bozeman proposal from Osmosis, which is.
01:10:28.252 - 01:10:35.620, Speaker A: Can you explain Interchange Security? Because I think so there's some new changes. I don't know if you've heard about the latest, which is Mesh security.
01:10:35.740 - 01:10:45.796, Speaker D: Okay. Mesh security is actually an opposing view and it was led by Osmosis. It doesn't came from the Cosmos atoms. Okay, yeah, okay, that's a big diversion.
01:10:45.828 - 01:10:51.780, Speaker A: Okay so, but, but like I think that's the model they want to go after, go towards now, which is mesh security.
01:10:51.900 - 01:11:45.700, Speaker D: You will find some interesting community discussions and I, and I, I can predict a mini civil war around which one is better. But let's, let's go with that. So okay, ICS or Interchange security is that instead of you as a new project building their own Cosmos zone. And you want, instead of you recruiting your own validators to have your own security or segregated security, you can just recruit some of Atom zone validator, the Atom validators to validate on your chain and you pay them the information reward of your token to this validator. So this kind of centers Atom as the hub as the Cosmos hub. It gets the Cosmos hub as a central security hub for the whole network. And this kind of resembles Ethereum's vision that the ethereum chain, the L1 is the security source for everything else.
01:11:45.700 - 01:12:28.160, Speaker D: So the goal here was to accurate value to the atom holders. So Atom token holders will benefit from being the source of security for every Cosmos zone. So actually it was a shift from the direction that Cosmos started for to shared security. The Mesh security is very similar in concept. But instead of everyone going to recruit security, recruit security from the Cosmos Hub or the Atom zone. No, we will build collateral like we build bi directional relationship. Osmosis can recruit securities from Celestia for example and Celestia gets a relationship with Injective and Injective have a relationship with whoever, right? Or something.
01:12:28.160 - 01:12:53.948, Speaker D: And by having this bilateral relationships we will end up by having a distributed network of security that everyone is secured essentially by everyone. So these are two competing visions. And you will find people in the Cosmos community advocating that MIS security is the thing that is the real goal. Some people will say, you know, ICS is the real thing. So that's why I'm expecting some fun dynamics.
01:12:54.044 - 01:13:06.236, Speaker B: I kind of get why Osmosis is pushing for this vision because this will accrue value to their token. Whereas the Cosmos core developers, they want to push for the other vision because that accrues value to the Atom token.
01:13:06.348 - 01:13:06.876, Speaker D: Yes.
01:13:06.988 - 01:13:13.532, Speaker A: That begs the question about the Cosmos Hub. What is its role within the entire Cosmos ecosystem?
01:13:13.596 - 01:13:23.820, Speaker D: The OG guy. So this is my simple answer. The Osmos hub is the OG guy. In the the Cosmos ecosystem there's no canonical.
01:13:23.900 - 01:13:36.652, Speaker C: I mean the Cosmos Hub is the one where there's the most connectivity and the most liquidity. There's no canonical. It's a game of Thrones around who gets to be the the de facto Cosmos hub.
01:13:36.716 - 01:14:00.736, Speaker D: But it lost the seat twice by the way. I would agree argue that Terra Deceit did Atom for a while and then Osmosis unseated Atom for a while. So Terra collapsed and disappeared. So it's out of the story. Osmosis is still kind of a competitor kind of to the Game of Thrones game on Cosmos. So we'll see. It's interesting.
01:14:00.928 - 01:14:03.340, Speaker C: It's a fun reality TV show.
01:14:04.120 - 01:14:29.740, Speaker B: It is back to our original analysis of gaming NFTs and DeFi. So I said I agree with you on NFTs and DeFi. I think gaming it might be a little bit too early to draw a conclusion. I think everything is so experimental. There's no game that actually works. There's some network effect around optimism like the Zero X Park guys, mud, but it's still theoretical.
01:14:30.960 - 01:14:32.500, Speaker A: A lot of stuff that they're building.
01:14:32.880 - 01:14:37.256, Speaker B: Exactly. It's too early to say Cosmos is out of the question.
01:14:37.408 - 01:15:05.252, Speaker C: Yeah. On the Web 2.5 games it's probably a question of distribution partners where if you do want to bring in traditional game studios, maybe there is a play there around having a really strong game studio. Just ship crypto enabled games. I don't want to call them crypto native. It's more basic. You know, there's some assets that are on chain but not fully full game state.
01:15:05.252 - 01:15:42.546, Speaker C: I think what ARGUS is building is very cool. That's more of probably the Web3 flavor. You know, everything fully on chain. I think a lot of that is also around. To what extent are you aggregating the brains that are actually building this? And it's a very different concept and mental model of what a fully on chain game is and what the notion of an autonomous world is. And there I mean also still competing against MUD on optimism. Dojo on starknet two very interesting frameworks.
01:15:42.546 - 01:16:16.396, Speaker C: And then where are the builders? And how do you get the attention of the people who are crypto native? They know how to build these autonomous worlds and they are willing and able to do it on an ecosystem outside of L2. And maybe there are. I guess to your point it's still an outstanding question. It's more of a thing that the Cosmos projects need to prove like the burden of proof is on them on whether you can amass enough of the intellectual firepower to to build something unique and interesting there.
01:16:16.468 - 01:16:24.524, Speaker A: Well, speaking of like mud, there's also ARGUS Labs, right. That's ran by Scott Sonardo which is building.
01:16:24.612 - 01:16:25.900, Speaker B: They're on Cosmos. Yeah. That's right.
01:16:25.940 - 01:16:40.352, Speaker A: On Cosmos. Yeah. Yeah. I haven't dug deep into what they're building exactly, but taking a quick look at their Twitter, some sort of EVM based shard. Not sure exactly what that means and haven't read through it yet.
01:16:40.376 - 01:16:58.208, Speaker B: But for context, they're the creators of Dark Forest, which in my opinion is the closest thing to giving us a magical moment similar to Defi Summer. It's not at the same level as Defi Summer, but it was pretty magical.
01:16:58.384 - 01:17:05.500, Speaker A: Yeah. Okay, so they're introducing World Engine which is a sharded roll up SDK built to horizontally scale on chain games.
01:17:06.200 - 01:17:48.512, Speaker C: Yeah, I mean that's been very stealth about this. I think now is being more public. Yeah, sharded roll up with a shared settlement layer and that settlement layer is probably going to be some Cosmos chain and there's probably some customizability there. Probably a game engine that's baked in. I haven't spoken to Scott about it. I'm not sure what the details are. And the question is can you execute that in a standalone Cosmos chain or can you execute that with an L2 and instead of shards you have L3s that settle onto that L2 and then you bake in custom My pre compiles in every instance.
01:17:48.656 - 01:17:49.328, Speaker A: Interesting.
01:17:49.424 - 01:17:59.136, Speaker B: Can I get a quick gauge of sentiment? Bullish neutral or bearish Cosmos? Because I'm hearing conflicting things again Dimitri. Bullish neutral.
01:17:59.328 - 01:18:03.660, Speaker C: Yeah, bearish Bearish short term, neutral long term.
01:18:04.200 - 01:18:05.136, Speaker A: I'm neutral.
01:18:05.248 - 01:18:24.118, Speaker B: Well, isn't. Can you actually be bearish short term than neutral long term? Because. So I kind of agree with Zaki that they have a 12 month window of opportunity. So if they don't succeed within the next 12 months, succeed, quote unquote succeed, do they really have another shot at dethroning Ethereum?
01:18:24.214 - 01:19:45.432, Speaker C: I guess I'm slightly optimistic of them executing something interesting but still not fully convinced that even if they execute it's going to be powerful enough to actually have some particularly long standing ecosystem or value prop. I don't consider myself an E maxi. I'm. I'm more like an eth realist around you know, like, like in the context of history, you know, or like the course of, you know, years or decades, like I don't know, try not to fight momentum, you know, just like, like lean into where things are heading and just try to build on top of that and not have like not try to step on each other's toes and build something for end users that will onboard the most retail, the most institutions because like that's where if we don't get that like the whole space guys, you know, like, like that's still my North Star around like how do you 100x the like the users, the liquidity, the developers, the applications and if, if you see something has like the most inroads to the the real world, that's your largest market as an entrepreneur. So like why do you want to take unnecessary platform risk if you could avoid it? Unless there's a really good reason to.
01:19:45.536 - 01:20:38.920, Speaker B: Personally, I don't know what to make of Cosmos but I want to share one counter argument that haven't been said to the bearishness towards Cosmos. The counter argument is that yesterday Imran and I spoke with a founder from Cosmos and the guy is, is I love the guy. A missionary builder and super smart and the vast majority of the conversation revolved around whether or not he's bullish on Cosmos in the long term. And why. Because that's the biggest risk for any Cosmos builder is the ecosystem wide risk, not the product specific risk. And the answer that he gave that I really like is the fact that he said pretty much anyone who has ever written solidity code and CosmosM says that CosmosM is a 10x better developer experience. And anecdotally I heard the same thing from independent sources.
01:20:38.920 - 01:20:47.460, Speaker B: I haven't verified myself. I never wrote any code in cosmwasm so I can't comment on it but this is a thing that I've heard a few times now.
01:20:47.760 - 01:21:02.600, Speaker A: Also the community he mentioned that he came from the Berkeley like community and like everyone, everyone in the burglar community is like pro Cosmos. Even the new people that are coming. And Dimitri, you went to.
01:21:03.220 - 01:21:06.764, Speaker C: Oh yeah, I want to get Andrew Diaz for sure.
01:21:06.852 - 01:21:10.316, Speaker B: I forgot he called Cosmos the Berkeley chain.
01:21:10.508 - 01:21:42.082, Speaker C: Yeah, yeah, yeah. It's gonna be painful. Yeah, I guess because you write, I mean like, like Rust I think has a nice tailwind because it's used by multiple chains I would argue like JavaScript. It's awful but people use it. There's a lot of tooling around there, there's a lot of security firms that are working on solutions to make it safer. I think yeah, if I'm to give maybe an area where also they could compete. It's around hardware resource provisioning networks.
01:21:42.082 - 01:22:24.132, Speaker C: They kind of have like a kosh on there. But can you basically have a way to coordinate a lot of machines to provide some compute storage, gpu, cdn, whatever. And if you do that then you need a way. Well you by nature have a lot of nodes and you likely need some state machine. You need a way to meter resources based on very specific things that those machines do. I think of like the Jensens of the world though they built on substrate. I think, like you could have that variant be built on Cosmos, where they provide GPUs for AI model training.
01:22:24.132 - 01:23:01.794, Speaker C: Very computationally expensive, A lot of cost savings that you can get, not because of the decentralized network itself, the redundancy actually makes it more expensive, but just the supply and demand. Just having more machines online that's globally distributed relative to ones that you could stuff inside a single data center. So that's also a pretty unique case because even if you like, I don't think you could get to L2 sequencer decentralization that is that broad, where if you need like hundreds of nodes or like thousands of nodes, that's particularly where you're probably better off with the Cosmos chain.
01:23:01.892 - 01:23:53.246, Speaker A: Was listening to one of Sunny's podcasts and he talked about the differences between Ethereum and Cosmos. And one thing he said was Cosmos takes an app first approach, whereas maybe Ethereum takes more of an infrastructure first approach. And what does that. And he gave a very, he tied it to a very clear example, which is like Google built out search, right? And then from there they work backwards into figuring out the infrastructure that can continue to help support search. Same thing with Facebook as an example. Then he drew the example to Cosmos and said, like, look, we build up this very modularized infrastructure so that anyone can build any type of app that's fully customizable to the app level, which Ethereum can do today, all the way today. And that is the edge that Cosmos has versus Ethereum.
01:23:53.246 - 01:24:03.576, Speaker A: Obviously Ethereum is starting to converge on the same path, but the question is like, are they fully there from a parody perspective? And you know what, your thoughts are typically around that thesis.
01:24:03.688 - 01:25:16.790, Speaker C: I mean, I, I would ask like, what burden are you putting on your developer and, and, and what needs do they have? I would argue in, in many cases, if you just want to create a monkeyp, you don't need to have a whole chain for that, you know, or if you just want to create like a marketplace place, you probably don't need a full chain. So it probably goes back to the type of application. Yeah, My sense is there's a much smaller pool of application devs that are willing to go through that pain of setting everything up. Like launching a network is very difficult. And if you are a smart contract dev, maybe you don't want to deal with that. So, so I think that customizability exists and is useful for devs, but probably not as many as we thought and a lot probably just want to deploy a smart contract and not worry about how do I bootstrap a validator set, how do I pay for security and worry, oh, if it's reflexive security, how is that going to break my app? You know, I think that's where there's a smaller pool of applications where that makes sense.
01:25:16.950 - 01:25:51.172, Speaker D: Yeah, I agree with Dimitri on this one and to this comment, Imran. I think Cosmos is built to make everything easy but they missed the part about value capture. Where is the value capture in this? Don't create Linux again. Linux is a very versatile tool. Everyone can use it, everyone can tell, but they didn't figure out a value capture mechanism. So Ethereum in this case is more similar to Microsoft or Apple when they have built like it's not. It's still open source and everything, but they have built something that will keep getting the user back and keeping locking the user.
01:25:51.172 - 01:26:07.514, Speaker D: So and now Microsoft is soloing Linux essentially right by ws, by like, by wsl, also like. So I think from a long term perspective the approach from Ethereum may work better over like 20, 30 years.
01:26:07.652 - 01:26:41.350, Speaker A: All right, well I know we. This is probably one of our longest recordings. I think this is the longest recording of all the sessions that we've done and I know we could have kept going on maybe to close out this conversation. Could there be a world where both can coexist? Both. There could be thousands of mini apps that run on Ethereum and maybe some larger. You mentioned Dimitri, infrastructure heavy apps that could run on. Could there be a light at the end of tunnel for Cosmos where they can both coexist.
01:26:41.350 - 01:26:43.970, Speaker A: I'm curious to hear your opinions on that.
01:26:44.090 - 01:28:00.444, Speaker C: Yeah, I mean again it depends on the use case and the market timing. I think Cosmos was a decade too early. In general I think they were solving for the right things but at the wrong time. And I think most more applications as they hit scale and they need a lot more customizability probably makes sense and different flavors where you have like my sense of the application that might make a lot of sense are the hardware resource provisioning networks. I think that as a sector has also been very difficult because the UX to their buyers hasn't really been addressed well and they've been trying to find what kind of customers make sense. Like for example there's this CDN project that was going to like the YouTubes of the world and they were saying oh we could reduce your CDN cost by 80% and that customer said well like it's a cost but it's not a cost center for me I would double my CDN costs if it meant increasing market share or user base. So I think like that flavor of like blockchain apps still hasn't found like the use case or the customer base.
01:28:00.444 - 01:28:36.976, Speaker C: That makes sense and I think they're still in the IBMAs. I think you can compete on cost if you have at least some equal performance uptime and ux. So I think like when they have more feature parity there, I think you could have these distributed network of nodes and you can do a lot of cool stuff around customizing it. I think we're still excited about that sector. It's just been a longer time for a lot of those applications to hit pmf. But I think there's something there. So I think like that flavor works particularly well for Cosmos chains and like the DY DX layer.
01:28:36.976 - 01:28:57.322, Speaker C: So I think you know, it just might be like a more niche segment. But I feel optimistic that they might find something. But you just need to be mindful that it's not just the Cosmos devs that are looking at these things, it's also folks that are building their counterparts on ETH rollups.
01:28:57.466 - 01:29:32.056, Speaker B: I have a similar feeling. For the most part I don't think Cosmos and Ethereum can coexist in the long term. One of them will crush the other. But if Ethereum crushes Cosmos, I think Cosmos is probably not dead. It probably is going to remain some niche. And what I'm seeing now is you have these chains that are for the most part infrastructure chains like Axelar Thorchain despite being a cross chain Dex, I consider that as infrastructure because it's really about bridging. Right.
01:29:32.056 - 01:30:05.050, Speaker B: Thor chain band protocol hits an oracle and there's a bunch of these like middle layer infrastructure stuff that are built on Cosmos and that seems to be the niche that Cosmos has found so far. These products would prefer to build on Cosmos than on a Ethereum roll up app chain and probably for good reasons. I don't know what the reasons are, but there's probably really good reasons why the specific group of projects all gravitate towards Cosmos. So that's my view on things long term.
01:30:05.170 - 01:30:39.764, Speaker D: I agree with this view by the way. Summit chains or some applications will have, will require. Will will prefer to have their own infrastructure, everything under the control. Yeah, if DYDX kept growing the way the same rate that you have been growing, I think it's better for them to stay as an app chain, have their own validators even. Why not Games, if they come come really big, then why not? But overall, smaller applications or like the liquidity hub can be will. I think it will. Ethereum will win overall over a long enough time.
01:30:39.852 - 01:30:59.434, Speaker A: And we talked a lot about this child, which is like, is Cosmos too decentralized for its own good versus Ethereum, which is a centralizing factor of like groups. Right. You have the research group, Lord Vitalik that's at the helm. Right. Then you have all different research groups and you have these communities that are underneath it. That's kind of propelling Ethereum forward. Right.
01:30:59.434 - 01:31:23.770, Speaker A: Compared to Cosmos. I don't even know who to look at. I look at Zaki and maybe Sunny. Right? And then they just got a grants program that just started a couple of months ago. Right. Before that, they didn't even have a grants program that you could apply to. So I feel like a part of this slowness against Ethereum is also partially how it's organized from a social construct perspective.
01:31:23.930 - 01:31:24.634, Speaker D: Great.
01:31:24.802 - 01:31:29.690, Speaker A: Cool. Well, thank you, Dimitri, for joining us. It was a great chat.
01:31:29.770 - 01:31:30.682, Speaker C: Yeah, thanks for having me.
01:31:30.706 - 01:31:31.482, Speaker D: This is fun.
01:31:31.586 - 01:31:39.330, Speaker A: For those that haven't hit subscribe, hit subscribe. Thanks again for joining us. Thanks for listening to Good Game. Don't forget to subscribe. We'll see you next week.

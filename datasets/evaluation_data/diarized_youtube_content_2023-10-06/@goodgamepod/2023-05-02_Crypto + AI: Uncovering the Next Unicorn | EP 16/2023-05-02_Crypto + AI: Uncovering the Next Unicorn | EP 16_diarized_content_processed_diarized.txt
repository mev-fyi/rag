00:00:00.360 - 00:00:15.025, Speaker A: We may actually find that AI and crypto converge to become one massive technology. And that's what I said. I hope actually web3 to become the checks and balances of AI so that they complement each other. But from first principles they have different characteristics, they were created differently.
00:00:15.105 - 00:00:33.187, Speaker B: What is certain is that the three most important enabling technologies that we can think of, blockchain, zero knowledge, proofs and AI, they're all converging and it's really mind boggling. If you told me this five years ago, I would not have believed you. But today it's. We're seeing that it's futuristic, but it's going to happen.
00:00:33.291 - 00:00:33.915, Speaker A: I agree.
00:00:34.035 - 00:01:24.987, Speaker C: Welcome to Good Game, a podcast for crypto insiders with your host Imran Chow. Welcome to good game, episode 16. Today we're going to be talking about AI and building on our AI and data podcast. About four months ago was that. And at that point we were talking about the intersection of AI and data because we felt the importance of how AI could bring the access of crypto data to the public markets. But now a lot has changed over the past four months whereby we're seeing probably hundreds of applications come in through our accelerator program whereby they can leverage AI in a way that would make crypto much more feasible for users. So it's a lot of great excitement around AI.
00:01:24.987 - 00:01:33.731, Speaker C: So we're going to dive deeper into the types of startups that we're going to see in the space before we get started. Chow, Fuda, any notes that you'd like to add?
00:01:33.843 - 00:01:39.539, Speaker B: Fuda, you actually have experience building hardware for AI, right?
00:01:39.667 - 00:01:40.131, Speaker A: Yep.
00:01:40.203 - 00:01:51.575, Speaker B: Tell us about that experience quickly and then I can share my own experience building my machine learning models. Just so the audience knows that why we're qualified to talk about this.
00:01:51.735 - 00:02:33.039, Speaker A: Yes, exactly. So actually like the startup that I created in 2019 was all about using new technologies, how to improve AI compute. And by new technologies I meant using actual light lasers. How can you do optical computing for AI? So it was a very, and this is related to my research I did in my PhD. So it was very interesting idea, but at the same time we are competing with everyone else who is creating accelerator for AI. And the funny thing is that we have companies that have been in the space trying to create dedicated AI chips for about eight years. You have something like graph cores, you have Sampanova, you have many, many other.
00:02:33.039 - 00:03:08.865, Speaker A: I can count 50 companies off the top of my head that were creating AI chips, but all of them are struggling until now. And Nvidia is still winning. And for a Very simple reason, which is like the software stack that Nvidia built that matches the Nvidia GPU is harder to replicate for any of these players. And eventually you had to pivot from this idea because we were all already late to the party. But during this time I get a lot of insight of how AI works and how AI compute works. And this formed many of my thesis of decentralized compute and stuff like that. And we'll discuss that for sure.
00:03:08.865 - 00:03:24.003, Speaker A: But yeah, given that I have already knowledge, a lot of knowledge about Web3 and crypto and also a startup experience in the field of AI, this area of AI cross or plus crypto is like very dear to me.
00:03:24.099 - 00:04:05.583, Speaker B: Yeah, so Fudan and I disagree a lot on the whole concept of decentralized AI. So we're going to talk about it for sure. But on my end before getting into crypto, I spend almost a decade building quantitative trading strategies. The models that I built was clearly not very nonlinear. In fact it was very linear models. So I wouldn't say it's AI necessarily. It's at best some kind of linear regression plus some traditional machine learning models like random forest support vector machines, those things really classic models rather than deep neural networks.
00:04:05.583 - 00:05:16.015, Speaker B: And the reason why nonlinear models don't work in finance is because the data is extremely, extremely noisy. I'm sure other people have figured out ways to do it to use neural networks in finance, but I didn't, I tried it and didn't work because of the noise in that data sets. But anyway, throughout those years I developed, I would say pretty useful intuition as for how machine learning and AI works by working with fairly large data sets. They're obviously not in the same order of magnitude as the data beneath OpenAI, but still fairly big because financial data is tick by tick hundreds of data points per second per stock for example. But yeah, so that's sort of my experience with AI and last few months obviously GPT made it to the world stage. Futa and I and Imran, we talked about AI a lot, especially how it intersects with crypto. We've all tried a lot of products so we have a pretty good feeling for what is really hype and what is real.
00:05:16.015 - 00:05:53.263, Speaker B: So we're going to talk about those things. My high level hunch is that right now if you picture the Gartner hype cycle, right, I think we're at the peak of euphoria for AI. I don't know if you guys agree and food that you're smiling, but I feel like we're at that peak of inflated expectations and we're going to get into maybe a few months, maybe a couple years of winter of disillusionment before things really become production ready.
00:05:53.399 - 00:06:12.835, Speaker A: Yeah, I agree and disagree at the same time. Like, I think like ChatGPT inspire people, so people are actually now active in business and inspiration to build the new products. Maybe they will not perform as well they expect. So I think we are closer to the peak, but not at the peak yet. So I think there will be a little bit upside from here.
00:06:13.135 - 00:06:36.605, Speaker B: So I listened to the all in pod last couple episodes. I stopped listening to them for 10 episodes because they kept on talking about the Fed. I'm done with the Fed. But last couple episodes they talked about AI. So I started listening again. I felt like there was really a lot of hyperbole. I felt the discussions were a little bit intellectually lazy.
00:06:36.605 - 00:07:30.185, Speaker B: So I felt like they didn't actually try the product. So they say things like, you know, BD and salespeople, sales departments as startups is getting, they're getting replaced. I just don't see that happening now. I think it will happen, but it'll probably take at least one or two years for that to happen. However, there is one thing that's real today, which is that GPT is helping developers become at least 20%, in some cases 100%, 200% more productive. So basically GPT is turning every developer from a 1x developer into a 10x developer. And I know this because I talk to all our founders that are technical and every single one of them tells me that they're using a combination of GitHub, Copilot as well as GPT as their coding assistant.
00:07:30.185 - 00:08:09.641, Speaker B: And they quote anywhere between a 20% productivity improvement to 200%. It's madness. So I didn't believe them. So one day I said to myself, I'm going to build something using GPT. So I wanted to build like a Twitter bot. And the first thing I wanted to do was, or the first thing I wanted to figure out was how to use the GPT API, which normally would take me probably a few hours to figure out. But this time I asked GPT, ChatGPT, how do I get started with the GPT API? And it gave me step by step instructions on how to do it.
00:08:09.641 - 00:08:41.143, Speaker B: And then I followed the steps. I ran into some bugs, some compilation errors and stuff like that. I copy pasted the errors back to ChatGPT and it debugged it for me. The whole process for me to get started with this API took me 15 minutes, which otherwise would take me four hours. So I felt it personally. I think in general, the coding productivity for me is the single most important application of GPT right now.
00:08:41.319 - 00:09:37.961, Speaker C: I think even the process of learning has changed dramatically as well. I have a couple nieces and nephews and I've chatted with them a few times and they're, I mean, literally everyone that I know is using ChatGPT for some sort of ancillary support, whether it's through like education, whether it's through writing up essays, et cetera. So I do feel like we're in this point right now within the space where humans are leveraging AI as a way to assist them within whatever tracks that they're building in. And I do think that's going to change over time as well, more dramatically with more software that comes out. Even if you think about like Tesla, right, Tesla. I have a Tesla and I use it, you know, I use the car primarily for like driving from point A to point B. But there are times where now I use like full self driving where, whereby, you know, I'd probably say about 30% of the time I use AI for that.
00:09:37.961 - 00:09:42.113, Speaker C: Right? So. And I do think that's going to change over time to probably 100%.
00:09:42.249 - 00:10:34.891, Speaker B: So you guys have been trying GPT. I'm sure you've seen cases where four months ago you were able to ask GPT something and GPT would give you a good answer back. Whereas today you ask them the same question and GPT is being extremely woke or politically correct, or for whatever reason refuses to give you the answer. And this brings to the question of decentralized AI. Right? So number one, what is the point of decentralized AI? It's basically for the same reason that we need decentralized money, decentralized finance, and decentralized social network. You don't want the company that created the AI models to tell you whether or not you have the permission to use it. Okay, so decentralized AI, I think is a big deal, but there's several ways to achieve it.
00:10:34.891 - 00:10:45.531, Speaker B: And Fudan and I disagree on this. So Fudan, what's your view of decentralized AI? Why does it work or why does it not work, or what are some of the areas that we should focus on versus not focus on?
00:10:45.643 - 00:11:33.999, Speaker A: Okay, so I agree we need at some point to decentralize AI in some sense. What I disagree with is that signaling compute and say decentralized compute is the best way to run AI. So clarification, I don't believe in decentralized compute as the most robust way to train AI models. But I agree with the need of decentralized AI because now as you mentioned, the companies that create the models have all the discretion in the world to set its parameters to select the data that model. And they can actually create what we know in research as AI bias. That AI models can be biased and the bias comes from feeding it with biased data because the model doesn't think for itself, it just trains on data. Right.
00:11:33.999 - 00:12:36.519, Speaker A: So if you feed it by maybe left leaning data, then the responses you will get from the model are left leaning. If you feed it with riot leaning data, it will actually like some research showed that even in computer vision, like someone used the computer vision to distinguish criminal activity and because the data that was fed to it was racially biased, actually the AI model actually classified more black people as criminals than. Yeah, so AI bias is real and it all depends on how you structure the model and how you train it on data. So decentralized data for AI is I think is a huge advantage if we can decentralize it and can resource it. The other thing is that instead of a few researchers working on creating a model, if we actually collaboratively work on developing model, maybe we can find even better models and GBT or transformer that was developed by Google. So in the areas of decentralized knowledge and decentralized data. I agree completely.
00:12:36.519 - 00:12:40.527, Speaker A: My hesitation is always in decentralized computer.
00:12:40.551 - 00:13:27.869, Speaker B: Okay, well let's dive deeper into this because it sounds like there's two ways to achieve decentralization. One is open sourcing the models so that you have a more unbiased set of people that help train the model or more unbiased data sets. So either because the LLM they use this thing called reinforcement learning with human feedback. So the human feedback is if the humans that provide the feedback to the model are left leaning, then the models will become left leaning right. So one way to achieve that is by open sourcing the models that are trained by unbiased set of people. And then the second way to achieve decentralization is decentralized compute. And matter of fact there, there's projects in crypto that, that builders, I can't remember the name, Render protocol, for example.
00:13:27.869 - 00:13:42.341, Speaker B: They're like they got onto the top 100 on CoinGecko recently following this recent AI AI wave. But you don't think that decentralized compute makes sense. Can you expand more on that?
00:13:42.453 - 00:14:25.695, Speaker A: This comes from my experience in the AI startups that I created. So, so let's think about AI compute is that you are trying to do compute in a massive amount of data, right? And AI compute for people who don't know how it works. All These models are 99%, or let's say 95 to 99% are matrix multiplications. So you get a massive amount of data, you create matrix multiplication, and we call this linear operations, okay? And then you have maybe 1 to 5%, what we call activation layers. Activation layers are nonlinear, which like Sigmoid reload, stuff like that. So this is the compute part, the other part, because you are dealing with massive data, you cannot do this all compute on one device. You need to actually use multiple devices.
00:14:25.695 - 00:15:17.379, Speaker A: And now the question becomes how we can move the data from this device to the other device, how we can split the compute between different devices. And when one device finishes a compute, it has to send its result to other devices to continue the computer. So we compute, we define the latency or the throughput of AI compute by the combination of both compute and data transfer. And as of now, data transfer is actually the main bottleneck. Like companies that develop AI accelerators, like Nvidia had to go and bike, acquire other companies and develop new technologies like a technology called NVLink, for example, that specializes in shuffling data or transferring data at high speed or high bandwidth to be able to overcome this data transfer bottleneck. So as of now, this is the main bottleneck. Now let's.
00:15:17.379 - 00:15:18.755, Speaker A: That is exactly.
00:15:18.915 - 00:15:51.109, Speaker B: Are you talking about this bottleneck in the context of training or inference? And so for our audience who don't know the difference between inference and training, training is when you build a model. So you know, for example, when OpenAI builds their GPT, whereas inference is when the user interacts with ChatGPT, and ChatGPT runs their model on the cloud and returns the answers to you. So this bottleneck on the network, are you talking about the context of training or inference? Because training is far bigger than inference.
00:15:51.197 - 00:16:29.923, Speaker A: Yes, in theory, this kind of data shuffling affects both. But the effect is way worse with training, because in training you are feeding with, let's say that you are doing computer vision in training, you are feeding the model with millions of images to train the model. So the amount of data you are dealing is way bigger. So the effect of data bottleneck is way worse in training than inference. Inference, you are sending the model a few images to tell you if there is a dog in the picture or a cat in the picture, something like that. So the amount of data you are using is less. Way less actually, let's say between 100 to 1000x less.
00:16:29.923 - 00:17:05.333, Speaker A: So let's focus on training, because training is actually where this problem is bigger. So now when you run this training in data centers, you still have this problem. You still need to move this data between different GPUs and this what causes latency and causes the throughput of the training to be lower. So let's now imagine that these GPUs are not sitting next to each other in a rack in a data center, but instead they are separating by buildings or even separating by streets or even separated by countries. Right?
00:17:05.469 - 00:17:20.885, Speaker B: So yeah, or Even like the GPUs are just the consumer grade GPU on my laptop. Like that's the idea behind the decentralized compute, right? The decentralized GPUs is to use the idle GPUs from your consumer grade laptops.
00:17:21.005 - 00:18:10.581, Speaker A: Yeah, this is another point I'm starting with the most important, which is I consider the bandwidth problem. But there are two other problem that, like what we call heterogeneous computing, that the devices you are using are not the same. And the third one is like, is a point that you exactly mentioned. The GPUs that you in your laptop or your gaming rig are completely different from the GPUs that are being used from that, and Nvidia itself developed new versions of GPUs that are more suitable to AI and will be actually very, very bad for gaming. So if you are Nvidia fan, you know that the RTX are the versions that are suitable for gaming RTX GPUs. Okay, so you will have this definitely. If you are a gaming guy, you will have, or a gaming girl, you will have this in your rig.
00:18:10.581 - 00:18:57.941, Speaker A: Right? The GPUs that are focused for AI are T100, V100, A100, and now Nvidia is launching the H100. These are different architectures of GPUs that is specialized for AI. They will not work well for gaming. So when you say no, no, no, I will use the gaming GPUs for AI, you're actually losing at least 10x advantage because the GPU is different. So between the data bottleneck and the bandwidth bottleneck, when you decentralize compute, and between that, the GPUs are different and between that, now if we decentralize computer, Imran will have a different GPU than you, than me. So if one of them is more powerful than the other, the powerful GPUs will have to wait for the weakest GPU to finish its work to be able to exchange data.
00:18:58.093 - 00:19:36.915, Speaker B: Okay, so I think I agree with you on training the large models. The bandwidth is just way too much. But let's say you want to train a small model or if you want to fine tune a model. Well, number one, the amount of data that needs to be transferred on the network might be digestible by this decentralized compute network. And number two, the latency doesn't matter because in training latency does not matter, especially when you train a small model. The latency matters way less than during inference because the user is not interacting with it yet. The user doesn't feel the pain yet because we're talking about training here.
00:19:36.915 - 00:19:40.839, Speaker B: So I feel like you can afford to wait a little bit longer.
00:19:40.967 - 00:20:18.655, Speaker A: Okay? Like you know that you, when you train data, you may, you are training that your model to actually study the effectiveness of the model. Because if your training is not good, you will have to change the architecture of the model a bit. So let's consider training is a one loop of many, many loops that you need to do to refine your model, right? So if every loop is giving you a penalty of 50, like 50% more latency, then the time that you will take to develop the model will be 50% longer. So you will come to the market later. You will lose competitiveness against your competitors who are using centralized compute.
00:20:18.735 - 00:21:09.217, Speaker B: But the hope is, so I understand the trade off, but the hope is that decentralized compute is cheaper than using something like Amazon or AWS or whatever that are more or less monopolies or oligopolies. So they have a lot of pricing power. Whereas leveraging a decentralized compute network where the nodes come from idle GPUs sitting on your laptop or my Xbox, like these are idle anyway. But if I can earn some tokens by contributing my GPU to the network, then great, I don't care about the cost. So the hope is that the cost of training models on the decentralized compute network, it's cheaper. So then the trade off is okay, yes, it takes longer to train the model, but it could also be cheaper. So I feel like it's a worthwhile.
00:21:09.281 - 00:21:57.455, Speaker A: Trade off depending on your use case. If you are hobbyist training a model for your personal use case or whatever, right? Then you can wait. You can actually prioritize cost and use a decentralized network because cost is your limiting factor. But let's, if you are a business like developing a new eye model for generative AI or something like that, and your time to market is all what matters, I think this is not a worthy compromise you can save 10x on the cost, but you will lose maybe a few months to launch your model or to get the production version of your model. So this will for me, during this time you are burning money by giving salaries to your employees and whoever. So this for me it will not be a worthwhile compromise if you are a business who is trying to prioritize your go to market.
00:21:57.575 - 00:21:59.087, Speaker B: Yeah, so this could be good for.
00:21:59.111 - 00:22:04.087, Speaker C: Like hobbyists I guess and those that don't have a time restraint.
00:22:04.191 - 00:22:47.985, Speaker A: Don't get me wrong, I think there is a space for this LS computer, but it has to be for niche use cases like Chow already mentioned smaller models. Right. Hobbyists. I think this LS Compute will be very valuable for inference because instead of you connecting to the OpenAI server in the US every time, if this model was open, you can actually have multiple groups or clusters of gpu, decentralized GPU power and now you are actually connecting with the cluster closest to you. So your latency in connecting with the server and your latency instead of having one bottleneck that everyone connects to, you will have multiple versions. I think inference can be very useful for. Sorry, the syntax compute can be very useful for inference.
00:22:47.985 - 00:23:05.389, Speaker A: My hesitation is always in using training on decent compute. And training is available because it requires most commute. And all the companies that are pushing for decentralized compute focus on training. And this is the part that is kinda choose something that will work, don't just push for training.
00:23:05.517 - 00:23:08.293, Speaker B: I want to push back on the inference part as well.
00:23:08.429 - 00:23:08.765, Speaker A: Go ahead.
00:23:08.805 - 00:23:28.135, Speaker B: So you're saying decentralized compute makes sense for inference? I think it might do. But don't you think that the best way to achieve decentralization for inference is simply by running open source models on your local device? Because there's zero latency, zero network latency.
00:23:28.255 - 00:23:49.377, Speaker A: Yeah. If you can run the model in your local device, please go for it. But let's consider something like large language models, LLMs that are open source, like llama. The smallest version is 7 billion parameters. Good luck running this on your phone. Good luck running this on your consumer grade laptop. Right?
00:23:49.521 - 00:24:02.385, Speaker B: Wait, are you sure about this? You don't think that these models can get efficient enough? Or laptops or computers, Personal computers can get good enough within the next couple of years in order to run these LLMs locally.
00:24:02.505 - 00:24:47.975, Speaker A: If you need a GPU, if you can miniaturize the GPUs enough to put it in a laptop and our miniaturizer GPU to put it in phone, that can work and actually A good example here is apple chips, the M1 and M2 chips, because they exactly did that. The M1 and M2 is not a processor, it's a system on a chip. So the chip has a GPU in addition to the cpu and that's why they perform well in rendering and a lot of AI executions. So there is this. I don't agree, like, actually we are getting there. But today large language models are not suitable for mobiles or like for consumer grade devices that doesn't have GPUs.
00:24:48.095 - 00:24:51.075, Speaker B: Okay, it sounds like we're still disagreeing.
00:24:53.455 - 00:24:57.195, Speaker A: The market will judge on our disagreement.
00:24:58.255 - 00:25:09.261, Speaker B: Let's meet in the market and see who's right and who's wrong. But speaking of the market, Imran, what happened with Drake and Grimes? Tell us about it.
00:25:09.293 - 00:25:43.357, Speaker C: Yeah, recently, I'd say probably over the course of the past three months, we're starting to see AI out in the open market and we're starting to see a lot of users that are training their own models in a way that could produce music that will sound similar to Drake or Kanye West. And in fact one of the songs went viral, which was, I think it was with Drake and the Weeknd. And I listened to the song. I think you shared it with me. Ciao. Listened to it. And I have to be honest with you, it was pretty good.
00:25:43.501 - 00:25:44.477, Speaker B: It was good.
00:25:44.661 - 00:25:45.945, Speaker C: It was, it was good.
00:25:46.405 - 00:25:52.105, Speaker B: And I don't know, I didn't like it, but I can see why it went viral.
00:25:52.645 - 00:25:53.827, Speaker C: Yeah, no, it was good.
00:25:53.901 - 00:25:55.383, Speaker B: It was close to the original.
00:25:55.559 - 00:26:31.535, Speaker C: Yeah. And what was also interesting was soon after that happened, the record label that owns the rights to Drake and others started going after pretty much everyone that listed the song, including YouTube. And so all of these larger like platforms had to delist the song. And then the question then becomes, who owns the rights to the music? Right. That's number one. And number two is what is the world going to look like post AI? Right. So if you think about where we were maybe 10 years ago with, oh shit, it was 10 years ago.
00:26:31.535 - 00:27:02.289, Speaker C: Yeah. With streaming as an example. Right. Or even a decade before then with MP3s, who owns the rights? How do you accrue as an artist? How do you accrue value? And then how does this support the entire ecosystem? So with MP3s as an example, being able to download it for free, no one was able. Like the artists weren't able to capture value nor the record label companies. That's why Napster went down. Then Spotify came in and said, hey, we're going to answer your problem here by creating a streaming platform that would allow anyone to stream for pennies on a dollar.
00:27:02.289 - 00:27:28.509, Speaker C: So artists ended up losing a lot of money to the streaming services, but they were able to capitalize on merchandise, as an example. But now in this world, music is the voice in and itself is a commodity. And there is no way to, like, accrue value. Because if the music can be created for free or near free, then how do you accrue value? Right. As an artist? And that's kind of where we are fundamentally.
00:27:28.637 - 00:27:37.141, Speaker B: And that brings to the story of Grimes, which was a week later from Drake, what happened there?
00:27:37.253 - 00:28:10.073, Speaker C: Yeah, so she sent out a tweet a week ago, and she said, anyone can run use my voice for free, but if you do use my voice, I would expect a 50% royalty. So have as much fun as possible with my voice. Do as many experiments as possible. I just want to collect a 50% royalty. And what was also interesting about this is that she isn't signed to a label either. Right? So she can negotiate this herself. But if she was signed to a label, then obviously there's more regulatory or more legal frameworks that they would have to follow.
00:28:10.073 - 00:28:15.937, Speaker C: But Grimes didn't have any of that burden, so she was able to do something like that quite easily.
00:28:16.081 - 00:28:37.809, Speaker B: And so that inevitably touches on the story of how do we use blockchains to fight deepfakes? How do you identify that a piece of content is produced by an AI versus the original creator? I know you've thought about this quite deeply. Let's talk about this.
00:28:37.977 - 00:29:12.811, Speaker A: Yeah, I would just take it a step. Wider Web3 technologies in general can help a lot in the AI, not necessarily the blockchain. Blue blockchain is just one piece of the story, right? Having blocks and having a public chain. But while we are creating blockchain, we actually created a lot of many, many technologies that can be useful. Digital signatures is one. ZK is one. So the collection of web3 technologies will actually enable or like, solve a lot of issues for AI.
00:29:12.811 - 00:29:41.663, Speaker A: And let's start with this one. How to authenticate content, especially videos and audio. Right? Because if I create an article that I try to associate to you, ciao. No one will believe me if. Unless it comes from your medium account, no one will believe me. But if I create a video, you of you broadcasting a broadcast, ebbing into shitcoins, people can believe it because people see it, right? Like, people tend to believe. Yeah, but.
00:29:41.799 - 00:29:47.831, Speaker B: But you can use general, like general AI to create videos. Is. Is going to be. Is Going to come soon. Like we're going to get it.
00:29:47.863 - 00:29:48.831, Speaker A: It's, it's here.
00:29:48.863 - 00:29:49.479, Speaker C: It's already here.
00:29:49.527 - 00:29:50.191, Speaker A: It's, it's already here.
00:29:50.223 - 00:29:57.429, Speaker B: It's like 10% of the videos I see on TikTok is AI generated. And if I'm not careful, I'm going to fall for them.
00:29:57.597 - 00:30:00.825, Speaker C: And most of them are Joe Rogan. Right? The Joe Rogan video.
00:30:03.165 - 00:30:03.709, Speaker B: Yeah.
00:30:03.797 - 00:30:48.295, Speaker A: So now people can believe, you can believe these videos and they can believe that you like shell this coin or that project or whatever without deleting this. And they have enough content from your podcast to have training data. So we are good. So the things, how would you prove that this podcast is yours versus this was fake AI? So even Fred Wilson from USV spoke about that. And the digital signature is one of the absolute best solution for that. That when you create a video, your camera itself can generate a signature or you can, after you make sure that the video looks good and like it's fine, you can sign it using your private key. Exactly.
00:30:48.295 - 00:31:18.851, Speaker A: Similar to signing a transaction. And now this validated content is great. It's correct. This can solve the problem to some part. Partially solves the problem. Why? Because after you create this whole video of the podcast, you want to get a video clip of it, you want to resize it, you want to do some editing to it. The problem is that once you do any modification or modification to the video, the signature is not valid anymore and you will need to re sign it.
00:31:18.851 - 00:31:57.909, Speaker A: And this is a bad user experience. So this can be solved by another technology that we developed at web3, which is zero knowledge proofs. When you do compute in some data, you can actually create a proof that this compute has run correctly. So let's say that you run a compute that cuts 30 seconds from your main video. We can simply prove that this, this, this didn't change anything. But to take a 30 seconds and we can read, we can generate a proof that this small video is a subset of the original sign video. And this can give like evidence that this video is still correct even after modification.
00:31:57.909 - 00:32:12.469, Speaker A: So between the digital technologies, between digital signatures and zero knowledge, we can actually achieve authentication in audio and video and all of this content that people tend to believe. So I think this can be fundamental in the future.
00:32:12.637 - 00:32:33.171, Speaker B: Okay, so let me summarize, just make sure I understand. So the additional signature is to prove that the content is created by me, for example, by the original creator, whereas the ZKP is used to prove that a remix is based on some other original piece of content.
00:32:33.323 - 00:32:33.851, Speaker A: Yes.
00:32:33.963 - 00:33:02.703, Speaker B: Okay, let's dive deeper on the digital. Let's start with the digital signature stuff. So the way this would work is let's say I produce a podcast or a video, I provide my digital signature using my private key, like on Ethereum, for example. But then I need to publish my public key somewhere, right? Like say on my Twitter or Facebook or whatever, so that people can use that public key to verify that the digital signature is indeed mine.
00:33:02.819 - 00:33:22.415, Speaker A: Yeah, that's true. And people are already doing this. For example, people who set an ENS domain, attach it to their Ethereum address. Right. And then they use this ETH name for their Twitter. So I can tell that, yes, that's Fuda Eth. And I can go to Etherscan, figure out what this Fuda ETH resolves to.
00:33:22.415 - 00:33:48.097, Speaker A: And then when I see this public key signed a video, then this is a video created by Fuda done. Like no one can dispute that or no one can fix that. Right. Same for example, for Mirror or for other products that are trying to create decentralized video. Because once you upload a video, the transaction that posts a video to the chain is signed by you and everyone can validate that this address is related to your identity.
00:33:48.201 - 00:34:01.435, Speaker B: So Basically we're using Web2 social networks to bootstrap the credibility of these digital signatures to be able to associate them with real people that you can trust on web2 social networks.
00:34:01.555 - 00:34:09.307, Speaker A: Yeah, until decentralized social media backs up and it becomes its own source of truth, you have to leverage Web2 kind of.
00:34:09.371 - 00:34:14.915, Speaker B: Okay, I want to talk about decentralized social media as well, because it's related to AI, but let's talk about that in 20 minutes.
00:34:15.035 - 00:34:15.587, Speaker A: Okay.
00:34:15.691 - 00:35:22.681, Speaker C: I think what's also very relevant here is Worldcoin, which is also a project by Sam Altman. The idea behind it is that every user would scan their iris and then they would receive a wallet with some role tokens. There isn't any plans in regards to what Role Coin will do in the long run, but there are some short term hints in regards to where this is going to go. One is identity. So creating a unified identity across the world is 1, 2 is they want to distribute KNOW tokens as some sort of like monthly stipend as a way for people to access crypto products. They didn't go into detail in regards to what that means, but what's interesting about this is the, is the fact that it's released by Sam Altman, who also co founded OpenAI. And then you have to kind of like think deeper about where this is all going to go, right? If we are going to be living in a world of full of bots and anonymous like users, how do you differentiate between one or the other? Right, and you also mentioned digital signatures.
00:35:22.681 - 00:35:55.901, Speaker C: I mean there's like, I don't know, like 40, 50 layer ones that all have different identities. And I think we're at a point right now where there isn't like a single identity point for any of the one users that we have. Right. I think that we're still in that like weird mix of just trying to transition into where people are going to be using their identity day to day. Maybe that will be solved by social media, we'll see. But worldcoin is, from what I'm reading, is creating this kind of unified digital identity experience. And if they succeed, then it could become the de facto identity experience.
00:35:55.901 - 00:36:02.565, Speaker C: What are your thoughts on this kind of intersection between OpenAI and Worldcoin and where it's going?
00:36:02.685 - 00:36:32.165, Speaker B: Just a quick thought before FUTA want to pass it to you, but just a quick thought. A year ago people were bashing work one and also people were wondering how the hell does Sam Altman work on two different ideas, like two seemingly very different ideas, right? Like a cryptocurrency project and AI. And now everyone is like, holy shit. Of course, because in order to battle deep fakes you need identities on the blockchain. Yeah, right. But anyways, Fuda, what do you think?
00:36:32.545 - 00:37:06.329, Speaker A: So, yeah, exactly. Like now everyone is connected the dots like you connect the dots backwards. So AI will make it easy actually to create bots. We actually use a new term for bots, we call it AI agents, right, which are software that leverages a large language model, LLM at the back end and you can jot an objective for it and let it go. Right here is an objective. Go build a company. Use ChatGPT to build a company and the AI agent will think for itself, create a task list, maybe even connect to the Internet to execute this task list.
00:37:06.329 - 00:37:45.425, Speaker A: So we will have AI agents that act like human and can do a lot of features like human. So Wallycoin comes into picture how to create a proof of humanity. Especially for a use case like UBI Universal Basic Income when you want to give some money for everyone, right? So Wallicoin started by the concept of okay, the easiest or the most cyber resistant proof of humanity is to scan the iris of everyone and have a database of everyone's iris. So this can work. There is one problem, privacy. Now you have one entity which is Wallicoin. Have all this database of everyone's iris and they can do whatever they want with it.
00:37:45.425 - 00:38:28.217, Speaker A: This becomes a problem how to actually solve this privacy issue and how to actually create this unique identifier or unique identity without invasion of the user privacy. So Wallet actually made a post a few weeks ago about how actually zero knowledge, ZK and ZK machine learning can actually help them with this privacy. So the flow goes as following. Now I want to create an identity on walletcoin. So I will scan my iris. But I don't want anyone in the wallet to have this IRIS scan of myself. So what I will do, I will store this IRIS scan on my phone or the device that I used to discover my iris.
00:38:28.217 - 00:39:08.415, Speaker A: And for Wallicoin to create an identity for me, they will create a machine learning model that needs to process this IRIS scan. So instead of me sending the identity to them, they will send me the model and I will run it locally on my device to create my identity. And then this identity will be tied to this IRS scan. There is only one catch here. How to prove to walliccoin and to the rest of the wallet that I run this model and I didn't run a different model because I can fake it. I can run another module, create a different identity or I can create multiple identities related to the same IRC scan. So here is where ZK comes into the picture.
00:39:08.415 - 00:39:34.839, Speaker A: Because if only coin send me and instead of sending me the AI model, they send me the circuit, the ZK circuit that represents the model. The model will create a proof that the user has only used this model. They didn't use a different model. So now we achieved two. We had two birds with the same stone. I maintained my IRIS scan, so that's a private. But I also confirmed it to the whole world that the identity was generated.
00:39:34.839 - 00:40:14.165, Speaker A: The same algorithm for generating identity was used for every user. So now we have a decentralized worldwide identity tied to my human face verification. But it's just my data is still private. So this is a very interesting concept. And for this one actually they mentioned one of our alliance companies cohort which modulus because modulus is exactly working on that how to actually create a proof for a machine learning model. So this IRIS scan machine learning model we can be converted into a circuit and this circuit will generate a proof for each a time we use it for inference or the greater identity.
00:40:14.285 - 00:41:07.409, Speaker B: It's really mind boggling how these technologies are all leading to the same all roles leads to the intersection of zk, AI and blockchain. Yes, five episodes Ago we said that this year we think that AI and ZK are the two most important enabling technologies in crypto. And now the dots are getting connected with each other. Like if you told me in 2017 that, okay, we're building a L2 blockchain using ZKP and AI, I would have told you this is a total scam. These three buzzwords in one sentence is the biggest scam ever, but today it's actually real. Maybe the tech's not ready yet, but on paper we can see it. It's going to happen.
00:41:07.497 - 00:41:11.525, Speaker A: Yeah, the use case is definitely here. Yeah.
00:41:11.905 - 00:41:58.327, Speaker C: But you know what's also very interesting is the fact that a lot of the drawbacks for crypto can be solved by AI, and a lot of drawbacks for AI could be solved by crypto. An example of this is drawbacks for AI is like centralization, data privacy and then what I call operational efficiency. Right. So like auditing, et cetera. Whereas with where I see the drawbacks for crypto is like scalability, security, governance and usability. And if you think about it, once they're both very robust, once they're robust enough, I do see this being very homogenized and working very in sync. In the future, maybe we could talk about some of those use cases.
00:41:58.327 - 00:42:05.023, Speaker C: Right. So like where, where do we think are the drawbacks of AI whereby we think crypto could solve some of those issues?
00:42:05.119 - 00:42:05.375, Speaker A: Yeah.
00:42:05.415 - 00:42:07.879, Speaker B: Imran, let's, let's talk about the privacy. Right?
00:42:07.927 - 00:42:08.351, Speaker C: Yeah.
00:42:08.463 - 00:42:09.463, Speaker B: In AI.
00:42:09.639 - 00:42:10.023, Speaker C: Yeah.
00:42:10.079 - 00:42:21.071, Speaker B: Fuda, I know you have a lot of thought on that. When it comes to both inference and training on proprietary private data, how does crypto and ZKP help AI?
00:42:21.183 - 00:42:46.175, Speaker A: Yeah, I think we discussed this a lot. Ciao. And we already gave one example. Wallicoin is an example of how to maintain the privacy of data for inference because this identity generation machine learning model will act on private data and the private data will not leak. This is a very good example of how to use AI with private data for inference. The other use case, which is even.
00:42:46.295 - 00:42:57.031, Speaker C: Can you give an example? Because in the real world, I know one of the examples that we often use is insurance, but yeah, so maybe a few examples would help our audience.
00:42:57.103 - 00:43:25.383, Speaker A: Yeah, let's take a few examples. But we can dive deeper into each one of them separately. Let's use insurance. Now you have an insurance company that writes a certain insurance policy and you want. And they are deciding to use a machine learning model to enforce this policy. Instead of using human to review every insurance claim, we'll use a machine learning model. But at the same time, this insurance, the person who bought the policy doesn't want to give all the details publicly.
00:43:25.383 - 00:43:55.355, Speaker A: They don't want to say when they were driving their car, how they hit the other car or whatever. Right? So this data that is in the claim can be privately processed by a machine learning model, maybe even locally, to make sure that we can get to the same conclusion about is this claim accepted or denied without sharing this data with everyone? This is one example. Even a better example is the new trend of machine learning models that can diagnose diseases. Right?
00:43:55.655 - 00:43:56.631, Speaker B: I love that.
00:43:56.783 - 00:45:03.411, Speaker A: So let's say that you have a company now that generated an AI model and somehow trained it like, we'll come to the training beast in a bit. And this training machine learning model can actually diagnose you if you have cancer or certain kind of cancer, using your x rays, your MRIs, all this stuff. So. But this company want to keep their model private, right? They want to keep this model on their server, otherwise they will lose their competitive edge. And you as a user want to, you have your MRIs, you have your X rays and you want to get a diagnosis from this machine learning model. But you are afraid to send this data to the machine learning model because someone in this company will have access to your medical records that actually knows where you live, how old are you, everything about you, and they know that you have cancer or whatever, right? So how to solve this dilemma? How to actually be able to run this private machine learning model on this private data? So one way is to actually provably anonymize your data. Or like you say, here is my data, it's authentic.
00:45:03.411 - 00:45:35.465, Speaker A: Maybe the doctor who generated this medical report can sign it. This is a signature. I just want to create an anonymized version of this medical record so you can run an anonymization technique to remove all your personal information. And you can also in the same time generate a ZKB that says that this authentic, this data is generated. It's authentic. It's still authentic. I just removed my personal information and now you can actually send this data to the machine learning model.
00:45:35.465 - 00:46:14.359, Speaker A: The model will run on this data and can give you a diagnosis, a correlation diagnosis, without revealing any personal information. So this is interesting. It gives you the functions that you want without leaking privacy. And if we take this a step further, you can do the same thing for training. What if this company is trying to recruit medical records to train their models? So now many people can do the same thing and maybe get even reward for it. They can get incentives to sharing their medical records. But without leaking the privacy, everyone will create this anonymized medical record and creating a proof that the anonymization didn't change the data.
00:46:14.359 - 00:46:35.553, Speaker A: She just removed the personal BIIs. And now we have a proprietary dataset that for many patients that doesn't leak privacy and the model can be trained. So this anonymization is one way where we can actually use technologies that we developed in the web3 space to solve the privacy issue of AI.
00:46:35.729 - 00:46:48.725, Speaker B: Just to touch on that. There's a problem in privacy, but there's also a problem of data authenticity, both of which is being solved with ZKP. So it's one stone, two birds.
00:46:50.625 - 00:47:07.813, Speaker A: This is a signature solve with authenticity and ZKBs solve is the anonymization or like the subset, it's similar to the video. Right. The signature solves authenticity and then the ZKB kind of keeps this authenticity even when you modify the data somehow.
00:47:07.989 - 00:47:31.173, Speaker C: You know, if you think about the real world over the course of the past decade, privacy has been a big problem in the space. Right. If you think about all the leaks that have happened recently with user data, user passwords, et cetera. Even if you talk, if you think about LastPass, I mean LastPass was hacked recently and that was pretty much a vault for all of your passwords, right?
00:47:31.229 - 00:47:48.441, Speaker A: Yeah. And even more fun, AI can lead to more privacy leakage. Did you read the article about Samsung engineers who used ChatGPT and to do some inference and by intention their private data went into OpenAI server and now it's part of the training set.
00:47:48.513 - 00:48:09.411, Speaker B: No one can I feel so terrified when I use ChatGPT about my personal data. By the way, this is yet another reason for decentralized AI. It's actually privacy. By decentralized AI, I don't necessarily mean compute, but like for example, running open source LLMs model locally so that my personal data doesn't get leaked 100%.
00:48:09.483 - 00:48:21.619, Speaker C: Yeah, I think that's a really good point, which is when you're interacting with these LLMs, they're also like learning and extracting data from you as a user, which I think could become a very important part of how crypto could solve this.
00:48:21.707 - 00:48:34.787, Speaker A: Yeah, I think OpenAI was transparent. If you are using the free tier of ChatGPT, they are using your data for research. Right. Which is like they are using your data to refine the model. So like it's clear and you are you signed yes to the terms of use.
00:48:34.851 - 00:49:07.197, Speaker B: So maybe 15 minutes ago you mentioned the concept of AI agents. Let's expand on it because it's also intimately linked to crypto blockchain and zkp. But let's talk about it because there's a lot of hype out there with baby AGI autogpt like those agents. Okay, so first of all, what is an AI agent and why is crypto relevant here?
00:49:07.261 - 00:50:11.813, Speaker A: Yeah, an AI agent, as I clarified a few minutes ago, is that we use as humans, we use a chatgpt, right? We use the model ourselves, we give it prompts, right? And then it gives us answer and we, then we link the dots. What if we automate this part as well? Like so a VC called UE created this baby AGI model which is just simply a very simple software. It combines an LLM ChatGPT in this case with a database to have just a memory, to have a longer term memory for AI, and then it was a program symbol. Let's set an AI agent here. You just give it a, an objective. What to do to build a startup, what to do to build a Web3 accelerator, right? And then you set this, you give this objective to the AI agent and it will automatically bring user OpenAI API to ask the question to ChatGPT. It gets the answer, put the answer back into a database and start iterating on this loop to create a list of tasks, how to satisfy an objective.
00:50:11.813 - 00:50:50.479, Speaker A: So now that gives autonomy to the AI agent. The AI can think for itself, it can create a list of tasks, and it can even go deeper and use and implement each of this set of tasks. So like let's say we need to build a website or chatgpt can actually give you the code to build a website. So it can build a website and if it's connected to the Internet it can go book a domain, launch the, upload the HTTP code and like, or the HTML code and launch website. So AI agent in general is an autonomous software that can think for itself, it can reason about tasks and can even implement it.
00:50:50.607 - 00:51:33.127, Speaker B: But how is this different from ChatGPT plus some plugin? So for those who don't know, you might have seen Anatoly tweeted about GPT plugin with Solana in such a way that people can type in some commands in ChatGPT and query their wallet transactions and balances inside GPT itself using their plugin. So the thing that really bugs me is what is the fundamental difference between an AI agent versus GPT plus unplugging? Because you can use the plugin to query outside stuff, right? Like you can Use that to query like Google, for example, or Wikipedia. And what's the difference?
00:51:33.271 - 00:52:03.287, Speaker A: The difference is who is the end user of this. Like a plugin is tells the end user is a human, right? You want to find the best route for a travel, right? So ChatGPT will go to Expedia, do the search, find the best route and give it to you. So the end user is a human. You have to decide, ah, this is a good option. This is a bad option, right? In the AI agent case, a human is not involved. A human just is involved in the beginning by setting an objective. And then the AI agent will do all these iterations.
00:52:03.287 - 00:52:11.795, Speaker A: It can do multiple iterations at the end, decides, this is good enough. I'm stopping here. You as a human, didn't you got yourself out of the loop, essentially.
00:52:12.215 - 00:52:19.103, Speaker B: And that inevitably touches blockchains very much. Let's talk about it.
00:52:19.199 - 00:53:19.367, Speaker A: Yeah, AI agents can also pay, can do payments, can receive payments. Let's imagine an AI agent that is trained well to publish an article, right? So you hire the AI agent to write an article using your style. You give it your writing samples and tell this AI agent please create an article about this topic using my writing style. So it will work on it and you can just pay it like that. You can have the AI agent can have a cryptocurrency wallet and you can pay it in USDC or ETH or whatever, right? Even better, this AI agent can decide, oh, I need some graphics. But I am the AI agent is not trained well to create graphics. So it can actually reach out to another AI agent that specializes in generating graphics and give it a prompt about what graphics it wants and attach a payment to this task and the other AI agent will do the graphics for you.
00:53:19.367 - 00:53:56.447, Speaker A: Then you would maybe to do a campaign or like promotion so you can reach to a third AI agent to create a promotion for the content. So there is even like more expand, there will be specialized, a version of specialized AI agents that can actually be autonomous to not just do tasks, but also to hire AI agents to do tasks and pay them. So crypto fits this well because without the payment trail that crypto creates, AI agents will depend on banks and like what. So our crypto payment rails are essential for this kind of AI agent to be autonomous.
00:53:56.591 - 00:54:44.113, Speaker B: That's a really good point, because in Web2, pretty much every social network I've seen or every traditional game that I've seen is extremely allergic to bots. They're culturally allergic to it. And technologically they have their APIs are permissioned they can deplatform the bots anytime they want. Whereas in crypto the interfaces are permissionless. And culturally, I suppose we are open to bots because, for example, in Defi, the most important group of players is the MEV bots and people are fine with it. Defi for me is basically like a game, a financial game where you have two groups of players. You have the MEV bots that are EV positive, they make money, and then you have the human players who are EV negative.
00:54:44.113 - 00:55:20.443, Speaker B: They lose money on average, but they're fine, they can coexist with each other. Fine. The MEV bots goal is to make money, whereas the human bots, the human's goal is dopamine, rush, lose money. So that's fine. But the point I really want to touch on is decentralized social networks and crypto games. Because we talked about this a while ago and we said that the vast majority. Actually I forgot if we said this on our podcast, but we definitely talk a lot about this internally.
00:55:20.443 - 00:56:12.017, Speaker B: But the vast majority of decentralized social networks and games are extremely uninspiring. They look like Twitter clones, or they're just games that look like traditional games, but putting their in game items as NFTs on chain. It's fine. I think it's okay for Twitter clones to have some reasonable success, but I find it extremely difficult for a undifferentiated product to become a generational business. So the thing I've been thinking about for a while is, okay, where is really that breakthrough for decentralized social networks and games? Because in order to have that breakthrough for you to become a generational company, you have to offer new experiences. You cannot offer the same experience as Twitter or other Web2 games and expect to become a wildly successful company. You have to offer new experiences.
00:56:12.017 - 00:56:41.847, Speaker B: So where does that new experience come from? I have a couple ideas. One is hyper financialization, which we can talk about in the future. But Defi is an example of that which I just talked about. Defi is a hyper financialized game. The other breakthrough is actually AI is AI agents. I think that there will be a future where the AI agents will become the dominant players or users of the decentralized social networks and crypto games. That is my vision.
00:56:41.847 - 00:57:40.701, Speaker B: Now do I know if this is going to happen for sure? No, I have no idea. But I think this is a very worthwhile area to look into for those who are building decentralized social networks and games for reasons that I mentioned before, which is that crypto is culturally and technologically open and compatible with AI agents. It's permissionless and you won't be able to deplatform the agents. So picture a social network where as a human you can interact with some very smart AI agents that produce useful content. Now, there's a lot of people who are, who hate AI, but there's a difference between AI and spam, okay, because previously you can have a lot of bots that produce scams, spam on Twitter, for example. But I think AI is now intelligent enough to produce actually interesting content. So in our mind we need to differentiate between spam and bots.
00:57:40.701 - 00:58:12.761, Speaker B: Bots can be very interesting. They don't have to be just spam. So you can picture social networks where humans interact with bots and you can picture games where some of the players or NPCs are AI players, right? So we have many examples like this. We have a game called AI arena and another one called Primodium. From our network, from our community, they're building super interesting AI games. But yeah, what do you guys think? Is this an interesting vision? Is this a dumb vision?
00:58:12.913 - 00:59:00.697, Speaker C: I think it's valid if you think about it. Just if you look at DEFI as an example and you're seeing all these MeV bots that are extracting a lot of value, you could similarly see this play out against all of the other crypto like products like gaming as an example. AI arena is a great example. There's even Dark Forest, which is another example I can give you. And you're seeing more and more bots being utilized as a way to extract economic value or points in a game. And what you're going to start to see in the future I think is just like more engineers coming to space that will compete for something, right? Whether it's value, whether it's a game, et cetera. And I think it makes the overall like ecosystem within crypto much more efficient in the long run as well, which is some of the interesting things that we're seeing.
00:59:00.697 - 00:59:02.049, Speaker C: How about you, Fudam?
00:59:02.177 - 00:59:52.977, Speaker A: Yeah, I agree. I think in gaming you give great examples and like already we saw this happening with Dark Forest. And people who are not familiar with Dark Forest, I encourage them to read Wells Robinson based on the Dark Forest and how actually developers created both to help them achieve their goals or implement their strategies. But I will just jump to the social media part of it. So now we use social media in a very different behavior. If you have a, if you want to ask about a recommendation or a question or even a restaurant, you have to have dinner you go to social media, right? But this will, if you ask this question, you will depend on your network, right? People who will jump in to answer you. But what if we have smart AI agents then can actually respond to your question and you don't have to wait for a few minutes or hours to get an answer, right? Or even AI agent to summarize what is happening.
00:59:52.977 - 01:00:38.385, Speaker A: You now log in Twitter, you have been coming back from your camping trip, you have been off Twitter for a few days and now you want to catch up to what happened over the three days. So instead of you just scrolling for hours to catch up to things, maybe you can just ask an AI agent to summarize what is the major events in my field of interest for a few days. So this actually can create even a better user experience. And we are seeing, seeing this happen. Like one of the companies in our cohort in our network, awesome QA is using AI to actually answer users questions in Discord or Telegram or even Twitter or any social media. Like I'm interested in this project. What is the most recent updates, what is the most recent governance proposals? You can ask this and AI agent can respond to you.
01:00:38.385 - 01:01:01.733, Speaker A: So I think there is, and we are seeing many companies actually are even launching content generation for you and generative AI is even a bigger topic. So you can put this aside for now. I think for social media the user experience can be enriched by having some smart AI agents that are not targeted to spam. Instead they are targeted to help users and help grow the network collectively.
01:01:01.909 - 01:01:47.105, Speaker C: Even if you think about social media today, there are a lot of bad things about social media today. You see virality, you see polarization of thoughts and biases. And I do think like, you know, social media was probably one of the reasons why we live in such a polarized world today is because you have two different, you know, left and right leaning individuals that are continuing to like build propaganda, tweets, etc. That kind of build on these types of user bases. So I'm curious on how bots could change that dynamic, right? Like could bots enable better and healthier conversations that would lead to less polarization of what we see today?
01:01:48.045 - 01:01:49.825, Speaker A: That's a hard question. Honestly.
01:01:51.125 - 01:01:55.165, Speaker B: Honestly, if anything, I think bots will lead to more polarization.
01:01:55.245 - 01:01:59.315, Speaker C: Yeah, because of just the nature of the LLMs.
01:01:59.895 - 01:02:24.731, Speaker A: I mean you can play both ways. That's, that is a problem. Depending on the AI agent you create, you can create an AI agent that will create, continuously create fake news that, that cannot be distinguished from, from real news and this, this AI agent will just keep bombing and people will send embayment to create more content. Or you can create a rational AI agent that filter for the truth. So it depends.
01:02:24.883 - 01:02:55.205, Speaker B: The agents and the deepfakes are going to play a massive role in the next election next year, in the next 18 months. And I think that there will be maybe one or two election cycles where AI and deepfakes are going to be massively influential until we get to that point where we can use blockchain and digital signatures to prove to authenticate content. And the window of opportunities is closing. One or two more cycles of elections.
01:02:55.245 - 01:03:06.381, Speaker C: I think what's interesting, I just saw a news article about this as Facebook is building a social media on a blockchain. I don't know if this hasn't. Yeah, you didn't see that?
01:03:06.533 - 01:03:09.025, Speaker B: How did we miss this? When did it happen?
01:03:09.565 - 01:03:19.237, Speaker C: I'll send you the link to it. But it didn't give much detail around it. But it did say that Mark Zuckerberg or like Facebook is experimenting with the social media on the blockchain.
01:03:19.381 - 01:03:20.773, Speaker A: What does it mean exactly?
01:03:20.909 - 01:03:25.181, Speaker C: Yeah, yeah, I'll look it up. But I just saw the news on this.
01:03:25.213 - 01:03:29.861, Speaker A: Is it decentralized social media? So is like. Is decentralizing himself? Kind of. So I would.
01:03:29.893 - 01:03:40.983, Speaker C: Yeah, but it's. It's supposed. It's not new, so it's not. It's not going to like pick Facebook and decentralize or anything like that. Yeah. So Meta is developing a decentralized Twitter alternative. Here's what we know.
01:03:40.983 - 01:04:40.281, Speaker C: Meta, the parent company of Instagram, Facebook and WhatsApp, is working on a decentralized social media project that can rival Twitter in ways that Mastodon couldn't. Okay, so there wasn't much news around it outside of just like a quick summary of what they're experimenting with. But I feel like this all has a play into the. Where like everything is converging. Right? You know, you have AI, you have deepfakes, you have bots, and then you also have like a universal identity layer that's going to become important in the long run of like, are you going to have 10 different signatures from 10 different wallets or 10 different layer ones that can authenticate who they are? Or is everyone just going to use one unified layer, one that can authenticate their signature and everyone can read it and know that it's valid? And so I think what's happening is that there is this. I think this war is coming very soon, whereby whether it's a social media, whether it's worldcoin. Whoever will want to own that identity end to end in this like post AI world.
01:04:40.393 - 01:04:42.993, Speaker A: Yeah, that's a good insight. Yeah.
01:04:43.129 - 01:04:49.513, Speaker C: Well, why don't we leave it at that? I know we're at time. Any final thoughts before we close out?
01:04:49.609 - 01:04:52.441, Speaker A: Like, I have so many more thoughts, but we need a couple more episodes to finish.
01:04:52.473 - 01:04:54.993, Speaker C: My thoughts. Yeah, for sure.
01:04:55.129 - 01:05:17.289, Speaker A: Yeah. But I think we covered a lot of ground and my last thought maybe actually, like we know that AI is already starting to transform the world and maybe Web3 can get its moment of usefulness by being the checks and balances that control AI. So this can be like what really the promise of Web3 is about.
01:05:17.417 - 01:05:39.231, Speaker C: Yeah, we've been always looking for our time to shine for crypto. I think we thought about games as the lightning in the bottom moment. We blame UI UX experiences for not having 100, 200 million users. But maybe AI will give us the rush that we're looking for in terms of product, market fit and users and ultimately that'll lead to more money, more users that come into the space.
01:05:39.343 - 01:06:13.897, Speaker B: Futa, again, there's something that you said I disagree with. There's this notion of AI and crypto being at odds with each other because. And Peter Thiel started this meme of AI being this centralizing force and blockchain being a decentralizing force. Fine, yes, I see it. But I disagree with the fundamental notion. I think the two are fundamentally compatible with each other by crypto providing a programmable interface, permissionless interface for AI. And for me, the two are the two sides of the same coin.
01:06:14.001 - 01:06:48.717, Speaker A: At the fundamental levels they have different characteristics. Right? Like in web3, anyone can launch a protocol. You can just go to a network and launch a protocol. AI on the other hand, is that unless you create a massive coordination layer to decentralize the creation of AI models and creation of data sets like it. So far it has been dominated by the larger players, Microsoft, Google, Meta, OpenAI. These are centralized entities that have tons of cash, the higher the brightest minds in the space and they log them for years to create something like a chatgpt. So that's different characteristics.
01:06:48.717 - 01:07:07.373, Speaker A: I don't agree that we may actually find that AI and crypto converge to become like one massive technology. And that's what I said. I hope actually Web three to become the checks and balances of AI so that they complement each other. But from first principles they have different characteristics. They were created differently.
01:07:07.509 - 01:07:27.721, Speaker B: What is certain is that the three most important enabling technologies that we can think of, blockchain zero knowledge proofs and AI, they're all converging and it's really mind boggling. If you told me this five years ago, I would not have believed you. But today we're seeing that it's futuristic, but it's going to happen.
01:07:27.833 - 01:07:28.617, Speaker A: I agree.
01:07:28.801 - 01:07:58.873, Speaker C: And maybe I can plug in our startup ideas if you go to Alliance XYZ ideas. We have listed many ideas for founders to look into that intersect with AI and crypto and hopefully this gives you some influence or some insight into, you know, come join us and build in a space we're at time. So thank you for listening and tune into our next episode. Don't forget to hit subscribe. Thanks everyone. Thanks for listening to Good game. Don't forget to subscribe.
01:07:58.873 - 01:07:59.825, Speaker C: We'll see you next week.

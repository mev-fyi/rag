00:00:00.160 - 00:00:14.798, Speaker A: In fact, I heard that this is already happening, which is like people I wouldn't call like black hats as an example, are already uploading code and finding out where the bugs are and then targeting those startups in crypto. This is happening today.
00:00:14.926 - 00:00:18.430, Speaker B: I mean, I'm using chat. I tweeted exactly this on the day GPT came out.
00:00:18.462 - 00:00:54.510, Speaker A: Did you really? Welcome to Goodgame, a podcast for crypto insiders with your host imran and Chow. All right, welcome back to good game, episode nine. This time around, we're going to be talking about crypto data and the upcoming AI field, which includes like OpenAI Chat, GPT, and many other new products that have launched in that field and how that may overlap with crypto. Before we get started, chow, anything? Top of mind.
00:00:54.622 - 00:00:56.686, Speaker B: I'm really excited about this episode.
00:00:56.870 - 00:00:57.834, Speaker A: I can tell.
00:01:00.574 - 00:02:08.114, Speaker B: You I'm not a total noob in AI, because before getting into crypto full time, I actually spent almost seven years doing data science and engineering. Obviously, that was not super deep neural network kind of work, but I developed some intuitions that helped me understand the latest how the modern AI works. So I'm really excited about that. And the other thing is, I think this more general topic of crypto data is an extremely under discussed, yet important topic. And the reason why I say that is because a few months ago, I came to the realization that every crypto company is a crypto data indexing company. Every single company spends so much engineering resource to solve their own data problem, and this problem can be solved at scale, horizontally, by third party data providers. And yet it has not been solved.
00:02:08.114 - 00:02:39.180, Speaker B: All of our founders, all of the founders of alliance, every time I talk to them, I would ask them, what is their pain point? And they would tell me they have problems with data. There's no good data solutions out there, even though millions of dollars of vc money has gone into funding these data startups. So I think data similar to what we talked about earlier about wallets and their ones in previous episodes, are one of the biggest impediments to mass adoption of crypto. Agreed.
00:02:39.252 - 00:03:37.650, Speaker A: And data has been one of the first sectors to take off in crypto. If you think about coin market cap, they launched around 2013. It was primarily a function of bringing like natural life price feeds for retail users. And since then, obviously coingecko launched soon after, and then it kind of like grew outside of that, just like speculative need. What's interesting though, is as soon as those two products launched and we started to see more or less like product market fit, and I wouldn't say product market fit in the sense of, like, crypto apps that have, like, millions of usage. But, like, there were crypto apps that were usable, and we started to see a lot of interesting bad behavior that happened in crypto and specifically around, like, money laundering or scams that took people's money away. And I think out of that, like, core need, you saw, like, chain analysis and others that grew out of that kind of, like, core need at the time.
00:03:37.722 - 00:03:38.374, Speaker B: Yeah.
00:03:38.674 - 00:04:16.646, Speaker A: But I think most recently was, you know, and when I say recent, I'm talking like, 2017. And this is the cohort that you are a part of with Masari, which is startups that were being built to provide natural price feeds to, well, clean the data, ingest the data, and then being able to provide live data streams for whether it's trading firms or exchanges, et cetera. And so maybe since you've gone through that kind of cohort, maybe talk a bit about how the market was back then, what were the core focuses, and then we could talk a bit about where we've gone since then.
00:04:16.710 - 00:05:16.544, Speaker B: Yeah. By the way, out of all these various data sets that you mentioned, whether it's exchange data or on chain data, I think the most interesting thing is on chain data, because that's something that's truly crypto native, and that's what we're going to talk about during the rest of this episode. On chain data has always been part of the long term vision. At Missouri, however, there were other things that were part of the long term vision as well, including exchange data and qualitative data. So the thesis we had in 2018 was that the first couple of datasets that will become relevant and important were going to be centralized exchange data and qualitative data. I, as head of product, I did not anticipate how quickly on chain data became relevant, which gave rise to the likes of June and Nansen in the 2018 2019 era. So Masara focused on a lot on centralized exchange data and qualitative data.
00:05:16.544 - 00:06:09.102, Speaker B: For better or worse, today, Masar is still at least a top three most successful data companies by annual recurring revenue. I think Massar makes more money than Nansen and certainly June. However, Massar is not the leading company in on chain data specifically, but Masari could get there. And by the way, I'm telling this story to show how quickly the space evolves, right? Like, I, as head product, I spent all day thinking about where the space is going the next couple of years, and yet I did not anticipate this rapid change in how data evolved. But more importantly, more generally, how the space overall evolves, which creates constant new opportunities for founders. So that's my personal experience at Masari, and that leads to the later stories with Nenson and June, if you want to talk about those.
00:06:09.238 - 00:06:49.658, Speaker A: Yeah, so, you know, you had like Masari, Coinmetrix, Kaiko that came around that 27, 2017 cohort. 20 18 20 19 20 20 were some of the more recent apps that were building the data space. One is called Dune, and obviously everyone knows Dune today. Back then they were pretty small and they have a very interesting story. Frederick had a very interesting story, who's the founder of Dune, about how he went through the 2018 to 2019 bear market. But the idea is very simple. The idea is ultimately to create an ability to connect with the data.
00:06:49.658 - 00:07:23.238, Speaker A: So the way doing analytics works is that they have nodes that ingest the data, clean it on the user side. Users can ultimately use SQL as a way to query the data and create incredible dashboards all real time. There's two aspects of Dune that makes it a very interesting product. One, it's community focus, similar to GitHub. A lot of the things, after doing some research, it turns out Dune is modeled very similarly to GitHub, which I thought that was very interesting.
00:07:23.316 - 00:07:52.344, Speaker B: Ju, in my mind is the most interesting crypto data company right now. Yeah, precisely because of this user generated content, which creates a really nice flywheel. So users come in, they create their own SQL queries and their new tables, and these new data sets become interesting for other users. So more users come in and create tables. And this creates a very nice flywheel effect.
00:07:53.084 - 00:08:44.672, Speaker A: And they also allow you to build on top of other people's queries as a product, which is just a way to add to that flywheel that you mentioned. But I was listening to one of his talks and he talked about what are the important aspects of Dune, why Dune and why data. He talked about quarterly reporting when you're, when you go public. Let's give Coinbase an example. Every quarter, Brian Armstrong will come and he will talk about how the performance of the company is, how it's done, and where they're going to go in terms of the next twelve months. The idea behind what Frederick is saying is, imagine if you could do this real time, all the time for any company. It really changes the dynamic of how companies are assessed and valued and how you can find opportunities in the space.
00:08:44.672 - 00:09:30.704, Speaker A: That's one big example he gave when he was making this talk about why Dune and why data. He also talked about, which I think is very relevant, is that all the data that we live in, the web two world is siloed and you can't see that data. Let's talk about Facebook or Google. I'm jumping around here, but Ben Thompson wrote this really great article that talked about data factories or super aggregators where Facebook and Google are like data factories. And ultimately what this means is Facebook. Google created a great product which was like either search or social networking. And the goal is to get enough demand where then they have the supply side of advertisers.
00:09:30.704 - 00:10:06.218, Speaker A: But the advertisers won't understand what the user is doing without processing the data and understanding the data in a way where they can target these users. And this created this effect where all the data is siloed into these large conglomerates, and no one can see the data, no one can see what's happening. And the power is then used and held by these large super aggregators. I think when you think about what Frederick said earlier, which was like, all this data is going to be ubiquitous and open, I think it's going to really kind of flip the model in regards to how companies are going to be built moving forward.
00:10:06.306 - 00:10:12.786, Speaker B: Yeah. And by the way, I agree with this point, this key point, that crypto data is fully public and global and open.
00:10:12.890 - 00:10:13.530, Speaker A: Yeah.
00:10:13.682 - 00:10:56.370, Speaker B: However, there is a really interesting counterargument that I heard from one of our founders. I can't remember who brought it up, but it's really interesting because precisely because of all the pain points with dealing with, specifically with reading on chain data, more and more centralized data providers are going to be built to make it easy for people to query and to read that data. So even though the raw data is completely global and open and public, the end user facing interface will be more centralized and gated. Again, I'm telling the story precisely because of how painful crypto data is to work with for technical people or non technical people out there.
00:10:56.502 - 00:11:28.948, Speaker A: I actually agree with that. Here's a perfect example. I'll give you one example is look, before Facebook and Google, they had no users, so they had no data. They had to create a compelling product that brought these users in, where then they were able to extract data and then reuse it to grow their empire. In today's world, we don't have that. Products have to be built in such a way that attracts users. And since their data is public, you're able to see what they're doing, how they're doing it.
00:11:28.948 - 00:11:53.804, Speaker A: But a key example I can give you is like Nansen. Right, Nansen. What they do is they create a web three data dashboard that allows you to see alpha. That's the key opportunity or keyword here that you want to think about. What they started with early was the ability to label transactions and label wallets so that you know who the smart money is in the space. Right?
00:11:53.884 - 00:11:54.356, Speaker B: Yeah.
00:11:54.460 - 00:12:20.276, Speaker A: And so over time, they built this huge cult following that enabled them to kind of expand into other products. And so they built nfts. They went cross chain, and they've, I think, labeled over 100 million wallets today. And so now, like, if I want to see, if I want to like Fomo in, I can just see who bought in into like a token. And if it's someone that's like, really well known, I can just like FoMo and buy it with them and try.
00:12:20.300 - 00:12:24.194, Speaker B: To get some alpha APM first, then do research.
00:12:25.134 - 00:13:17.482, Speaker A: Yeah, but it's a very different strategy in that where they're taking the data, they're cleaning it, refining it, labeling it, and showcasing that data in a way that's great for users. And I think it kind of changes the fundamentals of how startups are going to grow in web three. Now, if you think about where Nansen's going next, as an example, they acquired a company called eight board, which is like, I would call it portfolio manager wallet. And it's not crazy to think that they can use all the data analytics now that they have acquisition of users, real world users that are retail, they could create analytics on wallets. So with the assets that they have within their wallets and then be able to get Alpha directly from their wallet.
00:13:17.578 - 00:14:29.328, Speaker B: Yeah. And by the way, what you just said there about Nansen, but also you mentioned earlier chain analysis, because both started with tagging wallets and addresses. So what you said, this is a really important point, and this is going to be a recurrent theme throughout this episode, which is that, yes, data seems like it's possible to build a monopoly. In reality, what's going to happen is there's going to be a bunch of data products that are extremely verticalized. So in the case of Nansen and chain analysis, they're both focusing on tagging wallets, but they're targeting two different user segments. Chain analysis is targeting the law enforcement, the regulators, for example, whereas Nansen, despite building a similar product, they're targeting the analysts, the traders, the investors. So a recurrent theme throughout this episode and within the data crypto data landscape is that even if you see a large player that is dominating a niche, it's possible to build a very similar product, but targeting a totally different user segment.
00:14:29.328 - 00:15:19.602, Speaker B: That's the verticalization of data. And this is one of the highest conviction thesis I personally have about crypto data. There's going to be so many crypto data products. And to just to give you examples from alliance, in all nine, our last cohort alone, there were at least four companies that were doing data related products. So for example, we have Rayleon, who's building their user segment is growth, and product managers from crypto startups, right? They're providing a front end for those people. There is, for example, Aura, who's building a very high level of abstraction layer for retail users, the people who are not technical enough to use dune, for example. And we have data Leap, who is building a product for data engineers.
00:15:19.602 - 00:15:40.566, Speaker B: Again, a completely different user segment. And we have sort who is building an API product for Dapp developers. They're all targeting different user segments, and the different user segments have different requirements. So this is something that I think will happen very commonly in the next few years.
00:15:40.670 - 00:16:28.274, Speaker A: The crazy part about what you just mentioned is that what you just touched on is primarily data apps and some data developer tools. But the data landscape is pretty big in crypto. If you think about indexing collection, you have the graph goalsky, Kovalent, and some are decentralized, some are centralized. The ability for them to do is ingest data and bring out the data in a way that's easily consumable by developers. Obviously, if you look at the graph, it's designed in more of a decentralized fashion, whereas everything else is centralized. I guess the question here is, how important is decentralization or centralization when it comes to ingestion and then consuming that data?
00:16:28.394 - 00:17:18.028, Speaker B: It depends on the use case. Anecdotally, virtually every builder that I've spoken with that has ever tried the graph told me that it doesn't work for them. The decentralization is not something that they need. And the other dimensions in the other dimensions, such as latency, data coverage, liveness, data quality, the graph is just not good enough. And that's what caused the emergence of many centralized alternatives to the graph, many of which you mentioned. So decentralization is not, in my opinion right now, is only useful for maybe five to 10% of users. And those users will be the people who need real decentralization in their dapps.
00:17:18.028 - 00:17:41.420, Speaker B: So builders who are building decentralized applications, and they need their entire stack to be decentralized. Again, I've said this before, but the whole stack is as decentralized as its most centralized layer. So for these people who are building decentralized applications. They need the whole stack to be decentralized. And therefore, they might need something like the graph for decentralization purposes, but for everyone else, they prefer centralized solutions.
00:17:41.572 - 00:18:17.226, Speaker A: Got it. I know the graph. Just to add some more context to the graph, I know that graph. Just push out an update or something where the latency has gotten much better, but just wanted to add that point as well. And so you have, like, if you look at the crypto data like landscape, you have, like, the data apps that sit on top. You have developer tooling, like, doing analytics. You have indexing and collection, and then you also have, like, data sources, and data sources include, like, databases and, like, oracles and data warehouses as well.
00:18:17.226 - 00:19:38.084, Speaker A: So maybe we can touch on all three of those aspects, and maybe we could talk about data warehouses like space and time, as an example, that recently went through our program, and you had Zeta block. That's also kind of like a pretty up and coming startup that's solving this problem. But what is a data warehouse or data lakes? It's essentially like a pool of data that comes from many areas that are processed databases into the centralized hub repository of data. Data lakes are more or less like data that's coming in, that are unprocessed, that's raw in its form, and data warehouse is data that comes in, that's processed and tagged properly. The idea is very simple. It's like, how do we get all the data that we get from all these different data sources into one data warehouse? And then how do we build analytics on top in such a way that's powerful for the startup? And so we're starting to see, like, pretty serious players are coming into space now that remind me very similar of, like, my days at Microsoft, where you had these, like, enterprise software that was very, very, like, enterprise focused, that were solving, like, real world commercial use cases. Is that the same for crypto data today, or are we still very early?
00:19:38.244 - 00:20:19.172, Speaker B: I think we're extremely, extremely early. And obviously, there's a lot of enterprise players. But my gut feeling, my hunch is the entire field is wide open. No one has won it yet, including June. And I speak that from personal experience, like 2017, there were a bunch of competitors to Masari. And again, I keep coming back to that story that we didn't prioritize on chain data because we didn't anticipate how fast that was going to grow. And then opportunities just emerged out of a sudden that gave rise to June and Nansen and all the other data companies.
00:20:19.172 - 00:20:25.892, Speaker B: So this space is moving so fast that new startup opportunities emerge all the time.
00:20:25.988 - 00:20:58.768, Speaker A: I was talking to Alex from Nansen and he mentioned gaming as another big area that he wants to get into with Nansen. And that kind of is true to what we're talking about today, which is like, what would a world look like with all these startups that are building space? Could they build out their own beachhead, win success in their verticalized market, and then over time grow horizontally into other sectors? It's still too early to decide where it's going to go, but I feel like some very strong players are able to capture that opportunity and verticalize across different segments.
00:20:58.856 - 00:21:11.936, Speaker B: Yeah, I mean, the important thing is to figure out a good beachhead market, identify a specific user point and their specific pain point on a specific chain or on a specific data set.
00:21:12.080 - 00:21:12.560, Speaker A: Yeah.
00:21:12.632 - 00:21:45.484, Speaker B: For example, NFT dataset and targeting a specific group of users. It could be PM's growth people, analysts, traders, hedge funds, et cetera, et cetera, and build something really useful for them and eventually scale from there, because so far the space is so fragmented that no one has, has managed to build a good data solution at scale. There's a lot of players that solve this specific problem, but no one has managed to do it well for everyone.
00:21:45.644 - 00:22:48.248, Speaker A: So I guess this is an interesting question, which is what do you think is the monetization strategy for web three? Obviously, this is probably something that we're going to talk deep about, but web two was the creation of cookies, tracking the data and then using advertising as a way to extract value. Obviously, the core component of web two was data. This data is very, it's very siloed in these companies. People from the outside aren't able to see it. An example of this is Twitter pulled out their API for developers because they don't want anyone building anything with the data because it's so valuable to Twitter, Facebook, the same thing. Facebook wants to use data so they can get more advertisers using their platform versus anyone else. But now, in a post web two world into web three, data is ubiquitous.
00:22:48.248 - 00:23:15.412, Speaker A: It's everywhere. It really goes back to who can synthesize the data, who can clean, ingest the data, synthesize the data in a way that's going to give them the edge against anyone else. It's almost as if it's like everything is inverted compared to in terms of what's happened in web two into web three, and people are building from that lens. So I guess the question is, what would the monetization strategy be here for web three?
00:23:15.508 - 00:24:21.650, Speaker B: I mean, for the centralized companies, it's pretty obvious it's traditional b two B enterprise SaaS model. And then for the decentralized players, like the graph, I mean, they launched the token. I'm not sure if there's much work that has been put into, you know, creating value or accruing value to the token itself, I'm not sure, but it's, there's some, it's very difficult, especially due to the regulatory hurdles. And then there's a third group of people who I find more interesting, which is the retail users. Like the wallets. Right. If you own a wallet, can you capture value off of your own data? I think that's something that web three crypto fundamentally enables, is that for the first time, users truly own their personal data, their transaction data, their wallet data, and there's other people who want to take advantage of that data.
00:24:21.650 - 00:24:37.468, Speaker B: And potentially the wallets and the retail users can monetize this data that's on chain by selling the data to the users. The users could be, for example, advertisers who want to buy this personal data. Right?
00:24:37.596 - 00:24:38.940, Speaker A: Like an opt in basis.
00:24:39.052 - 00:24:40.344, Speaker B: An opt in basis.
00:24:40.844 - 00:24:51.244, Speaker A: I would imagine this, I mean, right now data is all open and public. So I would imagine like, you would need like zero knowledge proofs as a way to kind of block that access.
00:24:51.364 - 00:24:54.598, Speaker B: Something along those lines. Yes. Some kind of privacy technology.
00:24:54.766 - 00:25:35.202, Speaker A: Oh, so interesting. So we're so early where that, whereby, like users right now, it's a free for all, right? Because data is everywhere. And it's, I think I was reading somewhere that there's over like 1.5 trillion petabytes of data between just bitcoin and Ethereum alone, which is insane. And so you could argue that right now everything's ubiquitous and open. There would be a point in sometime in either ethereum's life or other layer ones where they'll start to think more about privacy. In fact, if you look at Vitalik's recent research paper, he talked about some of the areas he's excited about, obviously, account, which we covered last time.
00:25:35.202 - 00:26:16.508, Speaker A: The other was ZK, and getting some sort of ZK enabled protocol changes within Ethereum so that privacy could become a more important element for identity and users. Yeah, and I think that's going to become important, I think, in the long run regards to, like, how, you know, and I guess I just answering the question that I mentioned earlier is like, how do users monetize? Or how do startups monetize? Well, I mean, you could build like, great products where you charge business and SaaS there's ways where, you know, there could be an opt in base where users can themselves can give their data or delegate the data to companies like Facebook. Right. Where they then can monetize and pass some of the revenue back into the users for opting into that data.
00:26:16.636 - 00:26:34.988, Speaker B: Yeah, we touched on a lot of topics that seem all over the place, seem a little bit independent of each other, but actually, there is a very nice way to view the entire space. So let me try to summarize everything that we just discussed. Okay?
00:26:35.036 - 00:26:35.348, Speaker A: Okay.
00:26:35.396 - 00:27:06.828, Speaker B: So at the very top level, you have crypto data. Underneath that, you have two things. There's two things you can do with crypto data. There's reading and there's writing. So far, we've almost exclusively talked about reading, okay? Reading data from on chain sources. Writing is more like flashbots or the RPC providers, like alchemy or infuria. We haven't got the chance to talk about those.
00:27:06.828 - 00:27:49.550, Speaker B: But this is not the core of this episode. The core of this episode is focusing on the reading, the on chain reading the data, okay? And beneath that, there's different types of data. There's off chain data, there's on chain data. The more interesting part of the two is on chain data, because that's truly crypto native. Okay? So now we're focusing on reading on chain data. And there are, in my opinion, two specific pain points or opportunities in crypto right now. The first part is providing good datasets, good databases to technical users.
00:27:49.550 - 00:29:00.704, Speaker B: And the second opportunity is making sense of this data, interpreting this data. So that would involve some kind of front end, some kind of analytics, charts, graphs, or in the case of aura, for example, translating natural language into code, into graphs and charts and data. We can touch upon that later. So these are the two layers, okay? So again, to summarize, there's very raw data at the lowest level, okay? That's like inferior alchemy, you know, other RPC providers. Layer on top of that is the data indexing, so the companies that make data easy to access to read and better organized for developers. And the final layer at the very top is for the end users, the non technical people, to read that data. So this is the current, or at least my mental model of the current stack, and where the opportunities are, and opportunities are everywhere across the entire stack and horizontally across user segments.
00:29:01.004 - 00:29:10.756, Speaker A: I just feel like there's just so much opportunity in this space in regards to the data that's being utilized and how it's going to be used and how it's going to monetize over the long run.
00:29:10.940 - 00:29:21.460, Speaker B: Every person I talk to in this space, from investors to analysts to builders to DAP developers, have pain points related to crypto data.
00:29:21.612 - 00:29:34.884, Speaker A: Yeah, you shared a tweet with me the other day. It was from Varcel agarwal, Metavoice. And there's three things that stood out to me when you shared that tweet, by the way.
00:29:35.004 - 00:30:18.578, Speaker B: Just interesting side note, Vatsl and Metavoice is probably the perfect example of what I mentioned earlier about every crypto company is a crypto data indexing company because Metavoice is not a data company. What they're building is audio identity. Okay, so meta voice is just a side note, Metavoice is to audio identity what pfps are to visual identity. They're not a data company. However, they spend a shit ton of time solving their own data problems. That's how they came up with that tweet in which they talked about these different pain points that they experienced and offering solutions. If you want to take it from here.
00:30:18.706 - 00:31:17.998, Speaker A: Yeah, I mean, like the three things that stood out to me from what Watson said was liveliness of data, which we talked about earlier, what does liveliness mean? How current is that data relative to when the data was indexed? Two is the quality of the data, is it structured, is it clean? And finally, it's UI. Obviously, Dune has some element of good UI, but you have to either learn SQL to query the database, or you have to use formatted tables that have already been done by people that have already queried the database. That isn't the best experience. Startups like Aura and many others that are trying to solve for this area, they're trying to make it so that you can use natural language processing as a way to query the data just using human text, and then being able to convert that into queries via SQL, and then being able to get that data back as a way to showcase to the users what they're looking for.
00:31:18.126 - 00:31:33.822, Speaker B: And by the way, VatSL's tweet basically maps one to one to the layers of the stack that I mentioned earlier. The UI is the top of the layer and then the data indexing, the data quality and liveness is lower, the lower part of the stack.
00:31:33.958 - 00:32:09.974, Speaker A: So there's another tweet that I think you shared with me, which I want to talk about. It's from Xerox Kofi. He used to work in one confirmation. He was like a pretty. I think he's one, like one of the guys that did a lot of data stuff. There alongside Richard. But he mentioned that getting raw on chain data is like that work is already done, and the focus now is how do you interpret that data which you have? Nansen, Masari, many others are focused on interpreting that data, but he thinks that the vast amount of opportunity in starting a data startup is interpretation.
00:32:09.974 - 00:32:12.482, Speaker A: What was your counter to that?
00:32:12.658 - 00:33:12.864, Speaker B: I don't disagree 100%, but I would disagree with 50% of it, because I think both the raw data and the interpretation layer are equally important on unsolved problems right now in terms of raw data. I think he's right to say that the raw data problem is largely solved only for user Persona like himself, which is the analysts, the investors. But there is a bunch of user segments out there for whom it's not solved. Those would be the growth, the product managers, the data engineers, the Dapp developers. There is a bunch of user segments that are experiencing huge pain points with respect to querying, reading raw data that's not solved by any means, because how do I know that? It's because every single founder tells me that. Okay, so that's the first part. The second part is the interpretation layer for user Personas like himself.
00:33:12.864 - 00:33:46.428, Speaker B: I agree with him. It's not solved. And that's why there are companies like June Nansen who are solving small slices of the problem. I'm sure they're going to try to solve every single slice of the problem later on, but right now they've managed to solve a small slice of the problem. And there's companies like Aura who are translating super high level natural language into insights, and that might be a good segue into the whole discussion or whole topic around AI.
00:33:46.556 - 00:34:04.636, Speaker A: Yeah, why don't you give a quick synopsis on AI general? We can start with OpenAI chat GPT, and then we could talk about the ramifications of that into crypto and what are maybe some crypto use cases that we're starting to see.
00:34:04.780 - 00:35:14.528, Speaker B: Yeah, so I'll start by prefacing that I'm not an expert in AI. However, as I said before, I've been a practitioner in the data space for many years, so I developed some intuition. The thing that, in my opinion, sort of changed the whole AI space was this concept of backpropagation, which is a technique used to train large, complex, deep neural networks. So you can think of neural networks as a super complex and almost like a brute force model. You have a very large set of functions and you input a bunch of data into it and you try to optimize the outcome, the output of the model so training this, optimizing this large set of functions is very difficult. But with back propagation, or backprop, made things a lot easier, a lot more efficient, given the amount of compute power that we have in the, in the world. So in a hypothetical world where we have infinite amount of compute power or GPU's, we probably don't need something like backprop.
00:35:14.528 - 00:35:37.810, Speaker B: But because of the limitations with our time and our compute power, this is what, maybe around 1020 years ago, that really led to the rise of AI, by making the training part of AI, the model training part, much more efficient. So that was a fundamental mathematical breakthrough in AI that allowed for all the progress that we made in the next few years.
00:35:37.882 - 00:35:40.450, Speaker A: And this started with IBM's Watson, right?
00:35:40.522 - 00:36:09.736, Speaker B: I mean, IBM Watson, I think it was a huge player in this. But the whole AI history, like nothing in tech, goes from zero to almost, okay, there's AI, it's always a gradual process, and there's stepwise changes along the way. But, you know, we can trace the history of AI way back decades ago. AI is not really a new thing. It's not something that just emerged, you know, ten years ago. We can trace it back two decades ago in. Throughout the 20th century.
00:36:09.736 - 00:37:08.748, Speaker B: But anyway, so this is sort of my understanding of what really led to AI, like this mathematical breakthrough, as well as the constant improvement in compute power and the huge amount of data that we managed to gather around the Internet, around the world over the last couple of decades. By the way, that was thanks to web two, that we have so much data that can be used for training. These three factors led to what AI is today. So more specifically, I played around with chat GPT, basically since it came out first day I tried chat GPT, I was like, this is total crap. What kind of trash is this? How dare people comparing it to Google. Literally, day one, people were saying, this thing is going to disrupt Google. My natural instinct whenever I see something like that on Twitter is to be contrarian, is to say, this thing is overhyped.
00:37:08.748 - 00:37:42.764, Speaker B: And I tried it, I was like, okay, I don't think it gives me better answers than Google does. So that was day one of me trying chat GPT. Day three, I managed to get chat GPT to do something interesting for me. Asked it for book recommendations and recommendations of Christmas gifts, and then I was like, okay, this thing is actually pretty interesting. Could help me with some stuff in life. And then day seven, I was like, holy shit, this is the real deal. What did I do on day seven? Well, I was writing our request for startups.
00:37:42.764 - 00:38:31.134, Speaker B: And I asked chat GPT to rewrite things for me, and I realized how powerful it is, especially for people who are not native english speakers like myself. Okay. Whenever I write in English, I have to constantly think about new ways to say the same thing. I'm always looking for things to, or ways to say the same thing in a way that sounds more natural. So ask chat GPT to do a very simple command, which is rewrite this colon, and I would copy paste the paragraph into it, and it will give me something really, really, really good. Basically, chat GPT helped me rewrite the entire request for startups. Not only that, I even asked chatgpt to give me startup ideas.
00:38:31.134 - 00:39:00.310, Speaker B: Although chat GPT was mostly bad in most areas, in one particular area, chat GPT gave me really good ideas, which was, this is very meta, to give me the startup ideas at the intersection of crypto and AI and chat GPT gave me some really interesting ideas, which I also think would work. And we can talk about this in a bit. So that's my sort of my personal experience over the last two weeks about GPT.
00:39:00.462 - 00:39:29.130, Speaker A: I had a similar experience as you. I didn't go as deep as you did, but I started to do more research around this area and realized that there could be some big implications into what GPT can do in everyday life. Right. And so we talked a lot about, like, the. The kid at the homework that has a homework assignment where they can just rely on chat GPT as a way to do its own homework assignment. You have developers that, I mean, basically, homework is done. It's dead.
00:39:29.322 - 00:39:38.254, Speaker B: Yeah, like, we're gonna have to figure out how to revamp the entire education system. You know, grade school, primary school, secondary school, educational system.
00:39:38.554 - 00:40:20.678, Speaker A: Yep. And every aspect. Right. So, like, even if you think about developers that are using writing code instead of, like, boilerplate templates that they would have to write out, they can just ping chat GPT and then spin up a boiler template and smart contract auditing. I know, Charlie, you'll talk a bit about that, of just reviewing code instantaneously and pointing out different areas or bugs that chat GPT can point out. In fact, I heard that this is already happening, which is like, people I wouldn't call black hats, as an example, are already uploading code and finding out where the bugs are and then targeting those startups in crypto. This is happening today using chat.
00:40:20.766 - 00:40:23.874, Speaker B: I tweeted exactly this on the day GPT came out. Did you really?
00:40:26.694 - 00:40:31.558, Speaker A: Oh, my God. So this is already happening. So this is. It's pretty crazy.
00:40:31.646 - 00:40:45.664, Speaker B: Yeah. But the reason why we're talking about AI is really because we want to focus on some of the interesting things that could happen at the intersection of crypto and AI in the coming years.
00:40:46.564 - 00:40:48.356, Speaker A: And that is a large part of this, too.
00:40:48.460 - 00:41:22.010, Speaker B: Yeah, a handful of things that I think is going to happen. One is something that you mentioned just now, which is engineers using GPT as Copilot to assist them with coding. So before GPT came out, there's already a lot of engineers that use GitHub Copilot to assist them with non smart contract like web two software engineering. And in fact, I don't know if you saw this tweet by the CEO of Replid.
00:41:22.122 - 00:41:22.626, Speaker A: Yes.
00:41:22.730 - 00:42:18.734, Speaker B: The reason why I came across that tweet was because he sounded like he was a bitcoin maximalist. He said that bitcoin was going to be like, you know, the thing that will revolutionize engineering in the next ten years. I didn't get the logical sequence between bitcoin and engineering, but he did mention that AI was going to be the thing over the next ten years that will ten x the productivity of engineers. And that was before GPT came out. And so after GPT came out, I learned that our own engineering team at alliance was using a combination of GitHub, copilot and GPT as assistant to their coding. I also learned that from two founders, alliance founders, that they were using GPT to generate boilerplate code. So it's the kind of code that is not very important, but you have to write anyway.
00:42:18.734 - 00:42:34.226, Speaker B: So that's the boilerplate code and the kind of work that takes quite a bit of time. It's really annoying, but you have to do it anyway. But now with GPT or other copilot products, you're able to generate that kind of boilerplate code.
00:42:34.370 - 00:43:15.176, Speaker A: I mean, I'm thinking through the impacts that this will have into like, crypto. I mean, I get the idea, like the impact for engineering team is that you could be much more leaner, right? You don't have to hire x amount of people. So startups become much more leaner and much more focused. You have this natural, like, collaboration between all the engineers are imputing this data and they're all getting the benefit out of it because they're all kind of imputing the data, right. Similar to what GitHub is doing. So naturally, workforce are going to become much more leaner and stronger. But security is interesting, right? So right now, as you know, crypto has a security problem, and there's so many different aspects.
00:43:15.176 - 00:43:36.308, Speaker A: You have security engineers, there's startups that will have bug bounties that will offer to security engineers that will review code and get rewarded for that. You have interesting elements of crowdsourcing this knowledge. But now, if you think about what AI can do, it can ultimately do all of that plus an order of magnitude more.
00:43:36.436 - 00:44:48.188, Speaker B: It's very hard to predict how much impact AI will have on crypto in terms of security improvement. I think there will be meaningful impact, but it's hard to quantify that before it happens. But what I know for sure is, well, I mean, everyone saw the tweets on Twitter about GPT helping the decoders catch some bugs, smart contract bugs, and we have a company at alliance called Town no more who has been building a tool to automatically catch bugs before GPT came out, and now they're looking into using GPT as a way to help companies or smart contract engineers to audit their code. So I think security overall will increase. However, I'm not saying that AI or GPT or other LLM models will completely replace human auditors. I think what's going to happen is GPT and AI in general is very good at catching common but basic bugs, and they're better at this than humans. They're able to do this faster and at a greater scale than humans.
00:44:48.188 - 00:45:16.392, Speaker B: So then you're going to let humans try to catch the more sophisticated bugs, the bugs that don't appear very often in training sets, the data sets upon which the AI models was trained. So AI will actually assist the auditors as well, make their lives easier. So this is, I think, what's going to happen to security. And this is only one of the several areas, I think AI will make an impact on crypto.
00:45:16.488 - 00:45:41.832, Speaker A: Let's dive deeper into that. So let's say that developers now have access to this, like security in a box like solution, right? They have this, like copilot that will automatically assess its code. Could AI, because of this copilot, can developers take more risk and go deeper into new areas of innovation that may not necessarily happen before?
00:45:42.008 - 00:46:58.732, Speaker B: So one thing I thought of, I don't know how realistic this is, but I think it's possible to write a really detailed and precise set of requirements to AI in natural language, in English, and have AI produce the code for you. I'm not sure that we're quite there yet today, but I think it's possible to fine tune the existing LLM models in such a way that we can get very close to this vision, or at least in a world where we're able to write basic code, not super complex defi apps or whatever, by just using natural language as an input. And the output would be smart contract code. So imagine 2017, during the ICO bubble that GPT existed. What did I do in 2017? I read a bunch of white papers with, there was no colors, just a bunch of white papers. Imagine AI existed back then or TPK existed back then. Yeah, you probably would have been able to generate some decent code off of the, at least the really good white papers that gave detailed requirements.
00:46:58.908 - 00:47:01.244, Speaker A: Yeah, I mean, it would call out to bullshit right away, right?
00:47:01.324 - 00:47:02.304, Speaker B: Yeah, exactly.
00:47:04.724 - 00:47:19.592, Speaker A: Like, just from an efficiency perspective, I see like a ten x. What are some other products that you're seeing? You mentioned this earlier, like you typed something and they gave you some meta idea that chat GPT recommended. What was that idea?
00:47:19.728 - 00:48:23.172, Speaker B: So again, that goes back to aura and the bunch of Google of Web three that will emerge. I'm sure there's like 100 teams that are building this right now, but basically the idea is that with June and Nansen or whatever, users are not. They operate at a fairly low level of abstraction. They either write SQL code or they open a website and then click on a particular graph or chart or whatever, but they're not able to customize it. But with this new Google of web three under the hood, you're able to translate between natural language and code or instructions to interact with blockchain. The obvious idea is this Google of crypto. Another interesting direction is instead of just asking this product to give you information, you can ask this product to do things for you by interacting with blockchains.
00:48:23.172 - 00:48:57.216, Speaker B: For example, you can ask this product, okay, give me the top five yield generating pools ranked by risk reward on Ethereum, and then put my money into those pools. A natural language command, a prompt like this, and then the system will do it for you. The system will not only find the top five pools, but actually transfer your money into those pools. This might not be the best example, but I'm just giving you an idea of how this product can interact directly on chain with AI.
00:48:57.400 - 00:50:01.426, Speaker A: So here's something interesting that I read, and this is a little bit off topic, but Amazon is, is losing $10 billion a year on Alexa, obviously. I think Alexa and like Google, Siri and others that came out, I think they came out too early, obviously. Like, I mean, I've used it and I stopped using it both because of data collection, privacy perspective, and then also like, playing music in time isn't enough for me to have this speaker. But is that what's missing? Because, like, for me, like, what would be more practical is telling chat GPT, hey, you know, chat GPT, can you turn on the house? Can you do x, Y and Z? Can you go purchase x and like, give it like natural instructions where you don't even have to use the Internet anymore? Yeah, I mean, I feel like that is where the future is, where the Internet gets, like, the visual identity. I'm not saying this is gonna happen completely, but 30% to 40% of your Internet interaction, where you're searching on mobile or doing things on mobile, could be abstracted away into just a simple voice command.
00:50:01.530 - 00:50:32.880, Speaker B: Yeah, it's much easier if the interaction is completely digital, like, for example, interacting with the blockchain. It's a lot harder if you interact with the real world. Like buying grocery for me. Right? Yeah, but anyway, that's a signal. But it's funny that you mentioned Alexa's burning that much money because I heard OpenAI is burning. So OpenAI charges or spends $0.003 per query from users.
00:50:32.880 - 00:50:42.568, Speaker B: Sounds like a really small number, but given the amount of queries that the users do per day, they're actually spending $3 million per day just doing.
00:50:42.616 - 00:50:43.440, Speaker A: That's insane.
00:50:43.592 - 00:50:57.542, Speaker B: Just paying AWS. Actually, they run their models on AWS and that translates into $1 billion per year. So they're just basically burning VC money like crazy right now.
00:50:57.718 - 00:50:58.594, Speaker A: They are.
00:50:59.294 - 00:51:08.190, Speaker B: I'm sure they'll be able to figure out monetization model, but just to give you an idea of how much money this is burning at the moment, funny.
00:51:08.222 - 00:51:33.598, Speaker A: Enough, OpenAI was started as a research not for profit organization. And then I think recently, meaning like maybe a year ago, Microsoft put in a billion for the for profit side of OpenAI. So I definitely will. I think we're going to see some interesting elements of real world monetization and real world use cases where I think there'll be a clear use case for like, the everyday user and how to use the product.
00:51:33.686 - 00:51:37.006, Speaker B: Yep, there's three more ideas.
00:51:37.190 - 00:51:37.678, Speaker A: Okay.
00:51:37.726 - 00:51:45.290, Speaker B: Or topics at the intersection of crypto and AI that I want to talk about there. I think they're really interesting, by the.
00:51:45.322 - 00:51:58.730, Speaker A: Way, like, if anyone wants access to the request for startups and all the different startups that we think are going to be the future for crypto, including AI, you can go to Alliance XYZ and click on startup ideas.
00:51:58.842 - 00:52:29.020, Speaker B: So the first idea. So I came to this realization about crypto consumer apps. People keep complaining about how crypto is not the best way to build it's not the best rail to build consumer apps. Okay. Because consumers would have to install a wallet. Click on signing a message upon every action, and they may have to repeatedly re sign the transaction if they fail, because transactions fails, all fail, all the time. They need to replenish the wallet if they run out of money and so on and so forth.
00:52:29.020 - 00:52:45.014, Speaker B: Like, all these things create a huge pain point for consumers. But I came to this insight, which is that there is one group of users for which crypto actually offers better user experience than web two. And that group of users is bots.
00:52:45.834 - 00:52:46.614, Speaker A: Yep.
00:52:46.914 - 00:53:30.156, Speaker B: So bots don't have to go through all this pain that users are going through, at least the emotional pain. And at the same time, the bots don't need to worry about getting deplatformed by the web two, you know, the centralized social networks or financial services or games, because crypto is fundamentally permissionless. So I think that it's very likely that the first decentralized social network or game that will become extremely successful, that will gain mass adoption, will be one that fully embraces AI rather than one that resists AI, because all the web, two social networks and games, they resist bots.
00:53:30.270 - 00:53:55.830, Speaker A: So, okay, let's take some examples, right? So you have a game on chain game. You have two players, right? And maybe something like very basic game, like, let's say checkers or chess or whatever. It's completely on chain. So you design these bots, right, that are AI capable and they're competing with each other. What then? Like, like, I'm trying to contextualize this in a way that will show to our listeners what, how big this is gonna be.
00:53:55.912 - 00:54:08.306, Speaker B: The analogy is Defi. Okay, Defi, there's, let's say two groups of users. There's the retail users, and there's the bots. And as a retail user, chances are your counterpart is the bots.
00:54:08.490 - 00:54:09.018, Speaker A: Yeah.
00:54:09.106 - 00:54:46.402, Speaker B: On average, the bots make money, and you, as a retail user, you lose money, but it's fine because you play the game. For the dopamine rush, most people are fine with playing the game, this defi game, even if they lose money. I think something similar could happen with crypto games, which is that you're still going to have two different game modes, one game mode for bots and one game mode for retail users. And they have different goals within this game. And then the job of the game developer is to creatively find the two game modes for these two different types of user Personas, given their goals and their preferences, but they can still play against each other.
00:54:46.498 - 00:55:10.782, Speaker A: Got it, or they can play against other bots, then that comes similar to Dark Forest, where you have just bots against bots. And then it really is based on who designed the bots and how competitive are, like, how competitive are the bots with each other. And then this brings an enormous amount of developer resources, right. And developers into, into these types of games. And games could become very powerful over time.
00:55:10.838 - 00:55:32.998, Speaker B: The same idea applies to social networks, the web, two social networks. They resist bots, they want to ban bots. But there is a difference between being a bot and being a spam. I think with LLM models you can envision a world where bots actually meaningfully contribute to conversations rather than just spamming conversations.
00:55:33.126 - 00:55:55.148, Speaker A: I mean, you could say that you could see that with user generated content, like video, audio content, and we saw the rise of, who was it? The largest crypto, I'm sorry, largest AI following on Twitter. I forgot her name. But teo or something like that has like, I don't know, over 100 and 5200 thousand followers. All of the content is user generated and people like it.
00:55:55.196 - 00:55:56.904, Speaker B: Yep, 100%.
00:55:57.284 - 00:56:01.844, Speaker A: And so that would be very interesting to see. Right? Yeah.
00:56:01.964 - 00:56:44.488, Speaker B: And the final idea I want to talk about is it's a little bit of a utopia, but I like to see a world where AI is run and trained locally on your local device rather than from the cloud. And the motivation behind that is exactly the same as why you want decentralized money or decentralized finance or decentralized social networks. You as a user, you don't want to be censored by the companies that created those models. Picture a world where GPT becomes so omnipresent, so powerful, everyone depends on it, but they get to say who get to use it or.
00:56:44.536 - 00:56:48.408, Speaker A: Yeah, I mean, like, it's kind of the concept of like running your own nodes, right?
00:56:48.536 - 00:56:49.404, Speaker B: Exactly.
00:56:49.944 - 00:57:12.140, Speaker A: And so running your own AI models locally on your computer makes a lot of sense from that perspective, especially given that, like, who controls that AI model, right? Like, if anyone changes the data or gives a data or such, that it acts much more differently for people that are using it versus people that want to use it locally and have it for a specific use case for what they like, nothing makes a lot of sense.
00:57:12.332 - 00:57:59.100, Speaker B: So this idea of decentralized AI is probably the one thing I'm personally most excited about, because I think it's going to actually do real good to the world instead of there's a lot of people who worry about AI becoming or driving the world into a disability dystopian vision and decentralized AI is the thing that will prevent that from happening. Obviously, this is extremely, extremely technically challenging, and it's probably more of an AI problem than a crypto problem, even though it has the word decentralized. It's more about finding new ways to fine tune data locally to prune data, or to prune models locally to compress data locally. So it's more of a math problem, computer science problem than crypto.
00:57:59.132 - 00:58:06.996, Speaker A: Well, I mean, what about zero knowledge proofs, right? Like, we know the proofs, if change, then we know that it's been altered, right?
00:58:07.140 - 00:58:11.864, Speaker B: Potentially. I'm not sure. Yeah, I'm not knowledgeable enough.
00:58:12.884 - 00:58:27.184, Speaker A: We're just talking, but yeah, I mean, I think the world that we're going to be moving into next is going to be very different in the world we're in today. And I'm pretty excited about a lot of stuff that you mentioned on the AI side.
00:58:27.344 - 00:58:43.320, Speaker B: Point being, if you're looking to pivot from crypto to AI, don't do that, because there's a lot of opportunities at the intersection of crypto and AI. And I'm saying that because I know people are pivoting away from crypto and AI.
00:58:43.432 - 00:58:50.516, Speaker A: We had a startup the other day that applied and they ended up sending us an email saying that they're going to pivot to AI.
00:58:50.580 - 00:59:05.540, Speaker B: I don't blame them. I don't blame them. I mean, I mean, there's a lot of exciting things happening if you need to survive in this bear market and people like VC's are fomoing into AI startups. And if you really believe in AI, then sure, by all means, take the money.
00:59:05.732 - 00:59:15.684, Speaker A: Yeah. Cool. Well, I think we had a great discussion on data and AI and the implications of both. Any other final thoughts?
00:59:16.064 - 00:59:17.524, Speaker B: I worry about my kids.
00:59:18.144 - 00:59:19.524, Speaker A: Yeah, same.
00:59:20.024 - 00:59:30.016, Speaker B: I think the educational system needs to drastically change. I don't want my kids to learn skills that will no longer be relevant in 20 years.
00:59:30.160 - 00:59:56.408, Speaker A: Yeah, 100%. I also think, though, there is some important element of the world that we live in today. And what are some of those skills that are going to be good for the future, right? Completely. You know, I guess it's analogous to saying like, oh, you know, why use a cell phone? Why save the numbers when you used to save the numbers? We used to memorize the phone numbers. Or like navigation. Why use a navigation where you used to remember all the directions at the top of your brain?
00:59:56.456 - 00:59:57.124, Speaker B: Yeah.
00:59:57.464 - 01:00:22.414, Speaker A: And I think that's where we're going next, which is like, oh, why should we rely on chat GPT for everything, such as writing content or designing or developing apps, et cetera. Why not just do it yourself? And I think there's an important balance of the two, which is like, you know, having some retention of that knowledge is important. But then, like, leveraging what you can with chat GBT makes a lot of sense in terms of being able to scale.
01:00:22.494 - 01:00:40.612, Speaker B: Exactly right. Like my, just based on my personal experience over the last two weeks, I think the more important skill set to have in the next few years might no longer be the ability to do good research, to have answers to questions, but rather to ask the right questions.
01:00:40.708 - 01:01:26.514, Speaker A: Yeah, there is a lot of chatter about this, and I think this is probably true, which is like the next set of entrepreneurs that you're going to see, maybe not today, but probably over the next couple decades, is those that have the best ideas versus the actual execution of that idea, which I think is probably true. Right? Like once, I mean, chat GPT is still in beta. Like, it's not even like something that's productized yet. So imagine, you know, once this is productized in such a way where you could use these products and you can design, build apps that everyone can use, all just by using human language. That is going to be an interesting world to live in, especially with crypto added onto that. Cool. Well, thanks so much for your time.
01:01:26.514 - 01:01:32.702, Speaker A: If you haven't subscribed yet, hit subscribe on Goodgame. Otherwise we'll see you in January.
01:01:32.838 - 01:01:34.354, Speaker B: See you next year.
01:01:34.854 - 01:01:38.614, Speaker A: Thanks for listening to Goodgame. Don't forget to subscribe. We'll see you next week.

00:00:11.290 - 00:01:18.930, Speaker A: Today is the second installment of the Gnosis AI call, which we started last month. So every month we get together with a team that's building a AI capabilities and applications on gnosis chain. And this month we're super excited to have Origin trail. But yeah, further kind of quick context about gnosis AI. If you've been kind of following along this year, there have been a lot of things happening with regards to AI on gnosischain. Earlier this year at ECC, we had a hackathon called the Augment hackathon and we had another prediction market hackathon. And also in August of this year, we made an announcement with Origin Trail that Origin Trail V six, their decentralized knowledge graph was being integrated on gnosis chain.
00:01:18.930 - 00:01:55.562, Speaker A: I'm going to mute someone here. Sorry. That was super high priority for them. Okay, cool. So I'm sure that we'll jump into or talk about the DKG V six today, but just wanted to kind of establish that connection between origin trail and gnosis chain. So quick intro on Origin trail. Origin Trail is an ecosystem dedicated to making the global economy work sustainably.
00:01:55.562 - 00:02:42.720, Speaker A: By enabling a universe of AI ready knowledge assets, allowing anyone to take part in trusted knowledge sharing, it leverages the open source decentralized knowledge graph that connects physical and digital worlds in a single connected reality, driving transparency and trust. Advanced knowledge graph technology currently powers trillion dollar companies like Google and Facebook by reshaping it for web three. The Origin trail decentralized knowledge graph provides a crucial fabric to link, verify and value data on both physical and digital assets. So with that, I'm going to hand it over to Brennamar for a product demo. So welcome, Brennamar. Thank you so much for making the time and yeah, great to have you.
00:02:44.210 - 00:03:05.640, Speaker B: Thanks for having me, guys. Welcome to the call and excited to be sharing a little bit more about Origin trail to the noses community. So also there was a short intro, but perhaps would it make sense to go through maybe a few slides just so we accompany this so you guys don't look just at me, but actually have some visuals to see.
00:03:06.650 - 00:03:09.240, Speaker A: Yeah, absolutely. Go for it.
00:03:09.770 - 00:03:20.890, Speaker B: Awesome. So just going to please share and then I'm going to show you a short demo. Just see if that sharing works properly.
00:03:24.590 - 00:03:34.210, Speaker A: And when Brendamir is done with the demo, we can jump into an AMA. So save any questions you have for the end of the presentation.
00:03:35.270 - 00:03:41.860, Speaker B: I have to rejoin, I apologize, my computer doesn't let me share on this. Give me.
00:03:43.030 - 00:04:50.850, Speaker A: No problem. Is anyone else on the call? Building in AI or building on gnosis? Chain. More generally, feel free to. You can unmute your mic or you can also use the chat over on the right hand side. But also, no worries if people are feeling quiet. I will share our announcement that we made with Oregon show on our blog right here in the chat.
00:04:52.870 - 00:04:53.346, Speaker B: So that.
00:04:53.368 - 00:05:03.720, Speaker A: You can learn more about the decentralized knowledge graph v six. And looks like we have Brin Amir back.
00:05:07.200 - 00:05:53.064, Speaker B: Okay, once again, trying to share my screen. Thanks everybody for the patience and hi. Okay. One would think with all this great technology, we wouldn't have trouble sharing a simple screen, but that seemed to work, no? Fantastic. Okay. All right, so thanks again for having me. I'm going to just give a quick overview what origin twelve really is about, what the mission is, why it's different in the world of web three, because what I'm going to be presenting is not a blockchain, it's this decentralized knowledge graph.
00:05:53.064 - 00:06:47.420, Speaker B: So probably you're thinking, what the hell does this mean? So I'll try to answer that question and I'll give you a demo that you can do with it and soon with gnosis and origin trail together. So I'll jump quickly through it. Basically, I'll start with a super high level problem, I guess. I think you guys saw this guy before, famous Jeffrey Hinton, who left Google because of the danger of AI. I like to start my presentation with this because it turns out that even the sort of the biggest names in the industry got kind of scared of the technology. And there's this terminator scenario scare, which we can debate. Some people say it's kind of bogus, some people are genuinely afraid, but there's kind of more tangible, already visible scare, which is just plain simple, problematic content online, or rather the problem of misinformation.
00:06:47.420 - 00:07:52.880, Speaker B: And you could have seen this maybe on Twitter, for example, there was a lawyer, I saw this tweet months ago. A lawyer used Chad GPT to actually kind of get his case going and used a bunch of quotes from Chad GPT that didn't exist at all because Chad GPT hallucinated him out, ended know going with his to court and getting into trouble himself. So probably accidentally, I suppose, the guy was busy and he used Chad GPT to help him without maybe even bad intention at all, he got into trouble. And this is just a very simple case. Very soon we'll have more content online generated by AI than by humans. And when that happens, it's a very big question of what happens with how do we know which information we can trust? And having that said, we believe that there's an overflow of misinformation already and that it's coming as an even bigger tsunami at us. So trusted data is really the cornerstone of all of the systems we're going to be building, not just technical systems, societal systems.
00:07:52.880 - 00:08:39.888, Speaker B: So at Torgin trail, actually, we think that we're in the middle of a new knowledge revolution. The first happened with the printing press back in the day. And actually the problem that printing press solved was scarcity of knowledge. So you had know very few places in the world, usually churches, especially in Europe, who sort of hoarded knowledge and kept it on their own. They even sort of encrypted it by using languages people don't speak anymore, like Latin or like old Slavic here, where I come from, which is still spoken in churches, by the way. But this knowledge was basically only there once the printing press came out. Basically, we got a huge revolution, like literally renaissance, a lot of scientific discoveries, just because we solved the problem of scarcity.
00:08:39.888 - 00:09:11.260, Speaker B: Then we had another revolution with the Internet. We solved the problem of fragmentation of information through connectivity. Basically, we connected computers, connected different systems. All of a sudden, sending an email is not such a crazy, amazing thing or a message to somebody. And back in the day, that was quite an invention, but that also means sharing information. And Internet actually started, and World Wide Web specifically as a project in CERN for scientists to exchange knowledge. Today, we have another problem.
00:09:11.260 - 00:10:06.652, Speaker B: The problem is trust. I don't have to preach to the choir here, I'm sure since you're in the knows channel, you're kind of here because you know a little bit about blockchains, I suppose, and what trust problems we have. And the way we see this trust issue handled in this new revolution is obviously through decentralized AI. So we believe that actually knowledge is a new asset class, and that this knowledge is what pushes not just web three, but also web two. Fundamentally, over the last couple of decades, you can see that across companies like Google, Facebook, Netflix, actually a lot of them, Uber, NASA, IKEA, all of the biggest things that you can, biggest companies, whatever sector you pick, they actually have a ton of data, but not just data. They actually have very useful knowledge created out of this data. And there's a big distinction.
00:10:06.652 - 00:10:35.080, Speaker B: This data is a little bit more raw. Data is you have data everywhere, but it's very raw. And then moving this to knowledge actually requires doing a little bit of effort and contextualizing it, connecting it together. For example, OpenAI, famous example, literally trained their model on the knowledge of the entire Internet. And now it's one of the most powerful public AI systems that we have. But it's also tricky. We don't know how it's been trained.
00:10:35.080 - 00:11:07.764, Speaker B: We know who controls the weights. We don't have any control over it. So essentially, we don't have control over the knowledge within those models. So we're here actually to make a pitch that knowledge should be observed as an asset, and we can tokenize it and actually expose it to markets in web three. So with origin trail, we actually create something called knowledge assets. Okay, this is a slide I didn't intend to have in, but this is our advisor, Professor Bob Metcalf. You maybe heard of him by Metcalf's law.
00:11:07.764 - 00:11:52.380, Speaker B: So I'll skip that one and I'll explain quickly what knowledge assets are. So, knowledge assets are basically these containers of knowledge. They have three key value propositions, the value proposition of ownership. So basically, when you create a knowledge asset, it is yours to own, and that means you mint an NFT with this piece of knowledge that is completely entangled with it. So basically, we introduced this ownership component to the knowledge. Once you create a knowledge asset in origin trail, you can then discover it. You can literally write a query, such as a database query, and you can find all the results from the entire knowledge graph that was populated by anybody who was publishing these knowledge assets into the decentralized knowledge graph.
00:11:52.380 - 00:12:27.324, Speaker B: And then finally you can verify them, because you can verify the whole path of that knowledge. And I'll explain it in the demo. But essentially, once it's created, all of the provenance of whatever has been happening with that knowledge asset is seen on chain. So, for example, if you transfer the ownership of this knowledge, you'll see that as a transaction if you update the knowledge. And by the way, only the one who has the ownership of the knowledge can actually update the knowledge. You'll see that on chain as well. You see like, basically as any transaction, you'll see who executed this and what the actual operation was.
00:12:27.324 - 00:13:05.176, Speaker B: So we have this verifiable trail, as we like to call it, of what happened with the knowledge and the origin. So origin twelve, right. We've actually seen quite a lot of growth of this origin trail DKG over the past of the past couple of months since we launched, as introduced at the beginning, the version six of Origin trail. So there's currently over 2 million knowledge assets in the DKG. And actually there's a lot of different companies using it. I suggest if you're interested into that, because Origin Trail is one of the rare examples of productively deployed technology. Web three technology in the real world.
00:13:05.176 - 00:13:49.530, Speaker B: Just some highlights are the swiss railway companies using origin trail for almost four years now in various applications, expanding further into other railways, into Europe. The British Standards institution, together with us retailers, some of them, you can see them on the screen, like Walmart, Costco, Home Depot, using it for several years now to track security audits for imports in the US. A bunch of other applications in the food, beverage industry, pharmaceutical industry, you can check them out on our website. So this is productive technology, just not something that comes out, has no proven use. What does it look like? Sorry, come again?
00:13:52.700 - 00:13:54.170, Speaker A: They didn't mute themselves.
00:13:55.260 - 00:14:29.184, Speaker B: Oh, no worries. Hello to everyone who joined, maybe later. So how can you think about origin trail? This kind of tries to illustrate it best. So you can think of it as kind of a central knowledge graph that connects to multiple blockchains. And that's what this nosis integration means. So basically, as I said, you have one knowledge graph, one decentralized knowledge graph hosted on its own decentralized network which contains all of the knowledge assets. But then you can go and let's say if you're in the noses community, you can create knowledge assets on nosis chain.
00:14:29.184 - 00:15:31.784, Speaker B: If you're in the polygon community, you can do it there. If you're in polka dot, you can do it on, let's say the origin twelve pair chain, which is a custom chain for the DKG on polka dot. And the idea here is that we have this cross chain database almost of sorts, that you can do all kinds of queries in, where the blockchains are really used for what they're best for. So blockchains are not so great for querying that if they were, we wouldn't need all of these indexers. And they're also not great if you want to introduce a ton of information on them because of consensus and the constraints. So obviously, using the blockchain for it's good for tokenization, for value transactions, and then using the knowledge graph for what it's good for, for knowledge and managing and querying and doing interesting things on that side of stuff. So when you try to sort of think of it from another perspective, you can see these three layers, like the bottom layer being obviously blockchains, the decentralized knowledge graph being in the middle.
00:15:31.784 - 00:16:14.870, Speaker B: Think of it kind of like a knowledge graph based ipfs sort of type of network, but it has its own incentive system, so you don't have to use pinning. Rather there's a decentralized system for pinning the knowledge assets. And then finally on top, you have these knowledge assets applications where knowledge assets are the key primitive. And actually their identifier is an evolution of a URL. It's called a UAL, so uniform asset locator, and it's implemented according to certain w three c standards to follow. Knowledge graph technology. What is really interesting is that you can build all kinds of search engines, discovery engines, question answering systems on top of this, and I'll show you one in a bit.
00:16:14.870 - 00:16:48.492, Speaker B: And with this together, as I briefly mentioned previously, we're also introducing a specific new mechanism called knowledge mining. So, which I'll mention in a bit. But essentially the point of knowledge mining is that we are going to create systems that incentivize creation of useful knowledge, a knowledge asset. If you're a bit technical, this might look a bit interesting. If not, it's probably not. But this is the anatomy of a knowledge asset. So it contains knowledge.
00:16:48.492 - 00:17:43.948, Speaker B: It contains this knowledge NFT and knowledge state proofs conjoined with this UAL, and it basically sits in this DKG index, so you can do searches on it, and it's all basically verifiable signed information. What's really interesting is when you combine this knowledge graph approach, which is really the Symbolic AI branch, this older branch of AI, if you might say it like that, with this new branch of AI, the neural AI, and when you combine this knowledge graph and embedded representation, you can do actually very, very cool things. So one of the things that I'm going to show you just now is actually built like this, and I'm going to change to that, actually. So what you're going to see is. Here it is. Okay, I'm showing you. I suppose you guys can see it, right? Yes, I see.
00:17:43.948 - 00:18:40.560, Speaker B: You can see it. Okay, so this is kind of a new beta product we just launched, which is just a way to access this decentralized knowledge graph or these knowledge assets. And this one is particularly called Origin Trail world, because we're building basically a knowledge bank of knowledge assets for origin trail ecosystem in the widest sense. So what you're seeing here kind of looks like a chatbot, and I can actually ask it a couple of questions. For example, there's something like, let's say I can ask what is knowledge asset? And it's going to shoot out an answer. And what's happening actually now under the hood is what you're seeing is not Chat GPT, it's not generative AI, it's rather extractive AI. So what we saw now was an answer that was basically extracted from the decentralized knowledge graph.
00:18:40.560 - 00:19:17.852, Speaker B: And you can see these source knowledge assets here. So if I go, let's say to this particular link, I'm going to open up something called a DKG explorer. This is similar to your blockchain explorer, but it's actually not looking into transactions on the blockchain or not only on the transactions on the blockchain. It actually looks at these knowledge assets. So what you're seeing here on the screen is this small graph which is one piece of the entire decentralized knowledge graph, which is this knowledge asset. And you can see all kinds of things inside. There's a bunch of text, there are certain identifiers, and you can also see this NFT.
00:19:17.852 - 00:19:44.644, Speaker B: So if I click here, it's going to open up the specific block Explorer page for this NFT. So you can track what's been happening and basically that's what's being queried here as well. So you can see who's created, who was the issuer. You can also see all of these resources. Basically that's one example of a knowledge asset. So the questions I can ask here are basically being answered from these knowledge assets. And there's two modes.
00:19:44.644 - 00:20:21.584, Speaker B: One is the search mode. So if you do search, I can do the same question. Now with search, it's going to return a little bit of a different type of an answer. So it's just going to literally take the content from the knowledge asset and give it back to me. So this is a content we created. And if I choose the chat mode in this case, that introduces one additional step that basically just takes this extracted answer and reformulates it a little bit using an LLM. But basically the LLM doesn't do generation, rather only does a little bit of the fine tuning in the end of this particular knowledge.
00:20:21.584 - 00:21:11.760, Speaker B: So what's really interesting here, and by the way, you might see that this is a beta, so you can actually contribute to this knowledge base, is that we have actually a new program, this program that I mentioned, knowledge mining, that I'll return back to. But just out of another kind of example to introduce here, this is just one type of an interface. So you can envision many different types of interfaces. For example, the companies I mentioned use custom interfaces sometimes within their systems. And it doesn't have to exactly look like this. This is just kind of a knowledge asset application sitting on top, but it's querying the blockchain and the decentralized knowledge graph to get all of this information. And like I said, the decentralized knowledge graph is completely permissionless.
00:21:11.760 - 00:21:30.060, Speaker B: Anybody can run a node, anybody can publish these knowledge assets inside. So basically you can create your own knowledge assets and own them and expose them to knowledge markets. Which brings me back. Since we're running out of time, I'm going to just quickly skip back to this presentation.
00:21:32.400 - 00:21:40.876, Speaker A: Bernamar, sorry not to cut you off, but there's no rush. You can go over the half hour mark. If people have the time, they can stick around.
00:21:40.978 - 00:22:22.348, Speaker B: Awesome. Thanks a lot, man. All right, so I have a couple of things that I can expand a little bit on. The thing that's currently on the screen is actually a program that we are running since this summer, which is called chat DKG, pun intended. And actually with chat DKG, we're creating a framework of tools to build trusted AI systems on Origintrail. Some of those tools are built by us as core developers of Origintrail, and some are built by builders who are joining our grants program. So what you see here on the screen is basically a grant program.
00:22:22.348 - 00:23:18.184, Speaker B: There's a million trace tokens available. We already have a few builders building really exciting things such as browser extension for creating knowledge assets. So you can basically go around and highlight things on websites and create knowledge assets from that. Interesting versions of sdks where you can have a little bit more user friendly experiences than like using the classic basic API or sdks from the DKG clients. We also have some projects creating plugins for copilot, things like that. So all such ideas basically are potential ideas for chat EKG and such as building AI based tools on Nosis would qualify. Using, for example, the agent framework from the OLAS protocol is something that is very exciting.
00:23:18.184 - 00:24:05.128, Speaker B: We're, by the way, in talks with the guys for several months already and been doing some very interesting work together. So I'm looking forward to sharing more on that when it's ready, and that's going to be very soon. But if you're interested, if you're a builder, go head over to this page, chadiqg AI, or scan this QR code and you'll see all basically the propositions for these grants. And the rules are super simple. There's three rules. Basically, what you're building has to be open source. It has to use origin trail, of course, and then finally, and actually the most importantly, it has to solve a meaningful problem if it's something that's useful for other people in whatever way it's applicable.
00:24:05.128 - 00:25:00.670, Speaker B: So yeah, go ahead, check it out if you're interested. We'd be happy to meet you if you're looking to build at this intersection of, especially at intersection of knowledge, graphs and analysis. So as I mentioned, we're also basically finalizing the origin twelve Nosis integration. I've just been informed by the team that the initial testnet release just happened today. This is a pre release, so very soon we will have origin twelve DKG released on Nosis Mainet, which will unlock some very exciting capabilities and integrations, such as the integrations with all of the tools in the Nosis ecosystem. We've been around for quite some time, so we're very excited for this. Tools like Nosis safe are something we've been very fond of using since the days of the multisig back in the day.
00:25:00.670 - 00:25:57.584, Speaker B: I still also use it for some things for my own personal playing around smart contract activities. And yes, generally, like I mentioned, we were very interested in integrations with the community. I mentioned the OLAs protocol because we went furthest with the guys. But also we're looking for if you're a builder in the hygnosis community to reach out, it would be cool to see if we have some synergies. And yeah, basically what we're aiming for, like I said, in the next coming months is going to be this new paradigm, something we call knowledge mining. We're about to release a very detailed RFC on this process, most likely tomorrow. The plan is to release it this week so that we explain in detail what it's about.
00:25:57.584 - 00:26:44.736, Speaker B: I won't go into too many details just now, I just want to give a hint of the whole concept. It's a new pioneering concept in web three, or in the world in general, where just as bitcoin mining gives you, basically rewards you bitcoin incentives for providing hash power to the bitcoin network for security. Right. The idea is that with knowledge mining you also get tokens while providing knowledge for the decentralized knowledge graph. And that means also useful knowledge. So not just some random text. And the idea here is that useful knowledge is actually also determined as this crowdsourced knowledge gets populated, also gets determined by verified principles from web two in web three.
00:26:44.736 - 00:27:54.708, Speaker B: So for example, principles like the cross linking principles that Google uses to rank websites with their page rank algorithm, but also from economic signal by basically on chain accounts, which can either be agents or can be people or smart contracts. So the idea being that we enable this sort of collective curation, you might know of this concept of token curated lists. Well, it's kind of a similar concept applied to the knowledge graph, where ultimately we create together useful knowledge and actually get rewarded in tokens in value. For this particular case, this is actually going to be, like I said, started relatively soon and we're going to release an RFC for that within the next couple of days. That's a bunch of topics. I hope I didn't take too much of everybody's energy because I wanted to leave some time for the Q A. So I guess I can show this Q a slide now and yeah, let it over to you guys.
00:27:54.708 - 00:27:58.292, Speaker B: Hope that wasn't too cumbersome.
00:27:58.436 - 00:28:37.860, Speaker A: No, not at all. That was super informative and a very nice presentation. So thank you so much for doing that. Yeah, now's a great time to have Bernamar field some questions. So you can unmute your mic if you have a question, or you can use the chat over there on the right hand side and I can read the question for you. I can kick it off with a question in terms of the knowledge nfts. When an knowledge NFT is queried, or let's say for lack of a better term, the AI is looking for that knowledge NFT.
00:28:37.860 - 00:28:46.970, Speaker A: Is there a transaction that has to, does, does that NFT have a price associated with it?
00:28:48.300 - 00:29:34.532, Speaker B: That's a really good question. And the answer comes in two groups, let's say depends on what kind of knowledge you're looking to access. So just as accessing some record on the blockchain through a get call on, let's say, an RPC or somewhere doesn't incur a transaction, the same principle applies to the DKG. If you're accessing some public knowledge in the public state. But actually knowledge assets can also contain private knowledge. So you can think of it as kind of the following way. You as a person or company, you can spin up a DKG node, and this node can contain piece of the public state, like basically shared state, you can sync the entire public state if you'd like.
00:29:34.532 - 00:30:18.752, Speaker B: But you can also contain some private knowledge. And this private knowledge can still be also tokenized. They can be connected both public and private knowledge in one knowledge asset. So on top of that you can apply knowledge market principles. Therefore, let's say if I were to buy some knowledge from you, assuming that, let's say I want to do this, I would be able to, in public DKG discover that this exists. So in a way I would do like a Google search type of a query, and after this Google search type of query, I would be able to access it under your terms. So let's say you enabled it to be accessed through some form of payment or some NFT marketplace.
00:30:18.752 - 00:30:47.420, Speaker B: So I need to make a purchase. All of these come basically to play and they can be built on top. So all of these marketplace scenarios are possible. Therefore in that case you would incur a transaction. But if you're essentially accessing public knowledge, then no, it's basically you're querying a node that contains all this information that is public, which you can also spin up. So similar paradigm as let's say a blockchain RPC endpoint.
00:30:50.320 - 00:31:04.240, Speaker A: Cool. We have a question from cosmicloud. Can I query knowledge assets published from OTP with a squirrel query sent through a gnosis node? Would you consider this a form of bridging between two chains?
00:31:06.500 - 00:33:14.128, Speaker B: That's angraph can feed it in and can actually prove that that particular state of that knowledge asset was the same as it was minted on another chain because it can submit these proofs. So technically, yes, you can consider it as kind of a form of bridging though. We're not talking about tokens here, we're talking about knowledge essentially. So the NFTs don't really move, but the information is usable across different chains. That means you don't have to create the same knowledge assets on every blockchain. That kind of defeats the purpose, actually. The point here is to leverage the network effects and the network effects in terms of connectivity of knowledge.
00:33:14.128 - 00:34:16.100, Speaker B: What's really interesting for us, and I'm going to expand a little bit here, is this notion of creating an autonomous decentralized knowledge graph. And that's where we're heading actually with the development of origin trail. And just to give a kind of a slight hint of this idea, I'm not just talking about autonomous agents. Autonomous agents are an amazing discovery and tool that we basically think they're going to be one of the most, let's say the most users of such systems are going to be agents in the very near future. But actually another form of autonomously growing knowledge is just to connect different knowledge from different places. And I can give a bunch of different examples, but essentially it's kind of a one plus one equals three type of principle. And the simplest possible example to illustrate this is some form of, let's say inheritance.
00:34:16.100 - 00:35:27.372, Speaker B: So for example, you can observe it in people. If you have, I don't know, my father, I'm his son, and then he's the son of my grandfather. If you have these two records in two different knowledge assets, these are just two records of who is whose father, right? But if you connect them together, then you can make this connection that this person is actually the grandfather of this grandson, right? It doesn't sound like a huge deal, but essentially once these two things got connected, you could actually infer this knowledge, this additional knowledge, that there's a relationship between two things that were formerly disconnected. So this is just kind of a very simple, logical, basically ontological reasoning type of approach. There's many other different types of reasoning. And the point here is to get as many knowledge assets as we can into the decentralized knowledge graph to generate new knowledge autonomously. Now what's really, really cool here is by knowledge mining, if you're knowledge mining earlier, that means you're creating knowledge earlier, then there's a very high likelihood that other knowledge is going to point to your knowledge.
00:35:27.372 - 00:36:40.170, Speaker B: If you create, let's say a nosis ecosystem knowledge base and your knowledge bank is really best and mine is not as good, so people are going to be picking that and referring to that and linking to it, giving it additional signal, which essentially makes you eligible for more rewards as more knowledge gets mined. So the incentives are also not just about let's create a bunch of stuff, but it's more about creating, connecting these different things so we can leverage these connections to grow the knowledge and ultimately not replicate the same thing across different chains and get into situations such as, I don't know, fragmentation of liquidity like we have in web three, but rather have some sort of unified liquidity of knowledge, if you may, in a single place that connects to different blockchains so we can all use it. So we're super excited for that. And that's why we're really looking forward to the nosis integration coming very soon, within the next weeks. That was a long answer. I know.
00:36:44.460 - 00:36:57.020, Speaker A: We have a few people typing super exciting stuff. I'm eager to learn more about the upcoming integration.
00:36:58.160 - 00:37:08.832, Speaker B: We should totally do some live calls for the two communities together to showcase what can be built and how that would be really good.
00:37:08.966 - 00:37:13.970, Speaker A: Yeah, I would love to do that. Cosmic cloud is.
00:37:17.140 - 00:37:20.870, Speaker B: Cosmic. Hard question again.
00:37:22.760 - 00:38:01.970, Speaker A: I have a quick question. In terms of, I mean, stating a fact is one thing or a supposed fact is one thing, and then substantiating that that thing is actually a fact is another thing. Right? So on the near times, sometimes they'll do fact checks and say, hey, what this said is actually not true. This is misinformation. We've gone through the steps of fact checking. So how does origin trail deal with the problem of misinformation and someone stating that something is a fact? When actually it's not a fact.
00:38:03.220 - 00:38:53.660, Speaker B: That's a really good question. On the protocol level, origin trail has actually been developed according to several principles of development that we established long ago, one of them the critical one being neutrality. So that means at the implementation, protocol, implementation and design level, it has to be neutral also towards making such decisions. So myself, for example, even though I'm one of the developers of the project, should not have an influence on this, I'm not the one to say what is information, what is misinformation. Right? So from that perspective, the technology works like this. Anybody can create any knowledge asset, and essentially in the knowledge asset, what is contained is the assertions, these graphs. So anybody can make a statement.
00:38:53.660 - 00:39:22.580, Speaker B: I can say, I don't know. Right now it's sunny in Serbia. Well, it absolutely is not. It's dark, so I can do it. And then the question is that the knowledge asset application that's querying the knowledge graph actually has the ability to make this decision to decide what to do with the knowledge feed that's coming in. Several tools for this are available and some primitives that are key. For example, the key primitive is the ability to identify who published certain knowledge assets.
00:39:22.580 - 00:39:58.604, Speaker B: And that's why this on chain origin and basically update trail is important to verify that. Actually the way I published it, the arrows can be sure, okay, it's exactly in the same format. That's why these Merkel state proofs are part of the knowledge assets. So you can actually prove that a certain knowledge is included in a knowledge asset. You can do that on chain or off chain. So we get these basic primitives like, you know, who said something and you know that actually they said it in that particular form, which might sound trivial, but it's actually critically important. That's the fundamental.
00:39:58.604 - 00:41:03.310, Speaker B: And then on top, you can basically then decide within the application based on various factors, such as the connectivity of that knowledge, such as the Google reference I made, the Google Knowledge graph or Google page rank algorithms used, but also reputation systems. And we envision actually a bunch of those coming up. And I've been seeing some very interesting efforts in the web three happening lately, so would be really excited to see how we could apply those. Also together with dows for example. Because the idea here is that knowledge assets can be created by people who you know, and then you can basically root your trust within the reputation that they have with you. And of course the story doesn't end there. You can add more and more, but basically on the protocol level, the protocol is never going to tell you like this is true or this is not true, it's just going to enable you to exchange all of this information and then make sense out of it using the tools and the primitives that I mentioned.
00:41:03.310 - 00:42:02.800, Speaker B: And then ultimately you're able to fight misinformation. Because let's say it's not Twitter that is shadow banning people that you're interested in, or it's not some form of centralized entity that controls this knowledge feed towards you. Actually, you control the knowledge feed and you're able to create various different algorithms on top. So origin twelve itself, because it's a protocol, it's not the end solution. What I've shown is just one example, and actually that example is one knowledge application that accesses the knowledge graph specific domain on the knowledge graph, actually, that we decided is the one that should be accessible for this application. I see another question from cosme, not really an OT question. I'm curious what kind of throughput we could expect on Nosis mainet considering origin twelve transactions will not be simple transfers, but rather token mints.
00:42:02.800 - 00:43:04.220, Speaker B: That's a good question. We've done some testing on the Nosis Chiado network. Looks very promising, but all I can say is there is nothing like a real test, and the real test is going to be Nosis made it. I'm not just talking about technical aspects, I'm also thinking in terms of the usage, like how much usage there is on a specific chain, but also how much demand comes from it. And we're especially interested in seeing these integrations with AI agents because that's where we can see a lot of activity and potentially actually getting the Nosis team in a little bit of trouble. Like good trouble. Because what's happening on the current blockchain that origin trail V six is deployed on is that it's getting pretty high on the benchmarks for activity.
00:43:04.220 - 00:43:38.000, Speaker B: It's currently, if I'm not mistaken, the highest used blockchain in the polka dot ecosystem. In terms of transactions, there's a very large number of transactions. So as adoption starts growing on osis, we can expect that to happen as well. So I'm curious to see how that will work. But yeah, thanks for the question. That's not a question by BRX, but it's our community admin. Hello BRX.
00:43:40.340 - 00:43:58.250, Speaker A: Nice. Thanks for those I linked just while we're on the topic, I linked to the chat DKG GitHub and if you have any other resources that you'd like to link to, that would be great. You can share them in the chat there.
00:44:00.620 - 00:44:00.984, Speaker B: Yeah.
00:44:01.022 - 00:44:54.170, Speaker A: If we don't have any other questions, I have one final question, which is a very high level kind of newbie question. I'm not a highly technical person, but what's your elevator pitch on why decentralized AI matters? I mean, we're at a point right now where you mentioned we're at an inflection point. We have obviously OpenAI. You see a lot of headlines about Sam Altman and all this stuff that was going on with OpenAI, and very likely we could see a future where AI is owned by a few tech giants. So I kind of answered the question in a way, but yeah. Why does decentralized AI matter to you?
00:44:55.980 - 00:45:46.488, Speaker B: Yeah, I think you pretty much did answer it. I think the world is changing at a rapid pace. And with this new knowledge revolution, we're basically going to see a very different type of an economy. And in that economy, likely where we are going to be less relevant and machines even more, such as AI agents. So to stay relevant and to be part of that and to basically experience the benefits of all of this growth and new capability, we should be owners of the systems as well. And when I say systems, I don't just mean a bunch of servers or I really mean part the state as well. So the knowledge and the models should be something that we can also own.
00:45:46.488 - 00:46:47.832, Speaker B: And that's been from the beginning of the journey for origin trail, a big, big reason to go into this direction of a decentralized knowledge graph. Yeah, I'm actually looking forward to the future. I'm not a pessimist, I'm an optimist. I think with all of the great tools that are coming up, the revolution is going to take us to some really amazing places, and it's important to follow and to keep building with it and to experiment. But if you don't, then you get potential for very, very negative effects, not just being left out, but actually being in trouble of being owned by the system, rather you owning a piece of the system. So yeah, I encourage everybody to get on the train and start building, or learning at least about AI, but definitely start building. And we're happy to help here and happy to direct you folks to start creating your own knowledge assets.
00:46:47.832 - 00:46:52.850, Speaker B: That's going to be a very exciting opportunity very soon.
00:46:55.300 - 00:48:03.030, Speaker A: Yeah, I obviously agree. I'm sure many people on this call agree. You talked about important concepts like credible neutrality, something that matters deeply to gnosis, certainly to the network being credibly neutral. I think about just the fact that some of these concepts are difficult to understand they don't make intuitive sense to people. Talking about credible neutrality is sometimes difficult, or even more broadly like decentralization, to get that to resonate with people on an everyday basis. So, yeah, how do we beat the market? Or how do we come out ahead of OpenAI and convince people that we should be the owners of these networks, or the owners of knowledge, graphs and AI generally? I'm not sure how we get there, but it doesn't mean that we shouldn't try and maybe these things will become more intuitive to people over time.
00:48:06.040 - 00:48:12.250, Speaker B: I agree. Sure. Sorry, coming in.
00:48:13.260 - 00:48:17.800, Speaker A: Yeah, it wasn't necessarily a question, just thinking out loud.
00:48:18.400 - 00:49:38.336, Speaker B: Yeah, I can say from the angle of enterprise usage, when you talk to people about owning your data and how you can benefit from the knowledge from the data, it's still a bit early in the sense of the kind of a general public or kind of a normal person. But if you look at from businesses perspective, they know this for quite a long time. And actually there's a lot of requests we're getting for building such question answering systems, like I've shown you, from companies that don't want to use OpenAI because actually they're not allowed to. They're not allowed to send sensitive data to some API, and they don't know what the hell is going on after that hits the API. They're not allowed because of the policies or various different reasons. So we've seen a lot of companies come to us, especially the ones who we work with already, who have basically integrated EKG, come to us and ask, can you build something like that, like chat, GPT, but on our knowledge base. And that was basically the click for us, essentially pushed us in that direction.
00:49:38.336 - 00:50:12.368, Speaker B: Our intention was not to make this sort of chatbot the main app, but rather people started asking for it. So the market, if you will, is already understanding the value of knowledge. And I think people are as well, regular. I hate to say consumer, because I hate this word consumer. It sounds like. Or user. User sounds like drug user, right? Nothing against good drug users, but we're people, right? So we should not just use, we should own this technology.
00:50:12.368 - 00:51:06.844, Speaker B: And what I'm trying to say is, anytime you've seen this situation where, I don't know, some social media network gives you a commercial for something that you didn't mention on that network, maybe you didn't even mention it in chat, maybe you said it via the phone. I know it might sound like a conspiracy, but these companies share and sell data all the time and they use it to basically tune their sales and try to squeeze out as much sales as they can from the interactions they have with the users. And I'm not going to dove deep into how problematic or not this is, but it's proof. It's proof that it's happening. The knowledge is valuable, and it's just a matter of time. And we believe the time is now that we should give these tools to people. These have been very complex tools up until recently.
00:51:06.844 - 00:51:58.992, Speaker B: And now with the advent of these public chatbots, AI based LLM chatbots, people finally understand, aha, this is what can happen. If I feed my data into a system, it can be an assistant for me, it can do something for me, help me. But basically, it's starting to rise up. And we believe we are at this inflection point where very soon, everybody, just as everybody has kind of like some social media profile or some accounts on telegram or discord or wherever, we're also going to all have very soon our own knowledge banks. That's going to be something that is kind of the route for us running, also our own AI. I'm really looking forward to that future. So it's coming.
00:51:58.992 - 00:52:35.256, Speaker B: It's just progressing through the stages that it goes through. And the big companies got it first. And now essentially what we build with origin trail. We took a lot of this technology and put it in the open source world. So all of this knowledge graph tech that we're building within Rim and the wheel, we basically took the standards that are there, took the libraries that are there, added what was needed to create a protocol of this whole system, and basically the same tech that Google uses now. You can use the blockchain tech. Of course, we're building everything, not just in a multi chain way, but also based on standards.
00:52:35.256 - 00:53:04.148, Speaker B: So, long story short, things are ripening up, and we're finally getting all of the elements. We have the markets, we have blockchains, which are ripe enough to go in this direction. We're no longer in 2017, where we had Ethereum and some chains growing slowly. There's a lot of technology and a lot of progress has been made. AI boom. I mean, I don't have to tell you about this. I'm sure you guys are following that.
00:53:04.148 - 00:53:25.036, Speaker B: So a lot, a lot of things are converging in a really good way, and I think it's basically a matter of time that this boom becomes a boom also in our pockets, as it is in the pockets of the big companies. So, yeah, I guess longer thought rather than an answer.
00:53:25.218 - 00:53:52.390, Speaker A: Yeah, no, thank you. I mean, super interesting times. And the convergence between AI and blockchain is super exciting. I think it's a real product market fit makes a lot of sense to me. And thank you so much for the presentation today and all of your insights. So are there any events or anything else that you'd like to share with us before we end the call?
00:53:54.440 - 00:54:38.992, Speaker B: Yes. So in the coming days, like I said, look out for the release of the latest knowledge mining RFC for origin. Twelve heads up for the Nosis integration. There's also going to be a bunch of other interesting activities that are happening. So join us, follow us on wherever you feel like your network is, Twitter, telegram or something, or get in touch with. Yeah, that's, I guess, the most closest ones in the book. We have some very exciting events for next year as well that are happening, so particularly the GS one global forum.
00:54:38.992 - 00:55:06.590, Speaker B: So we're participating there as well on the main stage. And yeah, that I guess also is potentially something interesting for people. But yeah, I guess that's good enough for the announcements. Thanks again for the invite and it was a pleasure and hopefully we'll get to chat again soon on such a forum like this. Thanks everybody for coming and for jumping in the questions.
00:55:07.520 - 00:55:43.620, Speaker A: Yeah, absolutely. Thank you so much, Brennamir. And I'll also just share the gnosis Chain newsletter where you can keep track of events just like this one. Origin trail is in our newsletter somewhat frequently and we will have this call going forward every month. So the next one is, let's see here, January 3, I believe. And that will be with Brian AI. It's a new project that came out of a hackathon recently.
00:55:43.620 - 00:56:04.700, Speaker A: Yeah. Thank you so much, Brennan Mir, really looking forward to do the gnosis chain integration with origin trail and all the exciting announcements that you have coming up. I'm sure we'll talk to you soon and we'll do another demo just like this in the near future. So thanks so much. Take care, everyone. Have a great week and we'll see you on chain.
00:56:05.760 - 00:56:07.130, Speaker B: See you on chain. Cheers, everybody.

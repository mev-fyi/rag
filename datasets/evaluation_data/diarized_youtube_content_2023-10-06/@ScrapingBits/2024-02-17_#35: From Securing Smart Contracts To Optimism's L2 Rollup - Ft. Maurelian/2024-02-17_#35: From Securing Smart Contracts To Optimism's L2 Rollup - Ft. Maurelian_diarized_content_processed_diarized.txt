00:00:00.250 - 00:00:19.550, Speaker A: Anytime you're touching your bridge code, you want to be very careful. Doing so caused us to miss other security properties that we did need to hold. This resulted in us introducing some edge cases, but enough edge cases that would allow somebody to basically lock up a withdrawal.
00:00:20.050 - 00:00:53.210, Speaker B: Scraping bits is brought to you by the following sponsors. Fastlane Labs trustless mev mev protocol. Maximize your eth staking value with me v e exclusively on MeV IO and composable execute any intent on any chain. Coming soon to mantis app that is M-A-N-T-I-S-A-P gm gm. Everyone, my name is Tagashi, the host of scraping bits, and today I'm with a special guest, Braillian. How's it going, friend?
00:00:53.280 - 00:00:54.326, Speaker A: Good to be here, Digashi.
00:00:54.358 - 00:01:02.238, Speaker B: It's great to have you. I think it's going to be an interesting conversation. Let's put some context of people that don't know who you are, what you do, who are you, and what you do.
00:01:02.324 - 00:02:13.442, Speaker A: Yeah, so I go online by Morelian and I work at Op Labs, which is basically like primary organization building the optimism network, but there are others and increasingly more so building that. I'll often probably refer to it as optimism anyways. But at Oplabs, I'm a protocol security engineer, so it means I'm focused on ensuring the security of the protocol, especially enabling developers to secure the protocol and write secure code, make sure doing everything to take ownership for the security of that code and the significant amount of funds and assets that we are taking responsibility for, or at least our code is. And prior to that, my background in the Ethereum space started in 2017. Actually, I joined consensus and found myself in the right place at the right time when there was a significant need for auditing, there were people needed to secure their code. It was probably about half a year after the famous Dow hack had happened, like security was top of mind and auditing was the way that we were going about addressing that. And so I founded a practice within consensus called consensus diligence.
00:02:13.442 - 00:02:56.782, Speaker A: That was one of the very first auditing firms in the space and spent about four years there as an auditor, and then more and more building that team out. I say co founding it. I have to shout out, co founder of that team, Gonzalo, saw who is still there. But then after some time, I started to feel like I had been probably spending too much time telling people how to write secure code and what they were doing wrong and chastising them for not having specs, et cetera. And I guess when I saw people continue to not do the things I thought they should do. I started to wonder why. Why was it so hard? And I also wanted to be able to actually build something myself and not just be a spectator and a critic and be in the arena.
00:02:56.782 - 00:03:22.534, Speaker A: So I wanted to do something. I wanted to continue in the space. I wanted to go build the contracts myself, enable something important. And so I already knew Carl at optimism. He's now the CEO of op Labs and one of the co founders of the Optimism network. And so I reached out to him and joined to help with development and security here and have been doing that now since it's been at least two years now and before our main network launched.
00:03:22.582 - 00:03:30.330, Speaker B: Yeah. Cool. That's quite exhaustive. So were you doing cybersecurity in web two before you were in web3, or just doing something completely different prior?
00:03:30.410 - 00:04:04.982, Speaker A: I won't really go into the details. Education is in actually mechanical engineering and with a bit of an extra focus on mathematics. But I don't try to hide how much of a learning curve it was when I first started at consensus. Think if I were trying to make the same transition into this space now, it would be very difficult. But at the time, there was just this massive opportunity to learn along with everybody else in the community. And I took it and managed to. I think this is one reason that I was maybe a bit stronger on the leadership side of things when I started at consensus.
00:04:04.982 - 00:04:17.262, Speaker A: That's why, along with auditing, I focused helping build out a team of extremely talented people there, which for me was like, ideal. I got to look for the kind of people I wanted to work with and learn from.
00:04:17.316 - 00:04:24.338, Speaker B: Sure. Yeah. And then you got into protocol security, which sounds more severe than just DAP security. What's the kind of difference between that?
00:04:24.424 - 00:05:10.830, Speaker A: More severe? Yeah, it's an interesting thing because it is more foundational. I think that protocol level issues we've seen probably have rarely, if ever, been as sensational as just the straight up smart contract attack, like, you forgot a keyword and dead now things. It is super foundational. And I think the challenge there has been perhaps identifying the right mindset and approach. So at a high level, I think that what it's taken me and a lot of our team a while to realize is that writing secure client software or developing secure client software is quite different from secure contracts. They tend to be like a larger footprint. And we found that auditing is.
00:05:10.830 - 00:05:58.410, Speaker A: This is controversial in maybe smart contracts as well, but it does not feel to us that auditing is particularly effective with our fork of the guest. For context our primary components node, software components, our op geth, the op node, and a few other important things. But those are like really top. So they're written in go. And we found that actually just getting it out there and getting it running on testnets and into infrastructure providers hands and getting feedback from them and having people kick the tires on it has probably been more effective, as well as including it in our bounty programs. That seems to be the better way to learn about where the issues are in our software than putting in front of an auditor and asking them to find them all, probably, at least partially because they're just such massive code bases.
00:05:58.490 - 00:06:12.238, Speaker B: Yeah. So you would have had to read and understand basically the node extremely well to even be able to be, I guess, comprehensive, securing them. So I guess what was your approach to learning them, and if you were to do it again, how would you do it to learn faster?
00:06:12.334 - 00:07:10.986, Speaker A: I already was fairly comfortable reading Geth. I would use Geth as my EVM reference quite often. I think that's probably not what I would recommend to somebody just trying to understand the EVM, but it is what I was doing. And so I think just getting in and reading that code and asking questions of your team, making small prs gets you more comfortable there. Although I'll say that personally with optimism in particular, have stuck closer to the contract side of things and have in some ways treated the nodes as black box, as a strong term in an interface where we expect guarantees and certain behaviors and view contracts as something that interacts with those, that enforces the expectations from client software, et cetera. So I think almost a bit of a flawed premise would not pretend to be, say, like an expert in go security software.
00:07:11.118 - 00:07:22.198, Speaker B: You need to learn both. Right. It's like you have to learn this massive code base, understand how it works, and then you also have to be good at go, like comprehensive at go, obviously, which is a completely different domain.
00:07:22.294 - 00:07:34.270, Speaker A: Yeah, that's what's really amazing about Samsung, for example, he's found issues in the contract layer as well as pretty deep issues in the go clients. Probably other clients too.
00:07:34.340 - 00:07:56.626, Speaker B: Yeah. Because there is such massive systems, and I think normal people that do security on smart contracts and have never done these massive code bases would have a massive culture shock. The monster just got way bigger. Nice. And there's a big learning curve. So were you doing go security prior or did you have to get into that as well?
00:07:56.728 - 00:08:07.302, Speaker A: Yeah, at diligence. I only ever was doing smart contracts. So we had, as a team, had done audits clients, but I had not participated in those audits myself.
00:08:07.436 - 00:08:10.674, Speaker B: So how did you get into a level where you're comfortable auditing go?
00:08:10.732 - 00:09:06.150, Speaker A: Yeah, I'm not saying I'm there more. So the focus these days for me is provide the tools. And I don't know if this is too outside the scope of this deeply technical interview, but the culture and the practices and processes that go into writing secure code, whether it's in go or solidity. So it's been a couple of years of this. And so I think my influence on the node software has been more selecting the right auditors, working with them, and building infrastructure, more like soft organizational infrastructure, you might say, around the node software. So one story that I think really illuminates the intersection between the way that client software and smart contracts interact, at least in our system. And some of the particular challenges optimism faces developing client software comes from our experience in January of last year, I believe, maybe early February.
00:09:06.150 - 00:10:02.810, Speaker A: So it was probably three weeks after we opened our immunify bounty program, which has a payout of $2,000,042. And that 42, for a pretty short period of time, bumped us to the top of the immunify bounty board. It's kind of like the price is right kind of trick. So it was like three weeks later that we actually received a report from Zarik. And the impact of the issue was basically that on our l two network, anybody could manufacture eth effectively. And the way that they could do this was by self destructing a contract to itself so that the balance would be sent to itself, because it wouldn't actually properly remove the account from the try. So it did the send properly, so it would update the balance of the target account by increasing its balance.
00:10:02.810 - 00:10:39.682, Speaker A: But then it didn't delete the account at the end of the transaction. Yeah, terrible. And this came about because we were maintaining a fork guest that at the time we called l two guest. And so it was really like a legacy code issue. Don't even get me started about the OVM, the optimistic virtual network that predated this design. But it was basically like maintaining this backwards compatibility with a previous design, which included, of all things, like actually storing eth balances in an ERC 20. And so that's how we manage balances.
00:10:39.682 - 00:11:54.298, Speaker A: And at the time that this issue was reported, you couldn't even call this contract. Like, every function in it would revert, with the exception of, like, you could call the get balance or the balance contract, and probably the symbol to get an account's balance and total supply. But any state changing functions would just revert. But so we used this as a hack to manage account balances, and these were held outside of the state trifle. But then when you actually used the call op code on our l two and say you would send value if you sent value, we hooked in like we modified guests so that it would modify storage directly in that ERC 20 account to modify the balances. And so it was in that we made this change in guess basically we modified the call off code correctly, but we did not modify the self destruct opcode. And so really very clearly, to me at least, illuminates the way that our abstractions were not clean and we were getting these very fuzzy boundaries between the EVM and what actually happens inside the EBM.
00:11:54.298 - 00:12:19.490, Speaker A: That ended up getting us in a lot of trouble. Very fortunately, this was reported to us, because the consequence would have been that had somebody exploited, they could have basically printed ETH for themselves on RL two, attempted to withdraw it all to l one. And even if they couldn't, they could have manipulated uniswap pools to buy other assets and throw all the prices off and cause massive chaos on this network.
00:12:19.570 - 00:12:26.874, Speaker B: So how did you just feel basically like fixing that and then stealing these best practices within the devs and getting them on board?
00:12:26.992 - 00:13:11.770, Speaker A: The fix was quite simple. We managed to roll it out fairly quickly. For us, there's the additional challenge of having to work with node operators to get this out. And so if I remember correctly, we actually managed to convince people to run binaries without being able to see the source code with the changes we'd made, because obviously we did not want to leak this change. That's quite difficult to manage. People may or may not be aware, but Geth generally has a. It doesn't work in our case for various reasons, but like what Geth does, where a bug like this, they would typically sneak in and their policy is publicly that they'll only disclose this down the road.
00:13:11.770 - 00:13:35.958, Speaker A: They'll be like, oh, hey, by the way, we fixed this thing. Glad you didn't know about it. Learnings for us from that. I think our system has been completely rearchitected from there. One of the issues with that version of L two Geth is it was just, we had forked it and modified it heavily in many different places, and we couldn't easily bring in changes from upstream. We couldn't just rebase it on the main guest.
00:13:35.994 - 00:13:36.626, Speaker B: So many changes.
00:13:36.728 - 00:14:06.810, Speaker A: So many changes. So that was one of the major reasons that drove us to a completely new architecture that allowed us to pursue basically like a minimal diff from. And that is one of our driving goals, is to minimize the number of changes we need to make in Geth, which has the added benefit of enabling people to also create op versions of other clients, like rest, Aragon, et cetera. So that's great. I'd say. Yes. We have a really big focus.
00:14:06.810 - 00:15:29.590, Speaker A: Our culture really focuses on modularity, like modular designs between components, so that this allows you to get really clear about. I almost like to think of it as like the contract between. So not at all in the sense of a smart contract, but there's an idea of design by contract. And so that means that you are very clear about the contracts that various components have with each other, what guarantees they provide, and then the components that interact with those other components be very clear about what they need to be able to handle from them. And increasingly with that modularity, we're starting to really emphasize being more and more iterative, and so, like, very robust use of CI, obviously, test coverage, et cetera, but allowing ourselves to change more quickly and get things into production to us includes test nets. So we want to see that we're actually able to get stuff running, because, again, that's how we find that is the best way to secure a client. And it also, I think, increasingly is often a very good way to secure smart contracts because of this sort of emergent auditor culture where people are just reading code all the time.
00:15:29.590 - 00:15:50.250, Speaker A: We have bounties, people have different skill sets. So I think that counting too much on a small group of, say, one or two auditors to secure your code versus enabling and incentivizing a large community, there's say, like an increasing trade off and set of options that a team can choose from there.
00:15:50.400 - 00:15:59.726, Speaker B: And how do you go about doing epic unit tests? You have so many kind of modules to test. How do you cover everything in the most efficient way?
00:15:59.828 - 00:16:31.610, Speaker A: I'd say we use foundry. We're big fans of it. I think I was initially skeptical. People just seem too hype. And speed isn't everything, but it actually, speed is a lot. When you are modifying your tests and modifying your code in tandem and when you want to have a lot of tests, you don't want adding a test to be like a reduction in quality of life, just with unit tests. I think a basic thing is strong organization of your code.
00:16:31.610 - 00:17:08.626, Speaker A: So one of the things I like and miss about writing tests with hard hat and mocha underneath is nested describe blocks. They just like being able to be like, this is my block of tests for the transfer function. I'm going to just test the bejesus out of the transfer function here. And then you could even have a happy path and sad path, like a describe block within. That's like happy transfer tests and sad transfer tests. And then of course the sad tests are the important ones. So have to be thinking about your failure modes and making sure you're hitting.
00:17:08.658 - 00:17:10.598, Speaker B: Them and what's the best way to hit them.
00:17:10.684 - 00:18:02.120, Speaker A: I think that people tend to often think about the simple, say sad path. Is this owner only owner function going to be called by someone else? And that's an important test to write just to make sure you don't delete the keyword by accident. But I really think that what people often miss is the importance of being really crystal clear about what the security properties of your system are. So I think I use the term security properties and invariance interchangeably. And sometimes I think security properties is a better term because it's more loosely defined and allows more things. But invariance sounds cooler and so I find like it sticks more easily. And so we've just really heavily normed on the idea of invariance and for the most part, just like in a qualitative sense.
00:18:02.120 - 00:19:10.554, Speaker A: So an example of an invariant that we weren't keeping in mind with one of our latest iterations on our contracts, we did this bedrock upgrade. Anytime you're touching your bridge code, which we were modifying heavily, you want to be very careful, obviously. And so I couldn't possibly say we were over indexing on avoiding theft, but I would say that doing so caused us to miss other security properties that we did need to hold. So this resulted in us introducing some edge cases, but enough edge cases that would allow somebody to basically lock up a withdrawal. So if you're moving in the base case eth from l two to l one through our bridge, there's a seven day wait for that to finalize. But there were a variety of similar but different little paths that would allow someone, just out of the sheer desire to see somebody suffer, to lock their funds in our system in a way that would have forced us to upgrade in order to release them. And so this is obviously a huge headache for us and something we want to avoid, not the end of the world.
00:19:10.554 - 00:19:44.898, Speaker A: The funds are still safu in a way, but really unidenl painful for people, ourselves and users. And we had basically like the invariants that we were not being explicit with ourselves about were one, that idea that there should not be any unexpected ways that a withdrawal can fail. And then more precisely. If a withdrawal were to fail in some way, it should always be replayable. So it resembles that really old. I think people often know it as the king of the hill attack. Are you familiar?
00:19:44.994 - 00:19:45.830, Speaker B: I'm not.
00:19:45.980 - 00:20:23.918, Speaker A: Okay. I think this contract was called king of the Hill. And it was basically like, people just put money in, and whoever put the most money in got all the money. So you put in a dollar, I put in $2, and if nobody else adds to it, I can have $3. And it was just like, I think, an early instance of if the deposit comes from a contract that will revert on fallback, so I put my money in, and then the contract tries to send your funds back to you, it will revert. And so then, basically, nobody can add more money than you had originally. And I think that this contract was actually an auction.
00:20:23.918 - 00:20:59.998, Speaker A: So it's like, my highest bid. If I bid a dollar, and then you try to bid two, that will fail, because in your attempt to make that bid, it will try to refund my contract. And so we have the push versus pull heuristic for refunds. Now, that's pretty common. So that's an example of failure mode that wasn't being considered. And I think that usually what I'm trying to say with unit test coverage is that often, if you're not considering a failure mode, it's because you haven't thought about the invariance that your contract must hold.
00:21:00.084 - 00:21:17.202, Speaker B: Yeah. And I guess, how do you think about that? Because there's obviously sophisticated hacks or exploits where they're using external contracts and multiple function sequences in different ways, ordering sequences. How do you as a developer, even think that? Kind of.
00:21:17.256 - 00:21:47.502, Speaker A: Yes. Once this came to our attention, and this happened through the last, what we thought was, like, the final audit kind of thing. That's painful. We had to do some refactoring. So added context here is actually that we had a Sherlock audit. We thought that this was the final audit, and four or five of these very similar briefing funds, lockup, things came back at us, and we made what we thought we were like, okay, let's make the smallest possible fix we can. We really want to avoid changing too much code.
00:21:47.502 - 00:23:24.154, Speaker A: And so then we did that without thinking sufficiently deeply about the issue, and we went back for another Sherlock audit, and a couple more of these came up, and we're like, okay, shit. So, honestly, four developers spent almost a week getting clear about what it was that we had to do. So we wrote a document that was just like, what are the invariants in this contract? And what are the invariants in this contract? And these similar issues ended up having actually quite different root causes. And I think one way that we started to think about is we were like, okay, so if we managed to get much more crisp from, like, if the property is something like, nobody can lock up your funds, then we were able to distill it to, in this case, where it was like, if your call to this contract, the optimism portal, reverts, your call to the optimism portal should either revert or write to this mapping so that you can retry the withdrawal. And so the failures we were having were these reverts that happened in unexpected situations. So then we could develop the contract in a way, by being like, okay, so where are all the reverts? And we could print the IR and read through it and just look for the reverts and think, are we okay with this revert? Early in the function call, it's okay to revert because it just totally reverts without updating any state, and we're fine. But if it updates this first mapping, but then doesn't update this other mapping, we're in big trouble.
00:23:24.154 - 00:24:10.918, Speaker A: So it's hard sometimes to find ways to encode those, put those into code. I don't think that perfectly did get them into code, but we have, I think, really much more deeply internalized the idea of an invariant. And we have used forge invariants, that testing approach, I think it's really an excellent testing approach. It's tricky because the term like, I want to think of an invariant as a more general thing, and a forge invariant is not always going to get you at that thing. But I do think we have used forge invariants a lot to try to express our invariance encoding, and that's, for the most part, the closest we've gotten to actually putting our invariance into a programmatic expression.
00:24:11.014 - 00:24:50.342, Speaker B: Yeah. And I think the only problem with invariant testing now is you have to put it at the end of a function call, but you can't put it within a little window or block within the function. Then you can't really uphold or create these properties for certain areas within a call. It's always at the end. So I think that's where it goes wrong, just more like specification in that sense, I think, greatly improves security, because then you can read through it all and be like, okay, this isn't meant to be over this number. If it is, then there's obviously a problem. Instead of getting to the end of the code and not really being able to assert anything mid call, because imagine the function is just massive, right?
00:24:50.396 - 00:24:50.806, Speaker A: Yeah.
00:24:50.908 - 00:24:55.562, Speaker B: The only way to really mitigate this right now is to have multiple functions that form a function.
00:24:55.696 - 00:25:22.254, Speaker A: Yeah, that's actually a really good way of putting it, I think. So another thing we think about is writing testable code. You nailed it there, right. Maybe you need to refactor your code so that you can do that. And perhaps the practice of defining your invariance leads you to recognize that there is like a section of this massive function that say like a temporary invariant. And you want to be able to test that more closely.
00:25:22.302 - 00:25:51.670, Speaker B: Yeah, exactly. Because these small little blocks could be vital and are often where the code is going wrong. For example, you could have a massive code block, which is your main function, but it does an external call within it, and then does something with the end result. It maybe calls another external contract. You want to be able to test each external call individually and see what happens after, because maybe they merge together and do something. And then you have, it's always like a generalization at the end instead of very specific. So I think having both could be highly beneficial.
00:25:51.830 - 00:26:06.258, Speaker A: It would be pretty amazing if there was a mechanism by which you could annotate that. We actually had this, there was a piece of our code that we did not, I forget why, but didn't want to break it up. So that was more testable, as I say.
00:26:06.344 - 00:26:12.082, Speaker B: Yeah, fragmenting, you break it up as well, which is like an optimization unoptimization, I guess.
00:26:12.216 - 00:26:54.354, Speaker A: Yeah, totally. Just there's more places to maintain. I like the idea of being able to make inline comments and say in some kind of specification language, and say this property needs to hold from here to here. I suppose that inline assertions do give you that. Like the assert function does give you that. Although let me put this at you then. I feel I rarely see asserts in code, and one thing I do try to get us to do is if I see a comment on a require statement, for example, and somebody's pretty sure you shouldn't be able to actually call this, but we're putting it here just in case.
00:26:54.354 - 00:27:14.546, Speaker A: I'll say, let's make that an assert that semantically represents an unreachable condition, but we haven't really, to be honest, gone about say like using the SMT checker in any continuous way, or any of the other tools that really would actually go after that assert and be like, can I get at that somehow?
00:27:14.658 - 00:27:45.234, Speaker B: Yeah, I personally don't use asserts or anything in my code, but I think it's like an optimization kind of thing, but I think maybe that's a better practice. I'm not like a rust security expert or anything, but like a smart contract security guy. I think bigger language is out of my scope right now. But yeah, we're interesting to know about that, especially like if something could possibly happen, then it would be wise to have it, just to make sure it doesn't, otherwise just leaving up to chance. And it is a possibility. Right?
00:27:45.272 - 00:28:31.294, Speaker A: But not only that, but for example, I think so. There's a formal verification researcher on the solidity team and talking to him at Devcon, and he was mentioning how he had basically used a variety of tools and approaches for formally verifying the deposit contract. And I believe it basically involved using asserts. So one property is like this function always completes, or there are no unexpected failures in this function. It's like a censorship resistance property, very similar to some of the issues we've seen. And he was basically like, so at the end of this function, right before the closing curly brace, I just write assert false and then you just go after that. You just use all the tools that go after.
00:28:31.294 - 00:28:54.998, Speaker A: Use that particular approach to see if you can trigger that. And I do know Akitna, for example, it has different modes of targeting. The one that we used previously was a lot more like forge foundries and variant testing, but they also have a mode where it will simply just look for asserts in your own code.
00:28:55.084 - 00:29:12.446, Speaker B: Yeah, I think having the asserts and then pairing that up with fuzzing is like the best thing to do. Trailer bits did a paper on this and it did. In smart contracts at least you hit a high frequency of vulnerabilities, like maybe 60 70% fuzzing and invariant testing combination. So it's definitely worth doing.
00:29:12.628 - 00:29:18.682, Speaker A: Yeah, but again, you need to know what assert exactly to put in the core.
00:29:18.746 - 00:29:47.846, Speaker B: I wonder if there's a way to automate these invariants at all as well. What do you mean? Like have your program, I guess, generate the asserts or the invariance that it does hold, because that can happen because the code is basically what's happening and you can have a program that specifies okay, this is always happening or within this range. So it gives you asserts of actually what's happening instead of you making the asserts or invariance. And you kind of compare that with your mental model.
00:29:47.948 - 00:30:44.554, Speaker A: I think that in some ways I've heard a really strong type system as basically providing you that in some ways like you were writing a second spec that provides that for you. And reachlang, that was my understanding. There is that the type system there provided the spec that would give you those. I don't know that was asserts in its silly generation, but gave you that kind of property checking. Another thing that we worked on at diligence and I'm sad it hasn't gained more traction and I'm also guilty of not having adopted it. But is this language called scribble and toolset that in your natspec comments you can using a specification language? Well, the scribble spec lang, you describe your invariance. So you could say something like this notes must if this function is called this notes has to increment by one.
00:30:44.554 - 00:31:42.158, Speaker A: And that's pretty obvious. And so you just write that in a comment and it will generate instrumented code that would have that function wrap it in assert statement saying enforcing that. And then that's the main thing it does. And then you take whatever tool you want. Probably a fuzzer is the base case and try to trigger that assert. I think a little bit is just maybe I always thought, and this gets way back to the beginning of this conversation where I was like, I felt like I was trying to tell people had all these ideas about writing secure, smart contracts, but didn't really mostly just read other people's code and had opinions about how they should do it different. But yeah, I thought that people would love putting this in the Naspec comments, but natspec comments tend to get unwieldy to begin with a lot of the time.
00:31:42.158 - 00:31:51.834, Speaker A: And I think there's something to be said for keeping that minimal and not gumming up your code with a couple hundred more lines of bet comments.
00:31:51.962 - 00:32:19.002, Speaker B: Yeah. And it becomes even more significant as adoption grows. Like today, Google Play just changed their policy to allow tokenized digital assets on their apps and games. So people are going to be creating a lot more. Imagine like a hack on an NFT that's in a Google Play store. It's going to become like a whole new game to what we originally had. It's going to be interesting.
00:32:19.002 - 00:32:26.854, Speaker B: And I guess what are the kind of problems that you saw while observing auditors and protocol these horrible practices?
00:32:26.982 - 00:32:30.078, Speaker A: I think that what just problems you.
00:32:30.084 - 00:32:31.840, Speaker B: See in auditing in general right now.
00:32:32.610 - 00:33:21.294, Speaker A: For us, scheduling has been just a tremendous headache. I think that my thinking has changed on that to where I believe that there have been situations where we just, by scheduling an audit, say six months out, and then having to hit that date, have cut corners and written code less securely as a result. And this is all with the caveat that we eventually went and found those bugs, knock on wood. I'm pretty sure. But our estimates were off for how long it was going to take us to get the bedrock out, upgrade out the door. It was a much bigger project than we thought, and we underwent four or five audits in that process. And that was super expensive to us.
00:33:21.294 - 00:33:48.050, Speaker A: Like financially. Yeah. But I think the impact on our process was somewhat detrimental. Not entirely. There was definitely value there, but I don't like the stress and rework and overhead it caused us was really significant. So just not having, even just hitting arbitrary deadlines, because that's when an auditor is available, that sucks. And that's not doing us any favors.
00:33:48.130 - 00:33:59.974, Speaker B: Is there anything on the technical side as well, projects wise, just like auditing in general? Is it specifically hard for you or that can be improved by, I guess, tools?
00:34:00.102 - 00:34:30.590, Speaker A: Well, I'll talk about maybe one of my favorite audit experiences where we decided that we'd gone through a few of these and decided. I basically realized I couldn't really put the rest of the team through the stress of another audit. And so I'd learned enough at this point that we had an audit scheduled. It was with trail of bits, who I've always really enjoyed working with. We were going to cancel it. They're pretty cool about canceling things. They can always find someone else to fill your slot.
00:34:30.590 - 00:35:28.182, Speaker A: We were thinking maybe we should cancel this. But we decided what we do is instead of putting any kind of deadline, we would use them to define, to work with us, help to define invariants in the system, enumerate them. And they actually wrote a lot of echidna invariance tests for us that we then got and incorporated into our code base. And so that, I think was a great experience. So even just like using someone outside of your, basically someone who got some distance from the code to think more critically about what the code has to do has been effective for us. I think that's what often goes wrong, is you're bought in to your system and you can't look at it objectively. Tooling wise infrastructure for long running fuzzing campaigns right now, it's amazing that forge is getting.
00:35:28.182 - 00:35:55.246, Speaker A: It's a step change in the adoption of fuzzing and helping people understand the idea of fuzzing. But I don't think people are thinking a lot about how effective that is. And I think the default is a fairly small number of runs, 256 locally, and you can up that in CI, but I'd like to be able to get a cluster set up and really go at it for quite a while.
00:35:55.348 - 00:35:58.842, Speaker B: Just keep on trying multiple things and feedback loops.
00:35:58.986 - 00:36:45.582, Speaker A: Yeah. And it's like a DevOps challenge, I think, more than anything that we could take on and hopefully will not too far off. And then I also think that defining what I call custom static analysis properties is something that we should be doing a lot more of. This is reflecting just on us and where we're at. But how is it different from an invariant test or a fuzz test? It'd be something more like saying something high level, like, dysfunction always emits this event, or it reverts with this reason. And it's maybe not the same as doing like. I think even just checking that with a linter style property gets you a long way.
00:36:45.582 - 00:37:24.826, Speaker A: Like being like, is there an emit statement here, et cetera, that gets you a long way? And there's not really a great interface for doing that that we found at least the basic linters in the space are no longer maintained, as far as I can tell, and are slow and broken. So that's something that there's a great opportunity for someone just to stand up and maintain a good linter, a tool that we've used a little bit, but I'd like to see us using more is Semgrep, which I think makes that kind of rule pretty easy to write. And so that, or something that's maybe more ethereum native would be cool to see.
00:37:24.928 - 00:37:31.946, Speaker B: Yeah, I guess maintaining is the one thing, instead of just like creating it, then leaving it in the dust, I.
00:37:31.968 - 00:37:36.014, Speaker A: Think tool in general, not to blame anyone, honestly. I get it.
00:37:36.052 - 00:37:36.446, Speaker B: Yeah.
00:37:36.548 - 00:38:09.538, Speaker A: But although, okay, there's a plug optimism at our core is this massive emphasis on retroactive public goods funding. And I think that we've really brought that idea into the mainstream, at least like our ethereum mainstream. And so I think that for such tools, especially if we're using them, there's a great opportunity for maintainers to propose funding for that through our governance processes.
00:38:09.634 - 00:38:48.466, Speaker B: Yeah, there's only a small amount of people that are really working on tools of this nature, and it seems that a lot of the tools aren't really iterated on or using previous ones to evolve. It's more of just like creating it from scratch, maybe a different technique, not really expanding, at least from my point of view, like all really surface level, and not digging deep into what's critical, what black hats are trying to do, extracting all the money. It seems like it's very false positives and kind of surface level, not thinking of complex kind of things, which is fair, because it is quite a difficult task, but it'd be great to see an evolution of tools.
00:38:48.578 - 00:39:49.430, Speaker A: Yeah, definitely. I think to that point, it's often not obvious when you see the contract, there's such a disconnect between, I think, seeing the source code and seeing the contract on Mainnet. In a block explorer, if you have a system with a number of contracts, you can see where the money is. There's four or five contracts in it, but which one has the money? And you can just trace that back from how do I get there? And I think that that just makes it clear in a way that when you're staring at a GitHub repo, it takes a lot longer. I think that definitely it makes sense to me to be looking at deployments. They don't have to be on main net, but there's a whole class of configuration and deployment errors that you can also make when you're putting something on chain. And so it may not be obvious that when you are reading the basic source code, that the way that you are planning to deploy it is going to wreck you.
00:39:49.430 - 00:40:50.822, Speaker A: So I think that maybe that's one of the strong things about fuzzing and that other tooling could do, is focus on what the deployed system looks like, what the system looks like in the context of looking at forking networks, so that you are considering the system in the context of other systems that it interacts with. It's one thing about optimism, I think, is we're not probably less complex in terms of external interactions relative to a lot of DeFi protocols in our contracts. We bring the complexity in other places, though I certainly can't claim we don't have it. I do think that an innovation that the auditing space is looking for is to have people looking at deployed code. And even what we did with our Sherlock competitions is we said, look at this system, it's here. You have a block explorer on the Gurley network. And I suspect that is something that helped us get a better result than if we had just directed people towards a GitHub repo.
00:40:50.886 - 00:41:36.230, Speaker B: Yeah, I think for these public contests, just giving a GitHub repo with little context and not telling them where the money is, how money is accessed, deposited, withdrawn, I think just giving even that specific identification would speed up a lot of processes, a lot of auditors to get to the path of finding code. That's honorable, because then they have to read it all and get a context for it, find out where's everything stored through the code, which can take ages. The mass of code base, even just identifying that as a developer, that's also how you can build unit tests and invariants to mitigate that and follow your own path of how that gets there. And then I guess the other stuff is basically you just got to think of what influences it and go from there. High level, where is it? And then traverse backwards until you get to the root.
00:41:36.310 - 00:41:37.034, Speaker A: Yeah, absolutely.
00:41:37.152 - 00:41:43.454, Speaker B: I don't want to take any more of your time, but yeah, it's been great having you on. Great to chat to you finally.
00:41:43.652 - 00:41:54.190, Speaker A: Yeah, it's been super fun. I don't always get to, outside of quips on Twitter to delve into my thoughts around this and it can be really helpful to clarify some of my thinking too.
00:41:54.260 - 00:42:06.818, Speaker B: Yeah, great to reflect on as well. And even in the future, get to look back and see how you progressed. But yeah, we'll definitely chat soon in the future for an update and see how things have progressed. But until then, thanks so much for coming on.
00:42:06.904 - 00:42:35.738, Speaker A: Yeah, if there's one thing I can plug, I would say we are hiring. We are looking for devs and particularly have a role open right now for a protocol security engineer. So somebody who could apply or possibly just from the ground up build the kind of tooling that we've been talking a little bit about so you can find me. Probably best place is just on Twitter. I'm Morelian with an underscore after it. M-A-U-R-E-L-I-A-N underscore.
00:42:35.834 - 00:42:43.502, Speaker B: And I guess just an additional question to follow up on that. What do you want to see in these applicants?
00:42:43.646 - 00:43:18.594, Speaker A: Like, definitely knowledge of program analysis techniques, very valuable, strong opinions about what good code looks like in solidity, in particular Golang as well. I'd say that experience with node software is valuable. Background in auditing or building tooling and just like a keen sense of motivation and ability to take ownership in making these things happen and mindset that security should be an enabler and not an impediment to shipping software.
00:43:18.722 - 00:43:26.574, Speaker B: Cool. If you're someone that suits these requirements, go ahead and apply. They're hiring. But yeah, thank you so much for coming in and we'll definitely chat soon.
00:43:26.692 - 00:43:28.090, Speaker A: Awesome. Thanks to gotcha.

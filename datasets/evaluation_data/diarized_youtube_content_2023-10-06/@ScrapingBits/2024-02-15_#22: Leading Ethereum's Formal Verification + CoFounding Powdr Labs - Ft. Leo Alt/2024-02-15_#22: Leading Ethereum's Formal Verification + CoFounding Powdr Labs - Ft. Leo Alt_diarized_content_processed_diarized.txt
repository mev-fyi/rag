00:00:00.250 - 00:00:24.480, Speaker A: Every tool will have different strengths and, and weaknesses and it doesn't really make sense to try to only use one and think that you're getting everything out of it. Because inside fbes itself there are different techniques that will maybe find different types of bugs or be able to prove different types of properties. And you should really use as many things as you can. And of course, if you have to install ten different tools, you're not going to do it.
00:00:25.050 - 00:00:31.266, Speaker B: GM everyone, my name is Degachi, the host of scraping bits, and today I'm with Leo old. How's it going, Fran?
00:00:31.378 - 00:00:34.198, Speaker A: Hey, yeah, pretty good. Happy to be.
00:00:34.284 - 00:00:52.102, Speaker B: Yeah, yeah. Great to have you on. Thank you so much for taking time out of your day to come on. I know you're incredibly busy, so very appreciative of this opportunity. Just for the people that don't know who you are, I would love for you to give a short little intro of who are you and what do you do.
00:00:52.176 - 00:01:10.146, Speaker A: Yeah, for sure. Yeah. So hey everyone, my name is Leo. I am currently the formal verification lead at the Ethereum foundation, but also working on the jvms on powder and I've worked on the solidity compiler before. Yeah, I guess that's the things people will relate to.
00:01:10.328 - 00:01:27.974, Speaker B: Yeah. Before joining the Fury foundation as the lead FB guy, I guess. How do you even get to a position like that? Where did you come from and kind of progress your career into where you are now? Working on ZK co founding that, yeah.
00:01:28.012 - 00:02:03.502, Speaker A: So I did my PhD in SMT solving and formal verification. At that point it was not necessarily applied to Ethereum or smart contract. I went to that field because I was interested both in theoretical computer science. So complexity and these things and logic, but also in applying that stuff to systems. So not only staying theory, but also not only staying experimental. So this is a field that I felt like had all the things that I wanted. And during my PhD we were building tooling for softwareification, software and hardwareification, but more focused on software.
00:02:03.502 - 00:02:34.640, Speaker A: And then at the end of my PhD, pretty much, well, even before that, me and friends were always into bitcoin. And then I had a friend who was really into Ethereum and then we got into smart contracts, started just writing smart contracts for fun, and then at the end of my phd started trying to apply the knowledge we had on software verification to smart contracts. And that's when Christian from the solidity creator and back then the solidity team lead invited me to go work with them.
00:02:35.570 - 00:02:45.394, Speaker B: Okay, got you. Yeah. So how did you kind of know Christian at all I didn't. Oh, okay.
00:02:45.512 - 00:03:06.440, Speaker A: Yeah, I just started writing tooling for smart contract and just publishing it on GitHub, talking to people online. I was often asking questions on the solidity back then, gitter channel on GitHub, and I started contributing to the compiler as well, how we got to know each other and then had a conversation and then I joined after.
00:03:07.370 - 00:03:48.798, Speaker B: You know, powerful things, know Fe puzzles, et know if they're super powerful, most people would just close source them, right? So I guess it was early days, and building tooling for such an ecosystem in its infancy definitely would have sparked some interest within that kind of community. So I guess open source is a really great way of getting people gain recognition, right? Yeah, you're providing value in that sense. And then obviously people take notice and try and contact you and then give you opportunities. So I wonder why you chose formal verification over something like fuzzing.
00:03:48.894 - 00:04:27.010, Speaker A: For me it was just natural because that was just what I studied and what I was familiar with. In our academic group at university, we were very focused on formal methods, so we had our own sm two solver and we had more that kind of tooling and rest, I think fuzzing and automatic testing, these kind of things. Sometimes people do all of these inside a role methods group, but I think they are more common in like a software engineering department or research group. And so it just happened that in my group we were also a small team, so we were very focused on this one thing we were doing. And of course I was familiar with fuzzing and I knew people working on fuzzing, but I just ended up doing.
00:04:27.080 - 00:04:31.822, Speaker B: FB instead, just for some context. What specifically is an SMT solver?
00:04:31.886 - 00:05:21.486, Speaker A: So an SMT solver is more generically, it's an automated theorem prover. Theorem provers have existed for several decades now, and it started when mathematicians wanted to prove things automatically. So instead of you have ethereum, instead of trying to prove it by hand, you would apply mechanical steps and try to come up with the proof that ethereum is cracked for all cases, or find a bug in the proof, basically finding a rule that actually doesn't really apply. And of course this started a long time ago. And if you think about systems like cock or Isabel or Lean, these are more classic theorem provers. They're not necessarily completely automated, they require some human assistance. So these are called assisted theory improvers.
00:05:21.486 - 00:06:38.442, Speaker A: And SMT slowers came or maybe like a generation after that, or a generation and a half after that, in which you have a language called SMTlib, which you can use to express different theorems involving different data types or different operations. And then SMT solver will try to prove this, will try to prove the satisfiability of your statement automatically, fully, automatically. And proving satisfiability means you give a formula, a boolean formula that has to be true or false, and it will tell you whether this formula is satisfiable or not. Meaning satisfiable, meaning there is a valuation of all the variables in this formula that make it true and unsatisfiable. Meaning this formula can never be satisfied, can never be true for any possible values that you plug in the variables here. And it turned out that SMT solvers were very good for software verification because they are fully automated in the first place, and because the way that you write theorems that this SMT servers can understand is very similar to software. So the sub languages you would write are not like super complicated calculus and weird things.
00:06:38.442 - 00:07:14.914, Speaker A: It's more just like, it's very similar to programs. You would say a statement using variables, using integer variables or real variables, and make numerical statements about these variables, or arrays, for example. So, SNT solvers, they have logics, which consists of theories, and each theory gives you a certain sub language to play with. So for example, integers. So you have a theory where you can have integer variables and integer operations, and then you have a different theory in which you have arrays. And arrays are parametric, that you can use any type as the index type or the value type of the array. And you also have array operations.
00:07:14.914 - 00:07:49.742, Speaker A: So you can select an element from an index, you can store a value into an index, and you get an array out of that. So these sub languages that were built with just in two solvers were kind of very natural for program verification. Plus a lot of practical advances in first such solving, which is just Boolean formulas, there's no theory element solvers and then solvers. The practical advances that these solvers made in the last 15 years made them very practical for software verification.
00:07:49.886 - 00:07:59.814, Speaker B: Yeah, it's more of like a, I guess, mathematical way of proving something right, instead of just kind of throwing random inputs and seeing what happens after.
00:08:00.012 - 00:08:32.142, Speaker A: Yeah. So the way you would model a program, usually when you're using an SMT solver, is so that you encode the program using this mathematical language that SMT solvers provide. Then you need a property. So when you're firmly verifying something, you need a property that you want to either break or prove that it's safe. And this property is not only relevant for firm verification, but for anything, for fuzzing as well for foundry calls in darian testing or also hvM. And it's just a property that you want to know or you want to test. Right.
00:08:32.142 - 00:09:18.302, Speaker A: And for Fe, this means it's a pretty extreme interpretation for Fe, in which you're either trying to prove that this property is correct for any possible input, even without actually testing all inputs. Or if you can't prove it, it's going to try to give you a counterexample to that property, which is effectively a bug usually. Right. It's something that breaks your property. And the way that you will, again, using that in silver, is by encoding the program. And then you take this property and you encode the negation of the property. And then you ask the solver, is this possible, is this satisfiable? And the semantics of that are so that if the solver tells you this is unsatisfiable, it means that it's impossible for the negation of the condition you're trying to prove to be true.
00:09:18.302 - 00:09:56.330, Speaker A: So it's impossible for the property to be wrong. Therefore the property must be right. And if the solver tells you it's satisfiable, it's going to give you what's called a model, which is the valuation for each variable in the formula that make it true. Meaning here is a way to break the property to make the negation of the property be true and effectively showing you how to basically break the property and basically giving you a bug. Right. So this is the very basics of how an SMT solver is usually used for this type of analysis. But then, of course, there's a lot of different ways people can vary this technique and try out different things.
00:09:56.400 - 00:10:08.270, Speaker B: Right? Yeah. So the SMT Sol was really used for just making sure that the code was meant to do what it was meant to do. Right. It wasn't really looking for security vulnerabilities, as in like reentrancy, for example.
00:10:08.420 - 00:10:34.326, Speaker A: You can use it for that too. There are different sub techniques inside FB that will be more efficient to either case, but there are techniques that will be more efficient. When you're actually trying to break something, it's not going to help as much in proving that it's correct, but if it is broken, it's more likely to find the flaw than some other technique that is supposed to prove correctness of the property.
00:10:34.428 - 00:10:41.914, Speaker B: Okay. But for solidity, it was mostly just used for non security issues, right?
00:10:42.112 - 00:11:33.558, Speaker A: Yeah. It's still the case that fV, usually you're trying to prove correctness. And you can use fV, you can tweak it in a way that you're at the same time trying to find bugs, right? And it is true that what we see a lot in practice is that a lot of the bugs are actually fan embroidery techniques, right? So fuzzing, for example, is a very successful technique in finding bugs because of the nature of the technique. And whereas fe, it's designed to prove correctness. And then, I don't want to call it a side effect, but it is kind of a side effect that you can also find bugs with it. The tools, they are all written with that in mind, that you will get bugs, you will get counterexamples for these properties and get bugs. But it is true that it's harder to do it with fe than other techniques.
00:11:33.558 - 00:11:45.182, Speaker A: But it's also the case that many times some bugs will, they might only be found by fe, similar to how some bugs may only be found by fuzzing. So these tools are quite complementary, coming.
00:11:45.236 - 00:12:19.690, Speaker B: From a fuzzing point of view. If you were to just try and find every possible bug, you would just brute force it, right? Every possibility, every single context instance. And you'll eventually find something if given a long enough time frame or if it's smart enough to kind of minimize the time complexity issue. But yeah, if you complement them, then you're really hitting everything. But then that begs the question, if you've never done it, how would you really get into it? Formal verification without going to, let's say, university?
00:12:20.590 - 00:13:07.394, Speaker A: Yeah, I think it's a field that it's still mostly academic, the way people got into it. But I think especially on Ethereum, there's a lot of people without that background that know about it, which is pretty amazing, to be honest. And I think especially because the academic from verification community also gained a lot by Ethereum, because it's probably the first software community where FD is really applied. We have been trying to do this. I mean, FD has been applied in different ways, especially hardware, especially the medical devices and avionics industry. They do apply these things for decades already. But in software community, software was always too complicated to use rules in a day to day basis.
00:13:07.394 - 00:13:54.482, Speaker A: And in Ethereum, it's exploded because there are a set of incentives that make fv very doable for Ethereum. So for once, the programs are small by nature, right? So the smart contracts are usually simple, and they're small both because for a practical reason, on Ethereum, you have the bytecode size limit, right? And you also have gas itself, which gives an incentive for things to be small and simple. The second thing is obviously the financial incentive for things to be found early or for things to be hacked. And also the immutability aspect. Right. Of course people can upgrade contracts and do different things, but by nature it's also immutable. So these three things together make Fb very attractive for ethereum, and we see it in the Fb boom.
00:13:54.482 - 00:14:32.098, Speaker A: We've had Ethereum the last years with several tools, several companies doing these things. And also from an education point of view, where solidity developers that had never had any background informed verification, they know about FB. Maybe they already used it via HebM, for example, or now helmos or SMT checker or Manticore or Mithril. A lot of these tools, they apply FB methods and people may have used them before. And I think Ethereum basically has this point of connection that is not unexpected, but definitely surprising for a lot of people.
00:14:32.184 - 00:14:51.398, Speaker B: Yeah, I imagine it'll be really hard to get into if you don't really have the academic background of math, for example, like me trying to get into AI, I realize there's so much math involved and it's kind of a hindrance if I want to get into design models, for example. It's a critical role in FE, isn't it?
00:14:51.564 - 00:15:34.966, Speaker A: I think there's also a difference, though, in if you're writing the FB tools or if you're just using them. Of course to write these tools, you will need some background, potential solvering or system theory improvers kind of things. But if you're using the tools, a lot of teams, including ours, are working on making the dev acts like the UX of these tools, the best as possible. So that when you use these tools, you don't have to know anything about the background. You don't have to know basically, for example, making the API the same as fuzzing, right? You're like, here's a property, just try to break it or approve it. Correct? I don't want to know what's happening in the background. And that's what a lot of tools have focused on the past years.
00:15:35.068 - 00:16:11.394, Speaker B: Yeah, I completely agree. I think tooling right now in Ethereum is very convoluted and it's very hard to get up and running without doing a lot of research into it. The dev experience, and at least in my experience, hasn't been the best. So I've just never really used them. But obviously, if you just make it very streamlined, you just, for example, provide a property and then a contract, and then it just does it. That would be just the best, right? There's no learning of how do I set this up or what do I need all these dependencies? It's just you grab it, put it in, run it, and then there you go, for sure.
00:16:11.432 - 00:17:02.386, Speaker A: And one thing we've seen, especially last year and this year is so adeptools and H UVM, they kind of started this integration into the development, right? And with Hevm back then, a writer of devtools, you could write invariant testing, you could do fuzzing, you could do symbolic execution, right? And foundry went on a similar path, at least with fuzzing and the invariant testing, which you can do with foundry itself. And a lot of the symbolic execution tools and fe tools in general, they are providing foundry integration, right? So if you take actor, it can be used directly by foundry. Hevm has found integration. Hallmodes has found integration. Kevm has a mode with found integration. I think Sartora is working on found integration. So a lot of these tools, they notice that the best way is to.
00:17:02.386 - 00:17:18.200, Speaker A: Sorry about that. The best way is to basically take what people already use, which is things like hard hat, foundry and so on, and integrate the FE tools inside these development toolkits. And that's what provides the best ux to. Right?
00:17:18.990 - 00:17:37.994, Speaker B: Yeah, yeah. Because it's such like a big ecosystem. Everybody already know, for example, foundry and hardhub. Obviously, foundry has gained tons of traction. It's kind of the standard now. So if you want to have a tool that everybody uses, you would obviously integrate with the tool that everybody uses.
00:17:38.122 - 00:18:19.420, Speaker A: Yeah. Because if you ask someone, yeah, go here, install HVM, install, simply check, install homosexuals, install tutorial approver, install KVM, install everything. No one's going to do this. And it's one thing we usually tell people, they ask, oh, what's the best FB tool? What should I use? And you should use everything. Every tool will have different strengths and weaknesses, and it doesn't really make sense to try to only use one and think that you're getting everything out of it, because inside FB itself, there are different techniques that will maybe find different types of bugs or be able to prove different types of properties. And you should really use as many things as you can. And of course, if you have to install ten different tools, you're not going to do it.
00:18:20.270 - 00:19:03.350, Speaker B: Yeah, exactly. The installing everything is definitely something you don't want to do. You kind of just want like an aggregated source where you can just access them all at once, because it becomes this time kind of trade off with the person that's using is like, okay, do I really want to use this? Especially if they're for example like a startup, right? They want to work on their startup and get to MVP and start releasing. They want to spend all these hours trying to learn how to install something. Maybe an error comes up, they can't find the answer. It just becomes this very convoluted thing. But that begs a question of when someone wants to build an SMT solver, how should they really go about design phase and then implementation?
00:19:03.510 - 00:19:34.754, Speaker A: So feel like you wouldn't go about writing an SMT solver. This is usually not something that a lot of people are doing. Even like people that are writing tools for smart contract verification, for example, no one is really writing their solver. So these solvers, they are usually written by, they're like even a lower level in the stack. We are using these tools that usually come from academic groups. There are lots of this SM two servers out there. There are two main ones that almost everyone uses called z.
00:19:34.754 - 00:20:01.402, Speaker A: Three from Microsoft Research and CVC, five from Stanford University, others I think. So these tools, they are maintained and developed by these most academic or research teams and the people that build SV tools for smart contract, doing symbolic execution or symbolic fuzzing or different things. We basically use these solvers. Yeah, we wouldn't really write a solver ourselves. That's a lot of work.
00:20:01.456 - 00:20:19.038, Speaker B: It's just too. Yeah, it makes sense. May as well use the standards unless, you know, abundance of time to create your own. What led you to stop working at ethereum foundation as like lead form of verification, stop doing that and then moving on to a different kind of path.
00:20:19.134 - 00:21:17.230, Speaker A: Yeah, so I've been interested in the ZK space for several years now. I was always trying to write circuits and learn about how these things work. And actually one and a half years ago, almost two years ago, we actually started a project for doing fv for ZK circuits. So basically trying to write techniques based on SMT solvers or using SMT solvers or SMT servers, plus something else such as grubner basis, more algebraic approaches, applying these things to the K circuits, because these things were becoming really popular. And yeah, we wanted to bring the same type of techniques we have already in software with smart contracts to this space as well. So this is something we were actually focusing on inside our FE team in the EF itself. And so we were always close to the ZK space in a way more from this FBE and security point of view, but at the same time also having a compiler background.
00:21:17.230 - 00:22:04.980, Speaker A: So about two years ago, I think it's when me and a few other people started digging a lot into ZK evms. Pretty much just like understanding how would you go about writing making Ziki proofs about EVM execution. So we're just learning a lot about these things and becoming familiar with the project that we're doing this like two or three years ago, even though back then it sounded like it would still take a long time. So basically studying these techniques, trying to design new techniques of how to make this happen. And yeah, especially last year I was trying to do different things to experiment with different proof systems, for example, because we hear a lot about different proof systems. So you have starks, estarks, Halo two, Nova, supernova, the whole thing. And I wanted to experiment with all of them.
00:22:04.980 - 00:22:31.366, Speaker A: And it was basically an impossible thing to do. It still kind of is. And this is a problem that Christian and Tibu, who started powder with me, also experienced. And we basically decided to jump on it, write some tooling. And then we had some really good preliminary results and eventually decided to just jump on it full time and work on this as our main thing.
00:22:31.408 - 00:22:40.830, Speaker B: Now you're applying all your skills from Ethereum to now ZK, I guess. What is your kind of end goal for have?
00:22:40.980 - 00:23:35.090, Speaker A: So the idea in powder, the tool itself is to be a compiler middleware for many front ends, many backends. So this is of course how compilers already work, outside Ethereum or like outside blockchain, outside ZK space. Right. So you have things like LVM which accept many front end languages via LVmir. And then you have a single compiler pipeline through LVM, which then can also give you binary or assembly in different targets. So like x 86 or rm or risk five, et cetera. So the idea of powder is basically very similar, where we want to be able to use any front end language through the same compiler middleware into any possible back end, the back ends being the proof systems, right? And so basically being able to make proofs in different proof systems or even combine them, do recursion, application, all these kind of things.
00:23:35.090 - 00:24:12.694, Speaker A: And the way we do this is by writing a new language. So the powder IR basically is an assembly language that allows the users or also ourselves to write vms in powder. So we can basically write any VM in powder itself. And then with the simple transpiler from whatever front end assembly into powder IR, we basically can benefit from the entire workflow and the entire pipeline of the compiler, including static analysis, security passes, optimizations, all those kinds of things, and at the same time have access to a whole set of proof systems and aggregation.
00:24:12.742 - 00:24:52.822, Speaker B: Yeah, that seems like a lot of work as well though. So I guess how do you build all this stuff like an IR? That's actually quite good. How do you make that effective as well? Because people use IRS and security techniques as well, like fuzzing and all that stuff to make it more simple and understand it. So even compilers will be the same of checking for any, I guess, mishaps in the code. But yeah, I guess, how do you really go about building this entire stack? What's the process of it? Obviously it's gigantic, so there's got to be some kind of structure, but yeah, how do you really design this whole architecture?
00:24:52.886 - 00:25:20.622, Speaker A: Yeah, it's actually not that big. It's all in the abstractions. So all you want to do is just keep it layered and compiler passes. So you have several layers, several levels in the stack, and you just keep converting one to the next. And it's not like you need to have this one massive firm that does everything. The key point is being very modular. So for example, we have the IR language, right, in which you can define vms.
00:25:20.622 - 00:26:11.986, Speaker A: And with this language we wrote the RISC five implementation, basically how RISC five works. And like the instruction set basically in powder IR we also wrote voluda VM, and we're soon going to write like WaSm as well, and EVM. This is written in the language as well. And from that we do several transformation passes into different flavors of the assembly itself, and then doing some different passes optimization and so on. And then finally we arrive at a low level constraint language, which doesn't have the notion of programs anymore, it only knows about constraints at this point. We do a few more passes of optimizations and analysis and so on. And from this it gets transformed into the shape that each proof back end wants.
00:26:11.986 - 00:26:52.526, Speaker A: So this final part is actually pretty simple, because we are already at a language which is just constraints. And the bluebers also take constraints. So it's more just like it's a single file API where we just transform our data structures into the proverbs data structures. So this part is actually one of the simplest. And yeah, a lot of work actually goes into design of the language. So we had several designs, several iterations on the VM language basically, and we just keep changing it. And our idea is to be very iteration based, so we just write iteration and we're never really 100% happy with that.
00:26:52.526 - 00:27:43.310, Speaker A: Iteration, but we go for it anyway. We change our tests, we change our code, and then we start writing new things and then learn what we have to change next and keep changing these things. And one approach we have followed since the beginning is to focus on an end to end approach where even if not all modules in the middle are finished. We want to be able to follow an end to end path fully and at least attempt things. So that's why we decided on one front end, we decided on one back end. And then I said, okay, let's make this one path work, which was basically the risk five to actually two paths, risk five to halo two, and risk five to start. And we made the front end work, we made the back end work, we made the middleware really basic so that we can already make proofs for rust programs, for example, or any program that compiles to risk five or below to vm, now that we have bullet as well.
00:27:43.310 - 00:28:31.582, Speaker A: So now the middle is not finished. So the core of the compiler is not finished, but it has the bare features needed to go all the way from a rust program to a halo, two proof, for example. And then this enables us to basically keep working in a way that's very feature or like use case based. So we have a certain program we want to make proofs for. We just try it because the parser works, the compiler works, the proverb works, then we figure out, okay, so there's a certain feature missing inside the compiler, we just go and build that feature. And because everything's very modular, it's possible for us to follow this approach and then just build out each feature separately until a certain use case we really want to work, actually works. And yeah, I think this is basically the key to your first question.
00:28:31.582 - 00:28:43.294, Speaker A: How do we go about building what sounds like a massive project? It's really based on this, I would even say classic compiler architecture of layers, levels and modularity.
00:28:43.342 - 00:28:50.246, Speaker B: I think that even applies to anything or any kind of project. Sorry.
00:28:50.348 - 00:28:52.326, Speaker A: Yeah, I was just agreeing with you.
00:28:52.508 - 00:29:41.010, Speaker B: Sorry. Yeah, I think that goes with anything really. You got to modulize, otherwise you're never going to get to the end or at least the start of the journey. You'll always be trying to add all the features at the start and never actually reach the point where you can start iterating on it because you haven't got that initial product right. Given that you need to get to this MVP state, I guess how do you determine what is absolutely essential to include? And then how do you attack each kind of section of, okay, we need this first to make this other thing happen, and then we can finally use that last thing to get to MVP. So yeah, how do you decide on priorities and not trying to include every single feature at the first stage?
00:29:41.090 - 00:30:22.894, Speaker A: Yeah, so we basically decided we're not focusing on performance at the moment. This is, something is going to come later, but it's not the main thing for now. So for now we want to focus on developer experience and the usability aspect of going all the way from a high level program or from writing your own vm to proof system. So currently we have a few fronts going on. So we have the front end, which again supports things like risk five programs, invalidated programs, and soon EVM was, and so on. So a big part of the work is making sure that these front ends are fully supported and this is basically demand. Right? So we know people want to make proofs for RoS programs.
00:30:22.894 - 00:30:55.022, Speaker A: What's the easiest way to make proofs for bus programs? Either risk five or valida. But we also know people want wasm programs and they also want EVM because everyone still wants EvM. So I feel like these are the main front ends we have, and then inside each front end we know what to do. And then it's kind of like quote unquote just work on the other team. We have the proof systems and the main production proof systems we have nowadays are Halo two and Starks. Right. These are the ones used by pretty much, I guess all or almost all l two s, l three s and so on.
00:30:55.022 - 00:31:30.738, Speaker A: And so we focus on these two. So we have now, hello, two integration almost fully done. And then we're also working on the starks integration. And we also know people need to, they want to verify proof on Ethereum. So if you're on the Stark land, you also need to have some recursion aggregation set up to end up with the snark that you can go and verify on Ethereum. So it's again based on use case and user demand pretty much. And then the internals of the compiler is then what's the minimal set of features that we need to write that's going to enable this whole thing to link together.
00:31:30.844 - 00:31:31.546, Speaker B: Right.
00:31:31.728 - 00:31:39.894, Speaker A: How do we actually take all those front ends we want and link them to the back ends we want? So that's basically how the feature status is decided.
00:31:39.942 - 00:32:00.366, Speaker B: And you also mentioned like language design as well. Right. I do want to touch on how do you actually know when a language is good? And obviously you've had experience with solidity that compiler. What are the things you've kind of learned from solidity and you're kind of improving on with powder.
00:32:00.558 - 00:32:23.898, Speaker A: Yeah, I think there are quite a lot of lessons from solidity. I think one big lesson is to keep it simple, which sounds very simple. And again, it's a general software engineering concept, right. To not try to make things too complicated if you don't have to. And I think this is one really positive point of solidity. It's a DSL, it's made for Ethereum. It does its job.
00:32:23.898 - 00:33:12.698, Speaker A: You can very easily read solidity if you code in any web two or systems programming language. You can learn solidity in two days and start writing even slightly complicated things. Of course, you have to study the EVM as well, because if you don't know the EVM, then yeah, you're going to do weird stuff in solidity. But I think solidity does a really good job at being simple and effective at that, and really easy to read and write. One of the negative things that I would say we've also learned from solidity is to try to keep things out of the language, sorry, out of the compiler and written in the language. So this is one thing that rust does really well. For example, a lot of the things are written in the language itself, so tons of libraries of many different things are written in rust itself.
00:33:12.698 - 00:33:56.950, Speaker A: And the compiler only needs one specific module or typechecker type of module to support a whole set of different features because it allows these things to be written in the language. And in solidity. There's a lot of magic things that the compiler has to support, because these are things that are first class citizens in the language. And reducing the set of first class citizens in the languages also is also something we try to apply in the powder IR as well. Of course, sometimes it's hard to keep this principle 100% for practical reasons, but I would say this is like one big positive, one big negative that we keep in mind since powder is a startup.
00:33:57.630 - 00:34:31.620, Speaker B: Luckily you've found some co founders. But what are the real difficulties you're facing as a startup? Obviously you're juggling multiple hats, but starting up is not easy. So how are you kind of going through this process after going with solidity? And I'm sure you've done previous startups, but yeah, I guess. What have you learned in the past that you're now applying now? And what are you learning while building this right now?
00:34:31.990 - 00:34:36.950, Speaker A: Yeah, I think especially in the ZK space, it feels a bit hard sometimes.
00:34:37.020 - 00:34:39.686, Speaker B: To stay focused because there's so many.
00:34:39.708 - 00:35:19.060, Speaker A: New things going on. And every single week there is a different proof system or use case or, I don't know, crazy tool. It's really hard not to get nerd sniped constantly and go build different things just for fun. We're still doing this for fun, so we enjoy what we're doing and we think it's valuable. There's fun things everywhere to be done. And I would say this is tough. Just like deciding on the roadmap and really sticking to it and not letting yourself be distracted by either a new shiny thing that you've seen or different use cases, which we do learn about use cases all the time.
00:35:19.060 - 00:35:22.270, Speaker A: I would say it's hard not to get distracted.
00:35:22.350 - 00:36:02.510, Speaker B: I definitely resonate with that, building my fuzzer. I also talk to AI engineers and then I get extreme fomo of AI and feel like what I'm doing now is pointless. But after doing it for so long, it's like, why would I stop right at the end? May as well get to the finish line. But getting to the finish line is the hardest thing. The finish line meaning MVP at least, because the hardest thing really is getting to the MVP. There's so many distractions, so many things that can go wrong. And even if you get to the MVP right, people might not even want to use it.
00:36:02.510 - 00:36:47.760, Speaker B: Maybe you've just built out a ton of features that nobody really uses. Or maybe you use one out of ten, for example, and it's just like, oh, wow, why did I just spend all my time doing this? So I guess on that note, how do you know without, let's say, you didn't have a community behind it already, you don't already know kind of what's necessary and what's not. How do you identify what people want without, I guess, even having the people to begin with? I guess it starts from a problem you've had or something you identify and then you go through that, but then even then you don't know if people would also have that problem. So I guess, where does that mindset really come from?
00:36:48.610 - 00:37:33.866, Speaker A: Yeah, I think you're right. At first it was basically a problem we had and we're trying to solve, but also at the same time, we know a lot of people. We have friends working on different levels of the stack. So proof systems and cryptography on l two s, l three s, and l one itself. So I think we've also identified from this larger community the needs of different things and also just talking to people in general especially. We were in Paris with you a few weeks ago and my bird of use cases that I have not imagined before and that could potentially use powder as well, for example. And I think just always learning about different projects, different tools, different ideas and besides the ones that we already kind.
00:37:33.888 - 00:38:11.370, Speaker B: Of knew before with a form of verification. Just to jump a bit back, what are your thoughts on the AI future of, I guess, Fb and cybersecurity in that sense, because it is quite intimidating of the possibilities of what the future can be with AI. And that can obviously bring in some impostor syndrome of what I'm doing right now is redundant. AI will eventually take it. But I guess, do you think about that at all, of this huge AI revolution and it taking over software?
00:38:12.110 - 00:39:10.522, Speaker A: Yeah, I think on that security side in general, I think it would be really cool to see more AI powered tools. I think there are definitely some up there already, both in helping you construct the code, right. But also analyzing code. I think a lot of people extremely skeptical saying like, oh, there's no way AI can do what our current tools do. And yeah, that's probably true right now, but maybe one day we're going to be at a point where the AI is actually pretty good at very quickly identifying vulnerabilities and this type of things. The one issue that it's also true for the current AI already, just like how confident you can be on whatever the AI says. And this is particularly a problem in the security space, right? If the AI tells you, oh, yeah, this thing is safe, and then it's like, yeah, okay, but why and how did you find it out? And I think getting explanations out of AI is still a big research field.
00:39:10.522 - 00:39:47.506, Speaker A: And again, I don't know that much about AI, so I don't know how advanced this field is, but I know that it's a field people work on. So getting explanations out of AI decisions and thoughts. So I think this is something that has to be figured out before people really trust AI results for security. Of course, for the positive case, in the sense of the positive being a bug is found. If AI gives you a bug, then of course you can just test it. Right. So I think especially this case might be very valuable in the near future.
00:39:47.628 - 00:40:49.798, Speaker B: Yeah, I think it's always great to hedge, well, not hedge, but always try and learn a bit about new technology, including ZK AI, whatever, because I think in the long run it's about the things you regret that you want to. Well, if you want to start something, think about future. Will I regret not learning this now or down the road? Obviously, there's a lot of trade offs in opportunity costs. You might be focusing on startup and you don't really want to learn something part time, but it might be useful. Right? But I think it all comes down to time management, priority management, all that stuff, including whether you're focused or not. So I guess to achieve such great things, how do you really structure your day so you can focus 100% at times and really structure your day where you can be most optimal?
00:40:49.894 - 00:41:20.982, Speaker A: I think. Still, in the AI thing, I really don't know much about AI and I feel like I'm not the best person to get into AI, but I like to use it. So I do use GPC four daily to help me out with things. I feel like it's not very good at code yet, but I use it just to chat about ideas and ask for information. Like a power Google kind of. I feel like it got more productive since I started doing this. I feel like a lot of people did that already.
00:41:20.982 - 00:41:49.230, Speaker A: It's not nothing magic, but I think for me it works in general. I think being productive, let's see, fewer meetings, definitely, yeah. I have a self policy right now. Like Monday and Fridays, no meetings. And of course you can always have spontaneous meetings with the team and then discuss. We have ad hoc technical calls all the time, but just like no planned meetings. So you can start and end the week and in a focus way.
00:41:49.230 - 00:42:08.790, Speaker A: I think focus time, like the chat closed is also a good idea, but also on the other way around. Just like being communicative and then just like pair programming, these kind of things are super. I find it super productive to just work together with people on a feature or fixing bugs, reviewing pull requests, these kind of things.
00:42:08.860 - 00:42:41.406, Speaker B: Yeah, I agree. The pair programming thing is really useful. I haven't done it too much, but the times I have done it, you can really kind of hone down and focus. It's like an environment you're in, right? So since you're talking to someone or discussing ideas, it's kind of hard to get distracted in that sense. Whereas if you're alone, you have your phone, for example. Even if you have your phone in the pair of programming, it's still not going to get as distracted as if you're alone and you have your phone. Right? And even just like managing social media as well.
00:42:41.406 - 00:43:25.086, Speaker B: It's such a massive thing, right? And it's grabbing all your attention, or at least attempting to. And you got to find these windows within your day of focus. And that takes maybe 20 minutes to get into that kind of state. And it's so easy to break it. So how do you really limit distractions? Because obviously you can work hard, but to get into the state of working hard and being in a flow state is the most difficult thing, I think, or at least that's for me. So I wonder what your kind of strategy is to limit these distractions and really zone in to the task at hand.
00:43:25.188 - 00:43:46.180, Speaker A: Yeah, I think when I really want to get something done, I feel like it's kind of natural. If I'm really into a feature and then I just really want to finish it or fix a bug or something, then I feel like that itself is the thing that's nerd sniping me to do right now. Just like get nerd sniped by my own features. I think it's just the usual mindset for me.
00:43:47.030 - 00:43:56.678, Speaker B: I have the same kind of feeling with some features, but then others are just extremely hard to implement and then I get kind of like demotivated in some way. Do you ever feel that kind of way?
00:43:56.764 - 00:44:21.274, Speaker A: Yeah, for sure. Especially on the simply checker server for solidity. For a long time I was working on it alone. I had people to discuss ideas and review pull requests kind of things. But I was responsible for most of the implementation. And a lot of the time the implementation is really complicated and I had to study a lot and design things. And at some point all I could think of was like, I just want to not do any of the complicated features anymore.
00:44:21.274 - 00:44:32.002, Speaker A: I just want someone else to do it or I just want to be done with this. So I think, yeah, definitely can resonate with that. It's hard to always have to do the complicated stuff. This is for sure true.
00:44:32.136 - 00:44:47.074, Speaker B: Yeah, it's pretty annoying that to move on to the features that you do want to do, you've got to do these very difficult ones which are massive roadblocks and you actually can't get around them because they are a necessity for these other features. Yeah, I think, I guess good solution.
00:44:47.122 - 00:44:52.570, Speaker A: Is to just have good teammates that can also do that kind of stuff and then you can always just alternate.
00:44:53.790 - 00:45:36.694, Speaker B: Yeah, but for the people that are building tools by themselves, yeah, it's incredibly hard for me, at least I'm building a feature right now, which is a necessity for everything else, but it requires a lot of moving parts, which maybe is a flaw on my end for designing this in such a way. But I've also thought of different ways, but the overall kind of vision for it, it needs to be complex to some degree to even achieve it. But again, it could be just that I'm limited in my knowledge of software, but getting through these very difficult problems are extremely hard.
00:45:36.812 - 00:45:48.650, Speaker A: Yeah, it's definitely tough. And working alone itself, even if you're doing small features, easy stuff, just like working by yourself is always tough.
00:45:50.130 - 00:46:20.340, Speaker B: Yeah, I guess rewarding as well in some ways. But just to shift topic a little bit, you're working at Spearbit. Well as a freelancer, I assume, or a contractor. And how do you really go about the auditing methodology you take? How do you zone in to find critical vulnerabilities? Right. Maybe there's a different strategy, but I guess what is your kind of process?
00:46:20.790 - 00:47:02.018, Speaker A: Yeah, there's a few things that I personally, or also the other people that I usually do these things with do. I think one of them is really just like understanding what things supposed to do. That's why projects with great docs and these kind of things is always more of a, it makes your life easier if you can read a document and say, okay, so I understand what this thing is supposed to do. And obviously if the code is well written, you can try to match conceptually and say, okay, this gives me a good feeling, or not. And this is also kind of like, there's also this element of vibes. You just look into the code and then it's, okay, this looks weird, this looks a bit fishy. And I'll investigate a bit more.
00:47:02.018 - 00:47:31.594, Speaker A: Of course, it's like good practices, things people should be doing, things people should not be doing. And of course you hunt those down, usually more like in a methodic way where I just see, like they have this checklist of things they want to check. Right. And this is normal. I think everyone will have their own checklist of bad practices, good practices, and I think everyone has their own checklist. Probably companies have their own checklist as well. And you do these kind of things, but you also have this feeling of when things are looking fishy or not.
00:47:31.594 - 00:48:00.866, Speaker A: And then you can do vertical or horizontal. Right. You can just find a fishy thing and try and hunt it down, go into the rabbit hole all the way until you're either convinced that it's fine or you find a problem or you're convinced enough that it's fine. Or you can basically just try to take a shallow look onto the whole code base and then just kind of scan, feel the different parts. And I think it's always a combination of both. Right. So it's more just like you're always kind of like scanning, and then it just looks a little bit weird.
00:48:00.866 - 00:48:09.462, Speaker A: So you go a bit deeper and then you scan a little bit as well, and then you either backtrack or keep going. Yeah, this is not very, what I just said doesn't feel very scientific.
00:48:09.526 - 00:48:46.626, Speaker B: But yeah, having done it manually, you obviously have a good sense of what goes into it. And when you do it manually, it's an algorithm in your head, right? So I guess if you were to automate it, let's say in an abstract sense of very simple kind of things like step by step, what would you do if you had to automate it? Yeah, so what kind of steps would you take to build something that could automate your process, or to a point where it can discover critical vulnerabilities in an efficient manner?
00:48:46.818 - 00:49:40.758, Speaker A: I think you mean automate the manual process, not like an FP tool. I think visualization tools help, or better, visualization tools would help because I think sometimes projects have really complicated paths inside their whole smart contract suite where you're like, okay, how do I even get to this function? Okay, this function looks kind of fishy. And the way it's using the state variables, the torch variables, feels problematic. Or it could be double spending eth. But for that I need to verify, I need to check that this path is unique or that it can branch out in a certain point. So I think there's probably a lot of heuristics that tools like slither, for example, probably employ also from their own learnings and audits. So I think those visualization tools would be probably something I would try to tackle if I was trying to automate this process.
00:49:40.758 - 00:50:16.450, Speaker A: And I have used fe tools for this kind of stuff before. So I have a function that's really deep down this smart contract. It's kind of far from the entry point of the contract. Then how do I even get to this point? What are the functions that allow me to come here then? It would just put a broken assertion there, like assert false or something, and then run a few tools like HBM or simply check or others, and then see the counter example and see, okay, this is how I got to this function, which feels like overkill in a way, but I think this feels like one example that just came to mind.
00:50:16.520 - 00:50:24.100, Speaker B: Yeah, some more visualization tools. And I wonder, what if you had to fully automate it, how would you go about that then?
00:50:25.670 - 00:51:22.310, Speaker A: Well, fully automate then I would build on a few tools, because I think if you're automating the manual process, it's a lot of heuristics that you don't necessarily have mapped out in your head explicitly as you saw before. I even have a problem explaining what I do manually because it feels very intuitive sometimes. And you don't know why you're doing things. Of course. Again, there is this checklist and of course with experience, you know, when things look fishy or not. But I think automating the manual process, I just wouldn't know how to do it because what you're trying to do is basically, I think, yeah, the only way I can describe it is just like collecting heuristics and making detectors based on these heuristics. So again, tools like Slither, I feel like tools like Slither are probably a good summary of things you usually check in a manual audit.
00:51:22.310 - 00:51:52.942, Speaker A: That's why I don't know how I would go about doing that, besides doing what slither already does and fuzzing and these kind of things. Of course, sometimes we do set up our own fuzzing based on whether we want to prove equivalents of different reference implementations or these kind of things. But if I had to build a tool to automate a whole security process, I would probably build either a fuzzer or an FB tool.
00:51:52.996 - 00:52:22.022, Speaker B: Got you. Yeah. I mean, building something that fully automates finding every. I guess vulnerability is not an easy feat. As you said, it's a bunch of heuristics and ways of thinking which get complicated very quickly. And first of all you have to build the reconnaissance tool to kind of get all the information right. And then you got to start building, you got to account for all the different scenarios or what can happen, what things can change, what things, what can be influenced.
00:52:22.022 - 00:53:02.486, Speaker B: And with smart contracts, it's a multidimensional kind of problem. It's not traditional fuzzing where you just change the payload, it's more of changing the payload. That's one. But then you also have cross contract interaction. There's different contexts of all this stuff as well. Like someone can throw in 100 e to the contract, then what happens to all these other paths I just took with this 100 e? So there's also like actor fuzzing as well, and then replicating all of the past fuzzers with this new actor. So there's that dimension as well.
00:53:02.486 - 00:53:54.246, Speaker B: And then even you can say cross chain or multichain omnichan, whatever. Maybe it depends on off chain stuff. How do you modify that? And then it becomes an even bigger kind of problem in my eyes. It can be done. It's just a very tedious thing. And that's where I think AI would really come in. Because if you think about it any kind of fuzzer anything is really just a representation of your manual labor to build the tool, first of all, but it won't evolve unless you evolve it, whereas an AI can evolve by itself and understand all these dimensions intuitively after tons of training.
00:53:54.246 - 00:54:35.154, Speaker B: I don't know. It's an interesting field and I think it's definitely worth taking a look at. I do eventually want to get into formal verification. Well, not formal verification, but I guess fuzzing on ZK, especially on Aztec. That seems very interesting with know you have the ZK with the privacy transactions, but then you also have the abstract account abstraction. So it's like a whole new kind of realm, I think, for people interested in EVM Ethereum kind of stuff. Having said that, it has reached 1 hour and I don't want to take too much more of your time.
00:54:35.154 - 00:54:47.062, Speaker B: I do want to thank you for jumping on for this past hour and being able to connect with me, and hopefully you've enjoyed it as much as I have. But yeah, thank you so much for coming on.
00:54:47.116 - 00:54:51.226, Speaker A: Yeah, for sure, this was a great chat. Thanks for having me on, of course.
00:54:51.328 - 00:55:07.790, Speaker B: And for anyone listening. If you want to be on the podcast or want to suggest anybody coming on the podcast, just dm me at scraping bits on Twitter. Otherwise, thank you so much Leo, for jumping on, and I'll catch you all on the next episode.
00:55:09.970 - 00:55:10.460, Speaker A: For sure.

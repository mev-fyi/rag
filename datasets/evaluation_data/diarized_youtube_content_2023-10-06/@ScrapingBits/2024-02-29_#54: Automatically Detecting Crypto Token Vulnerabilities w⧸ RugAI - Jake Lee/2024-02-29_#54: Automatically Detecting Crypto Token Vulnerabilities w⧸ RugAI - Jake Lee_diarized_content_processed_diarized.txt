00:00:00.250 - 00:00:26.760, Speaker A: There are some pieces of information we have, some pieces of information we don't. But when we get a new token that is unverified and we're asked, what can we say about it? The best we do at the moment is we can search for that bytecode and we can try and figure out if that token is a fork of an existing token on an existing network. From that we can gauge a lot of information. We can look at how that token performed, we can look at things like the opcode diffs, and we can see what is slightly different about it. What kind of similarity do they have?
00:00:27.210 - 00:01:06.974, Speaker B: Scraping bits is brought to you by the following sponsors mev protocol maximize your eth staking value with me V, exclusively on MeV IO and composable execute any intent on any chain coming soon to mantis app. That's Mantis a P and fastline labs, the only MeV and intent centric team that has a daily deodorant application rate of over 68% Gm gm. Everyone, my name is Tagachi, the host of scraping bits, and today I'm with Jake for my first episode of London. How's it going, Ryan?
00:01:07.102 - 00:01:09.998, Speaker A: Thank you for having me. It's a cold morning in London.
00:01:10.094 - 00:01:14.340, Speaker B: It is a fairly cold morning. I'm wearing a trench coat. It's inside.
00:01:15.030 - 00:01:17.246, Speaker A: It's a bit colder than Dubai.
00:01:17.438 - 00:01:22.920, Speaker B: Yeah, just a tad, just a little bit. Just for the people that aren't familiar with you, who are you and what do you do?
00:01:23.290 - 00:01:52.922, Speaker A: Yeah, so my name is Jake. I'm the co founder of a project called Rug AI. Me and my co founder started about eight months ago, and it's essentially a token intelligence platform for retail users. So we do a load of sort of data analysis on chain data, predominantly EVM data, and we produce lots of reports on tokens, their safety, who holds them? We can get into that a little bit more here, but the idea is that it's intended for retail and it's designed to be extremely user friendly.
00:01:52.986 - 00:02:28.710, Speaker B: Very interesting. I think I remember seeing another platform like this fall. I can't remember what it was called, but when I had my first amm, which was called Soulswap, they gave us a red flag because we didn't have a time lock. Also, this is like an interesting field as well, because a lot of people in MeV want to get into it for LP sniping and a lot of telegram bots, I think would want this kind of technology as well in house, though, so it's not shared. Obviously, the reason behind it is. So when people invest they don't get wrecked because all these LP snipers are just sniping. So they're becoming top of block, first investor in the pool.
00:02:28.710 - 00:02:39.162, Speaker B: They want to know if it's a rug. Majority of them are, but it would be good to know what part of it is the rug and what to look out for. So how do you determine how something is safe?
00:02:39.226 - 00:03:15.066, Speaker A: It's a good question. So I think it really depends on the use case and the user. You got into snipers, where these guys are trying to essentially almost backrun the liquidity deposit or the sort of trading trigger turn on. Obviously, there's very little information at that point about a token. Most of them might not even have verified source code, and you may be able to perform some degree of simulations, but ultimately, if the source code is not verified, it's very hard to tell whether you could be blacklisted after the fact and then essentially rugged. So there's a whole load that goes into this. So new launch is extremely hard.
00:03:15.066 - 00:04:26.130, Speaker A: What we do is we tend to focus on a few blocks after launch at the moment, and that product is more user interface focused. So it's more for less for snipers per se and probably more for people who want to know after the fact when there's more data available. How safe is the token in terms of how we do that? That's a really good question. We look at a load of different pieces of information, some of it you alluded to with things like who holds the token? Is the liquidity of the token locked? Are the holders of the token related to each other? Are they actually snipers? Are they smart contracts? What are they? And do they have labels? And then once we've broken all that down, we get into other things, like simulations. So we'll perform very standard things and very standard checks. Does the token have a transfer tax? So obviously, when you buy it, do you incur a fee for buying it? And also when you sell it, is that the case? And those things modifiable? And also, finally, are any holders blacklisted? Right. So are there holders of this token that, for instance, can't sell it at the moment because of some trigger on the smart contract? And we do all this data gathering, and then in one succinct scoring system, we give you a number out of 100 based on all of this data.
00:04:26.280 - 00:05:20.834, Speaker B: Yeah. For LP sniping, it's very difficult because you wouldn't know the storage slots of what's happening because I've actually experimented with this as well, and I was writing an article on this, I don't know when it will be released, but you can build one of these scam or rug lps by building the implementation token. And in the implementation token you don't have to abide by the storage slot standard is what I've seen. You just need the function to retrieve it, not the actual position. So it could be zero one, or maybe you could spam a whole bunch of them and be slot number 20. This is not easy to identify without traces or looking into the CFG of the bytecode, which is the control flow graph, and seeing what slots are interacted with in each function. So I guess you could generalize for a transfer function and you could see which slot is being added and then subtracted like a mapping, for example.
00:05:20.834 - 00:05:45.046, Speaker B: And you can see the computation of the mapping with Shafri and the address being used, whether it's method sender and let's say call dollar zero. Then you can identify through that. But that's the hard part. So I understand why you do it later, because I assume you would do like state traces for any transfer which would be able to identify these pure bytecode contracts. Is that kind of getting the right gist for that stuff? Or tell me about how you do your recon.
00:05:45.238 - 00:06:24.930, Speaker A: Exactly. So there's a lot to break down there. I think the one thing that's worth noting is that when you talk about sniping a launch, there's a lot of things that can go wrong. If you don't have verified source code, or maybe even the block explorer doesn't have it yet, then you have nothing you can rely on other than what the network says. So you can find the bytecode of the underlying smart contract. You may be able to decompile it to some extent, right? But in terms of having a very solid, concrete understanding of what is possible is basically not really there, right? So I think for us, we opted to do it this way because the margin for error is a little bit better. We can save a lot more certainty.
00:06:24.930 - 00:06:58.622, Speaker A: And there's also a race to zero. So if you build a model that's highly sophisticated at block zero, there's no way of knowing for certain whether someone could find a way to get around your model. And then from our perspective, we're building a brand around protecting users. It's very precarious if we get duped and our users end up getting rugged on something that we've said is safe based on our model. So we have to be very cognizant of that. There's a lot of stuff we do. That works for unverified source code later on in the lifecycle, a couple of blocks after trading has begun.
00:06:58.622 - 00:07:08.786, Speaker A: Of course, I alluded to simulations. If people specific holders are being blacklisted, we'll be able to tell. That's all very standard at this point, I think, for the industry.
00:07:08.978 - 00:07:22.234, Speaker B: How are you able to tell? Is it through seeing these transaction history and seeing the storage difference and you see their address go into something, maybe like a mapping, or there's like a requirement check, an if statement requirement. How are you actually doing that?
00:07:22.352 - 00:07:52.638, Speaker A: Yeah, so we're able to do this without any source code. And we've built basically a simulation framework. We leverage a lot of things like foundry, and we've built a simulation framework that will allow you to essentially simulate any given holder transacting on this token. So we can account for things like variable tax rates depending on which address is buying or selling. And so we just produce a load of simulations. We know for certain that these simulations will, in most cases, give us an accurate view of this. There are some ways to dupe simulations like ecore.
00:07:52.638 - 00:07:58.946, Speaker A: You can get around it a little bit. There are some edge cases, but for the most part, we simulate things like this.
00:07:59.048 - 00:08:22.330, Speaker B: Okay, so let's say a big common thing in LP stepping. And I know this isn't your target demographic, but it is in the realm of it. So let's say I'm a bot, right? And the main thing that these scam lps implement is no bots allowed for ten blocks. And that's interesting. And even they might blacklist from deployment as well. What's the workflow for you? It's okay. Someone wants to buy this.
00:08:22.330 - 00:08:44.610, Speaker B: Do you just simulate with their address or do you already have all the addresses? Initially, and I think initially would be very difficult, especially if it's a mapping, because it's not an easy place to identify what is initially blacklisted. Let's say if they hard code it and didn't do like a constructor and you can't see the state diff, is that towards what you're doing? But I assume not doing that and waiting for people to interact with it.
00:08:44.680 - 00:09:13.950, Speaker A: Yeah. So I think the way I describe what we're doing is there's a degree of it being probabilistic. So we keep a track, we run indexes, we keep a track of who holds which tokens. We have all of that data. And of course, like you alluded to, some of these holders may be blacklisted. It's not something that we keep a track of live. But it's something that we can account for by if one of our users looks at a token, we queue up a job that says simulate this token, give the user all of the information that we usually provide.
00:09:13.950 - 00:09:40.162, Speaker A: And part of that will be we'll pick holders at random. So let's say we pick 200 holders at random. We'll run simulations for all these holders. And then we can come up with some degree of certainty. And if there are more than 200 holders, it's possible that one of them could be blacklisted when we missed it. But it's not super likely if we're selecting at random. So this is the idea is we're looking for quick checks that have some high degree of accuracy.
00:09:40.162 - 00:09:48.642, Speaker A: It's possible for us to simulate every holder. But of course everything costs gas and it takes a bit more time. And so we opt for something that's a little bit faster.
00:09:48.706 - 00:09:51.094, Speaker B: It costs gas to simulate. What do you mean?
00:09:51.212 - 00:10:16.910, Speaker A: So we're calling our own nodes, right? So we're constrained by how much we can simulate. And we have a lot of tokens that our users are querying. So it's better for us if we say one token simulation job is simulating 100 or 200 holders at random, and then that job is done. And then we can run up the next job. We have a huge queue, almost of backlog of jobs in our cloud queue. And then we pull them off one by one. There's only so much we can run through the two Gef nodes that we have.
00:10:16.980 - 00:10:19.426, Speaker B: Don't you modify your nodes though, so you can do more?
00:10:19.528 - 00:10:23.874, Speaker A: Not really. At the moment, we use things pretty much out of the box if we can.
00:10:23.992 - 00:10:50.282, Speaker B: You should definitely modify e of call to do multiple simulations because then you can just do one call. It's a little strat for anyone getting into node development. But you can modify it and you can do all the simulation? Yeah, you can just do a single eth call and you can do a whole lot more than what you get out the box. Basically whatever you want. That's a good upgrade. You have obviously your recon, and then you have your simulation and walk us through the simulation. How does this all happen? You have your score system.
00:10:50.282 - 00:11:17.378, Speaker B: That's four different things I saw in your docs. And the audit part is interesting. So I think that might be the hardest. So how do you audit one of these? Let's say it's a nonverified contract, so it's just by code. How do you audit and determine whether it's a honeypot? It's got some access control blocker after X amount of time or x amount of tokens are being minted or traded, or even if there's something that can completely rug which is like a mint for the owner. And how do you analyze this stuff?
00:11:17.464 - 00:11:44.462, Speaker A: Yeah, that's a great question. So there's two roads, right? They have verified source code, in which case we can do stuff that's a lot more explainable. And then also the road where they don't have verified source code. So all we have, maybe we'll go down the second route first. All we have in that case is deployed bytecode. We have probably the deployer address, maybe the transaction that the deployer used in terms of their gas settings like things like this. Maybe there's some pattern here.
00:11:44.462 - 00:12:26.058, Speaker A: But what we do is it's very difficult to concretely say for certain whether there is some sort of mintability or honeypot criterion, at least with what we have at the moment. This is all open research for us, but what we can do is we can decompile that bytecode and we can come up with the underlying opcodes that this contract contains. And then we can perform a load of pattern matching. We store a database of pretty much every deployed token. It's bytecode, it's decompiled opcodes. And then if it has source code, we produce things like an abstract syntax tree where we and run it through the compiler and we get a load of information. So basically take the verified source code.
00:12:26.058 - 00:13:29.550, Speaker A: There are some pieces of information we have, some pieces of information we don't. But when we get a new token that is unverified and we're asked what can we say about it? The best we do at the moment is we can search for that bytecode, we can try and find tokens which have a similar deployed bytecode, and we can try and figure out if that token is frankly it's just a fork of an existing token on an existing network. And from that we can gauge a lot of information. We can look at how that token performed and we can look at things like the opcode diffs and we can see what is slightly different about it. What kind of similarity do they have, what kind of confidence do we have? And then finally the tokens that are matched, did those tokens rug? Right? Were they honey parts? Did they have a mintable function? What happened to them? Just quantitatively, right? Did they have an LP rug? In which case that's not really any signal for the token you're looking at, but perhaps it's good to know maybe someone forked it, and maybe it's the same team that's just deploying these shitcoins in a factory. Basically that's what we do for unverified code. It's extremely difficult to do much more, but when we have the source code, it gets a lot more interesting.
00:13:29.700 - 00:13:32.286, Speaker B: Yeah. So how are you grabbing the source code then?
00:13:32.388 - 00:13:51.510, Speaker A: So we use the block explorer on Ethereum. That's the EFA scan. They allow you, if you have a key, to query it. I think there's something like ten requests a second. We can basically scrape them all. And then once we have the source code, we only need to fetch it once in general, unless there's a self destruct somewhere. So we can queue that up, fetch that, store it, and we don't have to fetch it again.
00:13:51.580 - 00:13:56.502, Speaker B: I think self destruct is now deprecated. I don't know if it still destroys the code.
00:13:56.636 - 00:14:03.206, Speaker A: There are some examples of tokens in the past that have messed us up a little bit, but from now on it is deprecated.
00:14:03.398 - 00:14:06.938, Speaker B: Yeah, I really like that opcode though. Can't believe they removed it.
00:14:07.104 - 00:14:08.502, Speaker A: It's extremely dangerous.
00:14:08.566 - 00:14:14.930, Speaker B: Metamorphic contracts are the best. You just continuously change them over time. It's the best. Completely removes immutability.
00:14:15.030 - 00:14:23.454, Speaker A: It breaks a lot of our assumptions in our processes in terms of how we store data. Like the fact that the source code is immutable in a sense.
00:14:23.652 - 00:14:24.014, Speaker B: Yeah.
00:14:24.052 - 00:14:25.210, Speaker A: So it's tricky.
00:14:25.370 - 00:14:41.046, Speaker B: I wonder if anyone's done like a proxy token. I think that would be quite interesting actually. Now I think about it, like the underlying token and the LP pair, let's say ETH and my token. I wonder if someone's done like a proxy, my token, where they can switch that to whatever one.
00:14:41.148 - 00:14:49.014, Speaker A: Yes, these exist. Yeah. Generally I think we can catch the delegate calls from just the bytecode, I believe. I'll have to get back to you on that.
00:14:49.052 - 00:14:59.270, Speaker B: But in general, yeah, you wouldn't even need the delegate call though. I feel like you could just do call and then have a hard coded address that you can just switch out and have the same function selector.
00:14:59.350 - 00:15:27.278, Speaker A: There are some examples. I think I can maybe fetch you some, but in general I would say when we see this, we flag the fact that there's a proxy contract involved here. And it's usually quite negative in terms of how we score things because it's not very standard for new token launches to be proxies. And it's a little bit dangerous. It allows a degree of flexibility that's a little bit insidious. We have to catch. What exactly are they calling? What does that thing do itself? It's very tricky.
00:15:27.278 - 00:15:31.462, Speaker A: It breaks a lot of our flow, so we just flag it as something to be wary of.
00:15:31.516 - 00:15:52.646, Speaker B: Yeah. Might explore the build. That sounds interesting just to write about. Not actually do. Of course, these custom tokens is after X amount of time. Actually, this was something I was exploring as well, just for research purposes. After X amount of time or X amount of tokens have been minted or traded or LP, whatever your condition is, it just ceases to withdraw and you can throw an error for the withdrawal.
00:15:52.646 - 00:15:56.942, Speaker B: I don't know if you found any of this. What are the most interesting things you found while doing this?
00:15:57.076 - 00:15:59.738, Speaker A: You mean withdraw from the LP?
00:15:59.914 - 00:16:02.640, Speaker B: Yeah, like trade back into Eth, for example.
00:16:03.410 - 00:16:08.062, Speaker A: Oh, I see. So what, after a period of time they prevent you from basically selling?
00:16:08.206 - 00:16:38.086, Speaker B: Yeah. So it's an if condition, like an if statement, and it would probably be like total supply and weigh up the token a and token b balances. And you can see that X amount has been traded, or, I don't know, X amount of time has passed. Obviously the traded one is a bit harder to detect, I think, or minted, et cetera. It could be anything. But after that condition has been passed and you can't trade back into ETH and it gets wrecked, unless maybe you're the owner.
00:16:38.198 - 00:17:26.678, Speaker A: Yeah, there are some tokens I've seen like this. I'd say the vast majority, though, are very standard. I think retailers have figured it out a little bit. They've realized that you can basically execute arbitrary code on these smart contracts. And so any team that one, doesn't verify their code is likely a bit sketchy, and two, they're looking for people to review that code. Hopefully a lot of people catch this kind of stuff. The things that I've seen that tend to work are less so these mechanical, smart, contract based things, and more like people will run a bot in the background and that bot will slowly ping holders off, maybe at random, based on some sort of very innocuous looking function at the bottom of the smart contract somewhere.
00:17:26.678 - 00:18:12.394, Speaker A: Those tend to be the most successful honeypots. So ones where it's maybe a little bit random, they can perhaps keep it running as a normal functioning token. Everything looks fine from the simulation perspective, and then all at once can trigger blacklist one by one to different holders. But anyone who's about to buy it and has a simulation run for them will be able to see that they could actually sell it at that point in time. These are the things that tend to work best, I think, from the scamming perspective, which is unfortunate, but the good news is that people have wisened up to the fact that if a token smart contract looks slightly od, it's more than likely a scam. And I think that's a very generalist, but a very sort of fair statement at this point.
00:18:12.512 - 00:19:10.634, Speaker B: Actually, now I think about it, that makes sense, because you can have, say, solidity, for example, you can have your verified contract, right? And I think I did this when we worked at STFX together, but you can have the same function name, but different parameters, and that causes a different function selector. So four bytes, I believe, if I remember correctly, it's been a while since I've done a solidity, but yeah, it creates a different four bytes, right? And so you can have the same name transfer or transfer from, but just add like a little parameter at the end. And for majority of people they don't know the difference or how this works. And then let's say in the lp you just do an assembly and you finesse it a little bit. Or even, I don't know, you can still do the transfer or like the one that's hidden. Let's say that you put it all the way at the bottom of the source code. Maybe you just build a giant token with a ton of source code, and then you add like this tiny one in the middle and just embed it.
00:19:10.634 - 00:20:01.962, Speaker B: So people just scan it or skim it and overlook it. People aren't just looking at the token if they're retail, or even if you do assembly like it's verified, but you can't read it unless assembly. And there's also obfuscation techniques as well. And I've written a fair bit about this on my website, which work, and to be fair, I think a lot of people don't do very advanced technical things in these contracts. It's more of just really basic stuff that it's just really hard to analyze in an algorithm. It's a lot of if statements like a lot of conditionals that are very niche, and to simulate them, you would have to do a lot like byte analysis basically, and taint analysis and all this other stuff. It gets very convoluted and it's not easier to do unless you've been doing it for a while, or you've been working on it for a while.
00:20:01.962 - 00:20:59.946, Speaker B: It's not like a one day thing, you have to build like an emulator. Or I guess you could fork with foundry or implement that yourself, but you still need to build these graphs like the CFG in each pathway, how all combines and interacts with each other. But the main thing to look for is like the require statements, the reverting conditions, and you can see a lot from that. But if they're smart, they would just do a lot of conditional switches, because that's what will trip you up. You might miss a single switch that happens at a certain time, and it might only trigger from, let's say, a combination. I think there's even things I've even seen this. It was a part of MeV, like an MEV contract, but you could actually dynamically switch your strategy based on the coinbase that was in the block.
00:20:59.946 - 00:21:35.770, Speaker B: So it could be like, do the specific arbitrage if Titan builder's coinbase was there, or switch to another one if it was, and I've never seen that before. But it was really interesting because they're always bidding like the PGAs, and whoever wins ends up. That's how it works. And there's actually different, obviously they all have different algorithms for their builders. Some are better markets that aren't volatile, while others are good in really volatile markets. So there might be different opportunities in both. I can't remember who did this, but that was one of the most interesting things I've seen, actually, in smart contract development.
00:21:35.770 - 00:21:38.294, Speaker B: But yeah. Anyway, enough ranting.
00:21:38.342 - 00:22:30.550, Speaker A: You touched on something which we've noted, which is that often a lot of these token scams are very simple, and the mechanism by which they scam is also very simple. Excuse me, sorry. So to give you an example, we've seen a lot of tokens that have a fairly standard set of source code. Like they may just look like a pure open Zeppelin ERC 20 implementation, but what they'll do is they'll define an interface on one of these source code files, and it'll say interface, and then it will say absolute random gibberish. And it'll define some functions on this interface that are also random gibberish. And then somewhere in one of these files they'll call this interface. So they'll modify one of the internal function calls to reference this interface.
00:22:30.550 - 00:23:17.290, Speaker A: But because this interface is inherited from some other deployed contract somewhere on the network, it doesn't come up. When you look for the source code of this token on the block explorer, and it's very hard to identify what it's actually doing, and it's also very hard to identify the presence of it. A lot of these things are the obfuscation techniques, like you've said, but they're just very standard, like week one solidity boot camp type things where you define interface, then you can give it an address and suddenly you can use all the functionality of it inside another contract. But what they do is they try and almost make it so incomprehensible that people just gloss over it and don't read into it. So there's a few of these that we've noted.
00:23:18.030 - 00:24:06.074, Speaker B: Yeah, I think actually probably 99% of developers don't actually know how to make obfuscated contracts or very convoluted ones. It's really like the 1% and even like black hats as well. They don't do any difficult things, they just do like private transactions and that's how it works. That 1%. There is a lot of advanced stuff you can do, but it really caps out quite quickly, which is why I stopped, because it got a bit boring. But if you really wanted to, yeah, you just embed it in an internal and then have that like a proxy or calls or hard code of address. So it's not a delegate call and it's not obvious exactly, but I think a good way of actually identifying this kind of stuff is looking at the gas of each function.
00:24:06.074 - 00:24:47.350, Speaker B: And you can do a gas diff instead of a code diff. I guess it's the same since each piece of opcode is a certain amount of gas. But if you see with a standard token, or any standard token is going to be way less than one, that's very convoluted, because they will have a lot of if statements, right. Maybe if they're smart they'll optimize it a lot and that kind of wrecks it. But I think more times than not it's going to be a lot more gas because I've seen ones that are just embedded if statements and it's just barely really convoluted for no reason. It's just a lot of nested conditionals.
00:24:48.990 - 00:24:54.374, Speaker A: They're often aimed to confuse, they're designed to basically throw off the human eye.
00:24:54.422 - 00:25:34.920, Speaker B: Basically, and like variables, just like makerdow or is it maker or compound where it's just like you don't know what's going on. These variables are crazy. It doesn't say what it's actually meant to be doing, like cattle dog and I don't know, wet barn or something. Yeah, they're quite interesting. How do you handle tokens of, let's say ownable functionality where, I don't know, let's say I deploy this token and I put certain access control restrictions in some functionality. How do you determine whether that functionality is important or whether it's not?
00:25:35.610 - 00:25:40.970, Speaker A: Yeah, it's a good question. So are we operating under the assumption we have the source code or we don't?
00:25:41.470 - 00:25:42.540, Speaker B: Either or.
00:25:43.390 - 00:26:27.394, Speaker A: I think in the case we don't. It's extremely hard for us to comment, really. And so what we opt to do is more just inform you that it's not verified. There's only so much we can do. But in the case where we have the source code, we do some quite complicated analysis, where what we do is we fetch all of the functions and all of the sort of inherited functions. So we'll go through all of the smart contract source code, we'll try and find every function call that is exposed to the external addresses, and then we'll break down those functions into their sort of recursive calls as well. And as part of that we may look at the function signature, we might identify any modifiers.
00:26:27.394 - 00:27:10.994, Speaker A: So in this case it catch things like Isoda or anything that's custom modifier. And yeah, most cases will catch these sort of modifiers in that step. Once we have all of these function calls, we can basically run the underlying recursive. It's a big long list of functions that are called one after another. We can give that as context to a large language model or a similar kind of model, then see whether that model can ascertain whether there are specific things that are concerning about this function. And as part of this process, we give it a load of context as well. We say, like here's an example of a malicious contract where this thing could happen and we give it a lot of structure.
00:27:10.994 - 00:28:06.498, Speaker A: So we'll expect a response in a specific sort of JSON format, and we'll ask the model to give us that response. And models will simulate a load of scenarios. But as you probably well know, at this point, a lot of these models tend to make stuff up. Sometimes their accuracy is a little bit questionable. They tend to hallucinate, as it were, where they'll say, okay, any address can infinitely approve transfers from any other address, but it's missed the point that maybe there's a modifier or maybe there's a requirement somewhere that prevents that from happening. So there are a lot of false positives, as it were. So what we do is we take all the scenarios that we've got here, and then we again run them through another model and we ask the second model, are these scenarios feasible? Are there any access controls that prevent this scenario from materializing? Is there anything that would prevent this from being concerning.
00:28:06.498 - 00:28:57.270, Speaker A: Is this concerning from the perspective of a user as well? We don't really care too much about. There's a possibility for reentrancy in this function. We're more concerned is there a possibility to prevent transfers or change the fungibility of the token and stuff like this? So that's what we do. And then we'll produce all of this information into one report. And this is, I guess our sort of flagship thing we do. It's still very early, I would say it doesn't quite get past every false positive at the moment, but it's somewhat promising. We flag a lot of problems that are pretty interesting and we've caught some rugs in the wild so far, which is great, but I think there's a whole load of research that needs to happen before we get something that we're fully cultivated.
00:28:57.850 - 00:29:13.260, Speaker B: You mentioned you caught some rugs in the wild before. How do you actually test a success rate like your benchmarks and measure the success accurately? Do you get alerted and look at the contract manually, or how does it all work?
00:29:13.790 - 00:29:40.006, Speaker A: Yeah, it's a great question. So at the moment we do a load of manual stuff. We have a sort of data team that fetches on chain data periodically. And we're looking for things, ironically, not so much for the ML side, but more for the marketing side. So we're looking for things that we can talk about, we can maybe go into on our product and maybe explain on Twitter or whatever. In terms of how do we benchmark the models. A big part of it is that we have to build a huge data set.
00:29:40.006 - 00:30:20.910, Speaker A: So what we're doing at the moment is because we're not actually quite publicly launched yet, our product is still in a sort of private beta stage, is all user actions on the product in terms of the tokens they're querying are all being stored in our database. So every time you query a token, we'll run the report and then we'll store the report so that the next user, of course, can see the report straight away. But for us, we can calculate tens of thousands of reports and we have them in our database. Once we're done with this data gathering, then it's a case of labeling and trying to work out if we can pretrain models to be more accurate than out of the box models.
00:30:21.070 - 00:30:53.006, Speaker B: When you say llms and you need a ton of data, right, there's not an insane amount of rugs and ML takes a ton of data. Are you synthesizing contracts that actually have exploits? And if you are, then wouldn't it be limited to that capability? Which might be fine. People might not be doing a ton of rugs, but then you might be giving a false positive, oh, this is not a rug, which is detrimental. But, yeah, how are you actually getting this data? And how are you getting enough of this data?
00:30:53.108 - 00:31:24.870, Speaker A: Yeah. So it's a question of, like, how do you ensure that your model generalizes sufficiently? It doesn't narrow in on specific examples you've given it? It's a very od problem. We pretty much don't use any pretrained models. We'll use everything out of the box, I think later on as we progress, there are quite a few rugs that have happened. I think there's order of a few hundred thousand. Now, some of those may be direct forks of other scammy contracts. So I think maybe when you boil it down, there'll be a lot less.
00:31:24.870 - 00:32:04.658, Speaker A: But there's certainly, I think, enough data points. If you collect most of these rugs on chain, plus you can catch a lot of very normal contracts. Right. It's very easy for us to simulate a safe contract. We can fork open zeppelin, we can change the name or decimals or whatever, and we have something that we can say is concretely safe. It's more difficult for us to identify scams, but that being said, they're easy to identify retrospectively, because we can look at swap data on chain, we can look at even what the chart looks like. If the chart's going green only and it's up for ten minutes, and then people stop trading it, we can be sure that it's a honeypot, pretty much.
00:32:04.658 - 00:32:11.510, Speaker A: So we can retrospectively classify tokens, which will, of course, help us build a data set really quickly.
00:32:11.660 - 00:32:26.780, Speaker B: You're not synthesizing data at all. It's trying to find all these rugs. Then you're doing code base. Is it the same? Is it a rug? Maybe you could do some scraping of what rugs were there in the past and just grab them all. But would that even be enough, though?
00:32:28.430 - 00:33:01.320, Speaker A: I think there's always, as we've had anything, a security problem, right? As of anything in security, there's a race to zero, where the hackers get smarter over time and you have to continually innovate. I think, to be honest, though, most tokens that are launched, especially the scams, are launched by pretty much the same people. They're more like factories these days, of people that are launching tokens, and often that comes of a degree of laziness, like they'll fork an existing token, things like this, they aren't writing custom contracts every time.
00:33:02.010 - 00:33:05.110, Speaker B: Okay, interesting. So how are you doing this wallet linking?
00:33:05.850 - 00:33:46.734, Speaker A: That's a good question. A lot of this is really like, how do you query on chain data as quickly as possible? We store historic transfers from the genesis block on Ethereum mainnet up until basically live. So we'll catch all sorts of transfers that wallets have done in the past. This is all stored in a huge basic and SQL database really fast one that we can query. It's indexed by address. We can give it hundreds of addresses and it will give us hundreds of thousands of transfers very quickly. Once we've built that data set, we're able to fetch, of course, the holders of the token from our indexes.
00:33:46.734 - 00:34:26.162, Speaker A: We can swallowances of users and we will fetch the sort of top n holders, in this case 200. And then when we have those holders, we can query our transfer data for their transaction history. We'll give it 200 holders, it will give us 100,000 sort of transactions or transfers with a from and a to address and an action that was performed. And these are all, by the way, these are all decompiled, so they're quite interpretable, right? It's a transfer of tether between these two addresses or whatever. Once we get all of that, we start building a big directed graph. This is where it gets interesting. We take all that transfer data, we build a big sort of.
00:34:26.162 - 00:34:55.146, Speaker A: Each transfer will be a from and a two. We build a big directed graph. And then we look at that graph and we may fetch interesting wallets from that graph and request additional transfer data for those wallets. So we'll start like, I guess I call it like propagating this graph. We'll build a huge network where some of the wallets will be holders, some of the wallets won't be holders. Some of the wallets will be like bridges, some of them will be binance wallets, this kind of stuff.
00:34:55.248 - 00:34:58.106, Speaker B: Do you also account for how long they hold it?
00:34:58.128 - 00:35:01.354, Speaker A: For how long they held the token for?
00:35:01.472 - 00:35:32.614, Speaker B: Yeah, what I was thinking about is people launder or they're trying to get you off their tail, so they send it to a contract, for example. Then they may wait a couple weeks or days and maybe not even in a pattern just to make it seem like there's not something going on. There's multiple people interacting or even sending to an NFT platform and buying an NFT, selling it for whatever amount, pulling up for a giant price, then using the hacked money to buy it. So it's like switching, and it looks like an exchange of two people, something like this, which is like a common thing as well.
00:35:32.652 - 00:35:47.034, Speaker A: There's a lot of this. I'll call it like address washing. Right. You can also use a KYC or non KYC exchange, and that basically acts as a mixer. So there are things know, get around what we're trying to do. We do what we can, right. It's not possible to catch everything.
00:35:47.034 - 00:36:16.162, Speaker A: Things like if you buy a token, you send that token to a smart contract, and then you withdraw it eventually, later on to a different address or something. We'll catch all that stuff. We'll identify that smart contract is a holder. And if the wallet that's withdrawing it is also a holder, there'll be a connection there, and so we can catch that kind of stuff. It's very hard to make the tokens disappear. If it's an ERC 20, they have to go somewhere. Generally, if it's post purchase, we can catch it.
00:36:16.162 - 00:36:48.186, Speaker A: But if you start funding fresh wallets, it's a bit more difficult. We've got this big, huge graph, which is basically incomprehensible. It's thousands of holders, hundreds of thousands of transactions. It's a nightmare. It's not a user interface friendly. So what we do is we basically take this graph and we apply a load of graph reduction techniques onto it. We're interested in things like if you take every source node, so every node that sort of has a transfer out of it, and you look at that source node, where can you get to? And we build a mental image.
00:36:48.186 - 00:37:20.994, Speaker A: We do a lot of depth of search, and we try and find sort of ways of communicating within this graph between holders that are particularly interesting. And then once we've got those rough pathways, we reduce the graph into a reduced transfer set. And then that's something that we can visualize and we can explain. The Gachi's wallet is connected to this smart contract via this transfer. That smart contract then sent funds to Jake's wallet via this transfer. And then we've reduced this huge problem into what is actually the interesting information. Okay.
00:37:20.994 - 00:37:23.398, Speaker A: These two transfers connect these two wallets.
00:37:23.574 - 00:37:46.562, Speaker B: Yeah, that's the hardest thing. It's funding the wallet and trying to be anonymous. Where does it come from? It could be from a mixer, but that's very suspicious. It could be Kyc, but now you're doxed, so it's not anon anymore. I think the best way is from just getting paid some way from like a Dao, maybe use an a non to talk to them get paid from it. Now you have a funding and then you do whatever you can with that. That's probably the only way.
00:37:46.562 - 00:38:16.810, Speaker B: I think I saw a couple of years ago of some guy that deployed his MeV bot using a bundle, but he flash loaned, used that flash loan money to do Mev, and he obviously deployed a contract to do the MeV. But I don't know how he actually got, I think at the time they were paying for the bundle. I don't know how he actually had the initial gas to do it. They must have paid it for him. But yeah, funding a wallet is hard, I think. Unless obviously you don't care about being identified through a mixer or something like that.
00:38:16.880 - 00:38:52.822, Speaker A: There's a way that most people do it, which is actually quite funny. We actually did a bit of virality last week where we had a look at wallets that had won an Ido on this platform terminal. I don't know if you saw this. We were looking into. They did an Ido for this new token called Satoshi VM, and they claimed that ten wallets had won this Ido. So we did a deep dive. We had a look at these ten wallets, right? Five of them looked pretty normal, but then there was this group of sort of five wallets that were not connected, but they were all funded from MexC in like a five minute period on the 23 December last year.
00:38:52.822 - 00:39:13.850, Speaker A: Mexc, of course, is a non KYC exchange, so I think there's maybe a withdrawal limit. But if you wanted to get gas to do a sell in this case, so sell on uniswap, you could do it on Mexic without KYC. And it's practically impossible to link the wallets or say anything concretely, because it's a mega offshore exchange with no KYC.
00:39:13.930 - 00:39:23.082, Speaker B: Interesting. That sounds like the best way to start a hacking campaign. I imagine they would like flag that later on. It would become basically the same as a mixer.
00:39:23.146 - 00:39:43.266, Speaker A: It certainly looks sketchy on chain, and of course we can identify that. I think anyone that funds a wallet fresh from Mexc at this point. There aren't that many legitimate actors that are doing that that way. If it's funded from somewhere like Coinbase or binance, where it's a KYC requirement, generally it's a different story, but it's known which exchanges don't. Kyc.
00:39:43.378 - 00:39:56.086, Speaker B: Interesting. So how do you use this data to assist you? I assume you would just say, okay, they've rugged before, or they've done some sketchy stuff in the past. But how do you identify. They've done sketchy stuff automatically.
00:39:56.278 - 00:40:19.902, Speaker A: It's difficult. A lot of deployers are fresh funded. These guys are not that stupid. They generally fresh fund the deployer wallet. It's very difficult to link sort of token deployments. What they do is actually surprisingly a lot of these Memecoin teams, these scam teams, I don't believe a lot of them are actually solidity devs. So I think they generally just fork a contract.
00:40:19.902 - 00:40:41.590, Speaker A: They'll use that contract forever. Right? So our sort of original discussion earlier on about can you decompile a bytecode of a contract and find similar deployments on chain and ask how did they do? Did they ever honey pot, did they ever blacklist and scam? That's generally a very efficient way of identifying when there's an absence of extra information.
00:40:41.740 - 00:41:07.490, Speaker B: What kind of algorithm are you using to do that, though? Because it could be very funded from, let's say you have a set of addresses like the exchange mixes, you would say, okay, these addresses are direct, they're on a whitelist or something, or blacklist, whatever you want to say. And you could flag those, but then you have ones that are funded from other wallets. So I guess you have to go to that wallet and see the same thing. And how do you determine if they've done a scam as well before they've been a part of something?
00:41:07.640 - 00:42:01.954, Speaker A: It's extremely hard and there's a lot of noise, right? Of course, like with a token launch, there are a lot of maybe hundreds or thousands of addresses trading this token. So there's a lot of noise. So it's extremely difficult. I think there's an element of, because we're trying to build something that's useful for the average Joe retail trader, that we can't go too far into the weeds and we can't go into the hypotheticals, right? We generally say things that we can concretely stand behind because if we can perceived as like fud, right? If we randomly say there's this possibility, there's this sort of very non concrete, very hand wavy connection, it's very difficult for us to stand behind that. And there's of course a big reputational part of that statement, right? We're trying to build a brand around concretely securing things. And so if we can't make concrete statements, it's a little bit against what we're trying to do.
00:42:01.992 - 00:42:09.954, Speaker B: And you mentioned you use llms, right? Don't you think they aren't that good. Why don't you build your own model, custom model for it. Why do you use llms?
00:42:10.082 - 00:42:44.414, Speaker A: It's in progress, mainly because we wanted to POC. So if we use an out of the box model, we can poc a framework we've built very quickly. The other thing to say is that we don't really use llms in the standard way. So a lot of your listeners might have a lot of experience using things like GPT to ask, how do I write this piece of code? And it's a very general sort of question and answer. Where you give it a question, you get a reply. We're less interested in using those models for that kind of stuff. We tend to use the model to determine what to do next instead.
00:42:44.414 - 00:43:04.450, Speaker A: So we'll give it a load of information. We'll say, can you come up with a scenario? And then based on that scenario, we may derive a new custom query for a different model later on. So it's more of a Lego box framework, a plug and play framework, rather than giving a model a load of code at the beginning and saying, is this code vulnerable?
00:43:04.530 - 00:43:08.294, Speaker B: Which actually worked back in the day. I don't think it really works that well.
00:43:08.412 - 00:43:47.270, Speaker A: I don't think it'll work well anymore. I think the problem is as well, because you're talking about solidity and there's a lot of nuances to the EVM, right? There's a lot of things that are different about solidity versus JavaScript, for example, even though their syntax is very similar, the way the EVM works sort of means that there are special cases that have to be considered. It gets very specific, so it's tricky. You have to ask very specific queries and prompts, and you have to give very concrete, specific examples. If you try and throw loads of code in one query, it's just going to get confused and start talking about nonsense. So that's what we found anyway.
00:43:47.420 - 00:43:51.426, Speaker B: Interesting. So what is the next steps for you? What's in the pipeline?
00:43:51.618 - 00:44:15.294, Speaker A: Good question. So a lot of our development now is focused on expanding networks. So we're interested in putting a lot of our product on networks like Solana. We think the SVM is interesting, but again, it's a completely different beast. So we have to take a lot of what we've got on EVM and find equivalent ways of working on Solana, which is extremely difficult.
00:44:15.492 - 00:44:21.918, Speaker B: But also Solana, you can't actually grab the bytecode, at least I haven't been able to do. I can't find it.
00:44:22.004 - 00:44:53.450, Speaker A: I think it's. Yeah, it's extremely, like there's a sort of naivety that these things are very similar. And I think the reality is that we have to rewrite basically everything, not just because the block speed is infinitely quicker, but also because the structure of how you're querying the data is different. Right. I don't think we can just make simple calls to the node that run simulations. I think we have to either rewrite rust programs or we have to do something smart. So there's a whole load of research we're doing on what's the correct way to roadmap onto Solana, which is extremely difficult.
00:44:53.450 - 00:45:16.366, Speaker A: The other thing is, we're expanding a lot of our models. I alluded to our audit model being very MVP. I think there are lots of upgrades we're making to that. So these things we're keeping very close to our chest, but things that will help us make a lot more concrete, accurate statements about tokens will reduce costs and will improve generally the model and the interface. So there's a lot of product improvements that happen. Yeah.
00:45:16.388 - 00:45:34.306, Speaker B: Actually, getting to an MVP is the best thing you can do, even if it's not ideal, because then you can start iterating on it. That's the number one thing. Like, a lot of people don't get to that point, and it just never releases. It's good that you started like that. Obviously, lms aren't the way, but it's better than nothing. It's better to hit the ground running than to prepare to hit the ground running forever.
00:45:34.418 - 00:46:08.690, Speaker A: Yeah, I agree with that. I think for us, it was a case of, can we build something that's better than what people have at the moment? And we demonstrate the answer was yes. Now we're thinking, okay, how do we take that model? Maybe modify it in different places, maybe make it more specific to the EVM problem, maybe leverage the fact that we can run simulations midway through our analysis and improve it. Right. The idea is not to lean heavily on llms. The idea is to build a complete framework around different models that will help us come to a very holistic analysis.
00:46:09.030 - 00:46:32.646, Speaker B: Yeah, interesting. I'm excited to see where this goes. I mean, we need cybersecurity tools in this space to even progress. Otherwise, people won't put their money into crypto. It's just seen as this rug and scam and Ponzi place. So I think the more infrastructure we can put in definitely helps the entire ecosystem of getting to the point of the end goal, which is place traditional finance, or at least get a portion.
00:46:32.678 - 00:46:35.238, Speaker A: Of the pie, finally get some user adoption.
00:46:35.334 - 00:46:45.054, Speaker B: Yeah, man. Especially during a bull market, there's going to be tons of scams. Also, how do you make money off this? What's the kind of revenue model do you take like a fee? How does it work?
00:46:45.092 - 00:47:11.650, Speaker A: At the moment, it's free. So anyone who wants to sign up, anyone's listening can go to Twitter. We have a waitlist, but we send out invites very frequently. It's free to use. I think later on we'll explore potentially some sort of paid service. But I think the main thing is, because what we're doing is disrupting the way users tend to go about their due diligence when they trade tokens. We're interested in capturing the users and getting the product to somewhere where it's extremely useful.
00:47:11.650 - 00:47:32.774, Speaker A: And it's almost a staple in all of these guys toolkits. That's our aim first. We're not super revenue focused now simply because it's a very difficult problem to build something that is a complete system that does this. And I think in order to be successful, it has to be a complete system. Right. You can't have people paying for a service that makes a mistake every so often. It's very detrimental.
00:47:32.774 - 00:47:37.390, Speaker A: So that's the idea. We will keep it free for a while. At least. It's free for everyone.
00:47:37.460 - 00:48:04.502, Speaker B: Yeah, I think free is the way, because actually in the gaming industry with League of Legends, they did a free to play and that blew up. For example, Chattick BT is doing really well. The free model gets a lot of people in. There's no barriers to entry. And then you can add features that make it better and then that's a really good model, is what I've seen. And it's the same with games like free to play plus cosmetics done. There's no barrier to entry of $20, $50 to get the game like aa, and then it's just not that good.
00:48:04.502 - 00:48:16.682, Speaker B: They even add like cosmetics as well. It just doesn't make sense. And the free to play model is the best by far. Even in Fura. RPCs do this as well. If you want a faster thing or more, whatever, you just pay an extra. That's the model and it works.
00:48:16.682 - 00:48:28.490, Speaker B: At least they get to try it and that's the best way to get people in the door. But anyway, I'm very excited to see how this all progresses. I think a lot of people are making cool stuff. Maybe you even expand to Mev later down the track when it gets a bit more advanced.
00:48:28.650 - 00:48:36.794, Speaker A: We'll see. The MeV arena is like the harshest arena in the space. I think it's extremely od to be competitive in that arena.
00:48:36.842 - 00:48:52.870, Speaker B: I mean, if you get it going well enough, I'm sure a lot of people would have partner or use it for that. You could get a block strap model where everyone uses it, and if you don't, it kind of wrecked, at least for the lp slide stuff. But, yeah, man, it was great chatting to you once again, and I'm very excited to see what happens in the future. Thanks so much for jumping on.
00:48:52.940 - 00:48:54.546, Speaker A: Thank you for having me. It's been a pleasure.
00:48:54.658 - 00:49:00.214, Speaker B: Of course. And if anyone wants to check out the product, go to rug IO. Is that correct?
00:49:00.412 - 00:49:02.594, Speaker A: Rug AI, AI, AI.
00:49:02.642 - 00:49:03.110, Speaker B: My bad.
00:49:03.180 - 00:49:06.902, Speaker A: Yeah, we're on Twitter as well at rug underscore AI, so you can follow us there as well.
00:49:06.956 - 00:49:10.810, Speaker B: But until next time, I'm sure we'll come on again when it's fully fleshed out and whatnot.
00:49:10.890 - 00:49:13.198, Speaker A: Oh, yeah, I'd love to. Thank you for having me this time.
00:49:13.284 - 00:49:15.118, Speaker B: Of course. Till then, take care.
00:49:15.204 - 00:49:15.900, Speaker A: Cheers. Thank you.

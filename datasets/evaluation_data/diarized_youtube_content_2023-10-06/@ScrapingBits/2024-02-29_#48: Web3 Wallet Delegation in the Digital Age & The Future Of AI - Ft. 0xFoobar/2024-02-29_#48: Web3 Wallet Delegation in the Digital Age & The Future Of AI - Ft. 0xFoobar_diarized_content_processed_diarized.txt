00:00:00.250 - 00:00:24.074, Speaker A: Currency is the best incentive mechanism for cryptography advancement the world's ever seen. We're getting a decade's worth of cryptography every year now it seems, because the incentive structures are lined up that way, it does seem like we'll just see breakthrough after breakthrough. People didn't think that ZK compression was going to be possible until 2026. And now here we are, three different teams from three different orgs are launching.
00:00:24.202 - 00:00:51.066, Speaker B: Scraping bits is brought to you by the following sponsors. MeV protocol maximize your eth staking value with MeV eth exclusively on MeV IO and composable execute any intent on any chain. Coming soon to Mantis app. That's M-A-N-T-I-S-A-P. GMGM, everyone. My name's Degachi, the host of scraping bits, and today I'm with Fuba. How's it going, friend?
00:00:51.168 - 00:00:52.986, Speaker A: Hey, great, how are you doing?
00:00:53.088 - 00:01:01.870, Speaker B: Not too bad, not too bad. Working hard as usual. Crypto never stops. So here we are. Just for the people that don't know you, who are you and what do you do?
00:01:02.020 - 00:02:16.502, Speaker A: Yeah, my background is technical, I guess, like everybody else on the gotchi setup. So, studied math, worked as an ML researcher for several years in big tech, and then got pulled into crypto, specifically defi with the obsession with open source and the composability and powers that that enables a bunch of tiny upstarts be able to topple bigger incumbents with sheer openness and people building on them. And that got me interested in crypto of what happens if you put money in the mix, what happens if you add open state on top of that. So, did a lot of consulting work for blue chips, designed cross chain bridging structures that have held up even in the wake of the recent multichain collapses. And then that interest naturally turned towards nfTs, maybe less sophisticated, but far more actual interest, and people able to identify with and use these and what the proper evolution of that looks like. Because in a lot of ways NFTs are actually more powerful than fungible tokens, even if it can be an inventor to make them composed with each other. So I've built out several infrastructure pieces aiming towards that constructs an onchain programmable identity, like a crypto based power of attorney or role based access control.
00:02:16.502 - 00:02:22.870, Speaker A: Be able to assign specific rights or specific powers separating asset utility from asset security.
00:02:23.020 - 00:02:39.706, Speaker B: Yeah, quite interesting. And you built up this whole reputation based off your work as well. I wonder why you chose the open source route instead of just going closed source. Obviously, if you make proprietary software and you don't want to share it, and it can make a lot of money. Why go down the open source route instead of closed source?
00:02:39.818 - 00:03:18.310, Speaker A: Well, first, I think at least in the EVM culture, it's very hard to gain trust with a closed source approach. Other blockchains like Solana haven't quite developed that yet, but my current focus being delegate XYZ, that lets users people a cannot build on you. You have to own the entire stack. And that's an extremely competitive process. And it's also just surprising how few competitors there are in crypto at the moment. I can count on one hand the number of competent dev teams that I'm familiar with that are even working on anything adjacent. And so speed matters far more than getting a little too cloistered private.
00:03:18.310 - 00:03:23.238, Speaker A: Far more products fail because nobody hears about them than fail because they got copied.
00:03:23.334 - 00:03:52.918, Speaker B: I agree. I think even for startups, to get to the initial product is quite hard, like getting to an MVP state, and then after you get to the MVP state, getting it out there to where people actually know about it. I wonder what your process was for delegate getting the first MVP out and then spreading that information to the public and getting people to use it. Right now it secured over $600 million in assets with 20,000 users. So what were the early days like, and how did you really scale from there?
00:03:53.004 - 00:04:32.482, Speaker A: It started out with more of a problem statement than a solution. We had a month where timeline was nothing but board APAC after board APAC. So a lot of people were intimately familiar with that this was a problem. There was just a lot of confusion and waffling on somebody actually doing anything about it. The most common failure case is people build something that is too specific and it works for their use case, but can't be generalized or applied to anything else. And then others come along and they say, this doesn't work for me. And so they fork specific one into specific two that works for their use case, but literally nothing else.
00:04:32.482 - 00:05:48.234, Speaker A: But it's very hard for most people to think architecturally, they get stuck at it works or it doesn't, and they can't have many opinions beyond that. So there were a couple of working groups actually tackling this problem even before I entered the picture. Warm XYZ had been alive for nearly a year prior, but to be frank, nobody had the jutspot to actually do something about it. To make these hard architectural decisions, there are so many pieces like, should off chain signatures be allowed? Should this be incorporated into an ENS subdomain system? What sort of gren, should there be subdivision into utility types? If so, do those need to be hard coded and strong opinions on both sides of the aisle on all of these? So I think I was the first one to actually make the decisions and launch something with it, and then put a lot of bd integration effort behind it, which has been probably 95% of the success. It's good to have a generalizable tool, but if nobody knows about it, then it's not going to get used. So that follow through has been distinct from past stuff where I've launched it and had a little burst and then died, was determined to see this through and keep pushing. And that's paid off.
00:05:48.272 - 00:06:08.162, Speaker B: Yeah, obviously it's paid off. As you mentioned, you've done stuff in the past with different startups where small bursts and then died. So the real differential factor is making a network and making sure people actually want to use it. Or what was the biggest problem that you realized in the past projects that you fixed in the current ones?
00:06:08.296 - 00:07:11.538, Speaker A: I think those were targeting different domains, but the common thread was expecting the tech to speak for itself. And this is, I think, false humility. A lot of times people say, oh, I'm too bashful, I don't want to tell the world, what if I'm bragging? That might make other people feel bad, the world should just come and look and make their own determination. But I think that's actually more arrogant than it is humble. Because you're saying that not only is your work so good that it's useful, but it's so good that the average uninformed person in a couple of minutes will be able to immediately generalize and ideate how this applies to them. And that's the case that for, frankly, nothing, you can invent a room temperature superconductor and most people still won't know what that is or how they can use it. So I think that just generally that more aggressive push on, frankly, support working with teams, helping understand their problems, helping them integrate it, troubleshooting when things go wrong and whatnot.
00:07:11.634 - 00:07:34.126, Speaker B: Yeah. And to get this idea of what their problems were, were you asking the same questions to everyone, or did a couple of teams mention them and you gave like an MVP and did some feedback iterations? Or was it just kind of like you build your first iteration, then go reach out to people and be like, okay, does this work for you? Do you need something like this? And give them that MVP early access kind of stuff?
00:07:34.228 - 00:08:24.926, Speaker A: I think more organically than most, it was pretty clear that this was a problem so everybody was happy for the solution on that front. But then when it comes to how it plugs into their specific stack, some might be happy reading directly from the chain, others might want a rest API, a JavaScript SDK. Really easy ways to browse and see experiences visually. So plugging in all these holes of maybe supporting infra, the registry is unique in that it's an immutable smart contract. So you do have to prep the rocket ship and then launch and see if it blows up or not. In this case it didn't. There's still a lot of surrounding mission control that you can do of do we have comms on the thing? Are there barriers we can clear out of the air that assist this immutable piece? And then I've got natural connections with a lot of projects and people in the space.
00:08:24.926 - 00:08:38.238, Speaker A: So through that outreach, hey, we liked it. It can do a, b and c. Can it do d? Sometimes the answer is yes, sometimes no, sometimes maybe. And so figuring out how do you generalize this much broader suite of applications.
00:08:38.334 - 00:08:49.190, Speaker B: Got you. Yeah, it actually reminds me, delegate of account abstraction, is that correct? Because you have your cold wallet, then you connect it to a hot one. The hot one does the stuff for the cold wallet, right?
00:08:49.260 - 00:09:37.282, Speaker A: Yeah. Account abstraction seems to have been redefined to mean a very narrow interpretation of does it implement ERC 4337 or not? But that's frankly an inferior version. We should have shipped 30 74 and there are still a lot of strides that need to be made there. So yeah, it's trying to solve the problem that even with 4337, for example, there are a lot of apps that check storage and equals message sender, and 4337 will never work for those. There are other websites like OpeNC, even the biggest of the biggest, that require n blur, that require off chain signatures to verify a login. And that's impossible to do if there's no private key that exists. I mean, maybe you can do some sort of 1271 workaround, but that is often.
00:09:37.282 - 00:10:11.642, Speaker A: Then that's an edge case, on edge case, and it itself is often never supported. So the goal here is how do you make account abstraction work on eoas? Because everybody has an eoa and everybody will always have an eoa. If you can build something that works for them, then you can build something that works for everybody. So it's a bit of a unique approach. Others are trying to layer on complexity on complexity, and hope that the current simple model will disappear. But that's often not the case in product evolution. It's that medium complex models don't get replaced with even more complex models.
00:10:11.642 - 00:10:21.618, Speaker A: They stick around and people put up with them until people invent something simpler. And so we're going for the how do we make this as simple as possible? Direction of account abstraction makes sense.
00:10:21.704 - 00:11:03.198, Speaker B: I think simple is always the best solution until you reach a new kind of iteration, and you can obviously ship that. But I think getting the first iteration now, seeing how it interfaces with the world, how people are using it, whether they're actually using it or not, so you don't waste your time building the next version and new features, which I think a lot of people do. It's just kind of jam all the features into the first version. Either one, release it and nobody uses it, or just two, never actually release it because it's still trying to perfect it before it's even version one, which I've done before, and I'm learning now to have to get MVP out no matter what, even if it's super cursed code. As long as you get that first version out, it's fine.
00:11:03.284 - 00:11:17.570, Speaker A: Yeah. The great irony is that people, when the two feature rich version fails because of complexity, they then try to jam in even more features because the reason it failed was because it didn't have enough. The feedback loop gets broken in weird ways there.
00:11:17.640 - 00:11:33.178, Speaker B: Yeah, I think it's quite a hard task to think like as a technical founder. You're just like, I want to release this high end thing that nobody's ever seen before, and it's just kind of hard without feedback from a user. It's just really left in the dark and you're up to your own kind of bias perspective, I think.
00:11:33.264 - 00:12:00.798, Speaker A: Yeah, that's what surprises me. I think the best thing you can do for product development is just be support. You can't hire external support. You need to be talking to users and seeing if you can explain the solution to their problem, and then see if you can alleviate the problem before it even happens. But you have to know what's going on. You have to know the people who reach out are only a small microcosm of the broader set of people who get confused and leave and never talk to you. But it's valuable info regardless.
00:12:00.798 - 00:12:12.550, Speaker A: You just have to get some semblance of product market fit and then try to expand from there instead of making one grand cathedral that is missing a support and crumbles on first contact with the world.
00:12:12.620 - 00:12:25.658, Speaker B: Yeah, I agree. Just got to keep on adding the extension onto the side. Just see how it works, whether people enjoy it. So did you do any kind of pre releases, early access lists or was it just like ship? Let them try it, put out a.
00:12:25.664 - 00:12:50.078, Speaker A: Beta version or two. But this was mostly for feedback on the code style, I think. And can we get a front end up and running compared to actual delegates? Unique in that it's heavily b to b, or at least the registry is of that. It's not immediately useful on its own. It requires other people to trust it as a source of truth. And this is very much the exception. This is rare.
00:12:50.078 - 00:13:21.798, Speaker A: If I launch an NFT, then people can buy the NFT and they have the NFT and they can be immediately successful. They can look at it, they can go sell it, they can transfer it around, they don't need anybody else to do anything. But for delegate, if you delegate your wallet then that's kind of useless on launch day. There are no additional features offered you, no utilities, no projects have been integrated. So it's hard to get user feedback without that. We kind of had to throw it out there and then see how people responded and start working on the projects.
00:13:21.894 - 00:13:48.718, Speaker B: I think feedback is the number one thing in any startup because otherwise you're just kind of building blind in the dark and just praying they're going to use the feature. Yeah, it's just not too fun. Then you build like this feature after hours of work and just nobody cares. You got sick. All right, let's try again. And you mentioned you talked to a lot of people, they would want either on chain or a restful API. And now you have an API, right? You have to keep that up with maintenance costs.
00:13:48.718 - 00:13:53.698, Speaker B: I assume so, I guess. How do you even earn money for an open source tool and keep it lively?
00:13:53.794 - 00:14:47.474, Speaker A: We've been focused on growth to this point. The immediate answer is that we don't. But the long answer is once we've cemented the network effects here, it enables this entire design space of what you can build on top of it. And that is, I think very strongly and easily monetizable. So the biggest example is delegate market or liquid delegate, where users can delegate to themselves from a cold wallet to a hot wallet for example. But it's also more interesting to think about what does it look like if you could delegate out into the world? You can hold a board ape and you can let somebody else play the dookie dash or the heavy metal game on your behalf. This solves the paradox of high floor prices combined with the desire to expand the community by separating asset utility from asset ownership.
00:14:47.474 - 00:15:32.962, Speaker A: So on this, for example, you can create what are called delegate tokens. And then transfer around or even buy and sell the rights to access, the ability to access delegation rights. And so this, I think, is an entirely new take on the kind of tried and failed model of renting and lending. Renting failed because the collateral requirements are just too high to justify it. And you've got these messy liquidations and counterparty risk to worry about. Lending platforms, it seems, are always one motivated seller away from a complete liquidation cascade followed by bad debt. None of them are set it and forget it today, it's always set it and come back in a month and see what's still standing.
00:15:32.962 - 00:16:09.266, Speaker A: And compared to that, by building out a delegate registry that doesn't introduce this counterparty risk, you can actually have a robust primitive that we can deploy and go rip bandwinkle and come back in five years and it's still standing no matter what the economics have done in the meantime. So that's a far more interesting economic primitive to me. That's just one of several, but it's probably the more immediate that we're launching. So I think that crypto, frankly, is so money adjacent that the hard thing is more often to find product market fit than it is to make money. And so that's where we focused our efforts to date.
00:16:09.368 - 00:16:40.620, Speaker B: That makes sense. I remember during the bull run, you would see all these NFT lending platforms, and the main thing you would kind of see is just the diversity in assets was just so low. Maybe one asset of every NFT and then it would just cost a ridiculous amount to even access. Even then you might not even have wanted it, right? It would just be like some random NFT. You were collection for five e to rent it. And then it comes to the question, why would you even rent this to begin with for some random collection? So this does make sense.
00:16:40.930 - 00:17:36.586, Speaker A: The reason was that none of these platforms took a backwards compatible approach. They said, you can rent this asset if you opt into this new ERC 49 whatever standard. And of course none of the valuable ones did, because it's a no name standard made by a nobody for a platform with no adoption. And so really you have to mold yourself around what is the current flow. It's also very arrogant, not to say impossible, but you better have all your ducks in a row to imagine that you're going to re emit, to imagine that you're going to reshape the very basic things people are doing. This idea, I think it's a theme, at least in my work, of you should be backwards compatible with what people are doing today. And that means if people are trading board apes, then you should work on board apes.
00:17:36.586 - 00:17:56.450, Speaker A: And if they're using eoas, then you should be interoperable with eoas. It feels simple when you put it like that, but so many people design a new world without offering a bridge to it or a way for anyone to try it out, and so it dies from liquid defragmentation or a number of other reasons.
00:17:56.530 - 00:18:44.706, Speaker B: When you put it like that, of everybody's in this current consensus of what's being used and what was kind of like, I guess the social standard to someone coming into the game and being like, okay, everybody, let's shift over to my standard. Everybody come over here real quick. And so we can capture my vision without any, especially with any reputation, any network, any of that stuff. If you put it like that in an abstract sense, it just sounds ridiculous. First of all. So a backwards compatible product is definitely the way and then through that, I think you could probably branch into that, but without initially allowing ease of access into the product, it just doesn't make sense at all. I think it's true for any product as well.
00:18:44.706 - 00:19:53.820, Speaker B: I think, for example, a lot of the security tools, it's just getting them set up and running is quite user unfriendly to the user. You have to set up all the environment variables, run through this documentation that seems just very hard to manage or go through. And it's just like a massive time waster, especially for the target audience, which is startups, and they want to spend their time on building the backwards compatibility and just ease of access for the user is quite a big thing. I've noticed, at least in startups. Startups would just have horrible documentation or just very convoluted ways of even accessing the product, which I think ultimately kills it because you only got like one shot for a user, right? And then unless on Twitter you see a blow up and everybody's talking about it, chances are they're probably not going to come back. So it's very first impression heavy, and you kind of got to get it right, which is very brutal, but very much the reality of startup life.
00:19:55.870 - 00:20:50.380, Speaker A: That's where I think a weakness of mine, which is that I'm very impatient and judgmental, has actually turned into a strength here because I'm able to look at my own things with the same eyes that I do other people's and say, if I were just trying this out for the first time, this would be way too confusing and I would click through for 30 seconds and then give up a never return maybe only works on a certain personality type, but can you pass your own sniff test? Can be quite valuable. If somebody shot you this in a cold DM, what would you look at, what would you think and why and when? The inevitable answer is that I would get confused and not try the right thing, then that needs to be fixed first and foremost. Above all.
00:20:51.150 - 00:21:45.918, Speaker B: Yeah, I think if it was to be like a cold DM, or even just thinking of it as you are the user, and why would you use this? You obviously have to have a problem that's presented and then the solution and how to access that solution. So I think having that perspective as a founder or a technical founder is very invaluable, especially if you're building a startup from, you've experienced a problem firsthand, and that's why you're actually building it, which tends to be majority of the time. Then you kind of know what the user wants, because you were the user. Through that, you can kind of see what's missing and then build from that. Yeah, I wonder your thoughts on ZK then, and doing this kind of account extraction on ZK platforms. If you're looking to do it at all, maybe you've gone into trying to expand on a different startup now or. Yeah, I want to just go into that a little bit.
00:21:46.004 - 00:22:46.610, Speaker A: I think ZK is incredibly powerful tech. You've got two subcategories of it, the ZK compression, which is what people usually mean when they talk about ZK roll ups and ZK privacy, which is what people think they're talking about when they hear ZK roll up for the first time. And maybe there's a ZKVK roll up coined that terminology where you both get the compression and the privacy. But mostly today we have the competition with optimistic. So I love to see the experimentation. I think that ZK sync, for example, has native account abstraction, or they've killed the idea of altogether, and everything has to be a smart contract account. So it's definitely one approach, and I'm excited to see a lot of people tinkering with it, but I don't know if it's quite general purpose enough for a broad adoption yet, while people are working out these kinks.
00:22:46.610 - 00:23:35.938, Speaker A: Yeah, I think that ZK privacy is going to be absolutely critical. There are still some technical quirks to be worked out, but the battle is much more, I think, on the social layer of say, like would ethereum be willing to compromise, or would ethereum be willing to not compromise and fight some very difficult battles to get base layer privacy enabled by default. I do think that there are. Crypto is currency is the best incentive mechanism for cryptography advancement the world's ever seen. And so we're getting a decade's worth of cryptography every year now, it seems, because the incentive structures are lined up that way. So it does seem like we'll just see breakthrough after breakthrough. I mean, people didn't think that ZK compression was going to be possible until 2026.
00:23:35.938 - 00:23:51.094, Speaker A: And now here we are, three different teams from three different orgs have all launched, or are launching maybe closer to five to seven this year to accelerate on that front.
00:23:51.212 - 00:24:23.582, Speaker B: Yeah, ZK is. I personally agree. I think the future of cryptocurrency just makes sense. Just makes sense. It's just in the name, right? Like privacy, all that stuff. And I think this account abstraction would be very interesting in it, because then you have private transactions and you could just designate this wallet to send to your cold wallet anonymously, I guess, and just be very hard to track. Kind of like a tornado cache, I guess.
00:24:23.582 - 00:25:07.518, Speaker B: Every protocol basically becomes tornado cache in that sense, which is quite interesting. And I wonder, I'm really interested to see how the whole environment plays out. And I wonder if people would even start using Ethereum again. Maybe it would just become like this laundering platform, laundering network, especially the bridge, the bridges, those are like where all the major hacks come from. And if people are able to send anonymous transactions and not really track where it's going, then it just opens up the game to black hats, giving them more advantages. But I guess with every innovation there also comes like problems as well, to varying degrees. But overall, I'm pretty excited about that.
00:25:07.604 - 00:26:00.080, Speaker A: Yeah, it's more of just a reversion to the status quo, where the idea that every transaction is public by default is kind of absurd. We don't know nothing else in the financial system, not cash, not bank accounts, not credit cards, not wire transfers, has this property, and it's obvious why it's impossible to get anything done that way. Like plenty of legitimate use cases like I want to pay for gas and I want to pay for gas or groceries in a foreign country and not get mugged on the way out, are pretty critical. Institutional use cases, like being able to enter exit, a twap without massive front running that completely destroys anything they have. That's critical. So yeah, it'll be very curious to see how it all plays out.
00:26:00.610 - 00:26:06.798, Speaker B: And are you working on any more startups as well at the moment, or are you just completely focused on delegate?
00:26:06.894 - 00:26:08.398, Speaker A: No, focused on delegate.
00:26:08.494 - 00:26:50.346, Speaker B: Okay, got you. And you mentioned you were an ML researcher prior to web free. So I wonder, what are your kind of thoughts on the next kind of frontier of AI? A bit curve in the topics, but it's good to kind of talk about. I've been quite interested in this because AI has been making so many advances quite recently, and there's always the idea of programmers are going to get replaced quite soon, I mean, relative of what you think is soon, but it can be a reality. And personally I'm trying to hedge, I guess, my skills to the point where I'm not going to get completely rugged from AI.
00:26:50.458 - 00:26:54.714, Speaker A: How much time do you think you have before you're out on the streets? Obsolete?
00:26:54.842 - 00:27:15.894, Speaker B: Yeah, I think a lot of people I've talked to think it would happen by 2030, where programmers are just like obsolete. All the jobs are going to be like data scientists, phds, and then you just have designers, basically. Yeah. I wonder what your kind of take on that is, given your background in it.
00:27:16.092 - 00:28:12.554, Speaker A: Yeah, there are a couple of dimensions that we're advancing on concurrently. The most obvious one is just size. We're figuring out how to make better and better chips, and we're making more of them, and we're hooking them up on faster clusters, and we have well now scraped most of the data that there is to be scraped on the Internet before we enter doom loop of chat bots training on themselves. So you've got the size dimension that's probably most impressive at most public, and still seeing rapid breakthroughs on that front. GPT four enables new, entirely new startups and applications that you frankly couldn't do on GPT 3.5. And so these are the kinds of phase changes that technology enables. But we're seeing them in six months now instead of six years, so it's much more visceral and easy to read.
00:28:12.554 - 00:29:28.018, Speaker A: And then the other dimension is efficiency, throwing out very hand wavy numbers here, because it depends on a lot of other factors. But you can train a model of similar quality in 2023 that to the same performance and accuracy metrics that you would have needed ten x the parameters to do two three years ago. And that efficiency is improving. It's still dwarfed by model size scaling up, but it's very real. And so you concurrently have these monolithic, put a man on the moon, 100 million dollar projects that are getting funded at OpenAI and anthropic and many of the others, but you concurrently have the older models that are getting accessible to the point where you can run mid journey on a consumer Mac. Yeah, and we're going to see like ten x mid journey, a model that's far higher quality, be able to be run on a consumer Mac next year through even better efficiency and algorithmic improvements. We've got both.
00:29:28.018 - 00:30:18.114, Speaker A: There's, how do you train the quadrillion parameter model? But there's also how good of a model can you squeeze onto consumer hardware? And both these are advancing pretty fast. The limitation we seem to be having is just on interactive environments. So we've run out of data on a lot of. They have scraped the entire Internet, and Google scraped all the physical books a decade or two ago, and it turned out that that wasn't even that large. It was really high quality data, but there were only so many books lying around. And then they scraped all of Reddit, and Reddit has consumed far too many lives. So I think you get more text from Reddit than you get from the books, but lower quality.
00:30:18.114 - 00:31:19.602, Speaker A: That is the trade off. But then, yeah, they scraped the books. They scraped the ship posts, they scraped the rest of the Internet. And pre 2021 Internet is kind of like undersea non radiated steel that was protected from the nuclear fallout of World War II because they have to go in material science and engineering, they have to use that for certain measurement devices. And so shipwrecks are this source of pristine steel that basically underwater is the only place in the world you can go to protect yourself as you're trying to work with these things. And in a similar way, pre 2021 training data is the only data you can trust to not have been contaminated by AI, in a way. So the next breakthrough on that front is going to be how can we design interactive environments where machines can self learn or reinforcement learning? You see this in chess.
00:31:19.602 - 00:32:20.346, Speaker A: Like, the best human players are rated 2800, and the best computers are rated 36, 3700, which is logarithmic. So essentially, a computer can be a ruck down to Magnus Carlson and still pull off the victory, which is insane to think about. But you need to design. That's possible. If we trained computers solely on human trading data, then it would have been tough to get higher than 2800. I mean, maybe better compute and better memorization gets you to 29 or 29 or 30, but you can't go much beyond that because you're learning off fundamentally flawed data. So what's the equivalent of that for language? What's the equivalent of that for economics? Maybe blockchains on the latter point, but I think that designing proper reinforcement learning environments is going to be the next breakthrough that enables scaling up.
00:32:20.448 - 00:32:22.540, Speaker B: Yeah, that makes total sense where.
00:32:24.750 - 00:32:25.066, Speaker A: If.
00:32:25.088 - 00:32:40.830, Speaker B: It'S training on a human right, it only gets to a certain point where it's reached, I guess, the pinnacle of it. And then from there there's not really any advancements, but if it starts to train on itself, then I guess it can go way beyond a human's capability.
00:32:42.370 - 00:33:03.186, Speaker A: Yeah, it's like playing basketball with a kindergartner. Yeah, you can win, but there's only so much in your skill set that you can develop because frankly, you don't need that much skill to beat the kindergartner. You have to be challenged by someone at or near your level to continue improving.
00:33:03.298 - 00:33:50.534, Speaker B: Yeah. So then it just trains off itself after getting to that pinnacle, and then from there it can start up advancing. So I wonder, are you doing anything to kind of hedge yourself against AI? Or what do you really see for the future of, I guess, companies? I've been kind of told by people, their opinions, where they think there's going to be two type of companies, right? There's going to be the ones that use AI, whatever it is, to some degree or another. There's going to be the bankrupt companies, the companies that don't use AI, and they just get kind of like priced out from competition. So I guess what's kind of your perspective on that?
00:33:50.652 - 00:34:34.180, Speaker A: Yeah, it's a good question. I'm probably not as dystopian nor utopic as most of the online commentary out, so I don't think it's going to wreck us all, but I don't think it brings us immediate salvation either. There are definitely real improvements. Like Google has figured out a good way for AI to design better AI chips, which then more efficient layouts. They look nothing like the neatly structured grids that you see on modern circuit boards. They're all over the place. But when you run the actual computations, somehow it seems to just work out that way.
00:34:34.180 - 00:35:52.554, Speaker A: What are the scarce resources in a world where intelligence is commoditized? I'd say is capital and capital and influence. I don't know. It's not a huge problem, actually, because commoditize intelligence and the world becomes free. If you have an omnipotent little program at your fingertips and you can ask it to tell you how to farm apples for 1000 of the cost, and now the cost of an apple is a penny instead of a dollar. The idea of in a post scarcity world, you don't need to worry about how will I extract rent? Because nothing is scarce and so you're not making as much money, but nothing costs as much anymore. Yeah, I don't think that happens as smoothly as that extrapolation. We can see very clearly that we should be post scarcity on houses and we're not because there are a lot of bureaucratic barriers to enacting new ones.
00:35:52.554 - 00:36:44.014, Speaker A: And you got a lot of people who have put their life savings into their health, into their house, and so they would be sad to see the value of that go down. So they vote for people who will fight against that. And that probably happens in a much stronger manner if you get disruption of broader industries as well. So, yeah, it's tough to say, but I think it's more beneficial than harmful to the world. It used to be that humans used to be the best at a lot of things and now we're not. For example, humans used to be the best at farming. If you're a horse, you have no opposable thumbs and you can't really plant seeds or whatever.
00:36:44.014 - 00:37:16.374, Speaker A: And now humans are no longer best at farming machines and robots are far better at that. But that didn't destroy the economy or it didn't make a generation of farmers destitute. So there's that on a much broader scale. But the world is kind of better off now if you fast forward a century. And so I do wonder, is intelligence this uniquely human thing or is it just another thing to commoditize and then focus on what it is that actually makes us human?
00:37:16.492 - 00:37:17.720, Speaker B: Right. Yeah.
00:37:19.050 - 00:37:26.406, Speaker A: A lot of words to say. I'm not doing much except trying to win in the fields that I see is right for competition.
00:37:26.518 - 00:37:34.314, Speaker B: Yeah, that makes sense. Just focus on what you like and what you think is an opportunity. Until the great takeover, I mean, it's.
00:37:34.362 - 00:38:20.698, Speaker A: Still hard to get a decent front end site done for yourself. I'm all about this. Robots will take their programming jobs, but can you hurry up and get on with it already? I've got stuff to do and the robots don't know react yet. So I think it's a little bit of I will maybe I need to play around more with GPT four and it's already getting good at data science, but I'd welcome this even now. The scarce resource is not how fast can I type? It's can I think right? Can I have the right ideas and that higher level strategy. So I think that intermediation of low skill programming, that's a thing is just beneficial overall. My job is primarily have good ideas and assemble the right people to make it happen.
00:38:20.698 - 00:38:22.086, Speaker A: Everything else is noise.
00:38:22.198 - 00:39:00.410, Speaker B: Yeah. If you have the idea, then everything else is just a tool to get that idea into fruition. In this case, this artificial intelligence that you could do basically any programming, you still need to direct it in some way. It won't create everything that has been invented instantly. It needs some direction of. You have this idea, okay, how do I convey this in a way that it can execute it? Because that's exactly what you do with humans, right? You have an idea and you try to execute it the best way you can by conveying it to other people and formulating a strategy, a to do list of what needs to be done, how it interconnects, how to ship it, et cetera. So that's, I think, what would be replaced in due time.
00:39:00.410 - 00:39:05.946, Speaker B: But the underlying idea and direction doesn't seem like it will ever go away.
00:39:06.048 - 00:39:44.258, Speaker A: Yeah, I mean, blockchains are maybe an interesting view into this. They've completely abstracted away the need to maintain a consistent back end computing environment, at least on the simple stuff. You can deploy a smart contract and it'll just run forever, or it'll be available to be triggered forever on chain. And you don't have to say manage your own redundant Kubernetes cluster on a cross cloud AWS setup. Someone's doing it somewhere. But that's so guaranteed that it's basically done for you by magic. And that attracted me to crypto.
00:39:44.258 - 00:40:12.238, Speaker A: I can focus on the fun bits, and the infrast side is mostly done for me. Now, obviously, as you build more and more flex apps, there's more infra. You need the simple idea of deploy a smart contract and it runs autonomously for you forever. I think it gives insight. We didn't stop programming just because we had consistent execution environment. It lets you do more and faster iterations within that because half your work is done for you and so you can do a better job at the other half.
00:40:12.324 - 00:40:24.258, Speaker B: Yeah, I agree with that. When I was doing DAP development as well, I've never gone into databases or managing all this information. It was just always there, always accessible at any given time. So I was like, this is perfect.
00:40:24.344 - 00:40:39.470, Speaker A: And you can make your own database mirror. Maybe it gives you better latency or gets around some rate limits, but those are just implementation quirks, not fundamental features. If given the choice, all else equal, I'd rather query the chain than query my own database.
00:40:39.570 - 00:41:01.486, Speaker B: Same. And I guess for developers that are worried about AI, what would you do to hedge yourself the later we get in? Do you recommend people to learn about how to train their own models? Supervised, unsupervised learning debrienforcement learning. Do you recommend learning that at all, or just focusing on what you're doing now? Try and get that done. Only worry about it when it comes.
00:41:01.588 - 00:41:54.526, Speaker A: I'd say soak up as much as you can. The reason that I studied math originally was doing more of a standard CS path and switched to math was that it felt like a lot of the CS knowledge was specific and highly likely to become out of date. At the time, we were developing apps like Android apps in Java, which is not dead, but also not something I've touched nor wanted to touch in the last decade. I was kind of right. Whereas the math underpinning, how much of that have I used directly? I don't know, but it gives me the toolkit to be able to rapidly understand new developments and catch up on them. Like I might not know. If you train Bert, then you might not know exactly how GPT four works, but you have a foundation for what's a model tokenizer, what are bottlenecks, how do cluster sizes work, what are common failure modes, what do lost landscapes look like? And so on.
00:41:54.526 - 00:42:22.582, Speaker A: I think just soak up all you can as generalizable skills as you can. The longer something's been around and been useful, the more likely it is to continue sticking around and be useful. The newer something is, the more likely it is to be quickly replaced as well. So that's the great fall in the seam. Tulib's law of Lindy or something. I wouldn't worry about it too much. Just try to learn the foundations as best you can, and then working hard is rarely in.
00:42:22.716 - 00:43:02.514, Speaker B: Yeah, yeah, I agree. I think the generalized skill set is something I am quite into as well. If you're doing one thing, try and link it to as many things as possible. For example, doing automated exploit generation. Now it links into reverse engineering cybersecurity algorithms as well, and then it can also go into forward engineering or building stuff from scratch, a whole range of things. It came from Huff originally, which I did manually, and then branched into that, and then through this I could branch into AI, for example, all these different areas. So I agree, by trying to hit as many fields as possible within the thing you're doing, given it's relevant.
00:43:02.514 - 00:43:14.874, Speaker B: But I think if you have some kind of path to evolve in learning, then I think that's a terrific way of never being stagnant and always learning. Basically. I think if you stop learning, then that's a problem.
00:43:14.992 - 00:43:21.594, Speaker A: Yeah, definitely. There's always going to be new stuff, but the skills of learning how to learn never go out of date.
00:43:21.712 - 00:43:46.562, Speaker B: Yeah. I wonder what was your process of starting a delegate team and wearing all these hats? Developing, building a network as a BD, shipping it, getting the front end, back end, all this stuff, designing architecture. How did you really wear all these hats and manage it to the point where you are prioritizing as best as you possibly can and then scaling as well? If you were hiring people, what constitute a good hire and et cetera?
00:43:46.706 - 00:44:28.338, Speaker A: Very reluctantly, I'd say. My overarching goal and vision and intention is very simply to build things that people use that has a host of downstream benefits, raising, hiring, employeeing, monetization and so on. But it's also deeply satisfying if I think that's the purpose of work, is to build things that improve other people's lives and setups. I'm very focused on are people using this or not? If so, what do they love? If not, what do they want? What could be better? Everything around that does flow a bit naturally in terms of I built an interesting tech tool. It flopped because there was no BD. Learned from that. Now I'm building this new tech tool.
00:44:28.338 - 00:45:12.158, Speaker A: How can we absolutely crush on the bd side? Who are the right people to bring on board? And then similarly, we have 120 hours worth of tech work we need every week. I can't do it all myself. We move past the ego stage very quickly to the pragmatist stage. So what's the right approach there? I think personally I enjoy the actual fundamentals of strategy and tech more than I do in management. Overhead, so targeting, I think, higher skilled people than median, but also less overhead than median. I've made boatload of mistakes and learnings, and there's always new problems to be solved. But I think I really enjoy the end result.
00:45:12.158 - 00:45:15.022, Speaker A: And so whatever's necessary to get there, I'll do it.
00:45:15.076 - 00:45:34.566, Speaker B: Yeah, for sure. What are the main points? What makes someone a good bd versus a mediocre BD? And how can you really get to that next level and make these great connections and genuine connections as well, not just using each other, but actually being friends first of all, and then forming a great relationship where you can expand on.
00:45:34.668 - 00:46:31.382, Speaker A: Yeah, that's a tough one. It's very easy to see skill in the things that you've tried to be good at. If you're a college basketball player, you can recognize why the NBA stars are so great. Maybe a simpler example is I played a lot in middle and high school, and so I have strong appreciation when I can see that people are windmill dunking because I've tried or at least thought about what it would be like to try and didn't get there compared to. If I watch ice hockey, I've never really tried to be excellent there and so I can believe that they're good, but I don't really see or feel it compared to what the median ice hockey player is. In a similar way, I've done a lot of work on the tech side, front end, back end, solidity coding, and so I think I can pretty instantly see show me your work and I can know what quality dev you are. And so something like BD, I'm good at it myself, but it's a lot more fuzzy.
00:46:31.382 - 00:46:56.978, Speaker A: There's not quite a portfolio of work. People are often better at presenting themselves than they are at actually executing. So I think that pure experimentation, let's try somebody out and see how they do and see if that's what we need or not, is a decent way of trying to gain more of that intuition. It's a tough problem. I consider myself more lucky than good on that front, although hopefully I can turn some of the luck into figuring out how to repeat it.
00:46:57.064 - 00:47:09.246, Speaker B: Yeah, it's all like a numbers game of what's working and what's not working and focus on the things that work and then get more quantity of that than not try and just filter out what's good. But you can only really do that from experience.
00:47:09.368 - 00:47:14.310, Speaker A: Yeah. So you just got to be willing, I think, try stuff, succeed or fail, and then do it again.
00:47:14.380 - 00:47:36.654, Speaker B: Yeah. Which is the mantra for just engineering in general. I think for anything, really to achieve anything, you just got to fail, see why it failed, identify it, and then apply the solution to the next iteration. And then eventually, hopefully it'll all come into fruition at the end. Yeah. Thank you so much for jumping on and spending the time with me today. I've probably enjoyed it and have learned a lot as well.
00:47:36.654 - 00:47:48.190, Speaker B: I'm pretty keen to see the future of delegate, the whole space, and even just AI in general. I think this is going to be very interesting to see how it all plays out and even look back at this in the future. So once again, thank you for coming on.
00:47:48.260 - 00:47:52.218, Speaker A: Couldn't agree more. Thanks so much for inviting me and having me on. I really enjoyed the combo.
00:47:52.314 - 00:48:15.170, Speaker B: Great. And for anyone that wants to use FubaR, this tool, just go to delegate XYZ and then you'll be presented with the page and you can go interact with that. Secure your on chain identity and if you want to jump on the podcast or suggest anyone to jump on the podcast. Just dm me at scrapingbirds on Twitter and I'll look into it. Otherwise, thank you so much for coming on and we'll see you in the next episode.

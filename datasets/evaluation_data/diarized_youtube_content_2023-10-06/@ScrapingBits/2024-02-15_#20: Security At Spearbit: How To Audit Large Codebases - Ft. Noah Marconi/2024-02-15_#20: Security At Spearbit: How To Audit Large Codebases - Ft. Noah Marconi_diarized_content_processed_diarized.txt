00:00:00.170 - 00:00:16.480, Speaker A: If you could break down a protocol, well, how do you know that's an invariant? And if you can break it down into smaller tasks or smaller ways of reasoning about it, maybe those would tip you off. So you're not automating the invariants, you're automating the work to get there.
00:00:17.010 - 00:00:26.998, Speaker B: GM. GM everyone. My name is Dagashi, the host of scraping bits, and today I'm with a good friend of mine, Noah from, from spirit. How's it going, friend?
00:00:27.084 - 00:00:29.030, Speaker A: It's good. Thanks for having me.
00:00:29.100 - 00:00:34.678, Speaker B: Of course. Thanks for coming on. And just for context, for the people listening, who are you and what do you do?
00:00:34.764 - 00:00:55.034, Speaker A: Good question. I describe myself as a researcher and developer, and that's something I was a set of titles that I was using before I even got into crypto. Yeah, I can get into a bit of background there. I spent about a decade in a different industry. It was market research, consumer facing, understanding, that sort of thing. And I sat on both sides of that industry. I spent time as a research consultant.
00:00:55.034 - 00:01:19.254, Speaker A: So designing, analyzing data, presenting it back to clients, but also developing my own set of tools. It was really cool. That was my entry into software development. I realized that a ton of that job is repetitive, mundane, and really not the exciting or glamorous parts. So I just started writing code routines to take got off my plate, and that was a bit of a rabbit hole. As soon as I started, I never looked back.
00:01:19.292 - 00:01:26.182, Speaker B: How did you get into web three, then? Obviously you're of spivit now, but what did it kind of take for you to get into this position where you are now?
00:01:26.236 - 00:01:53.518, Speaker A: Yeah. So with that, following that path, just getting into software development, the company I worked for had a software development half. So they moved me off of the consulting side and put me onto the software side, realizing that what I'm building should go into SaaS products. It shouldn't just sit on my laptop and help me. They can monetize it and sell it. So that was fun for a bit. I got to do some interesting models, some preparation of client ready graphics at the click of a button.
00:01:53.518 - 00:02:25.274, Speaker A: But then it got a little mundane. We did the exciting things, and then we got into, we just need more varieties of bar graphs and that kind of thing. So it's less exciting, less innovative. So I moved on to a machine learning lab here in Canada, airmiles. They're a major travel reward program. So I worked in their machine learning lab, and machine learning feels like innovation, at least at the exec or board level. So at the time, this was 2017, there was that big wave of icos and a lot of other things going on.
00:02:25.274 - 00:02:50.606, Speaker A: So they said, you're our innovation lab. Why don't you guys take a minute and take a look at blockchain and tell us what it means for us. So, long story short, what it meant for them is not a lot. It's happening, it's a big deal. But taking air miles and dropping them on the blockchain is probably not the best idea. Really destroys your revenue model. But for me, I was bit by the bug.
00:02:50.606 - 00:03:19.142, Speaker A: It caught me in a way that I decided this is what I want to do with my life. So I ended up. I describe it as that cliche, you quit your job, jump in with both feet, and work full time in the industry. So that was my entry point in 2017. There were tons of opportunities. So I caught up with a startup. I met them at the first eth Waterloo, actually, and ended up moving full time with them doing a bit of smart contract development for hires.
00:03:19.142 - 00:04:07.702, Speaker A: So they had a consulting angle where they were helping other projects. There was a vc sending them deal flow, but then they also wanted to build their own identity based protocol, so on chain attestations, and then commercialize that in different ways or onboard different types of businesses or users. And unfortunately for me and them, the big raise for that initiative was set to happen just as the market crested. So prices started plummeting, they went into free fall, and that company ran out of money, and I was now suddenly independent. So being independent, I stuck with it. I didn't use that to crawl back to where I was before, but that was a pretty cool entry. It catapulted me into the industry full time and then set me on an interesting path.
00:04:07.702 - 00:04:07.946, Speaker A: Yeah.
00:04:07.968 - 00:04:15.758, Speaker B: So you started as basically like a developer freelancer, and then how did you basically get into security, I guess.
00:04:15.844 - 00:04:53.580, Speaker A: Yeah. So that happened pretty early on just because the paradigm is so different. And what got me into the industry was just how jarring and different developing in this ecosystem is. I mentioned the lab. When I was at the lab, what brought me in really was my boss was looking at a problem. We were trying to do an experiment. He said, why can't I have a random number? Like, just why? And he said it kind of like, not out of anger, it's kind of half jokingly, but he's like, I just want a random number and why can't I? But the answer to that is quite an interesting rabbit hole to go down to.
00:04:53.580 - 00:05:43.654, Speaker A: It's a very deterministic system that's fundamentally different from what we were working with before. And also the fact that when you launch code, it's immutable. It's essentially, it's etched in stone, for better or for worse, and going from where I was before, where throughout the day, you can update models, you can edit your code on the fly CI CD processes, you can be constantly integrating new code. So having the stance that all of those things that I'm used to doing and all of those fallback options that I have are gone. Stepping into this industry was quite jarring in the sense that you can't make mistakes. So day one, that's the premise, is you can't make mistakes because everything is permanent. And where do you go from there? So very early on, in the earliest development days, I started reading audits.
00:05:43.654 - 00:06:02.782, Speaker A: Open Zeppelin was publishing some things which were quite interesting. Going through Open Zeppelin's test suite was actually how I learned how to code. That was my tutorial of how to interact with these ecosystems. And then that, again, is a bit of a rabbit hole. Right? You start reading other people's audits. There was. What was it? The DAsp ten is a website.
00:06:02.782 - 00:06:38.300, Speaker A: It's still live, but it had the top ten vulnerabilities that you need to be aware of. And that's kind of a kicking off point of, these are the top ten. What else is going on? And then just going through the lifetime of this industry, there are certainly tons of incidents that happened before I got in. So 2017. It's not necessarily super early. So you have the history of the Dow hack reentrancy, and several other issues that people have run into. But we didn't have complex DFI, so there are some basic security principles that you can put into place.
00:06:38.300 - 00:07:35.674, Speaker A: Slither mithral. Some of those automated tools can do a really good job of detecting some very common things. And then as the level of complexity and the variety of attacks that pop up 2017 onward, you kind of get a front row seat into some of those. What was the big parody? One teaches everyone abruptly and in a way they'll never forget, how to watch out for proxies and delegate calls, uninitialized implementations, that sort of thing. So having that front row seat and seeing things unfold was one way, and then the other way is just never losing that fear that as a developer, you can make a mistake at any time, and it's not anything about any individual. People make mistakes at predictable rates. So knowing that and being a little humble and saying, I'm no different, how do I make sure that an error that I've made in developing doesn't actually make it through to production.
00:07:35.674 - 00:07:45.530, Speaker A: So feverishly picking up information, following what's going on, looking at what other people are doing, reading other reports, that front row seat along the way helps quite a bit.
00:07:45.620 - 00:08:21.226, Speaker B: Yeah, definitely. I think it's a pretty prevalent thing. And even now the whole ecosystem of tracking these hacks is a more established. So it's kind of easier to see what's happening with like rec news or just looking at past reports on multiple platforms. Audit firms, they try and do public publications and all that stuff. So I guess what was your kind of transition into preparing to join spearbit? Getting into it and then getting to this higher level, I guess the highest you can get now.
00:08:21.328 - 00:09:08.602, Speaker A: That's partly a function of where I was in my career when I first started speaking to them. I didn't realize at first, but I actually had an opportunity to join Spearbit. Day one, I had a contact reach out to me, former CTO of Oracleize, the oracle that everyone was using before Chainlink came out. We actually worked together at that first company I was talking about, the one doing the on chain attestations. But he reached out to me, told me a little bit about some of, he said a group of us, some security experts in the industry are getting together and they're doing something interesting. Do you want to talk about it? And at the time, I was headed down a path going a different direction. So I was focused on not doing security audits per se.
00:09:08.602 - 00:09:52.230, Speaker A: It was part of my focus just doing independent third party security audits for small protocols or people trying to get started without the 200 million dollar raises, those smaller level projects. But part and parcel with that was getting in earlier. So not necessarily evaluating code after it was done, but telling them internally at least. I've been around for a while, I've seen some things and I can write code, but what I can also do is I can help your developers to start approaching code the way I would approach it. Spearbit now calls that VCIO. I didn't have a word for it, but basically it was internal security expertise doing internal security audits. So it wouldn't necessarily count as a third party audit because I was hired, I was internal.
00:09:52.230 - 00:10:46.122, Speaker A: Even as a contractor, it would still be an internal code review. But I spent a lot of time doing those internal code reviews, teaching devs, basically reinstalling the fear that I have that if you make a mistake, it's all over. Bringing that into the organization and developing a culture around it of how do we stop these errors from getting through we know they'll happen, but how do we stop them and applying those practices? So I spent a lot of time doing that with a range of protocols, some of them friends of mine, especially when they're friends of yours, they'll introduce you to other people when the project is done. So I was doing good work at the time, and I turned my friend down and I said, no, I'm not interested. I'm pursuing this other path. And then what was it coming on? A year ago now, actually, I talked to him again, and it was just after I went to permissionless. And earlier when we chatted, you mentioned some of the cool stuff that nascent was doing.
00:10:46.122 - 00:11:32.442, Speaker A: And I ran into Josh from nascent, who was talking about the security checklist that Brock just put out, some of the cool things that they were doing, but also the involvement of developers who work with nascent are also doing audits with this group called Spearbit. And he explained in a little bit more detail what it means to those team members. And I didn't clue in right away. It took a week or two after coming home, and I was like, wait a minute. Everything he described that sounded super cool starts to rhyme quite a bit with what my friend was telling me. So I reached out to him and I said, by chance, that group you were talking about, were they spearbait? And he said, yeah, it's spearbit. Do you want in? His immediate question was, do you want to join? So it was my second chance, and a lot of times you don't get two chances in life.
00:11:32.442 - 00:12:08.920, Speaker A: So I jumped on it right away. I talked to them, went through a bit of a process. There's all the interviews they do, the technical screening they do, and based on the work I had done with this individual, it's d nice in spirit is his name. I'm not sure if he has his full name docs, but d nice, the referral from him, the work we had done. So he'd seen my code before, that sort of thing. Plus the process, they started me off as an LSR, and then they started me off as an LSR. It's kind of cool with Spearbit as well, because you're not just put as an LSR and they know we trust your ability, and we're going to throw you out there.
00:12:08.920 - 00:12:50.914, Speaker A: Spearbit has a philosophy that different auditors are going to scrutinize the code in different ways. So I've heard. Part of what they like is that some people come from the dev side, some come from strictly a security analysis, cybersecurity background, who will approach the code differently. So what they've done for almost every audit I've been on, at least initially, is there's always another LSR there. So it's really cool to see people in action. I don't know, maybe I should tweet about it or put a blog post together. But if you were to distill down, each person you work with does a number of things differently, but it's kind of cool because you can pick up one thing from each LSR you work with.
00:12:50.914 - 00:13:30.574, Speaker A: Some of it's not even technical, just their use of third party resources or linking to educational materials when they construct a ticket, that kind of thing. Yeah. Working with those other LSRs kind of reinforces that, at least maybe to them or maybe to myself, that, yeah, I can keep up with these guys and I'm contributing and finding vulnerabilities and doing really interesting things with spear. Yeah. So from my point of view, it's been super enjoyable. There's tons of people that I'd never get a chance to work with, although my friend brought me in the introductions that I've had just through, hey, there's somebody super intelligent. You get a chance to work with them.
00:13:30.574 - 00:13:40.626, Speaker A: There's a very cool protocol that you and a team of five in total are going to sift through and chat with each other about and scrutinize. It's a very cool and rewarding experience. Yeah.
00:13:40.648 - 00:14:27.522, Speaker B: I can imagine getting around a group of very intelligent people. You kind of bounce off each other and you can see what people do differently and then kind of incorporate that in your own way or adjust something that you've been doing that isn't as efficient. So it's always great to be around kind of who you want to be or the direction you're trying to get in. Even just in life in general, you're the average of the people you spend the most time with. And when you're surrounded by basically elites, you're obviously going to get to that caliber, and that's going to be your minimum or your benchmark. And the only way you get better is by being around people that can kind of sharpen your skills. It's like you can't be around, for example, wood if you're steel, because it's not going to sharpen you.
00:14:27.522 - 00:14:34.450, Speaker B: You need steel to sharpen steel or something stronger. I don't know if that's true, but you get the point.
00:14:34.600 - 00:14:37.560, Speaker A: Your audio cut out for a second, it went back and in.
00:14:38.090 - 00:14:54.298, Speaker B: Yeah. But I guess, how do you approach I guess finding bugs. Do you go for criticals only or is there kind of some other approach you do?
00:14:54.384 - 00:15:22.082, Speaker A: It's definitely different. Definitely a different approach than that. And I hope it's unique because I describe there's value in what I do because I'm not just going in for criticals, I am looking for criticals. So you're not missing that. But with the contest to badmouth other people, right. You're always badmouthing the competition, and I'll throw in a little criticism of them. That said, contests are great, and I always prefer if I do an audit, that a contest happens after.
00:15:22.082 - 00:15:50.060, Speaker A: It's that added layer of scrutiny that I think is super beneficial. I have no ego about other people looking at things I've audited. But with the contest, you get some people who do treat it like an audit and they go top to bottom. They're looking for everything they can find. You get these other people that show up and it's almost like a smash and grab. They hope they find some criticals, maybe they hit it from a weird angle and they hope they find some uniques and it's smash and grab. You quickly do it and then you quickly move on to something else.
00:15:50.060 - 00:16:24.774, Speaker A: That approach I definitely don't use, and not to say everyone who does contests do that. But if there's hundreds of people that show up for a contest, there's certainly some smash and grab behavior there. But what I do with an audit is something I see a lot of people do with Spearbit as well, is it's thorough and it's top to bottom. So what you might do just to get on the board, so to speak, you are working with a team. It's not a contest, but it always feels good to be the first one to find a high or first one to find a critical. So showing up, you do a quick scan. And if in the call, the kickoff call, they indicate there's some errors that they're a little concerned about.
00:16:24.774 - 00:17:04.482, Speaker A: It's always good to use the client's direction to focus your attention. You might spend the first day doing a quick overview, getting comfortable with the system, but also peeking at some of those areas where if there's an obvious critical, it might be in there that's more. Yeah, just comfort level, getting familiar with it, and also that motivation. It's like Vegas. You don't know when you're going to get a reward, but when you do, it feels really good. So you can go in very quickly to look for a critical, but if you don't see something immediately. I really like the top to bottom approach and I've seen a lot of auditors advocate this, where you just read through everything top to bottom.
00:17:04.482 - 00:18:06.066, Speaker A: So that initial scan, it's not just a wasted time hoping for a fun critical, it's to get familiar with. Where are the entry points? Where can I actually just start digging through this protocol? So you do a bit of a breadth search and this is something that I've started doing more of spending a little bit more time on the breadth and then you go depth, you find that main entry point or you have a few entry points, deposit withdrawal, if you're thinking of vaults and that sort of thing are common entry points. And then you pick one of them and then you follow every thread, every path through that. Where it gets difficult and a little distracting is if you say I want to read top to bottom, you're not necessarily reading a file top to bottom. You're following an entry point top to bottom. And it's a little frustrating because two days in, if you're going super thorough, you might still be on one file, but you've gone through 50% of several files within the system with the libraries and that sort of thing. But I find the breadth really helpful.
00:18:06.066 - 00:18:47.186, Speaker A: And to answer your question, what you're looking for is everything. There's style changes that you might want to mention. If they're not commenting bitwise operations, it's not just for me, but it's for other developers that would come in later. You want to comment those. And those are things that if this were a contest based environment, you wouldn't necessarily note those things. What you're also doing early on with your depth based search is for a lot of these protocols, especially if they're poorly documented, you're trying to get a feel for what the specification should be. So as far as the developer is concerned, what do they think this code base should be doing?
00:18:47.288 - 00:18:47.698, Speaker B: Right?
00:18:47.784 - 00:18:56.982, Speaker A: And that's a lot of the time you spend up front is getting comfortable with it's supposed to be doing these things. And as you go through, you'll catch errors. Go ahead.
00:18:57.116 - 00:19:06.490, Speaker B: Just to break that, but let's say they don't have any docs or unit tests or even comments. How do you kind of go about knowing what they're intending to do?
00:19:06.560 - 00:19:22.430, Speaker A: Yeah, and that's a big issue actually, is trying to infer what they intend to do. But if you think about it, if there's an if statement that says if it's not the owner, don't let them go through it's pretty obvious that that's their access control. If they're doing some calculations, earning yield, that kind of thing.
00:19:22.500 - 00:19:49.770, Speaker B: I guess in the business logic side, because obviously you don't want people to hit like critical function that modifies state that influences everything. For example, like only owner that modifier, you don't want them to modify the owner state. But I guess the most critical things you're trying to understand is the business logic. So I guess how do you learn what's intended versus what's there when you have no reference of what it's actually meant to be?
00:19:49.840 - 00:20:30.550, Speaker A: Yeah, it's an interesting question, because a lot of how I learn new frameworks, new languages is by reading other people's code. So I'm very comfortable diving into a code base and reading it and based on what I see in the code, get a feel for, oh, this is what the code does. And it's quite literal. So it's, the code is doing this, why would they want it to do this? And you start to infer what they intend throughout the protocol. It's not strictly a code read through that we're doing as well. We do get a kickoff call. So at a high level, if it's a yield based protocol, if it's an amm based protocol, we do get a lot of direction.
00:20:30.550 - 00:20:56.574, Speaker A: At a high level, what the protocol is supposed to be doing. It's just at the implementation level, it's very common. There's no docs, it's very common. There's very little comments to explain how they're intending the implementation to satisfy those high level objectives. So it's quite literal. If the code does certain things, you infer that, yeah, that was intentional, that it does this. But as you go through, you're also piecing together, should it be doing this.
00:20:56.574 - 00:21:38.314, Speaker A: And it's one of those things where it would be a lot easier if protocols would thoroughly document their code and thoroughly specify, here's what the system should do at a high level. So you get that bird's eye view, then you go in narrow c four model is one I really like. So you go system level, component level, and then you can go extremely low level to implementation. So function by function, and if you describe what the system does, what the component is supposed to do, how they should be interacting, and then the implementation, what each function should be doing. So you're almost into behavioral driven type descriptions. If they were to give us that up front, we could go through that in great detail. And then you almost skip ahead a little bit.
00:21:38.314 - 00:22:09.954, Speaker A: So you're not reading through to infer what the protocol should be doing. Sorry, you're not reading through to infer what the protocol wants to do. You actually get to compare and say, the dev told me in painstaking detail what it should do. So now I'm evaluating. Does it adhere to spec? So that's the lightest level audit you can do is adherence to spec. So we go through, we get familiar. We either have the developer tell us, and there are some incredibly well documented protocols I've seen, and there's some that have none.
00:22:09.954 - 00:22:48.722, Speaker A: So they either tell us or I have to infer what we think the developer was intending, and then we go through and we check adherence to spec. Does this code do what the specification says it should do, which you find a ton of errors, and that's one level of audit. And depending on the protocol, you can find quite a few issues and highlight a number of things just going over adherence to spec. But once you've done that and you've gone through top to bottom and you've had good coverage throughout the protocol on that, then it gets really interesting. I've heard other auditors describe this part as their favorite part. It's what they really enjoy. Zach was the one talking to me about this with his breadth based search.
00:22:48.722 - 00:23:24.814, Speaker A: So regardless of the order that he does it, he loves when he's in the territory where you can be creative and you can say, now that I understand the protocol, and we've gone over all the little things and we've gone over the minutiae, how can it break? What's wrong? And is there an issue with the spec? Is there a hole, or is there something else going on in the protocol? The other way I've heard it phrased, this is an appsec guy told me, now you're looking for bonus features, and if you can find a bonus feature, those tend to be high and they tend to be quite critical. They're not informational bonus features at that point.
00:23:24.932 - 00:24:32.562, Speaker B: Yeah, I think the core of auditing comes to game theory. I think obviously it's quite easy or simple, not easy to find data validity inputs like data input validity. If it's like reentrancy, access control, any of that stuff is quite surface level. But once you get into game theory, there's like a whole realm of possibilities and you're basically doing symbolic execution in your brain at that point for what's possible. For example, can I send a million tokens to this and then interact with it? What happens then? Or what if I use a different address? Or interact with it using a contract instead of an EOA. What happens then? So it becomes like this whole minefield of, okay, I guarantee the developers don't think of every single possible scenario because there's so many different ways someone can interact with contract in an unintended way on the developer side.
00:24:32.616 - 00:25:48.714, Speaker A: Yeah. And that point is so interesting, because some of the best feedback I've had from projects, when I review the protocol, they're not necessarily impressed with what you find, and it doesn't matter the severity of it, they're not necessarily impressed by it. The best feedback has been projects stating that they're impressed with that security minded approach, that different angle of looking at their protocol that they've never done before or they've never seen before. And it's really cool to watch them start to transition. And then as you discuss things with the client, they start adopting that adversarial approach where now they're getting creative about their protocol and not necessarily how the implementation should be working. What are those breadcrumbs that they've littered throughout their protocol? And can somebody pick those up and discover a vulnerability, which is very cool that that time you get to apply those types of approaches depending on the protocol too. There's some auditors, I've heard them advocate, just approach everything like a state machine and think of what are the valid states for the protocol? What are the entry points to allow state transitions, and what are the valid state transitions between states.
00:25:48.714 - 00:26:44.942, Speaker A: And for a very simple protocol, that's a very cool way of going about doing it. It gets really difficult with complex protocols that have, it's combinatorial, the sheer volume of states. If you were to try to formally prove some of these later protocols that are coming out, if you were to try to formally prove them, there are not enough atoms in the universe to compute the number of states you have available. So you do get some protocols where you just can't use those types of methods. But as much as possible, if you can try to, in your head, at least on paper or a mental model, reduce the protocol down to a simple state machine, then that's a point where you can really reason about the protocol in a different way than line by line, looking for boolean flipped issues and that kind of thing.
00:26:44.996 - 00:27:10.018, Speaker B: Having touched on that, how do you kind of approach these big systems with all these possible states and combinations? How do you kind of approach finding vulnerabilities, or at least the critical ones, when there is all these combinations and infinite time complexity over something like incredibly high, where you might not even have enough time to compute every single possibility. So I guess, what's your approach to doing that optimally?
00:27:10.114 - 00:27:40.954, Speaker A: Yeah, there's, I think, two main patterns that initial code review. You're looking for things you've seen before, logic errors. Sure, you might not have seen the specific logic error, but you're looking for that class of error. If there's a compound conditional, you're looking for basic errors there where it lets the wrong one through, or you're looking for things you've seen in the wild before. So I mentioned the parity incident. If somebody's doing something similar with a delegate call, it's not just parity, but those other ones you've seen before. You're looking for familiarity.
00:27:40.954 - 00:28:36.494, Speaker A: So that's one thing you do as you go through. What you're trying to do with the protocol as well is you're trying to internalize it and you're trying to get that internal mental model of what is this protocol? How does it work? And there's a lot of contracts, especially the larger protocols. There's a lot of contracts and components in the system interacting with each other, and you're trying to maintain a mental model. So when I'm talking about, I usually mention mental RAm, quite often you're uploading all this information into mental Ram. And once you have that done, so I'll skip ahead a little bit, forget about the how. Once you have that done, then you can take that creative adversarial approach and knowing how everything interacts together. What's a way I can slip in and do something unintended? So that's kind of your end goal, and there's a whole host of vulnerabilities or issues that you can uncover through doing that.
00:28:36.494 - 00:29:12.406, Speaker A: How you go about building that mental model, though, becomes quite difficult when you have a large protocol. Ram is a great metaphor because you only have so much. So if you're uploading information into mental RAm, you can quickly run out or you can start dropping old information as you upload the new information. So what I do is I try to assess protocol by protocol. How easy is it for me to just fit this whole thing into mental RAM? And a lot of the time you can great. You read through, you get into mental RAM, and then you switch modes into more of a creative mode. And that creative mode is not independent.
00:29:12.406 - 00:29:56.726, Speaker A: If you say, I'm going to follow a thread, you say that out loud. So you either talk to your team members or you message them in discord, saying, right now I'm scrutinizing this part of the protocol. Here are some of the things that I'm looking for. I haven't seen anything yet, but if that tips you off front, run me, jump ahead and tell me what you see. A lot of times what will happen is you won't find something, but you've gone far enough into a topic that somebody else says, I'm ahead of you. On a different file, there's a library that interacts in a weird way and you've highlighted something that I know now that there's an issue, so that collaboration is also part of it. You kind of share mental resources and then how to actually upload it into mental ram.
00:29:56.726 - 00:30:37.874, Speaker A: There's this little trick, and I learned this years ago, just being in the research field, people store information visually, and it's really weird. So if somebody's recounting something or if they're giving you directions and you're sitting in a room at the time, it's really strange how you'd use certain things in that room. When they point one direction, you visually look in that direction. That's the farm over there that I'm telling you that you need to go past before you go over here. People do store information visually. That's why data graphics are so prevalent. So if you can take this protocol and start visualizing aspects of it, you can then unload some of that mental storage and start storing that information visually.
00:30:37.874 - 00:31:26.440, Speaker A: And you can then get a bird's eye view of a larger protocol and scrutinize it in different ways. And there's little things like, just to name some specific things. I love doing sequence diagrams because like I said, one of the earliest things I do is I follow through an entry point. And if that entry point touches that one main file, maybe it's a router that then goes to the main implementation file. But then that main implementation file has a library for some shared calculations, and that shared calculation might at some point take information from an outside source. And now you're in four or five different contracts and you're trying to remember where everything is. And if you've skipped five files over the chances that you're going to remember the context from that first file, you're halfway through an if statement that had a call somewhere else.
00:31:26.440 - 00:32:15.174, Speaker A: The Ods of remembering that in excruciating detail are pretty low, but if you draw that out in the sequence diagram, it's just there. You've now stored that information visually and you can very quickly jump back and forth between several files. I've started augmenting them a little bit too. So not just the calls and the return values between libraries, contracts and internal external calls, not just those, but also adding in all of the storage reads and storage writes, you can start to find some interesting things. Maybe the way the state model was described, that certain things happen. You call this function, this state is updated. But when that state is updated within that complex rube Goldberg machine of a function, call could matter quite a bit.
00:32:15.174 - 00:32:49.026, Speaker A: And I've uncovered some interesting vulnerabilities, some mundane ones as well. One of the more mundane ones is just seeing a giant storage load for a whole array before a binary search occurs. To efficiently look up the value you need. But loading that whole thing into memory kind of defeated the purpose. And very quickly, on just a diagram to show where a state loaded, you can catch that sort of thing. And to your earlier question about how thorough are we just looking for criticals, you can also find some efficiencies. If you see the same function is called several times because you might need that same value.
00:32:49.026 - 00:33:34.350, Speaker A: So you do a quick little calculation, you need that value. Early on you do some additional things, and then just before you do your final wrap up, you might need that value again. But in a sequence diagram, you can very quickly see that this exact same calculation occurred three times in the course of a single function call. And then sifting through very quickly visually, when the state updates occur, you can see, well, the first two state hasn't changed. You could have cached that value. But on the third one, again very quickly, you can see that it's recalculated because state has changed. This isn't about auditing anymore, but you can see beautifully designed protocols when you look at them through that lens.
00:33:34.350 - 00:34:15.214, Speaker A: There was one that I, not the last audit I did, but the one before you go through. And you see there's a bit involved because it's a large system, several contracts are involved and functions are dancing across them. And you can see storage reads throughout. And if you color code them, I get these yellow storage reads throughout the entire diagram. And then nice and tidy at the end, you see three or four storage writes. So it's just in every function you look at, you can see that the developer was very careful and deliberate. They would read all the information they need, they would execute everything they need to execute and then prepare to do the write at the end.
00:34:15.214 - 00:34:31.534, Speaker A: And it was nice and tidy and it made it so much easier to reason about. Yeah. And that kind of thing comes through glaring. It's visually apparent that certain things are occurring throughout the protocol. There's something I don't do that I have seen other developers do. There's some new. Not developers, sorry, auditors.
00:34:31.534 - 00:35:27.714, Speaker A: There's a new auditor who was asking me the same question as like, how do you go about digesting a large protocol? And I told him, and then he showed me what he does, and this is something I think I might want to do myself the next time is he not only diagrams out the code. So it's not a sequence diagram, it's more like a flow diagram. So you start with your entry point, and he draws a little box, and here's the name of the box, and here's what it does, and then there's an arrow and another little box or rectangle to the next thing that occurs. But inside or attached to each of those boxes, he's copying and pasting a little screenshot of the code. So not only is he able to visualize the entire code base, and similar to a sequence diagram, he can get a bird's eye view of the system he's trying to understand. But right there, present front and center, is he can see the exact code lines responsible for each of those connections throughout. So I thought that one was pretty cool.
00:35:27.714 - 00:35:38.106, Speaker A: So all that to say, there's more than one ways to unload from mental ram and make use of that. It's basically using a hard drive, putting things in a visual storage format. Yeah.
00:35:38.128 - 00:36:00.842, Speaker B: And that's obviously a limitation of basically understanding and having a comprehensive understanding of a large protocol, even a small one, depends on how much ram you can take on. Right. How much ram you have in your brain. But I guess what are the main problems apart from that, that you kind of encounter as an auditor?
00:36:00.906 - 00:36:24.646, Speaker A: Yeah. So problems would be, I'm going to guess at which interpretation you want me to use for that one, because there's some problems with tools available. There's problems that people introduce. The biggest problem I run into when I look at a code base, though, is that there is not thorough test coverage. So I'm not doing audit contests. It's an audit quite literally top to bottom, sideways and backwards. So we're looking for everything.
00:36:24.646 - 00:37:01.666, Speaker A: But if you're just looking to isolate issues, if you do code coverage analysis and see that something's not covered thoroughly, if it doesn't have a minimum of 100% code coverage, then there's probably an error there. And half the time, the earliest criticals we find would be something that could have been caught in a unit test. So the biggest problems with code bases are lack of test coverage. And it's something easy to do. Unit test. The developer knows what the function intends to do, so just write some tests in there and do it. That's one of the biggest problems.
00:37:01.666 - 00:37:28.726, Speaker A: But then for me as an auditor, some of the problems that I would run into is what we were talking about before off the call is that the tools available to us are maturing, but they're not mature. So we have things like slither, which is incredible. I've started poking around with slither a little bit. Not just running detectors, but slither. It's kind of a cool play on words. It uses slithir. So it's that intermediate.
00:37:28.726 - 00:37:56.470, Speaker A: The IR stands for intermediate representation. Slither is a python based framework that wraps an intermediate representation of your code base. And they've built tons of detectors, but there's still tons more that could be developed. There's things that we as auditors know to look out for, but we don't necessarily have the tooling to find the common things just yet. So tooling is such a big issue. There's common things we can define. Sorry.
00:37:56.470 - 00:38:24.702, Speaker A: There's common things we can find using deterministic tools, such as write a detector in slither, or like, I'm doing all these sequence diagrams and I'm writing them in plant UML. Plant UML is kind of cool. You can write it about as fast as you can say it out loud. So this function calls this other function. You write that little line and then plant UML will diagram it out for you. Slither could be doing that for us. Played around with it at a hackathon, too.
00:38:24.702 - 00:38:56.470, Speaker A: So tooling on the visualization side could definitely be improved. And likewise, on the fuzzing, you're venturing toward formal analysis. You're not there. It's just fuzzing. But you're using some of the same terms, like, you're using the word invariant, you're looking for protocol level invariants, and then you're setting out to fuzz them. Not necessarily prove that this invariant does or does not occur. Some of the fuzzing tools, I really do like them, but they still make you do a lot of the work.
00:38:56.470 - 00:39:26.180, Speaker A: And it's not necessarily a bad thing, putting the auditor in the driver's seat, but it is work, and it takes time. And if there were more helpers out there and some simple helpers. Right. If you think of foundry, foundry does a really good job of coming up with inputs for fuzzing. There's some randomization, but they also look at addresses referenced or used within the system. Which is they've put some thought into it. So it's not just a dumb, I see you talking, but I can't hear anything.
00:39:27.110 - 00:39:30.194, Speaker B: I just said some intelligence is in.
00:39:30.232 - 00:40:07.722, Speaker A: Foundry rep. Yeah, there's some intelligence built in, which is kind of useful, but it's not complete. You do have to explain how to handle each function, the super basic one where you have to approve before you transfer from that kind of thing. But if there's a complex protocol, if there is a multi transaction or multi call vulnerability in there, you do have to step foundry through some of those things of how to properly hit the protocol with valid function calls. Echidna would do a little bit better with it. And echidna is super cool in the sense that it uses Harvey Fuzzer. Under the hood.
00:40:07.722 - 00:40:43.062, Speaker A: You still write invariants quite similar to how you'd write them in foundry. But then Echidna will start exploring it and if it gets a revert, not necessarily a failure, so you can set it to fail on revert or fail on assert. If it gets a revert, it will remember, hey, that didn't work. But if it finds valid paths through the code, it will start remembering them and start trying to find deeper valid paths through the code. So that's super useful, but it's still not to the level that you'll cover everything possible. You can't be asleep at the wheel. You need to think a little bit about how you approach the use of those fuzzers.
00:40:43.062 - 00:41:28.200, Speaker A: I'd love it if there were better ways, better ways to speed run through some of that. Right. Auditors are time bound periods of time where professionals will scrutinize your code base. If you can remove any of the tasks or jobs that an auditor is doing, that same amount of time can be spent going deeper in other directions or save you a bit of money on doing two weeks instead of three. But, yeah, if the tooling out there could do things that I'm currently doing by hand or auditors are doing by hand, that would certainly save us some time. So, biggest problem, in the sense that you're wasting time and money, you're having a human do something a machine could do. If only there were somebody to write an analysis program that would get the code to do those things.
00:41:28.200 - 00:41:55.674, Speaker A: There's also some things that are coming out. You see a 16 z publishing some helpful resources. There's the 46, 26 vaults. They've put a set of property tests out there. So it's things like that as well. If there's common standards or common patterns that projects are using a 16 z, putting out that set of prop tests. When you show up as an auditor and you're testing a new vault, you no longer have to start from scratch.
00:41:55.674 - 00:42:28.454, Speaker A: You can start from that base point, modify it as needed if the vault is doing new and unique things. But at least every vault you look at, you have a standard starting point. So the tooling to analyze vaults just got better because they put that out. So I'm optimistic. It is a problem that we have maturing, not mature tool sets, but it's cool that they are maturing. And every month that goes by, we get something new to make our life a little bit better, or to make our ability to button down and secure someone else's protocol that much stronger.
00:42:28.502 - 00:42:57.250, Speaker B: And I wonder how you approach protocols that obviously don't have docs and unit tests. How do you approach setting up a proof of concept that's executable for something? So you would obviously have to set up the context initialization of this contract to make it all work. So I guess, how do you approach that? And I guess if there was a way to automate it, which I think is incredibly difficult, how would you kind of approach that from a theoretical point of view?
00:42:57.320 - 00:43:19.226, Speaker A: Very cool question. I didn't expect that. But yeah, it's super interesting topic. Because what I do today is not what I'd like to do tomorrow, figuratively. In the future, I'll describe what I want to do, but today, what I do. If they don't have a test suite set up and they don't have proper documentation, and I believe I found something, if it's basic, I'll just describe it. Like, if this Boolean slips the wrong way, I'll just describe it.
00:43:19.226 - 00:43:50.146, Speaker A: That's not a big deal. But they're just an example of, there's that first deposit inflation bug. There's a protocol that thought they circumvented it, but two transactions later, anything extra left in the protocol actually goes to the balance. So it's hidden the fact that this bug is still present, even though they took other steps to defend against it. So with that, I'd write a proof of concept. Now, these guys did have a test suite, so I didn't have to write it from scratch. But for the ones that I would need to write it from scratch, I'd still do something basic.
00:43:50.146 - 00:44:24.642, Speaker A: In foundry, you have to do your own deploy your environment, set up environment in the sense if there's three contracts it touches, you have to deploy and initialize each of those. So it's a bit of a pain if they haven't done that legwork for you. And then as simply as possible, jump straight ahead to the issue at hand. So if it's something small, you only write that small part. You're not writing an exhaustive test suite. But in the future there are other tools and techniques, tools in the sense of processes and strategies you can apply. We don't have the technical tools, so nobody's written this framework yet.
00:44:24.642 - 00:45:25.826, Speaker A: But if you think of what people do in the outside world, so outside of crypto with behavioral driven development, if you've heard of Gerkin based specs and cucumber as the suite that will help you test through it, you have that language of given when then. So given is what I was just describing, given the protocols deployed, would be you have that baseline starting point. There are certain things that need to have occurred first, and you can also add, and so given something was deployed, given a deposit took place, you can set up your initial environment set up. So this is my starting state, and then when, now you're talking about those state transitions. So those entry points into the protocol. When an attacker executes this function, and when they execute this function, typically when you're testing, it's your assertion, then this is exactly what I expect to happen, or this is exactly what I expect to be impossible to happen. So that's some of the language that you would use in and around it.
00:45:25.826 - 00:46:43.198, Speaker A: But if you start mapping that back to tools, what cucumber will do is if you write a Gerkin based spec, cucumber has different language support, but a lot of developers in this industry are familiar with typescript, so it will generate some placeholder functions in typescript for you to initialize that given and then to initialize that when, and then to not initialize, but execute that when, and to execute that then. And that's kind of neat. And if you follow that train of thought where you can describe a scenario, and I think that's what they're called, actually, they're Gerkin based scenarios, maybe they're specs, but either way you hear in the agile world Ux scenarios being described, if you translate what you say out loud or write down in Gerkin based terms, it's a very short leap to start writing code that does it. And the other really cool thing is that if you write that given and that's a function, and then later on you have another scenario that requires that same given, you can make use of it multiple times over. And cucumber does a really good job of that. So if there's overlap between thens or givens or whens, it won't make you rewrite them every time. And that's what we do today.
00:46:43.198 - 00:47:20.954, Speaker A: Every time we'll have one set of setup. But then if we need to execute several other functions, we tend to drop them into a before a block, or we'll just copy paste. You see a lot of test suites with copy paste in there. So if we were to start adopting in the future how we should be doing these things, even if it's not Gerkin, doing something Gerkin and cucumber like would be incredibly powerful. Powerful in the sense that it just stops me from doing the same thing twice. If there's the same setup I need to do, I put that in the given, and then I access that everywhere else need. And there's another parallel I can give you, too.
00:47:20.954 - 00:48:01.974, Speaker A: This came out of informal systems, so I'm not involved with just I saw that they published this, and it's incredibly cool. They have a repo or a project they call Adamcraft. And what Adamcraft does is it combines formal specifications. So they're not talking Gerkin, they're talking TLA plus. So if you define a protocol in TLA plus, TLA plus itself will just formally verify that the protocol is sound. So all of your invariants that you wrote into the protocol, it will prove or disprove them, but then your implementation is a separate consideration. So how do you handle that? So, they've taken it a step further, where all of the state transitions, I think all of them.
00:48:01.974 - 00:49:02.938, Speaker A: So it will be quite exhaustive. Hundreds of thousands of state transitions will be generated, and they have a specification around it. So it's a very specific JSON data format that they will produce into a directory of all the state transitions and then separate from that, just like I described with what cucumber and Gerkin are doing, they have a python based protocol where for your initialization and your state transitions, you have to write a function that will execute each state transition, and they'll give you a little placeholder to do it. But then once you've written those placeholders for each state transition and the initialization that needs to occur, it will just rifle through hundreds of thousands, if not millions, of state transitions to prove that your implementation adheres to the specification. So, like, boom. Mind blowing capability. And that's something we are not doing at all on the Ethereum or EVM side, but they're applying that to Cosmos based systems now.
00:49:02.938 - 00:49:31.170, Speaker A: So, long answer, but, yeah, that's kind of where I'd like to be in the future, rather than just doing. Quick little proof of concept. When I've manually discovered something, I'd love it if I could start saying, I think the protocol should do this, and then very quickly piping in those state transitions or those conditions, and then start rifling through more deterministic based state transitions rather than those randomized fuzz based transitions.
00:49:31.590 - 00:49:57.322, Speaker B: Yeah. So you're basically going for an example. You could start at like, I like to use uniswap as an example. So if you're trying to do a swap, you're basically going from the function and reverting down or going backwards until you get to a point where it succeeds. So I guess in that sense, it would be like, okay, so you need a pool. Okay, we don't have a pool initialized. How do we get a pool? Well, you create it.
00:49:57.322 - 00:50:21.262, Speaker B: And how do you create it? You need two different tokens. So how do you get these two different tokens? You deploy these tokens with the names, decimals, and whatever, and then you can use those addresses and then create the pool. And then with the pool, you can finally go back and it finally works. And then that's how you kind of initialize. Yeah. Quite interesting. And I think the tooling in the space is quite in its infancy.
00:50:21.262 - 00:50:33.650, Speaker B: Nobody's really tried to do anything beyond what others have done. I know. It's kind of just like, I guess, mutations of what's existing to certain degrees.
00:50:33.730 - 00:50:57.534, Speaker A: Yeah. We've had some big introductions of tool sets, but then, yeah, like you said, there's not a cascade of innovation coming through, at least for us on the developer side, where we have some set tools, and we do get new ones quite often, but they're not groundbreaking or earth shatteringly different. They're incremental improvements on the set we have.
00:50:57.732 - 00:51:30.730, Speaker B: Yeah. And I wonder what, on the topic of automation, I wonder how you would automate invariance and testing, like unit test invariance, which would be even harder than the previous question. But if that's capable, if something is capable of doing that, then it'll be quite powerful. So, I guess, how do you set up your invariance? Obviously, you read the business logic, you know the protocol. So you just set up like that what it's meant to do. But I guess, from an outsider's point of view, how do you kind of determine what an invariant is? So like an auditor's point of view.
00:51:30.800 - 00:52:16.278, Speaker A: Yeah. So you're in some interesting territory with the automation of it. That's a very good question, because we don't at all automate the generation of invariants. I've heard somebody try to go, they might talk about it separately, so I don't want to reveal all of it, but I've heard somebody suggest like going backwards from code to something like TLA plus and almost generating your spec off the code, where the spec is just quite literally a formal description of what your implementation is currently actually doing. They said they went down a path and it didn't quite work out where they were able to generate all of it. And I would guess that the sticking point would be the invariance. What should this code not be allowed to do? Yeah, it's quite interesting.
00:52:16.278 - 00:53:34.160, Speaker A: Quite an interesting question. You could infer some of it, so if there's any requirementstatements, required statements or anything in there, you could make some inferences based on that. And then I'm not super familiar with pyrometer, but I did see some of the initial headlines and descriptions about it where you're talking about what bounds is this function capable of ever seeing in the first place? And then you can start to infer some things off of that. But if you go pure, pure automation, pure naive based automation, you're just describing the world as it is, not necessarily describing the world as it could or should not be. I find within variance, we don't have clients necessarily tell us about them. Every once in a while you'll have somebody who's gone through and they've written a test suite with foundry based fuzzing, and they have a directory full of invariants that you can take a look at and understand their perspective, but a lot of them don't have it. So kind of the process that you'd go through without automation is during your read through, you identify some areas where, if this works well, and if certain categories or classes of vulnerabilities don't exist, then this invariant here must hold.
00:53:34.160 - 00:53:36.770, Speaker A: But that's based on human input.
00:53:37.350 - 00:53:37.954, Speaker B: Exactly.
00:53:38.072 - 00:53:55.650, Speaker A: Interesting. I'm going to guess you've thought about this or asked somebody about it before. Yeah. What are some directions that people have started to go to automatically generate them? Because for me it's 100% human driven task.
00:53:55.730 - 00:54:23.694, Speaker B: Exactly. I think it's very difficult, first of all, but I think a common way now is using AI, because AI is very good at pattern matching and understanding things in an automated way. So let's say you had some docs of, let's say, public contests scope, so it could probably reason about this and create invariance from that. Whereas if you didn't have AI. That's near impossible, I think.
00:54:23.812 - 00:54:30.654, Speaker A: Right. Because that pattern is quite far away from the input data. You do need something big to be able to make that leap.
00:54:30.702 - 00:54:33.858, Speaker B: Yeah. To basically understand and reason about.
00:54:34.024 - 00:55:27.330, Speaker A: That's really cool. That's a line of thinking that I might need to head down in the future, because I think with some of these protocols, one of the more important things you can do is develop invariants and prove or disprove that they hold. This isn't me. You might have heard it described in great detail, but like I mentioned, every auditor you meet or work with, there's, like, one thing you run away with and you internalize. When I was talking to Natalie at trail of bits, she described their audit lifecycle, and what I loved about it and instantly changed my worldview is that she said they spend the first little bit of time manually going through the code, which everyone's going to say the same thing. I described me manually going through the code. But while they do it, they pick up invariants, and then midpoint through the audit, they host a call with the client, and they go through in great detail, discussing all of the invariants they found and having the client confirm or reject.
00:55:27.330 - 00:55:48.582, Speaker A: No, that's not how we want it to behave. And then have the client add in as well. Once you start seeing what a third party is coming up with, you being intimate with the protocol might pick out other things. But that's a process that she highlighted. She highlighted it like, yeah, that's how everyone does audits. But, yeah, I told her right away. That's incredible.
00:55:48.582 - 00:56:31.100, Speaker A: That's quite different from what I do, because a lot of auditors will just run with the project, and if they find an error, they'll highlight it to the client early so they can correct it. But this is saying, we found nothing wrong. This is what we think the protocol should do, and these are the invariants that we've come up with that the protocol should adhere to. What are your thoughts on that? And that's a really cool touch point, but, yeah, it's so far away from getting language models involved to, say, based on the nap spec, based on the documentation, the markdown files you dropped in here are the rules. The protocol cannot. If there's no yields, you cannot get more than you put into the vault. If there is yields, there's a yield based calculation that you should be looking at.
00:56:31.100 - 00:56:39.834, Speaker A: There's those types of invariants that are centered around that high level understanding rather than line by line. There's something up. Yeah.
00:56:39.872 - 00:57:11.478, Speaker B: I think that's a very unique approach that I don't think anybody does. I haven't heard that in anybody, any kind of firm doing it, because that's basically just comparing, say, oh, okay, this invariant. We found these invariants. Is this true? Is this what's meant to happen? And obviously it's just a yes or no answer. If it's yes, then it's all good. If it's no, you found a bug quite easy, and it kind of accelerates the whole process, I think, actually, and I think that's strategy people should start picking up.
00:57:11.564 - 00:57:23.562, Speaker A: And even better, they can say, there's this other thing that you didn't think of. I didn't think of it either. As a client, you just made me think of it with these invariants you put in front of me. So that client engagement is very cool.
00:57:23.616 - 00:57:24.540, Speaker B: Yeah, for sure.
00:57:25.150 - 00:57:58.006, Speaker A: That's one of the strongest skill sets I've picked up from working with other people, just watching how they work with each other. There are certain techniques that you pick up where they discuss the things that they haven't found yet, which is the opposite of what I used to do when I was doing solo audits. I'd find something, then I'd talk to someone about it. But you shift that up and do it earlier, before you even test the invariance. You say, these are the invariants I think we should be looking at. When I'm manually reviewing, this is the area where I think they could have made a mistake. I'm going to follow that thread for a little bit.
00:57:58.006 - 00:58:25.242, Speaker A: Telling somebody before you've even headed down that path, the client could say, there's nothing there, because what you described is missing. This other thing that three layers down, we've accounted for. So it makes your time quite efficient, but it also expands. Trading ideas back and forth like that causes them to think of other things and tip you off in a way you never would have had. Yeah. So the automation. I'm a huge fan of automation.
00:58:25.242 - 00:59:28.382, Speaker A: Like why I was coding to begin with was taking things that everyone in the industry, as in, believed should have been done by a human. Because if you sell hours for a living, you want to tell everyone that the only way to do this is to sell more hours. So I'm a huge proponent of automation in the security research side, there's a lot of strides done in detection of things that are really easy to detect. So describing a pattern, excruciating detail. But, yeah, you're getting at which pattern should we even be looking for in the first place like pulling out those invariants is quite a big deal, I guess, outside of the language models. This isn't a prescriptive answer of how to automatically detect those, but I've learned over the year, about years, the only thing I've learned over the years about automation that might make it possible when it wasn't possible before is just breaking down the problem into smaller and smaller chunks. So maybe the big goal is discovering invariance, but what does that mean? And then you go a little bit deeper, and we're talking about the ranges.
00:59:28.382 - 00:59:59.162, Speaker A: Well, the invariant means that this one can't overflow would be one invariant if you dig down, and that's the invariant. My goal was to discover invariants, and the end goal would be certain specific examples. But if you can break down a protocol, well, how do you know that's an invariant? And if you can break it down into smaller tasks or smaller ways of reasoning about it, maybe those would tip you off. So you're not automating the invariance, you're automating the work to get there.
00:59:59.296 - 01:00:08.970, Speaker B: Yeah, exactly. Even just identifying them would be a massive leap in time efficiency and even code coverage.
01:00:09.050 - 01:00:34.870, Speaker A: And there's other things like the a 16, the z of, we have certain primitives that everyone's using, so we can manually go through and pre bake some of those invariants. So those pre baked patterns would certainly be the low hanging fruit. The easiest way to start automating some of this is just pre baking it for crypto primitives. But you're talking about some pretty cool territory where the machine discovers them.
01:00:35.020 - 01:00:44.220, Speaker B: Exactly. Yeah, I think it'll be very interesting in the future to see what happens. And we'll probably have another chat on it later on.
01:00:44.990 - 01:00:57.280, Speaker A: Right? Yeah, I'd love to see, actually, what other people think about that one, because no one's asked me that question before. But if you're working in that territory, too, some of what you'd come up with.
01:00:57.890 - 01:01:30.280, Speaker B: Yeah, the reason I asked is because you manually do it. And I think for any kind of automation, you need to know how to manually do it effectively, and then you can think of, I guess, deep algorithms to kind of do it for you, because there is obviously a way of thinking that allows you to. You're given a set amount of information, and then you have a specific way of reasoning about it. That's an algorithm. So if you break it down into smaller pieces, you can probably create that in an automated way.
01:01:31.050 - 01:02:13.222, Speaker A: That is true. It's so funny, because now I'm in an industry where now I'm on the side where I can't fathom how to automate some of this. But where I started was everyone else was saying that, and I was telling them, no, it's easy. You just do this. And one of the ways you can do it. So I don't think algorithmically, when I need to automate something, I think diagrammatically, think like a pipeline. And this is common in machine learning and data processing and whatever else, you get those directed asylic graphs where you have some input data as a node, and then that feeds into something else that might clean your data, feeds into something different, that might reformat it, and then you do these other things, you might split it and then regroup later on.
01:02:13.222 - 01:02:29.974, Speaker A: But if you break things down into pipelines, what is your auditor pipeline for? Coming up with an invariant. And if you can say it out loud. Yeah. You might be able to write some code around parts of it. Yeah. That's quite interesting. I don't think of auditing as pipelines.
01:02:29.974 - 01:02:37.486, Speaker A: I think of it. Yeah. We spend a lot of time manually reviewing. We need to know the spec, we need to confirm adherence to spec, and then we do some other stuff.
01:02:37.668 - 01:02:38.634, Speaker B: Yeah, it's all mindful.
01:02:38.682 - 01:02:46.866, Speaker A: Yeah. If you broke it down, minute pipeline like you're hinting at, that's fertile ground for some cool things.
01:02:47.048 - 01:03:05.174, Speaker B: Yeah. It'd be super interesting to see how things play out in the future and how the whole kind of field evolves. But until then, it's been a pleasure talking, finally chatting in person, hearing each other's voices. I learned a lot.
01:03:05.212 - 01:03:05.714, Speaker A: Likewise.
01:03:05.762 - 01:03:17.980, Speaker B: And it's sparked a lot of, I guess, ideas, hearing it from your point of view. And hopefully I've sparked some ideas in yours and the listeners, of course. But, yeah. Thank you so much for jumping on.
01:03:18.590 - 01:03:27.310, Speaker A: Likewise. I appreciate you having me. I enjoyed the great discussion. I don't know, I always love talking to people that make you think about stuff.
01:03:27.460 - 01:03:28.302, Speaker B: Yeah, it's amazing.
01:03:28.356 - 01:03:31.214, Speaker A: Yeah. Reframing certain things I thought about differently before.
01:03:31.332 - 01:03:43.040, Speaker B: Yeah, exactly. That's the whole idea of this. Have a deep conversations and spark new ideas and see how everything evolves from there. But, yeah. Until next time, everyone.
01:03:44.610 - 01:03:50.260, Speaker A: Bye. Our channel.

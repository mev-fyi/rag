00:00:02.040 - 00:00:43.116, Speaker A: Ladies and gentlemen, welcome to the Blockcrunch podcast, the go to podcast for investors and builders in crypto. And before we get started, just a reminder for you guys out there. The Blockcrunch podcast is intended for informational purposes only. Neither the host nor its guests or licensed financial advisors, and nothing discussed should be construed as financial advice. Views held by blockcrest guests are their own, and sponsorship messages do not constitute financial advice or endorsement. With that out of the way, let's jump right in. Today's episode is brought to you by Protocol Labs, the guys behind Filecoin.
00:00:43.116 - 00:00:52.784, Speaker A: And with us today is Colin Efrin from Filecoin, who can tell us a little bit more about what's one interesting way that people have used Filecoin to build. So, Colin, take it away.
00:00:53.204 - 00:00:53.540, Speaker B: Yeah.
00:00:53.572 - 00:01:33.074, Speaker C: File coin has been used to store hundreds of petabytes of web two data, helping web3 cross the chasm into what I would argue, mass adoption. Developers have built onboarding platforms like singularity, SQL and file drive, and more to mimic s three interfaces and onboard datasets like genocide testimonials from the Shoah Foundation, New York government public datasets, and large scientific data sets from universities like UC Berkeley. Within web3, Balcony has been able to provide redundancy for our top NFT platforms like Magic Eden OpenSea, storing a large fraction of web3's nfts and secure gaming assets through Unreal Engine five.
00:01:33.694 - 00:02:22.054, Speaker A: Hello there. Now, before I move on, I'd love to thank the hundreds of you who have subscribed to blockchain, because with your support, I've been able to share my real thoughts on specific projects that I don't usually share on interviews in a format that I enjoy more, which is bi weekly written posts. We've also been able to offer exclusive AMA's, sharing my investment frameworks, interactable models, and breaking down important trends before they become big. Now, we even had Elon Musk comment on one of our threads recently. So if you haven't already, head on over to theblockcrunch.com VIP and you can access dozens of hours of research for what you'd spend on a coffee a day, right? Hey, everybody, welcome back to another episode of the Blockcrunch podcast. Now, in the recent months, there has been a lot of talks about crypto and AI, and not just about how AI is going to change the world, but how it's already doing.
00:02:22.054 - 00:03:28.398, Speaker A: So with things like mid journey, creating detailed images from simple text prompts to chat GBT, replacing pretty much any type of office job that you can imagine. And what is interesting to me is that the implication on web3 is really unknown at this point, because anecdotally we've seen many investors and founders maybe pivot away from crypto to full on AI. And even in a recent hearing, we have SEC chairman Gary Gensler mentioned that the future of american innovation does not lie in crypto, but in AI. So at the same time, as an investor, I'm also seeing quite a lot of new companies find synergies between Web three and AI, from companies that use leftover mining hardware to do distributed computation for large AI models, to projects that use chat GPT to curry for on chain details. So I'm really curious to see what is hype and what is real. So today, to discuss all of this, I'm really stoked to once again have my friend and crypto OG, who many of you on the show are familiar with, Jake Brookman, who is the founder CEO of Coinfund, which is one of the very first crypto funds that's ever been investing since 2015. And Jake is also known to be extremely early to large trends.
00:03:28.398 - 00:03:55.364, Speaker A: I think that on the two times that he has been on the show before, we've talked about tokens, we've talked about nfts, and now a lot of his focus seems to be on AI and crypto. So this is a really broad, spanning episode where we're going to cover many potential ways that crypto and AI can overlap. And this will be part, one of a five part series where we talk to founders building at the edge of, of AI and web3 as well. So if you'd like to not be left behind, be sure to subscribe. And I'm really excited to have Jake on. So, Jake, welcome once again, man.
00:03:56.104 - 00:04:10.724, Speaker B: Hi, Jason. Thank you so much for having me. And I think this is, as we just talked about before we started recording, this is my third time on this podcast, and I don't think I've ever been on a podcast three times before.
00:04:11.064 - 00:04:35.203, Speaker A: Yeah, I'm super honored. And every time I think we were talking about this before we started recording, every time you come on, it's on the precipice of a big trend. And now, obviously, a lot of the mental energy for everybody in any circle remotely related to tech is focused on AI. And I know you've been paying attention to this space way before the crypto bro started getting excited about it, but I'm just curious, what was your first foray into AI? How did you get interested in it?
00:04:35.583 - 00:05:42.232, Speaker B: Yeah, thank you? Well, I studied math and computer science, and I've always been following AI to some extent extracurricularly. And I don't. I've never, like, worked in AI, or I've never done any sort of serious engineering or development in AI, but I know enough math to understand neural networks and how they work, and I've taken an interest in reading some of the papers that come out. Ten years ago, I actually had the beginnings of an AI startup that I was doing with my friend Nikolai, where we were using machine learning to try to understand brain data. And we actually got pretty far before the manufacturer decided to pull the device that we were using, and we went on to do other things. But I've had this sort of general interest in AI for a long time, and I would say, as it relates to crypto, there's a few touch points. I think, to some extent, web3 and AI are starting to very slowly converge over time.
00:05:42.232 - 00:06:36.144, Speaker B: And you can see this like, you could see the clues that were always there. It always has been right. For example, Ahmad Mustaki, the CEO of Stability AI, was actually a crypto founder back in 2017. If you read one of the most famous papers in AI, which is the paper on transformers, which came out in 2017, and transformers, of course, are the things that underlie all of these big foundation models that we're seeing make an impact these days. The last author on that paper from Google is a gentleman named Ilya Polisuchin, who, of course, is the CEO of near protocol. And then I would say there's other ways that AI and web3 have been converging in terms of people. But as far as coin fund is concerned, we made our first investment in this area.
00:06:36.144 - 00:07:12.574, Speaker B: It was about March of 2022, and that was a company called Jensen AI. They were working on how do we do neural network training, but using a decentralized network for compute? So this is a problem, which is very interesting in terms of opening up training, but it was also something that potentially makes that process harder. Not a lot of people were paying attention to that area at that time. But now, as we'll discuss shortly, it's starting to look a lot more relevant.
00:07:12.874 - 00:07:49.784, Speaker A: Yeah. And appreciate the introduction to Jensen as well. We're going to bring them onto the show to talk about that, which I think is a breath of fresh air in crypto when so many of the projects have looked so similar in the past few years. So I'm really excited to do that. And it seems like there was some sort of an inflection point where everybody started talking about AI in the past few months. And I think that was the launch of chat GPT when everybody and their moms started using AI. And I'm curious, in your journey in crypto since 2015, did you notice similar moments in crypto where everybody suddenly started talking about crypto? And what were the similarities or maybe differences between how crypto took off and how AI is currently taking off?
00:07:50.204 - 00:08:45.024, Speaker B: Things like chat GPT. So in other words, llMs, LLM assistants, let's put it that way, are just an incredible application layer demonstration of AI. And the reason it's so incredible is that you can explain the value proposition of something like a chat GPT in about 2 seconds, and you can have that person that you're explaining it to use the product in about 1 second, in fact. So one of the most amazing technology moments for me was the other day I showed up at my grandma's house. My grandma is about 86 years old and she only speaks Russian, but she knows how to use an iPad. And I said, grandma, here, like, talk to chat GPT and ask it some questions that you want to know the answer to. And she was able to use the product immediately.
00:08:45.024 - 00:09:48.684, Speaker B: I have a photo of her on Twitter doing it. This to me, is just such an amazing configuration, and it's supported by the results, right? Like the results are that chat GPT is the most adopted, the fastest adopted software or product software products, right? That has ever been like, they reached 100 million users, like almost instantly. And one of the reasons I think that happened is just because the low friction of how people can use it, we cannot say the same thing about crypto. Crypto has, you know, it's not, generally speaking, a product level or product layer technology. It's an infrastructural technology. It takes a lot more to get it installed, it takes a lot more to use it, and there's a lot more frictions for people who are trying to use products on top. So I attribute some of the success to that, this application layer approach.
00:09:48.684 - 00:10:15.574, Speaker B: But what we've also seen is that the discourse around AI has gone completely and utterly mainstream over the last year in ways that even crypto has not. So, yes, I think we're definitely in a moment where we've turned a corner as far as AI and the product market, so to speak, and in terms of progress around, you know, this technology.
00:10:16.634 - 00:11:10.762, Speaker A: Yeah. And it's interesting you bring that up, because for me, I think crypto felt like it had a mainstream moment with NFTs when they took off and they were so easy to understand. Obviously, it's still not as easy to buy an NFT as it is to just spin up chat GP to kind of use it. But I did feel like there was a similar moment of, you know, when crypto hit mainstream, but it didn't seem to have as much broad based kind of implications in terms of just its impact on multiple industries. I remember when NFTs first took, we were talking about how artists might be the biggest industry that gets disrupted, whereas when chat GPT was taking off, everybody was like, wow, we don't need bankers anymore, we don't need doctors, we don't need analysts. So it's interesting to see just how it's easy to underestimate just how big AI got in such a short amount of time. And that kind of reminds me of a quote that Peter Thiel once said in an interview.
00:11:10.762 - 00:11:29.564, Speaker A: He said that AI is authoritarian because he's referencing the large scale data mining that's characteristic of maybe like surveillance regimes. And then he said, crypto, on the other hand, is libertarian. And the implication is that the two are often at odds. So do you agree with that, as an investor who looks at both AI things and crypto things?
00:11:30.104 - 00:12:36.494, Speaker B: Well, I actually, I might diverge from that in the sense that our whole thesis on AI, web3, is really about turning AI into just as an open space, as crypto and blockchain and decentralization technologies. If I can talk about our thesis for just a second. Well, there's a pipeline that creates AI models. That pipeline starts with data sets. It starts with people, it starts with the academic progress around what a model should be doing and what it's computing. It then goes on to actually put those models into reality through compute, through training, and then make those models available through another form of compute called inference, meaning you're getting the outputs from the model and then the commercialization of those outputs in an API and some product. Now, that whole pipeline today is essentially owned by a handful of large technology companies.
00:12:36.494 - 00:14:19.654, Speaker B: And the whole idea of web3 times AI, the way that I see it in my mind, is that we can use web3 primitives to make that pipeline open and democratized. Like, I don't think we want to be in a world where OpenAI, by virtue of having the largest, best performing, most popular model, sucks in everybody's data. Like more data than Google, right? Or like, I just don't think we want to live in that world. I think the web3 vision is that data is self sovereign, maybe like libertarian in a sense, like it's a libertarian view, and we have enough technology, or we can create enough technology to turn that pipeline upside down, invert it, and enable people to not only govern and control the data that goes into these models, but to actually own models ourselves and have that innovation be open. I want to say, like one other thing about it, about the closedness of these things. There's a lot of extremely talented people in the world right now at OpenAI, at Google, at Facebook, at Microsoft, elsewhere who are working on the cutting edge of these models of llms. But I think, like most of these people, the way they think about it is once we get the results, once we get to the next stage of intelligence, we're going to protect the world from the dangers of this technology by keeping it closed, by working on alignment.
00:14:19.654 - 00:15:39.902, Speaker B: But when people say this, what they really mean, or what the consequence of what they're saying is, is that they believe that alignment can be solved by a small number of private people within their corporation, maybe like 50 people working at OpenAI or 100 people working at Google. But to me, the real solution for alignment lies when you open up these models and you allow thousands of people to work in alignment. You allow tens of thousands of people to work in alignment. And we've seen this in the market like we've seen open models, from stability AI, like stable diffusion. And more recently, they've also launched an open LLM competitor, which is currently in the process of being trained. And it's also going to go up to 175 billion parameters, just like GPT-3 but what we've seen around the open models is that the innovation just goes just in flex exponentially. People have created more innovations in the public open source domain around these existing models than the big proprietary tech companies have created internally.
00:15:39.902 - 00:16:11.494, Speaker B: And we also know that because the other day a memo from Google leaked, you know, saying this to this effect, that most of the innovation is currently coming from open source. And so the world that I want to see, and as an investor, I am a, I'm someone who is trying to make this world more probable with my capital. The world that I want to see is a world where AI is also libertarian. Right? It's, it's open, it has self sovereign data, and it is publicly governed in an effective way.
00:16:11.914 - 00:16:51.084, Speaker A: Yeah, I love the way that you put it in terms of using capital to push to increase the probability of the world that you want to see. And I do want to double click on that thesis you mentioned, because you guys put out this post September of last year, before everybody started using chat GPT. And this post, I recommend everyone checking it out. It's called open neural networks, the intersection of AI and web3. And in the post, you make the case that not only should compute be run on decentralized networks for AI, but then it will be. There's basically tailwinds pushing compute for AI onto decentralized networks. Can you recap the thesis there, like you've kind of talked about why you think it should be decentralized? What are the tailwinds that will make it decentralized?
00:16:51.784 - 00:19:06.854, Speaker B: Well, it's kind of a non trivial and quite contrarian thesis in the sense that, again, if you look at the people who are making the cutting edge progress, the last thing that they care about is my network that I'm computing this on decentralized. The top of mind things that these folks care about is, can I squeeze a little bit more compute out of the Amazon supercomputer that I'm using or the Microsoft data Center cluster, GPU cluster that I'm using? Because the reality, Jason, is that the reason that GPT four works as well as it does is because of this, like, underlying, you know, kind of like convenient convergence of the properties of transformers and the fact that they're parallelizable in that model, the computations are parallelizable and the fact that those computations are tractable by GPU's. So we've created some optimization gains on how much we can compute, almost not because we have a lot of compute, although we do have a lot of compute, but those optimizations happen because of the model, the way that the model is constructed and the things that it's doing. And so we're just reaching into this scale right now, where the models have become pretty intelligent, they can process language very coherently, and they even have really cool abilities, like theory of mind, or the ability to logically reason through a math problem or something like that. So we're just starting upon that innovation curve, and it has been enabled because we've reached into that scale painfully, as much as we could. Now, if I then go to these people and I say, hey, can you replace your data center with a decentralized network? What's going to happen is we're going to lose some of the hardware optimizations that you get when you own a ten to $15 billion data center. And the process of computation is going to be slower, and in fact, it's going to slow down the progress.
00:19:06.854 - 00:20:47.384, Speaker B: And so that's why historically, maybe, like in March of 2022, if you showed Jensen to someone working in AI, they might say, like, I don't understand why you're doing this. You're just going to slow things down. But what I think happens is that when you reframe the problem, not in terms of, like, how much can we push these optimizations and how big can we get the models, but how open can we get the models if we, you know, if we elevate the value of openness and recognize that this is like the only and the most proper way forward to, you know, to actually work with this technology as humanity, then this decentralization approach starts to make a lot more sense, because first of all, this approach is never going to get faster until we actually work on it and solve those very difficult problems. And those problems are deeply technical. They involve not just understanding how AI models are trained and not just understanding distributed systems, but they involve zero knowledge proof systems that kind of enable this network to train the models in a safe manner, in a manner that can be trusted. Moreover, I think if we put in the work to do that now, this process is going to get faster over time and it's going to enable competition between large models. So today, someone who creates something like a GPT four size model, well, actually, it doesn't cost that much to train GPT four.
00:20:47.384 - 00:21:41.460, Speaker B: I mean, it's tens of millions of dollars, but that's not like an intractable amount of money that cannot be raised. Right. But what happens is, like, in order to have the hardware to train that type of model, you need to spend like billions of dollars setting it up. And so I think over time, decentralized networks can actually grow bigger and potentially even more optimized than the data centers that sit inside of big tech companies. And what that means is that people will be able to crowdfund models at scales that are competitive or even outpace the scales that are available in big tech today. And, you know, I think that's a great world. I think that's a world where we want to be living in, because this technology will then be available to the world in a completely open source manner.
00:21:41.460 - 00:21:43.464, Speaker B: And we've seen that that causes innovation.
00:21:44.404 - 00:22:27.434, Speaker A: Yeah, and I think this is a great segue to talking about kind of the idea of control and oversight as well. But we're going to come back to that later because I want to double click on what you just mentioned. You talked about the kind of open source inclinations of the current AI community. And I think in the post that you wrote, you covered things like come and crawl this kind of, for our listeners, these kind of public repositories and collectives of just large datasets. And the way that these datasets are put together is in an open source manner, which seems to share a lot in ideology with cryptos kind of open source ethos as well. So I'm actually curious, why hasn't there been more interest? Or maybe there have been. I'm just not aware from the AI community in adopting kind of crypto technologies and using blockchains.
00:22:28.414 - 00:22:53.082, Speaker B: I mean, I think it's just early. And you're absolutely right. There's many data sets out there that are open and free to use. We write about them in our blog posts. Some of them are the pile. Leon Luther AI these are just sets of billions and billions of pieces of images or text data. Whatever the case might be, they're used to train them.
00:22:53.082 - 00:24:01.974, Speaker B: These data sets are actually used by both kinds of models, open models and proprietary models. They will inform their datasets based on open datasets as well. These things are really, really important, but they come with problems. One of the basic problems is if you want a really high quality data set, you need people who really understand AI and really know the practice of training and know what works to construct that data set and clean it in a way that's going to set up the model training for success. Another problem we've seen is that this was more the case with generative text to image AI, is that that AI would ingest the works of creators, that it would then generalize and be able to make outputs in that creator style. But that's not necessarily acceptable to all creators. Some creators feel that that is an infringement of their sort of copyright or infringement onto their business.
00:24:01.974 - 00:25:31.024, Speaker B: There's an opportunity here for governance, and I've talked to at least a couple of startups who are thinking along the lines of how do we create governable data structures where creators can either opt in their work to be part of a trading an open training data set can opt out of their work and make sure that their work is used the way that they would want their work to be used, and sort of make up a more high fidelity way that the training sets can be used. And by the way, I think the work that these people are doing are less about helping artists opt out of these sets, and more about educating artists about why they should opt in and what kind of financial arrangements and opportunities and royalties and things like that could potentially be possible in the future if your work is part of an open data set. Right? And it's just a very interesting view that this could be like a very valuable thing to do potentially in the future. Right. And so, I mean, the answer to your question, I think is just a little bit early. But we absolutely see people working on applying things like voting systems or daos or tokenization, two data sets that eventually will flow into this open web3, AI pipeline.
00:25:31.644 - 00:25:50.800, Speaker A: So you've talked about one of the specific use cases for crypto and AI, which is allowing maybe tokens to be used in governance and voting for data that's collected to train certain models. What are some other specific use cases that you've seen or you've invested in that you think are quite interesting in terms of the intersection between AI and crypto?
00:25:50.952 - 00:26:37.728, Speaker B: Absolutely. So I think, you know, I think if you broadly break up that pipeline into like data compute and commercialization or productization, I would say that most of the places that, where we've made investments today are kind of in that middle compute bucket. That's also because we kind of tend to think of the AI stack sort of technically as a technology stack. And maybe other investors think of AI web3 more functionally like, hey, we're creating assets for metaverses or something like that. But we tend to think about it from an infrastructure perspective. And in that infrastructure stack, the lowest levels are training and then also basically providing the model outputs. And that's called inference.
00:26:37.728 - 00:27:56.154, Speaker B: Now there's two kinds of inferences, and one of them is really interesting and the other one is really boring in my opinion. So one inference is when you take a model that exists and you sort of make that API available to the world. That's kind of what OpenAI is doing with their API currently. The reason I think that's a little bit less interesting is because when we see productization on top of that model, the products are usually a very thin layer that's not going to capture a ton of value, right? Like it's a, someone integrates that API into their SaaS software and now when you're typing in notion, you can have kind of an AI output if you want it. But like longer term, I think that that set of like integrations is less interesting versus like having like one personal assistant that really knows everything about you and you know, and is able to help you with any problem that you're working on. The other kind of inference is when you're making the model output available to smart contracts in the first kind of model inference, where you're just generally making it available. This is a race to the bottom.
00:27:56.154 - 00:29:01.974, Speaker B: This is like people are trying to optimize the delivery of the model output so much they're trying to make it as cheap as possible. And in this instance, when you're trying to do inference to smart contracts, you can never get it totally cheap because the blockchain computations are expensive and because you're always going to have to use a validation technology like zero knowledge proofs to show that the output of these models is valid. It's always going to be a little bit more expensive to do inference to smart contracts. And it's a totally different target market than AI APIs in general that are going to broader tech. This target market is going to people who are building smart contracts that want to use AI. Now why might that be interesting? Well, because you can create like even with small models, you can create a lot of utility in smart contracts that didn't exist before. For example, you can use a small model these days to do something like facial recognition.
00:29:01.974 - 00:29:51.704, Speaker B: And that means that you can create a smart contract wallet where, for example, it won't move any money unless your face scan matches the face scan of the person who created the wallet. So immediately you're throwing AI into the security mix of smart contracts and you're creating like much more interesting security than exists there before. And then you can imagine millions of other little things. There's little models that recognize text characters. So now you can have an OCR application, an application that translates written text into digital text, fully automated, as a smart contract, for example, requiring no humans whatsoever. And that's like really, that's really cool. It represents a, you know, huge efficiency, you know, is also a threat to the OCR market in some sense.
00:29:51.704 - 00:30:22.554, Speaker B: The OCR SaaS market, in summary, like decentralized training, as in what Jensen is doing, that has been kind of the core area of investment. There's very few companies working on that. And then inference to smart contracts, I think is the much more interesting area for delivering the outputs of the models. And you're going to have a couple of companies on your show in the next few episodes that talk exactly about this area.
00:30:23.494 - 00:30:49.024, Speaker A: Yeah, and I'm curious. So going back to your example about, let's say there is an AI company that's building facial recognition for wallet verification. Which area of the stack would you focus on if you want to capture the most value? Is it the company that's building that plugin four wallets to have the facial recognition? Is it the wallet company itself? Is it the company that's trading the data for the facial recognition? How do you think about where value accrues in that example.
00:30:49.644 - 00:31:41.700, Speaker B: I mean, I do think a lot of the value is an on chain inference, actually, because once you have a pretty well trained OCR model and it's open, or once you have a pretty well trained face recognition model and it's open, you can go on to, to productize that and those things will work for a long time and will be acceptable for a long time. So I think that in that case, most of the value flows through a system where you're actually paying for someone, some customers actually paying for the inference. Like let's actually scan Jason's face or something like that. Whereas general inference, I think, optimizes a lot of, I think it's harder to optimize on chain inference, and so it's going to have more longevity and capture more value in the longer term.
00:31:41.852 - 00:31:55.020, Speaker A: And just to clarify here, when you say inference, you mean the part where there's some input and then the input runs through the model that was trained on some data and then some output is given, that process is the inference process, right? Yeah.
00:31:55.052 - 00:32:10.724, Speaker B: So the inference process is just like running the model one time with an input and getting an output. That's what happens every time you talk to chat GPT, when you type something into the chat, it takes the whole bucket, right. And then runs it through the model and gives you the.
00:32:11.744 - 00:32:47.444, Speaker A: Yeah, and there's one company that I made an angel investment in that they're basically doing, they were doing this inference part where you plug in, you know, a human language prompt and then they would transform it into SQl query or transform it in solidity to basically query on chain data for you. So you can be like, hey, show me all the wallets that are interested in this style of NFT. And they, you know, basically show it for you without you needing to do any coding. Is that type of like almost like chat, GBT, LLM type of use case the biggest opportunity that you see right now? Or are there any other pockets of use cases that you're personally interested in investing in?
00:32:48.224 - 00:33:14.296, Speaker B: Yeah, well, great question. Well, you know, we've seen like generative, like visual generative AI. We've seen people generate images. We've started to see people generate videos that are starting to become more and more realistic. We've seen people generate 3d models. We've seen people generate 3d spaces and stuff like that. And of course we've seen sort of text based AI's, which are llms.
00:33:14.296 - 00:34:33.251, Speaker B: And the form that they take is usually an assistant where you can query the assistant and it'll help you think about things or perform certain actions. Now, one big unlock to llms in particular, by the way, is this idea of agents that once you are able to do things like browse the Internet or pull in the data from some account that you have, like Google account or, I don't know, Uber Eats account, then you are able then to have the LLM actually do tasks that are relevant to those accounts. Now, do I think that llms are the biggest opportunity? Well, it's an interesting question. I think llms are going to be the interface to almost everything else, right? Because you can, like, you can technically generate images, like, through an LLM. Like, you can say, hey, like, what would be the prompt that you'd send to stable diffusion that created, like, a beautiful birthday card or something, you know, and then that LLM would query stable diffusion and get the output for you. So I do think in that sense, llms are more, let's call it, like, user proximate. They're closer to the user, so likely to be used more, whereas generative art is more specialized.
00:34:33.251 - 00:35:04.983, Speaker B: It's more for, like, creatives and so forth. But all that being said, all of these models, Jason, actually work on the same principle of transformers as we talked about. And transformers are these machines that essentially predict the next token once you give it an input of tokens. Today, we think of tokens as words, but they don't have to be. They can be like binary digits. They could be some other representation. They could be pixels.
00:35:04.983 - 00:35:45.116, Speaker B: And so where I think these models are actually heading is into a mode called multimodality, meaning, like, a model can process all kinds of information, not just text, but also images as inputs and outputs, computer programs as inputs and outputs, binary data as inputs and outputs. And so what I think the way that I conceptualize intelligent AI in the future is, it's one model, but it can do everything that all these myriad models that we see today can do. At the same time. It can output images and movies and text and so on.
00:35:45.220 - 00:35:55.984, Speaker A: That would be wild. And I'm actually curious, if we put this in the context of crypto, what would say defi in a post AI world look like if we have AI fully integrated into defi, what does that mean for defi?
00:35:56.764 - 00:37:28.544, Speaker B: Yeah, it means that finding sort of secret, quote unquote secret alpha, is going to get a lot harder, because, of course, AI is going to be much faster and much more effective finding those things and seeing those patterns. I mean, like, I've been to a couple of AI conferences. I went to one in MIT in Boston a couple of weeks ago, where there's a lot of like enterprise people in the crowd. And of course there are some banks too, like fidelity. And, you know, they think that AI will overhaul investment management to some extent, whether it's, you know, how you interact with the clients, how you talk to them, what you talk about, how you explain investments, how you recommend things, but also in the strategies that are being used to invest the money themselves, like using AI to find opportunities or to screen a list of stocks, let's say, that have a certain property very quickly, or a list of cryptos for that matter. I think Defi with AI is going to become, generally speaking, a lot more usable because AI's will be able to explain what's going on in defi better and it will become more effective because it will do. If you think about projects like maybe yearn or other projects that optimize across sources of yield, that optimization can now happen potentially more quickly and with much, much, much less code.
00:37:29.144 - 00:37:51.552, Speaker A: Yeah, and I think it would probably be more secure as well, because there's been talks from, I think, one of our portfolio companies that wanted to basically put in all the bugs that have happened before, all the types of exploit that happened before, into a model, and trained that model to identify similar exploits that could happen in a code base. So imagine audit firms just being run by AI. I think that could be a pretty interesting future as well.
00:37:51.688 - 00:38:46.606, Speaker B: And just to give you a quick example, so I don't know if you follow this, but I've been playing around with this idea called pseudo languages, which is the idea that you can have a programming language that is specified as a GPT prompt, and then GPT will be like the interpreter of that language, and you can give it little programs and it'll run those programs. Like just yesterday I launched a shell for my pseudo language, which is called Jargon. And in that shell you can launch a program, a pseudo language program to be executed, but you can also ask the interpreter. It's like, hey, I don't know how a certain feature of jargon works. Can you explain it to me and show me an example and it will sort of read the jargon specification and will teach you how to program in it. So this is just amazing. Nothing like that has ever really happened before in programming.
00:38:46.770 - 00:38:58.518, Speaker A: Yeah, and I'm just seeing on a Twitter as well, jargon. So we're going to include the link for Jargon. This article that you wrote called an LLM based pseudo language for prompt engineering. I don't think I've ever heard about that? So I'm curious for our listeners to dig into.
00:38:58.526 - 00:39:02.074, Speaker B: It's a little nerdy, but yeah, it's very interesting.
00:39:02.374 - 00:39:55.514, Speaker A: And I think, you know, no discussion in AI can be complete unless we, you know, do a little bit of fear mongering, because people always tie AI to, like Skynet from Terminator. And I think what you mentioned just now, right, for an AI and crypto future to be fully integrated, will have all datasets be publicly sourced, trained for all the large AI models, will be governed by the public. And I'm curious, how do you think about that versus more closed source approaches with more oversight? Because as I understand it right now, coming back to the example of chat GPT, just because so many of our listeners are probably familiar with it, I think they put in a lot of guardrails about what you can actually prompt. And, for instance, you can't prompt it to create weapons or create plots to blow up cities or stuff like that. But in a publicly, in a completely open source scenario with crypto, does that become a problem?
00:39:56.654 - 00:40:52.490, Speaker B: Well, it may or may not become a problem, but I just don't see a world where in the medium to long term proprietary models dominate. I just don't see that at all. And so while we can make the case right now that says proprietary models are the most advanced ones, and therefore we can keep them closed and kind of protect people from their potential adverse effects, I just don't see that that world is sustainable. I think what happens is that compute becomes cheaper, more available. I think that open source starts to produce models that actually outperform proprietary models, and those models are going to be open. So in my view, like the game theory of this market is long term openness. There's no way around it.
00:40:52.490 - 00:41:41.496, Speaker B: It's happening right now. Short of some kind of major global political overhaul, you know, that's not going to change. And so we should just, like, accept the fact that we should embrace openness, and we should accept the fact that we all need to be working on alignment problems and educating people and, you know, trying to get models to do what we want them to do and not to do anything dangerous. And that's kind of how I see it. But I do think that there is, like, definitely risks there. There. If you connect a model to some sort of real world system or a dangerous system or a system that has risks, like trading, there are ways that these models are vulnerable, and there are ways that these models could potentially misbehave or not do what you want them to do.
00:41:41.496 - 00:41:58.134, Speaker B: And that could lead to impact. And so to mitigate that impact, I think everybody who is looking at this field needs to be working on that problem in an open and reliable sort of way. That's how I think about it, yeah.
00:41:58.174 - 00:42:16.350, Speaker A: And I think this is a great note to kind of close us out on. So for the founders out there who are listening, who might be interested in exploring crypto and AI, I know there's a lot of crypto founders that are interested in AI right now. What are the problems they should be thinking about? Like what should they be solving? And how can they get an investor like you to be interested in them?
00:42:16.542 - 00:43:36.244, Speaker B: Yeah, well, I think in that first bucket of, like, data, web3 approaches to data management, there's not a ton of people operating in that space right now. And so it's a little bit of an open field. I think in the compute area, inference and training, especially in the training part, there's not a ton of people who are sophisticated enough to even begin to solve that problem. But I think over time there should be more. And competition is good, I think in the commercialization part, especially for web3, meaning like how do we create smart contracts that use AI for interesting applications? There is a totally open field right now where if you're like a product person and you're excited about AI and you're excited about that AI being open, accessible, self sovereign and so on, there's almost like no products today that we can point to that that do that. I mean, there's a few, there's like people use generative AI outputs and make nfts out of them. But how do you query GPT four on chain? How do you use facial recognition on chain, as we've discussed, how do you have autonomous OCR and other applications? These are all open possibilities that people could be working.
00:43:36.904 - 00:43:55.096, Speaker A: Yeah, and that's extremely exciting. And I do think this is one of the kind of least talked about areas in crypto, specifically like how crypto and AI overlap. And I do think it will become one of the largest areas. So for people who want to continue to follow your thoughts, because you've been writing about this for such a long time, what are the channels that they should follow you on?
00:43:55.280 - 00:44:06.052, Speaker B: Absolutely. Yeah. Well, the easiest one is Twitter. I'm. And then also check out the coin fund blog. Blog dot Coinfund IO.
00:44:06.248 - 00:44:19.180, Speaker A: Perfect. Well, Jake, thank you so much again for coming onto the show for the third time. I'm definitely very confident that we're going to bring you on for a fourth time for some big trend that's going to happen again in the next few years. So excited for this and thanks for coming on, man.
00:44:19.332 - 00:44:23.424, Speaker B: I hope so, Jason. And thank you for asking great questions as always.
00:44:23.884 - 00:45:02.806, Speaker A: All right, that's it for this week's episode of the Blockchain podcast. So thank you so much for tuning in. If you enjoyed this episode, please make sure to subscribe on your favorite apps. And in case you didn't know, this interview is also available as a video on YouTube. And if you tag the blockcrunch on Twitter this week and tell us what you liked about this episode, ill be sure to respond to you as well. Now, if youd like to go even deeper, we have a vip tier where every week or so we write an in depth research brief or investment memo on a project and well have exclusive AMA's with myself where I answer all your questions as well. Now, we already have analysts from some of the top funds and companies in crypto as subscribers, so if you're serious about getting an edge in crypto, head on over to theBlockhunts.com
00:45:02.806 - 00:45:07.174, Speaker A: VIP to learn more. And once again, thanks for supporting the show and I'll see you next week.

00:00:02.040 - 00:00:08.714, Speaker A: Ladies and gentlemen, welcome to the Blockcrunch podcast, the go to podcast for investors and builders in crypto.
00:00:17.214 - 00:00:38.934, Speaker B: And before we get started, just a reminder for you guys out there. The Blockcrunch podcast is intended for informational purposes only. Neither the host nor its guests or licensed financial advisors, and nothing discussed should be construed as financial advice. Views held by blockcards guests are their own, and sponsorship messages do not constitute financial advice or endorsement. With that out of the way, let's jump right in.
00:00:39.314 - 00:00:54.414, Speaker A: Today's episode is brought to you by Protocol Labs, the team behind Filecoin. And with me today is Colin Efrin from Protocol Labs, who leads ecosystem there to tell us why people should choose Filecoin over alternatives. So, Colin, why should people be using Filecoin over other competitors?
00:00:55.044 - 00:01:27.926, Speaker C: Filecoin believes that web3 will only win by offering a better product at a better price point. When it comes to storage, Filecoin offers the most scale at the cheapest price, with the strong guarantees uniquely enabled by its open market of storage providers and its crypto economic incentives. Now, smart contracts on Filecoin, which launches in Q one of 2023, only make this more powerful. It enables users to create perpetual storage deals to store data forever at costs that are a small fraction of such centralized storage providers like SD.
00:01:28.110 - 00:01:53.800, Speaker A: Hello there. Now, before I move on, I'd love to thank the hundreds of you who have subscribed to blockchain. Because with your support, I've been able to share my real thoughts on specific projects that I don't usually share on interviews in a format that I enjoy more, which is bi weekly written posts. We've also been able to offer exclusive AMA's sharing my investment frameworks, interactable models, and breaking down important trends before they become big. Now, we even had Elon Musk comment on one of our threads recently.
00:01:53.942 - 00:01:55.700, Speaker B: So if you haven't already, head on.
00:01:55.732 - 00:01:58.500, Speaker A: Over to theBlockcrunch.com VIP and you can.
00:01:58.532 - 00:02:00.396, Speaker B: Access dozens of hours of research for.
00:02:00.420 - 00:02:43.940, Speaker A: What you'd spend on a coffee a day. Hey, everybody, welcome back to another episode of the Blockcrench podcast. Now, as you know, we've been diving deeper into AI and crypto and its intersection, and we recently did an episode with Jake Brookman from Coinfund. Just giving you a overview of how these two mega industries will intersect. And one of the companies that is working at the cutting edge between AI and crypto is Giza. Giza is a project combining AI and web3 in a way that makes a lot of sense to me because it's a machine learning platform that's built on Starknet, and it's focusing on deployment, scaling and solving deployment barriers that are very common with web two services. So don't worry, we're going to dive into how all of that works, what that all means.
00:02:43.940 - 00:02:49.144, Speaker A: And with me today are chem and Fran from Giza on the show. So welcome to the show, guys.
00:02:49.504 - 00:02:50.684, Speaker D: Thank you very much.
00:02:51.104 - 00:02:52.444, Speaker E: Hello. Thank you.
00:02:53.544 - 00:03:02.084, Speaker A: So just to get us started here, can you maybe tell us a little bit about how you guys decided to build Giza? And then we can maybe jump into what Giza actually is.
00:03:02.824 - 00:04:00.332, Speaker E: I can give you some context on how we started working on this last year. On March, I discovered all the space about rollups and Seiki rollups, specifically starnet, and found the technology that is being used underneath, in this case ckproof, specifically Starx. Super fascinating in terms of performance capabilities, but also how it enables scalability for the blockchain. And I thought that this technology could enable a bunch of new applications to be built on top of this case, Ethereum. And that's where I started looking to this intersection of ML and blockchain by using their smart contract language. That is not only a smart contract language, it's called Cairo. So it's like a mix of things that you can use for general purpose, but also for building smart contracts.
00:04:00.332 - 00:04:44.874, Speaker E: And I found that this language is like the perfect combination for building machine learning models that can be also smart contracts. And I went to East Amsterdam last year and participated in the fascistarnet hackathon that happened there. And build what it was the first PoC of what is Giza now? And build like a super smart model that can be deployed as a smart contract. And people were blown away like, well, this is actually possible to run models on chain. And I was like, yeah, I think it is. And since then, like, here we are, basically.
00:04:46.534 - 00:04:48.314, Speaker A: Yeah. And anything to add there, champ?
00:04:49.214 - 00:05:31.514, Speaker D: I think the following events sort of like, took us a little bit towards thinking around how to turn this incredible capabilities of not only smart contract machine learning, but also verifiable machine learning, which is, you know, has implications that is a little bit, I mean, much wider than just web3. So we started thinking around how to turn this into a product, how to turn this into a protocol. Yeah. Since then, sort of like, a lot of our efforts have been directed towards this thinking the deliberation around mechanism design of this protocol, but we can dive deeper in the conversation.
00:05:32.644 - 00:05:49.864, Speaker A: Yeah, I'd love to do that because what you guys are working on with Giza is being able to deploy these machine learning models on chain. So I'd love to dive into that kind of value proposition. Why is it important to be able to deploy it on chain? What about the current way of doing things is insufficient?
00:05:50.604 - 00:07:05.704, Speaker E: Yeah, super good question. I will say the main point here is if you want to use AI in the blockchain, do you need to rely on the usage of oracles? And if you need to rely on the use of oracles, that means that you need to have an AI model deploy somewhere of chain. For example in a cloud service where your model is in a macular service serving inferences, and then these inferences are being shared through the oracle, where the smart contract consumes these inferences through the oracle. But then you have then different pain points. For example, what happens if your modern microservice goes down? What happens to your smart contract? Basically you're like implants, like you have no way to recover from that problem, right? Unless your microservice goes back up again. Or what happens if there is a consensus problem in the oracle and your inference is not well received into the smart contract? So there are like several risks and this basically makes you the usage of AI not viable or feasible in the usage of protocols. For example, in DeFi, you won't make a DeFi protocol that relies on this kind of architecture because cool, put in risk the funds of users, basically.
00:07:05.704 - 00:07:39.764, Speaker E: So now the thing is with this new way of doing things, deploying ML models completely on chain, as a smart contract, you have the possibility of not relying on any of these architectures, not oracles or microservices deploy off chain, but have everything leaving on chain and just plug in directly into your protocol. The model as simple smart contract call to make the inference which makes things much simpler and composable basically.
00:07:40.744 - 00:07:53.540, Speaker A: And just to tie this into more concrete terms, what are some use cases that would require this utility? What are the things that we can do as users with Giza where you bring these kind of AI models on.
00:07:53.572 - 00:08:57.584, Speaker E: Chain, basically you can make any use case that you want. But going into specific use cases, I will say the most interesting ones are in the deFi space where for example, now if you want to have some complex, for example, deal strategy or asset management, you need to completely build this complex logic into the smart contract, which can be not very straightforward, will require a lot of auditing around it. And this kind of behavior is like for example for optimizing the yield is a super simple model that, for example many fintech companies in web two uses, but in web3 is not possible, right? Because you need to build this arching architecture to make it possible with all the overhead of auditing. But now, instead of adding all these overheads, you could just use a model and get the yield optimize result much more easily.
00:08:58.284 - 00:10:20.110, Speaker D: Maybe I can add that as a general sort of pattern that I've been noticing with all the use cases that we have been exploring, and also engaging with the partners that we have accumulated so far. I think like one major pattern is that wherever there is a complex set of variables that needs to be boiled down to either a decision or a singular parameter that is easier to analyze, you can think of reputation algorithms, you can think of credit scores. We are unable to accommodate these with the current deterministic smart contracts that cannot reach this first of all level of computation, but also indeterministic analysis. So any problem that has this type of complex set of parameters, it's intelligence layer, is probably helpful for creating that efficiency on chain, so you can add social choice problems to that as well. It links perfectly to this reputation algorithms case. Reputation algorithms only work if it's fine tuned to a particular needs of a community. You cannot really, like, apply one community's algorithms to another.
00:10:20.110 - 00:10:58.234, Speaker D: And that reparametrization is also a very difficult problem because you have decentralized governance. So decentralized governance, parameterizing a complex set of parameters, it becomes computationally almost impossible. So if you have a layer which understands the needs of the needs and desires of the community, and translates that into parameterizing the reputation algorithm, then you can have one layer that can fit many communities needs, generatively speaking. So I think this is a general pattern that I'm noticing with the use cases that ML is able to serve on chain.
00:10:59.254 - 00:11:31.934, Speaker A: Yeah, and I guess taking a step back here as well, I think from our previous episode with Jake from Coinfun, I think our lizard has learned that for these AI models, I'm oversimplifying, but there's mostly three parts. You create the model, you train the model by feeding it a ton of data, and then there's the inference part, where you give it some new input, and it's supposed to give you an output predicted by the model. So for Giza, are you moving, you know, all, all three of these parts, you know, the construction of the model, the training and the inference on chain? Or are you only moving certain parts on chain? What's the best way to understand that?
00:11:32.634 - 00:12:27.784, Speaker E: Yeah, we heavily focus on the inference side, so we let people do the training whenever they want. They can do it on their laptop, train their model there or in the cloud, AWS, Google cloud, whatever it is, we let people fully choose what they want to build, and not only that, but also using the framework they like. They could use Tensorflow or pythods or secret learn, whatever. And once they have their model file with the train model, that's where Giza comes in with the platform side of Giza, and people just upload their model into our model registry in the platform, and that's where things start to happen in terms of managing the models, deploying the Mssmark contracts, and that's where we manage everything from the monitoring to the deployment and the scalability.
00:12:28.924 - 00:13:24.314, Speaker D: Also, one thing that's important to note is that deploying these models on chain is a choice. In Giza, we don't actually monolithically deploy models on chain. We also allow for this other use case, which is the ability to run more complex models that the current on chain constraints don't accommodate today, but actually generate these inferences with the proof and the trace of its computation from the machine learning model. And then this becomes some kind of a defensibility against the Oracle problem, where you are unsure if the Oracle is reporting correctly, but you can actually check the proof on the verifier that is living on the desired chain, for instance ethereum or whatever chain that implements the verifier for sharp, which is the prover that we are using today.
00:13:24.934 - 00:14:12.264, Speaker E: Also to add, I think this is something really unique that you are working on, on gear science because of leveraging these technologies that we are using from starware. And in this case, as I was mentioning at the beginning, using Cairo, we can have these models both as a smart contract and also as single programs, which means we can deploy them as a smart contract, but also we can do this kind of behavior that we just described. That is, we run the inferences off chain in a microservice. We generated traces for these executions because the models are in Cairo, and we can verify completely unchained these inferences that were correct. So it's like a lot of flexibility and options to make these verifiable model inferences be available on chain.
00:14:12.764 - 00:14:47.424, Speaker A: Yeah, and I think one really important thing that you mentioned earlier, Fran, is that you're able to deploy these models on chain, but avoid kind of writing extremely complicated models directly onto the blockchain itself. And I always thought it was interesting because blockchains are resource constraint, by definition, you have to pay, hey, for block space and so on, whereas AI requires the opposite, it requires as much resources as possible. To train to do these inferences. So, can you maybe explain in simple terms, how are you able to deploy these models on chain without running into set of capacity issues as these models get more complicated?
00:14:48.364 - 00:15:57.770, Speaker E: That's a super good question. And before doing into the specifics, also, I give you a bit of context of what we are trying to deploy on chain, because there are like different complexities on the models that are available in terms of ML. Like you have simple algorithms like regression, or super complex algorithms like GPT four. Right. So in terms of on chain models, we are more focused on the simplicity and high value algorithms, which means everything that is going to be on chain are like regression algorithms, diffusion trees, boosting algorithms, algorithms that are like super cheap to execute, can be run on CPU personally and can provide a lot of value to different use cases. So in terms of deployment, we are focused on that. So on one sense, we don't need to run super expensive transactions and we don't need to store like weights into the chain itself to avoid these storage costs.
00:15:57.770 - 00:16:17.334, Speaker E: Because also one of the benefits of using our infrastructure for deploying models on chain is that we are using Starnet, which basically the main benefit is that the computation costs are super cheap, which means we can run the inferences for these simple models as a smart contracts with a very low transaction cost.
00:16:18.274 - 00:16:22.214, Speaker A: So, yeah. So, Fred, so when can we expect to see neural networks on chain?
00:16:25.084 - 00:17:29.470, Speaker E: Super good question. Actually, we are now working on improving the text that we are using underneath for deploying the models. Two days ago, we released our new library that is called Orion. Orion is basically a new library built in Cairo, in the new version of Cairo, Cairo, where we provide the building block for building these new complexities of models like neural networks, in an efficient way to be deployed, in this case, on chain. So you can imagine, like, we are building this new set of blocks, like tensors, functionalities, that is basically whole neural networks, the primitives that neural networks use underneath using efficient Cairo computations, so they can be run and change. Now, also, the cost of deploying this, this smart contract has been decreased over time as the technology of star net also improved. So now it's almost possible to deploy these neural networks.
00:17:29.470 - 00:17:33.914, Speaker E: We are almost ready to be able to deploy neural networks.
00:17:34.814 - 00:18:01.244, Speaker A: Wow. And I'd love to understand just how big of an impact this can have on all of crypto. So I guess, using the examples of well known projects, what are some ways that Giza can improve the utility of maybe some examples of well known projects? I'm sure you guys have thought about hey, how can we plug Giza into like uniswap? Or how do we plug Giza into like axie infinity? Like what are some interesting ideas that you guys had?
00:18:02.024 - 00:19:50.014, Speaker E: We are working in different verticals with different use cases. For example in the DeFi space we are working with some OG projects, DeFi 1.0 where we are like working on risk assessment for strategies of vaults, where basically instead of people of this protocol need to do the manual risk for these studies to be included into the bot now is going to be an automated process that is going to be handled by a model that is on chain and is directly connected to the protocol, which means there is no dependency on the person. We can automate the process and we can have better scalability also for providing better usability for the users and for other kind of verticals. For example, another one that is super interesting right now is on chain gaming is getting a lot of attention lately and we've seen like a lot of demand from this area in terms of how to read the gaming experience for these on chain games. And as all the logic and everything that is happening in the game is put on the chain, you can have things that are like very native to games like NPC's non playable characters. So this is something that, for example, if you play GTA or any kind of games, you can play against the computer, do arrays or do whatever, right? But for on chain games this is not the case.
00:19:50.014 - 00:20:20.574, Speaker E: And you need to rely something that is on chain to have this kind of behavior because now that these on chain games relate heavily on on chain usage, you can have it. So we are working on providing NPC agents to these on chain games where people can add these non playable characters, plug into the game to be able to accommodate this necessity of having a bigger user base when there is no one playing the game or not enough user base playing it.
00:20:21.194 - 00:22:13.768, Speaker D: Yeah, I think this is a really interesting use case because I'm kind of ideologically opposed to play to earn because of the inherent class dynamics that emerge from that in the ludic economy. And I think this is a much better compromise to create game conviviality for player experience than paying people to spend time in an environment where it's not fun for them to do so. But yeah, I think different use cases that I could talk about, which is interesting, is like Sibyl resistance I think is really relevant for a lot of different projects for different reasons. So proof of humanity type of use cases are things that we are exploring closely. This is more of a research but we are exploring how we can contribute with on chain machine learning to decentralized arbitration. How can we help scale and improve the game theoretic effectiveness of distributed decentralized arbitration and court systems and increase their usage? And there we are thinking around both, like integrating decentralized arbitration to regulate on chain AI, using on chain AI to assist decentralized arbitration, and then also hybrid court systems where humans and ML inference work in collaborative cooperation for more high value decision making. But in the sense, the use cases are so abundant that it's kind of like not to equate ourselves to Vitalik, but it's kind of like asking in ethereum's early days, what are the use case of smart contracts? Because what we're doing is just expanding the capabilities of smart contracts.
00:22:13.768 - 00:22:32.824, Speaker D: So this is going to be really up to the ecosystem to see where they can take this, actually. So it's kind of like a project that is nerd sniping the whole ecosystem as how do you use these new capabilities and improve on chain mechanisms?
00:22:33.244 - 00:23:14.576, Speaker A: I always thought this was very interesting, because I remember in 2017 or so, I was watching a YouTube video with Vitalik, and he basically said that the most interesting use cases are things that we haven't even heard of yet, or I haven't even thought of yet. And to me, at that time, I was studying business. So for me, that sounded like crazy to me, because every time you invest in a business, you want to know the exact business model, you want to know the problem they're solving. But then when you look back at all the big innovations, all the big zero to one moments in crypto, so far, it's things that no one basically predicted. It's always these new unlocks of just completely new paradigms. So I'm really excited to see kind of what people can build with Giza. But I love to kind of double clicked on one thing you mentioned, champ, which is proof of humanity.
00:23:14.576 - 00:23:16.124, Speaker A: What exactly is that?
00:23:16.464 - 00:24:47.474, Speaker D: So, proof of humanity is a way to authenticate that a certain on chain identity belongs to a single person, and that person cannot generate, in the same environment or in the same protocol, another account which becomes relevant for many different use cases. But the one that is kind of, I would say it being most applied to is UBI systems. UBI is a universal basic income, which is kind of like a utopian economic model, which is very much in discourse at the moment because of fears of automation and people losing their jobs. So there's this desire to find new alternative economic systems where people can sustain themselves with, like a minimum income that is like coming from a certain source of economic productivity. But for these systems to work, it is very crucial that there is no hyperinflation of the beneficiaries of the recipients. If there is no check in terms of who can subscribe to this, then you can actually farm this welfare system by generating infinite amount of bots and basically crashing and hyperinflating the token that is being minted towards the rightful users. So that's where proof of humanity is extremely crucial.
00:24:47.474 - 00:25:32.194, Speaker D: And we know of a couple of projects in the web3 ecosystem, namely circles Ubi, that is comrades from Berlin, and also Worldcoin, that are also like both of them, working basically like they are effectively proof of humanity protocols. The only thing they have to figure out is to make sure that they authenticate that one person has one wallet, and then UBi could work. Of course, then you have to figure out how to sustain that economic circularity and where is the productivity coming from to make that sustainable. But proof of humanity is basically the way to authenticate that one user is controlling one wallet.
00:25:32.974 - 00:26:18.604, Speaker A: And for context here, I think for WorldCoin, they just announced to raise, I think, $115 million. And for context, for elicitors, worldcoin basically has this device that scans your eyeballs and creates an on chain identity for you based on an eyeball, which is supposedly very hard to, or almost impossible to Sibyl. You can't create a fake eyeball and create fake addresses. And it's always interesting to me, because that company is partially started by Sam Altman, who is one of the founders for OpenAI. So he's almost starting a company to solve a problem that's created by his other company, which is this proliferation of AI. So I'm actually curious, how does proof of humanity tie into AI here? How does that tie into deploying AI models on chain?
00:26:19.634 - 00:27:27.964, Speaker D: Right now, we're relying on systems like web of trust, which is allowing for people to sign each other's wallets, kind of like in Tor, authenticate each other's wallets in a social manner by PGP signatures. This type of thing and circles is, for instance, using this type of network algorithm communication protocol. For authenticating humanness. You need at least three signatures to be a recipient of the UBI token, while Worldcoin is going the biometrics direction for authentication. So there's, like, different epistemological data sources that we can use in order to sense make uniqueness or humanness of a certain account. And this is not limited to biometrics, and it's not limited to social, but it's actually we can have machine learning analyze all of these different data sources and give a decision in the end. Again, like what I was mentioning earlier, a complex set of parameters and one output.
00:27:27.964 - 00:27:58.994, Speaker D: In the end, this is where machine learning becomes very useful. So this is what we are working on with circles, with our friends at gnosis to see how can we turn wallet history, how can we turn submissions of a photo proof or a video proof into proof of humanity without any type of human oversight or overhead, so that these systems can become much more scalable and context free for deployment?
00:28:00.214 - 00:29:08.304, Speaker E: For me also, there is another use case that is super interesting that we should explore as well is how to actually improve the user experience for wallets. And one of the biggest pain points here is how do you actually recover a wallet? Right, you need a seed phrase. Now there is the social recovery part as well. But what if you could link your identity to your wallet in terms of your, for example, your fingerprint identification or your facial recognition leveraging account abstraction? That is something super prominent now in Altoos, for example, and link this identity to your account so you can, instead of doing this key recovery or social recovery, you could use your actual identity directly into the account. Wallet to recovery, basically your wallet, like using facial recognition or fingerprint recognition. I think that's an interesting use case as well. That will come.
00:29:09.204 - 00:29:37.664, Speaker A: Yeah, we've talked a lot about potential ways you can apply these models to consumer facing use cases. One part of Giza we haven't talked about is the open source nature of it. The fact that you're deploying these models on chain for all to see, which might imply that other engineers who want to improve the model can easily contribute to improving these models in an open source environment. How does that differ, first of all, from how current AI models that are not on chain are built? And why is that important?
00:29:38.604 - 00:30:10.704, Speaker E: I think our focus is on open source right now. What we want to really cover is people building in open source, how these people actively contributing to open source can actually empower actually what is happening on web3 as well. And this is one of the main purposes. But the second thing is how we can actually provide the right wiretrails for people to build in the open using open source, but being governed by what is happening in the web3 space.
00:30:11.564 - 00:32:15.810, Speaker D: Yeah, I mean, our main intention was, as you well put it, Jason, it seems like an impossible romance between AI and web3, but we are obsessed about bringing them together because there is this web3 provides this ideological infrastructural capabilities for coordination. So what that means for AI is that we already see this in the open source, in a hugging face, for example, in open source AI, where there is a kind of supercharged movement in terms of creating derivatives, building on top of existing models, etcetera. So we want to take that to another level by making these systems composable, but also these systems as primitives that can be replicated with almost no cost and deployed in settings which the founders or the builders, initial builders, did not intend to. So I think this is the power, ecosystemic or ecological, even power, of web3, that we are very excited to bring to the world of AI. And of course, there is one thing that is kind of the elephant in the room that web3 did to open source, which is making open source sustainable in the sense that putting assetization, digital tokenization into the mix and allowing for this economy to persist. Open source obviously has a much longer history than web3, but web3 took it to such an interesting level where I think contributed significantly to incredible innovation, even in things like cryptography and zero knowledge and so on. So I think we can take this type of energy to AI and provide an alternative way of developing AI.
00:32:15.810 - 00:32:35.614, Speaker D: So if people don't feel aligned with tech giants, if they don't want, if they are machine learning engineers and inventors, and they don't want to work in Silicon Valley, maybe they should have an alternative path of doing that independently. So I think with Giza, that's going to be possible in the near future.
00:32:36.274 - 00:33:18.314, Speaker A: And I think that's a great note to kind of pivot, to zoom out a little bit and really talk about the market environment that Giza is in, in terms of the timing of building something like Giza, because it seems like AI has been the top of mind for at least a small group of people for many, many, many years. But it seems like only recently that it hit mainstream with the launch of chat, GPT, and everybody started to have a more visceral understanding of what even a relatively simple model can do. So I guess I'd love to get your view on where you think we are in terms of the entire lifecycle of AI. Are we on the very beginning of the development? What are some things that get you guys excited in terms of the maturity of the AI market?
00:33:19.054 - 00:34:31.824, Speaker E: In terms of maturity, the AI market has been for a while around. The thing is that it just hit mainstream. But for example, for enterprise, ML has been used for a long time, for many different use cases, but now it's like millions of people can have instant access to a super powerful AI model that is, in this case, llms, and how they can actually improve their lives or their work they are doing. And I think this is going to move forward very quickly. We've seen like the speed of developments from GPT-3 or GPT-2 to now GPT four, and the difference in quality of the output is like, quite remarkable. And how this evolves over time is going to be, I think, faster, not in terms of how models evolve, but in terms of the applications that are going to be made on top of these models. I think this actually the leverage that is going to happen in the next five years.
00:34:32.444 - 00:35:33.726, Speaker D: I think in general, with industry, scale comes first. Scale comes first and dominates and creates the space which is exactly what we're seeing in AI, right? Like the data compute, these are all subject to extreme power laws. So it allows for gigantic corporations or alliances to deliver cutting edge consumer experiences. But I think what follows after this scale carves the space. What follows after is interconnectivity and the effects that that brings about. So, like we, we can think of computer manufacturing versus the Internet as a similar sort of, like, one is subject to extreme amount of power loss, the other interconnectivity. And the interconnectivity provides such a ground for innovation that then it creates such an ecosystem of new technology.
00:35:33.726 - 00:36:41.180, Speaker D: And this is like we can think about, like Bell Labs not being able to capture all the innovation that is creating in a similar manner. So I think this is coming to AI. And I think infrastructures or ecosystems such as Giza is going to facilitate a lot of this new movement from scale to interconnectivity and learning transfers. And the other movement that I'm anticipating is so right now, AI, I think, is a bit of a sandbox. Even though it's in everyone's laptop or everyone's phone, it's still limited to a very normative experience of a chat exchange. While if you listen to Sam Altman or any other thought leader in AI, everyone is talking about how this is going to be transformative, life extending, and sort of utopian in many different ways. And that is predicated on AI's application to very critical sectors that are like medicine, like finance, like law, like defense.
00:36:41.180 - 00:37:55.254, Speaker D: So there's all these verticals that are waiting for adoption that is not going to get this adoption unless there is some kind of regulation, right? Like, no government is going to let AI sort of crash through these industries without regulating them. So AI is going to take a new turn where verifiable machine learning is going to be the key to enable the regulation of machine learning in all these high value use cases, because the ability to establish a link of accountability between a model and its output, which is literally what verifiable ML does, that is going to be the key that unlocks the expansion of AI from the limited consumer experience to wide range of adoption and invention in many different high value industries. So I think one is the ecologization of AI and the other is verifiability of AI. I see these trends as most exciting for sort of spreading the real utility of AI to the world, because many people who don't have access to the benefits are going to be able to benefit from it.
00:37:55.874 - 00:38:23.654, Speaker A: Yeah, no, thank you so much for that breakdown, cham. I think that that's a great way to kind of summarize the two big confluence of kind of tailwinds that are coming for AI. And I'd love to use this part to shift away and talk about takeaways for listeners here. So if elicitors are building projects or they want to learn about how can they integrate AI into their crypto businesses, how should they get started with their journey with Giza?
00:38:24.134 - 00:39:16.544, Speaker E: To start a journey with Giza is actually pretty straightforward because we don't let anyone out for using what we are building. So basically, anyone that is building ML models at the moment, using any kind of framework, is going to be welcome to use Giza and to use these models on chain or in a verifiable way. So the best way to contribute, for example, for the moment, is helping us building the foundations of what is now Orion, and how we can extend the functionalities of this runtime to have better support and performance for bigger models that can be run completely on chain.
00:39:17.284 - 00:39:59.492, Speaker D: I will echo what Fran said there. Like, the best way to get into this field, I would say, is to contribute, because it's literally getting acclimated to a new smart contract language, a new set of capabilities of doing machine learning on chain with that smart contract language. I also want to say it's not only a smart contract language, it's also like, you know, provable language. So it's not a language for creating provable programs. So you don't have to exclusively write smart contracts necessarily. So the best way to be involved in this ecosystem, I would say, is to contribute. And there's two ways that people can contribute.
00:39:59.492 - 00:41:10.684, Speaker D: One is to the core infrastructure to increase the capabilities of Orion. So helping us out with bringing Orion to completion, where new operators can be contributed to our repository. But also, if you are more on the entrepreneurial side of AI web3 development, then you can think about use cases and how these use cases can tangibly function with the constraints that are present right now. And we will also have hackathons throughout the years where people can come together and, you know, tackle different tracks and explore different use cases. But also we have a type form in our website where we grant a whitelist for deploying on Giza before we permissionlessly deploy on the main nets. So if you have a great idea, feel free to reach us out either in our discord or through the type four. I would say best way to be involved is to contribute.
00:41:11.304 - 00:41:36.474, Speaker A: Perfect. I think that's a perfect note to kind of wrap this up on so we'll include those in the show notes below. And gentlemen, this has been a really interesting episode. I do think this is the cutting edge of crypto that not enough people are paying attention to yet. So we're doing our best to illuminate that sector and educate people as well. So really thankful for you guys for being a part of that. And what are your twitter handles? Or what are the best way for people to follow you as a final shout out?
00:41:37.214 - 00:41:42.166, Speaker D: Well, Giza tech xyz is the handle.
00:41:42.190 - 00:41:57.222, Speaker A: Of Giza, so you guys heard it here. Go and check out the twitter. There's some pretty great blog posts explaining what Giza what Giza does. Highly recommend you guys to check it out as well. So thanks again for coming on front. And gem, it's been a delight.
00:41:57.398 - 00:41:58.190, Speaker D: It was a pleasure.
00:41:58.222 - 00:42:00.760, Speaker E: Jason, a pleasure. Yes, thank you so much.
00:42:00.862 - 00:42:30.384, Speaker B: Alright, that's it for this week's episode of the blockcast. So thank you so much for tuning in. If you enjoyed this episode, please make sure to subscribe on your favorite apps. And in case you didn't know, this interview is also available as a video on YouTube. And if you tag the blockcrunch on Twitter this week and tell us what you liked about this episode, I'll be sure to respond to you as well. Now if you'd like to go even deeper, we have a vip tier where every week or so we write an in depth research brief or investment memo on a project. Will have exclusive amas with myself where I answer all your questions as well.
00:42:30.384 - 00:42:44.064, Speaker B: Now, we already have analysts from some of the top funds and companies in crypto as subscribers, so if you're serious about getting an edge in crypto, head on over to theBlockhunts.com VIP to learn more. And once again, thanks for supporting the show, and I'll see you next week.

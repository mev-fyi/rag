00:00:00.250 - 00:00:04.526, Speaker A: Total, everyone.
00:00:04.628 - 00:00:57.262, Speaker B: The live stream will be up in about five minutes, maybe three. Okay, how are you this around?
00:00:57.316 - 00:01:05.710, Speaker A: This is the weekend.
00:01:40.290 - 00:01:41.040, Speaker B: Like.
00:01:42.930 - 00:01:52.640, Speaker A: No, super, like.
00:01:57.490 - 00:01:58.126, Speaker B: With the way.
00:01:58.148 - 00:01:58.990, Speaker A: That demand.
00:02:01.490 - 00:02:02.240, Speaker B: Really.
00:02:04.130 - 00:02:22.760, Speaker A: Kind of wants to. And once the international school, like, if you're not.
00:02:28.730 - 00:02:29.750, Speaker B: You gotta.
00:02:30.370 - 00:03:11.980, Speaker A: Yeah, we both, but we make like, that's why we're doing. Now she was in Germany as well, but for.
00:03:30.370 - 00:04:02.370, Speaker B: Hello, everyone on the live stream. We're just about to start, so hello, everyone, and welcome to the Ethereum engineering group meetup. So today we're going to talk about consensus algorithms. So we're going to talk about proof of work, proof of stake, and proof of authority based algorithms. And I'm going to talk Rob Dawson back there busy behind a laptop, is going to talk, and so is Adrian over there. So let's lead on. So consensus algorithms, it's all about.
00:04:02.370 - 00:04:37.010, Speaker B: You've got a decentralized network of nodes. How do you come to an agreement on what transaction should be put into the next block? How do you come to an agreement on what truth is all about? And so I'm going to walk you through some algorithms. It's focused on the Ethereum ecosystem. There are other algorithms that are used by other blockchain systems, but we're just going to focus on Ethereum today. So, as I said, I'm going to talk about Ethereum. Pow. We're going to have Pos and Casper talked about by Roth and IPFT and others talked about by atrium.
00:04:37.010 - 00:05:32.438, Speaker B: So proof of work, the overall process, the meta process that you're looking at is the miner assembles a set of transactions that are going to go into the block, and also some uncles, and then we create a candidate block. You do the mining algorithm, and then once the first miner solves the puzzle problem, it publishes its proof, and then everyone verifies it, and then it's agreed on as the block. So that's a very high level process. Let's drill into that a little bit. So we've got the miners, and so they assemble the set of transactions. How do they do that? If you've got lots and lots of transactions, more transactions than are going to fit into a block, how do you prioritize them? Well, you prioritize them based on who's going to pay the most. So everyone who wants to execute some code has to pay a gas price.
00:05:32.438 - 00:06:23.830, Speaker B: And the idea is that you look at the amount of gas that they're prepared to pay, the amount of money that they're prepared to pay for their transaction. And if someone's going to pay you this much money, someone else is going to pay this much money. Who are you going to mine first? So the obvious ramification for people who are submitting transactions is if you want your transaction to be definitely mined in the next block, you pay a lot of gas. And if you just want to pay a little bit, but you don't care if it gets mined sometime in the next few seconds, few minutes, or even the next hour, you pay almost nothing. You pay maybe 100 times or 1000 times less. So some miners will accept your transaction even if you're paying thousand times less than the maximum that you might pay. But it might take a while for your transaction to end up in a time period when not many transactions are available that want to be mined.
00:06:23.830 - 00:07:32.830, Speaker B: So what's an uncle, I hear you ask? So you've got a huge distributed network of 30,000 nodes in Ethereum. And you can imagine that at one end of the network you could be assembling a set of transactions which you put into a block, and then you could end up say creating this block 101, which builds a block 100 and then you're creating block 102. But meanwhile at the other end of the network, someone could have mined block 101 a and because in bitcoin you've got quite large inter block times, so large block periods, whereas in Ethereum it's down to about twelve or 15 seconds. It started off at 12 seconds and then the decision was made to increase it to 15. And so the reason that you're doing that is because you're worried about the amount of time it takes for blocks to actually get pushed across the network. And so what you do is you allow for the fact that, well, this might have some transactions that this doesn't have in it. So let's integrate the work that's been done, because if you didn't include this block, then all those transactions that are in there would have to be pushed back into the transaction pool, bringing in more transactions.
00:07:32.830 - 00:08:19.420, Speaker B: So then the miners create a candidate block, which they're going to create a candidate block header. So what they do is they put all of this information together. So parent hash being the message digest of the previous blocks and then the so owners apparently is a gentle, neutral term for uncle. There you go. We've all learned a new thing today, haven't we, beneficiary? So in bitcoin you have a coinbase transaction which pays the actual miner. So you don't need to do that because we don't have an unspent transaction output style of payment in Ethereum, you actually just have addresses. And so that's the beneficiary's address or the miner's address.
00:08:19.420 - 00:08:52.678, Speaker B: And then the estate routes are the route of the Merkel, Patricia Merkel tree. After all, the state's been updated, given the transactions, the transaction route receipts, and so a whole heap of other stuff. But in particular, you've got this mixed hashing knots down the bottom. They're not included in that hash that you do of the candidate lock header. And in fact, this diagram here, you should go to that link there, and you can have a look at this diagram. And it's actually a massive diagram that someone did about two years ago. And I'm really kicking myself.
00:08:52.678 - 00:09:39.538, Speaker B: Two years ago, I didn't come across this diagram because it's really good. Anyway, so someone, if they ever meet this person, should buy them a beer or something like that. So anyway, you put together all the information of what your block is going to look like, assuming that you're the one who mines it, and then all the miners have to solve a puzzle problem. So we'll remember from our cryptography, part one. Actually, part two talked about this in the cryptography sessions about puzzle problems, but they're essentially time memory hard problems, where you can prove you've done some sort of computational work to someone. So maybe you've had to hash something a thousand times, something like that. You can prove that you've done computation.
00:09:39.538 - 00:10:26.470, Speaker B: And so that's what a puzzle solving is. And so the idea is come up with a way of proving that these people, these miners, have done that computation. So we've got a block period, happens every 15 seconds. And then any proof of work algorithm, you've got this concept of epoch, which is every 30,000 blocks. And so if you'll do the amounts you work out, that's about 125 hours, which is every, what, four or five days. So the idea is each epoch, the parameters for creating blocks increases, so it becomes harder. So it's trying to take into account that you might have more memory in the cpus, or maybe the cpus become more powerful.
00:10:26.470 - 00:11:01.646, Speaker B: So each epoch, what you do is you work out a seed value. And so that seed value is just the message digest of the previous seed value from the last epoch. So it just starts off at zero, and then each four days or so, you create a new seed value just based on the last one. So something that you could precalculate. Now, for all of the seed values off to infinity, you generate a cache based on the seed value. So this is another deterministic algorithm. And you generate a memory array, which.
00:11:01.668 - 00:11:04.970, Speaker A: Is initially it was 16 bytes.
00:11:05.050 - 00:11:49.406, Speaker B: Based on the cache, you generate a data set. So the idea is that those 250 C bytes available to you, but you could quickly generate each entry in the table if you just needed to generate one or two entries or some small number of entries. So the full nodes or the mining nodes, they keep this full data set in memory. Whereas if you're say a telephone or some sort of light client, you would generate this on the fly or the pieces of it that you need. And so it's actually really smart, Albert. You've got a small enough this cache, which is small enough that even a limited device like my telephone over there could easily have in memory. It could be pretty fast.
00:11:49.406 - 00:12:41.022, Speaker B: And then you can quickly generate the other bits that you need when you need them. Or if you want to be a mining node and do things really quickly, then you have it all in memory, but then you're a grunty server style in some sort of data center style computer. So as I was saying, as time goes on, the parameters increase to make things harder. And so the cache started off at 16 megabytes back in 2014 ish, and then it's grown by another 128 kilobytes each epoch. The actual total data set started off at a gig and has increased by about eight megabytes each epoch. So currently we're at block number that, which is epoch number 195. And so the case right at the moment it's about 40 meg and the data set is about 2.5
00:12:41.022 - 00:13:25.934, Speaker B: gig based on my calculator calculation. So I'm pretty sure they're right. So that's a fair bit of ram, but not a lot of ram. So each epoch is 125 hours long. And so all of the nodes across the network simultaneously realize that they're now moving to the next epoch. So they all switch and use a new cache and a new data set each time we hit a new epoch. So obviously if you're a full node or if you're a miner, you're going to have precalculated that, because the last thing you're going to want to do is spend a minute or two generating this and stop mining for a bit.
00:13:25.934 - 00:14:08.346, Speaker B: So you're going to have some computer that's going to precalculate all of these data sets for all epochs and we'll be ready to just swap them in as the epoch comes. So once you've got this huge data set, then what you do is use a algorithm called a hashimoto like algorithm. So hashimoto is a particular algorithm. Then of course it was changed and changed and changed. So now it's called the hashimoto like algorithm. So it's similar. And essentially it does lots of hash and essentially does grab 64 blocks out of that data set switch data set item, took 256 blocks from the cache to create a data set item, and now you're doing 64 of them.
00:14:08.346 - 00:15:08.218, Speaker B: So that means you're doing 64 times 256 accesses out of the cache if you're generating it on the fly. So the output of all of this is a mixed hash, which is an intermediate result, and the result itself, which is message digest of the message digest of the block header. So you remember how we had our candidate block header that we were thinking about having a nonce value, so a number once, so that's your own unique value. And then the mix hatch, which was this intermediate value. So you're mixing everything together. You've got an intermediate value, you're combining it with these starting parameters that your node has got, and then you're producing a result. And then when you want to work out whether you've mined the right block, you say, is my result that I've just come up with as an integer, is it less than the target? And so the target is a value that is calculated from block to block.
00:15:08.218 - 00:16:11.802, Speaker B: And the goal is to make sure that the inter block period is 15 seconds. So you've got the heuristic of how are we going? How's the actual hashing power of the network going? Should we make this target bigger or smaller? To make the actual probability of finding the correct hash or a hash that gives a result that's less than a target, what's the probability? Can we hit bang on 15 seconds? Obviously it's a variable thing because it's a probabilistic thing that you're actually going to come up with a. So what you do is you publish the value using the F protocol. So I think Rob Dawson did a talk on peer to peer protocol about a month or two ago, and in that one of those protocols was the F protocol. And that's how you push out. Here is my new block that I've mined. So all of these nodes, they can look at the values that are coming in these persons, hey, here's a new block.
00:16:11.802 - 00:17:22.374, Speaker B: And rather than them, because you could do a, a service attack where you get them to get all the nodes to do a fair bit of work to calculate whether that really is a valid block or not, because you're not just going to accept it just because some node said this is a valid block, you're going to have to calculate it. So as a starting point, you do this calculation based on the intermediate value. The reason why you do that is what is finding a value that will be the probability of coming up with this means that you've got to have a pre image, but then maybe you could come up with headers that isn't a valid header. But anyway, then it does some level of protection before doing the full hashimoto algorithm. So I was going to do a lovely graph about finality and probabilistic finality, but I ran out of time. And so if we ever do this presentation again or have a specific presentation on proof of work, I promise this slide will have something, have a lovely graph in it, and I'll be able to explain the probability. So in summary, proof of work gives you leaderless block creation.
00:17:22.374 - 00:17:55.534, Speaker B: So there is no leader. Each of those nodes is independently doing that proof of work calculation. It gives you architectural decentralization. So if one of those miners blows up, loses power or whatever, it doesn't stop the other miners from coming up with valid blocks. Is there political decentralization? I think my next slide is. Yep. So in my next slide here, I've got the overall hashing power and who has actually mined the best block for each time period.
00:17:55.534 - 00:18:42.740, Speaker B: And this is actually quite interesting. So you know how we talk about these 51% attacks? Well, if we have a little look here, you can see that we've got one, two, three, or even probably it's almost 1234. And then if these are owned by completely different organizations, so that's good. But if those three collaborated, or if those four collaborated, then you could imagine you could have a problem. They could coordinate their activities to come up with what block they want to produce. So though we have architectural decentralization, a political decentralization is a bit have to have a think about it. So when we now look at some of these other algorithms, they're maybe not as bad from the political centralization as you might think.
00:18:42.740 - 00:18:49.510, Speaker B: There are some things that you might want to have a look at to learn more and proof of stake.
00:18:59.610 - 00:19:28.914, Speaker A: So thank you, Peter. And you've done an excellent job of doing great detail with proof of work. The proof of stake is going to be like much higher level. I'm going to keep it high level because the actual details of proof of stake in ethereum is still in active development. And so there's been talk for a long time. You'll hear the words Casper being talked about. And so Casper has been three to six months away since I started at consensus, which was in October last year.
00:19:28.914 - 00:20:21.554, Speaker A: It's still three to six months away. And it's probably more on that six month end than the three month end. So I can talk about why you care about proof of stake, what it is, and sort of how it works a little bit, and a little bit about when it might be coming. So three sort of good questions for us to try and answer, and hopefully we'll come back with some answers for that. So why? The first is the cost of proof of work, and this is kind of foundational to all the other reasons as well. And so if you look at the cost of proof of work, it's kind of the amount of energy that goes into proof of work, probably across, like, you spread from just ethereum and you include bitcoin. If you just pick bitcoin or just pick ethereum, it's like the cost of running.
00:20:21.554 - 00:21:27.234, Speaker A: The amount of power that you use for proof of work is the same that countries use for all of their energy use. So I think Iceland sort of size is definitely less than what's being used by creep of work these days. So you can look on the net, there's a bunch of different charts which show over time, and you can sort of see the amount of energy that's being used by bitcoin, for example, kind of has that growth curve that you love if it's your product and it's uptake, but you don't love if it's the impact on the environment, because you're doing some sort of inefficient thing. The next thing with the proof of stake is like Peter's slide, where you've got these sort of mining pools in ethereum, where you've got, essentially, you could pick this ether mine plus any two of the other big ones, and you've got like a break of the 51 consensus, 51% consensus. You've got that same sort of thing. So proof of stake is something to try and address that. And that's a common picture across many of the blockchain.
00:21:27.234 - 00:22:10.086, Speaker A: So definitely bitcoin has similar sorts of effective centralization points. So our decentralized technology, which is magic, has ended up with a little bit of centralization happening again. So proof of stake is sort of aiming to address that. And I guess with that, proof of stake was something that Vitalik sort of had that was always a goal with Ethereum, was to move to proof of stake. And so the thing that you kind of need though, for proof of stake is enough people that are going to be doing the work for it to be a viable option first. And so that's why it's been on the roadmap is something to happen. And the other thing that you need is a migration path that everyone can agree to and a good sort of solid protocol for working with it.
00:22:10.086 - 00:23:03.478, Speaker A: And those migration path and the good solid protocol are the bits that are taking the time for us to get there. So I guess that green. So we're going to save the planet by not destroying the planet with blockchains. And the other thing that is there with privilege stake is putting in some strong economic incentives for people to do the right thing. And so there's the idea of slashing a stake if you cheat. And so I will talk about that shortly. How does it work from the high level? How does it work? Well, what you do is you put aside a bit of money or ether, some sort of cryptocurrency, and you say, this is my stake that I'm putting into.
00:23:03.478 - 00:23:39.860, Speaker A: So depositing the money, the ether into say, a smart contract, that's your stake. Everyone can see that you've deposited this large amount of money. And so that idea is that the validators have locked up some of their coins at stake. After that, those people start validating their blocks. And when they're validating a block, they put a bet on what they think the right block is going to be. The people that make the right bet win money and income from doing that. So is that kind of at a high level makes sense.
00:23:39.860 - 00:23:46.118, Speaker A: Dance bases, some nods, some shaking heads. Okay, so proof of work.
00:23:46.204 - 00:23:47.190, Speaker B: Can I ask a question?
00:23:47.260 - 00:23:47.878, Speaker A: Please do.
00:23:47.964 - 00:24:17.150, Speaker B: Okay, you say that they'll start validating. Difficulty with, I mean, with proof of work, we understand the mathematical problem, creating something that's based. You can read what Brad Zamfa has written, you can read a whole, but they never actually explain what validating, what is the process, what's the mechanism?
00:24:18.610 - 00:24:48.558, Speaker A: So it's similar to, I guess, the proof of work. You're taking together a whole bunch of transactions and inserting them and saying, here's my block. And then you do the crypto proof, which says, yes, this is definitely to show that you've done that work to validate that block. With here it's essentially just taking these things, putting them together, and saying, this is the block that I propose. And so you're not doing the proof of work on it. You're just saying, here is the block that I propose.
00:24:48.754 - 00:24:50.102, Speaker B: Subjective decision.
00:24:50.246 - 00:25:00.698, Speaker A: Yes. As per normal. I guess proof of work in some ways is a subjective decision as well because you're picking which transactions you're inserting.
00:25:00.714 - 00:25:47.386, Speaker B: Into the block, making sure they're valid. I mean, validating from the perspective of is this a valid transaction? Are you spending money you don't have? When you executed that solidity code, did it throw an exception and hence it shouldn't have been included in the block anyway because maybe there was some precondition that was set up in previous transaction. So that is part of the validation. That's the validation process. So who decides who we bet? How does that work? That's a good question. That's my next question. This is part of the problem.
00:25:47.386 - 00:25:55.374, Speaker B: How do you work out? How do you randomly assign who wins in a deterministic system, is it like.
00:25:55.412 - 00:25:57.278, Speaker A: The price is right where the person.
00:25:57.364 - 00:26:10.900, Speaker B: Closes to the number wins? No, this is an open question. There's a conflict down on the Gold coast where I'm presenting on how you, in a decentralized way to offer random number, but that's research.
00:26:11.990 - 00:26:34.460, Speaker A: So I think part of it's going to be a smart contract and some of it might end up being around robin type system where you've got a list of known validators that are working on it. And so Adrian's going to talk about the way that IBFT works and some of the BFTs. So the byzantine fault tolerance sort of algorithms and ideas that are coming from there are influencing some of the.
00:26:34.990 - 00:26:36.902, Speaker B: So you already have to be a known validator.
00:26:36.966 - 00:26:50.010, Speaker A: You can't just be. Yeah, for this you definitely are a known validator. Like proof of work where you can just connect and throw with block. And if you win, that's great. That's right. So you need to be a known validator that has. So who knows?
00:26:50.090 - 00:26:53.306, Speaker B: There are centralized databases for validators.
00:26:53.338 - 00:26:59.058, Speaker A: There's a smart contract that sits on the blockchain is typically the way that people have talked about it being. So when you say you're going to.
00:26:59.064 - 00:27:05.620, Speaker B: Be a known validator, doesn't it just really mean, you know, your customer, any money or anything like that?
00:27:06.150 - 00:27:23.194, Speaker A: Most likely the way that you're known is not really known known, but you are in advance declaring yourself to be a validator by. So the proof is the stake that you put validator, but you don't have to supply any kind of information about.
00:27:23.232 - 00:27:25.340, Speaker B: What kind of rig you're running or.
00:27:29.950 - 00:28:28.366, Speaker A: Yeah. So I think a part of that then is with the gaming and the betting of it. So part of it is going to be making sure that people don't bet on divergent chains and double bet. So if you can bet twice, then you effectively are not staking anything. And so part of the way that the work is going to have to be is if you do end up betting, having the idea of burning the money that you did bet, and so on this block being the right answer so that I can get it both ways and always win, if that's detected by doing this double bet, you're actually risking at losing money. So there's a strong, I guess, financial disincentive for doing the wrong thing. Okay, so I have kept it very, very high.
00:28:28.366 - 00:29:38.130, Speaker A: I have not covered any details. There are lots and lots of questions and lots of very good questions, most of which are actually going to be covered in how the implementation is done and what the implementation details are. Because it hasn't actually been implemented, it's hard to say what the exact answers are going to be. And so one of the things that's happening in ethereum at the moment is they've always talked about Casper being one of the next milestones that was going to be like a hard fork, which is going to be the Casper hard fork that's now changed, I think mainly influenced by cryptokitties, that being able to have some sort of scaling solution is where a lot of the research emphasis has been. And so the idea, whatever the proof of stake implementation is going to be, is now coupled tightly with the sharding work that's happening. And so there's, I think, a link there. So that notes ethereum.org
00:29:38.130 - 00:30:55.280, Speaker A: with a really friendly URL hand sitting there, has the details of what the current direction is going to be. And the thing that I guess has been the gold standard for how Casper was going to be rolled out has been the e one, double 10 one. And so that is now almost certainly not how it's going to be implemented, mainly because the whole sharding work that's being driven is, I guess, pushing it in a slightly different direction. So the ideas that we've been talking about, or have been talked about for a long time about how Casper and proof of stake is going to work in the zoom, and here's the direction we're going in, it's not quite going to be the direction that it goes in. So while some people have left and there's been some movement around, I think there's a bunch of really smart people that are looking at the mean. I think there's consensus, have people, there's the Ethereum foundation, Vitalik is not a dull guy, and he's sort of working on it as well.
00:30:55.970 - 00:31:04.980, Speaker B: And for those people who are busy writing down that URL, don't forget the slides have been put onto the slack workspace in general.
00:31:08.470 - 00:32:08.614, Speaker A: Okay, so going back to my how much to stake slide. So the answer is, it depends on the actual implementation. So the original Casper, there's a configuration. So Casper, the original version of Casper was sort of sitting as a smart contract where you would stake your stake against that smart contract, talking about 1000 to 1500 of an e, which in today's dollars is like 600,000 to about a million dollars worth of staking for it. The thing with that though is that there is startups that are saying, okay, join our pool and be a part of our stake. And so you don't need to stake the whole thousand e for yourself. You can join a staking pool and they will run something on a cloud host which does all the mining work and does the staking for you when you get to be a part of it.
00:32:08.732 - 00:32:18.278, Speaker B: What's to stop those pools just turning into the same kind of large slice of the pie that you see with proof work today?
00:32:18.444 - 00:32:26.680, Speaker A: I guess it's that financial stake and there is that risk, I guess. Still not sure.
00:32:27.050 - 00:32:38.240, Speaker B: Is there a capping on the number of validators? Because I know that done what EOS has capped its elevation substantially. Is there.
00:32:40.930 - 00:32:56.420, Speaker A: How do you a cap of the max amount of ether that you could put in? Yeah, so I don't think it's a hard cap. Apart from the fact that there's a cap on the.

00:00:00.170 - 00:00:00.720, Speaker A: You.
00:00:01.490 - 00:00:17.280, Speaker B: Hello and welcome, everyone. This is the Ethereum Engineering Group Meetup, and today we've got Matt Garnett here and he's going to tell us all about what EIPS are going to drop in 2021. And Matt, why don't you introduce yourself?
00:00:19.730 - 00:00:48.646, Speaker C: No problem. Yeah, thanks a lot for having me on, Peter. I'm really excited to go over what's going to happen in 2021 for the Ethereum Protocol, but just a little bit about me. My name is Matt. You probably see me more often going by the moniker like client on the Internet. I am an engineer researcher at Consensus and a small team called Quilt. We do a lot of research and development on the core Ethereum Protocols.
00:00:48.646 - 00:01:13.460, Speaker C: We started out doing a lot of work on Ethereum Two, and some of our work on Ethereum Two led us to Ethereum One. And a lot of our work on Ethereum One has led us to thinking about and understanding and trying to share what we're learning about what's happening and where the Ethereum Protocol is going with everybody else who doesn't have time to full time pay attention to what every chat channel is saying.
00:01:17.610 - 00:01:26.294, Speaker B: Cool, thank you. So I'm looking forward to the talk, so please share your slides and yeah, tell us.
00:01:26.332 - 00:01:26.870, Speaker C: Sounds good.
00:01:26.940 - 00:01:27.560, Speaker B: Please.
00:01:31.230 - 00:02:28.646, Speaker C: All right. So this talk kind of started as a tweet that I've sent out about a month ago. I had a very strongly worded tweet that said 2021 was going to be the most innovative year of Ethereum since 2016. And then I had a long thread of all of the EEPs that I think have the possibility of dropping this year or will influence what the direction of the Ethereum Protocol is going. And I guess Peter saw this tweet and he thought that this would be really interesting to share with you guys. And I'm really excited to have this opportunity to share with everybody because core development is not something that most people have their eye on. People are generally paying a lot of attention to what's happening at the application layer, what kind of applications are being built, and even a lot of people in the space who are developing products on top of Ethereum aren't paying as much attention to what's happening in the protocol.
00:02:28.646 - 00:03:17.806, Speaker C: And I think that doing a better job about sharing this information with people and even involving everyone in the conversation. Then we can try and understand what the needs are of people and try and build a protocol that meets the needs that people desire. And this talk is hopefully going to be a little bit back and forth. I think that if I just go through it straight, that we're only going to be here for 30 or 40 minutes, but I would love to discuss the different EIPS and changes. So if you have any questions, feel free to just jump in and we can talk about some of that stuff. So before we talk about some of the future things that may happen in 2021. We can talk about the things that we know will happen in 2021.
00:03:17.806 - 00:03:54.998, Speaker C: And we know that the next hard fork for Ethereum will be called Berlin. And it's slated to have five different EIPS. And we expect this hard fork to happen in the next one to two months. And I'll talk about a couple of these EIPs a little bit more in depth, specifically 20 718 and 20 315. But let me just give a quick summary of these EEPs that we won't talk about more in depth later. So 29 29 is kind of the core change that this hard fork is going to have. And it is a gas cost increase for Opcodes, that access state.
00:03:54.998 - 00:04:45.446, Speaker C: So the S load Opcode is going to go from costing around 800 gas to costing about 2100 gas. And the reason for this is that there's been a lot of simulations and the developers believe that the actual computational cost of doing an S load is not properly reflected in the current cost of it. And so they want to increase it. And one thing that they saw when they increased, they did some simulations over the last few million blocks and they saw that about 0.1% of transactions on Mainet would fail with this gas cost change. And generally, core developers don't want to break things that already exists. There's kind of this unwritten code that says that if something is working on main net, that it should continue to work.
00:04:45.446 - 00:05:38.438, Speaker C: And we could debate that for hours on whether or not this is a good thing. But this is kind of what we believe today. And so they wanted to introduce a way to unbreak those transactions that will be broken 29 29. And so 29 30 is exactly what will unbreak the transactions. And to do that, they separate the way that you pay for S loading data and they allow a transaction to accept an access list, which in the access list you'll say, okay, in this address I want to access this specific state element. And whenever the transaction is, you calculate the cost of the transaction, part of the intrinsic cost, you have 21,000. That's the intrinsic cost of transaction.
00:05:38.438 - 00:06:49.178, Speaker C: And you add I forget the exact parameter, but you add around 2000 per element in this access list. And then whenever you're actually executing the transaction, it only costs 100 gas. And because the way that a lot of those contracts are written, they're passing only maybe a fixed amount of gas to a contract and that's what's causing it to break. And so whenever it only costs 100 gas, this is less than it was before in the contract's eye. And so this allows these transactions to continue to work. But the really neat thing about 29 30 is not just the reactionary introduction because of 29 29, it's also forward thinking in that it allows the core developers to have a lot more flexibility in how much is charged for state access. In the next hard fork they could again increase and they would know that optional access lists will continue to provide a method that people can spit transactions without having the contracts broken.
00:06:49.178 - 00:07:19.350, Speaker C: So that's a really interesting EIP. And so those are two really important things that needed to happen to the Ethereum protocol. And so we'll talk a little bit more about 2000 and 718. But 20 718 is kind of the method in which these optional access lists are understood in the protocol. We'll talk about simple subroutines later. And the last one is kind of just a housekeeping sort of EIP. The modular exponentiation pre compile.
00:07:19.350 - 00:07:50.740, Speaker C: The authors of the EIP found that is actually overpriced for what was really happening in the computer hardware. And so what they did, they did some simulations to come up with a better formula for actually calculating how much that pre compiled call would cost. So these are all the things that are slated for Berlin. We're kind of in the final testnet stages. I would expect this to happen in the next one to two months. Does anybody have any questions on those heaps that we just discussed a little more in detail?
00:07:55.130 - 00:07:56.374, Speaker A: I have one.
00:07:56.572 - 00:07:57.320, Speaker C: Yes.
00:07:58.570 - 00:08:12.540, Speaker A: This access list storage slots that are accessed by the transactions are coming along with the transaction, right?
00:08:12.910 - 00:08:13.660, Speaker C: Exactly.
00:08:14.430 - 00:08:15.962, Speaker A: Okay, cool.
00:08:16.016 - 00:09:19.182, Speaker C: Yeah, exactly that. And there's a lot of other nuance about this that you could kind of get into around. The ideas of an access list is only as good as the state under which it's being executed. You can imagine that if I create my access list based on a uniswap transaction that I run at block in and then block N plus one, it's moved so much that my transaction is no longer valid because there would be so much slippage. And so now my access list doesn't even make sense. And so there are concerns around how it is pretty rigid in how it's implemented, but for the purpose that it serves of unbreaking things, it's definitely doing that. Okay, so to start just talking about some of the things that we may see in 2021, it's kind of unfair to go through a list of grand EIPS that are going to significantly change Ethereum without talking about the grandest EIP that's being worked on at the moment.
00:09:19.182 - 00:10:17.140, Speaker C: And that's the serenity EP. This is something that was drafted and I think it's in the review stage and obviously Phase Zero launched in 2020. But this is a really important EIP because it officially begins this transition of ETH One and ETH two sort of being separate entities and having their own mechanisms which they come to agreements on specifications and stuff. And so this is really the bridge between those two kind of governance worlds. The most important technical thing that it really specifies is just what is the Ether issue and schedule during this transition of having both a proof of work and a proof of stake chain. So in 2021, I expect that we're going to see more EIPS related to ETH Two. And eventually I think that everything is going to be merged together where E Two will create EEPs whenever it wants to upgrade, much like E One does today.
00:10:17.140 - 00:11:12.850, Speaker C: So the biggest change that I expect that will really affect ETH One is probably going to be EIP 1559. And I think that most people on this call are familiar with it to varying degrees. But just a quick recap of what the change that 1559 will bring to us today. If you have a transaction and you submit it, the entire transaction is going to go to the minor. And you can kind of see in this example, like, all 100 GWe per gas spent will go to the minor. With 1559, this actually changes so that now a transaction will have a base fee at a tip, and the base fee will be burnt and the tip will be sent to the minor. And there's a lot of reasons why people believe that 1559 is a better fee mechanism.
00:11:12.850 - 00:11:48.398, Speaker C: There's a lot of economics that I'm really not an expert on. I recommend reading. I think it's Tim Roughgarden's paper that goes through the economics of it. But the high level, the way that gas prices are done today is very inefficient. It's kind of known as this first priced auction, and in the literature it's been shown to be a pretty inefficient way of doing these auctions. So 1559 is a much better mechanism in that sense. It doesn't make sense how we've kind of implemented blocks today.
00:11:48.398 - 00:12:52.866, Speaker C: They're so rigid in the sense that once you have found enough transactions to reach the gas limit, it doesn't really make sense that it cuts off so immediately right at the gas limit and that there's no slack for it to expand and contract with demand. Just like the social construct, like just including another 110 bytes to submit an additional transaction and some additional gas to include it. Like whatever the computation is, it just makes a lot more sense to have a little bit of slack there to reduce these extreme spikes in demand. And this is what 1559 wants to tackle. And then the other thing is the base fee. The base fee is there to kind of help adjust the cost dynamically with demand so that people aren't overpaying significantly just because they want to immediately see a transaction go through. And that's kind of what you see today.
00:12:52.866 - 00:13:46.120, Speaker C: If you want your transaction to immediately go through, you might significantly overpay what the real market rate is. The base fee will hopefully alleviate some of that. 1559 isn't going to magically increase the throughput of the chain, and most people tend to believe, and I think that there's pretty good analysis, that 1559 isn't actually going to make interacting with ethereum cheaper maybe on average it will because it is going to smooth out some of these extreme spikes. But in general, 1559 is going to improve the ergonomics of ethereum, but not necessarily increase the throughput and need the technical details around that. Does anybody have any questions on 1559? I it.
00:13:48.330 - 00:14:06.300, Speaker B: So with 1559, if I've got a transaction, there's no scope for me to be paying, say, two gigawee for the transaction as the gas price. It's got to be the base price plus something.
00:14:07.550 - 00:14:47.206, Speaker C: The base price is set to one. I think it's like one nano way and I forget the exact conversion. But depending on demand, it would be possible to have a two gigaway transaction. The base fee is going to move dynamically with demand. And so if we're seeing empty blocks consistently, the base fee will go down to approaching zero, at which point all you would pay is your tip. And if the blocks are empty, the tip may be minuscule anything at all.
00:14:47.388 - 00:15:10.000, Speaker B: Okay. Yeah. So essentially if we get to sub 100% blocks regularly, because that's all you need to do is get to about 80 or 90% four blocks and then suddenly the bottom price is very low. Okay. And that would still exist. So if people slow down their usage, then the price will drop. Cool.
00:15:11.170 - 00:16:21.254, Speaker C: That also reminded me one interesting thing I thought about 1559. At least 1559 has gone through a lot of iterations and the latest iteration, an interesting thing to note is that it actually doesn't have any mechanisms for moving the gas target. And the gas target is very similar to what we think of as a gas limit today, but it is exactly as more of a target rather than a hard stop because you do have this flexibility on expanding, contracting the size. And the gas target in the original 1559 proposal was going to increase and decrease with demand, kind of similar to how the base fee does, but it was eventually dropped through their iterations. And so today the gas target will be malleable in the same way that the gas limit is today and that's miners can sort of decide what they want the gas limit to be and sort of move it in that direction. About 1% a block, I think. And I thought that was like an interesting thing, that the gas target is going to kind of remain around twelve and a half million unless miners decide that they want to try and increase it.
00:16:21.254 - 00:16:31.530, Speaker C: But the protocol will accept blocks now up to two times as large if there's enough demand, meaning that there's enough people willing to pay the base fee and the tips.
00:16:36.510 - 00:16:37.498, Speaker B: Makes sense.
00:16:37.664 - 00:17:32.502, Speaker C: So assuming miners don't change anything, the biggest blocks we might see with 1559 is 25 million gas. Okay, I said that we would talk a little bit more about the 20 718 type transaction envelope. And so this is one of the IPS that is scheduled for Berlin. But this is a pretty significant change. I think it's like one of the most significant changes to the actual consensus code in the last few years. I think big changes that we've seen is create to adding the ability to have Arbitrarily sized return data, but things like even changing how you interpret signatures in Ethereum. These are all things that didn't change the structure of consensus objects.
00:17:32.502 - 00:18:37.874, Speaker C: And 1559 will change the structure of the block, it will add the base feed to it. But 20 718 is the first time that we're really going to change what a transaction, how it's represented, when it's encoded and decoded. And the way that this EAP has been implemented is whenever you want to introduce a new transaction type, you kind of define what the payload of that transaction and what the encoding scheme is. And so there's the possibility of doing RLP, there's a possibility of maybe doing some other encoding schemes. But the way that clients understand how to decode the remaining bytes is they read the first byte and that acts as a discriminator. And so 29 30 transactions will be a new type of transaction because they have this optional access list. And for clients to understand that they need to decode it in a different way than how legacy transactions are decoded, they will read that first byte and the discriminator will be, I think it's one.
00:18:37.874 - 00:19:25.022, Speaker C: And so if that first byte is one, it will decode the remaining bytes which are ROP encoded, and they will decode that into this access list transaction. And 50 59 will do the same thing. It will probably be transaction type two. And so clients will read that byte and then they will decode the remaining RLP bytes into a 1559 transaction with the tip and the fee cap. And so this generally opens the door for innovation. I think there's been desire for different types of transactions in the past, but there wasn't a good mechanism to do it. And the reason I say that is because the way that you encode things in Ethereum, we use this encoding scheme called ROP.
00:19:25.022 - 00:20:03.020, Speaker C: And ROP only has a few primitives. It kind of understands integers, it understands some bytes, it can understand hex strings, and it understands lists. And lists are kind of the core building block. There's not structures. You represent structures just as a list of elements. And if I wanted to decode a transaction, I would have to look to make sure that that list had I forget nine elements or however many elements are in the transaction. And so you could have an overlap because you could have two types of transactions and they might have the same number of elements and you can't differentiate between the two.
00:20:03.020 - 00:20:43.366, Speaker C: And so this has kind of made it difficult to introduce new things, and I think that's made people less willing to introduce this stuff. And so now that we have this discriminator, this kind of opens the door for some cool stuff. And these are a few EEPs that were kind of either they specifically inspired 20 718, like 20 711 came first. And the author realized that there was two things there. There was typing the transaction and then there was like the actual functionality that they wanted. And so they wanted to have transactions that could be paid for by other people. They wanted to have things that could expire.
00:20:43.366 - 00:21:29.798, Speaker C: They wanted to batch multiple operations. And there's other ones too, like rich transactions. You could have a transaction type which allows you to submit some sort of script, just EVM bytecode that's executed in the context of an EOA that would allow you to batch operations together and allow you to take the output of a transaction and use that to determine how to continue on. And these are things that are just not possible today with EOA accounts and account abstraction is something similar. It allows you to abstractly define the validity of transactions. And there's other stuff that could be possible. But I think the cool thing with 2000 and 718 is that it at least opens the door for those things.
00:21:29.798 - 00:21:50.590, Speaker C: I don't really expect this stuff to come in 2021. I think that 2021 is going to be very busy with 50 and 59 and East Two and these things. But maybe in the future we have the primitive now. Hopefully we can add some things that significantly improve the UX of interacting with ethereum.
00:21:52.050 - 00:21:53.540, Speaker B: Could I ask a question?
00:21:53.910 - 00:21:54.660, Speaker C: Sure.
00:21:56.710 - 00:22:17.960, Speaker B: So a byte gets added to the payload. How is this backward compatible? Is it going to be a protocol version change for the dev P to P? Is that how the clients are going to differentiate that this is a transaction that's got this byte at the front?
00:22:18.750 - 00:22:55.090, Speaker C: Yeah. It's important to break this into two different changes that are happening. The first is that first to say like the legacy transactions, they stay the same. Kind of the way you determine if you have a type transaction or a legacy transaction is when you're RLP decoding it. If the first byte is like a list length prefix that starts with F or something, then you know that's a list. If it starts with just an RLP byte, then you kind of know that's a type transaction. But there's kind of two different areas where type transactions come into play.
00:22:55.090 - 00:23:32.698, Speaker C: And that's like you said, dev P to P and then the consensus layer. And it turns out that in the consensus layer, there's no concept of lists of transactions. There is only transactions that you're executing. And then there's the transaction try. And the way that you generate the transaction try is you actually just insert the transactions into a try and then calculate the root of it. And so that doesn't require having a list of them. But for dev P to P, there actually does require having a list of transactions, because whatever you request or whatever, you're just propagating new things that you see, you send an ROP encoded list of transactions.
00:23:32.698 - 00:24:12.282, Speaker C: And there was a lot of debate about how exactly to encode this, and there's a lot of different ways you could do it. But what they ended up deciding is that the way that type transaction legacy will stay the same, but the way that type transactions would be encoded is you would encode the type transaction. Like we said, the first byte will be the discriminator, and then the rest is the payload. And then you would RLP encode that as if it was an RLP string. So the prefix will be B and then whatever the length is. And so that way, whenever clients are reading dev P to P messages, they'll say, okay, that was a legacy transaction. I understood that.
00:24:12.282 - 00:25:02.510, Speaker C: Okay, the next thing is an RLP string. Let me decode that string, and then let me decode the inner value of it to get the type transaction. And the way that they're making that backwards compatible with other clients is they're kind of overloading the meaning of transaction in old dev P to P protocols. So even if you were on e 63 or 62 or whatever, whenever you decode a transaction instead of whatever was defined in that ETH protocol, you will just use the latest, the newest understanding of what a transaction is. And so you kind of just abstractly know that your message is a list of transactions and then you use kind of the Berlin hard fork decoding of that list of transactions.
00:25:05.410 - 00:25:07.440, Speaker B: Okay, that makes sense. Thanks.
00:25:08.450 - 00:27:08.898, Speaker C: And so one of the complicated things about that is when you kind of overload that, you run the risk of you have upgraded your client, but your peer has not upgraded their client, and you propagate a new version of the transaction. And because there isn't a mechanism for understanding types of transactions, it just looks like garbled bytes to this old client they might disconnect from you. And so it's really important that all the clients when we go to this Berlin transition, that they do not accept transactions that are of 29 30 type until after the fork, because up until the fork, it's fair game to continue being part of consensus and not have an updated client, but afterwards it's acceptable. That was like an interesting thing that I thought that client developers came to the agreement on. Okay, so the next one wasn't actually in the original list of EIPS that I wrote on that Twitter thread, but this is 29 35 safe historical block hashes. And over the past few weeks, I've been spending some time, I've been going to the optimism live streams that they've had on Twitch, just kind of understanding a little bit more about how their code works and just thinking about more about some optimistic roll up things in general. And one interesting thing that I kind of came across is that the way that optimistic roll ups kind of work today is that they generally have to take the input transaction because whenever you submit a stage transition for an optimistic roll up, you have to submit your new routes and you have to submit the transactions.
00:27:08.898 - 00:28:00.994, Speaker C: And the way that most of them do it is they take those transactions from the call data, they bring it into memory and then they try and create some sort of authentication for it. And so they generally try and hash them and create like a root. And the reason they do that is because there is an inherent limitation on what the protocol can serve for block hash. Block hash will only return they can only return a hash from the last 256 blocks. So I can't go to a contract today and say, what is the genesis hash of Ethereum? Because that's more than 256 blocks old. And block hash is not really used for many useful things as far as I'm aware. I did a little bit of analysis and I think it's generally just used as like a pseudo source of randomness.
00:28:00.994 - 00:29:05.580, Speaker C: So people aren't using it as an authentication of what a block was. And so for pseudom randomness, you just need the last 256 blocks, that's really no big deal. But if you want to prove something about a certain block, then it can be particularly helpful to have more of those. Because if you want to prove something beyond one and 156 blocks, you have to include every single block starting from that 256 block and prove all the way down to where you want to go and then hash all of that input data and make sure that the routes match up. And so it's really expensive to do that on chain. And optimistic roll ups would benefit hugely from just taking advantage of what clients already do because clients already calculate these transaction routes. It's trivial to just create proofs against those blocks, it's just the block hashes aren't available.
00:29:05.580 - 00:30:12.750, Speaker C: The unfortunate thing is that because the way that this system is set up where you only have that limited number of blocks and that optimistic roll ups have to implement their own hashing schemes. There's a post a few weeks ago about the optimism roll up in it and they said that the cost of the transaction optimism roll up was around 27,000 gas. And that wasn't even executing. That wasn't executing a fraud proof that's 27,000 gas just to include the transaction on chain. And that's a lot higher than what the theoretical best we could do is. Because if you say a transaction is on average 110 or 120 bytes and the gas cost of a transaction is or the gas cost of a byte of call data is 16 gas, then you should really only be spending a few thousand, two, three, 4000 gas per transaction. And so they are coming in around five times potentially six times worse than this.
00:30:12.750 - 00:31:26.866, Speaker C: And the reason is because they have to do all of this work to calculate the routes and bring the call data into memory and operate on it whenever clients are actually doing all of this already. So 29 35 is I'm really talking more about it as just like the general idea of making historical block hashes available. The way that 29 35 does it is actually really interesting. And it's not really clear if that's the best way or the preferred way to do it. But it says that we should introduce a new pre compile and that pre compile should have some certain state layout where whenever a new block is minted or mined, you just put the root of that block into a certain storage slot in that, and then you just calculate as part of the state try. And the reason that they do this instead of creating a new data structure is just philosophically, if you think about a state transition for Ethereum as the input is a block, the current state try and a transaction, I guess the transaction is a block. So it's just a block and the state try then that's a really simple formula.
00:31:26.866 - 00:32:20.330, Speaker C: And if you had to add another data structure to keep track of the block hash, that would be three inputs. And so, philosophically, I think that's why they put it under the state try rather than a separate thing. If that's the best thing, that's not really clear. But I do think that in general, having the historical block hashes is really important and I think this has a really good chance of being included in a hard fork this year because it's something that has been desirable even back in 2016. I think EP 98 or something was talking about the idea of having these historical hashes available. So this is something that I really think is likely to happen this year. Does that make sense? Is there any questions about why that's useful?
00:32:25.390 - 00:32:26.700, Speaker B: It sounds good.
00:32:27.630 - 00:33:40.210, Speaker C: Cool. Okay, so EIP 31 two, the binary try structure. This is an EIP that describes how to change the current state try, which is a modified Patricia Merkel tree, which is a hexary try, meaning it has like eight nodes coming out of some sort of extension node to a binary try where each node only has two children maximum and there's a lot of reasons for it. Why did they go with hexare state tri? In the very beginning. I was doing some old GitHub issue spelunking and I came across an interesting write up that the Hexaritry was originally chosen because it was believed that Hashing was going to be a massive bottleneck in. Ethereum because there's going to be so many state trinodes and hashing is an expensive operation and so hexarit tries are a bit more optimized for minimizing. That hashing because you do have eight elements in there and those are just concatenated and then hashed.
00:33:40.210 - 00:34:39.630, Speaker C: But what people have found over the years is that hashing really is not the bottleneck. State access is like gray lay outweighs whatever bottleneck the hex area try the hashing was introducing. And so if we're not even getting the benefit of minimizing hashing that really removes the desire to have the hex area try. But there's more of a proactive reason to switch to the binary try and it supports much more efficient merkel proofs. I think that there's several people on this call who have done a lot more research than I have into stateless ethereum and why this is the case. But generally the numbers have shown that efficient merkel proofs are generated out of binary much more efficient merkle proofs are generated out of binary tries. And as we move to integrate ETH one and ETH two we introduce these things like stateless ethereum and maybe shard execution.
00:34:39.630 - 00:35:34.290, Speaker C: Merkel proofs are very important and so if we can reduce the size of them, that's huge. And for that reason this VIP is almost definitely going to go in in the next twelve to 18 months. I put as like a last little thing that it resolves a long standing frustration of developers. Hexary tries are just less intuitive to reason about than a binary try. And that's not necessarily a reason to ever make a massive change to a protocol, but it's kind of just like the bonus point of a lot of other good things about this change. All right, we'll go on. We have an unnumbered EIP the merge.
00:35:34.290 - 00:36:29.770, Speaker C: I expect this will definitely have an EIP number this year. And the merge is kind of the name of this process where ETH one begins to use the proof of stake consensus engine in ETH two rather than the proof of work consensus engine. And I think that we have kind of the leader of the merge effort on the call at the moment, Mikayo. So if there's any questions, I'm sure he can answer them much better than I can. But this is a very exciting EIP. I definitely think that this change is going to come in the next twelve to 18 months because there's just so much desire to not have this fractured ecosystem. And especially as the price of ether significantly increases there's even more pressure from external sources to unlock validator funds.
00:36:29.770 - 00:37:38.746, Speaker C: And I didn't write this down, but there's also pressure from miners with 1559. There's a lot of changes that are happening to the ecosystem and the faster that we don't want to rush something and we want to make sure that it's done the best way and it's the most secure that it can be. But there is a lot of pressure from a lot of different areas to reorient ethereum as one distinct unit rather than two different kind of protocols. One important thing to mention is that the merge itself is a very specific piece of the ethereum upgrade path and there's a lot of things about Ethereum Two that are said that Ethereum Two is going to make Ethereum so much more scalable. And I don't want people to get the idea that as soon as the merge happens that they're going to be able to submit more transactions at cheaper prices because the merge is just a very small piece of that. There's a lot of other things around increasing the data availability, and that's a completely separate topic. And it turns out that those aren't even like serializable projects.
00:37:38.746 - 00:38:02.440, Speaker C: Those are things that can really be done in isolation and it's really about which ones are complete first that goes in first. And so we may end up seeing that the merge happens before we have the scalable data availability layer. And if that's the case, then no, just using E Two consensus engine won't necessarily lead to a much more scalable system.
00:38:06.410 - 00:38:34.100, Speaker A: Thanks, Matt, for describing this. Yeah, it's definitely going to be like an EIP this year. One of the biggest challenges is to pass this EIP through the all core devs governance process. Actually, we're about to start moving to the all core devs since this week.
00:38:34.550 - 00:38:39.860, Speaker C: That's awesome. Excited to have everyone discuss it more.
00:38:41.030 - 00:38:42.820, Speaker A: So we'll see how it goes.
00:38:43.510 - 00:38:45.330, Speaker C: Yeah, fingers.
00:38:47.770 - 00:39:16.990, Speaker A: Yeah, definitely. Yeah. I was just going to ask to the previous slide as well to ask the question. Yeah. The binary tri structure, as Joseph just posted in the chat. So there is also a workal trees that have been proposed by Dengrad recently. There isn't the AP yet.
00:39:16.990 - 00:39:23.758, Speaker A: Right. But this is probably one of the alternatives to the binary try structure.
00:39:23.934 - 00:40:10.560, Speaker C: That's true. Yeah, that's a good point. And that's something that's really flown under my radar lately. I am really apprehensive to imagine that the core Ethereum protocol will I don't know, I guess that it's really not that complicated of a system. I read some ETH research posts last year talking about, I think, kind of the idea of the vertical try and at that point it seemed like regenerating these things every block because I assumed that it's using some sort of polynomial commitment scheme that was still infeasible. But I don't know. I definitely think it's going towards where we want to go.
00:40:10.560 - 00:40:16.100, Speaker C: I'm just apprehensive that that's something that's going to be ready in the next couple of years.
00:40:18.070 - 00:41:18.280, Speaker A: Yeah. From my understanding, the oracle tree just suggests, let's say we keep the same hexery try structure, but we replace Hashing with categ commitments. So it will be not like you're rebuilding the whole thing bridge block, like the huge yeah, so it will be just replacing Hashing and the try structure can be the same anyway. If we replace miracle Patricia try as we have it today, it's a breaking change to the applications, probably because I'm not aware, but probably some applications really use these miracle proofs built against this try today. So it's a huge change, I think.
00:41:20.810 - 00:41:30.860, Speaker C: What are your thoughts on breaking changes related to the merge. I think there's definitely going to be some things that will be different.
00:41:32.190 - 00:42:11.590, Speaker A: Yeah, we will try to avoid as much as we can, but anyway, it's not possible to keep up with all the things that were like Hoof works related, like the block hash which is used for MLS. If we can't support both semantics of the block hash, that's going to be the problem. One is the randomness, the other one is verifying the block header.
00:42:14.890 - 00:42:40.960, Speaker C: Yeah. The interesting thing is 1559 will also modify the block header. So breaking changes are definitely coming to Ethereum. I think that you guys are doing the right thing about looking to see who and how are things used and trying to understand the impacts and avoid breaking things that are being used for very important applications and things that are being used by many people.
00:42:43.430 - 00:42:55.060, Speaker A: Yeah. My intuition is that we should talk with the community more and see the feedback on these kind of things.
00:42:56.570 - 00:43:16.070, Speaker C: Yeah. Well, thanks for that information about the vertical trees bringing up Joseph's comment and I don't have the chat open. Any other questions for me or Mikael about the merge?
00:43:17.470 - 00:43:44.450, Speaker D: Oh, yeah. I wonder during all these mergers, how much does it impact everything that many people with wallets are not really participating? You see all the speculation going on buying all the cryptocurrency. Would you guys say it's really sort of slowing progress and distracting that lots of these people aren't really as involved even though they have the currency?
00:43:46.090 - 00:44:11.390, Speaker C: I don't think that that's necessarily slowing anything down. The goal of the merge is to allow for the highest degree possible, everything to continue operating the same. And I don't necessarily think that that demographic is someone that is significantly guiding us to the future, deciding future changes for the Ethereum protocol.
00:44:13.410 - 00:44:22.590, Speaker D: But in sort of like majority voting and all that, if you ask people to vote and then there's no sort of feedback.
00:44:24.290 - 00:45:07.600, Speaker C: Okay, I see. Yeah. This is like the most complicated thing about governance, right? You have all these DeFi governance projects. You can just buy tokens to vote for things and that doesn't necessarily create the best outcomes. I wouldn't want the Ethereum protocol to be a plutocracy where you can just use a token to vote. But if you don't have a token to vote, then you don't have a great metric that you can just look at and say, oh, this is what majority said and so this is the best thing to do. And so it creates like a very murky water to try and get feedback from different groups of people and understand what the community wants.
00:45:07.600 - 00:45:16.100, Speaker C: I don't know if I'm getting to your question. I may still be misunderstanding. It.
00:45:17.830 - 00:45:19.746, Speaker D: Makes more sense. Yeah, thanks.
00:45:19.848 - 00:45:20.500, Speaker C: Okay.
00:45:31.850 - 00:45:32.294, Speaker A: All right.
00:45:32.332 - 00:46:27.866, Speaker C: We can move on. If there's nothing else, then see, we are doing okay. EIP 20 315 is another one of those Eeves that we talked about the very beginning that are going into the Berlin hard fork and this EIP has actually been ready for quite some time. It's sort of been waiting for a hard fork to go into and Berlin is the first hard fork in quite a while. And so obviously it's going to be included. What this EIP is going to give us, it's going to significantly improve how contracts are written who need to make lots of jumps between internal functions. And a lot of times, whenever you're implementing or if you're writing the solidity, it gets implemented into a way where if it needs to return to a certain place in code, then you kind of have to juggle this.
00:46:27.866 - 00:47:48.580, Speaker C: On your execution stack and it ends up being a bit messy and increases the complexity of the code and increases the cost of executing. And so this new stack that is introduced to actually track return addresses to where whenever this return sub is called, it should actually go back to. And so these three opcodes are introduced. The jump sub is whenever the jump sub is called, it looks at whatever the program counter is, it adds that to the subroutine stack and then it jumps to a begin sub label that starts executing the subroutine. And then when the subroutine is complete, it returns and calls the return sub and the return sub pops off the last top element of the subroutine stack and sets the program counter to that plus one and then continues executing. And obviously you can have nested subroutines and what have you, but this is just going to be a nice EIP to improve how contracts are written and the handling of internal functions within contracts and stuff. It any specific questions on this one?
00:47:49.270 - 00:48:04.118, Speaker B: Not a question, but a comment that I think this will make code analysis of EVM bytecode much simpler for code that's been compiled, say with a solidity version that supports really? Yeah.
00:48:04.204 - 00:48:09.962, Speaker C: Is that just because there's a lot of manipulation of stack to get the return address back off?
00:48:10.016 - 00:48:17.500, Speaker B: Usually, no. Well, you'll know, where functions are supposed to be at the moment, it's a bit of a mess.
00:48:18.270 - 00:48:19.340, Speaker C: Okay. Yeah.
00:48:19.890 - 00:48:23.840, Speaker B: Actually analyze the actual where code is and how it all fits together.
00:48:24.290 - 00:48:25.662, Speaker C: Yeah, that's a good thing.
00:48:25.716 - 00:48:26.510, Speaker B: Simpler.
00:48:27.650 - 00:48:55.960, Speaker C: Yeah, that is true. The interesting thing is we'll have to see, I assume like Solidity, the Solidity compiler will pretty quickly get on this, but it will be interesting to see how contracts written with this will compare in cost and how they look at the bytecode level to ones that are compiled with the legacy forks in mind.
00:49:00.490 - 00:49:57.930, Speaker B: Susie obviously had some ideas on that. Forgetting what I mean, I assume you'll have a begin sub would replace a jump desk and your jump sub is going to be just another jump, so those two aren't going to add anything and the return sub is going to replace a return so I don't think it's going to make your code any bigger. So you're not going to be paying more to store the actual contract. And I assume they'll be priced in a similar way to the existing op codes. So it shouldn't change price or size of a contract. That's my guess. I would also speculate, not having any knowledge at all and just guessing, but I would have thought that the Solidity team would have an alpha release that produces this stuff already.
00:49:57.930 - 00:50:09.950, Speaker B: And if you maybe turn the right sort of options on, you might even be able to produce this sort of contract. That'd be a speculation.
00:50:10.930 - 00:50:22.306, Speaker C: That would be great if that was the case. But we are in the field of cryptocurrency and blockchains and so nothing's ever given.
00:50:22.488 - 00:50:32.038, Speaker B: Yeah, well, one of the big pushes for this EIP was the Bloke used to be the head of security and I can't remember his name off the.
00:50:32.044 - 00:50:33.394, Speaker C: Head, but greg COVID?
00:50:33.522 - 00:50:39.034, Speaker B: No. For ethereum foundation. Is it Martin somebody rather I can't remember.
00:50:39.152 - 00:50:42.314, Speaker C: Oh, yeah, Martin Swinde was the think.
00:50:42.432 - 00:51:07.120, Speaker B: Yeah. And so and I think he and Alex, who works on the Solidity compiler, I think they were having big conversations on the Ethereum Research Discord Channel and that's back months and months ago, so actually back in mid last year. So I reckon I've probably got a version ready to go.
00:51:07.570 - 00:51:44.842, Speaker C: Yeah, that makes sense. It all right, we can move on. I think we're getting pretty close. Just probably a couple more EIPS. Another smaller EAP is 29 37. This is an EIP that introduces a set indestructible opcode. This is basically just creates a new context variable within your frame of execution that says if self destruct is called, do not allow it to destruct the contract.
00:51:44.842 - 00:52:36.560, Speaker C: Just accept the gas for self destruct or whatever and treat it as sort of as a no op. And there's a lot of different reasons why you might want this. If it's a library contract, it might be nice to reason about that. That contract is always going to exist. You can kind of do this today by statically analyzing, you can do this today by statically analyzing, but that requires going through the contract looking to see is there a self destruct opcode, is it possible to run, does it delegate call into something that might self destruct? So there is a little bit more work that needs to be done to actually do it. Whereas what was envisioned with this EIP is that this opcode would be the first buy of the contract. And so you could in constant time determine if a contract is indestructible or not.
00:52:36.560 - 00:53:49.378, Speaker C: And the real origin of this EIP was a lot of work that went into account abstraction. And without going into too much detail, account abstraction allows you to programmatically define if a transaction is valid. And a major issue with account abstraction that needed to be solved was how can you deal with the chain reaction of validity requirements collapsing. And so you can imagine that your transaction relies on 100 different things that exist in Ethereum and the 101 thing that it depends on is like the existence of a contract. And so now all of a sudden that contract disappears and all of your entire chain of dependencies fall through and your transaction becomes invalid. And then maybe as a byproduct a couple of hundred other transactions become invalid and that would create some sort of denial of service vector for clients because they could never know. How much computation is it going to take to actually validate this account abstraction transaction and put it into the chain.
00:53:49.378 - 00:54:42.886, Speaker C: And what set indestructible allowed you to do is actually reason about is this contract always going to exist? And if it's always going to exist, then we know that we can depend on it, maybe we can't depend on some certain state element within it, but at least we know that it's going to always exist. And so that was the origin. It kind of split out from a kind of abstraction because the authors believe that there is some value in being able to reason about in constant time if a contract will always exist. And this is something that we might see in 2021. It's just a little bit lower priority than some of the other stuff we've talked about. But it is an interesting little EEP that could allow for some interesting use cases. It probably not many questions on that.
00:54:42.886 - 00:55:43.526, Speaker C: I think it's fairly self explanatory. It okay. 30 74 is not one of the EEPs that I discussed in my original Twitter thread. But I did talk a little bit about kind of this field of ideas that I think Ethereum is going to see in the next one to two years. And that the idea is that there's a lot of things that people want to do with an externally owned account. They want to be able to send multiple transactions at once because a it's easier from a UX standpoint and b it should be cheaper because a significant part of a lot of transactions is paying 21,000 gas just for the intrinsic cost. And if you could amortize that across ten transactions that would significantly reduce the cost of actually interacting with the chain.
00:55:43.526 - 00:57:02.418, Speaker C: And sure you could have a smart contract wallet that does these things, but smart contract wallets still haven't really got the adoption that we would like to see and they're just really expensive. It requires upfront costs to actually deploy. And so there's been a lot of thought about how can we provide some of these things that people want. And this is EIP by one of my colleagues and I originally was kind of against it, but I think I've really come to think this might be the best way to go forward because it is really a primitive that allows for a lot of other things to be built on top of it. And that's kind of the soul of ethereum is creating an environment where you can programmatically define things and things aren't rigid. And so this pre compile, basically the input is some call data and a signature. And this pre compile will do an EC recover on the signature and see what the address is and then send the call data on to whatever the target address was and it would set the message sender to the recovered address.
00:57:02.418 - 00:58:04.898, Speaker C: And so immediately you should realize this would eliminate the need for this idea of metatransactions because metatransactions came to be because there is no way to set message sender without going through a contract or something. There's no way to emulate message sender being equal to an EOA. And so that's exactly what this EIP would allow. And the really cool thing about this EIP is that because it is a very simple primitive it would allow for smart contracts to be built kind of around it, which would allow for batching transactions. Because you could imagine that there might be a smart contract out there that the input is just multiple call data and multiple signatures. And you could send all of those and it would send it one by one to the pre compile, bounce it to the target, run through all of that and then come back and execute the next transaction in the batch. And this could be done with an EOA.
00:58:04.898 - 00:58:54.920, Speaker C: And so I really like how it's very simple. Other solutions that we kind of saw earlier was 20 711. That was the original idea of sponsored transactions, batch transactions that requires a new transaction type. There's a lot of rigidity about how to think about what's possible there. I wrote an EIP 27 33, which is a transaction package which has a lot more bells and whistles to it, but significantly increases the complexity of the protocol, the complexity of reasoning about transaction validity, whereas 30 74 is a lot simpler of an idea and really provides the maximum amount of flexibility. That a solution that you're looking for. Should have.
00:58:54.920 - 00:59:00.060, Speaker C: Any questions on the cap.
00:59:10.270 - 00:59:21.280, Speaker B: Given the title? Is it really trying to aim at someone else is paying for a transaction? Is that sort of what the intent is?
00:59:23.810 - 00:59:52.940, Speaker C: That was really the original intent because there is no mechanism in the protocol to pay for a transaction for someone else. And so that was kind of the original intent. But we had a lot of discussions because I had authored this EIP that I thought was superior because it had batching and all of these things. And then through time we really realized that having the primitive in the EVM would allow for you to build all those mechanisms around it.
00:59:56.430 - 01:00:32.040, Speaker B: Sure. So I'll say back to you how I think it works and you're going to tell me I'm wrong, I'm sure. But I create a transaction and inside it I have data which is showing that I want the transaction to look like it's come from it. I then fire it at this pre compile and then it'll make it look like it's coming from Sandra. Is that the idea?
01:00:32.890 - 01:00:41.914, Speaker C: That's the idea. Know the caveat that Sandra had to sign something? Sign like the inner transaction that you're ah, okay.
01:00:41.952 - 01:00:45.002, Speaker B: Yeah. So there's no way of me just faking know?
01:00:45.056 - 01:00:45.850, Speaker C: Yeah, exactly.
01:00:46.000 - 01:00:50.780, Speaker B: I get Sandra to send me a million dollars or something. Yeah, all right, that makes sense.
01:00:52.690 - 01:01:43.994, Speaker C: The really strange caveat to this, though, is that as it's written, there is no replay protection. And that seemed really weird, and it came out of a lot of discussions about how this thing should operate. And we really kind of came to the realization that if you sign something you're not supposed to, you can get in a lot of trouble. That's just how it's going to work with private keys. And so we really need to build systems that avoid people from signing things that they shouldn't sign, and we should allow for these smart contracts that exist around it to do replay protection. And the cool thing about that is that really opens the door for what is possible with replay protection today. You have to serialize your transactions.
01:01:43.994 - 01:02:01.060, Speaker C: The nonsense have to be sequential, but because we've abstracted that away, it might be possible for you to have like a hash based replay protection where the transactions are non sequential and all you're doing is checking to hash the transaction that's existed before.
01:02:06.070 - 01:02:28.374, Speaker B: It puts a lot more onus on the smart contract to developer to make sure that, say, if there was a system for voting and you were allowed to vote more than once, that whoever creates that voting contract make sure that you can't replay the same vote transaction, for instance.
01:02:28.422 - 01:02:58.470, Speaker C: Yeah, definitely. That's definitely the biggest question mark in the CIP. It's something we feel like that's the right way to go. There's still probably some more work to really understand. Does this fully make sense? And I expect there's going to be a lot of pushback because it is pretty radical to not have a replay protection in a protocol enshrined thing. But yeah, I think it's interesting.
01:02:58.620 - 01:03:09.130, Speaker B: I reckon if it goes through, people will muck it up and then there'll be people who will exploit it and then researchers write research papers on how it was exploited.
01:03:13.630 - 01:04:01.130, Speaker C: That'S the only guarantee in this world is that people will mock it up. Um, okay, I have two more EIPS. I know that I'm probably gone quite a bit, but let's just go through these last two. They're pretty interesting ones. So, EVM 384, this has not been formally drafted as an EIP, but it will likely be formally drafted. And I think it's one of the most interesting changes that's coming to Ethereum. And I really think there's a high likelihood because it allows such a powerful new way of writing contracts and it really reduces the burden on core developers.
01:04:01.130 - 01:05:20.900, Speaker C: Today, if you want to interoperate with another chain that uses a different crypto primitives or you want to use a new crypto primitive that hasn't been supported in a hard fork yet, you're basically out of luck. Your best option is to implement these really expensive operations, these really expensive modular operations on integer sizes that are bigger than 256 bits. You have to emulate that in EVM and it's incredibly expensive to do. But this EVM three eight four, the paradigm behind it is that what if we reduce the bottlenecks that exist in cryptographic computation and it turns out like a lot of those bottlenecks don't really have to do with a glue code that kind of take some result and move it to the next thing. It's really all about the big integer arithmetic. And so EVM three eight four defines a few modular math operators that operate on a 384 bit field and that could be increased to whatever other size fields that are really relevant for the crypto primitives that are coming out. But right now, 384 is enough to do BLS twelve 381, which is kind of the big one that people are wanting to see in Ethereum One.
01:05:20.900 - 01:06:20.374, Speaker C: But this is such a cool EIP because if you want to put crypto into ETH one, it's very complicated because if clients have different use different libraries for those crypto printives, because the core developers aren't going to write an implementation of BLS 1231, they're going to use a library. And if different clients use different libraries and there's some weird edge case where maybe they disagree, that creates a massive consensus failure and that's something that people don't want to have. If everybody uses the same library, then you kind of have the same problem where, oh no, what if there's like this weird edge case? Then we're kind of stuck with this forever. And that's like a protocol thing. And so core developers feel like they really need to audit these libraries to make sure that they are doing the right things. And so there's a lot of burden on core developers. Whereas with 384 it's permissionless, anyone can write an implementation for BLS 1231 and we can have people in the community audit it.
01:06:20.374 - 01:06:40.640, Speaker C: And there's not the reliance on core developers to kind of do everything. It kind of like pushes out and delegates some of that work onto the community. If they really want a crypto primitive, then they'll implement it and they'll fund people to review it and to ensure that it's safe and does the correct thing. It.
01:06:53.270 - 01:07:14.550, Speaker A: One thing about this EVM 384, if we have like BLS implementation based on this of codes, right, we will have to pass it through the audit procedure as well. Right. So to be sure that it's written correctly.
01:07:15.610 - 01:07:16.360, Speaker C: Yeah.
01:07:20.350 - 01:07:31.500, Speaker A: So probably makes sense to use one single library I know, which is audited and use it across the.
01:07:33.630 - 01:08:18.842, Speaker C: I mean, my preference for BLS is to have it implemented natively. I think that BLS is a special primitive because it is part of the Ethereum family now with E two, and I don't see any reason to not support it natively. I don't think that that means that we shouldn't do three EVM 384. I think there's still a lot of benefit of having those module math operators to support other crypto primitives. But yeah, I think I'm a proponent of 25. $37. Okay, this is the last one.
01:08:18.842 - 01:09:02.170, Speaker C: This is a pretty quick one, and this is something that actually is pretty old. This was implemented last year. I think it was finalized last year. Basically, this is the upgrade to the ETH wire protocol. And the really cool thing about it is that it significantly reduced the bandwidth that clients were using. And the reason why is that before, whenever you were a client and you were peering with people, as soon as you saw transactions come in and they were new to you, you sent to all of your peers. And so there was, like, this crazy swarming effect where there was a lot of duplicate information being sent over the network.
01:09:02.170 - 01:09:25.700, Speaker C: Because if you've peered with multiple people and they've peered with some of your peers and you're sending all these transactions back and forth, you're going to see some transactions you've already seen just because your peers are just seeing it for the first time. And so this was causing bandwidth usage to be quite high, and E 65 introduced this new way of propagating transactions. Where.
01:09:39.290 - 01:09:42.150, Speaker B: Is it me or is Matt stopped?
01:09:43.530 - 01:09:43.846, Speaker A: Yeah.
01:09:43.868 - 01:09:45.990, Speaker D: No, I think it was Matt.
01:09:47.070 - 01:10:00.760, Speaker B: It's all gone. Hello, Matt? Can you hear us? That's not good.
01:10:02.330 - 01:10:04.350, Speaker D: I guess he said this was the last slide.
01:10:04.370 - 01:10:36.170, Speaker B: Didn't did he did I'll fire him? A slack message. See if I can get him. I think Matt's off the call. Yeah, I will quickly fire a message at him. There he is.
01:10:40.700 - 01:10:45.972, Speaker E: I really didn't expect to talk that long, and I think my computer actually just died.
01:10:46.116 - 01:10:47.050, Speaker B: Oh, no.
01:10:48.160 - 01:10:53.550, Speaker E: I'll grab my charger. I don't know if I'll make it back onto my laptop in time.
01:10:55.700 - 01:11:01.010, Speaker B: So I can share my slides and you can talk. You're on your mobile at the moment, are you?
01:11:01.540 - 01:11:03.472, Speaker E: Yeah, I'm on my mobile, yeah.
01:11:03.526 - 01:11:31.290, Speaker B: Okay. Actually, I'll get out of that window. Move this window over here. Yeah, I've done this before and done it wrong. Okay. And then if I go share screen, google Chrome, share. All right, so we're right at the start, and then I'm going to go into this window, and I'm going to move forward really quickly.
01:11:31.290 - 01:11:38.750, Speaker B: All right, so back over to you, Matt. Can you see the screen?
01:11:39.680 - 01:12:01.504, Speaker E: I see it, yeah. Thanks for pointing that out. This is very helpful. Yeah, I really only have maybe one more minute on this slide, and that's pretty much the presentation. But just. To close this out. I think I was just discussing how and why does E 65 significantly reduce the bandwidth that clients are incurring.
01:12:01.504 - 01:13:07.370, Speaker E: And the way that it does it is instead of always propagating all of the transactions, you receive the full transactions. It would actually only send the full transaction to a square root number of peers, and all of the rest of the peers would receive just a list of new transaction hashes, and that would allow your other peers to see the transaction hashes and then compare them to what transactions hashes they've seen. And if they haven't seen certain hashes, they can request only those transactions. So it creates a much more efficient protocol of propagating data. And it turns out that that's actually exactly how blocks have been propagated in the ETH wire protocol for a number of versions before you don't send a full block every time to all of your peers. You only send a full block to maybe a square root of your peers, and you just send a new block hash to the other peers. And if the peer hadn't seen that block yet, then it might actually request to have the full block since then.
01:13:07.370 - 01:13:49.860, Speaker E: The reason that I put this in this presentation, though, is that Go Ethereum is planning to deprecate all of its protocols below E 65 sometime this summer. And that was kind of the outcome of the discussions about how to do 20 718 transactions and this weird thing about overloading transactions with these type transactions. And so the outcome of that was that they would just deprecate. And so all of their clients will have to be on E 65, E 65 or greater this summer, or they're going to kind of be ostracized from communicating with gas nodes.
01:13:51.900 - 01:14:06.590, Speaker B: Okay, that's interesting. So I guess all the other clients have to update and be ready, and I guess it's got to go in in a hard fork so everyone knows which block to switch on.
01:14:07.760 - 01:14:42.900, Speaker E: Well, actually, I don't think that it would be a hard fork because the dev P to P layer is more of, like an agreement among clients. So for E 65 or E 66, that's kind of being built, they don't have to do it at a certain block number. You just kind of roll it out to clients. And when you're negotiating your connection with another client, they're going to tell you what their capabilities are. And so if they are E 65 capable, then you could communicate with that protocol. If they're not, you would drop down to 64, 63, whatever they're serving.
01:14:43.060 - 01:14:53.844, Speaker B: Yeah, that makes sense. That's right. So it's all a matter of all the other clients have, otherwise they won't have a common protocol version that they share.
01:14:53.982 - 01:14:55.310, Speaker E: Yeah, exactly.
01:14:55.760 - 01:15:00.300, Speaker B: Okay, makes sense. All right, I'll move to the next slide.
01:15:00.640 - 01:15:32.036, Speaker E: Yes, please. So that's my contact information. Thanks a lot for listening and the questions. I definitely appreciate it. I'm always available on Twitter at clients or feel free to email me. That's my email if you have any other questions or comments about this stuff. I'm also happy to stay on for the rest of this time and just discuss or talk about anything related to the topics here or anything else in people's minds.
01:15:32.228 - 01:16:02.012, Speaker B: Sure. Thanks. Thank you for your talk. But before we thank you, we'll quickly go through this so that people know what's coming up. So on March the third, you can find out about scale, which is a L2 scaling solution. And Constantine Clado is going to get up early in his time zone in the Ukraine, but it'll be 05:30 p.m. In Brisbane, Australia.
01:16:02.012 - 01:16:47.472, Speaker B: And Matt, if you're going to be on that one, it's going to be midnight or something. Sweet. Yeah. And then after that we've got the Cross chain workshop, which is actually now going to be done just across two days rather than two weeks. And I am in the midst of putting the agenda together or actually publishing the agenda. So the program committee have worked out the agenda and we have got researchers from all over the world and also applications people from all over the world who are going to be presenting at that and it's going to be awesome. So if you're interested in Crosschain, then this is definitely going to be the place to be.
01:16:47.472 - 01:17:35.210, Speaker B: It is free and you can go to eventbrite to get tickets, but if you go to that URL, you'll have the latest information then two weeks after that. So on the 17th, Mikhail is going to tell us all about the ETH one e, two merge and how it all is. And I still haven't got before or after Sharding removed, which we agreed I would because that sounds too sensational, but it's going to be a sensational talk. So it's going to be awesome. Um, so that's in March 17 and then I haven't got a talk the 31st yet, but on the 14th.

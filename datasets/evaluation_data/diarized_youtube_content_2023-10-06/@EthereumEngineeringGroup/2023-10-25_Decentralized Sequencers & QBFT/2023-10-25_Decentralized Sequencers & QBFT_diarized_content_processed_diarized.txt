00:00:03.050 - 00:00:43.050, Speaker A: Hello and welcome, everyone. My name is Peter Robinson, and this is the Ethereum Engineering Group. Meetup. So today I've quickly put together a talk on decentralized sequences and Qbft. And for people who are watching this going, but how do the two intersect? I'm going to explain it and so hopefully by the end of this, you will be reasonably convinced that it's a good idea. Okay, let's share my screen. Okay, so can anyone or everyone see my slide?
00:00:43.870 - 00:00:44.650, Speaker B: Yep.
00:00:45.630 - 00:01:40.726, Speaker A: Okay, brilliant. All right, so some of this talk is taken from a talk that Roberto Saltini wrote, so just acknowledging that. And so I'm going to talk about decentralized sequences, which I think is going to hopefully get you into the idea of why a BFT consensus is a good idea. And then I'm going to go through Qbft in quite big detail and then I'm going to talk about ZK friendly blockchain consensus protocols. Okay. Decentralized sequences. So in a ZK roll up system, you have the roll up, and normally it's rolling up to Ethereum, but the roll up could be rolling up to another roll up or another blockchain.
00:01:40.726 - 00:02:43.706, Speaker A: But let's just run with an L two rolling up to an L1, where the L1 is Ethereum. And so you have a sequencer which is all about ordering transactions. You have approver, which is creating the proof, the ZK proof, and then you've got the prover contract, which is how you verify what's in the proof. So the small bit of information that you put on Ethereum so that you're happy about the sequencer improver having done the right things. And so a user submits a transaction to the sequencer when you've got a whole heap of information, a whole block or multiple blocks, the prover then requests information from the sequencer and they get the block header at the start of each transaction that is state tree. At that point it may be some information about Bridging and also some information about consensus. And so then that goes into the prover.
00:02:43.706 - 00:03:52.994, Speaker A: So it's got all that information and then it generates a proof of the actual transactions have executed correctly and that the storage has been updated and the state has been updated as per what's in the block header and is able to prove that. So at the moment, if you look at any of these systems, say scroll or linear or the polygon Zkevm, they're all using centralized sequences. So essentially a single node sequencer. And so it could just be a database as much as anything else. It doesn't need to be any blockchain or anything because it's just this single node. And so if you think about if you were going to design a decentralized sequencer, you're going to have different nodes and they need to be able to fairly come to an agreement on the order of transactions. Additionally, some of those nodes might be malicious or maybe just even misconfigured.
00:03:52.994 - 00:04:48.060, Speaker A: So when you think about that that sounds a lot like a consensus protocol. That's what they do. You have a shared distributed database, you have a lot of nodes, and you need to agree on the order of transactions and some of them might be faulty. So that's a consensus protocol. And as well, before those blocks hit the prover they need to be final, there can be no suggestion of there could have been a fork and you might prove something that's no longer real on the blockchain. That can't happen. So you need finality to be deterministic and it'd be awesome if it was fast finality and even better, single block finality so that then the block on the blockchain gets finalized and then you can prove it immediately, so you don't have to wait, say, 20 blocks or something.
00:04:48.060 - 00:06:36.436, Speaker A: So when people talk about decentralized sequences, a big topic of conversation is, well, how decentralized? So we've been happy with centralized single node sequences, databases, and everyone's been popping champagne corks. So do we really need to be fully 101% permissionless decentralized? Does it need to be as decentralized as say, ethereum? Or could you just have say, 20 or 30 permission nodes? Could you have some smaller set and maybe that will be okay for some situations, maybe it'll be okay for all situations, maybe for some systems it's a path to decentralization, but not the endpoint. So I think it's a valid way of doing things though. And so that whole let's use a restricted number of nodes, probably not permissionless, then I think that's a Byzantine fault tolerant consensus protocol. And so that means that your decentralized sequencer could be, for instance, a Qbft blockchain network. So I've said BFT a lot, but what's it actually mean? So, consensus is all about agreement across a distributed system and blockchains need to agree on the canonical blockchain. So the order of transactions in blocks, the order of blocks in the so I was using Bing, which uses Dali to create images, and I said Byzantine general's problem, give me the picture.
00:06:36.436 - 00:06:56.070, Speaker A: And so it gave me this. But before I go on, can anyone tell me what is the problem with this picture? Sandra, do you want to guess?
00:06:57.000 - 00:07:18.110, Speaker B: I'm pretty useless at guessing, but it looks like not everyone can see what's happening mean. There's a lot of people looking on and just a few people sitting around the table and it's quite a big scroll. You can't necessarily see everything that's written there. I don't know.
00:07:18.720 - 00:08:42.884, Speaker A: Okay, well, the insufficient information is actually a good point. But for me, the whole idea of the Byzantine generals problem is the generals can't gather in one spot, they specifically can't gather around one table to get an opinion because they're essentially a decentralized system. And so they each have their own perspective on the world and they can send messages to each other, but they can't actually collaborate in one place. I use the diagram from Wikipedia, which more easily, I think, demonstrates it. The definition of a Byzantine fault is a condition of a computer system, particularly a distributed computer system, where components may fail, but you've got imperfect information on whether the component has failed or not. And so when you look at this diagram here, you've got those six generals around, and they've got their six armies that are going to attack a fort, but they can't talk to each other directly. They can't gather around that table, and so they can have the idea we're all going to attack at dawn.
00:08:42.884 - 00:09:44.796, Speaker A: But what happens if it's raining? Have they agreed on that? So maybe some of them get cold feet and they all know if they all attack at once, it's a positive outcome. Maybe they take the fort if they all retreat, another positive outcome, maybe no one gets hurt. If some attack and some retreat, then it's going to be disaster, because then the people in the fort will be able to take them on successfully and kill them all. So the idea is of this Byzantine generals problem is being able to communicate with insufficient information in a distributed system and also handle the fact that maybe some of those generals might have been paid off by the people in the fort to act maliciously. Or maybe the messengers who are communicating between the generals disappear, they don't make it. And so, again, insufficient information. Yeah.
00:09:44.796 - 00:10:42.204, Speaker A: So what happens if they're malicious? And what happens if some of the messenger riders between the generals are captured? So a BFT consensus is Byzantine fault tolerant. So it can handle this sort of problem where you've got potentially malicious nodes, potentially just even faulty nodes, where maybe they go offline, or maybe the network connection goes offline. And so in my experience of working with these sorts of systems, the reason why you have these failures is misconfiguration. So one of the nodes maybe hasn't upgraded to the latest fork. Fork goes live, it goes off the air, or some other misconfiguration. Network failures are really quite a common issue in a hugely distributed system. Hardware failures do happen.
00:10:42.204 - 00:11:46.108, Speaker A: So hard disks die, the switch dies, bits happen, malicious behavior is possible. Invariably, though, the malicious behavior could come down to a node. Bit of software has been hacked, has been taken over by a malicious actor. So even though you trust the company to operate their node, they might not have good operational security, so their node might get taken over and then it might do malicious stuff. So when trying to understand BFT consensus protocols, it's worthwhile trying to understand the history of them. Back in 1982, we've got Lamport and Co came up with the Byzantine generals problem, so there's a paper for that. And then in 1999, Castro and Liskov produced the paper on PBFT.
00:11:46.108 - 00:12:43.412, Speaker A: So practical, Byzantine fault tolerant. The bitcoin paper talked about blockchains and ideas around that and worrying about faulty nodes and malicious nodes. And so probably was inspired by those two papers. And that led to Tendermint in 2014, which tried to come up with a way of having a PBFT algorithm that would work for blockchain. Then in 2017, early, we had Click put in as an EIP, which is a non BFT algorithm that works on Ethereum. And then we had IBFT and it was well, let's take the ideas from Click and the ideas from PBFT to create a BFT for Ethereum. However, it had some issues.
00:12:43.412 - 00:13:46.040, Speaker A: And so then Roberto Saltini and others being David Highland Wood created IBFT Two, which fixed the safety and liveness issues. At the same time, some other people came up with an algorithm called Hot Stuff, which tried to fix some of the scaling problems that you've got with IBFT but increased latency. And then lots of variations have been created based on Hot Stuff. Importantly, the second author of Hot Stuff created Hot Stuff two earlier this year. So that's a recent edition. The Enterprise Ethereum Alliance created Qbft in 2020 and it is IBFT Two with very slight changes, but it's also been formally verified. So that's a good algorithm.
00:13:46.040 - 00:14:43.160, Speaker A: And so yeah, noting very clearly that Click is not BFT, so don't think of Click as a BFT algorithm. So when you're trying to understand BFT algorithms, it's good to understand the commonalities for all the PBFT and anything that inherits from it. It has this three step approach where the block proposer is somehow other elected, and then it sends out a message to everyone saying hey, here's a block. And then all the validators then communicate by some mechanism and say yes, we've seen it, we are locked onto that block. And then there's agreement because everyone can see that everyone else is going to be cool with that block. And they've all voted on that block and they say all right, let's commit the block. And then it's committed.
00:14:43.160 - 00:15:31.880, Speaker A: And so all of the algorithms have that in common, that basic, here's a block, we've seen the block, let's commit it. Three phase activity where the differences come is around. There's trade offs between latency and messaging. And so is it. The block proposer send messages to everyone, they send messages back to the block proposer, and they do that process multiple times, which ends up being higher latency. Do all the validators communicate with all the validators, which is PBFT? Or do all the validators communicate with all the validators? But they also use gossip, so they don't have to be connected with. Say you had 1000 validators, they don't need to be connected with all 1000 directly.
00:15:31.880 - 00:16:42.210, Speaker A: And so you've got IBFT, IBFT Two and Qbft use that all to all. So you end up with low latency, but you've got higher message complexity, which means the messages are larger potentially. And also the other big difference between the different protocols is how do they handle round change, and that's when there's a failure. So another thing to think through is, well, which of them were designed for blockchain? And so all the ones along there, tendermint and beyond, are all designed for blockchain. Another thing is what about ethereum? Which ones have had ethereum in mind when they've been developing the algorithm? And so that's just the IBFT Qbft range and trying to bring it down into more detail. So they're all BFTS, they all offer that instant finality. So when a block is produced, it's done.
00:16:42.210 - 00:17:47.700, Speaker A: The hot stuff, because of their mechanism of block proposal to all nodes and back again, they have a lower message complexity. So the message size is smaller, whereas it's of N squared. So it essentially binds more messages together and it includes messages within messages, so you end up with larger messages if there's a failure case IBFT and IBFT had N cubed message size, whereas Qbft is N squared and tendermint is FN squared. But then there are some other parts to it where a lot more messages end up getting sent and hot stuff. And hot stuff too. F is the number of faulty nodes. So it's less latency though then is a huge difference where hot stuff, the latency is really high, whereas in Qbft tendermint it's lower safety is if you produce a block.
00:17:47.700 - 00:19:14.844, Speaker A: Is that correct? Have we updated to the right state and are there no clashes? And so we've got a yes for all the Qbft, IBFT and everything, but not for the original IBFT. Liveness is could the blockchain get to a state where it can't produce any more blocks? And again, that's generally yes, responsiveness is around. Is there a situation in which the consensus protocol could get to the point where to produce another block could take a very, very long time and tendermint in certain failure situations can take quite a while to produce another block? Formal verification is another important piece which is proving that the algorithm is actually correct and doesn't contain bugs. So Qbfts are yes for that. Whereas tendermint and hot stuff, they've got some parts of the protocol done, but not the whole protocol. And hot stuff too is too new, so it doesn't have it for those people being immutable. We're using Go ethereum as our code base and so having a consensus protocol that's Go ethereum based or even could work on the beacon chain client would be a real bonus.
00:19:14.844 - 00:19:53.416, Speaker A: And so we're interested in Golang. So hence yeses and no's in red here and ZK friendly contractor validator set. So that's definitely a yes for these and not so sure for these others. And I'll explain that a little bit more later on. Actually, I'm not going to explain it in this talk completely. Anyway. So how does Qbft work and what does that Q stand for? Q stands for so Quorum was a blockchain client that Morgan created.
00:19:53.416 - 00:21:02.230, Speaker A: It was a fork of Go ethereum back from 2016 17 and it contains many of the features of it of modern ethereum, but it sort of misses some and it has a whole heap of extra features and is now managed and maintained by consensus. So the protocol has the following properties, so it gives you consistency so you don't get forking. So you can't have the diagram on the right there where you have alternative blocks at the same height. You always will end up assuming honest nodes with the same sets of blocks in the blockchain and the blockchain will grow. So you'll have in an append only fashion, so you'll have honest nodes will put blocks on the end of other blocks and liveness. You won't get a situation where you can't add more blocks. And all of this has to be despite there potentially being attackers who could collude to attack the system.
00:21:02.230 - 00:22:30.396, Speaker A: And so the maximum theoretical resilience of the protocol is that equation over there. And as you can see with this table, as you end up putting more nodes in, you can handle more faulty nodes. So with Qbft the block proposer can be rotating so it changes each time, or it can be sticky where it stays the same until the block proposer fails. And this whole block proposal piece is programmable. So potentially you could create a POS algorithm over the top of Qbft for choosing the next validator and in fact that's something that mutable we're going to do. So the following slides assume a rotating block proposer, and so in this system, so imagine we've got four validators and you've got the block proposer and we're up to block five, so you've got the block period and then you've got a round timer, so you do multiple rounds trying to create a block. And so for our system, the block period is going to be 2 seconds and for the round timer it's by default 10 seconds.
00:22:30.396 - 00:23:26.770, Speaker A: So I think we should probably set that to something lower, like 2.1 second or something like that. So all the validators know which validator is the block proposer because there's a deterministic algorithm that selects it. So they all know for this round and for this block, this validator is the block proposer. And so it sends out a pre prepare message containing the proposed block to all the nodes and it also virtually sends that message to itself. So whenever you see a message being sent out to all nodes, logically think as well, even though I'm not drawing it on the diagram, that it's also being sent to itself. So when you're trying to calculate how many messages has it had, base it on that.
00:23:26.770 - 00:24:34.890, Speaker A: So then all of the nodes then or validator nodes then gossip to all the other nodes that there's a prepare message saying hey, let's use this block and that we're going to use it for this block height. And so they all send that message to everyone. And again reiterating about when I say gossiping, remember that we're using dev p to P which uses Cademlia. And so each of those buckets can hold 256 nodes. So even in the local pool it'd have 256, but then it's got 256 slots of 256. So you're going to have to have a lot of nodes before it's not going to be a direct connect. When a validator node has received a quorum of prepare messages, so remembering that it counts its own message that it's sent out, then it's ready to send out a commit message.
00:24:34.890 - 00:25:58.576, Speaker A: And so then when the validators receive a quorum of commit messages, that is three, including the one it sent itself, it finalizes the block and adds it to its local blockchain. All nodes send out that fully signed block to all other nodes in the network. And so this is just a standard ethereum message saying hey, here's a new block. And in that way, even if only one of those block validators gets everything done in time, you will still have a valid block. So something to note about Qbft is that, say Validator v one, it's going to have a certain block with a certain set of signatures, but the other Validators might have a different set of signatures because it's going to depend on which of the other Validators connected to it first, sent it its message first, and it received first. So if it received a message from V four, v three and V two first, then it would have that. And so these signatures are put in the extra data field and are not covered by the actual block hash signature.
00:25:58.576 - 00:27:09.690, Speaker A: And so hence it doesn't matter which of them are there, as long as there are a quorum number of them there. When each node receives a quorum number of these commit messages, it sets a timer out to the end of the block period so that's that block timeout. So it sets a timer so that say, if they finish all the messaging they need to they've produced the block and they're only say 1 second in, or one and a half seconds in, then they'll set that for say 1 second or half a second so that they keep up that two second block period. And then each node then will have that block timeout, timeout at around about the same time. And then each node will set up their round timer for the next block. And if you're the block proposer, then you'll send out that pre prepare message again to all the other nodes. If say, not all the messages make it for instance, and you don't receive the expected one, then you'll do a round change.
00:27:09.690 - 00:28:18.770, Speaker A: But this round change messaging should only happen really rarely. And so how round change works is that you have that timer and so say that timer goes off before all of these messages had completed. So before we were ready to do the commit message, then instead the timer goes off and then all the nodes will send out a round change message. And so if that happens again, then the round timer for round one is exponentially larger. So I think it's twice as large and then round two will be twice as large as round one. So the idea is to double the round timer each time to try and help ensure that you get a block done in time. Yeah, and so that will just kick off the block production again.
00:28:18.770 - 00:29:53.550, Speaker A: So what about Qbft in go ethereum? What can I say about that? So the code was ported from Geth in 2016 maybe, or maybe it was early 2017 and there were changes taken from upstream, but not all. And the code base was deemed feature complete in 2021. So they're doing changes, but there's no major feature development. And so many of the features or other, they've got a lot of different features in the code base. So if you're trying to extract Qbft from the code base, you do need to do a bit of extraction of just the right features and not all the private transaction stuff and the node permissioning and smart empty block handling and all the other stuff because you don't need it. So not covered in this spec or the paper, but in Qbft you've got the Dev P to P sub protocols, a part of Ethereum. And so IBFT, which is the original, it used a Dev P to P sub protocol called ID 64 because at the time we're running up to F 63, but obviously when Ethereum upgraded the Dev P to P protocol, then that clashed, so it didn't work.
00:29:53.550 - 00:31:04.580, Speaker A: So when IBFT Two was created, there was Istanbul 99 and so it's obviously in a different range, so it's not going to clash. So both IBFT and IBFT Two, they override all of the protocol messages so they completely can handling the protocol and not delegating to the S protocol at all. That's got a problem because then when Ethereum upgrades, maybe they add some stuff that needs changes to that protocol. And so Qbft it delegates to ETH protocols. And the important part of that is that then if there are ETH protocol changes to handle improvements in Ethereum, then you can be using that with Qbft, whereas with IBFT Two it's just not going to work. Validator voting so it can be via RPC calls and then vote by adding information to the block headers. That's how click does it? So you've got some validator node and you call into that validator node to do some sort of vote for adding a new node.
00:31:04.580 - 00:32:27.712, Speaker A: But a much better way of doing this is to have a contract on chain and then the validators read the information out of that contract and call this get validators to get the list of current validators so that it allows you to have arbitrary business logic in there on how you elect validators and all sorts of information. So I haven't done this part. Yeah, I've got some thoughts on it, but the thoughts are still crystallizing. One of the things I'm doing is I'm working on an EIP that will do the interface between approver and a decentralized I in January. I think I'll be at the point that I'll be able to talk publicly on this. So for Joanne, who's joined pretty recently, let's see if I can fly. So this little bit here, the blockheader per transaction state bridge and consensus, that's something that I'm writing an EIP on.
00:32:27.712 - 00:33:39.528, Speaker A: And I think we're going to have broad support from the prover companies. So the idea will be that you could have a range of ethereum clients, so Aragon geth Besu Reth, and as long as they implement the API, then they could be used with any prover. And so you could use linear or polygon Zkevm, possibly a changed ZK sync that does type two roll ups. That's what I'm working on and I've got some ideas on the consensus. And in January I'm going to say what I'm thinking and essentially what I've put into the draft EIP. And so it'll give you an opportunity to haggle about it and say what you think. So my gut feel is that BFT consensus algorithms are a good option for decentralized sequences, and Qbft, I think is a good BFT consensus algorithm.
00:33:39.528 - 00:34:30.668, Speaker A: Trying to work out exactly what we need to do to have Qbft or some other BFT work in with a proving system is ongoing research. And that's one of the things I'm working on right now. The merch store is still up and running. I'm still selling T shirts sold about two or three last week. Next week we're going to have Juan Blanco, who's going to talk about the Vs code solidity extension that he's created and that many, many people around the world use. I'm going to talk about Passport, which is a wallet, and then there is a slot there in December the 6th. I have some ideas about who's going to talk anyway.
00:34:30.668 - 00:35:25.330, Speaker A: We'll see if that comes together. I've got a great idea for the Solidity Interview Challenge at the end of the year, and then I'm going to talk about that decentralized sequencer friendly consensus algorithms. And then just to mix it up and prove that this is just not an Immutable meetup, christian is going to talk about other wallets that are really trying to do very similar stuff to what passport are doing, where they're trying to be a crypto wallet without getting in the way. So making it easy for the next billion people to use blockchain. Tim Bico said that he's going to get back to me next week and tell me when his ethereum governance talk will be rescheduled for. So that's probably going to be February, but we'll see. There's a whole heap of socials and stuff.
00:35:25.330 - 00:35:33.330, Speaker A: So are there any questions?
00:35:49.530 - 00:36:17.600, Speaker B: Not really a question as much as a comment, Peter, that I know there's also a fair bit of research going on regarding decentralized sequencer improver for Linear and someone like Roberto who is also involved in that, and Michael Kalanan. So it might be interesting for you also to touch base with.
00:36:19.490 - 00:36:20.094, Speaker A: Yeah.
00:36:20.212 - 00:36:31.794, Speaker B: Just to see where they've got to with that and maybe be part of your talk next year or something like that.
00:36:31.832 - 00:37:37.526, Speaker A: Yeah, it's possible. And I mean, I've talked with Nicola Liaxon and Declan Fox and Ben Edgington about the whole thing and talked about least our ideas and what should happen, and also talked about the standard. But, yeah, I'm happy to talk to them. My goal is to actually have a draft. My goal had been to get draft EIP out this week, but I think it's going to be next week. My take on it is, and I don't think this is saying anything out of turn, didn't have an NDA, so should be so at the moment, Linear has an integrated client, essentially a single node, similar to how polygon Hermes come polygon ZK EVM works. So you've got this integrated thing.
00:37:37.526 - 00:38:25.800, Speaker A: And so the idea, I think, of having separate blockchain nodes, so hyperledger bears or something, using Qbft or a POS algorithm on top of Qbft, I think makes a lot of sense. And then all the provers they need the same information, whether they're type one, type four, I think they're going to all need the same information to get information out of them. So I think the proof of consensus is complicated. It's funny. The other stuff is I think there's ways and means of doing it, but we need to have it so that you don't lock yourself into a certain consensus algorithm. Yeah, it's interesting that Roberto and Mikhail are the ones looking at that.
00:38:27.530 - 00:38:40.060, Speaker B: Part of the conversation. I'm not sure exactly to what extent they're involved or which part of it they're looking at because there's a whole group of them busy exchanging ideas and looking at things.
00:38:42.590 - 00:39:17.538, Speaker A: Sounds very interesting. Excuse me, everyone. And Serge. Do you understand qbft now? What do you reckon? Better than I did yesterday. Well, that's good. Yeah. I can tell everyone that it's all learning all this stuff and then trying to work out how it's all going to work in our decentralized ZKE EVM world where we're all hanging off ethereum.
00:39:17.538 - 00:39:56.542, Speaker A: It's complicated, but we're going to get there. And I think that then we'll have ethereum, all these roll ups and L three S, and maybe there'll be other L1s that will still be around in like five years time, but maybe not. Maybe this will be where we'll end up and we'll have all the innovation on L two. Maybe. Yeah, who knows? All right, so thank you, everyone for your time today and have a great day. And Danielle is she came and went anyway, I was going to say she's joining just as we're leaving. All right, talk to everyone later.
00:39:56.542 - 00:39:57.178, Speaker A: Bye bye.
00:39:57.274 - 00:40:01.810, Speaker B: Thanks. For the old Peter. Bye bye, everyone. Bye.

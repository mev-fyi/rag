00:00:00.330 - 00:00:33.400, Speaker A: You. Hello and welcome everyone. My name is Peter Robinson. This is the Ethereum engineering group meetup. Today I'm going to be talking about Yule and solidity inline assembler. So a tiny bit about me. I've been doing product development stuff for more than 30 years, cryptography for more and 20, and blockchain stuff for a decade come about seven or eight years, depending on how you want to look at it.
00:00:33.400 - 00:01:13.680, Speaker A: Currently working at immutable as head of blockchain research, helping us change gamefi. So essentially gaming with blockchain and we're creating a blockchain platform. I mean that's really the big thing we're doing. Okay, I will share my slides, so hopefully everyone can. Yes, I've got some thumbs up. That's good. Okay, so let's talk about solidity and assembler.
00:01:13.680 - 00:02:55.680, Speaker A: So I'm going to talk about the continuum essentially between solidity and bytecode, and just how that all fits together and how to think about things. And then I'm going to talk about dive into inline assembly, and then I'm going to talk about your contracts. And lastly, initially when I wrote up this and the initial spur about a year ago was someone said, is it possible to jump between functions without a function call in solidity? And is there a way of magicking that up? And I thought there was, but I sort of was foiled by the compiler after all, which was unexpected. So let's have a look at solidity. So you can think of you've got plain solidity, which is a high level language, and I know a lot of people are thinking, oh, not sure how high level it is, but still it's a high level language in the scheme of things. And then you've got bytecode, which is just plain opcodes, and so you can type in the opcodes one at a time and the parameters and put a stream of bytes together, and that's obviously very low level, but in between you've got some options, and so you can have solidity with some inline assembler that can be used to optimize the code or do some extra things. And it's more low level than plain solidity, but better than bytecode, more understandable.
00:02:55.680 - 00:04:03.544, Speaker A: And then you've got Yule, and it's a programming language which is a little bit like opcodes, but a bit up from that. So it's more of an assembly language. And so when you've got solidity inline assembler, the Yule is actually just a little, that is the Yule code, and you're directly inserting it into solidity. And so when you're thinking about that continuum, the solidity is going to be less gas efficient, whereas the bytecode is going to be more gas efficient. And what the difference between these two are depends on exactly what you're doing. And so obviously more gas efficient is great, but there are other trade offs, and so one of them is essentially transparency or even comprehendability. So as you go more towards having raw bytecode or assembly language, it gets quite complicated what's going on.
00:04:03.544 - 00:05:10.270, Speaker A: And I think most average solidity devs are going to have trouble understanding what you're doing in your code, whereas as you are going into pure assembler, pure solidity, it's more understandable what's happening. There's also speed of development. So I'd say that you can bang out some solidity code reasonably quickly, whereas if you're doing stuff in Yule or in bytecode, it's going to be a painfully slow process of trying to put things together. So the reasons why you would do things in Yule or in inline assembler is that some things are impossible in plain solidity. So you might want to do something that is just not possible. And another thing is that you might want to do things that are more efficiently. And so let's look at the inline assembler and try and look at what can be done there.
00:05:10.270 - 00:06:33.210, Speaker A: So you could imagine this as a contract, and so you've got one storage variable implementation, and you've got say a constructor, you pass the parameter in and you assign a value to that storage slot. And so that storage slot is going to be storage slot zero. And so if this was a proxy, so you were going to be having another contract operate within the same storage space, then you're going to have a storage collision, probably because it'll be using storage slot zero as well. So what you'd really like to do is use a storage slot that's a long, long way away from where normal contracts will be storing stuff. And so it's difficult to do that just using pure solidity. But what you could do if you dive into some inline assembler is you can call the sdor opcode, and you can actually specify the storage slot that you want to use and you pass in your parameter. So it's a way of specifying exactly where you want to store some information.
00:06:33.210 - 00:07:27.716, Speaker A: And so that's just not available using plain solidity, or not easily available. Another thing that you might want to do is you might want to call a function. So doing a call and then you might want to return exactly what you called, what the return data was. So you don't want to package it up into a bytes or anything. You want to directly return exactly what you got back and return it. And so there's no real way of doing that in solidity. And so if you use this sort of mechanics here, where you're actually saying, all right, I want to revert, and the data that I'm returning is at memory offset zero, and it has this length.
00:07:27.716 - 00:08:57.460, Speaker A: And so you just can't do this in plain solidity. Another one that actually uses the same code, but is a different thing to think through, is it's efficiently using memory. So every time you use more memory in the EVM, you have to pay a memory expansion cost. And so initially, if you're just using pure solidity, it uses the first two words as a scratch pad for doing stuff, and then the next word is a memory pointer, and that memory pointer is used for saying where is the next available memory for allocation? And so the thing is that when you allocate memory, you just keep on allocating more. So even if you stop using it, the next time you allocate memory, you allocate at the end. And the reason for this is that if you had some sort of allocation de allocation scheme, then it's quite complex, and normally contracts are quite small, and so you don't want to be having a memory allocator and having to worry about deallocation and then reusing memory areas. So given that, you might say, well, look, I know what's going on in this contract.
00:08:57.460 - 00:10:15.120, Speaker A: So for instance, with this fallback function here, this assembler code has full control over what's going on. And you can say, look, I want to use, rather than worrying about starting at the free memory pointer at the fourth word, I'm just going to wipe out the scratch pad area, because I don't need the scratch pad area, I don't need that free memory pointer. So I know what's going on and I'm going to use all of the memory. And so doing that will make this cheaper because you're not doing as much, not allocating as much memory, and hence not having as much memory expansion cost. Another thing that you can use inline assembler for is efficiently extracting fields out of bytes. So a way of passing information, arbitrary information to a contract can be to have a bytes and have inside that bytes a whole encoding of data. And if you require all the fields in the bytes, then just using normal abidcode makes a lot of sense.
00:10:15.120 - 00:11:38.700, Speaker A: However, if you just want one of the values, for instance this vowel here, then it's going to end up costing you more. And so that abid code and that call to extract one cost 52,000 gas. Whereas if you dive into the inline assembler and you do an M load from a specific address, and hence you're not doing as much memory manipulation, you end up having a much cheaper call. So it can be cheaper. So obviously I've done something that's very deep in the information there, whereas if that valve was, say, the first or the second, it might not have been cheaper. The other thing to think about is this Abid code. It's nice and simple when it's just plain uint 256s, but if it was a dynamic type, for instance say an array, or a bytes, or an array of bytes, or something complicated like that, then probably it's best to let ABI decode do all the decoding of the data structure, so there's a safety versus efficiency cost there.
00:11:38.700 - 00:13:19.130, Speaker A: And as well, if you look at it, you can see exactly what's going on here with this Abidcode function, whereas when you look at this code, it's more opaque and it's more difficult to work out what's going on. The other big use case of inline assembler is sometimes you'll be passed information that is not ABI encoded. So ABI decode works great if the information is ABI encoded, but if it isn't, then you're going to have to, by hand rip the fields apart. And so this is all solidity code right in front of you, but the two un eight and two U bytes, 32 calls into code similar to what I showed you just before, where you're reading stuff directly out of memory and at a certain index. And so this code here is actually from the wormhole bridge, and so in the wormhole bridge they're going from a variety of blockchains, and hence their encoding format doesn't worry about ABI encoding simply because other chains don't support ABI. So they've obviously maybe initially developed this on a different chain that didn't have Abi encoding. So that's a good reason for diving into some inline assembler, because the plain solidity is just not going to be able to do all of this decoding.
00:13:19.130 - 00:13:27.050, Speaker A: Okay, so, are there any questions about inline assembler?
00:13:30.030 - 00:13:31.980, Speaker B: Thank you, yes, sorry.
00:13:34.770 - 00:13:43.010, Speaker C: I think the first question I am interested in is how often do you think inline assembly is actually used in practice?
00:13:44.230 - 00:14:28.800, Speaker A: Yeah, I think it depends on the contract, I think it is used surprisingly often. That said, a lot of the times you see it hidden inside of, say, open zeppelin contracts. So someone in open zeppelin has put it in, or someone's contributed it. Lots of people have looked at it, audited it, then it's not used, then you don't have individual people modifying it. But I'd say it's quite widely used. Maybe not in every single contract, but I'd say that pretty much at least once per project you'll find at least some.
00:14:30.690 - 00:14:31.440, Speaker C: Thanks.
00:14:35.670 - 00:14:36.270, Speaker A: Frank.
00:14:36.350 - 00:15:54.186, Speaker B: So I have a question related to so the examples you've been showing. Some of them, I think three out of five they could be implemented as compiler optimizations. For instance, you wouldn't really need to do it by hand like the one you mentioned before, where you're just getting one field, the last one, there's a simple, I guess, static analysis or data analysis on the instruction to detect that you only need the fifth component and so you can optimize for this case and the previous ones as well. You mentioned something like it's too costly, so you want to optimize the gas cost and so on. So does it mean that somehow the solidity language is limited? It is apparently even the example you have with this proxy, and you have to manually tweak the address. It seems to be very dangerous to me. So is the solidity language somehow limited and then you have to patch it, but at the same time you get to something that's very error prone and what could you do to make it better?
00:15:54.368 - 00:17:58.980, Speaker A: Yeah, well, I agree that I know there are many optimization steps and it would be really interesting to see. Is there a way of, could more optimization steps be added that would help make a lot of these things irrelevant? And in fact, it is even worth noting that you should always compile code and test out code with the latest version of the compiler, because maybe an extra optimization step has been added that would magically make this cost the same or less than this. And I mean, it's entirely possible. And I guess what you could imagine people could do is people could offer patches to the Sol C compiler and say, here's an extra optimization step, particularly focusing on ABI decode and abidcode when there are unused return values. And just focusing on that and that alone would be a pretty big thing, because even to have a way of going, you've got a byte and you say, I want to have the word at this index rather than people handcrafting stuff as well, you'll suddenly have people who are all using the same library. And then you go to think to yourself, has anyone tested that library? How many tests are written? And then you realize that there are half a dozen tests for a library that's 1000 lines long and it's mainly an assembler. I'm obviously overtly dramatizing it, but you know what I mean.
00:17:58.980 - 00:18:13.270, Speaker A: Yeah. So I think you and others could contribute to the salsi compiler to make optimizations to make a lot of these things redundant.
00:18:15.870 - 00:18:38.960, Speaker B: And I have one last after what you said that you can use some open Zeppelin contracts with some assembly code in it. So is there a problem with versioning, for instance, and upgrades to the Ethereum virtual machine and so on? When you use the contract, do you have to make sure that you use the correct version of the contract and so on if you import it?
00:18:39.270 - 00:19:57.770, Speaker A: Yeah. So for myself, I think I'd always be wanting to use the latest stable version of those contracts. And I guess I would naturally assume that they've been optimized for modern versions of the solidity compiler, which is optimized for the EVM. But as we all know though, there are now many chains that have got EVM compatibility and many roll ups that have now got varying levels of EVM compatibility. So you can imagine SolC is going and those open zeppelin contracts are going to be optimized for Ethereum. And so if you're programming for, say some other system, how it's been optimized may be suboptimal for you, but using a contract that a lot of people have looked at and feel is good is probably much safer than you writing your own code. So you should, where possible, be using templated stuff that a lot of people have worked on, even if it is slightly suboptimal.
00:19:57.770 - 00:20:12.932, Speaker A: Are there any more questions? All right, cool. Questions are good. By the way. Shows you. Hi Peter. Yeah, go ahead.
00:20:13.066 - 00:20:23.000, Speaker D: Hi, sorry. So with by IR on, is that assembly that you write optimized by the UL compiler.
00:20:24.060 - 00:21:21.424, Speaker A: So I was looking at this. So they're trying to understand exactly what all these optimization steps at various layers do. So it seems to me there is no separate UL compiler and it's also the sol C compiler, but I expect there's a separate Yule section. So there was talk about the intermediate representation being compiled down to Yule and then having steps that tried to optimize Yule, but from what I can tell, that doesn't actually happen. So the IR stuff I don't think actually gets to the Yule language. But I might be wrong there because I didn't play around enough with Sol C. Does that make sense? Yes.
00:21:21.462 - 00:21:21.904, Speaker B: That's good.
00:21:21.942 - 00:21:59.176, Speaker A: Thank you. All right, cool. Okay, Yule. So the idea of Yule is the whole contract is written in assembler. And so absolutely everything. And so the people who wrote Yule, they wanted their programs that are implemented in the language to be as readable as possible. And so they had the thought that you could have solidity and generate Yule or have some other high level language and generate Yule.
00:21:59.176 - 00:22:49.260, Speaker A: But as far as I could work out, it wasn't actually doing that at the moment. But maybe I missed something. The control flow should be easy to understand just by looking at the code. And the idea was that it was going to help with formal verification and optimization. The transformation from Yule to bytecode should be straightforward and you should be able to do whole of program go. If it could get solidity to Yule, I think it would be quite valuable because you'd be able to say for the abid code, you could point at what's going wrong and where's all that extra gas being used. So I think it'd be quite valuable.
00:22:49.260 - 00:24:13.184, Speaker A: So given the design goals, you've got things like for loops, if and switch statements in the code, and you've got function calls as well. But that means that you can't play around with the control flow using jump and you also can't fiddle around for the stack using say, swap or jup. And so it means that you don't have to worry about the stack or jumping around code and offsets and things, which makes dealing with the low level language much simpler. It sounds like a small optimization or small change, but it actually is very powerful. However, if you want to, you can go nuts and implement your own bytecode in the middle of your code. And so for instance, here you're loading up a value X and then you're saying, I've got one word input on the stack and I'm not going to push anything on the stack. So this code will pop one word off the stack, won't push anything onto the stack.
00:24:13.184 - 00:24:59.750, Speaker A: And the actual op codes are these ones here. And the input thing that's going to be at the top of the stack is going to be X. And so then it'll process that. And so even in Yule, you can still, if you really wanted to, you could go swap and dupe and all the rest of it and jump. Or importantly, if there was some new opcode, or say, if you're working in an EVM where they've introduced an extra opcode that isn't supported in Ethereum, then you could use this verbatim to have to call that opcode. Just going to go and.
00:25:01.960 - 00:25:03.388, Speaker B: Click mute.
00:25:03.584 - 00:25:13.120, Speaker A: All right, so when you're looking at your code, you've got an object, which is the top layer.
00:25:13.300 - 00:25:14.716, Speaker B: There was a question.
00:25:14.898 - 00:25:15.836, Speaker A: Oh, was there?
00:25:15.938 - 00:25:20.110, Speaker B: Yeah, Hayden has a question. Apparently you're right. Got his hands.
00:25:21.600 - 00:25:25.472, Speaker A: Sorry, I didn't notice it. Please go ahead. That's right.
00:25:25.526 - 00:25:27.756, Speaker D: Could you just go back to the last slide for a minute?
00:25:27.788 - 00:25:28.370, Speaker A: Sorry.
00:25:29.860 - 00:25:45.968, Speaker D: Yeah, this verbatim instruction you can pass in the opcodes as like a string, it seems. Is that dynamic? Like, can I use that as like an eval, if you will? Or does that have to be compiled?
00:25:45.984 - 00:26:03.816, Speaker A: Yeah, I'm almost certain. That's got to be constant. I think that's got to be constant. Otherwise. Yes. No, it's got to be constant because this is going to end up being the bytecode that gets deployed. And so that's not going to be dynamic.
00:26:03.816 - 00:26:05.740, Speaker A: That's got to be constant.
00:26:07.120 - 00:26:14.430, Speaker D: Is it possible to dynamically execute bytecode that isn't compiled as a contract code?
00:26:14.740 - 00:26:52.440, Speaker A: Yeah, it is. So what you could do is you could have some code that could generate some bytecode, it could deploy that as a contract and then you could call that contract and then execute your arbitrary code. So that would be a way of having arbitrary code or even self modifying code if you really wanted to. You could grab the current code, modify it a bit, deploy it as a new contract, call it, and then come back and then go back to the user, the EOA.
00:26:52.780 - 00:26:59.740, Speaker D: Right. But that code always has to be deployed as a contract. Like it's no way to say execute code off the stack or something.
00:26:59.890 - 00:27:52.940, Speaker A: No, no way of executing code off the stack. Thank you. You could implement your own interpreter though, which is obviously going to be pretty costly. But you could have an interpreter written in solidity or in EVM bytecode that then does something. Thank you. Okay, so, Yule, so you've got different code sections, and the code sections are created and put together one after the other. So you could have multiple more code sections, but generally you just have two.
00:27:52.940 - 00:28:30.280, Speaker A: The first one is the init code, which is essentially the constructor. And then the second section is the actual runtime code. So the code that's going to be deployed. And so, yeah, so I'm going to go through an example. And the example is a proxy. And so you can imagine you could have a proxy that's like this in solidity. And so what it does is it's got an implementation address.
00:28:30.280 - 00:29:55.442, Speaker A: Actually that should be implementation, not impul. And then if it gets called with anything, it's going to call the fallback function, and then you call delegate call and you pass in the message data and then you get a result back and then you just go require, okay, and then if it's not true, then it's false, and then you can say all right, delegate call failed. So that's actually not a very good proxy for two different reasons. So one is that you're using a storage slot zero, which is going to be a storage collision, and the other one is that you're not propagating the error out, which is not very helpful. You could try and have a better proxy written in solidity with some inline assembler that could look a little bit like this. So we store the implementation at a storage slot defined by the address. So in other words, you deploy the contract, it's going to have a certain address, and then you use that number being the address as the storage slot to use, and you could store the implementation there.
00:29:55.442 - 00:31:28.910, Speaker A: And the thing to think about is when you call address, that's just going to take one that's just one opcode and isn't going to use a lot of gas. Whereas if you've got to load up a big long word like do an S load of an address, then of a memory slot, it's going to be far more costly. So you could do that, and then maybe you want to be able to get the implementation address that you've stored, and so you could have s load address again. So the address of the current contract and using the address as the storage slot number and then returning that implementation. And then the actual proxy could look like this, where you load up the address, or you load up rather the storage slot defined by the address as the target to call, and then you copy the call data to address zero or memory location zero. And then you do a delegate call, passing all the gas, calling the target contract, passing the call data size, and you specify zero as the length of return data. And so what that does is it says I don't want to know about how much is returned because I don't have a memory.
00:31:28.910 - 00:32:51.260, Speaker A: What you'd normally have to do is allocate some memory and then it would copy into that memory. You'd have to say how much to return. And the problem with that of course, is that if you specify more than available, then you've got to truncate when you're returning. But if you're returning more than you had allocated, then it'll say, oh look, you need to allocate more memory and so suddenly you've got lots of conditions, whereas this way what you do is you go return data copy and you just pass in the return data size and then you can go revert and return the error message or return, and return the return data. So that's a minimal proxy that you could write in solidity with some inline assembler. So what about though, if you wanted to try and make that smaller and hopefully more gas efficient using Yule, the first thing to do is obviously write that init code that we saw. So essentially what we're trying to write is this bit of code here where we are storing the implementation parameter at a storage slot defined by the address.
00:32:51.260 - 00:33:51.966, Speaker A: And so we've got to think that there's no call data in the init code. You've got the code segment contains the init code that you're executing, and immediately following that is the runtime code, and immediately following that is the ABI encoded parameters. And when the code returns, when the init code returns, it must return the offset in memory of the contract bytecode. So the runtime code and the length of the runtime code. So the first thing we do then is we do a data copy. So this is actually a code copy, but in Yule, because it's designed for eWASM and for EVM, it's just got a generic one called data copy. And you'll notice that I use return data size.
00:33:51.966 - 00:35:07.960, Speaker A: So the return data size opcode returns zero until the first time that you do a call. And after that it returns the length of the call data due to the previous call. So hence it's a great way of loading up zero with a single opcode and not much gas. And to make code clearer, there's actually going to be a push zero opcode in the forthcoming fork. And specifically so we don't have this crazy stuff where people go, what on earth is going on? Yeah, so we return data size and then we go the data offset of the runtime data. So you remember they were copied one after the other, and then the length. And what we want to do is we want to copy the actual runtime data, but we also want to copy the parameter which we've got, which is a single word, which is the address of the contract to be proxied to.
00:35:07.960 - 00:36:37.374, Speaker A: So you could do add data size, runtime comma 32. But if you do that, then you will actually give you the opcode for add and it'll push this constant onto the stack, it'll push this constant onto the stack and you'll end up with more code. So Yule at the moment doesn't support simple constant addition, which is quite frustrating because I think just having zero X 54 there seems rather error prone, whereas having data size plus 32 would be far simpler and less error prone. But anyway, so that's what you've got. So we're copying the runtime code and the parameter into memory and we're copying them to offset zero. So then we wanted to, so then what we need to do is we need to get that the actual parameter, which was the implementation address out of memory. And so because the stuff that we copied in this previous command was copied to zero, that it means that the actual parameter is going to start at data size of the runtime.
00:36:37.374 - 00:37:27.102, Speaker A: So essentially the end of the runtime code. And so we load up that into a variable. So essentially we push it onto the stack and then we do s store at the storage slot defined by the address of that variable that we've got in the stack. So loading, storing the implementation address, done. Tick. The next thing is to return the code to be the runtime code. So we say it's stored in memory, starting at address at memory slot zero, and the length of it is the data size of runtime.
00:37:27.102 - 00:39:23.850, Speaker A: So remembering that return data size is returning zero. Now that we've got the contract deployed, now we've got the runtime code, the contract code that we want to have. And so for this you've got the call data is the first four bytes are the function selector, and it's followed by the ABI encoding of the parameters. And the execution is going to execute and it's going to stop when you either encounter stop invalid or self destruct or revert or return, where revert and return will return the memory offset, followed by the length of the return value where that there should be return value. Okay, so the first thing to do then is to get the function selector. And so that is just the first four bytes of this word, first word of the call data. And so we have to shift it 224 bits to the right and then we put it on the stack and then we say, well, if the function selector equals the function selector for proxy get implementation, then what we're going to do is we're going to load up the implementation address onto the stack and then we're going to store it at offset zero in memory and then we're going to return and we're going to say, well, we're returning one whole word and it's located at offset zero in memory.
00:39:23.850 - 00:40:40.370, Speaker A: And then after that we've got to, we're returning. So if we haven't done get implementation, then we must be doing the fallback function which is going to be proxying to the implementation contract. And so the first thing we do is we say, well, let's copy all of the call data from offset. So we want to have it end up at location zero and we want to start from location zero in call data and we want to have all of the call data. So go and copy it all. And then we're going to need zero later on. And so if we could have actual bytecode, I could be doing dupe now because I know we've got some zeros on the stack and I could be using dupe, whereas this though does a very similar thing because essentially I say I want to have zero available on the stack and I'm going to use it later.
00:40:40.370 - 00:41:40.880, Speaker A: So we do that delegate call. And so delegate call, you pass the gas, you load up the storage slot defined by the address, which is the implementation address. You say that the location in memory of the parameters that we're passing in are at zero and we're passing in all of the call data that we were given. And the return offset that we want the data put at is zero, but we only want zero lengths of the return data. So don't give us any of the return data. And so that's the delegate call and it's going to give success, which is going to be one or zero. And so the next thing of course to do is to copy the error message or the return data back to memory offset zero.
00:41:40.880 - 00:42:39.518, Speaker A: And then we say, well, if we are zero, then if success is zero, then that means that we failed. So let's revert. Otherwise, let's return. So that's your code. And so imagine that you've got this simple bit of example code where we've just got set and get for setting a Uint 256 and getting a Uint 256 back. So if you implement that really tight solidity that was mainly in line assembler compared to Yule compared to just bytecode. And so I got the bytecode of the Yule code and tried to work out how I could optimize it further and I couldn't work out anything that I could do to make it smaller or tighter.
00:42:39.518 - 00:43:41.474, Speaker A: And so your contract deployment is less, not quite half, but almost, whereas the actual function call is almost the same. I mean 63, 61 gas is almost nothing. So yeah, not a lot in it for the actual function call that you're using set, but an awful lot in it for the contract deployment. So I hear you say then, well, tell me the use case, why would you go to that pain to write that Yule code? Because that did seem a bit complicated. And so imagine that you've got a system where you've got proxy contracts for on chain wallets. So you've got account abstraction that people always talk about. So imagine you've got a wallet that's used for account abstraction and everyone ends up with their own wallet.
00:43:41.474 - 00:44:46.940, Speaker A: So you might be deploying a million of these contracts and the actual wallet code, it could be quite large. And so you don't want to have to have every single user deploy that large contract because it's going to cost a ton of money. So what you do is each user deploys a really small contract, so a minimal contract, and they then talk to the wallet contract, the actual implementation. So that is when I think this code is most likely to be used is when the deployment costs are super critical and it's really, really small amount of code. If you were deploying something and it was a really large contract, I think trying to write it in Yule would be really error prone and pretty scary. So are there any questions about the bit that I've just been over the Yule code?
00:44:49.790 - 00:45:19.870, Speaker C: Just about that last thing that you were talking about, Peter. Yeah, it's a trade off here, right? Because you are, what's the right word? By setting it up like this, you're ending up having to use a delegate call. So you are charged more when you make a call, but you're not having to deploy so much code in one big go. And I guess that's the trade off that people want to make. Or in some situations it makes sense to make that trade off.
00:45:20.040 - 00:46:01.650, Speaker A: Yeah, exactly. And it's a big trade off. And even that get implementation call, if you don't have that, there's a few fewer bytes that you've got to worry about and everything gets just that little bit smaller. But being able to say, well, what implementation am I pointing at? Can be very useful. But as you point out though, you are doing a delegate call, whereas otherwise you wouldn't be. But then it does allow you to have an upgradable contract. So in this wallet implementation.
00:46:01.650 - 00:46:35.646, Speaker A: So you've got to have some way of knowing that you've signed even in one of these account abstraction wallets, you know you've signed something somehow. And so when you've signed it, then you're saying, all right, well I want to sign for the fact that I want to upgrade to the new version of the wallet contract because there's a bug in the old one or something, or a new feature. And so you're still going to end up wanting to do a delegate call just so you have that upgradability feature. Yeah.
00:46:35.668 - 00:46:38.240, Speaker C: So in that context it doesn't make any difference then in.
00:46:39.410 - 00:46:41.870, Speaker A: Exactly. Cool.
00:46:41.940 - 00:47:00.950, Speaker C: Thanks. Actually I've got one more question for you. You talked about Yule at the beginning about how it be useful for various things and I'm wondering again, it's a sort of similar question actually before. How much do you think Yule is actually used for writing contracts?
00:47:02.090 - 00:47:37.086, Speaker A: I don't know. It's one of those things. I should have done the web search, shouldn't I? And tried to see what Yule code is out there. Has someone implemented something massive in Yule? I know the example that they've got in the Yule manual is an ERP 20 contract. You would be nuts. Why would you be doing this? Yeah. So I just can't imagine there being much out there.
00:47:37.086 - 00:47:42.050, Speaker A: But I guess I have not looked. So maybe I'm mistaken.
00:47:43.750 - 00:47:44.066, Speaker D: Yeah.
00:47:44.088 - 00:47:57.560, Speaker C: I was just wondering does that mean it's achieved its goal of what they were trying to do with it? It's a useful intermediate language if you like. That comes out of solidity for example. But I wonder. Yeah.
00:47:58.330 - 00:48:11.082, Speaker A: Anyway, well that's the thing. So you'll examples in another window. I'm quickly doing Yule example. Think if I end up with a million hits or something.
00:48:11.136 - 00:48:13.626, Speaker C: Yeah, it's all good. I've just understood it.
00:48:13.728 - 00:48:34.654, Speaker A: Yeah. See I mean you've got lots of people wanting to do beginners guide to and telling you how to do. I mean I'm not getting GitHub repos or anything. Which surely would be. That would be the way to know. You would hit GitHub repos where there's something yol there's code search in GitHub.
00:48:34.702 - 00:48:35.554, Speaker C: I'll try that.
00:48:35.672 - 00:48:41.400, Speaker A: Yeah, you do that. Circle back with us by the end of the talk in about another ten minutes.
00:48:43.210 - 00:49:00.810, Speaker B: I've got a related question actually. Do you know if there are any, let's say optimizers for Yule that would take advantage of the structure of the code because it's structured, let's say EVM code and do things that you can't do on the EVM bytecode.
00:49:02.190 - 00:49:29.810, Speaker A: And that's very close to what Hayden was asking about earlier. And so if I type here soul C and just hit enter. So there is like an optimizer options and there's optimize Yule, but that's a legacy option ignored, and then use optimize to enable Yule optimizer.
00:49:35.050 - 00:50:05.760, Speaker B: The other side of my question is it's, let's say a friendly version of EVM bytecode, but if you create an intermediate language, you would have maybe more reasons to create it rather than making it easier to read. Otherwise, I don't really see the point. Like LLVM for instance, you created as well to be the target of different compilers and you can have some passes, optimization passes and so on.
00:50:07.250 - 00:50:55.040, Speaker A: Yeah, well, look, I thought, well, maybe there would be a way of having some yule code and extending it so you could mix solidity and Yule. But no, I don't think that's possible. But again, that might be me not looking hard enough. Like I know you can create an ABI, but I think how the solidity compiler works is it essentially copies some code into the code that's being compiled and it copies them in order. And so it's just going to copy some yule code in and then it goes, I don't know how to do this. All right, let's try and jump between functions in solidity. Without making it too obvious.
00:50:55.040 - 00:51:58.500, Speaker A: Imagine that we've got, so you've got a deployer top, and last time, so they get set up initially and to message sender, and then you can send one ETH to topcat and you must send one ETH. And if you send one ETH, then the timestamp gets reset and top gets set to message sender. And then there's a payout function, pay, which is external. And so it says you've got to wait one day since last time and you've got to be the one on top. We're going to then pay out to message sender. And of course then you do a transfer. So you work out what balance you've got and you transfer it across.
00:51:58.500 - 00:54:30.574, Speaker A: So that's some really simple code that's not jumping anywhere but that you could have. And so I thought, well, what happens if we had this code? So who noticed the difference between this code and this code? Is there any difference, this code and this code? All right, what does that I do? Anyone, any thoughts on what that little letter there does? Any budding solidity auditors on the call? Okay. All right, that's a modifier. Modifiers don't have to be explanatory or helpfully named, they can be just one letter, and I'm sure people would probably try and find the smallest letter possible. So imagine that this was the modifier, and my grand plan had been to use verbatim directly in the inline assembler, which I would have thought would be useful, because you know how I talked about, you're on an EVM that isn't the Ethereum eVM, and they've got some extra opcode that you want to execute, and that would be a really good way of doing it where you put in verbatim and you put in the opcode, and then you return a value based on that opcode. So say for instance before, say solidity supported or before Yule supported, returning the chain ID via that chain ID op code. You could imagine that that could have been a useful thing to do, but anyway, you're not allowed to do that, which is really annoying, because that had been my cunning plan, to have this code and jump to anywhere I liked, including to, I was going to jump to payout, and so you could have pay and then you could do the s load.
00:54:30.574 - 00:55:47.002, Speaker A: So caller is going to give you message sender, and s load zero will load up storage slot zero. And if the two of them are equal, then you're going to execute what's in here. You obviously can't do that, but what you could do as a modifier is you could execute this afterwards. Let's have a look at the code again. So we do pay, we call payout, and so that modifier that I've declared here, because it's got the underscore semicolon first, it means that this code ends up at the end of the function, so the person is going to do the call, and then we're going to say, well, if the message sender is equal to s load zero, and if they're equivalent, so if they're not equivalent, then stop. So essentially if the message sender isn't so just so we know, what is storage slot zero. So storage slot zero is the deployer.
00:55:47.002 - 00:56:51.464, Speaker A: So essentially if the caller isn't the deployer, then stop. And so actually that should be revert, shouldn't it? I should have done a revert zero, comma zero, not stop, because if I just do stop, then it'll work. But if I had have done revert, so that should be revert. So if the caller isn't the deployer, then revert, so that should be revert there. And so in Yule, and hence in the solidity assembler, inline assembler, you can actually specify the storage slot by the variable name, which obviously makes life easier. Another way you could do it is you could have. So these two ways weren't actually going to, they were assuming that was revert, they were just going to make it fail when someone tried to claim.
00:56:51.464 - 00:58:02.160, Speaker A: And so you could get in then eventually and claim all the money. But another thing you could do is you could have function do nothing and function payout with the same function selector, the same function signature. And then you could say, well, if the deployer is message sender, then actually set function one to become payout. And then what we're going to do is we're going to call function one with message sender, which was caller. And so that'll happen before the other code. And so then what's going to happen? Actually, I should do a stop at that point, shouldn't I? So I should have after fun one, I should have then done stop and then that would have done an assembly stop. Sorry, my code here was done in a bit of a rush, unfortunately.
00:58:02.160 - 00:59:01.780, Speaker A: But you can see though what you can do is just have a little bit of a play with jumping around. But I didn't end up doing what I had hoped to do. So I had hoped originally to do this, and I spent an enormous amount of time trying to get that to work and I couldn't get it to work as is life. Okay, so there is assembler code, inline assembly code, and the Yule specification, which you should have a look at. And in the examples in the assembly two directory, you find the code that's here. So I'll just talk about the talks that are coming up and then we can go over to questions again. So next week Philip Zetner from Lephi is doing a talk on his thoughts on bridge aggregation.
00:59:01.780 - 01:00:30.300, Speaker A: Then in two weeks I'm going to be talking about ERC 1271, which is another standard related to account abstraction. We've got Leo who's going to talk about Amms, and he's going to take us from knowing pretty much nothing about amms to multidimensional amms and all sorts of whiz bangery. We've got Oliver from, can't tell you off the top of my head, but he's from an auditing company and he's going to tell us his thoughts on smart contract auditing. We've got Sriram Cannon and he's going to talk about Eigen layer. And then last but not least, in June we've got David talking about bridge agnostic cross chain messaging, which I think is going to be a similar thought, but probably a different, very different take on the amm work, rather the bridge work that Philip's doing. And as well, I think that talk will show the results of all of the work that uniswap are doing on bridge agnostic messaging. And yep, if you're watching this here live, you can watch the recordings on YouTube.
01:00:30.300 - 01:01:08.680, Speaker A: Join Slack, join the meetup, come and ask tricky questions live. And also there's a formal methods reading group. Go into the slack and into that channel and you'll learn more about that. So I've talked for a bit over an hour and are there any questions? We're all questioned out, which is not a bad thing. Questions whole way through is good too. Yeah.
01:01:11.690 - 01:01:30.860, Speaker C: I was just going to say that I didn't find many good examples of pure Yule implementations. There are a few things that ERC 111 55 contract. It's quite a lot of Yule used inline assembly. I think that's probably what I would say just from a quick look that I can see. Definitely.
01:01:31.950 - 01:02:12.950, Speaker A: Yeah. So people are doing it as inline assembly, which makes sense because use it when you need it because that contract that I did, it's great as a one off and it's fit for purpose, but as a general bit of code that you would want to create something much bigger. All right, how's that? Kiki got it earlier on. I should have watched the chat. All right, talk to you all later everyone. Have a great day. Bye bye.
01:02:12.950 - 01:02:14.434, Speaker A: Bye bye.
01:02:14.482 - 01:02:14.930, Speaker B: Thank you. Peter.

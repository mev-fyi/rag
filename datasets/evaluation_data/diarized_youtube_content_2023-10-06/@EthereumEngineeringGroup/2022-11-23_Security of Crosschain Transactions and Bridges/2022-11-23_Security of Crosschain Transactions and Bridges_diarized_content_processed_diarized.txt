00:00:01.290 - 00:00:18.960, Speaker A: Hello and welcome, everyone. I'm Peter Robinson, and today my co worker, Ermiya Sabibi, or Dr. Ermiya Sabibi, is going to talk all about cross chain security. So, Ermius, before you share your slides and kick off, why don't you tell us a bit about yourself?
00:00:20.610 - 00:00:43.290, Speaker B: Sure. Thanks, Peter. And thanks, everyone, for coming. Hello. I'm Hermes. I joined consensus about a year ago to work on cross chain communications research. Before that, I was with IBM research for about eight years or so, the last four of which I used to lead the blockchain R D group for the Australia lab.
00:00:43.290 - 00:00:49.660, Speaker B: My team and I were primarily focused on enterprise blockchains, so that's a little bit about me.
00:00:50.110 - 00:00:57.230, Speaker A: Okay, cool. So, are you happy for us to ask tricky questions the whole way through, or should we wait to the end? What would you prefer?
00:00:57.890 - 00:01:10.660, Speaker B: Yeah, I think what I'll probably do is maybe pause in between key sections to take questions. But if there's anything burning, please feel free to interrupt me along the way as well.
00:01:11.190 - 00:01:13.966, Speaker A: For sure. All right, well, please share your slides.
00:01:14.158 - 00:01:43.710, Speaker B: Okay. All right. Can you see my screen? Yes. Awesome. Okay, so, thank you again for coming. What I plan to do over the next hour or so is really talk about this broad topic of security of crosschain protocols. Here's a quick outline of my talk.
00:01:43.710 - 00:02:23.880, Speaker B: What I'll do is start off with a bit of background on what crosschain protocols are, why they matter, what some of the key challenges in the space are at a very high level, and then we'll talk a little bit more about security risks in the space. And there are numerous. Right. So we'll introduce a broad framework for how to think about the different risks in the space. Specifically, we'll introduce four layers or categories of risk. Specifically, network risk architecture, risk implementation, and operation risk. And we'll spend a fair bit of time looking at the different challenges and considerations in the space through this framework.
00:02:23.880 - 00:03:18.252, Speaker B: After that, what I'll try and do is ground this a bit more through concrete case studies of hacks that have happened over the past twelve months or so. And specifically, we'll look at the hack that happened, the attempted hack on Rainbow Bridge, and the hack on Ronin and nomad protocols. And then finally, I'll have a few concluding remarks. So, as you know, one of the key realizations we've come to collectively in this industry over the last couple of years or so is that the future is likely going to be multichain. And what that means is that we'll likely have a number of different layer ones. Layer twos and beyond, all with thriving ecosystems that are going to coexist and serve a range of different purposes. And in this context is what we've seen.
00:03:18.252 - 00:04:40.096, Speaker B: Crosschain protocols emerge as an important building block that essentially enables these different ecosystems and chains to seamlessly interact, ideally in a manner that preserves some of the core tenants we value in this space. And so crosschain protocols essentially enable this seamless exchange of data and value across different chains, and in doing so, reduce the fragmentation that would otherwise arise from a multichain world. Right, and they also enable scalability, increase liquidity, and overall improve market efficiency in this whole multichain world. Moreover, I think there's a promise in which such protocols can enable and open up a whole new design space for how we think about natively crosschain applications and the whole new design space that could potentially unlock. And this has clearly been realized by the broader space, and this is somewhat evidenced partially by the value and investment that we've kind of seen in the space. If we look at the total value locked just in bridges alone, we'll see that late last year it reached almost 30 billion in total value locked just on the Ethereum side alone. And that has somewhat declined with the decline we've recently seen in the broader crypto industry.
00:04:40.096 - 00:05:49.292, Speaker B: But nevertheless, the scale of what we still have in TVL, around 6 billion, still somewhat alludes to the significance of such infrastructure to enabling a multichain future moving forward. And of course, coinciding with this, we've seen a number of different protocols emerge, over 100 or so different projects in this space that are all targeting different aspects of crosschain communication protocols. The flip side of this, of course, is all the security challenges we've been observing in the space, right? So over the last twelve to 15 months alone, we've seen around 2.5 billion stolen and bridge exploits. For context, that's roughly two thirds of all d, five more than two thirds of DFI exploits that we've observed in that space. And on the right, what you see is the leaderboards that rect publishes the range of hacks we've been observing in the DFI space. And you'll see that the bridge exploits basically kind of dominate this list with almost 50%.
00:05:49.292 - 00:07:04.660, Speaker B: And the actual value of these hacks is astounding and somewhat significant. On the left, the chart you see is from Masari, and the green spikes that you see dwarfing the white ones are really the bridge exploits in terms of their scale and magnitude that we've observed. Of course, an important point to note in the slide as well is the hacks that didn't happen. Right? So we've noticed almost a billion in potential losses and vulnerabilities that have been disclosed by white hats, and it's just a coincidence that these were not really kind of caught by malicious actors, otherwise the scale in which we would have observed the losses in the space could have been much, much bigger. So it's clear that crosschain protocols have a significant role in the future of the web3 space. And it's very evident that there are significant security challenges that are currently plaguing the space. And an obvious question to ask is why? And here we'll start off with a cursory set of answers, and then what we're going to do in the course of this talk is really kind of delve a bit more into some of these bullet points in some depth.
00:07:04.660 - 00:08:07.768, Speaker B: As a start, of course, the question will be what would be the incentives to target this space? And the obvious one is that there's significant value locked mostly in token bridges that back these protocols. And we briefly alluded to that earlier when I mentioned that at its peak we had about 30 billion locked in Ethereum alone. So there's significant value that really creates a honeypot for hackers. And in the technology itself, what we can see is that there's a large attack surface, and we'll explore this in a bit more depth. The protocols generally introduce new trust assumptions, which are a source of new and additional risk. There's complexity in the environments, the tools and frameworks that need to be used, given we're spanning different ecosystems and platforms, some of which are nascent and are not as well understood as, say, the EV app, for example. We've also noticed that the practices employed by teams might not be as rigorous as we'd like.
00:08:07.854 - 00:08:08.104, Speaker C: Right.
00:08:08.142 - 00:08:54.072, Speaker B: And there are a few examples of this that we'll go to in some level of depth. So there are a range of reasons and challenges. And really what we'd like to do in this talk is explore some of this in a bit more detail. So, security risks, I think as a starting point, before we get there, it might be useful to talk about what we mean by crosschain protocols and crosschain interaction at a high level. You can think of all the different types of crosschain interactions that we have in these three broad categories. One is asset exchange, and here what we're trying to do is enable two or more parties to swap assets across networks. I might have token a and network a.
00:08:54.072 - 00:10:07.868, Speaker B: You might have token b and network b. And really what such interaction involves is the exchange of my asset for yours across these two networks in a manner that is fair. The second is asset transfer, and this essentially is the movement of the value that are represented by an asset from one network over to another. Essentially, it could mean that I want to move eth from ethereum over to say, avalanche, right? And essentially we only want the value of that one eth that I want to transfer existing in only one of these chains at any given time. And we're trying to mimic the transfer of the value of that ETH across chains as opposed to actually moving the asset. And lastly, we have this broad category, which is general purpose message passing across networks, right? And this enables a whole range of new applications beyond the two interaction patterns that we mentioned. So to complement this, I think it's worth thinking about the crossing protocols in this layered stack here.
00:10:07.868 - 00:11:09.632, Speaker B: Essentially what we're trying to call out is that crossing protocols really kind of serve different purposes and are not really a monolith. It's worth thinking about these different layers and what they do and how they depend on each other. At the bottom layer, we have this idea of a messaging protocol, and here this layer is really kind of responsible for the transfer of state information from one network to another, how it's tested or validated, and all the considerations around proofs associated with state that's communicated from one network to another. A layer above that that you'll also see highlighted in blue, which is here as coordination protocols, is really any additional orchestration you might want to do on top of such messaging. And this could be to ensure atomicity in the interaction that happens across chains. And one of the protocols that we've been working on in this team, GPAC, is one such protocol. On the left hand side you'll see at the bottom token bridges.
00:11:09.632 - 00:12:33.496, Speaker B: And really what these enable is the transfer of value from one network to another, on top of which we typically build liquidity networks that enable different entities to exchange assets. Right? So as you'll notice from my description roughly in terms of how the interaction patterns or modalities on the left somewhat relate to the layered architecture view of crosschain protocols on the right might look something like this, where at the base layer we have this messaging protocol, enabling a range of possible applications to be built on top of that, token bridges that enable asset transfers, and liquidity networks that essentially enable asset exchange. And it's worth, of course, acknowledging that there will be different variations to this. It doesn't necessarily mean that all liquidity networks are kind of built in the stack as an example. So before talking a bit more about some of the security challenges, it's good to probably start off by stating at its essence, what are some of the properties we're trying to achieve. As we noted, what we're trying to do with cross stream protocols is really coordinate state change across networks. And implicit in this is at least two core properties that we're trying to achieve.
00:12:33.496 - 00:13:27.970, Speaker B: One is that state we communicate from one network to another is valid and final according to the consensus rules and other protocol rules that are employed by the source network. Right? So think of this as a safety property. And the second is that all cross chain state information that's communicated is done so in a timely manner. And you can think of this more broadly as a liveness, a censorship resistance and so on concern, right? So these are loosely stated. On top of these, of course, we can have a number of additional properties that we care about. For instance, you can imagine that there might be cross chain applications that introduce invariance in how things are supposed to be across chain or invariant in terms of the integrity of state that needs to hold across chains, and that could be an additional property you layer on top of this. But at its core, these are the two properties we care about.
00:13:27.970 - 00:14:33.744, Speaker B: So with that in mind, it's worth thinking about the different risks and categories of risk that kind of emerge when thinking about the space more broad. In here, we call out four different categories of risk, or layers of risk, if you will. The most fundamental layer is the network risk, as you might have noticed in how I stated the core properties before. Essentially by having crosschain protocols that are trying to coordinate state exchange across networks, we're making fundamental assumptions about the soundness and safety and liveness of the networks themselves. Right? So that essentially can be one source of risk, as we'll see in a bit more detail later. On top of that, of course, we have risks that relate to the architecture or the design of the protocol itself. Different protocols will make different security, will have different security properties, will have different trust assumptions, and make different trade offs.
00:14:33.744 - 00:15:22.100, Speaker B: And that can itself be a source of risks that need to be considered and mitigated. Following from that, of course, is implementation risk. And a simple way to think about this is code risk, though it could be broader, right? And here it's essentially any risks that stem from the creation of artifacts and code relating to the protocol itself. And lastly, we have operational risk, which is really risks that stem from how these protocols are operated and managed. And typically such protocols involve a number of different moving pieces managed by different actors. So there's a whole large surface in which risk emerges in the space as well. And we'll see some of this through concrete examples.
00:15:22.100 - 00:16:36.680, Speaker B: So what I'll do over the next few minutes is really kind of delve into each of these in a bit more detail, citing examples where relevant. Before I go into network risk, I'll quickly pause to see if there are any questions thus far. Okay, so network risk, as we briefly mentioned, crosschain protocols enable the coordination of data across networks. And the assumption here is that the underlying networks essentially kind of guarantee safety and finality of state. They can essentially kind of guarantee that state that is correct and valid in one network somewhat continues to hold after it's finalized, as an example. Right, and the consideration here is that if state is reverted in that network after a period of time, any corresponding changes that we might have applied on another network, on a destination network, as a result of that state that's reverted, now ends up in a more in an inconsistent state. And this is beyond the control boundaries of crosschain protocols themselves.
00:16:36.680 - 00:17:37.790, Speaker B: And you can imagine that such a reversion could happen for a range of reasons. There could be protocol bugs and forks that cause reorgs or a 51% attack, and this is a fundamental limit to the security guarantees the crestian protocols can offer, at least for independent networks. Right. It's worth noting that in independent networks, what we have is two separate sources of truth, whereas in something like a roll up, for instance, where the source of truth is really the underlying l one, such reversions are less severe. Right. You could imagine that the roll up itself kind of goes back in state because the l one has reverted as an example. So this is certainly an important consideration, and one that Vitalik himself called out as potentially a fundamental limit to the space which shapes his outlook on where he thinks multi chain future will evolve to.
00:17:37.790 - 00:19:50.890, Speaker B: What are some of the considerations that stem from this? Obviously, as cross chain protocols are being constructed, thinking through the likelihood that this could occur in smaller networks, with weaker guarantees being much higher than, say, this happening on ethereum as an example, and also thinking about what types of mitigations can be made to reduce the potential contagion of a small network failing, basically impacting subsequent networks that otherwise wouldn't have been impacted. Right? So crosschain protocols themselves can be vectors of such contagion. So thinking through how protocols are designed to at least mitigate that impact is going to be important, and it's worth acknowledging that this is more systematic risk, as opposed to idiosyncratic risk, where essentially one network failing in this manner basically impacts all bridges to and from that network. As an example, a second category, which we'll spend a fair bit of time on, is protocol architecture risk. Right? And to delve into this in a bit more detail, it's worth again revisiting that layered stack that we spoke about, where at the bottom we have a messaging protocol that essentially enables state transfer and deals with all of the mechanisms around how that happens, how state is kind of validated and taken to be true across networks, as an example. And what I'll do is at least talk about the messaging protocol and the token bridge layer in a bit more detail, starting more with the messaging protocol, which I think is a foundational piece to think through the different architectures that emerge here at a very broad and high level. It's of course worth starting with the simplest scenario we can think of, right? And here a good example of that is the early hashtag log contracts, right? The original tier null and protocol, and various iterations of that.
00:19:50.890 - 00:20:51.916, Speaker B: What such protocols allow two parties to do is essentially atomically swap one asset for another. I might have token a on network a and you might have token b on network b. We might agree on the terms of an exchange off chain, which includes, say, how much time we want to allow for this exchange to play out and what the exchange rate will be, as an example. And then what we do is essentially kind of have contracts on both chains where we both lock our funds conditional on revealing the secret, some secret, right? And only one party would know what that secret is. And as they reveal that secret on one chain to claim the assets of the counterparty, the corresponding secret can be used by the party to essentially claim their corresponding assets on the other network. These are somewhat well studied protocols. There are obvious limitations to it.
00:20:51.916 - 00:22:13.280, Speaker B: Obviously they are primarily just for asset exchange purposes. They unfairly disadvantage one party, which is known as the free option problem that we won't go into. And the user experience in general in such protocols is not ideal. So to do anything more meaningful, we all of a sudden now have to actually transfer state information from one network to another, where a destination network now has to reason about the validity of state that it's received from another network. And if you think of the most secure construction you can imagine, one such model would be a state validating bridge. In this model, what you have is a destination network, let's say network b, that receives state from network a validates the state transitions corresponding to that state and independently verifies that any state that it receives is valid according to the rules of that protocol. Today, the scenario in which we have such protocols is really in the context of roll ups, right? And you can imagine the ZK roll ups or optimistic roll ups that fall in this category.
00:22:13.280 - 00:23:24.044, Speaker B: And this is the most secure construction you can think of, because each network is independently kind of verifying all it needs about the state and state transition associated with the underlying network. A bit less so is what we can categorize as consensus verifying bridges. And here what each network is doing is not really kind of validating state and state transition, but rather at a high level verifying that consensus has been achieved in any block that it receives. So in this scenario, networks essentially kind of relay blocks amongst each other through the help of potential intermediaries. And each network can independently verify whether the block it received or a block header that it's received has valid consensus according to the consensus rules of the source protocol that it received state from. These introduce a number of challenges, as we'll talk about a bit more. So a variation of consensus verifying bridges that are starting to emerge is what we call Zk bridges for now.
00:23:24.044 - 00:24:40.180, Speaker B: But essentially the idea here is that instead of having each network verifying the consensus of another network, that that is somewhat done by off chain pieces or off chain components in zero knowledge, and then validity proofs are sent to the networks themselves to verify. This reduces some complexities, introduces others, as we'll see in a bit. So as we delve into different architectures here, essentially this slide is trying to capture what we can categorize as trustless mechanisms that weren't used somewhat loosely. And we'll talk in a bit more detail, the last two or the bottom two in this slide. The other extreme you can imagine is of course trusted intermediary protocols. Right? And it's worth starting with the extreme example that might look like where essentially between two networks you have one designated centralized party that is responsible for attesting to state. It's trusted on both sides of the network to basically be the sayer of what's true on information that is being relayed across these two chains.
00:24:40.180 - 00:26:22.660, Speaker B: This is obvious limitations that I don't need to explain to this audience, particularly in the event of recent events with FDX collapse as an example. So one thing to highlight with external validator bridges, as I'm showing them on the left, where you have a single party, this is sort of the model we use with exchanges today, right? So if you think about purchasing one of your assets from one network and purchasing another one and kind of withdrawing, if you will. This is sort of the model we're using today, right? So this is obvious limitations. If we decentralize that a little bit more, what we have is what you see on the right here with external validator set bridges. And the idea is somewhat similar to the previous one, except here we have a set of parties that attest to the validity of some state and the set of parties and the mechanism they use amongst themselves to have some honest majority is what's trusted as the arbiter of truth. Another variation is what we call optimistic bridges, and we'll delve into this in a bit more detail, is an approach that essentially is similar to optimistic roll ups, relies on optimistic mechanisms with fraud windows to essentially kind of resolve any disputes about the validity of state. The difference between, say, external validator bridges and optimistic bridges is that optimistic bridges make an honest minority assumption, as opposed to the honest majority assumption of the validator, said Bridges.
00:26:22.660 - 00:27:23.428, Speaker B: So I'll spend a bit more time going into least four of these patterns that we've seen, because they're interesting points of discussions and sources of risk to discuss and consider. So the first one is consensus verifying bridges that we lightly touched on. Right. And in effect, as we briefly mentioned, the way such protocols work is we have two networks that need to interact and communicate with each other. We essentially have intermediaries that will take block headers from one network, let's call it the source network, and relay it over to another network, which we can call a destination network. And what destination network does is really run a light client protocol of the source network. It does some checks on a block header to see whether some notion of consensus has been achieved in the source network as it relates to that block.
00:27:23.428 - 00:28:24.104, Speaker B: You can imagine this to be, for instance, that it might check that sufficient proof of work has gone into a block, it might check that a sync committee has attested to a block, and so on. Right? Or some validator set, a majority validator set, two thirds validator set, for example, has attested to a block. And what's ideal about this approach is obviously doesn't introduce new trust assumptions and intermediaries. Obviously we'll need components in between that relay blockheaders from one to the other. But really those entities at best can censor transactions and not really affect whether we consider a state or a blockheader as valid or not, because a destination network is independently verifying that. But it's worth acknowledging that, of course, the destination network is not really performing state validation. It's not really checking to see that the transactions in a block are valid.
00:28:24.104 - 00:29:44.712, Speaker B: And as a result of this, it inherits the same limitations lite client protocols of a network might have. And there are different attack scenarios to think about here, like an eclipse attack, where you might have a number of validators that collude to deceive a destination chain about the state of facts as an example. The big challenge about these approaches, of course, is that they're complex to build and costly to maintain and operate. As you can imagine, what we need to kind of do is constantly relay blockheaders across chains and have this complex operation of verifying consensus implemented in smart contracts on both ends. Right? This can be prohibitively expensive, which is a big part of why we don't see these bridges being somewhat widespread as a pattern, or this approach being widespread as a pattern. And it's also worth, of course, noticing that it incurs continuous cost, as opposed to cost that's dependent on the demand associated with cross chain messaging. Another consideration is because of the complexity of implementation of such bridges, it increases the likelihood of implementation risk, which we'll touch on in a bit.
00:29:44.712 - 00:31:25.290, Speaker B: And a good example of that is some of the vulnerabilities that were found on the Rainbow bridge, or things associated with it, that would have directly impacted the rainbow bridge itself. As I noted earlier, a variation of this is ZK bridges, which I think is a promising area of research and still in its nascent stages. And the idea here is that it basically has the same properties that we talked about in consensus verifying bridges, but instead of having the destination, the different chains implementing logic to verify consensus in smart contracts, which can be prohibitively expensive. Instead, what we do is have off chain components that generate validity proofs that consensus has been achieved for some source chain according to its consensus rules, and then send over that proof to a destination chain to independently verify on its own. And this has a number of advantages, but inherits most of the limitations that I mentioned about light client bridges in terms of cost of operation. Even though we expect this to be less over time and optimized to a large degree, there are still significant costs associated with such bridges today, but it's an interesting area of research and potentially could be the foundation of how we build bridges in the future. So the next two patterns are external validator set bridge and optimistic bridge, which I'll talk about.
00:31:25.290 - 00:32:42.876, Speaker B: These two patterns broadly describe a majority of the bridges that we see and crosschain protocols that we see in this space and as we mentioned earlier, with external validator set bridges, essentially we have a set of parties that are trusted to test on the validity of state. The assumption is that we have an honest majority from these set of parties. And the reason why such bridges are such approaches are quite popular is that they're relatively easy to build and reason about and cheap to operate. There are numerous variations in the details of how these types of bridges work, but at a high level you can have either proof of authority bridges or proof of stake bridges. In proof of authority. Really what you're trusting is that the set of parties that are permissioned to operate the bridge as validators essentially have their reputation at stake. And there's a possibility of legal recourse to these parties that would essentially serve as a deterrent from them acting against the protocol or acting maliciously.
00:32:42.876 - 00:34:06.200, Speaker B: There are a number of assumptions here, right, that might not hold true. And thinking through what that might look like in terms of the degree of decentralization, the set of parties, the mechanism they employ, whether this notion of a proof of authority and the reputation being a significant deterrent, are all real questions that we need to ask, especially in light of recent events. The other approach is proof of stake, and this is a bit more easier to reason about. And essentially what it does is essentially bakes into the protocol, sickening the game, right? So each entity in the validator set has some amount of value at stake that gets slashed if they misbehave. There's a number of different dynamics to consider here where, say, as an example, if the value that they're staking is a bridge specific token with small liquidity, not a lot of market demand, and so on, the price could wildly fluctuate. As an example, one bridge token I looked up just yesterday had gone down by about 95% in value, and you can imagine how that would influence the economic assumptions and guarantees of the validator set of such bridges. There are numerous limitations that are of course somewhat apparent about this approach.
00:34:06.200 - 00:35:12.764, Speaker B: You introduced new, significant new trust assumptions and the security implications that has, the degree of decentralization is often difficult to reason about and not very transparent in terms of how protocols communicate about what that validator looks like, validator set looks like. And there are numerous limitations on the mechanisms that these protocols employ. And of course these validator sets can censor transactions. They might have interests that don't necessarily align with users of these protocol. And so this creates opportunities around front running and a number of other things. And there's a bounded known cost for bribing these set of actors there often might be permissioned, they might be known, and there's a bounded cost towards attacking this protocol. A second approach, of course, is optimistic bridges, which we briefly touched on, and the variation here is that we're essentially kind of using an optimistic approach.
00:35:12.764 - 00:36:35.544, Speaker B: With fraud windows. What this means is that there's often one or more trusted attesters that attest to the validity of state and entities that relay any attestations from an updater about state in network a as an example, and send it over to network b. That state is not immediately trusted. Instead, we wait for some period of time, the fraud window, at which point any watcher entity, or any entity that essentially is responsible for keeping this whole protocol honest, can dispute the validity of that state or report fraud. And the security property this affords is that we can essentially rely on the existence of at least one honest party, which is a weaker assumption to make than say that an honest majority will always act honestly. An ideal construction of such protocols, which is typically how most protocol teams communicate, is to assume that the watcher set is permissionless, right? Which basically means that you can have any number of watchers that are observing this protocol that you might, as an attacker might not know about a priori. But there are obvious challenges and limitations to enabling this.
00:36:35.544 - 00:38:01.590, Speaker B: That primarily comes from the fact that it's difficult to prove fraud on a destination chain, unlike roll ups, and there are different reasons for this, and as we go into the case studies, some of this will be apparent. Another challenge is incentivization of watchers. These are entities that are responsible for essentially detecting that a fraud has happened, but they have to incur a bunch a significant amount of work upfront to ensure the integrity of state and to ensure that an attester isn't misbehaving for the off chance that they might at some point get a reward for reporting fraud. Another consideration is that there are different griefing vectors, primarily because we can't reason about whether a fraud report is true or not. And there are numerous edge cases that such protocols need to consider around liveness failures of a destination chain. If we're assuming things happen within a certain time window, like fraud windows for instance, failures in liveness in one network could significantly influence how we think about the space. To finish off this section, I'll go a step higher, a layer higher, and talk about token bridges, because I think doing so is important, as these are a perpetual source of risk to this broader space.
00:38:01.590 - 00:39:26.492, Speaker B: And token bridges, as you recall, are this mechanism through which we enable transfer of value across networks. A typical mechanism that's used to do this is where assets are locked on one chain, and synthetic representations of those assets are minted on a destination chain. What that basically means is that we now have an invariant, right, which is that the total amount of locked assets in a source network has to match any outstanding synthetic assets that exist across different chains that are backed by that source asset. And essentially those synthetic assets are a claim against the bridge, right? So if this invariant breaks over time, either because a hack happens on one end or the other, then this invariant breaks, and these tokens, these synthetic tokens, potentially become worthless. And this is worth considering because any entity could hold those synthetic tokens. You might never have used a bridge, but might own one of these synthetic tokens, which are not actively disclosed. At times they are, say, one bridge's representation of some asset, but rather they're kind of called wrapped eth in this network, and you don't really know that it's backed by a specific bridge, and that you're exposed to the risks of that bridge.
00:39:26.492 - 00:40:09.170, Speaker B: So if you're holding such a token, even though you've never used the bridge and such a hack happens, and this invariant that I mentioned breaks, then essentially you're exposed to having your assets being losing their value. So it's a significant source of risk. An additional consideration, of course, is that the fact that we lock these assets on the source network creates this honeypot that is the primary incentive for attackers to target cross chain protocols in general. Before we go to protocol implementation risk, I'll pause here to take any questions, because I think that was a fair bit.
00:40:13.730 - 00:40:58.330, Speaker A: Yes, it was. And I'm not sure if anyone else is going to ask a question, but I will. So, with those token bridges and the synthetic assets, the honeypot on the source chain of all those locked assets, is there an alternative? Is there a way of getting around this problem? Because I can imagine if you had hTlcs, you wouldn't have the problem, because then you're not linking a synthetic asset or other, you're not storing all that value on the source chain as locked assets. So is there an alternative?
00:40:59.810 - 00:41:53.022, Speaker B: Yeah, that's a good question. I think there are a couple of things to consider there. One is, if you think of assets that have a known issuer, right? You can imagine USDC as an example. So USDC is, as you know, a stable coin backed by USD, issued by Circle, and basically pegged to the US dollar. In such a case, even though today quite a few protocols synthetically mint USDC on networks, you can imagine that over time going away where circle itself natively issues these assets on these different networks. So essentially, you don't need to bridge those assets out from where they're natively issued in order to have synthetic representations of them in destination networks. Right.
00:41:53.022 - 00:42:45.840, Speaker B: So that's one scenario. The second, of course, as you mentioned, is where you might have these liquidity networks and asset exchange that might be able to address a number of these different use cases where you might not need to bridge the asset out. I think that will address a number of use cases, but I think because of some of the difficulty in how you could compose cross chain interactions, you might still want to take ETH from Ethereum, have it as wrapped ETH on Solana, and do a bunch of things that are a lot more complex, that make sense within that ecosystem. That is a bit more difficult to do if you just end up with Eth on one network as an. That's. That's the set of considerations there. Does that make sense?
00:42:47.170 - 00:42:49.342, Speaker A: Yeah, it does. That sounds good.
00:42:49.396 - 00:43:42.260, Speaker B: So thank you. No worries. I have a question. Are there any generic interchange protocols that are being implemented that you know of that are being implemented across different types of chains? So basically coming up with a standard, like a rest API or some type of communication protocol, that's very generic, so that way information can be trusted and sent across networks? Yeah, that's a good question. So I think there's probably two parts to that. One is, you might recall in that layer diagram I showed, like, that bottom layer of the messaging protocol is sort of meant to capture this broad case where you're trying to essentially relay state across networks. Right.
00:43:42.260 - 00:44:55.622, Speaker B: And so protocols that target that layer are trying to do some of that, where they're basically trying to be this general purpose messaging layer that's relaying state. And some of them do it at a much general level where they're essentially kind of relaying just block headers, and from there you can prove complex properties. Others are essentially relaying specific messages that relate to the protocol itself, on top of which a lot can be built. The second part of your question is around standardization, and there are efforts in the EEA that Peter and others were driving around eventually in the space, converging to standards that make interoperability possible. And we're not quite there yet. And I think it's probably because we're still early in this phase where we're kind of probably in this divergent exploration phase before we kind of converge into standards around patterns that make sense and APIs and a layered stack with clear interaction patterns that emerge and make sense. Does that answer your question? Yes, it does.
00:44:55.622 - 00:44:56.520, Speaker B: Thank you.
00:44:56.910 - 00:45:00.202, Speaker C: Excuse me, can I jump in and ask a question?
00:45:00.336 - 00:45:01.020, Speaker B: Sure.
00:45:02.670 - 00:45:30.740, Speaker C: So, would it be possible for you to rank these bridges in terms of security first and cost second, and how do they evolve over time? So you could consider, begin by, like, for example, one bridge could be considered like a cosmos, or the other would be roll ups or something like side chains. And if you could just rank them through examples, it's easier to draw a picture of what is more trustworthy in general.
00:45:32.390 - 00:46:42.090, Speaker B: Yeah, that's an important consideration, I think. And layer two, l two beats team has been doing a fair bit of work trying to surface some of the considerations in how we think about the security and the risk of some of these bridges. We've been doing some work with our partners around better understanding and having a clearer view of the risks of different protocols and eventually getting to a state where we can hopefully kind of rate these different protocols based on security and so on. You'll notice that in my discussions, I kind of left it very high level, right, where I'm talking about the different architecture patterns, but the details there make a world of difference. Right. So you can think of some of the architecture patterns in these two categories I presented were trustless and protocols with trusted intermediaries. And within those, the way I laid them out, at least on the trustless side, was roughly how you can think of which pattern is more secure.
00:46:42.090 - 00:47:02.100, Speaker B: But when you distill this down and kind of go into the individual protocols, the details will make a world of difference. But that's work teams like l, two beats, socket, Levi and a few other of our partners are doing and that we're kind of collaborating with them on.
00:47:02.950 - 00:47:44.480, Speaker C: Yeah, thank you. My question was, like, for example, in case of roll ups, it's the roll up team which basically does one implementation of bridge and which is, okay, there could be one source of truth, but when you take, for example, Polygon, it has like three or four different bridges, and maybe there could be way around, like, maybe they are bridged to binance and maybe they are bridged to cosmos, and there's like a plethora of different bridges, which makes it more complex to gain a normal understanding of what assets goes where and how it's cloned and cloned. Yeah, that's a bit more.
00:47:46.130 - 00:48:31.120, Speaker B: Yeah, I agree. I think kind of trying to more better reason about these different bridges that all service the same network, I think is important. It's a bit difficult in Polygon's case, as opposed to, say, with a roll up native bridge. Right, where you can clearly reason about the roll up bridge itself as native bridge being a lot more secure. It's slightly different in the case of Polygon, but keep in mind, that really just speaks to the architecture risk that we just covered. But then there's implementation risk and operational risk, which we'll get to in a second.
00:48:31.570 - 00:48:32.878, Speaker C: Cool, thanks.
00:48:33.044 - 00:49:07.258, Speaker B: No worries. So protocol implementation risk. So here essentially is somewhat straightforward. The risk here is that crossing protocols are complex infrastructure, right. We have numerous components, different moving parts, some of these components operated and managed by different entities. The components are not just on chain and off chain, but target different environments and use different tools and frameworks. Right.
00:49:07.258 - 00:50:11.760, Speaker B: So the likelihood of bugs occurring as a result of basically implementation risk is somewhat significant. And you could have protocols. I think it's worth underscoring that you can have protocols that have sound, robust architectures and security properties, but still have significant implementation risk. And this goes to the question we just discussed a second ago. And implementation risk, of course, is exacerbated in environments where you have nascent tools and runtimes, new networks and protocols that might not be as tried and tested, or that people might not be as familiar with as, say, the EVM as an example. There are some mitigations here, and this list is far from complete. And there's work we're doing to really expand and be comprehensive on this in a risk framework that we are building with a few of our partners that I'll talk about at the end of this talk.
00:50:11.760 - 00:51:06.640, Speaker B: But some of the things you can consider here are formal verification of key contract of contracts as an example. Right? And our trusted smart contracts team might have a thing or two to add to that. There are other practices, of course, like high coverage and testing, whether that's unit and fuzzing and property based testing, integration tests. And we'll see examples in our case study of one protocol that probably could have done a bit more of this, where the bug could have been caught if they say, for example, had tested against production data, had the same tests, but tested against production data. Frequent audits help, but it's worth knowing that audit drifts happen where what's deployed versus what's audited might not exactly match. There might be a delta that can be a source of significant risk. And of course, audits don't capture everything.
00:51:06.640 - 00:52:05.182, Speaker B: The caliber and experience of a development team matters. Unfortunately, the examples I'm going to use to make some of the case around implementation risk is where the team is really well known, really great, and more than capable by all accounts. But obviously, considering the Calburn experience of a team is a key point. And bug bounties certainly help in enabling honest actors to report such vulnerabilities before they're discovered by malicious actors. Examples of these, over the past twelve months or so to call out are of course these four ones, and there are many. What I'm calling out here is anything above 100 million. And the polynetwork hirack, for instance, Peter has done a talk on this in the same forum that you can refer to.
00:52:05.182 - 00:53:32.734, Speaker B: The wormhole hack and BNB bridge are examples in which attacker was able to spoof the validator signature. So basically both these bridges are external validator set bridges, and the vulnerabilities that were discovered in the bridge essentially enabled an attacker to spoof validator signatures. The Nomad bridge is a logic bug that essentially enabled an attacker to validate arbitrary messages by bypassing the validation process altogether and was able to steal funds. Now, these are things we know about, but I wanted to call out the things you might not have heard of, and these are vulnerabilities that were disclosed through bug bounties. And I'm specifically kind of selecting these three examples because if we just looked at the architecture using the lens we spoke about a few minutes ago, these three bridges would really rank as more secure and trustless, right? So arbitram, as you all know, is an optimistic roll up. The bridge it employs, its native bridge is a state validating bridge. But recently a vulnerability was discovered that would have enabled an attacker to essentially hijack the bridge contract itself.
00:53:32.734 - 00:55:07.020, Speaker B: What that would have enabled an attacker to do is basically take any incoming deposits into the arbitrary bridge and stealing those funds. A gauge of how much could have been lost in such a scenario is one way to look at that is the average deposits per day, which is around 5000 e, or to look at the largest recurring deposit observed on this bridge, which is around $250,000,000 or 168,000 e. The white hat that reported this got a very decent bounty, but this could have played out very differently, and it's worth considering, right? Even though the bridge is secure by design at least just looking at the architecture, implementation risk is an important consideration. Rainbow Bridge is a consensus validating bridge, and earlier we mentioned how such bridges are trustless and secure and so on. But three different vulnerabilities were discovered over this year, and at least one of them could have resulted in a $240,000,000 hack on this bridge, and lastly on Cosmos IBC, a critical vulnerability was discovered that could have impacted all Cosmos IBC chains. And the impact of that, I think is somewhat self evident. The takeaway from this is that protocol implementation risk is perhaps the most significant source of risk that we're observing to date.
00:55:07.020 - 00:56:25.682, Speaker B: Quite a lot of this is evidenced from the hacks that we're seeing, but fortunately, there are a number of different vulnerabilities that are also being reported by white hats that are mitigating some of the impacts this could cause in the broader space protocol operational risk. So this is somewhat self explanatory. As I mentioned earlier, crosschain protocols have numerous components, off chain pieces and on chain pieces operated by different actors, admins that have special privileges. To change parameters of these bridges, and a number of other considerations, and the practices and processes and mechanisms that are employed to ensure that all of these pieces operate as expected and are secure is a critical consideration in the operational risk. Right. So how keys are managed, how external validators are kept secure, as an example, and we'll see examples in our case study of failures in this type of risk. So the existence of such privileged parties like bridge admins and external validators consistently poses risks.
00:56:25.682 - 00:57:50.842, Speaker B: Upgradability of contracts is another consideration, as it can introduce how that's done and what it introduces can create new sources of risk that need to be carefully thought of. Some of the mitigations are to have robust, decentralized and transparent mechanisms and processes for ensuring that such bridge operations are carried out in a secure way, that there's clarity in how they're done and how they're managed. Monitoring capabilities to ensure that things that we don't expect, like the invariant I talked to you about in token bridges, right, the total supply locked on one end should match all outstanding on another end. These types of monitoring capabilities become critical to ensure operational safety, but at a minimum, monitoring to ensure anomalous activities, like very obvious anomalous activities, are important. An example of where that failed, that we'll look at in a bit more detail, is the ronan hack, where the hack itself, where the token bridge was drained of funds, was not detected for six days. The only time it was detected was when a user asked for their funds and the bridge wasn't working. Having established practices and playbooks on how to do incident management and response is critical.
00:57:50.842 - 00:58:51.284, Speaker B: And we'll see an example of where that could have been done better and standard security, best practices that we employ everywhere else, I think, and ensuring that that is maintained in off chain systems and key management practices and so on. Are critical pieces in ensuring operational safety. So what I want to do next is look at case studies where we look at three bridges. But before I do, I'll pause for any questions. At what point does programming language or the type of implementation done by the team play into the security vulnerabilities that have been found across some of these hacks? Yeah, good question. So that was in the protocol implementation risk section that I discussed. Right.
00:58:51.284 - 00:59:27.250, Speaker B: So, implementation risk, the way to think about it is really as code risk. I mean, it's a simplified way of thinking about it, and things that relate to smart contract bugs, issues in dependencies that different components have, and maybe vulnerabilities in those dependencies and not necessarily in the code relating to the protocol itself. All of those considerations fall in this category of protocol implementation risk. Does that answer your question?
00:59:29.060 - 00:59:29.808, Speaker C: It does.
00:59:29.894 - 01:00:52.270, Speaker B: And do you see that being the biggest factor in terms of, or how does it weigh in terms of other types of vulnerabilities? At the moment, yeah, at the moment, it's the biggest source of risk. So the two big sources of risk in cross stream protocols today are implementation and operational risk. And most of the failures that we've observed over the last year or two are really kind of attributable, mostly in part to implementation and operational risk. And a few slides ago, when I was going through the four different hacks, like polynetwork, BNB, wormhole, Nomad, and then also talking about the vulnerabilities that were discovered in arbitrum, rainbow and others, those were all examples of implementation risk in these case studies that we're going to go through next. I'll try and make that a bit more concrete, where through talking through specific hacks or attempted hacks, we can kind of get a better sense of how that framework kind of somewhat translates into these concrete cases. Thank you. No worries.
01:00:53.280 - 01:01:32.170, Speaker A: So one of the issues you noted was that, I think it was the ronan one, they didn't even notice for a week because they weren't monitoring their systems or monitoring them in important ways. I'm sure they had some monitoring, but they weren't monitoring the bridge to make sure that the value on each side matched. Do you think that's a common problem, that there's not enough active monitoring of bridges to make sure things aren't happening and thus being able to stop them halfway through if something.
01:01:34.620 - 01:02:34.476, Speaker B: Yeah, that's a good question. My hope would be that these hacks we've seen over the last year or so have been a learning experience for different teams. Right. And whatever monitoring practices teams might have had a couple of years ago is probably very different today. Hopefully, by learning from the failures of others, we can see evidence that teams are monitoring based on, say, as an example, the rainbow bridge attempted hack, where the team was quickly across the attacker trying to do something, and they didn't have to do anything to prevent it, but they're actively communicating what the attacker tried to do, how it failed, and so on. And so they had monitoring capabilities. Beyond that, it's hard to say whether all teams are doing it consistently because this is their operational practices that might not be actively disclosed and so on.
01:02:34.476 - 01:02:52.850, Speaker B: Even though now we've started to see teams more vocally speaking about the kind of monitoring they do and early detection systems that they might have in place to kind of detect potential anomalous behavior, I imagine this will mature over time. Yeah. Does that answer your question?
01:02:54.740 - 01:02:55.708, Speaker A: Yes, it does.
01:02:55.814 - 01:02:56.710, Speaker B: Thank you.
01:02:59.000 - 01:03:17.850, Speaker C: There's a very cool product which is called forta F-O-R-T-A which kind of spans across the entire blockchain activity, and kind of flags different kind of risks in general. So I think it's a good one to look at.
01:03:18.860 - 01:03:25.180, Speaker B: What's it called, forte, did you say? And what kinds of risks does it flag in general, out of curiosity?
01:03:26.720 - 01:04:02.730, Speaker C: Okay, I'll just read it out for you. So I think they pretty much flag the risks in different colors. So maybe yellow is like a medium, red is a high risk environment, and maybe they enable smart contract risk, any developer kind of risks. So maybe implementation risk could be one of them. This is one I came across a year ago, and it was a pretty good product, good to look at, I think. Now I'm opening the site, and they have flagged a couple of hacks, in retrospect, which occurred after.
01:04:03.260 - 01:05:18.160, Speaker B: Right, right. Yeah, that's definitely something worth looking at. I guess Peter's question was more about active transactions happening across both networks and detecting anomalous behavior in real time. I think if this tool somewhat helps teams do some of that, I think would be quite valuable. Another challenge, I think, specifically with something like multichain, for instance, where if what you want to do is observe this invariant around token bridges that we spoke about earlier, where the total amount locked matches all outstanding synthetic assets across networks, how a team manages where those locked funds are stored versus how they might be distributed, and so on, makes some of that monitoring a bit more difficult. There was a recent thread between the L two beads team and multichain, trying to discuss tracing multichain funds, for instance. So having transparency and how some of that works might make monitoring possible, not just for the teams themselves, but external entities that have a stake in the proper operation of bridge.
01:05:18.160 - 01:06:30.568, Speaker B: So in the interest of time, I'll move on to our case studies and there's a fair bit to cover here, so I think I might move quite fast. Basically, in case studies, I want to look at three incidents. The first one of the Rainbow bridge is really an example in which the architecture and the design of a protocol served its intended purpose in detecting an attempted hack. Right? So this is a good example of where the design of a protocol is demonstrated to function really well. The Ronin bridge hack is an example in which the architectural assumptions and the security assumptions of a protocol fail, but also other operational failures that occurred that resulted in this hack. And the team has learned a fair bit from that incident in their road to recovery. And lastly, the Nomad protocol, which we'll delve into in a bit more detail, is primarily an implementation risk, but it has an element of an operational risk as well.
01:06:30.568 - 01:07:07.604, Speaker B: And I'll delve into some code and give you a better sense of that in a bit more detail. So the Rainbow bridge basically had two hack attempts this year, one in May and another one in August. To understand this, I think it's worth talking about the Rainbow bridge itself and what it is. The Rainbow bridge is a bridge between Ethereum and Mir and the Aurora networks. It launched last year. It has significant value that transacts across that bridge. With over 2.8
01:07:07.604 - 01:08:00.256, Speaker B: billion since its launch. That number is probably a lot higher now. This number is a couple of months old, and most of the activity kind of involves the token bridge, a token bridge where assets are locked on the Ethereum side and minted on near an aura. And the bridge itself, by design, kind of employs a combination of a consensus verification bridge and an optimistic mechanism, and I'll talk a little bit about how that works. The Ethereum to near side performs a consensus verification bridge, whereas the near to Ethereum side is an optimistic mechanism. Here's an illustration of what that looks like. So on this site we have the Ethereum blockchain, and here the near blockchain.
01:08:00.256 - 01:09:24.440, Speaker B: And the way this protocol essentially works is for blocks that come from Ethereum to near. There's an Ethereum light client on near that basically kind of ensures that verifies anthash, ensures there's sufficient proof of work, and does a contentious verification, if you will, or a lite client header verification of any block that comes from Ethereum over to near. So the team has implemented that litecoin capability as a contract on near. The reverse side, however, would prove to be very expensive to do so. Near validator signatures, our ED 25519 signatures, implementing the verification of all those signatures on block headers that come from near would prove very difficult. So instead, what the team does, or what this protocol does, is it has an optimistic verification mechanism where blockheaders are relayed from near over to Ethereum, and over a 16 hours window, fraud can be reported, right? So it's a slower path. And if fraud is reported, anyone can essentially dispute a very specific signature, saying this signature is not valid or not from a validator that is known.
01:09:24.440 - 01:10:33.184, Speaker B: And the protocol itself can, the contract itself can verify that signature. So it's a cost saving measure that still kind of does consensus verification, but in an optimistic way. And so the hack that was attempted on both occasions looked something like this, where in this protocol, these actors that are in between, that are shuttling blocks back and forth are called relayers. And anybody can stake some amount of money to become a relayer. It's not a permissioned activity or not a permissioned role. And anyone can essentially serve as a watchdog where they notice any fraud that might be happening and can essentially contest a particular block during that fraud window. And what attackers tried to do in both occasions was to first become a relayer by depositing some amount of money, in this case, five e constructing an invalid near block and then sending it over to Ethereum.
01:10:33.184 - 01:12:10.980, Speaker B: And in both cases, watchdogs immediately, or these watchers immediately kind of detected that this block was fraudulent and contested it right away, and within four minutes, even though the allowed fraud window is 16 hours. What is interesting is that in both cases, the watchers which you'd expect to be rewarded for this were front run by MeV bots, right? That basically detected that a watcher was reporting some fraud and would get compensated as a result. So MEV bots basically kind of constructed their own transactions that front run the watchers. The end result is that an MEV bot is compensated, but the watcher that did all the work of ensuring all the verification needed to do to ensure that state is valid and detecting the fraud did not get any compensation. The learnings from this beyond, of course, this is an example in which the design of a protocol worked well, is the MeV situation and the incentivization of watchdogs. The team argues that the front running is not an issue, because in a scenario in which you have fraud happening on a network, you want to incentivize the market to report this as fast as possible. And if MeV bots are the way to do that, then that should be something that is utilized, as opposed to something that's considered a defect in the protocol.
01:12:10.980 - 01:13:33.724, Speaker B: The issue I think that will probably surface over time is how you incentivize watchers, which are entities that need to do a whole lot of work up front and potentially never get compensated for it. There are a number of mitigation things that could be considered, but these are active and things to consider for optimistic protocols in general. The second one is around Roninbridge, so this is one of the biggest hacks that has happened in the defi space, so it's worth discussing. And it's a failure both in the security assumptions of a protocol, but also the operational scenarios at a high level. The Ronin bridge is really a bridge between Ethereum and Ronin, which is a side chain for the Axie Infinity game, which is a play to earn game. The bridge basically kind of custodies or locks Ethan USDC on Ethereum and mints it on Ronin. The bridge generally is an external validator bridge, with nine validators, and five of which are required to attest to any block before it's relayed between Ethereum and Ronin and the company behind Axio Infinity.
01:13:33.724 - 01:15:33.440, Speaker B: Skymavis apparently owned four of the nine validators, and had a special arrangement with a fifth validator that basically allowed it to sign transactions on the behalf of another validator. So, needless to say, this becomes a scenario in which the assumption that you have nine independent validators, five of which agreeing to something is sufficient to secure the bridge, doesn't really hold, because you have, in effect, one party owning five of nine signatures. So the way this played out is that an attacker did a spear phishing attack on an employee to gain access to their IT systems, to Sky Mavis's IT systems, and directly compromised into control of four of the validators of the Sky Mavis validators, and used a special arrangement that Skymavis had with Axidao to essentially kind of have a backdoor onto this fifth validator. And once they were able to do that, they had the relevant set of signatures, the threshold, and the majority to basically sign any messages that enabled them to essentially steal 624,000,000 on 23 March, which was a significant, significant event. What's interesting is, as we noted earlier, the hack was not detected for about a week, and that highlights some interesting properties. I'll do a quick aside before we kind of go back into the details of the hack itself to talk about some of the work that went into laundering these funds by the attacker. First thing is the attackers basically tried to take these funds through exchanges, presumably through fraudulent KYC on these exchanges.
01:15:33.440 - 01:17:02.370, Speaker B: Exchanges obviously kind of moved to blocking those funds, and the attackers then moved on to kind of using tornado cash to launder the OFAC. You know, the Office of Foreign Asset Controls basically started to sanction these specific addresses associated with this hack. The reason is because the entity behind this hack was apparently the Lazarus group, which is a nation state funded group from the North Koreans that's funded by the north korean state. So here a game of whack a mole started to emerge where OFAC would sanction specific addresses, but the hackers would essentially kind of move funds to different addresses and then to tornado cash after a few attempts of this. Basically what OFAC did was to sanction tornado cash altogether because sanctioning independent addresses wasn't particularly working. So what's interesting about this is it provides a bit of context to how this tornado cash sanctions played out. This wasn't the only instance, but the fact that you could have an organized, sophisticated nation state actor mounting attack on such protocols, and then the regulatory action that kind of follows offers a bit more context on how to think about the seriousness of security and such protocols and their impact into the broader space.
01:17:02.370 - 01:18:35.888, Speaker B: In the interest of time, I'll kind of skip through most of this, but basically the learnings for the team was to obviously have a lot more processes and practices in how they secure their validators, increasing decentralization, hopefully by independent entities and how that's managed, they went through rigorous audits which uncovered other vulnerabilities. And that's worth noting as well that there were other things that probably weren't that could have been sources of risk and subsequent hacks in the space. So the lessons from our perspective, from an architecture perspective, if we're going to have external validator sets and talk about the set of validators and how large it is and how difficult it might be to compromise some quorum of validators, really understanding the true level of decentralization and having transparency around that, I think, becomes critical. Employing good and clear, robust operational security practices and how off chain components are secured, I think is critical, and, of course, monitoring. Right. So as we've touched on a fair bit, I'll move on to the Nomad bridge hack, but this is going to be a bit more of a deeper dive into the details of the implementation of Nomad at some point. So I want to pause to see if there are any questions.
01:18:35.888 - 01:18:46.706, Speaker B: And I know we've been going on for some time, so I'll try and move fast. Okay?
01:18:46.888 - 01:18:49.262, Speaker A: I think it's all good, ermius.
01:18:49.326 - 01:19:54.522, Speaker B: Keep it up. Okay, so the Nomad bridge hack is an example, I think, of an implementation risk and an operational risk. So what is Nomad? Nomad is an optimistic protocol for arbitrary messaging across a number of chains. It had bi directional communication between Ethereum, Moonbeam, Avmos, avalanche, gnosis chain, and Nikomedia. The project differentiated itself through being primarily security focused, right and on the right. What you see is the fact that the team highlighted that a fair bit, including quotes that basically say that we're secure. The reason I'm mentioning this is not to kind of highlight a failure in this, but that if we're just looking at architecture, the optimistic approach that Nomad had, I think these statements might make a fair bit of sense.
01:19:54.522 - 01:21:38.950, Speaker B: But when we consider the other categories of risk, we discussed implementation and operational risk that's somewhat pervasive across all networks. And getting a degree of confidence about such infrastructure in the presence of these multifaceted risks, I think becomes challenging and worth appreciating. So the bridge launched earlier this year, and to understand what exactly the Nomad is specifically relating it to the layered stack that we talked about earlier, it's really this base layer with an optimistic mechanism, but it also has a token bridge on top of that that enables the transfer of assets from one network to any of those other connected networks we mentioned a couple of slides ago. At its peak, the bridge had about $200 million locked in on the Ethereum side. And on 1 August, this severe decline that you basically see is funds from the token bridge being drained. So to understand and appreciate the subtlety of the bug that caused this issue, I think it's worth looking at the high level architecture of Nomad first, and then kind of delving into the code. At a high level, the architecture kind of consists of off chain components, and on chain components, we have this notion of an updater, which will sound familiar, which is the entity that's responsible for attesting to messages and the validity of messages.
01:21:38.950 - 01:22:36.330, Speaker B: We have relayers that are responsible for shuttling messages from one chain to another, and watchers that are the entities that are responsible for reporting fraud. And on the right side, we have this notion of a home replica on any origin chain, where messages originate from a replica, which is a contract on a destination chain that is responsible for essentially managing incoming messages. And of course, this token bridge, which has that lock mint semantics that we spoke about, a quick view of what that might look like. Right. So from an architecture perspective, here I have an origin chain. Here I have a destination chain. Basically, that home contract I spoke about, which exists on an origin chain that is sending messages and a replica, that is a contract on the destination chain.
01:22:36.330 - 01:23:42.242, Speaker B: And those off chain actors that we spoke about. When a user tries to deposit funds to a token bridge, essentially what happens is some dispatch message is sent to this home contract, which essentially builds and maintains a Merkel tree of messages that are outgoing from this chain. The Merkel route is updated every time new messages come into this home contract that are destined for a destination chain. And after a period of time, this entity, which is an updater, which listens to events of the Merkel route being updated, signs one of these Merkel routes and attests to it. From there, a relayer basically takes the tested Merkel route, sends it over to a replica, which essentially kind of maintains this new route, and starts a timer, if you will. Watchers can report fraud at this point to basically say this new route that was received doesn't sound right. Maybe the updater is trying to equivocate or something is wrong.
01:23:42.242 - 01:24:44.130, Speaker B: Right. And so they can essentially report fraud. Once that window expires, a user that wants to essentially get a corresponding asset minted calls the replica contract, proving that they deposited on the source chain by using whatever the new Merkel route is, that is now considered valid. And from there, essentially, new assets are minted and sent over to the user. Needless to say, I'm showing a simplified example of two networks. But as you can imagine, information from one home contract goes into multiple different chains, some of which we've mentioned, we've listed out earlier. So what are the interesting pieces of code? Well, on the home side, you have this idea of a dispatch, right, when messages are sent, and this snippet is just for information purposes, to give you to kind of ground the mental image we spoke about earlier.
01:24:44.130 - 01:25:41.270, Speaker B: But on the dispatch function, essentially what we have is a message is added to the Merkel route and added to the queue and eventually attested to by an updater and sent over. On the destination side is where the interesting pieces start to come in. And here, essentially, we have an update function, which is what a relayer will call when they're communicating this new route over to this replica. They're basically saying an updater has attested to this new route and sending it over to the replica to now kind of start the timer, if you will, for that new route. And once that elapses, anyone can call this function which is proven process. And as the name implies, it tries to do two things. One is it proves any message you give it against the latest route that it has.
01:25:41.270 - 01:26:28.200, Speaker B: And second, it does whatever action is associated with that message. If the action is to mint a new token, because this needs to be sent to a token bridge which knows to process that message and mint a corresponding that essentially happens through this proven process. And this is the interesting piece of code we'll delve into in a bit more. So here you'll see proven process, which calls a number of different things. One is the prove, as we said, it kind of has two pieces, the proven process. There's the prove function and the process function. And both of these somewhat rely on this acceptable route, which basically tries to see is this a valid route or not? Right.
01:26:28.200 - 01:27:35.934, Speaker B: So let's look at that in a bit more detail. What the proof does basically is to see if this proof is valid, associate this message with the associated route. On the process side, what we do is check to see that the given message is valid against a route, and of course process the associated message an acceptable route. Here is something that basically checks to see that the route that we have is now considered past its fraud window, and it's a valid route that we know about. So in terms of the sequence of flow that you can imagine just using those same functions we've been talking about, you can imagine an update here where a new route is submitted, let's say r two, and a new fraud window is started after a period of time. Someone could call prove on some new message using that route through this prove function. And then lastly can call process.
01:27:35.934 - 01:28:19.926, Speaker B: Right? So this basically breaks up that proven process into two separate functions. This is just for clarity, but for our purposes, doesn't matter as much. So the process function basically tries to do this acceptable route, which both of these functions depend on. Right. And this is responsible for determining whether the route that we're validating against is valid or not. Before we go into the specific hack, it's worth looking at scripts that are associated with this implementation. And here we have a deployment script that essentially deploys these different contracts, the home contract and the replica contract.
01:28:19.926 - 01:29:44.630, Speaker B: And this script makes sense. Basically what it's trying to do is it says when you deploy the replica contract and the home replica, it might not make as much sense to have the replica prove routes that have been proven in the past before. And so instead what it does is it takes whatever exists in the home root contract and says, okay, let's bootstrap the replica contract with this route as a valid route, as a starting point, which makes sense, it reduces the overheads associated with the replica contract and bootstrapping it every time we upgrade. The problem starts here, where in the first instance, where you're deploying the home and replica contract, the root of the home contract, the Merkel root of the home contract, is essentially empty. And what that means is, as we're initializing the replica, this confirmat, and the committed route that we're using is essentially zero, because the committed route is whatever route exists we assume exists in the home contract. But given it's a fresh deployment of the home contract, this committed route is essentially zero. So we now have a state in which this replica contract has been bootstrapped with confirmat zero being a valid route.
01:29:44.630 - 01:31:26.630, Speaker B: What are the impacts of this? Well, looking at the replica contract again, the process an acceptable route. Essentially what happens is when we call process to process some message, and in this case, let's assume it's an invalid message, we have this check here. That's our sanity check, right? Is this an acceptable route? Basically what that does is calls acceptable route with messages, trying to essentially retrieve whether this message has an associated route with it, because we've proven it in the past. And what happens is, when we're trying to retrieve a map with an invalid message that we haven't seen before, basically solidity will kind of take the default null value, and now we're going to do an acceptable zero. Logically, you'd expect this wouldn't be a valid route, but for the reason that we noted earlier, where zero has now been included as a valid route that has already been confirmed and can be processed, we end up in a scenario in which any invalid message can essentially be processed. It's not hard to imagine how this could be exploited. An attacker basically constructed arbitrary messages that basically said that it's burnt a corresponding set of assets on a destination chain, essentially the synthetic assets, and so was entitled to claiming the locked assets on a source network, and through that process basically stole funds on Ethereum, which are where the assets were locked.
01:31:26.630 - 01:32:25.130, Speaker B: Very briefly, how this played out. The code was audited by Quantstamp and there were a few findings. The team tried to address the findings associated with that audit report and in doing so, made a few extensive changes that weren't re reviewed or re audited by Constamp. So as far as constamp is concerned, it wasn't really in scope. These changes that were done to address the findings. And from Nomad's perspective, these post remediation changes were part of what they expected would be audited. Nevertheless, the changes were a bit more notable and extensive, and so kind of introduced the scenario in which this logic bug somewhat came into existence as a result of addressing the audit findings.
01:32:25.130 - 01:33:55.890, Speaker B: Why didn't tests cache these? Well, there are obviously a number of tests in the code, but the issue was that none of them kind of test against what a replica contract has been initialized with. Right? It doesn't test against a fork of the main net data or fork of production data, which means that the unit tests and integration tests that existed basically couldn't catch this. I'll skip details about how the hack unfolded. It's just this aspect of it I think is quite interesting in the sense that unlike other hacks, we didn't just have the attackers kind of taking the funds, but a whole slew of actors, over 100 entities, parties that basically exploited this vulnerability just because of how easy it was to copy the existing transactions that exploited it with a few modifications and kind of do the same thing. The outside of that was that a few white hat hackers did participate in order to kind of recover the funds. So the learnings, I think in terms of incident response, I think there wasn't a pause function associated with the process function, and this was called out in the audits, and that could have been done better, and the incident response overall could have been much better. Which leads us to the lessons and takeaways.
01:33:55.890 - 01:34:35.010, Speaker B: Integration, testing and testing overall, and coverage is critical. Monitoring, again, as we said, is a key point. Having clearly defined incident response plan and the ability to pause a bridge, I think is really important. And audits, this is somewhat obvious to say, but audits are limited in scope. They don't necessarily find everything, they don't necessarily evaluate all aspects of this complex infrastructure. And so a lot can be missed and they're a snapshot in time. Right? So these drifts in audits, which we touched on earlier, can be a source of unassessed risk.
01:34:35.010 - 01:35:43.580, Speaker B: So I will conclude with a few remarks, basically that having secure, decentralized and robust crosschain protocols are critical for enabling this multichain future. We spoke of and designing and building and operating such protocols is difficult. And there are numerous risks that are multifaceted. There are limits to what these protocols can guarantee. And this relates to the network risk that we spoke about. And even though today what we're observing is a lot of implementation and operational risks and failures that stem from that, over time some of that will mature and the architecture of network risks will probably start to become a lot more prominent concerns we need to think about and this is an exciting space to build and research and if you're interested, I'd encourage you to look into it a bit more. Acknowledgements to Peter, for all his feedback and insight, and to the range of teams that are doing amazing work and research and analysis in this space.
01:35:43.580 - 01:35:46.380, Speaker B: Any questions?
01:35:55.300 - 01:36:07.130, Speaker A: I think congratulations, as we have some claps and I think that that's certainly in order. And, I don't know, maybe we're all questioned out because we've all already answered hot questions.
01:36:08.620 - 01:36:15.896, Speaker B: No worries. I know this took a fair bit of time, so thank you all for attending. I appreciate it. Yeah.
01:36:15.998 - 01:36:32.048, Speaker A: And what I suggest is if people think of questions later or if people who are watching this on YouTube have questions, just post them into the chat or the comments, rather, on the video. I think that's the way to go. All right. It.
01:36:32.214 - 01:36:32.544, Speaker B: Yeah.
01:36:32.582 - 01:36:39.408, Speaker A: So thank you very much, Ermius, and see you all next week for next week's talk.
01:36:39.494 - 01:36:40.864, Speaker B: Bye bye. Sounds good.
01:36:40.902 - 01:36:41.580, Speaker A: Thank you. Bye.

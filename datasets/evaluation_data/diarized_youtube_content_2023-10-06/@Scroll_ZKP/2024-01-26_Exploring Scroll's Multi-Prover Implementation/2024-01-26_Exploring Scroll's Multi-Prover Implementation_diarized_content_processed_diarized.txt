00:00:01.290 - 00:00:25.414, Speaker A: Hello, everybody. Welcome to this Twitter space today with our colleagues from the scroll engineering team and also colleagues from the Automata team, Justin Drake. Welcome in, everybody. Please sit in. We are going to start shortly. Alrighty, so we're ready. We're it up.
00:00:25.414 - 00:00:44.940, Speaker A: I think we have all our speakers online. Thank you, everybody for joining to kickstart this amazing Twitter space. I'm going to intro my fellow colleague Mohammed from our research team at scroll to lead the way in this Twitter space. Please, Mohammed, take it away.
00:00:46.830 - 00:01:29.446, Speaker B: Thanks, Juan. Hello, everyone. Thanks for joining. Today we're going to talk about our recent announcement about using multi proverb for scroll. As one already said, we have many people of our team, Drew, Sandy, Hai Chin, me, and also very special guests from Israel Foundation, Justin Drake and from our dear collaborators, Automata Deli and choir. So we have a lot to unpack today. Without further ado, I start introducing scroll and automata very quickly for you guys.
00:01:29.446 - 00:02:15.000, Speaker B: So scroll is an EVM compatible ZK roll up. I guess that's for us. Automata is privacy focused multiproduct service company. They have a range of different products that are focused on basically integrating privacy enhancing technologies and cryptography into multiple levels of web3. Yeah, I guess you guys can hear more from Delhi and Chua and I encourage them to unmute themselves.
00:02:18.250 - 00:02:19.442, Speaker C: Thanks, Mohammed.
00:02:19.586 - 00:02:20.262, Speaker D: Hi, everyone.
00:02:20.316 - 00:03:04.486, Speaker C: This is Delhi. I'm the co founder of Automata. So we are actually building a modular attachment layer that will be extended to extend machine level trust to Ethereum and other ecosystems. So essentially we're introducing a new concept, proof of machine hood, where billions of devices and machines can be fully attested on l one, l two. Actually, the collaboration with scroll is part of this because we are using trusted hardware to achieve some of the additional functionalities. In this case, it's actually another prover to make sure that the existing proving system is sunt. So yeah, thanks for having us.
00:03:04.486 - 00:03:07.240, Speaker C: Glad to work with you guys. Actually.
00:03:08.430 - 00:03:40.740, Speaker B: Perfect. Thank you. So today's agenda is mostly around unpacking what is multiprover roll up design, why it's interesting or necessary, and later on, talk about a little bit about the detail of implementation. What are the complexities around implementing SGX program and so on. So let's start with the basic, and this is a question for Haichan. What is a multi roll up and what's the motivation to building such thing?
00:03:42.710 - 00:03:51.334, Speaker D: I think Hai chan got disconnected for some. Hai chan, can you hear?
00:03:51.452 - 00:03:55.960, Speaker E: Yeah, I can hear now, but sorry, I lost the question.
00:04:00.010 - 00:04:02.502, Speaker D: Oh, sorry. Yeah, mo, go for it.
00:04:02.556 - 00:04:12.300, Speaker B: Thanks. So, yeah, I want to start the discussion with you defining for us, what's a multi prover roll up and why we want to build such a thing.
00:04:12.830 - 00:05:12.026, Speaker E: Yeah, so I think before we jump into the multi prover rob, we probably first talk about the current rops, which are all single proverb. So what does like a single proverb means it only rely on one mechanism to validate all of the transaction happens on a L2 sample. There are two main categories. Now, one is the optimist rob, and the second, the ZK row up. So the optimistic Rob relies on using the fraud proof, so that if anything like wrong happens after the sequencer upload a batch of transaction data, and then the state transition. But something like, people disagree with the state transition, they can use the fraud proof to challenge what sequencer send up to the ECM, so that it can challenge the state transition. Because they think like after applying the same set of transaction, they end up with a different state route.
00:05:12.026 - 00:06:25.830, Speaker E: And then another way is the Zkrop that relies on the zero notch proof protocols to actively generate proof that going to validate all of the state transitions happens on the L2s. Now, both of the single proof rob, they just rely on single mechanisms. So one example on the ZK Rob. So one concern is that the ZK rob, especially for the ZKE EVN, it's a very complex software, that it could be like the state, could be not bug free for a very long time. And then, so previously Vitalik point out like that, it could be a concern that if it's a bug, and then seems like it's a very centralized way, like the people are relying on the ZKevm to validate all of the L2 transactions. It could be like a concern, like people can exploit the box inside the ZKevm to assert any invalid transactions, or invalid state transactions to the L2 user funds. So the multi prover motivation is mainly like that.
00:06:25.830 - 00:07:09.960, Speaker E: If we can add an additional prover or proof alongside of the existing proofs, so that we can now, if both of the proofs, or more than like one proofs agree on the same set of the state transaction, after applying the same set of the transactions, then it will give a stronger guarantee and the most security guarantee to the L2 user that these transactions and the state transition is valid after applying the same set of the transactions. So more like, to be more precise, like that multi prover roll up is that you're relying on more than one mechanism or more than one proof systems to validate the state transaction happens under the, it.
00:07:12.740 - 00:07:35.610, Speaker B: Perfect. That brings a natural follow up question. What happens when these multiple proof systems that we have in place disagree, and whether that imposes a new risk or trade off on our system or. Yeah, I want to ask Justin to go ahead and pitch in about.
00:07:39.020 - 00:09:12.120, Speaker F: I mean, I guess it depends on how it's configured, right? Because it's a bit like a multi sig, a k of n multisig. You have the n different verifiers and then you require k of them in order to move forward. So one possible configuration, for example, if you have two verifiers, would be a two of two. And so in some sense you're gaining on safety because there needs to be a bug in both of the verifiers to cause an invalid state transition on the l two, but you're losing on liveness because the two verifiers could disagree. I guess one of the nice things about having SGX as one of the verifiers is that it's fairly unlikely that the SGX itself, a verifier, has a bug. And the reason is that, broadly speaking, what I expect will happen is that you're compiling an existing client, like GEF or some other client into SGX, and so it's not like you're rewriting from scratch using very fancy technology and circuits. So if there's going to be a bug, I think it's more likely to happen on the snark verifier.
00:09:12.120 - 00:09:23.290, Speaker F: You're not really losing that much liveness by introducing a second verifier which is SGX based.
00:09:25.840 - 00:10:01.590, Speaker B: Makes sense, basically regain a lot of security without compromising a lot hopefully of likeness, right? Yeah. So let's be a little bit more specific about how school is approaching multi proverb. Can you tell us what was the thought process about the way school approach this? You know, just a little bit about how you think about this problem and how is the school is going to this.
00:10:06.360 - 00:11:38.000, Speaker D: Hai Chin has disconnected again, so I'll take over, I think for think. First of all, I would like to credit Justin for the idea of using a tease for a multipruer setup. I think it was December 2022 when Justin authored the e three research article on it, and I think we started looking into how to implement it and whether the trade offs are worth it almost immediately. And in our configuration we essentially use two provers because there are multiple ways you can do it, and both of them have to assert that the same state route has been produced by the same batch. And actually Justin mentioned that you gain safety, but you lose some liveness temporarily if, let's say, two of the provers disagree. But actually I spent some time thinking about it recently, and I think it's possible to still have liveness, but just not finalize the blocks or the batches. So how it would work is essentially you would post a cross chain communication, but you would still have the sequencers producing the batches.
00:11:38.000 - 00:12:12.480, Speaker D: And so you can still continue posting the batches on chain, but just not finalize them until the security council or the governance picks the correct setup. And so if that's the case, then you essentially make no trade offs at the benefit of having a significantly higher safety guarantees because in this case, you have to have both of the proof systems fail in order for your funds to be stolen or an illegal state transition be proposed.
00:12:16.310 - 00:12:24.440, Speaker B: Yeah, that makes sense. Basically we could still keep sequencing without finalizing. But.
00:12:26.330 - 00:12:28.710, Speaker D: Yes, you can proceed with published.
00:12:30.010 - 00:12:39.900, Speaker B: Yeah, I mean, a natural follow up question is whether we fall too far behind from finalization and whether we create a huge backlap or not.
00:12:41.790 - 00:13:19.478, Speaker D: But the thing is, you still can finalize off chain because if you run a full node, you don't actually need the state route to be finalized on chain. You can still finalize things off chain. Obviously for cross chain communication you would need on chain finality, but you sort of guarantee at least partial liveness, which means that you can still, say, publish oracle updates, et cetera, et cetera. And certain mission critical tasks can still proceed without you risking the funds that have been locked in.
00:13:19.484 - 00:13:34.102, Speaker B: The sense. Makes sense. Haitian, I think you're back. Do you want to pitch in a little bit about how scroll is approaching multiproover? What are our criteria?
00:13:34.166 - 00:14:31.402, Speaker E: And so, yes, sorry about the buggy. So there are three, I think, objectives we want to achieve when we're designing the multiple system for school. First is that the multiproof system should enhance our security. That means it should be more secure than a single proof with the ZKE EVM. And the second, we don't want to trade off on the finality time because one of the advantage of the ZK proof is that it can have very short finality time, like within an hour compared to maybe other proof system could be like, takes days to finalize all the transactions on the swims. And then the third one is that we only want to introduce marginal cost to the L2 transactions. We don't want to say, okay, we definitely want to make all our transactions on scroll be more secure, but we don't want to make it be much more expensive.
00:14:31.402 - 00:15:34.900, Speaker E: So that are the three criteria objectives we want to achieve. So we go look at different designs on those multiproof systems. So first of all, because we want to have better security for the four L2s, that means, I think we agree that we should have always on multiproof systems, that means all of the state translation should be verified by at least one decay proof and then with additional proof systems. But now because of the other two requirements we have, is that the short finality time and the cost efficiency requirement that actually narrows our options for adding a secondary provers we want to have. So we then explore some options for picking up a second prover inside our multi proof system. On scroll previously. First of all, we consider fraud proof, but fraud proof has a problem.
00:15:34.900 - 00:16:20.830, Speaker E: The drawback of the fraud proof is that it requires a seven days challenge window to finalize any transactions. So if you're combining the fraud proofs with the ZK proofs, actually the finite time now becomes the longest finite time of the either proof. That means like the finite time will increase from within an hour to seven days. So it's not what we want. And another option is like we want to see if we can build another ZKVM prover. I think that'll be some long term goal we can still pursue, but still take much more effort and a time to build a second ZKVM proof. And then probably the proof application will cost more.
00:16:20.830 - 00:17:34.230, Speaker E: So that's why we turned on to the third options is to choosing this TE prover, which stands for the trust execution environment prover. So this is like, I think as Pogo mentioned, that Justin proposed this a very long time ago. So the TE is basically allows you to run software in a secure area of a processor that the data and memory is inaccessible to other components in the system. That means if you like a very secure enclave inside a system that no others can access the data inside that, then you can keep some secret, secret key there that only the enclave can have access to. Then inside this secure area you can then run a state validation software to validate all of the state transitions on the L2, and then eventually signed by the secret key that only is available inside this secure enclave, not going to validate the transaction there. So now one of the benefits of the running the TE is that it's very flexible. You can very easily run software inside this secure enclave.
00:17:34.230 - 00:18:05.970, Speaker E: And then additional cost for verifying the TE proof is marginal because you need to only verify the signature is correct. And then also it doesn't increase the finality time because it's very fast to run those software to validate the state transitions of the L2s. So that satisfies all our objectives. So that's why we choose to combine this TE approver with the CKE event prover to secure the scroll transactions.
00:18:06.470 - 00:18:39.840, Speaker F: Hi Chen, I have a bit of a question for you actually. Would it be fair to say that the scroll sequencer acts like a third verifier, some sort of centralized trusted verifier, because in order for blocks to go on chain, they have to be signed off by the sequencer. And so even if the SGX and the snark are kind of broken, so long as the sequencer hasn't been taken over, only valid blocks will make it on chain anyway.
00:18:44.170 - 00:19:22.820, Speaker E: I think in some sense you can treat it as a third way to validate the transactions. But I would say I think the sequencer, since decentralized, has a lot of control over what transaction to include and what state transaction there. So I think it can increase a little bit on that. But I would say it's better to have other proofs mechanism to validate the transactions. So more like someone proposed something and then others will be validators to validate whether your proposed of that transaction and then the state from old route to new route is correct or not.
00:19:25.270 - 00:20:56.930, Speaker D: I think it's a good segue to actually discuss the side effect of having multi provers is the fact that we can more confidently decentralize the protocol now and the prover network to be specific, because one of my worries previously was that, let's say for now, because we control the provers and basically the provers, as long as we are honest, the provers are only going to publish the validity proofs that don't have any exploits inside, so don't maliciously modify the state or something like that. That was one of my worries when we decentralized. So what happens if there's a bug that we haven't figured it out before and now people can actually exploit it? Because now we act as a barrier protection barrier in between the prover computation and the proverification on chain. And so multiprover is a good way to actually allow us to decentralize without worrying about that side effect. Because now let's say if there's a bug in one prover, you would have to figure out how to exploit the second prover in the same way to actually steal funds or make an invalid state transition. And so I think it's a great side effect to have from the fact that we introduced multipruers would you agree with that? Hai Chen.
00:20:58.630 - 00:21:18.482, Speaker E: Yeah, I totally agree. I think this is one of the motivation that motivates us to build a second prover so that make it easier for us to because our eventual goal is to make scroll decentralized. So this is one step towards our goal to making our proverb to be decentralized.
00:21:18.546 - 00:21:19.160, Speaker D: First.
00:21:21.150 - 00:21:43.920, Speaker F: Would it be fair to say that the SGX prover can also provide very low latency proving? And so if you want to build a bridge, some sort of SGX based bridge which is very low latency, which is faster than the 1 hour settlement that comes with SnOC proving, you could do that if you wanted to.
00:21:47.970 - 00:21:50.838, Speaker E: You mean you only rely on the SGX proverbs?
00:21:50.874 - 00:21:51.074, Speaker G: Yeah.
00:21:51.112 - 00:21:57.746, Speaker F: So if you wanted to build a bridge for, let's say low value payment amount or something like that, then you.
00:21:57.768 - 00:22:59.346, Speaker E: Would, yes, I guess you could do that. I think that's the argument or controversy of relying on SGX or NAT technology is that you're basically putting the trust onto the Intel SGX because Intel, because intel controls some master key there. But I feel like for some low value things it's possible that you can rely on only SGX proof alone. But if you have more assets, I would say it's better to having more than one, more than the SJX prover alone. So it'll be giving you more secure sense. And previously also I think in the blog post we talk about this downside of those Te implementations and how I manufacture because you're putting trust to that. So it'll be great if we can combine multiple tea provers from different hardware vendors and then different kind implementation to have more diversity there.
00:22:59.346 - 00:23:05.290, Speaker E: So it could be giving stronger guarantee than just trusting on a single hardware vendor.
00:23:07.710 - 00:23:59.526, Speaker G: Yeah, I actually totally agree with Haijan. So I guess the idea of having multiple proverbs is actually to have diversity within your entire protocol community. So far in as let's say, because tees are not restricted to just Intel Azurex. This specific implementation that we have now presently at the moment is actually based on Intel Azurex. But there are actually other vendors that produces tes. For example, ARM has their CCA confidential compute architecture, AMD has their AMD SUV, sorry Aws. Amazon has their nitro enclave.
00:23:59.526 - 00:25:25.560, Speaker G: And then I think even some of the chinese cloud providers have their own version of tes. There are also open source TE projects like Keystone. So the thing is, when we talk about Te, we know that Te itself is actually a very diverse kind of group. So some people might not trust intel some people might not trust AMD, but the thing is, if we're able to form this kind of like PE council, and then if we actually design our solution, our protocol to be one that actually relies on the integrity of, relies on at least on just one single honest party, then having all these multiple kind of like provers, multiple t provers, multiple ZK provers will actually make the entire system more robust. So yes, just like how Ethereum actually looks at having multiple, having this client diversity to kind of improve the robustness of the protocol itself. So if there's a particular kind of implementation bug in one of the clients, the other clients can actually, you need to actually have the same bug in multiple client implementations, which itself is actually a very unlikely. Yeah.
00:25:28.730 - 00:25:57.010, Speaker D: I guess I have a bit of a question for Haijin and Justin about the long term future of multiprovers. Do you think SGX is just a stepping stone or tes in general are just a stepping stone towards an environment that has multiple validity proofs, different validity proofs acting as multi provers? Or do you think TES and SGX specifically is here to stay as one of the multi provers?
00:25:59.110 - 00:27:03.302, Speaker F: I would say it's temporary for a couple of reasons. One is that there is a memetic downside to using SGX at all. Even if you try and educate people, just the mere existence of tes can come with a memetic downside. And then the other thing is that if intel were to be compromised, then it can lead to a liveness failure. So if someone within intel has access to the keys, they can just cause know we have permissionless sequencing and permissionless proving, then the attacker can just submit an invalid block and give a valid SGX proof. And so if we're one of my thesis is that eventually we're going to have roll ups without governance, right? It's going to be fully immutable code. And at that point even governance can't fix things.
00:27:03.302 - 00:27:08.760, Speaker F: And so we're not going to want to rely on intel for liveness there.
00:27:12.190 - 00:27:48.050, Speaker E: Yeah, I agree with Justin, because the liveness concern is definitely like a trade off for relying on the SGX. So currently we need to design certain like using the governance or security Council as the way to step in to prove disagree. So to keep the liveness and to decide what are the correct state transition there. So I think eventually, if we have multiple different ZKevMs implementations or other proof systems, it would be better to run more trustlessly.
00:27:50.070 - 00:27:57.880, Speaker D: And Justin, since you mentioned Chad, did you want to say something?
00:27:58.570 - 00:29:10.234, Speaker G: Yes, I would actually like to kind of extend the argument a little bit. So if we just talk about, let's say if we have two provers or for TES, we would just rely solely on intel, then I actually agree with what Justin and Chun is saying. But like I kind of described previously, right, there are actually multiple vendors for intel, sorry for intel being one of them. And once we actually increase the kind of like the diversity of the provers that are involved in this multiproof system, if we want highly robust solution, we might have an end of n agreement. But the thing is, we can always have, say, two thirds majority consensus to have it be finalized. That means, let's say if we have three different verifiers, two of them would have to agree before it is finalized. So in this case, let's say a hypothetical situation where we have AMD tE, an intel tee, and the ZK proof system screws.
00:29:10.234 - 00:30:39.322, Speaker G: ZK proof grow up. So in this case, even if, let's say, intel's key gets compromised, right, we still have a way for us to have likeness because AMD keys are fine, their machines are not compromised, and then the ZK proof itself is fine also. So in that way, I would actually argue for a more diverse kind of environment. And the other point that I want to kind of share a little bit also is that when we look at diversity or kind of like multifactor proving, you would want to have a kind of like, you want to have a different method of actually performing this proof. So for example, when we have multifactor authentication, we typically would want to have something that we own, something that we know and something that we are, they have different properties. So let's say if we want to have a multiprover system, you'll actually form a more robust base if there are multiple approaches to actually perform this verification and this proof. So, for example, we have validity proof in the form of ZK proof, and then we have actually a re execution proof in the form of PE.
00:30:39.322 - 00:30:48.080, Speaker G: And then we might actually also have some form of a consensus proof. Maybe this is just something that I'm thinking about.
00:30:50.050 - 00:31:34.400, Speaker F: I guess if, let's say one of the vendors goes offline and the governance can rotate that specific vendor to another vendor, then it's fine. But if you're thinking about the end game, right, where there's no governance whatsoever, then really the only verifier that requires no maintenance at all is going to be pure code and that's going to be a snark based verifier. But I agree this is quite a distant future where we have roll ups without governance. And in the medium term, what you suggest the k of n multivendor tes makes a lot of sense.
00:31:38.990 - 00:32:42.160, Speaker D: Yeah, I think that roll ups without governance are quite a long way away. So I think it's fair to assume that for at least the foreseeable future, tes are fine because we can just use governance or security councils to switch around in case they fail, like one of the implementations fail. Going back to what I was starting to talk about before, Justin, you mentioned the mimetic factor in these, and I remember when you first published the article about using SGX, there were a lot of replies of people saying that oh, it's SGX, it's broken, whatever. And how do you think we as a community should approach educating people that actually certain use cases the security of SGX or tes in general is additive. So you don't depend on their security, they're just there to increase your security.
00:32:44.530 - 00:33:42.690, Speaker F: Right. I mean, I guess one way is to just show by example, and I think the multiverse is a great example. Another really great and simple example is staking. So if you're an operator of validators, the signing key needs to be a hotkey that's connected to the Internet. But if you put that hotkey within SGX, then now you have an additional layer of protection, even if your computer has a virus or gets hacked. And one of the things that I'm hoping will happen relatively soon is that it's very easy for any operator, including solar operators, to protect themselves with SGX. I think a lot of the professional operators are already doing that.
00:33:42.690 - 00:34:36.110, Speaker F: Right? They have signing Cleese within enclaves, but it's not really a technology that's super accessible to solo operators. I believe that puffer has written basically this anti slasher SGX based protection and they've open sourced it. And I believe someone from the community wrote like a really detailed tutorial explaining how to set it up. But yeah, it's still a little bit complicated, there's a few steps to go through and so maybe what needs to happen is someone provides a package solution that just works at the press of a button and you get the same protections as Coinbase would, which I'm pretty sure they use tes.
00:34:39.970 - 00:34:55.330, Speaker D: Yeah, so essentially you see the future of staking where the majority of the stakers use some form of tees to protect the hotkeys. The signing keys.
00:34:55.490 - 00:35:19.570, Speaker F: Yeah, exactly. And actually maybe an even simpler example to understand is hardware wallets, right? Like sure you have the freedom to not use a hardware wallet and just use metamask and have your private keys on your computer. But it is just a strict improvement to have some sort of separate device which is connected to the computer which could be compromised.
00:35:23.110 - 00:36:13.490, Speaker D: Yeah, I think that makes sense. I think we just need to put more effort into helping people understand that there are certain use cases where SGX or tes in general actually are beneficial to your security and not something that you should worry about or something that can basically result in you losing your funds easier than what would have happened without it. Sandy, you have been quite silent this entire Twitter spaces. So do you want to chime in? I would like to say you're the business head at school, so what is your perception and why do you think that multi brewers are an exciting path from your perspective?
00:36:14.390 - 00:37:00.194, Speaker H: Gosh, thank you for that. Thank you for that plug Toggrel and for picking on me. Love it. So I think I want to kind know, give a very big shout out to, as Justin mentioned, all the contributions from external parties that made this possible. This is really kind of, it takes a village to build the next level of security standards for row ups. And from my perspective, I think anything that increases the security of a row up makes me sleep a little bit better. And I think running a row up has really changed my perspective on how much responsibility it is.
00:37:00.194 - 00:38:56.294, Speaker H: Both kind of mainly to everybody that is bridged to scroll and who is building on scroll and who is trusting us with their time and their resources and participating in this essentially open source experiment to build the global coordination layer and be the transactional layer to scaling Ethereum. And that's super exciting. I think from my perspective, the implementation of multi proofer really gives me the confidence to kind of go to market a little bit harder and to onboard more builders and be more confident and just kind of in our point of interaction with lps and people who are thinking about, oh, how do I deploy? I think this gives them, and hopefully gives us that extra layer of confidence about so called like, funds are safe, but in a mathematical and engineering geared way. So I'm super excited for this. And I think the great thing about multi provers, I think it was Justin, like a year ago and kind of said, this is kind of like adding a two fa, you wouldn't necessarily think about how important it is until your Twitter or your account gets hacked. But now almost everybody, most people would recommend two FA unilaterally to any kind of messaging or login system, because it's just like inevitable that the security standards needs to increase as our lives and part of our lives that intersect online and on chain starts to increase. So we think this is kind of going to be a very basic set and we think all the roll ups will essentially adopt it.
00:38:56.294 - 00:39:00.546, Speaker H: And we're very proud to be kind of pioneers in this particular direction.
00:39:00.658 - 00:39:21.360, Speaker B: I think it's a good segue, I think it's a good segue to ask our friends at automata to tell us a little bit about what are the main complexities behind building. Yeah, let's start with that.
00:39:23.090 - 00:40:34.898, Speaker C: Yeah, actually I like to see, I'm trying to tone down on the complexity actually, because to be honest, in reality, building in te building intel SGX for us it's relatively easy right now because we have some etc. Building blocks that we have created throughout the years, especially on things like handling Ethereum transactions. Ethereum blocks because previously we also tried create an Ethereum block builder in PBS architecture. So it was able to produce a main net block on Ethereum too. So thanks to that project, we actually have some foundations for creating the proverbial prover for scroll as well. So what we did was just basically following scrolls ziki vms back and tried to reproduce re execute the transactions following the same state transition functions and eventually submitting the result on chain. So that at layer one you can just compare the result coming from the ZK proof and the result coming from our approver as well, essentially.
00:40:34.898 - 00:40:49.034, Speaker C: Right now I agree with what Sandy just said. You can treat it as just two fa, it's additional check that you want to pass before giving it a grid line because running without it could have.
00:40:49.072 - 00:40:50.346, Speaker D: Other risks as well.
00:40:50.448 - 00:41:03.550, Speaker C: So this is kind of our take on this. I would say we have some experience on building this and happy to also explore other angles of securing in general the road lab or blockchain systems.
00:41:04.290 - 00:41:16.740, Speaker B: Perfect. Can you tell us a little bit about how was your engagement with the scroll? Why do you guys did this and why you guys did this in open?
00:41:25.960 - 00:42:17.796, Speaker G: Okay, so maybe I'll start off with why we decided to do this in the open. I think all code wants to be free. That's the kind of like the cliche way of saying why we should do open source. But in a sense we built on shoulders of giants, right? For example, the Intel SREX Rust SDK that we built the t prover on is actually an open source project that's incubated by Apache. So it's called the t clave Intel SREx Rust SDK. So the way how we see it is that when we build in the open. And then we kind of review whatever that we have.
00:42:17.796 - 00:44:10.852, Speaker G: This would attract contributors, people who are interested in the space to come in, take a look at our code, and this would actually refill, improve the quality of the code. More ice makes all bugs shallow, right? And this is something that we want to do. And the other thing is that since the code is open source, someone else who is interested to continue building this can just take it, work on it, and then build something even better out of it, or take it and then kind of modify it for some other purpose or for some other roll ups or port it to some other te vendors like AMD or AWS. And this is why we made it open source. As for the kind of like the engagement between automata and Scroll, I would really want to thank scroll for actually giving us the opportunity to work on this with them. So the whole project actually started off as kind of like a grant given by scroll to actually explore the feasibility and the feasibility of the idea. Whether does it even make sense for us to do all of this? It sounds good on paper, but is the performance of interst good enough? Can we actually do all the things that we say? Are we able to perform the necessary attestation for the intersjx to prove that the tea itself is actually secure, to prove the integrity of the enclave itself? What about complexities of the enclave? Because like what Hyen mentioned, right, the enclave is like an isolated part of your hardware.
00:44:10.852 - 00:44:38.610, Speaker G: It actually doesn't have any access to your network card or your storage. So there's actually this marshalling of data across all these trust domains. I'll be able to do all of this and then that's how basically the engagement started. So we are really grateful for the opportunity that scroll provides. And of course this whole thing.
00:44:41.060 - 00:44:41.376, Speaker D: How.
00:44:41.398 - 00:45:03.130, Speaker G: To play it is actually a very good example on how te technology itself can be used as a way to actually enhance the robustness or the security of a robot. Because screw is actually a detailed roll up.
00:45:06.700 - 00:46:08.540, Speaker E: Also chiming a little bit like we are also very glad we're collaborating with Automata as automata has very strong expertise in the SGX and te implementation wise. And also just looking to the future which how the scroll protocol will interact with automata SJX provers. We have some preliminary designs, but we're going to drill down on the details of other protocols. And then there's a lot of things we need to also to make sure that the whole protocol is still secure and then become more secure after adding the TE provers and also while still keep the liveness there. And the second thing is like we are going to also working with automata to auditing the code before we really put them into the production and then to put into the real like the production to secure all of the scroll state transitions.
00:46:10.080 - 00:46:47.976, Speaker D: Hi Chen, another question for you. Since we made the announcement yesterday, I got a few people asking me who asked me whether they would be able to permissionlessly run an SGX prover. I think it would be good for us to highlight whether it would be possible and what are the hurdles and what are the steps that we have to take in order for it to be possible. Would you like to expand on it a bit?
00:46:48.078 - 00:47:46.670, Speaker E: Yeah, I think it's totally possible to run the XGS proof of permissionlessly, but we're still kind of reviewing the security implication and some of the incentive mechanism to see whether we're going to do it on day one or be first run by a committee and then later be fully permissionless and decentralized. But I think the first step is definitely won't be like running as a centralized sjs proof, we'll be like having a committee to run that. But we are kind of like reviewing whether it's possible to just renting like fully formation lists on day one. It probably requires some of the, because running SJX provers do require incurred some costs, although it's not too much, but kind of figure out will be any incentive mechanism for people to incentivize to run the SAS proverb and then whether the security implication for that.
00:47:49.200 - 00:48:10.900, Speaker D: Cool. Justin, in your opinion, is a multi prover a first step in this road towards a roll up that doesn't have a multi sig, that only has a delayed upgradability or you don't think it can happen without enshrinement.
00:48:15.780 - 00:49:30.330, Speaker F: Um, right. So I think for, for some period of time what I expect to see is that there's going to be the ability for a multisig to press a big bread button if there's basically an invalid state transition, which could make it on chain. And what I expect will happen is that there's going to be an artificial delay. It doesn't have to be very long, it might be on the order of 5 minutes. And the nice thing is that if someone is suggesting an invalid state transition function with correct proofs and there's a five minute delay, well, 5 minutes is what is like five times five slots. So it's like 25 slots. And so more likely than not you can have an automated system, basically, which goes ahead and presses the big red button, and then you need a mechanism to go reboot the chain, I guess.
00:49:30.330 - 00:49:38.350, Speaker F: Sorry, does that answer your question? Can you actually repeat the question?
00:49:40.560 - 00:49:53.520, Speaker D: Yeah, to a certain degree. So my question was whether multiprovers are the first step in a path towards a roll up that doesn't have instant upgradability in the validating bridge.
00:49:56.180 - 00:50:04.900, Speaker F: Right. To not having instant upgradability with the multisig. Is that what you mean?
00:50:04.970 - 00:50:05.156, Speaker G: Yeah.
00:50:05.178 - 00:51:00.788, Speaker F: Right. Okay, so let's say that we want to remove the multisig then. Yeah, we want to remove the possibility of having these invalid state transitions go on chain. And yes, I think I would be most comfortable with something like three verifiers that are written with different languages, different teams, and things like that. Part of the scary thing, actually, is not just the technical risk that comes with the verifiers, but it's also the social risk. I think it's very easy to obfuscate a bug if you're a malicious developer and one of these teams writing a verifier. So that's also something to be taking into account.
00:51:00.788 - 00:51:41.280, Speaker F: And so what is the cost of infiltrating a team? Maybe it's not that high. Maybe it's $100 million, let's say. And if you can gain $10 billion from doing that, it's really scary. I think another tool that can help in addition to multi proving is formal verification. I mean, still very early days, but maybe AI can help in some way in automating a lot of the grant work that comes with formal verification.
00:51:42.740 - 00:51:54.920, Speaker D: Hopefully not a Chat GPT audit, though, because I've heard that there were a couple of teams that have posted that they audited their smart contracts in Chat GPT.
00:51:55.580 - 00:51:57.210, Speaker F: How did that go for them?
00:52:00.780 - 00:52:03.640, Speaker D: I haven't followed up on it, but it was just funny.
00:52:05.520 - 00:52:57.180, Speaker F: One of the interesting things is that, and actually yesterday I was on bankless recording an episode, is that eventually we're going to want real time settlements so that we can have synchronous composability with all the other rollups. Right. The rollups being individual silos today is kind of a temporary thing. But one of the very scary things of synchronous composability and real time settlement is that you're just not allowed any room for error because you don't even have this five minute window to press the big red button. All the funds can just go from one slot to another. And so, yeah, I think we need a combination of Lindy, of multi provers and formal verification.
00:53:00.960 - 00:53:56.060, Speaker D: I would actually say that. Another thing that could work quite well here in the combination with formal verification and multipruers is having multiple implementations of the validating bridge. So essentially having a bridge implementing in solidity and another bridge implementation in like huff or something else, and just ensuring running them in the same setting as a multipruer, where you essentially only mutate the state if both of them agree on the same state mutation. And I think those three might be the path. Like if you combine formal verification, multipruers, and two implementations, or two or more implementations of the validating bridge, we might actually have a chance to avoid needing instant upgradability.
00:53:57.300 - 00:55:04.260, Speaker F: Right? That's a great point. The bugs could not be in the snarks themselves, but they could be at the solidity level or whatnot. And there's compiler bugs all the time, right? Like compiling solidity is very complicated. Compiling Viper, whatever it is, it's very complicated. And just as a small kind of historical story, when we had the deposit contract, it was initially written in Viper, and it's a very simple contract, and we had the bytecode formally verified, and the formal verification process found multiple bugs in the Viper compiler. So yes, we do need to be mindful of compiler bugs. The nice thing is that the smart contract layer and the verifiers are meant to be simple, right? You don't actually need to formally verify the proofers, only the verifiers, and that's in some sense easier.
00:55:04.260 - 00:55:16.840, Speaker F: I mean, I guess a lot of the complexity is in the circuit, right? So all the complexity of the circuit is condensed in this one verification key, and this is where it becomes hairy.
00:55:20.060 - 00:55:49.750, Speaker D: Yeah. I think one of the advantages that circuits have is that unlike smart contracts, there are fewer people who can understand them, and therefore there are fewer people in the world who can actually exploit them. Whereas with smart contracts we have almost, what, a ten year history of smart contract exploits. So there are a lot more people who are actually capable of exploiting them.
00:55:51.800 - 00:57:00.440, Speaker F: Right. That's a good point. On the AI point that you made, I do imagine that there will be a moment, a tipping point, where ais are just so much better than humans at fighting bugs. And then the question becomes, is the team that has this capability a black hat team or a white hat team? And if it is a black hat team, then we might be, for a small period of time in a bad position. And one of the things that we've observed historically is that even simpler protocols than zkvms, things like bridges, which intuitively speaking should be at least an order of magnitude simpler, if not two orders of magnitude simpler. They still have tons of bugs. So maybe we need to wait for AI to develop a little bit before we can really remove all the guardrails.
00:57:02.220 - 00:57:21.264, Speaker D: I guess we would have to help develop improve AI ourselves, because if we just leave it to the black hats, then we might be in a situation, as you mentioned, where they front run us. And it's not pretty if that actually happens, right?
00:57:21.462 - 00:57:32.616, Speaker F: I guess you could just wait for it to be commoditized a little bit. So it's public knowledge that these technologies are available and they found all the bugs in the scroll circuit.
00:57:32.748 - 00:57:33.430, Speaker D: Yeah.
00:57:35.560 - 00:57:36.470, Speaker G: For sure.
00:57:36.920 - 00:58:04.170, Speaker D: All right, I think we're out of time, so I would like to thank everyone for listening. Justin, thanks for coming. Deli and Jua, thank you for coming, and thanks to the rest of the scroll team for coming along. So I wish you all a great day, and hopefully we get to hang out more in one of these Twitter spaces in the future. Again.
00:58:06.220 - 00:58:07.072, Speaker F: Thank you, guys.
00:58:07.126 - 00:58:10.396, Speaker D: Bye bye.
00:58:10.428 - 00:58:11.168, Speaker B: Thank you.
00:58:11.334 - 00:58:13.660, Speaker F: Thank you. Bye.

00:00:22.290 - 00:01:15.530, Speaker A: So welcome, everyone, to the last day of this Cke EVM audit education session. So today we're going to have four talks. So the topic of today's session is to share some of the experience of the ZkeVM development, as well as some other ZK circuits development in general, some lessons we learned during auditing, and then something that we think will be very easy or prone to arrows. So basically, people are going to share a bunch of things that they have during the ZK circus development. So first, we'll have Barry to talk about the claims. So he want to think that Zke EVM auditing needs to verify. And then Jose and Jordi, we're going to share some of the auditing preparation and some bugs in the ZkeVM.
00:01:15.530 - 00:01:42.420, Speaker A: Azu on EF. Also, we're going to talk about the challenge API that we modify in the hello two. And then a little bit about the ZkevM python specs that we develop. And the last Oriole from Scroll will talk about some special behavior in the scroll ZkevM, some considerations. So first, I'll give the time to Barry to talk about. To give his talk.
00:01:44.950 - 00:01:57.100, Speaker B: Thank you. Hi, Chan, can you hear me? Yes. Okay, let me share my screen. Can you see my.
00:01:58.510 - 00:01:59.210, Speaker C: Yes.
00:01:59.360 - 00:02:01.738, Speaker D: Yes. Okay, cool.
00:02:01.904 - 00:02:33.462, Speaker B: Yeah. So, like Haichan said today, I want to talk about the claims that we want to verify, and I'll also talk a little bit about some of the mistakes that we found along the way. So this talk is like 30 minutes, but I think we'll have time for questions at the end. But also feel free to jump in with questions as we're going. This can become more of a discussion than like a presentation if people have things they want to talk about. So feel free to jump in. So let me just introduce the topic a little bit.
00:02:33.462 - 00:03:31.800, Speaker B: So when we're auditing things, we want to verify claims, and we want the claims that we're verifying to be really strong. Like, for example, we want to say that the ZkVM is unhackable. That's not a very useful claim because we don't really know what hackable means, but we do want to verify things about, like, it's impossible to take money out of the Zkavm. Or there is this implicit set of claims that we all kind of have in our mind, but there's also. Oh, let me go to full screen. Where is that? Anyway, let me just keep going. So we all have these implicit claims that we have in our mind, and the goal of today's talk is to point out some other claims or some other things that we want to verify.
00:03:31.800 - 00:04:08.400, Speaker B: So I talked earlier about how we want to make the ZKVM unhackable. And one big part of that is validity. We want to make sure that invalid state transitions are impossible. That from the state before and the state after, you have to follow the rules of EVM. This is a validity claim that we want to verify. And let's dig a little bit deeper into this. So validity is really capturing a bunch of different things that validity captures.
00:04:08.400 - 00:04:48.400, Speaker B: Oh, we don't want to do invalid state transitions, but it also captures things about solidity smart contracts. For example, the ZKEVM is going to execute these smart contracts. And these contracts are built by people who don't know anything about the ZKVM. They know things about the EVM, and they make smart contracts that's secure in the EVM. And the assumptions that they're carrying over needs to be enforced in the ZKVM. Let me give an example. So let's say that we finish ZkVM and we find that everything is totally fine.
00:04:48.400 - 00:05:33.880, Speaker B: The ZKVM is unhackable. But if someone deploys like a comet smart contract, like Uniswap, that contract is not completely covered by the ZKVM rules. This is another thing that we need to be super careful about. One example of this is that the Zkavms that we're auditing right now are not 100% EVM compatible. And we learned from previous experience that when we change the EVM, even in a smaller way, it has these huge cascading changes. One example of this was like repricing some gas opcodes, broke a whole bunch of smart contracts. There was a bunch of smart contracts that would give like 10,000 gas to do a whole bunch of operations.
00:05:33.880 - 00:06:02.980, Speaker B: And when the 10,000 gas wasn't enough, it failed. The contract wasn't able to kind of continue. That kind of broke a bunch of smart contracts. And this is something that we need to keep in mind when we're auditing ZKVM. The assumptions that the developers have are different. They could be different from what we have or what the ZkAVM provides. Let's dig a little bit deeper into.
00:06:02.980 - 00:07:09.228, Speaker B: So, like, we have to be aware of this contract that people are building and how they're using the EVM when we're auditing the ZKVM, because the ZKVM is different. And those differences could affect a lot the security of some contracts going one step deeper, we have to think about the solidity language itself, because the solidity contracts don't talk directly to the EVM. They go through the solidity compiler, where the solidity compiler does a whole bunch of things and produces this EVM bytecode. And that's what the EVM interprets. And there's a whole bunch of assumptions in the solidity language that we need to be careful about too. One example of this is that the Zka EVM uses snark friendly hash functions for the storage, or the two release candidates do, and solidity assumes that you're using ketchek for this. I'm like, the guarantees of these two different hash functions are different.
00:07:09.228 - 00:08:24.324, Speaker B: It's not clear how collision or how pseudo random the snark friendly hash function is. So one potential attack is that you could try and fill up the Merkel Patricia tree by producing a whole bunch of non random values. Let me slow down and just expand on that a little bit. So, like, the way that the, the way that the, the storage tree works is that like, items are like randomly assigned. Like the depth of the tree is variable, and if you're able to put items in really inconvenient places in the tree, then you can make the tree grow very deep, and that could be a problem. Also, it's important to remember that this is probably not the best example, because if I understand correctly, both of the release candidates have different storage trees, which might have like a fixed depth. And if they have a fixed depth, then this kind of changes the assumptions here a bit.
00:08:24.324 - 00:09:25.236, Speaker B: But it's also important to remember because solidity uses this for mappings. Right. Solidity will, when solidity does a mapping, it will kind of randomly assign the value that's mapped to a position in the tree and then just map that position to one. This is another solidity assumption that we need to be super careful about, because with the CKVM, because this is changing something that solidity had assumed was going to be different. And this is another place where I think we could find some bugs when we're looking at the interfaces of these three different systems that we're talking about. So this is kind of a fun example of how these three things come together. So when we were making ZKPM, we thought about removing gas, right? We thought that like, oh, why do you need to have gas? Isn't like the size of a proof and implicit gas limit.
00:09:25.236 - 00:09:51.968, Speaker B: Why not just remove it? And that would help everybody. But it turns out that gas is a really important security feature. And gas is used in CKVM. Gas is used in EVM by solidity developers to limit what a certain contract can do. It's also used by solidity. So when in solidity you have two ways of sending money. Well, you have more, but like, let's just say two.
00:09:51.968 - 00:10:39.900, Speaker B: You have transfer and you have call, and transfer is the safe way. This transfer protects you from this so called reentrancy attacks, which is just such a huge common bug. And transfer protects you against this, whereas call doesn't. And how does this work? Well, solidity, there is no transfer opcode in the EVM. What solidity does is whenever it sees a transfer, it kind of replaces that with a call that has this gas limit. It says you can do a call, and whatever you do inside that call has to be 2000 gas, no more. And if gas disappeared, if we decided to say, oh, gas isn't important, we can get rid of gas, then every transfer would become like a reentrancy attack vector.
00:10:39.900 - 00:11:35.264, Speaker B: Right? Because we would remove the protection. The protection here is the gas limit, because 2000 gas isn't enough to do a reentry eight c attack, because it's not enough to do another call. Let me finish and then I'll explain a little bit more about a reentrancy attack. So if cast disappeared, then it would be a really big issue. So this is an example of where the three things I talked about kind of connect and make the DKVM sort of vulnerable. And this kind of interface between three different systems is somewhere where I think we need to be really careful. Yeah, basically, I don't know if people know what a reentrancy attack is, but basically a reentrancy attack is where you call one contract, and then that contract calls the original caller and does something else.
00:11:35.264 - 00:12:11.980, Speaker B: That's a reentrancy attack. But anyway, that's not super important to worry about. I think everyone is up to date on these kind of attacks, and if not, you can just google it. There's a lot of information about them out there. Okay, so let me give some conclusions for the first part of the talk. The first conclusion is that what we're assuming is much, much bigger than the yellow paper. The assumptions we are also inheriting from common smart contract practices and the solidity language.
00:12:11.980 - 00:12:52.810, Speaker B: Those are two other assumptions that we need to be super careful about. Also, if we invite developers to deploy any contract on ZKVM, we have to be sure that the changes in the ZKVM don't make those contracts vulnerable and as we learned from Harrod talks before, we have to be very careful about the changes that we make. So that's the first part of the talk. The second part is about liveness. So we talked about making the ZKVM unhackable. The other major thing that we want to do is talk about is the guarantee liveness. And this means that you can't pause the system.
00:12:52.810 - 00:13:31.168, Speaker B: Pausing the system is like making it impossible for a user to withdraw or breaking a smart contract. Make a smart contract that in the EVM would be able to continue operating, but in ZKVM it's kind of frozen or paused. These are the lightness guarantees that we want to check. We want to make sure that the system is unpausible, and we have to make sure that deposits and withdrawals are unpausable. And also that on the contract level, there's no way to break a contract that's deployed. Yeah. So the first thing to talk about here is the gas price changes.
00:13:31.168 - 00:13:36.250, Speaker B: There's some gas price changes included in ZK in the release candidates, and.
00:13:38.860 - 00:13:39.176, Speaker D: We.
00:13:39.198 - 00:14:36.604, Speaker B: Want to make sure that those gas price changes don't break other smart contracts or other common smart contracts. Like, one example of this is that I don't know if people still use this pattern in solidity, but it's often the case where you have a limited amount of gas and you need to do a whole bunch of things. People definitely still use this pattern where you have a limited amount of gas and you want to do a whole bunch of things. If we change the gas price and you're not able to do all of those things, or if we change the implicit gas price and you're not able to do all of those things, then this contract is broken. And this is extra difficult because defi kind of has this pattern of composing a whole bunch of different contracts together in arbitrary ways. And if you're able to build this kind of string of calls that you need to do, like aave needs to call uniswap and Uniswap needs to call, I don't know, another one. And then you go back and you go through this cycle and you need to do a whole bunch of these different things.
00:14:36.604 - 00:15:20.724, Speaker B: If those kind of things are broken, then that can break some downstream defi smart contracts. So gas price changes need to be very carefully considered, and searching for these places where gas prices are broken is something we should definitely do. I don't know if that fits into ZKVM auditing or not, but maybe we should definitely do that, yeah. Okay, so basically if a contract or if a chain of contracts get paused, that can be really bad. That can break the liveness guarantee. If Dai got paused that would be a disaster. Or if uniswap got paused, that would be a disaster.
00:15:20.724 - 00:15:59.680, Speaker B: And that's a worst case scenario. But there's other scenarios where it's not as bad, but it's still terrible. And that's where you have like oh, I have this contract that's dependent upon Uniswap and Dai and it works on main net, but on Zkevm it doesn't work. That's another thing that we have to be super careful about. We have this. The other thing to mention is that I think that there's gas price and then there's implicit gas price. There's the explicit gas price and then there's the actual gas price that exists.
00:15:59.680 - 00:16:48.512, Speaker B: And that's maybe another thing to worry about the economics of like oh, I'm able to make this block and I'm only able to include like ten of these upholds. That means that economically the fees are going to be a bit higher for this transaction. But yeah, anyway, just be careful about the implicit gas price as well as the explicit gas price. Maybe that's a good output from the auditing to have a list of, to have a mapping of the implicit gas price to the explicit gas price. I think that that would be a really good exercise to sort of get familiar with the actual cost of these different opcodes. Cool. And the implicit gas price is broken into two pieces.
00:16:48.512 - 00:17:26.850, Speaker B: Like the first part of the implicit gas price is the prover cost and the call data gas cost. Both of those things will affect the implicit gas cost. The other major thing is that if there's a per block limit on certain hub codes, then that also imposes an implicit gas cost because you have this limited resource that you need to make a full proof for and that has overhead and things that need to be included in the implicit gas cost. But anyway, I would be really interested to see implicit gas cost numbers. The other thing is data availability. I'm getting to the end of the talk. Okay, cool.
00:17:26.850 - 00:18:33.240, Speaker B: The other thing is data availability. The idea here is that if I perform a state transition where the new state data is not known to other people, if I'm the only person who knows that new state, then I pause the system and I can demand a ransom from people in order to publish the state. I think that a lot of roll ups have these forced withdrawal mechanisms and if this data is not available, you could break the forced withdrawal mechanism. And basically, what is the claim that we want to guarantee here? And the claim here, I think, is basically data availability claim. So there's two claims here. There's data availability, which means that you publish all the correct call data that you've consumed in the block. And the second claim here is that the result of the state transition of that block is completely determined by the call data that you published.
00:18:33.240 - 00:19:17.520, Speaker B: So let me dig a little bit deeper into why completely determined is important, because if I'm able to include some random state alteration in that block, that means that no one else is going to be able to. That means that I can hide the new state. I can make it impossible for people to know what the new state is, even if it's just like one bit of difference. You're able to make multiple blocks. And after you make multiple blocks, it's going to become harder and harder for people to calculate the new state. Yeah, so data availability is a super important guarantee. And this is one thing that we've changed.
00:19:17.520 - 00:20:18.600, Speaker B: This is potentially the biggest change that's not going to go away, and that's that data availability cost is considerably different. That it used to be that optimizing smart contracts, you wanted to optimize for the computation costs, but now when you're optimizing smart contracts for optimism or for optimistic roll ups or for ZK roll ups, you end up optimizing for call data. You want to minimize the data that's published because that's the biggest cost. And that means that the gas costs of all the opcodes change considerably, that coal data becomes super expensive and everything else becomes really cheap. And that's another thing that we should be careful about when we think about the topic of gas price changes that call data. Gas prices are huge, they get a lot bigger, and the implicit amount of call data is also bounded by the layer one gas block limit. Those are the only operations that are bounded by the layer one.
00:20:18.600 - 00:20:54.772, Speaker B: And that's another super important thing to be careful about and to think about. Okay, so that's the end of what I've prepared to talk about. Let me go through the conclusions. So there's a bunch of things we want to be careful about. And it's not just about the EVM's assumptions and verifying things that the ZKVM matches the EVM. I find that when I'm auditing things, it's always at the interface of systems where we find issues. And here we have the interface of three different systems built by different people.
00:20:54.772 - 00:21:25.804, Speaker B: Who didn't talk to each other and are like just random people on the Internet. In some cases, it's solidity developers, the solidity compiler developers, and the ZKeVM developers. And if the ZKVM is broken and the EVM is broken, that's good. If a certain smart contract is broken in the ZKVM and the EVM, that's good. If it's broken in the EVM and not in the ZKVM, that's a validity issue. Right. And if it's broken in the ZKVM and not an EVM, that's bad.
00:21:25.804 - 00:21:52.084, Speaker B: That's a liveness issue. Yeah. So there's a bunch of things to be careful about. I would focus on the place where the three systems meet where solidity developers are assuming something about solidity. Solidity is assuming something about the EVM, and the ZkAVm doesn't satisfy that assumption. That would be where I would focus my. So, okay, that's the end of my talk.
00:21:52.084 - 00:21:55.290, Speaker B: I got some time for questions now if people want to ask me about stuff.
00:22:12.270 - 00:22:19.770, Speaker D: Do you know of anything in particular that is not well specified in the yellow paper or that's different in practice?
00:22:22.690 - 00:22:31.230, Speaker B: Okay, so you're talking about differences between the EVM and the ZKVM?
00:22:32.290 - 00:22:40.180, Speaker D: No, the main net EVM. Is that something that, you know, that's not clear in the yellow paper?
00:22:41.510 - 00:23:17.518, Speaker B: I think that the yellow paper is quite difficult to understand. I think there's a whole bunch. It's formal, and I also think it's a little bit out of date with the current EVM. And it's definitely out of date with the current ZK EVM because the ZkVM doesn't include 1559 and things like that. But yeah, the liddity yellow paper is just quite difficult to understand. And I think that the place that I would check is like the newer things because I think it hasn't been. People have tried to keep it up to date, but it's quite difficult to keep it up to date.
00:23:17.518 - 00:23:31.220, Speaker B: So I would say the newer hard forks and opcodes and things will be like one place to check. And just in general, just be careful about the yellow paper. It's quite difficult to understand.
00:23:32.710 - 00:23:39.400, Speaker D: I'm glad it's not just me, but. Yeah, good point about the newer stuff.
00:23:42.170 - 00:24:51.600, Speaker B: Okay, so got another question in the chat from Mikhail. What if the EVM is fixed change broken after ZkVM was deployed? If a bug in EVM will be rebased as feature after discovery? Okay, so this is basically a question about, okay, what if there's some zero day or issue in EVM? Will the ZkevM will be updated to include a fix for this book? I don't know. That's a good question. And that touches on should we have upgradability features at all? Should the ZkVM be constant without changes? And that's a hard thing to think about. What I think is the best way to make secure evms will be, or to secure roll ups will be to have multiple different ways of proving fraud. So you could have like two different validity proofs, and you could have two different fraud proofs, and we could have all of these working on chain, and then users can just do whatever. Then if there's a bug in the EVM, we would need to update these four different things.
00:24:51.600 - 00:26:12.624, Speaker B: I'm not crazy about having an upgradability feature, especially in long note, because all upgradability features allow you to also just steal all the money, which is not good. Yeah, I don't know. I think that there are things that we could do having upgradability features, like having a very long delay and allowing users to withdraw, but it doesn't really give you the same, like being able to withdraw is you're still losing stuff. Like if there's contracts deployed and network effect and stuff, it's really hard to upgrade those or to withdraw those. But anyway, I think that there's definitely certain class of places where we would have to do an upgrade, and I don't know exactly how we would go about doing that. I hope that's helpful. I guess one thing I was looking.
00:26:12.662 - 00:26:44.532, Speaker E: For was more precision when it comes to the attack model here or the attacker model. That strikes me that you want to support everybody who is able to produce EVM pipe code of any sort of valid shape. It doesn't have to have gone through the solidity compiler, if I understand this right, firstly. Secondly, sort of deviations I think you're talking about here effectively focus on runtime deviations under any input, if I'm not mistaken.
00:26:44.596 - 00:26:44.872, Speaker B: Right.
00:26:44.926 - 00:26:56.344, Speaker E: So in principle, there are different ways to test for that, with or without relying on commonly deployed smart contracts, let's say. So can you just try to focusing.
00:26:56.392 - 00:26:57.224, Speaker B: On the attacker model?
00:26:57.282 - 00:27:00.130, Speaker E: Can you try to summarize that a little bit?
00:27:01.380 - 00:27:08.096, Speaker B: Sure. Okay. Yeah. Because it seems like in principle you.
00:27:08.118 - 00:27:13.250, Speaker E: Could have multiple attacker models too, but I think it's helpful to spell it out.
00:27:15.560 - 00:28:01.570, Speaker B: Okay. So I think it's easier to have multiple attacker models. I think that there's the attacker who wants to break a contract that's deployed, there's an attacker who's focusing on a solidity contract that's deployed on ZKVM and the attacker is using their knowledge of solidity and EVM. And the difference between EVM and ZKVM in order to break that contract, that's one. There's an attacker who's trying to break the liveness of the ZKVM and basically they're able to make any bytecode they want and deploy it. The attacker in the first case is also able to do that. They don't have to go through the civilian compiler either.
00:28:01.570 - 00:28:19.530, Speaker B: Yeah, this is a really hard question because it's very broad, like what I'm talking about here. I'm talking about a whole bunch of different attacker models and what other ones do we have? There's someone who's trying to hack the. Is this useful? Am I answering your question correctly here or.
00:28:20.380 - 00:28:24.232, Speaker E: Yeah, I think you're partially answering my question because to my mind.
00:28:24.286 - 00:28:24.504, Speaker B: Right.
00:28:24.542 - 00:28:34.248, Speaker E: So the differentiation between bytecode level versus solidity, language level is probably somewhat helpful, I suppose.
00:28:34.344 - 00:28:34.604, Speaker B: Right.
00:28:34.642 - 00:28:45.936, Speaker E: I mean, in a practical sense, you can have attackers who are crafting bytecode sequences, as it happens in other domains, or you can have people who just come up with smallish programs that they.
00:28:45.958 - 00:28:47.664, Speaker F: Run through the compiler and then for.
00:28:47.702 - 00:28:53.860, Speaker E: Differences or what have you. Right. At least those probably should be separate, that's what I'm guessing.
00:28:54.600 - 00:28:56.950, Speaker B: Right, yeah, that makes sense.
00:28:59.240 - 00:29:09.780, Speaker E: But the differences, I think you might be mixing up things a little bit here, like in terms of teasing out the differences. I guess you're relying on different. Under an input.
00:29:09.860 - 00:29:10.490, Speaker D: Right.
00:29:11.260 - 00:29:28.300, Speaker E: There exists an input under which you can sort of have any of the three things you have on the slide, but that's sort of how you attack problems. That's your oracle.
00:29:30.180 - 00:29:59.880, Speaker B: Yeah, I'm definitely mixing up a lot of things here. In general, I think the scope of the attack surface here is really broad and that's why I'm just talking about many things at once. Maybe, but I think that. Let me answer the grace, am I finished time here? Should I answer the rest of the questions in the chat?
00:30:00.860 - 00:30:08.750, Speaker C: Oh sure, just a few minutes. We have a schedule after 730, but that's good. We're good.
00:30:10.560 - 00:30:13.950, Speaker B: Okay, so good to keep going or good to finish?
00:30:15.120 - 00:30:16.556, Speaker C: Good to keep going.
00:30:16.738 - 00:30:17.870, Speaker B: Okay, cool.
00:30:21.540 - 00:30:54.810, Speaker F: I have some comments, questions to, well, first some clarifications. In the case of polygon, for example, we don't have a deep limitation in the storage. Storage is a processor, so it can be as deep as you want. What's limited is the total number of hashes that the storage can do in the proof. But we don't have this limitation. So that's something that's good on that.
00:30:55.920 - 00:31:04.590, Speaker B: The limitation on the depth also enforces an implicit limitation on the overall number of storage accesses that you can do.
00:31:06.640 - 00:31:08.290, Speaker F: Overall. Exactly. Yeah.
00:31:09.460 - 00:31:09.824, Speaker B: Here.
00:31:09.862 - 00:31:54.620, Speaker F: The thing is that, of course, there is also always this limit. The question is that if this limit is, let's say, reasonably high, this will not affect only really pathetic smart contracts or smart contracts that are really bad. But in any case, this is lock in. So you can maybe imagine that you can. Well, actually, you can do that in the patricia tree, because you calculate the ketchup, and then you just try to calculate many, like a banishing place, and you can try to make a branch very deep so that the clients have to access more databases. But this is lock.
00:31:56.400 - 00:32:30.970, Speaker B: Wait, hold on. This is somewhere where it's different, because with the MPT, the depth of the tree is dynamic. And one of the assumptions that the MPT lets you make is. MPT stands for merkel Patricia tree. It's the storage tree that's used in the EVM. It allows you to assume that the depth of the tree is going to be less than this number because it's randomly assigned, and the depth of each branch is never going to grow longer than this without a whole bunch of computational work. And this is one thing that's different.
00:32:30.970 - 00:32:42.590, Speaker B: That's a potential assumption that solidity could be making and that the gas price calculations could be making, and that other implementations are now making.
00:32:44.720 - 00:32:59.410, Speaker F: The implementation or implementation. The path is hash. Well, it's hash, so you can go deep, but limited to some levels. Right.
00:33:00.820 - 00:33:03.250, Speaker B: And the depth is unlimited, is that correct?
00:33:03.940 - 00:33:15.520, Speaker F: The depth is unlimited, yeah. But you need to find. Well, it's limited by the hash. It's 256 bits. But if you get to the 256 bit, it means that you have collisions in the hash.
00:33:15.680 - 00:33:16.532, Speaker B: Yeah, right.
00:33:16.666 - 00:33:17.510, Speaker F: Which is.
00:33:19.660 - 00:33:23.560, Speaker B: Right. You can definitely grow your tree faster than you can grow the MPT.
00:33:26.140 - 00:33:58.244, Speaker F: You can grow. It's owner cases again, for spasmica tree, which is similar to Patricia tree, but it's like you are limited. So you can maybe make some leaf at a specific point that's a little bit more expensive. But that means that I will put you some numbers for the depth you need. Imagine that you go very deep, and you go to 100 bits. 100 bits of hash. Okay, so bitcoin doesn't have that.
00:33:58.244 - 00:34:22.380, Speaker F: Okay, so you go there. So that means that there are 100 levels. If we can do in the full system, we can do more than a million of levels. Well, you can hack it, you can make it worse, but it's going to be really difficult to reach the limit.
00:34:25.600 - 00:34:56.760, Speaker B: Okay, that's fun. I think that the other major different assumption here is with the snark friendly hash function. This is something that I would want to be careful about here too, but I guess the randomness doesn't really affect. Wait, it's a spice marker tree. So the randomness would affect the like, do you use ketchek for finding the address or do you use something snark friendly?
00:34:57.340 - 00:35:16.190, Speaker F: Well, we use a snark friendly for the tree structure itself, but solidity. So for the smart contracts, they are using ketchup to find, in general, solidity use the catch act to find the storage plates. So actually in the case of solidity, it's both.
00:35:20.480 - 00:35:23.010, Speaker B: I think that makes me feel a little bit better.
00:35:24.100 - 00:35:25.264, Speaker F: Yeah, this is one thing.
00:35:25.302 - 00:35:26.290, Speaker E: The other is.
00:35:31.630 - 00:36:02.194, Speaker F: Should I continue? I have more things, but it's okay here. The famous question of the time lock to bootstrap will have some way of updating the smart contracts for sure. I think it's a security issue. This should be but here defining the rules. I think that Vitalik make a good point in the last article defining some acceptable rules there. But this is a debate that we can have. I want to be decentralized, but I also want to be safe.
00:36:02.194 - 00:36:34.078, Speaker F: And if there is something wrong in the smart contract, be able to do something at some point. This is something that we. Gas model, we are using gas model of ethereum plus. So this is for the explicit, but then we have the implicit, the implicit are what we call the CK counters. It's these resources, these limit resources. In the proverb, these limit resources should be reasonably high for normal cases. But yeah, this is something that we need to check and see all the edge cases and very interesting.
00:36:34.078 - 00:36:49.846, Speaker F: The point that these are smart contracts that my concern is not in the explicit gas, it's more in the implicit gas that smart contracts that can change these things. Interesting point here.
00:36:50.028 - 00:36:58.120, Speaker B: Me too, Jordy. One thing to mention there is that the other place where you definitely have implicit gas changes is the call data gas cost.
00:37:01.790 - 00:37:31.122, Speaker F: The problem is that the data cost. So the idea is that the data cost is the same in layer one and L2. That's it. That's the point. If you are doing L2 is because you want to have a better gas cost, but you cannot charge the same for the gas cost in L2. The real cost is the same. Other thing is what you charge here.
00:37:31.122 - 00:37:45.800, Speaker F: Statistically it's okay, because one thing compensates the other. But an abuse of that availability is something that the system you can break somehow. The system.
00:37:49.850 - 00:38:02.490, Speaker B: Also implies a different gas block limit for call data, right. Because that limit is defined by the layer one gas, whereas all the other gas block limits is defined by the L2 gas.
00:38:03.890 - 00:38:44.934, Speaker F: Yeah. One of the things that in order to prove, to prove is that in the smart contract of the roll up, we guarantee that the quantity of data is limited because we need to prove. Our constraint or idea is that you put some data, and even if it's random data, you should be able to generate a proof. Maybe it's a proof that this data goes nowhere. So that doesn't change the state. It's just no pressure. But the proof should be always able to prove that whatever data you are putting there, it can be random data, it can be transactions with a wrong nons, transactions with a valid or invalid signature, transactions with a wrong other p format.
00:38:44.934 - 00:38:54.190, Speaker F: Or you can put any data and the prover should be able to prove that this data has a state transition. So you should be able to build the proof.
00:38:57.730 - 00:39:04.030, Speaker B: So you're not only proving that the EVM is compatible with something, you're also making proofs that this is incompatible.
00:39:05.170 - 00:39:40.970, Speaker F: Exactly. And this is very important for what we call forced transactions, force transactions. It's a L2 transaction that the user can put in layer one and then the sequencer is forced to include these transactions. This transaction can be anything. In general, it's going to be a withdraw because you are probably blocking him. But it can be any transaction there and it can be something that's wrong. So you should be able to process that.
00:39:40.970 - 00:39:56.602, Speaker F: Okay, so that's one of the hardest points that we have in the system. And this is hard. This is the things that I'm a little bit scared on these forced transactions. But we need that for the forced transactions because you want to censorship resistant.
00:39:56.746 - 00:40:12.200, Speaker B: In this case, that's a whole other audit. That's a whole other set of scope. That's not EVM. That's like a super set of the EVM. That's EVM plus a whole bunch of other things. Yeah, that's big.
00:40:13.370 - 00:40:53.614, Speaker F: Yeah, well, that's the thing here. Well, you call validity in the second part. So validation, in our case, we do it by running the is for us. So we warranty that the EVM is doing what's supposed to do, because we are passing the tetherium test, or at least most of the tetherium tests, this is how we guarantee somehow the validity. Of course, there are some exceptions and things, and it's not that easy, but that's a good starting point, at least. And the critical part is the Solness is the one that you sense, actually, it's like when you have a transaction, it can happen. Three things is that you can generate one proof, and only one proof to be valid.
00:40:53.614 - 00:41:32.346, Speaker F: So that's one new estate valid. Another bad thing is that you can generate two different valid estates. So you have the same transactions, and you process one way, and you generate one state, you process one other way, you generate another state. Here. The way that we are protecting this against that is that in the smart contract, if two proofs appears that goes to different states, then the system is halted somehow. So that's something that's wrong in there. But there is another case, and it's the case where there is some data that you cannot generate a proof.
00:41:32.346 - 00:42:16.254, Speaker F: There is some constraints that it's okay. This is this transaction, and it's impossible to generate a new proof that goes from this estate to this new state. At this point, you have to upgrade. So it's bad, but not the worst. You just upgrade the smart contract. Maybe you need to wait a month, but funds are not going to be lost, maybe are going to be stopped, which is bad, but it's much worse if you just lose the funds. Yeah, these are the three things, the three kind of errors that three kinds of concerns that I have.
00:42:16.254 - 00:42:59.434, Speaker F: The worst thing is the validity is that you can generate only a single proof, but this proof is valid. It's a new estate, but this estate has a lot of money in my pocket. Okay, so that would be the worst case scenario, when you can generate only one proof, and this proof is wrong. It's not valid. But I think that this, with the test and good audit, it should be. I'm not going to say easy, but at least much more easy to audit this part than the other two parts. Yeah, that's what the comments that I wanted to make.
00:42:59.434 - 00:43:00.780, Speaker F: Sorry for.
00:43:02.690 - 00:43:03.950, Speaker B: Thanks, Jordi.
00:43:08.610 - 00:43:15.490, Speaker C: Well, that brings him nicely into his talk, I guess. Jordy, you can take the stage.
00:43:16.230 - 00:44:15.790, Speaker F: Yeah, maybe I can continue. Maybe I will pass the word to Jose. Jose is going to explain a little bit, what's the criteria for designing the system. Jose, maybe you want to share your screen and have the stage. But while you are sharing the screen, just want to say that the idea of the system, or our system, one of the designs of our system is the modularity. So the idea is that we can split the things between the rhythmic JSON and the functionality, the assembly code on top of that, so that there is many people working in parallel in the same way. And this also should benefit a lot, the auditing, because the pieces are relatively.
00:44:15.790 - 00:44:25.960, Speaker F: There are a lot of pieces, but each piece is relatively small. So this should be handable altogether. But Jose, maybe you can start.
00:44:26.490 - 00:45:06.942, Speaker G: Okay, nice. Thank you for the introduction. I'm going to go very quick about the approach that we are following to build the Zika Vm. You know, that we can follow like a circuit based approach or state machine approach. Our solution is mainly based on the state machine approach, and each of these has pros and cons. You can see the secret, essentially is a set of connected gates, while state machine is a sequence of states in which, in a pure state machine, we have relationships between consecutive States. Regarding performance.
00:45:06.942 - 00:46:04.674, Speaker G: The main thing that you need to see is all these are just a matrix of values, and you need to see how many columns, how many polynomials do you have, and which is the size of these polynomials in the number of values. And we've been seeing in these sessions about different state machines. We talk about the Fibonacci state machine, and remember that we have all these relationships between values of the same state and the next state. And we also care about this cyclic behavior in a secret approach. Well, secrets are very nice to build computations that are very expressive. For example, this circuit, we can have in a different stage of the computations. We can have just the amount of gates that we need to express our computation.
00:46:04.674 - 00:47:01.046, Speaker G: This is a good thing. And then in a circuit, we can have complex relationships connecting these gates. Finally, all this is translated, by the way, this is the arithmetication of plunk. This is translated in a matrix also. So again, we have here this matrix with columns that are constant and columns that are part of the values of the circuit, which is the witness of the circuit. Then let's see, which lessons do we learn from these models? We must say that the Zika Vm from polygon is a kind of hybrid system. In the pure circuit model, gates that are used at each state of the computation can be very tailored to the computation.
00:47:01.046 - 00:47:39.378, Speaker G: I mean, you don't need to use more stuff than you need. In general, there are like, complex relationships between non consecutive stages. And then we don't need to assure any cyclic behavior, because essentially the computation goes forward. Okay. In a pure state machine, I'm talking here about pure, because I think that all the projects, in fact, are building some kind of hybrid thing. In a pure state machine, the relationships are between consecutive estates, as I said. And we need to assure this secret behavior.
00:47:39.378 - 00:49:14.930, Speaker G: And the main problem that state machines have is that you may end using, having many columns that are not really used in the computation, because in the state machine, the state always has the same amount of columns. So maybe you are not using some of these columns, okay? But when state machines really shine, and they are very useful, is when the computation involves some kind of branches, you do one thing or the order, depending on some value there is, when we find that state machines behave better in this case than pure circuits. And the reason is this, because imagine a circuit that we have two possible computations. Here I have like a multiplicative Fibonacci on the upper branch, and in the lower branch I have an additive Fibonacci series. But finally, I'm using only one of these computations, depending on this e zero. So here, most of the time I'm wasting, I'm computing one of the branches and all the computation, all the values in the witness will be not really used. Okay? So in the state machine model, we can create the concept of an if and a jump without wasting as many resources.
00:49:14.930 - 00:50:53.490, Speaker G: And essentially we are going to read if we have jumps or not from this assembly. And the idea is to change from one state to the next one according to instructions, okay? This is the approach of polygon, among others. And then to manage jumps, we also introduce some program counters and we jump to the correct instruction, and we find that in this way, the execution trace of the state machine is only computing really useful values. Okay? And this is why the main model for the main computation is in fact a state machine. It doesn't mean that we are not thinking in mixing this with other possibilities, but the main computation is based on a state machine. But as I said, the main problem is that if we build a huge matrix with a lot of columns, probably we're going to end with, in many states, we are going to end with a lot of values that are not really meaningful, and we are just nullifying them in some way. So the other big idea when building, or the lesson that we learned when building the Zika ABM, the polygon Zika Vm, was to in fact split the computation in different execution traces.
00:50:53.490 - 00:52:42.680, Speaker G: And then each state machine, each processor, each executor, if you remember our talk about the Fiberacci state machine, each executor is creating a particular piece of the execution trace with the correct columns for the computation that this state machine is doing. And then we have the specific pill that is enforcing the identities or the relationships that this trace must fulfill. And finally, we are building an architecture in which we have several microprocessors or microstructures. Each of them is devoted to compute some part of the processing of the Ethereum transaction, and then we are connecting them. And then in one processor, if you remember the talk of Jordy on the first day, he said that we have like free inputs, we have values that you can put on the mainstream machine without any validation, because the validity of these values is going to be achieved in this secondary processor. And then we do lookups to assure that this is fulfilled. I would say that this structure, with different processors trying to use the correct, or try to use the best approach, the best model for each computation, and so on, I think is what we have learned as we have developed the IBM and with a great vision, I must say, from Jordy, with great intuitions about which were the best ones.
00:52:42.680 - 00:52:48.760, Speaker G: I don't know, Jordy, if you want to complete a little bit, what we have learned also here.
00:52:51.790 - 00:53:35.622, Speaker F: Yeah, many things. Well, we learned, one of the things that was interesting was the step to godilocks. Godilocks just reduced all the winners computation from 256 to 64 bits. That means that even if we have, for example, actually we have around 650 polynomials, but they are 64 bits. So if you compare, for example, with 256 bits, then it's like having 150 polynomials altogether. Okay, the execution, the windows computation execution is really fast. The other point maybe, right?
00:53:35.756 - 00:53:37.682, Speaker G: I mean, among other things, it reduces.
00:53:37.746 - 00:54:24.758, Speaker F: Quite a lot, reduces the Ram. The execution is also the other thing. The other is more subtle, but the fact of using state machines, specialized state machines, state machines, that they just do very strict things. So a concrete thing. Well, this has a lot of advantages. The first is that one of the advantages is, for example, the parallelization of them. So because the state machine is doing just a specific thing, and a lot of times it's doing the same thing, many times you can paralyze this quite well in general.
00:54:24.758 - 00:55:10.750, Speaker F: So that's the point, because that's the thing. The second is the number of constraints. This is because we put all the logic, all the complex part of the logic in the assembly. The number of constraints of the system, the polynomial identities, is quite small. So we are talking with, I don't know, it's like something like 200 polynomial constraints or 300 polynomial. It's a little bit more, but in any case, it's a little bit more. It's a listed number of polynomials, but it's a relatively small number, because in the meditation, it's just a processor.
00:55:10.750 - 00:56:24.800, Speaker F: We don't care what's running on top of that, it's just a processor. So this is a good learning. The quantity of lines of code that you need to audit in the imitation, which is the pill, is this language that we build for, that is relatively small and concrete. And the other thing that's important is that the pill only affects the soundness. So the pill don't really affect, or doesn't affect very much in the validity part, because at the end, it's a processor, processor, you need to check that the processor is doing what's supposed to do. But the processor is very simple. So it's very easy to verify that this modularity that, as I mentioned, having a language specific language is abstraction of making a language for imitation, and another abstraction of making a language for building the ZKBM itself, the assembly that's building on top.
00:56:24.800 - 00:57:33.010, Speaker F: This simplified a lot, the development, because we can have specialized people working in these tools. Of course, this requires some investment in tooling, but this is mainly what we have been doing. So all the Tooling for debugging, for checking, for seeing the values, all this is splited. So it has been very helpful to divide the work, divide the work inside our team. But this should also help a lot in divide the work between the auditors. An auditor can focus in the arithmetization of the ketchup same machine, or the arithmetic of the Arith, or a procedure that's computing the CDSA in the ROM, or a procedure that's computing the mall boot of code in the ROM, or the procedure that's parsing the RLP. So you can really split the pieces and focus in auditing this way.
00:57:33.010 - 00:58:16.886, Speaker F: Okay, so these are the main topics I want to share here. My biggest concern, the biggest concern, especially for the soundness, I already told you how we are mitigating this soundness. Okay. The soundness is that. The thing is that at the beginning you will publish a proof in the system, but this proof will not be usable until sometime mode. So that there is time for a good proverb that's generating a valid proof, and a different proof, so that it will help the system and the system, so the money will not be withdrawing, this is whole. But the soness is the most difficult part to warranty and to audit.
00:58:16.886 - 00:59:01.306, Speaker F: And we need to have this soness in order to reduce this time, actually to remove this time. In the best case, if we have the warranty that the soness is good, but just for you to think about. If you remove all the polynomial constraints, you will be able to generate a valid proof. The problem is that you will be able to generate many valid proofs that goes to different ways, but the good one, you will always be able to generate the good one. So that's one of the point. And here for the biggest concern probably, is that the assembly language is okay. The processor is not like a standard processor.
00:59:01.306 - 01:00:02.878, Speaker F: It's a processor that's a little bit different of the standard processors. And they have some explicit things that are unique to the ZK. Actually, it's a processor that's not computing things, it's a processor that's checking things. The way it works in general is that all the data that the processor use, you can freely put, anybody can put, and then you are just checking that this data that you put is okay, it's valid. So this processor does not multiply, but this processor checks that multiplication is done the right way. This processor doesn't read values from the memory, but this processor checks that the value that you propose to the system is actually in the right place in the memory. Okay? So it's more about checking than about computing.
01:00:02.878 - 01:01:07.234, Speaker F: And this differential, this differential way, you need to change a little bit your mind in the way you write the programs or the way you audit and you check the programs, okay? And this is probably the most difficult part that we need to get used to, that is learning a new language. We did it in the team. It's a really new language. But this is probably, as we say, this is the most difficult part. And yeah, this, I just want to mention, for example, one of the bags that we already found, maybe, Jose, you can comment, but for example, in the sparse mercury, there is an assumption that I think that when you are emptying some edge cases and you are emptying, you need to do some extra validations. You need to be sure that when you are removing one value from the sparse mercury tree, then this value must exist in the system. So we didn't check that this value didn't exist.
01:01:07.234 - 01:01:58.626, Speaker F: So this could be a vulnerability. So it's very much about checking everything and being sure that you don't miss anything. One of the tricks here is that if you check the ROM and you go to the ROM, you will see a lot of dollars, each dollar in the ROM. That means that it's a free input. Okay? And the exercise here is that you need to check for every single input that you are putting, because it can be a random input, actually, that this input, it can be only unique. And this means that going through all the code and checking that this uniqueness that you are valued, verifying that all the values that you are putting in the system are okay, this is how you warranty. This is probably one of the things that I'm more concerned.
01:01:58.626 - 01:02:50.620, Speaker F: Very interesting, all the points that Barry made here. I think that having a good documentation of all the differences between the ABM and the zig ABM is fundamental for any systems. On having all the details of all the systems here, I can mention some of them, they are very concrete. But for example, one thing that we decided is to. Well, actually it's not removed, but convert the selfless stroke in transfer all there is an AP, for example, that's already doing that. This simplifies a lot of things, because actually, and this is also something that breaks many things in the current EVM. But you can actually can deploy different smart contracts in the same address or redeploy things.
01:02:50.620 - 01:03:31.778, Speaker F: It has some logic there that with removing the census truck helps a lot of the things. This is for example, one of the changes today. We're discussing, for example, jump of a desk in the middle of call data or in the middle of some places, some checks that you need to do. Robert, we are avoiding this. There are a lot of details. So there are some details that we are just thinking if we consider, or we don't consider. Here we have Carlos.
01:03:31.778 - 01:04:08.254, Speaker F: But I think that there are very few exceptions where we are not following the full compatibility of the ABM. And in those exceptions, for example, in this case, solidity doesn't generate a code like that. So this is, for example, if you are not doing something very crazy, you will never notice a difference. The big difference, of course, is this implicit gas model. We already talked a little bit about that, but it's a must. And this is probably the biggest concern. Well, it's the biggest thing that we need to analyze.
01:04:08.254 - 01:04:34.860, Speaker F: But the thing is, for me is having documented all the differences. This is the first step, just to check that the smart contracts that we want to run on top are going to have difficulties or not. Just to finish, maybe just share a little bit. I want to put just a list of the things that needs to be audited. Let me share the screen.
01:04:38.830 - 01:04:40.118, Speaker B: I stopped.
01:04:40.214 - 01:04:46.542, Speaker F: Okay, let me see. I want to put this one, this.
01:04:46.596 - 01:04:47.200, Speaker B: One.
01:04:49.810 - 01:04:56.190, Speaker D: Just here's.
01:05:01.910 - 01:05:31.980, Speaker F: One side. We have the derived mitigation, the mitigation. This includes all the different state machines. We don't have that many, actually we have twelve state machines. Biggest one, the most difficult one, probably the paddings. One here with the pading. It's the padding for the catcher on the hashing, which goes together with the hashing once.
01:05:31.980 - 01:05:55.486, Speaker F: But the others are quite straightforward. Even the main one is quite straightforward. Probably there is one state machine that's like another processor itself. It's a full system itself is storage. The storage is a processor where you can just work with this sparse mercury. Okay. Then we have the ROM.
01:05:55.486 - 01:06:39.310, Speaker F: The ROM, while we have different pieces here is just from understanding how the assembly works and so on. So here there is a full topic of how you would strap the ROM and how you finish the ROM. And this is something specific. How you do the RP, how you do the CDSA, how you do the bootstrapping of the transactions. And then the smart contract deployment and the execution. But then you have the opcodes, the pre compiled smart contracts, counters and errors, context reverts and two chatters. These are different parts of the ROM.
01:06:39.310 - 01:07:00.546, Speaker F: But you can divide in these different pieces here. Okay, here we have also the full topic is the smart contracts. Mainly the smart contracts are two smart contracts. One is the roll up and the other is the reach. This is normal. This should be a normal smart contract audit. In this site.
01:07:00.546 - 01:07:32.606, Speaker F: Then we have all the cryptographic part. Here you have mainly the stark and the structure of the stark that we are using. We are going to publish, I don't know if it's public already, but we're going to publish just how the protocol works. Back and forth of the stack. And a special topic here is on the indulgence recursion part. We're using a lot of recursions here to validate different segments of the network. We are aggregating proof.
01:07:32.606 - 01:08:05.994, Speaker F: So this is an important topic that needs to be checked here. Okay. And finally, there is a miscellaneous thing that there are things this should not affect a lot, the security. But it's good to take a look. Maybe at the node, the sequencer, the aggregator, the breach, the wallet. And there are different pieces in the system that maybe if the sequencer is using a private key, then this private key needs to be protected. Something that at some point needs to be checked.
01:08:05.994 - 01:08:39.482, Speaker F: Okay, here the way that the plan that we have here is that we are planning to freeze all the code. Let's see if during December. Let's see if it can be a beginning of December. Maybe it's mid December. They're just a stop of a current development developing on that we are going to genesis the network in one, two weeks. We'll include in the test net of the aggregator, the aggregator part. And then we are going to fritz everything.
01:08:39.482 - 01:09:03.034, Speaker F: So we're going to fit everything there and we are going to focus very much in the auditing and taking a look on that. Okay. So that's a little bit the planning that we have and the learnings and the status. That's very much what we have until here. Testnet.
01:09:03.082 - 01:09:03.502, Speaker C: Thank you.
01:09:03.556 - 01:09:41.822, Speaker F: Maybe I want to just check, just say that the testnet has been running quite well. We generated more than 10,000 proofs since we started. Yeah, probably many has not stopped it. So it has just been working very well. And the grade of compatibility that we are getting is quite good. We need to improve a little bit the performance of the sequencer. We are working hard on that front.
01:09:41.822 - 01:09:59.860, Speaker F: That's probably the biggest thing that we have currently. And yeah, let's see if we add this aggregator, but it's working quite well. So thank you grace. I don't know if you.
01:10:03.350 - 01:10:26.634, Speaker C: Yeah, maybe we can ask if there's a question. Otherwise we are running a bit late, 15 13 minutes late. Maybe we can take one question and then continue if we don't have any questions. I have a question if we have time otherwise I can ask it in the chat. No, it's okay. You can ask. I think we have one for one question.
01:10:26.634 - 01:10:54.066, Speaker C: Okay, so you're doing that. One of the biggest threats is actually sound miss bugs. So can you provide an explicit example of what can go wrong? For example in which component there might be a bug and how an attacker could exploit, for example if the arithmetization somewhere is wrong, which component will be the bad one and how someone will.
01:10:54.088 - 01:10:55.620, Speaker D: Be able to exploit that.
01:10:57.430 - 01:10:57.842, Speaker B: Yeah.
01:10:57.896 - 01:11:36.462, Speaker F: Mainly from that imitation perspective is that you forget some constraint in the pillow. So that's the typical thing. Okay. But in the wrong part, for example, let me put you an explicit example. Imagine that you are doing a division. We don't have an arithmetic state machine that computes divisions, that checks divisions, but we have a same machine that checks multiplications. So actually what you do is you put a free input, you put the result of the division and then you just check that the result of the division times the quotient is the dividend.
01:11:36.462 - 01:12:05.638, Speaker F: Okay. If you don't do this check. So actually if in the ROM you don't put this check actually so I can put the result of the division any value that I want. And this would, maybe we just translate in going to a different state on the system and this would be problematic. Yeah, this is a simple example. This is a simple example. But it's full of examples.
01:12:05.638 - 01:12:16.254, Speaker F: Yeah, actually the ROM is full of, if you see, every time you see a dollar, it means that there is something you need to check. And it's very easy to forget something.
01:12:16.452 - 01:12:32.174, Speaker C: So that's one part of the question, and the other one is how someone could exploit that. For example, is it possible to give malformed traces that has, what you mentioned like that, the result of a division.
01:12:32.222 - 01:12:35.860, Speaker D: It'S different than the correct one.
01:12:36.730 - 01:13:24.740, Speaker F: Yeah, but you need to check the particular thing. But imagine that here for an example, I just explained the addition, but I explained that addition. But for an addition, it could be exactly the same, or the subtraction. So imagine that I'm doing a transaction, and when I'm doing a transfer of a value, I'm just putting that, and I need to subtract my balance. So if I don't check that the balance, that the subtraction is valid, I could put that five minus three equals 25, and then I just save in my balance 25. So I could exploit this by incrementing my balance in the wrong way, because I didn't check that the result of a division is correct.
01:13:25.830 - 01:13:29.206, Speaker D: Okay. Yeah, makes sense. Thank you.
01:13:29.308 - 01:13:38.120, Speaker F: That's an example. But you can do very crazy things if you have this soundness problem.
01:13:39.610 - 01:13:40.360, Speaker B: Thanks.
01:13:42.170 - 01:13:49.930, Speaker C: Thank you. Thank you, Jordy. I think we have time for now. Hand is over to.
01:13:50.750 - 01:13:54.366, Speaker D: Thank you. Hello.
01:13:54.548 - 01:14:47.710, Speaker H: I'll share my screen. Can you see my screen? Yes. Okay, so I will start. I think my talk will be brief. So I will talk about two different topics. The first one is the challenge API, which is something that we introduced in our hello to fork. And it's a trick that we use as an optimization for the circuits.
01:14:47.710 - 01:15:48.510, Speaker H: And the other topic I will talk about is that we have a simplified implementations of our circuits that we somehow put in the scope of our specs, and they are written in Python. So let's start. So, in the original Halo two proving system, all the advice columns are committed together in one phase. And here the advice columns is how Halo two, it's the name that Halo two gives to the witness. So this would be the values in the polynomial commitments. And with the challenge API, what we can do is split these advice columns into different phases. And in each phase we commit only the set of witnesses that belong to that phase.
01:15:48.510 - 01:16:40.702, Speaker H: Then between those phases, the proverb can request challenges. So that's a random value from the verifier, and these challenges can be used in the constraint. So these challenges are exposed to the circuit, and the way we turn this into a non interactive is as always, using phamier. So here is a small diagram of how it would work. And basically the only thing that we need to concern on the API level is to define which columns or which witnesses belong to each phase. And then how many times we want to query challenges from the verifier at each phase. And then the proverb and the verifier will reply this and get the same challenge.
01:16:40.702 - 01:16:42.610, Speaker H: And they will use this challenge.
01:16:44.470 - 01:16:44.834, Speaker B: For.
01:16:44.872 - 01:17:29.810, Speaker H: The proof generation and proof verification. And then the approver is able to use these challenges in the constraints. So now let's see where we use this. So in general, we use this challenge API to compress values that don't fit in the field by using random linear combination. So for example, the APM word is 256 bits and we are using a field that is around 253 55 bits. So an EVM word doesn't fit. So one way we could solve this issue is by splitting the word into high and low values.
01:17:29.810 - 01:18:07.302, Speaker H: But that already has some issues because you need to do a range check on each of those. So maybe you need extra stuff. So what we do is following this challenge API. On the first phase we would commit 32 eight bit values which would be constrained to be between zero and 255. There is a typo here, so we know that we constrain these values to be bytes. Then we get a challenge. We commit the word in RLC.
01:18:07.302 - 01:18:52.250, Speaker H: RLC stands for random linear combination. And then we constrain that this WRLC is equal to the random combination of these bytes. So with this we now have a value which will be in a particular witness in a column of the second phase. And with this value we can do equality and inequality checks of words just using one value. So for instance, if we have lookup tables that contain words, we can check if a word is in the table or not. And just taking one column in the lookup table. So that's one case, and the other case is for dynamic length byte arrays.
01:18:52.250 - 01:19:54.426, Speaker H: So in general, if we have dynamic length by the rate and we want to do a lookup using that array, we would mostly need to split that into several lookups. But with the RLC, what we can do is similar to before. But now instead of taking 32 values, we take n eight bit values, we commit them all. Then we get the challenge. Then we commit the RLC of this array, and then we add the constraint to force that this array RLC is equal to the random linear combination of its bytes. And with this again we can do equality or inequality checks of this array just using one value, and it doesn't matter how big the array was. And we use this trick to verify catch ups.
01:19:54.426 - 01:21:02.630, Speaker H: So what this allows us is that we have an array that we want to hash and instead of maybe doing one lookup per catch f. So that's the function that runs iteratively and keeps absorbing a list of bytes. We can take all the bytes and calculate the RLC, and then with a single lookup we're able to match this byte array from one place to another. And in this case the lookup would be a table that contains the result of the verification of the ketchup verification. Yeah, we actually, for this case we also want to look up the size of the array, because if you have arrays where all the bytes are zeros, different length arrays will result into a random linear combination that is zero. So you need to distinguish them. So we also add the length to the lookup.
01:21:02.630 - 01:22:19.258, Speaker H: So some final notes on this challenge API is that we are adding some complexity to the proving system, and in turn we get this optimization where we can get equality checks or inequality checks with one value. And the downside of this challenge API is that it makes it more difficult to split circuits or proofs if we have different circuits and we want to calculate different proofs for each circuit and then aggregate them. If these circuits are doing lookups from one to the other, and they are using RLC, they require the randomness to match. So these circuits need to commit, then derive a challenge that is the same for both circuits and then use this challenge with witness of a second phase. So it makes it hard to split circuits. And we have some ideas on how to do that, but it's a bit tricky. So this is the first topic.
01:22:19.258 - 01:22:31.000, Speaker H: Maybe I will ask if there are some questions about this topic. I don't see that.
01:22:32.250 - 01:23:09.300, Speaker D: What's cool about the knife I read? Sorry. Yeah, what's cool about the challenge API is that we can actually re implement the lookups and multi set equality and copy equalities on top of the challenge API as a chip, and then we can remove it from the hello too. In fact, Dera also thinks it's a good idea. That's all. It's not.
01:23:11.290 - 01:24:02.906, Speaker H: So it was not a question, right? It was a comment, those comments. Okay, thank you. Okay, so if there are more questions, maybe you can ask later while I will continue. So the second topic is this Python simplified implementation that we have that I think can be useful for auditors. It's very useful for us to reveal the cirques. So on one hand, we have the cirques that in our case are written with hello two, and these can be theirs and verbose. So if you just get an implemented secret, sometimes it takes more time and effort to understand what's going on.
01:24:02.906 - 01:25:11.226, Speaker H: And then on the other side, we have the secret specification, which is much more concise and easy to follow, but we cannot play with it. And by play I mean that you have a spec that gives a list of constraints, but you cannot put some numbers and test if those constraints pass. You can do it mentally, but not automatically. So we found middle ground, and it's that we have most of our circuits implemented in a simplified way in Python. So for instance, every time we have a polynomial constraint, what we do in the Python implementation is we just use an assert on equality checks for arithmetic expressions. Whenever we would like to define a lookup, we just do an assert that a list of values or list of expressions belong to a hash table or to a list. And with this we achieve a higher level of readability.
01:25:11.226 - 01:26:14.670, Speaker H: But we can play with different inputs, test some assumptions, try to break it, iterating quickly, and here I have two examples. So this one is a snippet from our state circuit, and in this case, this circuit is modeled as the verification of the transition between one row and another. And for instance, here we can see that we have ifs. And of course, in a circuit you cannot do ifs. But the idea is that as circuit developers, we know how an if is translated to a circuit. It doesn't look as clear as an if in Python. So here we may just read an if with the understanding that we can see the match of this if and corresponding expression.
01:26:14.670 - 01:27:12.870, Speaker H: And we can do this translation very mechanically. So in this case, when we have an if with a statement, which is an expression, we just multiply the expression to the constraint, and if we have a negation, it's just one minus the expression. So in this case, for instance, we can see that just an equality to zero, we just have an assert dives is as I said here. In this case, we don't have very strict rules. We just try to make it easy to understand and give all the details so that when the circuit is implemented, the translation should be mechanical. So for instance here, this could be a range check with a polynomial expression. In this case, since it's just two values, we don't need to do a lookup.
01:27:12.870 - 01:27:56.226, Speaker H: And we even have nested ifs, which would just be applying the rule of translating an if to an expression. You can just write this into an arithmetic expression and so on. Or here there is an assert range. So we would expect to have a table with all the possible values and then do a lookup. And also, another good thing about this is that it makes it easier to test some inputs and debug constraints that don't pass, because this is Python. So if the assert fails, you will just get exactly the line and a trace of where it failed. And here is another quick example.
01:27:56.226 - 01:29:06.140, Speaker H: This is from the copy circuit, and in this case this Python simplification models the idea of having different rotations, so that from one constraint we can access three different rows. And we just model this by passing a list of rows and using indexes to access one, the first row, the second, or the third. And in this case, as I said, we are not very strict of how we model this, because the aim is to make it easy to understand. So here there is this type, which is the constraint, constraint system, which just mimics an object that outputs expression. So for instance here the condition is the same as an if it will multiply all the constraints contained within this part. Here all the constraints will be multiplied by this kind of selector. So here are some caveats about this.
01:29:06.140 - 01:30:19.860, Speaker H: Even though we have this simplified implementation, matching it with halo two is the best effort. So it requires manual checking, and usually that's been done so far with the reviewers. So all the circuits that we have written, we first write this Python version, and then we do the hello two, and it's easier to verify the correctness of the constraints in the Python version. And then for the circuit version in hello two we just need to make sure that the translation is correct. So we require manual checking, and there's no automated way to verify that both are equivalent, which would be a nice thing to have, but currently we're not working on that. And in particular we have some simplifications that go beyond translating or just to give an example, in the evm circuit, each step takes a variable number of rows. But in this Python implementation we have just modeled each step as like a single object.
01:30:19.860 - 01:30:47.950, Speaker H: So from one step you can write constraints to verify the next step, but we lose the concept of rows, and that's the end of the second part and also the end of my presentation. So if there are any questions, comments?
01:30:53.170 - 01:31:05.970, Speaker F: So one quick question about the spec. Your current spec is essentially, you can think of, it's kind of reference implementations of the circuits. So did you get a chance to identify there's any bugs in the spec?
01:31:06.040 - 01:31:11.620, Speaker B: Like why are you maintaining the code base of the Python code.
01:31:12.090 - 01:31:44.590, Speaker H: So we have identified many bugs through this Python implementation. And the process that we follow is that first we write the Python implementation and then we have a review process with our peers. And in that phase we have found a lot of bugs. Then we fix the bugs that we encounter, and then after that Python implementation is merged, then we work on the halo to circuit implementation.
01:31:45.010 - 01:31:45.920, Speaker B: I see.
01:31:49.670 - 01:32:18.090, Speaker C: I also have one quick question. I have seen that in your Python implementation you have something like unit tests for each circuit. Is it possible to actually provide something like what we can provide to the scroll ZKVM? Basically some execution traces that will run through the whole ZKVM. Is that possible to do it with the Python implementation?
01:32:18.990 - 01:32:31.310, Speaker H: No, currently not. We don't have that prepared.
01:32:32.210 - 01:32:32.862, Speaker F: Okay.
01:32:32.996 - 01:32:52.840, Speaker C: And if that was the case, then for any input that you could give in the python implementation, the final output that said that for some execution traces you can't produce a proof should be the same across the two systems, right?
01:32:53.530 - 01:32:54.280, Speaker H: Yes.
01:32:54.890 - 01:33:11.426, Speaker D: Okay, thanks. Okay, so if there's no other questions.
01:33:11.528 - 01:33:14.450, Speaker A: We can hand over to Orio.
01:33:19.910 - 01:34:24.280, Speaker D: Hi everyone. Share this. Do you see the screen? Yes, we can see a screen. All right. Yes, I would like to talk about the KVM of Scroll and PSE. So we had a big introduction already by detail from haitian over the past sessions. So this is continuation of that and for auditors.
01:34:24.280 - 01:35:32.030, Speaker D: So let's propose a mindset here. So when we design things and implement, usually we think first of completeness, but just natural. But auditors should focus almost only on sadness and avoid biases from the witness generation course, biases from the intent of it. And this sounds obvious as a generality, but when you're dealing with many things, as you can see, don't let mistake myself when you lose track of if you have seen something checked in the witness generation or was it in the circuit. So obviously, let's check in the circuit. My prop was to make checklist animates document anything that's not obvious or that's confusing, that maybe not a bug, but is dangerous. Right.
01:35:32.030 - 01:36:09.688, Speaker D: And also I find it useful to document the positive finding, meaning things that were actually checked and are correct and are good from the point of view of the auditor. And this is useful. And we have also found bugs like this based on someone sending positive findings and then someone else then like triple check. And then this leads to finding a bug. So we post as much as possible. This is always useful. And the rest of our slides, they are basically the worst kind.
01:36:09.688 - 01:36:45.924, Speaker D: So it's just a list, all the explanation about how it works. I refer to previous sessions by Haishan and V spec, python implementation, and so on. So here I'm only giving a list of pointers for inspiration. I hope to inspire. So some more generalities. You want to look at how these cells are wired or you witness. So usually a cell is a connection between what comes before and what comes after.
01:36:45.924 - 01:37:45.424, Speaker D: Normally it participates in two or more constraints by exceptions, but that should be the best case. Exceptions need to be reviewed very carefully, and it's very easy to accidentally have separate cells that are supposed to be the same one or that are supposed to be copied. And the reason for that one example is that someone writes a function and they allocate everything that they need so that the function is easy to use. But then someone else comes in, tries to use two such functions, for instance, and it looks like this is how it works, and this is the only way to use those functions without changing them. And you end up with two different sets that are not connected and they always supposed to be the same. There are things that happens even when you know it shouldn't. So check.
01:37:45.424 - 01:38:16.320, Speaker D: So that's the most obvious thing. Also easy to forget. So it has to be on every cell. If you have two cells, do not forget. So how the EVM does range check. So it's either boolean check, so simple constraints, or it's lookup bytes. So it's a table with all the 256 values of bytes, then combinations of those bytes as a sum.
01:38:16.320 - 01:39:00.992, Speaker D: And then there are also the function tables. So other functions are two bytes inputs to one byte output, and implicitly those three values are also checked. That's another way to range checks. Also the range checks, they are done a lot using simply by putting the values in the white column. So an entire column is range checked to be bytes. So just have to check that the entire column is kind of connected to its bytes lookup. Then we are checking constraints, of course.
01:39:00.992 - 01:40:12.330, Speaker D: So there is a lot of boolean logic or some arithmetic on viewing normal numbers, and check that this is done correctly, that there are no overflows and such. So again, not just completeness, but soundness. Two ways implication. And as was explained earlier, we expect everything to be deterministic. So the initial state, like the hash of these state woods, and the final state, the next hash of these state roots, that should be completely deterministic based on the data that is also on main net. There might be exceptions, there are like little pockets of nondeterminism in some places, equality checks or division and stuff, but the outcome should be completely deterministic. To go specifically in how we use hello.
01:40:12.330 - 01:40:51.990, Speaker D: So that's the mental model here we say columns, the polygon team says polynomial, that's the same. And the gates, they are applied on the entire columns, on every rows. And that's why we need selectors. So selectors vigates would be like columns. And this is a good representation here because you see that the gates, they tend to use multiple walls and also they are holes. There are some cells that are not used. That's something to know difference.
01:40:51.990 - 01:41:30.904, Speaker D: In case you learned about hello two from some other place, we use it quite differently. So in particular in VVM, these selectors, they are all dynamic. So when they are static it's easy because it's at compile time, it just has to be right there. But in VVM they are dynamic. So we have to check that first, the range of the selectors, they can be boolean or they can be multivalued. There are some places where it's zero, one or two, this sort of thing. We could say selector.
01:41:30.904 - 01:42:20.480, Speaker D: It's like the instruction of the opcode of instruction. So need to review all these ranges, need to make sure that these selectors are actually enabled. Kubernetes put some zeros everywhere, so there must be some logic there. And generally we have to think about every row and every possible combination of selectors. So when the selectors, they can be mutually exclusive and some can be independent activated at the same time. So we have to think about what happens in all cases. And again at Lu war that was generic.
01:42:20.480 - 01:43:18.634, Speaker D: Then we have a little difficulty here in this structure of the columns is that usually the data doesn't match the size of the column. So we're going to need some padding. So then you can ask, is it possible to have padding in the middle or not? What does the padding mean? Can it be misinterpreted by something else? We have another kind of padding which is for zero knowledge, which is the blinding factors. That's something we want to remove, but right now it's there and it complicates things a little. So that's something to look at about hello two. What we modified. Mostly we don't use the secret builder of hello two.
01:43:18.634 - 01:44:03.706, Speaker D: We have custom constraint builder. Each circuit has its own way with some business logic inside. So all those things that you might have learned from some other tutorials, let's say they don't really apply, but like the custom constraint builder fights a little bit with the built in lo two. So it's good to check that it swaps. We want to disable the ZK features, so for instance, there are no blinding factors in the commitments. And probably we're going to remove them in the tables as well, like those blue ones. So that will simplify things if we do it.
01:44:03.706 - 01:44:53.610, Speaker D: But just then we need to check that this was disabled correctly. Another important change is it uses the KDG polynomial commitment with the Planck multi open protocol. So this needs to be checked as well. I guess there will be scope for that and see, there is no consequences unintended in the protocol. Something about decree or anything else. Another change, the instance is given as a polynomial evaluation, not polynomial commits. But the authors made sure to still include the instance still committed just by hashing instead of polynomial commitments.
01:44:53.610 - 01:45:53.802, Speaker D: So that looks good with the reference there and the multifaceted pool that was just explained in previous talk. Besides that, then we can look at the EVM. So all these circuits, they tend to have a structure like this, where there is a start and an end and some intermediate values. So since the gates, they apply on every row, you need to really understand the logic of what makes a wall, the first one or the second one when it ends and when the next thing starts and when the padding starts. So that's initial final conditions. In the example of the process of circuit that processes instructions, its initial state and final, this is called begin block and end block. And then you have some nesting inside.
01:45:53.802 - 01:46:45.002, Speaker D: Then you have begin and end transactions and you have call can have nested calls and then return return. So need to check in the state transition that the context are managed correctly. So one way that contexts are managed is with the call id that you will find in the source code. And that must be unique. And right now we use another field which is called read white counter to generate this call id. So also need to check that this is a good idea, that it fulfills the uniqueness. And we need to check that everything like memory and storage and stack and other things, they are scoped.
01:46:45.002 - 01:47:49.390, Speaker D: So there is a scope of a transaction and there is a scope of contract call and nesting. So something to look at how this is done. Next we have the steps inside of the process also that's one cycle of the EVM. So it looks like this is what I was referring to, where you have some selector that says this is the beginning and this is continuation. And you need some counters to check the logic of how this work comes after this one and how this one comes after this one. Also these tests, they are viable size as shown on the example here. So there is some logic that from this wall here, it tries to look in which position is the next one, right? So this needs to be enforced and everything inside the state needs to be copied or updated.
01:47:49.390 - 01:48:52.838, Speaker D: For instance, the program counter must be plus one in the white wall and all the other fields of the state. And this must happen in all cases, like all oprode, all error states and whatnot. So in all cases all registers are updated. And some of these columns here in the register processor, something I mentioned, they need to be connected to lookup tables. Also check that this is all connected because you could fill this table independently and the connection to lookups happens afterwards in the way, right? First you fill the column table and then you say which ones are looking up into which columns. So check connection. And some of those cells here, they are not used.
01:48:52.838 - 01:49:44.454, Speaker D: So it's a little funny to have so many cells that are not constrained. So it's worth thinking about this. Then of course we need to look at the implementation of every of code. We need to look at the semantics of something that was also mentioned earlier. There are so many details of EVM that smart contract might rely on, just very many, and some are not obvious. So I don't know how to make a comprehensive list of all the details. For instance, maybe going through all the eips and all the yellow paper and looking for things that look funny, as they say.
01:49:44.454 - 01:50:36.546, Speaker D: If you understand funny, some examples here, then there is how lookup tables are used. So in hello two, it's intended to be static, just like the selector. And in the EVM it's all dynamic. So that means the contents of the table to be looked up, it has to be constrained, and every single cell of it has to be constrained. Otherwise that could be. Maybe it could be like a voight in the memory you can write anything you want because there are no constraints on that cell. We have found the team has found some bugs of this kind, then to check the way that the read write hazards or consistency are verified.
01:50:36.546 - 01:51:43.336, Speaker D: This involves the call id from earlier and what's called the read write counters recycle counter, basically how many operations happened. There is also support for reversible writes for when contracts revert. So go one level up in the stack and four wave changes, then a lookup table. Usually we put multiple small tables into one big column and those are isolated using tag, but that was explained in an earlier talk. So we need to check that the tags are correctly used everywhere. And we have also fixed tables, so not just dynamic and we need to check also recompile time like generation of those tables. So then something that was also mentioned already.
01:51:43.336 - 01:52:32.440, Speaker D: So basically RLC, it's a way to compress many values into one, so that the qualities and lookups are a lot cheaper. But this is very difficult to get it right, and as of now it is not. It is kind of mocked. So by the time this gets into the audit, it will be fixed, I suppose. And this needs to be verified. This is everywhere. So there needs to be a path of looking at all things that are called RLC in the code and check that they are sound in the way that was explained earlier, so that all inputs are committed correctly.
01:52:32.440 - 01:53:09.140, Speaker D: But this is very counterintuitive. I recommend to read this chapter five of Justin's book here. It explains exactly with examples of some problems when doing fiat Shamir and the multifaceted proof. So that was explained earlier is a way to do it soundly, but also it is done in hello two. In Vlocas there is already RLC inside and so it's also a good idea.
01:53:09.210 - 01:53:09.830, Speaker B: To.
01:53:12.520 - 01:54:15.428, Speaker D: Use the API that does it correctly inside. So more on Fiatromere, you need all the inputs to be hashed to be part of the instance. And the input is not just about the secret. So you cannot think only about the secret, you have to think of the entire protocol. So everything that goes into the transaction that asks mainnet smart contract to do something. So everything that's input into that which needs to be also part of the instance of a circuit needs to be committed at the beginning of the proofs and then we need to check the flow. How is this data? Is the quality between these inputs at different stages achieved then in scope, first going to be verifying the aggregation.
01:54:15.428 - 01:55:14.540, Speaker D: So which is a secret verifier in secret. This has transcript part. This must verify the gate. So there's a way to compile the gates of the EVM into an aggregator verifier and then the crypto of it. So crypto is pretty complicated because it's a non native elliptic arithmetic inside corporate suppose will be the contract verifier and how it does the transition, how it accepts, and we also not forget the supply chain of all the dependencies everywhere. So good to check always. We can also attack the proverb maybe so this is an exception to the first thing I was saying.
01:55:14.540 - 01:56:00.036, Speaker D: But we do care about the security of the prover, because maybe some malicious transaction, some incorrect block data could crash prover somewhere. If approver is not able to generate approved. This was also discussed with earlier, what happens then? The chain is stopped. Also not acceptable. Going to be fairly difficult to wisdom about the resources of the circuit. We also had the discussion about the gas limit and so on. So the way it's done now, I believe it's those steps.
01:56:00.036 - 01:56:56.570, Speaker D: So first there is the block and then the trace, and then finally the state transitions. So what if you have a problem in the last step? If it's not possible to make a proof, or the proof crashes, or it just doesn't have enough resources, you need to go back to the block and exclude that transaction from it, right? Make a block that actually can be proven. So this sort of rezoning, right, that I'm proposing and everything else, always of crashing software, denial of service. So that was just a list. So now probably several of those issues are of an entire discussion of their own. So please do discuss it with us. And that is all.
01:56:56.570 - 01:57:29.390, Speaker D: Anything you want to go back to? Maybe I zipped through it, but this is intended. We can go over these slides again that will be shared as well. So I hope people get more ideas about things to check. So bigger checklist.
01:58:26.650 - 01:58:49.306, Speaker A: Okay, so if there's no more questions. So then that's the end of this entire CKeVM auditor education sessions. And thank you everyone for joining the sessions. We were going to share the recordings and also all of the slides later on with everyone. We will probably just update in the.
01:58:49.328 - 01:58:51.258, Speaker D: Notion page, so I can just keep.
01:58:51.344 - 01:58:59.250, Speaker A: An eye on that so we can review all of the recordings. And thank you everyone for joining this session.
01:59:00.630 - 01:59:03.570, Speaker D: Bye guys, thank you.
01:59:03.640 - 01:59:06.450, Speaker B: Bye bye. Thank you. Bye.

00:00:05.560 - 00:00:49.385, Speaker A: Hello everyone. Thanks for joining this week's protocol symposium session. Today we have tarun who probably doesn't need an introduction. TAR has been doing legendary stuff in mechanism design and web3 in general. From osmosis to conflate. Today we are going to talk about how much security does your abs really need? Which is I think a question that was never really looked into carefully before. So excited to learn about it and take it away.
00:00:49.425 - 00:01:30.771, Speaker B: Tara, awesome. Yeah, well thank, thank you for the introduction. I my screen for some reason I can't see the zoom. So if there are questions please let me know. I can stop. But yeah, so this talk is really about, you know, formalizing some of these kind of notions of what is the correct amount of security that a restake network needs. So, so you know, when you think about proof of stake, you know the, the naive threat model is hey, if I double spend, you know, that causes a certain amount of damage.
00:01:30.771 - 00:02:59.015, Speaker B: So the amount of stake that's needed sort of needs to be, you know, above the, the worst case double spend in, in some abstract sense. And usually people try to think of this in terms of hey, if like the largest size of transfer or largest wallet address has X units then sort of I need 3x if it's a BFT protocol or I need 5x if it's an optimistic responsiveness protocol, et cetera. But in a lot of ways this notion of how much security does a POS network need is very, can actually be quite complicated and you can view AVS's and restaking as a natural generalization of proof of stake. So this talk I'm going to kind of go through the high level description of that. And so the first part of the talk, you know, some of you might have seen before, but I just want to make sure everyone has the same sort of initial background of like why we study it this problem in this way. But the second part of the talk, which is something that hasn't been done before, is really understanding the proofs and like sort of what the math involved looks like at a very high level and I think from an economic standpoint. And my collaborator Malesh is here so he maybe he can also field questions if I miss any in the chat box.
00:02:59.015 - 00:03:47.205, Speaker B: You know, from an economics perspective, one way of thinking about proof of restaking is as a matching market, which is sort of the classical construct. So we're sort of going to look at it initially in three different ways. First we're going to talk about thinking about restaking as a matching market. Then we're Going to kind of sort of talk about the notion of how much stake you need needs to be the minimum amount of security that you need to avoid cascading risks, which we'll define. And then finally we'll talk about how the optimal amount of rewards or fees that you need to make such system sustainable actually depends on your choice of threat model. Okay, so this is. This is an example of a matching market, as I mentioned.
00:03:47.205 - 00:04:43.763, Speaker B: This is sort of, you know, your classical example you might get in class of like a dating or roommate matching type of thing where each person is represented by vertex. There's a bipartite graph. So this is sort of the stable marriage type of thing. Of course, I just took this from some textbook, and it's obviously very normative based on the choices of names and partitions. But the idea is that each node gives a ranking, and then based on the rankings, we try to find matches that are feasible. And in some cases there might be rankings that make no match, no perfect matching feasible. And so a natural question is, you know, what is what? One of these markets, what is the matching market? Sorry, give me one second.
00:04:43.763 - 00:05:35.885, Speaker B: I'm. Someone keeps ringing my doorbell. Sorry about that. Apparently my plumbing is broken. There's something someone had to do. So sorry about that. So what is a matching market? So matching markets exist in a lot of places.
00:05:35.885 - 00:06:18.307, Speaker B: And you know, the common examples you see are kidney exchanges, hospital and resident matching, and sort of dating. And the idea is you have sort of a set of inhomogeneous goods. You know, there's some shared properties amongst them. There are sort of some properties you can compare them on, some that you can't. And there's a set of demand, which is buyers who have a lot of constraints on what they can buy from the set of goods. So, for instance, if I'm getting a kidney transplant, I can only accept kidneys with a certain blood type or certain sort of antigen type. So you might say, hey, look, matching sounds like auctions.
00:06:18.307 - 00:07:25.965, Speaker B: I have a bunch of goods, I have a bunch of people, they have some constraints and I clear them. But one clear thing that's worth thinking about is auctions really focus on, you know, oftentimes revenue maximization for the seller or sort of welfare maximization for a buyer and seller. So, you know, it's a good outcome potentially for a seller to only sell 1% of the goods if it maximizes their revenue, if they restrict supply artificially in some sense, which actually gives them a higher overall revenue. On the other hand, matching markets are much more focused on Stability to perturbation. So if you've taken a sort of econ or algorithmic game theory class, one of the first things you learn is the stable matching theorem. And this is this idea of, of these kind of matches you find via certain algorithms, like the Gail Shapley algorithm, tend to have a stability property under removal or addition of vertices or edges. And if I look at crypto, overall, crypto actually has both auction type mechanisms as well as sort of intent or matching type mechanisms.
00:07:25.965 - 00:08:22.885, Speaker B: And obviously we're going to argue restaking isn't this. So matching markets are sort of naturally represented using graph theoretic constructs. There's sort of a natural sense in which the supply side gets to be one set of nodes, the demand side gets to be another set of nodes, and the edges are possible potential ways you can match them together. This graph is usually static in most traditional matching markets designs. For instance, you know, if I look at the hospital residency matching, well, the set of residents every year is kind of known ahead of time or the maximum set. I guess people can drop out or die or things like that. And generally there's a central planner, so there's, you know, some central entity that's actually computing the algorithm for the matching.
00:08:22.885 - 00:09:11.725, Speaker B: Decentralized matching markets don't have either of these features in the sense that the graph can change at any time. Nodes can join and leave whenever they want. Potentially services can join and leave whenever they want as well. And parties don't kind of find an optimal matching in the classical sense. Instead, they sort of take incentives and try to figure out how to construct a portfolio that kind of approximates optimal matching. Okay, so a natural first thing to say is restaking can be viewed as a decentralized matching market. So what does this mean? Well, one thing to note is that decentralized matching markets are much harder to analyze.
00:09:11.725 - 00:09:52.411, Speaker B: And so we'll talk about exactly how you formulate what a restaking matching market looks like. But just to give you a high level idea of why it's hard, first, when you're permissionless, a thing that was a match before might suddenly not become a match. And suddenly you're unmatched. And what that means is if I'm a service, I'm like an AVS and a restaking network. A node operator might leave and suddenly I'm either attackable or I don't have enough. No operators are present, and so suddenly my service has died. So it's almost like a blockchain that dies because all the operators leave and because people are Free to join and leave at will.
00:09:52.411 - 00:10:53.641, Speaker B: You have to have other means of kind of ensuring you have a minimum amount of stake. Second, having no centralized planner means you can't do things like mechanism design without money. You sort of need incentives to kind of keep stake aggregated in a particular place. And finally, in general, these markets need explicit adversarial models. So, you know, if you, because you don't have a central planner, you sort of effectively have to come up with sort of a notion of like, what actions can an attacker do? What does it mean for someone to attack? And, you know, how much stake do they need to even execute attack? Okay, so none of the graphs we'll look at will be this complicated, but we're going to talk a little bit about the basic combinatorial objects. We'll see study, and then how we can quantify things on those objects. All right, so the main object of study today will be something called a restaking graph.
00:10:53.641 - 00:11:37.603, Speaker B: And so we'll go term by term and kind of describe each of the items here. Sorry. So first we have the set V, which is the set of node operators. So these are people who are running the client and, you know, validating transactions, slash, voting on slashing transactions, things of that form. So think of them like proof of stake node operators. They're running a client, they're kind of running potentially some type of consensus, and they have to lock up stake in order to participate. The stake is this vector sigma.
00:11:37.603 - 00:12:24.081, Speaker B: You can think of it as a vector that lives in rv, which is sort of the set amount of state that each node has. Another way of thinking about this is as a vertex label. But I like drawing it like this because it's a little cleaner to see. Next we have the services or AVs. And from the perspective of how to think about it here, you should really think of these as like separate proof of stake networks or separate networks that require some notion of stakeholders and rewards and incentives to be operated. And so in this graph, you can see that the two node operators V1 and V intersection, which is this middle operator, are operating service one. And also for service two, you can see that V intersection and V2 are operating service two.
00:12:24.081 - 00:13:25.823, Speaker B: Now, the difference between restaking and normal staking is this sort of node in the middle V intersection, this node stake can be reused to secure both service one and service two. And that is actually quite important and very kind of controls a lot of the threat model. The next thing is a, you could think of this as a vertex label on the service partition, which is the Maximum profit from attacking a service. So this is sort of, you know, when I kind of started I was talking about this idea that hey, what is the, you know, how much stake do I need for a proof of stake network? Well, maybe I say an attack. The only attack I care about is a double spend and if I know the maximum size of a wallet someone might have, then I can sort of back in what that is. Now, proof of stake is much more complicated today. As you all probably know, there's more in stable coins on Ethereum than there is stake itself.
00:13:25.823 - 00:14:10.625, Speaker B: So in theory there's an attack, but there's often, you know, it sort of suggests that the threat model for what the maximum profit is is actually much more complicated to compute. But for our purposes we will think of it as a vector that's given there's some oracle that's telling it. In practice, if you're doing empirical research, you're going to have to find ways of estimating this. Finally, we have one final vertex label which is the corruption threshold. So the corruption threshold is this notion of what fraction of stake has to collude in order to perform an attack. So, you know, if I'm in a BFT protocol, it's one third in order to have to collude. If I'm in a longest chain protocol, it's 1/2.
00:14:10.625 - 00:14:50.425, Speaker B: If I'm in an optimistic responsiveness protocol, it might be 1/5, et cetera. Right, like so there's lots of these thresholds for applications that aren't pure proof of stake services that have other sort of means of communication, you will have different quorum thresholds. But generally this is the idea here is that this reflects some notion of what is feasible. And finally, as I mentioned earlier, you can have operators who operate the same service, multiple services with the same c. Okay, this is the whole setup combinatorially. Hopefully it's not too complicated. But it's a bipartite graph with certain vertex labels for the two bipartitions.
00:14:50.425 - 00:16:16.889, Speaker B: Okay, so you might say, hey, okay, this seems like some random thing, like why should I give a shit about it? Well, this is what the Eigen layer restaking graph so far has looked like over the last three or four months. On the right is the services, on the left is the operators, and the red and green edges are people adding or removing edges based on rewards, based on points, whatever. And you can see that the graph is changing quite a bit dynamically. And so a natural question is what does it mean for this graph to be secure in some sense? So to do that, we first have to talk about a notion of attacks. Okay, so there are two conditions that are necessary to talk about when we talk about attacking a restaking graph. Profitability and feasibility. Profitability is can I make money even though I might have to lose some stake? And feasibility is are there enough people in a cartel who are colluding to attack the service? Okay, so what is profitability? It says I have a subset of services A and I have the maximum profit from attacking that service and that subset.
00:16:16.889 - 00:17:09.021, Speaker B: And that needs to be greater than the maximum slashing penalty for attacking. Maximum slashing penalty for the cartel B, which is a subset of operators that is attacking for feasibility. This says for every service S that is being attacked, the stake held by the cartel B that is attacking the service S is greater than alpha S times the total stake. So this gets back to this notion about. So what this says is like if there's a set of operators B that is attacking a service S. For instance, suppose that service is a BFT proof of stake chain or a roll up sequencer or something like that. Then you need the stake to be greater than 1/3 times the total stake of that service.
00:17:09.021 - 00:18:08.827, Speaker B: So the cartel that's operating, say if it's a decentralized sequence or something, needs to have at least 1/3 of that SE in symbols using our notation from before. For a given set A, you have services subset of services and a given set B of subset of operators. These two constraints define profitability and feasibility when the profits add up linearly. So if we go back to this graph, so if we look at this, each service is individually over collateralized. And so this is where we'll get have a difference between proof of stake and restaking. So service one has a maximum profit of four, but there is six units of stake stake there. So if the slashing penalty burns all of the stake, then it's not profitable.
00:18:08.827 - 00:19:15.645, Speaker B: The same thing is true for service 2. However, if all the validators collude to attack both service 1 and service 2 simultaneously, it is profitable because I can extract 8 units of profit from both and I only have to worst case spend seven units of profit or seven units of stake. So this naturally leads to a notion of a cascading attack on a rescue graph. So we'll, we'll first see in pictures and then we'll kind of talk a little bit about it. I want you to think more like a defi cascade or a liquidation cascade on a centralized exchange, because that is kind of the, this is sort of a more controlled analog of that. So step one, imagine we, we, we, we, you know, we have a bunch of stake, and in this case maybe we lose 20% of stake. So in this case, this fraction of stake lost is PSI is 20%, which comes from this validator V1 being knocked out by V1 being knocked out.
00:19:15.645 - 00:19:54.835, Speaker B: This immediately means that the operator v cap v intersection can attack service one profitably. So before we had a profit of four and a total stake of four. Now we have a profit of four and a total stake of three. And so this, this one can attack this. And once this attacks this, this opens up an attack on service 2 because the, the remaining stake is only 1. And so with a profit of 4, you can have a net profit of 3. As I said before, this is sort of the proof of stake version of a lending liquidation cascade.
00:19:54.835 - 00:21:27.599, Speaker B: Okay? So a natural thing to say is how do we quantify these? So we first talk about notions of valid attack sequences. So what this means is, you know, we have a set of services A and a set of operators B. And we have a sequence such that after, you know, after we execute one attack, the next attack is valid. And so this is sort of exactly what we saw on the previous slide, where one attack was executed, then there was sort of, which opened up another attack, which opened up another attack. And we define a worst case measurement termed RSI of G, which is the maximum percentage of stake that can be lost due to a cascade attack given an initial loss of psi percent of stake. So in the previous example there was this notion that node operator 1 was lost, maybe they got ddosed, maybe they got hacked somehow their stake was lost. And so conditional on that being lost, what is the maximum amount of stake that can be lost? We can write that in symbols by saying take the maximum over subsets of validators with less than or equal to psi percent of stake and then take the maximum overall valid attack sequences over the graph with that removed, and look at the ratio of the total stake lost in the attack divided by the total initial stake.
00:21:27.599 - 00:22:21.695, Speaker B: So this ratio is between 0 and 1, and it sort of quantifies the percentage that maximum amount that can be lost given a initial shock of size psi. So this definition is nice. It's a worst case definition, of course, but you know, it, you might say, hey, this is great. This might say something about how much stake we need. For instance, we might need to, we might want to choose the stake sigma V such that the cascade coefficient RSI of G is smaller than some tolerated amount. So for instance, you Might say, hey, we want to choose the minimum amount of stake needed such that we're willing to lose at most 5% of stake, given that we have size less than 33%. Well, it sounds like this thing solves all our problems, unfortunately.
00:22:21.695 - 00:23:21.775, Speaker B: Well, in a very nice paper, Naveen and Tim sort of proved there actually exists an infinite family of restaking graphs with N validators such that RSI is one. And remember, when RSI is one, that means you have a cascade that wipes out the entire network, which is obviously not what you want. So in our paper actually we drew a version of this which I think will hopefully make it easy to see. But in this representation, this is what we call the hypergraph representation of a restaking graph. Each of the black dots is a validator and assume they all have the same stake for this purpose and each of the boxes is a service. So for instance, the red box at the left with three validators, that's a single service. And the blue box with the six validators, that's a single service.
00:23:21.775 - 00:24:01.675, Speaker B: And as you can see, they overlap. Right? So the validator in the upper left corner is participating in the upper blue box as well as the leftmost red service. Now what happens is we first have this sigh loss. So imagine the silos is just again a loss of one validator which opens up the attack to the rest of the service. You could imagine that the, the Profit from attack is 3 and the stake there is 2. So it's net profitable. But then by that being knocked out, imagine the profit for attacking a blue square is six.
00:24:01.675 - 00:24:30.095, Speaker B: Well now it's profitable to attack the blue square or blue rectangle. But once I knock out the blue rectangle, I actually open up an attack on one of the red ones and then that opens up an attack on the last blue one. And you could imagine that you can retile this arbitrarily many times and hence you get this infant family. Okay, so that's the bad news says sort of hey, we, we have to be a little careful.
00:24:31.595 - 00:24:32.907, Speaker A: One quick question.
00:24:33.091 - 00:24:33.855, Speaker B: Yeah.
00:24:34.395 - 00:25:01.655, Speaker A: So the. In, in the last slide, when we talk about like this infinite family of graphs that are susceptible to the whole state being wiped out for some side do we know like how big is this size? So like for instance, I imagine if size is too big, we shouldn't be too worried like the necessary or does it mean. Or the torium says for any side that exists in the family. Is the question clear?
00:25:02.475 - 00:26:09.445, Speaker B: Yeah, yeah, I think. Sorry, I just went down. I just shrunk it so that we can see this. So the idea here, and so this is sort of what this kind of result will get at, is the notion of psi is sort of a notion of a smoothness. So it kind of says like, hey, if I'm willing to tolerate a, a loss, a shock of size, size, so like 10% shock, what is the maximum amount of stake I can lose, right? If I make psi equal to 1, so I make psi equal to the entire stake, well then it doesn't matter, right? There's no stake left anyway. So it sort of, and so the question just kind of a little bit like the proof of stake or proof of work model, which is like, hey, I have this threshold 1/3, if 1/3 take over, can I lose all my stake? That would be an equivalent question you might ask. And that's something that you kind of have to consider.
00:26:09.445 - 00:27:36.655, Speaker B: But the main point here is that, and I can go back to this, is that this rsi, what they show is that if you're over collateralized in a certain way, you can actually bound the this function as a function of psi. So for instance, if I'm over collateralized in a certain sense that we won't exactly talk about, I can bound this. This is sort of the proof of stake analog of your decentralized stablecoin needs to be sufficiently over collateralized to avoid cascading depeg events. The problem is the over collateralization is very strong to the point that for many graphs, every service is over collateralized by as much as the total profit. And in concrete terms, this over collateralization condition says, suppose I have two services, one that has one eth of max profit and one that has a million eth of max profit. This sort of thing that says you need to have as much stake as the sum of all the profits means that the 1 ETH attack surface needs to attract on the order of a million in one eth to be safe against cascading attacks. Which is kind of crazy, right? Like clearly they're very different things.
00:27:36.655 - 00:28:50.615, Speaker B: Like the one E thing might be an oracle for meme coins and the million E thing might be a decentralized sequencer. So why should the meme coin oracle have to pay as much as a sequence fare? And so there's sort of this natural question of like, well, this model sort of does you get the safety property, but you do it at such a high cost that it becomes impractical. So natural question is like, does this, does this route to pricing AVS security kind of have a dead end? So the next Thing we're going to talk about is incentivize restaking graphs. And so this is the kind of natural thing you might expect, which is like in proof of stake you have a notion of a block reward, you have a notion of a fee. You know, validators and in restaking networks are themselves also not altruistic, right? They are doing it for money. And hence, you know this meme. So imagine we have a restaking graph, again sort of a similar setup, except now we have another vertex label on the services, which is the rewards R.
00:28:50.615 - 00:29:30.895, Speaker B: And the rewards R represent an amount that the service is paying to attract stake. So this is how I choose my inflation, for instance, or maybe this is what fees I generate. But here we're just going to consider a notion of an abstract reward paid in the same base currency as the, the, the restaked asset. Now in practice, of course, people will pay you in their token. And it's more complicated for this model we remove that complication. Of course, I think that you can add that in, but it complicates a lot of other stuff. The second thing is we allow the validators to adjust their stake in response to rewards.
00:29:30.895 - 00:30:22.057, Speaker B: So maybe one of the rewards changes and all of a sudden the other validators are, it becomes profitable for them to join. And when they do that, they change the restaking graph. So the idea is now the restaking graph itself is dynamic. And when you have a dynamic restaking graph, you can actually halt these cascades. So from the previous example, we initially have this silos, so which is the upper left corner. And then we have the attack A1, B1. But now because all of the validators in B1 have disappeared, it's actually profitable for some of the other validators to start restaking on new services.
00:30:22.057 - 00:30:50.897, Speaker B: Because if you think about it, imagine there's 10 ETH of rewards given out by a service. And imagine there are three people splitting them equally so they each get 3.33 and 1/3 eth rewards. Imagine one of them is fully slashed. Well now two people are getting 5 eth rewards. So a natural thing to do is if I'm someone else, well, I, I, I know that someone was able to be profitable at 3 1/3. So I'm going to try to join and, and capture that spread.
00:30:50.897 - 00:31:36.525, Speaker B: And so that's, that's sort of what you, you can think of as the, the reason for rebalancing. It's like pure profit motive. So as I mentioned earlier, we have to consider sort of the adversary involved. And so in the profitability that we talked about earlier, we had this notion of attack profitability that's linear. So it, it's just summing over the maximum profits or services, and it's subtracting the maximum stake that can be lost. The one thing is that this type of profit assumes the adversary face no costs. There's no marginal cost for attacking multiple services at the same time.
00:31:36.525 - 00:32:26.489, Speaker B: But in reality, in order to do such an attack, there is such a cost because in order to aggregate stake, the adversary will have to buy the stake. And in the process of buying the stake, they push up the price of stake. So then the next, the amount of stake they have to aggregate to do the next attack goes up. So there's a notion in which if you believe the adversary has to face costs in doing these attacks, which in practice they do, then this linear profit is too simplistic. Moreover, there's a sort of notion in which linearity is uneconomical and can go wrong. And we won't dwell too much on this, but the main idea here is that when you have these linear profits, it's possible that rebalancing actually causes. Can cause attacks in the future.
00:32:26.489 - 00:33:17.479, Speaker B: So the idea is after some nodes are taken out, certain operators rebalance, and upon rebalancing, they actually create a new attack. And the reason for that is that they. The rebalance actually increases the overlap between services. So now it's cheaper to attack a service because you can use the same stake once to attack multiple services. But, you know, I just want to show pictorially what this looked like. Didn't talk in detail, but otherwise. So a natural question is, you know, who should be our adversary? So, you know, if I think about DeFi versus proof of stake, the threat model in defi has a notion of cost of attack in the sense that if I do an Oracle manipulation, it costs me something to do that.
00:33:17.479 - 00:34:14.175, Speaker B: And there's sort of a notion in which if I have to do many Oracle manipulations, I have a decreasing marginal profit. So we consider the simplest version of this, which is the P norm profit in terms of maximum profits. This function has this property of submodularity. And as P goes to infinity, you get this, you get this profit which has the max over the services in the set, which is effectively the same as saying you can only attack one service at a time. So you can view this as the proof of stake profit in that I can only, there's only one service to attack. So the nice thing about this family of profits is it lets us Interpolate between this sort of very non local linear profit where there's no marginal cost of attack. So I might as well attack everything to the thing that I have really high marginal cost like I do for a single proof of stake network.
00:34:14.175 - 00:35:07.215, Speaker B: And you attack one at a time. And you can think of this notion of restricting the adversary to these types of profit functions as equivalent to localizing the attacks. And we'll see what that looks like in the proof. So the main thing is in this threat model we sort of weaken the adversary to kind of place the realistic liquidity and cost of attack constraints on how many attacks you can attack simultaneously. And then we also assume the node operators are smarter, that they're looking at the rewards and they're adjusting their stake. So the graph is dynamic. And so the thing we show is that if the rewards are sufficiently large, you can also actually buy bound this R side, this maximum cascade length.
00:35:07.215 - 00:36:21.293, Speaker B: And you can, you can also even compute the rewards algorithmically as opposed to kind of needing these hard thresholds. And so what this says is as a choice, as a function of how much marginal cost you think an adversary faces, you can choose a set of rewards that guarantees you you won't be in a cascade of a certain length. Unless you know, an adversary can attack a large number of services. So concretely, maybe I choose p equals 2 which is square root of S, and I say, okay, I'm going to give rewards that are proportional to square root of square root of the number of services. By doing that, I am secure as long as the cartel that attacks me has less than square root of S over S. So one over square root of S times the total stake. Which might be fine if say, you know, there's only one eth max profit in my network, you know, yes, if someone is willing to attack the 1 million eth network, then it's fine, you know, I, I can't really do anything about it because otherwise I'd have to pay some something linear in the amount they could be attacked for.
00:36:21.293 - 00:36:58.375, Speaker B: And so this sort of allows each service to choose a threat model of like how, you know, hey, as long as a cartel is less than a certain size, we're safe. So the interpretation if the adversaries face costs, the node operators are smarter and the services pay enough rewards, only a small amount of state can be lost in cascading attacks. And these, this sort of guarantee degrades smoothly to the people's one case which is linear. Okay, before I continue, maybe I'll stop to check if there are Any questions?
00:37:00.275 - 00:37:27.545, Speaker C: Can I ask a question which. Is there any work or research done as to if there are constraints on the graph in terms of the intersections of. Of like serv. Sorry, I don't know the terminology but like if you. If there are constraints on how much intersection there can be amongst different services in terms of the state they're looking at.
00:37:30.445 - 00:38:17.635, Speaker B: Yeah, so yeah, it's a good question. So we'll actually see that in the proof that they're. That bounding the amount of intersection is the most important part. I think that's the thing that Tim and Naveen's paper doesn't really talk like their over collateralization condition is so strong because it says it does something such that the overlap is sort of doesn't matter. But that means you have to be so over collateralized that you don't care about that. But yeah, what we'll see in the proof is that there are a number of local constraints that are very important to kind of showing that, you know, rebalancing in these rewards work. So, so yeah, there are definitely things around that I think they're kind of hidden in the proof of why they're there.
00:38:17.635 - 00:38:49.561, Speaker B: But there's probably some, you know, I'm not sure. Our constraints are sort of minimal or sharp or tight. And we'll talk about that in open problems as well. All right, so proof of the interstellar. Okay, so let's go through the setup. So we have a restaking graph G with set of validators, services, stake attacks, max attack, profit threshold and rewards. We have V validators with stake sigma V.
00:38:49.561 - 00:39:51.607, Speaker B: And for notationally I will abuse notation repeatedly where I will use V to mean the set of validators and also the number of validators. So apologies in a minute. Same with the set of services we have corruption profits and I will use S and for both the set and the number of elements, alphas of course is attack threshold, R is the rewards of service payout. And this is an arbitrary attack sequence. We're going to concern for such attack sequence or not even for attack sequence. For any set. For any sort of node that's a service S, we consider its neighborhood boundary S and boundary S refers to the set of operators that are validating it.
00:39:51.607 - 00:40:34.207, Speaker B: So in the image to the right you can see the box around the blue nodes. That's the boundary of service one. And similarly for any validator we can talk about the boundary of that set as the set of services that are operating that or services that that validator is operating. It's a lot of words to describe a kind of geometrically intuitive picture, especially for by graphs where like. Because there's no self edges like the notion of neighborhood is very clean, but just so that you can have it formally described as what it's. And this is what it looks like. Finally we're going to define, and this is related to your question, the notion of an overlap.
00:40:34.207 - 00:41:36.375, Speaker B: So the overlap is the amount of for given two services S and T, it is the amount of stake that is operating both of them. So for instance, the overlap between services S1 and S2 is equal to the amount of stake that V intersection V sigma has. Obviously the name V intersection is meant to convey this notion that it is the overlap of the two. Okay, just want to double check, make sure any questions or it's set up make sense. All right, keep going. All right, so five sort of key steps. So the first thing we show is that the submodular profit, the sort of marginal costs are high for the user, localizes the size of an attacking cartel in some sense.
00:41:36.375 - 00:42:24.013, Speaker B: Actually, there's a slight typo here, but as the number of services goes to infinity, the. The. The ratio of the maximum cartel size to S, so this is actually should be the thing on the left divided by S goes to zero. So this means that as I get a lot lot larger and larger number of services, the maximum size of the set of attackers that can collude profitably is sublinear in S. Secondly, small enough overlap implies that the maximum number of services that can be simultaneously attacked is also small. So again, sorry, another typo. But this should say as the number of services goes to infinity, the maximum size of a set of services in a valid attack divided by S goes to zero.
00:42:24.013 - 00:43:12.285, Speaker B: So that says it's, it's asymptotically sublinear. So what this says is actually by use having this marginal cost, we can localize, we can, we can show that you can't attack the whole network at once. In fact, there's a maximum size of a set you can attack. The third thing we show is that if the rewards are sufficiently large, the maximum length of an attack sequence is one. So remember in the last slide we talked about an attack sequence that has length T. And the third step shows, hey, actually if you give high enough rewards, actually the maximum length attack size 1. So the first two steps say we can show the maximum size of an attack is bounded in some ways.
00:43:12.285 - 00:44:04.031, Speaker B: And the third step says actually it's only a length one attack. So when you get all three of those, now you can Talk about, hey, we could definitely bound the total amount of stake you could lose. The fourth step, which is actually quite important, which is that if the reward we also show if the rewards are large enough, rebalancing doesn't create new attacks. So that was sort of the thing I talked about earlier, where it's possible that rebalancing actually increases the overlap and makes an attack profitable. And we be sure that it's a reward that's not true. Finally, we show that discriminating on rewards is able to help you incentivize low overlap between services. So this means that paying out different rewards to validators based on how much they contribute to the overlap allows you to incentivize low overlap.
00:44:04.031 - 00:45:02.711, Speaker B: So this is something that's different than proof of stake, where generally you want to do rewards per rabba to get sort of optimal outcomes. Okay, so the first step is localizing the attacking operators. So this is saying like, hey, no cartel, that attacks can be sort of large relative to the number of services. So given an attack ab, we want to show that set B is little O of S. So sublinear in S was strictly submodular, which says as the network gets bigger, the maximum percentage of operators that could profitably collude shrinks. Okay, so what does this proof look like? Well, recall that our profit in this case is the p norm of the vector PI, which we can bound term wise by the maximum. So we kind of we, you know, you can see the maximum I pull out.
00:45:02.711 - 00:45:53.845, Speaker B: And now we have a bunch of terms raised to the P and then summed up raised to the 1 over P. There are a of those terms and each of them is less than or equal to one. So now we get that the pnorm is bounded by the maximum Profit times the 1 over P power of the set A. Secondly, a very trivial lower bound is that the total stake that is used in the attack is lower bounded by the minimum stake times the total number of the size of the cartel. Now one really important thing to note is that the minimum stake is actually a network parameter. So if you think About Ethereum, there's a 32e staking minimum. And obviously people are debating what whether that can be changed or not.
00:45:53.845 - 00:46:24.011, Speaker B: But the notion of all of the bounds in this paper are given a minimum. We give you a bound. So these are tunable parameters by the network. And so all these networks have to think about this. An attack is profitable if the profit FP of PI is greater than the total stake that could be lost. So this is a worst case analysis where you lose all the stake when you're slash. I think, you know, average case analysis, which allows for partial slashing and things like that is quite a bit harder.
00:46:24.011 - 00:46:49.925, Speaker B: And we can talk about that. But the worst case analysis at least gives you some idea of what you can get. And now we combine these inequalities and we naturally get this notion that B is sublinear in S. And so when P is greater than one. So now we can show the set of cartels is asymptotically small. Okay, great. Now let's do the same thing for the sets of services.
00:46:49.925 - 00:47:49.435, Speaker B: So given an attack ab, we want to show that the set of services is also sublinear when the payoff is strictly submodular and when the overlap is bounded above and below. And so this gets to the question we got earlier, which is, hey, are there some constraints or properties on the graph that are necessary to kind of achieve safety? And the main one we use here is that this overlap, this notion of how much stake is shared between services is bounded in some suitable sense. So we're not going to give the full proof. It's, you know, annoying effort, you know, annoying combinatorics exercise. But I will sort of give the high level description of it. And a lot of the proof is sort of inspired indirectly via sort of proofs of low Ashokalemma. You can kind of think of this overlap condition as sort of the failure probability in the low Ashok Lemak.
00:47:49.435 - 00:48:24.677, Speaker B: Okay, so for your set of attackers B for each service define the set B sub S as B intersect the neighborhood of S. So this is a set of validators who are in the cartel B who are trying to attack, who are validating S. So it's a set of people in the attack who could be attacking S. And now do something very basic. Just use inclusion and exclusion to expand the stake. Now. And this, you know, this, this is the main crux of the proof.
00:48:24.677 - 00:49:25.857, Speaker B: So you can read in the paper, when the overlap is bounded, there exists a psi. Actually it should say in, in 01, but certainly greater than zero such that the total amount of stake in the intersection of all of these sets is bounded by psi to the K. So this gives us a nice geometric series. In this geometric series we actually get a lower bound because inclusion, exclusion has a bunch of, sorry, a bunch of negative terms which are our, sorry, our geometric expansion. You know, we, from this you can see that there's a lower bound that comes from sort of upper bounding the negative terms. And we can Upper bound the negative terms using this, which, you know, for simplicity, I just made, shove that all into this constant C. And now since we're summing over services, we can sum over only the services in A.
00:49:25.857 - 00:50:28.823, Speaker B: And now we get a term that depends on the size of A. And again, remember, the profit above is bounded by something that's A to the one over P. And if you do out the profit condition for this, you have something linear in a, something less than, linear in A is less than or equal to S, you get the sublinear. But this kind of thing is a way of saying, like, hey, provided there's low overlap, you can't really attack a lot of services all at once, which is a very key point. Okay, step three, which is shows that rebalancing lets you halt long sequences. So given an attack sequence without rebalancing, so that's sort of like from the Tim and Naveen paper. We show that only the first attack is a valid attack if you have rebalancing, provided that A is sublinear.
00:50:28.823 - 00:51:32.675, Speaker B: So provided the previous result holds. Basically what we show, and a lot of this proof feels a lot of this paper feels a lot like sort of formal verification where you have a bunch of inequality conditions for each of these profitable and feasible conditions, and you show that the sequence of those holds went down in a certain order. So first thing, attack one is profitable and feasible. The second is it's feasible without rebalancing. The third is we show it's infeasible with rebalancing. So when people rebalance profitably, all of a sudden the feasibility constraint, the amount of stake that is in the cartel B is not there anymore. And the TLDR of how you do that is you kind of can show that there is a way to bound the amount lower, bound the amount of stake that flows in on restaking on rebalancing as a function of the rewards, and it's sort of increasing.
00:51:32.675 - 00:52:14.315, Speaker B: And from that you can kind of show that when the rewards are sufficiently high, the amount of rebalance stake is sufficiently high to make it infeasible. The fourth step is rebalancing could cause new attacks to be profitable. But the claim is if it's strictly submodular, I. E. There is a strict oper, strict marginal cost per attack, and rewards are high enough, this can't happen effectively. This requires a couple conditions. First, the attack is infeasible without rebalancing and feasible with rebalancing.
00:52:14.315 - 00:53:13.905, Speaker B: These are the conditions we want to not hold and we show that the second condition is monotone, decreasing in rs, and so there's some threshold at which it can't hold. And again that comes when RS is omega vessel R. Okay, so let's take a recap. We, we did a bunch of steps, we did a bunch of random combinatorics and proved a bunch of inequalities. Where does this get us? Well, let's combine all of our steps and see what we get. So first, if we write out R psi, R psi is is less than or equal to psi, the amount of st maximum amount of stake you lose in the shock plus the total stake you lose attack sequence divided by the total initial stake. As we saw, step two said that the attacks were sort of the number of services you could attack are bounded.
00:53:13.905 - 00:53:47.605, Speaker B: Step three said the number of the length of an attack sequence is size one. And then step four says, hey, if you rebalance, you won't create a new attack. So it's not your attack sequence won't grow longer, it'll only shrink. And so that those three combined. Say we only have to look at lent one attack. There should be a side plus on the right side too. Step one says, hey, this Sigma B1 is now sublinear in s, so we can actually bound it by this term.
00:53:47.605 - 00:54:23.685, Speaker B: And every service has at least Min Sigma V6. So again, this min you should think of as like the 32 ETH in Ethereum. And now we get the result. So all of this is great. This actually means that we get, you know, with sufficient rewards and incentives, you can actually avoid these cascade risks. But the problem is this still relies on this notion of the overlap being small. So to the question we got earlier, there's clearly some constraints on these graphs to make them safe and avoid these kind of bad outcomes.
00:54:23.685 - 00:55:14.367, Speaker B: So we'll just kind of very quickly go over this. This is kind of the last couple things and apologies for typo in a second, but conclusion should be spelled correctly. But steps one to four shows that if we have low overlap, we, we can be safe. So the idea is, hey, give stakers less rewards if they increase the overlap between two services. So maybe I am staking on services one and two and both of those services are paying me 10. Someone else comes in and stakes on the exact same services. If we naively distributed the rewards, we might say, okay, well we're going to give 5 ETH each to both of the stakers, but the service could actually discriminate against both of you.
00:55:14.367 - 00:55:46.475, Speaker B: So instead of getting 5 ETH, you might get 4 ETH. So it's sort of where we're shrinking your rewards if you cause higher overlap. You could kind of think of this as, you know, in Ethereum proof of stake. There's this notion of emissions curve that's a function of the percentage of supply stake. It's the same type of thing, except instead of it being as a function of the percentage of supply staked, it's as a function of the overlap. So we do, to do that we define the set of max overlap. We now define a reward per validator.
00:55:46.475 - 00:57:21.287, Speaker B: So based on how much they're, whether they're in this sort of maximum overlap set, and then from that we actually get a thing that says hey, as long as we discriminate on rewards enough, then the overlap will be bounded. So this says there are unique ways in restaking with rewards to actually ensure safety and they're uniquely different than normal proof of stake because instead of it being based on what fraction of the supply is staked, you now also depend on the overlap with other services. All right, so so far all these results were asymptotic results. But as we said earlier, there's real restaking graphs and real profit functions that are live. So how do we compute optimal rewards relative to the sort of theoretical results? And what we show is there's a way to use submodular optimization where you as the service pick a sort of amount, a sort of maximum size you're willing to tolerate of a set of attackers. And then you can do some, you can do some sort of convex approximation and get an approximate set of optimal rewards. Okay, so this is the last slide, so I know we're running on time, so apologies, open problems.
00:57:21.287 - 00:58:12.465, Speaker B: First, are the required rewards here tight? So you know, we give these lower bounds, but can you show the opposite upper bound? They're like, hey, like if you give too much in rewards, you something else kind of, it becomes uneconomical. Like the amount of rewards you have to pay is more than the maximum possible profit everywhere. Sort of seems like it's true. But we have, we didn't prove that the entire setup was worst case optimization. So as I said, we really like the worst case cascades. But what happens in the average case? What happens when you have partial slashing? What happens when the cartels are random or they have to coordinate in a random way? The average case depends a lot on the rebalancing strategy. And so it looks more like a learning theory problem than come pure come to works.
00:58:12.465 - 00:58:37.265, Speaker B: The final thing is that the setup misses this sort of principal agent problem, which is the node operators are usually delegated capital. It's not their money that they're staking. How does this change, you know, the overall model? And this is something that's also a problem for proof of stake. There's been a little bit of research on it, but it's still generally open problem. And with that I can take some questions.
00:58:43.235 - 00:58:45.123, Speaker C: Can I ask another question?
00:58:45.299 - 00:58:45.987, Speaker B: Yeah.
00:58:46.131 - 00:59:33.975, Speaker C: Can you go Back to slide Like 56 I think. Yeah, 57. Sorry. I think, yeah, I think I probably have to read the paper to fully understand everything behind this. But like intuitively to me it seems like the condition that you want is that like rewards are not, not necessarily that rewards are high enough, but that rewards are like somehow well calibrated across all of the different services. Like in the sense that they're like, like almost intuitively they're even across all of these services. What's wrong in my thinking, like why is it sufficient that they're high enough?
00:59:34.835 - 01:00:14.933, Speaker B: Yeah, this is a good, this is a good question. So two things. The first is that the higher your reward and so actually maybe I will go to the previous slide. So the main thing to note here is that the higher your reward, the higher your the amount of stake that rebalances. And the reason for that is that the, if you write out the profit function for each validator it's rewards times percentage of stake that I own. Right. And as I increase the rewards I'm increasing my likelihood of being profitable.
01:00:14.933 - 01:01:11.221, Speaker B: So, so one thing we, we didn't mention is we assume there's some positive non trivial cost for an operator. It doesn't necessarily need to be a lot, but it's. There is a notion of a cost and so they have a hurdle rate like they have to earn more than in rewards than their costs in order to participate. And there's this competitive aspect where if everyone operates everything, then everyone's rewards are diluted, right? So it's like everyone, if you have the complete graph and everyone operates every service, then everyone's rewards are quite small. It's your percentage of the overall stake of the entire restaking network. But you can imagine there's a competitive equilibrium where people readjust based on the rewards and then the question is what's the minimum amount of rewards you have to give so that you can reach that competitive equilibrium that satisfies all these constraints. Does that kind of make sense?
01:01:11.413 - 01:01:17.189, Speaker C: Yeah, I think that makes sense. Is it the case that rewards are constant across the different services or that's not.
01:01:17.237 - 01:01:35.231, Speaker B: Yeah, yeah. No, this is a good question. So, so, so this is actually where it gets tricky because a lot of people's rewards are paid in Ethereum fees they earn, but also in their native token. Right. So they're emitting block rewards in their native token effectively. And so they can control that. Right.
01:01:35.231 - 01:02:10.895, Speaker B: They can be like I'm giving you 500 ANI token, but obviously that will have a highly variable price relative to eth. Right. Because you have to measure everything relative to the restaked asset itself. And basically I think the main thing to think about for this is like, okay, this whole thing assumes that the services have a lot of control over the rewards that they emit, right. But they really don't. They actually have to take market pressure on that. And that's outside of this.
01:02:10.895 - 01:02:15.965, Speaker B: That's like one thing I would shove into the average case behavior because it really does depend on that.
01:02:16.135 - 01:02:17.825, Speaker C: I see. That makes sense.
01:02:17.985 - 01:03:13.813, Speaker B: This is just trying to get the combinatorics of the worst case correct because the worst case sort of gives you into the fact that you can even get a result like this for worst case says the average case could be much better. Right. Like you, you could require far less rewards to get the same. And again, if we look at the real graph and you compute graph statistics of the real graph, it's like, it's interesting. There are a couple AVSs that are pivotal, mainly Eigen DA and obviously like rewards and slashing have to go live next month for, for it to be reflect more reflective of it. But you can see that like there is sort of already some notion of concentration based on what people's perception of the expected rewards are because the rewards aren't live yet. But, and so the idea of this, this combinatorial stuff is at least a way of you getting, hey, I can.
01:03:13.813 - 01:04:19.986, Speaker B: What graph statistics should I compute, what kind of measurements matter and what a notion of an attack is. And then you can kind of iteratively imagine improving that model. Cool. I think I saw one other question. If there's a market for resaking services and wouldn't this market drive up rewards outside the security optimal to attract res? Yeah, this is a good, this is a great point. So Alejandro's question is basically, hey, isn't there some also some competitive pressure between the services? And so maybe this actually gets to your point of like, can they really offer constant reward? Well, maybe, maybe. Service one offers 10e of 10eth of rewards.
01:04:19.986 - 01:05:43.197, Speaker B: Service two offers 11 ether reward and is able to attract, you know, reduce the stake at the 10 ETH of reward by 20%. And so then there's this notion of like is there a race to the bottom of you know, people trying to increase their reward? And then, and I think this is where actually modeling the rewards of stochastic in the sense that whatever token they're paying with is actually, and the volatility of that token and the price is actually quite important to understanding the, the how much can they actually do that? Because there is a cost for them. You know, one thing we don't model here is we don't model a cost to the service of paying the reward. Right? So if I'm a network, say I'm a shared sequencer. I think a decentralized sequencer is actually like the ideal restaking network to think of that's different than POS because it's something where it is actually generating fees in the native currency because people are generally paying a neath but it may also have its own token rewards and it has a different security threshold. And basically there's a sense there, right, where like some of the income is an eth so that you can kind of view as, but it's variable depending on activity. And then some of the income is in the tokens which might be fixed but has variable price.
01:05:43.197 - 01:06:17.945, Speaker B: And there's a cost associated for the issuer, the service for creating those tokens. Right? Like they're diluting their market cap or you know, there's some liquidity costs you have to account for. And so yeah, you have to account for all of that to figure out like what, what sort of like how much is this tit for tat strategy of each of them raising their rewards going to work, right? Because they're paying. In this model we ignore the fact that the services pay a cost to increase their reward. But it's a good point that that's the natural extension.
01:06:21.575 - 01:06:51.121, Speaker A: I have another question. So given this result, like suppose this model is a good model that reflects the reality. Do you think this result says that Eigen layers and risk taking platform providers need to enforce conditions that ensures there is not much overlap between different services? Or do you think like it's the job of the like?
01:06:51.273 - 01:06:51.625, Speaker B: Yeah.
01:06:51.665 - 01:06:53.525, Speaker A: Who is better suited to do this?
01:06:53.905 - 01:07:30.405, Speaker B: Yeah, that's a good question. So I think so the, the one place I think the networks themselves should be kind of enforcing constraints is probably similar to proof of stake. So hidden in these proofs there's a lot of this. Do you see this like min over v sigma V? That is the like 32 eth min you have to stake in Ethereum it's like the minimum amount of stake you need to, to. To get into a service that actually you could imagine that there's a global minimum. Right. Like Eigen layer says no Eigen layer service is allowed to admit operators with less than 2e staked or something.
01:07:30.405 - 01:08:29.743, Speaker B: You know and I think that is where they should be actually using this control because the, that is where you can then make it easier to learn. Yeah, all everything else flows downwards from that. I think the services however should be allow. Should be figuring out how to optimize our rewards to do this. I think it's if the whole restaking network does it and they try to use their own token to do it then it really just becomes a single POS network and you lose the like network effect of I don't have to validate everything. And so I do think fundamentally the services should be controlling the rewards to lower overlap but the, the network can choose these kind of global parameters like the minimum amount to be safe. And, and, and again this is very similar in my mind to some of the arguments you see in Ethereum about issuance where you know, sort of people talk about like what should the issuance curve look like, what should the minimum amount stake be? And, and and I think in, in restaking those are separated questions.
01:08:29.743 - 01:09:24.151, Speaker B: I think the issuance curve is the responsibility of the AVs and the minimum stake is the responsibility of the network and a molesha. Any let me know if I missed anything? Nope. I like, I think the bigger questions are sort of what you had like going outside the model, what you had on your conclusion slide. I think like we can get stuck arguing within the context of this model about issuance and so on but I think like the principal agent problem in particular is maybe more first order. Yeah, yeah. The principal agent thing I think is the hardest part. There's also another question of like you know, in practice proof of stake networks have had far less attacks than proof of work networks.
01:09:24.151 - 01:09:58.685, Speaker B: Right. And there's sort of some natural reasons for why that have more to do with the opportunity cost of attacking is much higher. And so incorporating effects like that is actually quite important in a lot of ways. But yeah, look, I'm not saying this is the end all be all. I'm saying this is the beginning of the journey of restaking research. It's a little bit like defi papers in 2019 or proof of stake papers in 2017. It's sort of like I think people are starting to realize it's quite a rich area.
01:10:10.025 - 01:10:15.925, Speaker A: Well, thanks again for the presentation. It was awesome. Yeah, I'm very convinced to read the paper.
01:10:16.705 - 01:10:23.085, Speaker B: Awesome. I'm sure other I can. I can send the slides. Let me just fix all my typos so. Because I have a few.
01:10:23.835 - 01:10:29.755, Speaker A: Perfect. Thanks a lot. Thanks, Tarun. Thanks, Malish. Thanks everybody for joining. See you next week, hopefully.
01:10:29.915 - 01:10:30.235, Speaker B: Take care.

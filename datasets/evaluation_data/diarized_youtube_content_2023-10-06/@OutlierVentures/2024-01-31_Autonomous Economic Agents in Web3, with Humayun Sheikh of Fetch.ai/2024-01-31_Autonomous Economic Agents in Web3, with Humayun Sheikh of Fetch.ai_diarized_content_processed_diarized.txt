00:00:00.250 - 00:00:08.314, Speaker A: Okay. So today I'm really happy to welcome on the show Hamayan Sheikh, co founder and CEO of Fetch IO. Welcome, Hayne.
00:00:08.442 - 00:00:11.680, Speaker B: Hey, good to be here. Jamie, good to see you.
00:00:25.290 - 00:00:39.610, Speaker A: So we were just catching up offline. I haven't seen your new house. You haven't seen my new house. And then you're renewing your wedding vows in the summer. So we're going to get together, hopefully at some point in person. Obviously a lot to catch up on. We know each other pretty well.
00:00:39.610 - 00:00:57.582, Speaker A: I'm not going to spend a huge time covering your background or the kind of potted history as to fetch. The kind of headline is, we've been working together for several years. I think back in 1717 was when we met.
00:00:57.636 - 00:00:58.880, Speaker B: Right? Yeah.
00:01:01.250 - 00:01:41.098, Speaker A: We got history. We've covered that in other podcast episodes, albeit some time ago. So I'd recommend if people want to understand my background and the kind of backstory to fetch, you kind of go search that out. So let's get into what exactly fetch AI is. It's a software stack that you built over the last several years that allows for this kind of unbundling of AI into its constituent parts to allow for it to happen in a kind of more distributed and decentralized way. And the goal of that is obviously to remove intermediaries that effectively. Today, AI monopolies.
00:01:41.098 - 00:02:39.374, Speaker A: If you think in the context of most major functions on the web, we have these kind of large, centralized platforms with economies of scale, which effectively are now AI monopolies because of the data sets that they've enjoyed as we've trained their AI models. And in doing so, we allow more entities to participate in the AI boom, participate in the value that's going to be created. So let's get into that technology stack. As I understand it, there's kind of some key concepts. We've got agents, autonomous economic agents, we've got colarn, which allows for this kind of more distributed collective learning. We've got the framework that's then produced out of that. And then the most important part, I guess, which is we've not yet seen in the context of AI, is this execution layer, the ability to execute in an economic sense.
00:02:39.374 - 00:03:20.758, Speaker A: But maybe let's start just with what an AEA is, an autonomous economic agent, and how that's different to software agents, because I remember when we first met back in 2017, we were very interested in the convergence of blockchain and AI, but we weren't from your world, your world of machine learning, obviously, you're one of the early investors into DeepMind, which went on to become Google's AI competency. And you had this idea of agent based systems where you guys were innovating in this world of agent based systems. So what's different with an AEA to a software agent? And how are those enabled on fetch?
00:03:20.934 - 00:04:22.394, Speaker B: Well, I mean, in software terms, software agents are quite well known for a very long do in games. A lot of the time you set up these software agents which go and execute stuff and get learning, do some training. But the concept here was to bring it out in terms of actually individuals, businesses or tasks to give them the autonomy of execution. So hence the autonomous agents. Now, the economic part comes in from there is an element always of an economic value. That economic value could be visible or invisible or direct or indirect, but ultimately what you're doing is you're making more and more efficiencies to reduce cost, for example. Right? So the objective here is to give that ability for individuals and small businesses to automate these tasks without the need for building these big monolithic structures.
00:04:22.394 - 00:05:25.982, Speaker B: So to kind of create an analogy with Web two, if you look at what web two has done, is the microservices. The microservices architecture takes this monolithic thing and you can actually break it down into components, but ultimately it's still in a centralized way, and it's a big monolithic system which is now being broken down into microservices. So now if you extend that same concept out of the microservices, which is centralized into a decentralized space, that's when you get the AEAs. So what they are is they have service based agents which have some economic ability to autonomously make a decision on which you as an individual or a company would part to the agents to then execute that. So it's very similar to the concept of microservices. Just that in microservices you need to be on one platform in autonomous economic agents. One, there is an economic agency, and second, there is also this ability to decentralize the whole thing and to do it in a distributed manner.
00:05:26.046 - 00:06:05.120, Speaker A: The economic part is enabled because of blockchains, these kind of ledgers of account that now mean that value exchange between agents can become economic. And I know that we're probably going to get to that a little bit later with the execution layer, but I think that this idea that agents can collectively effectively form a market together. So the individual agent might be fairly dumb or fairly narrow in what it can do, what it can understand, what it can execute, but collectively they can kind of form effectively marketplaces right. Between themselves, they solve four problems.
00:06:05.570 - 00:07:18.806, Speaker B: So if you look at an agent, although it might be even dumb, but still has a use, right? So for example, if you said, oh, go find me a taxi, which is what we do all the time, and I will kind of use mobility as the use case. So if you think about that, what you're doing is it's a dumb task, it's just saying this is my requirement, go and find me something, right? And that's what if you take the example of these ride hailing services which say them in Uber being one, what they do is they take that request from you and then they convert that into a search query, which then goes and finds the other side, right? So that's all they do. Now for the minute, let's just come back to the machine learning side in a little bit. But let's look at the initial tasks that exist, right? Uber didn't start from being the big Uber that it is today. It started from a very basic service where at point A, somebody requests a cab or a limousine service and point B, somebody routes it to you to actually deliver the service. So it's that connectivity which is important. Even they're dumb, it still is the connectivity, but you can make them more intelligent.
00:07:18.806 - 00:07:47.794, Speaker B: So for example, the autonomous economic agent can use your context without passing it to anybody. So it can use the ability to collect data from you or you and use that in your advantage, to your advantage to go and execute something. And hence the autonomy is granted by you to the agent. So that's a little bit of a kind of difference there.
00:07:47.912 - 00:08:28.074, Speaker A: And I think that permissioning is important. And I like the idea of sovereign agents in that. Currently we've got platform agents, that survey platform. They serve the interest of the platform. We give them that permission by using that service. But effectively, all the data that's the byproduct of me using that platform is owned and controlled by the platform and is used to train their AI models to make their systems more efficient. And so again, sticking with Uber, that's routing it's price, discoverability, maybe some kind of preferences about the ride that then allows for these kind of monopolies to exist.
00:08:28.074 - 00:08:43.362, Speaker A: Because of course, with AI, it's all about aggregating data to better optimize that model to deliver a more optimal outcome. And it becomes very hard for a new entrant to come into the market.
00:08:43.496 - 00:09:09.782, Speaker B: I just want to make a little point there to kind of improve the outcome. For whom is the question. Right? Yes, the efficiency is being improved for whom? Not for the consumer or the supplier, it's for the platform. That's the whole objective. The objective is to make as much money in the middle. Right? So when you optimize it, you optimize it for the platform. Mainly, of course, there is obviously a component.
00:09:09.782 - 00:09:22.282, Speaker B: You can't optimize it just for the platform because then the service would fall short and nobody would use it. So they have to look after both sides. But what I'm saying is that the main objective of optimization is to make more money.
00:09:22.436 - 00:09:58.890, Speaker A: Yes. Value extraction from the exchange of value between the two sides of the marketplace. And so if you can decentralize or distribute that to the individual agents themselves or a representative agent, you remove the intermediary, you remove the costs. But that then begs the question, well, whose AI model is it that is being trained to coordinate these agents? And I guess that's where Colarn comes in, right? And it's called colarn because of collective learning.
00:09:59.040 - 00:10:56.158, Speaker B: Yes. Let's take an assumption that 10,000 people are using this new agent based ride hailing solution and there's 10,000 cab drivers who are also kind of providing the service. They're all generating data in one way, shape or form now. And that data at the moment is used by a centralized entity to train the machine learning model. So now what we're suggesting is that there's this machine learning model, which sits in the middle, which is a collective learning model. You have the ability as individuals, as the suppliers or the consumer of the service, to connect to that and train that model. Now what's the benefit? The benefit is it's the same data that's going to a central entity is now training this model, which is shared and collectively owned by the people who train it.
00:10:56.158 - 00:11:36.070, Speaker B: So all those 20,000 people, suppliers and consumers, actually own that model. So when somebody consumes that model, they have to pay for the consumption. So when I say consume, I mean either you kind of give the model to somebody or sell the model to somebody, or somebody takes a prediction from that model. So for example, here's my GPS coordinates. Give me XYZ. Right. So when you pay for that model, the colon architecture distributes that income or that economic value to all the people who've trained this model or provided the data, or provided the compute.
00:11:36.070 - 00:11:37.866, Speaker B: So it gets distributed to everybody.
00:11:37.968 - 00:12:30.054, Speaker A: Exactly. I think that's when it gets really exciting. Right? So if you imagine every platform, in simplistic terms, as an AI model, whether it's Uber, whether it's Google search, you name it, if you imagine that as an AI model. And you imagine that however it's predefined when it's set up, participants who are training it, especially in the early days, can effectively take a stake. They become stakeholders, owners, shareholders, actively in this AI model just by using it. So just by doing what they would normally do with Uber, they get hopefully the same or better service, potentially cheaper than the 20% fee, and they get to get a stake in the network. And you can imagine that becomes very powerful from bootstrapping perspective.
00:12:30.054 - 00:13:02.822, Speaker A: Well, why would I shift between Uber, which works very well, to a new platform? Well, if I can get a stake in it, and we've seen that work very successfully with tokenization of protocols more generally in Web three, there's kind of just a quick point because I know that the more kind of technical people might be thinking, well, what about oracles here? But I know that the way that you're looking at is that you would just have oracle agents, right. Oracles become another form of agent that are contributing to the system through like a data API or something.
00:13:02.876 - 00:13:21.462, Speaker B: Right? Yeah. So really what our objective is, this is not just about one chain, right. This is about the whole ecosystem. So interoperability is very important. Right. So you might want to do something somewhere else. You might want to transfer the economic value from one chain to the other chain.
00:13:21.462 - 00:14:03.866, Speaker B: The problem web3 has been having recently, as you will see, is that there's a lot of this incestuous trading, which is very enclosed, but we still haven't managed to bring real world use cases in a meaningful way onto the chain. There's a lot of financial solutions, which is great because that's also a reason to have this decentralization, but it's not really the value generators. So when I look at financial systems I think of like share trading, token trading, whatever they are a manifestation of real value somewhere else. Right. What we have not done in web3 is to bring that real value on chain yet.
00:14:04.048 - 00:14:06.890, Speaker A: Yeah, real world value exchange.
00:14:07.230 - 00:14:58.390, Speaker B: Real world value exchange. In terms of when you mentioned oracles, we're not saying, oh, one day we're just going to shut the shop for Web two. No, that's not the point. It's Web 2.5 because you're going to have oracles who are going to bring data from centralized sources from web two to bring into web3, because unless we are receptive of it, we will not be able to overcome the bootstrap problem because there's a lot of infrastructure which already exists in web two. We have to use it, we have to kind of bring it to web3 and then find solutions which don't exist and build them for web3. So that's really one of our key kind of themes, which is how do we bring the current infrastructure? And I gave you an example of microservices.
00:14:58.390 - 00:15:22.290, Speaker B: It already exists, why reinvent it? But it doesn't exist in a decentralized manner. And that's what we're kind of trying to do. Because you can build services, but how do you bring them onto chain? How do you bring into the decentralized world? You can take it, you can connect it to an AEA, it could be called an AEA oracle, it could be called an AEA service, call it whatever you want, but that's really the theme of it.
00:15:22.360 - 00:15:52.922, Speaker A: So let's talk about the framework. So we've done AEAs, including oracle agents. We've talked about co learn, collective learning, and how people can then collectively own people or businesses, entities could, DAOs could collectively own those models. And of course those models could overlap. So if we're thinking about multimodal transportation, I. E. I might want to use a taxi, a train, a plane, I might want to walk for part of it, I'll need to know the weather effectively.
00:15:52.922 - 00:16:40.938, Speaker A: You can have those models overlaid. And so I remember going back to even when we were thinking about what we were calling fetch AI, that kind of concept of fetch is that as a person, as an end user, you can just put your kind of ask into the system and it will be coordinated for you real time. Right. And if something changes, then that system is dynamic and it makes that change on the fly, effectively. So I think your plane gets canceled. Well, you figure out the new plane, adjustments need to be made to the taxi ride, when you're getting picked up, the other side, et cetera, et cetera. But let's talk about the framework.
00:16:40.938 - 00:16:44.618, Speaker A: So what's the framework? Component of the stack?
00:16:44.714 - 00:17:04.290, Speaker B: Right. So we call it open economic framework. But it's not just economic. Let me split it into two sections. So the framework is how do these things interact? So we're laying out the initial kind of workbook for that. Right. So we're saying, okay, these agents can interact with this.
00:17:04.290 - 00:17:53.170, Speaker B: I mean, how do we give the name service for agents? How do you search and discover the agents? That sits in kind of one side of it, and it's open, so you can actually come in, you can say, okay, I don't like this way. I'm going to suggest a new way. You can make it, improve it, it's open source, right? So hence the term open. The economic part is the marketplaces. So if you think about what you can do with such a service, there is no limitation. As you said, you could use it for mobility, multimodal transport. Now, if you think about it with this chat GPT generative AI, what is really interesting is that it's a user interface.
00:17:53.170 - 00:18:53.206, Speaker B: Our ability to communicate with the machine has just become easier, but you still need to execute these tasks that you are actually just going to generate. So what you have now is these marketplaces, which is going to come up. So your travel from point A to point B includes you drinking coffee, having lunch, finding a taxi, booking a flight. So all of these overlapping marketplaces, which certainly sit in a silo at the moment, because how we've evolved doesn't have to be that way. So these marketplaces bring the economic component onto the open economic framework. So we're building and we're enabling people to deploy these marketplaces, the search mechanism, the discovery, the actual going out and kind of providing the relevant results to these agents to make the decision. And that's the economic part of it.
00:18:53.206 - 00:19:27.470, Speaker B: So the open economic framework enables you to do the kind of auto protocol generation between the agents. It also enables you to build these marketplaces. I'm not saying you have to build them, it's more a process of, okay, one agent says, I want X, the other one says, I'm selling X. So how do you connect them together? And once you connect them, there's a marketplace, right? What is the framework? What is the protocol? How do they communicate? How do they find each other? That is covered in the framework.
00:19:27.550 - 00:19:53.978, Speaker A: So as you say, you look at a lot of the generative AI stuff at the moment it's great, but it's largely just producing media, and it doesn't really do much very else other than, as you say, allowing you to maybe communicate better with machines. So it could be a UX in which you could verbally or in written form communicate with a machine for it to better understand what you want.
00:19:54.144 - 00:20:04.846, Speaker B: Yeah, I mean, it's a very good example. If you ask it to do, could you go and book me a flight? Well, I'm not connected to that service. It will tell you the best way to do it, but then say you.
00:20:04.868 - 00:20:58.522, Speaker A: Still have to do it. Yeah, right. And similarly, it could be plot a route for me. You're still going to have to navigate that route yourself, and if something changes, you're going to have to manually adapt to that on the fly. And I think the minute that you create a framework in which agents, a device could have an agent, a person can have an agent, a company can have an agent, an individual retail store could have an agent, a seat on a plane could have an agent. All of these things, because they now have these protocols, can start communicating with one another and optimize against whatever function they've been given and effectively negotiate. And presumably the outcome of that is actually the world gets optimized.
00:20:58.522 - 00:21:33.340, Speaker A: And I think the example I use, I really like at the moment I'm thinking about trying to do a presentation. Maybe we can work on it together. Is the death of search, death of search, death of websites. Because if you think about most of the stuff we do today, it requires you as a user to go to Google, try and help Google understand what you want through multiple searches, navigate websites, and their ability to help you discover what you need or not, all the way through to then finding out the thing that you finally want isn't available in stock or something like that.
00:21:34.430 - 00:22:21.510, Speaker B: Architecture at the moment, yes, I agree. And that's exactly the point we're trying to bring to the market, is unless we change the whole system, it's going to be very difficult to change it the way we are. And taking your point of Google search, if you're looking for a document, you're not going to find a better place, right? You're going to find it there. But if you are looking for a document and you need to compare ten documents and you need to get the output of those ten documents, I mean, that's where we're heading into the action site, which is now kind of what Bing has launched. And I'm sure Google will also do the same. What they're doing is they're looking and going through the information, the text. These are large language models, right? So they go through text and they produce the results.
00:22:21.510 - 00:23:09.878, Speaker B: But what mean, I can't think myself if I need a product these days, I don't actually go to Google to search for that product. I'll go first to Amazon and say, does Amazon sell the product? Now, this is the example of search changing. So if I need to do an action, just coming back to your point, if I need to do an action, which is like, I want to book travel, I don't need to go to Google, I go to booking.com, right? But then I have different components of that travel because I want to book a cab, I want to book a train, I can't do that from booking.com. I have to go and do the work. What we're closing is you say that stuff using the large language model type approach, the chat GPD approach. You explain this to your agent.
00:23:09.878 - 00:23:29.918, Speaker B: Agent already knows your context, it already has access to your calendar. It's a task that you want it to execute, and it should do that without the effort. The onus is not on you to find things. The onus is on the automation tool to find you things. And you can then choose, yes, no, maybe, or give me some more.
00:23:30.084 - 00:24:19.840, Speaker A: Yeah, and this is interesting because you see what Microsoft Bing's doing with chat GPT. It's this faster horses kind of analogy. Ford when people ask them, do you want a car? They said, we just want faster horses. When Microsoft looks at chat GPT, it thinks somehow this is going to allow them to just do search a little bit better. But ultimately their model, business model, same as Google's, is ads, it's selling ads. And so all they're thinking about is ultimately click throughs and ads, not necessarily how they can help you find exactly what you want and action it perfectly. And I think this is the really interesting about sovereign agents.
00:24:19.840 - 00:26:12.302, Speaker A: So if you think about something like Alexa, at the moment, I have Alexa in certain parts of the house, but I generally feel I turn it off a lot of the time. I feel uncomfortable with Alexa just listening to everything, because I don't want Amazon to know everything about me, I don't want them to have complete context to me, because I know that the lecture is an agent that serves a platform, actually over my own interests. But if there was an Alexa that I trusted fully, because I could audit its ownership, I could audit its logic, or somebody could, then I'd quite happily have that on my mobile device. And for as long as it's on, it could be recording me to know my context and then to predict my need before I've even thought of it, and to carry out actions on my behalf. And that is a total paradigm shift. And I think when I see what's happening with chat GPT, and you think about how that could be used by platforms or by malicious actors, it actually feels like an AI arms race. Just as a dumb user, me on the other end of trying to navigate the web, where how can I trust anything anymore? How can I trust that the entity that I'm dealing with on the other side, in the best outcome, is an agent serving a platform, not a malicious agent pretending to be a platform, let alone then what's going to happen with it? And so I think now is the time where we, as users of the Internet, of the web really need an agent that we can trust to navigate that environment.
00:26:12.302 - 00:26:18.360, Speaker A: Right? Navigate platform agents and malicious agents, yeah.
00:26:18.890 - 00:27:14.866, Speaker B: Just to add to that point, if you think about what you're doing here is all these agents that you interact with, they optimize for the platform, right? And again, even if you leave that aside for a second, and you just said, alexa, go and book me a taxi. So, yes, you have interconnected services, but now you're connecting in a very inefficient manner. One platform to another platform to another platform. Ultimately, you want to just go to the cab driver and get a taxi, right? So if Alexa were able to just go straight to the taxi on your behalf and just book it for you, you'll cut out all the platform work. Right? So it's quite inefficient, even in technical sense. Machine learning must be definitely faster if it's in a centralized place, in one location and all of that. But for me as a user, it's very inefficient.
00:27:14.866 - 00:27:18.620, Speaker B: The amount of people I have to pay to get to a point.
00:27:19.630 - 00:27:58.594, Speaker A: Each platform is having to relearn the context is the point, right? Whilst if that's in a distributed sense and you have your sovereign agent that has complete awareness of your context, then it will know you've confirmed a flight at 05:00 p.m. From Heathrow airport. It knows that you normally take a taxi, it knows you like to get to the airport at least 2 hours before the flight. It will just book the taxi, it will send you a text message or alert saying, by the way, maybe it asks you to confirm it, or it might just, again knows your preference and it knows you. It's effectively your personal assistant, right?
00:27:58.712 - 00:28:25.230, Speaker B: Yeah. So paradigm shift is definitely coming. It's going to be difficult for these big organizations to actually adapt to that because of their revenue model. And you made a very fair point. It's all about ads, it's about selling. For me, it's really inefficient. I don't want to look at 10,000 ads, I just want to get my stuff done.
00:28:25.230 - 00:28:27.726, Speaker B: So why go through that pain?
00:28:27.908 - 00:29:00.790, Speaker A: It's also inefficient for the advertiser because if you look at the conversion or click throughs on ads, it's like anything close to 1% is a great outcome. So think about the huge amounts of money that advertisers are wasting on trying to convert into a sale, where you could imagine a retailer would just have its agents negotiating, maybe even negotiating on price with your agent or whatever preferences.
00:29:00.950 - 00:29:07.354, Speaker B: Even if you leave that bit out, just the ability for me to find what's in their stock when I need.
00:29:07.392 - 00:29:13.398, Speaker A: It directly my size, which could be delivered within my preference without the need.
00:29:13.424 - 00:29:31.966, Speaker B: To go through ten other search mechanisms like going through Google, then going to Amazon or somebody else and then connecting with their website and then giving them my context and login details and everything else and then ultimately finding out that the size doesn't even exist. That's very inefficient.
00:29:32.078 - 00:30:09.166, Speaker A: Yeah. So maybe just finally we close off on the partnership with Bosch announced. What date are we today? We're like the 23 February, I think it was yesterday, 22nd you announced the launch of a foundation with Bosch. I know Bosch is a partnership you've had for a very long time now in different forms. Can you talk about that partnership and why now? Why have they pulled the trigger now on this? I know you've since at least 18, right.
00:30:09.348 - 00:31:22.886, Speaker B: I think you're fully aware of well, the long time ago we started speaking to Bosch. So what I think changed perhaps now is the ability for these big organizations and entities to realize that paradigm shift is coming, right. They're not going to be able to stop it. They need to be part of it if they want to stay relevant. And Bosch actually I think is one of the most forward thinking kind of companies I've kind of worked in this space now an old enterprise who is very forward thinking. So that's what I mean, there's plenty of startups of course, but what we have been working with them is they wanted to be german entity, very conservative, they want to make sure everything is right. So they went through our technology, they went through our concepts, they went through everything that we have been doing, why we have chosen things, why we have not chosen things and trying to evaluate even our decision making process, even speaking to me multiple times to find out what I think needs to happen.
00:31:22.886 - 00:32:47.678, Speaker B: So they've done their due diligence in over three years probably now. And what became quite apparent was that yes, there are components, there's multiple chains available to execute the transactions and there might be other things like oracles or these components exist, but there is no place where all of these are coherently put together so that they actually work to deliver the task which needs to be done. So for example, the ability to train models. They have a lot of data, their devices have a lot of data, but they don't own the data. The consumer owns the data. How do you train a model where you don't perhaps take the data because of data privacy? But you can offer a service to your consumer that if you buy a washing machine, for example, you could be training a model and actually getting paid back on that washing machine, right? So these are the kind of things they looked at, and mobility being one of their most important use case, where the car, the value extraction is not just about providing the car, the hardware, it's about how you can actually use overlapping verticals to unlock new economic values. So, for example, if you're driving in a car and you need to charge, it's an EV charging.
00:32:47.678 - 00:33:26.922, Speaker B: How does the user benefit from an agent is auto booking and making sure the time is there to book and charge while they're charging? They could be ordering a coffee. The agent, I mean, everything has to be seamless because that's where we're going. And that ability to do that only exists on a fetch platform at the moment. Right. There is no restriction on other people issuing new services, and we'd love to integrate them. And that's also one key point, which Bosch is very focused on, is that there has to be interoperability. And we are of the same opinion that we can't do it alone.
00:33:26.922 - 00:34:01.574, Speaker B: It has to be because it's a paradigm shift. We need partners, we need collaborators, we need people to build these services who they can execute and sell to the agents, rather than in a centralized manner, do it in a decentralized manner and benefit from it. So all these components kind of led them to this whole foundation, and it's kind of a big validation for us. I mean, we're really honored that they have actually decided to join the foundation, not just as a joinee, but as a partner.
00:34:01.702 - 00:35:03.126, Speaker A: Yeah. And obviously, presumably a sign of more to come, right? More kind of partners coming in. I remember conversations I had with Bosch back in the day when they joined the Iota board. So they have been incredibly forward thinking in experimenting and trying these things out. I think that was even back in maybe 1718 that the way that a lot of these manufacturers of things have thought about the direction of travel is if they're just left creating the things and they're not kind of participating in what happens. The data that's produced by those things, the AI models that train by those things, then effectively that's a race to the bottom versus the googles of the world. And so it makes sense for them to kind of collectively come together and to be able to participate in the value that's created from the things in the Internet.
00:35:03.126 - 00:35:05.982, Speaker A: Of things. They want the stake in the Internet, not just the things.
00:35:06.036 - 00:35:06.254, Speaker B: Right.
00:35:06.292 - 00:36:06.666, Speaker A: And I think that's a really powerful way of thinking about it. Well look, congratulations on that partnership. As I said, I know it's a long time in development and I know this year is going to be a really exciting one for you guys and I just think it's been great to see. When we made our investment back in 17, I think a lot of people just, it felt like Sci-Fi when you tell them about fetch. And I think now it's starting to feel very real and I think generative AI is hopefully starting to, the boom is starting to give people the context but it then also asks all these questions like how open is open AI and I think Colarn speaks to that, right? Or well, how can I begin to execute beyond just kind of producing a little bit of media. So definitely recommend people check out what you guys are doing. Thanks for coming on mine.
00:36:06.778 - 00:36:09.740, Speaker B: Thank you, Jamie. It was a pleasure and hopefully speak soon.

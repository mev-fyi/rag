00:00:06.650 - 00:00:41.446, Speaker A: Hello everyone, and welcome to this tech Tuesday Outlive Ventures. With me is mudit Marta, technology analyst. I am Aravonomas, CTO and founding partner of Outlive Ventures. And we have Afri Sheldon, who is many things, but has done many things, but I'm calling you e two multi client testnet pioneer and Ethereum community member and contributor, and many other things. Yeah, really happy to have you here. And today we'll go into e two. We're running this on crowdcast.
00:00:41.446 - 00:01:33.580, Speaker A: We're also streaming to Twitter and YouTube, and the session will be recorded and available on our YouTube channel. So plenty of opportunities for people to see this. I'll give you a very quick intro on Ethereum two. The wire process and the launch of the Beacon chain last week, which was of course a high point up to now and what's to come. And yeah, then we'll get into discussion about that. I hope to get many questions from the crowd, but we have plenty of subjects in case we don't go into those slides. And then Afriel gives you a chance to introduce to the audience, of course, as well.
00:01:33.580 - 00:02:53.458, Speaker A: So of course, brief disclaimer, although I don't think we'll say many things that could be interpreted as investment advice, but we're not giving any. So why Ethereum two? Why is this even necessary or desired or otherwise? Well, ultimately there's many things of modernization and technological improvements, but the main reasons are really migrating from proof of work to proof of stake and greatly increasing the capacity of the Ethereum blockchain. So proof of work to proof of stake. So going from those big number crunching data centers to ideally just lots of little devices, user operated in people's offices, homes or otherwise, because you don't need more than that. And with regard to capacity, Ethereum has been running basically at capacity for a long time because this is the gas used history. This doesn't 100% translate to transactions like amount of transactions per second. But basically the room that was available in the blockchain has largely been used.
00:02:53.458 - 00:03:22.430, Speaker A: It's increased slightly over time by adjusting some parameters, but for the better part of two years, it's been running at capacity. So there should be more to make more possible. So yeah, the e two upgrade makes a lot of that possible. We'll have to see how hard that chart will go once the capacity is there. But that's one of the main ways to do it. Now, the roadmap is very simple. No, it's not.
00:03:22.430 - 00:05:00.720, Speaker A: Okay, well, this was Fatalak's idea about how the future of Ethereum could look five or ten years in. But fortunately there's a simpler roadmap where through a process, a multi year process, that the innovations have been researched and done and tested to get to the point where we are now, where there's been lots of research on combining sharding and proof of stake and proof of stake in the first place. To make that possible in a more decentralized manner, formally specking it many testnets and the launch of the deposit contract, which was a few weeks ago, and the actual launch of the beacon chain called phase Zero, which was exactly one week ago. And from here on out we'll go to phase one, one and a half and two, where the Ethereum main net actually migrates to the Ethereum two structure interacting with the beacon chain and then ultimately making many sharded blockchains possible, each offering a lot more capacity than the current chain and a further vision on scaling as recently presented. Like sharding and the begin chain make things possible once the main chain is migrated there. But it's not the only way towards increasing capacity. ZK roll ups make increasing capacity possible as well, and you can combine the two to basically multiply what you get.
00:05:00.720 - 00:05:48.300, Speaker A: So we never see the unit here somehow on what the timeline is. These things get delayed as reality strikes in, but results happen. And at some point we might have thousands transactions per second, or hundreds of thousands of transactions per second. What we know now is that we have a beacon chain. So that has been realized. There was a launch pad created for that, which I think was well done or polished for user to participate in this. Get your EtH to the post contract, get your node set up, which software can you run? What do you need to do? Quite clear explanations and enabling everybody to do what they needed to do.
00:05:48.300 - 00:06:57.198, Speaker A: And the chain was launched was a live stream, which reminded me a bit of the rocket live streams as you get them sometimes, yet not quite, because these were all dudes in rooms. But the fun thing was like there was a bit of the excitement and attention of oh yay, the first block is in and oh, now we have the first debug done. And you could see that a lot of people were definitely looking out for this. You can go for years with so many bug fixes and testnets, but in the end it all has to work. And it did. So that was good to see. So the current stage where we're in with phase zero, what does that do and what doesn't it do? Well, it does a few things which haven't been achieved before, which is proof of stake consensus with, well now I think 20,000 plus validators, independent validators through finalization.
00:06:57.198 - 00:07:47.390, Speaker A: So not diverging like getting rid of the risk that you might have after so many blocks, still the chain being reorganized, the nodes come into consensus of well, this epoch is closed off, it's finalized, that's it. We're not accepting any changes here anymore. And it keeps a record of the validation mechanisms that does that now and later for the shards. Once the sharded infrastructure is introduced, it will keep that role. But it does not do many things, a whole range of things that you would expect from blockchain. It doesn't allow you to transact, it doesn't have accounts, it doesn't make any transfers between accounts because it doesn't have them. It doesn't allow you to withdraw your ETH.
00:07:47.390 - 00:09:09.562, Speaker A: So anyone who has deposited their ETH into the deposit contract and now is on the beacon chain that ETH isn't coming out anytime soon, then do smart contracts. So that's sort of manage people's expectations. It's something that facilitates and I guess one of the main reasons to want to have it out now is just to get experience with it, to see if the proof stake mechanism with so many validators and all the new code and the different clients where it works out in practice, but the actual usefulness is still to come. Well, we've come here through many testnets, which Afri, you've played a big role in as well, so we'll get into that in far more detail later on as well. They all had good names, so I want to know more about that too. And yeah, again, metrics over time. Also something we'll go into deeper a bit about the deposit process because of course a few months ago we had the yield farming craze and now there was another bit of a craze of hey, the two deposit contract is now live.
00:09:09.562 - 00:09:47.400, Speaker A: There are supposedly up to 20% yearly returns. We need to get our deposits in. There was some fomo there. You can see the history of the amount of Eth that was sent into the deposit contract. So this, I guess here where my mouse is just slightly after November 22, that's I think the date of the launch or slightly before it. So there was a bit of a slow period, but then suddenly people started fomoing all over each other. And up to today still deposits are coming in and that can still be done.
00:09:47.400 - 00:11:09.970, Speaker A: Every validator needs to have exactly 32 e deposited for it to be eligible to validate on the beacon chain, and that's still being done. And new validators are still coming online as they are now being allowed. So we're 1.2 million eth, which is quite an impressive number, especially considering the fact that that's never coming out unless the further roadmap is actually progressed. And so unless the beacon chain actually gets useful and gets this withdrawal functionality now, some people apparently have bought into the fomo, but not quite followed up on it, because it's not a case of just making a transaction. No, you have to make your transaction, you have to actually run software, you have to secure your keys, you have to run a node for it to participate to get yield. And if you're not doing that, you're actually losing deposits, like losing part of your 32 e deposits, because as one example, there's about 100 or slightly over 100 of these transactions where somebody has made a 32 ether deposit, and now this is stuck on the ETH one, the current chain, you can see, hey, 32 ether has been deposited.
00:11:09.970 - 00:12:26.954, Speaker A: And here we look at the beacon chain explorer, and basically they haven't validated any blocks, they haven't proposed any of the blocks that they were allowed to propose, and they've lost up to now 0.869 ETH, or Beacon ETH as you might call it, or might not, where of course they'd have to go through all this checklist, set up a system and a firewall and install the node software and do all of those things that come with infrastructure to actually make that run. And yeah, as I said, there was about 100 of the many validates which still haven't started. But then again, there's 26,000 plus who have run now are running their infrastructure, so that's good. Now we've seen one of the big goals with the proof of stake infrastructure, and especially with this proof of stake infrastructure, is to make it possible to have many independent validators. And you can't 100% sure say whether validates are independent. You can for some say that they're not, or likely not.
00:12:26.954 - 00:13:30.830, Speaker A: Because if, for example, the deposits for five validators were all made from the same Ethereum one account, well then you can be pretty sure that those five validators are actually operated by a single entity. And there's quite a few cases of that where very large entities have made lots of deposits. But even if they're made from independent Ethereum accounts, it still might be one entity behind that. But anecdotally, you see a lot of people saying on social challenge and et cetera, that they are actually running their own nodes and running them in their own environments and their own hardware. So there's definitely a good amount of that. But we're also seeing that basically all of the large entities, the exchanges, the staking providers, and where that overlaps, they're all running e two infrastructure, and they're all offering this to their clients because of course, not everybody has 32 e. What's current valuation? Like $15,000, I don't know.
00:13:30.830 - 00:14:39.400, Speaker A: To spare to log into a node that they run to manage the keys, to manage that whole infrastructure and to get the rewards. So yeah, you might just want to take your one and a half e or whatever you have, go to a kraken, a figment, the binance or whatever, and well, get me the rewards minus your fee, please. So it makes sense for them to do that. But of course there's a lot of people who are running their own infrastructure, and companies like projects like Dapnode make that a bit easier to basically have out of the box version of a system with an operating, like a node with an operating system and then necessary libraries and node software to get going. So yeah, I'd like to talk a bit about that further up as well. That was all for my 50 minutes intro. How am I doing 50 minutes? That's not too bad.
00:14:39.400 - 00:15:01.022, Speaker A: As you afri, could you give a bit of an introduction? Like, how did you get into Ethereum? How did you get into involved with e two and the things that you've done there? It.
00:15:01.156 - 00:15:30.690, Speaker B: Of course. Thank you. Thank you for inviting me. I've been active in Isum community for a couple of years now, and everything started with a small nonprofit project. I was working on doing some blockchain research, and I believe in 2015, when I were kind of forced reading, the.
00:15:30.760 - 00:16:03.620, Speaker A: Ethereum sounded quite robotic. I don't know if there's anything you can do about that. It was good before when we tested in the green room, but now it's been really robotic. Seems like a network issued it.
00:16:05.270 - 00:16:07.300, Speaker B: Network is fine on my end.
00:16:08.310 - 00:16:20.546, Speaker A: Okay. Yeah. Still quite robotic. It. Yeah. Well, let's go for it and see if it's. If it's understandable.
00:16:20.546 - 00:16:26.120, Speaker A: If it doesn't, then let's try to resolve it in some other way. Okay, go on.
00:16:28.590 - 00:18:13.930, Speaker B: Yes. What I was saying is that I was reading the Ethereum white paper and immediately fell in love with the idea and with the potential of extending the blockchain idea with some higher abstraction level by adding some so called Turing complete programming language or execution environment on top of blockchain. And this is how I got involved with Ethereum community, not only in professional life but also in my private time. And I joined the Ethereum community. I became moderator on Reddit, I helped up building the Ethereum Stack exchange, and later on I joined parity technologies where I was doing release coordination for the parity client. And today, earlier this year, I started looking into ethereum two how it can be of any contribution to this years of effort working towards staking and development of the beacon chain. And I just helped with orchestrating the different east two clients with trying to make them work together and spinning up various multi client testnets.
00:18:13.930 - 00:18:30.190, Speaker B: And this eventually concluded into a mainet launch for the beacon chain last week. And I guess that's where we are now and why we are having this conversation.
00:18:32.370 - 00:18:59.180, Speaker A: Great, thanks. Yeah, I paused this slide with the various testnets. Could you tell a bit about that history? Like there's the single client testnets, then where there's various iterations of multi client testnets. Firstly, what did the history look like and why were there so many testnets? Why was it necessary? What was learned on the way?
00:19:02.430 - 00:20:03.398, Speaker B: Yeah, sure. So you have different stages or different stages of development, and you always iterate over the different stages until you come to a point where you go into the next stage. And when you implement these two specification in one client prison, was the first client written in Glo Lang, and then other clients joined or other teams joined building other reference implementations in other programming language. And before you can do anything, you basically have your own test suite. You run your code against some kind of conformance tests, and at some point you want to actually make this thing run and do something. And then you do get into a stage where you stop the simulations and you start putting up actually developer testnets. They are kind of not public and they are not of any value for the community or a broader audience, but just for the specific client team working on a single client.
00:20:03.398 - 00:21:34.214, Speaker B: And once you get to a point where you are satisfied with as a developer, as a house client is working, you get to a point where you want to actually have public testnets. And the most popular public east two testnets were the ones by the Prism team, which had the toppers and Onyx and the Sapphire testnets, where they had their own onboarding infrastructure, and they basically had large scale community run tests with a lot of validators. But then again, this is only one client and you need many more steps to get towards the main net that comes with a broad client diversity. And this is when I stepped in earlier this year and started helping to just actually taking these existing modules and plugging them together. And after some testing, I found out that the Teco team, which is the Pegasus team, building AAvA implementation of the east two spec, a fairly young client, they were building their client or testing their client against the lighthouse east two client, which is a rust implementation. And so I realized that it's really easy to make these two clients work together. So I kind of taught myself how to actually launch a beacon chain.
00:21:34.214 - 00:22:17.240, Speaker B: So I had to deploy a deposit contract myself on the girly testnet, and I had to do some validator deposits and create a chain spec. And then I feeded the chainspec into Tegu and Lighthouse. And then I was super happy when I realized that both these clients are actually able to run on the same network. And I quickly shared these findings with the client teams and they were also kind of excited. And then from there on, we iterated this first testnet, didn't even have a name, but then we tried to coordinate on a target version number of the specification and tried to release one testnet with validators from both the Tico and the lighthouse team. This was the Schlady testnet. Excuse me.
00:22:17.240 - 00:23:11.480, Speaker B: And then with each iteration of development in parallel, the researchers or the client teams were like updating the spec and the spec get new version bums. Sometimes we had breaking changes, most likely in the communication layer. And so whenever there was a new version of spec, we discarded the old Testnet and came up with a new Testnet. Then there was a widow testnet, which added prism. So we launched this testnet with three different clients as validators, and there were a lot of bugs, and it was really interesting to track them all down. In a way. All these clients that participated in these networks were able to stabilize their code and be more certain about their testnet readiness, mainnet readiness at some point.
00:23:11.480 - 00:24:31.970, Speaker B: Then we launched Altona Testnet, which added the Nimbus client in Genesis. So we had four different clients as Genesis validators, and we kept going on until we reached the quite popular Madasha milestone. The medasha testnet was intended to launch with five clients adding the Lodestar client. However, Lodestar was never really intended to be a client, and they were like, I'm really sorry for putting so much pressure on the chainsaft team. The Lodestar is more of a collection of typescript libraries for east two, and it's a very important project, but it's not, never meant to be like a mainet or Testnet full node implementation, even though it's possible to run a Lodestar node, it's probably not the main use of Lodestar. But then again, Midasha was quite successful and this was the first really public community run Testnet because we publicly announced deposit contract and asked community members to pick their own client, run their own node and make their own girly deposits. I think was the first time we actually tested the launch pad in Midasha.
00:24:31.970 - 00:25:47.580, Speaker B: And this testnet was also really interesting because we were able to maintain it very long. We had a major incident after a couple of weeks, but we managed to resolve it. And basically after that we came to the conclusion that we are getting ready for a main net launch. And what we did then is doing these so called dress rehearsal testnets where we just simulated the beacon chain launch. So we just took all the clients in their latest state deposit, did a small deposit contract and just simulated this entire launch procedure doing the first three epochs, and then discarded it again. There was Spadina, there was sync and a couple of more testnets. And in parallel to this efforts there were also these attack nets efforts which are small managed test nets that were specifically set up to being taken down by researchers or security engineers or any other who can find any weakness in the system.
00:25:47.580 - 00:26:03.730, Speaker B: And this was just another step in parallel to further stabilize these client implementations. And I think that's where we are now. After all these testing efforts, we have a main net launch.
00:26:04.070 - 00:26:06.206, Speaker A: Yeah. And it worked. Congratulations.
00:26:06.318 - 00:26:09.438, Speaker B: Yeah, fairly smoothly.
00:26:09.614 - 00:26:38.620, Speaker A: Yeah, several things to get to that one question that I had you already answered, I wondered, is there like a fifth client or a 6th client? Well, there sort of was, but not quite. By the way, I think it's already really impressive to have four main net ready clients, but yeah. Do you know of any other efforts to build yet another client beyond like Lodesh you mentioned, or others?
00:26:40.050 - 00:27:52.462, Speaker B: Yeah, I mean there have been a lot of attempts and there are still teams building towards such, working on such efforts. But really for mainnet it basically breaks down to three or four clients. So I mean we talked about Lodestar, which has a brilliant team and they have created so much value in creating all these libraries. It just kind of put them in an unfortunate lighting when this launch kind of didn't work out for their validators. But then again, they still add a lot of value to the east two ecosystem with all their libraries and services they build. You also have the Trinity team from the assume foundation, which kind of works on Python implementation of the east two spec, but they are not I don't know what the latest is on this, but they are working towards this, but they are not as close to production readiness. And the other teams, and then I think there were just some teams that dropped off, I think the harmony team which had different yava implementations.
00:27:52.462 - 00:28:10.330, Speaker B: I think they just merged with teco team. And eventually there was this effort by parity technologies to build this shastba client, which was another rust client, but it was deprecated in very early stages.
00:28:10.990 - 00:28:24.480, Speaker A: Right, I see. Do you have an idea about client diversity for the current main net? Like how many people are running lighthouse or prism or I guess, is it even possible to see?
00:28:26.210 - 00:28:52.710, Speaker B: I think there's a web service for that. Let me just pull it up. I think it's called east two nodes, but I'm not entirely sure. No, I don't know. I know that you know this website east nodes, which is basically scraping the Ethereum one network, and I'm pretty sure there is an east two equivalent. I just don't have the name handy right now. East two nodes.
00:28:52.710 - 00:29:24.130, Speaker B: Oh, it's just called east two ether nodes and it says 100% prism. Oh no, that's midasha. Okay. It's not maintained. You have it here, it's existing, and I think they will probably put some work into extending this. But then again, it's probably easier to just go to. Short answer is no, I don't know that.
00:29:24.130 - 00:30:01.920, Speaker B: And I could just give poor guesses. But if we had time and could run some analytics, we could, for instance, go on beacon chain explorer and go into the blocks and just look into the graffiti, because some clients have a default graffiti. So here's one block proposed with tico version 20120. Then there's one proposed with Lighthouse. So you could run some analytics on this and maybe do some interpolations or guesstimates on how the clients are distributed. But these are just. Here's a nimbles one.
00:30:01.920 - 00:30:10.506, Speaker B: Yeah. And so there are ways to estimate this probably, but it's not very accurate.
00:30:10.698 - 00:30:24.850, Speaker A: There's no way of telling really. Yeah. I put beacon chain on for light blocks. Indeed. You can see well, this is possibly steak fish because they tend to use the fish, but here you see Lighthouse. Indeed. Nimbus.
00:30:24.850 - 00:31:04.820, Speaker A: I'd be interested to know, since so much effort has been put in making it possible to run with multiple clients, would be good to see whether people actually doing it or 95% ended up running one of them. But yeah, good, test that then. Maybe back to this slide. You posted this. What are we looking at? What is this?
00:31:08.470 - 00:31:20.998, Speaker B: These are two charts next to each other. Let me just pull it up on my computer because it's very tiny on my screen, so I can.
00:31:21.084 - 00:31:23.334, Speaker A: Okay yeah, I can increase it.
00:31:23.372 - 00:31:24.726, Speaker B: No it's fine, I have it right.
00:31:24.748 - 00:31:25.974, Speaker A: In front of me. Okay, good.
00:31:26.172 - 00:32:34.890, Speaker B: On the left hand. So it's basically what I did is for the different testnets and different clients, I kept spinning up nodes in an environment where similar conditions, so I was able to run on different clients on the same network under the same hardware conditions. And I tried to gather some high level client metrics. So the slide you have here is the most popular one because it shows the synchronization progress and the synchronization speed over time. So on x axis you have the time, I launch them all at the same time. So you can easily see how the left graphic, how everything starts at the same block height or block slot zero at the same time. And then you see basically orange is lighthouse, then you have purple as prism, blue is nimbos, and this greenish is teco.
00:32:34.890 - 00:33:33.066, Speaker B: You see how long it took them to synchronize the network on top you have the time, it takes them 4 hours, 6 hours and so on. And it basically just gave some indicator for early indicators how clients would perform in production. These metrics are now weeks old, so the client teams are very active releasing more optimization. So I would be very carefully consuming these numbers. I try to keep doing this once in a while. I also plan to do it on mainnet and also plan to do it on a regular basis. So you can see if clients improve over time, or maybe not, but this is just during the testnet phase, it was just giving teams indicators of where they are.
00:33:33.066 - 00:34:05.740, Speaker B: And on the chart to the right you see the same metric just broken down in slots per second. So you have the synchronization process here you have the lighthouse at 25, prism at 17 slots per second and so on. It basically just visualizes this data and it shows that there are some kind of, some patterns that client teams can further analyze. And I published the raw data on GitHub, so you could just take a look at this.
00:34:08.190 - 00:34:16.720, Speaker A: Yeah, great. Yeah, I remember previously you published similar benchmarks for eth one node, right?
00:34:17.570 - 00:34:19.102, Speaker B: Yeah, it's been a while ago.
00:34:19.236 - 00:34:43.094, Speaker A: Yeah, indeed I remember this but yeah, this is great indeed. Especially if you can be able to track it over time, because you almost get this competition between the client nodes teams. Right. Teku has some work to, to do, say, or used to have.
00:34:43.132 - 00:35:10.526, Speaker B: At this point, Teco is not doing so bad in this regard. They can keep up fairly well. It's just in this scenario, because I think I did three or four different benchmarks and I used for each of them different hardware also. So you just pulled up one example and in another example, Tico was, for instance, performing better than another client. So you cannot directly say Tico is the worst. No, it's not. It's clearly not.
00:35:10.526 - 00:35:20.370, Speaker B: It's, Tico is a really good client and just in the scenario they turn out last. We have to be very careful coming to conclusions here.
00:35:20.520 - 00:35:32.600, Speaker A: Yeah, makes sense. Cool, thanks. Buddhist, I want to ask you maybe have questions that you'd like to ask Afri at this point.
00:35:33.210 - 00:36:09.666, Speaker C: Yeah, I'm pretty intrigued about the iterative development of various testnets, and I think Afri spoke about sort of battle testing the different test nets with private networks where only few developers were given access, where they would sort of run some attack vectors and do some vulnerability testing. So was probably wondering whether or not there were any major vulnerabilities that were discussed that were discovered along the process and anything in that regard that you.
00:36:09.688 - 00:36:10.660, Speaker A: Might want to share?
00:36:13.190 - 00:36:30.550, Speaker B: Probably. I wasn't really closely following this effort. It was conducted by the Ethereum foundation and they gave out bug bounties for this, propagating these testnets. And I don't exactly remember what the results.
00:36:34.410 - 00:37:14.200, Speaker A: Yeah, yeah, good question. I was wondering also about it, because if you compare the approach of these e two testnets versus the incentivized test nets of, say, cosmos or some of the other networks, the way for people to, for an attack. Bounty, okay, you can have a successful attack and then you get the bounty, but other than that, there wasn't an economic incentive for people to participate in these test nets. Right.
00:37:15.210 - 00:37:20.170, Speaker B: Yeah, there was no incentivization beyond that.
00:37:20.320 - 00:37:23.020, Speaker A: Yeah, the participation was really good.
00:37:23.710 - 00:38:03.510, Speaker B: Exactly. This was quite surprising how long we kept the medasha testnet alive. For example, it was running stable for a couple of months. And this just shows how committed the Ethereum community is to deliver Ethereum too. And I'm quite happy that so many people voluntarily run their own validators and they continue doing so. We now have a post launch testnet for developers to test further more things, or for users or validators to test their staking setup. It's called purmont.
00:38:04.170 - 00:38:30.240, Speaker A: Okay. Yeah, indeed. That's good. Ideally you want to do that before exposing actual value, but yeah, it's really impressive. I've been following many of the incentivized testnets around and it's always a good way to get people together. But yeah. It's really impressive that without any direct economic incentive, so many people participate over time.
00:38:30.240 - 00:39:21.680, Speaker A: It's good to see. Yeah. I also want to say to the audience, any questions really welcome to ask us or Afri, anyone who's watching on Twitter or YouTube or LinkedIn, do hop over to crowdcast, because that's where you can actually send questions. Maybe I would like to discuss nodes, because you've been doing some work with Dapnode as well. Could you briefly explain what Dapnode is and the work that you've been doing with them?
00:39:23.270 - 00:40:21.966, Speaker B: Sure. Depth node is a very amazing and very exciting project in Ethereum. They have been around for a while, and not only in Ethereum, but most of them coming from the Ethereum community. And the initial idea, or the bigger vision, is that everyone should be able to easily run your own node. And there have always been critics that say it's difficult to run bitcoin nodes, difficult to run Ethereum nodes or whatever nodes, and in the end everyone just uses infra or hosts a node in cloud on AWS or digitalocean or whatever. And that node team, they came up with a quite brilliant solution. They just give you a set of docker scripts that allow you to just get your own old hardware.
00:40:21.966 - 00:41:11.362, Speaker B: If you have an old server, an old laptop, or like an old whatever small computer lying around, you can just turn it into a depth node by installing the node packages on this. And it's basically a collection of scripts that read how to explain it. So they have a package registry on the Ethereum blockchain, and it's recommended to run an Ethereum node on the step node. So if you have enough hardware to sustain an ethereum full node, the step node reads this full node and this queries the step node packages and then you have a built in depth store. Unfortunately I cannot share my screen here, otherwise. I could just demonstrate it.
00:41:11.496 - 00:41:14.226, Speaker A: No, definitely you can. I'll stop sharing and then you can.
00:41:14.328 - 00:41:15.506, Speaker B: No, I don't think I can.
00:41:15.528 - 00:41:17.650, Speaker A: It's the device.
00:41:20.950 - 00:42:04.238, Speaker B: It'S pretty nice. So you have like a dashboard, it says, look, my ethereum node is synchronized and then you can click on depth store and then you can just, so you don't need any command line interface, no experience at all. You can just install these packages and you can just go to the depth store and just see, oh, there's an IPFs node, let's install it. Or there is girly testnet node. I want my own girly endpoint at home, so I just install it. And this is really convenient when it comes to running your own nodes and it comes with a VPN. So you can even connect to your own depth node at home from your mobile device or if you travel from your laptop through this VPN connection.
00:42:04.238 - 00:42:50.706, Speaker B: And you can always access your own node where you know this is a node you have control over. No one is being able to tamper with it or giving you false results. And you can easily integrate this into your metamask in the browser, for example, so you don't query infuria anymore, but your own full node at home. And this is something I believe is very important for the ecosystem. And I still believe everyone should be able to run their own node despite of their background or hardware or technical knowledge. And that's why I believe the depth node team is doing an amazing job delivering on this promise. And on top of that, just recently they started selling pre installed nodes for you.
00:42:50.706 - 00:43:09.610, Speaker B: So you can just go on their website and buy different sizes of hardware and they come pre installed with the depth node system. And you can just say, look, I want to run an ethereum node or bitcoin node or whatever else they offer. They have swarm and many packages.
00:43:13.230 - 00:43:26.480, Speaker A: Nice. You mentioned they use Ethereum blockchain for their package management, is that correct? Exactly how they do it.
00:43:28.210 - 00:43:54.790, Speaker B: They integrate with the Aragon package manager. So you can basically publish release hashes on chain and the depth node at home or at your office or wherever you run it, it just listens to this package manager and if there's any update it notifies you and then you can review these updates and you can manually install it or you can even enable setting to automatically install these updates.
00:43:56.570 - 00:44:25.806, Speaker A: Nice. Yeah, because package management, I think it's a big risk that everybody trusts NPM, everybody trusts apt or whatever. And having it on chain is no guarantee that it's genuine because you can have the hash of the faulty package. But it's a pretty strong way to ensure package integrity and you're not dependent on any other trusted sources.
00:44:25.998 - 00:45:21.300, Speaker B: And to finish answering your last question, of course there are packages for east two available. You can launch a beaker chain on your depth node and you can also run a validator on your depth node. And this all comes with graphical user interface. So on your depth node, if you run a beacon chain, then you can open, for example, if you run a prism beacon node, you can open the validator interface that comes with the so called prism UI. And then you can use this to import your keys or generate keys or use a remote wallet. As soon as this is implemented, and you can have your validator at home, your keys on your own device, and you don't need to run a validator in the cloud or go to a staking service. And I think there's a lot of value in this.
00:45:21.830 - 00:45:37.960, Speaker A: Yeah, it sounds really good. Yeah, great to have that. And are they like, is that not a company or is it a collective or project?
00:45:40.990 - 00:46:11.710, Speaker B: I can't answer in legal terms, but they are fully open source. You can download all, everything from GitHub. They are fully transferring as far as I know, and I would say they are some kind of collective, funded through, they are kind of nonprofit funded through grants. It's not like they make a lot of money by selling hardware. It's more like a convenience option. If you want to not install it yourself, you just get it pre installed from their website. But other than that, you are always free to go to GitHub and get all these packages.
00:46:11.710 - 00:46:21.990, Speaker B: And they have a very good documentation. You can just install it on your own. And once you're done, you basically control this entire node through a web interface.
00:46:23.130 - 00:46:54.770, Speaker A: Yeah, great. Is it good? So everybody go to that node or otherwise get your clients running. We're approaching the end of the hour. Anyone in the audience, let us know if you have any questions that you'd like us to address. And maybe you have some subjects that we didn't touch upon.
00:46:57.270 - 00:47:01.940, Speaker C: Not really. I think we've covered most of the things we intended to.
00:47:03.270 - 00:47:14.600, Speaker A: Great, thanks. And Afri, is there anything I didn't discuss, did you like to address here?
00:47:15.850 - 00:48:05.030, Speaker B: Not necessarily. So, I mean, we, we just launched mainnet last week, and I think this is a huge milestone from the first idea of the beacon chain in 2018 to the actual beacon chain launch last week, there was a lot of stuff happened, and now I think all the teams, they kind of monitor closely how the speaker chain works, how the main net works, and how their software runs in production. But I believe soon we will start working towards the phase one integration of the shard chains. And I'm really curious how 2021 will look like in this regard. And I'd be happy to continue the efforts, helping with testing and integration.
00:48:05.930 - 00:48:46.134, Speaker A: Yeah, definitely. It should be interesting because the first is integrating the shards, and then the 1.5 is attaching or docking the Ethereum main chain to one of the shardlike. Yeah, let's see how that goes. I also wonder if we'll have Ethereum classic classic, or how is it that somebody will continue to mine on the private chain? Probably somebody will, but if there's any significant adoption there or that everybody goes out to e two version. Yeah, it should be very interesting to see. And also this is the plan.
00:48:46.134 - 00:49:31.918, Speaker A: This is a plan. But somebody proposed. Well, there should be a quicker way for people to withdraw their rewards from beacon chain. Right. And executable beacon chain. Can we make some things possible on the beacon chain already? So, yeah, both interesting to see the plan process. Will everything go according to plan and how will that go? What will seal in a way and what else will come up? What else will people make possible using this? And yeah, it should be interesting, let's say, I'm pretty sure 2021 will not look like just a long list of slots and epochs on the beacon chain.
00:49:31.918 - 00:49:58.920, Speaker A: And that's it in its current state. So, yeah, it's been very interesting to see. All right, well, yeah, thanks very much for coming on. Super interesting to hear all this from the inside. Next week we'll go into gnosis, safe and multi signature wallet with Anna Georgian Lucasure. So we'll learn a lot about that. Hope to see many of you then.
00:49:58.920 - 00:50:04.606, Speaker A: So, yeah, again, thanks, Afri, and thanks, Muditz, for coming on.
00:50:04.708 - 00:50:05.358, Speaker B: Thank you.
00:50:05.444 - 00:50:06.140, Speaker A: See you all next week.

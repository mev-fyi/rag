00:00:02.730 - 00:00:16.590, Speaker A: You. Hello and welcome everyone. I am Arun Fernames, CTO and founding partner of Outlier Ventures. And with me is Justin Drake, researcher at the Ethereum foundation. Welcome, Justin.
00:00:17.090 - 00:00:17.934, Speaker B: Hi.
00:00:18.132 - 00:00:38.150, Speaker A: Today we'll take a look behind the curtains of e two and eth two, or Ethereum research in general. So, yeah, really excited to learn more about what's happening there. Could you give the audience like a 1 minute introduction about yourself, what you're doing at Ethereum foundation?
00:00:39.610 - 00:01:19.350, Speaker B: Sure. So as you said, I'm a research at Ethereum Foundation. I focus on e two, which is basically a set of upgrades to Ethereum, which includes proof of stake and sharding. And in the early days, what I did was a lot of research. But I guess now that the research to a large extent is complete, my role is moving, is shifting. One of the things that we're doing now is more implementation work. And so we're working with various implementers, we're hiring staff ourselves, and I'm helping with that effort.
00:01:20.730 - 00:01:53.978, Speaker A: Excellent. Thanks. Yeah, so from my side, I'll try to give a very brief introduction into e two, as hopefully as much of a beginner's mind as I've been able to maintain despite being in this space for years. And yeah, I will dive into it more deeply. For anyone who has been following me on Twitter, the tiny spider in my webcam is still there. It's here right now, moving around. So if you see it walking by, do give a shout.
00:01:53.978 - 00:01:59.890, Speaker A: I don't know, it actually just shows up. But there is actually a tiny spider in my webcam.
00:02:02.150 - 00:02:03.300, Speaker B: Here we go.
00:02:03.910 - 00:02:23.744, Speaker A: Yeah, that's a bit slow. I don't know if this shows up. Sorry, my screen is not showing for me. Try it again.
00:02:23.862 - 00:02:25.664, Speaker B: It was showing for me.
00:02:25.782 - 00:02:42.180, Speaker A: Yeah. Okay. Yeah, I just wanted to make sure wasn't showing from me. Cool. All right. Yeah. So, brief disclaimer.
00:02:42.180 - 00:03:28.352, Speaker A: None of what we are talking about is investment advice, financial advice, or of any kind of other financial advice. Very short background about agile ventures. So we've been backing web three founders since 2014 with a blockchain agnostic view. That said, many of the companies that we've been working with and projects that we've been working with have been building on Ethereum or also on Ethereum. It's basically a factor that cannot be ignored anymore. At this point, even for those who are building on other chains, there's always some form of bridging or interoperability. Our thesis has more and more evolved to become towards to encompass open metaverse.
00:03:28.352 - 00:04:46.824, Speaker A: So looking at new data economies, Defi defi as the financial primitives, NFTs as the software and virtual goods of different shapes and sizes to form these kinds of virtual physical worlds that blend in together. And we do that through the base camp accelerator for early stage startups and the ascent token launch program for projects who are closer to a token launch, where we help them with all kinds of activities around that. And we also run validators on up to now, mainly Cosmos SDK based networks. No e two validators yet, but who knows, at some point we have a few more networks in the pipeline. So yeah, to me, the challenge to explain e two in a nutshell is going to be a very small nutshell. If you have to say eth two, then what is eth one? Well, of course, from very high up, Ethereum is a way to build decentralized applications, to build decentralized smart contracts. They have a front end and a back end, and at the back end somewhere there are clients and there's a blockchain.
00:04:46.824 - 00:06:08.324, Speaker A: Now this is an extremely simplified view because, of course, what's in here, what's happening in this blockchain, the EVM, the virtual machine that executes smart contracts and networking layers, all the scalability limitations that people have been talking about, they reside mostly in here. I guess there's a bit of the scalability limitations that blend over to the front end. You want to make sure that end users can still work with Ethereum and have fully self sovereign interaction with the network, even if it has larger shapes and sizes. And I think some of those aspects have informed the e two roadmap and sort of meant that some options that might be able to scale Ethereum have been not chosen to proceed with because they would lead to more centralization or they would lead to less accessibility. And yeah, the path that I think has stayed really true to decentralization and openness. Now, ultimately, e two is a way to scale Ethereum. It's an evolving way, an evolving concept.
00:06:08.324 - 00:07:11.500, Speaker A: There are various names for it. The serenity upgrade has been named, there's various other names. There was a seven phase plan at some point, and fortunately over time that has been able to simplify and bring results at an earlier point. This is the pretty complex, but mostly recent and up to date view on what that roadmap looks like. And this was drawn by Fatalik in March last year. So yeah, almost 18 months now, but we're quite far ahead in executing this roadmap, really, which includes the launch of a phase zero in proof of stake. So migrating away from the proof of work algorithm, which is currently the algorithm securing the blockchain to proof of stake.
00:07:11.500 - 00:09:11.148, Speaker A: Doing that in a way that allows lots and lots of independent validators, far more than other proof of stake algorithms. And yeah, as a next step, as an eagerly awaited next step, allowing that to actually run what we know as Ethereum, the existing blockchain, the EVM, the contracts, the defi protocols, what everybody is familiar with that will at some point be supported on e two in what's known as the merge, meaning that what's currently Ethereum blockchain will be merged into the proof of stake consensus algorithm and from then on get its life with that proof of stake algorithm securing it and having new additions and any execution of smart contracts and logic happening over there. And then there are many things that can happen beyond that point that might lead to further scaling or new possibilities, partially also enabled by the fact that there is then a proof of stake consensus behind it. And yeah, that's sort of further down the horizon, which I think ultimately can make the experience like, okay, there's now this phase zero, the beacon chain is there, we can look out to the merge when what's happening on Ethereum can happen on the proof of stake blockchain, which adds a lot of improvement. And after that, there are more and more improvements that we can look forward to. That can happen at some point when things are ready and people agree that they're ready to put live out there in production. This is view back to the launch of that beacon chain.
00:09:11.148 - 00:10:14.960, Speaker A: So this is the phase zero, the proof of stake beacon chain, which is now still running, which has various clients and block explorers. And what's quite interesting is that to me at least, what's needed for a validator is a deposit of 32 ether in a contract and running some validator software on and out somewhere. And of course, in the beginning there were lots of deposits, enough to reach a threshold to actually relaunch this thing. But this was in December, and from that point on till today onwards, people are still depositing more ether and more ether to be able to run more and more validators. There were over 180,000 validators on this proof of stake network. So yeah, it's really impressive. Now you can of course have your, well, I think it's pretty widely agreed that those are not 180,000 fully independent parties.
00:10:14.960 - 00:11:26.060, Speaker A: Some entities run shared hardware, they run hundreds or even thousands of validators on partially shared hardware. But at least some portion of that will actually be independent people, people running at home, running in a data center, whatever it's a very large set of different entities running those. Probably quite likely the largest set of, at least for blockchain, set of validators and maybe for any distributed system. I don't know if somebody is keeping the record books on that. And ultimately the amount of ethernet that has been deposited to make that work, we're up to over 6 million ether, $13 billion valuation of. Ultimately a vote of confidence that this thing will ultimately be usable in more than just a proof of work chain that's waiting for some future event to happen. So, yeah, that's really quite impressive.
00:11:26.060 - 00:12:51.812, Speaker A: So yeah, ultimately the beacon chain, currently quite limited, but really doing his work to show that consensus at this scale is possible, proof of stake consensus, not doing any of these things which people tend to associate with blockchains. But the merge is the first phase, first step that will make these things possible. And after that there's things like sharding, there's things like increasing block sizes, roll up, those kind of things that will offer additional capacity upgrades. Now, I've included this very briefly. This is from you, Justin. A list of cryptographic technologies used in blockchain and novel cryptographic innovations which might be used, could be used to further improve. I'm going to go into it too deep now, but we might go into it as we go into discussion because I think ultimately what is important to realize is that, and then that be good to get your view and background on the e two beacon chain as it is, and the actual launch of the merge and further steps would not have been possible without certain cryptographic innovations and the application of certain cryptographic technologies.
00:12:51.812 - 00:13:07.260, Speaker A: So, yeah, it would be really good to get a view about that too. But I cannot finish this session without asking you this question. So let's get that out the way when this thing is going to happen. When merge.
00:13:17.580 - 00:13:23.720, Speaker B: Okay, great. Fantastic. Yeah. So is that your first question? When merge? Or is it your first question?
00:13:23.790 - 00:13:25.316, Speaker A: Yeah, when merge. When merge.
00:13:25.428 - 00:13:47.970, Speaker B: Okay. When merge. I think internally we have this goal, you know, to try and get it for, for this year. But you know, it's a very ambitious goal. I think the more likely realistic outcome will be that we'll have the merge in Q one next year.
00:13:48.740 - 00:14:49.750, Speaker A: Yeah. And maybe to get a bit more understanding of what's in the way because beekey chain is running. That's great. And when the merge has happened, it means that existing e one clients, or the execution environment clients like, well, open ethereum I think now has been sort of discontinued. But never mind. And all other EVM clients, they'll have to be adapted to some extent to basically start to trust the proof of stake consensus rather than the proof of work consensus, and maybe some other things, maybe also on client side, wallet side, are there any adaptations needed there or other things that are still in the way to make this happen?
00:14:50.680 - 00:15:34.864, Speaker B: Right. Okay. So in terms of things that we need to do to make it happen is first and foremost we need to make sure that the beacon chain is secure. So you're right that it has been running for six plus months, and it is correct that there's billions of dollars, $14 billion securing the beacon chain. But arguably, the beacon chain is still not ready to support hundreds of billions of dollars of value at the application layer. One of the kind of things that we got to learn through the bug bounty program is that there's still bugs and there's still really bad bugs in the eve two clients. And so one of the things we want to do is basically have more eyes on the beacon chain.
00:15:34.864 - 00:16:55.852, Speaker B: Now, thankfully, all these bugs that we've known since launch have been reported by good people or have triggered kind of accidentally and not caused too much chaos on the beacon chain. But there is a real possibility that someone motivated could invest a lot of time and energy to find these bugs and exploit them. And I guess from the attacker's perspective, the return will be greater if you attack post merge. So we really want to take a paranoid approach. And one of the things that we've been doing recently is hire aggressively on the security front. So we have a whole dedicated Eve two security team now, and over the next few months, we're going to onboard them and we're going to have them, to the largest extent possible, do deep due diligence on the clients. So just to give you a little bit of context of the eve two clients, the Ethereum foundation writes a spec, and then the idea is that the wider ecosystem outside of the Ethereum foundation goes, implement the spec.
00:16:55.852 - 00:17:45.420, Speaker B: So this is very kind of reminiscent, for example, of the Internet spec and client. So we have the ITF standard for TCP, IP, HTML, Javascript, et cetera, et cetera. And then we have the various browsers, Chrome, Firefox, Safari, that are outside of the IATF. And the approach that we had at first was that every client would have its own security team. But one of the things we found is that it's too much to ask for these teams to have a dedicated security team. It's not like they're the size of Google Chrome and they can afford a large security team. So what we've done here is that we've actually recentralized to an extent the security team within the Ethereum foundation.
00:17:45.420 - 00:18:19.640, Speaker B: Another important thing that needs to happen before we can merge is basically for the beacon chain to do at least one upgrade. So on the e one side of things, the devs have a lot of experience doing upgrades over the last six years. On the other hand, on the beacon chain, we've never done upgrades. So we have this very small upgrade called Altair, which we want to do before the merge to kind of test the process of doing a fork.
00:18:21.660 - 00:19:10.184, Speaker A: Yeah, it makes a lot of sense. There's been a successful launch, right, but not a successful upgrade yet. So you want to test those ten things as well. And I think, yeah, we interested to get you a bit like what you mentioned. If there were an exploit, when would you want to execute it? If someone would know of a vulnerability that wouldn't able to do some kind of exploits. And in any case, in that context, there currently isn't a way to transfer out beacon chain eth, if you want to call it that. So even if I would be able to have some looking forward, I would be able to do that.
00:19:10.184 - 00:19:34.160, Speaker A: There isn't currently a way for me to get it out. So in that sense it's also maybe not been battle tested to that extent yet, because there's no carrot for people to try and do that. They can't get those rewards out if they would be able to. If there would be security exploits.
00:19:35.300 - 00:20:17.324, Speaker B: Yeah, that's correct. So I guess there's kind of two places where it might make sense for the attacker to attack the beacon chain. Maybe the first one would be pre merge, but that doesn't make too much sense. And then there's post merge and post merge there's kind of two things that they could try and do. One is they could disrupt the Defi ecosystem and maybe they could open a short position and just have some profit there. Another thing they could do, which you alluded to is try and grab some of that eth that's being staked. And I guess there's a couple of ways that an attacker could potentially do that.
00:20:17.324 - 00:21:11.680, Speaker B: The first one is that they could try and hack the so called withdrawal keys. So when you're a staker, you have two keys, you have a hot staking key and a cold withdrawal key. Now if best practices have been followed, it will be quite difficult to have access to this withdrawal key, which should be in cold storage. And so really the next best thing that an attacker can do is to have access to the hot staking key. Now it turns out that there is a way to use a staking key to extract value and that is actually using a ransom attack. So on the beacon chain we have the notion of slashing, which is that if you do something wrong with your hot staking key, then you get slashed. Now, an attacker who has access to your staking keys, they can threaten to slash you.
00:21:11.680 - 00:21:13.696, Speaker B: So they can threaten you to lose money.
00:21:13.718 - 00:21:19.200, Speaker A: Yeah. They can threaten to double sign to. Exactly. Violations to the protocol.
00:21:19.700 - 00:21:31.110, Speaker B: They can also hold you at ransom and say, I will not slash you if you pay me, for example, half of what you would have been slashed if I did slash you.
00:21:33.900 - 00:21:35.012, Speaker A: Yeah, indeed.
00:21:35.076 - 00:21:44.890, Speaker B: So that is quite a scary attack. And it's something that we have actually a team of academics dedicated to studying this one ransom attack.
00:21:45.820 - 00:22:16.580, Speaker A: Yeah. In that sense, with these kinds of systems, over time, there's some form of confidence. If there's theoretical attack and it hasn't happened, it's definitely not perfect, but it says something like people say, well, bitcoin has been going for twelve years. It hasn't been hacked, so it's secure. Ethereum has been going for this time. So it has been. So it's at least somewhat secure.
00:22:16.580 - 00:22:32.548, Speaker A: And that applies potentially to this ransom on the beacon chain because that could be executed now if I would be able to. Because people can get slash now they cannot transfer, but they can get slashed.
00:22:32.564 - 00:23:04.020, Speaker B: Yeah. So in order for this attack to really work, you need both the slashing and the withdrawals. So it wouldn't quite work right now. It would actually work when we enable withdrawals and that's going to be separate from the merge. At one point we were planning to have withdrawals when we merge, but actually that plan has changed. We now have what we call a minimum viable merge where we want to merge as soon as possible with essentially no features. And so the withdrawals will be postponed until after the merge.
00:23:05.080 - 00:23:08.944, Speaker A: Okay, so withdrawals after the merge, not before the merge.
00:23:09.072 - 00:23:13.780, Speaker B: That's correct. And same with other features like transfers.
00:23:15.560 - 00:23:31.470, Speaker A: Okay, is that because what's being merged in is the whole Ethereum execution environment? That has been proven and there isn't much changing to that?
00:23:33.280 - 00:24:14.010, Speaker B: Well, we want to merge as soon as possible for various reasons. One is that the proof of stake is much more efficient from an economic standpoint. You just need fewer, much less issuance. And we talk about the triple happening where we basically reduce the issuance by a factor of eight. We also want to do it from an energy efficiency standpoint. The energy usage of proof of stake is roughly 10,000 times less than of proof of work. And we also want to do it to benefit from various security upgrades that proof of stake provide.
00:24:14.010 - 00:24:55.620, Speaker B: And in order for us to do that as soon as possible, the strategic move that we've made is to basically sacrifice all the features and postpone those so that we can have an earlier merge. I guess one other thing that has prompted us to go down that route at a more accelerated pace is there was a few months ago some threats from the miners who were not happy, for example, with EIP 1559, and we're putting some roadblocks. And the fact that we have these threats was kind of an encouragement for us to remove the miners altogether from the equation and go for professional.
00:24:56.280 - 00:25:23.810, Speaker A: Yeah, got you. Okay. I have a few questions from the audience, and I think a few were applicable, so let's take them now. Because you mentioned the security team, Lucy was asking how large is the security team as a percentage of the development total? And is it further divided in swift groups? Fanny. So, yeah.
00:25:29.700 - 00:26:07.164, Speaker B: The eve two team within the film foundation is actually quite small. It's only 20 people, and we've hired a lot recently. So that includes all the recent hires. We've had eight recent hires, and the security team is roughly five people. Some people kind of do more than just security. Now, in terms of who's part of this team, we've had people who have been very good at finding bugs in the past. So, for example, Proto has been extremely good at finding bugs, even though he's not really part of the security team.
00:26:07.164 - 00:27:02.930, Speaker B: And so he's helping onboard some of the new security members. We also have Danny and myself, who have been managing the bug bounty program. So again, even though we're not dedicated to this security team, we're intimately familiar with all the vulnerabilities that have been found, and we've been helping to fix them with the clients. And in terms of the hires, we have four hires, one called Antonio, who basically straddles between security and cryptography. So going forward, the Eftube project will rely more and more heavily on very advanced cryptography. And so right now, the advanced cryptography that we have is called aggregatable BLS signatures. So he started there, and actually he's found some bugs already.
00:27:02.930 - 00:28:31.704, Speaker B: But moving forward, he'll look at the other cryptographic primitives. We also have David and Tyler, who are trained security researchers from the traditional world, as they were the web two world. And they're very experienced at digging into the code and just finding bugs using various methods, either using kind of advanced tooling, but also kind of just through visual inspection and just grocking the spec and comparing the spec with the implementation and looking for discrepancies and things like that. And we also have Frederick who joined us, and he's more of a high level person who makes sure that we don't have any blind spots, that our processes are good and things like mean. On the topic of security, one thing that we've done a lot is kind of work with teams outside of the firm, foundation and individuals. So for example, through the bug bounty program, we've worked with a fuzzer called Guido Franken who's found plenty of bugs. We've worked with a security researcher called Kwan who's also found lots of bugs and is very, has a very similar profile to Antonio.
00:28:31.704 - 00:29:15.924, Speaker B: He's very good at finding these cryptographic bugs. But we've also worked with various security consulting teams. So for example, we've had the deposit contract, which you screenshotted, be formally verified by runtime verification. And we've had maybe a dozen other engagements to look at various parts of the spec. So we have done a lot of due diligence. But one of the motivations for having an internal team is that the barrier to entry is so high that when we work with the external consultants, they spend almost all their time just onboarding and very little time actually finding bugs.
00:29:16.052 - 00:29:17.550, Speaker A: Yeah, I was going to say that.
00:29:18.080 - 00:29:31.200, Speaker B: So we want to make the upfront effort and investment of onboarding a dedicated team who can really grock both the spec and the implementations, and then from there onwards, find bugs.
00:29:31.540 - 00:29:56.010, Speaker A: Right, got you. So you mentioned on a few occasions bugs have been found by those individuals or those external parties. Were they like in the cryptographic theory or the implementation of that cryptographic theory or somewhere in between? Both. Say a bit more about that.
00:29:57.180 - 00:30:52.890, Speaker B: Yeah, so all the bugs that we found were implementation bugs. The theory is very sound and it's easy to convince itself that theory is good. On the other hand, the implementation has a lot of nitty gritty details. And so there's basically two types of bugs that we have. One is correctness bugs, which are some of the worst bugs because they lead to consensus failures where basically you have two clients, for example, who might split, and that creates a fork, which is very bad. And you have liveness bugs that could be denial of service attacks or it could be crashes, which basically takes a node offline. And I think most of the bugs that we found have been on the liveness side of things, but we have also found correctness bugs as well.
00:30:52.890 - 00:31:13.840, Speaker B: And on the liveness side of things, a very large source of bugs has been lip PTP, actually. So we have this networking layer, which has quite a bit of complexity, which is outside of consensus, but you still need networking in order for the network to operate. And we've held a lot of denial of service bugs.
00:31:20.260 - 00:32:12.230, Speaker A: Yeah. Praise from Lucy from Brazil in the comments. Yeah, I think that was really good. You the context as well, that onboarding piece, you're going to have this close knit group inside the theorem foundation who have it all in their heads, but it doesn't depend on just them. It depends on that whole community around it, companies, independent teams, independent researchers. But you are the ones who can. Ideally you'll see something and you almost immediately spot it, or at least be able to put it in context when somebody sees, hey, I think there's something wrong here, right?
00:32:12.680 - 00:33:00.720, Speaker B: So beyond just being able to spot the bugs and find them ourselves, we also trying to really empower this team to make use of external resources and so effectively have a coordinator role. So one of the things that we found is that when we have these external security engagements, they work really well when they're super, super focused because the barrier to entry is low, and then they can just extensively and exhaustively just study this one topic. And so if there are any bugs, they will most likely find them. And so this team needs to be able to make informed decisions as to who to work with and kind of what subsets of the spec and implementations to go dig deep.
00:33:02.500 - 00:33:20.570, Speaker A: Yeah, yeah, got it. So there was earlier question. Vitalika said that lays are not a technical problem, it's a people problem. Can you comment on this? I don't know if that's why. Firstly, I don't know if you know that comment, otherwise we can skip over it.
00:33:22.460 - 00:33:25.160, Speaker B: Is that in reference to the merge? It's a people problem.
00:33:25.230 - 00:33:31.790, Speaker A: I think it would be in delays to the delivery of eth two to the merge, or those kind of things.
00:33:32.800 - 00:34:17.240, Speaker B: Okay. I would agree that the merge is very much a coordination problem. We've simplified the merge so much that the technology is actually very simple. We're basically just black boxing the execution engine. So that's the EVM and all the state, and we're connecting that black box to the beacon chain. And so these two existing components, e one and e two, are basically just being merged together with a very small merged surface, if that makes sense. And then we're just removing a tiny bit, which is the proof of work.
00:34:17.240 - 00:35:05.480, Speaker B: Proof of work in terms of the complexity of the code base is almost nothing. So removing the proof of work is easy, and having this very small merge surface is also easy from a technical standpoint. But as I mentioned, it's not about the technology per se, it's more about the confidence that we have in the security of the beacon chain. It's the confidence that we have in the process of transitioning from proof of work to proof of stake and really thinking through all the various edge cases. For example, what happens if the proof of work miners who have no incentive to behave properly, don't behave properly according to the rules, they know that they're going to be terminated. What kind of games could they play? And so we really have to think through all of these scenarios.
00:35:06.640 - 00:35:53.690, Speaker A: Yeah, so there's some aspects of clear this has to be done. Like we need to have one upgrade successfully done, we need to have maybe done a reasonably full review of all of the implementations. And I guess in general there's just some time aspect as well that you want those kinds of things to play out, at least to some extent, for more people to have been on boarded with this, for more people to have experienced these things, because when the merge has happened and things do go wrong, or to some respect, you want more people to be involved already.
00:35:55.340 - 00:36:55.310, Speaker B: Right. In the development process of forks, there is a natural pipeline with quite a bit of latency, right? There's like the dev calls that take some time, and then there's a suite of testnets, there could be 3456 testnets. And then even once we've agreed on everything, we still need to go implement what we've agreed upon. And we need to distribute all the software we need to make sure that the adoption is very high. And so all of these things naturally take many months. And when you zoom out, most of the time spent is not in the technology, it's not in the implementation phase, it's really in just everything around it. And the slow coordination and governance that we have.
00:36:55.310 - 00:37:01.680, Speaker B: I think you're muted.
00:37:02.500 - 00:37:26.360, Speaker A: Sorry. Yeah, good, thanks. Yeah, thanks. You mentioned that the aggregate BLS signatures, that's the one list on top here, right? Can you say a bit more about that and how that enables, how it's been necessary for the beacon chain and how it enables that, right?
00:37:26.430 - 00:38:00.464, Speaker B: So we have extremely high decentralization standards in eve two. We want to be maximally decentralized. And part of that is basically lowering the barrier to entry, to being a validator. And the plans early on were to use a naive traditional signing scheme. Now the problem with digital signatures is that if you want to verify many of them, the verification time starts to add up. So it might take one millisecond to verify one. That's very fast.
00:38:00.464 - 00:38:55.296, Speaker B: But if you have to verify 10,000, then suddenly that's 10 seconds verification time, which is huge, especially if you want to verify these 10,000 signatures on a regular basis. And so our original plan was actually to limit the number of validators because each validator has overhead in terms of signature verification. And in order to guarantee that we don't have too many validators, we have a very high minimum deposit threshold. And it used to be 1500 e, and back then no one really questioned it because it was not a lot of money relative to today, but today it's an insane amount of money. It's like $3 million or whatever. I'm very glad that we've put in the very difficult investment of moving to BLS signatures. So what BLS signatures give us is the ability to aggregate.
00:38:55.296 - 00:39:19.550, Speaker B: So if you have, for example, 1000 signatures, all signing the same message, then you can aggregate all these signatures and verify just the aggregate at roughly the same cost as verifying a non aggregated signature. So there's roughly a factor of 1000 x improvement in the signature verification time.
00:39:23.280 - 00:39:42.450, Speaker A: In the mechanics of the beacon chain, how does that play out? Because there's these 180,000 validators and growing, and for every block there's signatures, and for every epoch there's signatures. How bless is used and that stuff?
00:39:42.840 - 00:40:16.584, Speaker B: Yeah, sure. So the way that it works when you're a validator is that you get invited to vote every single epoch. So one epoch is 6.4 minutes. And so every epoch right now we have roughly 180,000 signatures that we have to verify. And these get split over the course of the epoch into what we call slots. So one slot is 12 seconds, and we're going to be verifying roughly 180 divided by 32 because there's 32 slots.
00:40:16.584 - 00:41:33.140, Speaker B: So the signatures are kind of spread out across the slots, but still 180,000 signatures is a lot. And so we make use of aggregation. So the trick basically is that every validator will make a signature off chain, and then off chain at the networking layer we have an aggregation mechanism. So when the signature gets gossiped around, as it gets gossiped to a peer, and then the next peer, and then the next peer, there's more and more aggregation that happens. And then once it's kind of partially aggregated to a sufficient extent, the block builder, the block producer, will take these aggregated signatures and then post them on a beacon block, and we have kind of capacity to go up to a million validators and more. So even in the kind of extreme scenario where we have, for example, 33 and a half million e, which corresponds to roughly, let's say 32 million e, which corresponds to a million validators, we would still be able to support that thanks to BHS signatures.
00:41:34.120 - 00:42:10.240, Speaker A: Right, because the capacity is, that limitation is not the rough number as it would be on the individual basis, because then indeed there would be like for the million divided by 32, well, thousands and thousands of signatures that any validator would have to validate independently. But they get a bunch of aggregated validators of validations or signatures, they just add theirs and pass that on. And so the network traffic also remains limited and the validation time remains constant.
00:42:10.980 - 00:42:31.960, Speaker B: Right. I mean, there's not that many hops, there's a few hops in the pit networking layer, and the aggregation happens quite fast, but it still does happen off chain at the networking layer. And these votes are what we call attestations, which are basically voting on which chain you think is the correct chain. And that's part of proof of stake.
00:42:32.300 - 00:42:56.450, Speaker A: Yeah, great, really insightful. And other new cryptographic systems, algorithms, solutions that already play a role in the beacon chain, or that will, once the merge has been done, or after that.
00:42:57.380 - 00:43:28.724, Speaker B: So right now, that's the main one. One that is coming, I think, fairly soon is what we call secret leader election. So right now we have this issue in the beacon chain, which is that everyone can see ahead of time who will be the next block proposers. And that is a problem because an attacker could figure out what the ip address of the next few block proposers will be and ddos them@the.net.
00:43:28.782 - 00:43:33.964, Speaker A: Yeah, because when you say who, it's in terms of their public key.
00:43:34.082 - 00:43:34.700, Speaker B: That's correct.
00:43:34.770 - 00:43:41.100, Speaker A: But if you could somehow determine, hey, they've signed a block earlier using this public key from this IP.
00:43:41.600 - 00:43:42.024, Speaker B: Exactly.
00:43:42.082 - 00:43:46.320, Speaker A: Then I could nicely ddos those and hence cause a lot of trouble.
00:43:47.140 - 00:44:38.610, Speaker B: Exactly. So that's one of the kind of the lowest hanging fruits for an attacker to cause disruption. And the way that we solve this issue is with what we call secretly delection, which basically means that it's not possible to tell which pub keys will be invited to create a block in the next few slots. And the way that works basically is that the beacon chain is going to sample some number of pub keys, let's say 100. That will be the block proposers for the next 100 slots. And every block proposer will have the option. Well, will have the option to privately shuffle this list in such a way that no one other than them knows what the shuffle is.
00:44:38.610 - 00:45:31.840, Speaker B: Okay, so it's not a perfectly secret shuffle in the sense that they know how the list was shuffled, but from the public's perspective, they don't know. And so if we have, let's say, 100 block proposers that are each doing that, we just need one of the 100 proposers to be honest, in the sense that they don't reveal to the world what their own shuffle was. And that will give us basically a perfect shuffle at the end of these pub keys. So we're kind of obfuscating the pub keys, kind of encrypting them in such a way that as the owner of this pub key, you are able to track where the shuffle is. But no one else knows that, right?
00:45:31.990 - 00:45:44.084, Speaker A: Indeed. And even the owner of that pub key would be limited in their abilities to ddos, and they probably wouldn't be incentivized to do it. Yeah.
00:45:44.122 - 00:45:51.370, Speaker B: So the owner of the pub key is only able to track the one pub key that they own, and they have no incentive to ddos themselves.
00:45:51.740 - 00:45:57.950, Speaker A: Right? Yeah, indeed. Doesn't seem like there's any.
00:45:58.800 - 00:46:27.590, Speaker B: Right. They want to produce a block and not get ddos so that they can get. And in terms of rewards, there's actually two rewards that we have in the beacon chain. The first one is going to be issuance. And most of the issuance, seven eight of the issuance is actually for the attestations. So when you create a block, the rewards that you get for issuance are actually quite small. It's only one eight.
00:46:27.590 - 00:47:05.200, Speaker B: But there's another component of rewards, which is basically the part of the transaction fee that doesn't get burnt, and that is going to be much, much higher than the issuance. And so we could be looking at every block being worth thousands of dollars in terms of transaction fees and mev. And so you really want to make sure that you get your blocks out. You're really incentivized, because a lot of the value that you're going to get validating is going to be when you produce these blocks, not when you're making the attestations.
00:47:06.660 - 00:47:19.430, Speaker A: Right. Great. Thanks for that. I'm going to go back to some questions on the audience. The train and hotel problem, is that familiar or not familiar? Because otherwise I'm going to skip it.
00:47:19.800 - 00:48:06.640, Speaker B: Yes, it is familiar. What is the problem? Okay, so you have a train, well, you want to go on a holiday and you need a train ticket and you need to book a hotel room. How do you make sure that you book both or you book neither? So it's a problem of atomicity. So the booking systems for each are basically separate systems. And it's possible that you book your tickets and then as soon as you try booking the hotel, then they're out of hotel rooms and you're out of luck. And now you have this ticket but you don't have the room. Now this is basically in reference to what we call asynchrony.
00:48:06.640 - 00:48:53.600, Speaker B: So right now in ethereum you have the EVM and you can make these atomic transactions where one happens if and only if the other one happens. And in the context of sharding, we're basically introducing asynchrony. So there could be a hotel on one shard and a train system on the other shard. Now at the consensus layer, once you have scaling, asynchrony is a fundamental thing. You can't scale without asynchronous. So that's something that we have to accept. The good news is that asynchrony is everywhere.
00:48:53.600 - 00:49:38.076, Speaker B: I mentioned already, in the real world, when you're booking a train and a hotel, you already have asynchrony, but this is to a very large extent abstracted away from the end user. And if you look, for example, on the Internet, you have your web browser, you're downloading images from various places, you're downloading javascript from various places. These servers themselves are making asynchronous queries to databases. The whole web is asynchronous. Or even when you look at a single computer, you have multiple cores in your computer. These are all asynchronous and they're making queries to your hard drive and to all sorts of I o that's connected. And so we know how to deal with asynchrony.
00:49:38.076 - 00:50:22.396, Speaker B: That's a kind of a fundamental piece of computer science, and it's going to get abstracted away from the user. Now, to answer specifically the question, train and hotel, one very easy solution, for example, is to have these two components which you really want to be atomic, just to put them in the same synchrony zone, right? So for example, you could put them both in the same roll up or put them both in the same shard, whatever that means, and then once they're in the same shard, then you do your synchronous transaction, which is atomic. But there's all sorts of other techniques that you could use to abstract away these complications from the end user.
00:50:22.588 - 00:50:52.600, Speaker A: Yeah, so basically there are multiple solutions to that asynchronous problem and to give some context to it, indeed, it is about sharding because it is a bit beyond the merge and what's possible, because after the merge, hopefully at some point we're going to get data sharding and then maybe execution sharding, and you're going to have roll ups that are specific to one shard or can indeed include multiple shards. And that would then be one solution.
00:50:54.060 - 00:51:16.480, Speaker B: And this is a problem that will be solved at the application layer, not at the consensus layer. So I imagine it will be solved similarly to, for example, token standards like ERC 20 or ERC 729 21. And so basically there's going to be a bunch of experimentation because there's various different approaches that you can have, and then the best approaches will win out and get standardized.
00:51:16.900 - 00:52:02.640, Speaker A: Yeah, indeed. The current ecosystem of and ultimately the current state of Ethereum and then state in the sense of what's on the blockchain district sense, has become what it is because of various steps on the way. The introduction of ERC 20 of other standards and the fact that it has been synchronous up to now has led to the state that everybody is using that synchrony. So if you say, I'm going to take that away, it's like, okay, what now? What? But if it had been asynchronous from the start, then there would have been a different ecosystem and it will be solved, like you say. And it's still possible to have forms of synchrony, but just limited to a certain scope.
00:52:03.220 - 00:52:24.340, Speaker B: Right? Yeah, no, I mean, there is going to be some amount of pain, some amount of tooling will have to be redeveloped, things like token standards will have to be partially rewritten to take this asynchrony into account. But it's not a fundamental barrier to Ethereum being successful.
00:52:25.240 - 00:52:26.512, Speaker A: Yeah, indeed.
00:52:26.576 - 00:52:51.170, Speaker B: And another thing I'll say is that we also have fundamental asynchrony between different chains. Right. And so right now we're seeing all sorts of projects that try and bridge different blockchains, and we also have roll ups. You can think of roll ups as being their own kind of asynchronous execution zone relative to the EVM. And so we're going to have asynchrony everywhere and we're going to have really lots and lots of innovation and experimentation to learn from.
00:52:54.020 - 00:53:53.460, Speaker A: Yeah. For application builders, is there a place for them to start or otherwise? Well, this is, of course, looking a bit further. Well, no, let me summarize, because for the merge itself, there will be some consequences for application builders, but they will hopefully be minor. And once we live in a sharded world, there will be more consequences. We spoke a lot about the security aspects, battle, testing what's there and the tax, et cetera. What about the other side of it? If I'm ave, if I'm compound, if I'm maker and that switch gets flicked, I want to make sure that my stuff runs right, both on chain and interacting with the chain.
00:53:53.880 - 00:54:52.404, Speaker B: Right. So we've really made a big effort to try and to the maximum possible extent, preserve the ecosystem that we have running right now and have a transition which is completely smooth for these ecosystem participants. Now, one of the biggest changes probably is going to be the block times. So instead of having this random process of block times with an average, I think around 13 seconds, it's going to be regular blocks and it's going to be twelve second slots. So we might actually see like a slight increase in capacity, and we're going to see more predictability with these regular twelve second slots. Another kind of edge case is around randomness. So the way that randomness is done today in many applications is basically using the proof of work component, but we're removing the proof of work so there won't be randomness from there.
00:54:52.404 - 00:55:42.192, Speaker B: And so what we're doing is that we're kind of using Randall, which is kind of a different way of doing randomness. And we've made a significant effort to try and understand which application would break with this change of randomness. And it looks like there aren't really that many applications, but that is one of the edge cases. But other than these few edge cases, that should be a very smooth transition. I mean, another thing that we're breaking is the concept of a proof of work light client. So one of the big visions of Ethereum is that in order to access Ethereum trustlessly, most users will be using light clients. We don't want them to be running a full node because that's quite expensive.
00:55:42.192 - 00:56:32.260, Speaker B: We want people to be running light clients on their phones without having to trust a company, for example. And unfortunately, the light client ecosystem is very nascent today for various reasons. But the good news is that because we don't have light clients, we're not going to break the light clients once we remove proof of work. And so the focus going forward is going to be on the proof of stake light clients. And actually this upgrade that I mentioned, the Altair upgrade, will introduce like clients and the proof of stake like clients are much, much better than the current proof of work like clients because e hash introduced all sorts of complications for the like clients.
00:56:33.980 - 00:57:03.470, Speaker A: Yeah, indeed. I'm familiar with that. It's simpler to validate bitcoin proof of work on the Ethereum blockchain. Well, that is viable, but the other way around is like, don't even try it. Right? Because in the execution environment, that would be bitcoin, where you can't even have a light client. But other situations as well, where you have very limited capacity, very hard to verify that.
00:57:04.340 - 00:57:48.540, Speaker B: That's partly bitcoin's fault because it's not a very flexible system, but it's also Ethereum's fault in the sense that the light client is needlessly complicated with the proof of stake light client. The way it works is we have what we call a sync committee. So we have this committee of validators that is basically invited to vote on what they think is the state of Ethereum at any given slot. And it's just an aggregated signature, like one aggregated signature, and you just have to verify that one aggregated signature on whatever platform you have, which could be another blockchain, as you mentioned, or it could be a device, like a mobile device.
00:57:50.740 - 00:58:20.730, Speaker A: Nice. Good. We're at the end of time, so we have a few questions left, but there should always be something left for the next one. This was super insightful. Thanks a lot for coming on today, Justin. I don't know if you have any asks or things to give to the audience before we go. I'll post our Twitter handles here as asked.
00:58:22.220 - 00:58:35.324, Speaker B: No, I mean, I am happy to answer any questions that you ask that I haven't answered. You can reach me on Justin Drake on Telegram or on Twitter. I have open dms Drake at.
00:58:35.362 - 00:59:04.196, Speaker A: Justin, thanks. Thanks a lot. All right. And well, we do these streams every couple of weeks, so make sure to subscribe here or on YouTube or on Twitter, or all of them, of course, to keep up to date with these kind of sessions. Again, thanks a lot, Justin. I learned a lot and that was a good session. Thank you.
00:59:04.218 - 00:59:05.760, Speaker B: Thanks for having me. Bye. Cheers.

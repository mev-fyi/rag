00:00:00.170 - 00:00:42.826, Speaker A: So recently, the Cypher team audited the Beanstalk Wells edition to their protocol. It's an AMM Dex, as well as having a twap oracle built on top of it. We actually streamed me doing a lot of the audit live, and there's a link in the description, so you can see most of those videos. And for us, a major step that we took in securing this protocol was we wrote an invariant test or a stateful fuzzing test suite for this audit. And at the end of audit, we actually made a pull request to the repository with our invariant test suite or stateful fuzzing suite. In this video, Alex is going to walk you through this stateful fuzzing test suite that we made for the Beanstalk Wells protocol in this live session with the cypher team. So auditors and protocols enjoy.
00:00:43.008 - 00:01:08.462, Speaker B: Okay, so I'll start with an analogy that I actually spitballed with Hans a couple of days ago. So think of the matrix. Right, the film. So in the matrix, you got base reality, and then you got the matrix. So base reality is where everyone lives and it's like the real world. And then the matrix is the simulation of the real world where whoever has root access gets to define all the rules. Well, think of Mainnet.
00:01:08.462 - 00:01:59.874, Speaker B: So Ethereum, Mainet, wherever you're going to deploy the contracts could be arbitrary, Mainet, whatever, that's based reality. And what we want to do is create a simulation, a matrix where we get to define all the possible actions and we get to find all the possible truths. And that in our case, is the invariant test suite. So as far as the contract is concerned, it's real. But as far as we're concerned, it's a simulation of reality without all the consequences. And we can define all the actions that can possibly happen in this simulation, and we can define all the truths, all the invariants that should always be true to this contract in this simulation. Yeah, as I said, this invariant test where we want to act like this simulation of reality, where we want to implement as many actions as reality would present, this contract with, and we want to define a couple of things that should never break.
00:01:59.874 - 00:02:43.294, Speaker B: So what I've done here is gone to one of the earlier commits, just so we can see, like, I'll walk step by step through how they involved, basically. So the first thing that I do is look through the tests that are already in the repo. So if they're using the foundry, great. We can use some stuff from there. Are they using deployment, setup, helper functions? What turned out in beanstalk you had the setup well, with these overloads where you can kind of get more granular, you can deploy things, and it will kind of set everything up for you. So straight away, this is great. I can use this, find out what it actually deploys.
00:02:43.294 - 00:03:22.070, Speaker B: So, this deploys a well, a constant product, two function, and some mock pumps. So, we'll just assume for now that this invariant test suite, for the time being, is not going to be testing the pumps, but we'll get access to an actual well and a constant product function. So, straight away, what I did was create this new folder. And as you can see, we're using this horsefact style handler and invariance. So, in the invariance, this is where we define our truths. So we have actions and truths. This is where we define our truths, which are just our invariants.
00:03:22.070 - 00:03:48.422, Speaker B: So, in the setup, deploy the well and pass the well into our handler. We can go into that in a minute. I'll go into here, but here's our first invariant. So, this is really simple, kind of looking through the code, I was like, okay, so, well gives a total supply. A well function calculates a total supply. Surely they should always be equal. So we went out to the team, and it was confirmed that this should always be true.
00:03:48.422 - 00:04:11.774, Speaker B: So, assert equal. The LP supply that came from the well is always the same as the calculated LP token supply from the well function. It's fine. That's our invariant. Nice and simple. So, if we jump over to the right hand side of the screen, we've got our handler. So, this is where we define all of our actions that can possibly happen.
00:04:11.774 - 00:05:11.694, Speaker B: So, what's the process of doing this? So, what I did was combed through the interfaces. So we've got iwell, which is also an IERC 20, and we've also got this time section at the bottom. What I want to do is, to start off, I just want to define everything that a well can have performed upon it. So, we'll start with add liquidity. And what this does is we take an address, seed, so, just a random mint from the fuzzer, a random amount for token amount in, and a random amount for token, one amount in, and then we bound to reasonable values. We mint it to the random sender, we approve it, and there's a function that has a precursor to the ad liquidity called get add liquidity out. And that just gives you a minimum, and we use that to call, a valid call to add liquidity in the well.
00:05:11.892 - 00:05:16.126, Speaker C: So, Alex, why are we bounding the inputs?
00:05:16.318 - 00:06:06.180, Speaker B: We are bounding them, because this kind of feeds into a kind of ethos that invariant tests have, which is we want to mold the fuzzer in these invariant tests to only perform valid actions, because there's only a finite amount of actions in a fuzzing run that it can do. We want to make sure that every single one of these is valid. So, let's say we make an ownable function available for anyone to call in this fuzzer. The fuzzer will call it with a random c, and it will revert. And that kind of wastes a run because you don't actually change the state on that contract. So we're not getting the most out of all of our invariants. So the reason we're bounding the address is because, well, we need to, because it's only 20 bytes, so we need to bound it to un 160 max and convert it to an address.
00:06:06.180 - 00:06:44.330, Speaker B: These values are kind of just like reasonable values between zero and un 96 max. We assume that they are reasonable values for token holders to have token holder amounts of, basically. So we want to make sure that when we get here, we mold these values into states that are realistic so that when we do call ad liquidity, it doesn't result in a revert. It's reasonable. It's an ad liquidity. It's a valid action that the protocol expects, because what we're trying to do is break the invariance with valid actions. So there's a caveat.
00:06:44.330 - 00:06:45.898, Speaker B: Go on.
00:06:45.984 - 00:07:06.738, Speaker C: I was just saying, is there a scenario where you go, okay, I'm going to bound this to something reasonable, and you accidentally leave out something that is reasonable, like you think, oh, so and such. And such a number is reasonable. Is there a way for us to. Or is this just kind of the skill of writing invariant tests? You got to be good at bounding your.
00:07:06.904 - 00:07:30.220, Speaker B: Yeah, I think you can get a feel for it, because if you don't do it, eventually, somewhere down the line, you'll see some reverts and you'll dig backwards and you'll realize, oh, it's because I provided liquidity, basically the entire balance of some token. The entire supply of some token. And that doesn't make sense. So you might get an overflow somewhere. Does that make sense? Cool.
00:07:32.110 - 00:07:44.030, Speaker D: Yeah. Hans's question was exactly what I was going to ask as well. Is, is there a reason why you are fuzzing the address seed as a UN 256 type rather than just address directly?
00:07:44.190 - 00:07:52.034, Speaker B: That is a good question. Maybe the foundry fuzzer can fuzz addresses. Yeah, that's a good question.
00:07:52.232 - 00:07:59.086, Speaker C: I actually don't think it can, last time I checked, but maybe it does. I think the way that you're doing it is correct. But yeah, we could double.
00:07:59.118 - 00:08:03.750, Speaker D: I have fuzz tests, but I didn't know whether there was a distinction for invariance.
00:08:04.490 - 00:08:24.026, Speaker B: Oh no, there is no distinction. It's the same kind of system that's being used. Note how we do the reasonable values for this bound is one to un 60 max, because we don't want. The zero address is not a valid input here. And some tokens will refuse transfers. So there's a caveat to this. So we're bounding it to reasonable values.
00:08:24.026 - 00:09:20.430, Speaker B: So these always kind of pass. So these actions always are valid, which means invariant tests won't catch a lot of stuff. So like access control issues, anything that someone's missed a modifier, these won't catch them. And that's why it's so important to think of invariant tests as an aid to audits and not the primary audit tool, because this will miss the vast majority of low hanging fruit, essentially that only manual reviews and static analyzers maybe can help with. Okay, so once we've added liquidity to the. Well, notice that we add the message sender to this list we have in here called slps. Now, do you remember the horsefacts article spoke about ghost variables? Well, that's what this is right here.
00:09:20.430 - 00:09:50.940, Speaker B: We want to keep track of every address that provides liquidity, so that when we eventually implement these again, we need to make them valid. So anything that gets fuzzed into here, any values like an index seed, we need to bound that to the number of lps in our ghost variable, so that we pick one that actually has liquidity and then bound the amount that it wants to remove so that it actually goes through again, we don't want anything to revert in this.
00:09:51.870 - 00:10:10.170, Speaker D: How do you go about determining which ghost variables you want to use? Is that purely dependent on, say, for example, we've added liquidity, so we want to remove, and therefore we want to make sure we're removing from address that's already added. So are you looking at the other functions or is it sort of like a general rule of thumb?
00:10:10.330 - 00:10:45.114, Speaker B: I mean, my rule of thumb is anything that is strictly necessary. So if we get to remove liquidity, that is only going to work as defined by, well, protocol, that is only going to work if it's being called by an address. With liquidity, you don't need to store the amount here, because as long as you have the address. When you get to remove liquidity, you can bound an output amount, a removal amount to the balance of that address. Does that make sense? But we can get remove liquidity bit in the next.
00:10:45.152 - 00:10:46.314, Speaker D: Yeah, that makes sense.
00:10:46.352 - 00:10:47.914, Speaker B: And I guess just a very quick.
00:10:47.952 - 00:10:58.174, Speaker D: Follow up to that is would you maybe be thinking about that as you're writing this first handler or would you like, when you come to remove, be like, oh, I need to go back and add that.
00:10:58.292 - 00:11:20.838, Speaker B: Yeah, usually when you get to remove, I just knew it was going to be my next step, so I put it in here anyway. But to be honest with you, as far as it goes here, you don't need it. This is just doing nothing right now. We're just adding to this and not using it at all. But yeah, usually you'd implement this when you go and implement these ones. Perfect. Cool.
00:11:20.838 - 00:12:00.306, Speaker B: Okay. I got any more notes on that? I don't think so. Okay, so straight away all this is doing, when we call forge test, it's going to run all the unit tests and it'll run these actions because this is the other critical part. So back to our invariance after we've set up the. Well, we passed it to our handler so that the handler knows what to call add liquidity on. For each action that we implement in the handler, we need to add it to our fuzz selectors. Okay, so as you can see, we've got add liquidity here.
00:12:00.306 - 00:12:45.360, Speaker B: It's the only public function that we've got in this contract right now. We want to grab that selector, add it to the fuz selectors and add the target contract as just the handler. So what this will do is by default any contracts that get deployed in setup, the fuzzer thinks, okay, that is a target contract. So I'm just going to try and fuz stuff towards that. When you call this function which is in the forgelib, this defaults to only the contract that you've added using target contract. So now only this handler will be the target contract for the fuzzer. Any questions?
00:12:46.050 - 00:12:51.762, Speaker C: Have you worked with target artifact at all? I could never get that to work. That's probably out of scope for this part.
00:12:51.816 - 00:13:03.446, Speaker B: But just curious, as far as I'm aware, this is the easiest way to do it because it eliminates any, just like garbage just hanging around. You have complete control over what the.
00:13:03.468 - 00:13:25.040, Speaker C: Idea behind target art effect is that when you do target contract, you would do target artifact for like a proxy to make it so that, okay, here we're just going to sign all these function calls. To this. Never mind. It's supposed to make dealing with proxies and upgradable contracts easier, but I will figure it out.
00:13:25.970 - 00:13:37.178, Speaker B: Cool. Okay. Any more questions on this pretty simple setup so far? If not, I'll jump to the next commit.
00:13:37.354 - 00:14:06.330, Speaker D: Yeah, no questions on that, but just. Good point that Patrick raised. I think, obviously, when the complexity of the code base increases and you've got things like proxies or maybe like struct inputs and stuff that are harder to furs and set up, I think, obviously it'd be good to try and reason about those as well at some point as we go forward. That's often why I end up sort of abandoning either the more advanced testing or getting sort of lost.
00:14:07.870 - 00:15:17.330, Speaker B: Yeah, that's a really good .1 of the things when we were working on the staking contracts is it got to a point where it was so complex that we couldn't actually implement every action because there were different states that the contract would be in where certain actions would be invalid, and there were just lots of different paths and redirects and actors to the point where we thought, you almost have to cut the opportunity cost. What are the most important actions that are most likely to have the biggest impact, or where you even think? As an auditor, I have a spidey sense that this is doing something wrong. Target those functions first as actions and target those states first, because that's the quickest way that by using your intuition, you might find something that your spidey sense is tingling on or something. Okay. So after add liquidity, it looks like what I did was these time functions we saw earlier on. Now, these turned out to be not so important in this protocol because of the way I set it up.
00:15:17.330 - 00:15:54.810, Speaker B: As I mentioned earlier, we were only mocking the pumps. So as Patrick was looking at later in the audit at the pumps and how they did the t watt pricing, these would have been more important there if we hadn't have used this setup well, which just mocked them. Right. But we did it anyway. So advanced time just uses warp from the foundry cheat codes with a fuzz time, and we bound it to un 16 max. Again, that's just a random reasonable value that I decided, yeah, why not? We don't want to warp time. Nothing's going to happen.
00:15:54.810 - 00:16:21.570, Speaker B: There's not going to be a period of time of like a year where nothing happens to this protocol. So we want to kind of just bound it to a reasonable amount and fast forward that way. And then with the advanced block, I just did move it forward one block. So the fuzzer. Once we add these to our fuz selector. So we've got add liquidity, advanced time and advanced block. The fuzzer now has three actions to choose from in this handler to call, and it will call it randomly.
00:16:21.570 - 00:16:55.374, Speaker B: It might call add liquidity three times in a row with a bunch of different values. Randomly assign calls to each one of these. Maybe that's a good time to look at Andrew Tumble. So this is where we can define our runs and our depth. So each run is like a simulation from start to finish. Okay, so each run here we've got 64 runs will have a depth of 64. That's how many calls will happen in that run.
00:16:55.374 - 00:17:36.046, Speaker B: So that's how many random actions will be applied in each run. So we started off with 64 by 64. And what I ended up doing was in the later commit, I think I'm like just four and something like that. Because all the actions that I set myself to define in here implemented. And what was more important was to go deeper into each run. So almost simulating a longer period of time with more actions and more users to try and break those invariants. I personally feel like, especially with these protocols like amms, that's a lot more important than the number of runs you get.
00:17:36.046 - 00:18:10.554, Speaker B: But you can experiment with these as you go, and you'll find that sometimes if the depth is smaller, you may not get any reverts or errors at all, you might not break them. The deeper you go in is where you give the fuzzer a chance to break some of the invariance you define. Any questions on that? Cool. Okay, so check out the next one. Okay, so we've added here remove liquidity and remove liquidity. One token. Notice that.
00:18:10.554 - 00:19:08.426, Speaker B: Okay, so we have now implemented the removal functions in here, and let's take a look at remove liquidity. So we fuzz an address index this time and we bound it to the number of lps we have because we want to choose an existing LP, because that's who is going to be withdrawing or removing liquidity from the protocol. An LP amount in, we bound to the balance of that user between one. To be fair, this should probably be zero, because then that would cover instances where someone tries to withdraw, they have a balance and they have a zero, and they just pass it zero. So that could actually be more useful, which I just spotted. Notice how also this is kind of an annoying one. So right at the beginning we say if LP's length is zero, then return.
00:19:08.426 - 00:19:34.222, Speaker B: That is actually a wasted call. What we could do instead is redirect this call to add liquidity instead. I think we would have to convert the meat of this into an internal function, though, just so that we could redirect it properly. Or maybe we could call that. But, yeah, this is, unfortunately a wasted run. I just did it for time's sake. I just wanted to get these actions implemented.
00:19:34.222 - 00:20:25.214, Speaker B: And most of the time, this isn't true anyway, because in setup, it sets up a couple of lps, and ideally, we get to fuzz, adding liquidity also. So we bound the values, and we did the same thing again. Change the prank to message sender, and we remove liquidity. And this is the ghost variable again. So if we've removed all of the liquidity that this sender has, then we want to make sure we remove it from the lps, because it doesn't have. We just want to keep the storage in this contract of the ghost variables healthy, so that if it comes around again and we call remove liquidity, but the balance of the message sender is zero, it doesn't kind of screw up our invariance. So this is where we actually broke this invariant.
00:20:25.214 - 00:21:06.666, Speaker B: And you notice I commented it out because this was breaking. And to go any further and write any more actions without just breaking stuff, I had to just let this pass. And what we got out of that fail was a stack trace of how to make it fail, which is what I have here. So, from the output in the invariant run, I was just able to essentially just copy, step by step, what it was doing. And this became the beginnings of our trello ticket, where we describe the issue and how to reproduce it. And it ended up being really simple. I don't think this was needed in the end.
00:21:06.666 - 00:21:44.906, Speaker B: So that was kind of my process here. Every time something would break, go to the stack trace, reproduce it in a unit test, create a separate file for that, and then move on and try to think of more invariants and define more actions. Any questions? All right, so I think I can just go to latest. Yeah, so this is the latest commit on the latest branch. Noticed how I altered the well. So I'm deploying a pump initially now, and I'm using an overflow where I pass in the pumps. This is just because I wanted a real representation.
00:21:44.906 - 00:22:33.370, Speaker B: And again, you can evolve these as you go along, where you see the most value, you can just chip away and increase the coverage more and more. But in here. So let's see what we've got altogether in our ghost variables. So we've seen this already. We've got our list of lps we've got approved by. So this is a set of lps that have approved some other address to spend their tokens, because one of the actions that we wanted to implement is approval and transfer from for LP tokens themselves. So an entry in here will map to a key in here, and the value will be an address set of approved to because you can approve to multiple addresses.
00:22:33.370 - 00:22:36.782, Speaker B: Does that make sense? Any questions? No.
00:22:36.916 - 00:22:37.886, Speaker C: Make sense.
00:22:38.068 - 00:23:29.150, Speaker B: Cool. Okay, so if you think back to the horse facts article, he had a call summary invariant. So we've actually got this as well. So we've got this down here, and this enables us, when we run the invariance with VVV, to print out a summary of what happened. Okay, so we've got here. Now, the reason that I added these were because we were getting under overflow reverts on some of these calls, and I still wanted the invariant test to go deeper into the run rather than just halt there. So one of the places that that was happening, any of these remove liquidities, right? Oh no, it had to be these.
00:23:29.150 - 00:24:01.050, Speaker B: So let's say we were removing liquidity one token out. So the usual thing would happen. We'd check the lps. This time we would increment the call. So we're tracking, this is the thing that we print out in the summary below. Just say, hey, we're trying to remove liquidity one token, do the usual bounding, and whenever there's a liquidity event in the well protocol, you kind of have this precursor that will return you. We saw it early on with add liquidity, like get add liquidity out or whatever.
00:24:01.050 - 00:24:35.940, Speaker B: And it uses most of the same math that the actual function does. It's just more of a view. So we were seeing reverts under an overflow reverts in this function that would also appear in here if you didn't call that one first. So what we do is we try get remove liquidity one token out. If that fails, we add to a fail. So what you'll get in the summary is a summary of, okay, this is how many times we called it, and this is how many times it failed. Now this is where.
00:24:35.940 - 00:25:07.710, Speaker B: So during the course of the audit, we kind of had to figure out if this was desired or not. I think there is one comment in the code for one of these functions where it says an overflow is desired here. So we kind of have to take that into our recommendations when we're writing the report, should it happen if it does. Okay, that's great. That's fine, whatever. We can kind of move on and continue with our lives. So bound a to B is inclusive for both parameters.
00:25:07.710 - 00:25:10.814, Speaker B: Can you explain that?
00:25:10.852 - 00:25:14.900, Speaker D: Again, it just means like for example, on two.
00:25:15.830 - 00:25:48.886, Speaker B: Yes, it's inclusive of zero and one. Yeah, correct. We also have these sync and skims all the IRC 20, I call them transfer LP, approve LP because it's the LP token itself. Transfer from. There was a bunch of others that I chose not to implement here. So like increase approval, decrease approval. As far as I'm concerned, that's not really going to affect the kind of boat that I want to look for in here because that's just like ERC 20 functionality.
00:25:48.886 - 00:26:21.110, Speaker B: I don't want to test ERC 20 functionality. Yeah, and you'll notice we have a bunch of other invariants that we define in here as well. So I think that's pretty much everything. This is as far as I got. So it's not overly complex, it's just these two contracts. And again, one is defining the truths that we want to always be true about this system and the other is just defining all the actions that, the valid actions that we want to happen in our simulation. Go ahead, Ans.
00:26:21.450 - 00:26:44.190, Speaker E: So just at a glance, I feel that you have to write a lot of codes and some of them are just to check the typical ERC functionalities. So I wonder if foundry provides something built in, just for example for ERC 20, something like that.
00:26:44.340 - 00:27:16.358, Speaker B: Yeah. So you're saying we could have like a base handler for ERC 20? Yes, I think that's definitely possible. Yeah, I think the difficulty is every project is going to be slightly different in terms of the setup. So in here we could definitely make it type agnostic. So like just an address and then cast it in a base contract. Yeah, I think that's a good idea. I think that's a good idea because this one's pretty simple and a boilerplate would have worked here.
00:27:16.524 - 00:27:22.330, Speaker E: Yeah. I can't imagine how much we will need to write for peak protocol.
00:27:23.950 - 00:27:44.126, Speaker C: Actually, that might be a good repo to have and people can import it. We've seen attacks, I think people are calling them like inflation attacks, where if a protocol does balance of address this for some calculation and somebody sends them a bunch of money.
00:27:44.228 - 00:27:44.590, Speaker E: Yes.
00:27:44.660 - 00:28:11.302, Speaker C: So that was one of the findings that we had actually on the reserve protocol. If we were able to send it a bunch of money, its internal calculations were off. So I agree. Maybe there's just like we do like cipher foundry or cipher invariant mock and then you just do like handler add the cipher and variant mock and that'll just add everything from there and then. Yeah, I agree. I think that's something that we could definitely build.
00:28:11.436 - 00:28:23.006, Speaker B: Yeah, I think that's a pretty low hanging fruit as well. I think we can up in an hour or so. Maybe I'll take that as an action item coming out of this, actually. And we can use it as a supplement to any content that we write.
00:28:23.108 - 00:28:57.426, Speaker C: So I have a question. This is something that you and I have spoken about. Sometimes when I'm writing invariance, I like to have fail on revert be false to start because you were kind of walking through, all right, so I bounded this and then I did this, and then I did this, and now we have it. Such everything is good. All transactions are valid. I feel like sometimes it is nice to just say, okay, I'm just going to say, hey, call this function with whatever have fail and revert be false. And then just see if you can break this invariant.
00:28:57.426 - 00:29:18.814, Speaker C: And then it just requires a lot less code to write. I agree with you that, yeah, you're going to get worse coverage, but I feel like in some scenarios where you need to do this very weird niche case, maybe you need to write a lot of code. You can kind of just sanity check yourself. I'm repeating myself at this point. You kind of just sanity check yourself by just doing writing a little bit of code.
00:29:18.852 - 00:29:19.006, Speaker B: Go.
00:29:19.028 - 00:29:28.942, Speaker C: Fail on revert equals false. What are your thoughts on that? Is there some flag we can put in to be like, hey, this one have fail on revert be false? Yeah, what are your thoughts?
00:29:29.006 - 00:30:19.710, Speaker B: Yeah, I don't think there's a flag we can put in, but I agree. I think you can definitely start off with it as false just to be a bit looser, especially to get your foot in the door and have something running. What I will say is we want to end up with that as set as true because the reason I like setting that as true, it forces me to understand the protocol more upfront when I'm writing these tests. So it forces me to understand, oh, reasonable bounds for this or this and whatnot. I have to go that little bit deeper than just surface level, not much far deeper, but just enough so that I can understand what valid actions there are, if that makes sense. But yeah, 100%. I think if you want to start with false, you can be a bit looser about how you define the actions.
00:30:19.710 - 00:30:33.526, Speaker B: But I do think you want to end up here so that you get as much of these calls done as possible in each run makes sense. All right, gang? I think that's everything from me. Cool.
00:30:33.708 - 00:30:36.518, Speaker C: Any other thoughts? Questions from anybody else?
00:30:36.684 - 00:31:02.400, Speaker B: Han says so bounding helps exploring more reasonable paths, right? Yeah. Bounding just ensures that when those actions are called, it ensures that they're still valid so it's not a wasted run. So, so long as you bound it to values that are within what the protocol expects, when you go and add liquidity or whatever, it's not going to revert and kind of waste that run.
00:31:05.890 - 00:31:36.842, Speaker C: More to tack on to what Alex just said, too, when you're doing one of your runs, you have that fail on revert equal. True. So let's say you do. Okay, my random un 256 is going to be un 256 max. And there's some. And in your invariant test, you've written like, oh, take that value plus one or something, okay, you're going to get an overflow, right? And so it's going to fail. And if you have fail on revert equals true, then your test is going to be like, oh, we found an edge case.
00:31:36.842 - 00:31:58.750, Speaker C: We found an invariant when it's really just, you wrote your test in such a way that, okay, you expected that bounding helps explore more reasonable paths, but it also helps make sure that it doesn't revert on a silly, like, oh, on a silly edge case that isn't actually an issue with the protocol, but more of like, an issue with the way you wrote your tests.
00:31:58.910 - 00:32:31.226, Speaker B: Yeah. So this isn't as much of an issue. If you have that fail on revert set to false, the run will discontinue. Right. So when you set that to true, you're just being more strict with yourself. You're saying, ok, if something reverts, I want to know, because then it means my assumptions are slightly incorrect and I want to make sure that I fix it. So what Patrick was saying about having fail and revert to false in the early stages, that's just a way to get a fairly deep run, even if there are some reverts in each run.
00:32:31.328 - 00:33:01.606, Speaker C: So like a fail on just, just even a little bit more. So a fail on revert false would be okay. Hey, if we get like a really silly ERC 20 revert or whatever, that's fine. We won't count that as a failed run. We will only count that assertion being broken as a failed run. Like assert the total lp supply equals whatever it says. Okay, this is the only thing that will cause this to be a failed run.
00:33:01.606 - 00:33:17.100, Speaker C: If you have fail on revert to be true that says that assertion, and then anything else that will cause it to kick out a failure. But if you have fail on revert to be false, that means the only thing that will break the test is if that assertion is broken. Does that make sense?
00:33:18.990 - 00:33:53.382, Speaker B: There's a very interesting word that Hans used there, legitimate reverts. And I just want to touch back on the fact that we are avoiding legitimate reverts. So again, we're not going to catch everything because we are just supplying it with what we think is valid stuff. What I said about manual reviews and finding other bugs, this isn't going to catch those. We're avoiding all the legitimate reverts. We're giving it very reasonable stuff and trying to break some invariance with very reasonable stuff. Like, that's the whole point.
00:33:53.382 - 00:34:03.146, Speaker B: So yeah, this is definitely, again, an aid to an audit rather than the primary tool that we use. Your brain is still going to catch way more than this.
00:34:03.328 - 00:34:04.060, Speaker C: Thanks.
00:34:04.430 - 00:34:40.662, Speaker D: I just realized as well, in terms of bounding the address, it probably does make sense to use the UN. Yeah, it does make sense to use the Un, because then you can bound, like you said, alex, between one and 160 max. Otherwise you'd have to use the VM assume. But what that does is that basically skips that run, which obviously we don't want to waste a run there. So then the other alternative would be to cast from an address back to the UN, do the bound check to then back to an address. So actually, yeah, I think going forward, hands back to your question again, probably makes sense to just fuzz the UN and then cast it to an address.
00:34:40.716 - 00:34:45.894, Speaker B: After you've done a great point about this. All right, gang, cool.
00:34:45.932 - 00:34:47.218, Speaker D: Well, thanks, Alex.
00:34:47.394 - 00:34:48.130, Speaker B: That was really useful.

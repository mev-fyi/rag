00:00:00.240 - 00:00:24.246, Speaker A: Hi, everyone. So we're going to talk about potential application in, you know, restaking, in particular with restaking cloud, specifically looking at putting together a decentralized RPC network at what that might look like. There's a lot. Well, I'm sure maybe show of hands, how many people are familiar with restaking? All right, you're here, so.
00:00:24.310 - 00:00:24.630, Speaker B: Okay.
00:00:24.662 - 00:00:52.958, Speaker A: Most people probably are familiar with restaking, and I imagine you're familiar with the difference between kind of like, eigen layer economic restaking versus restaking cloud. Show of hands. All right, one person. Okay, so maybe we'll start with, like, a 32nd blurb on that. But before that, we'll introduce the two, you know us two, the presenters. So I'm Mike. I'm the founder of Etherfi.
00:00:52.958 - 00:00:58.426, Speaker A: We're a new liquid staking protocol on Ethereum. And I'll let Korai.
00:00:58.530 - 00:01:07.894, Speaker B: Hi, I'm Korai. I'm the founder of Chain Nodes. We are a centralized RPC provider, high performance, and we also do validators as a service.
00:01:09.354 - 00:01:32.900, Speaker A: Great. So with Etherfy, the thing that makes us unique, we actually just launched on Mainnet on Friday. And as of yesterday, you can actually now stake. That's very exciting. You can go to Ether Phi and stake your ETH. There's two things that make Etherfi interesting. The first is we are a liquid staking protocol where the stakers actually hold their keys.
00:01:32.900 - 00:02:09.714, Speaker A: So with other liquid staking protocols, typically you would delegate your ETH, and the node operator generates the keys. And so you're taking on some counterparty risk as a result of that. With Etherfy, you're not doing that. The stakers hold their keys. And then the second thing that makes us unique, relevant to this event is that Etherfi, the liquid staking token ETH, is natively restaked. So in other words, you don't need to do anything extra. You just hold the ETH, and it'll automatically give you all the benefits of restaking, which are none right now, because restaking isn't actually live.
00:02:09.714 - 00:02:21.888, Speaker A: But in the future, it's gonna be glorious. Trust me, you'll be able to get all the benefits of restaking. Okay, so. And then maybe I'll let Corey, you want to talk a bit about.
00:02:22.056 - 00:02:47.054, Speaker B: Sure. So, as mentioned before, we are a centralized RPC provider. We focus on low latency and try to have the highest uptime in the industry. So as part of our push towards the, like, our help for the crypto industry, we want to participate in a decentralized version of our rpCs. And, yeah, this is what we are talking about today.
00:02:48.194 - 00:03:19.214, Speaker A: Great. Okay, so before we move on, based on what you guys showed, I think it would be helpful maybe to talk briefly about what restaking is and the two different kinds of restaking. So we'll start with that. So the whole concept of restaking is you have this ETH that you put up in order to be able to get the write to run a validator. And in exchange for running a validator, you're getting protocol rewards. Make sense. Easy enough.
00:03:19.214 - 00:03:57.170, Speaker A: Obviously, the issue with that is your ETH is now locked up. And so that's where liquid staking comes in. Okay, simple enough. Now, the risk of slashing empirically is pretty minimal. I mean, it's close to zero if you just look at it historically. And so the idea is you've got this 32 ETH, you've got $60,000 or more of ETH sitting there, and it's underutilized, basically. Like you're putting up this huge amount of capital, but it's being used basically to run a validator with minimal risk associated with it.
00:03:57.170 - 00:04:53.984, Speaker A: And as a result, could you reuse that same stake Deeth to provide security to other services? So other services might be other blockchains. So if another blockchain doesn't want to try to spend huge amounts of money bootstrapping a token, so can they just reuse the existing security and Ethereum in order to bootstrap the blockchain? And then in exchange they would provide some fees back to Ethereum, so Ethereum would accrue value. So the concept is simple enough. So there are different ways of restaking. So one form of restaking, which eigenlayer uses, is whereby you actually set your withdrawal credentials for your validators to an eigenpod, an eigenlayer smart contract. And that smart contract has some programmable slashing based on the other services that the ETH is being restaked with. So the other services that are being secured makes sense.
00:04:53.984 - 00:05:37.466, Speaker A: So that way the ETH, when you try to withdraw it has to go through the smart contract. If the validator has misbehaved on those other services, then it will get slashed. And that's where the economic security comes in. Simple enough. Okay, so that's one model of restaking. Another model of restaking is what if you could just use the consensus layer node in order to run some sort of other services where the only thing you're really putting at risk is future fees, future staking rewards that you're getting instead of putting the principal at risk? And that is the restaking cloud model. The advantage of that obviously is you're not putting your principle at risk.
00:05:37.466 - 00:06:30.568, Speaker A: You're not introducing smart contract risk because you're not routing your stake de through another smart contract layer. The disadvantage obviously is there's not as much economic security associated with that. And so the types of things you would run on that typically would be lower stakes type things. Now in most use cases of RPC networks or RPC endpoints, it's relatively low stakes for, I'm sure how many of you have run, have used RPC endpoints, right? So I imagine if you're like me or like Corey, when you use RPC endpoints, you're just querying the same damn price, you know, 5000 times a day, or you're querying the status of some pool. The stakes aren't super high. You know, maybe you try, you pull it from two different RPC endpoints and make sure that the, the numbers match. And if they're wrong, some dashboard displays the wrong number, not the end of the world.
00:06:30.568 - 00:07:05.710, Speaker A: There are obviously if you're doing more high stakes things like trading arbitrage, you really need those numbers to be accurate or if bad things happen. But in most cases, RPC endpoints are relative to other applications like relatively low stakes. And so it's actually a pretty good application. It's also, relatively speaking, really simple. Like an RPC endpoint, as we'll talk about, is something that a node already does. It generates a lot of revenue. There's conservatively probably hundreds of millions of dollars being spent on RPC endpoints right now.
00:07:05.710 - 00:07:58.136, Speaker A: So there's a revenue model that's already there and. Yeah, and it's easy to implement. So I think in addition to the more fancy hardcore crypto stuff, da layers, oracles, other blockchains, there is a use case for other more simple things that could be built on restaking that are quite nice and could generate revenue to stakers and node operators. Okay, so with that, let's talk about RPC endpoints. From the looks of the audience, I think you guys probably already know all this, but we'll go through it anyway and then we'll talk about how a decentralized RPC endpoint with restaking might work. So a typical ethereum node looks kind of like this. You've got an execution client that's running, maybe it's geth or maybe something else.
00:07:58.136 - 00:08:50.748, Speaker A: If you support client diversity and then you have a consensus client. These are basically two separate blockchains, again, as everybody knows, two separate blockchains that are running, they kind of talk to each other to make sure they're in sync. And then externally, anybody who needs to talk to the blockchain has a JSON RPC protocol that they can use to talk to the node. So you send it a message, it queries what's going on in chain and gets back to you relatively straightforward. And the way an RPC endpoint service would work is you have a whole bunch of nodes that are out there and they're peered and talking to each other. And then you put a load balancer in front of it that handles things like accounts. So you want to make sure, okay, this user is the user that's doing the requests, it handles billing.
00:08:50.748 - 00:09:55.764, Speaker A: So you make sure you charge the right user for the right thing, and then the user just queries the load balancer, effectively that then forwards on the request and then gets back to the user. And this tends to be very highly optimized, geographically distributed. Running a well designed RPC endpoint service takes a lot of work, and for that reason, money is charged for that service. There's a bunch of services out there. Again, I'm sure all of you have heard of and used these popular ones would include things like Infuria, quick node chain nodes, typically these days, and the prices have come down, it's about $50 a month for a typical, you know, typical use case. Inferior tends to be, you know, a little bit more pricing, but you know, the broader market is about $50 a month. So if you think about the economics of this, you know, $50 a month for, you know, getting an RPC endpoint service.
00:09:55.764 - 00:10:57.596, Speaker A: If you imagine this now being run on a decentralized network with solo stakers or solar node operators like that actually could represent a pretty significant increase in revenue for that operator. It could boost their revenue by 50 to really like 500% depending on the ratio obviously of customers to operators. If you're running a node, typically you're getting 5%. Again, this is not the universal number, but usually you're getting earned 5% of the staking rewards. So if you're running a single validator, 5% of the staking rewards comes out to around $15 a month. They are making off a validator your cost, depending on what you're doing, whether you're running in cloud or on prem service, or if you're really crowding your validators, if you're running a couple thousand validators on a single machine versus you're running one validator on a machine, your cost is going to be a few dollars a month. Like that's basically the ballpark.
00:10:57.596 - 00:12:07.084, Speaker A: So you have a margin of, let's call it like ten ish dollars a month per validator. Now remember, the cost of an RPC endpoint is around $50 a month. And so if your ratio is one to one, if there's lots of customers demanding this service, then that's, you go from making dollar ten a month to making dollar 60 a month. If the ratio is not quite that high, maybe you're only getting one customer per ten operators. You've still pretty much doubled the revenue that the node operator is generating. So this is important because if you're building stuff and this includes like a lot of restaking applications that people talk about like DA layers and Oracle networks, you know, there's a big question like, okay, so who's paying for it? Like why would another blockchain, you know, and how many rewards are they gonna accrue back to Ethereum? Not that these problems won't be solved, but in this case it's really obvious. There's a price, there's an amount of money, and it clearly is an amount of money that's material to the node operator and obviously to the staker if they're getting a share of the revenue.
00:12:07.084 - 00:12:24.464, Speaker A: So economically, I think this type of application is low risk and generates meaningful income for all the stakeholders involved. Okay, so with that, let's see how it might work.
00:12:27.604 - 00:13:33.124, Speaker B: Okay, so how would a decentralized RPC actually work and how would it integrate with the restaking cloud? So first of all, a really important point here is that as Mike already mentioned, the validators already run the same software that an RPC provider is running. So basically they have the interface already to give access to blockchain data and to propagate transactions. And that's really important because right now validate on nodes are very underutilized. If you have a depth node, for example, at home as a solo staker, it's basically at 5% cpu utilization, and all the other 95% are free to make RPC calls. And the interface is already there, so the validators actually don't have to run anything else in this system. So the first part of course would be the restaking cloud middleware, where it would integrate with a liquid staking protocol like Efify to register validators who want to participate in this. The validators themselves are actually the node operators running the validators.
00:13:33.124 - 00:14:50.378, Speaker B: They would need to register and just open the RPC port for, for basically this RPC system. And then they would need to register with the middleware or validator registry contract, which lists all the different node operators that have open ports for RPC requests. So as with the centralized infrastructure, it would be very similar. You would basically have a load balancer that fetches all the endpoints from the validator registry contract, from the middleware restaking cloud middleware, and then it lists all the node operators, including the IPS. It load balances between all of them depending on the calls that are coming in. And it connects to every single one of them obviously, and just tries to distribute load that's coming in. So as a user, if you now make a request, basically the same RPC call that you are sending to infura via metamask or some wallet or via Uniswap, whatever those RPC calls go to the load balancer and the load balancer uses latency weighted round drop in.
00:14:50.378 - 00:15:57.818, Speaker B: This is really important because when you have applications like this, distributed systems where the load balancers are not directly connected to the nodes below, they cannot know the cpu utilization or anything else. The only thing they can know is how fast does it respond. And the slower it responds, the more requests are hanging on this one node. So it is utilized less. So in the end to make sure that all of them are used pretty much the same, because every validator again is worth 32 if, and everyone should be treated pretty much equal if they have similar stakes. You can use the latency to make sure that it's well balanced and responses are as fast as possible. Now, to have a truly decentralized system and to actually provide censorship resistance, you also need to make sure that you don't use DNS or centralized load balancers, because otherwise the same thing would happen as with centralized rpcs.
00:15:57.818 - 00:17:02.244, Speaker B: The solutions for decentralized rpcs today are mostly with centralized load balancer that distributes load to different RPC endpoints. You can see this everywhere in the market. When you search for decentralized rpcs, there's one DNS address like one domain that you connect to one load balancer run by one company, most of them american, and they would still censor you if OFC wants them to censor sensor. So it would be pretty much the same thing. So the first bit that I said DNS, how do you decentralize this? Well, we already have a system for this, it's ENS. So we can reuse this existing system to fetch the IP addresses plus even the HTTPs certificates from ENS instead of DNS. And like centralized certificate authorities, you can fetch them from the blockchain and make sure that you don't need to trust like DNS resolvers or american companies to actually give you the right data.
00:17:02.244 - 00:18:13.860, Speaker B: Now, with the load balancers, it's a little bit more difficult. But first of all, let's get into the penalization, which is part of restaking in general. So how would this work? As Mike mentioned, in this case, with the restaking cloud, you're not putting your 32 ETH at risk, you are putting actually your rewards at risk. So as a validator, you want to make as much rewards as possible, especially as a node operator, because again, this might ten x your revenue. So in the end, you want to actually receive those rewards and it's a significant part of your business. So what you do is you have this software on the load balancer that sends the most common calls, and there is actually a list of ten or 15 very common calls that happen every single block, hundreds of millions of times, probably all around the world, because everyone needs the same kind of data. When a block comes in, they want to know, okay, what happened during this block? And a trace call, for example, if you trace a single transaction, or if you trace a block, tells you a lot about what happened during this block.
00:18:13.860 - 00:19:09.340, Speaker B: Most people also use if get block by number, which tells you which transactions have happened, who sent money to whom, and so on. Now what you do is you take those most common calls, and every time a new block comes up, every 12 seconds or so, you send all of those ten to 15 calls to every single operator. And then you compare the data that you receive. And if the data is wrong from, let's say, ten of the node operators, you have, 110 provide wrong data. You don't redirect calls to them like the load balancer decides, okay, one third needs to be on this block already, because otherwise they might be faking that it's actually progressed already. Maybe there's no block yet. Once one third of the operators are on this block, we request the data for this block from everyone, and then we compare.
00:19:09.340 - 00:20:29.494, Speaker B: And the ones that don't fit into the responded data, you just kick them out and don't redirect requests, which means essentially because you don't redirect requests, they don't earn money. And using this system, basically the load balancers are in the restaking cloud like the relayers, and they try to make sure that people are penalized by not having requests forwarded to them. Now, the second part that I talked about, decentralizing the load balancers is a little bit more difficult, because in this system, the validators or the node operators are actually the ones with the stake, obviously. So they are restaking and they are providing the services, the extra services to earn money. Who are the load balancers? Well, in the slides before, I always had just one load balancer. Again, the most common thing that decentralized rpcs do today, if you want to decentralize the load balancers as well, you need to put an incentive on running those load balances. So part of the revenue of redirecting all the requests need to be shared with those load balances.
00:20:29.494 - 00:21:23.128, Speaker B: The load balances can be actually whoever wants to run some cloud application with the software that's already provided. So it's pretty similar to running node, it's pretty similar to running geth and prism as a validator. You just run the software in the cloud and it's high throughput. It's different to the nodes themselves. If the nodes can handle, let's say 100 requests per second, the load balancers most likely need to handle thousands, if not tens of thousands of requests per second. So they don't do a lot, they just track who is making requests. Then this is used to charge the customers, like the users from before who are sending the requests, and then they forward based on the system that I described before, making health checks and so on in the background.
00:21:23.128 - 00:22:21.718, Speaker B: And that's it. Now, if you have this system, you can have a second smart contract, which is like a load balancer registry where load balancers can enter and exit and the user themselves in the slide before. Actually in this case they would not use ens, they would use the relayer registry contract and they would just themselves decide which one of the load balances do I want to use. Now this sounds not ideal, but it actually is, because what will happen in reality is they will choose randomly and then the load will be somehow balanced. And the thing about those load balances is, again, they need to be high throughput anyways. So in this case it's really not about making sure that load is balanced between the load balancers. It is actually for censorship resistance, because if you as a user see, okay, my transactions are not propagated when using those load balancer, this load balancer, you can just switch to the next one.
00:22:21.718 - 00:23:03.984, Speaker B: So it's very easy for you to use the same exact system, but just rotate in case one of the load balancers does something wrong. In this case, the user can also report certain malfunctioning load balancers and they can be kicked out based on certain amount of negative feedback. Towards them. Just like the validator nodes are kicked out by the load balancer when they misbehave, it would be pretty much the same. But in this case, the users report the load balancers. So yeah, you can decentralize every aspect of it and make sure that it's actually censorship resistant, which is the goal of a decentralized RPC. Thank you very much.
00:23:03.984 - 00:23:05.624, Speaker B: Any questions?
00:23:08.404 - 00:23:20.224, Speaker C: Okay, this one is interesting from RPC network also serve other networks.
00:23:21.484 - 00:23:26.184, Speaker B: So this is a concept still, and.
00:23:26.644 - 00:23:29.104, Speaker C: It'S a great concept. That's what I'm asking. Yeah, thank you.
00:23:29.604 - 00:24:28.848, Speaker B: But so basically the concept here, it's just about the ethereum. RPC calls, RPC calls to the execution layer because it's the, like, it's very easy to do this. Like I said, the validators already run the software, so they don't need to do anything else. If you now start with other blockchains, it gets more complicated because the node operators have to do something else. They have to run a different software. They have to make sure that they have the capacity to run nodes, like polygon, for example, which is just a different beast, but it can be extended like, because this system is not dependent on what's actually on the chain, but rather is the data accurate? Based on all the node providers that I already have, is it accurate on all of them? You can do whatever you want. You can also open up the beacon chain, you can run polygon nodes or l two s or whatever.
00:24:28.848 - 00:24:29.968, Speaker B: It can be extended.
00:24:30.056 - 00:25:14.748, Speaker C: Yes, sorry. The follow up question is, because it brings back the old good memories of the swarm and the early days of Ethereum that we would just want to have on our own. P two p, and then whisper never took off, then we are where we are now. Like the centralized providers have to do it. But the thing it is, if this thing goes, would it be when the dunk shards come and then we have this kind of full downshotting come, then there is a project called the Portal Network by the Ethereum foundation. You get the closest path to get your data from a data blob. So you are still talking about Ethereum node, but then you have this kind of data structure, you want to find that, whereas the user data is there.
00:25:14.748 - 00:25:39.002, Speaker C: Again, it is just like a smart routing on a rock pc within the Ethereum itself. Is it going to be only the consensus node or would you can think about, you can host some sort of a blob, specialized blob for people to serve that. Is that like, I think you're reusing the solo stake at the home node runners area. Right? That's what trying to do.
00:25:39.098 - 00:25:39.586, Speaker B: Exactly.
00:25:39.650 - 00:25:40.626, Speaker C: Okay. Okay.
00:25:40.730 - 00:26:24.190, Speaker B: So yes, of course you can, like I said, you can extend it as much as you want and you can provide access to whatever you want. The question will always be what do the actual users of those rpcs, what do they need? And this is probably more a question of let them use the rpcs because the rpcs are already widely utilized in the world and we see that people actually need it. And once certain other applications like Deng sharding comes up and, and there are certain other data points that are very important to projects or users around the world, this will be probably something to think about in the future and extend.
00:26:24.302 - 00:26:26.194, Speaker C: Fucking cool. Great.
00:26:28.014 - 00:27:05.320, Speaker D: So there's a bunch of opportunities now that are coming into specific types of requests on rpcs, mostly not querying but submitting and the whole intents and the whole order flow. So there's definitely a huge business model on RPC. On RPC endpoints, this seems like the basis for starting to serve and maybe to build something on top. As you say, this is, you say.
00:27:05.352 - 00:27:13.094, Speaker C: Something like a commitment signature, like validator is signing. So you can call one of the consultants, they can sign it for you and you send an intent.
00:27:14.434 - 00:27:26.214, Speaker D: That could be one option. Yeah, exactly. Why not? So this is interesting, right? So basically, yeah. So I guess it's like how do you start thinking in that direction?
00:27:27.434 - 00:28:31.540, Speaker B: So specifically for this application, not really. But you are right that there are many applications like MeV blocker for example, that you actually use the order flow to, to background swaps or something like that and then make extra revenue. This will depend on again certain things because taking the order flow and not propagating it to all the nodes, that's not part of the spec and it will actually violate what you are doing the system for. It will remove the very vanilla system of just using a peer to peer network and distributing transactions. But obviously like building applications on top and saying, okay, there's, I don't know, decentralized rpc.org and then there is Mev blocker, decentralizedrpc.org. So people can specifically use the MEB blocker to not propagate their transactions, but rather have them back run and shared revenue with and things like that.
00:28:31.540 - 00:29:03.304, Speaker B: You can reuse this system and that's the cool thing about it because the validators are already there, the load balancer is already there, and if you just want to reroute transactions that are of certain type, you use the load balancer software and you say ok, if this is true, when a new transaction comes up, don't forward it to all the nodes. Instead send it to the network of builders to create a background transaction and then share the revenue with the user.
00:29:05.724 - 00:29:29.574, Speaker C: Balanced. Is it possible that he can categorize this players who are participating in this registry geographically? So if you're doing some kind of an order flow, not day and night, when the est opens up, that's where the order flows mostly comes from, and the azure opens up, there's always kind of demand. So the machines can be load balanced like that?
00:29:29.914 - 00:29:44.858, Speaker B: Yes, of course. I mean the load balancers are using this latency weighted drawing drawing, which essentially means that if a load balancer is in the US and some node operators are in the US, most of the requests will go to, it's kind of.
00:29:44.866 - 00:29:46.698, Speaker C: A priority queue for that, right?
00:29:46.746 - 00:30:22.112, Speaker B: Exactly. That's it. And the other way around as well. If you have decentralized load balances, a user might choose a specific load balancer that's in the US region because he's in the US, or he might choose some other region just because he doesn't want to be censored or whatever. So yeah, there are plenty of opportunities here, but it's always the load balancers choose the nodes below because they are just good at handling huge amount of traffic and the user select the load balances. So if they do it right in both cases, then you have low latency. If they do it wrong, then you have high latency.
00:30:22.112 - 00:30:43.884, Speaker B: But for really high. For applications that are like where latency is hugely important, decentralized rpcs might not always be the best case. So you might just run your own node or whatever, but still it's possible. And the system would balance itself to do what you just said.
00:30:45.274 - 00:31:41.328, Speaker A: Yeah, but I think, yeah, I think the idea that this could be a platform for a bunch of other applications, like some of the ones that were mentioned is a good one. And I think the value of a credibly neutral decentralized RPC endpoint network where the nodes are geographically distributed instead of being in the same two data centers that all the rest of the nodes are, you actually have some nodes, I don't know, sub saharan Africa or way over in Asia. There's a lot of value in that. So you can specifically send transactions to propagate in certain ways or to avoid mev or whatever. As was discussed, there's lots of cool stuff that you can bill here, and instead of the revenue for these services going to a handful of centralized large companies, you basically recycle that revenue back to stakers and the individual solo stakers that actually help.
00:31:41.416 - 00:31:44.464, Speaker C: And these operations will be restaked, right, for security?
00:31:44.624 - 00:31:53.164, Speaker A: Yeah, exactly, that's right. So the value of this is you're deciding who gets to stay on the network through the security provided by restaking.
00:31:54.784 - 00:33:05.884, Speaker B: And maybe also one other bit here. It's not just me be blocking, but also because you have this distributed system of solo stakers all around the world, you actually have a system where you can directly communicate with the miner, the validator. In this case, before proof of stake, this was actually a hot topic to be connected to an RPC of a miner who is building a lot of blocks to get included as fast as possible. In this case, the load balancers are always connected to actual validator nodes. So if they like, you can even build a custom call that says propagate fast or whatever, and the load balancers can send the transaction to all connected validator nodes. Which if you have a huge system and if you have a liquid staking protocol that's let's say doing 10% of the blocks, then you would have a one in ten chance that the transaction gets included actually in the next block, even if it's just a split second before the next block. So there can be applications for high throughput as well, just because you have a direct link to lots of validators, which you can't find anywhere right now in the world.
00:33:07.544 - 00:33:09.944, Speaker A: Thank you. Great, thanks everyone.

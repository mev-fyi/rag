00:00:00.320 - 00:00:30.553, Speaker A: Exploring policies in AI. I'll start with our virtual panelist, Dr. Barrett and Dr. Saurabh and we'll keep on going. Just have you guys introduce yourself then Ryan, you can take it. Hey, Barry, introduce yourself and then we'll.
00:00:30.569 - 00:00:32.045, Speaker B: Get started with the questions.
00:00:32.945 - 00:00:45.945, Speaker C: Yeah, sure. Can you guys hear me? Audio okay. Sweet. Yeah. Thank you. Thane. Yeah, my name is Barrett, medical doctor by background, kind of.
00:00:45.945 - 00:00:57.515, Speaker C: Yeah. Worked in academia for a bit left. Now work in tech, specifically the intersection of psychological science and blockchain. A lot of overlap with AI and super excited to be here.
00:01:03.255 - 00:01:38.875, Speaker D: I guess I can go next. I hope you all are hearing me. The PhD type of doctor, I guess background is in kind of applied AI and machine learning bias and where do I say this? And domains where data scarcity is prevalent. I'm a faculty member here at the CS program and a senior research scientist at the Human Centered AI Institute at Howard.
00:01:55.545 - 00:01:57.765, Speaker A: And Shayna. Could we have you introduce yourself?
00:01:58.985 - 00:02:00.193, Speaker E: Oh, yes, most definitely.
00:02:00.249 - 00:02:11.587, Speaker F: Hello, my name is Shayna Douglas. I'm the founder of a consulting organization called NFT clt. My background is in engineering, specifically consumer electronic manufacturing.
00:02:11.651 - 00:02:13.323, Speaker E: If you're familiar with surface books, surface.
00:02:13.379 - 00:02:26.971, Speaker F: Pros, I go overseas, manage those factories, those relationships and get products built, all sorts of. But now I'm primarily a blockchain and I'm really excited to talk to you about how blockchain integrates with AI as.
00:02:27.003 - 00:02:29.171, Speaker E: Well as when it comes to policy.
00:02:29.363 - 00:02:33.211, Speaker F: We do a lot of business development out of a special economic zone and.
00:02:33.243 - 00:02:35.307, Speaker E: Indigenous sovereign nation in the United States.
00:02:35.371 - 00:02:44.555, Speaker F: So can speak to the lens of what it's like to be a part of creating progressive frameworks to support. Support developing emerging ecosystems.
00:02:45.175 - 00:02:45.751, Speaker G: Awesome.
00:02:45.823 - 00:02:49.311, Speaker A: Ryan, do you have you introduce yourself? No problem.
00:02:49.343 - 00:02:49.991, Speaker G: Good evening, everybody.
00:02:50.023 - 00:02:51.071, Speaker D: My name is Ryan Little.
00:02:51.143 - 00:03:01.555, Speaker G: I'm a network engineer. I've been a tech for about eight years. I love it. Definitely open up my life to a whole new world of experience. Got into government contracting and policy and this is definitely the future.
00:03:04.095 - 00:03:15.233, Speaker H: I can go ahead. Hi everyone. My name is Christine Lebe. I'm a senior criminology major, business administration minor here at Howard, and I serve as the community and external affairs director.
00:03:15.289 - 00:03:35.305, Speaker I: For the Howard University students and good evening everyone. I'm Xavier Maddox, a senior political science major, legal communications minor from Georgia, and I'll be here on behalf of the Government affairs and Policy department for Houston.
00:03:35.875 - 00:03:46.535, Speaker H: Yes, of course. So the first question is, how do you envision AI reshaping the workforce in the next decade? And what opportunities or challenges does this create for college graduates?
00:03:52.035 - 00:05:05.665, Speaker F: I Can take that one, you know, myself, I came from tech, you know, Fortune 100 companies. And the emergence of AI technology really gave me the confidence to step out and feel like I had the tools that I needed to become an entrepreneur. From getting any old tasks done, like sending out emails, just things that take up too much time if you allow them to really thinking through business models, plans, thinking how, strategy, through gathering research. I really do believe that AI specifically opens the door for college students and folks who are coming up in the workforce to hone in on that specific skill and development of training AI models, knowing how to interact with them, because that's going to be very valuable. And I think we're seeing a lot of especially like job roles and functions are optimized because of AI and other systems that are put into place. But, you know, it's going to be really up to students to understand how to use the tool and make the tools work for them versus the other way around.
00:05:11.645 - 00:06:03.889, Speaker D: I guess I can go next. Yeah. AI, like any other new tour invention, is going to bring opportunities and possibly new roles associated with those opportunities. It's most likely to foster innovation across different fields. So trying to see for students particularly to understand the technologies and kind of fill in and improve things from where they are for the next generation to do will bring on more skills, more things we can do anywhere. I work in healthcare as well, so a lot of things from folding proteins to potentially curing cancer. So there's a lot of positive applications of AI that could benefit the students.
00:06:03.889 - 00:06:08.845, Speaker D: And just learning about it would probably prepare the future.
00:06:13.465 - 00:06:49.155, Speaker G: Well, I would say within the next decade, I felt like AI would definitely more proficiently, more efficient within our lives. Right now. There's kids learning how to code, there's kids learning how to do many things within the world of it. And of course things change. Life is always changing and developing whatever was happening in the future, I believe that with the proper programming, policy, securities, and of course infrastructure, with our everyday life when it's changing, hopefully our youth will be able to make life AI more adaptable for us so that it would change with us in our life and it would be more convenient for us as well.
00:06:54.295 - 00:07:01.279, Speaker F: For myself, you know, this sounds very strange, but I find myself getting into conversations with AI models a lot.
00:07:01.447 - 00:07:03.711, Speaker E: The tool that I use for myself.
00:07:03.783 - 00:07:10.775, Speaker F: Is Claude, and I have often caught the model in its own implicit biases.
00:07:10.935 - 00:07:13.875, Speaker E: And correct it and encourage it to.
00:07:14.255 - 00:07:31.951, Speaker F: Take certain evidence and reformulate its thought process and, you know, the outcome, especially when it comes to like, historical context that I feel like is optimist from like black culture, you know, our perspectives and things like that.
00:07:32.023 - 00:07:33.119, Speaker E: It's very evident.
00:07:33.207 - 00:08:53.115, Speaker F: So I think number one, even just like taking out the time to nerd and train models, it not only benefits like the application itself, but it benefits you as the end user who is looking for specific like feedback, right. And is looking for the tool to support you in a certain way. So I think that's number one very critical in terms how we like interact. And then number two, like, I think it's also really great if you can find ways to integrate like AI into kind of every everyday solutions, you know, like, like in my fields, at the intersection of art, entertainment, NFTs, crypto, it's like really easy to spend a few moments using AI to come up with an image or to prototype an application and then use blockchain to like put your stamp on it. I mean, I think that's really important because not all of us have access to like, you know, the labs or things like that to go out and experiment or try ideas and prototypes. So yeah, I forget exactly what the main question is, but yeah, that's kind of my thoughts on how AI should be kind of like interacted with and trained and used.
00:09:01.515 - 00:09:08.335, Speaker I: Are there any specific programming languages or platforms that are essential for students who want to work with AI?
00:09:13.315 - 00:09:56.309, Speaker D: I can take that one. It depends. It depends nowadays, which was not the case probably a few years ago even. But it really does depend on what you're trying to do. And I'll kind of go on some level of granularity here, I guess if you want to, for example, create AI. Creating AI involves some type of programming language. Often there are some tools and websites out there that often that are called low code or no code solutions, which some do.
00:09:56.309 - 00:10:46.445, Speaker D: Let you partially train an AI model and when I say train, the general idea should be we feed it some data and it learns something. If you want to go like really deep into it. The programming language of choice is Python. There are some other languages that are on the come up, but predominantly it's centered around Python at the moment. If you're looking into working on kind of creating A.I. now, if you're looking into interacting with A.I. and utilizing it to build tools and services out there, there are a bunch of options centered on APIs and as well as interfaces.
00:10:46.445 - 00:11:14.335, Speaker D: If everyone's gone online and used ChatGPT or Gemini, if that's the type of experience you want, there are interfaces there that are ready, but you want something curated and specific. There are other tools as well that you would probably look into. There's quite a lot for me to just list off the top of my head, honestly. But I'd like the other panelists to weigh in.
00:11:18.035 - 00:12:08.837, Speaker C: Yeah, so I'm not, I'm not technical, so I don't know how to code. But I was playing around with GPT Engineer the other day. I think it rebranded to lovable and I was able to make a fairly functioning website like in 20 minutes like with a GitHub and like all of that. And like I think AI's biggest skill set is you know, taking language and then being able to structure the kind of the data sides for that. So I think being able to program in like one year with AI, you'd be able to talk to it very naturally as you would. And we were able to develop fairly complex applications that's more on not the actual building the AI, more like using AI to build apps. So I think anyone that has a very SaaS focused business is at risk because you could get out competed very, very rapidly by someone that does an article.
00:12:08.837 - 00:12:11.185, Speaker C: They would be able to make something as good as that.
00:12:13.245 - 00:12:34.967, Speaker F: Which is a. You know, it kind of almost democratizes access to technology and what we're able to create in a way that we haven't had before, which is a good thing. But of course I know we'll get into the dangers and other risks that come along with being able to have so much information, data, being able to be created and also found. But I was going to say the.
00:12:34.991 - 00:12:36.039, Speaker E: Tools that I use are more on.
00:12:36.047 - 00:13:13.299, Speaker F: The application side, one on the art kind of side I would say mid journey if you use discord, that can be in your discord and you can pay for the paper to get like really great models. Like I have like fashion designer just Columbia, she just had a whole show all generated fashion through AI. And then the fashion students there like created the pieces. So to the point about like rapid proto prototyping, it's not just in tech, it's in other industries too. You can use the tech and leverage for other passions and interests. And then I'll just name drop. The other one that I mentioned was Claude AI.
00:13:13.299 - 00:13:24.019, Speaker F: That one is an ethical, you know, quote unquote ethical model that's more business focused. So if you're looking to establish yourself as an entrepreneur, offer business services, things.
00:13:24.067 - 00:13:25.987, Speaker E: Like that, it's really great because it.
00:13:26.011 - 00:13:50.505, Speaker F: Knows how to do it in a nice. And then lastly there's one that's coming out that's in beta, it's called Jiu Jitsu, which is like an aggregation of a bunch of AI models from Gemini, Claude and a few others. And I think they have a, like a white list or something that you can sign up for right now. But it's one that's been on my radar for sure.
00:13:52.205 - 00:14:11.625, Speaker G: I agree with Python, I work with Python personally myself, also Java, Linux, Wireshark and Putty, they all are the most essential for programming and language and they have an extensive library and also the labs as you spoke about, so you're able to write the code and create things as well as configure the network within the network.
00:14:18.325 - 00:14:26.615, Speaker H: Sounds good. Okay, next question. How is AIG weaponized by cyber criminals and what new challenges does this create for defenders?
00:14:33.035 - 00:15:24.095, Speaker C: Yeah, I take this bunch of, bunch of different things. I think one of my favorite stories was, I think this was like six months ago, this company, they got like hacked by an AI where someone sets up like 10 fake profiles, got a person onto a call, 10 video chats that were all like deep fakes and convince this person to sign some big transaction over. So you were on a group meeting with people that you know, but all of them were deep fake AIs. I, I think it was probably like an insider for them to have got that much information. But I think that one is one example that was stuck in my mind. And yeah, like even in this day and age we see people falling for very basic phishing emails, phishing calls. And if you're a cyber criminal, your ability to do that is limited by one person doing it on a phone.
00:15:24.095 - 00:15:47.965, Speaker C: With an AI, you could do thousands at the same time. So I think definitely going to see a spike in that. And there's still a massive percentage of the population that is not well versed on AI. And so wouldn't you know, deep fakes, like we all probably are aware about it, but that they, they wouldn't be. So I think that's probably the most easy to do in imminent danger. A couple other things, but I'll let someone else, someone else answer. If not, I can hop back on.
00:15:50.785 - 00:16:14.005, Speaker G: Some hackers tactics like phishing, malware, behavior analytics as well as data analysis. And they're able to pick their victims depending on what type of job that you do or the type of things that you're into, type of industry that you're into. So it's very important to have a very strong policy and infrastructure and as well as be trained and aware of when we see those type of things happen.
00:16:20.105 - 00:17:19.653, Speaker F: Yeah, I was going to say it's kind of interesting AI and how cyber criminals just to tie it to like why regulation is so important. It's not just at that level. You think about like industry, like music industry, where AI is essentially being used to take over the office's job, right? Which was something that you had to, you know, you had to have real talent for. And now that data that has been already captured through popular music is being used to feed models and recreate voices, right. Of like, you know, very talented people. And even in that way, when people start monetizing off of that, right now you're putting out fake Drake or fake this or fake that. It's kind of just another extension of how like deep fakes this idea that like all of the content that we have out there can be aggregated and used to create other content that might not be actually attributed to the actual artist or actual owner or actual person right at the end of the day.
00:17:19.653 - 00:17:42.195, Speaker F: So it's not just like cyber, it's kind of like every industry is at risk of kind of crossing an ethical line when you come to like the sensitivity of data and how data is. I think in every industry you have to be very mindful and take responsibility and concern when working with AI.
00:17:45.055 - 00:17:55.595, Speaker D: One other thing at least that I think wasn't addressed for cyber criminal activity specifically, and there's a lot more threats outside of cyber criminality, of course.
00:17:57.695 - 00:17:57.983, Speaker C: Is.
00:17:57.999 - 00:18:56.355, Speaker D: The spread of misinformation and disinformation targeted with the ability to just generate seemingly really good human like text. It's getting harder and harder to distinguish what was written as by a human and is true versus something that is fictitiously generated by AI. Things you read online start that do form or an impact, your opinions start to be criminalized and used as attacks on your thought. Which is a very, I don't want to go too much into the philosophy but you know, the idea that you know, you, you read something online and it was once obvious that it was once written by a human is not now. And it's, it's, it's a, it's a, an attack on information.
00:18:59.415 - 00:19:21.855, Speaker H: So that kind of leads to a follow up question for this one. So how do we go about protecting the identities of people who are giving their data consciously and unconsciously and specifically like because I know that like if like AI like calls you, they could answer, ask you like yes or no questions and like you just saying yes, they can collect that recording and then use it for like other purposes.
00:19:21.975 - 00:19:23.199, Speaker E: So how do we go about like.
00:19:23.247 - 00:19:25.967, Speaker H: Combating instances like that? Wait, I'm sorry.
00:19:26.031 - 00:19:31.703, Speaker F: Can we interrupt real quick before we answer that question? Can we have Dr. Nias introduce herself?
00:19:31.759 - 00:20:00.805, Speaker B: She just came in. I'm so sorry for being late everyone. Hello, My name is Dr. Nias. I am a research scientist and human center AI at the HCAI institute. Institute. My research area is broad but it is in mostly the socio technical landscape with a focus on how technology can be used to promote and protect cultural values.
00:20:00.805 - 00:21:25.025, Speaker B: So I'm very, very happy to be here and again, I apologize for my tardiness and I can address this a little bit, but I think that it's important that I think this response is going to be more policy driven for me, which I don't tend to lean as a computer scientist on policy level work. But I do think that there's going to have to be some protections that are employed even in how AI, because it's pervasive and it's becoming embedded in ways that we see, but also in ways historically even that we don't see, see and aren't readily immediately understandable by all. And I think vulnerable populations are going to be the most at risk for these type of things. And so I really think it's going to take policies to say that we have to make these systems, make it more clear that these systems are being used and employed and provide people the opportunities to opt out or consent to their use and not. But right now I think we're in a really interesting space where it, the technology I think is moving past like the speed at which we can kind of regulate it. But I do think that there is going to be a need for more regulatory influence.
00:21:32.175 - 00:22:31.553, Speaker D: Yeah, I tend to support the regulation on the policy level, but I just want to echo that. It's just a really hard policy question. There's always questions about opt in versus opt out. There's also the balance between yeah, we want to protect data, but data also makes the AI better. So where is the line? And since we are kind of at this point earlier in the AI being involved in society, I feel like a lot of these questions are yet unanswered and at least in my opinion they're very domain specific. So I probably don't want AI to have my name if possible, but then I also want it to be personalized to me. I wanted to help doctors diagnose illnesses, but then do I really wanted to have my health records.
00:22:31.553 - 00:22:50.325, Speaker D: So those questions are fundamental and they probably existed for a while. Something being transparent versus something being private and secure. So we will have to work harder to figure out what's the best, most widely accepted answer.
00:22:52.245 - 00:23:10.525, Speaker F: I think this is where blockchain comes in as a really great solution for protecting anonymity, allowing us to peer to peer, trans. You know, transact that data in a global manner and at scale and even authentication. Right. As a creator, if you're a creator.
00:23:10.565 - 00:24:24.027, Speaker E: Who'S using AI, you want to be able to attach your name, your likeness, because those were your thoughts, you know, that came that you did train, you know, especially on the, in the artistic world when you're talking about prototyping, fashion, all sorts of things. So blockchain is a way that again, you can stamp that, you know, asset, digital asset that was created by AI or an original source of data that's being put into a model in a private way that's not necessarily attached to your Social Security number and name and address, but to say a soulbound token or you know, something else that represents your participation on in the ecosystem and the Internet ecosystem. So yeah, that's something that is continuously evolving is privacy and data protection. That's really why blockchain exists and why we have features like ZK rollups that allow transactions to be bundled and then batched together. Because that's the name of the game. As we get in more plugged into the Internet of things and AI is able to access data, we do have to have some safeguards so that we can give access to that data. And blockchain tokens is just like one way to go about it.
00:24:24.027 - 00:24:55.865, Speaker E: But it's a popular way that is gaining a lot of adoption. So much so that we see crypto being floated around, you know, as a way of, you know, supporting voting and secure and privately, you know, tracking operational efficiency in the government in an anonymous way as well. So there's just a lot of ways that those to blockchain AI kind of intersect to solve that issue of like public safety or potentially solve that issue of public safety.
00:24:58.845 - 00:25:36.425, Speaker C: Yeah. Second, the blockchain recommendation as well. Yeah. Like the ZK0 knowledge things are super useful of way of kind of privately preserving data. I think the other thing is also as well that, you know, do I want to give my data to, you know, OpenAI like this centralized, like a company where I can't really see what they're doing with the data. I don't know how the model actually runs. So I think the idea of some of these decentralized models where they're open source, you can kind of see where is you can verify yourself that its privacy mechanism does actually work because it's open Source and not controlled by one entity.
00:25:36.425 - 00:26:01.515, Speaker C: On the other hand, I think a lot of people probably don't care about giving away the data. Naively so. So I do think some of these protection things are really important because people are not aware of some of the dangers of, you know, in 10 years time your health data might be useful, something really negative against you and you're not aware kind of now. So I think it's super important. But yeah, skeptical whether people actually care.
00:26:03.135 - 00:27:29.873, Speaker B: Can I jump in again? I also think that a lot of times when we think about what you said, personal data, right in our identities we think about ourselves as individuals. But I do think there's some collectivism that we need to consider around our communities and our culture. And like, do we wish to retain like ephemeral in the moment things that maybe aren't even recorded or held for the future? Do we wish to have analog or in person interactions that aren't filled with fueling the data machine? If we wish to organize, to what degree now are we being surveyed or studied or monetized? And so I think we can, a lot of times we can think about things like our personal data, our Social Security number, our finance records, our health records. But also I think from a cultural lens there are other things that even if it's not protecting it from others, using it against us, it may be a need where we just want to protect it because it's ours, right to have and to utilize and to propagate in the ways that traditionally they have done. I see this a lot with Native American communities. When they first started developing chatbots and there was a request to like develop a chatbot to preserve some of the languages. And the elders were like, no, we understand that it could be a value.
00:27:29.873 - 00:27:55.275, Speaker B: We do not wish for our culture to exist in that space or within that modality. It's not a part of what we do and it had to be respected. But I think we're getting to a space where we can't opt out even if we wanted to, for reasons that may or may not be good, but just because we should have the ability to do so.
00:28:00.985 - 00:28:21.245, Speaker I: Thank you. And this next question kind of ties into the previous one. As we all know, the younger generation has been very involved and increase their usage of artificial intelligence. So are there any safeguards to increase protection for our younger AI users from AI danger?
00:28:26.185 - 00:28:29.053, Speaker E: Well, I'll just say one thing that we did.
00:28:29.249 - 00:28:30.733, Speaker F: My organization, we do a lot of.
00:28:30.749 - 00:28:32.861, Speaker E: Collegiate outreach on emerging tech.
00:28:32.893 - 00:28:37.925, Speaker F: And when it comes to AI, for instance, we have our Students use it to prototype.
00:28:38.085 - 00:29:42.925, Speaker E: But the reality is we make the adults, like the camp counselors, you know, control the device, you know, be the in there all of age and allow the students to input, you know, kind of their ideas. So like as a third party coming in, doing programming, or if you have siblings, you know, if you have younger siblings, be the bridge to help guide them because you'll be able to help teach them how to interact and work with the AI model as well and be able to catch things, you know, to like the situation that unfortunately happened with the student and the response that AI provided, you'll be able to kind of be that filter. And then the other thing is not all AI like applications models are created alike. So, you know, being mindful of which one you choose, you have a choice, right? If you wanted to go use OpenAI, which is centralized, a decentralized platform, one that prides itself on being ethical, like all of those are consumer choices, that it's. As we get into this age where you might not have an option, to the earlier speaker's point, you.
00:29:43.265 - 00:29:45.345, Speaker F: You want to be able to make.
00:29:45.385 - 00:29:55.793, Speaker E: Decisions on the options you do have. Like, where are you putting that data? How is that data being used? How is it being culturally captured? You know, in a sense. So those are just a few of.
00:29:55.809 - 00:29:57.205, Speaker B: The tips that I have.
00:29:59.635 - 00:30:26.665, Speaker G: Yeah, I definitely agree. We definitely have to continue to educate the users and let them know what platforms are of use to them that they can go to and learn about it. Online monitoring is very important that we have the monitor networks. Of course, we have to monitor places that, where we're exposed to things that can damage us. Critical thinking. We always have to critically think and make sure our programmers are doing ethical AI development when the program.
00:30:32.805 - 00:31:11.725, Speaker C: Yeah, I can hop in as well. So I think we saw like with social media, the impact it had on a lot of people with this kind of instant gratification that their ability to sit and read a book kind of disappeared. And with AI, like, one of the fears is the ability to like, think, critique and reason is going to disappear because. Because they've effectively outsourced that to something else. So I think that is, you know, one of the things like teaching them to think for themselves, to be rational and not kind of believe everything the AI spits out and hallucinates. Don't know exactly effective strategies of going about that. But I think that's the kind of main thing that came to my mind.
00:31:14.785 - 00:32:40.985, Speaker B: I have done interaction research with children and one of the things I've learned is that through that process in grad school is that children don't have the ability to consent for good reason. And so a lot of the same challenges we've had around identity and risk of AI kind of becoming pervasive. And when I say that word, I mean like just present and available in a lot of the products that we use immediately is how the data is being collected on behalf of young people without appropriate safeguarding for their ability to consent. And it becomes a challenge, right? That I think until it becomes a challenge, something happens, it probably won't be addressed. But I do think that those of you that are thinking about design of policy and how to tackle these things, that is something that I don't see a lot of folks talking about. And I don't know if the major companies that are integrating AI tools into their products are reducing those with the tools that are being used by young people or not. But I do think that it is something that is worthy of consideration.
00:32:45.485 - 00:33:34.495, Speaker D: I think I can add some more here, I guess. Second, everything everyone has ever like said so far, critical thinking, attention spans, all of those are great. But I also, I'll go back to the kind of theme, policy, policy that places accountability on AI is causing harm. Now that's again, since everything is new, think of it as the invention of airplanes. Things are really dangerous then I feel like we're still at that forefront into making planes safer or AI safer. So the best thing to do until policy comes around, and it's going to come around hopefully soon. And policy moves slow.
00:33:34.495 - 00:34:24.365, Speaker D: So the best thing to do is to have a healthy dose of skepticism on the responses you get from AI. Read it, utilize it, but understand that AI hallucinations is still a thing. Sometimes get responses that are often not true or based on fact. And as a researcher I can tell you that is not a solved problem. So whenever you do use AI, know that you're getting an answer based on some very, very complicated mathematical understanding of language. So oftentimes the math goes and that part is yet to be solved. So a healthy dose of skepticism will go a long way in current times.
00:34:24.365 - 00:34:26.805, Speaker D: To keep you safe from EIA danger.
00:34:28.385 - 00:35:58.155, Speaker E: I wanted to add one more thing that is more future focused. As I mentioned at the start, there's an indigenous sovereign nation that has an economic zone called Catawba Digital Economic Zone that is meant for E residency and essentially allows individuals and organizations in this space to protect their digital assets. So when you start thinking about AI using AI to create digital assets works that you're considering proprietary to you Whether it's code, contracts, art, I think it's going to be critical one to protect all of that in some sort of organization and the economic zone that we developed that looks like LLCS s cores, but also one specific for smart contracts and digital assets like DAOs that's decentralized autonomous organizations and down on profits as well as chartering digital asset banks. Like really protecting your assets right now. There may not be regulations that really allow for consent in the way or that warn consumers of the type of data. But as we get as we start attributing tokens to individuals and their identity as well as the assets that go along with them, I think it's going to be strategic to think about how all of that data you protect in your own kind of organizations or business or in collective communities that can support the protection of those assets, that culture and whatever is being, you know, captured in these new Internet ecosystems.
00:36:04.695 - 00:36:12.175, Speaker H: Okay, next question is how can policy promote safety of digitized identities?
00:36:14.435 - 00:36:20.371, Speaker F: Well, I guess I'll kind of just flow into that one. So for instance, the framework and Catawba.
00:36:20.403 - 00:37:24.565, Speaker E: Digital Economic Zone number one actually recognizes digital identities. Most states don't have legislations that recognize digital communities or digital identities and give them rights and protections as a traditional organization. So that's going to be like key for other states to model. There are folks like Delaware, Wyoming who already are on that kind of train of thought. But again there are more progressive economic zones who are putting in place regulatory framework that takes the best of the best from all of across. And I know that's blockchain specific, but with AI, what's cool about this regulatory zone is that because it's indigenous, sovereign nation, they're protected and can protect their people how they best see fit. Whether it comes from blockchain digital asset regulations, AI And I think more people thinking about aligning themselves with zones that have more nimble frameworks could better serve you as you're thinking about, especially if you're an entrepreneur, continue to build in these types of spaces.
00:37:33.635 - 00:37:55.755, Speaker G: There is also an executive office that was created by the President and it's for the Digital Identity Task Force and it was made specifically for that purpose. So they started of course with themselves because of course they do it unclassified, classified and all type of documents every day. So they created task force to be able to help themselves and protect protect themselves as well as our future nation.
00:38:20.555 - 00:38:27.095, Speaker I: Thank you for that. How can we use fine print policies to protect user data and users?
00:38:33.315 - 00:38:54.465, Speaker G: I would say the biggest thing will be primarily privacy it protects users by how the way the company stores users and shares their personal data. This creates a boundary and also illegal binding to forms the use of the privacy in the decision making. Four things that help with that of course is transparency, data updates, legal compliance and of course continuously educating the user.
00:39:02.445 - 00:39:32.865, Speaker D: Yeah, I'm not potentially a big fan of fine print policies because I never read the terms. Well I do actually, but most people I know don't read terms and conditions so I don't feel it's up to the user. But maybe a policy at the government level which mandates certain requirements to be included on the terms of service would probably help. Obviously the specifics of the policy, I will leave that up for debate.
00:39:35.205 - 00:40:56.785, Speaker B: I'm putting on my HCI hat right now or my UX hat and I also agree with Dr. Saurav, like I don't read it, but I do think that there could be a much more nuanced way of identifying which policies are present. Kind of like how on your food we have nutrition labels, we kind of take that for granted. There was a time when that didn't exist and there was a time when maybe ingredients were added but you really didn't understand what those ingredients were, how they contributed to your health in one way or the other. And someone said, well maybe we need to make this data available in a way that is a little more consumable and understandable by folks who are consuming these foods. And I think that it could be a project for brilliant student, someone who's really into like data visualization or graphics or things to look at different ways of demonstrating the risks that may be associated with using certain platforms or policies or just through symbolism, through other things other than like these long term contracts that the government likes to like. You know they speed read on the commercials when there's some legalities in place.
00:40:56.785 - 00:42:23.677, Speaker B: But I do think that those, those things that are kind of antiquated can be updated to empower users in a different way. And I think just to add on top of that, having not just having policies that are present and available for people to read or have access to, but also really providing a way for folks to understand how to consent or reject the use of certain things very clearly because I think sometimes it's like you just kind of don't have a way to go around it if you wish to pay your mortgage right, you have to consent or you're not going to be able to pay your mortgage and have a house. And that doesn't feel empowering even though you've written out the policy for me to read right for use of your app. So I think that's also a consideration. Like you can have the policy there to quote unquote protect the user. But if we really aren't put in a position where we can't not use these products and exist or navigate society in the same way, then what is the benefit? I equate it to like when you go to restaurants, but now and like you have to scan the menu right to do it. And some people, I guess that's kind of cool.
00:42:23.677 - 00:43:03.099, Speaker B: But imagine that you don't have an up to date phone. You can't afford a phone that's repaired that has a phone that can do that, or you don't have access to WI fi because you can't afford it, or you just can't like read the small print that's going to show up on your small device or the menu like that. It creates accessibility issues for vulnerable people that we haven't considered. And it's like, but I like to eat and I like to eat out. And people say, well you don't go eat out. But that doesn't really help create a healthy society. If folks have to do things a certain way, one way, right.
00:43:03.099 - 00:43:09.735, Speaker B: And that way maybe even risky, it's just not, it's not good for our society as a whole.
00:43:16.965 - 00:43:25.145, Speaker H: Okay, and last question is, how can we ethically train new AI models? And how can users govern the use of sensitive data?
00:43:27.565 - 00:44:23.945, Speaker E: Oh, this is my favorite thing. My husband always makes fun of me because I'll get into like long wars with AI on historical things. Especially when it comes to like black history or African spirituality. There are certain topics that I was super well versed and that when I saw myself engaging I was definitely not getting information that I knew to be true. Having, you know, studied, having those books and being able to reference those books and like cited sources and facts that maybe those models weren't picking up or catching was really huge. And like getting, making sure that I was getting a different response for like for instance, my business that it was around in that area or the community that I was serving around that area to make sure that, you know, it was not only having actual correct facts, but also the tone and the way that they were speaking about these topics was more well rounded and holistic than it had initially presented at first. So don't be afraid.
00:44:23.945 - 00:45:03.215, Speaker E: It may sound silly to be going back and forth with a robot, but if, you know, like, I don't think this response is have that human centered approach or is accurately capturing, like, what I know know or what I have facts around, like, spend that time. Because it's, it's really helping the. Everyone you know who uses these models to get better responses. And hopefully, you know, you have AI models that just have a little bit more of an empathetic and more global human touch than necessarily they may be getting initially from the initial programmers and coders who kind of established the foundation of the different AI system that we're all using.
00:45:05.955 - 00:45:40.665, Speaker B: Shannon, I am so with you. So I just, I submitted. Paper hasn't been accepted or rejected yet, but the title is Did ChatGPT just gaslight me? And so the idea is that I was doing the. I don't know how many of you have tried the how many hours in strawberry challenge with ChatGPT, but it's something that went across social media where you ask and it gives you the wrong answer and you try to. People have tried to, like, teach or like, how you would do a human. Like, well, let's work through this together. Like, let's count the number of letters and then let's count the number of each letter.
00:45:40.665 - 00:46:01.161, Speaker B: And so you take different approaches. And it seemed as if every approach you take, it's like, no, there are only two Rs, right? And you're like, well, can you spell it? I can spell it. And how many hours is two? And it just, it keeps going. And so you finally may just say, you're wrong. I think that's where I landed. Like, you're wrong. And it was like, oh, you know what? I am wrong.
00:46:01.161 - 00:46:40.595, Speaker B: Right? And I have to look at that again. And you're right. So for my situation, I had asked ChatGPT to develop a code, a program to count the number of hours, right? And so it gave me this really beautiful, like, code, like, environment with the code and potentially with the output of the code that looked very code like, but it was wrong. It was real. The code was perfect and right. But the way it was presented was giving me the wrong answer. And I was like, why would you present it as if you ran this code? Right? To get the answer and you did it.
00:46:40.595 - 00:47:32.337, Speaker B: And it was like, you're right, I shouldn't have presented it that way. In the future, I will be more mindful of how these responses and it just made me think that is exactly what you were saying, Shayna. Like, I. There's terms like explainable AI which talks about this idea. I don't know how familiar you guys are with, like, modeling and like, how this black box exists. Where features are extracted and we can't always really explain in human terms how it comes up with this really brilliant end point of like data. But I'm thinking that we need actually more reflexive AI that can be like, I think this might be the answer, but you might want to check behind me, right, Versus what you were talking about, Shayna, which is like, this is definitely the source that I use to get this to write this paragraph.
00:47:32.337 - 00:48:30.605, Speaker B: And you're like, that doesn't even exist. Like you made that up. So the tone would be helpful. The reflexivity where it's like, I'm not exactly sure, but here's a stab I took at this response or at this advice and it's funny when we're talking about ours and strawberries or I asked ChatGPT to write my bio one time, right, without allowing me early on, and it was a lot of hallucinations, as Dr. Saurabh said. And I think those things are funny. But when this AI is being used to determine how much time someone's going to get in prison or whether or not a child should be taken out of a home because they may be at risk of harm, it becomes really real in that moment when people think it's giving good answers or what type of treatment you may get for your very rare cancer, things of that nature.
00:48:30.605 - 00:48:54.225, Speaker B: And so I do think more than just people saying I have to be judicious in how I use this, which should also happen. I kind of wish we could look towards developing AI that could have some of that reflexivity within it to say, I'm not too sure, but this is where it's landing for me and then do with that what you will.
00:48:56.725 - 00:49:21.295, Speaker G: I really like you guys answers. It was a personal experience that applied directly to you guys and I love the fact that you took the time to teach it. That way it can go off of you. So that's mitigating the biases within the data sets and also the accident to prioritize data privacy, implement security measures, obtain informed consent, and then ensure transparency within the algorithms.
00:49:36.365 - 00:49:48.413, Speaker A: Thank you all everyone. Can we give a round of applause for our. Thank you so much, Dr. Saurabh. Thank you so much, Dr. Nyes. Thank you so much, Shayna.
00:49:48.413 - 00:50:22.855, Speaker A: Thank you so much, Dr. Barrett. Now we're going to open the floor to our audience. If you guys have any questions that you'd like to come up and ask any one of the speakers, now's your time to do so. If not, we will go into the logistics six for the Hackathon question And if you have any questions later, just drop them. All right, thank you speakers, you guys are free to go now. We're about to go into the logistics, but again, thank you so much for giving us your time and your expertise.
00:50:23.835 - 00:50:24.227, Speaker B: Thank you.
00:50:24.251 - 00:50:25.255, Speaker C: Thank you for the invite.
00:50:26.515 - 00:50:28.375, Speaker B: Bye bye guys.
00:50:33.935 - 00:51:32.245, Speaker A: Okay guys. So welcome to the inaugural AI Policy Hackathon. This is an in partnership with Apart Research. Apart Research hosts Apart Sprints across the globe and we are a new Apart Sprint site in collaboration with the Google Developers Group. So here's some more information about Apart Sprints. You can find other virtual hackathons that are hosted this month and throughout the rest of the year, as well as previous challenges and other submissions that have actually been published and have won first place prizes. Also, after you submit your research paper in the review session by our judges, you may or may not be selected to join the Apart Lab research accelerator which is I think attendance week long, kind of like research fellowship where you get to get your paper reviewed by a senior research mentor and you get invited to a conference.
00:51:32.245 - 00:52:06.979, Speaker A: But moving forward for our hackathon we have three special awards sponsored by Musematrix, Y3K and the Brave Ideas Lab. You just spoke with our sponsors in this panel and we'll get more into the details about their tracks. So one AI and Social Justice. This is sponsored by Brave Ideas Lab. You can consider any of these bullets, however it is open ended. You can frame your policy around any issue that is imminent or any issue you are passionate about. AIM DSCI is sponsored by MuseMatrix.
00:52:06.979 - 00:53:00.005, Speaker A: You can consider things like ethical guidelines for AI in science or in AI and research. And lastly, our third and final track is AI and blockchain sponsored by Y3K. And here are some three bullets that you could consider. So moving forward, our Hackathon prompt is develop a research paper that guides new policy and AI models in human interfaces. So just keep in mind that the AI systems are increasingly being embedded critical infrastructures across all industries. Policy frameworks are the modality that addresses governance for AI. So for example, your research paper can examine how the algorithmic decision making behind AI models.
00:53:00.005 - 00:54:01.841, Speaker A: And another option is that you can supplement your research paper with a technical piece. So any code that you think accurately demonstrates your policy or is a supplement to it, you are about to submit that with your submission as well. So some information about prizes and judging. All submissions are due on Wednesday 11:59pm Prizes will be process directly between the recipients, one of you guys and your sponsor. And we'll be sure to send out those details as soon as possible when judging is over and submissions will be judged by Thursday and we'll communicate with you guys when that is finalized. So your goal for submission, just to recap, is to develop a research paper. You can work independently independently or in teams up to five.
00:54:01.841 - 00:54:41.725, Speaker A: If you have any questions, please scan the GDG Group meet and we'll be sure to answer it as soon as possible. Additionally, another resource we have for teams formation is the GG GroupMe or the apartments Discord channel. So there is going to be a specific channel for projects and teams. On the Discord page you can find teams just by connecting on which ideas interest you and if you haven't already joined the Discord, you can scan this QR code. You can find the channel for Hope Desk and Projects and Teams. Make sure that if you're posting.

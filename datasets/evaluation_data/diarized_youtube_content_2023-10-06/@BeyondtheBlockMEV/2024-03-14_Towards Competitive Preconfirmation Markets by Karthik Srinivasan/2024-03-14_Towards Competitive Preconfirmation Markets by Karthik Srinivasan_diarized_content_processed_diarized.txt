00:00:00.330 - 00:00:38.438, Speaker A: Yeah. Please give a warm welcome to Karthik from Sorella Labs. Hey guys. I'm Karthik, working co founder of Sorella Labs. We are an MEV focused research and product organization. Right now, we're building a hook on uniswap V four to kind of mitigate LVR with an off chain coprocessing mechanism. So using an auction off chain and bidding back value back to LPs, this talk is going to be about fair and competitive markets in the pre confirmation and shared sequencing paradigm.
00:00:38.438 - 00:01:22.278, Speaker A: So like really new research topics in the Ethereum research purview, and a very nascent design space. So I'm eager to really try to elucidate some of the emergent designs. Cool. So in terms of the scope of the talk, we'll first go through definitions. Right now, the definitions for this stuff is really kind of confusing, and I think a lot of different people have different definitions. So we'll try to iron that out. Then we'll go to emergent MEV that is result of just consensus mechanisms generally, but also in this interoperability paradigm between L two s, kind of this cross chain MeV that is an emergent property, and the externalities of that.
00:01:22.278 - 00:02:35.120, Speaker A: We'll then talk about proposed designs for base sequencing, shared sequencing, and then talk about intra app interop, which I think is going to be the first step for universal synchronous composability and interoperability between L two s in general. So what exactly are pre confirmations? Very generally, I think pre confirmations are agreements between a user and a preconfer where the preconfer is almost always a sequencer. The user is going to send in a request for an intent, and the preconference has the option to respond with a promise. Now, what exactly is, like the mechanism with which this promise will be fulfilled? That depends on the specific preconf paradigm, and we'll go over a couple of examples. This kind of varies, but essentially the user has some probabilistic certainty likeliness that they're eventually going to see finality on the L1. And this is very desirable, right? Because now we can have web two latencies, but web3 very decentralized like finality, and then decentralization guarantees. So here's a depiction of what's going on.
00:02:35.120 - 00:03:44.690, Speaker A: Cool. So we're actually very familiar with pre confirmations from L two s, right? So anytime I'm interacting with an l two in between, the last time it posted its state route to the l one, and when it's next going to, I'm getting precons from the l two and the actual certainty I have that these are proper transactions. And this is actually my state on the l two that is undergirded by the collateral of the specific pre confirmation, which is reputational collateral on behalf of the centralized sequencer and whatever labs entity kind of spun up the shared sequencer. So it's essentially me saying, you have the ability to completely rug me right now, but you doing so would be such a reputational cost, and I know your reputation that it just wouldn't be economically feasible. Right. The intent types that are satisfied for l two precons are kind of limited by the specific expressivity you have on the L two. So this is based on the actual Vm of the L two, and any expressivity you have within that language.
00:03:44.690 - 00:04:30.286, Speaker A: Another is stake pre confirmation. So this is a newer paradigm, and it's, I think, going to definitely take off, especially with Eigen layer. Now, in everyone's view, essentially you have the precon for opt into additional slashing, and the collateral is going to be economic. In this case, right now, the intent type is completely arbitrary. It is essentially whatever you can specify logic for slashing conditions like the world's your oyster here, and you can get really creative and have really cool mechanisms built out of this. Arbitrary intents that are satisfied with economic or restaked economic collateral. So an example of this are proposer preconfs.
00:04:30.286 - 00:05:12.670, Speaker A: Essentially, any number of proposers can opt into restaking and being preconfers. So opting into whatever the additional slashing conditions are. In this case, it's if I receive a promise and I'm not in your slot, then you will be slashed. And I have a 32 block look ahead. So I'm just going to go to the pre conference, see who's closest. It's the N plus two proposer. I send him my request, he responds with a promise, and I have economic certainty, as long as what I'm actually getting promised is less than the slashability amount that I'm going to get included in his slot.
00:05:12.670 - 00:05:51.658, Speaker A: Now, shared sequencing, this is towards l two composability, very desirable, so that we have less fragmentation on ethereum. Essentially, the idea is that instead of each roll up doing both execution and sequencing, we kind of split the two up and have sequencing done over all roll ups together. This is beneficial because now you can have cross roll up MeV extracted at the level of the shared sequencer. So users send to the shared sequencer. Shared sequencer does the ordering for each roll up, goes to the roll up. And then all the data from the roll ups and the shared sequencer, like a quorum certificate, go to the L1. A flavor of this.
00:05:51.658 - 00:06:33.386, Speaker A: And the shared sequencer is getting precuts to the users at web two instance. A subset of this is base sequencing. So this is essentially realizing that we have the L two s using the L1 for data availability and for finality right now. So we can also just have it get sequencing from the L1. And if you think about what this picture looks like with the L1 in the shared sequencer now essentially the users are submitting to the L1. Ordering is happening on the L1, and then this roll up state is being derived from L1 blocks, right? That's kind of the mental model to have. So now there's some emergent Mev that is a result of not only this inner domain cross chain system, but also consensus in general.
00:06:33.386 - 00:07:22.358, Speaker A: Firstly, last look problem. So this is pretty huge for any sort of consensus mechanism, but it arises from giving monopoly power of sequencing or execution quality to one sole proposer for some window of time. And this is a huge problem where extraction can occur because the monopoly player has plausible liability that they were acting in a malfeasing manner. So an example would be if I have 200 milliseconds where no one can check whether I am properly including transactions, I see a huge swap come my way and I want to be on the other side of it. Sorry. And prior to me matching this, another transaction comes in and matches it, right. I can censor that transaction that matches it, take it for myself, and no one would be the wiser because I have plausible liability in the consensus mechanism.
00:07:22.358 - 00:08:00.658, Speaker A: Another example is in this 200 milliseconds price on finance moves 50% and then I arbitrage LP as a result, and I have complete plausible liability. So this is always increasing as a function of last look time. The actual dependency on time is different depending on the specific type of extraction. But generally for price stuff, it's square root time dependent. The other new emergent Mev is cross roll up Mev. So the idea here where shared sequencing kind of takes off is that if I have roll up a and roll up b, I get value x and y from sequencing them both independently. That value is coming from MeV.
00:08:00.658 - 00:09:00.230, Speaker A: But if I am able to sequence them together, I get x plus Y plus epsilon, there's some delta and it's positive values being created. The reason for this is that now I have this kind of second order effect of MeV that occurs in sequencing them both my mental model is consider I'm sequencing arbitram and optimism, and then I extract both all MeV on both chains, and there's also a dex at the end that are at two discrepancient prices. So I'm just going to reset it and take the delta as arbitrage for myself. So roll ups need to opt into shared sequencing to essentially give the sequencing rights to this decentralized sequencer, and they need incentives to do so. This is essentially the way in which roll ups would be incentivized to opt into it. They would say that, look, if we're sharing sequencing, there's going to be value created, this can be distributed pro rad among all the roll ups and we'll all be better off. Unfortunately, they do have to agree on a canonical shared sequencer.
00:09:00.230 - 00:09:47.730, Speaker A: So a very high throughput shared sequencer might not have the same credible neutrality that the L1 would have. For example. Now it's an open question of is it going to be a domino effect for l two s to opt into shared sequencing where a few movers opt in? Now everyone's better off opting in? Or is one or two of them going to think I'm better off staying on my own because I think I can monopolize on myself. I personally am of the opinion that this allows for a long tail of VMs. So I think that all the VMs, like the long tail VMs, are going to kind of go into this shared sequencer, and then there's going to be two really big players that are like semi monopoly powers that kind of silo themselves. And the last question is, who's Mev? So they're getting value created. That value is going back to the roll ups.
00:09:47.730 - 00:10:37.222, Speaker A: But there are adversely selected parties at the end of the day that are suffering from this extraction. In my example, it would have been, in the rebalancing example it would have been maybe someone on a centralized exchange, I don't know. But it gets very difficult to see who exactly deserves this MeV and how do we redistribute it in the most equitable way? So some proposed designs in the space, three front runners. The first from espresso, is high throughput consensus mechanism, plus precons from the shared sequencer. So the precons are going to allow for web two ux, and it's going to be the same ux on L two s that users are used to. You're going to have instant finality. So even if the L1 reorgs, you have what the L two state across all the roll ups should be.
00:10:37.222 - 00:11:11.822, Speaker A: So you're not worried about the L1 at all. You just need eventual inclusion. And then you can also give the L1 proposer rofer on whatever L two block space was sequenced so that you have composability with the L1. This has like an asterisk, because now you have finality condition on that block being included. But if the L1 proposer actually opts into this, then they would probably price in that risk into the pre comps they're giving on the L1 L two arbs. The next design is from Justin Drake. This is no hard fork required.
00:11:11.822 - 00:11:48.222, Speaker A: Proposer precons and a new includer role. So essentially any number of proposers in the next 32 slots opt into restaking and the slashing conditions of preconfers. I go to one of them, get the preconf for my request, and just send that preconf to any of the next proposers. And they're incentivized to include it. Because if I just do base V plus epsilon, it's not touching any contentious state. So they're more than happy. And then the last one is Xante everything.
00:11:48.222 - 00:12:47.274, Speaker A: So this is the execution ticket idea, where essentially we're going to auction off in advance the right to be the sole proposer of the L1, and then do the same with l two block space, all Xante, and then hope that the really sophisticated players who have very good notions of price, can aptly price in the MEV, extract it and have that flow in protocol. So this incentivizes monopoly sequencing, which allows for kind of the maximal coincidence of wants intrachain, some critiques of each. The first one, you're opting into a new consensus mechanism, so you don't have liveness because you have instant finality. Obviously, it's going to be a high throughput system sequencing across all L two s. So nontrivial hardware, it's going to centralize the validator set and definitely less credible neutrality than using the L1 as a shared sequencer. Number two, this is Justin Drake's design. So as long as the L1 proposer is giving out preconfs, they suffer the risk of miss lot.
00:12:47.274 - 00:13:48.006, Speaker A: Right, and that's aliveness fault on their end from the preconf side, but they really didn't do anything wrong. The other thing is that it's a really long less look. So for me to give my preconf to the includer, I essentially need to get it back in a timely fashion. But this isn't really a property of the design, because he essentially, whoever I send the preconf to has an arbitrary last look and can just send me back my preconf whether rejected or accepted, maybe like 100 milliseconds prior to inclusion. So he's only going to fill me if it's profitable for him to do so, which is why this design specifically isn't great unless you have a centralized notion of the pre conference competing with each other. Now, the Xanti one, this one requires, as previously mentioned, very good notions of price, and that's going to be a centralization vector, because only really sophisticated players going to actually compete in this. It's very stat RB because you're competing in what you expect the extraction to be rather than when it's being priced in.
00:13:48.006 - 00:14:38.742, Speaker A: So you have deterministic arbitrage, or more deterministic arbitrage, which will result for a better pricing of the actual opportunity. And it's very difficult to return MeV to users. In this case, it's going to flow through the protocol. So here's my thesis for the minimum viable interop that we'll see like PMF soon, I think. And this is intraapp interop. So at Sorell Labs we're building a coprocessor that is essentially cognizant of information that's occurring outside of the blockchain, and actors within the blockchain that are also cognizant of that information are going to act as a result of it. As a result, it's always best run X post auctions as the block is being constructed, because then you can factor this into the bids that are coming in to do whatever in the system in the application itself.
00:14:38.742 - 00:15:59.120, Speaker A: And this is very easy to do through siloing the application specific consensus mechanism with restaking and essentially running x post auctions as the block is being built, in this case a shared sequencing block for every block, making sure that we can define who the adversely selected parties are in our application and then repay them the value of the competitive auction. So in our case, this is going to be the LPs, but it could be arbitrary in any given app. And now the power of this is if you have intra app sequencing and your app doesn't rely on any other state, you have independence of state, right? So now preconfs are very easy because anyone's really willing to accept your application specific bundle because they know it doesn't touch any other state, right. It's not contentious. There's no ability for them to extract on and perhaps price that later based on additional information that arises as a result. Now you have the apps that are able to control their MEV. So not only will they be able to control their MEV and then give it back to the adversely selected parties, the shared sequencers also have less search base in this kind of combinatorial auction over the entire transactions that are being included on all l two s.
00:15:59.120 - 00:16:44.270, Speaker A: And that's fantastic, because now not only do you have centralization limited on the side of the app specific arbitrage opportunities, now I can focus on one app and only ARB that app. It's also feasible for less sophisticated players to come in and actually build these intra l two blocks, which is very desirable properties. The issue, some issues is that it's not true synchrony, right? I can't get a flash loan on one l two and then bridge it to another l two and then liquidate someone and then bridge it back and pay it off. That's going to come hopefully with hardware acceleration and much of the sort. But I think that's a ways off and it's very difficult to get any semblance of interop. That is what users want. That's closer to this in the interop.
00:16:44.270 - 00:17:50.320, Speaker A: Essentially my idea is that this is what users want because as long as you have app specific Interop, you can tune the consensus of your app specific block time to whatever arbitrary time you want to. Right. As long as you're running that high throughput consensus mechanism, now you're able to use the preconfs that you give your users with other apps that are able to price in your preconfs and have interoperab with them. But that also has middlemen involved. But it is some semblance of the interoperability that you would want to have at scale in the asymptote of the space itself. The other issue that's a bigger issue is that l two s are less incentivized to integrate right now because they're not getting the MEV rewards because it's all being taken care of at the application specific level. So I think this is the bigger issue where it's like how do we get the L two s into the shared sequencing paradigm? So now we can do the app specific interop and then get the single slot finality that we do through the actual shared sequencer, which is necessary for the interrupt to happen.
00:17:50.320 - 00:18:04.260, Speaker A: But yeah, just kind of a foray of the design space and hopefully way we're able to solve a bunch of these issues you have.

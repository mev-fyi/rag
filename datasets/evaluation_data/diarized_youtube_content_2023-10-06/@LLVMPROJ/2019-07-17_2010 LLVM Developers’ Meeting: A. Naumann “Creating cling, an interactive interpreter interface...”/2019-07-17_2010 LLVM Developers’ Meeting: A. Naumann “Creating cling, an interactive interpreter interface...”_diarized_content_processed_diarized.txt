00:00:06.420 - 00:00:40.640, Speaker A: Well, so welcome to listen a little bit about what we plan with Kling. There are four people working on this project, three out of which are in this room. We work together with Fermilab. This was the original title of this presentation. It's rather long, but it's much more precise about what I'm actually going to talk to you about in the next half an hour. So cling is a c interpreter, sort of. It's definitely interactive.
00:00:40.640 - 00:01:47.810, Speaker A: You can basically use it like any interpreted language. There are people who use it even inside a CGI environment for web servers, and it sort of has an abbreviation meaning. The reason why we are interested in c plus plus interpreters is because the high energy physics community has huge amounts of data which are really serialized c plus plus objects. And we have many physicists who are obviously physicists and not computer scientists, and they need to write analysis algorithms in c plus plus to analyze the data. And so we have, I would estimate in total, about 20 million lines of code to analyze the data. And that's all in c plus plus. The software which helps people analyze that data, uses a c plus plus interpreter as a front end that allows people to write their algorithms interactively, and then later on migrate it to the 20 million lines of code frameworks that they use.
00:01:47.810 - 00:02:28.620, Speaker A: We are already doing that since 15 years. We use synth for that, but Synth has several limitations that start to bug us now. So rewriting the whole thing with clang was an obvious solution. So we sat down and tried to come up with a plan on how to do this properly on a blackboard. Now I'll show you what we ended up with. What we needed to convert to clang is the set of requirements that people have right now, because we don't want to break people's code just because we introduce a new interpreter. So we need to be able to have statements at the translation unit scope.
00:02:28.620 - 00:03:05.316, Speaker A: I will explain that to you later on. It's very obvious once you think about the prompt people use. Implicit includes. They don't need to state the pound include for types that are known to the frameworks. Framework is just a set of libraries for us. We load dynamic libraries automatically. We automatically declare variables that have not been declared, and we have something which is horrible when you talk to a compiler, which is dynamic scopes.
00:03:05.316 - 00:03:42.380, Speaker A: And I'll explain a little bit more about what's horrible about it and how we are going to solve it later on. In my first slide, I already told you that actually it's not really an interpreter. So in the traditional sense, it really isn't an interpreter, because we try to compile as much as possible. It's also not connected to LLI. Really we are doing something different. What we are trying to do is we try to evaluate things at runtime because of speed reasons. We will try to jit compile it, and we want to have just like any interpreter, pseudo instantaneous response.
00:03:42.380 - 00:04:14.116, Speaker A: So when you look at the bigger picture, this is the usual thing. I left out all the details. This is the part that is relevant for us. You can see that we start with C code, which has these nasty extensions, these interpreter extensions. Then we go through SEMA and clang, and then we go to the execution engine. These are the key ingredients that we need to interface with. And so cling talks to SEMA to straighten the code so that SEmA understands it.
00:04:14.116 - 00:04:51.690, Speaker A: And then of course we also have the handle on the execution engine. I decided to give you an idea of the use cases, the applications that we use the interpreter in, because that tells you the requirements that we have and why we have the requirements. It gives you a motivation for that. One of the main motivations is the code development. For physicists, writing code means translating an algorithm that they have in their head into c plus plus. And the algorithm depends on the output. So it's actually an iterative process.
00:04:51.690 - 00:05:47.856, Speaker A: They start with an algorithm, they look at the output, and then they change the algorithm, they adapt it, which means they have a continuous added and run cycle, and we want to shorten that as much as possible. Rebuilding the whole executable with hundreds of shared libraries is just not an option if you want to do it this way. So in synth and the current interpreter, interpreting an empty function that moved an empty function is really 300 times faster than recompiling. It is not surprising it's just an interpreter, right? But that's the motivation. Of course, we could also use Python, and anybody who's sane would not use c plus plus as an interpreter. Right. But the big advantage is that once you have your code, your algorithm written in c plus plus, you can just take it and check it into the revisioning system, and it will be part of your experiments framework.
00:05:47.856 - 00:06:45.180, Speaker A: So it's very easy to transition this algorithm and to publish it to the other physicists. We also make it very simple to transition code from being compiled, from being interpreted to being compiled. The x tells the interpreter to execute this file, and if you add a plus in the end, then it doesn't get interpreted, but compiled. And people actually use this as a standalone build system which is working on any platform that we support. So it's a very simple way to build shared libraries. Another use case is signal slot. We use signal slots and we connect things with simple function calls as strings, which makes it very easy to change things, to very easy to customize things.
00:06:45.180 - 00:07:35.290, Speaker A: And of course a simple extension of that is the use of plugins. Here too we have the calls as strings, and that's very nice because we have basically no linktime dependency. It's a very loose coupling of libraries and also runtime detection. If you don't have a library, then you don't use the plugin mechanism. A whole new chapter is the Python binding that we use. We also offer Python as a front end to our c plus plus libraries, and we don't produce wrappers and extra code to describe our c plus plus, our c plus plus types. But instead we do this dynamically because of course our interpreter has all the information about types and their functions and so on.
00:07:35.290 - 00:08:27.690, Speaker A: So the trick is that we pass this information into Python and then Python has a shallow image of the same thing. So that calls into an object get actually forwarded to c plus plus. This sounds very difficult, but it's very know if you have this code in C, it simply translates to that code in Python, and you see how similar that is. There are a few more use cases. For example, our huge binaries are run in different contexts and we need to configure them. And the way we sometimes do that is by defining configuration objects in c plus plus, and it's very easy to change them. They just get interpreted and loaded at runtime.
00:08:27.690 - 00:09:14.922, Speaker A: We use the reflection information that is obviously part of the interpreter that you get for free when you have an interpreter. We use that for serialization and documentation. Synth was also used as an artificial intelligence configuration engine, actually for a computer game, and it was invented for remote configuration of integrated devices. Kind of fancy, but once you have it, you can use it really in many contexts. Okay, so now that you see where it's used, let's look at how we are going to implement these features. In claim the core part is the interpreter. That's the one which deals with c view of things.
00:09:14.922 - 00:09:53.798, Speaker A: Then we have a meta processor which steers the interpreter, and then we have the user front end. I will of course focus on the c plus plus interpreter. The main difference between an interpreter and a compiler for me comes from the prompt, and I will guide you through this step by step. So we have the prompt here. Okay, now what if somebody enters int I and initializes it with 17? Okay, then 17 is not right. I want to have it to 42. And then we define a function at the prompt.
00:09:53.798 - 00:10:02.814, Speaker A: So it's not yet done. We have a continuation. We return. We're still not done. We return plus, plus I. Okay. And then we call the function.
00:10:02.814 - 00:10:42.196, Speaker A: And here you also see how this is simply not c plus plus, right? You cannot compile this. This is not legal. So what we need to do is we need to transform that input. First of all, we need to sort to separate statements from declarations. We put declarations into their own namespace, which doesn't even, I mean, we could also put it onto global scope. But whatever details we need to extract them, we put them here. And then the statements we need to wrap in functions so that they get callable.
00:10:42.196 - 00:11:11.644, Speaker A: Otherwise we cannot call them. Of course. Now the problem is that this comes in line by line. So this thing here needs to be somehow added to the int I. And we do that by growing the ast and actually growing the memory buffer as well. We then need to remap the globals. Once we have the ast, we convert it to a module.
00:11:11.644 - 00:11:39.610, Speaker A: And then we need to map the globals from the old module to the new module so that we have the same values. If they were updated. We need to have that updated value. We need to be able to call the same functions. And then we run only the new initializers. And then we call the statements tab, like over here. So you see, that's how we can convert something which is really awkward at the prompt into valid c plus plus.
00:11:39.610 - 00:12:01.164, Speaker A: We also do library auto loading. And we were a little bit afraid of that. But actually it's dead trivial with clang because there's a nice error message, hey, symbol unknown. And we're like, yeah, okay, get me the symbol. We look at the library, we load the library, we map the symbol, and then we go on. Yes. Just on a previous one.
00:12:01.164 - 00:12:36.928, Speaker A: Do you have problems with side effect? Are you running all the prompt every time that you. No, we cannot. No, we go on with no, but there is nothing to run here, right. There is only these wrecker functions which wrap the statements, and we just execute the last one, not the ones before, of course. So that was very nice and very simple. Thank you. We also want to have includes optional.
00:12:36.928 - 00:13:31.444, Speaker A: The way we do this with synth is that once you load a library, we get the reflection information for this library. So the interpreter has knowledge about all the types in this library. With clang, we need to do this differently. And there our reflection information as we see it is stored in the PCH in a precompiled header. So we want to have multiple precompiled headers which is nicely supported, probably maybe one per library or one per set of libraries per product, and we load them all in. We need to prune contents of PCH. And I think one part is already supported, namely if you generate a Pchb which depends on a Pcha which you load while generating Pchb, then you don't want PchA contained in Pchb, right? You want them separate, you don't want to re include all of Pcha and PchB.
00:13:31.444 - 00:14:32.520, Speaker A: I think that is already supported. If I'm not mistaken. The part that we also need is that right now people have the ability to suppress types from being visible in the interpreter, so to say internal types, types that are not part of the API, and we want to keep it this way. Now, the big problem here is of course that we cannot screw up the asT. So when we veto nodes in the aSt, we actually must make sure that nothing depends on it. And of course this dependency is tricky, right? It's not just decalus, which I believe are in the attributes, it's more like the include what you need approach that we saw playing philosophy. The next part is that we want to be able to call compiled code from the interpreted, I mean from the interpreter, and also of course to be able to call the interpreter from compiled code.
00:14:32.520 - 00:15:12.040, Speaker A: So in the end what you get is actually slight recursions, which we actually have in reality. And a year ago that wouldn't work, but now it just magically works. There's no problem. It was really nice to see that stack overflow once we had this infinite recursion like yay, it breaks. So here comes the tricky part, dynamic scoping. It's really nice to have that at the prompt. What people do is they open files which contain c plus plus objects, right? I told you that our data is c plus plus objects serialized to files.
00:15:12.040 - 00:15:52.620, Speaker A: So they open these files and then they can access the objects by their name as they were stored and call functions on them. That's of course at runtime, right? So they would write something like this. Yuck. Then came Sebastian Riedl, I believe is his name, and had a fantastic idea. He was like, why don't you just tag this thing hissed. Of course she had the problem, right? Why don't you tag this as of dependent type? Then Sema will say whatever and just let it go through. And then later on we can fix up the ast that was built and make it a valid ast so that code can be generated.
00:15:52.620 - 00:16:48.252, Speaker A: So what would that look like? Well, that's actually kind of simple. We just need to escape it, so to say, so that this expression gets evaluated at runtime, it's not that tricky, right, because at runtime the file has been opened. And then when the interpreter evaluates this thing, it can, upon seeing an unresolved, an unknown identifier, it can query the file. So that's how we introduce dynamic scopes as a last fallback lookup. Reality is of course much more complex than that. In reality we need to take care of parameters that are passed in the context of this function, for example into the interpreter. And we need to make sure that return values that are returned by this function call end up in the function.
00:16:48.252 - 00:17:27.770, Speaker A: So we need to make sure that the type conversion happens and all these things. Okay, here's the next problem. Our interpreter allows people, and I told you already, right, to change their code. And what does that mean? If they change their code, it means they have a piece of code which they unload, they change it and they reload it for a compiler. This is nuts. This doesn't make any sense, right? So what we need to do is we need to take the ast, we need to remove, we need to prune certain top level declarations, those corresponding to a file. And then we compile the file again.
00:17:27.770 - 00:18:17.300, Speaker A: As you can see over here, people load a file. You create an object, you call a function on the object, and then you unload the file again, you edit it, and then you load it again, you get the different answer. So of course we need to know which parts are grouped in one file so that we can unload them. And much more important, we need to do some dependency analysis. And again, this is similar to what Greg Silverstein showed with the include as you use or what you use, because we don't care know easily. I would say there is deckle use. We know what's being used, which types have been used.
00:18:17.300 - 00:19:06.466, Speaker A: That doesn't work because if you have one file which uses types declared in the same file, then that's just fine. What you want to know is whether there was another file loaded later which uses types of the file that the user wants to unload. In that case you would veto the unloading. You would say, sorry, that file is still used by some other file, we need to keep it. So that's the kind of dependency analysis we need to do. Now once you agree with the user that, okay, yes, we can unload this file, then we actually need to ask the execution engine for all the symbols for all the globals of types from that file, so that we call their destructor. And I personally am not sure whether we have the information from the execution engine what types the globals have, so that we can call the destructors and so on.
00:19:06.466 - 00:20:08.480, Speaker A: I'm sure we can pull it off, but I haven't looked at that yet, so here's a rather long conclusion, so don't be afraid, I'm not yet done. You're still going to stay here for a few more minutes. But I still wanted to summarize right now what cling really is for us, because even when we say interpreter, what it really is, as our computer scientist told us, it's an ahead of time compiler, because we try to compile as much as possible before running the code, and all the rest we then compile later. We extend c plus plus slightly so that it's more natural to be used at the prompt. And actually we can also take these extensions and use fixit to create proper c plus plus so that people can really just take their code and put it into the framework. We interface clang and we are not completely done. We want to do more than what we have right now.
00:20:08.480 - 00:20:51.034, Speaker A: Now the main ingredients for us, that's the prompt library auto loading. The optional includes the dynamic scoping, the calling between the transition between compiled and interpreted worlds, and the un and reloading of libraries and sources. Since I'm allowed to be here and talk to you, I wanted to at least let you know what we are missing. And now that clang is so advanced when it comes to c plus plus, it's really amazing. I mean, everything we were hoping for is already there. So now our wishes get crazier and even more corner case like. What we are looking for is a memory buffer which allows us to grow.
00:20:51.034 - 00:21:32.802, Speaker A: So the start may be fixed, but we might need to increase it at the end. I'm not even sure whether this is really sufficient. Maybe the start also needs to change. There was an idea about a year ago about chaining memory buffers so that if you reach the end of one memory buffer, you go on to the next one. We need something like that because, well, we don't want to reparse the whole memory buffer, so we want to stop the parser at one top level declaration, append to the memory buffer, and then resume the parsing. That's our plan. We also need the parser to tell us that it's not yet done with a top level declaration.
00:21:32.802 - 00:22:05.166, Speaker A: So maybe what we can do is enter code completion token or something. I don't know yet how exactly we can do that. If you have an idea, then please let me know. This is a key item for us. We need to solve the memory buffer before we can proudly state that cling is working as we want it. Cling version .1 the second part is the ast dependency analysis.
00:22:05.166 - 00:22:47.218, Speaker A: If you want to do unloading, then we need to figure out which types are still needed and which types can be removed. For that we really need the full blown graph of the types with their location. We have the location, but we need to build the graph. I told you that we use the X filename plus as a simple way to build head libraries, and we would like to keep it this way, actually. And ideally, of course, given code that has already been jitted, we don't want to recompile the whole thing just to dump it out to disk. I know this is really borderline. I'm sure that we are the only one ever using it, but I was wondering whether it would be possible.
00:22:47.218 - 00:23:34.978, Speaker A: Okay, possible to dump jitted code into a shared library of some sort. But fine, I thought so already. So it's getting close to Christmas, and so we were wondering whether there's anybody else who's interested in getting ast dependency graphs, because I think they are very nice tools. If not, we'll try to do it ourselves and ask many questions. Yes, so now you want to know what of what I presented are plans and what is actually implemented, right? So that slide tries to answer that. These are the things that work. We have a simple prompt that's working.
00:23:34.978 - 00:24:27.140, Speaker A: I can show it to you offline later on. We can call from libraries into the interpreter and vice versa, and we can do the auto loading. We are right now working on the dynamic scopes and I expect this to still go on for at least a few months. We still want to make the prompt a little bit more solid. So also there, there's still some work going on and we need a proper implementation of a growing memory buffer for that. And we interface this small interpreter that we have right now with our analysis framework just to make sure that what we have is actually what we need and that we are developing in the right direction. So that's mostly concerning reflection information so that we can do serialization and so on.
00:24:27.140 - 00:24:54.294, Speaker A: Yeah, and for the rest, you've seen the plans, right? So I think that we can pull it off. In the beginning I was very scared because the concept of a compiler and an interpreter is so different. But I believe we managed to, with your help. Really, we did only very few things. We managed to get a plan for everything. In case you want to find us. We are of course here until tomorrow.
00:24:54.294 - 00:25:25.266, Speaker A: But that's not what you care about. This is what you care about. It's in subversion over here. You're welcome to check it out. The code's copyright is actually already pointing to clang. The reason is, of course, that once we are done, once we are happy with some fundamental functionality in Kling, we would like to offer it to clang so that it gets included if the community thinks that it's worthwhile. Right now we are not really satisfied.
00:25:25.266 - 00:25:44.160, Speaker A: We think that what we have right now is not interesting enough to be offered. So we first want to get the memory buffer and so on done. And once we have that, then I hope still by the end of the year, then you'll get an email with a huge patch or something. We'll see. So. Okay, thanks a lot.

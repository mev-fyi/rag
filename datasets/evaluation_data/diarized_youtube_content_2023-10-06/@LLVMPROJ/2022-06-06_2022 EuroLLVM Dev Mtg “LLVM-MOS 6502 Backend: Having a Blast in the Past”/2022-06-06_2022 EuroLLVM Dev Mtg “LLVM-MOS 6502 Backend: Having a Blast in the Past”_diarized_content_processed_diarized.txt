00:00:00.570 - 00:00:25.558, Speaker A: Ah, okay. Hi, I'm Daniel Thornberg. I'm the main code gen author behind the LVM most project, and that's a project to make a 65 two backend for LVM. So, brief bit of introduction. If you haven't happened to heard of the 65 two, it's an eight bit cpu, and it was, in all of these devices, a bunch more that wouldn't fit on the slide. These devices were wildly popular from the late 70s through to the early 90s, when the chip was in heavy use. S.
00:00:25.558 - 00:01:21.590, Speaker A: Amazingly, several million of these are still sold today. It's like one of the fewest transistor accounts that you can get on, like a real practical cpu. And there's still huge retro computing and retro gaming communities around these. So it's not uncommon for people today to still find themselves knee deep in 65 two assembly. That being said, the first question I get asked about this is why on earth make a LVM back end for a 40 year old chip? Personally, I was interested in writing software for one of these old systems, and when I looked at the current crop of C compilers, despite its age, a kind of consensus is formed that it's just not possible to machine generate good code for this chip. And that's relative to the remarkable ease with which a human has writing good machine code for the 65 two. It's considered one of the easiest assembly languages for a novice to write good code in.
00:01:21.590 - 00:02:04.530, Speaker A: And good here is maybe ten to 20 times more performant than the current reference C compiler for this. So I didn't think this was an intrinsic state of affairs. I didn't really buy that there was absolutely no way to create a performance code generator for this. So I wanted to take LVM, all of the principles and practices that have gone into its crop of code generation techniques, and apply them to this problem to see if it would work well. And if it were to work well for the 65 two, there's other weird tiny microarchitectures that are still relevant. Things like pick the 80 51 and z 80, it'd be possible to open LVM up to these small, like tiny microarchitectures that are common in embedded systems. So given the set of constraints.
00:02:04.530 - 00:02:52.846, Speaker A: Wait, this. Oh right, skip the slide. So in particular, some of the things that make this chip really difficult to develop for, and canonically, it makes it hard to write c for it only has 256 bytes of stack. So the normal way of using a c stack of putting local variables relative to a stack pointer, you can't do that using the hardware stack pointer, it only has three registers, they're only eight bits wide, and you can't dereference a pointer using them. If you want to dereference a pointer, you have to put it in memory. In the first 256 bytes of memory, which is special, has special addressing modes, and you need to manage exceedingly carefully, like way more carefully than memory is typically managed on most compiler targets. So given those constraints, we were able to make a pretty good end to end solution for this target.
00:02:52.846 - 00:03:29.390, Speaker A: We have a c and C plus plus front end. Someone made a rust port, which is remarkable. And on average we generate what I would call sort of okay code from the point of view of an assembly language writer. That is actually considerably better than the current state of the art, not even the reference compiler, which were maybe two to three times better then. But what's interesting is we've seen this thing generate really, really good code. It just doesn't appear to do so consistently. And when we look into why go in case by case, in the cases where it's generating suboptical code, it appears to be more an issue of polish.
00:03:29.390 - 00:04:19.018, Speaker A: Various code generator passes in LLVM will expect the instructions that it sees to look a certain way or have certain properties. And if those are violated, then often early returns happen, and entire scopes of optimizations just don't happen. So one of the things that we've had to do is go through and regularize things and make sure everything looks normal, which is very difficult, because the chip is absolutely not normal. That being said, while we're polishing it, you can use it to make real projects, even ones with a degree of performance sensitivity. So here's a demo that someone put together for the Atari 800. So notable about this. It's not a super complicated demo, but it does have effects that have to happen in the interval between vertical blanking on an NTSC or PAL video signal.
00:04:19.018 - 00:04:58.966, Speaker A: So very relatively tight tolerances in manipulating hardware registers, which is surprising considering that the entire main loop of that was 511 lines of really, really high level rust. So that was able to go all the way through LVM. And there was music playing, but I didn't want to try to deal with the sound system here. But yeah, all things together to get a sense of scale that gets compiled down to maybe a 30 kilobyte executable in the native format of the Atari 800. So to do that, to get reasonably good code out of LVM for this tiny target, we had to do a bunch of weird stuff. I can't talk about even a third of this because it's a ten minute talk. The general theme is regularization.
00:04:58.966 - 00:05:48.582, Speaker A: We took this processor and tried to make it look as normal as we possibly could. So in any way that we could possibly lie to LLVM, we did, to make it look like it was sort of risky, like x 86 at the weirdest, and largely if you can do that, so long as you're willing to later go through and remove all of the lies and lower things to the way that they actually are, and often you can do that in constant overhead, so you don't actually lose anything by doing so. There are a couple of exceptions though, and those are the more interesting ones and the ones that generalize outside of a target. So I wanted to tackle them specifically how we handled the stack and how we handled the limited number of registers with regards to the stack. Like I mentioned, you can't put locals on it, it's too small. So typically what you do is maintain one in software, which you bump manually by doing arithmetic. You can do that, but it's really, really slow.
00:05:48.582 - 00:06:26.626, Speaker A: This is the canonical reason why you can't write a good C compiler for this chip. But assembly language programmers just don't deal with this at all. They just look at their call graph in its entirety and reason well, I only wrote this section over here to be recursive, so why don't I just allocate everything else in global memory, and then I'll set up a stack pointer only for the recursive region of the program. So we do that analysis exactly. We go and walk the call graph in a conservative fashion. For each translation unit, find regions that we can prove don't recurse, and then allocate their memory statically, which is admittedly only half the story. There's two reasons to use a stack pointer.
00:06:26.626 - 00:07:39.130, Speaker A: One is recursion, the other is asynchronicity and reentrancy. If we were to be conservative with regards to interrupt handling and asynchronicity, we'd have to assume that unbeknownst to the compiler, an interrupt handler could call main, which would make everything possibly need to use a stack pointer, and globally disable the optimization, which is incidentally how C usually models things. It tries not to do detailed reasoning about the call graph in this fashion, but since we consider our translation unit to be the whole program, we default with linktime optimization on and ship all of our SDK as bitcode. If you have that model and are willing to annotate, say, where interrupts or asynchronous entry points happen, then you can also find the things that are possibly callable for them and make those regions use dynamic stacks too. So with this regime of minor annotation, we were able to get a pretty good solution to allow most code that we've seen for the 65 two to operate in a pretty much stack free fashion, which matches what we've seen for assembly language code that's been written for the platform. So that's the stack, the register set. LVM really doesn't like having only three registers.
00:07:39.130 - 00:08:13.446, Speaker A: The greedy register allocator largely does not seem to have been built to operate in that constraint of an environment, which makes sense. There's not really many real targets that only have three registers, but depending on who you talk to, the 65 two didn't either. In fact, it'd be difficult to imagine programming on something where there are only three places to put values. Processors from this era typically would call themselves something like a memory register architecture and the zero page. This first 256 bytes of ram is kind of blessed in this fashion. It has a lot of the properties that you would describe to registers. It's homogeneous.
00:08:13.446 - 00:08:45.166, Speaker A: There are special addressing modes to deal with them. So it's kind of tradition on this chip to treat these locations as if they were registers. And we take this quite literally. We reserve 32 bytes of them and present them to the entirety of the code generator as if they were architectural registers. And we maintained this illusion until very, very late in code generation, like near the time when assembly is being assembled. At that point they can be lowered to symbols and actually placed somewhere by the linker. And this allows us to have a really normal calling convention.
00:08:45.166 - 00:09:23.870, Speaker A: We basically just ripped off RISC five and were able to have values flow in and out of functions more or less like you'd expect. And we were able to take advantage of everything that LVM offers for doing so. Putting that all together, we made a reasonably good target for this platform, and it's getting continuously better. We'd like to upstream it eventually, but there's a couple of big elephants in the room. We have a really big diff from upstream. Outside of our target, it's like 20,000 lines, but mostly it's just test divergence, little tweaks here and there to upstream code gen passes. We need to decrease that diff and get the project down to its core.
00:09:23.870 - 00:09:45.190, Speaker A: In the long term, we'd like to finish the experiment and get to actual human level performance and evaluate the cost and value of moving LLVM in that direction, but I've. I've left out a huge amount of information. We have tons of documentation. You can also contact us, and if you have any questions, I'm an open book. So thank you very much for listening.

00:00:07.050 - 00:00:45.558, Speaker A: Hi, I'm Jack McCray. I'm from xmos and I'm going to be talking about how we allocate task stacks on the x core. The X Core is a risk microprocessor designed by xmos. It's been supported by LLVM since 2008, but you might not have noticed it since it's not had a significant code update in about ten years. One of the reasons is that our currently shipping toolchain is maintained out of tree, and one of the reasons for that is our implementation of stack site calculation. If you're wondering why that's an important feature to us, a major feature of the X Core is that it has several logical calls which share an address space, and they're pretty quick to launch. This example launches hello world in a child thread.
00:00:45.558 - 00:01:25.270, Speaker A: I would explain exactly what's going on, but it takes about ten cycles to dispatch a puts call in another core. We can run code on up to five of these cores before we see any resource contention. Slowing down subsequent threads and ram access always takes a single cycle. So put simply, a single thread can only use 20% of the processor, and not threading is just wasting time. However, we don't have a page to MMU or hardware memory protection, and we see lots of audio and AI applications which want as much memory as they can get. This creates a situation where we can't over provision or thin provision our task stacks. But we also can't detect an under provision, so we have to get stack sizes exactly right.
00:01:25.270 - 00:02:21.946, Speaker A: And since parallelizing even small jobs is often profitable, we see lots of short lived threads, and managing their stacks by hand becomes a burden for users. To ease the pain of managing stacks, we use some special symbols to annotate functions for their stack requirements. Linker then consumes these and allocates stacks statically, so the runtime overhead is close to zero. Simply, each function defines a related end stack word symbol with an expression which evaluates to its stack requirement in words. A function stack requirement includes that of any child threads it launches and any functions it calls, and we expect child threads to join before the calling function returns. So that we can take child threads stack from the end of the parent stack, which we can do really quickly. We allow simple expressions on integer literals, so a function which doesn't call any further functions has a stack requirement of just its local fringe size, and we allow other symbols so requirements of called functions can be referenced by name.
00:02:21.946 - 00:03:02.354, Speaker A: There's also a max operator which evaluates to the greater of its operands. This is useful for finding the hungriest of a function's call. Ease and simple addition and multiplication are enough to express requirements for child threads, since they launch and join within the lifetime of the function call. We allow some other expressions which are used less, but these are enough to express requirements for any c functions. Clearly, writing this out by hand would be a burden for users, so our back end will emit these symbols automatically wherever it can. But one obvious issue is that this can only handle direct calls, and indeed this approach will fail on even the most basic function pointer use. So to tackle this, we introduced the concept of function pointer groups.
00:03:02.354 - 00:03:51.442, Speaker A: We ship a modified clang which allows a function pointer variable in c to be annotated with a group name, and functions can be added to one or more groups. The annotation is done using attributes which ultimately cause the creation of some additional symbols which are defined using a special max reduce directive. This allows us to define a symbol for each group of functions whose value is the greatest stack size requirement for any of those functions. We can then use the symbol in another function's stack words expression to add enough stack space for the worst case call e for an indirect call sign. Again, our backend, in cooperation with the modified clank can usually do this for us for annotated code. Our current backend implementation of this runs as a preemit pass. It produces stack requirements expressions just before we write out the assembly.
00:03:51.442 - 00:04:50.118, Speaker A: This has the advantage that we know local frame sizes, and we can be pretty confident that subsequent passes aren't going to invalidate the expressions we generate. A feature of the xcore instructions set is that direct calls in C can always generate direct call instructions, which we can expect trivially to get the name of their call e. So again, direct calls are easy, but indirect calls are harder, since getting our function pointer annotations through to this stage is nontrivial, basically because it's so far displaced from our C code, and metadata gets stripped out during instruction selection. Our workaround is one of the reasons we've not attempted to upstream this behavior. So finally, where are we taking this in the future? We already ship this to users in its current form, but we want to get it to an upstream simple state. To do this, we're planning to move most of the calculations so that it happens before instruction selection, and to rework our front end changes to make them less x core specific. Thanks for listening, and if you have any questions or comments, I'd love to hear them.
00:04:50.118 - 00:04:51.410, Speaker A: My email address is in the slides.

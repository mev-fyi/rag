00:00:00.330 - 00:01:02.910, Speaker A: So, hi, my name is Justin Wagner, and today we're going to bring together what I'm sure are two of your favorite topics, fuzz testing and instruction selectors. So, as many of you have heard, we're currently trying to bring up a new instruction selector, which we're calling Global ISO. So if you're not familiar with that, you can learn more from Quentin's talk that proposed it back at the 2015 US meeting. You can get up to speed by watching the talk at the 2016 meeting, and of course, you're always welcome to join us at the BOF tomorrow that Christophe, Renato and Diana are hosting. That said, you can go ahead and forget about Global ISO for now. Today we're going to talk about applying fuzz testing to LVM's instruction selectors and backend. This is obviously motivated by our desire to test and need to gain confidence in global ISO, but the work is equally applicable to today's selection, DaG and fast ISO implementations.
00:01:02.910 - 00:02:24.490, Speaker A: So through the next rest of this 30 minutes or so, we're going to briefly recap fuzz testing and kind of walk you through how we've applied this to generate LVmir and find bugs in our back ends. At the end, there'll be some time for Q and A, so I'm sure some of you are asking, what is fuzz testing anyway? It's not really a new concept, but it's certainly learned some new tricks, and it's been kind of regaining popularity lately. At its simplest, fuzzing is just kind of generating inputs and throwing them at a program and seeing what breaks. Generally, this is either generating random data from scratch or taking a corpus of kind of interesting inputs and running random mutations on them. Interesting inputs could be, say, valid C programs if you were fuzzing something like clang or LVM assembly if you were fuzzing your favorite LVM tool like Opter LLC. So more recently, the idea of guided evolutionary fuzzing has come along, where you actually instrument the program under test so that the fuzzing can kind of detect new internal states and base its evolution process off of that. This makes the fuzzing process a bit more effective and a lot more efficient.
00:02:24.490 - 00:03:17.958, Speaker A: It's also the basis behind AFL fuzz and LVM's own lib fuzzer. So lib fuzzer, of course, has been discussed by Costia, both on the LVM blog and at the LVM dev meetings before. It's come a long way since some of those talks, and Costia has talked about it several times in non LVM context, which I'm sure you can find if you look. So let's work through a little lib fuzzer example here to give you kind of an idea of how fuzzing works. We'll use a simple test function that looks for a particular string kind of one byte at a time. And incidentally, small puzzles like this are exactly how you read a test for lib fuzzer. So I mentioned that these tools instrument the program to guide their random mutation.
00:03:17.958 - 00:03:56.310, Speaker A: Notably, Libfuzzer actually uses coverage counters. It embeds coverage counters for the control flow edges in your program. So it's actually able to get feedback based on whether or not a change hits any new code. So, as you can see, there are a few branches in this function. So we'll kind of show you how the coverage feedback directs fuzzing here. So here on the right side of the slide, I've added a kind of blocks and branches representation of the program. The arrows represent branches, and we'll fill in the blue blocks to kind of represent what a coverage counter trips.
00:03:56.310 - 00:04:37.374, Speaker A: We'll start from an empty corpus here. That is to say, we won't actually give this any inputs to start from, so it'll just generate from nothing. So the first thing that the fuzzer loop does is it goes ahead and chooses an item from your corpus. Since there's nothing here, that obviously means it chooses the empty unit, and we'll run a mutation, right? So let's say we mutate by adding a byte. Say we can add Q here. We're going to stick to ASCII for the purpose of this example, but you can imagine this being kind of any arbitrary byte. So the queue increases our coverage because it hits the entry block, it passes the first condition, and it obviously hits the return block.
00:04:37.374 - 00:05:18.660, Speaker A: So since it increased coverage, we're going to add it to our corpus. We won't immediately change course, though. We're going to continue running mutations on the unit for a little bit in case we can add coverage in multiple ways. So we could get maybe an x, a seven, and a y here. They don't actually increase coverage anymore, so we don't add them to the corpus. Note that if these had come before the queue, we would have added them to corpus because they would have added the same thing. But since by all accounts they're equivalent to the queue for our purposes, so we'd only add the first one.
00:05:18.660 - 00:05:46.646, Speaker A: So now we choose a unit from the corpus again, and we start to loop over. So mutations could add bytes, they could modify them. You could get QZ here, or you could get y. They could also remove them. And eventually we're going to get to a point where we generate an h, which actually increases the coverage. So we throw that into the corpus as well. And so each time we finish with a unit, we're going to loop and randomly select a new unit.
00:05:46.646 - 00:06:02.622, Speaker A: Again, this can be units we've seen before. It doesn't really matter. It's just going to choose one arbitrarily, obviously, for our purposes. For the purpose of the example, the h is the most interesting one there. So we'll continue from there. So now when we find something that starts with h, we increase coverage. We keep going.
00:06:02.622 - 00:06:50.510, Speaker A: We might find this substring here, and eventually we're going to find the string that we're looking for. So this could take a while because we could end up searching in the wrong direction for a while or something like that. But eventually we're going to get there. So you'll notice in this case, the function under test happens to be fully covered. But in practice, that doesn't really happen for real code. Full coverage is fairly unrealistic for reasonably sized programs, especially since you're probably going to be changing the program over time and continuing to run the fuzzer. So in practice, your fuzzer is going to kind of continue to run and find new inputs that increase coverage for essentially ever until you find a place where your test function exits or your program crashes.
00:06:50.510 - 00:06:55.626, Speaker A: So that's lib fuzzer, and it's already embedded in LLVM.
00:06:55.658 - 00:06:55.962, Speaker B: Right?
00:06:56.036 - 00:07:40.462, Speaker A: So what's so special about instruction selection that we really even have anything else to talk about here? So there are already a number of fuzzers in LLVM, including ones for clang and clang format. And the LVM assembler MC has fuzzers for the assembler. And. Oh, and these are all pretty useful, and they do find bugs. But you'll note that there is not an LLC fuzzer, and there's a pretty good reason for that, which should become clear in a moment. Okay, so here's an example of an input that the clang fuzzer might generate. If you squint, it looks a little bit like c, and you can see some kind of keywords and types in there.
00:07:40.462 - 00:09:04.460, Speaker A: But even if this doesn't actually find any problems in clang, you can see it's not going to be generating any code. Even given that we can drive our mutations based on code coverage, there are enough distinct error paths in clang that it's going to be quite a while fuzzing like this before we actually find anything that hits the back end. Similarly, here's an input to lvmas that the as fuzzer found a while back and triggers an assertion. So this has since been fixed, but you can see the same kind of thing here. We're exploring the dark corners of our parsers quite well, but this isn't really an efficient way to find back end bugs, we're just not going to get to the instruction selection in the backend often enough. I should note this example is particularly notable in that if we were to write a naive LLC fuzzer, we'd probably hit this exact same input and find this exact same bug at some point, since obviously the first thing that LLC needs to do is run the assembly parser or the bitcode reader. So we would be finding bugs, but we wouldn't necessarily be gaining that much confidence in the instruction selector, because we just wouldn't be finding that kind of bug often enough.
00:09:04.460 - 00:10:28.990, Speaker A: So instead of mutations on the input byte sequence, what we really want is to mutate the data structures in memory after we've parsed them, so that we can start out with something that's semantically interesting. For instance, if we're working with Lfmir and we change of a load of an I one to an I eight, then we also need to go and change all of the bytes that are related, things like the type of the pointer we're loading from and the types of the uses to match. So conveniently, the lib fuzzer interface provides custom hooks so that you can replace its mutation algorithm and work with whatever you want as an input instead of just a straight byte sequence. So an example of this in action is the Lib protobuffs mutators, or Lib protobuff Mutators project, which provides these lib fuzzer compatible mutator functions for protobuffs, with the idea that if you can deserialize your data structures from protobuffs, you can just use this project to get deeper fuzzing for free. We did actually consider going this route and just writing a protobuff deserializer for L of Mir, but based on our analysis, we weren't entirely convinced that this was going to be an easier task than just writing our mutators directly. It would also make it harder for us to use the vast amounts of llvmir we have lying around as an input corpus. So to implement your own custom mutator.
00:10:28.990 - 00:10:57.774, Speaker A: You simply need to provide this one function, this Llvm fuzzer custom mutator. Now this is basically just a function that takes a data buffer and modifiers it however you want. There are of course a couple of caveats. You're given a maximum size that you need to respect, and you're given this seed value. Now this function needs to be deterministic. Given the same input data and the same seed, you're supposed to perform the same mutation. This means that you can't just grab like a Std random device and run with that.
00:10:57.774 - 00:11:48.974, Speaker A: You need to go and use a pseudorandom number generator. So before we go further, we should briefly discuss the trade offs of where exactly in LVM to inject this custom mutator. So there's two intermediate representations in LVM that are kind of meaningful for trying to feed instruction selection and backend passes. These are Lvmir and machineir or miR. So superficially, using mirror sounds like it would be way better. There are a number of advantages to that, notably in that with Mir you could run individual machine passes directly on it and you could probably test in smaller chunks. However, there are a couple of reasons that we opted to use the lvmir at this point.
00:11:48.974 - 00:12:50.114, Speaker A: So first of all, mirror actually has back references to Lvmir, so you need to fill those out. Now, conceptually, you can actually usually stub those out so that you can kind of have mirror with these stubbed out back references to LVMR. It doesn't matter, but this would limit very much exactly which passes you can run on it, because you need different amounts of IR for different stages in the pipeline. Secondly, the very initial stages of instruction selection are basically working directly on Lvmir anyway. While they're given mirror, the machine function is completely empty at that point, and it's just back references to lvmir. So really, if you wanted to generate mirror, you need to generate both mirror and the relevant lvmir to go with it. The other side effect of going with generating Lvmir is if you have mutators for Lvmir, you could potentially use these for other things, like if you wanted to write fuzzers for optimization passes or something.
00:12:50.114 - 00:13:41.650, Speaker A: So this is a nice thing to have. So I lied a little bit earlier when I told you that we didn't have any fuzzers for backends. There actually is a little bit of prior art there. There's this tool in LLvM called LVM stress, which is basically just a program that generates random, semantically meaningless, but completely valid IR. So this has been around for a while, and it's used pretty often for bringing up new back ends or bringing up a fast ice cell implementation or something like that, and it is pretty effective. But the pattern you usually see with this is people kind of use it at first, and then they kind of forget about it once they've brought up their component. It's not really that useful for continuous testing and running as you make changes to your back ends.
00:13:41.650 - 00:14:41.458, Speaker A: However, this random IR generation logic is a pretty good place for us to start in terms of designing our actual custom mutator. So what do we want in that custom mutator? The LVM stress model basically starts from nothing, and it adds a whole bunch of instructions, and then it injects a bunch of control flow after that. This doesn't quite work for us, because a mutator that's simply appended to existing programs wouldn't really be very interesting for our purposes. This is especially true when you consider starting from an input corpus. If all we did was add to the end of functions in our input corpus, we really wouldn't be using that input corpus to our advantage. That said, it isn't really that bad to just take LVM stresses model and adapt it to injecting stuff into the middle. Since LVmir is an SSA form that's a single static assignment.
00:14:41.458 - 00:15:47.020, Speaker A: We don't really have to worry too much about state, and we can kind of just define our problem in terms of adding operations on SSA values. We can add an operation on an SSA value, replace any uses for stuff that we change, and then we can delete dead code afterwards, and we end up with something new that's also valid. So that's the approach we're using. We define a set of operations in terms of kind of source values to operate on, and a sync value where the result needs to go. For example, an add operation would have two sources, the left and right operands, and then there'd be some use of its result, which would be the sync syncs. We need to make sure our syncs are side effectful, or that they feed into a chain that is side effectful, so that we can run dead code eliminations safely, which makes it so we don't have to track very precisely exactly what we've changed and clean up after ourselves. Okay, so let's work through the algorithm we're using for injecting an instruction here.
00:15:47.020 - 00:16:27.986, Speaker A: We'll just work with a single basic block in the example for simplicity. So the first thing we do is we need to choose an insertion point for our new instruction. This will conveniently divide the instruction list in two for us. So this obviously uses the random engine to choose in practice. But for the purpose of the example we'll just go right in the middle and put this right before b one. So now that we've split the block in two we can consider everything before that point as a potential source and everything after that point as a potential sync. Next we need to choose a source by randomly selecting from the list of sources.
00:16:27.986 - 00:17:04.820, Speaker A: So here we'll say we choose l one. Note that this is before we choose an operation. This is so that we can use the sources type to constrain the possible operations. We could choose. This way we're more likely to use instructions that are already in the function rather than creating a random operation that uses all types that aren't there and having to create new sources and syncs and just getting kind of combined unrelated things. That said, we do sometimes want to create new sources. So what we do is we always consider in the list of sources like there's an extra element and if you choose that element it means create a new arbitrary source to start from.
00:17:04.820 - 00:17:46.706, Speaker A: And that would be maybe a load or global or a constant or whatever. So once we have a source we can choose an operation. So we need to choose one that's compatible with this source. And since l one is an I 16 we could choose something like add I 16 here we could also choose some other integer math or a bitcast or a function call that happens to have an I 16 as its first argument. But we couldn't choose something like fad since the types would be incompatible. So now we need to fill in the rest of the sources for the ad. Obviously there's only one more.
00:17:46.706 - 00:18:42.260, Speaker A: So we choose in the same way as we chose our first source. We choose from the list of sources that are available and the extra source that represents creating a new one. This is obviously constrained though by the type now instead of the first time when it was completely anything. For the purpose of the example, let's say we happen to choose l one here again, which is fine, obviously because the type matches, it's an I 16. So now that we have our operation built we need somewhere for the result to go. So here we don't actually want an instruction so much as an operand of an instruction. So what we do is we kind of go through the list of all of the operands of all of the instructions in the sync list, and we choose one of them again, we throw in an extra element representing create a new source or create a new sync where we'd create a store operation and use that operand or something like that.
00:18:42.260 - 00:19:27.822, Speaker A: For reasons that will probably become clear in a moment, let's say we chose l two, or, yeah, let's say we chose the second operand of the shift here, which happens to be a reference to l two. So if we replace that with b two, you'll notice that l two is no longer used anywhere. So we can go ahead and run dead code elimination on this block and l two will disappear. So there we have a successful mutation, and now we have a new function. So this approach is pretty simple, but it forms a fairly powerful concept. These changes completely change the function over time, but each one individually doesn't change it very much. This means that we're not going to go from one state to another and have completely different coverage.
00:19:27.822 - 00:20:16.866, Speaker A: So this will let the fuzzer engine do its job more effectively. So working with a single basic block is fine, but it's obviously not enough. So we need to introduce new control flow as well. It turns out you can model this basically exactly the same if you think about it as splitting blocks. So if you're given a source with an I one type, what you can do is you can choose conditional branch as one of the operations, and then when you choose that, you just split the block in two and wire up one of the edges to the new block that you created. The other edge conceptually can go kind of anywhere you want to any block in the function, but we avoid a lot of problems by taking a queue from it, the same way that lvm stress does it. And all we do is we always just create a loop back to the block we're in.
00:20:16.866 - 00:21:23.750, Speaker A: This doesn't make the most interesting control flow, but when it happens multiple times, you can at least get nested loops. It's more complicated if you want to branch to other places, because if you skip blocks and things, you need to deal with updating the liveness and all of that. So obviously in the future we probably want to handle that, but for the purposes of instruction selection, you get pretty good results for what you can test just by doing this. If and when people want to fuzz optimization passes and things like that, we'll need to revisit this. So adding interesting code to throw to instruction selection is all well and good, but at some point we don't really want our function to just grow and grow forever. I mentioned earlier, there's a maximum size that you have to respect when you run the mutation, so we need to avoid growing beyond that maximum size. That said, we don't really want to stay too much smaller, because generally speaking, larger IR is probably going to be more interesting for the back end and more likely to find bugs.
00:21:23.750 - 00:22:30.460, Speaker A: So what we do is we make the odds of removing code just start very low and then increase quickly once we get into the ideal size range, until when we're close to the limit is basically just all we do. The actual removal of code is pretty straightforward. If you choose an instruction to delete, you can find a source in the same way we did earlier, constrained by the type to replace all uses of that deleted instruction. And then since deleting the instruction might make the operands dead, you run dead code elimination just like before, and you end up with a slightly smaller function. So that's our strategy for fuzzing. But what kind of bugs do we actually find doing this? There are a couple of types of issues that are easy to hit, like crashes, and we generally run the fuzzers with sanitizers so you can catch memory issues and undefined behavior. Since this is instruction selection, we can also run the machine verifier to check for issues with the generated code.
00:22:30.460 - 00:23:18.326, Speaker A: Beyond this, it would be nice to be able to check for correctness of the generated code in addition to just avoiding crashes and finding that kind of issue. Unfortunately, this is actually pretty difficult. The problem stems from the fact that our input is completely random. So even though it's semantically valid, it doesn't have any particular semantic meaning. So this makes it really hard to tell if the generated code represents the input code correctly. So what are our options here in terms of, in the context of testing global ISL, we could conceivably compare it against selection deck. This is of course kind of tricky though, because the different instruction selectors aren't necessarily going to generate the exact same output.
00:23:18.326 - 00:24:23.150, Speaker A: There can be differences in register allocation and the exact instruction scheduling and things like that. So we have experimented a little bit with writing kind of a diff tool that can paper over this kind of difference, but there's a lot of work to be done there for that to really be fruitful. The other approach to correctness checking is to do something like they've been doing in Glfuzz or graphics fuz as they're calling it now, where basically you just constrain your mutations to be only ones that don't change semantics. So things like adding zeros and multiplying by ones. There are actually quite a few transformations you can do in this way that won't necessarily change the intended result for them. That works quite well, because then they can just do an image diff of the two results and see if they're the same. For us, it's a little harder, and we run into the same problem as before, where comparing the output of two instruction selectors doesn't necessarily work all that easily.
00:24:23.150 - 00:25:51.058, Speaker A: So since there are a few variations of what exactly we want to fuzz, we went ahead and structured the IR mutation parts as a library that can be reused by any fuzzer that wants Lvmir as an input. The design principles behind this library are fairly pragmatic, but I think they've turned out reasonably extensible. Essentially, you can just build your own mutator, and you can specify the types it wants to work with and the IR operations it wants to use. So the main reason the types are configurable is really because global ISIL started out focused on zero, which means things like vectors wouldn't select because it's not implemented yet, so you really find only the bugs you already know about if you're throwing those at that. On the other hand, writing an instruction selection fuzzer that doesn't have vector operations would be kind of silly. So there is a nice advantage of keeping this configurable types design though, which is that you can kind of limit what you generate to things that are relevant to the domain of your problem that you're fuzzing for, whether that means you want to stick to legal types or you want to throw crazy stuff like I back end or whatever. Making IR operations configurable is slightly harder than the types, because in types you can just provide a list of all of the types you care about, whereas IR modifiers are a little bit more elaborate.
00:25:51.058 - 00:26:51.790, Speaker A: So the semantics preserving fuzzer is a good example of where you need this feature, because obviously a lot of your mutations in the ISL fuzzer I was describing before don't preserve semantics. So essentially what we do here is we provide kind of an abstract mutation strategy interface that you can implement. And there's two kind of main styles of thing that you do here. There's the kind of operation injector, which is the algorithm I talked about before, and the operation mutator, which is just something that takes a single instruction and does something to it. The modifier strategy is needed for the deletion. You want to just start from an instruction and do the algorithm on that it would also be useful for semantics preserving transformations, since obviously the grabbing random sources and replacing stuff doesn't work for that. If you want to add one, you kind of have to start from an instruction or add zero, I suppose.
00:26:51.790 - 00:27:42.030, Speaker A: So. We do provide most of the implementations of injectors you'd expect for creating various instructions and calling functions and splitting blocks, and it's easy enough to add your own if you wanted to do something else, like intrinsics. Okay, so that's how we built an instruction selection fuzzer, and now you're probably wondering really how this turned out. So it actually has been pretty reasonably effective in finding some of the AR 64 global ISIL bugs and missing features. It's also shown that selection DAG is surprisingly hard to crash when you give it normal types. It's also usable today. Well, as soon as it's actually committed for testing your own backends, whether that's selection DaG, fast Icel, or if you've already jumped on the global ISL bandwagon.
00:27:42.030 - 00:28:07.590, Speaker A: I've also built up this framework for IR mutators that should be usable if you did want to go ahead and start writing fuzzers for other things that take IR as input. So that's it. Thank you all for your time. And we'll open up the floor for any questions. You have nowhere.
00:28:16.970 - 00:28:29.390, Speaker B: Using iron filter and compare those ones with just jizz version running on wheel or emulator.
00:28:31.570 - 00:28:48.790, Speaker A: That idea has been thrown around for the, without an actual emulator for the IR. Well, I suppose you could do LlI and then an emulator. I haven't tried that. It seems like a good idea though.
00:28:48.820 - 00:29:21.710, Speaker B: It melt injection.
00:29:22.290 - 00:29:30.386, Speaker A: No, that's just like the adding an IR operation I'm calling that is just injecting an IR operation what people also.
00:29:30.408 - 00:29:43.380, Speaker B: Do to make faults that will mess up proposed that could be used.
00:29:45.510 - 00:30:25.090, Speaker A: Yeah, I think the, the model where we're talking about the kind of semantics preserving stuff, that's where that would kind of fit in. So obviously if you do something like the semantics preserving changes, in addition to being something like add zero, could be do an operation that's completely unrelated to your result and just store that somewhere arbitrary. And so that is perfectly something we can test here as well. But it runs into that thing where we haven't quite worked out how to test correctness, because that's very likely not to cause a crash. That kind of changed.
00:30:27.830 - 00:30:34.086, Speaker B: You said that if you split a block and introduce loops, you only use cell loops probably to preserve dominance, right?
00:30:34.188 - 00:30:34.646, Speaker A: Yeah.
00:30:34.748 - 00:30:46.770, Speaker B: So could the user if he has his own dockery and keeps his up to date. Could he change the way you introduce control to.
00:30:46.860 - 00:31:08.080, Speaker A: Sure. Since you're only actually doing one operation at a time, it wouldn't be that hard to change this from, oh, the list of sources is everything before the split block to the list of sources is everything that dominates the location you're changing at. So this idea, I think is actually pretty straightforward to implement. I just haven't tried doing it yet.
00:31:12.050 - 00:31:13.070, Speaker B: Strategy.
00:31:14.710 - 00:31:52.240, Speaker A: Yeah. And so the reason that it's done this way so far is largely that's what lvm stress did so far. So I wanted to reach at least parity of that. And it's just kind of, okay, we can do this later because at least especially for selection, Dag, it's like control flow doesn't really matter for the instruction selector. Yeah, if you did want to use optfasses, that's more interesting. And in global isol it's kind of relevant because we are talking about doing cross block selection. So it's definitely something that we want to, want to get to.
00:32:01.090 - 00:32:02.640, Speaker B: Writing IR office.
00:32:07.570 - 00:32:21.080, Speaker A: Ah, I haven't like, do you mean, I guess you could run arbitrary IR passes and kind of see what happens? That'd be kind of interesting. I hadn't thought of that.
00:32:24.650 - 00:32:25.960, Speaker B: Any other questions?
00:32:50.850 - 00:33:20.826, Speaker A: Sorry. Oh yes, so I haven't, I haven't started using the crossover function yet. It's definitely something I want to do. The exact semantics of how you'd wire up two arbitrary chunks of IR is a little tricky, but I mean, if you were doing it at the basic block level, you could say just wire up the fees differently. And I think that would be kind of fun to do. I haven't tried it yet, though I.
00:33:20.848 - 00:33:34.560, Speaker B: Have made a question myself. I was just wondering if you already have enough experience in a particular area, like you would find.
00:33:39.270 - 00:34:08.420, Speaker A: Well, and I think most of that, at least the experience I've gotten so far is really the. Okay, crashing, just looking for crashes isn't really enough in this context. We don't crash very often even. Well, global ISL does if you throw vectors or I 9000 and ones or something, but you don't find the kind of deeper bugs just by looking for crashes. So we really do need to do this correctness approach to get more out of this.

00:00:03.130 - 00:00:47.900, Speaker A: Hello, everyone. Today, mature and I are going to be presenting XTSL, a tool we've been working on with a lot of other people, for prototyping MLIR in Python. So Matthew and I are PhD students at the University of Edinburgh, supervised by tabias Grosser. And broadly speaking, our research group does three things. The first is actually research into compiler technologies. We really like MLAr and really like doing research on MLIr itself. The second thing we do is open source development with other departments and other universities for their computing needs.
00:00:47.900 - 00:02:03.220, Speaker A: One of the partners that we've been working on recently is the climate modeling project in Edinburgh, which is kind of ironic because it's got the least predictable weather of any place I know of. But so we try to make the predictions run faster, things like that. And we teach a compiling techniques course with about 150 undergrads every year. So ideally, because of all the MLIR research and work that we do, we'd really like to teach them MLIR, right? It's got a ton of great ideas, and we really would like them by the end of the course to know how SSA works, to know about blocks and regions, dialects, rewrites, things like that. But in practice, a lot of the questions that we get are about practical concerns about building an industry compiler. Things like Tablegen, Cmake, C plus plus templates, compilation times are a big problem for undergrads, and that's a problem for us, right, because it's not really what we'd like to teach in the course. What we'd like to teach is the core concepts themselves.
00:02:03.220 - 00:04:12.922, Speaker A: And this problem actually extends to our partners as well, right, because they don't really want to be writing the industry compilers either. They might be doing experiments, and some of these things that make us as compiler engineers productive, get in the way of some of the other things that we do. So how do we solve this problem? We have this crazy idea, why don't we just re implement MLIR in Python? Can we take the same great concepts that we'd like to teach the students and leverage and have it in an environment that's more familiar for undergrads than C, and to the researchers who use quite often python for their experiments? That's kind of a crazy idea, right? Who implements a compiler in Python? But we did it. So it's a kind of a unicorn of a compiler, Scotland's national animal here, and it actually works quite well, right? So here is a small example of something that in MLA could be done in tablegen, but here it's in exactly the same environment as the rest of the compiler, right? It's python with type annotations and some of the concepts that we've developed with AidL as well, things like constraints with some automatic verification kind of built into the API, and it's similarly extensible. You can add your own custom printing and passing syntax, you can add custom verification, nice convenience initializers, things like that. And we found that both undergrad students and our partners find this much easier to get started with than the initial hurdle of learning the same kind of infrastructure in MLIR. Once we have that, we can actually build up MLiR using this Python API.
00:04:12.922 - 00:05:05.850, Speaker A: And we found that quite successful as well for people to get started with who kind of struggle with the typos that they might introduce in the MLIR directly. Here the IDE gives you support. If you've mistyped something, there's autocompletion. It works quite well for our use cases. One of the things that is possible in XDSL, but isn't possible yet in the python bindings is things like rewrites. So once again the users can write a full end to end compiler defining both the operations and the rewrites in the same environment, and be quite productive with that. We also have the full ecosystem of Python tools available for us, right, so here there's a screenshot of a Jupyter notebook running fully in your browser in Webassembly.
00:05:05.850 - 00:06:43.082, Speaker A: So you can just go to a web page and compile the toy tutorial faster than you can git pull the llvm repo. And that also lowers the barrier to entry quite a lot. So for the compiling techniques course, we actually have students implement a full compiler from a small programming language to a RISC V assembly that they can then emulate. So that's a full end to end flow without using MLR at all. But one of the things we definitely didn't want to do is create a rift between these two frameworks, right? So we really want the two communities to work together to make this whole tooling better and actually have these frameworks be used alongside each other. We really see XDSL as a sort of sidekick to mLAr that lets you be productive in prototyping some small features before paying the engineering cost to implement it nicely in efficient C plus plus industrial grade sort of things, especially for things like research ideas where you're trying out a lot of things and you really want to fail fast before committing the full kind of engineering effort. And one of the great features of MLIR is the textual format that lets us be fully interoperable with MLIR at any stage of the compilation.
00:06:43.082 - 00:07:47.460, Speaker A: So the tutorial notebooks, for example, you can take the toy tutorial IR, give it to the MLIR version, and it compiles down perfectly, it's fully interoperable. And similarly, you can have a flow that might go first to MLIR, then do a compiler path in Python, transform the IR, give it back to MLIR, and use all the optimizations that are in that stack basically for free. Right? So one of the examples of that is a project by a student that we've worked with that uses xdsl as almost a front end to get started with, right? So you do some optimizations in the xdsl level, and then compile it down to MIR and get some significant performance improvement over some existing databases. Next, Mathieu will tell you a bit more about how the interoperation might work in practice and into the future.
00:07:48.630 - 00:08:45.278, Speaker B: Thanks a lot, Sasha. So as we mentioned, we kind of have all two frameworks in completely different languages, different paradigms. So how do we actually connect them together? So you might think, yeah, maybe this is this python binding solution, but in our case, we're actually leveraging the textual representation of MLIR in our compiler. So by using the exact same textual representation, we can transfer things back and forth from XDSL and MLiR. So you might already think, oh yeah, I mean, we have kind of a generic syntax, but still we need to understand the dialects themselves. So if we pass the single program that just do two additions in Arif, well, we still need to understand the dialects Arif to kind of have a meaning of these things, to be able to manipulate them, for instance. So for that we're leveraging as well Iidl, which is kind of a meta ir to represent dialects.
00:08:45.278 - 00:09:47.874, Speaker B: So we can share these programs back and forth from MLI and XDSL, which result in actually sharing the dialect definitions themselves. So this allows us, by just sharing the textual syntax and one single dialect, to be able to leverage all the dialects we can have in MLIR, pass it to xdsl, and use them directly. Similarly, we want to do the same thing from XDSL to MLIR, so that people in the MLI, so people that want to kind of prototype their things in python and then use it in MLir once it's done, they can try to kind of port this thing a bit easier than it should. We also want to kind of do the translation from ODS as well. That's something we kind of are working on right now, is going from ODs to ideal and ideal to ODs to allow for kind of a better portability. So you might ask directly why not using the Python bindings again? And I kind of want to give you three reasons why we did not do that. The first one, to be honest, is just it's faster to write it again, it's faster to rewrite your own framework in Python.
00:09:47.874 - 00:10:33.718, Speaker B: Like it took us like the basic starting point was just in a few days, we already had something to represent programs and to do small rewrites on it. And doing this with python bindings is a bit harder because you need to interact with the kind of C plus plus infrastructure you have. So that's kind of one of the reasons. The second reason is more an engineering reason. We're working with people that do not want to have a huge dependency of C. They don't want to depend on MLIR, on LLBM and all of that stuff. I mean, if MLiR was built in Java and then you had a C interface on it, would you have used it in the first place? Or would you think, oh, this is a Java thing? Like we don't really care about this? Well, for a lot of people this is the case, they don't really want to use this entire MLI ecosystem thing because they don't really understand it.
00:10:33.718 - 00:11:59.822, Speaker B: And lastly, the reason is that, as we said, we kind of PhD students, so we like to do research, and one of the area of research we have is actually MLI itself. If you ever thought about oh, what if we add debit types in MLIR? What if we try to reason about immutable data structures in MLIR? Well, all of these things require us to kind of modify MLIR itself. And if you ever looked at the MLI code base and how IR definitions work, well, it's really hard and it's like really a long time to understand what's going on, whereas in our case, in our XDSL framework, we don't really care about optimizing it, we just care about having something simple that we can easily understand so we can reason with it and modify it. So this is why also for us, having a standalone project is nice. So how do we maintain compatibility then, since we don't use Python bindings, we have re implementation of things from MLIR? Well, MLIR is a project that has a lot of commits every single day. How can we just, being a few PhD students, a few research assistants, how can we actually maintain this and keep track with MLIR? So for that I'm using what I like to call kind of the pyramid of needs of the MLIR compatibility. So first you have to base the thing you need to handle, and this is the textual representation and the intermediate representation, the textual format and the intermediate representation.
00:11:59.822 - 00:12:47.330, Speaker B: So this is like all the generic syntax for operations having blocks, regions, SSA, value attribute types, et cetera. And this is something that change really, really rarely. The last big change has been the addition of properties. But before that, over the last two years, I don't remember any major change in that direction. Then, since we want to port dialect from one framework to the other, we need to kind of have the IDa dialect both in XDSL and in MLIR. This, I expect it to change a lot in the next few months because we're actually actively working on it, but I expect it to be stabilized at some point, such that we only have kind of monthly change and not even at that point. So then we want to have those dialect definition that we need to pull from one to the other.
00:12:47.330 - 00:13:29.310, Speaker B: Well, these change a lot. These change weekly, even daily sometimes. Well, for this we leverage the IDL dialect to be able to generate these, meaning that we don't have to pay the weekly cost of updating MLIR if we can do that kind of automatically. And then finally there is the last thing that in our case we don't really care that much is being compatible in terms of API having the same functions, having the same functionality. So for instance, I include in that case the pattern reviter which we re implemented. But then MLIr has a lot of project, a lot of IDs, MLIR actions, we have also the dataflow analysis. In that case we don't really need to have the exact same mechanism.
00:13:29.310 - 00:14:04.362, Speaker B: We may want to. In that case we will port it, but there are so many things that we don't necessarily care about all of them. So even though if they change almost daily, and we have a lot of API changes, in our case it's not really important for us. So this is why kind of maintaining xdsl currently is more in terms a change every month rather than a change every week or a change every day. So if you think of this. So we kind of present this idea in python. I know it's crazy, but some other people might have other languages in mind.
00:14:04.362 - 00:14:58.810, Speaker B: We talked with some people that thought about doing it in C sharp, why not? But then you have some people that have, they need a certain language, because this language allow them to express something they cannot in other languages. For instance, if there's a lot of people thinking of writing front ends for mlir, a front end for writing kind of their programs in a specific way, in like a nice syntax with nice macros, et cetera. Well, this can be allowed. You can do that in a language like racket. Right now people are doing this with front end in python, not necessarily good, but if you choose the right language racket here, it can be done kind of. So if people would write kind of the sidekick ID, like building this new framework in racket, that would be useful for them. Similarly, some people are crazy enough to try to reason about semantics, so why not using a language that allows you to reason about semantics, like lean or cock, for instance.
00:14:58.810 - 00:15:48.858, Speaker B: And then some people are trying to new language like these fire mojo things. The idea you need to keep here is that these should not be separated projects. These should all be connected somehow into kind of a meta framework. We have kind of MLIR connecting with XDSL, connecting with whatever you could implement in other languages through textual, IR and IDL. And please, if you do that, use these tools to allow, to kind of share these abstractions between all these frameworks from this meta framework thing. So we've presented kind of ID in Python, prototyping MLI in Python, and hopefully for some users this will be actually pretty useful, even though for most of us it sounds a bit crazy. And hopefully some people can try other stuff, can try to experiment on it.
00:15:48.858 - 00:15:58.800, Speaker B: And this allows us to essentially prototype MLiR directly in a language more appropriate to prototype in. Thanks a lot.
00:16:06.230 - 00:16:07.890, Speaker C: For Shashimati.
00:16:09.750 - 00:16:23.730, Speaker D: You mentioned IRDL as like a solution to kind of share dialects between these two programs. But I assume that's only about the dialect definitions. And if you want to have things like transformations and optimizations, then currently those are reimplemented on both sides.
00:16:23.890 - 00:16:58.580, Speaker B: So for now, if you want to use a specific optimization in MLIR, you can always translate to MLIR and then get it back. However, there's some people working on PDL on the transform dialect, which are other ways to share transformation using the textual representation or using these intermediate representations. So while for now we're kind of reimplementing things, we can see in a way, if we evolve to more declarative transformations, then we could see them being translated from one framework to another.
00:16:59.270 - 00:17:09.378, Speaker D: So at some point we might have an MLIR dialect specifically for optimization logic. That could be basically the IRDL version for optimization.
00:17:09.474 - 00:17:11.720, Speaker B: Cool. So we have PDL and transform. Yeah.
00:17:13.050 - 00:17:22.540, Speaker C: Anyone else? Great. If there's no one else, then our next talk starts in twelve minutes.
00:17:26.990 - 00:17:40.830, Speaker D: It's kind of ironic you mentioned compile times as a problem of MLIR, and then you're going to use Python to write your compiler. So do you have issues that if you have a Python compiler, that the compile times are bad, or is it just not a problem with prototyping?
00:17:42.690 - 00:17:49.330, Speaker A: Yeah, it's not really been an issue for us so far. Right. It's not slower enough to be a concern.
00:17:56.010 - 00:18:17.660, Speaker E: So thanks for this work. It's super interesting. I have a question. Let's say one of your students invented super thing that we would want in MLIR. How do you envision contributing this back to MLIR? Because then they haven't been actually exposed to the MLIR open source community.
00:18:18.670 - 00:19:06.346, Speaker B: So that's a good question. First of have, when we have dialects, for instance, we hope that we can translate them more easily using IDL, and then translation for IDL to ODS for transformation. That's true. They would need to be kind of rewritten, but in the same time, all transformation in Python are not really meant to be as optimized as you would expect in the MLIR project itself. So in any way there's work to be done to port it, you need to have better data structures, or using a different part of the framework to encode your transformation in kind of a better way. So for now we have a story for kind of the dialects, but for the transformation themselves, maybe with PDL and the transform dialect it could be better, but we don't really have that right now.
00:19:06.448 - 00:19:31.380, Speaker A: I think we also have examples already of people starting to upstream things that were initially prototyped in XDSL. Right? Like IITL is kind of an example like that. Right. And then the immutable data structures is another PhD student in our group who's also similarly planning to. Once they've kind of developed them in Python, upstream them, so everyone can use them in Amaya itself.
00:19:31.750 - 00:19:51.080, Speaker B: And also, there's also thinking right now there's kind of no alternative in Python. There's like a lot of people that like to write compiler in Python, like DSL in the research community, but they're currently writing it in completely different paradigms. So at least bringing it to the same paradigm with the same concept kind of make it easier for them.
00:19:54.170 - 00:20:03.260, Speaker C: Anyone else? Great. So if there's no one else. Thanks Yash and Matthew, you and our next talk starts in ten minutes. Thanks.

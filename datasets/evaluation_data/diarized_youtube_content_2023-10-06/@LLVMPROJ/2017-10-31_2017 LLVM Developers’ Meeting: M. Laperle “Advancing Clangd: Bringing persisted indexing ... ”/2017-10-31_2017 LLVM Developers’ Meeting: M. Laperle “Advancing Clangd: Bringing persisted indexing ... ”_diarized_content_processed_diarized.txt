00:00:04.990 - 00:00:42.800, Speaker A: Good afternoon everyone. I'm very happy to be here today to talk to you about clangd. So today we're going to talk a bit about clangd in general. So what's new since the last developer meeting? So it's going to be a bit of an update. Also, what is clangd? In case you don't know clangd. And then we're going to go a bit deeper into the proposed indexing infrastructure and then you'll see it's like solving a similar problem that the index wall building solution presented before is solving. So there's definitely some things we'll have to put in common.
00:00:42.800 - 00:01:43.590, Speaker A: And yeah, we're going to talk about the current state, all the features that are supported and being worked on, and we'll talk about future challenges and possible collaborations. So about me I'm Makali Labelle, I work at Ericsson. I've been working there for a few years. I was working a lot in the eclipse community before, specifically in CDT, which is the CNC support, and now I'm kind of a new ish client contributor since the beginning of this year and I'm pretty enthusiastic about CNC tooling and ides et cetera. But I'm not a compiler expert, but maybe soon. So what is clangd? In case you don't know what it is, it's a tool in the clang extras repo. Its goal is to implement the language server protocol, often called the LSP, specifically for CNC.
00:01:43.590 - 00:02:38.558, Speaker A: So this protocol goal is to implement all the language smartness features in ides, so things like code completion, fine references and open definition. So it puts it into a protocol in JSON RPC. So any client can talk to any language server to support many different languages. So it's a good way to kind of mix and match languages and clients. So we regularly test client with visual studio code because this is where the language server protocol was born. So there's a good client library there to test things. I also test regularly with CIA, which is an id we are working on at Ericsson with other companies and also with Eclipse.
00:02:38.558 - 00:03:49.978, Speaker A: And I'm hoping that more we can add more like Vim and Emacs because they're also very popular even inside Ericsson. So this just to illustrate a little bit how it works when you use an editor and a language server. So on one side you have the tool, so you can have vs code or eclipse, something like that, and then on the other side you have your language server and in this case here it's clang d so whenever a user opens a document, then a message is sent from the tool to the server to notify that a document has been open. So then at that point the server can start parsing the file, maybe loading some caches so that it's ready to process other requests from the user, like code completion for example. Then whenever the user edits the file, then another message is sent from the clients to the server. And then there again the server can update repars or dated caches. And from the server to the client it can send messages as well.
00:03:49.978 - 00:04:40.422, Speaker A: So it can send diagnostics, which is basically errors and warnings. So you can get errors and warnings as you type for a very quick feedback. So the big value of this protocol is that everyone kind of agrees on this protocol. So you can really mix and match languages and editors. I have a click. So the current status of clangd so here in this table you have the features and there's a column to say whether or not it's supported in the protocol, whether or not it's specified in the protocol, and whether or not it's implemented in client D. So you have a lot of very useful things already, like formatting code completion diagnostics.
00:04:40.422 - 00:05:40.838, Speaker A: So it's already very useful to assist you programming. And then when you compile you're pretty sure everything will compile because you already have diagnostics from client. We have some go to definition support, but it's actually going to the declaration because we don't have index upstream yet, and we'll talk a bit more about that later. And we have things that are very close to being done, like source hover and document highlights. And you see in this table there are a few of them that are not possible right now because we don't have the index upstream yet. And then there's quite a bit of features that are not specified in the protocol that we would like to see in clang D. And it's not 100% clear if this should be specified in a protocol because the language server protocol is meant to be kind of language agnostic and kind of a lightweight protocol.
00:05:40.838 - 00:06:43.840, Speaker A: So those are things that we will try to propose in the protocol. But for sure we want inclined either as an extension to the protocol. And it's pretty easy to extend the protocol because it's just some JSON RPC messages, so you can just add some and as long as the clients and the server agrees on it, then it works great. So what's new? Since the last developer meeting there was a lot of improvement in code completion so it gives much better results, much more detailed information about all the completion items. You have code snippet support, and it's also much faster, so you can do code completion really more quickly. Even like reparsing the file and getting code completion is much faster. You can go to declaration, so that was done quickly after the developer meeting last time.
00:06:43.840 - 00:07:13.818, Speaker A: You can do a signature help. So as you are typing parameters for your function call, you will get a little pop up that will tell you what the parameter types are, et cetera. So that's very useful. And there's a very small extension that allows you to switch between the source file and the header. And you might be wondering, why did we put this in clang d? It's so simple because it's just based on the file name. So right now it's based on the file name. So if you have foo h, it will switch to foo c.
00:07:13.818 - 00:08:12.762, Speaker A: But later when we have the index, even if your files are not named the same, we will use the index to figure out where the definitions are for a given declaration so we can find the corresponding source file. And as well there are now more command line options, so you can set the client resource directory, for example. And you can also now set the path to the compilation database. The compilation database if you don't know what it is, it's a JSON file that contains all the compiler arguments that were used to compile your program for all source files. So client can use that file to figure out which includes and which macros to use when parsing the files. So it's important to be able to find this file so that client can parse files properly. There's also been a lot of performance improvements, so now there are multiple thread workers, so you can open multiple files at the same time.
00:08:12.762 - 00:08:49.270, Speaker A: It will parse at the same time, so it's much better. There's a better preamble management. So as I was saying, this is important if you want to get quick results for code completion, and anytime you modify the file, you don't necessarily want to reparse all the included headers. So if you can cache that, then it's much faster. And there was a lot of bug fixes and rearchitecturing and cleanup. So it's all very good and promising, and the community is really growing fast. There's maybe four or five people that are very regularly working on it.
00:08:49.270 - 00:09:29.762, Speaker A: It doesn't sound like a huge number, but it's actually not that much code client, so it's actually very good. And there's also more people that are more occasional contributors. So I think it's a very good number and it's progressing pretty well. So indexing. So in case you don't know why we want to do this. So for example here, if you have a main CPP file that includes Foo H header with a declaration to foo, and then you have a call to Foo. So if you open that main CPP file in an editor and client parses it, it can very easily find where that Foo was declared.
00:09:29.762 - 00:10:15.330, Speaker A: So that's not a problem. But when you want to actually find where Foo was defined, which is very often what the programmers want to do, then you somehow need to know about Foo CPP and the location of Foo. So one way you could do it is when the user wants to find a declaration of Foo, then reports all the source files and then find it. But this is way too slow. You need some sort of database of where all the symbols are defined. So this is why we need indexing. So we've started working on a language server even before Clang D was kind of proposed recently.
00:10:15.330 - 00:11:06.230, Speaker A: So the first prototype was actually just a very small project in a git repository. It was really at the stage of experimenting with code completion in Klein using the ast visitors and then parsing the JSON. So that was very bare bone. And at Ericsson and my team were very new at using clang, so that was a good way to get up to speed with what we could do. And then on a mailing list it was communicated that people wanted to work on clang D and support the LSP in the clang repository. So that was the perfect opportunity for us to join forces and work on that. So we migrated kind of our prototype code to the client code base.
00:11:06.230 - 00:12:01.830, Speaker A: But we started off in a branch because we wanted to start this bigger feature of indexing. So at that point, client was using LLVM's Yaml parser for JSON instead of the one we were using in our prototype, which was a lib JSON CBP. And the JSON RPC was kind of a handwritten, but it's not a very big part, so that's not a big problem. And when we migrated to clangd, then we already had the open declaration feature working because as I said, it's very easy because clang already knows where it is with the includes. So that was a pretty easy feature to do. And at that point we were not reusing any of the clang index component code. So we were really kind of manually visiting the AST so that was not the best solution.
00:12:01.830 - 00:12:59.866, Speaker A: So a bit later. So yeah, those prototypes have numbers, but it's not really how it went, but just a way to think about them. So we wanted to introduce the notion of persistence, so really having a database so we can actually find the definition of the function. We were still using the AST visitor to find where the user was pointing at to figure out what you wanted to jump to, which is still not the perfect solution. But we started using some client index code, a class called index data consumer that can be used to feed the index. So that's super handy because it figures out it walks the ast for you and then there's a callback to handle the symbol occurrence. So you can just store that in the index and then carry on.
00:12:59.866 - 00:13:39.830, Speaker A: So at first we didn't really have a file format for that. Just to get things started, we came up with this very awesome, simple, very slow index file format. So it's SVSI file format, it's really just a linear amount of things. So I'll show you a bit the layout after, if you're curious. At that point there was no definition and headers handled because you kind of have to track to make sure you don't duplicate them. So at that point we just decide to deal with function in source files. So the format of the SVSI file is very simple.
00:13:39.830 - 00:14:28.274, Speaker A: It was just dumping the number of files and then the name of the file, and then the number of symbols and the name of the symbol, and then so on, more symbols, more files. So it's very slow. If you need the symbol at the end of the file, then you need to read the whole file. If you change any of the files, you have to rebuild the whole file. So that was terrible, but everything, we could connect all the dots and kind of have a working prototype. So the first thing we want to improve after that is making a better format, a better way to save data. So then we figured out that we could reuse the same code to actually find where the user was pointing with the cursor as the code we were using to feed the index.
00:14:28.274 - 00:15:01.962, Speaker A: So there was a lot of more code reused. So that was good. And at this point we actually upstream that cleaned up code to have an open declaration already in client d. And then we started to replace the file format with a new class called index data storage. And this was very much inspired from Eclipse CDT's database. And I'll explain a little bit how this works later, but it's basically a myloc like interface to writing and reading to a file. So it's very flexible.
00:15:01.962 - 00:15:58.942, Speaker A: We also introduce a b tree so we can find things in logarithmic time, so we can find file entries or symbols much much faster. And so at this point we were not dealing really with definition headers, just going step by step. And we started handling events for source file changes but not headers. We started tracking dependencies of files. So for a given header we tracked which files actually included this header with this information. This allowed us to figure out when a user opens a header in the editor. We actually didn't know which compile arguments were used in the context of this header because the compilation database, the JSON file I mentioned before, only has entries for source files.
00:15:58.942 - 00:16:48.750, Speaker A: So with this dependency information we could actually figure out which source file includes this header and then find an entry in the compilation database. So now we were able to open header file properly in editors and then get proper diagnostic and completion. So it was already a good improvement. So how does the index data storage work? So it's quite different from the index while building solution. So yeah, it's a malloc like interface to writing to a file. It can store just bytes and there's also some helpers to store integers, strings and more importantly you can store pointers so you can do very complex structures and persist it to disk. So you can do like link list or any kind of weird data structure you would do normally in memory.
00:16:48.750 - 00:17:42.622, Speaker A: And it was very inspired from eclipse city to database because we worked a lot with this before. So we tried to reuse a similar strategy, but it doesn't mean that it has to be the ultimate solution for this problem. What does it look like in terms of layout? You just have a simple py version in case the format changes so can rebuild it. Then you have a table of link lists to free blocks of a given size. So when the user allocates data in the file it creates a data block and then when the data block is freed it's converted to a free block. That free block, depending on the size, is then inserted into a list of free blocks for later. So whenever you do a new malloc and you need a free block to allocate memory, then it looks in the list of free blocks for available blocks to reuse.
00:17:42.622 - 00:18:46.162, Speaker A: So it's a pretty simple layout, but it's pretty flexible. So you can really store any kind of data, really any kind of bytes you want. So it differs a little bit from the index while building in that you have one file that contains all the information. So it's not multiple files that then you query, it's just one file that has many pointers inside it, so it's a bit different. There's a caching mechanism, so you can also think of this file as 4k pieces. So whenever you want some data in the database, depending on the offset, it will figure out what the piece id it needs and then it will fetch that piece and put it on the cache. And the size of the cache is configurable, so we can make sure that client d doesn't use a huge amount of memory.
00:18:46.162 - 00:19:40.854, Speaker A: We can configure that cache to any size we want. And then the b tree is a pretty classic b tree. It's a tree with nodes that contain multiple children, and it's a balanced tree and you can do logarithmic insertion, search and deletion. Deletion is a bit more complicated, but it works, so that helped a lot, making the index faster compared to the super very slow index file. And the keys in the b tree are actually pointers inside the data storage. And the nodes themselves are just data inside all the same file. So the tree itself is very lightweight, it just points to other objects in the database which are themselves much bigger.
00:19:40.854 - 00:20:38.860, Speaker A: So here in the previous slide I had puts like ABCDef, you can think of them as file names, for example. And here we're pointing to actually to actual file entries in the database which can contain more data like the occurrences, et cetera, et cetera. So we can use that to quickly find a file in our database and then get its occurrences. So now that we have a better persistent mechanism, we wanted to add some of the missing things that I've mentioned before. So for example, we were not really tracking when header files changed and things like that. So for that we started adding timestamps to know what was the time at which we indexed the files. So we know that when client restarts we need to reindex them or not.
00:20:38.860 - 00:21:37.786, Speaker A: And then whenever a header changes, now we do use the dependency graph to reindex all the source files that are dependent on the header. And now not just definitions are stored in the index declarations and references as well. And also everything in the headers are also included in the index. Although the headers are only indexed once, so the first time it's encountered it's parsed and its symbols and occurrences are stored once. So that's something that could be improved. And the index model was changed to be a bit closer to the index while building proposal, so that we're slowly converging towards something similar. So at this point we have the open definition and fine references working, but I tried to cram so much new things for the conference that I haven't had the time to fix all the stability bugs.
00:21:37.786 - 00:22:12.966, Speaker A: So it actually crashes sometimes when indexing clang d. So eventually I will fix this. Okay, what does the model look like? So this is all in one file. So you would start at the lower left. So you have the client index interface. So this contains access to a b tree of files and a b tree of symbols. So if you're interested in finding the definition of a symbol, then you use the USR, which is the unified symbol resolution.
00:22:12.966 - 00:23:22.718, Speaker A: So it's kind of the, as it was explained before, it's kind of a unique identifier in the index to find symbol and be able to do navigation across units. So you use the USR to find the symbol you're interested in in the database, and then you can go through the occurrences of the symbol because the client index symbols contains a linked list of all its occurrences. So as you go through the link list of occurrences, you search for the occurrence that has a role, that's definition. So this sounds like a lot of work in computation, but it's actually very fast because things are cached in 4k pieces and it's actually just in one file. So it's quite good. And then the b tree of files, if you go back to the lower left, you use it. If a file changes, then you find the file entry in the b tree, and then you get all the occurrences in the file and then you delete them because the user might have offset all the occurrences in the file.
00:23:22.718 - 00:24:19.554, Speaker A: So you kind of have to rebuild all those occurrences. And then if it happens that you're deleting an occurrence for a symbol that has no occurrences anymore, then we delete the symbol. It's kind of a reference counting mechanism at the same time so everything gets cleared and the memory is freed in the database. So I'm going to do a quick demo. I just want to show you the integration in the ides. Can you see? No, sorry. This is better.
00:24:19.554 - 00:25:11.700, Speaker A: Okay, so this is the thea ide and you can see I opened it in my browser, so it looks just like a normal ide, except the backend could be running, I don't know. In Australia here I have the clangd indexing code, and now because of the index, I can find all the references to vector. You can see it's very fast. I have 384 references to SCD vector. And of course this is not an index of all LLVM codebase. I just picked the client codebase and all of its headers, but it's still quite a bit of headers and definitions and it's pretty fast. You can find all the STD vectors very quickly then.
00:25:11.700 - 00:26:19.272, Speaker A: Sorry. Okay, so now here I have a method called to put raw record pointer. It doesn't matter what it does, but now I can control click on it and actually jump to definition of this symbol instead of jumping to the declaration. So that was not possible before without the index. So it's a good improvement. So this was in TIA, but because clangd uses the language server protocol, any IDe that supports this protocol, it's very easy to integrate clangd and get similar results. So here in vs code I can do final references and I get the same results.
00:26:19.272 - 00:27:06.908, Speaker A: And the amount of code in vs code is really very tiny. It just says whenever I open a split plus file, start clang d. So it's almost nothing. Same thing in eclipse. I can find all references here and it works the same except this weird to do label, but that's not my code. Yeah, so that's just a quick demo to give you an idea of how nice it is to be able to plug this in any ide. So some of the challenges we have we have worked more on modeling the index and making it persistent on disk, and not so much on the actual indexing time.
00:27:06.908 - 00:28:00.184, Speaker A: But for sure the lack of header caching is going to be a major issue. So every time we parse a source file, if it includes string h many many times in the code base, and we'll reparse it again and again and again. So there are possible solutions for this. We haven't looked so much into it yet, but it should be possible to use maybe pre compile headers or pre tokenized headers, or maybe the modules inclined. So there are several ways we could try to fix this. One problem is that a given include can be when you include the header, it can be in a very different context. So we have to make sure that it's still valid to use the cache information even though it's in a different context.
00:28:00.184 - 00:29:01.116, Speaker A: So we might need some heuristic to, even if it's not exactly the same context, so different macros are defined. And maybe we'll have to be like okay, maybe we'll let it pass and it will be not quite as accurate, but it will be faster at least. So there's some ways maybe we can try to introduce some heuristics maybe also we could make the indexing in multiple phases. So maybe index all the top level functions and not index the bodies of the function and then do a second pass to get all the references in the body of functions, things like that. So at least the user could get some functionality and then while the longer indexing finishes and when it's fully finished then all the functionality would be there. Other challenges, we have to watch for all the possible file events. So on Linux you would use maybe inotify to know if a file changed and if you need to re index.
00:29:01.116 - 00:30:13.400, Speaker A: But if you have a really large source base like even llvm, then you're gonna go above the maximum that inotify allows you to go. So right now we rely on the client to send client the file events. But the problem is that we need to be able to go beyond this maximum and we also need to watch for changes for system includes. So it's not so much I think the responsibility of the client, but the server will start to have, a client will have to start having to watch all the files itself and maybe will have to spawn multiple processes to work around the problem with the large number of files. So that's kind of an open question. There's a lot of opportunities for collaboration. So as you saw just before this presentation, the index, while building feature in xcode nine, I think most likely could be reused and maybe even replace entirely the index storage that we're using in clangd.
00:30:13.400 - 00:31:27.776, Speaker A: And I think it would be good if we put some background indexing code in clangd that maybe we can move it from clangd to the more common clang indexing code instead of just clang d so others could use it. So other interfaces then clang D could use it. One thing we'd like to support is also making the index extensible so that other tools for static analysis could add information to each symbol or each occurrences so that they can use the same format without having to have their own. We also experimented with LMDB for doing the symbol mapping similar to what Xcode is doing. And there's an open question about whether or not it will be possible to integrate that library, that external library into the client code base. So refactoring, we're really interested in refactoring. One challenge will be if we want to put it in the protocol, we have to somehow specify it well enough that it can support other languages and enough options, but not too many.
00:31:27.776 - 00:32:16.750, Speaker A: So that's just the protocol itself is a challenge and also making use of the refactoring framework introduced with XCO nine. I think it's really good opportunity and we really want to add more refactorings and code generations. So that's a very good opportunity for collaborating with people working on Xcode. And the quick assist support was kind of a feature in eclipse that even when you don't have errors you can do control one and then start modifying some code. So maybe inverting conditions and things like that. So it's a bit related to refactoring and we want to work on this as well. So I put some references in case you're interested in the client d itself or the protocol or the, the ide that we've been working on.
00:32:16.750 - 00:32:21.730, Speaker A: There's sometimes for questions. Thank you.
00:32:26.500 - 00:32:29.860, Speaker B: Hi, two questions. Do you work on Windows?
00:32:31.560 - 00:32:36.230, Speaker A: Depends on the day. Linux, Mac and sometimes windows. Why?
00:32:38.360 - 00:32:39.984, Speaker B: I mean like clunkd.
00:32:40.032 - 00:32:49.348, Speaker A: Does it work on clang? Oh, does it work on Windows? That's the question. Sorry, I haven't tested recently, but that's definitely the goal to make it work on Windows.
00:32:49.524 - 00:33:11.650, Speaker B: I see. And the second question is how well do you do with templates? I mean if I got a template type and I call some methods on instances which are not immediately obvious what the type is, will you be able to find all the symbols that I actually mean?
00:33:12.420 - 00:33:41.210, Speaker A: So far I haven't seen problems in this situation, but I suppose it could be some weird cases. And we're relying on the decline index component code to get the occurrences and so far it's been looking pretty good. But of course we could do more testing on that front to find some more edge cases. Hello.
00:33:41.580 - 00:34:00.128, Speaker C: So I was just curious in terms of your persistence layer. The kind of first thought that came to me was using something like rocksDB or something in the kind of level dB family instead of building a persistence layer from scratch. What were your thoughts about that?
00:34:00.214 - 00:34:01.356, Speaker A: Which kind of DB?
00:34:01.468 - 00:34:04.720, Speaker C: Like rocksDB or level dB? Something in that family.
00:34:04.870 - 00:34:05.644, Speaker A: Berkeley DB.
00:34:05.692 - 00:34:09.468, Speaker C: There's all these kind of different persistent key value stores that people have built and optimized.
00:34:09.564 - 00:34:22.328, Speaker A: I don't know those specifically, but LMDb I think would be a good candidate to replace what we had in the prototype. So definitely we're open to reusing instead of having our own stuff.
00:34:22.414 - 00:34:23.524, Speaker C: You can chat offline.
00:34:23.652 - 00:34:40.950, Speaker A: Yeah, I'm not afraid to dump, subcode and reuse and stuff. Okay, any more questions? Then? Thanks again. You too close.

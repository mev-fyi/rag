00:00:01.050 - 00:00:40.780, Speaker A: Good afternoon and thank you for coming for the last session. For today, the session will be about fuzzing. In particular, I will talk about fuzzing clang and LVM itself using a library called libruff Mutator. And this is a joint work between myself and two more guys in my team, Vitaly and Matt, who are present in this audience. So I will talk about fuzzing in general. I will talk about fuzzing components of clang and LVM, and I will concentrate on fuzzing them better. Let's go.
00:00:40.780 - 00:01:35.510, Speaker A: First of all, let's remember what fuzzing is. If you test your application or your API, you typically send a fixed number of fixed inputs into your API and then observe the behavior when you fuz the same API. The process is that you generate random inputs, or semi random inputs for your API and feed them into your API in an infinite loop. There are lots of different types of fuzzing tools. We call them fuzzing engines. My talk mostly is about coverage guided fuzzing tools, and specifically about leapfuzzer. There are also tools like AFL, which is also coverage guided fuzzer.
00:01:35.510 - 00:02:19.690, Speaker A: And there are lots of other tools that are not coverage guided fuzzers. One of them is well known in LVM community. It's called csmith. Well, Klee is also well known in LVM community, I believe. So what is coverage guided fuzzing? Suppose you have an API that consumes some data, and suppose you already have a test corpus for this API. Then in an infinite loop you pick a random input from your corpus and apply random mutation to it, and then feed this mutation to your API. While doing this, you observe the code coverage.
00:02:19.690 - 00:02:49.474, Speaker A: If you see any new code coverage, you say, okay, this input is interesting. Let's put it back to the initial corpus. That's it. That's all about coverage guided fuzzing. And there is a library for doing coverage guided fuzzing in LVM. The library is called Leapfazer, and this slide shows how to use it on a very simple case. So we have an API in this case.
00:02:49.474 - 00:04:04.914, Speaker A: It's a single tiny function called fuzzme, which consumes data. And who can spot the bug, by the way, who can spot the bug in the function has me. You don't count who else? Out of range? Okay, I've heard out of range. Yes, this element may will cause buffer overflow, and it's very hard to find this kind of bug with testing, but very easy to find this kind of bug with fuzzing all you need to do to fuzz this code with lip fuzzer, you need to compile it with a special switch. Fsanitize fuzzer and if you want to find buffer overflows, also f sanitize address and then run it. We already have a bunch of what I call simple fuzzers in our LLVM tree that includes clank format, clank fuzzer, dwarf dump, two different demandlers and so on. But having the fuzzers in the tree is not enough, right? You may have tests, but unless you run the tests, you'll not find the bugs.
00:04:04.914 - 00:04:50.700, Speaker A: Same with fuzzers, you need to run them somehow. Luckily there is a service called OSS Fuzz, and I'm one of those who built this service. The service is a continuous automated fuzzing for open source software. And if you're interested in more details, here is the GitHub link. And there is a link for my talk at using security earlier this year. But in short, this is a black box for you where you put fuzzers and get bug reports out. Of course, LVM is already integrated with this service, so we get some interesting things out of it.
00:04:50.700 - 00:05:48.074, Speaker A: The demandler is probably the simplest fuzzing target there is, because what demandler is demandler is a single function that consumes data and produces buffer overflows. Excuse me, it produces something else, but sometimes buffer overflows as well. So we have couple of demandler fuzzers from LVM in OSS Fuzz, and this is an incomplete list of bugs that were found. Most of them are fixed. This is a fuzzer for clank format, and we have just a tiny bit of bugs reported here. But unfortunately that's not because clank format is almost bug free. On the contrary, it's so buggy that the bugs pop up in the first seconds of fuzzing, and the continuous fuzzing doesn't give anything else.
00:05:48.074 - 00:06:13.730, Speaker A: So unless we fix those, we will not know about more interesting bugs. Also, I have dwarf dump fuzzer, quite a few bugs. Some of them are fixed now, some of them are not. And the most interesting we have clunk fuzzer. It's the most sophisticated code. It doesn't actually fit on the slide in reasonable font size. And we have quite a few bugs found, and some of them are fixed.
00:06:13.730 - 00:07:34.190, Speaker A: So how do we find bugs in those four fuzz targets in LVM that I mentioned so far? Lip fuzzer takes an input from the corpus and flips a random bit more or less that it does a few other tricks like inserting magic values or removing byte sequences. But the essential part of the fuzzing is bit flipping. And what do you think? How much c plus plus code will you get by bit flipping some other c plus plus code? Not really much. This is what we get when we fuzz clang in a regular bit flipping way. So if you pass this four byte sequence to clang, it will think it's a C Plus plus, but we'll have a hiba fro flow in Alexa. If you put this byte sequence, it will also do something nasty like use after free also in a lexer and note these four bytes. Cass it thinks that this is a misspelled class, so it invokes a whole bunch of logic for reporting misspelled keywords and then fails spectacularly.
00:07:34.190 - 00:08:26.858, Speaker A: You can also put some total garbage here and get an infinite cpu and ram consumption. Are these bugs interesting? I would say they are somewhat interesting, but they do not ever touch the optimizer and the code generator. They stress the lexer mostly, and sometimes the parser. My biggest trouble with these bugs is that nobody is fixing them, but they're also not the most interesting ones. So what about fuzzing deeper layers of LVM? And this is not just about LVM or clank. This is a general problem of fuzzing APIs that consume highly structured data. Suppose you have an input that is a valid input for that API.
00:08:26.858 - 00:09:37.670, Speaker A: You flip a bit. This input doesn't parse anymore, and so you only stress the parser. You don't go anywhere deep inside the application. So a couple of years ago, we started doing what we now call structure aware mutations, which is a specialized solution for every given input type. How it works we suppose that we already have a corpus of inputs that parse that are valid according to the syntax of the input language, and then we parse a random input and we apply a local mutation to that input in memory such that the object remains valid in terms of the syntax. And then we feed this mutation into the API. Lipfuzzer has two functions that allow you to implement structure aware mutations for your data structure.
00:09:37.670 - 00:10:35.910, Speaker A: One function is actually not the function that Libfuzzer provides, it's the function that Libfuzzer wants you to provide. The function is called fuzzer custom mutator. It consumes data, and you have to mutate this data in place according to the rules of your input language. The second function, this time is provided by Libfuzzer, is the function that will mutate raw data that you provided. So if you want to parse your data structure, identify a leaf data member, and then mutate it as raw data, you can do it using lip fuzzer provided mutations. If you have seen or watched on YouTube a talk by Justin Bogner from half a year ago called adventures in fuzzing instruction selection. Justin has done exactly that with Llvmir.
00:10:35.910 - 00:11:22.550, Speaker A: He implemented a custom mutator that takes bytes, parses them as llvmir. If they don't parse, the data is rejected. If they do parse, we get an lvmir object in memory, and then the mutator actually changes the IR a little bit and returns it back. And then the fuzzer feeds it to the LVM pass that we are fuzzing. Look at these beauties on this slide. These are two bugs that we detected a few days ago on OSS fuzz by fuzzing. By running this LVM ice cell fuzzer.
00:11:22.550 - 00:12:06.178, Speaker A: These are valid lvmirs, both of them. They parse the optimizations, try to work on them, and then something goes wrong. In one case we have an assertion, in one case we have internal compiler error. Note that these two pieces of Lvmir were synthesized from scratch. Like Fuzzer didn't know anything about anything, it just started working and synthesized those two fine pieces of code. But I'm going to talk about something else now. We at Google have a big hammer.
00:12:06.178 - 00:13:05.202, Speaker A: It is called protocol buffers, and every time we see a nail, we were trying to apply this hammer to that nail. Sometimes that is not a nail. So the rest of my talk about using a hammer to something that is not a nail looks similar. Though for those of you who don't know what protocol buffers are, it is a mechanism for serializing structured data. This is more or less all you need to know. And the tiny example on this slide shows a data structure defined as a protocol buffer message. The data structure has two fields, a string and an integer, and the second box shows an object of this type as it is serialized on disk in a text format.
00:13:05.202 - 00:14:34.878, Speaker A: Protocol buffers also have a binary, highly compressed format as well. Given the proto buffers, we have implemented a library that applies a single random mutation to a given protocol buffer message. This is a library that, given a valid message, produces another valid message that is almost the same as the first one. And this is an example of mutations that you can get from protobuff mutator. For example, if you had a message containing hello and 42, one mutation can get it to help 42 and another mutation will may change 42 to 911. The protocol buffers could be nested so it is a tree like structure in general and protobuff mutator may apply changes not just to the leaf members of the function but also to the tree structure. With Google have a lot of APIs that consume a protobuffer and so consider this is your API that already consumes a protobuffer that you want to test and for example it has a bug.
00:14:34.878 - 00:15:53.430, Speaker A: If a very specific input is provided, in this case help and 911, then in our build system, in our infrastructure all you need to do to start fuzzing this API is these three lines. You define a proto fuzer that consumes a given message type and then you pass this message type to your API. This is it and this is a nail. This is the thing that is well suited for using your hammer on now clang is the screw, but we have still tried. First of all, we have defined a protobuffer, a protobuffer type that represents a tiny subset of c. Let me try to show you the full text if can. Yep, so this is the actual protobuffer that is committed to Lvm trunk what it says there is a variable reference.
00:15:53.430 - 00:16:20.674, Speaker A: There is l value. There is a constant. There is a binary operation that could be of several different types. The binary operation contains the type, the left operator and the right operator, both of which are r values. The r value is one of variable constant or binary parameter. So this is a fairly typical description of an expression. Then we have a seiden statement.
00:16:20.674 - 00:16:58.530, Speaker A: Then we have an if else statement. We have a while loop. We have an arbitrary statement statement sequence and then a function. This is it. 93 lines of code with spaces and comments. So we have defined this protocol buffer that resembles a subset of c plus plus. Next we did.
00:16:58.530 - 00:17:47.896, Speaker A: We implemented a very simple and straightforward function that converts this protocol buffer object in memory into a string that is an actual c plus plus code. And this is very straightforward boilerplate c plus plus that just takes the protocol buffer in memory and dumps it as a c plus plus. Excuse me. And then we implemented the fuzz target in the usual way. We have a protocol buffer and let's feed it into our API. Except that the API consumes c. We have a protobuffer.
00:17:47.896 - 00:18:28.830, Speaker A: So we have to do this intermediate step, translate a protobuffer into c plus plus. We reused this function handle cxx from the plain clunk fuzzer. So what this function does is it consumes a string of c plus plus code and then does whatever the usual clung binary does, except that it doesn't read or write files. That's basically clang. And the current state of this fuzzer is it's a toy prototype because it only generates a small subset of c plus plus language. Actually, it's a c. It's a subset of c.
00:18:28.830 - 00:19:37.644, Speaker A: Yet we have found a few things, and as I hope you will see from this and the following slides, the tests that we generate, they go through lexer and parser without any problems because they are just very basic, very plain c without any fancy syntax sugar or lexing sugar, and then they stress the optimizer and the code generator. This is more or less the typical example that is generated from my protocol buffer. As you can see, there are lots of while statements, and there are lots of assignment statements and some binary operations. In this example, there is no ifs, and this particular case caused clang to hang in jump trading. Here is another case. It caused use after poison, which is a fancy way to say use after free in selection dag. This one caused a fatal error, and this is my favorite.
00:19:37.644 - 00:20:14.876, Speaker A: We found it last week. Last week? No, I think we found it on Monday. It was actually a regression which was caught within a couple of days after the buggy commit was in. It's an alder reference in scale revolution. So let's compare the two approaches, the approach that we've taken in protobuffers and the approach that Justin have taken in icel fuzzer. First of all, I want to say that the approach taken by Justin makes a lot of sense. This is amazing thing.
00:20:14.876 - 00:21:04.060, Speaker A: It has to be done this way. Absolutely, it is much more work, but it is already done. So this is not an argument against ice cell fuzzer. It might help us to reuse a large corpus of existing tests that are already in LVMir form, although we're not actually using them right now to fuzz. And this doesn't introduce any new things like we don't introduce any new fake AR in protocol buffers. And since it doesn't involve clank with us LVM IR directly, it is somewhat faster. So what about the protocol buffer mutator approach? First of all, it's easy to express a subset of C Plus plus.
00:21:04.060 - 00:21:49.710, Speaker A: Very easy. I've done it probably in 20 minutes, but it's pretty hard to express full C plus plus. It will be a sophisticated project. I could see two ways to distinguish this work from IR mutation. First of all, we can try to target a very specific subset of language and fuzz only that one example would be nested loops, for example, to fuz poly. And the second benefit of this approach is that it is not LVM specific in any way. We can apply it to other languages, we can apply it to other compilers, and so on.
00:21:49.710 - 00:22:55.600, Speaker A: I've mentioned Csmith in the beginning of the talk. So what about Csmith? Who knows about csmith, by the way? Good. So csmith is a generation based fuzzer, meaning that it knows the syntax of a subset of C, and it generates the inputs that follow that syntax. It's an amazing fuzzer. It has found many bugs in all the compilers that I know of, but it doesn't use the trick with the coverage feedback that coverage guided fuzzers use. And so the hypothesis, proven by many other cases, is that CSmith doesn't actually find enough bugs, it could find more. And one of the ways to improve our protocol buffer based fuzzing is to combine them with csmith like syntax or grammar.
00:22:55.600 - 00:23:57.140, Speaker A: Fuzzing ClANG in general and fuzzing clang with protocol buffers is, for lots of reasons, problematic. First of the reasons is unfortunately not technical, but social bugs are being fixed too slow, if at all. The simple fast targets I mentioned to you, not all of the bugs get any attention. Like demandler bugs are fixed. Clank bugs are sometimes fixed dwarf dump, sometimes clank format almost never. And the related but still a different problem is that we often have infinite loops in the compiler. This is another example of plain C code that we found by protocol buffer fuzzing with clang.
00:23:57.140 - 00:25:08.988, Speaker A: Clang never finishes compiling this piece of code. It's pretty simple code, but for whatever reason it tries to color evolution it infinitely. And even if we didn't have any timeouts, clang and LVM are too slow for efficient fuzing. We typically get from five to 20 inputs per second, and this is with both clunk protocol buffer fuzzing and IR level fuzzing. So what's next? First of all, both clunk protofuzzer and LVM ISL fuzzer have been added to oss fuzz just very recently, so we don't really have statistics to compare and do some reasoning. Both of them did find several bugs, but that's not enough. We'll observe if you want to contribute to clunk protofazer, there are several ways to help us that I can see.
00:25:08.988 - 00:26:06.860, Speaker A: First of all, if you like this approach, try to express some other subset of C Plus plus as a protocol buffer message. It could be a larger C Plus plus subset, or it could be just a different subset. Again, the most interesting example for me is nested loops, but you can find something else, and if you find some interesting subset of C Plus plus, it would be 100 to 200 lines of very straightforward code to write, more or less a boilerplate. It would be interesting to make the generated programs runnable, like in C Smith, because the currently generated programs are just nonsense. If you try to run them, nothing interesting will happen. They will probably either crash or go into infinite loop. And it's also entertaining to try the same approach on other compilers.
00:26:06.860 - 00:27:18.948, Speaker A: Now, how can you contribute to fuzzing LVM in general, not only clunk protofuzzer? First of all, please try to fix the crashes, the timeouts, and the out of memory bugs that were already found. There are probably 50 of them. If you don't want to fix the bugs yourself, but you own the code that has the bugs, please answer to the code reviews. We have several instances of people who want to fix the bugs, but they're not owners and they don't get any responses. This is related to a discussion that is going on forever in the community related to the starter projects. So unfortunately, fixing bugs is not a starter project, is not a good starter project because the code review never happened. And my last message to you, if you are developing a new feature, please create a dedicated fuzzer for it from scratch because it will save you time and energy in future.
00:27:18.948 - 00:27:30.010, Speaker A: And once you have this fuzzer, we'll gladly have it on oss fuzz so that it fuzzed continuously and automatically. This is it. Thank you for attention and questions.
00:27:31.180 - 00:27:37.450, Speaker B: Thank you for presentation and we have plenty of time for questions.
00:27:42.460 - 00:28:07.990, Speaker C: Hey Kastra, I haven't seen a lot of types in the generated subset of C or C plus plus code. So if I want to stress the clamp front end type checker, or somehow I want to test clamp front end, but I want to bypass the type checker. Do you think it's easy to do using protobuff generated c code?
00:28:10.280 - 00:28:12.512, Speaker A: Can you bypass the type checker?
00:28:12.576 - 00:28:36.350, Speaker C: Yeah, because it's not a tree structure anymore when the types, abundant types are involved. But this code, basically almost all the generated code, as I imagine, won't pass the type checker. There will be some type errors and you cannot test anything after that.
00:28:37.520 - 00:29:01.910, Speaker A: So can we generate the code that will pass with more types that will still pass the type checking? Yes, I believe we can, because this will be a part of grammar. Now, if we can express the grammar in a way that we don't have type bugs, then we'll just generate it without type bugs, but it could be tricky. Okay, thanks.
00:29:03.480 - 00:29:22.030, Speaker D: So the crux in csmith is undefined behavior avoidance. So the property that we want isn't just runnable, it's deterministic. And so all optimization levels have to return the same answer. And the problem is, it's very hard to compose this with the search based on coverage. It's really a research problem, and I don't really know how to solve it, but we should drink some beer and maybe figure it out.
00:29:25.600 - 00:30:00.200, Speaker E: Hey, don't worry, I'm not going to ask you about Windows support for libuzer, but I do want to ask you, early on you mentioned that with the whole code coverage thing, whenever it finds that a new code path was taken, it will add that to the corpus, right? So is there any way to get some feedback from the tool about what code paths it was not able to encounter or like a summary of the percentage of code that was covered? Because something like that might help you be able to devise new inputs to manually add to your corpus.
00:30:00.860 - 00:30:50.650, Speaker A: Can we get the information about what's covered and what's not covered? So first of all, the corpus that the fuzzer generates is just a set of files. You can then take the set of files and run it through your target with your favorite coverage tool, and then you will have the coverage report from your favorite tool. Now, the service Ossfuz provides the coverage dashboard using sanitizer coverage, which is far from perfect, but it's the only one that scales today, and tomorrow we'll have a bof related to clank source coverage, which is totally amazing in the way it visualizes the code, but it doesn't scale on large applications yet. Sadly, there is no perfect answer, but there are several good answers here.
00:30:55.180 - 00:31:06.156, Speaker E: Does it do anything to try to encounter other branches that it hasn't been able to, or does it basically just keep generating random inputs based on the mutations, and then hope that it finds something that it hasn't covered before?
00:31:06.338 - 00:31:41.610, Speaker A: This is a question, I believe, about lip fuzzer itself. So lip fuzzer does random mutations on randomly chosen inputs, but the inputs are chosen with different weights, and the weight given to the input depends on the frequency of branches that it covers. So yes, it tries to steer the execution towards new stuff, but this is mathematical statistics. I'm not very strong at. I'm not sure I'm doing good job. I hope I do.
00:31:43.260 - 00:32:15.364, Speaker F: Hello, thanks for the talk. We saw a lot of compilers now utilize web services or even in the cloud. My question is, we see a lot of bugs like chip confusion and stuff like that. Do you think you find a lot of bugs that could be exploitable even if clang is using like ACL and other things? Because it kind of can be a concern if you try to run compilations as a service, if you can call it like that.
00:32:15.482 - 00:32:48.220, Speaker A: Can we find the bugs that can be exploited? Yes, yes and yes. So these are the bugs. What? Yeah, this is better. So these are the bugs that are currently open in the OSS fastbug tracker. They're public. As you can see, most of them are assertion failures and maybe one stack buffer overflow one. Yeah, but we're building clang in debug mode.
00:32:48.220 - 00:33:08.736, Speaker A: I've tried all these reproducers on the release mode and half of the bugs are now buffer overflows or use after free. And since clang is not hardened in any way, it's just an analytic binary, probably without ASLR even. I believe half of these are somewhat exploitable and maybe a couple are easily exploitable.
00:33:08.848 - 00:33:20.744, Speaker F: Okay, actually you have a peak flag in cmake, but it's broken. I have to do a peer about that, but. Okay. Yeah, that was what I thought actually. Thanks.
00:33:20.942 - 00:33:30.670, Speaker A: So if you want to find exploitable bug in clinic, you don't want to stress test the LVM. It's much easier to stress test the lexer, which has all the gadgets for you.
00:33:33.200 - 00:33:54.400, Speaker G: Hey Kostier, thanks for your talk. I saw your fuzzer, which tests the optimizer in the backend based on a subset of c. I was wondering if you think there's opportunity to use the new fuzz mutate library to stress the same components of LVM, hopefully bypassing the clang front end costs.
00:33:54.820 - 00:34:02.790, Speaker A: So can we use the fuz mutate library? That's exactly what LVM icel fuzzer does, so we already have it.
00:34:05.960 - 00:34:18.430, Speaker G: Okay, I guess I just wanted to also make a note of. In fact, yeah, I've seen a couple of the dwarf dump fuzzer bugs come through.
00:34:19.360 - 00:34:20.270, Speaker A: A couple.
00:34:23.360 - 00:34:40.320, Speaker G: I just wanted to highlight the fact that as someone who's not a code owner in that area sending out patches, it's slow because there's no review feedback. But I just wanted to emphasize that if you are the code owner in these areas, it would be really helpful to get that feedback.
00:34:45.220 - 00:35:01.960, Speaker C: Hey Kirstia, one of the weaknesses you identified was basically that C plus plus definitions file in the proto is not really big enough to generate more interesting inputs. Could we potentially auto generate that from an EBNF syntax of C plus plus?
00:35:02.110 - 00:35:29.008, Speaker A: Can we generate the protocol buffer description from some higher level description? I think we can. It might be tricky because, well, I'm not an expert in syntax parsing, but I've heard that C Plus plus is context sensitive, and I also heard that protocol buffers are not context sensitive, so it might be a challenge to bundle those two together. But it would be an extremely interesting.
00:35:29.094 - 00:35:31.170, Speaker C: Exercise, maybe an intin project.
00:35:35.160 - 00:36:20.530, Speaker H: So first of all, thank you for giving the talk. The thing I wanted to share was an observation. We have been running fuzzing extensively internally and have found something that surprised us, which is that fuzzing is really great at finding regressions, much more so than the latent bugs in the system. Our main use for our fuzzer at this point is finding small examples that point out miscompiles relatively quickly after a change was introduced. The other just side comment I wanted to make given review has been mentioned a couple of times. Here is I want to remind everybody, you don't have to be a code owner to review something so long as you're competent in the area.
00:36:25.320 - 00:36:42.170, Speaker E: I have another question, which is you mentioned that the structure where fuzzing for clang source code is slow, like you said, for like five to 20 inputs per second. What would be the other end? If the mutator was not slow, or if the program was not slow, what could we expect? What's the overhead of the fuzzing library itself?
00:36:44.060 - 00:37:25.030, Speaker A: When I profile so where the overhead comes from while fuzzing clank or lVmir, the fuzzing library doesn't introduce any overhead. There is a constant overhead from the sanitizer and from coverage instrumentation roughly to x. But when I profile this thing, I get all kind of weird things like passmanager. I've heard that there is new passmanager coming soon, but yeah, we see passmanager, we see some strange flag parsing stuff in the profile. So there are some inefficiencies in the LVM infrastructure which I haven't dug into.
00:37:25.580 - 00:37:33.576, Speaker E: Let's say we had an executable that returned zero in its main function and a mutator that did nothing. How many inputs per second could we.
00:37:33.598 - 00:37:49.230, Speaker A: Expect to get so on demandler, which is not exactly what you described, but a simple thing on demandler. Unless we hit the timeout case, we get about 50 to 100,000 executions per second.
00:37:49.920 - 00:37:51.992, Speaker E: Does it do anything in parallel or is it all.
00:37:52.066 - 00:37:54.688, Speaker A: No, it's just one core, one cpu one process.
00:37:54.774 - 00:37:54.976, Speaker F: Yeah.
00:37:54.998 - 00:37:55.570, Speaker A: Okay.
00:37:57.060 - 00:38:12.148, Speaker B: Thank you for presentation and answers about CSmith. So it's really powerful tool. We have found a lot of bugs with using it. So csmith two, I think. Yeah, it's welcome.
00:38:12.314 - 00:38:16.244, Speaker A: So John and I need some beer tonight. Thank you.
00:38:16.282 - 00:38:22.370, Speaker B: Thank you. And I think this finishes our presentation for today and.

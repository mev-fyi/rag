00:00:07.690 - 00:00:54.498, Speaker A: So yes, my name is Ralph Kaunberg. Thank you for being here. I'm presenting work on user defined optimization strategies, and this is joint work with my colleagues Marcel Kursta and Roland Leisure, who are also here, and Yevgenia Kovalenko and Sebastian Hach. And what we are concerned with is code from the high performance computing community, especially legacy code. Let's suppose you are a developer of some at a company like Cray or so, and you're working on legacy code, and you see that in the code you're currently working on, your hotspot. Somewhere in that code doesn't matter too much what it's exactly doing, but what's happening is that you see that three or two or whatever you're using is not doing what you want. So the assembly that comes out is not what you would like to see for your architecture.
00:00:54.498 - 00:01:38.458, Speaker A: No matter what reasons this has. I'm pretty sure that everybody has experienced that at some point. And now essentially the only option that you have is you rewrite that code and basically do the transformations that you would expect from the compiler, in the ideal case yourself. We are going to present a second option, but the first one, just to give you an impression, well, could result in something like that where you do some kind of inlining of the function call. You saw you vectorize the inner loop. That means you have to introduce some fix up code for the loop, and, well, it all gets a mess. It's not too important what actually is written down here, just to give you an impression what you might want to see.
00:01:38.458 - 00:02:38.110, Speaker A: And it's pretty clear that if you're writing that yourself, you're losing all kinds of maintainability, readability all gets a mess, and you probably have to do that for every architecture you want to run on. So that's not really an option. And what we are trying to do is give you a language extension. We have implemented that in clang that allows you to specify exactly what transformations you want to run on a specific part of the code and in what order. So what you see here is that noise statement in the front, which is actually an attribute, and the programmer specifies exactly that he wants to do loop fusion of these two, then inline the call to bar, do loop invariant code, motion, vectorize the code in a data parallel fashion, and then unroll it four times afterwards. And this essentially gives you exactly the same code as we saw it here, but you can do it well without actually rewriting it yourself. So you can tune your code without doing the manual rewriting.
00:02:38.110 - 00:03:35.162, Speaker A: So this transparently gives you access to all optimizations and transformation phases that are available in LLVM. Plus we have some additional ones that are, well, basically came out of discussions with the HPC people that said, well yeah, we would like to put a statement here and do this. For example, something that we call specialized loop dispatching. And what you see at the top is a for loop that runs from zero to a and the programmer wants to say yeah, I know that in my program a usually has the values one, two, three and I want to optimize for that. And what happens is if you write specialize and a equals one, two three, we generate a switch statement with optimized code for these four loops for the values one, two three. And it's pretty clear that inside here you can optimize further. So to sum it up, noise allows you to create user defined optimization strategies.
00:03:35.162 - 00:04:10.258, Speaker A: You can tune your code without actually rewriting it. It does not leave you from the problem that you still have to solve the phase ordering problem, you have to do that yourself. We don't do that for you. We have a few special purpose transformations. The vectorization is also, we employ our own technique that also allows you to vectorize inner loops and if statements in all various kinds of ways. It's an extension to clang and we try to do it as minimally invasive as possible. So we hope to maybe in the future integrate it back into the clang trunk.
00:04:10.258 - 00:04:27.130, Speaker A: Also, depending on the feedback we get here. And yeah, the proto types being evaluated at a high performance computing center in Stutgart and it's going to be open source soon under LLVM license. Yes, and by that I want to thank you for the attention and you can come visit us during the poster session.

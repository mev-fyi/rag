00:00:01.210 - 00:00:01.582, Speaker A: Thank you.
00:00:01.636 - 00:00:15.280, Speaker B: Hello, everyone. I'm Cindy. And I'm here with the rest of the LVM code of conduct committee. And we're just going to tell you some updates in the most recent years. So first, I'll let all the members introduce themselves.
00:00:17.010 - 00:00:18.590, Speaker C: I'm Tanya latner.
00:00:20.210 - 00:00:21.790, Speaker D: I'm Christoph Bales.
00:00:22.770 - 00:00:26.390, Speaker E: Mike Edwards. David Blakey.
00:00:35.770 - 00:01:20.280, Speaker C: We didn't practice this so well. Informal discussion. We definitely want an informal discussion today. So I just kind of want to give an overview of what the goals of the code of conduct committee is and the code of conduct. So the code of conduct is a document that's got explicit writing for expected behaviors for our community members. We want to ensure that all the members of the Elvin project community have a productive and psychologically safe experience, and they're really guiding principles that are used to sustain and attract many and diverse contributors and users and applies to all LVM spaces, which includes virtual and in person.
00:01:25.450 - 00:02:00.100, Speaker B: The committee is basically a point of contact to address issues that may arise, and it's also a governing force to uphold the code of conduct. And the slides speak well to what the code of conduct committee goals are. But a non goal is to police people for the way that they speak or to punish people if there is a disagreement or a problem that arises. And so our hope is to be able to provide guidance and documentation for people functioning proactively in our community, in all spaces across.
00:02:05.190 - 00:02:05.518, Speaker A: It.
00:02:05.544 - 00:03:00.310, Speaker D: So it has taken a while for the code of conduct and code of conduct committee to get established. So there's a number of milestones on the slide back in 2015, which is now eight years ago. Right. A code of conduct was introduced in draft mode. Only just last year it moved out of draft mode and it is being enforced in all LVM spaces. We started also at the same time publishing transparency reports, which you can find on the website if you're interested in knowing a little bit more about the kinds of issues the committee has encountered. And we're starting to see that some other open source projects are looking at this as an example and following our steps.
00:03:05.370 - 00:03:20.410, Speaker E: So with the transparency reports that we've been able to publish, we've kind of been able to break down on some different categories. And these were actions or like recommendations that we made in the report, correct?
00:03:20.560 - 00:03:20.826, Speaker F: Yeah.
00:03:20.848 - 00:03:28.410, Speaker B: So each transparency report has what the violations were, and then this is the breakdown of each violation category compared to the code of conduct.
00:03:28.570 - 00:03:29.280, Speaker F: Sorry.
00:03:32.130 - 00:04:13.934, Speaker B: So we've had about three transparency reports that detail multiple incidents. And the way that this usually works is that folks email us on the code of conduct@lvm.org. And then we as a committee, discuss the problem and then kind of communicate with both the party that emailed us, but then also any related parties. And then we kind of come to a conclusion of what violations did they commit and how to move forward. And so this is just a breakdown of what those violations have been. And I think there's three big chunks, right? The be respectful, be careful in the words that you use. And when we disagree, try to understand why.
00:04:13.934 - 00:04:54.342, Speaker B: And I think that there is a common theme between these three big chunks, and it usually just means that people care about the community getting their work done. And sometimes disagreements happen and no one intends to be hurtful. And that is a big reason why the code of conduct committee exists, is so to help move conversations forward when these conflicts happen. And most times than not, no one means any real harm. That's all. So this is kind of more numbers about this. An interesting part is there's been ten incidents.
00:04:54.342 - 00:05:14.450, Speaker B: Only about half have resulted in violations and only one resulted in punitive action. And so again, our goal of the code of conduct is not to police people, it's not to punish people, it's not to hold people accountable. It is to make sure the community can keep moving forward with the great work that everyone does with LVM.
00:05:18.470 - 00:05:47.290, Speaker E: I think one point that we try to stress a lot with the code of conduct is we want people to ask before something escalates to the point where we actually have to take action on it or there is a report. So we really, really try and encourage everybody that if you have a question about something or you think something's not right, please, please come to us and ask and say something, because we'd much rather have a discussion and conversation around some things and try and research a problem and help find a solution for it before it actually has to become some type of thing that we have to take action.
00:05:59.710 - 00:06:44.750, Speaker C: Our update. So, as Mike was saying, we don't see everything. There's only so many of us, and some could not be here today. And it's impossible for us to watch all areas of the project. And what we really want is as a community to uphold these values, and we want to empower you to be the person that speaks out that says something. We are definitely here to provide advice and guidance, but don't feel like you can't say something if you see something that's not quite right. And you can always reach out to us, even if you don't want to report an actual violation, but just say, hey, what do you suggest I say in this situation? We're happy to help.
00:06:44.750 - 00:07:18.256, Speaker C: So we're relying on all of you to help us out. And as we mentioned, not every conflict results in some kind of violation. And I really hate the word violation, I want to say, but it's like technical term that we keep using. But really we're here to educate and to help the community to communicate in a productive manner. Okay. And there's some examples. We have often seen contentious code reviews.
00:07:18.256 - 00:07:19.604, Speaker C: I'm sure many people in this room.
00:07:19.642 - 00:07:20.520, Speaker G: Have seen that happen.
00:07:20.590 - 00:07:51.040, Speaker C: People are passionate about how they think something should be done. I think we saw that in April's slide or her keynote. There's always like something driving behavior, and it's good to try to think about what that might be. We can definitely help with that. And if you observe potential violations but you're not directly involved, we've also gotten some people emails about that you can do that. You don't have to be engaged in the particular conflict. Please reach out.
00:07:51.040 - 00:08:04.740, Speaker C: And if you're leading an elevm event, we have a lot of meetups that are virtual or in person. Please help us and ensure that it's a safe space and people are abiding by the code of conduct.
00:08:09.400 - 00:08:10.180, Speaker A: Stick.
00:08:12.860 - 00:08:37.328, Speaker E: If, however, you find that you actually need to report a violation or really, I mean, honestly, even to reach out to us, email is the best way. Right? Conduct@llvm.org and just give us a note about what you think either the problem is or a question that you have. One of us will take a look at. It's a mailing list. It comes to us. We all take a look at it.
00:08:37.328 - 00:09:27.356, Speaker E: We'll triage it quickly and figure out what the best response is. We try to get back to you very quickly to at least acknowledge the fact that we've received the email and we're working on it. And then we have to get all of our schedules together so we can sit and talk about things. We try to do things asynchronously, but a lot of times with these things, it's actually really good for us to talk. But we try to do that on a pretty regular basis so that we don't have to wait a long time. And then if we determine that there's an actual violation that needs to be investigated, we will put a subcommittee together for each particular incident, and then we go off and investigate and then take further action if necessary. And then once we reach a decision on something, we will inform the reporter of the resolution.
00:09:27.356 - 00:09:31.520, Speaker E: And we also provide an opportunity for people to ask questions and appeal if necessary.
00:09:37.660 - 00:10:25.720, Speaker B: I did just want to finish off on one note. All of us are active contributors to LVM. We aren't some higher lord that then looks down on the rest of the community and says, you have to do this this way. And a big part of that is we care about holding us accountable as well. And the transparency reports are one way of ensuring that the community is keeping track of what we're doing, how we're assessing situations. There's a lot of active documentation and a response guide of how we handle every email that comes to us. And we gave you a short snippet in the last slide about that process, but it's actually very well documented and how we decide whether something is an immediate issue or not, or whether it takes further escalation.
00:10:25.720 - 00:11:07.770, Speaker B: And so if you are interested in this, please follow up with us. If you have any questions or concerns, also come here. Let us know if you have questions, concerns right now. And then last year we also had a community o panel discussion with other open source folks that care about having a safe environment to work in. And so last year we had a panel discussion with Sage SARP, who runs open source workshops for code of conduct, and then folks from include C who work very diligently in trying to create a similar environment for the c plus plus community. And so, yeah, there's two mics if anyone wants to ask questions.
00:11:15.020 - 00:11:20.670, Speaker C: We'll take any questions that you have now, no question too big or small.
00:11:21.840 - 00:12:34.870, Speaker H: So I don't have a question about violations. It's more of an observation in that I think we're not actually replying to a lot of people that are trying to, for the first time, contacting either on discourse issues, pull requests. A lot of these are effectively getting ghosted because somebody doesn't step up or somebody's busy. Another thing we're very poor at is being able to tell the community when we've got other things on, I'm buying a house or I'm having a baby, or we're really busy on the farm or whatever like this. And so then that doesn't help. People think, oh, they're ignoring me, I'm just going to commit. Is there any way that you can start kind of including these in the metric? How well we're, what proportion of discourse threads are actually replied to? Which ones actually come to a solution? Which ones just seem to die out and get a better idea of then what can we do to keep the momentum going on more of these conversations and issues, pull requests, that kind of thing as well.
00:12:37.000 - 00:13:30.470, Speaker C: I will say, at first, when you were talking, I was thinking you were talking about like, we have moderators for different infrastructure and the lack of visibility into that. I definitely want to acknowledge that as a code of conduct committee, we are going to be improving moderator training and getting that information from the moderators because we don't see everything that's happening right now that's getting taken care of. Moderators are actually fantastic on a lot of our infrastructure. But then I realized more bigger picture of what you're talking about, which I think kind of falls in the realm of code of conduct, but kind of doesn't at the same time, I don't know if you saw the talk we had earlier, it was about open source health metrics in general, that just the talk was right before this. I think that what you're really getting at is like, what is the general.
00:13:31.240 - 00:13:32.372, Speaker G: Health of our community?
00:13:32.426 - 00:13:59.470, Speaker C: In the sense that when you don't respond to a polar quest, you don't respond to a post that actually could be really offensive and unwelcoming for a lot of people and off putting. And we don't want that sort of perception of our community either. So I think this is something that maybe is not just in code of conduct bucket, but as a community as a whole. We should start looking at these metrics and figuring out how to address them where we see the pain points.
00:14:01.200 - 00:14:53.164, Speaker D: Maybe I'll just add that yesterday in community o workshop, this also came up. Like, how do we, one of the many things we discussed, how do we make sure that newcomers have at least acceptable experience? Like, if you post something and you never get any answer whatsoever, in my book, that's an unacceptable experience. That's one of the examples we looked at. Like some other open source projects have an automated bot that if you didn't get any reaction, just post message, sorry, you haven't seen any reaction. And then a person actually picks up on that and tries to find you, for example, a review that actually will respond to that. And actually, we started an issue track where some of these ids on how to make improvements, how to make steps. It's the community o repo in the LVM GitHub project.
00:14:53.164 - 00:15:18.568, Speaker D: There's now a number of ids there. And so one of these ids is like, can we create a bot that at least, like on pull requests, detect when something doesn't get reacted to, especially for newcomers, where you wouldn't expect them to find their way in other ways. So I think there's lots of ways where not just code of conduct come team members, but like everyone else can volunteer to make things better.
00:15:18.734 - 00:15:20.250, Speaker A: Okay, thank you.
00:15:23.020 - 00:15:24.250, Speaker G: Any other questions?
00:15:33.230 - 00:15:52.338, Speaker I: Directly? Building off of that as a newcomer, it can be kind of difficult to know who to add as the reviewer for your patch. Besides just looking through the commit history or past reviews, is there some form of consolidated documentation of like, this is what you generally should do, or is that in the works?
00:15:52.424 - 00:16:17.180, Speaker D: Or you're going to say the dreaded word maybe? I don't know. I know of like two sentences somewhere on the LLVM's Dork website in the developer policy that basically tell you what you already said. Like, you look at the get blame and see who were the people who were last active here. That might be a good start, but there's probably room for improvement there.
00:16:17.550 - 00:16:18.362, Speaker A: Got you.
00:16:18.496 - 00:16:19.738, Speaker D: Was that the best word?
00:16:19.824 - 00:16:44.980, Speaker E: I was thinking the code owners file, which no one looks at anymore. I think one thing that we definitely could do a better job of as a community is collectively trying to figure out escalation paths for things. Right? I mean, we talk about a bot that could be an autoresponder that could at least acknowledge the fact that you've made a contribution. We welcome the fact that it's a new contribution. We're really happy that you did it. We're seeing that there's no activity here. Let's see if maybe we can get you connected to somebody.
00:16:44.980 - 00:17:32.994, Speaker E: I think the difficulty that we have is that because we aren't a company where we can sort of force communication to happen certain ways, we rely on volunteers. We have to get some people that are willing to step up or have office hours or whatever, I will say that I think in the last year or so, or maybe the last couple since COVID Anyway, there's been a pretty concerted effort from a lot of people in the community to make themselves more available. I think we need to figure out maybe how to consolidate some of that information and get it in a place that will help. Certainly newcomers know where to go look to figure out how to escalate if they're not getting any movement on something. A lot easier said than done. Easy for me to sit up here and say it. I'm not quite sure how to execute on that yet, but I think we'll certainly work on it and try and figure that out.
00:17:32.994 - 00:17:35.198, Speaker E: And if anybody has any ideas, I'm all ears.
00:17:35.294 - 00:17:36.130, Speaker A: Gotcha.
00:17:37.590 - 00:17:56.890, Speaker C: I just want to make a quick plug for community o. This is definitely the area that we're focusing on, we have a GitHub repo that we made public that has issues. Now we're trying to put things as issues in it. So there might already be something like that. But if anyone is interested in tackling many of these things, please take a look at that.
00:17:57.040 - 00:17:58.380, Speaker A: Cool. Yeah.
00:17:59.390 - 00:18:13.670, Speaker I: One common strategy is like, there are some reviewers who do a lot of reviews, so it's like, oh, I know if I add this person, maybe then they'll review it, but at the same time you're adding to their giant log of reviews. So not sure if there's a better solution.
00:18:13.850 - 00:18:14.740, Speaker A: Thank you.
00:18:16.950 - 00:19:05.518, Speaker G: I actually wanted to add to this conversation. I know that in a few other communities, I don't know if it's already forming here or not or exists or not. There is a group of people like first contact working group or first contact special interest group. So a group of people who more focusly are looking into who the newcomers are and how to help them, how to make sure that the onboarding documentation exists and it's in good shape. When it comes to adding reviewers, there are communities or just even sub teams within the community. Like, don't add me, I don't want more emails from GitHub or Garrett in other teams. Please add me because otherwise I will not be able to keep up with figuring out whose patch is.
00:19:05.518 - 00:20:04.930, Speaker G: So like having these things written down in an onboarding documentation where people can understand not just the tools but the preferred processes. And sometimes this onboarding documentation really goes down to the level of the working groups and sub teams within one community, because not everybody likes to operate the same way. But if you have like a first contact and onboarding group who can help the community at large to figure these things out and have it documented, that can be a good step. And it's a good incentive for that group to say that, hey, if you put time into and energy into it now, then you will have more people in the community to whom you can then distribute this responsibility and this kind of help. So it will not be you forever who's doing this. So kind of flipping it around a little bit and telling people why it is good for them to do this in the first place and how it is in their interest. In my experience, that also helps.
00:20:04.930 - 00:20:47.380, Speaker G: So that can be something. And the community that I mentioned, the 13 years old community, it's called Openstack. And they actually do have a bot that responds on a Garrett review when the person never contributed before, saying, hey, welcome new contributor. I mean, it's not a guarantee still that the contributor will get a quick actual human review, but it also works very nicely. So I think someone was mentioning that, and it was a good investment for that community to at least do that just tiny little thing that makes the person feel better, that, oh, they recognize that I'm trying to contribute here and it makes people feel really nice. Thanks.
00:20:48.230 - 00:20:50.340, Speaker C: That's a great suggestion. Thank you.
00:20:51.110 - 00:21:32.094, Speaker F: Yeah, I was basically along the same lines, going to respond that I think everybody's different. Some people feel more comfortable just adding a random reviewer and see where the asynchronous communication goes. But if you do feel more comfortable with some human to human interaction, I think just like looking at the LLVM calendar and pick the closest seeming working group. As a newcomer, I thought initially like, oh, those are meetings where people who know what's going on are all talking about important things. And you couldn't just come in with my random newcomer question, but there's often less on the agenda than you would expect. But people still show up and are waiting. So I think maybe pointing to those options to find office hours as like, go look at the calendar, show up.
00:21:32.094 - 00:21:37.700, Speaker F: Probably somebody there is going to volunteer to help direct you to the right place. If there isn't somebody there who can help you.
00:21:40.470 - 00:22:05.350, Speaker D: Maybe on the community agenda and the office hours. I think the one biggest issue we've had with growing that is basically advertising. How can newcomers find that this thing exists? Or people who are maybe outside of the community to start with? So maybe this is a call to action for everyone, like, tell people these things exist and advertise further.
00:22:10.330 - 00:22:11.760, Speaker A: You it.
00:22:13.250 - 00:22:22.720, Speaker C: Any other questions? All right, great. Well, thank you, everyone, for attending, and we'll be around if you want to ask us a question offline.
00:22:22.880 - 00:22:23.830, Speaker A: Thank you.

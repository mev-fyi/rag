00:00:07.750 - 00:00:44.950, Speaker A: Yeah, thank you. So I'm going to talk about a problem we've got, and we're interested in anyone's advice, or anyone who's interested in similar things. Xmos make microprocessors, and the tool chain used to target those processors is based on LVM. So this is what we do. We can piles. We have a C and C plus plus compiler that goes via LLVM GCC. We're hoping to move to clang soon to Llvir, which then we use the X core back end, which is Xcore is our instruction set architecture.
00:00:44.950 - 00:01:26.114, Speaker A: And currently we're on 3.0, mainly because I love VMGCC, but we're hoping to upgrade that to something more modern. And then that goes to our binary utilities. We also have a separate front end, which is for the language XC, and XC is c, but we've got extensions there for multicore processing and real time I O and memory safety as well. So our processors are mainly used for real time embedded applications, and in those we have timing constraints. So we get code like this. This is not actually real code, this is an idealized version of it.
00:01:26.114 - 00:02:12.222, Speaker A: But here we have these functions which are waiting for external I O events. They're waiting for an edge to go high on an external I O signal and outputting on that. And in the middle of it we have a timing constraint, have an assertion that the times that these things happens can't be too far apart. What we're actually saying here is that between these two points, if the time is less than a certain constraint, 270 nanoseconds, say, then the program doesn't work anymore because the external I O protocol requires it. Okay? So we have these fine grained, rather hard timing constraints in our program. What we do have is we have a tool to check it. So when the binary comes out, finally you can run the static analysis tool that tells you whether your timing constraints are met, which is great.
00:02:12.222 - 00:03:00.142, Speaker A: Okay? So you can go forward in confident that your program won't break because of these things. And that's what enables the real time stuff, and there's lots of stuff in the processor, deterministic execution and so on to make this work. So that's great. What's our problem? Well, our problem at the moment is the LLVM optimizers, which are great, and we benefit a lot from them by using the tool chain, but they aim to improve average time, right? They intimidate to make a function or a loop run as fast as possible, and they will think about a whole function, or maybe they might see a loop as hot or not or whatever, but they don't really separate out particular paths that you're interested in. And this means that from a worst case execution time constraint perspective, these optimizations can make things worse. Here's an example. Scheduling can mess this up.
00:03:00.142 - 00:03:23.830, Speaker A: This is the same code as before. We've got some code in there. So in this situation, things might be met. Everything is great. But if the scheduler decides to move the code sequence two up there, it can take too long. Between that first I o operation and the second and the one in the loop, it breaks the constraint and the program's broken. This is not a move from a working program to a nice slightly faster program.
00:03:23.830 - 00:03:54.020, Speaker A: This is a move from a working program to a totally broken program. Now, this is just an example. Obviously, that same optimization might make your constraints go from broken to working, right? So it's not that the optimization is bad, it's just not aware of what these constraints are. It's not just scheduling. I mean, loop invariant hoisting, same problem. If you move code sequence two from there to there, we get the same problem, it breaks the code. So that's our issue.
00:03:54.020 - 00:04:31.338, Speaker A: What are we going to do about it? I don't know. So this is something we're just starting, and we'd really appreciate advice of the way to do this in an upstream friendly manner. What I do have some hopes about things that will make us able to do this within this framework. We're hoping that actually most optimizations are okay. These comotion ones kind of have pathological cases, but a lot of optimizations are fine for this kind of thing. So we can just ignore those and let them go through. We also that we saw those things out in the scheduler, or at least kind of in the target lowering.
00:04:31.338 - 00:05:06.506, Speaker A: They're close to the final code emission. But we probably don't need, want to be restricted to basic blocks for this. I mean, you've seen from those constraints before that they go across basic block boundaries, and that could be a problem for us. But we really want to avoid a big fall. We don't have the time to go and make every optimization kind of worst case path aware, so we want to do it. So we're hoping that it's more a matter of tuning the things that mess things up rather than totally rewriting. So that's where we are and that's it.
00:05:06.506 - 00:05:07.160, Speaker A: Thanks so much.

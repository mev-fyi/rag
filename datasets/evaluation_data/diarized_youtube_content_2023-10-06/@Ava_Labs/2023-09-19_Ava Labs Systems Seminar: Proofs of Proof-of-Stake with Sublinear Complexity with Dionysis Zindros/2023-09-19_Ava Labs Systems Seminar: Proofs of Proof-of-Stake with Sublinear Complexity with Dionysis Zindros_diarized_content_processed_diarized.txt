00:00:10.330 - 00:00:10.634, Speaker A: Sweet.
00:00:10.682 - 00:00:33.430, Speaker B: So, welcome back to another system seminar for this week. I'm super excited to introduce deonistis. He's a postdoc at Stanford. He's taught a blockchain foundations course, which has been one of my favorite classes at Stanford. So if not one of my favorite message. So, Denise has published many papers for this talk. He's going to be talking about proof of proof of stake with sublinear complexity.
00:00:33.430 - 00:00:45.580, Speaker B: So I'm super excited about this talk. So just for the format, typically it's like 30 to 45 minutes presentation and then, like, questions at the end. So with that, I'll let you take over.
00:00:46.670 - 00:01:00.138, Speaker A: Yeah. Thanks, Sam. Yeah. So Sam was my student in blockchain foundations, and now he's doing an internship in a big blockchain company. So, yeah, very proud and good to connect again. Okay, so proof of. Proof of stake with the Blinger complexity.
00:01:00.138 - 00:01:07.706, Speaker A: This is a paper that we wrote with my colleagues reshagrawal from Munich Tomb Yokim.
00:01:07.738 - 00:01:07.898, Speaker C: No.
00:01:07.924 - 00:01:31.740, Speaker A: And ertem nosratas here at Stanford. And it just got accepted, actually, for publication at AFD, advances in financial technologies, taking place in October in Princeton. In case you can make it, Trish is going to present it there. Yeah. So here I have a kind of artisanal deck of slides to you. I hope I can maybe do a little bit of whiteboarding if there's any questions at the end. Hopefully we can do that.
00:01:31.740 - 00:02:08.740, Speaker A: All right, so let me tell you a little bit about what we're trying to do here by starting with a problem that we're facing, kind of. So the way that things look like today in the ecosystem of, let's say, ethereum. I'm using Ethereum here, by the way, as an example. Proof of stake chain. But what I'm going to say today applies to all sorts of proof of stake chains that follow a similar format. So you're going to see that whatever I'm saying, it follows for algorithm, it follows for Cardano. You'll see kind of the technicalities there.
00:02:08.740 - 00:02:38.154, Speaker A: So, ethereum is one example. If you want more details on all the other systems, you can look at the paper. It's all there. All right, so if we go to whatever users are doing today in their wallets, a user typically has metamask. Here they are. And what does metamask do? Well, metamask just connects to a central server which is operated by infura or alchemy or some other operator. And then that is the server that connects to the rest of the Ethereum network.
00:02:38.154 - 00:03:10.566, Speaker A: So the rest of the ethereum network consists of these full nodes that are maintaining the blockchain and making sure that everything is fine. But the metamask wallet, really, it's fast. But on the other hand, there is a bunch of problems. What are these problems? The problems are, well, the server is trusted. And what are they trusted with? Well, this is a non custodian wallet, as people like to say. So they're not trusted with your keys per se, which means they cannot really spend your money. However, they can really lie to you.
00:03:10.566 - 00:03:52.594, Speaker A: They can just tell you, oh, here's a transaction that happened and then you will believe it. Like the metamask wallet will just tell you, this is your balance, right? And even if you look at metamask itself in the interface, if you try to add a network, it gives you like a warning that tells you, yeah, you need to trust the server. So that seems kind of contrary to the ethos of decentralization that we're trying to pursue here. And if you think back to nakamoto's paper on bitcoin, the main problem we're trying to solve is double spend, right? And, well, infuria really can double spend here, right? They can have some money on chain tell you that they gave it to you and then use it somewhere else. So really that's a double spend. And we're not really avoiding that. So there's a big issue of centralization.
00:03:52.594 - 00:04:22.426, Speaker A: And, I mean, we may trust infuria, okay? It's a big company. They're well funded, they're operated in the US and so on. But then what if they get hacked? I mean, they may not be malicious, but somebody might attack their systems. And that's not the best, to only rely on one server. And additionally, even for infuria themselves, this is a huge liability. Right? The umbrella company develops Metamask and infuria. If infuria gets hacked, for them as a company, it's a liability if somebody starts double spending.
00:04:22.426 - 00:04:57.580, Speaker A: So even in their own interest, it is to remove this kind of point of centralization, I think, yeah. How can they double spend? They don't have your keys. Right? They double spend their own money. Right? So imagine I'm infuria, I have a million dollars or not a million dollars. Let's say I have $30,000. I keep it in my own wallet, I give it to Sam, right? But then I had this transaction from you, and I report a fake transaction to you that I send it to you and then you give me your car. And then as soon as I have the car keys, I drive off to Venice, and then your money's gone.
00:04:57.580 - 00:05:47.302, Speaker A: You think you have the money, but it's not there. Right? So that's a double spend. Okay, so we have this problem of how do we decentralize this? On the other hand, if we want to look back at how typical decentralization works, we have this full node alternative where you have the wallet, which from now on, I'll just call this the verifier, because we want this to be verifying. And it directly connects to some provers here, which are really full nodes, actually, and they maintain the chain themselves. And then the wallet is actually talking to them, downloading everything and verifying everything. Right? And there is a question such as, did I get paid or do I own this board? Ape or whatever you want to ask. But this has the issue that it might be slow.
00:05:47.302 - 00:06:20.834, Speaker A: Right? So let's go over a little bit. What are the assumptions here and how this thing works? Okay, so briefly, the client connects to some part of the network and it tries to figure out if it received a payment. And then these provers are well connected with the rest of the network, which is here. And the rest of the network is maintaining the chain. Right. Among the rest of the network, which is keeping the chain, you have an honest majority assumption, maybe two thirds that are honest, to make sure that the chain progresses correctly. Signatures are put correctly.
00:06:20.834 - 00:06:49.358, Speaker A: Right? And then among the people that you're connected to as a wallet, you assume that maybe multiple ones are adversarial. Even almost everyone is adversarial. But you need at least one honest connection to make sure that you receive. At least if you get paid, you need to know it somehow. Somebody needs to tell you, right? So you need to make sure you're not eclipsed. So on the network level, you have at least one honest connection. But on the whole network, among validators, you have honest majority, two thirds, let's say.
00:06:49.358 - 00:07:23.542, Speaker A: So kind of, that's the setting. And you can imagine this is pretty slow to validate. So how does this look like? Well, they are maintaining the chain and they're sending you everything, right? They're sending you all the transactions, they're sending you all the blocks, and you need to check all of these things. And this is about five days to sync. Right. Now on Ethereum, if you have a very fast connection, it's not super good, right? So we have kind of these two alternatives. One is you connect to infuria, you're super fast.
00:07:23.542 - 00:08:03.474, Speaker A: On the other hand, you're a full note and you're super slow, it's not very good. So can we do both fast and secure? That would be a nice combination. So that's kind of the purpose of the stock. How do we do that? How do you maintain decentralization while also being able to run on a mobile phone or running on a browser? Lightweight, without too heavy communication, too heavy storage, too heavy battery use all of these things, right? Or computation. Okay, so recap, how does a full note work? I'll start from this, and then I'll kind of start removing things until it becomes very lightweight. That's kind of the game plan here. So let's look at the chain.
00:08:03.474 - 00:08:27.658, Speaker A: So in the chain, in the Ethereum chain, you have the most recent block, the tip. And it looks a little bit like this. It has a block header. And then in the header it has a state route, which is a Merkle tree route. Merkel, Patricia, try. And in Ethereum, it doesn't matter. And then within that you have some state variable that is of interest to you as a light node.
00:08:27.658 - 00:08:45.874, Speaker A: Right. This is what the client wants. It could be, okay, I want to look at the Uniswap contract. What is the value of this variable? Or I want to look at my balances. There's a similar tree for balances. Okay, do I have five ether? Or did this event get executed? And then there's a receipt tree. Okay, I can check all of these.
00:08:45.874 - 00:09:27.326, Speaker A: And then all I need to do is check this Merkel inclusion proof. So the goal of the light client is to get the state route of the most recent block. Once they get that, because they know that they have at least one honest connection, then they can rely on the honest connection to send them the tree proof. And then they cannot be lied to as long as the state route is correct by the custody of merkle trees. Okay, cool. So our goal will be to just retrieve the latest block, the tip of the canonical chain, and among that block, we just need the block header. That's all we want, right.
00:09:27.326 - 00:09:50.838, Speaker A: So we kind of reduce the problem. I don't need to verify the whole chain. All I need to know is what is the latest block, what is the header of that block? And then I can verify my state and transactions in that. Cool. If we look at consensus and how it works, each of the blocks contains some sort of signatures that are confirming it. In Ethereum, it's a little bit more complicated. You have like a bunch of different systems.
00:09:50.838 - 00:10:22.398, Speaker A: You have LMD Ghost, which is a longest chain style protocol, working together with Casper FFG, which is a finality gadget but for this, let's just look at Casper FFG, which is just counting signatures. So it's not super complicated. Right. All you need to do to tell if a block is finalized is you look at the population of stakers, and then you count two thirds among them and make sure that they've signed the block. And then that tells you that this is a valid block. As long as honest majority is okay, the signatures should be fine. Right? No adversary can gather two third signatures.
00:10:22.398 - 00:10:54.054, Speaker A: And this is similar. I mean, if you've read some of the simple papers in the literature like streamlet or hot stuff, this is very akin to that. Algorand is also working like this with these kinds of signatures. Okay, so that seems easy, right? Because if I have this, what can I do? As a light client, I can just connect to two provers. By the way, the provers are the full nodes that are connected to the rest of the network. They have full processing power and they're helping me get verified or verify. However, many of them can be at Resaro, even 99% of my connections.
00:10:54.054 - 00:11:12.594, Speaker A: Right? So here's a simple idea. I ask them, what is the latest block? And then each of them sends me a block. And then, of course, the block itself contains a timestamp. So if you look at the timestamp, you can see, oh, this is block number five. It has enough signatures. I can count two thirds of the signatures. And then the other prooper can send me block number seven.
00:11:12.594 - 00:11:36.970, Speaker A: I count the signatures as valid so they cannot serve me invalid blocks. And then I can just keep the latest. Right? So I can say, okay, this is block number seven. I'm all set super fast. However, there's a problem with this. And the problem is, well, the stake shifts all the time. The population that is actually authorized to sign the blocks is not the same today and one year ago.
00:11:36.970 - 00:12:17.634, Speaker A: Because who is able to sign, who's authorized to sign is exactly who owns coins, which is kind of what you need to retrieve by looking at the chain. So it's kind of a recursive problem. So are we back to square one or not? So maybe we can use some ideas of this signatures to speed up things without validating the whole chain. So that's kind of the idea here. All right, so let's look at some technology that Ethereum has deployed over the past year or two to kind of alleviate this issue. And then we will use it more efficiently than they were planning to make it kind of super efficient. All right, so this is called the sync committee.
00:12:17.634 - 00:12:59.640, Speaker A: It was in the Lodestar update. And the way it works is you split time into periods, and these periods have a duration of one day. So you can think of the chain progressing as usual, but then you chop it up into periods, and then those periods have a duration of one day for each period. The validator set that is responsible for validating is very large. It looks like this for ethereum, this could be even like half a million nodes. And these are really the people who need to sign off of blogs to get you to the Casper FFT finalization, at least maybe two thirds of these nodes. And Ethereum has a complex mechanism of ensuring these signatures come together.
00:12:59.640 - 00:13:52.930, Speaker A: There's different epochs, different phases and so on, but it doesn't matter for our purposes. But what they do in the sync committee is they take this 500k validator set for each period, and then they do a sampling. They do a subsampling of this committee down to 512 validators. So it's like a bunch of people, but much, much smaller than the whole 500k set. And those people, well, if you have honest majority in the underlying set of 500k people and you sample 512 of them, then this honest majority ratio will be preserved as long as the sampling is uniformly random and cannot be predicted by the adversary. Right. So you have these small committees that are responsible for each period, and you ask them to sign the blocks that pertain to their period.
00:13:52.930 - 00:14:26.270, Speaker A: So what they do is they take their public keys. So here I have the public keys of this committee for epoch n, right? And then what I ask them to do is, well, whenever a block appears in their own period, they're asked to sign it. And that marks as soon as it's finalized by the underlying committee, they sign it as well. And that's the way they signal that, yeah, this is a good block. So we do have honest majority among the SIG committee. They sign the blog. If I see two thirds of signatures on that blog, I can trust it as a light client.
00:14:26.270 - 00:15:16.910, Speaker A: That's the kind of way they work. And this PKN, by this PKN notation, I mean the set of all the public keys in the nth period. The committee, the sync committee of the nth period. Cool. Now, the light client, all they need to do is they need to check that the block that they are being served has two thirds of signatures by that current committee. And so the problem really reduces to what is the latest committee? Can we find out this PKN? And of course, we're kind of back to the previous problem that we had, which is, well, stake changes hands all the time. How can I find out that piece of information if I don't look at the whole chain? Well, there's a little bit of extra detail in how these committees work, and this is these handover messages.
00:15:16.910 - 00:15:45.126, Speaker A: So one of the requirements for the sync committee is that each of the members of the sync committee, they're asked to sign the next sync committee's keys as soon as they become available. So if we live in Epoch J, and I'm part of that committee, and I'm playing honestly, at some point my turn is almost over, but the new committee is elected. So the new committee is sampled. Here it is. I can see it because I follow the whole chain. I'm a full node. I can see the sampling process and how the randomness is generated.
00:15:45.126 - 00:16:27.782, Speaker A: So what I do is I take this whole set of new keys of PKJ plus one, and I put my signature on it. Everybody else in epoch J, by the way, I use epoch and period interchangeably here. Everybody in the JT epoch will see the same thing, and then the honest people will sign also PKJ plus one. Right. As soon as two thirds of the committee sign. This denotes kind of a valid handover from epoch J to epoch J plus one, which means that a live client observing this can verify that there has been a handover from Epoch J to epoch J plus one without actually looking at the underlying things. Okay, so let's look at how this protocol works.
00:16:27.782 - 00:16:56.118, Speaker A: Now, the verifier again connects to multiple provers. I just have two here for simplicity. One of them is honest, one of them is at Rosario. And then the honest party is sending the succession of committees with their public keys and the handover messages. So they have the signatures and then the live client. All it needs to check is it verifies each of these signatures to see if it's correct. Of course, the verifier has the Genesis block, so it knows the first committee of the Genesis era.
00:16:56.118 - 00:17:35.226, Speaker A: And then once they get this committee, well, they can verify the blog by checking the signature of the committee to the blog. And then they have the state and all is good. Right? If a malicious frugal wants to send an invalid succession of handovers, they cannot do that because they cannot reproduce a signature towards an invalid new committee. So they may be able to give you a prefix up to a point that is valid. But then if they try to give you an extra committee that is invalid, they cannot collect enough signatures to do that and convince you. So the only thing they can give you is basically stale data, which is also what we had in the full node case. Okay, so we can forget about blocks.
00:17:35.226 - 00:18:10.666, Speaker A: Now. The purpose is to just get the latest sync committee, and that's one way to do it. Now, this is still faster than. This is much faster than what we had before with a full node. Of course, we're not even sending blocks. But still, like every day that has passed in the history of the system, we need to send 512 different keys, and then also two thirds of 512 signatures. Yeah, you can aggregate maybe the signatures into one signature and do some public key aggregation, but you still need to have all the 512 keys for every day.
00:18:10.666 - 00:18:57.750, Speaker A: So, yeah, it's sufficiently light, it's reasonably light, but we want to make it faster. So let's see how we can do that. So, the idea for this is that instead of just sending the whole 512 keys per committee, what we do is we hash it. So, here, the proverb takes the public keys of epoch one, hashes it using, let's say, chapter 56 or ketchag, and then obtains this hash of the committee. And same for two, JJ plus one, the latest committee, and sends those to the verifier. Of course, now, the verifier cannot check any signatures or anything, right? So it's possible that the prover is lying. But remember, we have the assumption from the full notes already that at least one of our network connections is honest.
00:18:57.750 - 00:19:20.734, Speaker A: So maybe 99% of them are compromised, but at least one of them is honest. So we can rely on this honest party to give us the correct state of the world. So here I have an honest party. They're giving us the correct succession of committees as hashes. And then I have an adversary who's giving us an incorrect succession of hashes. And maybe let's say that there's a. I mean, if they're the same, I don't need to care.
00:19:20.734 - 00:19:59.418, Speaker A: The adversary is just giving the correct data, so they must be different if there's an issue, right? Well, that means that they must differ at some first point. So let's suppose that they first differ in location j plus one. Now, what the verifiers do is this is going to be a multistep process. So first they receive these hashes from the provers. They look at them, they do this comparison, they put them like this, one on top of the other. And then once they find their first point of disagreement by comparing the hashes, they go back to the provers, and they say, oh, look, I think there's a disagreement here. I see the same hash in location J for Epoch J, and then in epoch j plus one, I'm seeing something different.
00:19:59.418 - 00:20:31.090, Speaker A: Can you show me the signature and the public keys for those particular epochs? For the jth epoch? Right. And then the adversary should be unable to present you with a signature because they don't really have it. But the honest guy. Well, no matter what the adversary says and whatever they claim, if they're challenged, they should be able to answer because they have this signature. So it's okay. Right? So that's the basic idea. Now, the verifier takes all these hashes again, puts the arrays on one on top of the other, compares them element by element.
00:20:31.090 - 00:21:34.890, Speaker A: Once they see the first point of disagreement, they take the previous one and that one, j and J plus one, and they request these hashes to be opened from the provers and the signatures to be presented from committee of Epoch J to committee of J plus one. So the point here will be to retrieve the first point of disagreement among the committees. If I can do that, then I'm all set for verifying my state. Right? So now if we look at the complexity of this asymptotically, we still have an of c complexity here, right? So why? Because, well, for each day of the past, I needed to send a hash. So the complexity of this thing, if the lifetime of the system is c, if the chain size is c, I still have big o of c data that I need to communicate. It's much faster, but I still need to send linear data in the previous lifetime of the system. So now for the final construction.
00:21:34.890 - 00:22:15.874, Speaker A: Can we do even better than that? And hopefully we can bring it down exponentially. We can do something that is asymptotically better than this. All right? So the idea is really very similar to what we have done with these hashes and these first point of disagreements. But I'll show you a slightly faster way of finding the first point of disagreement. All right, so what's the trick? The honest prover takes these hashes, which hash the committee public keys and organizes them into a merkle tree. So they take the hashes of the two first committees, and then they organize them like this. And then they get up to a root, right? And then all they send is the root of this tree to the verifier.
00:22:15.874 - 00:23:14.442, Speaker A: So this is like, oh, this is the whole history of the world, of all the committees that have happened, right? So this is, I hash the public keys, I take them together into a tree. This one piece of hash, this is the whole thing, right? The verifier, of course, doesn't know anything, but this is a commitment for the prover. Now, again, we have potentially two provers, and they might be claiming different roots of this tree. And now the verifier will play them in this kind of challenge response game of multiple steps in which they will try to find the first point of disagreement by looking at this tree. So how does this look like? Okay, well, initially, the bad guy and the good guy, they're sending different routes, right? If they send the same routes, we're all set. If they send different routes, what the verifier is doing is they're telling the proofers, look, I have a different route. Can you give me the two children of your route so that I can figure out what went wrong? Right? Yeah.
00:23:14.442 - 00:23:50.078, Speaker A: So both verifiers send their children, and then the client, again is comparing. Right. If the first part matches, that means that this whole subtree is exactly the same, so I can forget about it. Now, on the other side, if there's a difference, I can recurse and I can say, okay, look, these two nodes are different. I need to find out why. Can you send me the children of them? And then I can go, well, if those are different, now I can go to the first part so I can continue on this, and I can ignore the right hand side. If it's the same or if it's different, I don't care.
00:23:50.078 - 00:24:14.394, Speaker A: I just want to find the first point of disagreement. So the number of steps in this process is just logarithmic. And then at some point, I will end up in a leaf where there is one node. When there's one leaf which represents a committee that both of them agree on. So it is the honest committee. It is the valid committee of Epoch J. But then the next one is something that they disagree on.
00:24:14.394 - 00:24:39.862, Speaker A: This is j plus one. And once I've reached that stage as a verifier, I can ask the provers. Okay, I see these keys in the tree. Can you give me the signatures that are verifying the handover? And again, the adversary approvers should not be able to find that signature, but the honest prover should have no problem. No matter what the adversary does, they can always defend themselves. So that's how you can find the first point of disagreement here. Cool.
00:24:39.862 - 00:25:13.870, Speaker A: So once you have this treat, this is a bisection game. By the way, if you look at the literature, these bisection games, they started back in the early 2000s by Ron Connetti. He has a paper on referee delegation of computation and he does many, many cool things about it. This technique is also used by arbitrum to resolve kind of optimistic roll up disagreements. So it's a very cool technique that has very wide applications. It's not invented by us. We're just, like, changing it for adapting it to discovering committee disagreements.
00:25:13.870 - 00:25:55.178, Speaker A: Okay, so once I have this tree, once I have the root of the tree, and I know which one is valid because, well, it was not challenged by it, by anyone, then I can go ahead and verify my transaction. How does this work? Well, I just ask all of my network to reveal the leaf of the latest committee in that tree that I know the root is valid. Right? So I know that this thing is valid, and therefore, I ask for proof of inclusion here. And it needs to be provided by anyone on my network. And it will be provided because some person will be honest, they will give it to me. And now I have the public keys of this committee. I can check their signature on the latest block.
00:25:55.178 - 00:26:23.414, Speaker A: Take that block, take the state, find my balance. Got it. And this is blazingly fast. We can sync in less than 10 seconds in ethereum. And also, theoretically, it's more interesting because, well, the height of this tree is just knock c, where c is the lifetime of the system. So the number of interactions is really fast, and then each interaction is just one hash, essentially, or two hashes super fast. One last thing.
00:26:23.414 - 00:27:18.934, Speaker A: Is this tournament idea? Well, in the last few slides, I just assumed you're connected to two different people, but you might be connected to multiple ones. You don't know who's the honest, but you can see how you can play them against each other, right? So you can say, oh, you two play against each other, you're disagreeing, some of you is wrong. You challenge each other, and then there's one winner, and then you play the winner against the winner of the other group, and so on. And the honest party is guaranteed to win against another rosary who's claiming something fake, right? So you can have the honest party prevailing in this kind of tournament, and you can do this quite efficiently. There's an algorithm in the paper on how to run this efficiently, but you can already see, I mean, from this picture, the number of games that you're going to play is not too much. If you want to do it fully, properly, it's going to be a linear number of games in the connections that you have. Typical connections are maybe like ten or 20 connections.
00:27:18.934 - 00:27:44.400, Speaker A: So this is pretty fast. All right. We've actually implemented this. We made it for Ethereum. It works. So I want to share my screen and show you real quick how that works? Let's see if I can share my entire screen. Okay, it, does this work? Do you see my screen as well?
00:27:45.170 - 00:27:46.510, Speaker B: Yes, that works.
00:27:46.660 - 00:28:04.710, Speaker A: Yeah. Okay, good. So we have this kevlar sh, which you can go to, and you can also download it yourself. So, well, it's an NPM package. You run this Kevlar thing, and then you can run it on your console. So I'm already running it here, but I can rerun it. So I just run Kevlar.
00:28:04.710 - 00:28:31.594, Speaker A: Boom. Right? It already synced. So what it does is this sits on my computer and acts and plays this bisection game by connecting to multiple provers. So we've deployed a small prototype network of provers. You connect to them, and then you play the bisection game against them. If some of them is at Rosario, you can find out what is happening and it's also keeping it live. So if there's new data arriving, it will keep updating.
00:28:31.594 - 00:28:55.830, Speaker A: And then it gives you this local URL, which is an RPC URL, and then you can go to your, let's say firefox. And then, let's see here I have my metamask, and then I've created a new network called Propulse, which is essentially just a local host network. And that's it. I can see transactions. I can send transactions. If I send myself money, it's going to appear here, really simple. So please try it out.
00:28:55.830 - 00:29:13.440, Speaker A: It should work. Give us feedback. I mean, GitHub is here, paper is here. You can just go ahead and try it out and you can even write some code for it if you're interested. Okay, cool. So back to the whiteboard, I guess. Let's see.
00:29:13.440 - 00:30:11.486, Speaker A: Share. Okay, right? So a couple of statistics here is how our work compares to what is already out there. I mean, full node, we cannot really compare because it's very slow, right? You need hundreds of gigabytes in days. But what we did was we created some fake chain data that mimics the real data, pretending that the chain will continue running for ten years, the Ethereum chain in particular. And then we run our light clients on that to see how it works. Right? So if you run the normal light client, which is what Ethereum has come up with, with the sync committee, which is you download all the public keys, then you need about 100 megabytes and 100 seconds to sync ten years worth of data. If you do this hash trick where you just send hashes and you find the first point of disagreement by the hashes this is brought down maybe 99%, which is great.
00:30:11.486 - 00:30:50.646, Speaker A: So this is about 1.1 megabytes and 8 seconds. And then if you want, you can run the super light construction, which gives you this kind of nice tree bisection game. And now it's just half a megabyte. Now, if you run this simulation for more than ten years, let's say 15, 2030 years, you can see how things are changing over here, right? So the live client's total communication is growing kind of linearly with the years of past data. So as time goes by, after 15 years have passed, more and more data is downloaded. If you look at the Strawman construction.
00:30:50.646 - 00:31:30.614, Speaker A: Well, when I say strawman here, I mean the hashes. And then superlite client is the bisection game. So all of this is captured in this little piece of area, right? And then this is this graph. So here again, you can see the hashes work really fast, but it still grows with time. Whereas if you play the bisection game, it doesn't matter how long the system has been running, it's all just like half a second per game or something, right? And then you run maybe multiple games in this tournament format, so it might take you 8 seconds. But no matter how long the lifetime of the system is, it's super fast. And I guess, I mean, after 15 years, we'll probably put a checkpoint in Ethereum, so it doesn't matter that much.
00:31:30.614 - 00:31:50.110, Speaker A: But from a theoretical point of view, it's kind of interesting that we can do that, and it doesn't matter how long things have been going. So, yeah, we have this website. You can try it on for Ethereum. It should work and you can contribute. It's all open source. And then, yeah, the paper is here. You can scan this barcode.
00:31:50.110 - 00:32:10.920, Speaker A: It's all there. It's an easy paper, I'd say. It's so super mathy if you skip the proof parts that are in the appendix, it's super easy to read and has some nice graphs, and it explains the construction in more detail. It also generalizes beyond Ethereum. So, yeah, that's pretty much it. And yeah, we have plenty of time for questions, I think.
00:32:24.880 - 00:32:26.270, Speaker B: Josh, do you have a question?
00:32:30.480 - 00:33:05.368, Speaker C: You're muted if you're talking. All right, he's gone a rogue. I have a question, actually. I know you haven't talked much about anything ZK related to this. I know that other networks have attempted to create similar features. I think Cello has this thing called plumo or something like that. And I know Coda obviously has their recursive snarky instead, I guess I'm wondering what your thoughts are if you believe there's a preference in what is better.
00:33:05.368 - 00:33:18.590, Speaker C: Is it better that we just have this simple signature scheme and can use that, as opposed to having some crazy recursive snarking thing where you have to implement the entire chain logic potentially inside of this snark? Curious what your thoughts are, right?
00:33:19.200 - 00:33:42.544, Speaker A: Yeah, that's a great question. So I think long term ZK is very promising. Maybe two years down the line, maybe some life clients will be ZK enabled. Let's see. There's a few advantages, actually, to ZK. It's constant computation time, so the verifier doesn't have to look even at logarithmic data. And then the interactions is just like one interaction.
00:33:42.544 - 00:34:14.320, Speaker A: You just ask for it, you get it. So you don't do all this game of interactions. That's one advantage of ZK. The other ZK advantage is that even if you're connected to a faulty node, they cannot give you a history that is invalid. So they can give you history that is stale, but they cannot give you a history that is invalid. Whereas in this construction, if all of your network is compromised and you're eclipsed, you can actually be lied to because you will not find the first point of disagreement, which is a pity. Right? So ZK has these advantages, and I think that makes it better in this aspect.
00:34:14.320 - 00:35:13.084, Speaker A: As for whether it's deployable right now, as you mentioned, like plumo, mina, coda, all these constructions, they have blockchains that are tailored to be ZK compatible, which makes proving somewhat more efficient as compared to, let's say, ethereum for Ethereum, or for other deployed systems. It is very hard to make these proofs, not because of engineering, but because the prover time is really forbidding. Right. So we run some experiments on, well, the state of the art kind of way of proving Ethereum using ZK is a paper called ZK Bridge by Dan Bonet and so on. And we try to reproduce their experiments. And what we're looking at in terms of prover cost is about, well, it's in the tens of millions of dollars per year to operate, let's say. So this is both for Ethereum, it's for Cosmos, which is a much simpler ecosystem.
00:35:13.084 - 00:35:53.020, Speaker A: You just have like 100 validators. And this is just for the sync committee, right? If you want to do the full validator set, this is completely impossible right now. But, yeah, we also use a sync committee here, but this thing is much, much more efficient. Right? If you want to run approver here, you need less than $1,000 per year. So we're talking about, like, a factor of 1000, at least, maybe 10,000. Now, my personal estimate is that right now, if you want to run ZK on Ethereum and you paralyze it very efficiently, it's going to be about $40 million per year to operate these provers. One advantage of running these provers is that you only need to do it once.
00:35:53.020 - 00:36:22.360, Speaker A: You don't need multiple provers. If you have one prover, you can take this proof and replay it. Once it's computed, it's good, and you can send it and it can be consumed, and you don't need to compute it again. Right? So you don't need, like, a whole network of provers. As long as you have two, and one of them is honest, or one, and one of them is honest, it's all fine. If one of them stops operating, we will know and we can spin up another one. Whereas for this network of light client provers, for the bisection game, you need, like, a whole network that they remain online.
00:36:22.360 - 00:37:01.652, Speaker A: You can talk to them, but then their cost of operation is really cheap. They just need to run a full node and answer your questions on the Mercot tree. As for implementation, on the engineering side, right now, like ZK, libraries are not super mature. It's a very fast evolving ecosystem. I think it's pretty complicated to implement these things. But this will not be the case down the line in, like, two years, in the same way that we don't have to ever implement our hash functions or our signature schemes, all these are nicely packed into libraries. I think we will have the same core zero knowledge in a couple of years down the line, and then we'll talk again and maybe we'll see more adoption of this.
00:37:01.652 - 00:37:53.114, Speaker A: I'm hoping that we can get ZK to do this. Yeah, I'm hopeful. I think with some improvements on the science and with some improvement on the engineering side, it will be a very reasonable solution. Okay, well, if there's no more questions, let me ask a question to you guys. Can we build a light client which has this kind of efficiency for avalanche? And also, what's the protocol, guys, that you're running? We don't know. There's the paper. Most of it is documented, but the current version, I think, is kind of undocumented.
00:37:53.114 - 00:38:02.050, Speaker A: It would be nice to have these a little bit more documented so we can work on things like this and make light clients for avalanche as well. Do you have a light client. What is this efficiency?
00:38:03.670 - 00:38:42.130, Speaker C: Yeah, I can chat about this, or Steven, I don't know if you want to take the lead on the response here. I don't know if you're at your desk. He is not at his desk. Yeah, great question. So I think one of the big things that makes like efficient on the network complexity side, I guess, is that we don't actually end up aggregating signatures per block anywhere. And I'll let Steven chime in after the. There is no signature or group of signatures or anything like that attached per block.
00:38:42.130 - 00:39:41.710, Speaker C: Now I think Ethereum has this notion of the signatures are actually in the header because they're rewarded and whatever like that. But we do actually have BLS multi signatures. They're not used on the primary network for anything like this yet. But what we would like to do is, and we actually have implemented this. Well, not me, but Stephen and Dan implemented this, is creating these periodic acceptance proofs of state on the primary network where basically a group of the network, or really all of it just basically gossips a BLS signature of their last accepted block or periodically accepted blocks that you could then use per chain to actually do something exactly like this. Now the difference I think is maybe exactly how you do this handover function between different things. I think that there's more complexity there because you have multiple chains kind of going on.
00:39:41.710 - 00:40:33.890, Speaker C: But the idea really where it fits in now is that we have this cross subnet messaging protocol. So subnets are these blockchains on avalanche, and they also have BLS multisignatures. And so we have this periodic proof mechanism that we could use that are just generated signatures of some sort of state. And then ideally light clients in the future will basically just read these BLS multisignatures with some form of like a state transition of validators that is also signed by that group. And then you could have clients throughout everything without requiring web browsers or something like that to sample. Now the difference here is it really becomes two processes, which is sampling on avalanche continues like it does. But then from there you have those participants actually produce some sort of signature attesting to the accepted state.
00:40:33.890 - 00:41:05.790, Speaker C: And then maybe there's some sort of incentive there where if you sign the wrong route or something like that, or like sign conflicting routes, you get penalized in some way or something like that. So long story short, we have a path to get to something that I think is really compatible with this. And we already have the cryptography deployed. We just need more validators on the network to adopt and register BLS key, which will happen soon because the next staking transaction type will mandate. Yeah. Steven?
00:41:06.290 - 00:41:48.474, Speaker D: Yeah, I think the probably more concise way to say it is like avalanche consensus doesn't require public key infrastructure, it requires authenticated channels. And so there is not an implicit client cert produced by the consensus process. And so it's probably not going to be super easy to map the logic of the sync committee logic over. But what you could definitely do is have a secondary process that produces that client certificate, and we're actively looking into the best way to do that. And then once you have the client.
00:41:48.522 - 00:41:49.680, Speaker A: Certificate, then.
00:41:51.410 - 00:42:12.398, Speaker D: As we've already talked about here, there's a number of different mechanisms for how you could either use your hash based challenge approach or like a ZK thing, or any number of alternatives for doing that. Just kind of picking whichever one matches your security assumptions and performance requirements in.
00:42:12.424 - 00:42:34.140, Speaker C: Terms of better specifying what's going on on chain. We definitely are working on that, and we're working with some more researchers lately, I think you know, Andy Lewis, PI we're working with on some kind of more consensus formalization. We're also working with the folks at Uni burn with christian cushions group on publishing more research.
00:42:34.590 - 00:42:39.260, Speaker A: Christian is right here, actually. He's visiting Stanford these days. Oh, there you go.
00:42:40.110 - 00:43:25.500, Speaker C: Tell him hi. They're doing some research into more theoretical, I think, better proofs of actual consensus processes that are running and then potentially suggestions for what could change with it or how efficiency could be improved. So I know his group is working on that. So you could definitely ask him for some sort of update on what they've been thinking about. But yeah, I think that's if you have any suggestions, as well as better ways to engage your guys'research community, we also are interested in that, obviously, and so if there's better ways we can get involved or like things that are clearly missing, it sounds like a clear specification here, maybe a starting point. We'd love to know.
00:43:27.550 - 00:43:34.320, Speaker A: Okay, yeah, let me think about that and get back to you. But thanks for the answers. Yeah, that clarifies a lot of things. Great.
00:43:37.090 - 00:43:52.920, Speaker C: My other question for you is, actually, have any of the wallets expressed interest in actually integrating this and getting proofs off of either state for balances or logs or transaction inclusion or anything like that?
00:43:54.570 - 00:44:29.114, Speaker A: Yeah, there's a bunch of directions. We actually have a metamask pull request where we embed it into metamask itself. There's been some interest by some metamask people, but I don't think they're going to merge in after all. They're a bit conservative. They have this kind of modularity available to the new versions of metamask where you can build modules that it's like extensions, I guess, which allow you to interact with a wallet. The current infrastructure, these extensions. Snaps.
00:44:29.114 - 00:45:06.650, Speaker A: Exactly. Yeah. Sadly, the way that the API snaps works right now doesn't allow us to have access to the network layer to be able to do these things. So we're kind of talking to them to try to see if we can get some more features available to snap so that we can make it into snap, so that it doesn't have to be merged into the main thing. So that's it for metamask. Other than that, we've been talking to a bunch of smaller wallets, both on ethereum and then on a bunch of different chains. One interest is also on the application of these kind of technologies to verifying l two.
00:45:06.650 - 00:45:56.774, Speaker A: So, like optimistic roll ups, you can do something similar, like. Yeah, for example, you could maybe make something like an arbitrum and so on. And then there's some interest from Cosmos, like, for example, Celestia Axelr and so on, to maybe have a likeline for tendermint, which works in this fashion. This should be even simpler than Ethereum. So we're looking into that, and then there's a few forks of Ethereum, like the gnosis chain, that have expressed interest, but nobody really has deployed this in production. All of these are just small experiments that we're doing between ourselves and small number of servers. I think Kevlar has a couple actual users that are interested in this, but nothing beyond the hardcore people that are interested in light clients.
00:45:56.774 - 00:45:59.760, Speaker A: So it's just an experiment for now. Yeah, nothing. Production ready?
00:46:01.410 - 00:46:07.280, Speaker C: Yeah, I think we have a collection of opened and unmerited prs on the metamask front as well.
00:46:09.350 - 00:46:25.308, Speaker A: Yeah, they're a little bit reluctant to accept external it.
00:46:25.414 - 00:46:32.080, Speaker C: Cool. Anyone else have anything?
00:46:36.880 - 00:46:41.010, Speaker A: If that's all, then maybe we can wrap it up here. Sam, any more questions?
00:46:42.980 - 00:46:53.156, Speaker B: I actually did have a question, so I wanted to know a little bit more about the overhead on the provers. So if you go back to the tournament kind of slide that you were.
00:46:53.178 - 00:46:53.750, Speaker C: On.
00:46:57.320 - 00:47:05.456, Speaker B: This requires the provers, which are like the full nodes, to interact with each other. Is that.
00:47:05.578 - 00:47:37.248, Speaker A: No, this is the picture. I think the picture might be a bit misleading. So what is happening is that the verifier is connected to all the poors, and then he draws this kind of picture. Right? So he starts here and he's like, okay, I'm going to play this guy against that guy. So then what he does is he connects to this guy. He connects to that guy. He starts by requesting the merkle tree roots from everybody, and then he lumps them into groups that are in agreement with each other.
00:47:37.248 - 00:48:00.112, Speaker A: And then if people are in disagreement, he's going to say, okay, I'm going to take you and I'm going to take you. I'm going to play you against each other. And if one of you is honest, they're going to win. Right? And then I'm going to take the winner. But the verifier always has to be the mediator of this process, because if two provers are at Rosario, if a prover is at Rosario, he might just claim that he's playing the game. But the honest guy is like, left hanging. Right.
00:48:00.112 - 00:48:09.630, Speaker A: So you definitely need to be standing in the middle in this network. It's kind of a data availability issue where you cannot really prove that the other person did not play the game. Yeah, good question.
00:48:10.480 - 00:48:11.420, Speaker B: Sweet.
00:48:14.640 - 00:48:25.760, Speaker C: Jacob, when you calculated the cost, you said that it costs like $45 million to run this on Ethereum. How was that cost exactly calculated?
00:48:27.460 - 00:48:40.868, Speaker A: Yeah. So maybe I can. Let's see. Right. So should be up to date.
00:48:41.034 - 00:48:42.004, Speaker C: All right.
00:48:42.202 - 00:48:54.552, Speaker A: I think it was called. Yeah. Okay, let's look at the latest version of the paper. This is not public yet. We have a couple of changes here. All right. Sorry, I'm not sharing my screen.
00:48:54.552 - 00:49:10.872, Speaker A: Yeah, that was silly. Let's see. Okay, let's try this. You should be seeing my screen. Yeah. Okay. Right.
00:49:10.872 - 00:49:40.436, Speaker A: So this is the latest version of the paper that is not up yet. I can share this draft with you. The version on eprint is a little bit older. So in the related work section, we have this comparison, and there's this bunch of stark, stark constructions. And the most promising that we found is this construction called ZK bridge. So if you look at their paper, they have some estimates, and we kind of run the numbers here. So it's all in this footnote.
00:49:40.436 - 00:50:32.440, Speaker A: So in this kind of section six of this paper, they're using the 128 validators on one cosmos block, and they're trying to prove it by, well, you need to run like 32 instances of this Amazon very bulky server, and it takes 18 seconds. According to their claims, they're not open source, so we cannot really reproduce everything, but we just run the numbers back off the envelope based on what they have on the paper. So in Cosmos, they have a rate of about one block per second. Some chains have more. I mean, cosmos consists of many zones, but that's maybe a usual block time. So you need this many servers to be continuously operating. And then this is the type of instance that you need in order to run these ZK proofs that are quite bulky.
00:50:32.440 - 00:51:30.992, Speaker A: So the innovation in the ZK bridge paper is that they actually can parallelize this into 18 times 32. Instead of having one huge, huge server that could never exist even with this amount of rAm, they split it up, but they need to be parallelized. And then the output of these servers are collected by kind of an aggregator approver that collects these intermediate proofs and makes a bigger proof. And yeah, this is the cost on Amazon AWS. If you look at the particular region here, which we looked at pricing on in June, and then you may be able to do it on Hetzner, which is a much cheaper alternative, it might be like ten times cheaper. However, their experiments on this paper are using Amazon, which I don't really know why, I don't know if they were able to reproduce in Hepsner, but what they report is Amazon AWS experiments. And then in Ethereum, you may be able to do it for the sync committee.
00:51:30.992 - 00:51:59.556, Speaker A: You might be able to do it with half a million if you change the numbers a little bit. But this paper is really state of the art, and we don't really have any code for this to run. So it's only the original ZK bridge team that can reproduce these. And this is super optimized. So if we run it in kind of older ZK systems, it might even be much more expensive. So that's kind of roughly where we got these numbers from.
00:51:59.738 - 00:52:04.070, Speaker C: I dropped the link to that paper in the comments as well. The Zkbridge paper.
00:52:05.080 - 00:52:18.970, Speaker A: Nice. Yeah. So if you look at the last section six, there's some experiments there. They report the cost of running in Hetzner, but their experiments are actually undertaken in Amazon AWS. So you need to do a little bit of adjustment to find them.
00:52:21.420 - 00:52:22.904, Speaker C: You get kicked off Hetzner.
00:52:22.952 - 00:52:23.116, Speaker A: Right.
00:52:23.138 - 00:52:24.590, Speaker C: That's why they probably don't do.
00:52:25.520 - 00:52:50.084, Speaker A: That's one reason. Don't know. I don't know. Hetzner is a little bit antagonistic to cryptocurrencies, especially with mining. I think if you run like proof of stake stuff, they're still okay. By the way, I can also send you the latest draft of the paper that we have. There's one which is uploaded, which is what I linked to in the QR code, but I can also share.
00:52:50.084 - 00:52:58.440, Speaker A: I can send us the latest draft so you can read also the comparisons against the Kbridge, which is a newer paper from ours.
00:52:58.940 - 00:53:37.956, Speaker C: Yeah. I think on our research side, the summary is like, we believe that we're vastly underutilizing some of the on chain cryptography that we have. For example, I think this challenge is one of the biggest pain points to me about actually using crypto right now is that we all talk about this crazy, decentralized world of everything, but then when it comes down to actually using the chain, forget we said anything, right? Like, you just hook up the servers like you would be otherwise. It's not even like anyone even checks multiple sources, right? It's just like, you connect to one RPC, and that's your truth. Right, right.
00:53:38.058 - 00:53:49.048, Speaker A: One very simple thing you could do in the wallet. Right, exactly. Is like, you can connect to just two rpcs run by different companies, and then if they disagree, you can just raise the alarm. Right. That's a very simple thing. You can do it. Nobody's doing it.
00:53:49.048 - 00:54:05.630, Speaker A: You don't need fancy crypto for this thing, and it would help tremendously towards a more decentralized world. So that's like a very simple step. We don't need all this fancy, either ZK or even, like, these simpler hash and signature protocols. It's just like two connections. Why not?
00:54:06.480 - 00:54:22.308, Speaker C: Yeah, I mean, I think these are the sort of things that we have our own wallet, actually called core. And as that gets a little bit more stable, it's newer, so we're still catching up on a lot of the functionality of metamask or some other stuff. This would be a fun way to differentiate ourselves, I think.
00:54:22.474 - 00:54:36.004, Speaker A: Yeah, I think that would be amazing, even engineering wise, I guess adding a new connection doesn't require moon math or any very fancy crypto, so it would be a good selling point.
00:54:36.202 - 00:54:47.560, Speaker C: Yeah. People today just hook it up to their own node, and then it's like, all right, well, that's the RPC security that I need, right? 99.99% of people, they're like, what do you mean? Run my node?
00:54:48.160 - 00:54:51.100, Speaker A: Exactly right. Like I need a server on my basement.
00:54:52.480 - 00:54:56.204, Speaker B: Sweet. Well, thanks for coming, Denise. That was awesome.
00:54:56.242 - 00:55:10.370, Speaker A: Yeah, thanks, Sam, for the invitation. This was really a pleasure to see you again and to be here and to meet all this team. Wonderful. Yeah. Thank you so much for taking the time also to be here today, everyone.
00:55:12.040 - 00:55:28.480, Speaker C: Thanks for coming. See you soon. See you. There's.

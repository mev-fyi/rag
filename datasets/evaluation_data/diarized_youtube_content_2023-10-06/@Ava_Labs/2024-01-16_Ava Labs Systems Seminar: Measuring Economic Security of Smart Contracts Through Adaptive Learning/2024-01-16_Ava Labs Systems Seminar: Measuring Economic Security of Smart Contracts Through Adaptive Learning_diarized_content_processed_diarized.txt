00:00:10.330 - 00:00:31.960, Speaker A: Thanks very much for joining us today. We know each other from Connell Tech, and actually I worked for a little while on the project you're going to present today. I think so. Very, very excited to see that and very glad to have you join us today. So, yeah, whenever you're ready, feel free to start, and we're very excited to have you.
00:00:32.970 - 00:01:26.450, Speaker B: Great. Yeah, thanks, Martin, for inviting me. I'll present our work on Lantern, which is a tool for measuring crypto economic security of smart contracts. And as Martin mentioned, Martin also collaborated on this project to make it more user friendly and so on. So let me start with the presentation, and feel free to interrupt me if you have any questions. All right, so this tool is based on adaptive learning, and I'll introduce some aspects of it, but the focus of the tool is to measure crypto economic security of smart contracts. And so, as we know that smart contract security is, to put it mildly, in shambles, routine multimillion dollar hacks are kind of not even making news anymore.
00:01:26.450 - 00:02:36.634, Speaker B: And one of the main reasons for these hacks is that the composition between contracts has gotten quite complex. And this is kind of helped along by the fact that these contracts can interoperate very easily. So, for example, lending contracts can use decentralized exchanges as price oracles, and even multiple decks contracts can be aggregated together in the form of these routing contracts and so on. And of course, when you have flash loans that interact with decentralized exchanges or lending contracts, they kind of break the crypto economic assumptions of these other contracts. This is one issue which I think exacerbates the problem of crypto economic security of smart contracts. And the second issue which exacerbates this is this notion of MEV, which broadly defined as an ability of a miner or a validator to extract value by either reordering, inserting, or censoring transactions. So the insight for this talk is we can use MEV as the measure of economic security because in some sense, miners or Validators are the most privileged actors in the ecosystem.
00:02:36.634 - 00:03:28.000, Speaker B: Now, while they can't do extraction, that's kind of know permission. So, for example, if you have, say, permissioned access to some oracle feeds or something, maybe that's not covered in here. But still, MEV in some sense represents the worst case adversely advantage. So we'll use MEV as the measure of economic security for the purposes of this talk. And so the question is, how do we even measure Mev and potentially discover even new MeV strategies that have not been seen in the wild? I'll touch upon some of the potentially interesting new MEV strategies that we discover using the tool. But this is the broad question that we are trying to answer here. So, to give you just an overview of the problem, assume that you have a pool of user transactions and a set of possibly composable smart contracts and the current blockchain state.
00:03:28.000 - 00:04:13.930, Speaker B: The problem is to maximize the validator's extractable value, and the strategies or the degrees of freedom that you have is potentially reordering the transactions that are available from the users or potentially inserting new transactions from the validator. Now, prior approaches that have dealt with this problem can be categorized into two buckets. The first one is what I call heuristics based. So these approaches kind of encode a specific attack strategy. So they are essentially looking for patterns such as sandwiches or arbitrage and so on in transaction data or blockchain state. And these approaches are kind of efficient at finding these patterns. So they are essentially looking for these simple patterns.
00:04:13.930 - 00:05:29.074, Speaker B: But of course, these approaches are not generalizable to either new contracts or new transaction types, because these approaches are not really looking for identifying the worst case behavior by a minor or validator. They're essentially looking for just these specific patterns. So as a result, these approaches are not attempting to find the worst case adversely advantage, whereas the second kind of approaches in this category is formal methods based. For example, this tool called clockwork finance that we also worked on at Cornell, and this was presented at SNP earlier this year. So this kind of approach leverages formal verification to find the optimal value of the inserted transactions and the optimal order of the transactions available from the users in order to maximize MVV. So the broad kind of perspective that these approaches take is they are kind of trying to model the worst case adversely advantage and in some sense discover the maximal ev that a miner can make by reordering or censoring transactions or inserting new transactions. But of course, a drawback of these approaches is while they are generalizable, they don't scale to more complex contracts or even strategies that span multiple transactions.
00:05:29.074 - 00:06:21.430, Speaker B: Say for example, when transactions are more than ten tools such as clockwork finance, that's too much for them to handle. And even contracts such as curve finance, which has loops in them. It becomes hard to analyze contracts which have loops through a formal verification approach. And so, as a summary, these approaches are either efficient but not generic, or these approaches are either generic but not scalable. But Lantern bridges this gap. So lantern is a generic and scalable learning based tool to find mev opportunities given you have some user transactions available and some potentially composable smart contracts. Now, generalizability and scalability are two important properties of Lantern, but let me introduce you to some other properties of lantern as well.
00:06:21.430 - 00:07:11.430, Speaker B: So besides generalizability, one other property that is quite neat in practice is it has native smart contract execution. So what I mean by that is basically we are not translating smart contracts into, say, simpler models. So, for example, the heuristic based strategy would probably just translate smart contract behavior, such as uniswap, as just going from one node to another node in the graph or something like that. Or even formal methods based tools translate the smart contracts into simpler models. But this approach has native smart contract execution in that we are dealing with smart contracts as just black box environments. So we treat the smart contracts as black box environments. And as a result, whatever strategies that are output by lantern are directly executable against this bytecode.
00:07:11.430 - 00:07:56.706, Speaker B: And as I mentioned, lantern is scalable. So we can deal with complex smart contracts. Even contracts that have loops in them are okay because we are not kind of doing some program analysis or some fancy formal verification. But we are dealing with these smart contracts as black box. So even complex smart contracts or contracts or strategies that have, say, span over large number of transactions, such as more than 50 user transactions, or even strategies that involve more than ten insertions by the validator, they are also okay for lantern to explore. And finally, it turns out that in practice, the tools should be adaptable to computational budget. So it should not be the case that it's either zero or one given the resources that you have.
00:07:56.706 - 00:08:35.300, Speaker B: And so what lantern does is as you provide more and more servers to it, it is paralyzable. So it can adapt to the resources that you have available. And also it can adapt to the time budget that you have available. So you can preempt the tool early enough and you'll discover the MEV or the strategies until that point. But if you let the tool run for longer, it will keep improving and give you higher and higher values of mev. So I just want to give a quick pause here to see if there are any broad questions around the approach, and then I'll talk more about the approach. Okay.
00:08:37.670 - 00:08:51.560, Speaker A: So I remember when I worked on the project. So, for the native smart contract execution, what runtime are you using? What environment are you leveraging for the smart contract execution by now?
00:08:52.330 - 00:09:43.426, Speaker B: Right. So the runtime that we have is a fork of the main net, which is supported by the. In our examples, in our evaluation, we are dealing mostly with ethereum at least for those evaluations, the runtime is basically a fork that is supported by hard hat and an Arigon archive node. So Aragon archive node kind of gives you all the historical state that you need, and hard hat kind of supports the forking of the main net from a particular point. So, our evaluations are based on historical data. We are not running the tool in real time. I'll talk more about real time usage of the tool, but at least for our evaluations, we were dealing with past blocks.
00:09:43.426 - 00:10:42.910, Speaker B: And so we were able to basically fork the main net at a particular point in history and then conduct our experiments on that forked state, which was supported by both Hardat and Arigorn. All right, so as I mentioned, this tool is learning based, more specifically, adaptive learning. And so the tool has these two modules, as you can see. One is the learning based optimization module and one is the simulation environment. Both these modules together kind of take the user transactions that are available and the blockchain state. And both these modules work in concert with each other. So the learning module will basically kind of sample a concrete transaction sequence to be simulated, and the simulation environment will simulate this transaction sequence and give the feedback of what was the value that was extracted by the validator in this particular transaction sequence.
00:10:42.910 - 00:11:44.242, Speaker B: And so these modules kind of work in tandem with each other, and the learning module will learn from the feedback of the simulation environment. And we do multiple iterations of this. And as a result, after you have that sufficient number of iterations, you can output what was the optimal transaction sequence and what was the optimal value that was extracted by the validator in all these iterations. So, as I mentioned, the action space that is available for the learning module is either it can reorder the transactions that is available from the users, or it can insert new transactions. Now, you must be thinking like inserting new transactions is quite tricky, right? Because in general, when you insert new transactions, you can have very complicated behavior. So you can even create new smart contracts by inserting new transactions and so on. So we kind of limit this search space for the learning module by having templates of transactions that you can insert.
00:11:44.242 - 00:12:20.778, Speaker B: So for example, this is one template that works on amms. So this template says swap alpha zero, token zero with alpha one, token one. Here, alpha zero and alpha one are kind of the variables of the optimization. So the module will try to find out what is the right value for alpha zero and alpha one. But it will do insertions of this form. So we don't allow arbitrary insertions, but insertions which are following this particular template. And so as a result, for a particular smart contract, you can kind of craft the templates that you think are beneficial for any mev activity.
00:12:20.778 - 00:13:37.206, Speaker B: So if you have Amm contracts, you can craft templates like these. If you have, say, lending contracts, as we do in our evaluation, you can actually craft templates where you're topping up collateral, you're probably liquidating positions and so on. So these are just basically actions that you can do with the contract, but it's kind of necessary for the learning module to guide its exploration. These are the action space reordering of user transactions and inserting new transactions that follow certain given templates to the learning module. All right, so the goal of the learning module here is to basically find the sample transaction, sample sequence, which maximizes a particular function f, which is the validator's extracted value in this particular transaction sequence. And why are we doing it empirically? Because, well, we don't have any analytical solution as to what is the maximum value that can be extracted given some black box smart contracts. And so this exploration is empirical in the sense that we are relying on the accurate simulations of these transaction sequences to get what is the estimate of the value that's extracted from this transaction sequence.
00:13:37.206 - 00:14:43.950, Speaker B: And we do this exploration empirically and find out what was the maximum value that was extracted by the validator. So at least in our evaluations, we find that this empirical exploration that's guided by this learning based algorithm is able to perform quite well in practice. And so just to give you a sneak peek into the system, you have a given block height edge that kind of specifies the state of the blockchain. You have a sequence of concrete transactions that's given to the simulation module. And the simulation module just returns what's the value that was extracted from this sequence of concrete transactions. And as I was discussing about the runtime environment, the simulation module will basically spawn a runtime environment using hard hat and arigon, at least for our evaluations, and run this particular sequence of concrete transactions and give you the value that was extracted in these transactions. There are some details here around simulation that I can go into.
00:14:43.950 - 00:15:35.274, Speaker B: For example, if you are forking off a blockchain state and the validator or the miner has a fresh account, you kind of need to have approvals for transferring tokens from uniswap contract or other contracts. And you need to kind of do some setup every time you do this. But those are some details that we can ignore for now. And let me now talk a little bit about the learning module. So the learning module basically receives these user transactions and the templates, and its job is to basically sample transaction sequences and output the maximal extracted value that it has seen so far. And also what was the sequence of transactions that allowed it to extract that value. And so the sequence of transactions that it outputs is what we call a strategy, quote unquote strategy output by lantern.
00:15:35.274 - 00:16:23.082, Speaker B: So this sequence of transactions is basically directly executable on chain as is. So you do the simulation and learn from these simulations, and as a result, at the end when the transaction sequences are output, those are directly executable on the main net. Let me not go into the details of the learning module just yet. We can come back to it if we have time. But the simulation module basically just folks the blockchain at a particular height edge executes these transactions. And finally, because you want one scalar value of what was the value that was extracted, it kind of converts all the non native tokens. In our evaluation, we are dealing with EtH.
00:16:23.082 - 00:17:30.274, Speaker B: So it kind of collects all the non eth tokens and then sells them on either any dexes or any centralized exchanges to get what was the final equivalent value in ETH. Now, we are of course not selling these tokens in our experiments on a centralized exchanges. And so here the assumption is we have the prices from binance, like the minutely fine grained prices from binance, and we use those prices to say what was the equivalent value of Eth that was extracted from these tokens? Assuming no sleepage on binance, but on Dexs, it faithfully simulates these swaps back to Eth and gives you the final value of equivalent value of Eth that was extracted. And of course this is just for our evaluations. If you shift to any other blockchain, you can get an equivalent value either in avex or any other token of your choice. All right, so just to give you a high level overview of what the learning module is doing here. So the learning module has this objective function f, which is the value ev, but it has some design variables that is trying to optimize over.
00:17:30.274 - 00:18:24.626, Speaker B: So the first design variable is order of transactions, and the second is what are the values inside these template insertions that you are doing? So, as I mentioned, there was this template swapping alpha zero tokens to alpha one token. So alpha zero and alpha one are kind of the variables of the optimization that this model is trying to optimize over. And the other variables of optimization are of course the order of transactions and so on. We also have some bound for these optimization to make the search space exploration quicker. So if you know that maybe the miner or the validator will not need to, say, swap more than a million dollars to extract meaningful amounts of EV, you can actually bound the search space quite well using optimization bounds. And so a very high level sketch of the algorithm. I would encourage you to go look at the paper.
00:18:24.626 - 00:19:41.130, Speaker B: I'll keep this talk a little bit on the short side. So if you are interested, you can have a look at the paper for more details of the algorithms, but at a very 10,000ft overview of the algorithm, abstracting out all the details is just a very simple algorithm where you're initializing a random distribution initially and you're iterating for a given number of iterations, one to n, and you sample from this distribution. So this distribution is over the variables of the optimization, namely the order of the transactions and the values of the insertions that the miner is doing. And so you sample from this distribution, you send it to the simulation environment to evaluate what is the value that was extracted from this particular sample. So this sample is basically a concrete sequence of transactions, right? This sample is saying what is the order of the transactions and what is the value of the variables inside the insertions that I'm doing. So as a result, you get a concrete sequence of transactions, you simulate that and you get, what were the samples that maximized my ev? And you update the distribution to be a little bit biased towards the good samples. So the samples that give you higher ev, you kind of shift your distribution to explore around those good samples.
00:19:41.130 - 00:20:15.210, Speaker B: And you keep doing this. And hopefully at the end of any iterations, you encounter many good samples that are giving you higher ev. So it's kind of like a pattern of exploration and exploitation that's going on here. So you kind of explore different regions of the search space and whichever regions are good in terms of EV, you try to kind of bias your distribution towards the good samples and then exploit those regions to get good transaction sequences.
00:20:17.230 - 00:20:21.110, Speaker A: Are you okay with taking questions during the presentation?
00:20:21.270 - 00:20:26.694, Speaker B: Yeah, that's totally okay. So just shoot away just real quick.
00:20:26.832 - 00:21:09.820, Speaker C: When you update the sampling distribution, there's kind of say you're in your first round, right? If you hyper change the distribution to really focus in on the best result, then you can run into some local minimum or local maximum issues. But also if you don't bias it enough, then you kind of aren't really making a huge amount of progress. So how does the strength of how much you're biasing the distribution relate to what n is and is there like a relationship between how you handle that? I'm just interested in how you think about that.
00:21:10.590 - 00:21:57.260, Speaker B: Right? Yeah, that's an excellent question. So I was not going to go into the details of it, but it's actually good that you asked this question. So these exploration exploitation kind of routines, or the algorithm routines, they have this kind of random teleportation that's built into them. Exactly. In order to avoid problems like getting stuck in a local maxima region. When you update the distribution to be biased towards the good samples, the distribution really is this bias distribution plus still some random component in the distribution. So the distribution still allows you to teleport to some random region, just like the page rank algorithm and so on.
00:21:57.260 - 00:22:47.578, Speaker B: You still have the freedom of escaping that local maxima region with some probability, and with some probability you are exploiting that region. So this distribution really is a composite distribution. And just in the next slide, actually, maybe I should just switch to the next slide. So, as you can see here, this is the distribution for a very simple optimization problem that we encounter, which has just two variables. But the important thing to note here is basically the black triangles. Here are the good samples, the light blue dots are the gaussian samples that we have. So the distribution is basically saying that around these black triangles, which are the good samples, I'm going to sample around them in a gaussian way.
00:22:47.578 - 00:23:31.890, Speaker B: But there are also some random distributions. So the green rhombus or the green square that you see, those are the uniform kind of the uniform part of the distribution. So you are still sampling around the black triangles, but you are also sampling randomly as well, sometimes, which are denoted by the green rhombus here. So it's a mix of both and going more into the details of the algorithm. Yes. That is influenced by how early or how late you are in your iteration. So when n equals one, or when you're in the second or the first iteration, you are really still not very much biased towards the good samples.
00:23:31.890 - 00:23:56.320, Speaker B: And so the probability of the random teleportation is high, but towards the late cycle, you do have high kind of exploitation happening and very less exploitation happening. And how much, that is a matter of hyperparameter tuning. But yes, that aspect is there. Does that make sense?
00:23:57.170 - 00:23:58.350, Speaker C: Yeah, thanks.
00:23:58.500 - 00:24:29.766, Speaker B: Okay. Right, so this is just an example. I didn't even introduce the optimization problem that this distribution is trying to solve, but it still gives you an idea of this composite nature of the distribution. So this distribution is talking about sampling real values. So sampling two real variables here, represented by the x and the y axis. So these variables are basically appearing in the insertion template. So alpha zero and alpha one were real variables.
00:24:29.766 - 00:25:10.946, Speaker B: So swapping some real number of tokens to some real number of tokens. Right. So these are real numbers. But we also recall have another variable of optimization, which is just the order of transactions. And so now how do we do sampling from an order of transactions? And how do we kind of bias our distribution towards the good samples? This is just a very brief visual picture of it. I can go into more details if there's interest, but the very high level overview is each node in this graph that you see. Each node represents a concrete sequence of transactions or a concrete order of transactions.
00:25:10.946 - 00:25:39.382, Speaker B: So for example, this particular node says that the order of transactions should be u one u one, m one u two. M two, u one are the user transactions. So two transactions from the user one, another transaction from user two. And m one m two are just the insertions from the minor. Right? So this is a concrete order of transactions. There's another order of transactions that's possible, where the minor's transactions are at the end. That's this particular node.
00:25:39.382 - 00:26:39.860, Speaker B: So each of these nodes are kind of samples from this design space. And how far are these different samples depends on what is the edit distance in some sense between these two orderings. So if two orderings appear close, they are kind of related by an edge in this graph. And so the idea is when you're sampling from this graph, you are kind of sampling around a particular good sample. What that means is if you're sampling, say, this particular node here, this particular node, and suppose this is a good sample, it gives you a high ev. Then we sample around this region, and around this region means orderings that are more or less similar to this one. Right? So in some sense, the distance between these orderings when we are sampling is determined by what is the kind of the edit distance between them.
00:26:39.860 - 00:27:46.060, Speaker B: So that's the way to represent orderings in a way that you can sample from them meaningfully and also update your distributions meaningfully when they encounter a good sample. Any questions on how we are sampling? Permutations of transactions one caveat here is that you don't want to kind of have orderings where you are kind of changing orders of transactions from the same user, because as you know, the transactions from same user kind of need to be ordered through the nons that they have. So if a user has sent two transactions, you really can't reorder those transactions because those transactions need to be ordered through the nons that the user has kind of like set for them. But you can, of course, reorder transactions across users, and so we kind of do not reorder these two transactions. These two transactions, in essence, for lantern, are identical. U one and u one. There's no point in reordering them, but you can of course, reorder first user's transaction, second user's transactions, and miners insertions as well.
00:27:46.060 - 00:28:37.830, Speaker B: Okay, so this is the way we sample permutations for the learning module, and this is the way we sample all the other real numbers for the learning module. This is just a sneak peek into it. I can talk more about the details if people are interested. And so let me now talk a little bit about the evaluation. As I already hinted, we do our evaluations on ETH and looking at historical data sets, so we're not evaluating it in real time, but I'll touch upon that in a bit. So, evaluated lantern, or most popular smart contracts on ETH, Unison v three, Unison v two, sushi swap and Ave. And the data set for this is basically, we looked at the historical blocks and filtered those blocks where you have large amount of activity happening.
00:28:37.830 - 00:29:57.346, Speaker B: So more than 500 ETH being traded on sushi swap and Unisoft v two, and more than 1000 eth being traded on Unisoft v three. Or if you have some liquidations happening, on our way. And as I mentioned already, we have freely available prices from finance for getting the equivalent value in terms of ETH for our simulation. And also as a baseline, we use the flashbots data that is made public by them for how much are the bribes that are being paid by searchers to the miners or the validators. Now, recall that lantern is trying to measure how much profit a validator miner can extract from this transaction sequence, whereas the baseline is measuring how much bribes were being paid or how much, quote unquote tips were being paid from the searchers to the miners and the validators. Now, we think that this is a good baseline because for the period that we looked at, a large portion, say more than 95% of the profits were being paid as bribes to the validators or minors. Because we don't have any idea of how much profit the searchers are making, we think it's a good estimate to actually measure how much bribes they are paying to the validator or the minor, because that is an overwhelming majority of the profits that they're making.
00:29:57.346 - 00:30:38.158, Speaker B: So that's the baseline in the experiments. And also, as I mentioned, for the templates, we have the swap templates for the amms. And we have some liquidation and collateral topping templates for AAVE. So these are the templates for these particular smart contracts. The baseline is flashbots, and we use the historical data from ETH. Another caveat for the baseline is in the baseline, we see that the bots are basically exploiting users transactions and paying bribes from their profits. Whereas when we look at historical blocks, lantern also kind of reorders the bots transactions themselves.
00:30:38.158 - 00:31:30.190, Speaker B: So in some sense, Lantern has more freedom than what happened on the baseline. But the baseline is there just for a perspective on how much NDV Lantern is able to uncover. So now let me show you some graphs. So, for uniswap v two, this is the value of eth that Lantern was able to extract in our data set. And flashbots, the orange line represents how much bribes were being paid in that particular block. As I mentioned, there's no one to one comparison, but it still gives you an estimate of how much EV Lantern is able to extract in those particular blocks. Now, Lantern is able to learn the popular strategies of front running users transactions, sandwiching users transactions in order to extract value from them.
00:31:30.190 - 00:32:19.354, Speaker B: But as I hinted earlier, it is also able to learn some new strategies that I can talk about. Now, the first strategy is what we call Lazarus strategy. So the Lazarus strategy is basically around bringing a debt transaction back to life. So, for example, this particular transaction actually failed on mainnet, but what Lantern does is basically reorder this transaction to a place where it can actually succeed, but it also frontruns this transaction. So in a sense, you are bringing a failed transaction back to life, but in order to extract value from that transaction. The second strategy is what we call gas leaching strategy. So usually bots have safeguards in their transactions when they are doing mev activity.
00:32:19.354 - 00:33:24.390, Speaker B: So that even if a validators are not supposed to, at least under the social contract of flash bots and whatnot, they are not allowed to kind of reorder bots transactions, so to say, unbundle their transactions. But bots still have safeguards in their transactions, so that if their transactions do not land at the right place, they are not at a loss. But some bots actually don't have these safeguards. And so this particular bot, which is by any means a very active bot, which has 400,000 transactions on the main net, this bot does not have this safeguard. And we notice that whenever you kind of reorder these transactions of this bot, even a little bit, this bot ends up paying a lot of transaction fees to the validator and that's because the bot already has a high gas price in order to compete in the MeB auction. But also, this bot runs into an infinite loop whenever you reorder its transactions. And so as a result, it ends up paying large amounts of transaction fees to the validator.
00:33:24.390 - 00:34:08.766, Speaker B: That's interesting. It usually doesn't happen because validators are afraid of being kicked out by the flashbot's social contract or whatnot. But nevertheless, these kind of vulnerabilities do exist even in bots smart contracts. And so we also evaluated Lantern on unisoft v three. This is again a comparison of lantern against the bribes that were being paid in these blocks by flashbot searchers. And here also, lantern learns the popular strategies of front running sandwiching, and also the new strategies that I talked about, Lazarus gas leaching. But it also learns just in time liquidity strategy, because uniswap b three has more sophisticated ways of providing liquidity.
00:34:08.766 - 00:35:08.674, Speaker B: And so when we allow lantern to also provide or remove liquidity, it uncovers more mev as a result of just in time liquidity strategy. So the way to interpret this graph is when we allow the templates for removing and providing liquidity on GSOP V three, it uncovers an additional mev that's represented by the y axis compared to when it was not able to allow to provide liquidity on unison v three, and it was just doing swaps on JSON v three. This particular graph just represents the just in time liquidity strategy profits for lantern. And we also looked at some composition. So when you have compositions of contracts, when you allow lantern to trade on multiple elements, it is able to uncover more mev. Also because of arbitrage between these contracts. And by the way, these kind of strategies are not really already encoded in lantern.
00:35:08.674 - 00:35:55.426, Speaker B: As I mentioned, these contracts are black box environments for lantern. And all these strategies of arbitrage sandwiching, front running, Lazarus gas leaching, these are actually learned by the tool as a result of the learning algorithm that I highlighted earlier. And we also experimented beyond amm, so also included lending contracts. And here, when we allow lantern to kind of be able to perform liquidations on our way and swap those liquidated amounts, and uniswap and Sri swap, it also uncovers significant mev when compared to the baseline. Now, I want to talk a little bit about the execution time of the tool. So, this graph is a little bit complex. But the way to interpret this graph is across our data sets.
00:35:55.426 - 00:36:58.170, Speaker B: These different lines represent the quartiles across the block numbers or different quartiles of block numbers. And the y axis represents how much of MeV, the final MeV that Lantern uncovers, how much fraction of that MeV is uncovered as time progresses. So the green line shows that for 50% of the blocks, as in the median blocks, Lantern is able to uncover more than 90% of the final lev that it will uncover in, say, 30 to 40 seconds. Now, this evaluation is on a single server with 24 cpu cores, 48 cpu threads. And the algorithm of lantern is quite parallelizable. Because you are doing these independent samplings in each iteration, you do many samples, right? It's very paralyzable. And so if you parallelize this across multiple servers, we have done some experiments around that, but not made at least the parallelization part of it public.
00:36:58.170 - 00:37:53.386, Speaker B: But if you do more parallelization across multiple servers, you can actually bring down this time to less than 12 seconds, which is, at least for ethereum, the inter block arrival time. So you can actually use lantern real time if you give it enough servers. After all of this evaluation, I just want to highlight a little bit around applications of lantern. So, for developers and researchers, they can actually directly use lantern to study how much value is extracted from their contracts. Users can use lantern to understand how much value is being exposed through their transactions. And finally, strategic agents, while we don't like it, even bots and players like them can actually use lantern to extract value from contracts. As I mentioned, this particular graph does not kind of support real time usage by these strategic agents.
00:37:53.386 - 00:38:37.180, Speaker B: But it's possible through parallelization across servers. Now just I want to touch a little bit upon limitations before actually concluding. So in order for any learning algorithm to succeed, you need some mild regularity conditions on the search space. Now, because we are dealing with smart contracts, the search space can actually be arbitrary, right? So the contract can behave arbitrarily in terms of ordering of transactions or transaction insertions. But at least for the contracts that we observe, the most popular contracts actually swap and so on. The surf space is quite regular. So, for example, the just in time liquidity strategy has a very regular surf space that you can actually easily learn.
00:38:37.180 - 00:39:31.414, Speaker B: The second one, as you might be already thinking about, is you have to provide these manual templates to lantern, like swap templates, liquidation templates, and so on. So these templates need to be provided one time for each contract so that latex can actually meaningfully explore the search space. With that, I want to conclude. So we actually formalize the economic security of smart contracts as a learning task. The approach that we take is generalizable to any smart contract because we treat the smart contract bytecode as a black box environment and the output strategies of the transaction sequences output by Lantern are actually executable on chain azures. Lantern is scalable to complex smart contracts like uniswap v three in our evaluations. And also it can work with large number of user transactions.
00:39:31.414 - 00:39:55.380, Speaker B: In our experiments, more than 50 transactions. And it uncovers significant mev when compared to the baseline. And last but not the least, it was also able to kind of not only learn the popular strategies, but also learn some new strategies that were not documented earlier. With that I'd like to conclude and happy to take any questions.
00:39:58.710 - 00:40:28.960, Speaker A: Awesome. Thank you very much. I see your first question already, so let me just open that real quick. So the first question is, do the strategy impact time to finality? I'm not sure. I think this is not really. Yeah, maybe whoever asked the question can clarify a little bit more what they mean or Kushaldo, do you have an initial thought already?
00:40:30.930 - 00:40:34.750, Speaker B: Could you repeat the question? I don't think I got question completely.
00:40:34.900 - 00:40:38.430, Speaker A: Do these strategies impact time to finality?
00:40:42.070 - 00:40:46.066, Speaker B: Yeah, maybe I need some clarification for the question.
00:40:46.168 - 00:40:56.360, Speaker D: I think just no, because it's unrelated to consensus or how long it'll take to finalize blocks. I think it's orthogonal to the answer.
00:40:56.810 - 00:41:28.602, Speaker B: I see. Yeah. These strategies are happening purely in the application layer. And so these are just like normal transactions from users, except that these transactions are from the miners. Well, you are kind of trying to reorder these transactions and so on. But of course you have to finalize the transaction sequence before you're publishing the block. So mostly yes, these kind of strategic behaviors do not impact time to finality.
00:41:28.602 - 00:42:36.134, Speaker B: But there's been some recent research which kind of points to the fact that sometimes maybe it's actually better to wait and maybe even publish an empty block or even miss your turn in order to perform some strategic behavior. But mostly as long as you publish your block before the deadline to publish, it doesn't impact the time to finality for transactions. Go ahead, Michael. I was just going to ask on the graph with the latency for how long it takes to execute that strategy, is that assuming all of the transactions in the mem pool are known at the start time, a block builder could insert, or just learn of transactions at the last second and still insert them wherever they want. But I was curious if that was.
00:42:36.172 - 00:42:37.830, Speaker A: Taken into account in the measurements.
00:42:38.650 - 00:43:45.334, Speaker B: Right? Yeah, that's a good question. So at least the way we evaluate it, we already have all the transactions that happened historically. And so those particular graphs were actually plotted, assuming that you have all the transactions at the start, and you are now just exploring how to order them and how to insert new transactions. Having said that, if you do have transactions that are coming on the fly, you still can do something like what lantern does. It requires some slight modifications to the algorithm where you have to kind of now do more exploration with some more attention given to this new transaction that has come on the fly. But there are some open questions there. It is possible, definitely, so that you don't have to throw away your work if a new transaction comes in, because this algorithm is more like iterative algorithm that's building up slowly.
00:43:45.334 - 00:44:07.220, Speaker B: So even if a new transaction comes, that doesn't mean all your past work is void. But yes, that requires some modifications to the actual algorithm. In summary, those graphs are assuming that you have all the transactions in the start. That's interesting. Think about. Thanks for the presentation. Yeah.
00:44:10.630 - 00:44:47.742, Speaker D: I had one question, which I'm not very familiar with learning models like this in general, but I was curious. How much did you iterate in the design of the sampling algorithm for taking those successful or good samples and turning those from the uniform into gaussian distribution, or to change how you sample around it, and how much does that impact the results? Is that something you try out? A bunch of different things? And if trial and error, is that a fairly standard approach to changing the sampling distribution? I'm also super curious if there's any links or citations in your paper or anything like that, that I could read more about how that works and whether or not that's something you change a lot or just kind of use that as default, right?
00:44:47.796 - 00:46:32.930, Speaker B: So yes, there are some references in the paper that talk about how these adaptive learning algorithms are applied outside blockchains and in general for other kinds of optimizations, like where to place certain chips on a silicon circuit and so on. But it was actually some trial and error to get the permutation distribution right. So, as you see, for variables that take real values, gaussian distribution or some sort of exponential distribution is good enough for actually exploring around it, right? So you are kind of exploring around it. But when you have permutations as another variable of optimization, really the question is, how do you define the distance metric between permutations? So, for example, if I have a permutation, that's a good sample, how do I sample around it? What are some permutations that are near to it? One is edit distance, one is maybe the longest common subsequence, maybe one is how many transactions are at the same place in both the permutations. So there are different, different ways of defining distances between permutations, and that will influence how you are sampling from the distribution of permutations. So we played around with two or three distributions, but the best that worked out was how many kind of swaps or how many kind of changes or edits you have to do in your permutation to arrive at the second one. So that was something that took trial and error.
00:46:32.930 - 00:46:50.630, Speaker B: The other one that took some trial and error was how much exploration and exploitation you have to do. So those are some matters of hyperparameter turing that you have to do for all learning algorithms. But yeah, most of the time was spent around defining the right distance metric for the permutations.
00:46:51.610 - 00:47:25.250, Speaker D: That's really interesting. One other question I had is, so you said that you ran this on mostly historical blocks, where you also had the transactions that were actually included from the MEV bots, which could then be resorted in your output in order to say what the MEV would actually be. Have you tried simulating this on a go forward basis, that you have a view of the current mempool in the same way as those MEV bots would be, and also so that your results are not potentially biased by viewing those MEV bots transactions and sort of biasing it from the start towards those places? And if so, what results did you get on that go forward basis?
00:47:26.550 - 00:48:31.414, Speaker B: Yeah, so this is kind of like a methodological challenge, because at least if you look at the historical data, it's really not clear which transactions are really the bots transactions versus which transactions are private order flow or users transactions. So at least for the historical data, I think it's a real methodological challenge. But at least going forward, if you are monitoring the mempool, you do know what transactions are, user transactions and so on. But still, there is still a methodological challenge there because you still don't know the private order flow transactions, even if you're monitoring the Mem pool, whereas bots do have access to private order flow. And so then it becomes unfair to compare against, and maybe that's coming from private order flow, which is not available to lag them for reordering. So we have not tried the going forward approach of just monitoring the mempool and so on. That can be done.
00:48:31.414 - 00:48:40.380, Speaker B: But as I mentioned, there are still some methodological challenges with respect to private order flow there. So all this evaluation so far has been on historical data.
00:48:41.390 - 00:49:09.140, Speaker C: I guess for that, if you're looking at a going forward basis, it's much more treating this research as if it's an actual MEV researcher or MeV searcher, whereas this is saying, what is the theoretical maximum, or maybe not theoretical, but what is the empirically measured maximum MEV at that time that could have been extracted, right?
00:49:10.550 - 00:50:27.630, Speaker B: Yeah, exactly. That's exactly right. And the view that we take, at least for this research, is we also want to think about concerns around consensus instability and other kinds of things. So that becomes important, because if the bots transactions are exposing some mev, if you reorder them, or private order flow is kind of giving you more mev, then you can actually fork the chain and have these time bandit attacks where you kind of folk the chain and subsidize it using the EV that you extract from those transactions. So the historical evaluation is giving you a perspective on what was the vulnerable surface area for the blockchain versus going forward. It's really, if you do that evaluation, it's really around how much money I can make if I were an MBB searcher. So both of these are like different lenses of looking at usage of lanterns, but we took the historical approach as our main evaluation.
00:50:30.050 - 00:51:12.650, Speaker D: One more question also from the perspective of myself, someone that is not very familiar with AI, but heard recently that one of the biggest innovations that's enabled Chachi Bt to be so successful is the quality of embeddings that they have been able to come up for the data, as this is sort of, maybe not first, I've seen some things that are similar to this, but one of the first projects that's trying to use AI in order to figure out what the maximum economic value might be for these. How much innovation do you think there is in terms of defining what a great embedding is? I know you iterated on a bit, but it sounds like something that's early stages. Do you think there's a lot of potential value left on the table by iterating on those embeddings that you use? And if so, do you have any ideas or directions that you're interested in exploring?
00:51:14.190 - 00:52:18.042, Speaker B: Yeah, that's actually an excellent question. If you think about it, the permutation metrics that I highlighted there, those are really embeddings of these permutations on a real number line, where you start from a particular point on the number line, and you say, what is the embedding of this particular ordering, and how much distance is there between this embedding and the current embedding? So you're kind of really embedding these orderings on a real number line, so on a scalar line. But of course embeddings can be more complex than that, like vector embeddings. Of course. I think that is definitely an interesting direction that we have not thought about yet. But I think there's a lot of scope in actually finding good embeddings and it would also speed up the exploration if you have good embeddings as you highlighted. So there's definitely an interesting direction.
00:52:18.042 - 00:52:20.222, Speaker B: Yeah, cool.
00:52:20.356 - 00:52:22.900, Speaker D: Thanks again for doing this talk. This has been really interesting.
00:52:23.750 - 00:52:35.878, Speaker B: Yeah, no worries. And sorry for any hiccups. I'm actually a little bit under the weather today so I know it's a big seminar so I didn't want to cancel at the last moment. But thanks for bearing with me.
00:52:36.044 - 00:52:55.020, Speaker A: Awesome, thank you very much. Do we have any final question or otherwise? I sent around the paper earlier, I'll send it around again. Kushal, thank you. Thank you very much for joining us today and yeah, then hopefully see you soon.
00:52:55.550 - 00:52:58.650, Speaker B: Yeah, thanks Martin and thanks Alafir.
00:52:59.010 - 00:53:01.226, Speaker A: Awesome, thank you. Have a good day. Bye.

00:00:09.200 - 00:00:23.234, Speaker A: All right, thanks, everybody, for joining the system seminar today. And thanks so much, Ellie Davidson, for joining. Ellie is a R and D lead researcher and engineer at Espresso Systems, and today she'll be talking about the marketplace for shared sequencing project. Thanks, Ellie.
00:00:23.934 - 00:01:12.644, Speaker B: Yeah, thank you so much. It's really exciting to be here. Um, yeah, so we've kind of recently released this blog post that describes what we're calling a marketplace for shared sequencing. And so this is, instead of describing us what espresso does as a shared sequencer, we're kind of, you know, describing it as a marketplace because that's actually what it really is. And in this presentation, I'll go into, you know, like, what it is, what the problems that it's trying to solve are, and, you know, and how it fits into what espresso has, has built so far. So to start off with, there are kind of two parts to shared sequencing. So shared sequencing generally, you know, we use it to, to describe what it means to sequence for multiple roll ups at once.
00:01:12.644 - 00:01:42.960, Speaker B: In theory, you could be sequencing for multiple l one s, you could be sequencing for l three s. But, you know, generally it's, it's used in the context of l two s. And so there's two parts to it. You need some way to select who is going to be in charge of the sequencing. So generally this is the proposer. You need some way to select them, and then you also need some sort of finality gadget to commit what it is that you sequence to make sure that it can never change in the future. So most of this presentation is just going to focus on the first one.
00:01:42.960 - 00:02:09.284, Speaker B: Espresso does both of these things. But, but yeah, the marketplace part is mostly based on just the proposer assignment. So. All right, now let's dive in and kind of describe what the problem is that we're trying to solve at espresso and what the problem shared sequencers in general are trying to solve. So we have roll ups. They're horizontally scaling ethereum. This is really great.
00:02:09.284 - 00:02:36.296, Speaker B: We can shard computation across a bunch of different applications. We can increase the throughput. We can also take advantage of heterogeneity. So, for example, we can take advantage of nodes that are really powerful, that can compute these zero knowledge proofs, and weaker nodes can verify those proofs. So all of this is really great. This is a really great ecosystem. And here's what this looks like.
00:02:36.296 - 00:03:15.142, Speaker B: So we have each individual roll up. We have a few examples here, and they basically all post either a fraud proof or a ZK proof and they post their state to the l one. And so this is the kind of the state of things today. But the problem is that rollups run what we're going to call isolated sequencers. And what this means is that they each decide the order of their transactions all by themselves. And they don't have any knowledge of what the other roll ups are doing, and they don't necessarily have knowledge of what's happening on the l one either. So what this means is that you get some really big drawbacks.
00:03:15.142 - 00:03:55.570, Speaker B: You get drawbacks in that it's very difficult to interoperate between all of these different roll ups. On top of Ethereum, if you want to interoperate, you essentially have to. One roll up has to sequence transactions, it has to go all the way through to Ethereum, get finalized. That takes up like 20 minutes, then it has to, then the other roll up has to read from that and do the same thing. So you have very poor interoperability. You also can't get what we call atomic execution, which means that you can't ever guarantee that if one transaction executes, another one definitely executes, or they both fail. And these are two potentially really desirable features that we want.
00:03:55.570 - 00:04:41.584, Speaker B: And so a lot of times in the system we're calling this, we have l two fragmentation, we have these great l two s, and they're really great at scaling Ethereum, but their ecosystems are all very disparate between each other. So then let's now look at what the job of a sequencer is. So a sequencer is basically whoever is in charge of deciding the order of transactions. Usually in most consensus protocols, including Ethereum, this is also called the proposer. So the way that this works is users submit their transactions to some sequencer. In this picture we're showing a centralized sequencer, which is what rollups today have, which is just basically a single server, the centralized sequencer. They decide the order of users transactions and they post the state update to the l one.
00:04:41.584 - 00:05:26.112, Speaker B: So there's a few things that the sequencer does. So mainly they just sequence the transactions. But the other important thing that they can do is provide pre confirmations. And these pre confirmations are guarantees to the user that their transaction will become final on the l one eventually. And as long as the user trusts whoever is sequencing these transactions, they don't have to wait for finality on the l one, which is really good. For example, it would be very poor user experience if I as a user wanted to submit a transaction and then I have to wait 20 minutes to find out if it's really going to become final. A pre confirmation gives users a very strong guarantee.
00:05:26.112 - 00:06:03.694, Speaker B: It's not a 100% guarantee that their transaction will become final, but it's very strong. Okay, so this is what the sequencer does. And then just quickly you say, well, how, how might, you know, you choose who gets to sequence, who gets to sequence? So you have a couple of options. So the most natural option is some sort of like, round robin or random selection approach. So this is in most consensus protocols. You'll randomly elect a proposer each round, and then that proposer is, like, in charge of deciding the order. You could, however, also run an auction.
00:06:03.694 - 00:06:51.634, Speaker B: And this auction, you know, everybody bids. Whoever bids the highest price for the right to become the proposer in the consensus protocol, they win and they get, they get the right to propose. So these past kind of three slides are just to kind of set the stage of, you know, what this, what this ecosystem is. All right, so we kind of talked about how there is this disadvantage to isolated sequencers. This fragmentation interoperability between all of these different l two s is difficult. And so this is why we introduced the concept of a shared sequencer. So, a shared sequencer is something where you have a unified party that is sequencing for all of the roll ups at once.
00:06:51.634 - 00:07:40.404, Speaker B: And it's interesting to note that this can actually be the layer one themselves. So a layer one is actually a shared sequencer, if you think about it, it's just sometimes not used that way. Or this could be an external shared sequencer, like something espresso is building, which I'll touch on later. But so, yes, we introduced this shared sequencer architecture, and it has really good advantages. So, basically, the big advantage is that you have improved interoperability, and you can get these atomic transactions. If you have the same party that is deciding the ordering of transactions for roll up a and for roll up b, they can ensure the atomic transactions. And so they can ensure that two transactions are definitely included together and that they both execute or they both fail.
00:07:40.404 - 00:08:20.308, Speaker B: And so, and then another point here is that if you're specifically, if you're using the layer one as your shared sequencer, this has been referred to as based sequencing in Ethereum. You also get the advantage that you get all of the decentralization and security of your layer one, which is desirable. So, like I said, you could use the l one as a sequencer, or you can use a separate sequencer. So this is kind of where espresso fits in, and you can use what we call a layer 1.5. So this sits between the roll ups and the l one. And this layer 1.5 does two things.
00:08:20.308 - 00:08:58.888, Speaker B: So it provides sequencing and then it also provides data availability. Now, fundamentally, this layer 1.5 actually does not need to provide both of them. You have designs that might only provide data availability, only provide ordering, but in Espresso's case, we do provide both. And later on in the talk, I'll discuss what are the advantages of having a layer 1.5 in between? Because at first glance it might seem, well, you're just adding this extra layer, why don't you just use the l one? It seems like there's these great advantages to just using the l one as a shared sequencer. So what's the point of this layer 1.5?
00:08:58.888 - 00:09:34.874, Speaker B: And I'll touch on that later. So, all right, so up until this point, we have isolated sequencers. They're bad because we have a lot of fragmentation. So we introduce a shared sequencer, and the shared sequencer gives us really good interoperability. But now we come back into that question, well, how do we decide who gets to propose for this shared sequencer? And you have a couple of different options. So you can just run a round robin or a random election protocol that is totally fine. And in fact, like, that is what most protocols do today.
00:09:34.874 - 00:10:09.044, Speaker B: But you can also run an auction. And so this auction design is where the kind of the, is like the core idea of this marketplace for shared sequencing. So you have a couple of options when you run an auction. And so the most naive, or like the most straw man example, is that you run an auction for someone to propose for all of the roll ups at once. So this person can order the transactions across all roll ups. And this is really great. This is good because you have.
00:10:09.044 - 00:11:01.462, Speaker B: Sorry, I'll actually back up. This is really good because you can enable atomic transactions across any roll up. For example, a user could say, I have a transaction that I want to be atomically executed across 20 different rollups. And you could enforce that because you have the same party that's sequencing and proposing for all of the roll ups at once. So next, let's kind of look into a shared auction versus an isolated auction. So this is analogous to a shared sequencer versus an isolated sequencer, like we discussed before. So an isolated auction would be an auction where people bid for the right to sequence for each individual roll up, and it's each individual, and you may have different winners that win each bid versus the shared auction is when someone bids to sequence for this entire, all of the roll ups at once.
00:11:01.462 - 00:12:10.334, Speaker B: So they're kind of two extremes. And here's a couple of notes. So a shared auction revenue might be higher than just the combined isolated auctions, because in a shared auction, you can do these atomic transactions, you can have cross roll up, defi logic, etcetera. And so you may actually be able to earn more revenue in a shared auction rather than like an isolated auction. But you run into this big question where what do you do with the revenue? So what we've talked about up until this point, we've said, oh, you know, having a shared sequencer is really great, but a point that I kind of purposefully did not include is, well, where does all the revenue go? So currently, rollups have their own sequencers, and they capture all of the fees from sequencing. If you have a shared sequencer that some other party, whether it be espresso or the l one, naturally those layers all of a sudden get all of your revenue, and that's not very good. So the key idea of this marketplace design is that we want to enable the revenue to be redistributed back to roll ups so that they're no worse off.
00:12:10.334 - 00:13:09.638, Speaker B: Hopefully they're better off, but at the very least, they're no worse off participating in a shared sequencer than they are in just running their own sequencer by themselves. So, but this kind of leads opens this big question, well, how do you actually share the auction revenue among all of these individual roll ups? If someone bids, say, $10 to sequence for all of the roll ups on the shared sequencer? Like, how do you decide which roll up gets what? And so this is the problem that we're kind of trying to solve. And there's a lot of analogies to this problem to kind of help frame it. I think the best one is a music festival. So bands play at a music festival, and the festival sells tickets to individuals, but obviously some bands are going to bring in more people and more tickets than other bands. So how does the festival decide how much revenue to give back to each band? And the idea is that if you don't give enough revenue back to the band, they're not going to agree to play at your festival. And that's not very good.
00:13:09.638 - 00:14:05.126, Speaker B: But if you give too much revenue back to them, well, then you're taking away revenue that maybe should have actually gone to other bands. So there's real life analogies to this problem. So basically here what we're going to do is how can we design an auction that has a few key traits. How do we design an auction where we get the benefits of shared sequencing, where we're allowing parties to see going through multiple roll ups at once, but we're doing so in a way where individual roll ups are better off in the shared sequencer and they get their fair share of revenue. So first, let's do kind of a strawman attempt. We'll have two options for people to bid on. So bidders can either bid on the whole bundle of all of the roll ups at once, or they can bid on each individual bundles and we choose whichever option generates the most revenue.
00:14:05.126 - 00:15:13.980, Speaker B: So, for example, if someone bids $20 on the entire bundle of all of the roll ups, and the sum of all of the bids for the individual roll ups only sums to say, like 13, obviously, we're going to choose the bid for all of the bundles because it generates more revenue, it generates $7 more revenue. And then when we decide to reallocate the revenue, we'll say, okay, so this bundle, one, the bundle for all of the rollups, one, but we're going to take the bids for the individual roll ups and we're going to use that to determine the value of each roll up. So in this example, the entire bundle was worth 20, but individual roll ups, like a was worth three, b was worth $2, c was worth $3, etcetera. So we're going to find the proportions of that to the total. You know, find out how much each roll up is worth proportionally to each other, and then apply that to the $20. But there is unfortunately, a problem with this. And the problem is that roll ups might just artificially bid high just so they can get more revenue.
00:15:13.980 - 00:16:13.304, Speaker B: So, for example, let's say a says, okay, I know I'm only worth $3, but if I just bid $10 for myself, as long as I don't bid enough, that the entire, as long as I don't bid too much, where I actually have to pay that $10, I just get more of the revenue. So, like, why wouldn't I do this? And this is called shill bidding. And shill bidding prevents you efficiently allocating all of the revenue back to roll ups because you're not getting accurate reflections of how much each individual roll up is worth. And the point of the auction is not only to decide the proposer, which is important, but is to also determine the worth of each roll up. And you determine the worth of each roll up based on how much people want to bid for the right to sequence for that roll up. So obviously, if someone is shill bidding that's preventing this efficient allocation. So, yes, let's say that a shill bids, they say, oh, I'm going to shill bid for $10, even though I'm only worth three.
00:16:13.304 - 00:16:56.014, Speaker B: Well, the result is then that the total bundle still ends up winning. So the bundle is worth $20. It still has the most. It's still worth the most. So the bundle ends up winning, but a gets too much revenue redistributed to it, so that's not good. But then you can go even further and say, well, what if both a and B, both shill bid and they both say that they're worth $10 when they really aren't? Well, all of a sudden now the bundle of all roll ups is not worth the most. And so what happens is now that each individual roll up gets sequenced by itself and you lose, you lose the ability for the shared sequencing, because if you're sequencing roll ups by themselves, then we're kind of back to the current state today, where we don't have any shared sequencers.
00:16:56.014 - 00:17:34.093, Speaker B: So this is not good. Well, what do we do to solve this problem? So we can allow a combinatorial option? So instead of just having the option to bid on either all of the roll ups at once, or only individual roll ups, someone can bid on any combination of roll ups that they think is valuable. So let's look at an example. So proposers can bid on arbitrary bundles. So this is a combinatorial problem. And if you have shield bidding, you risk being excluded from the winning bundle. And I'll kind of go into this on the next slide.
00:17:34.093 - 00:18:08.546, Speaker B: And just optional, you can also burn part of the bids if you want to disincentivize shield bidding. But that's orthogonal to the design of the auction. All right, so we have, we have these three bundles here. So we have the bundle of all of the roll ups like we had before. We have the bundles, or we have the singleton bundles of each individual roll up, and then we have this bundle of only three roll ups. So let's look at the shill bidding situation. Let's say a and b, like last time, they overbid themselves and they bid two more than they're worth.
00:18:08.546 - 00:18:52.050, Speaker B: Well, what's going to actually happen is that a and b will be excluded from shared sequencing, but the other three roll ups will still win. Like they'll still be included together. So what we're going to have happen is that you end up with the winning combination is going to be three things. It's going to be the bundle of three roll ups, C, D and e, and then the a bundle and the b bundle just by themselves. And the reason is because that is the revenue maximizing combination. So in this case, oh, I should have put a numbers example on this slide. But basically you say which combination earns you the most revenue? You just take the sum of all of the bids.
00:18:52.050 - 00:19:55.204, Speaker B: And since a combination of many bundles will likely be, have a higher bid than the sum of its individual parts, you end up with this kind of combination. So yeah, essentially the point is that this prevents shill bidding from messing up the redistribution of allocation because if a roll up shill bids on itself and bids too high, it basically just gets excluded from the shared sequencing. But you could argue that actually maybe shill bidding is not the end of the world. So why might roll ups want to shill bid? Well, they might have a view that they want to make a minimum amount of revenue for their roll up blocks before they allow someone else to sequence for them. So shield betting actually can function as a reserve price. And in this model, every roll up would, instead of shield bidding on themselves, they would post a reserve price. And it says if no one bids more than this minimum price for me, I will just, I will just sequence for myself.
00:19:55.204 - 00:20:35.520, Speaker B: And in this way, you know, maybe shill bidding isn't such a problem. So the design of this marketplace is what we're calling ad hoc shared sequencing. And the marketplace is that you're allowing roll ups to sell their block proposal rights by each slot. So if we work through an example, I'm a roll up. I set my minimum bid price, my reserve price to be dollar ten. If no one wants to bid more than $10 for either my, my individual roll up or my roll up as a part of a larger combination, then I get to sequence for myself. And then I obviously, you know, get all that $10 back.
00:20:35.520 - 00:21:35.224, Speaker B: But if someone says, oh hey, I'll actually buy the right to sequence you for $11, you know, then someone else can buy your sequencing rights. But there's a couple of, there's a couple of caveats to this problem. So the first one is that this is a combinatorial option, which means that if you have, you know, if you only have like five roll ups, that's fine because you don't have that many possible combinations. But if you have 100 roll ups or 1000 roll ups on the shared sequencer, this very quickly becomes intractable to like find the optimal allocation. So what do you do? Well, the solution is that you can find just a good enough allocation, you say, okay, maybe I run some sort of an optimizer for a minute, two minutes, and I output the best allocation that I have found within that time span. And then because all of the bids in the network are public, someone else can come and offer a better allocation if they find one. And if someone finds a better allocation, then maybe you give them some sort of like finders fee.
00:21:35.224 - 00:22:21.692, Speaker B: But this is basically how we can get around this intractable problem of having a combinatorial auction where you could have like thousands upon thousands of possible combinations. The other part of this is that you need to run the auction pretty far ahead in advance. And there's a few reasons for this. So you have two parts. One is that you may want to run the auction ahead of time in advance, just for sort of economic incentive properties. So if you run the right to propose a block, but you have to decide whether or not you want to propose that block very far in advance, you don't actually know what your actual revenue will be from that block. So this is different than like proposer builder separation and Ethereum.
00:22:21.692 - 00:23:12.240, Speaker B: Today, instead of bidding on the actual revenue you'll make in that block, you're bidding on the revenue that you expect to make. And maybe this has some good economic properties, but there's also some more technical reasons why you have to run this auction very far in advance. And one is that you need to have ample time to solve this combinatorial problem. You want to give ample time not only for one party to solve it, but also for other people to potentially post better, better combinations. And then two, you need to make sure that your consensus protocol has plenty of time to know about the results of the auction. So you don't want to end up in the case where a party wins the auction, but the consensus protocol just hasn't had time to learn about that yet. And therefore the consensus protocol doesn't properly, properly let that person propose.
00:23:12.240 - 00:23:50.568, Speaker B: So you could end up with an example where I won the auction, but the consensus protocol doesn't know about it, and so they reject the block that I propose. You don't want that either. So there's kind of economic reasons you might want to run this lottery or, sorry, this auction really far in advance. And then there's some technical reasons as well. And then, as I mentioned here, if you run the auction far ahead of time in advance, the bidders don't know the exact value that they're going to make from their block that they propose. And so they're, they're bidding based on the expected value. This can have some nice economic properties, but one of the downsides is that the expected value does not change very often.
00:23:50.568 - 00:24:20.494, Speaker B: And so you're just going to end up with everybody submitting the same bid every single time, and then you just end up with the same people winning the lottery or the auction every single time, and that's not very good. You end up with, like, centralized builders. You know, maybe one builder ends up getting a monopoly. You don't want that. So to address this problem, we're going to take this auction and we're actually going to run a lottery. So we're going to introduce a little bit of randomness into the selection. So here's what the lottery looks like.
00:24:20.494 - 00:25:12.804, Speaker B: Instead of, you know, potential builders submitting bids into the system, you're going to buy lottery tickets. Each ticket is going to have a set price, and this price can be dynamically adjusted over time. So after each round of the auction, you can say, oh, a lot of lottery tickets were sold, so I'm going to raise the price for the next auction. Or if very few lottery tickets were sold, you can lower the price, but all of these lottery tickets for a single auction are the same price. And instead of bidding, you basically decide how many lottery tickets you want to buy. And because there's a fixed number of lottery tickets, you know, your chances of winning, of winning the auction based on how many tickets you buy. So if I buy ten tickets and there's 100 tickets, I know that probably are in expectation over time, I have a 10% chance of winning, of winning the lottery.
00:25:12.804 - 00:25:54.642, Speaker B: And so in this way, we introduce this extra amount of randomness into the protocol, and this kind of forces you to have different proposers in the protocol instead of always having, like, the same proposer and then. Yeah. And so really quickly to wrap it up. So we have this design. Our whole goal in the beginning was we want to have this auction that allows roll ups to sell their block space, but only to sell their block space if they're going to make more revenue than they would by not selling it. That's the goal. Our goal is that roll ups are always better off by joining a shared sequencer than.
00:25:54.642 - 00:26:43.274, Speaker B: Than they are by sequencing by themselves. Well, how do we solve that problem? We have this auction where people bid roll ups, consider reserve price to ensure that they get a minimum amount of revenue each round, and then any extra revenue made through the auction is redistributed to roll ups. So the key properties of this are that, like, revenue is redistributed to the roll up itself. So that's our goal. But how might, then you could also say, well, how is this actually implemented in consensus? And so this is actually where I spend most of my time. I spend most of my time in espresso working on our consensus protocol. So how is this implemented in consensus? Well, instead of a round robin leader election, you're going to have, you're replacing it with this auction.
00:26:43.274 - 00:27:26.248, Speaker B: So that's the first step. The second step is doing so Ethereum calls this execution tickets. And this is instead of proposers being, this is basically exactly what I described. Instead of you randomly electing proposers or doing a round robin, proposers are elected through this auction. And another part of this is that you expect the people who bid in this auction or who buy lottery tickets are going to be very sophisticated. So this is a big difference between many consensus protocols and kind of this marketplace design. A lot of the times in consensus protocols, leaders, because leaders are like round robin, they're not always expected to be very sophisticated parties.
00:27:26.248 - 00:27:52.824, Speaker B: They're expected to usually be the same level of sophistication as a regular validator in the network. And in fact, they're the same, they're all of the same set. So the proposer is chosen from the set of validators in the network. This is not the case in this new design. In this new design, you have validators who vote in the network and you have proposers. And those two sets are not necessarily, they're not necessarily the same. They may have overlap, but they don't have to.
00:27:52.824 - 00:28:33.534, Speaker B: So that's kind of how we implement this into consensus. And then the other part is, well, censorship resistance. If you have a common proposer across all of the roll ups, you could argue that you might get some censorship. So, for example, let's say you have a roll up that often has a lot of sanctioned transactions in it. That's its value prop, is that it's a privacy roll up. It offers shielding, transaction shielding and anything like that. Let's say that a lot of proposers don't want to include that roll up block because they don't want to touch anything that might be sanctioned.
00:28:33.534 - 00:29:34.728, Speaker B: Well, in that case, a roll up like that, if you have one shared proposer across the entire shared sequencer, that roll up is going to be censored and it's not going to be included. But with this marketplace design, since you can have multiple proposers, you can actually have proposers who want to propose for other roll ups, and then you can have proposers that are totally fine sequencing for a sanctioned roll up or sanctioned transactions, and they can still propose for that roll up. So you get better censorship resistance because the parties that are proposing for each roll up are more aligned with the incentives of that roll up, rather than saying one party has to sequence for everybody. And if that party isn't aligned with all of the roll ups, then, like, too bad for the roll ups. And then the final part is that the key change from that this requires from our consensus protocol standpoint, is that now we need to support multiple proposers. So most. Well, not most.
00:29:34.728 - 00:30:11.664, Speaker B: You have consensus protocols that don't have leaders. But most consensus protocols today probably run on a leader based paradigm. You have one leader who proposes the bloc, everybody else votes on it, et cetera. Well, now we need to support multiple proposers, and that is, in my opinion, a very interesting research space. So, there's a lot of other consensus protocols that don't have leaders, or rather, maybe they have leaders, but the leaders are chosen after the fact. So you could look at dags. Dags are probably the most common, like, well known form of a consensus protocol that doesn't have explicit leaders.
00:30:11.664 - 00:30:45.954, Speaker B: And so I think here we can actually use a lot of the ideas from dag designs and kind of port them over to our proposal or to our consensus protocol without making our protocol a full. A full bag. So, that's kind of the consensus view of the lottery. And I'll wrap it up with a couple of further. Further thoughts. So, there's some open questions that I didn't really touch on here. The first is, well, have we actually fixed the shill bidding problem? So, you know, we say, oh, shill bidding functions as a reserve price.
00:30:45.954 - 00:31:28.420, Speaker B: But one thing I didn't mention is that it doesn't completely solve the shill bidding problem. So a roll up might set a reserve price, but they still might be incentivized to shill bid a little bit to see if they can get, like, a little bit of extra revenue. And it might just depend on what the bids are for that particular round. So we haven't actually completely fixed the shill bidding problem. The other thing is, well, what if you have some sort of a tight knit community? So, for example, there's a lot of roll ups, like super chains or hyperchains. Maybe they actually want to participate in the shared sequencer as a group. Maybe they find that they don't really have a lot of economic value being sequenced by themselves.
00:31:28.420 - 00:32:27.534, Speaker B: So they're just always going to participate as a group that could also be something else that happens. Thirdly, is this compatible with based sequencing? So based sequencing has been kind of a hot topic in like the Ethereum community lately. And the short answer to that is yes, although I won't really go into why, why that is, but, but yes, this can be 100% compatible with based sequencing. And then the final question is, how often do you run the lottery? So running the lottery can be, can be a bit complex because you have to solve this combinatorial problem. And even though we're time boxing the combinatorial problem, you know, to be a couple of minutes, it's still like a complex thing to run. So you don't want to run the lottery for every single, every single block that you propose. Instead, you want to run the lottery for say every 100 blocks, and then you use the randomization to like randomize each individual proposer.
00:32:27.534 - 00:33:08.824, Speaker B: But you also don't want to run the lottery too infrequently because you want people to be able to update their bids and properly reflect what, like the accurate price of each roll up. So that's a lot for some further thoughts. But now basically just want to say like the takeaways, that was a lot of, a lot of talking. The takeaways are basically we're building a marketplace for shared sequencing. How are we building a marketplace? We're using a combinatorial lottery to efficiently decide who gets to sequence for roll ups. You can view this as an auction and then just adding a little bit of randomization on top of it as a lottery. But the core idea is that it's an auction.
00:33:08.824 - 00:33:44.014, Speaker B: And then finally the main part of this idea is that roll ups are always better off participating in this system than they are being sequencing just for themselves. So that's the key value prop here, is that roll ups are always going to make as much revenue or more revenue in a shared sequencer with this design that they're gonna make by themselves. So that's the end of the presentation. Thank you, I appreciate that. Yeah, and would love to, if anybody has any questions, that would be great.
00:33:46.594 - 00:34:30.814, Speaker C: Hey, yeah, great, great presentation. I really enjoyed it. I had a bit of a question on. So when you say like atomic execution or inclusion, you can maybe include a batch where you have a transaction roll up one and roll up two, and they're either both executed or both fail. Is that including in the EVM you have transactions that revert? Is that including that case, or is a transaction that reverts considered included? And so like basically, are you guaranteeing just the inclusion or the actual successful execution of the transactions?
00:34:30.894 - 00:35:04.652, Speaker B: Yeah, that is a really, really good question. So a transaction that reverts would be considered only atomic inclusion, not atomic execution. And the. So there's a, so like espresso or any shared sequencer can offer atomic inclusion pretty easily. The difficult part is going from inclusion to execution. So there's two ways you can do this. One is that the proposers can have to post collateral and basically say if they post something that doesn't atomically execute, they're slashed for some like very large amount.
00:35:04.652 - 00:35:46.444, Speaker B: And the key point is that you need to slash them for a lot, like they need to post quite a lot of collateral, because you want to make sure that they don't ever make more money by breaking their promise than they do by keeping their promise. The other solution is once, at some point in the future, we have real time proving. If you have real time proving, you can prove within the time span of a single block that the execution is correct, and therefore you actually don't have to trust, you don't have to rely on economic collateral. But right now we don't have real time proving. So you get atomic execution by basically requiring proposers to post collateral and then slashing them if they don't.
00:35:47.004 - 00:35:52.584, Speaker A: So could you explain one more time how the real time proving removes the need for economic collateral?
00:35:53.684 - 00:36:54.282, Speaker B: Yes. Yeah, so actually I think that's a good point. It might not entirely remove the need for economic collateral, but the idea is that if you have real time proving, you could actually, so actually I'm going to back up. So a key part of this is that the nodes in the consensus protocol do not execute transactions. So if the nodes in the consensus protocol were executing transactions, you could have the consensus protocol enforce atomic execution because the nodes would not vote for, they wouldn't vote to sequence a transaction if it didn't, like, atomically execute, but we don't have that in a sequencing protocol. So with real time proving, essentially you would do a proof, you would facilitate message passing in between the different, the different roll ups. And it would basically look, you would basically enforce the execution when you are the atomic execution at the roll up level.
00:36:54.282 - 00:38:06.860, Speaker B: So I don't think I'm describing this very well, but the flow is that a transaction goes to a sequencer, the sequencer sequences it, and then after that, the roll up interprets what the sequencer has done and it executes the block. So if you have real time proving, you can basically have it so that a roll up will only execute their block if they receive a valid proof of the other roll ups state. So if you have a transaction that's atomic between two roll ups, your roll up will only execute their side of the transaction if the, like, the state proof is also included from the other roll up is also included. But to do that in a timely manner, you need maybe not real time proving, but you need like fast proving. You could technically do it without fast proving, but then it's, and that is done today, but it's not a really great user experience because, you know, you have to do this message passing. I will point out that there is this project that Polygon is working on called Ag layer that's basically doing this. So they are, they are not using real time proving, but they are basically facilitating the message passing between different roll ups.
00:38:06.860 - 00:38:25.580, Speaker B: So that a roll up, when the roll up is executing its block, it's taking as an input the proven state of another roll up, and therefore it's only executing its block if the proven state of the other roll up is in fact correct. So, yeah, that's a little bit of.
00:38:25.692 - 00:38:31.134, Speaker A: It is complicated, but I'm roughly following it. I'll say. I don't think I'm going to get past the point of roughly following it.
00:38:33.074 - 00:38:33.842, Speaker B: So.
00:38:34.018 - 00:38:50.026, Speaker C: Sorry, is the, if the validators aren't, you know, executing the transactions, which makes sense. Right. How does the system guarantee that those transactions are paying fees at all?
00:38:50.210 - 00:39:42.974, Speaker B: Ah, that's a very, very good point. So there's a few different structures you can do. So one of the fee structures is that you can have the, you have one fee transaction or a very low number of fee transactions for the whole block. So the idea is that whoever builds the block would take the fees and the fees would pay directly who builds the block? They would directly pay the proposer. This could actually be abstracted. So like the user doesn't actually have to worry about that, but their fees pay whoever is proposing the block, and then the proposer has to include a single transaction in their proposer that properly pays the network, and the network does execute that single fee transaction. So that's basically the idea is that you kind of abstract the individual transaction fees away and you put them into one big fee and the network does actually execute that fee.
00:39:43.314 - 00:39:50.050, Speaker C: So that would then assume then that the builder is able to guarantee that those transactions are paying fees.
00:39:50.162 - 00:39:50.458, Speaker B: Right.
00:39:50.506 - 00:39:53.094, Speaker C: Or is somehow able to do that.
00:39:53.834 - 00:40:14.974, Speaker B: Yeah. So the builder is expected that they, they're going to have to execute the transactions. Yeah. So that's also how they determine, like, if you get atomic execution like they do have to execute them, but the idea is that they're a very sophisticated party who can do that, whereas the validators on the network are very unsophisticated and, you know, can't reasonably do that quickly.
00:40:18.774 - 00:40:23.474, Speaker A: It seems like there's a number of questions. So I open the queue. Patrick, you're up next if you want to ask.
00:40:25.254 - 00:40:40.686, Speaker D: So I guess, like in terms of like if you could go back to the slide maybe where you talk about the individual seat, like roll ups fitting into the sequencer, like any one of the slides where you see them all together kind of. Oh, like, like one of those is fine.
00:40:40.750 - 00:40:42.334, Speaker B: Yeah, yeah.
00:40:42.914 - 00:41:28.974, Speaker D: So I maybe have a dumb question around some of this because I think the research changes so much at all. I'm not, I'm never sure exactly what the view is on some of this. So with a shared sequencer, do these roll ups have to have, like, basically would need to pick espresso as like the exclusive shared sequencer that they would use? Or you mentioned like that there is like a based sequencing compatibility, like, or like, so you could augment whatever maybe ETH is doing in terms of its sequencing. Or is there some view where like, cause you mentioned like Polygon, for example, has the egg layer, which is some would say a competitor to what you guys are doing in terms of like having a shared sequencing? So like, how do you guys think about trying to corral potentially disparate projects?
00:41:29.394 - 00:42:02.562, Speaker B: Yeah, so that's a, that's a good question. So a few points. So a roll up technically does not have to choose a single sequencer, and this is actually what exists today. So right now with centralized sequencers, the centralized sequencer does most of the sequencing, but someone can also forcibly like inject a transaction directly to the l one. And the centralized sequencer has to respect that. So fundamentally, rollups don't have to choose a single one. But there's a really big trade off if you choose more than one.
00:42:02.562 - 00:43:08.108, Speaker B: So if you choose a single sequencer, or if you choose a main sequencer, it's one thing to have a backup sequencer in case one fails. But if you choose a single main sequencer, you get a really good property of fast finality. If you trust that sequencer and they're the only one who can ever sequence for you, then once that sequencer says something is final, it's not going to ever be reorged, even if it hasn't made it to the l one yet. But if you have multiple sequencers, then you run into, you don't really get this fast finality, because if I'm a user and I submit my transaction to espresso, but the roll up is using like some other project too, well then I don't know the order that my transaction is actually in when it hits the l one. So my execution might be different than what I think it is. So fundamentally, rollups don't have to choose a single one, but really for the best user experience, they do. Now to your other point, AG layer is, I'm actually really interested in the AG layer project and the AG layer is actually very complimentary.
00:43:08.108 - 00:43:50.944, Speaker B: So the AG layer actually has a shared sequencing component. So the way I understand it at least, is that a shared sequencer like Espresso would still sequence the transactions. It's just that the AG layer would come in afterwards and do all of its proof aggregation and validity checking and stuff like that. So I think that the two are actually quite, quite compatible. And then as far as base sequencing, in Ethereum, espresso is compatible with based sequencing. And what that means is at its definition, based sequencing means that you're allowing Ethereum proposers to propose for your roll up. That's like the definition that Justin Drake, who proposed it in the first place, has landed on.
00:43:50.944 - 00:44:54.544, Speaker B: Espresso does that. So I didn't really go over this in the slides, but what Espresso does is that they allow the l one proposer this right of first refusal, which is basically whoever wins. So no matter who wins the auction, the l one proposer always has the right to purchase the right to propose that block for the amount that won, plus some extra fee. And so in this way, the l one proposer can always choose to participate in sequence for espresso if they want to. And therefore espresso is based, you can get interoperability between the l one, but the main difference is that you don't necessarily have an l one sequencer. Every single espresso block is the difference between the espresso implementation and maybe what we call, what we're calling vanilla based sequencing, which is what Justin originally described. So I guess as a summary, to answer your question, no, roll ups don't have to have a single sequencer, but they probably should because otherwise you get very poor user experience.
00:44:54.544 - 00:45:16.868, Speaker B: So, and as far as like corralling roll ups, yeah, it's kind of like a network effect thing. Obviously, we hope that like Espresso will have a good network effect. And that's one of the really big drivers behind us. This marketplace design is that, you know, roll ups should always be better off in this design than they would be elsewhere. So like why not join, you know, join this marketplace? That's kind of the idea.
00:45:16.996 - 00:45:27.092, Speaker D: Um, yeah, it'll be interesting to see how that plays because I know a lot of people have said the exact same thing about their shared layer.
00:45:27.268 - 00:45:27.596, Speaker B: Yeah.
00:45:27.620 - 00:45:49.248, Speaker D: And so, like it'll be interesting to see how, how the network, like, it almost seems like you have these network of network effects rather than just like 1 /hour but I'm very curious to see, obviously everyone's pushing like unique functionality and like interesting enhancements that like being in there sort of shared consortium provides. So I'm very interested, but thank you for answering the question. Sorry, that was like three or four questions, Bumble.
00:45:49.296 - 00:46:15.624, Speaker B: Yeah. And one also note too is that you can choose different sequencers for different blocks. So the problem really comes if you have a single roll up block that's using two different sequencers, but you actually are okay. If you say, oh, on even blocks, I'm going to use espresso and odd blocks, I'm going to use someone else that's actually okay because, you know, who seque, like, you only have one party who's in charge of sequencing at a time.
00:46:16.044 - 00:46:27.476, Speaker D: And the hope there would be that you could potentially like incorporate the composability of maybe other sets of roll ups into your roll up. That would be the idea, to use those like, okay, yeah, and the other.
00:46:27.500 - 00:46:52.180, Speaker B: Thing, I mean, this is kind of an open, definitely like an open debate in the community is how often do you really need different kind of composability. So composability with like Ethereum is great, but do you need it every single block? Maybe not. And maybe if you don't need it every single block, some blocks you choose to, you know, use like a base sequencing and then other blocks you don't, and maybe get cheaper sequencing because you, you don't need it. I mean, that's a very open question.
00:46:52.252 - 00:47:35.854, Speaker A: But yeah, I've got like a long list of questions, but I'm just going to ask one that I have scribbled down and see if anybody else has more. When you said Espresso gives the right of first refusal to the Ethereum, the l one node for shared sequencing, what type of incentive do you think that creates in the market? Because doesn't that mean that if somebody is bidding on the economic value of sequencing, that slot or that lottery number, and they don't know what the value will be? Since we're sort of doing the lottery in advance, doesn't that mean that the Ethereum node at the player one level gets to see what the value is of it and then decide whether or not they want to pay more for it. Do you just have to pay a large enough fee or give some reward to the person that won the lottery and then got kicked out? Or how do you handle that incentive?
00:47:36.554 - 00:48:15.016, Speaker B: Yeah, so that, it's a good question. And I would say it's like that's something that we're very actively thinking about. I think there's a couple, there's a couple of ideas. So in the ideal future, we would actually want to just let the Ethereum l one proposer participate in the lottery like everybody else. The problem is that Ethereum proposers are only known like 32 blocks in advance, and you have to run this lottery more than that, like longer than that in advance. So they can't reasonably actually participate in a lottery, but in the long run they should just like participate like anybody else. And therefore you don't get this problem that you said in the short term.
00:48:15.016 - 00:49:13.364, Speaker B: Yeah, this is kind of, this is kind of a problem. But the idea is maybe that, you know, the ethereum, the Ethereum proposer would, I guess the hope is that the bids are accurately reflecting the value of the roll ups. And if they're accurately reflecting the value of the roll ups, then the Ethereum l one proposer might not actually want to bid more like they'll, because they'll have to pay this extra fee and they're only going to pay that extra fee if they can actually extract like that much extra value. And they'll only be able to extract that much extra value if they're doing some sort of like l one l two, interoperability that the regular proposers can't. So that doesn't entirely like solve, answer your question. I guess the answer is like, this is something we're actively thinking about it, but in the long term, it, once Ethereum proposers can just be known really far in advance through like secret single leader election, then they'll just participate like everybody else.
00:49:15.104 - 00:49:22.034, Speaker D: One other question that I have, Aaron, just interrupt you. I think Josh has had a question for a bit. Josh, I don't know if do you want to ask your question?
00:49:27.654 - 00:49:31.954, Speaker C: I think Josh like dropped and then maybe rejoined right when you asked that.
00:49:32.814 - 00:49:40.634, Speaker A: I got confused because I tried to open the queue, but then it seemed to have disappeared, which I think is because we all unmuted at some point and I don't like the queue anymore.
00:49:42.094 - 00:49:48.850, Speaker D: Sorry, I had to go pick up my ultrasound but my question was, can the same fragmentation exists with l two s also exist?
00:49:48.882 - 00:50:29.844, Speaker B: Like many l 1.5s? Yeah. So, yeah, that's, that's a good question. And yes, there's a possibility. Obviously, if you have a lot of them, that's definitely a possibility. I think the idea is that it'll be kind of similar to the effects of a lot of like layer ones where. Yeah, you have multiple layer ones and maybe those aren't as interoperable as we would like between them, but they kind of have like strong enough ecosystems among them that it's not like, I guess, well, I shouldn't maybe say that though, because, like, it would be great if l ones were actually more interoperable.
00:50:29.844 - 00:51:09.334, Speaker B: So I don't want to say that it's okay that they're not interoperable, but maybe the idea, the idea is that it won't be so bad. Okay. I think my honest opinions are that. I think the hope is that hopefully it's espresso, but probably like a couple of shared sequencers will win out in the end is probably the idea. So you'll probably have like maybe between one to three that went out. And if you only have a few, like a really small number, then maybe that's like, okay. But yeah, I actually do agree that like if we end up with 100 shared sequencers, then have we really solved a problem? But hopefully that's not the case.
00:51:09.334 - 00:51:14.830, Speaker B: I don't know. I don't really have a good answer to that if I'm being honest off the top of my head, then.
00:51:14.902 - 00:51:23.302, Speaker A: Jacob, before you go, I think Yulin has one more question as well that he asked in the chat. Just wondering if this, what you presented.
00:51:23.358 - 00:52:04.528, Speaker B: Is a proposal or already running software with certain tools. Yeah, that's a really good question. So we currently implemented, we have a shared sequencer that does not have this marketplace design. So the current implementation that we have on Testnet just has like a randomly elected leader, like most consensus protocols, and that leader is in charge of sequencing for all of the roll ups at once. So that's our current implementation. But right now we are actively like coding. Well, I'm personally finishing up the planning stages and then we're like literally starting next week, we're actively coding to start on this marketplace design.
00:52:04.528 - 00:52:19.314, Speaker B: So the hope is that we'll have a testnet for it, hopefully within a few months. And we do also have like actual roll up projects that are on our testnet as well. Yeah.
00:52:23.254 - 00:52:25.594, Speaker A: I think Jacob and then Matt are up next.
00:52:26.574 - 00:52:48.364, Speaker D: Yeah, I had a question around since a lot of these shared sequencing layers are trying to have this like network effect, what are the technical attributes that you think are really important to attract certain subsets of applications? You can attract like a lot of applications, but if they're not in these groups, they're not going to want to talk to other anyways. And you won't.
00:52:49.784 - 00:53:31.142, Speaker B: Yeah, that's a really good question. So I think, well, at least from the consensus protocol side, which is where I spend most of my time, a really, really big focus of us has been high throughput and low latency, which is the focus of every consensus protocol. But we've put a lot of effort into getting really high throughput because we also offer data availability. So I think one of the things we have seen in the ecosystem is that roll ups just, they just want a lot of throughput. Well, they want data to be very cheap, and you get cheap data by having really high throughput. If we can be a network that just has really high throughput, a lot of roll ups will just want to be part of that and we get network effects from that. The other part is low latency.
00:53:31.142 - 00:54:18.150, Speaker B: So we specifically, our consensus protocol is called hot shot. It's based on the hot stuff two protocol, which is a linear based protocol and it gets very good finality. So a pretty fast latency. Obviously the latency depends on how much data you have in the network and also your geo distribution of your nodes. But in our latest benchmarking that we've done, we are able to get like 1 second block times and it takes two or it takes two rounds. Our protocol is like pipeline, but basically in a summary, we can get about 2 seconds to commit a block under good conditions, assuming that like, you know, the proposer is online and they don't miss their slot. And what we found is that that's also really important for roll ups.
00:54:18.150 - 00:54:47.694, Speaker B: So I guess the idea, to answer your question is the most important. Parts of us have seemed to just have really like a really performant consensus protocol, and that really is what most roll ups seem to want. Because having a performing consensus protocol that's also fast gives you like cheap data availability and you get, I mean, obviously having a fast, faster confirmation times than ethereum is really powerful. So yeah, I suppose hopefully that's an okay answer.
00:54:53.564 - 00:54:59.748, Speaker A: My question is, can you go over the effects of a sequencer that goes.
00:54:59.876 - 00:55:02.284, Speaker B: Offline or is corrupted?
00:55:02.404 - 00:55:08.260, Speaker A: And can you compare if there's a difference between base sequencers and shared sequencer?
00:55:08.372 - 00:55:45.328, Speaker B: In this case, yeah. So first off, I'd say that base sequencers can also be shared sequencers, so they can be the same thing. And. But, yeah, if a sequencer goes offline. So I'll talk specifically in espresso, you have a couple of scenarios. So in a regular consensus protocol where you only have one proposer that proposes for everybody, if they go offline, you know, the protocol is still safe, but you lose, you lose like your fast finality. So you might have to wait like 30 seconds or like for the next block or whatever, and that's not really good.
00:55:45.328 - 00:56:32.864, Speaker B: But so you're lo, you're losing liveness a little bit. But if there's like no safety violations, if you have multiple proposers, it's actually kind of cool because you can still maintain liveness. So if just one of those proposers goes offline, that's fine because the rest of them are still online and the rest of them can still like get their block committed. So it's actually kind of nice because you can still continue to make progress even if one proposer is offline. As for malicious behavior, I would say, you know, our protocol follows just your standard byzantine fault tolerant model. So we tolerate one third, one third percentage of the stake to be an adversary. Specifically, we have a bribery model, which I could go into if that's interesting.
00:56:32.864 - 00:56:51.944, Speaker B: But yeah, I'd say as far as like, byzantine stuff goes, you know, the model, our consensus protocol is like just as secure as, you know, any other BFT consensus protocol like the finality gadget in ethereum or anything like that.
00:56:52.684 - 00:56:53.644, Speaker A: Cool, sounds good.
00:56:53.684 - 00:56:54.068, Speaker B: Thanks.
00:56:54.156 - 00:57:05.096, Speaker C: Yeah, so you mentioned that like, your kind of end to end latency for acceptance or like finalization was around like 2 seconds.
00:57:05.240 - 00:57:05.896, Speaker B: Yeah.
00:57:06.040 - 00:57:19.576, Speaker C: What are your opinions on the user experience of some, a system like espresso versus a centralized sequencer? Because like, if you look at existing roll ups right now.
00:57:19.680 - 00:57:20.324, Speaker B: Yeah.
00:57:20.664 - 00:58:07.346, Speaker C: The user confirmation time is like really short, zero, essentially. It's like, you know, probably, you know, 100 milliseconds to like send your thing to the, you know, whatever to the sequencer. Now, of course, there's obvious drawbacks with having a centralized sequencer. You know, you're trusting that person. Like if they have failures, you have an outage, things like that. But like during the happy path, normal case that like most l two s are operating in today, that gives the user experience a phenomenal, essentially normal web two user experience of interacting with stuff. So, like, do you expect pushback from users when l two s kind of switch from a centralized sequencer to something like espresso?
00:58:07.410 - 00:59:09.664, Speaker B: Yeah, this is a really, really great question. So this is something that, it wasn't relevant to the presentation, but there's this idea of pre conformations. And so there has this idea going around and it's not a new idea, but it's kind of becoming repopularized, where basically the proposer of espresso or any protocol can offer those 100 millisecond pre conformations, and as long as they propose and they get their block committed, then they're honored. So the idea is that the user could actually still get those 100 millisecond pre confirmations from the proposers of their slot. Now, there's slightly different trust assumptions than like in centralized sequencers today. So you do have the assumption that the block actually needs to get committed. And so that means the proposer needs to make sure that they propose their block on time and also that the network is not in some asynchronous state where, you know, nodes can't vote.
00:59:09.664 - 01:00:27.014, Speaker B: So there's a, there are some slightly extra assumptions going on there, but I think if we look in practice, those are pretty reasonable. So you do run the risk if you have like an asynchronous period, and under that circumstance, well, then it's too unfortunate for the user. The network won't commit their block. But if a proposer is honest and they're proposing their block within a timely manner, then they do have a good amount of control over getting their block committed, which is important. Now, there also are some interesting plays on the specific consensus protocol and depending on how that works, because like, some consensus protocols, so I will say, like, we have a pipelined consensus protocol, and if you're pipelining, you require two blocks to commit, but those two blocks have different proposers. So it is potential that, you know, if, if you one, like, you propose honestly, but then the next proposer doesn't propose, you know, oh, maybe your block gets reorged. However, I'll caveat with saying that that was a problem with hot stuff one, but that's not a problem with hot stuff two, which we have recently switched to in our protocol.
01:00:27.014 - 01:00:41.714, Speaker B: But I guess this goes to say that basically the proposer of each block can still offer those 100 millisecond pre conformations. You have slightly different, different trust assumptions, but you should still be able to get the same user experience for, like, the end user.
01:00:44.534 - 01:00:51.514, Speaker A: Oh, yeah. I want to be respectful of your time because I know we're already three minutes over, but I have more questions. I see Megan is behind me with another question.
01:00:52.014 - 01:00:54.714, Speaker B: I have plenty of time. I'm happy to stay like if people.
01:00:55.414 - 01:01:45.994, Speaker A: I have at least two more questions, so I'll ask one and then get behind Megan and lining. One of the questions I had, I don't know, are, is not clear to me. When you're running like this, there's obviously like an exponential process or algorithm you'd have to run in order to figure out what the most profitable block would be. You could mine across some random ins, L2s or roll ups, but when you don't actually know what is in them. I see how that makes perfect sense. When it comes to these are the transactions that are coming from each of these roll ups. How can I sequence them most profitably? But when it comes to just, there's an expected value from them, how do you actually run that calculation? I'm just sort of having a hard time imagining what that looks like, whether it's just, well, I probablistically say here were all the transactions run it based off of if I could have proposed at some random slot at the same time yesterday, or what you end up doing in that case.
01:01:47.414 - 01:02:42.926, Speaker B: Yeah, probably similar to what you described. So when parties decide how much that they're going to bid in the auction or how many lottery tickets they're going to buy, they'll basically say like, they'll probably end up running like a simulation that says, oh, if I built blocks now, how many of the transactions that I know exist for the current block being proposed, how much would I have made? And I'll set my bid accordingly. And they'll probably do this over a course of time. So they'll say, okay, over the past month, on average, I make $20 from like, from simulating this like sequencing. So I'll bid $19 as an expected value in the auction. But yeah, to your point, I think it's going to be just like simulation and seeing how much you make on average and it's going to adjust. It's not going to be completely accurate, but it'll be up to the people who are submitting the bids to decide how they want to calculate what that is.
01:02:43.070 - 01:02:45.874, Speaker A: Cool. Yeah, that makes sense. Market mechanism cures all.
01:02:49.734 - 01:03:43.930, Speaker B: Hi Ellie. Thanks. I've enjoyed this conversation so far. I just had a question for, for you. Protocols such as op used by base and op stack, I am familiar with their sequencing protocol, also including multiple components like a batcher that actually does the compression and then the proposer which confirms the new Merkle route after the transactions that are in the included block are executed. In the instance of espresso, where sequencing might be a bit more fragmented across multiple machines. How does the protocol ensure that those end state Merkle routes being posted by the proposer are consistent with what is currently being like, especially if it's kind of almost like execution is kind of being run on in different execution environments.
01:03:43.930 - 01:04:21.442, Speaker B: Right. And so they're not necessarily aware of each other. How does it manage that so that they don't have like conflicting state, I guess. Yeah. Okay, so I think a couple of points are, so any shared sequencer, not just espresso, kind of introduces what we're calling this derivation pipeline. And so normally in a centralized sequencer, decentralized sequencer actually, like before they even sequence transactions, they like filter out transactions that don't pay fees that don't, maybe that reverts, et cetera. And so whereas espresso is sequencing and they don't execute.
01:04:21.442 - 01:05:15.450, Speaker B: So espresso actually, or the roll up has to actually do those things after the sequencing instead of before. So when I say paying fees, there's two kind of fees. There's like the sequencing fee that you're paying for your data to be on the network, and then you have your gas fees. So espresso or any shared sequencer is aware of the sequencing fee, but they're not aware of the gas fees. So it's very possible that you might have a transaction that pays its sequencing fee properly, but then runs out of gas or something like that. But to your question, the way it works is basically that espresso sequences and then the roll up has this derivation pipeline, and that would either be like a committee of roll up nodes, or it could even be like a single node because it's not a trusted, there's no trust assumptions like you can prove whether or not they followed the protocol. So basically, some node after espresso sequences would run this derivation pipeline.
01:05:15.450 - 01:05:58.594, Speaker B: The pipeline would take what espresso sequence is. It would turn it into a roll up block, it would execute it, it would calculate the state root and it would batch it and it would post it on chain. So in terms of op, I actually was not the one who worked on espresso's op integration. So hopefully what I'm saying is somewhat accurate. But basically, yeah, all of the batching and stuff is done after by some node that's outside of the espresso protocol. But because it's not a trusted role, because you can easily prove whether or not someone can always prove, oh, you didn't actually derive the state correctly. Hence that would be a fraud proof in op.
01:05:58.594 - 01:06:12.084, Speaker B: It's okay for that to be maybe a centralized role? Um, yeah. Does that answer your question, or did I miss miss the mark? No, I think that's that's as good. As good as I could assume. Thank you.
01:06:13.664 - 01:06:28.718, Speaker A: Does anybody else have any more questions? All right, thank you so much for coming out. I think that was, like 30, 40 minutes of questions. So really, really appreciate you coming to give the presentation. I really appreciate you. Questions?
01:06:28.856 - 01:06:36.214, Speaker B: No, I really, really appreciate you guys having me. This is really fun. I really appreciate all the questions and. Yeah, this is great.
01:06:36.754 - 01:06:42.122, Speaker A: Thanks so much for coming. It was really great to see what you guys are building. Really excited to see them in production soon or testnet.
01:06:42.218 - 01:06:43.294, Speaker B: Yeah, yep.
01:06:43.714 - 01:06:44.490, Speaker D: Awesome.
01:06:44.642 - 01:06:54.614, Speaker B: All right, thank you. Bye. Sa.

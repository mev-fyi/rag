00:00:07.770 - 00:00:09.854, Speaker A: GM. Guys, how's it going?
00:00:09.972 - 00:00:10.830, Speaker B: Gm?
00:00:11.890 - 00:00:12.590, Speaker A: Look at this.
00:00:12.660 - 00:00:12.894, Speaker B: Good.
00:00:12.932 - 00:00:13.710, Speaker C: How are you?
00:00:13.860 - 00:00:22.270, Speaker A: Great. I love this, like this new stream setup we have. Everything feels so official, you know? I don't know. It's very well put together. Shout out to Sam.
00:00:23.010 - 00:00:23.760, Speaker B: Good.
00:00:24.210 - 00:00:25.640, Speaker C: We're legit now.
00:00:26.330 - 00:00:43.770, Speaker A: Religion now. That's a good way to put it. Very excited to be here today. Wow. I think the past 48 hours has been very fun. I think not only for us here at offchain labs, but also everyone in the community, the users, the dgens, the projects. I think everyone's been pretty excited.
00:00:46.750 - 00:00:58.266, Speaker C: It's only like a casual couple of years of work all coming together towards something that's making, using ethereum and arbitram actually massively cheaper. I mean, who cares?
00:00:58.458 - 00:01:07.620, Speaker B: Yeah, but it's not the end of the journey either, right? We have a long way to go to make this even better, even more scalable than it is, right?
00:01:07.990 - 00:01:09.474, Speaker A: 100%, yes.
00:01:09.672 - 00:01:18.660, Speaker C: That constant blockchain grind of like, okay, that's over now. What's the next thing? Where are we going next? Denkoon blobs. That's old news.
00:01:19.590 - 00:01:25.238, Speaker A: I used to think there was a point where we'd actually relax a little bit, but there is no, that's right.
00:01:25.404 - 00:01:27.800, Speaker B: We need to add a zero as soon as possible.
00:01:28.110 - 00:01:53.614, Speaker A: Yes, the meme. Embracing the meme. Okay, so before we get into it then, for people who don't know, I'm Hunter. I do community strategy here at Offchain Labs. I'm joined today by Harry, co founder and CTO at Offchain Labs as well. And of course Ed Felton, who's also a co founder and chief scientist here at OCL. And yeah, I think it's like we have a ton of stuff to talk about.
00:01:53.614 - 00:02:09.240, Speaker A: Obviously, you already mentioned a couple things, Ed. Maybe we can start off just with maybe like an Eli five on Denkun and maybe how Arbos v 20 atlas kind of mixes there.
00:02:09.850 - 00:02:12.562, Speaker B: Maybe I'll talk about Denkun and Harry can talk about Atlas.
00:02:12.626 - 00:02:12.902, Speaker A: Perfect.
00:02:12.956 - 00:02:13.334, Speaker C: Sounds great.
00:02:13.372 - 00:02:52.242, Speaker B: Cool. All right. Yeah. So Denkun is the latest Ethereum hard fork or upgrade that has been live for about two days now. And it brings a bunch of improvements to Ethereum, things around how, say, ethereum validators can stake and unstake and some useful technical improvements. But the big thing that Denkun brings brought is EIP 4844 or data blobs. And so what this is basically is, it's a different way that Ethereum can store and provide availability for data that is lower cost.
00:02:52.242 - 00:03:12.570, Speaker B: And it's lower cost because it does less, but it does enough to support roll up chains like Arbitrum. And really, all the L two s. So new way of having data that's much lower cost. And that translates into a big opportunity for roll ups like the arbitrum tech roll ups. And that brings us to Atlas.
00:03:14.270 - 00:03:33.982, Speaker C: Yeah, so Arbitrum, atlas with Denkoon blobs are available, but there's nothing kind of. It's a whole new API. It's a whole new thing that is kind of, hey, there's this blob. There's a new transaction type. There's all this new stuff. Roll ups get nothing out of the box. And kind of, as you may have seen, some roll ups already are using blobs.
00:03:33.982 - 00:04:25.410, Speaker C: Other roll ups aren't using blobs. Arbitrum one started using blobs around a day after they started existing on Ethereum. And that's because this is a significant architectural difference. And so work had to be done in order to both sort of have the batch poster, which actually is responsible for taking user transactions and putting them onto Ethereum. To actually understand this new type, the actual smart contracts had to be modified in order to actually be able to receive the blobs and be able to make use of them and kind of perform the same duties as they do with call data, except on this new data type. It also required a lot of advanced planning. And if you look the arbitrum dao a month ago, or more than a month ago, was talking about this and talking about Arbos Atlas, because this is not a thing that kind of anybody could just do.
00:04:25.410 - 00:04:37.380, Speaker C: This is a thing that's kind of a comprehensive change to the whole system in a fairly deep way, rewritten on top of in order to be able to use this whole new data type.
00:04:38.950 - 00:04:58.282, Speaker A: Gotcha. And I think you kind of mentioned it there, Harry. So in this case, obviously, Ethereum upgraded to kind of support blobs, but also every l two individually had to do the same. Is there kind of like, at this point, is every l two supporting blobs right now, technically, or there are some.
00:04:58.336 - 00:05:13.026, Speaker B: I guess all of them. Most of the major ones are, but the rest, we assume, will bring blob capability online over the coming days or.
00:05:13.048 - 00:06:15.682, Speaker C: Weeks, roughly speaking, I think a lot of the complexity here comes from kind of call data was relatively simple, and that you get the data in your smart contract and you can do whatever with it. You can hash it, you can kind of store it, you can do anything you want. Blob data. You instead, introduce a bunch of new cryptography using kind of the KZG commitments is the way that those show up on Ethereum and actually sort of integrating those into fraud proving systems or into validity proving systems tends to bring along kind of a good bit of complexity. It's very doable, but it's also kind of very nontrivial, the work necessary in order to do that. And I think that kind of getting those components integrated, it's not as simple as just basically you're posting blobs there. It's that when those blobs get posted, your whole sort of roll up, validity, fraud, what have you, system has to account for it and be able to handle it.
00:06:15.816 - 00:06:53.360, Speaker B: Yeah. So the engineering team at offchain labs started working on this integration last year, and then it was tested on the sepolia testnet before Ethereum was ready with their dencoon upgrade. So, yeah, when Ethereum brought this data blob functionality in two days ago, one day later, the Arbitrum atlas upgrade was deployed and arbitram one started posting these data blobs, and you saw a big reduction in transaction cost at that time.
00:06:54.450 - 00:07:07.362, Speaker A: That's awesome. Yeah, I remember when I was tracking it yesterday too, and I'm like, I think the first swaps were like a dollar 30. I tried it again after blobs went live. Like literally right after blobs on the lives. $0.40. I'm like, okay, it's a little cheaper. I tried it again after 510 minutes.
00:07:07.362 - 00:07:27.340, Speaker A: It's like $0.04. Okay, that's a lot cheaper. Yeah, it was very surprising. I think before we do dive into EIP 44 in particular, there were different EIPs in Atlas. Is it worth just like broad kind of brush? Just mentioning those real quick?
00:07:28.510 - 00:08:08.460, Speaker C: Yeah, okay, let's see now I'm going off the top of my head. So you're testing me a little bit. There's a number of. And these are kind of all things that were picked up from Ethereum and that kind of when sort of arbitrum adopts an upgrade. It's interesting with Denkud in general, there's really sort of two things that happened. One is that Ethereum started supporting these blobs and arbitrum wanted to make use of it. But there's also, for any Ethereum hard fork, this notion of kind of, well, Ethereum is making changes to how the EVM works, then maybe arbitrum would want to actually pick up similar changes.
00:08:08.460 - 00:09:14.206, Speaker C: And this doesn't happen automatically. In fact, it actually kind of caused, I would say, a decent amount of kind of pain in the arbitram ecosystem. Not from this consensus upgrade, but from the previous consensus upgrade, which added a new opcode called push zero, which was incorporated in Arbo s Eleven, which happened, I'm not sure how many, but a number of months after it had been deployed on Ethereum and developers kind of had certain EVM code, would work on Ethereum, wouldn't work on Arbitrum. Not very fun with Denkoon. Arbitrum as part of Arbo S 20 was updated to include all of the core relevant changes from the Ethereum upgrade into arbitrum. And kind of from that, you have transient storage, which is kind of this big, and you also have kind of changes to how self destruct works. And you also have an interesting kind of low level technical detail about sort of copying memory, which is probably, I would say the least exciting of those three.
00:09:14.206 - 00:10:02.160, Speaker C: Transient storage. You've probably heard a bunch about this from Uniswap V four, which kind of was built using transient storage. And the Uniswap team did a lot to kind of push for people to get excited. I'm not going to go into kind of the lower level details of exactly what it does, but it essentially provides a version of you have memory that's kind of just in your smart contract and just in sort of like a particular kind of call to your smart contract. So it disappears the second you leave it. You have storage, which is permanent, and then you have transient storage, which is somewhere in between and kind of lasts for a transaction. And then, so the self destruct one is interesting in that this isn't why it was done.
00:10:02.160 - 00:11:03.940, Speaker C: It was done as preparation for verkel trees, because self destruct will actually remove entire accounts from the state. And doing that after verkel trees, complicated. I am not an expert here, but kind of very messy. It has a nice side effect though, which is that one of the biggest types of vulnerabilities that's affected Ethereum smart contracts is based on this pattern of your smart contract is using a transparent upgradable proxy, because you want to be able to upgrade the logic. And your logic contract, which is kind of the actual backing code for it, contains a call to self destruct, and it's not permissioned, and anybody can call it. And so they can basically completely brick your smart contract if they can find a way to call self destruct in the logic contract. And I think the highest profile version of this that occurred was a number of years ago.
00:11:03.940 - 00:11:24.920, Speaker C: There was a huge amount of ETH that's locked and is still locked to this day from a smart contract wallet that gnosis had that had this issue, and someone came along and triggered it, and the money was trapped forever. So the fact that that can no longer happen again is pretty nice.
00:11:26.090 - 00:12:06.370, Speaker B: Yeah. So that's sort of a good housekeeping improvement in Ethereum, that it makes Ethereum safer. And by making it safer, like Harry said, it helps to lay groundwork for future changes to Ethereum, in particular the vertical trees, which are an improved way of managing the state of Ethereum, which we think is coming, which is coming at some point in the future. So this is the next step in a longer roadmap for Ethereum, just like Atlas is like the next step in the further development of arbitram.
00:12:07.430 - 00:12:42.382, Speaker A: Interesting. And I think all that makes as much sense as it can to someone who doesn't do any core development work. For what it's worth, when I was doing research on this beforehand, the conclusion I came to, and I feel like it was coming through, and how you guys were explaining this, is we're essentially giving a lot more capacity to l two s today through blobs and APO 44 in particular. But we're also kind of setting it up so that the structure of transactions and whatnot are essentially going to be ready for the future of Ethereum when sharding or something kind of comes into play.
00:12:42.436 - 00:13:49.160, Speaker B: Yeah, exactly. So one of the clever things that the Ethereum community did in how they designed this EIP 4844 data blob mechanism is that there's a lot of room for growth, that the code in a roll up that can handle these data blobs, that there will be future generations of the data blob mechanism in Ethereum, which will be more and more capable, they'll be able to handle more data and handle it reliably and with lower cost. And the beauty of the design change that happened now is the roll ups won't have to change their code at all to use these improvements, because this is because the API, that is the way that rollups talk to Ethereum to use these data blobs, is already set up to handle the future roadmap of Ethereum. And so that's pretty great. What it means that is as Ethereum upgrades into better and better versions of the blob technology, that roll ups will just automatically take advantage of that.
00:13:50.730 - 00:14:13.594, Speaker A: That's awesome. I don't know. For some reason I kind of learned this, I think, like two days ago before the taxi went live. It's just so cool. It's like one of the little things that I don't want to say was snuck in there, but just wasn't included in the grandiose marketing and from people on CT that just roots this really cool little fact there. We're really literally future proofing ourselves for the future of Ethereum.
00:14:13.642 - 00:14:52.780, Speaker B: Well, that's like, to me, this is just an illustration of why the really big and robust and diverse Ethereum technical community is so valuable, because you have so many eyes on these proposals and so much public discussion of what they are and how they can work, and that you really get that distillation of the best ideas across the whole community. I mean, it's true in Ethereum, it's true in the arbitram community as well. You just have a lot of brains that are thinking about and talking about this, what can happen, and not just what is the amazing thing we're going to do, but what is the best way to do that amazing thing so that it's going to have legs into the future?
00:14:53.950 - 00:15:30.422, Speaker A: No, definitely, yeah, 100%. And I think with that we can jump into a little bit of the EIP 44 stuff. I think on the surface, kind of like the explanation of blob data makes sense to me, but I think there's a lot of nuances there that are really important. I think one of which is that you can correct me if I'm wrong. I feel like I've been kind of viewing this as more of like it's essentially a global market that's on Ethereum, that every l two is more or less kind of competing for space on, essentially. I guess the question here is, do other l two s essentially affect pricing for blob data, for example?
00:15:30.476 - 00:15:32.086, Speaker B: Arbitrary? Yeah, they do.
00:15:32.268 - 00:15:32.566, Speaker C: Yeah.
00:15:32.588 - 00:16:05.822, Speaker B: Let me talk about how the pricing works, and there's a lot of nuance in it, but at a basic level, it's pretty simple that Ethereum has a target of using three blobs per ethereum block. So that's one blob every 4 seconds, on average. One blob, excuse me, one data blob. A data blob is about 128 data. It's just a fixed size chunk of data. And ethereum has this target of about one blob every 4 seconds. And so Ethereum keeps track of how many blobs are used.
00:16:05.822 - 00:17:02.942, Speaker B: And if the usage is above the target, then the price of blobs will go up. Ethereum will automatically adjust the price of blobs so that if usage is above the target, the price goes up. If usage is below the target, the price goes down. And so if you think about this, basically, if there's a lot of use, that will cause the price to go up, and the price will go up and keep going up until the users kind of back off a little bit, right? Because the price is high, so the price goes up, then people will slow down, and then the price will kind of come to an equilibrium to like a middle level where the price is high enough that people are not overusing it, but also low enough that people are really using it at the target. So right now, we're in very early days, and in fact, the price is almost zero. The price is at the minimum because the roll ups use is not quite up to that. Three blobs per block per ethereum block.
00:17:02.942 - 00:17:57.350, Speaker B: One blob per 4 seconds target. But if usage of blobs continues to grow, then you get to the point where the blob price will go up and it'll sort of stabilize at some middle level. But it's kind of supply and demand, right? There's a fixed supply of blobs, one every 4 seconds, and the price will go up as needed to make sure that blobs aren't overused. So you can think of that as a kind of anti spam mechanism. That's one way of thinking about it, right? If people start spamming Ethereum with blobs, the price will go up, and it will go up enough to scare off the spammers. But you can also imagine a scenario where roll ups want to use an awful lot of blobs, and so the blob price goes up higher. So we're kind of living in the super happy time right now because blob prices are absolutely on the floor.
00:17:57.350 - 00:18:36.580, Speaker B: They're minimum, literally one way. That is a billionth of a billionth of an ETH for each byte of data in a blob. So that's incredibly cheap. It might not be that way forever, but it will be cheaper than data has been. And as Ethereum grows its blob capacity, right, then that target will no longer be one blob per 4 seconds. It might be one blob per second or one blob per 64th of a second. We can kind of see what's going to happen, that Ethereum will grow its capacity, and every time they grow capacity, prices will come down and roll ups will be able to do more.
00:18:38.550 - 00:19:18.560, Speaker C: You can look at this and think about this very similarly to how kind of regular gas has worked on Ethereum in that you have kind of a very similar situation where you have this pricing adjustment. You have the 15 million gas per twelve second target. It can go above there, up to 30. If that happens, the price rises, it can go below there, the price falls. And periodically, miners. Wow, okay, that's old. Validators have voted to increase the amount of gas that the network can actually handle in order to allow for more.
00:19:20.850 - 00:19:22.430, Speaker A: I almost hit that slip for a second.
00:19:22.500 - 00:20:10.890, Speaker B: So one thing that's important for people to understand about this is that the price of blobs is a separate price from the price of ethereum gas. Right up to now on Ethereum, there's been just one kind of gas and one price. But now with blobs, there's regular gas, if you will. And there's this new thing called data gas. Some people call it blob gas, but data gas is the official name, and those two prices can go up and down separately. And so even if the Ethereum gas price goes up a lot in the old days, before EIP 4844, if the Ethereum gas price went up, then everything would get more expensive on roll ups because roll ups were using gas, Ethereum gas, to store their data. Now roll ups switch to using blobs.
00:20:10.890 - 00:20:16.260, Speaker B: The gas price on Ethereum can go up, but if the blob price stays low, roll up users will still be happy.
00:20:18.150 - 00:20:41.338, Speaker A: That's a great way, I think, to actually visualize it now. Yeah, essentially like call data in this case can be considered that, essentially like space or storage, that both L1 and L two share. Which is why L1 congestion. It gets really expensive for L two s. But in this case, blob gas is literally just for L two s. Yes, interesting. I think that's a great way to think about it.
00:20:41.344 - 00:21:39.814, Speaker B: I mean, anybody can use it, but the blob functionality is really kind of designed ideally for roll ups to use. And this is part of Ethereum's roll up centric roadmap. The idea that Ethereum is, in addition to being an ideal platform for a lot of things, it's working to make itself an ideal platform to build roll ups on. And so this is a huge step down that road to provide this blob data capability that does just what roll ups need and is cheaper, because while it meets the needs of roll ups, it doesn't try to meet all of the needs. So to give an example of the difference that between blob data and the old call data, that allows blob data to be cheaper, call data lives forever, whereas blob data. The Ethereum consensus nodes remember it for 18 days. That's plenty long for roll ups.
00:21:39.814 - 00:21:53.040, Speaker B: But the fact that the network is not committing to store that data until the end of time actually allows it to be a lot cheaper, cheaper for Ethereum to provide, and therefore the price can be lower.
00:21:57.890 - 00:21:58.698, Speaker A: Go for it.
00:21:58.804 - 00:22:18.120, Speaker C: Oh, no. I was just going to say I am going to be really interested to see what other weird things people use blob data for, because I completely agree with ED that kind of roll ups are the natural sort of use case. Although I'd be shocked if there weren't some really weird, interesting other things developers figure out to use them for.
00:22:18.650 - 00:22:35.694, Speaker B: We may see some things develop. Yeah. Other uses for blobs that are creative and interesting, and some of those could be quite valuable. Some of them could be kind of spammy. And if the spammy ones come along, then the price of blobs may go up a little bit until the spammers are scared off.
00:22:35.892 - 00:22:39.726, Speaker A: Inscriptions V two is that we're hinting at whatever.
00:22:39.828 - 00:23:19.430, Speaker C: Yeah, we've actually talked about this some internally, it's relatively awkward, because one of the interesting characteristics of blobs is that when you buy a blob, you have to buy a full 128 data. And so you can't right now kind of easily sort of just get a fraction of a blob, which means that use cases like inscriptions are a little trickier because you can't just have large numbers of users swarming into post transactions. You need either sort of an application where a user kind of wants to use all of it, or an application where the data gets aggregated in some way so that a lot of kind of different things can combine into a single blob.
00:23:19.510 - 00:23:26.640, Speaker B: So inscriptions running on top of roll ups. Yeah, the roll ups use blobs. That's a thing that can happen.
00:23:27.490 - 00:23:29.230, Speaker A: Gives me too many ideas.
00:23:30.610 - 00:23:34.050, Speaker B: I don't think that's going to come as news to the inscriptions folks.
00:23:35.030 - 00:24:08.406, Speaker A: That's a good point. I think it's worth maybe just digging into that data storage kind of piece there a little bit that you mentioned, ed. So after 18 days, essentially the stuff is parsed from regular. It sounds like Ethereum nodes. I feel like to me, the obvious question there is a, how does one access that data? And B, how much does that actually grow? The state. If I were running a full node, how much would that actually grow?
00:24:08.428 - 00:24:58.522, Speaker B: The state of Ethereum, if you're running an arbitram or Ethereum node. Ethereum node, yeah. So I mentioned the 18 days thing that blobs only live for 18 days. The other thing about the other place where Ethereum makes it cheaper is that Ethereum consensus nodes that are, say, staking and participating in the consensus protocol, they have to look at the blob data and verify some cryptographic properties of it. But if you're running a normal Ethereum execution node, you don't ever need to see the blob data. Your node doesn't ever need to see it. And that's because the execution layer of Ethereum doesn't get to see the blob data.
00:24:58.522 - 00:25:49.354, Speaker B: Ethereum will record that blob data kind of as part of its consensus. But the execution layer of Ethereum, the smart contracts running on Ethereum, they can't access the blob data directly. And that makes it cheaper because Ethereum nodes that aren't participating in the Ethereum consensus protocol don't need to download blobs, never need to see them. That makes it cheaper. And roll ups don't need Ethereum nodes to see that data, because the roll up just needs to know that the roll ups nodes can get the data and they can get it from Ethereum consensus nodes. So that's the other thing that Ethereum does to make blobs less functional, therefore cheaper, but less functional in ways that roll ups don't mind. Yeah.
00:25:49.354 - 00:25:58.670, Speaker B: So if you're running a normal ethereum, just a normal full node that's not staked, then your full node is probably never going to see these blobs.
00:26:00.850 - 00:27:03.166, Speaker C: It's funny, ever since the merge, we've been in a situation where we've had, there's ethereum with kind of the execution layer, and then there's the beacon chain. But the beacon chain hasn't really kind of like, if you think about it in terms of abstractions, the beacon chain hasn't really leaked out at all to the execution layer in any way that kind of most people really think about or care about. And so if you've been running an arbitrary one node, your arbitrage, one node points at your guest node or whatever execution client you're using, and that's it. And that's kind of a big change. Now, post 4844 is that the consensus layer actually has become really relevant, because the consensus layer is where these blobs are. And the consensus layer is if you're running a consensus node like prism, it's storing a couple of weeks worth of blobs, which is kind of only a couple of weeks. And so it's sort of not continuous state load.
00:27:03.166 - 00:27:21.980, Speaker C: It's only sort of an extra sort of amount of hard drive space that you need, which kind of makes it very reasonable, but you do. To run an arbitrary node now at least to run an arbitrary one node as of yesterday morning, it has to have two RPC endpoints, one for execution, one for consensus, which is really interesting.
00:27:23.310 - 00:27:44.730, Speaker A: Oh, interesting. I feel like also, I don't know, I mean, don't get me wrong, I'm sure that a consumer hardware will still kind of normalize the whole probably 500 gigabyte 1 TB options that people have. But I was looking the other day for internal hard drives for my PC. Got an eight terabyte one for like $100. That's incredible.
00:27:44.810 - 00:27:48.114, Speaker B: Pretty good. Yeah, a lot of blobs on there.
00:27:48.312 - 00:27:50.660, Speaker A: I got a blob machine over here running now.
00:27:51.270 - 00:27:56.034, Speaker B: Well, except you won't need to store too many because you can drop them after 18 days.
00:27:56.232 - 00:27:57.220, Speaker A: Thank God.
00:27:58.070 - 00:28:00.034, Speaker B: If you're an ethereum consensus node.
00:28:00.082 - 00:28:07.570, Speaker A: Yeah, everything is scaling online. We're doing the scaling on chain and then the hardware companies are doing the scaling for data, which is a great.
00:28:07.580 - 00:28:58.520, Speaker B: Yeah, so I said before, right, that Ethereum has this target of basically three blobs per blob, or one blob every 4 seconds. The place that number comes from is actually looking at sort of how much bandwidth do typical end users have to download blobs if they're running a consensus node, how much storage they typically have. It's really those kind of practical limits on what regular people's nodes can do that sort of set these target and max rates. Just like the Ethereum gas limit is chosen partly based on sort of people thinking about, well, how much could a regular end user's machine actually do? Same way. And so as machines grow, you expect all these systems to get more capacity, gas limits, blob limits to go up.
00:28:59.690 - 00:29:03.146, Speaker A: It's kind of like inflation of the hardware in a good way, in this.
00:29:03.168 - 00:29:12.320, Speaker B: Case, in an excellent way. Yeah. More slot makes our hardware a lot more capable over time. So all of our systems can do more.
00:29:13.650 - 00:29:21.920, Speaker A: Is it possible that pricing just becomes too cheap to the detriment of an l two?
00:29:22.610 - 00:30:11.642, Speaker C: No, this is where congestion comes in. This is this idea of kind of like, and this is sort of like essentially fairly a basic form of kind of market economics in that kind of Ethereum and arbitrum provide capacity, and they provide a fixed amount of capacity actually, and within there you have some amount of demand. When there's less demand than supply, it can be really cheap. And in fact, and I don't know, maybe we're going to get into this later. I think on Monday night, a change will be executed that the Dow voted on to lower the minimum base fee from 0.1 guay to zero one guay on arbitram one. But that's just the minimum.
00:30:11.642 - 00:30:53.222, Speaker C: That's sort of like, even if there's less demand than supply, some amount of fees are still collected for execution gas. But that's different than what does the price actually look like? And if you look just last night, I think among the kind of market turbulence, arbitram one actually ended up congested where the gas price was more than 0.1 way because there was more demand than supply. And very similarly to Ethereum, how we talked about kind of with, if it's using more than kind of like the target amount of gas, the price goes up. Arbitrum one operates in a very similar way. And so these things equalize. And essentially, the set of transactions that people are willing to pay the most for will get in and other transactions won't.
00:30:53.222 - 00:31:06.914, Speaker C: And if there are kind of more people willing to pay at the current price than there is supply, the price will keep on rising and it'll continue rising until it levels out at some equilibrium where the amount of demand and the amount of supply are equally matched up.
00:31:07.112 - 00:32:40.318, Speaker B: Yeah, it's kind of fundamental to the design philosophy for an open and permissionless chain that if your pricing mechanism is designed correctly, then you don't have to be opinionated or judgmental about which transactions can run which transactions have value, because the price will equalize and the people who, the transactions that are willing to pay will pay and others will not. So if somebody shows up and they want to buy all of the capacity of the chain, then as long as they're willing to outbid everyone else, then so be it. The chain is not going to be judgmental and say, well, your application, your use, is not virtuous enough, is not valuable enough. This just kind of not rationing by sort of administrative action of some committee somewhere. But if there is a lot of demand for the resource, rationing by price is fundamental to the way blockchains work. And I think roll ups, probably after this transition that's happening now and over the coming days, are going to be in a situation that's kind of like Ethereum, where prices are set by supply and demand. And the idea that there's a fixed price on the transaction that is going to be the same today and tomorrow, that's not the case.
00:32:40.318 - 00:32:47.780, Speaker B: That prices will vary. And people who do transactions when the prices are lower will get a better deal.
00:32:50.390 - 00:33:09.862, Speaker A: So considering the fact that we mentioned earlier that HL two kind of has to essentially opt into this upgrade, would you say that probably each l two also has I guess their own different strategy and how to approach blob posting, for example. Because I've noticed for example some l two s have posted more blobs than others.
00:33:09.996 - 00:33:10.680, Speaker C: Yeah.
00:33:11.150 - 00:33:59.618, Speaker B: So if you look right now at the data just at this moment, you'll see that starknet is posting a lot more, doing a lot more blob transactions than others. They tend to post one blob at a time when ethereum allows you to post up to six at the same time. And I don't know exactly what their strategy is there, but certainly there are different ways that chains can use this blob capability. And we're going to see chains strategies adapt if blob prices go up. This means that there's a premium on adopting strategies that are really cost efficient. Just like whenever anything is expensive, people try to figure out how to get their job done while using less of that thing. And so we're going to see this adaptation over time.
00:33:59.618 - 00:34:04.780, Speaker B: But you definitely do see some differences in strategy across different roll ups and I think that's going to continue.
00:34:05.950 - 00:34:24.418, Speaker A: I think it's so funny too because over the past probably couple of hours, 24 hours maybe, I think I did see someone from this darknet team almost like apologize for taking up too much blob space. I was like wow, I don't know, it's kind of interesting. I wasn't complaining, but I guess maybe we should be.
00:34:24.504 - 00:35:03.520, Speaker B: Yeah, I'm not complaining either. Right? That's the thing, right? The chain will ration the resource and set the price automatically. So there's a sense in which you can't use too much. If you're willing to pay for what you use and other people are not willing to pay for that capacity, then more power to you. If the price goes up then maybe they'll use less. And in fact that could be built in, right? I wouldn't be too surprised if they have a strategy that adapts to the price and behaves differently depending on the price. Use more blobs when the price is low and try to economize when the price is high.
00:35:03.520 - 00:35:13.040, Speaker B: That would be probably a clever thing for them to do. Maybe that's their strategy, I don't know, we'll see if and when the price starts to move.
00:35:13.490 - 00:36:09.982, Speaker C: Yeah, the interesting thing here is basically kind of the economics of batch posting. Certainly for arbitrary one. And I would hope for roll ups in general. I think for roll ups are that of kind of passing through the costs of posting to ethereum to their users. And so essentially, kind of right now, blobs are so cheap that your efficiency really probably doesn't matter that much. Whereas kind of if sort of, there was enough demand for blobs that the amount of blobs being the price of blobs actually went up, then suddenly it would start to make really meaningful difference how efficiently you're actually consuming blob space. If you're really inefficient, your users will be paying more, which probably means you'll end up with fewer users, potentially, and then kind of have less demand to consume blobs in that direction.
00:36:09.982 - 00:37:04.354, Speaker C: On that note, and this is a bit of like an esoteric fun fact, I'm just reminded it's very nontrivial to actually make fully efficient use of blob space. Because blobs are this very mathematical thing that's very much not just, here's my data. And sort of, it's interesting in that we did a bunch of optimization work, although we didn't actually perfect it, we decided not to, because we got within, I forget, like 98% of filling it, to the degree that the extra 2% would have to come from some very weird and kind of risky code and encoding schemes. And that was where we decided, okay, for now, we're going to top out here, just because the mathematical complexity of actually being fully efficient. And Ed, you might understand why this. I don't even.
00:37:04.392 - 00:37:08.770, Speaker B: Totally. So it's a funny.
00:37:09.130 - 00:37:10.806, Speaker C: Yeah, let me give just a little.
00:37:10.828 - 00:37:59.170, Speaker B: Bit more detail on that. Because the blobs are these sort of cryptographic constructs. The blobs are made out of words, and a word is 32 bytes of data. But it turns out that each word, in blob math, if you will, each word is represented as a big number, a big integer. And you'd like it to be the case that any integer that you can write with 256 bits can be in a blob. But in fact, there's like a small range of those possible integers that are not allowed for esoteric mathematical reasons. And that means you can't just take bits of data and drop them in as blobs.
00:37:59.170 - 00:39:06.300, Speaker B: Because it might be that when you line up the bits of your data, whatever your data is, that there might be some word which interpreted as an integer, is like, in the forbidden range, and then your blob would be invalid, and that would lead to sadness. So you actually need to think very carefully about arranging that each one of the little 32 byte sections of your blob, interpreted as an integer, doesn't fall into the forbidden range. And so you need to check that. And if it is the case, you need to move stuff around. And we're not here for a graduate seminar in cryptography, but bottom line is that there's a lot of tricky stuff that you need to do to use blobs effectively. And you can always squeeze out an extra fraction of a percent by being that much more clever, meaning that your code is that much more complicated. But from an engineering standpoint, you don't want to introduce too much complexity in order to gain a tiny advantage cost.
00:39:06.300 - 00:39:31.940, Speaker B: You really have to think carefully about the risk versus reward. There. That's one example of the deep sort of technical and engineering work that the engineering team had to do to make this happen. For users, it's just like, hey, we have blobs now. It's a lot cheaper, but there's a ton of this sort of intricate engineering that happens to make that actually possible.
00:39:32.790 - 00:40:01.110, Speaker C: I remembered where it was that we kind of the actual detail. Yeah. So it's essentially exactly like you described. So using up all the words is easy. And then there ends up being kind of an awkward extra set of bytes that are available and that we figured out to use. And each word is 32 bytes, and then there's kind of some other bytes. So we figured out who to use, and then there were some extra bits available because each byte is made up of eight bits.
00:40:01.110 - 00:40:12.240, Speaker C: And that's where we decided to stop and say, okay, if there's extra bits, we're going to use the extra bytes because that makes a pretty nice difference. The extra bits we're not using.
00:40:14.450 - 00:40:32.102, Speaker A: I kind of get that this can be a very stupid analogy, maybe, but, okay, almost when you're trying to optimize for throwing out the trash, you want to put as much stuff in the trash as possible, but it's kind of hard to figure out what to put kind of all the way at the very top because it gets smaller and smaller as you close.
00:40:32.156 - 00:40:39.110, Speaker B: Exactly. Yeah, it's kind of like that. And you don't want to spend, like 20 minutes carefully packing your garbage bag.
00:40:39.190 - 00:40:39.820, Speaker A: Right.
00:40:40.350 - 00:40:59.760, Speaker B: If it's not completely full, well, maybe you make, like, one extra trip to the trash place a year, so be it. Yeah, it's kind of like that. You want to be a little bit careful about how you pack stuff in, but don't go crazy.
00:41:00.450 - 00:41:04.030, Speaker A: There's like a certain level of efficiency that you can reach before it gets inefficient.
00:41:04.850 - 00:41:25.638, Speaker B: It's not worth it here. I mean, because it's a computer doing it. It's not you doing the work, it's a computer doing it. But still, if the software is more complicated, the risk that there's some bug that's going to bite you at the worst possible time, and even worse, maybe even lead to a security problem that comes in when you add complexity. And so at some point you just.
00:41:25.644 - 00:41:29.718, Speaker A: Have to say, enough, 98% sounds good to me.
00:41:29.884 - 00:41:31.260, Speaker B: That's way better than.
00:41:32.030 - 00:41:48.926, Speaker A: Yeah, I think one thing maybe worth just like also throwing in there because, I don't know, maybe there is a difference, maybe there isn't. I think up until this point, we've just been talking about all twos. What about orbit chains? Whether they're all twos or all threes, and maybe even ones that are just alt da, do they even see any of this stuff?
00:41:49.108 - 00:43:15.914, Speaker C: Okay, so there's a whole matrix of different kind of combinations here. The only one that in terms of kind of normal prices, will end up seeing a major, sorry, there are two that will, with normal, with kind of normal behavior that will end up seeing a large pricing reduction, which are l two s on top of ethereum, or, sorry, maybe I'm not doing right, which are roll up chains, l two roll ups on top of ethereum or l three roll ups on top of arbitram one. L two roll ups because they'll be using blobs directly, l three roll ups, not because they're using blobs, but arbitram one is becoming significantly cheaper currently, and roll ups on top of arbitram one, because arbitram one itself is cheaper, will end up seeing their own prices fall significantly. Anyone using Altea on their primary alt data availability mechanism, they won't see any difference. Although interestingly, with arbitram, any trust, where it's always been, you have your data availability committee. But if for whatever reason data availability committee disappears, or kind of enough of them disappear to not be able to use that as your data availability layer, the system can fall back to posting on Ethereum. And in that case, actually any trust chains could benefit in that.
00:43:15.914 - 00:43:48.520, Speaker C: Before the cost differential between we're on any trust data where it's super cheap and then we need to fall back would be huge. And so it's always been kind of like, you can fall back, but it's really a crisis. It's kind of a major crisis, whereas this kind of will interestingly close the gap a little bit in that it won't be quite as big of a deal if your committee can't actually sort of form and reach consensus because the fallback option is a lot cheaper than it had been before, at least for now.
00:43:51.050 - 00:44:02.620, Speaker A: Interesting. That's a great point, actually, as you mentioned, in the worst case, the transaction difference for users, I guess, currently wouldn't be that different.
00:44:04.350 - 00:44:29.460, Speaker C: Yeah. Right. Now with blobs as cheap as they are, and it's interesting because I think the expectation is that it's fairly temporary. But for now, the prices on arbitrum one and the prices on Arbitrum Nova are going to be very similar. Now, with arbitram Nova, you're not dependent on Ethereum. And so as blobs become congested, they'll become quite different again. But now the prices are going to look very similar.
00:44:30.390 - 00:44:47.698, Speaker B: Yeah, right. That's really the advantage of Nova, is that the price is going to stay where it is. Whereas with an arbitrage one, if blobs get more expensive, then things will get more expensive on the chain.
00:44:47.874 - 00:45:16.180, Speaker C: Exactly. So if you're, like, looking at long term planning and you're saying, hey, I want to build a game and I want it to be a certain level of cheap, and I want to kind of not be worried about, hey, blobs are going to get filled up. You still want any trust or some form of alta, presumably. But if you're a user and you're looking at the prices today and you're not really thinking about the future, it's going to look quite similar, which is kind of crazy. And I never thought we'd see the day.
00:45:17.670 - 00:45:28.934, Speaker A: Yeah, that's crazy. And the cooler part, of course, is that yesterday technically was only like kind of part one of two with cost reductions on.
00:45:29.132 - 00:46:02.602, Speaker B: Exactly. Yeah. So right. Yesterday there was the arbitram Atlas upgrade. On arbitram one starts using blobs. You see a big cost reduction on this coming early Tuesday morning, early morning hours of Tuesday morning here in the US east, there is another set of fee cuts that were approved by the Dow that are going to kick in. And so that's going to be just a reduction in other parts of the cost.
00:46:02.602 - 00:46:38.700, Speaker B: It's going to reduce the cost of data posting even more because there was a kind of surplus charge on data posting that has existed that will be eliminated per the Dow's decision. And then also the minimum gas price for execution. On L two, the Dow has cut from 0.1 guay to 2.1 guay. So to a 10th of what it has been. And so those changes both will take effect on early Tuesday morning, us east time.
00:46:38.700 - 00:46:48.080, Speaker B: And so, and so we expect to see a lot of transactions to get a lot cheaper when that happens, even cheaper than they already are.
00:46:49.010 - 00:48:15.370, Speaker C: The whole thing was really interesting in that kind of, the Dow had a vote on this, I think, that started ten days ago, in order to kind of actually vote to execute this change. And it is purely kind of a change in sort of the economics of the system as controlled by the Dow. And the vote ended up being 99.85%. Cutting these prices, which is really interesting in that kind of, it's a vote to kind of, in the short term, reduce the amount of profit, that revenue that the Dow is taking in into its treasury in the interest of adoption, in the interest of picking up kind of way more users and being way more competitive and having arbitram one be the best place to be if you're a developer or a user, even kind of at the very short term effect of sort of reducing the amount of fees collected into the treasury. I think based out of sort of a sort of long term vision of this should be the place everybody wants to be and everybody ends up, and kind of the benefits will come in the long term of sort of doing this on the short term and seeing 99.85% all kind of basically almost every single voter share that sentiment was kind of really interesting and cool.
00:48:15.520 - 00:48:22.878, Speaker B: And so the result is a big win for users and developers who are on arbitrum one or who are going to be on arbitrum one.
00:48:22.964 - 00:48:23.214, Speaker C: Right.
00:48:23.252 - 00:48:45.730, Speaker B: Big reduction in the cost of users using the chain and really a transition to a more mature kind of economics for the chain. So it's exciting to see it. And it's great that when the Dow made the decision, it made it with such strong consensus.
00:48:46.070 - 00:49:02.954, Speaker C: Yeah, it's going to be really interesting to see how fees play out just in that, as we were talking about earlier, kind of, you have, how does capacity get allotted? What if there's more demand than supply? There's congestion. And so the really interesting thing to see evolve over time will be kind.
00:49:02.992 - 00:49:03.580, Speaker B: Of.
00:49:05.310 - 00:50:17.490, Speaker C: These essentially sort of semi artificial sort of revenue sources are being reduced now, where it's kind of, no matter how much demand there is to use the system, everybody's going to get charged for this. And the major factor that remains is this, like, if there's more demand than supply, people are going to be biding for space and pay more, and that gets collected. And so there's kind of this really interesting, I don't think anybody can predict. Question of, like, what does this look like over the next six months? In that there's plenty of scenarios where demand picks up and there's kind of essentially kind of permanent congestion in that sort of, there's no floor, and there's always enough demand to fill the supply, which is exactly what Ethereum has been like for years, and where the price is kind of market set based on people have put a certain value into their use cases on the chain that they're willing to pay for, and there are enough people willing to pay that value in order to actually fill up the whole capacity. And you have this kind of, I would say, healthier, more organic system where you can't really predict what that's going to look like, other than sort of to make guesses about what adoption will look like and how much people will value actually using arbitrage and block space, but it'll be really cool to see it evolve 100%.
00:50:17.560 - 00:50:42.562, Speaker A: Yeah, and I think that's what I was trying to convey to a lot of the people that I was speaking to even yesterday when all this crazy stuff was happening. Kind of the whole thing about all this stuff being cheaper fees, not necessarily cheaper fees, just like vastly trying to increase capacity for. When we get to that moment that you're talking about, Harry, where even l two s are maybe just as full of demand as ethereum is. Right.
00:50:42.716 - 00:51:01.006, Speaker B: So then l two s can still be cheaper because they have more capacity, have more capacity already. And of course, we're continuing to push the envelope to grow scalability, and every time you add capacity, price drops more users can do more stuff at lower cost. And that's really a big part of the story.
00:51:01.188 - 00:51:47.118, Speaker C: Yeah. And I'll note, by the way, arbitram ones had kind of more, been kind of right along, or sometimes passing demand compared to Ethereum, or at least usage compared to Ethereum for a while now. The big arbitram one, though, has around, I guess, what is it now, like six or seven times the amount of capacity as ethereum has of. It's not that prices go up when the demand reaches kind of the similar level as Ethereum. It has some headroom pass there, although I think kind of the expectation is that probably even with that headroom, there's so much value people get out of using it that it could end up in a place where kind of you're above the floor price.
00:51:47.284 - 00:52:20.040, Speaker B: Right. But then you have improvements coming along, like stylus, which will make computation, which will allow applications to do a lot more computation for the same gas. And so that also increases the capacity of how much amazing stuff can be done on arbitrum one or other arbitrum stack chains within the same gas limit. So scalability is just all about letting people do more on the same chain, and that makes things better for everybody.
00:52:20.570 - 00:52:38.154, Speaker C: Oh, yeah. It's a nice pivot into the, like, okay, but what next? And sort of like, we're talking about, like, hey, this stuff could end up sort of congested, but nobody really wants that. And so figuring out ways to actually increase the supply is a big deal. And kind of in there. Ed just was saying arbitrum stylus.
00:52:38.202 - 00:52:38.414, Speaker B: Yeah.
00:52:38.452 - 00:53:19.754, Speaker C: Which should sort of, in terms of using this execution capacity, it doesn't increase the capacity technically. It makes way more efficient use of the capacity. So for every sort of smart contract call that you could make to kind of execute a certain operation, that call takes up less resources, because the code to run it is actually running on a more efficient webassembly virtual machine. So you have that. You have kind of orbit chains right now in their kind of current standard configuration, where kind of roll up technology provides you kind of a method of scaling. That method of scaling can be replicated horizontally. And so you can have arbitram one and arbitram two.
00:53:19.754 - 00:53:56.710, Speaker C: And both of those have their own independent capacity, which is kind of another great technique. And I think applications that are looking to kind of really sort of have kind of dedicated, encapsulated user bases and kind of pick up a large amount of usage themselves are looking kind of in that direction very much. And then. And maybe Ed can say a few words onto that. Onto this. You have kind of some interesting ideas around kind of a concept that we call chain clusters, that actually give you kind of a hybrid ground where you have sort of separate chain space like orbit chains give you. But they're configured in a way where you can actually interoperate between them much more effectively.
00:53:57.850 - 00:55:10.640, Speaker B: Right. I think the big takeaway here is that there's a lot of stuff that is going to be coming available in the future to provide a lot more throughput, a lot more capability, faster interoperation between chains, greater composability. And really, that capacity is going to be increasing in every dimension on the same chain across chains. In terms of the number of chains, we see growth along all these lines. And that's important because there is so much unmet demand for functionalities on blockchains, so many things that people would like to do that are still limited by gas limits or by costs. And we're going to continue to push, we in the community will continue to push this forward, and we're going to see there's really so much unmet demand now that expanding capacity in every dimension, I think, is going to just allow more and more interesting stuff to happen.
00:55:12.450 - 00:55:17.774, Speaker A: 100%. Yeah, that's a great point. Like multidimensional capacity. That should be like the next tagline.
00:55:17.822 - 00:55:21.090, Speaker B: That we have growing in every dimension.
00:55:22.950 - 00:55:24.770, Speaker C: The bobs are getting bobbier.
00:55:28.730 - 00:55:30.790, Speaker A: They're being gashes. They're becoming gaseous.
00:55:36.730 - 00:55:43.050, Speaker B: Yeah, I, wait, the memes here, we need more good blob memes.
00:55:43.870 - 00:56:12.420, Speaker A: We definitely mean, I'm sure they'll come as the blob space gets more efficient. Maybe, possibly. But I think maybe yesterday was peak blob memes, to be honest. Anyways, I think that was great. I think that was a great overview of Denkin, Atlas, et cetera. Really looking forward to seeing all these updates that we're talking about. Start to whether it's like testnet, mainnet, et cetera, kind of hit the market and people kind of give their feedback on it.
00:56:12.420 - 00:56:24.040, Speaker A: But, yeah, that was awesome. I think we can probably end it off there then, anywhere. Alpha. I think I'd be a little too uncomfortable, to be honest. We'll stop at chain clusters. I think that's enough.
00:56:26.090 - 00:56:27.560, Speaker B: Oh, man, I like it.
00:56:32.110 - 00:57:19.954, Speaker C: It's not every day that an upgrade that kind of required this much coordination and this much effort. And I don't just mean like the arbitram changes, I mean, the ethereum changes, too. And at off chain having kind of the prism team as kind of a major part of the company, we've really gotten to kind of be really in the weeds from the start on kind of all things 4844 and kind of be able to sort of really kind of be driving on that, sort of like, both the Ethereum side, the arbitram side, engineering side, it's really been kind of like this crazy, comprehensive effort, and it's just amazing to see.
00:57:20.092 - 00:58:18.940, Speaker B: Yeah. So I kind of had this moment as these upgrades were happening, and everyone was sort of on video calls and watching all of the different metrics and monitors. This was kind of like a spacecraft landing, and you kind of have the vibe of that in terms of the people in the room talking about stuff and seriously focused on their monitors with ridiculous numbers of different graphs and numbers updating on their screen and then sort of chattering to each other in this hypertechnical talk. But also, it's a celebration. So this really was like, we landed two spacecraft on the moon and neither of them tipped over. So that's kind of what it feels like to me. It's an amazing moment that is really a culmination of a huge amount of really dedicated work by people not only in offchain labs and the PRism team and the nitro team, but also across the whole ethereum community and the whole arbitrum community.
00:58:20.350 - 00:58:40.800, Speaker A: 100%. Yeah, I think that was a great way to end off. We're about to hit the hour mark. That was amazing, Ed. I can't do any better than that, but thank you guys for coming on. Yeah, I think I'm looking forward to doing one of these again for the next moon spacecraft landing. We do.
00:58:40.800 - 00:58:51.430, Speaker A: I don't know. I think that'll be stylist most likely, but nonetheless. Thanks for coming on, guys. I hope everyone appreciated that overview of Denkin and Atlas and, yeah, we'll catch you guys on CT.
00:58:51.770 - 00:58:54.482, Speaker B: Thanks. Good seeing everybody. See y'all.
00:58:54.626 - 00:58:55.890, Speaker A: Have a good one, guys. Bye.

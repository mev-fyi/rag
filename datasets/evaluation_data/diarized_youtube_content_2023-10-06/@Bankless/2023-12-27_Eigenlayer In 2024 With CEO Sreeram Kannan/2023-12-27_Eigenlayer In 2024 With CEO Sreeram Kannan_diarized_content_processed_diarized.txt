00:00:00.250 - 00:00:09.802, Speaker A: Let's keep all the blockchain wars. L1, l two, l three. Like, like aside, right? Just let this sink in. It's insane. It's amazing. It's unusual. It's.
00:00:09.802 - 00:00:23.280, Speaker A: It's like we've becoming this much, much more coordinated. In fact, as a species, I think our evolutionary advantage is that we are able to cooperate in at a scale that is simply not possible for other species in a flexible way.
00:00:24.610 - 00:00:25.960, Speaker B: You one.
00:00:26.890 - 00:01:08.118, Speaker C: Welcome to Bankless, where we explore the frontier of eigen layer. Eigen layer is just about two quarters away from main net, and the excitement and demand for Eigen layer has been relentlessly crushed. Undoing. And while recording this very episode with Sriram and Teddy from the Eigen layer team, Eigen Layer passed a billion dollars in deposited value into the eigen layer system, making the future of Eigen layer in 2024 a very interesting topic to explore here on the show today. And to help me explore a more technical topic, I've brought in a technical co host, Mike Norder from the Ethereum foundation is joining me today. He's a researcher at the EF. He is a malady on Twitter, and he's most known on bankless as my rock climbing budy in Brooklyn.
00:01:08.118 - 00:01:09.310, Speaker C: Mike, how's it going, my dude?
00:01:09.390 - 00:01:17.734, Speaker D: It's going great, David. Yeah, thanks for having me on. Have been a bankless listener for a long time, so to be here hosting with you is a real treat. So thanks again.
00:01:17.932 - 00:01:34.858, Speaker C: Well, whenever we need technical co hosts to explore technical topics, I always learn more than a few things. And that's definitely what happened here on the episode today. We just finished recording the episode with Sri, Ram and Teddy. What were your big takeaways? Did you get all of your questions answered? What did you think?
00:01:35.024 - 00:02:25.270, Speaker D: Yeah, I'd say my biggest takeaway was kind of a new mental model for thinking about how Eigen layer fits into the system. And that is as a way of democratizing access to restaked rewards. So the point Sriram made was that in today's world, like, without Eigen layer, a dominant liquid staking token issuer could have internalized all of that restaking yield and given it only to people who issued liquid staking tokens with them. And this would be like a stronger centralizing force, because only that single pool would have access to those rewards. So the way Eigen layer kind of fits into this picture is by creating an open, permissionless marketplace for both the buyers of economic security and the sellers of economic security, and to kind of allow everyone to access it in a more transparent way, hopefully will help democratize and distribute those rewards more evenly.
00:02:25.350 - 00:02:59.726, Speaker C: I think perhaps, said another think, and that description I think really fits into what the EF people care about, the Ethereum foundation people care about, which is antitrust forces around protocols. I think that's kind of what you're alluding to with Eigen layer is that without Eigen layer, there might be a monopoly in a single liquid staking token becoming the dominant restaking token. But I think maybe your mental model after this is Eigen layer is kind of the resource traffic controller for restaked assets and networks and yield and security. Is that a fair way to articulate this?
00:02:59.768 - 00:03:17.018, Speaker D: Yeah, exactly. A way of kind of opening up the market and making sure that it doesn't centralize around one single shelling point and also another really cool point. Just to kind of add on to that is how he described Eigen layer as a way of kind of propagating the meme of ETH as a unit of account.
00:03:17.104 - 00:03:17.354, Speaker B: Right?
00:03:17.392 - 00:03:34.158, Speaker D: So the initial set of tokens that can be restaked are all denominated in ETH. And so this Eigen layer is kind of a vehicle by which ETH as the unit of account for economic security in the whole ecosystem continues to be spread. Was another really cool mental model that he brought up.
00:03:34.324 - 00:03:57.698, Speaker C: Yeah, that facet specifically, I think I resonate with on a very large degree, and I think that's going to be a big theme in 2024. So, Mike, we're going to have more restaking content throughout the year. I think it's nerd snipe to me. I think it's nerd snipe to you. I think it's nerd sniped. A lot of people in Ethereum. What questions do you have left? What is still on the frontier of this restaking meta that you want to explore?
00:03:57.874 - 00:04:36.260, Speaker D: Yeah, I think the last thing that still sticks with me, and this is kind of one of the first things we talk about with Sriram, is this idea of what is economic security in the context of delegation. Right? So when there's the principal agent problem, where the principal is the person who owns the stake and is restaking it and the agent is the node operator, how can we think about economic security when the slashing is associated with the node operator, not the person who actually owns the capital that's at risk? So, yeah, I kind of want to keep deep diving on that. And as Sriran mentioned, that applies beyond just Eigen layer that applies in east delegate staking and across the board.
00:04:36.950 - 00:04:58.774, Speaker C: I think the principal agent problem is one of the main problems that plagues not just crypto, although definitely crypto, but really humanity at large. And now we are also discovering it inside of the Eigen layer system. Guys, we're going to get right into the episode with Sriram and Teddy from the Eigen Labs team. But first, quick disclaimer. Me and Ryan are both advisors to Eigen layer. All bankless disclosures are available@bankless.com. Slash disclosures.
00:04:58.774 - 00:05:34.470, Speaker C: And with that, let's get into the episode. Kraken knows Crypto Kraken's been in the crypto game for over a decade, and as one of the largest and most trusted exchanges in the industry, Kraken is on the journey with all of us to see what crypto can be. Human history is a story of progress. It's part of us, hardwired. We're designed to seek change everywhere, to improve, to strive. And if anything can be improved, why not finance? Crypto is a financial system designed with the modern world in mind, instant, permissionless, and 24/7 it's not perfect, and nothing ever will be perfect. But crypto is a world changing technology at a time when the world needs it the most.
00:05:34.470 - 00:05:55.354, Speaker C: That's the Kraken mission, to accelerate the global adoption of cryptocurrency so that you and the rest of the world can achieve financial freedom and inclusion. Head on over to kraken.com bankless to see what crypto can be. Not investment advice. Crypto trading involves risk of loss. Cryptocurrency services are provided to us and us territory customers by Payword Ventures, Inc. Pvi, doing business as Kraken, introducing USDV, a better type of stablecoin.
00:05:55.354 - 00:06:34.246, Speaker C: Currently, billions of dollars in stablecoin yields each year are paid to tether circle and other central issuers of major stablecoins. But what if yield could be shared with the protocols that use it? Those protocols, in turn, can decide how to reward their users. USDV shares its yield with a community of apps and developers that mint it. Every USDV is backed, one to one, by us treasury bills, which pay yield. This yield flows out to the community of USDV issuers, so your protocol or app can get paid for helping end users convert other stables into USDV. This works thanks to a breakthrough technology called color trace from layer zero. Without it, it was impossible to attribute users of a token with a specific issuer.
00:06:34.246 - 00:07:03.662, Speaker C: But now we can. USDV is live on Ethereum, optimism, arbitrum, and other chains. And it's already available on over 20 exchanges, such as curve bitget, velodrome, and Stargate start participating in the yield from treasury backed stablecoins@bankless.com. USDV Cello is the mobilefirst EVM compatible carbon negative blockchain built for the real world. And now something big is happening. Introducing the celo L2. It's a game changing proposal that's going to bring Cello's rapidly growing ecosystem home to Ethereum.
00:07:03.662 - 00:07:28.682, Speaker C: Vitalik has shared its excitement for the cello L2 on the cello forum. So has Ben Jones from optimism. But why? The cello L2 will bring huge advantages, like a decentralized sequencer offchain, data availability, and one block finality. What does all that mean? Rock solid security, a trustless bridge to ethereum, and more. Real world use cases for Ethereum without compromise. And real world adoption is happening. Active addresses on sello have grown over 500% in the last six months.
00:07:28.682 - 00:07:54.642, Speaker C: With the cello L2, gas fees will stay low, and you can even pay for gas using ERC 20 tokens. But cello is a community governed protocol. This means that cello needs you to weigh in and make your voice heard. Join the conversation in the cello forum, follow@cello.org on twitter and visit sello.org to shape the future of Ethereum. Bankless nation I'm excited to introduce you to Teddy Knox, a research engineer over at Eigen Layer, working on the Eigen da team.
00:07:54.642 - 00:08:16.790, Speaker C: That's data availability. Previously, Teddy was working inside of the cosmos ecosystem and later as a protocol specialist over at Stakefish, and has joined Eigen Layer, bringing all of his previous expertise into the world of restaking. And with Eigenda as the first avs developed in house by Eigen Layer, Teddy skills being put to the test. Teddy, welcome to Bankless.
00:08:16.870 - 00:08:17.894, Speaker B: Thanks for having me, dude.
00:08:17.942 - 00:08:45.326, Speaker C: And returning to Bankless, we have Sriram Kanon, the father of modern restaking. Sriram was a professor over at the University of Washington, where he ran a lab focusing on information theory and his applications in communication networks, machine learning, and blockchain systems. But eventually, the nerd snipe of crypto economics got him like it got the rest of us, and he started Eigen layer in 2021 in order to open up a new dimension of trust networks built on Ethereum. Sriram, welcome back to bankless.
00:08:45.438 - 00:08:46.674, Speaker A: So we're excited to be here.
00:08:46.712 - 00:09:30.626, Speaker C: David guys, I'm really excited for this conversation. The excitement around Eigen Layer has definitely been heating up, and there's been a lot of things happening inside of the Eigen layer ecosystem. And so today on the show, I kind of just want to get a download as to where things are and where things are going with the world of Eigen layer as it approaches real time like production in house, the main net, all the cool things that is going to impact Ethereum and all the trust it's going to bring. So I kind of want to start just getting a high level snapshot of where we are with Eigen layer. Sriram, I'll start with you. Just the current state of Eigen layer development. Where are we on the roadmap? What is in the near term roadmap and what are people over on the Eigen layer side of things excited about?
00:09:30.808 - 00:10:23.102, Speaker A: Yeah, the few things. Number one, on the main net we launched the protocol, just a staking site on mainnet around June, July and we started conservatively. It was a goddess launch with a small TVL cap, and we've been successively raising that over time as we test the stability of the protocol. And so there was a cap rise day before yesterday of this recording. And I think we are now at $1 billion Tvl for restaking. So that is on the main net, the broader ecosystem of Eigen layer comprises stakers, node operators, people building new services, and our own service called Eigenda. And all of these are live on our public testnet where stakers have staked and delegated to node operators.
00:10:23.102 - 00:11:13.694, Speaker A: Either the node operator can be themselves or they can delegate to a third party node operator. We have a bunch of really strong node operators from the blockchain, ecosystem, blocktainment, Coinbase, Cloud, Google Cloud, peer to peer figment. All the major operators on our Testnet and also our service eigenda is live on the Testnet. So this is a data availability service which is intended to expand the data bandwidth available for Ethereum roll ups and layer tools. And then finally anybody can build and deploy actively validated services which are basically, you can think of them as Eigen apps, like applications. But these applications are not necessarily consumer facing. These applications will be used by consumer facing applications.
00:11:13.694 - 00:11:40.838, Speaker A: These could be oracles, data availability, bridging, finalization services, all these kinds of things. So that's where we are on the ecosystem. So the testnet is public and live. We are going to this, to the main net, this exact same configuration to the main net between q one and q two, depending on audit and hardening. So very excited to have the full ecosystem kind of get together to start up more open innovation.
00:11:40.934 - 00:12:29.258, Speaker D: Yeah, congrats on the recent raise of the amount that you're allowed to restake. So just to add some color here for the listener, there's about 447,000 ether denominated restaked tokens. So, yeah, that's almost exactly $1 billion and about 200,000 of that. So nearly half of that is with Steth. So I was just kind of curious how you choose the different limits for the different liquid staking tokens that you allow people to restake. And also a follow up question, why did you choose only ETH denominated tokens? Have you thought at all about people restaking, like USDC or other tokens? Because generally speaking, it's just the value of the token, more so than the fact that it's e denominated that adds value to the system.
00:12:29.424 - 00:13:02.130, Speaker A: Yeah, absolutely. Thanks, Mike. Also excited to have this conversation with Mike here. Why are we choosing this particular set of tokens? Why denominated? How do we choose the caps? All kind of complex questions, but the first thing is we chose a guarded launch so that we can test the protocol at various levels of TVL and safety. Right? So that's the first thing. And we chose the liquid staking protocols to have a cap, whereas native staking does not have a cap. So native staking is uncapped.
00:13:02.130 - 00:14:03.622, Speaker A: This is because native staking is already very complex to actually go and execute, because you have to go, and when you stake in the beacon chain, you have to set the withdrawal credentials to the eigen pod. And furthermore, any lags. So the withdrawal lags exist on the Eigen layer platform. So whenever you want to withdraw any unit of ETH or any other token from the Eigen layer staking platform, it takes seven days before you can withdraw it. This withdrawal lag is there so that when you're staked and providing services to operators, if there's anything that malicious that you've done, you can be slashed within this period. So it's standard in all kinds of staking protocols, but it also acts as a measure of safety for us because actions do not happen instantaneously, like if you're doing on a bridge. Who knows? Somebody can drain a pool TVL instantly, whereas staking is a necessarily long term activity.
00:14:03.622 - 00:15:06.878, Speaker A: So having this kind of like a one week withdrawal lag gives us a measure of safety that simply other protocols may not be able to achieve, just because the timescale of staking is fundamentally very different from the timescale of other kinds of financial activities. But adding on to this is when you have native restaking, you have the additional lags on Ethereum itself, because you have to go and withdraw from the beacon chain becomes more noticeable. So all of this means as far as the safety limits are concerned, we can be more aggressive on the native restaking than we can be on liquid restaking. So that's why the native staking is uncapped. And we have to decide onto some cap for all of these different services. And we just chose these numbers based on both market representation that we do know that some lsts are more dominant than the others. So we don't want to say that they're all very low, but we want to also have representation of multiple different liquid staking tokens in the platform.
00:15:06.878 - 00:15:41.994, Speaker A: So that's why we did that. Regarding your question, why restrict to lsts you can think of, the question's premise is absolutely right. Eigen layer, even though we popularly call it a restaking platform, and that's a narrative, the fundamental thing is it is a permissionless programmable staking platform. It's staking, you stake your ETH, you could stake your USD, you could stake a bond, you could stake whatever you want. It is programmable, so anybody can come and program it to what the staking conditions are. And it's permissionlessly programmable. It's not programmed by us or anybody we know.
00:15:41.994 - 00:16:51.226, Speaker A: Anybody can come and create these staking and slashing conditions. So yes, the premise is absolutely right, that Eigen layer can incorporate all kinds of tokens. But the reason we focus on the ETH and ETH related tokens to begin with is that we think, number one, clearly there is a big market opportunity there that ETH, there is a lot of the lsts as well as native staking is locked in. And when you're promising to validate Ethereum, you might as well promise to validate some of these other networks. But more broadly, I think we are also trying to support a lot of the services for the ethereum ecosystem. And when your risks are denominated in ETH, it is much better for your underwriting economic safety mechanism to also be denominated in ETH. Imagine I'm doing 100,000 ETH transaction between one roll up and another roll up, and you want to say like, hey, I have enough economic safety out of Eigen layer to do this transaction.
00:16:51.226 - 00:17:29.654, Speaker A: Now, if I know that I have lsts worth maybe 120,000 ETH backing this claim, that's actually like a much more rigid mapping than to say, oh, I have 100,000 eth, but I have some x dollars USD backing it. Because now I have to account for the volatility and slippage between these two different tokens over the period of the collateral and unwrapping. Add to this the capital efficiency of lsts because LST is already earning certain amount of reward. We found that this is the best configuration to start this platform off with Sriram.
00:17:29.702 - 00:17:52.366, Speaker C: Is this just an articulation that the ether unit of account has network effects and so it's just easier to use that unit of account because the risk is denominated in ETH, the collateral is denominated in ETH. In these networks, people tend to think in ETH. And so while it doesn't necessarily need to be eth, it just kind of makes sense to be eth. Is that just a fair summary?
00:17:52.478 - 00:18:21.674, Speaker A: That is absolutely right. And this is what we want to incentivize the most. And so the idea being that initially, so over time we are going to completely make this permissionless. Like anybody can list any token and each abs can decide how to relatively value these tokens. Somebody may not like to use USD, they may only want to use certain lsts. Some people may want to use any of them as long as they have enough economic value. So this is up to the services.
00:18:21.674 - 00:19:21.374, Speaker A: So we want to get out of this layer of saying, hey, you can only do this or that, but we just have to steward this platform in the beginning. To add to one of David's point, I think when people think of the network effects of ETH, I think this is a new dimension of network effect of ETH, which is that when you are transacting and denominating in ETH in the system, that means the right backing collateral for economic safety and validation is also ETH. This creates. So this is a network effect between the monetary premium of ETH, which is that this is used as a unit of denomination to the utility of ETH, which is, it is actually used as the backing system for economic safety. I think this is a new, I would say, emergent effect that eigenve brings to this market that strengthens actually the dominant position of ETH. Cool.
00:19:21.412 - 00:20:08.880, Speaker D: Yeah. And just to kind of double click on this economic safety, economic security point, I think we might have talked about this offline. But just so to kind of bring it into this conversation, I guess one thing that always feels a little weird about the meme to me is the fact that the economic security denomination is an ETH and the owners of that ETH aren't necessarily the ones running the services that could be slashed. Right? So this is the classic principal agent problem. It shows up in Ethereum staking too. Right? So I guess, how do you think about economic security, when the people who are at risk of being slashed aren't actually the ones doing the task of the ABS operation, they're the ones who the capital was delegated to, but they're not actually the owners of the capital itself.
00:20:10.290 - 00:21:04.594, Speaker A: This is a great question, and I think maybe one of the most important for our entire field to actually consider and understand. So I wouldn't claim to have simple answers to this question. So to rephrase this question, the idea is economic safety is coming because somebody is putting down their stake and then running the node operations, let's say themselves, and saying that, hey, if I don't run these operations correctly, then I'm willing to lose my ETH. So the first point I want to bring here is that if the staker and operator are the same person, this is a very unusual type of risk. I call this endogenous risk. Endogenous risk means, unlike going and putting your ETH into a lending platform with ten x margin position or 100 x leverage, where you're underwriting certain kinds of price volatility risk. That's what you're doing.
00:21:04.594 - 00:21:45.914, Speaker A: When you're doing that, when you're staking in the Eigen layer platform, an eigen layer is constrained to validation tasks. You are underwriting endogenous risk. Endogenous means something that you do yourself. You can control yourself, you not being malicious, and if the protocol is correct, you will not get slashed. It's very different. This is why the usual mental model of people thinking of, oh, this is leverage. Leverage is not quite accurate because it is endogenous, whereas all other forms of risks that people are used to, when you think of rehypothecating stake, or like rehypothecating your house or any of these, are subject to exogenous price risks.
00:21:45.914 - 00:22:32.074, Speaker A: Okay, that's number one. But the risk is purely endogeneous only if the staker and operator are the same. Like, that's what Mike's alluding to here, and it's absolutely true. The staker and operator have to be same, or in our view, to be inside the same trust zone. So the staker has to trust the operator that the operator will do right by them. The fact that the staker and operator are not necessarily the same means no, they have to establish some other mechanism of trust between themselves to actually make sure that I will delegate to somebody while putting my eth at risk. So these mechanisms can be manifold.
00:22:32.074 - 00:23:24.302, Speaker A: And one mechanism is social or legal. Oh, there are major operators, and they are legally regulated, and they're not going to go and do something which is provably malicious. When we think of all the kinds of this is, I think, very important, and people in crypto don't fully appreciate it. I think that among the set of ways in which a company or like a system can cheat, they usually choose to cheat in ways that are not observable, because observable means like you're liable. And what these systems do is make it completely transparent because there is a slashing condition. There is an observation that you actually double signed this block or whatever the set of things are, so it makes it perfectly naked that you're cheating. Like this doesn't happen very often.
00:23:24.302 - 00:24:07.462, Speaker A: I think this is something when people think about, oh, you know, all these Wall street guys, they do this and that and all that. Nobody goes and does something where it's perfectly universally observable that they're actually cheating. This is very important. So how to solve the principal agent problem? The real world mechanisms are, hey, I'm in a certain jurisdiction, I trust certain other entities outside my blockchain protocol, and I'm therefore going to delegate to them. This might be one mechanism. Another mechanism is they use technological substrates to actually minimize the principal agent problem. For example, we're working with this platform called a project called Cubist to build anti slashers.
00:24:07.462 - 00:25:11.680, Speaker A: Anti slasher is this idea that, hey, there is a piece of code that simulates the slashing conditions and then makes sure that when I'm issuing a signature, the slashing conditions will not be violated. And this piece of code alone runs inside a trusted execution environment like an intel SGX or an AMD trust zone. So what this does is it gives a sense of correctness between the principal and the agent, because even if the agent wants to manipulate it, they're still running it inside the tee. So therefore they cannot really cheat the principle. And in our platform we have a protocol called puffer, which is based on trusted execution environment, and they are actually doing liquid staking for ethereum itself and also restaking based on these tes. These are two different ways, legal, social, and number two is technical. There's also like a third way, which is economic, which is the rocket pool way, which is saying, hey, yeah, the principal and agent are the agent.
00:25:11.680 - 00:25:47.594, Speaker A: The principal is going to lose something, but the agent is going to lose something too. So you just try to correlate the fates of these two people. But in our fundamental analysis of the economics, this really only works if the slashing is bounded or bounded for some reason or the other, and on eigen layer being a fundamentally economic safety platform. It's not clear, like, what will be these bounds. So that's the three different ways, social, technical, and economic, to minimize these kinds of principal agent risks. And I think this is a generic question, not for eigen layer, but for the entire field to actually answer.
00:25:47.632 - 00:26:28.322, Speaker D: Yeah, for sure. And just kind of one more high level question before we dig into some more of the details of eigenda and stuff. Yeah. One thing I think that comes into question when thinking about restaking is that it does fundamentally change the incentives of being a staker in ethereum. Right? So if you think of the protocol as kind of like having two incentives, now it has the consensus layer rewards, and then the execution layer, rewards. Like consensus is for participating in the block voting on blocks. What's the head of the chain? Execution rewards are kind of these congestion fees, like gas fees, and also the MEV rewards given to proposers Eigen layer kind of tax on a third set of rewards.
00:26:28.322 - 00:27:10.070, Speaker D: Right? Like these are restaking rewards. So the main issue I see potentially with this is that these rewards are outside the purview of what the protocol can see and what the protocol is designed for. Right? So if this kind of warps the incentives of the protocol, it might, for example, increase the demand for staked eth significantly. Or also it might make it so that solo staking, kind of the opportunity cost of solo staking is very high because restaking yields are bigger than the other two components of the reward. And so in order to be competitive as the staker, you also need to be a restaker. So these are big kind of themes that I've been thinking about, but would be curious to hear your high level response on these before we dive deeper.
00:27:10.730 - 00:27:58.242, Speaker A: Yeah, absolutely. I think also complex question and landscape to think about and filled with second order effects, which are not totally anticipatable. But I'll start with one thing. This is the hard thing about building permissionless platforms. Who knows what somebody else can do, right? When Ethereum is building in the MEV was one example, liquid staking is another example, restaking is another example, where these are emergent effects that could not be anticipated fully. So, having said that, I want to make a bunch of observations. So the first observation is that anything you could do with restaking, you can already do with liquid staking.
00:27:58.242 - 00:29:14.430, Speaker A: Right? One major LST, the dominant LST, could just simply, you know, the economics are simply not only being used for Ethereum staking, but I'm also making this promise as the dominant LST protocol that ABCD will happen. Right. And this leads to a completely different set of effects, which is that that LST, because it has figured out that it can do ABCD, now completely consolidates the market because it is able to tack on additional things. This is exactly the kind of the problem that Meb boost was trying to solve, which is that if you're a major player, you can do auto protocol deals. And if you're a smaller player, you cannot do auto protocol deals, and you're completely subverted by an auto protocol deal. So just like Mevboost and the PBS roadmap basically tries to democratize the opportunity for making these out of protocol deals, Eigen layer is an opportunity to democratize these outer protocol deals and make it as formal, transparent, clear, and verifiable as possible so that anybody can enter into these kinds of agreements, not only the dominant player. So that's the first thing.
00:29:14.430 - 00:30:18.210, Speaker A: Anything that you could do with restaking could have already been done with lsts. The second thing, I think, in order to affect Ethereum's protocol economics, when I hear some of the concerns about Eigen layer and restaking, makes me wonder in one sense, because these people are much more bullish about Eigen layer than I am, because they're basically saying the statement, once I formalize it will make it clear. They're saying that the total amount of reward and yield that will come out of restaking should be higher or of exactly the same magnitude of all the defi yield that would come out of any kind of LST and other things. So it's only at that scale that this starts to become significant. But having said that, maybe it can happen. And we are, of course, believers in the technology. That's why we're building it.
00:30:18.210 - 00:31:47.710, Speaker A: But how does it affect Ethereum's protocol economics? It does definitely warp the incentives, but it warps it lesser than if Eigen layer wouldn't exist. And, like, one LST basically significantly integrates this kind of an idea inside of its own protocol. I think people don't see it, like a lot of people on Twitter, for example, saying, why doesn't Eigen layer commit to self limiting or whatever ideas? And I think it is the same reason why MeV boost is a neutral platform, the same reason why PBS has to be neutral. There has to be a mechanism for new protocols to be built to be completely neutral so that the playing field is level. Because if we self limit the dominant lsts, what are they going to do? They're going to say, hey, I have to internalize this because these guys are going to self limit. So there are all these second order games that people don't transparently understand, but these are, and I'm not claiming to have all the answers for the second order games, but at the minimum, the observation is that the presence of a more neutral platform democratizes restaking yield rather than centralizing restaking yield into only the LSD. Now at least, like if I'm a homestaker, I can opt into Eigen layer and then adopt at least a few of the protocols which are lightweight and easy to run and participate in that additional rewards, whereas in the absence of Eigen layer, that would just simply not be possible.
00:31:47.710 - 00:32:57.978, Speaker A: So that's number two. Number three, we know and hope that the number of such protocols is high, but we know that there are some protocols which fundamentally rely on decentralization rather than relying purely on economics. An Eigen layer is a highly expressive platform because it has this feature we call double opt in. Double opt in means a staker and operator have to opt into the protocol, and the protocol has to accept the opt in. So double opt in basically means protocols can express subjective opinions on who can opt into their protocol, into an ABS, as well as give additional rewards to certain people than to other people. So because Eigenve is this highly expressive platform, and there are services which fundamentally rely on decentralization, rather than fundamentally relying on economic safety, those services could actually incentivize decentralization itself. Like for example, there's one of the services building on top of us is this thing called witness chain, which offers a proof of location protocol, basically offers a geographic location oracle, which itself is geographically decentralized.
00:32:57.978 - 00:33:47.822, Speaker A: It uses stakers and then tries to measure network latencies across various nodes to certify that, hey, you are in this zone or that zone. Now it's possible for an evs to say, I want to add a geographic decentralization bonus to my reward structure. And homestakers, being more geographically distributed, could potentially take part in that. Other people can offer other kinds of subjective oracles which try to analyze stake flows and stake correlation to determine whether it's the same guy staking across these different entities or it's actually distinct homestakers. So all these things give me confidence that there'll be some amount of incentives for decentralized home operators that can come through Eigen layer, which in its absence actually just makes it significantly worse than centralizing.
00:33:47.966 - 00:34:32.030, Speaker C: That was a fantastic, just high level overview of, I think, some of the big questions about Eigen layer and kind of restaking specifically. And I want to bring Teddy into this conversation, to open up the Eigen Da rabbit hole. Because I think this can be a more narrow understanding of what it means to be an avs. And because eigenda is being incubated in house by Eigen layer, there's definitely some additional knowledge I want to pull out of you tedy here. So I want to ask the question, what is eigenda? But I want to ask it in three different ways, because I think we can kind of get three different answers out of it. There is Eigenda, the data availability network. There is Eigenda, the first internal incubated restaking network by Eigen layer.
00:34:32.030 - 00:35:11.370, Speaker C: And then there's eigenda as this very proximate data availability layer to Ethereum. So what is Eigenda? As it needs to be for Eigen layer to incubate its own network? Like, why does Eigenda need to be a thing internal to Eigen layer? How does Eigenda compare to other DA layers? Like, there's many DA layers out there. How is Eigen layer different? What are the unique properties? And then lastly, what does Eigenda specifically do for Ethereum, the Ethereum ecosystem that other data availability networks don't do? So, three questions all about what is Eigenda? You can start however you want to start, Teddy.
00:35:11.450 - 00:36:26.870, Speaker B: Yeah, sure. Well, so Eigenda was both an opportunity and a necessity for Eigen Labs, because we had the plan for Eigen layer and we needed a way to demonstrate it to the world. We wanted to build a product that was truly useful for people to attract stake and other ABS projects to Eigen layer. But on the other hand, it was also an opportunity because we looked at the landscape of DA providers and saw an opportunity to build a DA layer from first principles that was better. The goal of Eigenda is a trustless, decentralized, hyperscale DA layer built on top of Eigen layer. And alluding to one of your questions about alignment with Ethereum, that sort of implies alignment with Ethereum, given that we're building on top of Eigen layer. So I think the main thing people want to know is how is it trustless, decentralized and hyperscale, and how does that set it apart? I guess I'll start with trustless.
00:36:26.870 - 00:37:25.638, Speaker B: Eigenda operates on the basis of operator nodes which opt into the eigenda network via eigen layer. And so operators are providing storage bandwidth to the eigenda network on the basis of the amount of stake that they have attributed to them. So if I'm an operator and I manage to get 5% of the eigenda network stake. That means I'm going to be receiving roughly 5% of the data. And this is how we achieve this trustless quality to eigenda. We ensure that every operator is only handling the amount of data that it is on the hook for providing. And this is also what sets it apart from a naive data availability committee, which, although very simple, does not provide these trustless decentralized guarantees.
00:37:25.638 - 00:38:57.954, Speaker B: The hyperscale part is what I think is the most interesting about eigenda, which is that eigenda's capacity scales with the total bandwidth of the operator set. This means that as the number of operators joining the eigenda network grows, the amount of data that eigenda can support writing and reading to also grows. And how do we do this? I mean, most other DA layers either involve relatively simple data availability committees or maybe involve some amount of consensus, and we try to take a hybrid approach where we remove peer to peer consensus from the dispersal process of data. So eigenva can generally be thought of as this operator set which is interacted with via a disperser service. So data is sent to these operators, and this disperser service, which can be understood as something like a decentralized sequencer in a roll up analogy, is responsible for collecting these various signatures that form a data availability proof and posting these signatures on chain to Ethereum to certify availability. And there are several other pieces of technology which I can't go into yet, which ensure that data is available not only that it's stored, but that it's not being withheld, and systems for payment and for slashing.
00:38:58.002 - 00:40:04.778, Speaker C: I want to go into the unique properties of eigenda just a little bit more. My mental model, my map for understanding eigenda is kind of like a dank sharding sidecar, where it has a lot of properties that EIP 4844 at full dank sharding also have, except that it's also a separate network, except it is also secured by ETH. So it seems to be like a very proximate replication of dank sharding, just as like a sidecar network running in parallel to Ethereum. And why is it in parallel to Ethereum? Well, because it's using ether as stake, and so it seems to be like the closest approximation to danksharding data availability while also retaining the security of ether, but yet it is a separate network from Ethereum data availability first, Teddy, is that a fair articulation? Do I need to amend that? Is that accurate? Is that inaccurate? And to what degree that is accurate? How is that extra useful to Ethereum versus other far more distant data availability networks that aren't so close to Ethereum?
00:40:04.874 - 00:40:31.506, Speaker B: Sure. Yes. Well, that's generally accurate. I like to think of dank sharding as being sort of the public option that will eventually arrive, and Eigen layer as being a very closely aligned private option. So Eigen layer has plans to support greater throughput than dank sharding, but in the short term, they generally align in terms of bandwidth planning.
00:40:31.698 - 00:40:43.126, Speaker C: And so why would someone use eigenda over some sort of more third party networks or alternative layer ones? What benefits does Eigenda bring to the table?
00:40:43.238 - 00:41:30.280, Speaker B: Well, so Eigenda settles to Ethereum. This means that roll ups will have lower latencies when settling to Ethereum themselves. This is one of the larger advantages. The other is that Eigenda is going to be generally Ethereum lined product going forward. We don't have any plans to sort of try and move away from the ethereum ecosystem. And so when roll ups who are already deciding to commit to Ethereum use eigenva, they can be assured that we're planning on the basis of 48, 44 and dank sharding in the future.
00:41:30.590 - 00:42:33.390, Speaker A: You asked about how we got started with Eigenda, and I think Teddy gave good answer there, which is that it is not only a proof of concept that, hey, you can build something interesting, but also a proof of value that you can build something useful on top of Eigen layer. And value is needed when you want to get this kind of a platform bootstrapped. You want to start Eigen layer, who's going to use it? Who's going to come and build protocols on top of it? We have at least one useful kind of product on top of it. That's Eigenda. But how did we actually arrive at this is, there's an interesting story. This was back in 2021 when we were working on just coming up with some of the core ideas around Eigen layer and restaking, and I had decided to fund this startup, just bootstrap, use my own money to do it. And we were know maybe more than six months down the journey at that time.
00:42:33.390 - 00:43:23.066, Speaker A: And I was talking to many vcs, and one of the vcs I talked to was Kyle Samani from Multicoin. And I gave this, you know, here's Ethereum you can stake, and then you can use it for other networks, and you can have these kind of slashing and things like that. And I said, oh, these are just looking like fraud probes and optimistic roll ups, they suck, they're not going to work. And I was curious why he said it. And then I asked him, why do you think optimistic roll ups suck and they're never going to work? And he said, because they're very expensive. And I was not close, paying close enough attention to know that optimistic roll ups are more expensive. And I said thank you, and finished the call.
00:43:23.066 - 00:44:29.810, Speaker A: And then we went back and called the team and I said, hey, I heard that optimistic roll ups are more expensive. Can we dig into why this is the case? Just go ahead and look at it. And we find it's all just data costs, right? Because you don't even have to write a proof to Ethereum, so why is it more expensive? And then I looked at it and we have actually been working on data availability for a much longer period as an academic. In fact, one of the first papers on fraud proofs and data availability that Mustafa and Vitalik and others wrote, I was actually on the program committee and I championed this paper to be accepted in financial cryptography. And so we'd been thinking about data availability for a long time and I knew that of all the things we know how to scale, data availability is the one we know most how to scale. And looking at the cost, it's like, oh my God, there's a huge opportunity because we didn't know how to get this platform started. That was the other question that we couldn't answer in any of these vc pitches is, oh, you build this platform, who's going to come and build anything on top of it? It's like, I don't know, this is useful.
00:44:29.810 - 00:45:20.420, Speaker A: From that it became we are going to build Inda, the first data availability service because we know exactly how to scale data availability and we have this platform. In fact, we even had a paper called a's a data availability oracle like two years before this episode. And basically that was basically saying that hey, this is an off chain network that certifies data availability to Ethereum and we just didn't know how to bootstrap this. And Eigen layer was designed to solve the bootstrapping platform. So we became our own customers to actually then build Eigenva. And I did tell Kyle this like a few months back, and he's like most people when I say something like that, they just get annoyed. But you're the only one who took it positively and came back and thanked me after.
00:45:20.420 - 00:46:07.870, Speaker A: So going to the other question on why Eigenda? And one of the things is, I think Teddy was alluding to earlier is Eigen layer is built as the only ETH centric data availability layer. Okay, what does it mean by eat centric? Ethereum centric. So it's Ethereum centric in many ways. Other data availability layers are actually blockchains. They say modular, but it's actually an entire blockchain. There is a consensus layer, there is a new asset, there is a new trust layer, there is also a new data availability system, all of them packaged and actually packaging. It brings you certain superpowers.
00:46:07.870 - 00:46:52.686, Speaker A: And the superpower is if you natively run a roll up on top of that blockchain, you actually inherit much better security. Because if data is not available in that system, let's say something like Celestia, if data is not available, then the blockchain itself will fork around such a failure. So if you're a native rollup on Celestia, you actually get a lot of security guarantees. But if you're an Ethereum roll up, your ordering primitive in Celestia has no bearing on it. From the viewpoint of Ethereum, everything is just a committee. If you're an Ethereum roll up, you have a roll up contract sitting on the Ethereum blockchain, and it's just viewing some certificate from some committee. That's all it can do.
00:46:52.686 - 00:47:39.310, Speaker A: It cannot do a contract cannot do data availability sampling. A contract cannot do whatever set of features that are actually available on that other platform. So we, instead of clubbing all these things and clubbing two separate goals, which is I want to build a blockchain of my own and I want to provide data availability services to the Ethereum ecosystem. Started from first principles. How would one build just a data availability adjacent, a data availability layer which adjoins the Ethereum network? So the first thing is Ethereum has rollups rely on Ethereum for ordering and consensus. Therefore you should not need to have a separate consensus. A separate consensus adds nothing to your own Ethereum roll up ecosystem.
00:47:39.310 - 00:48:09.046, Speaker A: Okay, so that was the first thing. Remove consensus. And once you remove consensus, you see that the design space for actually maximizing throughput and reducing latency and all these other things explodes rather than reduces. Because now you don't have to do another thing, another module consensus being another module. You don't have to do it. You only have to do data attestations. You just have to certify that data is available.
00:48:09.046 - 00:48:31.520, Speaker A: Now you can start to think from first principles what set of things you can do. I can use some examples. I think Teddy alluded to this earlier. The idea is, for example, in eigenda, the way it works is there is this committee, this committee is staked. What you stake, there's a natural thing to stake, which is eth. And we have Eigen layer. So that's one side of this.
00:48:31.520 - 00:49:47.422, Speaker A: The second side is because we had to think wearing the Ethereum hat on. We have to make sure that nodes that participate in Eigenda need to have very limited resources or can manage with very limited resources. Now, people say, like, oh, this is a big constraint. Like the Solana people, for example, say, oh, this is a big constraint, but there is a power in adopting constraints and then seeing actually how to, because these constraints are meaningfully adopted, right? They're adopted for, I want to maximize decentralization or whatever, and then ask, let's say each node has low amount of bandwidth, but you have an insane number of nodes, like Ethereum has, whatever, 900,000 validators. They may all not be distinct nodes, but the whole system is set up in such a way that if you have 32 eth, you should not need a lot of bandwidth to participate in the network. So one of the things we said is, hey, I want to adopt decentralization, but if you centralize, I'm going to make you pay more in the sense that now you have to store more data, now you have to expand more bandwidth if you're more centralized. So till now, even if you're validating Ethereum, if you're a single operator running 10,000 validators, versus if you're a single operator running a single validator, both of them have the same expense basis.
00:49:47.422 - 00:50:20.846, Speaker A: So there is like an inevitable drift to centralization, because if you centralize, you're more efficient. Eigenda breaks this. Oh, if you centralize and you have 30% of the stake, and somebody has 0.1% of the stake, you have to do 300 times more work to hold 30% of the stake than you would if you're holding 0.1% of the stake. So we start not only from like, okay, when we think of Ethereum centric, the first thing, no ordering. Let's just do like, data availability.
00:50:20.846 - 00:51:01.402, Speaker A: The second thing, what is the asset to use? Use eth. The third thing, what is the principle? What is the philosophical substrate on which you're operating? Get as much decentralization as possible. Get node operators to participate with very limited resources while minimizing the benefit of centralization. So these are some of the decisions that went into building. Like Ignda, there are certain emergent benefits from it. For example, when you want to do ordering and consensus in your own chain. One of the things you have to do is you have to lock the state, have a leader, the leader proposes the next block, and that's how you build the chain.
00:51:01.402 - 00:51:40.854, Speaker A: Whereas in eigenda, what happens is because we are not doing ordering, ordering can be just data attestations or data availability claims can be completely paralyzed. So David sends a data availability claim to Ignda nodes. They all receive a chunk of the data availability claims and send David a certificate. And similarly to Mike is sending a data blob, splits it into small chunks, sends it to the eigenda nodes, they all send him the claim, they send the same thing to Teddy, all of them in parallel. So you're not deadlocking on the state at all. Second, your censorship resistance is not gated off. Eigenda is not gated by some leader.
00:51:40.854 - 00:52:14.006, Speaker A: There is no need for a leader. It is what we call self leader protocols. Like if you're a sequencer, you can yourself decide, hey, I just send the data chunks, encode and send the data chunks myself. I don't need to wait for that leader. And the leader becomes the MEV center of the entire data availability system. So essentially what we found is actually being a data availability adjacent to Ethereum as a first order design principle unlocks a variety of different things that we had to actually innovate from.
00:52:14.028 - 00:53:04.514, Speaker C: First principles on metamask portfolio is your one stop shop to navigate the world of defi. And now bridging seamlessly across networks doesn't have to be so daunting anymore. With competitive rates and convenient routes, Metamask Portfolio's bridge feature lets you easily move your tokens from chain to chain using popular layer one and L2 networks. And all you have to do is select the network you want to bridge from and where you want your tokens to go from. There, Metamask vets and curates the different bridging platforms to find the most decentralized, accessible, and reliable bridges for you to tap into the hottest opportunities in crypto, you need to be able to plug into a variety of networks, and nobody makes that easier than metamask portfolio. Instead of searching endlessly through the world of bridge options, click the bridge button on your Metamask extension or head over to Metamask IO slash portfolio to get started. Arbitrum is the leading ethereum scaling solution that is home to hundreds of decentralized applications.
00:53:04.514 - 00:54:05.242, Speaker C: Arbitrum's technology allows you to interact with Ethereum at scale with low fees and faster transactions. Arbitrum has the leading DFI ecosystem, strong infrastructure options flourishing nfts, and is quickly becoming the web3 gaming hub. Explore the ecosystem at portal Arbitrum IO. Are you looking to permissionlessly launch your own arbitrum orbit chain? Arbitrum orbit allows anyone to utilize Arbitrum's secure scaling technology to build your own orbit chain, giving you access to interoperable, customizable permissions with dedicated throughput. Whether you are a developer, an enterprise, or a user, arbitrum orbit lets you take your project to new heights. All of these technologies leverage the security and decentralization of Ethereum experience web3 development the way it was always meant to be, secure, fast, cheap, and friction free. Visit Arbitrum IO and get your journey started in one of the largest Ethereum communities are you launching a token? Is it already live? How are you managing the legal and tax for providing token awards for your team? Toku simplifies everything about managing token grant compensation, and you can get started with them for free.
00:54:05.242 - 00:54:42.854, Speaker C: You'll have access to top notch legal and tax support to handle the distribution and management of tokens for your team. Toku caters to every step in the process, from user friendly legal templates for granting tokens to tracking vesting periods and calculating withholding taxes. Toku understands every grant structure, Token purchase agreements, restricted token awards, restricted token units, token options, and all the other ones. Toku is already simplifying this today for leading companies like protocol Labs, DyDx Foundation, Mina foundation, and many more. You can learn more about how Toku can help you streamline your token management and get started for free. Visit toku@toku.com slash bankless or click the link in the description below.
00:54:42.972 - 00:55:14.926, Speaker D: Sweet. Yeah, no, this is super good and I kind of want to drill down into some of the mechanics. So Teddy, I'll ask you two questions about kind of the day to day of running eigenda. So I guess tying it back to 4844. The initial design is set up so that there's going to be target of three blobs per block, three blob transactions. Each blob will be like about 128. Design is conservative so that we know that if all Ethereum home stakers can keep running this on the same Internet connection before just kind of like alluding to what Sriram was mentioning.
00:55:14.926 - 00:56:02.810, Speaker D: So just curious on the numbers for eigenda as far as how many kind of kilobits per second and also me as a solo staker on my home Internet connection, will it be reasonable for me to be able to run a eigenda restaking service and kind of participate in that network. The second question I have is around these slashing conditions, right? So when we're thinking about the kind of settlement assurances of eigenda, like someone who posts DA to the service wants some guarantee that that DA will be available with some economic security, can you just talk about what the slashing conditions actually look like and how those violations would be resolved if someone didn't fulfill their promise of making that data available?
00:56:02.980 - 00:56:57.140, Speaker B: Sure. So I'll take the throughput question and then pass the slashing conditions to you, Sriram. But we've launched our testnet guaranteeing around 1000. We've launched our network according to the design Sriram just talked about, the amount of bandwidth you need to run an operator is not at all related to the total throughput of the network. It's related to the amount of stake that you have assigned to you. And so this should make it possible for smaller operators within the eigenda network to still receive chunks of data and earn on their staked assets. So on our testnet, the benchmarks we've run locally have suggested that it can support roughly up to three megabytes per second.
00:56:57.140 - 00:57:41.680, Speaker B: And we're pretty confident that we can get to ten megabytes per second by mainnet. All of this is powered by roughly two things. One is improving the speed at which we can encode blobs. Each blob has a combination of read Solomon encoding and KZG encoding, which is somewhat expensive, but also not an optimization problem. That can't be solved. On the other side, is just increasing the number of operators. And so we see it is very possible to get to 100 megabytes per second one year from the launch of eigenva on main net.
00:57:42.930 - 00:58:19.980, Speaker C: Teddy, you threw out some numbers just now, like 1000 kb/second which, I mean, when I download stuff, I'm downloading stuff on my computer that's need way. I need way more speeds than that. But also, at the same time, we're talking about crypto economics, and so cryptography compresses stuff. And then you started talking about like ten megabytes a second, which is starting to be a number I can reason about just overall. Is that a lot? How much is that? What do we get from that? How can we compare these things in maybe more qualitative, less quantitative ways?
00:58:20.450 - 00:59:30.340, Speaker B: Sure. So one ethereum block is roughly 200 kb. This is every 12 seconds, and you can do the math to figure out how much that is per second. EIP 48 44 is moving us towards something like 32 just to do an apples to apples comparison. Celestia is about 167 kb/second so this is just comparing with the status quo. But I think that what we're looking at just from a market perspective with eigenda is a situation where the cheaper block spaces, which is essentially what DA is providing for roll ups, the cheaper block spaces, the greater we're going to see induced demand. Everybody knows in their heart that blockchains would be mainstream if it was cheap enough and reliable enough for people to use.
00:59:30.340 - 00:59:48.710, Speaker B: And so obviously ten megabytes per second worth of transactions doesn't sound like a lot, but that would represent a roughly 50 x increase over the current status quo when people are using Ethereum or Ethereum roll ups.
00:59:49.130 - 01:00:30.294, Speaker D: One quick follow up before Siram talks about slashing conditions, because I'm sure that's going to be an interesting part of the conversation. So you mentioned that if you have more restaked ETH as an eigen da node, then you're responsible for more data, right? Just trying to understand the mechanic here. Would that potentially incentivize large node operators to kind of Sybil themselves and have many smaller node split into many smaller operators to not have as much data responsibility but still earn the same rewards as people solo staking? Or is there kind of just a linear scaling on the amount there?
01:00:30.492 - 01:00:33.874, Speaker A: It's linear on the amount. It's basically proportional to the amount of stake.
01:00:33.922 - 01:00:40.440, Speaker D: Okay, cool. Yeah, and so I guess going on to the slash and conditions question Sriram would love to hear.
01:00:41.070 - 01:01:58.770, Speaker A: Yeah, I'll just add a little bit on the throughput thing. When I first did the numbers and tried to calculate like, oh, Ethereum's data bandwidth is 80 something kilobytes per second right now. I was like, oh, why is it so slow? Or why is it so small? And I think there is a lot to improve here, but I want to kind of phrase this in the broad arc of human evolution, I think of these bytes inside the team. We say our goal on building eigenda is to maximize coordination bandwidth. If you think about it, these are complex coordination systems. We have all these parties in Ethereum certifying and maintaining this ledger based on which lots of coordination is happening, like movement of money and other things. So usually if you just neglect the last, whatever, five to ten or maybe even 20 years of history, we were as a species able to coordinate on very few things, like we would elect who is the president? And a president can specify very simple immigration policy.
01:01:58.770 - 01:02:47.934, Speaker A: Immigration good, immigration bad. That's one bit right we had coordination bandwidth, which was like five bits per five years, like something really small as a species. And suddenly I think we are. This takes some time to sink in. We are scaling that to kilobytes per second, to megabytes per second, to gigabytes per second. So what this means is suddenly the rate at which we can coordinate as a species, maintain common information, enact powerful coordination conditions, just like insanely skilled. And I think this is just like, if you think about it like this, the Internet unleashed this information superhighway.
01:02:47.934 - 01:03:28.090, Speaker A: Like, we can kind of talk to each other, but that's still not the same as the ability to coordinate with each other. Because I may be talking to you something, I may be telling somebody else something, because this is not global, verifiable state. And with systems that promise common data availability or more block space, essentially, we are talking about the rate of the bandwidth of coordination as a species, right? Let's keep all the blockchain wars, l one, l two, l three, aside, right? Just let this sink in. It's insane. It's amazing. It's unusual. It's like we're becoming this much more coordinated.
01:03:28.090 - 01:04:17.566, Speaker A: In fact, as a species, I think our evolutionary advantage is that we're able to cooperate at a scale that is simply not possible for other species in a flexible way. Like, you all know, a harare in his thesis says, our humans are special because we cooperate flexibly in large numbers. And it is cooperation when we're talking about a shared da bandwidth. It is flexibly because I can program all kinds of new vms and conditions and contracts and interesting arrangements on top of it and in large numbers, because we can have everybody agree on this common state. This is insane. And as a community, that's what we are setting out to accomplish. It's just good to put it in that perspective rather than the day to day thing of, hey, I'm doing x better than Y or Z.
01:04:17.566 - 01:04:59.386, Speaker A: We have two mechanisms right now for ensuring the fidelity of data availability. Number one, proof of custody, which ensures that people store the data, but it doesn't have a mechanism to ensure that people serve the data. So that's proof of custody. Proof of custody is basically if you don't store the data and you have to respond in certain ways, you have a secret, you have to sign some blobs based on the state of the data that you're storing. And if you don't do it correctly, you'll be slashed. So proof of custody is a mechanism to ensure that you're storing. But what if you're storing, all the nodes are storing data, but they all collude and coordinate to not serve the data to anybody.
01:04:59.386 - 01:05:39.306, Speaker A: So that's a problem. So while proof of custody relies on economic security. Okay, because you will be slashed if you don't do your proof of custody. How do we ensure that people serve? It is by ensuring that the operator set remains decentralized and collusion resistant, so that there is a competition to serve. Because no one node has all the data, the data is dispersed across many nodes, and as long as you can get a quorum number of nodes, you will be able to retrieve all the data. Now you have a market where there are many independent players who have the data and are willing to serve. Unless everybody colludes together, or some large number of stakers collude together, you will be able to retrieve the data.
01:05:39.306 - 01:06:02.382, Speaker A: So that's the mechanics. So it borrows both decentralization from eigen layer as a separate principle, as well as borrow economic security from Eigen layer. Furthermore, we are actually building new security mechanisms which are on top of this, which I think we are not yet ready to share, but we'll be ready to share in the coming months.
01:06:02.516 - 01:07:05.870, Speaker C: One thing that I think is pretty cool about just the primitive of restaked capital is that it opens up opportunities for interoperability across networks that wouldn't otherwise have been interoperable. And one of these things that I've been keeping an eye on is the superfast finality layer out of NieR, which is in partnership, in collaboration with Eigen Layer. Sri Ram Teddy I've been on a quest to learn how all of the many, many Ethereum L2s which are fragmented, how do they recompose back into one unified network? We have so much scale on Ethereum. We have horizontal scaling, we have vertical scaling, but we don't have yet a composed, coherent network, at least from the perspective of the end user. And there seems to be many different answers as to how all of these networks become recomposed. But one answer that I always come back to is low latency settlement finality. If one roll up can have assurances that settlements from a different roll up are final, all of a sudden we can unlock a lot of composability.
01:07:05.870 - 01:07:25.782, Speaker C: And this is something that I think is what you guys, Eigen layer and Nier are pioneering with this super fast finality layer. So, Sriram, maybe you can just walk us through this partnership, this collaboration with Nier and the super fast finality layer. What is it and what is it doing? And what is its impact upon the Ethereum roll up landscape?
01:07:25.846 - 01:07:45.870, Speaker A: The idea of a super fast finality layer is to ensure that you get instant finalization guarantees. So what happens is the roll up rights to this layer. This layer is. Think of it like a chain. The chain is getting economic security from each staking. Let's keep that on the side. Just think of it like a chain.
01:07:45.870 - 01:08:27.674, Speaker A: The roll up writes settlement commitments to this chain. This chain then writes the settlement commitments to Ethereum. Okay? But the order in which these commitments can be returned is rigid based on this chain. So what happens is I write a commitment to this chain, and this chain gives me a certificate that, yes, this is the order in which this is going. Now I can take it to another roll up, which is also tethered to this fast zone, and say, yeah, this fast zone is verified that this is actually happening, so I can move value back and forth. And what this does is solve some of the liquidity fragmentation problems. Because instead of liquidity residing primarily in the roll ups, the liquidity can reside in this fast zone.
01:08:27.674 - 01:08:59.846, Speaker A: And people have hooks to draw liquidity in and out of it. Like, each roll up has a hook to draw liquidity out of this layer and then give it back. This is like just in time liquidity across all the different roll ups. Because now you have a common zone which can move really fast, which has economic security because it's borrowing it from each staking. And now it becomes a zone where a lot of these things compose. So this is the idea that we are exploring with Nier. But other projects are also building somewhat similar things on Eigen layer.
01:08:59.846 - 01:09:58.502, Speaker A: One is omni, which is building a shared liquidity layer. Alt layer is building super fast finality layer, specifically tailored around the rollup and eigen layer ecosystem. So these are some of the attempts at solving the rollup interoperability problem. There's another interesting thing, David, that goes on with the roll up interoperability even without this fast finalization. Imagine I want to move value between one roll up and another roll up at a timescale which is much faster than seven days. Let's say both are optimistic roll ups, and I want to move value between them. Then the way to do it is if I want to move like 100,000 ETH, if I have from an eigen layer service a promise of more than 100,000 ETH slash ability, then I can take that commitment as final and then use that trigger to move value between these two roll ups.
01:09:58.502 - 01:10:55.694, Speaker A: So the roll up fragmentation and the fact that roll ups are fragmented. And second, the fact that roll ups are fundamentally denominating in ETH basically gives another utility to ETH as a staking asset for moving value across these different roll ups. And so we have bridges which are specifically building around this concept of what we call attributable security. Each bridging claim buys a certain amount of security from eigen layer and then moves value around. And as long as the total attributable security that the bridge holds is less than the total value moved around, you're actually completely safe. So this adds another interesting utility to ETH as a staking asset in backing these bridging claims. A fast finality layer accelerates the rate at which you can do it, but that's basically the kind of overall landscape that we're looking at here.
01:10:55.812 - 01:12:00.382, Speaker D: Yeah, super cool. And I think now that we've kind of covered a number of different use cases for eigen layer, I want to bring the discussion up to this idea of kind of aggregation across many different AVss. So I think a common theme that's been discussed is this idea that as someone who has capital they want to restake, they might have a hard time deciding which avs to delegate to, or sorry, which avs to opt into, which node operator within that abs to delegate to. And so this kind of brings forward this idea of some abstraction layer between the restakers and the actual avss. So I think this is kind of where the liquid restaking token discussion usually fits in. So I would be curious to hear how you think about layers building on top of eigen layer and how they're managing risk of many different avss and many different node operators to ensure the fungibility of the liquid restaking token. And kind of just generally your opinion on these tokens as a concept and the potential implications to the eigen layer ecosystem.
01:12:00.526 - 01:12:51.586, Speaker A: Yeah, I mean this layer of abstraction that Mike is talking about, the idea is that as a staker, I don't want to kind of sit and make these decision as to what is the set of node operators, what is the set of avss. Maybe I should allocate some portion to some avss, some portion to others. Should I accept rewards in only eth or can I accept rewards in new tokens? There's just like a lot of different dimensions that simply don't exist. As a staker in Ethereum. You just go download, stake and run. It's clear. Well specified being a double opt in platform, Eigen layer also brings all these new things like at what price to accept an abs does it offset my operating costs? There's all kinds of questions that go around it.
01:12:51.586 - 01:14:01.846, Speaker A: So these liquid restaking tokens are one subset that basically tries to address these kinds of questions. The idea being they create a decentralized organization which basically tries to adjudicate and make these decisions and take stake on people's behalf, and then go and delegate it to various operators. So the questions there are, firstly, are lrts good for the Eigen layer kind of ecosystem? And I think I had a somewhat different answer six months back, and then actually considering various things, I think on net they're actually very good. The reason is, imagine that somebody wants to build a lending protocol or some other thing based on your Ethereum stake, that's staked on Eigen layer. Now, there are two ways to do it. One is to do it kind of inside the Eigen layer platform and say that, hey, if you get slashed, I'll actually go and withdraw your stake from Ethereum. If you get liquidated, I'll actually go and withdraw your stake from Eigen layer and Ethereum.
01:14:01.846 - 01:15:22.306, Speaker A: And another option is I have a liquid token, and then I just have people exchange hands. Like I get liquidated, I give my liquid restaking token to David. And the previous one actually has worse cascade risks, because instead of when the liquidation happens, I now have to unwrap my Eigen layer position, which means eigen layer security fluctuates and also eigen layer goes and unwraps your Ethereum position. So the Ethereum security fluctuates. So what I've started seeing liquid staking tokens, as are a layer of buffering, basically, let the financial thing be buffered at a higher layer rather than any financial thing like create a shockwave that goes through the entire ecosystem, right? Imagine there is some big decentralized stablecoin or something built on top of this, and some eth to USD price change happens. And without this layer of buffering, you undergo this massive shockwave which goes through Eigen layer, which goes through Ethereum, rather than just getting buffered out at the top and people just exchange, oh, you got my liquidity staking token instead of I got it. That is much safer, I think, for the entire ecosystem, knowing that these systems are permissionless and knowing that these things are anyway going to happen.
01:15:22.306 - 01:16:14.814, Speaker A: Okay, given that now the same kind of alignment problems that Ethereum had to wrestle with get either amplified or similar problems show up with Eigen layer. Because one of the things is, if there is one single dominant staking token, and that Dao makes all these decisions, Eigen layer loses the free market property. At least in Ethereum, price discovery was automated and algorithmic, and Eigenve relies on two sides of the market. Avs is bidding a certain price and stakers accepting or rejecting that price. If you had one collusion on one party representing the interest of the entire other side, then you don't have the free market movement. So this is something that we have to figure out, like Ethereum had to figure out. We have to figure this out over time.
01:16:14.814 - 01:16:57.838, Speaker A: But one high level lever is unlike Ethereum, which has to be absolutely neutral and completely protocol. Eigen layer can have some governance levers to actually move the system to be healthy across the multiple sides of the market. So that's just a labor that we have. But in general, I think these liquid restaking tokens, we are seeing, like many highly talented teams come in and build this, which I think is net positive not only for Eigen layer, but for Ethereum itself, because it induces more competition, a new opportunity to actually participate in the liquid staking market by also being part of the liquid restaking protocol.
01:16:57.934 - 01:17:42.250, Speaker D: Yeah, and just to kind of continue on in the risk direction, because I think it's super interesting. So you were talking about how Eigen layer can kind of be more opinionated about some of these risks. I think maybe part of that equation is the slashing veto committee. So I guess I'm curious how you see the importance of that as a tool to underwrite the risk of things built on top of Eigen layer, and also kind of the trade off between being a permissionless kind of platform that anyone can build on. Anyone can launch any avs, but then also some of them are going to be kind of king made in that the committee is supported for them versus not for others. So can you just talk about the tension?
01:17:42.410 - 01:18:09.554, Speaker A: Absolutely. Absolutely. So the goal of Aguilaria is to be completely permissionless, but how we start up the platform. I think in Justin's words, these platforms have path dependence. So you want to make sure that the platforms start off safe. So we are going to start with a bit more permissioned than totally permissionless on day one. And the way it's going to work is the slashing veto committee needs to know what slashing to veto.
01:18:09.554 - 01:18:53.554, Speaker A: So, which means it needs to know what is your avs. So there is an onboarding condition. Either the slashing veto committee themselves do, or they trust some other committee to do basically the onboarding of various abs that minimizes the risk profile. It has to be audited. It has to follow certain guidelines. All these kinds of things are enforced in that layer so that we can onboard safe and useful services before eventually becoming a completely permissionless platform. So each service, over time, they start off with the slashing veto, and then over time, as the platform matures, and as also the services mature, there's going to be an option to be free of the slashing veto committee.
01:18:53.554 - 01:19:27.294, Speaker A: Like you can just go and say, hey, I don't want the slashing veto committee because I'm rigid, I'm ossified, I don't need to actually trust this. Okay, so that is an option. But more generally, I think I made the MEV and PBS analogy earlier. We can follow some of the kind of ideas from that space. One of the things that in MeV boost happens is there's this concept of a relay. A relay is a doubly trusted party from both the block proposer and the block builder. Both of them trusted for different properties, but that is a doubly trusted party.
01:19:27.294 - 01:19:58.950, Speaker A: Similarly, a slashing veto committee is a doubly trusted party from the ABS and from the staker side. The staker are trusting the veto committee to veto illegitimate slashing. The ABS is trusting the veto committee to not veto legitimate slashing. So it's a doubly trusted party. So you can take that abstraction and think of this veto committee as an entity, and now you can say just exactly what happened in Meb boost. You can create a marketplace of veto committees. There doesn't have to be one veto committee that some small group of us decide.
01:19:58.950 - 01:20:37.590, Speaker A: There can be a marketplace where people can come in and say, hey, here's a new veto committee we have self coordinated to form. Essentially, this is like an adjudication committee between the avs and stakers. And of course, if the avs is completely rigid and solid and ossified, you don't need adjudication. So you go to a null or empty adjudication committee. But the more untrusted you are, you are underwriting some amount of trust from the adjudication committee. So we envision this as one of the ways in which Eigen layer, as an ecosystem evolves to remove this permissioning. This is one of the ethos that we want to follow is minimize subjective decisions at the Eigen layer level.
01:20:37.590 - 01:21:08.260, Speaker A: Like this is one of the reasons we don't build a liquid restaking token. This is one of the reasons we don't say which tokens can be staked and which tokens cannot be staked initially, even though we are starting with a permissioning procedure there. Over time, it's going to be completely permissionless and people can decide. And this is the aesthetic. I think a protocol should minimize subjective decisions. Subjective decisions should be made by agents who have both rights and responsibilities, and they can figure out how to exercise it. So that's the ethos in which we're building.
01:21:08.630 - 01:21:39.914, Speaker C: The credible neutrality of eigen layer, of course, is going to be super important, especially as, oh, by the way, congrats guys, because during this podcast, Eigen layer just crossed $1 billion in TVL. I'm sure that makes you feel fantastic and also perhaps a little bit nervous. At least I think it should. And we have all of these liquid restaking token teams that are going after that pie, right? It's a big pie. It's super valuable. And the credible neutrality of the Eigen layer protocol, of course, makes plenty of sense. It ought to be that way.
01:21:39.914 - 01:22:20.170, Speaker C: But what about the neutrality of Eigen labs, the organization, as it tries to help some of these liquid restaking tokens bootstrap? Because of course we do want these things. But I can name like five names in my head about who would enjoy to be like the Eigen layer approved liquid restaking token. And of course, you also can't work with every single liquid resaking token down the long tail. A, because you don't have enough resources, and b, because one of them will be a rug. And so how do you guys think about just like neutrality when it comes to supporting the liquid restaking token ecosystem from the Eigen labs perspective?
01:22:20.670 - 01:22:46.574, Speaker A: Yeah. It's not only for liquid restaking tokens. This is the case for avss. Let's say there are three bridges which want to build or like finality layers and all of these things. So we face this kind of a problem. So one of the ways at least we want to minimize our own role in many of these processes. So we want to create external committees which will make a lot of the decisions over time.
01:22:46.574 - 01:23:24.014, Speaker A: For example, onboarding, right? Onboarding AVss. We don't want to say, oh, I like this avs more, therefore we are going to onboard it, but not that avs. Rather the onboarding process should be merit neutral but risk sensitive, right? You cannot onboard based on, oh, this is going to be a bigger abs, that is going to be a smaller abs. Instead it is onboarded based on this is going to be more risk. This is going to be less risk. So it's risk aware, merit neutral kind of onboarding process. But it is a hard trade off because we have to also make sure that at least some people build.
01:23:24.014 - 01:23:48.466, Speaker A: If nobody builds, you can be credibly neutral when nobody's building. So it is a hard trade off. I think layer ones, many of them had to do this. Ethereum itself had to do it. Do you support Uniswap or not support uniswap? And there's a position of the protocol, there's a position of people. And Eigen Labs itself is a big team. It is complex.
01:23:48.466 - 01:24:06.602, Speaker A: So I'm not going to pretend I have some great answer here, but we are trying to both make sure that projects build on top of eigen layer, but also make sure that other projects don't feel like there is a barrier to come and build on top of eigen layer. So that's how we split the difference here.
01:24:06.656 - 01:24:48.310, Speaker C: Teddy, as a research engineer at Eigen Layer, one of the things that excites me about Eigen layer is that it can spawn an entirely new dimension of crypto economic networks. The way I kind of articulate Eigen layer is that we were living once upon a time in flatland space when all we had were blockchains. And now with Eigen layer, we're entering a third dimension, a new dimension of crypto economic trust networks. And I would imagine that that is a fantastic nerd snipe for you over. As a research engineer, the success of Eigen layer depends on many networks coming on board. And so I'm sure you engage with some of these networks. Some people have ideas about networks that could be built.
01:24:48.310 - 01:25:23.234, Speaker C: There are stealth networks being built, I'm sure, because that's just how it works. Can you kind of just give us a vibe, a charcuterie board, a taste test of all of these different kinds of networks that maybe you're working with or just in discussions with, are we going to see millions of networks in the fullness of time? Or maybe just like ten to 100 networks in the fullness of time? What can you say about all the yields that these networks are going to spit off? Are they going to be great? Are they going to be little? Just kind of like, give us a taste of the future for Eigen layer in 2024?
01:25:23.432 - 01:25:58.810, Speaker B: Yeah. So Sriram has this slide in his talks where he goes over. There's like five different categories of abs and probably more. We've got coprocessors, Oracle networks, obviously a variety of DA layers. There's going to be a cambrian explosion in the same way that there was with l ones and other sort of general token based crypto economic schemes.
01:25:58.970 - 01:27:11.826, Speaker A: Yeah, one way of thinking about it is how many SaaS services exist on the cloud era. People think about modules, they think about like, oh, there's data availability, there's settlement or whatever. But if you look at, like, if you put a similar hat, you may say on a cloud, there may be like one database platform and one virtual machine. Like there'll be two layers. But actually if you look at the cloud, you'll see like thousands of successful SaaS companies, software as a service companies. And it's because as a civilization, I think our tendency is to hyper specialize, because when we specialize, there is a lot of value in specialization and composition, right? I specialize and I just do a database for games for this, for games which are coming from AA studios or whatever, or just for a database for games, for the Unreal engine, right? Something super special. But that itself is a big enough and interesting enough market that somebody will build that kind of a special layer.
01:27:11.826 - 01:27:21.020, Speaker A: So that's our long range thesis is there's going to be like lots and lots of modules, just like there's lots and lots of SaaS services.
01:27:21.550 - 01:28:23.322, Speaker B: We can think of it as a new kind of financial market because I don't know, if you look at, for example, bonds. Bonds are a generalization of a loan where money is actually changing hands over time. Restaking is different from that because money is not directly changing hands. It's enforcing a crypto economic set of incentives and scheme. But I guess the gravity of the invention of a generalization of this kind of financial instrument is on the same order of magnitude. We think that similar to how the number of bytes and kilobytes and megabytes and gigabytes of coordination we're able to generate through blockchains and DA layers continues to grow, that the number of crypto economically secured services will also grow.
01:28:23.456 - 01:28:43.860, Speaker C: All right, guys, well, I've already learned quite a lot in this episode. I'm going to have to relearn this, rewatch this, re listen to this to make sure I can understand some of Mike's questions and Sriram's answers. Sriram, I think you said main net sometime. Q one, Q two, 2024. Is that all of the details you can give us? And what else are you looking forward to in Eigen layer in 2024?
01:28:44.310 - 01:29:54.614, Speaker A: Yeah, we have an upcoming main net launch in Q one, Q two. We'll expand the scope of what kind of slashing and attributions that can be done. For example, we have this mechanism we call attributable security, where you're not just getting this idea that hey, if my service goes wrong, x dollars will get slashed, but I will be able to redistribute specifically a portion of that x dollars. So combining the idea of pool security and attributable security, and creating mechanisms where a particular avs has a portion of that pool as a specific attribution, that's something that we are expecting to launch also in 2024. We have, of course, Eigen DA, which I think is going to be a very important and useful primitive for rollups. We have many partners launching rollup services like decentralized sequencing from espresso. We have altlayer launching these finalization and other services for rollups.
01:29:54.614 - 01:30:44.342, Speaker A: We have major bridge partners like Polymer Lagrange, wormhole, launching a bunch of different bridging services. We are also excited about AI related services coming up on Eigen layer. Like imagine you're sitting inside an ethereum contract and you can make a call and get an AI service and it's answer certified with a certain amount of economic security. So that if you take an economic action, you have protected till that amount of value. So you can think of DeFi itself becomes more intelligent, because now you have this ability to get much more computational resources on your disposal. This is the category of coprocess that Terry was referring to. So we're excited about all these cascading.
01:30:44.342 - 01:31:21.350, Speaker A: There's also other things. For example, there is, you know, value, which can be controlled more by a protocol rather than mev value necessarily going all to the validators. So an application can, you know, this group has to consensus in order to certify the MEV, and they will redistribute a portion of the MEV back to protocol. All these kinds of really interesting use cases coming up with Eigen layer this year. So looking forward to encourage more builders to come on top of our platform, both as roll ups on Eigenda, but also as building brand new services on Eigen layer.
01:31:21.770 - 01:31:27.270, Speaker C: If people want to just learn more, get information, open up the docs, get started. Sriram where should they go?
01:31:27.340 - 01:31:47.040, Speaker A: Eigenlayer.org yeah, there's also know forums where we have research discussions on the eigen layer system. There is a blog where we put up regularly material on new things. Also the Eigen layer Twitter handle, which points to all these different things over time.
01:31:47.890 - 01:32:20.520, Speaker C: Well, Sriram, I think the evolution of restaking networks, ABS networks, is going to be one of the more fascinating things in 2024. And one of the reasons why I like it is because it goes right down to the heart of ETH, which I think the monetary arc and development of ETH as a monetary asset I think is one of the most fascinating things in crypto. And Eigen layer seems to be the next evolution on that story. So as a podcaster who likes interesting podcasts, I thank you for bringing this evolution to the world. Teddy Sriram, thank you so much for coming on bankless today.
01:32:21.050 - 01:32:24.166, Speaker A: Thank you so much David and Mike. Our pleasure to be here.
01:32:24.268 - 01:32:35.082, Speaker C: Bankless nation, you know the deal. Crypto is risky, staking is risky. Restaking is even riskier here. But it's probably more fun too. You can lose what you put in. We're headed west. This is a frontier.
01:32:35.082 - 01:32:38.154, Speaker C: It's not for everyone. But we are glad you are with us on the bankless journey.
01:32:38.202 - 01:32:38.620, Speaker A: Thanks a lot.

00:00:02.970 - 00:00:52.794, Speaker A: Welcome to Bankless, where we explore the frontier of Internet money and Internet finance. And sometimes that frontier is at a conference like last weekend, where over a thousand developers, founders, builders, and investors attended the Starkware Sessions in Tel Aviv in order to participate in growing the StarkNet ecosystem. This is Bankless's Starkware Session series, which are nine bite sized episodes interviewing the founders, builders, and ecosystem developers of StarkNet. Every once in a while in the crypto world, a conference happens, but not everyone is available to attend. Don't worry, Bankless has your back, because I go to basically every conference that's out on the frontier, and I bring an entire podcast studio in tow with me in order to make sure that the Bankless nation stays on the frontier of what's happening in crypto. In this interview, we are talking to Igno Yama, omer from Ignoma. Igno Yama is an interesting product where most things that we talk about on Bankless are on chain.
00:00:52.794 - 00:01:50.426, Speaker A: We're actually talking about hardware in this episode. ZK proofs are computationally intensive, especially for CPUs. So Ignayama is working on building chips which are just asics first FGPAs and then asics later to help speed up the prover set of ZK proofs. And so while ZK proofs are computationally intensive, we still want the ability for anyone to run those proofs. And so the bullcase for Ignora is to put a bunch of ZK prover chips in all of the hardware and devices that we use in this world. Disclosure ryan and I are actual investors into Ignora, so we have exposure to what Omer is building here. But the thesis is that self sovereign ZK technologies are going to be so proliferated, and we need ZK provers to be equally as democratized and accessible so that individuals can confirm their own ZK proofs.
00:01:50.426 - 00:02:32.778, Speaker A: The fact that ZK Rollups and other ZK technology are valid when we have chips that are specialized for this, we can extend this out to more and more people highly aligned with the Bankless philosophy. So that's why we are investors. I hope you enjoyed this interview with Omer, but first, a moment to talk to some of these fantastic sponsors that make the show possible. Kraken has been around for almost as long as crypto itself. As crazy as crypto is, kraken has remained a rock for its clients, building out a platform designed to stand the test of time. Kraken is all about proof, not promises, which is why they've pioneered a Proof of reserves, a system that lets Kraken's customers verify for themselves the solvency and responsibility of the Kraken exchange. And for this reason, and many more, we've chosen Kraken as Bankless's strategic sponsor for 2023.
00:02:32.778 - 00:03:10.102, Speaker A: And once you're done using Kraken to get your dirty fiat money into pristine crypto assets, perhaps you should check out Arbitrum, where so much of the frontier of crypto innovation is taking place. Arbitrum just announced their Stylus initiative, which is their brand new programming environment. That lets developers deploy apps using their favorite programming languages like Rust C C alongside regular old solidity EVM apps. Sets can use any coding language they like, and it simultaneously drops L2 fees by an order of magnitude. It's a big deal. So many of your favorite DFI apps have already deployed to Arbitrum, like Uniswap. But did you know that Uniswap isn't just for ERC 20 tokens anymore? Uniswap is also an NFT aggregator too.
00:03:10.102 - 00:03:43.454, Speaker A: To make sure that you are getting the best price on your NFT purchases, uniswap gives NFT collectors and traders powerful tools, all from the cozy comfy Uniswap interface. By the way. It's also got a native Fiat onramp it's also deployed on like every L2. And it's got this nifty cool thing called a universal router that ensures that you always get the best price on your trades. Crypto protocols like Arbitrum and Uniswap are becoming super powerful. So make sure that you're also using a wallet that's equally as powerful, or else you'll be missing out. If you're looking to upgrade your wallet experience, check out Phantom, the number one wallet of Solana, which has recently come to both Ethereum and Polygon.
00:03:43.454 - 00:03:58.578, Speaker A: Phantom has native NFT support, giving you your own NFT gallery from inside the wallet. Phantom is both a browser extension and a mobile wallet, and is also the only wallet to span both the Solana and Ethereum ecosystems. Check it out at Phantom app. And now let's get into the interview.
00:03:58.674 - 00:04:11.290, Speaker B: Bankless nation. Once again, we are here at the Starquare Sessions in Tel Aviv. And I'm here with Omer of Ingoyama. And Ingoyama is doing something quite interesting that you might not be familiar with. Omar, can you kind of walk us through why we need Ingoyama?
00:04:11.370 - 00:04:47.190, Speaker C: So, like every successful technology in history, we can say that there are three pillars to this technology. We have the software, the algorithms, and the hardware. So zero knowledge, which is a core technology in our space, it's basically a cornerstone for trustless computing, which is what we need for decentralization. It's just such a technology, and we want to make it successful, we want to make it mainstream, we want to make it at the hands of everybody. So out of these three pilots, basically what we do is we are taking care of the hardware.
00:04:47.930 - 00:05:08.126, Speaker B: And so this is the hardware as in once upon a time, the Bankless station will know I got into the world of Ethereum through GPU mining. There's also the world of asics proof of work. And this is the same sort of subject matter, but as it relates to zero knowledge computation, how is this world similar to the proof of work industry? And how is it also different?
00:05:08.308 - 00:05:53.250, Speaker C: Right, so dynamics can be very there are similarities, but I think one step before we need to understand what exactly is the connection or what do we need hardware for? Zero knowledge, and specifically zero knowledge. It's been around like decades in academia and only recently over the last three years, it's doing the transition into industry. And we chose in the space represented by many companies, what we chose is to focus on very specific type of zero knowledge provers. You might have heard about Snarks. Starks and companies such as Zero Knowledge rollups. Right. And basically they have some very interesting properties, this type of zero knowledge systems.
00:05:53.250 - 00:06:39.302, Speaker C: One of them is that the proof is very small and the other thing is that it's publicly verifiable. Okay? So before you even go into explaining what zero knowledge is and why do we need it? Just in terms of the analogy to proof of fork, what we see is that there is kind of like a trade off because we gain all of these very nice properties, but we need to pay somewhere. And where we need to pay is by computing this proof. So roughly, it takes seven orders of magnitude more than the computation itself to actually compute the proof. Once you have the proof, you have a lot of power, right? But to get to this point you need to spend a lot of money and compute power. This is where hardware can make a big difference. It's still going to be seven orders of magnitude more computation.
00:06:39.302 - 00:07:38.910, Speaker C: But the fact that what you'll feel in terms of the cost and the time that it takes you. We aim to make it as simple as possible, obviously, but also as close as possible to the user experience and developer experience that we have by just running the computation. Now, what it means is that, as I said, trusted computing and zero knowledge can mean many things. There are definitely few applications that we see today that are touching or try to replace exactly the old mechanism of proof of work by something that's based on zero knowledge. There are huge advantages of doing so, but this is far from being the only use case. So I think that right now we are talking about level that is way lower, somewhat lower than the actual proof of work type of mining that we had in the space. But it's definitely involved it has some kind of relationship.
00:07:38.910 - 00:07:47.874, Speaker C: For example, you can build something similar to a proof of work mechanism based on zero knowledge, of course with many benefits that I can go over.
00:07:48.072 - 00:08:23.310, Speaker B: So it's been part of the trajectory of much of Ethereum to actually get rid of hardware. Like we want to proof of stake because we don't want to have proof of work miners. But there's a dynamic here about zero knowledge computations which also is part of the broad Ethereum roadmap where we want like ZK roll ups with zero knowledge proofs and other reasons to apply zero knowledge technology to what we're doing here. Which means that are we committing to some sort of hardware layer to the Ethereum future because of just the commitment to zero knowledge?
00:08:23.810 - 00:09:01.338, Speaker C: Yeah, so that's a good question and I think that to understand it or to answer it first, I do need to explain why ZK zero knowledge is useful in the context of Ethereum. So let me just take two big ideas. One is scaling, the other is privacy. Now, in scaling, what zero knowledge basically is doing is kind of compressing just like trying to simplify it a bit. We try to compress many transactions that we just don't have enough room, put them on chain. So we put only the proof and it's verifiable computation. Everything should be fine.
00:09:01.338 - 00:10:12.206, Speaker C: In a way we are saving a lot of money by doing so, right? The end goal is to have it in a full decentralized manner, right? You don't want people to actually or to create this kind of market around or this kind of dynamics where you actually need it's open only for certain type of actors. You want to enable anybody to obviously verify approved. This is definitely super cheap and efficient, as I said, is the properties of these Snark stocks that we chose. But you also want the proving and computing the proof to be done basically by anyone on even commodity hardware or close to it such as GPUs. So this is just when it comes to scaling. I don't think that we are committing in a way to a future where we actually need to pay more or to consume much more electricity. I think it would save us much more when you try to compare it to what we know until now, privacy, this is like an application, this is like another thing that we can gain that was not accessible to us before.
00:10:12.206 - 00:10:59.310, Speaker C: Privacy at scale, privacy on chain, privacy as a L2. I think it's kind of an application that zero knowledge is bringing and of course you need to consider the cost of such an application. Personally I think it's a rightful cause and would pave for a future that is really great and it's worth to kind of put some effort into it in terms of computation. Long term thinking. Again, this hardware is going to be in, I don't know, your iPhone. So part of the chip would run ZK, it would be seamless, right? It would be very efficient and so on. So again, I don't think it's going to go into committing to where we were coming from and ruining this proof of work to proof of stake transition.
00:11:00.290 - 00:11:30.780, Speaker B: So the idea that I have for the future of ethereum and actually even baked into the ethereum roadmap is to ZK the whole entire blockchain. But then there's like applications that can use ZK tough and there's other L2s that can use ZK stuff. All of this, anytime a zero knowledge is executed upon that's a computation that needs to be run. Where are we today? How is that computation being done today? And with the future that you have in mind, how will it be done in the future, right?
00:11:31.150 - 00:12:44.702, Speaker C: So yeah, that's true. ZK is very powerful and it can find use cases in many places and obviously all of L2 ZK roll ups and I think also at some point optimistic roll ups would start using this technology to some extent. So we are talking if you try to sketch like a graph of the number of proofs per unit of time. So what I think would see is that now it's growing and it's keep growing, which is very interesting and at some point it will consume kind of a lot of electricity. As you said, any application that is being built on top of a roll up eventually would require to verify it on chain and it means another proof that needs to run. Not only that, you want to often to run the same proof more than once so that in case something happens to one of the proverbs you have like a backup, right, so it can scale. Definitely there are other type of ideas that are counter to that scaling which are for example kind of packing more than one proof together.
00:12:44.702 - 00:13:56.950, Speaker C: So because basically you are proving a computation, you can also prove another proof, right? So you can just stack them up in some kind of recursive manner and this kind of saves you a lot of the trouble. This is a lot of what we see today in ziki rollups, how they moved, like stalker for example, moved into using recursion which allows you not only to stack poofs one onto another and eventually end up just with one poof, it also makes these poofs way smaller. Right, because you can just aggregate them together. And so this is kind of counter trend to the growing need in proofs. What will happen is that with the introduction of hardware, getting these proofs going to be the threshold or the barrier to get this very complex proof and computation will just get lower and lower and usually just like with other inventions, what it means is that there will be more and more use cases using these proofs. So I think that overall we're just seeing increase in the number of poofs but definitely it would be contained, it will be contained at the hardware level, it will be contained in the algorithmic level in a way that will be manageable and for us as a community, it will eventually be a net positive.
00:13:57.290 - 00:14:09.770, Speaker B: So, to use a metaphor, would you say it's fair to say that Ingoyama is trying to build the engines to run zero knowledge computation like you're building the combustion engine for zero knowledge?
00:14:10.430 - 00:14:37.206, Speaker C: Yeah, kind of. I mean we are building computers, you can look at the traditional computer architecture and something is missing. I mean something that finite fill arithmetic, some discrete met. Like the stuff that is fundamental in the computer architecture is not really accelerated. It's not used in AI network storage, acceleration. But it is needed in cryptography. Even not just zero knowledge foliomorphic encryption and even lattices and such.
00:14:37.206 - 00:14:50.890, Speaker C: Like the basics of post quantum cryptography. Everything is built on the same math. We are just trying to bring a modern type of computer architecture that will support natively this type of computations.
00:14:51.630 - 00:15:16.754, Speaker B: So is the idea that what you just said, that we have this new thing in this world called zero knowledge proofs. They're computationally intensive. Is the future state of the world one where there is a new component, a new hardware component in perhaps every single device out there. My phone, my computer, my laptop that is specialized to run a zero knowledge proof. Is that kind of the future that we're looking at?
00:15:16.872 - 00:16:03.502, Speaker C: Yeah, absolutely. We also can tell it's going to start from more of the server side, like the data centers. This is where it's easier to kind of take a whole new computer architecture and just push it and then get some optimizations in running ZK provers. But phones, the phone factor very small is going to be very hard. But let's say decentralized identity, right? This is something that we know several phone vendors, manufacturers are looking very deeply into. So this will require some of these functions, like some of picos that are relevant to the broader, like Ziggle computation, but they can also fit inside like chips that are being manufactured by others. Also when it comes to privacy, eventually you need it in your hand, you need full control.
00:16:03.502 - 00:16:07.954, Speaker C: So that's definitely going to be like in every one of our hands in phones and so on.
00:16:07.992 - 00:17:02.402, Speaker B: Yeah, so I know one of the big conversations that's going out here at the Sarquare sessions is account abstraction and how account abstraction uses the secure enclave of a phone to store data, to unlock assurances about a private key. And so there's already the conversation happening about how does our physical hardware impact the technology that we have in the virtual space. Right. Even though we all love to be in the metaverse, the physical nature of our hardware is still very important. And so maybe to use another metaphor is like we have this secure enclave to soar private keys and that's a physical component of our devices that help us do our crypto things. And then what you're perhaps envisioning is that there's also going to be another additional part of a hardware that is meant to do zero knowledge computation to allow for zero knowledge computation to be done by the individual on their device. Does that all line up with you?
00:17:02.536 - 00:17:45.102, Speaker C: Yeah, I think it does. When I look at the future, in a world where ZK is cheap, there's no reason why you cannot just verify any computation you do. I mean, everything you are on the phone, including communication with secure and clave and so on, can be verifiable. You can also output a proof that the computation was done correctly. It's even more important once you outsource the computation to someone else? I don't know, to the cloud. Everything can be verifiable and it should. Right? So I think we are talking here about kind of a new modern type of architecture that will also include a component that is specialized for this type of cryptography.
00:17:45.246 - 00:18:03.058, Speaker B: Yeah. And if we don't have this kind of research and this kind of R and D effort that you're doing, then we probably ultimately outsource that proof generation to a third party, which is not exactly what we're going for in this world of self sovereign technology. Is that a fair assumption?
00:18:03.234 - 00:18:42.302, Speaker C: It is. I mean, there's an ongoing research on how you can actually separate the compute intensive part from the privacy preserving part of the computation. It's not easy. There are a few ideas right now it seems very far away. So I think definitely a way to go is to try and get everything done on the hardware locally. And it's a future, it will take a lot of time, but we'll get there. Meanwhile, there are many use cases and applications that can still run only on data centers by miners and some people and corporates that have access to this specialized hardware.
00:18:42.302 - 00:19:02.070, Speaker C: That's for sure. But yeah, we are going into this future where there's asics there are different chips that can be used in any type of computing device and can bring you this technology to the level that again, user experience going to be completely seamless. You won't feel that you are computing a pool.
00:19:02.430 - 00:19:10.860, Speaker B: So maybe we can really judge about how trustless and self sovereign the world is with how far your chips have proliferated across the world.
00:19:13.090 - 00:19:32.660, Speaker C: It's one way to look at it. Again, remember that right now even the roll ups, the Ziki roll ups, all of them are more or less centralized. So they're still far away to go. We still need know. We are hardware players. So we are long term thinkers. This is how we are building the company.
00:19:32.660 - 00:19:50.774, Speaker C: Yeah. I mean, at some point I do hope that many of us would have this freedom of just verifiable and private type of privacy preserving computation. Verifiable computation. It will take time until it will get basically to be democratized and be by the hands of anybody. Yeah.
00:19:50.892 - 00:20:08.634, Speaker B: So the topic of hardware is not one that we've actually talked a lot about on Bankless. And so this is probably striking the imaginations of a set of Bankless listeners that doesn't previously get a bunch of attention. Walk us through the roadmap for how a chip actually gets produced and what is the roadmap for ignayama.
00:20:08.762 - 00:20:42.598, Speaker C: Right. So first thing to understand about us is that we are not religious about hardware. Meaning that there are a few types of specialized hardware with differences. I can name a few FPGAs, GPUs, and of course asics like these specialized chips, for us it's about finding where is the pain and then solving it and when I say solve it, it's about catering for the little guy. Again, we want to make the user experience seamless. That's the goal. That's the ideal.
00:20:42.598 - 00:21:20.226, Speaker C: And what it means is that right now, in terms of roadmap, we are doing a lot of R and D internally to kind of build our hardware and our IP to run everything. What we want to do is basically run everything inside of this specialized hardware and then we try to feed the right solution to the right problem, right? So you can think about let's take Starcore, right? We are in a Starcore event. Let's take Starcore, for example. So for Starcore right now, the prover is centralized. It's one problem. It's not the most important problem they have. They have also a problem with Witness generation, with sequencer.
00:21:20.226 - 00:22:10.546, Speaker C: They pay much more on getting the transaction on chain for fees than they pay on running the prover. So when we're talking with stockware and we want to develop hardware, what we basically try to do at this point is just to move the bottleneck from the prover to somewhere else in the system, okay? Now, at some point, these other places in the system would also have their bottleneck removed. The only bottleneck that I predict will remain would be the hardware for Zeke approvers and maybe a bit beyond. But right now it's just about being efficient enough and cost effective enough to move this buttonneck someplace else in the system. That's one example. Obviously, we have projects where we want to optimize on the throughput, right? We want to run as many poops at the same time and we don't really care about the cost. Let's say there are other projects where we care just about the form factor.
00:22:10.546 - 00:23:02.566, Speaker C: We have a project, by the way, for Filecoin where it's mostly about just replacing GPUs with FPGAs that are tiny, right? It's like small, it fits a data center. So it really depends. Overall, our vision is, and I think this is the long term solution is to have these dedicated chips and to go to this place we first needed to come up with an architecture, something very similar to a GPU. If you try to think about it, like many, many cores that run in parallel but are suitable to the type of computation that you can see in zero knowledge. And once we have this figure out, remember that Zika and this public question many ask is it's a fast moving space, right? Everything is kind of changing. How do we derisk it when we build something that is meant to last for many years to come? And one way that we try to do it is by basically building it in a programmable way. That's one thing.
00:23:02.566 - 00:23:42.350, Speaker C: And the other thing is to battle test it all the time, right? So every time there's a new ZK protocol primitive coming out from academia even, we try to kind of retim it and see if we can support it and to what extent. And then we fine tune our design. Hopefully we'll be able to go to a tape out, which is, to your question, kind of the no return point where we kind of say, okay, this goes, and when it gets back, it's in silicon. Then it goes into, I don't know, miners and whoever needs it. So hopefully we'll be able to go to this to tape out soon. Meaning when I'm saying soon, it still mean like can be a couple of years. And it's really going to depend on how this market is going to evolve.
00:23:42.350 - 00:23:52.598, Speaker C: We first want to target roll ups, Ziki roll ups. And therefore we are very much dependent on their decentralization efforts and we try our best also to help with what we can.
00:23:52.764 - 00:24:02.970, Speaker B: Omar, if somebody is interested by what you are doing and what you've talked about here today, how can they join, how can they help? Who do you need help from or how can people get involved?
00:24:03.470 - 00:24:31.966, Speaker C: Right, so at this point we do mostly R and D, my team. They are a bunch of very talented cryptographers mathematicians and hardware guys like chip designers, architects and so on. We are trying to build an ecosystem in software. What we're going to do soon is going to open source much of what we do. Hardware is traditionally a very closed source type of environment. This is not good for a space. We try to break this narrative.
00:24:31.966 - 00:24:59.206, Speaker C: We try to go and be and walk in the open, be transparent, and also put some code and IP out there for people to use and play. Feedback is critical from developers mostly that are going to build on ZK. Any type of application, everything is applicable. You can find us in Twitter ingo ZK. We have a website we launched not long ago in Gonyama.com. We have a GitHub with all of our stuff open. We have a discord that soon.
00:24:59.206 - 00:25:10.734, Speaker C: We're going to launch it officially. Right now, if you are working on some technical problem and want to join the discord, meet the team, this is a very good place. Reach out to me and I'll be able to connect you with the team.
00:25:10.852 - 00:25:12.126, Speaker B: Omar, thank you so much.
00:25:12.228 - 00:25:12.620, Speaker C: Thank you.

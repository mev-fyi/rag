00:00:00.760 - 00:00:40.780, Speaker A: Hello everyone. Welcome back. It's been a little while. I figured out that in the middle of this sort of international, everyone's stay at home period, we might as well do a stream. And for quite a long time I've had people ask me, can you stream something about the work that you do, the research that you do? And I've been a little bit hesitant to do so. And the reason is that working on a research project is a little different from the other coding projects we've done. First of all, there's sort of a large codebase that's there already, that there's a lot of intricacies to understanding, but also because doing research is not just coding.
00:00:40.780 - 00:01:54.026, Speaker A: A lot of what you're doing is just sort of thinking really hard or like drawing diagrams and trying to figure out what you're even supposed to do. But now that enough people have asked and we have this opportunity where I'm working from home anyway, I figured we let's just do it and see what happens. I think the style of the stream is going to be a little bit different from the other streams in that there'll probably be more explanation here and less direct coding, although we will be doing both because I'm about to dive into a pretty technical part of a pretty technical code base. So I'll try to explain what I can as we go along, but please, I'll try to monitor chat a little bit, but I if you feel like you're not following, then let me know and I'll try to explain a little bit better where we're at. Remember, I'm very familiar with this code base and you are not. And so I'll try to keep that in mind. What was the other thing I wanted to say here? Yeah, so the other way in which this is going to be different is that I have a solution in mind for the particular problem that we're going to tackle, but I have no idea whether it's going to work.
00:01:54.026 - 00:02:34.996, Speaker A: It might be that we try to implement this and then it just doesn't like some other problem crops up and it's going to take like a week of thinking before we find a solution to it. This is sort of how research works and if that happens, then hopefully that'll still have been a useful stream. But let's just sort of keep that in mind as we dive into it. I also want to mention that some of you might be in this video to sort of look at how does a database work internally. And in a sense this stream is a bad example of that. And the reason is because Noria is not like a normal database internally. It works fairly differently because it's really a dataflow system that acts and pretends like it.
00:02:34.996 - 00:03:04.240, Speaker A: It's a database when it's not actually. But I guess you're about to find out. All right, let me just see here whether there's anything we're going to start. Oh, yeah, that's another good point. How long is the stream going to be? So this one's going to be a little bit shorter as my plan, than the normal streams. The normal streams are sort of relatively open ended. And we, we know that the thing we're trying to solve is going to take like several sessions to complete, whereas here my hope is that maybe we can solve this problem in this stream.
00:03:04.240 - 00:04:03.824, Speaker A: And I'm aiming for maybe like 3 hours, but really we'll just have to see and see to what extent we get stuck. And, and crucially for me it's going to be how long does explaining things work? Because as I mentioned, we'll be diving in really deep here fairly quickly. And so there's a lot of stuff for me to explain before we even get to the technical meet. All right, so with that all said, how about we start the technical bit? So the research project I'm working on is called Noria. It is the sort of tagline as a dynamically changing, partially stateful data flow for web application backends, which is a mouthful to say the least. But the basic idea here is that the system arose from the observation that databases are not really built for the web applications that people write today. When people write web applications, they're usually very read heavy.
00:04:03.824 - 00:04:36.762, Speaker A: Not always, but often. And databases sort of optimized for the opposite use. Case reads have to do all this complicated processing, right? They had to execute SQL queries, I mean, parse and plan and execute your SQL statements. Whereas writes are very straightforward, right. The writes just do an insert into a table that sort of goes to disk. And this means that the work that the application does the most takes the most amount of time and resources, which seemed backward to us. And so what Noria does is something called materialized view maintenance.
00:04:36.762 - 00:05:38.118, Speaker A: And this is a, there are many other systems that do the same thing. And the basic idea here is to sort of flip this model on its head and say that we're going to store the results of all queries and then we're going to compute the result whenever the inputs to the system change. So think of it as rather than executing the query when you do a read. We're going to execute the query when you do a write and then sort of remember that result so that subsequent reads are fast. And this is very similar to what many applications do in practice today, right? People stick like redis or memcached or something in front of their SQL server and sort of cache the results that they get out of the database or that they compute or the results of many queries potentially just stick it in memcached. And then when you do a read on your next request, you're going to first check the cache and then check the database if it's not in cache. One reason why we wanted to not have people do that and maintain their own cache and have the database do it instead is because the database knows what all the queries are.
00:05:38.118 - 00:06:27.548, Speaker A: It knows the sort of dependencies between the different data sources and the operators. So in theory it can do a better job of managing that cache than the prog or it has all the information it needs in order to do that job. And so it shouldn't have to leave it to the programmer to do all that sort of massaging and for every application to have to re implement it itself. So Noria, basically, you can sort of think of it as an automatic cache, although it's really a lot more than that. The other aspect to this, so you see here, it's dynamically changing. So the idea here is that if you add more queries to your system, then Noria will automatically start managing those new queries. If you have queries that compute roughly the same thing, then Noria is going to merge as much as that compute.
00:06:27.548 - 00:07:34.860, Speaker A: Like if you have two queries that both do a join over the same two tables, then ideally the Noria should only do that join once. If a write comes into either of the inputs to that join, Noria is also partially stateful. So this is a big difference from most existing materialized view systems. And the idea here is that imagine you have a sort of prepared statement query, right? Something like, say a trivial example here of select all from like articles join votes, and then you're going to select out the count of votes. So you're going to group by the article id where articleid equals question mark. It would be insane for the database to compute all of the join results for all articles ever and then maintain that because most of the articles are not going to be viewed again, generally is sort of a window of these recent articles get visited and older articles do not. And so in Noria we have this notion of partially stateful data flow wherever only the results for parameters of queries that you have asked for get stored.
00:07:34.860 - 00:08:25.410, Speaker A: So if you've asked for article seven, then the current vote count for article seven is going to be stored in Noria's caches. If you have not asked for article 16, then article 16 will not be in the caches. And if there are rights for article 16, those will also not be incrementally computed. Think of this as basically we can support eviction. So that's sort of the setup here for what Noria is like, which brings us to the problem we have to solve today. There's a bunch more stuff here, numbers, and we're far faster than MySQL, which is not really that much of an achievement because it doesn't take that much, but it is really cool that it can do a lot of this automatically. And now we're going to get technical to try to explain what the actual problem is.
00:08:25.410 - 00:09:00.700, Speaker A: So let me draw for you an example. I'm going to start out with an example that's pretty straightforward and that does not have the problem that we're going to fix today. So this example is one that you'll see a lot even in our research paper. We have this. So imagine that you have two think of these as base tables. So it's going to be article and vote. And these have the schema you would expect, right? Article has like an id, it has a title and a body.
00:09:00.700 - 00:09:43.162, Speaker A: And vote has something like an article id and a user id. And then imagine that the user wants to compute the vote count for each article, right? So this is going to be an aggregation. Think of data as sort of flowing this way. When a new vote comes in, it needs to be sent to the aggregation in order to get counted, right? So this is going to be vote count, right? So this is an aggregation, it's just a count that groups by the article id of vote. And then there's going to be some operator down here, which is going to be actually a left join, which we indicate with this symbol here. And there's sort of a data flow path from here and here. So you'll notice I'm drawing these arrows.
00:09:43.162 - 00:10:34.880, Speaker A: And the reason for that is because Noria is a data flow system similar to some other systems out there that do a similar kind of materialized view maintenance strategy. And the idea here is that as opposed to a regular database where these queries, the arrows would sort of be pointing the other way. Like if you did a join, the join would have to go to the article table and then fetch the article and then go to the vote table and like pull all the votes that match and then count them and then produce the join here instead. What we're going to do is we're going to have this data flow. This is going to be a view at the end here, which is sort of going to be the net total result of doing this join. And the idea here is that if a new article comes in, that article is sort of going to come down along this data flow path. It's going to hit the join operator.
00:10:34.880 - 00:11:22.842, Speaker A: The join operator is going to do a lookup into this side of the join for the current vote count for, let's say this was article seven, then it's going to do a lookup for seven. If it gets back a value saying like, let's say seven, its current vote count is 42, then it's going to produce a record that flows down here saying 742 and maybe some other fields about that article. Right? Does that part of it make sense? Right. The join operator gets an update from the left saying article seven was added. It queries the write for the current state of that key. It gets back some number and it stitches those together into a single update that flows down from it ultimately hits this view at the end. And this view is materialized.
00:11:22.842 - 00:12:03.860, Speaker A: Think of it basically as a hashmap. So this is going to have essentially a giant sort of table of. These are parameter values, right? So these are basically the question marks in your query. So if the query is something like what we're really writing here, right, is select article Dot id and count vote, dot. User from. Really should have written this in advance. It would have been easier.
00:12:03.860 - 00:12:41.250, Speaker A: From article. It's going to be like a left join vote. I guess this is going to be like using id, not quite, but sort of group by article id. And crucially, the query that the user issues is going to be something like where article dot. My handwriting is terrible on this equals question mark. Right. And what you'll note here is that.
00:12:41.250 - 00:13:27.706, Speaker A: There we go. What you'll note here is that this question mark here is sort of going to be what we're going to use as the key in the hash map, right? So we're going to have inside of the box here for, let's say the user uses question mark of seven. We're going to have the results for seven. Right. So ultimately what's going to happen here is when we do, when we execute this query, nori is going to sort of go, look at this query and go, oh, that's this view. Um, I'm going to look up into that view using the value seven, which is the user, the value the user provided for this parameter. And I'm going to look up what the results for seven are.
00:13:27.706 - 00:14:04.770, Speaker A: And if it finds an entry in this table, then it's done. The, the read doesn't have to do any more work, it doesn't have to do a join, it doesn't have to do an aggregation, it just returns those results. And that's great, right? Our read is super fast. And now imagine, to sort of complete the picture here, imagine that a user votes for an article. Let's say they vote for article seven, right? So a new vote comes in for article seven that arrives at the vote count operator. The vote count operator goes, hmm, let me think for a second here. Let's write here to make it clear.
00:14:04.770 - 00:14:39.880, Speaker A: It knows that, well, it knows many things, but amongst other things, it knows that sevens count as 42. It sees that this is for seven, and therefore it needs to add one to this. So it's going to emit what we call an update. So the update consists of two deltas. One is a negative 4742. Saying that in the past I sent you the information that the sort of, that this tuple existed, that for the key seven, the value 42 there, and it's going to send a positive for 743. Right.
00:14:39.880 - 00:15:13.990, Speaker A: This combined update here, it's going to flow down into the join. The join is going to do a lookup to its other side and find the corresponding article information for number seven. And then it's going to produce two output records. These records are going to be a negative 4742. And the other fields for article seven is going to be a positive for 743. And the other, um, fields for article seven. Right? So, title and body.
00:15:13.990 - 00:15:57.120, Speaker A: And in fact, that most of the columns, most of the values in these additional columns are going to be the same for the negative and the positive, because they haven't changed. And there are various ways in which the system could optimize this so that it doesn't send the same values twice whenever a value changes. Ultimately, these both then arrive in the view. And the view sees both these records. It sees the minus, which is going to make it remove the results it has from seven. And then it sees the plus, which is going to make it add new results for seven, which is going to be this updated value of 43. And so now if the, if a user issues another, another query that looks the same and with the value seven, the seven is going to do a lookup into here again, and it's going to see the updated value that includes the count, 43 instead of 42.
00:15:57.120 - 00:16:48.748, Speaker A: Okay, so this is sort of the, the very high level overview of how Noria uses dataflow to give you materialized views and, and crucially, as we see, are incrementally maintained, materialized views. Right. Another strategy you could imagine is that when a new vote comes in for seven, we're just going to forget everything we knew about seven. Like, we're just going to remove every entry and every table for seven, and then if someone asks again, we'll just recompute it. Or you could imagine that if a vote comes in for seven, we're going to query all votes ever for seven and just recompute the results from scratch. Of course, doing this sort of just add one is a lot more, a lot cheaper and what Noria does when it can. So I'm going to take some questions from chat here, because this is sort of the, this gives you the model that we're going to be working on when dealing with the bug that we're going to be solving later.
00:16:48.748 - 00:17:11.124, Speaker A: So if anything is not clear about what Noria does here or why, then now's the time to ask. Does this work with, well, on a write heavy application because of all the updates. Yeah. So that's the trade off this is making. Noria is specifically made for read heavy applications. If you have a write heavy application, Noria might not be for you. It is not intended to be.
00:17:11.124 - 00:17:43.840, Speaker A: It is specifically for the case where you do far more reads than writes. Like orders of magnitudes more read than writes. That said, it's not as the writes are terrible here, it's just that the writes are doing a lot more work. Noria does support things like batching updates and stuff, so it won't be that bad. But Noria is certainly not built for that kind of work. I'm wondering why Noria was not built on top of stable technologies such as postgres or Redis instead of starting from scratch. So it's not clear how you implement this model on top of postgres and Reddit.
00:17:43.840 - 00:18:19.372, Speaker A: Specifically. Noria needs to have full knowledge of all the queries. It has to control how data flows between all these operators. It needs to have full insight into every write and every read in the system. The second part of that answer is that they're really slow. So Noria is orders of magnitude faster for reads, especially than postgres or MySQL. There's sort of an amendment to this, which is Noria has much weaker guarantees about consistency than postgres, for example, gives.
00:18:19.372 - 00:18:58.950, Speaker A: It gives similar consistency guarantees to sticking memcached in front of MySQL as opposed to sort of full asset guarantees that are a real database would give you. And similarly for Redis is not clear that would buy us anything. That said, Noria does have. So these base tables are actually stored in RocksDB. And this is where our imagination here is that these are actually what storage engine you use. There should be swappable and it should be pretty straightforward. The interface there is very easy.
00:18:58.950 - 00:19:47.340, Speaker A: Yeah. So this answer the question of is it strongly consistent? It's not strongly consistent, although what we do, Noria's consistency story is not well defined. And this is one of the challenges with the system that it's sort of hard to even explain what we provide. But in general, the goal here is that when you do a read, it's going to reflect past writes and it's not going to go back in time for any given view. So basically, think of every view is going to be a snapshot of you doing a query at some point in the past. We don't give a guarantee about what that point in the past is. And if the system quiesces like input stop to the system, then the result that you get from reading is going to be the same as if you just executed the query over the, the base data.
00:19:47.340 - 00:20:18.190, Speaker A: Is the caching view really a hash map, as you hint, or is it more like a bag? So the caching view is actually an EV map. So this is something I've talked about elsewhere. In one of my talks. I think it's on YouTube somewhere. So it is more like a bag. And it also does some other cleverness to de duplicate the, the records. But essentially it's, it's sort of a.
00:20:18.190 - 00:20:46.124, Speaker A: Yeah, essentially it's a bag. And then it has a bunch of cleverness around concurrency so that you can do reads completely in parallel without synchronization and you can still do writes concurrently. So that's sort of a separate data structure that we're not going to be talking about today. Is Noria production ready? No, it's a research prototype. It is definitely a research prototype. I think it works. I would not use it in production.
00:20:46.124 - 00:21:29.196, Speaker A: I think it could be made production ready if a bunch of engineers sat down with it and just went through the code base with a kumb. There are a bunch of things that matter in production that does not matter for research. There are a bunch of things I know I want to change about Noria's interface and inner workings and that sort of stuff that it's just not worthwhile spending time on in a research context. But if you were to use this for something real, you would want to. How far along is it? So Noria, you can totally use Noria. Like it supports sort of most of SQL. I don't want to say all because it doesn't, but it supports all the stuff like the query I've shown you here and a bunch of others.
00:21:29.196 - 00:22:08.670, Speaker A: So one of the things we've done is taken the Lobsters website, which is sort of like hacker news, and we can run all of their real queries like the ones they actually get when you access the lobster's website. All of those we can run. And we have benchmarks that show that in the Noria paper, which is linked from the GitHub, repo is write heavy, an absolute value or relative to the number of reads. Well, so Noria has some amount of writes per second. It can tolerate what that number is depends essentially on the complexity of your query graph. Right. The more work you have to do on every right, the more expensive your write path is going to be.
00:22:08.670 - 00:22:45.578, Speaker A: And so if you have really complex queries, your writes are going to be slower, your reads are the same speed no matter what the queries are, which is kind of cool. Effectively, if you have more complex queries, it translates to lower write speed and to higher read update latency. So the latency between when you do a write and when it becomes visible is basically the time it takes for that write to propagate through all the operators. So in that sense, there's no absolute right performance number. It also supports sharding. And so that's the kind of stuff that would let you speed up the right path. The only thing it could be based on is a storage engine.
00:22:45.578 - 00:23:10.070, Speaker A: But I think all the querying engine, its primitives, cannot be based on some existing tech. Yeah, exactly. Basically all of Noria's, uh, query stuff is custom made because it sort of has to be. It just does not work the same way a normal database does. There are no scans or no index lookups. In the same way, all the queries are turned into dataflow. Like when you write this query to Noria, which you can, you can write exactly this query and give it to Noria.
00:23:10.070 - 00:23:46.734, Speaker A: What's going to happen is that Noria's sort of internal engine is going to turn that into the dataflow graph on the left. And from that point forward, the SQL does not exist as far as Noria is concerned. It's just a string that it uses to look up node indices in the dataflow graph. So Nori is a replacement for postgres and read heavy application. Yeah, you can think of it that way. We've actually implemented the MySQL binary protocol. So in theory there's a shim we've built that you can stick in front of Noria and then just make it listen on like port 3307 or something.
00:23:46.734 - 00:24:30.690, Speaker A: And then any application that uses the MySQL client library in theory should be able to just like switch to point to that instead of MySQL and everything should just work. In practice, it's not quite that simple because Noria doesn't actually support all of SQL, but that's sort of the idea that you should be able to use it that way. Rockstb uses LSM trees. The writes aren't too terrible, so the bottleneck is not rights to base tables. The writes here are just inserts which like are, even if they have to go to disk, they're not that expensive compared to all the compute you have to do internally in the graph. Great. Oh, there are more.
00:24:30.690 - 00:25:20.658, Speaker A: Who's working on Noria? So we're actually a bunch of people that are working on slightly different parts of Noria. And over time, who's worked on what has also changed a lot. It's primarily a research project out of MIT, out of the parallel and distributed operating systems group, although we have some contributors from Harvard, including Eddie Kohler, who's a professor there, and Jonathan, who's doing his master's at Harvard. And then we have several master's students and PhD students at MIT in my lab, and two of the professors from pdas, they're also working on it. How do you know not to propagate the updates on a write? That's a great example. So the question here is, we only store data for keys that were previously queried. How do we know not to propagate the updates? And I'll get to that in a second.
00:25:20.658 - 00:26:07.818, Speaker A: That is sort of related to what this bug is about. My roommate, well, it's my girlfriend, but yes, she is playing Animal Crossing. Yeah, sorry. And Malta, of course, who's at Brown. I still think of him as being at MIT, but Malta is a now assistant professor at Brown University and has also been a major contributor to the project. He's one of the co authors on the Noria paper. So he has been working primarily on the sort of translation between SQL and dataflow and the various optimizations you can make there and sort of the dynamic aspect of being able to add more queries and have it reuse parts of the data flow that match up between queries.
00:26:07.818 - 00:26:38.966, Speaker A: Think of this as sort of multi query optimization, which is also a well studied problem in the literature. And he's also now working on sort of policy and security privacy and GDPR compliance stuff on top of Noria. Noria is turning the queries into data structures to be written to disk. No, that's not quite true. So none of this is data structured. This is think of, you can sort of think of each of these boxes in the data flow as a separate process. You can think of them as actors.
00:26:38.966 - 00:27:25.084, Speaker A: They're not actors, but you can think of them that way where when the article actor gets a new insert to the article table, it's going to store it to disk and then it's going to send a message to all of its children in the data flow, one of which is this join saying a new article was added, and then the join actor is going to go, oh, I need to produce a message to my children telling them about this article. So I need to ask my parents to construct what that output is going to be. So none of this is data structures. In fact, all of the state that's stored below the base tables is in memory. Yeah. So this other question here is about SQL. Queries are usually way more redundant than normalized data.
00:27:25.084 - 00:27:58.242, Speaker A: In the original schema, cross joins, for example, have an exponential nature. And it seems like if you store that, your memory will go through the roof. So this is one of the reasons why Noria has the support for partial materialization, where we only materialize the keys that someone asks for. Because if we materialize the result, all of the results for every query, your memory would just explode. Right. When you do a join, the size of the output of that join is sort of proportional to the product of the sizes of the two tables. Well, depending on how you write your query and the semantics of your data.
00:27:58.242 - 00:28:27.820, Speaker A: And so this is why Noria tries very hard to not materialize everything ever it. Well, whenever the query allows. Instead, it tries to only materialize the things that the user has explicitly asked for and allows you to evict those things over time. This is sort of one of Noria's primary features. Updates and deletes are fine. So updates are of. Think of it as sending a negative followed by a positive to the base table, and removals are just sending a negative to the base table.
00:28:27.820 - 00:29:23.704, Speaker A: No, there are no actors in Noria. I'm just, it's a useful mental model for thinking about how this data flow stuff works. But it's not actually what's being used internally. In fact, what actually happens is that these are more like each is their own future, and then we just run all of these futures on a thread pool and we separate them across machines and stuff. What happens if a hotkey in the cache gets invalidated? Also a good question. So if a hotkey gets invalidated, there are no invalidations in Noria in this way. If you look at this right here, a new vote came in for article seven, which was in cash.
00:29:23.704 - 00:29:46.744, Speaker A: The value gets updated in place. It does not get removed. And so subsequent reads are basically never miss. There are cases where they might miss and we'll get to those in a second. Great. All right, so now let's get into. Let's get a little bit closer to the issue we're going to tackle today.
00:29:46.744 - 00:30:09.968, Speaker A: So I'm gonna maybe try to move to the side here if I can. Apparently I cannot, so. Oh, this is gonna be interesting. I don't even know how to move in this. I guess I have to switch to the move tool that did not used to be the case. Very sad. All right, so here we're gonna talk.
00:30:09.968 - 00:30:37.626, Speaker A: We're gonna use a slightly different graph. Um, let's go with that. Color is pretty. Um, so I'm going to go back to this graph that we had previously. Uh, but sort of more in the abstract at this point. So one of the things that's cool about Noria is that all of these edges, right, are really just channels. They're just ways for one operator to talk to another.
00:30:37.626 - 00:31:29.362, Speaker A: And so we can actually make any of them be network links if we want. So this is one of the ways that Noria can run in a distributed fashion. But we got the question earlier of how do you do this? Sort of like, if you have a table down here and it starts out empty, then what happens if a user read comes in? Right? If some user is like, well, hey, what's the current value for seven in the query that we saw before? And the database goes, well, I don't have an entry for seven. What do you do? And crucially, what happens if, like, many clients all ask for seven at the same time? Which could also happen. Yeah. And this is where Noria's part notion of partial comes in. And this is actually much of what the complexity in Noria comes from is dealing with these kinds of cases of being able to have missing state.
00:31:29.362 - 00:32:20.898, Speaker A: So specifically what happens to Noria here is we issue what we call an up query. So an up query is a way to send a message back up through the graph to your parents, like towards the roots. We generally call these loops and these roots for somewhat weird reasons. Databases do them the other way, but it's fine. So here, if a query comes in for seven, what we're going to do is we're going to issue an up query which you can sort of think of as traversing all of the edges in reverse all the way back to the nearest place that has the data. So you can think of this as if this has a materialization. If this stores some data that contains seven, then we're done.
00:32:20.898 - 00:33:08.970, Speaker A: We can just respond from the data that's stored here. And we don't need to do this additional upgrade. But if seven is also missing from this operator, then we need to forward the upgrade to our ancestor, and then our ancestor needs to look at its data and see if it has seven. And if it does, it responds. Otherwise the upgrade recurses. Ultimately, if nothing in the graph has that key, if like no one has ever asked for seven anywhere in the world, anywhere for any operator, then you're going to end up with a query hitting the base table, at which point it basically doesn't become a scan, but it becomes a lookup in the base table, which is guaranteed to have all of the results for seven. So we, so it's going to have like some amount of records as what we say here is that up queries recurse until they hit a materialization.
00:33:08.970 - 00:33:44.000, Speaker A: Well, until they hit in the materialization. There are two types of materializations. There are partial materializations like this one and this one, and there are full materializations like this one. And the biggest difference between these is that if you do a lookup into a partial materialization and you do not find the data, then you need to recurse. If you do an upcurry into a full materialization and you do not find the data, then you know that the result is empty. This also means that for partial materializations we actually need to store tombstones. We need to know that.
00:33:44.000 - 00:34:11.216, Speaker A: We need to know that we know the result for a given key. And so therefore we remember sort of tombstone saying seven was empty. But ultimately this is going to recurse all the way up to seven. And then the sort of clever part here is when an up query, let's go with this color. When an upgrade ultimately hits some data. So in this case it found this data over here. Let's make this the yellow box.
00:34:11.216 - 00:34:57.998, Speaker A: Right? So this is the data for seven. And no one down here has seven, then what it's going to do is it's going to forward that chunk of data for seven just along the normal data flow path. Think of it as it's going to send it as if it was a write, but it's going to essentially create one batch that has all of the results for seven in that one batch. When that batch of records for seven hit the join, the join is going to do the same thing a join normally does when it gets an update. It's going to do a lookup into here for whatever the join key is. It's going to get a result and it's going to stitch together some new version of that yellow block that includes the relevant record from the right hand side. It's going to forward those and it's also going to fill in the value for seven.
00:34:57.998 - 00:35:25.760, Speaker A: Because it now knows the value for seven. It's going to forward that down here. It receives seven, it then fills it in because it sees that this is a response and now has the data from seven. And any subsequent query for seven is now going to hit instead of miss. So that's the basic premise for up queries. We should spend a little bit of time to sort of talk through this as well, because upgrades are a key concept to what we're going to be dealing with today. So if you have questions about upgrades, now's the time.
00:35:25.760 - 00:36:09.568, Speaker A: I know that I'm moving quickly through this. This is a lot to take in, but in order for us to get to somewhere we can solve an actual problem, we need to go through all the things that work first. So, like, ask questions at whatever sort of level you feel like you don't understand this, a kind of pull based lookup. You can think of it that way. Although it's important that the response to an upgrade is sort of treated like a normal write. This means that the operators do not need to have special code to deal with the sort of partial case. The operators is written to take records from.
00:36:09.568 - 00:36:59.230, Speaker A: From their ancestors and produce records for their children, right? So for a filter to take, sort of a simple operator, the filter operator takes records from its parent, and then for each record in that batch, if it matches the filter, then it's included in the output it sends to its children. If it does not match, the filter is not included. A join is a little bit more complicated, right? Where for every record in the batch input you get, you do a lookup in your other ancestor for the. Whatever is the join key, and then you sort of splice together the results and that produces the output batch. But the nice part of this is all of the operators are basically, are more or less unaware of the fact that partial exists. The operators can just know about their own semantics. And that's all.
00:36:59.230 - 00:37:42.524, Speaker A: Let's see here. Could an upstream upgrade hit two nodes at the same time with different results? Yeah, so this is going to be the next step, which is how do you deal with consistency when you have a queries? So it's a good question. We're going to deal with that in a second. Does the upquery recursion tend towards the shortest path? In general, when you analyze a given graph, the upper e must take a given path. There might be multiple paths. In the case of unions or in the case of joins, you get a choice. In terms of getting a choice, Noria tries to be smart about which path it chooses.
00:37:42.524 - 00:38:17.146, Speaker A: Like if you have a full inner join, the upquerect can take either path, but it should not take both. And the details for that are relatively complicated. But for a union you have to upquee both paths. I'm only talking about things that have two ancestors, multiple ones, generalize. But if you have an upgrade that comes to a union, it has to take both paths. And if you have an upgrade goes through a join, you pick either path and then when the response comes back, it's going to query the other side. And that query you can think of as being the other part of the up query.
00:38:17.146 - 00:38:59.158, Speaker A: So you end up exploring both paths and there it tries to be intelligent about which one it does the replay from and which one it does the lookup into. How do you remove tombstones so you can evict entries in Noria? Currently the process is relatively stupid. It basically does randomized eviction, which is not great, but you could implement something like LRU or whatever. For us, the important thing was to support eviction. Choosing an intelligent eviction scheme is sort of not that interesting. This is one of the examples of a difference between production and research. In research it matters that we can support eviction.
00:38:59.158 - 00:39:27.940, Speaker A: It is not terribly important that the eviction is also smart. That's sort of a separate area of research, because most materialized view systems cannot support eviction at all except on sort of the full query level. Like remove an entire query or keep the entire query. Whereas here we can be a lot more fine grained by what we include and what we remove. Don't understand SGBD's. I don't know what SGBD are. So you'll have to explain that to me.
00:39:27.940 - 00:40:11.780, Speaker A: Is it worth understanding why we traverse to the left parent and then the right parent in the case of a left join? So in the specific case where this is a left join, you must query the left side. The reasons for this are somewhat complicated and not relevant to what we're going through today, but you must choose the left. If it's a full join, an inner join or an outer join, you can query either ancestor. It does not matter. There might be different performance, but it does not matter in terms of semantics. There is eviction when materialization gets too big. Yep, you have a main DB at the bottom.
00:40:11.780 - 00:40:40.030, Speaker A: There's no main DB. Well, so, so if you're talking about them, the view at the bottom, it's really just like a hash map. It has no smarts, it doesn't know about queries. All it knows about, if someone asks me for seven, I look up in my hash map and if I have seven, I return that. Otherwise I upgrade. And so every, every operator, every node in this data flow graph only knows about its own semantics. It does not know about queries or anything like that.
00:40:40.030 - 00:41:13.910, Speaker A: None of these are databases in and of themselves. They really like the join operator really only knows about joins the tables at the top, have an interaction to some kind of persistence engine, currently rocksDB, but it does not have to be. But that's only for durable storage. They don't use the query interface really for that. With the upcree go, both pass from the join. So I think I've covered that reminds me of laziness. It is sort of like laziness.
00:41:13.910 - 00:42:31.530, Speaker A: You sort of force the funk that is seven. When you get enough career for seven, the model sort of falls apart if you look at it too closely, but sort of because you sort of essentially manage this tree of dependencies you need to explore in order to get the final result. What data type are you using underneath? Where would it be too hard to add? Pluggable eviction? No, I mean, eviction is sort of just separate. The way eviction actually works currently is you can insert an eviction record into the system at any point. Like you can insert here saying I want to evict something from here, and then it's going to flow through the data flow, and when it hits here, it gets evicted from there and then we're down. You have to evict from anywhere you evict, you have to evict all the way to the leaves for that key because otherwise you run into consistency issues and we talk about this in the paper eviction scheme sounds conceptually similar to garbage collection, maybe kind of a little bit different. Oh, dbms.
00:42:31.530 - 00:43:12.060, Speaker A: Ah, that's fine. Graph data sorter. There is a graph data searcher actually to keep track of the full data flow graph. Although it's relatively immaterial, we don't really do any advanced analysis of the graph itself, although you could for things like query optimization. Great. All right, so now we're going to move on to step three, which is over here. Alright, so now let me pose you with a problem.
00:43:12.060 - 00:43:46.234, Speaker A: Let's come up with. All right, now we're going to start talking about unions. So I'm going to have two base tables. So these are base tables a and b, let's call them a and b. And then over here we're going to have a union. And then down here we're going to have some kind of view. All of the view is going to be partial.
00:43:46.234 - 00:44:14.250, Speaker A: The union does not need to be materialized because it doesn't need to have any state to compute. Right. So an aggregation needs to have a materialization because it needs to store the current count or this current sum. A union is stateless, is a stateless operator, much like a filter. A view is, is materialized, of course, because we need to be able to read from it. And the base tables are materialized because we need to be able to query into them and they need to be durable. And now let me pose you the following problem.
00:44:14.250 - 00:44:42.244, Speaker A: So imagine that again, some query comes in for seven here. That's a terrible color. Let's do a better color. Let's do this color. So a query comes in for seven here. And let's say that the view does not have seven, so it needs to upgrade. Well, because this is a union, we need to get the results from both A and B.
00:44:42.244 - 00:45:08.490, Speaker A: Right. So V here is going to send an upgrade up here for seven. And it's going to send an upgrade up to here for seven. Okay, that's great. Now A is going to respond with its records from seven. B is going to respond with its records from seven. And then these are going to arrive as two separate replay responses, both for seven to the view.
00:45:08.490 - 00:45:41.230, Speaker A: Now imagine that the view here, just the moment it gets the first replay response, is going to start serving reads. So this initial read that came in for seven, let's draw that maybe in a different color. This initial read that came in for seven, the moment this first response comes in for seven, the state for seven is no longer missing. Right. Because in V's state there now is an entry for seven there. But it only has half the records. It only has the records from a and it does not have the records for B.
00:45:41.230 - 00:46:23.956, Speaker A: And so if we now responded to this query we'd be including only parts of the results. Now there's an argument about with eventual consistency this wouldn't be a problem. That's true, although this doesn't in the more general cases is a problem. Right. We can't consider state to be present until we have all parts of that state. And so what we're going to do is we're going to have the union wait until it's gotten replay responses from both sides and then issue only a single replay response downstream. So rather doing what we're currently doing here, the union, when it gets the first seven, this is the first replay response for seven.
00:46:23.956 - 00:47:16.210, Speaker A: Up courier response for seven. It's not going to forward it. Instead it's going to keep this little box where it's going to stick the seven and then it's going to open a similar box on the other side and it's not going to allow through this replay for seven until eventually the replay from seven from the other sides arrives and fills this box. At this point the union has filled both its boxes and then it can combine. Because it's a union, right. It can combine both of these upgrade responses into a single seven response which then fills the state in v completely immediately. Does that make sense why we need to do this? Why we can't just expose the partial state? Let's think about this for a second because this is also important to what we're eventually going to get to fixing.
00:47:16.210 - 00:48:00.688, Speaker A: All right, so hopefully this one, this should not be too complicated yet. This is just like, obviously we can't just take the first response we get. We need the union basically needs to know about the fact that it's a union and that if one upgrade response came then there will be others. Oh, that's a lot of questions at the same time. Seven is not a primary key. So results may be in both a and also b. Yeah, seven does.
00:48:00.688 - 00:48:50.030, Speaker A: So Noria does not require primary keys anywhere but here, even if seven is a primary key, it might be a primary key of a and b, in which case there'll be one entry in a and one entry in b that they both need to be replayed. Yeah, there's no uniqueness constraint here on the column that seven is hosted in. How is it that a materialized child can have a stateless parent from which it needs to draw data? The reason for that is because here the view is materialized, right? And the parent, the union is stateless. And that's fine, because if this view needs state. Sorry, maybe you can't see what I'm drawing. If the v at the bottom needs to fill some state, it just asks its nearest materialized parents or ancestor rather. So in this case, it sees that it's the.
00:48:50.030 - 00:49:17.160, Speaker A: The way this actually works. You could think of this as the upgrade is just sort of sent along the edges until it hits something that is materialized in reality. The way this works is that Noria does an analysis of the graph and it tells v that if you are missing state, you should send an upgrade to a and you should send an upgrade to b. It doesn't even mention u to v. And so v actually sends the upgrade directly to that. It's not. Hop up the graph the way I've drawn.
00:49:17.160 - 00:50:06.072, Speaker A: What happens if there's different value? I think you need to expand on that. Can you at least start letting data stream over the network before the full state is complete? And in theory you could, although we're about to get to a complication that would probably make that hard. Great. All right, so one of the places where we run into a challenge now here. So what I'm going to do is in red here. So bread is okay. I'm going to start injecting rights into the system.
00:50:06.072 - 00:50:50.114, Speaker A: So here, there, you can imagine that there are a bunch of concurrent writes coming into the system, right? And some of them might be for seven, but some of them might be for some other key, like, say, eight. This poses a problem with upgrades. And the reason for this is imagine that on this path. Let me erase a little bit here. Ooh, that was larger than I wanted. Let's do this color. Yeah.
00:50:50.114 - 00:51:17.402, Speaker A: No draw. Yeah. Why can I no longer draw? Oh, that's why. Let's bring this guy back. And then let's bring back what we had here of. Okay, so the seven response here and the seven response here. All right, I.
00:51:17.402 - 00:51:38.406, Speaker A: And now imagine that there are some rights that come ahead. So these happened before, if you will, the seven upgrade we got. And some writes that come after. Similarly here and here. Right. Because we don't want the system to sort of stop. We want the system to keep going, basically at all times.
00:51:38.406 - 00:51:58.980, Speaker A: If the system had to stop whenever there was an upgrade and not process any writes, this is. Would grind to a halt whenever any read missed. And so we really want the system to just keep going as fast as it can in any given position. And this obviously complicates matters. But it's something we'd like to do. Okay, so now let's imagine that this is a right for seven. This is a right for eight.
00:51:58.980 - 00:52:52.502, Speaker A: This is a right for eight. This is a right for seven. So before we get to this, let's move back to here, we need a little bit of a primer. Someone asked earlier what happens if a write comes in for. Or how do I mention in the very beginning of the stream that if you get that we don't do any work for a key that no one has read? If no one has asked for key seven, then if we get a write for seven, we should store it on disk, but we should not compute anything for it. And the way this works in practice is that, I guess, yeah, let's go all the way back to here, actually. So for our vote count table, for example, here, its current state is it knows the count for seven, but it doesn't know the vote count for anything else.
00:52:52.502 - 00:53:28.208, Speaker A: And the reason for that is no one has asked for any other key, so it hasn't bothered computing it. Imagine now that a new vote comes in for eight. The eight that seems fine. So right now comes in for eight, comes down here to the vote count. The vote count looks up in its table and it sees, well, I don't have an entry for eight, right? This is missing. There's no value here. What's it going to do? Well, it can't forward anything, right? It can't tell the downstream view what the new count is because it doesn't know what the old count is.
00:53:28.208 - 00:54:03.098, Speaker A: So it has two options. Either it could compute the current count for eight and then respond, or you can just drop the update. Noria currently does the latter. And the reason for this is if no one has asked for eight, then why bother computing anything for eight? You could, you could spend a bunch of resources sort of counting the, let's say, million votes that there are for eight. But why bother when no one has asked for it? Let's just do that work when someone asks instead. Because it could be that no one will ever ask or that they won't ask for months. It could very well be.
00:54:03.098 - 00:54:38.820, Speaker A: And so Noria currently, when it gets a write for a partial entry that it does not have, it just drops that update and does no more work. And this is the way that Nori avoids doing work for keys it doesn't care about. Which then brings us back to this problem. All right, so consider what happens when these rights flow through the union. Right. Ultimately, these rights are going to feed into this union and the union. It's stateless, right.
00:54:38.820 - 00:54:59.166, Speaker A: So it doesn't know whether to drop or forward updates. So it's just going to forward everything. It wouldn't know whether we missed. It's going to forward it to the view. The view down here has seven but does, does not have seven yet. Right. This is the green stuff here is after we've gotten seven.
00:54:59.166 - 00:55:16.810, Speaker A: So it gets a right for seven, which it drops. And then let's just imagine that it gets the two things from the left, right. So you get seven and eight from the left. It's going to drop both of them because it has no state for them and it doesn't. So it doesn't know what the past state is. So therefore it doesn't know what to do about those updates. So these are just going to be dropped.
00:55:16.810 - 00:55:37.046, Speaker A: And then the, when the up courier responds for seven eventually arrives and the state gets filled in. So at that point we have the state for seven in the view. Then any subsequent write for seven or eight. So anything that comes after the up queries. Right. Is going to flow logically after this. Right.
00:55:37.046 - 00:56:37.660, Speaker A: They're going to come in after here and those are going to be applied because at the point when we receive them, we do have the state for seven. We do not miss when we get that right. Okay, let's pause there again for a second before we continue. Let's see, in the case b stops working, does it keep processing union requests until it's out of memory? What do you mean by stops working? I have not talked about failures at all yet. Could you probably get an incomplete flag on these updates so the upstream processor can start their computation? When you say upstream, do you mean downstream as in physically down on the drawing you could, although it's not clear they can do anything until they have the complete result. Often they're computing on full values. It's not clear they can do anything with a partial response, although in some cases it could.
00:56:37.660 - 00:57:17.600, Speaker A: What happens if a returns a different value for seven than b? Well, the semantics of a union is that you get the results from both. It's not a discrete union, it's just a straight up union. So it's all the records from a and all the records from b with no deduplication. As in tell me if x matching pattern z comes in. Yeah, great. Let me just sit and think for a few minutes. That sounds about right.
00:57:17.600 - 00:57:57.098, Speaker A: Okay, so hopefully this sort of image makes sense of we're going to drop rights for keys that are missing, but if we get updates for keys that are present, then we're going to apply them. So now you know most of the stuff that you need to know about sort of partial and how that works. But now we're going to get to a place where it gets complicated. And so I'm going to move to another drawing so that this one stays less busy, in theory. If I can find my mouse. There we go. All right, try to keep the same color schema here.
00:57:57.098 - 00:58:13.820, Speaker A: So yellow are the operators. Okay, so we have an operator here, which is a. And we have an operator here, which is b. Looks more like a d, but it's a b. Just have to trust me on that. And we have a union. And then down here we have a view.
00:58:13.820 - 00:58:54.864, Speaker A: Great. So now let's see what happens. If we're going to have, I guess, upgrades where something like this color. We're going to have an upquee response from a. Actually, here's how I'm going to draw this to make it a little bit clearer what's going on. I'm going to change this drawing a little so it's clear what the order of operations are. So let's go back to this.
00:58:54.864 - 00:59:33.312, Speaker A: No, no. That color. So I'm going to do this. And then we're going to say that, sort of think of these as being like, at the same time, this is sort of the single pipeline into the union, right? So the union that there are two things that are connected to the same sort of socket on the union. So, like, the union has one channel input because it can only. The union can only process one thing at a time. And so it chooses to think of it as a select over a and b over a receive and b receive.
00:59:33.312 - 01:00:05.020, Speaker A: Right? And so it only gets one at a time. And then a and b send entirely separately. So now imagine what happens if. I don't want the plot. If the order that the union gets things in is it's going to receive an up query response from a. Let's assume that these are all for the same key for the time being. Then it's going to get a right from b.
01:00:05.020 - 01:00:41.350, Speaker A: Then it's going to get a. Actually, let's do this. Then it's going to get a. All right, so the order here for the union is that it's going to get an upcurry response from a. Then a write for the same key from b, then a write for the same key from a. And then the upcurry response from b. And let's see if you start to spot the problem.
01:00:41.350 - 01:01:29.782, Speaker A: Can the node at the bottom start processing some data from the partial union, like filtering. In some cases it could. The complexity is probably not worth it to have it process incomplete data. Ultimately you're going to have to do this merging somewhere, and the union is a good place to do it. And remember, the downstream operators are still processing writes and stuff, so it's not as though the system stops if the upgrades are tagged somehow. Could you either drop all the updates before, or it gets tagged responses back, or start aggregating the values? So there are sort of tags here. The tags are generally what upquery path is this and what key is it for? But ultimately, like, the merge just has to happen at some point.
01:01:29.782 - 01:02:16.900, Speaker A: And so doing it early while processing writes means that you avoid the complexity of having downstream things have to deal with incomplete data. Like computing on incomplete data is complicated, and so just not having to deal with that is easier. And because there are concurrent rights anyway that the union is letting through, it doesn't really make too much of a difference. Do you have the full documentation somewhere? There is no full documentation. Most of it is in my head, sadly. There's a lot of detail in the paper. So from the GitHub repository for Noria, there's a link to the paper from OSDi 2018, and that has a lot more detail about how the system works and why it works the way it works.
01:02:16.900 - 01:02:59.784, Speaker A: How do you get a one, b one and a two, B two? No. So this is an important point. Every channel here is in order. So we assume that if a sends, if a sends, let's do like a one and then a two, right? And b sends b one and then b two. Then at the union you will receive them in order. Think of this as like each of these is tcp. So the union might receive like a one, then b one, then b two, then a two.
01:02:59.784 - 01:03:42.160, Speaker A: That's a valid thing for it to receive, but it cannot receive like a two, a one b two. Like b one. Like this would not be a valid order because it doesn't respect. It doesn't respect in order delivery on every path across paths. It basically does a select over them, sort of a non deterministic select. Yeah. So the problem here, as some of you have started to observe, is that what the union is going to do, let's avoid littering here by getting rid of this stuff.
01:03:42.160 - 01:04:17.234, Speaker A: The problem here is that the union, let's name these. So this is going to be, don't want to erase. This is going to be a. Actually, let's do, let's say that this is going to be a one. This is going to be b two. Just having names is easier. This is going to be b one, and this is going to be a two.
01:04:17.234 - 01:04:44.640, Speaker A: And then I'm going to go ahead and erase these up here because they're not terribly important. Right. So the problem we run into here is the union first receives a one, right? So it. It sort of constructs. Think of it as it constructs it, like its left box and its right box. Right. And then it sticks a one in here.
01:04:44.640 - 01:05:04.998, Speaker A: And now it's going to be waiting for b two. Right. So, okay, we've handled this guy. Now we got b one. What does the union do? Should it forward b one? Right. It has to make a decision. It can't skip ahead on the channel to b two.
01:05:04.998 - 01:05:20.520, Speaker A: Because it has to handle these in order. So it needs to handle b one first. It also can't choose to handle a two. It got, like. It did a non deterministic select from its parents. And it got b one. What does it do? B one is for the same key as a one is.
01:05:20.520 - 01:05:55.850, Speaker A: So it turns out that the right thing for the union to do is to drop b one. Drop b one. And how does it know to do this? Well, what it's going to do is going to look at its sort of pockets on both sides. And it's going to see if it has a non empty pocket for the same key as the right it received. And the right is from a different side than the pocket. Right. So the right here is from the b side.
01:05:55.850 - 01:06:21.952, Speaker A: And the pocket that's filled is from the A side. Then what that means is that the union knows that eventually in the. In the case here of a and b, right. I've gotten a replay, an upcurry response from a yemenite. I will get an upgrade response from b. The thing I just got was a write for the same key. Which means that I still haven't received the upcurry response.
01:06:21.952 - 01:06:48.950, Speaker A: And the write happened before the upcurry response. So the upque response must include this. Right. Or the way to think about this, maybe, is that b two. B two must include b one. It might include a bunch of other stuff, but it must include b one. Because b one happened before b two at b.
01:06:48.950 - 01:07:22.942, Speaker A: So when B took sort of a snapshot as what is my current state for the key? Let's say all of this is, like, for key seven. Because that's what we've been using, right. So when B got the upgrade for seven, at that point, it must have already processed b one and therefore b one must be included in b two because they're both for seven. That make sense. And therefore, dropping b one is the right thing to do. If we did not what we could, in this particular case, we could actually forward b one as well. It would be fine because the view would just drop it.
01:07:22.942 - 01:07:58.500, Speaker A: There's no reason to forward b one. We know that no one downstream of us is going to care about b one. Okay, now let's imagine that we get a two. Now what do we do? Okay, so we've already got an a one. And by the, by the same argument, the b two must include b one. A one must not include a two because at the time when the a one sort of snapshot was taken for the key seven, a two was not at a. A had not received a two yet because it had not yet produced a one.
01:07:58.500 - 01:08:27.100, Speaker A: And so when it produced a one, a two was not present at a, and therefore a one must not include a two. So dropping a two is out of the question. If we drop a two, then the state represented in a two is just gone forever. And so it never gets represented in the downstream view, which would be bad. It would be as if that record never existed. But we also can't forward a two. If we forward a two, the view is just going to drop it because it doesn't have the state for the key yet because the upcoming is not yet completed.
01:08:27.100 - 01:09:06.640, Speaker A: And so the, it turns out the result. And what you need to do here is if you get a right for think of it as for a non empty pocket. So in this case, like a come, the a pocket has an entry for the key that the write is for. Then a two should basically be unioned into this stored thing. So this is now going to include both a one sort of union a two. And keep in mind here, a one is like a snapshot of all the state of seven. And then a two is just an update to that state.
01:09:06.640 - 01:09:56.599, Speaker A: So all we have to do is apply that update to that snapshot of the state. So notice that the behavior is different depending on where we get the update from. Okay? And then finally, when we do get b two, eventually, then. Now the story is pretty straightforward. We get b two. B two fills this slot and at this point we can produce an upgrade response from this whole thing, which then includes a one plus b two plus a two, but crucially, not including b one. And this will be a sort of consistent snapshot at some point in time in the input sequences from a and b.
01:09:56.599 - 01:10:24.840, Speaker A: Assume all of this is for the same key currently. Yeah, sorry, I hit the mic. All right, that was a lot for us to go through. So, questions. Make a box for b one. Make a box for b one. There's no box for b one.
01:10:24.840 - 01:11:26.618, Speaker A: How do we distinguish between b one and b two? Is there some sort of artificial timestamp? Okay, so there are two questions here. One is, how do we know that b one is a write or an update, and b two is an upcurry response? Given that I said that, upcurry responses are basically treated like normal updates as far as the operators go, and the answer to this is up. Query responses are tagged as being such, like they still have records, just like normal updates do. But they also have a little. Think of it as a flag that says that I am actually an upque response for a query for this key. Apart from that, you can distinguish b one and b two by the sequence in which they arrived. But you wouldn't if all you had was the sequence.
01:11:26.618 - 01:12:00.600, Speaker A: You're right. You would not know which one was an upgrade response and which one was just a normal update. Could the pocket not be a list of sorts? Yeah. So in practice, these pockets aren't pockets at all. They're really just hashmaps from the address of the source. And then the union knows how many parents it has. And so it basically looks for any given update, it looks up in the hash map, the source of the packet, and then sees whether there was an entry or not for that source, for that key.
01:12:00.600 - 01:12:38.342, Speaker A: And then when the length of the hash map is the same as the length of the or the number of ancestors, then it knows that it's completed the upgrade. How is order determined? Don't know what you mean by how is order determined? Why can't we use b one instead of b two? So b two. B one is an update, b two is a snapshot. Think of this as b one is going to be something like one vote got. It's gonna be like plus one vote for article 72. B two is gonna be. Here are all the votes for article 72.
01:12:38.342 - 01:13:20.690, Speaker A: And so b one is sort of a delta, whereas b two is the complete result set. And so b one is not sufficient to fill in the state at the downstream nodes. B two is much larger than b one is, because b two includes everything for that key for the upgrade key, whereas b one only includes a particular delta. Isn't that the same thing on both sides? If b two includes b one, yeah. So b two includes b one but a two, but a one does not include a two and a two. Similarly, is an update. It is not a snapshot.
01:13:20.690 - 01:14:12.010, Speaker A: It only includes one delta, whereas a one is a complete snapshot of the state from a. For the upquery, key writes and updates is sent via channel, which acts as a queue. Yeah, like these yellow lines here are. They're channels if you're. If the nodes on either side are on the same machine and there are TCP streams with like, serialize and deserialize if the parent and child are in different machines. Okay, so hopefully this, this problem makes sense. And it also explains why unions have to buffer and what they have to do in the presence of concurrent updates.
01:14:12.010 - 01:15:08.964, Speaker A: Like, you can see how deeply we've, like, transitioned into a very deep part of Noria here. Are there questions about this before we move on or sort of about the general workings of this area of Noriae? Reminds me of video codex in some sense. You could think of it this way. Yeah. Like a one and b two are. Are, what are they called? Keyframes. Whereas b one and a two are just.
01:15:08.964 - 01:16:05.590, Speaker A: Are just delta frames, or iframes. If you come from a video editing background, that might help. Yeah, we will eventually get to coding, but first I have to explain what it is we're going to be coding and what the problem is. Basically, we're about to get to the bug. The next drawing I make is going to be about what the bug is. All right. How does the union know that it's waiting for b two? And why does that mechanism not automatically solve the problem? The union knows that it's waiting for b two because, again, assuming all of these are for the same key, because it sees that the left pocket is non empty.
01:16:05.590 - 01:16:28.196, Speaker A: Right. So it knows that there's sort of a. An empty hole in the right pocket. Again, all of the same key. Right? So the left pocket for that key is not empty, and the right pocket for that key is empty. And therefore it knows that it's waiting for something from the right hand side. We use b two because it's a whole thing, not because of consistency guarantees.
01:16:28.196 - 01:16:56.598, Speaker A: Correct. We must use b two because b one is not complete. B one is a delta. B two is not a delta. Do you foresee a lot of issues with latency of TCP streams? No. All of this is the right path, and you can do a lot of nice batching here. The latency of TCP doesn't really bother me because, again, this is Noria is written for read heavy applications.
01:16:56.598 - 01:17:25.980, Speaker A: And the reads never. Well, the reads in the common case, right. In the stable case of the system are just going to be reading from the view down at the bottom. They're never going to have to traverse any of these inner edges. And so the reads are just super fast every time. They're not affected by all of this inner latency. Are we talking about a very small amount of time creating this hash? Like this isn't of the first read where writes occur in a short span of time.
01:17:25.980 - 01:17:56.940, Speaker A: What hash are you talking about? There's no hash here. So Noria could be used for video streaming. I don't think that's the takeaway. Alright, so I think we're gonna move on to what the actual problem is. Alright. If this is the first stream you're catching, you're catching a weird one. I can tell you that straight away.
01:17:56.940 - 01:18:33.270, Speaker A: Alright, so now we're gonna have to talk about sharding. But we're getting there. We're getting there. All right, so here's what we got. Let's call her. So now I'm going to present you with a slightly different problem which turns out to be similar. Imagine that you have some base table and you want to shard that base table.
01:18:33.270 - 01:18:54.776, Speaker A: So really let's say we have two shards. So this is a shard one and this is a shard two. And let's say that this is sharded by some column c one. Right. Let's sort of denote the sharding key over here. This way. Much better drawing the left ones than the right ones.
01:18:54.776 - 01:19:08.406, Speaker A: It's weird. And now imagine that you have some operator down here. Let's say that it is a. I don't really want to define what it is, actually. Let's do that. Sure. You have some other table over here.
01:19:08.406 - 01:19:25.610, Speaker A: I don't really care what it is. It's b. It's not charted. It's fine. Then you're going to have a join down here. And the join is also sharded. So there are two shards of the join, j one and j two.
01:19:25.610 - 01:20:03.458, Speaker A: These are sharded by whatever the join column is. So let's say that this is CJ for the join column, right? So if the. If you look up by like article ID, then it's going to be sharded by article ID. This is for various relatively uninteresting reasons, it makes sense to do this. And there's going to be some view at the bottom. And the view at the bottom is also going to be sharded. And what I mean by sharded here is that we're going to have multiple instances of the same thing, of the same operator.
01:20:03.458 - 01:21:16.650, Speaker A: And when they're sharded by, let's say this is CV. So I guess we can see a, when a, when a particular operator is sharded by some column, what that means is all of the rights for, for which that columns value modulo the number of shards is equal to that number. So for example, let's say that the value for, for Ca, for some record, let's say we have some new record up here and the value for CA is going to be this field is two. Then what we're going to do is we're going to do to modulo the number of shards, in this case two shards, which is going to give us zero and zero is going to be the 0th shard. I guess really I should name the zero. And so this entire record is going to end up going to this shard as opposed to this shard, right. If we got another record where CA was one, then we do one modulo two, we get one and it would go to the other shard.
01:21:16.650 - 01:22:18.390, Speaker A: This is how sharding is roughly going to work. And then whenever you have connections between operators, the connection sort of logically looks something like this. Notice that I'm not drawing them all the way to the boxes. This, I guess I can draw all the way to the box. And then you can sort of think of there as being like a shard, a charter operator here that does this sort of modular computation and then sends the updates to the corresponding shard and draw these as this little ball that has multiple children. Right? So there's going to be this little ball that we're going to call a charter. And so imagine that all of the updates that arrive on the path from b and all the updates that arrive from either a one and a two, they're all sort of going to flow together and then they're going to go through this charter and be sent to the appropriate shard of the downstream operator.
01:22:18.390 - 01:23:05.050, Speaker A: Of course, you can avoid this. If the, let's say here, if CJ, if CJ is equal to CV, then this is much easier, right? Then what you could really do is you don't need to do this extra sharding. You can just have j one connect directly to v one and you can have j two connect directly to v two. You don't need to reshard, but if you do need to reshard. So the picture we're drawing on the left here is if CA is different from CJ is different from Cv. So this is Ca is not equal to cj. And this is Cjdev is not equal to CB.
01:23:05.050 - 01:23:48.820, Speaker A: Okay? So that helps. But in order, if we're going to have this one charter that all of the updates from above are going to come to, then we need to make sure that all of the updates go into it. And so we actually need to combine the updates from multiple shards both here and here in order for them to go to the sharder. And so we need some kind of thingamajig here. We're gonna draw that with a triangle, just for fun because it looks like a triangle. So we have this triangle here. And what I'm gonna call this, this triangle is I'm gonna call the triangle a shard merger.
01:23:48.820 - 01:24:58.100, Speaker A: And I'm gonna call this a sharder. Right? So the shard merger merges the output of different shards and the sharder shards all the inputs it gets, right? So b, for example, b in the top left here, b is not sharded, but it, but the output stream of b needs to be sharded because J is sharded. And so there's going to be a sharder there, but not a shard merger because there are no, there's only one shard, so to speak, of B. So it doesn't need to be merged. And it should be fairly obvious at this point that a shard merger is really just a union, right, because it's taking mobile inputs and just combining them. And whenever we have a union, lo and behold, we need to do this buffering, or in other words, we need to implement this sort of pocket system, right, that we've been talking about. Does this sort of model of sharding make sense before we proceed? The, the bug we're fixing will appear on this image, I promise.
01:24:58.100 - 01:25:26.446, Speaker A: Income sharding. Yeah. You're not wrong. Um, it seems to me John is getting better in drawing a writing on his thingy. I mean, maybe, I mean, I think it's possible to maybe understand what this drawing is supposed to be. It's unclear. It's like the aggregator pattern, sort of.
01:25:26.446 - 01:26:16.958, Speaker A: So while you think about questions about this, this layout, one thing that's worth observing here is that you might think that there's sort of a bottleneck here, right? There's sort of an obvious bottleneck where what? Like if this is not charted, if this line of this connection is not charted and the charter is not charted, right. And this is not charted. And this is not charted, it seems bad. And in fact, this guy isn't even charted. And this guy isn't charted. Then are we really getting any benefits from sharding? Do we actually expect to see a speed up if people enable sharding? It's a good point. This is one of the things that we'd like to get rid of in Noria if we could avoid having to do.
01:26:16.958 - 01:26:52.490, Speaker A: Basically, this is whenever the sharding key changes and you have to do a shuffle, as we call them. We call this sort of combination of a shard merger and a sharder. I can draw this here somewhere if I can find my cursor, because it's really small. This plus this is equal to a shuffle. So we don't have to do a shuffle between b and the J's because there's no sharding of b. But we do have to do a shuffle between a and J because our sharding key differs. And we have to do a shuffle between j and v because our sharding key differs.
01:26:52.490 - 01:27:33.652, Speaker A: And currently these shuffles are not sharded in Noria. And we would like to have sharded shuffles to basically avoid this bottleneck. But keep in mind that this bottleneck is entirely stateless. Right? Like the both the Shard merger and the sharder are stateless and they're relatively quick operations. They're really just doing routing. And so first of all, you could sort of imagine you could do this as a very low level network types function, but also most of the, most of the compute, which is usually where the, the resources of the system are bound up, is still sharded. This is mostly just sort of the wiring.
01:27:33.652 - 01:28:24.180, Speaker A: And so we expect this wouldn't matter too much because you still get to shard the compute and the storage. Crucially, which machine does the sharder run on? Does it matter? So keep in mind that sharding does not have to be for multi machine. Sharding also matters for multicore. You could imagine that if you have many cores, you still want to shard operators so that you can process like more join operations in parallel for the same join. Normally, Noria is every Noria operator is only ever processed by a single thread at a time. Think of it as every operator is a future, and that future itself will only ever run on one thread, even though the sort of multiplexing of which thread runs which future. There's never two threads running one future at the same time.
01:28:24.180 - 01:29:00.650, Speaker A: And so you might want to shard an operator even in the single machine case, in order to be able to take advantage of more cores. And this is one of the things that's nice about this dataflow model. It's pretty easy to map it onto both multicore and multi machine. As far as where the sharder and the shard mergers need to run, they can run anywhere. It is nice for the shard merger to run relatively close to the parents and the sharder to run relatively close to the children, but it's not required. So, yeah, it could be anywhere. Really.
01:29:00.650 - 01:30:01.140, Speaker A: Shard sounds like a made up word at this point. Yeah, you're not wrong. I have said charting a lot up query as well is a similar one. We're like, it just sounds to me now, Sharney reminds me when I use the crush algorithm in order to know what data went where. Yeah, so, so that's another question here, which is, how does the sharder decide where to send each data? The scheme I've given you here, it's just a symbol like hash. Hash partitioning, where you just hash the value and then you take it modular the number of shards and send it there. There are improvements we want to make here, too, where you'd really like something that's a little bit more dynamic, both so that you can add and remove shards, but also you really want more like a value range partitioning, where you could say, if one key is particularly hot, you might want to say this key goes just to that machine and no other key goes there in order to satisfy that load.
01:30:01.140 - 01:30:56.822, Speaker A: And so that's the kind of stuff that we're looking at adding, but have not added yet. What's the difference between sharding and multithreading? Um, so sharding just lets you have more operators to handle the same work. So sharding in and of itself is really, you can think of it as a slowdown, right? It, it's adding more operators to do the same work, but it enables better multi threading or more multi threading, because you can run those additional operators in parallel. So sharding enables more multi threading in your data flow. It also enables more machines to be used in order to sort of take on the load of the system. Looks like the sharder can be easily sharded, but the merger can't be sharded because it must do buffering. So this is actually one thing I'm not sure about.
01:30:56.822 - 01:31:36.940, Speaker A: I think you might be able to shard the merger as well, but I don't know yet. This is one of the, like, research questions, right. And the problem we're going to solve today is somewhat related to that, although not quite the same. What key do I press to cycle through the autocomplete control n how's the shard merger? Stateless. The shard merger is stateless in the sense that the only thing it needs to keep track of for these pockets for replays and whenever the re the for upgrades. Sorry. It needs to buffer an upgrade response only until it gets a response from the other shards or the other ancestors.
01:31:36.940 - 01:32:22.980, Speaker A: But beyond that, it's stateless. Like it doesn't keep persistent state per key. It only keeps relatively ephemeral state for upgrades. In the current system, the number of shards is fixed, which is another it's sort of related to, but not quite the same as wanting range partitioning. Alright, so now let's get to what the problem is. And we're only going to solve one part of this problem today because the other part is much more complicated. So let me bring up our upquee color here.
01:32:22.980 - 01:33:02.304, Speaker A: This color. All right, imagine that. How are we going to do this? Imagine that an up query comes for seven. Seven is our enemy here. And it goes to view two because. So this is where like CV is going to be the both the column the view is sharded on, which is going to be the same as the lookup column of the view. Right? So if you want to query the view on column value seven, you only have to ask one shard.
01:33:02.304 - 01:33:52.370, Speaker A: This sort of speeds up, reads a lot because if you had to ask all shards, it would be kind of unfortunate, although there are cases where you want to do it. So your query for seven goes to view two because seven mod two is one, which is two because I didn't zero index these indices, which is annoying, but it's fine. So a query comes in for seven to V two and V two misses. So V two needs to upgrade. All right, so V two has to send an upquery. And in fact, I'm going to make a slight adjustment here to make this work out. I'm gonna say that this is actually a right join.
01:33:52.370 - 01:34:29.216, Speaker A: Should have drawn this the other way around. So it was a left join, but it's fine. And you'll see the reason for this in a bit. So this upquery needs to go do both shards of J and to see why the lookup key here is seven. Right? So we. We want everything where cv is seven, right? That's the query that we're sending up here. Well, we don't know because.
01:34:29.216 - 01:35:08.532, Speaker A: Because of this, right? Because of this. The fact that CJ and Cv are different. We don't know whether to, whether we, whether Cv equals seven is at j one or j two. In fact, there might be some records on j one and someone j two, because j is just sharded by an entirely different column. And so unless we knew something else about the data, we have to ask both shards. Alright, so j one and j two both get enough query for. For where Cv is seven.
01:35:08.532 - 01:35:36.200, Speaker A: This is all well and good. Imagine that they both miss. Okay, so now they both have to upgrade. So I'm going to draw these in slightly different shades because that might be useful later. So we're going to go one is going to be greener, one is going to be bluer. So j two has to issue an upgrade. But it's issue an upgrade for cv equals seven.
01:35:36.200 - 01:36:17.210, Speaker A: But because of this thing, we don't know whether it's at a one or a two. Right. So this upgrade needs to go to both a one and a two. So far so good. But now, and this is the kicker, the upcurry we made to j one, it has the same problem. It's looking for cv equals seven. Because of this, it needs to upgrade both the shards of a.
01:36:17.210 - 01:36:55.920, Speaker A: See what the problem is. Both a one and a two both receive an up query for the same key twice. This means that they're going to send two responses for the same key at the same time. And so what happens to our poor, poor union over here? Let's, I guess red is right. So we're going to go with green. Some kind of bright green maybe. Yeah, it's good.
01:36:55.920 - 01:37:34.226, Speaker A: So our little shard merger here, I like to draw them like this with a little dot in the center to indicate this is a shard merger, which is sort of a special form of a union. So this union is going to receive a one, a one, a two and a two. All of which are up courier responses. And if we think about what that looks like for a second. Right. So it conceptually has a left pocket and a right pocket. Remember, it has one of these for each value.
01:37:34.226 - 01:38:08.766, Speaker A: The problem here is the value, the sort of key, I should say key, not value. Here it has one set of these pockets for each key. But the key here is the same for all of these. All of these have key is like CV equals seven. So when a one arrives, that's great. What if another, what if the input to this is such that the order is a one, a one, a two, a two. Okay.
01:38:08.766 - 01:39:04.780, Speaker A: We receive the first a one and then we receive the second a one. What do we do with this guy? What do we do when we receive this? And what do we do when we receive this? It's not clear. Okay, so let's. Let's discuss the problem and then. And then I will explain how we're going to fix this particular problem. You might also observe that there's another huge problem here that I've sort of just ignored, which is this is definitely bad and sad. You'll notice that this one innocent up query here had to ask n shards of j, right? Each of which, so that's a multiply, has to ask n shards of a.
01:39:04.780 - 01:39:51.520, Speaker A: And this, some quick maths is n squared. This is not great, right? A single query for a key led to n squared up queries. And this means that, like, if you imagine that you have many shards because you wanted a fast system where you have a lot of data, this means you're doing a lot of upgrades. And in theory, this, it shouldn't be necessary. There's no reason for both of these occurs to happen because they're asking for the same data. So in theory, there might be a way for us to make only one of these happen, but we need to make sure that it has to happen. If either J one or J two needs the data, right? Imagine that J one does not need the data and J two does need the data, then we still need the upgrade to happen.
01:39:51.520 - 01:40:31.710, Speaker A: Exactly once. This purple problem, this problem down here, this is research. I have some ideas for how we might want to do that. And we're basically not going to be talking about it today. Like, I'll answer some questions, but like, we're not going to be dealing with this today because I don't know how to solve it. If we had some time at the end, although it seems relatively unlikely, whereas this problem, I think I might have a solution to bug. See, I told you it was going to be on this drawing.
01:40:31.710 - 01:40:42.230, Speaker A: Alright, let's discuss. Oh, Tom. Tom. Hi. Stay safe. You too. Man.
01:40:42.230 - 01:40:52.566, Speaker A: It is a big mug. I love this mug. It's as big as my face. It's filled with tea. This is an unsafe, undefined behavior. Macro. Only 1 April stream.
01:40:52.566 - 01:41:12.366, Speaker A: I wish. No, this is my day to day. It's dealing with this stuff. Quite complicated, to summarize. Yes, I agree. This is one of the reasons why doing a stream on this is something that I've been hesitant to do. Because I realized all of this stuff needs to be explained and all of it is fairly technical.
01:41:12.366 - 01:41:29.930, Speaker A: The fact that it seems like maybe people have been able to follow is a great sign and better than I expected. Like, this is some complicated stuff. And like, if you. If you think about all the explanation we had to do in order to get to what this bug is. We're very deep. Or deep, deep down the rabbit hole. Right.
01:41:29.930 - 01:42:17.420, Speaker A: And so, summarizing at this point, this would basically take as much time as it took us to get here. Add counters for both a one and a two, and only propagate when the counters are equal. Do you combine a one and a two. So remember, one thing to keep in mind here, just to complicate the picture a little bit more, is these are rights. There may be writes in between here, right? Might be a bunch of writes here. And more importantly, let's do this in like white. This is like a one and a one prime and this is a two and a two prime.
01:42:17.420 - 01:43:11.670, Speaker A: A one is not necessarily equal to a one prime because it might have been rights in between. A two is not necessarily equal to a two prime because there might have been rights in between. And so what do you do? It might be that there are ways to sort of replace these. They're like, you only keep the last one, but how do you even know what the last one is? So again, remember here that we're in this weird position where the shard merger does not know how many up queries there were and so we wouldn't know how many responses it needs to wait for. If j one happened to have the records it needed, it did not miss. For CV equals seven, then there's only one up query, in which case we don't want to wait for the last one because there is only one. So we would wait forever.
01:43:11.670 - 01:43:48.410, Speaker A: Again, I have a proposal for how we fix this bug. I just want to talk to through what the bug even is. N two? Yeah. N squared would limit your closest size. Yep. Can we try to shard by the same key or does that become complicated? These assume that these view, the sharding of these views cannot be changed, or if you were to change them, they would lead to significant inefficiencies. Basically, the way to think about this in the context of this particular graph.
01:43:48.410 - 01:44:33.310, Speaker A: A needs to be a is a base table that's sharded. A needs to be sharded by its primary key because otherwise you doing primary key lookups, which you do a lot of, would be extremely inefficient. So a one needs to be sharded by ca. J basically needs to be sharded by the join key. If it's not sharded by the join key, then every join lookup has to talk to every shard of the join, which would be really bad because most of what joins do is do lookups on the join column. And so those two are just set. And the view is sharded by the lookup key of the view, which is what you want to shard by, because otherwise every read has to talk to every shard of the view.
01:44:33.310 - 01:45:33.410, Speaker A: And so this means that all of the shardings here basically set you. If you change them, you introduce enormous inefficiencies to the read or the write path. And so changing them is not really an option. A context is key here, that's for sure. If you solve the first problem of redundant up queries, wouldn't it also help the second problem by reducing the number of up queries to n queries of j plus n queries of a? So two n. Yes, there is an argument here for if we solve the upquery explosion problem, which is what we refer to it sort of internally, as that would solve this particular shard merging problem. It turns out that even if we somehow found a way to solve that sort of performance problem, there's still other query graphs you can come up with where a union might have to deal with this case.
01:45:33.410 - 01:46:19.834, Speaker A: It's a little bit too complicated to try to work through what those cases actually are live, but just trust me that there are other cases. So even if you solve the upgrade explosion, you still need to solve this union problem. Think of it as this union problem is like a correctness problem. It's a correctness bug, whereas the upquest is a performance problem that also happens to reveal a particular correctness bug. Can you buffer weight with the same locking concept with pockets in the sharder as you do in the merger for up queries? Right. So this is a good thought. The idea here that's being proposed is basically what if the up queries, rather than going directly to a.
01:46:19.834 - 01:47:07.152, Speaker A: The upgrade sort of went via the shard merger, and then the shard merger sort of combined the up queries and then they followed the path. Thing is, you don't really want to do that. There are a couple of reasons for this. One reason is that now the shard merger has to do a lot more work. And the other is that now your path for upgrade is a lot more complex because everyone tries to talk to the shard merger, and then the shard merger tries to talk to everyone, which means you have this like fan in and fan out problem, which leads to a bunch of performance bottlenecks, essentially. The nice thing about having up queries go directly through the source and not the upgrades do not actually follow the edges of the dataflow graphite. They go directly through the source and bypass any operators in between.
01:47:07.152 - 01:47:38.806, Speaker A: Only the responses flow in line in the data flow graph. And that's really nice because it means your upquery has to go through fewer hops. And it also means that you can use the network essentially more efficiently. But it would allow the shard merger to deduplicate. So that would be the upside. But as I mentioned, that still would not solve the other places where this union bug comes up. You only keep the latest snapshot, but you keep track of how many snapshots you've seen.
01:47:38.806 - 01:48:23.462, Speaker A: How do you know when you've seen the last one? How do you know which one is the latest? If you don't know how many upgrades there are, there might be some point where you've received an upgrade response. You've received an equal number from both sides, but there are still more coming. And it's not then you would still produce multiple upgrade responses. So. So a sort of non solution to this problem, right, is that we produce one up query response for every up query. Because what's going to happen then is J one is still then going to receive two up query responses and J two is also going to receive two, which is not really what they're expecting. Yeah.
01:48:23.462 - 01:49:02.868, Speaker A: So the upgrades go directly to the shards. What if the Shard who has cv seven says an upgrade to the Shard merger telling it that it found the record? Yeah. So you could have, you could have the shard merger tell if the upcurse went through the shard merger, then the shard merger could tell the. If the, if they went through the sharder, then the sharder could tell the shard merger how many upgrade responses to. Wait for that is one possible solution. But it still then requires all the upgrades to go through one path. So there's a good question that's being raised.
01:49:02.868 - 01:49:41.440, Speaker A: What exactly is the right behavior here? And it's not entirely clear when you have these upgrade responses where the union can't really distinguish a one and a one prime. It also can't distinguish a two and a two prime, except by virtue of time. And so it doesn't really know how to connect these. It doesn't, it doesn't know how to resolve this. And so that is part of the problem. And that observation is going to be part of the solution. Can you hash the pocket key with value and upgrade idea? So now we're getting pretty close to the solution I have in mind.
01:49:41.440 - 01:50:03.130, Speaker A: So I think we're just gonna go I'm gonna go ahead and give you my proposed solution and then I'm gonna p and you can discuss it while you think about it. Alright, so my proposed solution is as follows. I'm going to use. What color do I want to use? Pink. Pink is great. Let's go with pink. Red.
01:50:03.130 - 01:50:18.236, Speaker A: Green. Let's go with yellow. Like a bright yellow. Yeah, bright yellow. Bright, bright yellow. Beautiful. That kind of bright yellow.
01:50:18.236 - 01:51:02.130, Speaker A: Alright, so my proposed solution here is as follows. Rather than have the pockets be per key, we're going to stop doing it per key. We're going to have the pockets be per tag. And I'll get back to a tag is and requesting shard is my proposed solution. A tag is a particular up query path. So J one's up query path here and J two's upgrade path share the same tag. And so for the purposes of the examples we've talked through so far, you can assume that the tag is basically not there.
01:51:02.130 - 01:52:02.440, Speaker A: The tag needs to be there in order to deal with cases like when you have many, many upgrades. Like many different upgrade paths, all of which are different, but some touch the same nodes. But for the purposes of explanation here, I'm basically proposing that instead of keying this by key, we're going to be keying it by, sorry, and the key obviously comma key. So instead of keying the pockets just by key, we're going to be keying them by which shard made the request and which key it's for. And this also means that the upquery responses to these have to include this information. So that information has to be included in there in addition to the records in the key. This essentially means that the union just buffers completely separately for the upgrades that J one does and the upgrades that J two does.
01:52:02.440 - 01:52:53.932, Speaker A: The other reason why this is important and why I'm proposing the scheme is because ultimately, when the up query makes its way down here and eventually reaches the sharder, the sharder can now inspect this information in order to make the decision of whether the response should go to the left or to the right shard. Now, you'll observe this does not fix the problem of there being multiple identical upgrades happening at the same time. It doesn't avoid the performance problem, but it fixes the correctness issue. It basically allows us to distinguish a one and a one prime and a two and a one prime, a two and a two prime. By having them just be completely different. They exist in like parallel universes. So the fact that something.
01:52:53.932 - 01:54:40.470, Speaker A: The fact that a one is in a pocket only affects a two and updates if they are upgrade responses for the same shard. And then the change we're going to do to handling rights is that a write has to look at all pockets for all of, for all values. Let me draw that, actually. So if you get an update like this guy, or this guy, or this guy, or this guy, then they are going to check pockets for all requesting shards for that key. And they're going to have to update anything that's in the pockets using the same rules that we had previously for unions. All right, so while you think about that, I'm going to go pee and they'll be there. It it.
01:54:40.470 - 01:56:22.360, Speaker A: Alright, what do we think of the solution? If you consider adding a phantom reference to the prior shard as a means of preventing this multi lookup, I don't see how that helps. Rolls got game that you're in the wrong channel. Yeah, exactly. So the observation here is that the performance problem is definitely a problem, but the correctness problem is a correctness problem and needs to be fixed first. And especially because this particular issue can come up in other contexts too. In essence, both a one plus a two and a one prime plus a two prime will flow downstream completely separately. Yeah, that's the idea.
01:56:22.360 - 01:57:34.148, Speaker A: Well, not quite. Yeah, the plus the union of them. So the union is going to completely separately handle a one plus a two and a one prime plus a two prime, where the primes are the ones that were requested by j two and the non primes are the ones that are requested by j one. If the tag includes the path of the upquery, couldn't a one, a two inspect the tag to see if the result is going to float to the same place downstream and that way throughout redundant queries. So the problem with that approach, the observation here is a one sees that it gets two up queries and a two sees that it gets two up queries. Why doesn't it just answer the first one? And the problem here is, when a one gets its first up query, how does it decide whether or not to wait? And if it decides to wait, how long does it wait for? That's the problem you run into. We could have it wait and then sort of deduplicate, but that gets complicated.
01:57:34.148 - 01:58:14.866, Speaker A: You basically need to introduce artificial latency for it to wait, and even then it could get wrong. And crucially, you could end up in a really bad place where for a one, the first upgrade response arrives and then like enough time passes that it decides to respond. And then the second one arrives and so it sends two responses, but at a two, the two upgrade requests arrive almost at the same time. So it only sends one response and deduplicates them. And now the union is going to get two a one s and one a two, which is going to be bad. The better way is to not emit two queries. I agree, but again, it does not solve the problem.
01:58:14.866 - 01:58:52.196, Speaker A: There are other graphs that do not have the upper explosion problem, but still have the root gets multiple queries for the same key problem. Basically what this is revealing is that the union pockets cannot just be per key. That is insufficient. Deciding on which queries you should response or not seems a lot harder. Yeah. The other thing that's nice here is that with this particular solution is that a one and a two do not know anything about this. If they get an upquee for a key, they respond to the up courier for that key.
01:58:52.196 - 01:59:43.980, Speaker A: That's all they do. And so that basically solves this particular problem. Or rather the receivers of the up query do not need to know anything about de duplication or looking for things that are the same or how many queries are going to get. They just get a query and respond to the query. And then we can tackle this problem of the upgrade explosion separately by doing research, which is like magic. All right, so now that we understand what the problem is, why not have j one and j two talk to each other to avoid sending duplicate queries? That's a great question. One problem with that is here I've drawn everything with two way sharding.
01:59:43.980 - 02:00:44.260, Speaker A: But if you have a particularly large system and you have a lot of load, you might have hundred way sharding. You really don't want a hundred nodes to have to coordinate to answer any up query, right? I mean, it could be that's part of the solution to solve the upgrade explosion problem, but it seems pretty costly. Right now you're going to run something like consensus between 100 nodes in order to satisfy one up query. At that point, the explosion might even be better because you don't need the coordination. It's not clear, but this is why I say this is just research separately and it's separate from the bug that we have to fix less complexity. Yep, this also has much less complexity to just change the union pocket bucketing. Basically, the union could eventually try to not send the same response downstream with this approach by sending the last one to everyone for a given time window.
02:00:44.260 - 02:01:42.600, Speaker A: That could also be, you're totally right that it could be that the union could eventually become smarter about this and be like, if I have, like I have two a's in pockets for the same tag in the same key but different requesting shards, and then I get like both the things that would fill the other pocket for both of them, then I can just send one and say that it should go to both or something. There might be some optimization we can make there later, but that is definitely an optimization and not something that's necessary. I totally agree with you that the observation is if you have 100 nodes, then 100 duplicate up queries basically like under squared is really bad. And I totally agree. The coordination would also be really sad. Like if you had to run paxos over 100 nodes for every off query. That's also really bad.
02:01:42.600 - 02:02:28.530, Speaker A: I actually have some ideas for how we might solve this that do not require coordination or of query explosion, but that's still very much in the research phases and like, not worth trying to dig through now because it's, it's mostly a lot of me like brainstorming rather than us trying to solve something, which is the plan for right now. All right, so let's finally, finally jump into some code. Oop, nope. Here's the code. All right, so welcome to the Noria codebase, Noria. Actually, let me give you an LS here. Let's remove all these guys because they're not important.
02:02:28.530 - 02:03:04.812, Speaker A: Let's remove some, like move some log files and stuff. Okay, so this is the root of the Noria repository. You'll see that there's a folder called applications, which is a bunch of different like benchmarks and stuff. I don't know whether still in Noria benchmarks, this should go away. So applications has like example, benchmark example applications and benchmarks. Like for example, the graph I showed you earlier of like article invoke. That's actually one of the Noria benchmarks.
02:03:04.812 - 02:03:32.720, Speaker A: Similarly, I mentioned that we have all the queries for the lobsters website, and we have the application for that is also in this directory. Then there's the orchestration folder, which contains things like being able to run all the Noria benchmarks distributed on EC two, that sort of stuff. The Noria benchmarks folder should have gone away. It shouldn't be there. Ignore it. And then there's Noria and server. So Noria is the client side of Noria.
02:03:32.720 - 02:04:19.188, Speaker A: It includes basically the API bindings similar to the MySQL client library or the postgres client library or whatever. It has all of the code necessary to interface with the Noria server. And then server has the implementation of all the server side stuff, which is the kind of stuff that we've been talking about now. That's where all of the data flow stuff works. All of the SQL to dataflow, translation stuff works, and all the other stuff for just like routing requests and migrating the data flow from one, from representing one set of SQL queries to a new set of SQL queries, that sort of stuff. All right, so let's go into server because that's where most of this will matter. So inside server we have a couple of different directories.
02:04:19.188 - 02:05:05.560, Speaker A: These are essentially subcraits because building Noria already takes a while and being able to not compile all of it each time turned out to be useful. Common mostly has shared traits and types. It's not that interesting. Dataflow contains all of the dataflow engine of Noria. So this is basically the stuff we've talked about so far in the stream. Mirror is the middle intermediate representation for Noria, which is what we call parsed SQL before it's turned into dataflow. So this is the layer that takes all your SQL queries, all the prepared statements we get from the user, parses them, and it produces basically a query graph that it then does optimizations on.
02:05:05.560 - 02:06:20.430, Speaker A: And mirror is the thing that does those optimizations at the sort of SQL operator layer and then produces the resulting data flow. And then source is the stuff that contains all the server side glue codes is like the HTTP server for handling controller requests, things like coordination between different Noria server instances, the thing that drives all of the futures that represent different Noria operators, and of course a bunch of tests. In this particular case, I'm going to bring us in to a file called payload. So payload includes most of the files. Let me make this a little bit bigger. So payload includes basically all the stuff that gets sent over the network, primarily things that get sent between different Noria instances and between different operators. The primary one about these is packet.
02:06:20.430 - 02:06:59.340, Speaker A: So packet is just an enum of the different packets you can send. I won't go through this in too much detail, but the ones that you need to be aware of are message. So message is a normal update. This is just so link here has the source and destination address, and data is basically just a vector of rows or deltas rather, and then replay piece. So a replay piece is a part of an upgrade replay. The reason it's called a piece is because as you know, sometimes they need to be assembled. There are some other reasons too, but those are out of scope here.
02:06:59.340 - 02:07:18.876, Speaker A: So you'll see that every replay piece also has a link. Right. It has a from and to address for the upgrade response. It has a tag. So this is the stuff I mentioned of. A tag is the way that we distinguish different upgrade paths that happen to intersect on an edge. Right.
02:07:18.876 - 02:07:58.940, Speaker A: You might imagine multiple upgrade paths where they happen to cross the same edge or the same operator, but they're not the same upgrade path. And so we need some way to tell them apart. So what a tag is and data is the delta contained in the replay. And then it also has this replay piece context. So replay piece context you can ignore. This regular case includes information about which keys this replay includes data for. So this is basically like CV equals seven, right? So it contains seven unishard, which is a field we're not going to be talking too much about.
02:07:58.940 - 02:08:35.786, Speaker A: But Unishard is basically what did this upgrade originally only go to one shard of the parent as opposed to the drawing we've looked at. Right. The upquery went to all the shards of the parent operator. So unishard would be set to false. Sometimes. If, if a, for example, was charted by v by CV, then only one of the ace would be queried and then Unishard would be set to true. And so you'll observe that a union only needs to buffer if unishard is false.
02:08:35.786 - 02:08:50.960, Speaker A: That is, it only needs to buffer if the up query. The original upgrade went to all the shards. So that's what Unishard is for. And ignore. You can ignore. Let's see if that. Yeah, great.
02:08:50.960 - 02:09:25.382, Speaker A: So that's most of the stuff that we need for this particular stuff. And now we're going to switch to union. Actually, let me pull up, I actually wrote a test for this because it's useful to have a failing test that we can try to fix. So this build just start snoriae in the testing context. It starts it with 16 shards. You can ignore the other parameters. And I have a documentation here which basically explains the stuff that I've explained so far in the drawing.
02:09:25.382 - 02:09:48.692, Speaker A: Right? So we're going to have a base X and a base Y. They're both sharded by a. We're going to have a join that's charted by some column b and a reader that's started by some column c. And it sort of talks about the problems that arise in this particular context. And then it sets up that graph. So this is not using the SQL interface to Noria. This is using like the low level data flow interface.
02:09:48.692 - 02:10:30.520, Speaker A: So we add a base table, base X that has just three columns because we're going to need three columns in order to shard by three different columns. So they're called base call, join call and reader call. And it's going to be have a primary key of the zero. So base call is going to be the primary key, which is going to make Noria Shard base X by the 0th column. So this basically sets C A, right. This is basically a, in our drawing, it's going to set CA to be this column and then we have some other base and that other base is sharded, but it's not really important. Then we have a join and the join is going to join the two base tables just like we saw.
02:10:30.520 - 02:11:02.650, Speaker A: It's going to be a left join between X and. Yeah, I right. So X here is on the left side rather than right side in the drawing. And it's going to join on the first column, zero indexed of x is going to be the join column, right. So it's going to end up being sharded by that column. So this is how we get a sharding of the join that's different than the sharding the base table. And finally, the reader, which is what we call a view node internally in Noria, is going to have lookups happen on the second column, zero index, which is going to be reader call.
02:11:02.650 - 02:11:44.484, Speaker A: And Noria is going to shard this view by the lookup column like we discussed. And so therefore this view is going to end up being sharded by the third column as well. What this produces is a graph that looks the same way as we had in the drawing, and it's going to have the same problem as what we talked about in the drawing. And then what the test does is it does a bunch of writes. It tries to make sure that the writes get spread across all of the shards of, of the base table and that the writes are going to hit every shard of the join and that. So you'll notice there are lots of different values of the first column, which is what the base is sharded by. So we should spread across all of those for the join column we use.
02:11:44.484 - 02:12:19.428, Speaker A: Actually, this could probably be, I as well, to be honest. Probably wouldn't have mattered. But this is going to be spreading over the number of shards in the sort of join column dimension. And then I make sure that the, there's only one value that appears in the column we're going to do lookups for. So if we do one lookup on key one, that's going to hit all of these records that we've inserted. So we basically end up with sort of a maximal upgrade, where really all of the shards have data for this single upgrade. And so this maximizes the, the chance, if you will, that we end up in this weird case.
02:12:19.428 - 02:12:57.970, Speaker A: And notice that it is a matter of probability, because the union might never detect that this happens. Right. It might be that the upgrade responses arrive so that we get like a one and then a. We get a one and then a two. And so the union goes, oh, I have both, and then sends it, and then we get a one prime and then we get a two prime, and the union goes, oh, I'm done, send it. So the union might never detect anything bad. But in order to try to make sure that that happens in this particular test, I basically have everything produced lots of rows, so that that is relatively unlikely.
02:12:57.970 - 02:13:33.690, Speaker A: And then we do a single read. And so this read is just going to do a lookup by the shared value that all the records have. And then it checks that the result is correct. And if I run this test, which tried this earlier, let's see if it still works. Nice. All right, so this crashed, perhaps unsurprisingly, and it says, not implemented detect chained union. This is an old word for this bug before we really understood what was causing it.
02:13:33.690 - 02:14:10.146, Speaker A: But if we look at the implementation of union, we see that that's a, this unimplemented over here. And if we look at, if we sort of squint at the code just above it, you see that really what it does is it looks at all the keys that the replay was for and that it has this like buffered. And if the buffered already contains an entry. So these are the pockets essentially, for this source, for this key. Then it goes, I don't know what to do. So basically it panics when it detects the case that we drew earlier, right? It receives an a one. And then it receives an a one prime.
02:14:10.146 - 02:14:42.840, Speaker A: That's when you're going to hit this unimplemented. That's this panic. And so this test indeed reproduces the problem that we had. And if we want to, we could sort of, I think I already have this somewhere, but let me copy it anyway. Let's do graph, dot, dot. And then we're going to do x dot, graph, dot. And see what that gives me, maybe.
02:14:42.840 - 02:15:09.420, Speaker A: Oh, there we go. Yeah. So here, this basically shows us what the graph layout is of the data flow. So you see the base y, which is the thing we join with. We have base x, which has these three columns. And it says, that it's sharded by the bay by base call 16 ways. This little full circle in the top right indicates that it's a full materialization egress.
02:15:09.420 - 02:15:32.674, Speaker A: You can basically ignore. It's sort of a sender node that lets you cross boundaries, ignore it, ingress, same thing. You can ignore them. And then, you see we have this shard merger. This is the icon I drew earlier, right? So this you say, see, it's desharted to avoid sharded shuffle. So I mentioned how we don't have sharded shuffles. So this, you see, is not like dashed.
02:15:32.674 - 02:16:02.390, Speaker A: This, this operator is not sharded. And then this is a sharder. So this is a shard merger. This is a sharder. And this shards by join column. And then that arrives at the join and the join joins on. You can, if you read this carefully, you'll see that this ends up joining on the join column, and you'll see that it is indeed sharded by the Join column itself.
02:16:02.390 - 02:16:34.920, Speaker A: And then at the bottom, we do another, like shard merger and then another sharding. And then we end up with the reader, the view at the bottom, which is charted by the reader column also 16 ways. And you see this is partial. That's what that little symbol indicates. And the same thing with the join. I'm not going to go into why the ingress is materialized, not to join. That's for a different time.
02:16:34.920 - 02:17:18.450, Speaker A: All right, so we have the graph we expect. And now let's look at what this, what this crash actually was. So this crashed said detected chained union at seven. All right, so what is seven? Seven is probably union op. Why is my mouse acting up? That's very annoying. Stop acting up, mouse. All right, so seven is this shard merger up here, right? So this shard merger up here is the one that detected that something was wrong, which is what we expected, right? Like this is the union in the drawing that also saw something being wrong.
02:17:18.450 - 02:18:22.218, Speaker A: And what did it see being wrong? It got something from shard three on key two. Right? So it got something from shard three of base x specifically for key two. So which key this is sort of doesn't matter, right? Oh, that's interesting. That might be a different thing we need to keep in mind, but yeah, this, this just tells us that the union observed the issue that we expected it to observe. Any questions about this graph or the problem we just ran into? Does replay mean up? Query response? Yes. Replay is the word we use for upgrade responses for relatively legacy reasons. Replay pieces on upgrade response.
02:18:22.218 - 02:18:40.222, Speaker A: Yeah. All right. Yeah. So I think this graph should not be terribly surprising. That's weird. Was it just xdot or is. Maybe the battery is running out of my mouse.
02:18:40.222 - 02:19:28.180, Speaker A: That'd be annoying. Let me plug this mouse in so that it doesn't die. Come now, mousey. There we go. Much better. Is there any particular reason why all the nodes are sharded 16 ways by default? So by default. By default, Noria doesn't actually shard like you specify when you run the thing.
02:19:28.180 - 02:20:22.466, Speaker A: When you run Noria, you specify what you. Why is this being difficult? The only reason. Whoa. What is happening to this window? Whoa. My buffer is just being all sorts of weird today. Huh? Um, if you look at the test, actually, you see that I set the number of shards, and the reason I set the number of shards pretty high for this particular test, or to 16, which is like, whether it's higher or not doesn't really matter, is because the bug is more likely to be detectable at the union if the number of shards is high because there are more up queries you need to wait for. So there's a higher chance you end up observing, uh, multiple upgraded responses for any given source.
02:20:22.466 - 02:20:45.030, Speaker A: Shard. I thought we're going to query key one. We did query key one, but the replay is for a different key. Right. Remember, the. The join has a different lookup key. So that's why what we're really seeing is the up queries for the keys that the join needs.
02:20:45.030 - 02:21:33.960, Speaker A: But you're right. That is the observation. I was like, that's weird. But I think that's the reason why. I think that's the reason why it could be that. It's a good question, actually, whether the key we use for the grouping of the pockets should be the up query key, which is going to be like, cv is seven. Or in our case, like one, which is what we're querying for, or whether it should be the key in the values that come back.
02:21:33.960 - 02:21:53.090, Speaker A: Oh, sorry. When it says key, what it means is columns. It's the key columns. It's printing. And the key column is two. So that's okay, great. That makes me feel better.
02:21:53.090 - 02:22:15.768, Speaker A: Everything is shifted by one line and not refreshed until exposed. Yeah, I think it's, um. It's a tmux bug. I think it's weird. Yeah. So the. The reason it showed two was because two is the key column.
02:22:15.768 - 02:22:46.500, Speaker A: The value is going to be one if we look at it. Okay, that makes me feel a lot better. And notice the little comment above here. Which is something I wrote way back in the day when I realized that this would be a problem, but didn't really know what the problem was or how to fix it. So I wrote we need to keep a queue of replays from each side, apply writes to all queued replays from that side, and then emit all front of queue replays in lockstep. So that was my proposal at the time, which is one of the ones we talked through. Right.
02:22:46.500 - 02:24:14.826, Speaker A: And this gets kind of weird, although you could imagine doing it this way maybe, but I don't, I'm not convinced it's any better than the solution we now came up with. Alright, so let's try this and see what happens. Okay, so the things that need to change here is that the union basically needs to have some way of knowing the tag, which is currently it doesn't know the tag either, and it needs to know the tag, but it also needs to know which, which Shard was the one that requested the upker in the first place. Right? So if we look back at the drawing, that's the information that we're proposing we keep here is the tag, which we have to add, and the requesting shard, which also needs to be included and is not currently something the union is told about. So we're going to go back to payload and what we need is this replay piece context currently doesn't really include enough information, I think, actually. So it includes the tag. Right.
02:24:14.826 - 02:25:00.730, Speaker A: The tag is up here, but we also needed to include like requesting shard. It's going to be a use size. In theory it could be an option use size, but I think I want it to be a use size probably. Yeah, I think I want it to be a use size. And then we're really just going to do like error driven development here. Compiler driven development. It could be a neo vim issue, although I've also seen the issue crop up in mutt.
02:25:00.730 - 02:25:48.074, Speaker A: It's hard to say. All right, so obviously now we're going to get a bunch of errors with, in places where we don't mention this field, right, which is sort of what we want. So node process 87. Okay, so this is the code that when a packet arrives at an operator, it needs to call a method on that operator basically. And this is the code that does that. So you'll see this is for node type internal, which are all the operators. You'll see there are a couple of like special node types like egress and readers and charters.
02:25:48.074 - 02:26:27.090, Speaker A: But most of the normal relational operators are internal. And here since I get tries to extract some information, it looks like it's turning a replace piece context into a replay context. I wonder why I did that. Well, that's fine. So really what we want then is to also have requesting shard to be communicated as part of whatever that translation is. That's probably going to give us some other issue up here. Yep.
02:26:27.090 - 02:27:24.180, Speaker A: So this is going to be also include that information, please. And we also actually want the replay context here to include the tag, which is not currently something that's included. So here we'll also want to include the tag, which hopefully it has somewhere. That's a good question. Does it have the tag replay piece tag? Because this is all the information that's provided to the union and the union needs to know the tag and the requesting shard unishard for unimportant reasons. The key column and keys. Alright, see what this gives us.
02:27:24.180 - 02:27:56.510, Speaker A: All right, so now we're back at the union, line 450. So this is also going to be requesting shard and the tag. Great. So now we have that information in the union. Let's see if that's actually enough, whether there are other things we need to pass. Okay, so domain mod line 1569. So domain mod is a part of Noria I haven't told you about yet, which is.
02:27:56.510 - 02:28:38.360, Speaker A: Well, there are many parts, but the way that Noria executes operator graphs and this actually warrants a new picture, although this would be a much simpler picture, actually. The way that Noria models these operator graphs is as follows. If you have a graph, let's go with I like blues. Let's do a nice little blue. I'm gonna draw circles because they're easier to draw. If you have a graph that has like all sorts of funky edges and stuff and things like maybe there's another guy over here, over here. And then there's like a thing and then there's some stuff.
02:28:38.360 - 02:29:12.760, Speaker A: And this has a thing maybe. And this has a thing. Right. So imagine that this is your data flow graph and it's abstract on purpose. Then I told you earlier that Noria only ever has one thread that operates on one node at a time, which is true, although Noria actually goes a little bit further than this and it uses something called thread domains. So the basic idea here is we're going to draw these sort of artificial boundaries. And how we draw them is something that I'm not going to talk about, but, well, I'm going to talk about a little bit.
02:29:12.760 - 02:30:00.162, Speaker A: So this is sort of a connected components diagram, except we subdivided more it's more like a Voronoi diagram. And the idea here is that all of the nodes in one pink circle will be handled by one thread. The reason this is advantageous is that it means that this channel, for example, does not need to be a channel. This is really just a function call because there's only one thread operating on this whole pink circle. And so when this thing produces an update, there's no reason to send it anywhere. We don't have to serialize this. We don't need synchronization of a channel.
02:30:00.162 - 02:30:41.052, Speaker A: We just do a function call that invokes this operator with whatever that update was and in some cases can save you a lot of work. So imagine you have something like a large chunk of updates or something. Having this sort of thread local operation can save you potentially a lot of work. And it avoids things like contention on channels. And it has many other benefits. It avoids a bunch of Mem copies and avoids cross core movement of data. So there varies, there are various reasons you want to do this, but you don't want these pink circles to be too large because of true large.
02:30:41.052 - 02:31:35.188, Speaker A: Then like all of the other cores on your system might sit idle because they have nothing to do. And then there's one thread, it's just like spinning on this because all the work is in one domain. So you want sort of a, you want to divide your data flow graph into domains, that's what we call these, so that you have enough domains, you can saturate all your cores, but as few domains as possible given that constraint. And so that is what, and so the extreme case of this, of course, is every node is in its own domain. That's not what Noria does, but you can imagine. So domain mod RS is really the code that handles all of the stuff that happens in one pink box. And if, if one pink box includes only one operator, then there's relatively less work that has to happen here.
02:31:35.188 - 02:32:25.920, Speaker A: But think of this as like, this is the thing that like accepts incoming connections, decide which node it's for, does the processing fills in missing state, handles requests from readers when there's like an upgrade request to it. It does all of, like the logic that is greater than that of a single operator. All of the, all of the stuff that has to do with talking to other nodes. Anything that's like intra node as opposed to internode operation. Yeah, it's basically divide and conquer on the resources. And there's a trade off here that's not immediately obvious for how you choose what this should be. All right.
02:32:25.920 - 02:33:24.722, Speaker A: So what this code is doing, domain mod is a pretty large file because it turns out there's a lot of internode stuff, like there's a lot of bookkeeping and logic that's needed there. And in particular, one of the things that domain mod does is it is the thing that it is the thing that sends out up queries in the first place. So here, for example, this is so seed all happens if a node in a domain is asked to respond to an up query, then it's going to look in its own state to see if it can. Right? So imagine that we've been asked to send someone the state for seven. We can only do that if we have the state for seven. So it looks up whether it has the state for the key that matters. And if that state is missing, then we need to send an upgrade to our ancestor to fill in the state that someone downstream of us asked for.
02:33:24.722 - 02:34:26.890, Speaker A: As that's what this case is here. So the tag is already there and here we need to set requesting shard. And what is requesting shard going to be? Well, requesting Shard here is actually pretty straightforward. It's just going to be self dot shard unwrap or zero. Right? So if we are uncharted, so that's the case where self shard is none, then it doesn't really matter what we say set requesting shard two, because the downs, if there is a union that has to do this buffering, it's basically going to ignore our. It doesn't matter whether the requesting shard information is included because it will only have one ancestor if we're not sharded. Basically, you won't, you won't ever run into this sort of shard merger case if we're not sharded.
02:34:26.890 - 02:35:06.900, Speaker A: Okay, what other cases are there? This is, what we're doing here is basically walking through all the places where we send up queries. This is 1688. What is this case? This is for relatively stupid reasons. This is basically the same thing. So this for requesting shard is also going to be self shard, unrep or zero. In fact, I think all of them will be. But let's see for sure.
02:35:06.900 - 02:35:51.378, Speaker A: There's actually, I'm going to give you a little bit of a spoiler here. This solution is insufficient because there are some cases where, imagine that J, the J's here are not materialized and so the up query goes all the way from v to a. Then it turns out the union needs to know some additional stuff. But we're just going to ignore that problem for now because this is still progress. 2309. This is if a. So this is in handler replay.
02:35:51.378 - 02:36:55.580, Speaker A: Alright, so this branch we hit, if this is when a domain receives an up query response, then it processes that, it passes it to some node, and then after the node is processed it needs to do some additional things. And here I think we can just ignore the requesting shard because it's not relevant. Again, there's a lot of code here that I'm just sort of glossing over and it's because Noria is big and complicated and it's nothing. It's not worth your time to go through it control plus to reclaim that lost line in the Vim command bottom. No, this is, it's actually a rendering bug in Neo vim. I mean, I could just resize my font and that might do it, but. Okay, great.
02:36:55.580 - 02:38:00.544, Speaker A: So now it compiles. That means in theory, we're passing requesting shard now in all the places that we need it. And this also means that at least in theory, I feel like there's something that's missing here. I feel like there's something that's missing because when you send an up query response, the requesting shard of the upker response should not be your sharding, but the sharding of the person who requested. So I think we actually did that wrong. Questing Shard. Yeah, I think actually what has to happen here is I know what's happening.
02:38:00.544 - 02:38:52.126, Speaker A: There's a different payload. So this is the forward path, right. This is the upper response, but the up query is what needs to be tagged with what the requesting shard is. So there's another packet type which is request partial replay. And this is the one that needs to have requesting shard because only the thing that sends the up query in the first place knows which shard it is. All right, so in other words, requesting shard, this is wrong and I this is wrong, so let's bring that back. All right, so 306, this is a request.
02:38:52.126 - 02:39:31.870, Speaker A: So this is one of the places where this should be self shard unwrap or zero. 409. This is a request, so that needs to include r one. This is a request, so that needs to include ours. And this is a request. Great. So now we make sure we send it everywhere.
02:39:31.870 - 02:40:07.530, Speaker A: No. 2434 and here. And now we need to make sure that the response gets tagged with requesting shard with the information. The response gets tagged with the information from the request. Right. So what's this going to look like? So this calls seed replay. So that's going to have to include questing shard.
02:40:07.530 - 02:40:56.080, Speaker A: Arguably this function should be rewritten now that it takes as many arguments. But we're not going to do that here. Crossing shard is going to be a use size here. And if this, okay, so this case is easy, right, because this is in the same function. So we know this sort of is, we got asked to do a replay and we're going to send the response straight away so we can just copy the information over the other case. I think it's going to be a little bit harder. I guess we're about to find out 1580 and so this is a little more complicated.
02:40:56.080 - 02:42:07.200, Speaker A: Not sure how we're going to do this. So Noria has this, Noria has this feature where if it gets an up query, it'll wait a little while before satisfying that up query because it assumes that there might be more up queries for the same, for different keys for the same tag and it would like to batch them together, which isn't really gonna work. So I think what this is gonna be is that maybe what we should actually do is change the meaning of tag. I think the tag here is actually gonna be, oh, we can do this. That's fine. Okay. So the question becomes how do we get requesting shard into this function? This means that when we batch up query requests, we have to batch them by tag and requesting shard, which is a little bit sad, but it should be fine.
02:42:07.200 - 02:42:50.500, Speaker A: So 1475, this does seed all and this does nasty stuff. Yeah. So here you see their buffered replay requests. These upqueeries used to be called replays and replay requests. That's why you see that in the code. Arguably we should just rename all of these to be, to match the upquery language. Why don't make requesting shard an option to avoid the unwrap? Or we could, it makes the data structure larger.
02:42:50.500 - 02:43:26.432, Speaker A: So this is a data structure that gets sent with like almost every packet. So keeping it small is nice. And making it an option would increase its size by a few bytes. That's the only reason really. I don't disagree with you that maybe it's better as an option. But given that it's totally fine to use the value zero if there are no shards or if the thing is not sharded, I don't think it's worth it. Yeah.
02:43:26.432 - 02:44:06.138, Speaker A: So I think here what we need is this. Elapsed replays really needs to include questing shard. So I guess here we put that after the tag. So questing shard. Alright, so elapsed replays. Yeah. So buffered replay request is currently essentially a hashmap from tag to the batch we're collecting.
02:44:06.138 - 02:44:58.016, Speaker A: And I think the key will actually need to be a tuple of tag and requesting shard so we don't accidentally collapse requests that are from different requesting shards but along the same tag. Which means that the place where we push to buffered replay requests. Buffered replay. Actually, you can just do this. So that's going to be from tag and usize. And where do we push to it? Entry. This is going to be an entry of tag and requesting shard, which hopefully we have access to in this context.
02:44:58.016 - 02:45:14.060, Speaker A: We do. Great. Let's see what that does. Great. So now we actually have the wiring, correct? Oh, yeah. YouTube is way worse than twitch. It has longer latency and worse quality.
02:45:14.060 - 02:45:42.720, Speaker A: Can you make it an option? Non zero? No, because it's not non zero. Shard. Zero. If you have two shards, the shards are zero and one. In theory, we can make everything be one indexed, but that would probably break things all over the place. So it's not really worth doing, really. What I want is like a non Max U 64 because you're.
02:45:42.720 - 02:46:11.860, Speaker A: It has the same. It serves the same purpose where the max value can serve as none. But until we get. There's like a proposal, I think for a trait that's going to be like constantly, it's like a const. Known unused value trait, which you could have like a wrapper type that's non max size, for example. But without that, I think we're just gonna leave it in theory. We now have all the wiring we need.
02:46:11.860 - 02:46:54.466, Speaker A: So now the question becomes, what does the union do? And I think what we need is for the union. Let's see here. Replay pieces. Yeah, it's awkward. Um, there are a couple of reasons why this is awkward, but basically this has to be keyed by tag, usize, and the key. And the key is a vector. We have far too many vec data types.
02:46:54.466 - 02:47:27.090, Speaker A: It's a little unfortunate, but it's because, um, you could imagine that the key is a compound key. Like, the thing is sharded by or keyed by multiple columns rather than just one column. A data type is our enum of primitive data type in the system. So this is things like, it's basically an enum of like int and string and float and stuff. And so if you go back to the drawing, right. We needed the key to be tag and requesting shard and key, rather than just key. It used to be just key.
02:47:27.090 - 02:48:14.490, Speaker A: And now it's tag requesting shard and key. And now I guess replay pieces. It's going to be a bit of a pain because this, the key here is going to be that. Does this even know the tag? Oh man, actually. Okay, so you'll see that. So on input raw is a thing the union implements that tells it about the replay context of the updates. You'll remember that I told you that operators don't generally know that something is a replay.
02:48:14.490 - 02:48:40.634, Speaker A: All they know is that something is a normal update and that's all they know how to process. So there's an on input function, that's what most of them implement. And on input you'll notice has nothing about replays. It doesn't know whether it's a replay or not. And unions are a little special because they need to do this buffering. So they get to implement on input raw, which also gets information about whether it's a replay and if so, what type of replay. And you'll see that we match on that.
02:48:40.634 - 02:49:58.540, Speaker A: And in the case where the replay context is none, so it's a regular update, then we don't have a tag, we don't have a requesting thing. And so here you'll notice that it actually has to do this is where it does the lookup for whether there are replays in any pockets related to the update. And so this we're definitely going to have to update because this is going to have to check all of the pockets for that key. Which makes me think that replay pieces is actually going to have to change a little bit. It's going to have to be not this, but vec data type to a hashmap from this two replay pieces because we need an efficient way to, at which point this should really just be a b tree map, to be honest. We need an efficient way to find, to find all of the tag usize pairs for which this key needs to be updated. I think that ends up being right.
02:49:58.540 - 02:50:59.150, Speaker A: It's going to be a little bit awkward. This patch probably needs a little bit more infrastructure. Yeah. The reason to switch to a b tree map here is because tuples are ordered by the parts of the tuple. So you can do something like I want to do a range lookup on everything. Where the key is equal to this and these have any value is an efficient query you can do against the b tree map as opposed to having a hashmap where the values are hash maps, a nested hash map. Why is the hash table key vec data type of the key and not the key itself? Wouldn't it lead to bugs from different keys of the same type? Yeah, so that's basically what I'm observing here, that that really, this should be like.
02:50:59.150 - 02:51:47.020, Speaker A: Yeah, it's kind of awkward because I think actually what value you look up into here by depends on the tag. So to backtrack a little bit, unions are actually broken in a bunch of different ways. And one of them is the thing that we're looking at now, which is unions basically assume that there's only ever one replay path through them. And that's why it could get away with this. Right? Where if there were two replay paths, it would just crash. It would not work correctly. But if there's only one replay path, then there's only one set of columns, and therefore you're fine.
02:51:47.020 - 02:52:46.300, Speaker A: This will never have a mismatch. And now that we're introducing this notion of there might be multiple, then this gets iffy. So really, if we wanted to stick with what, with the assumption that unions already have, which is basically there's only one tag through me. In fact, let's do that for now. And then we're going to have a to do, these need to be per tag. What's the advantage of BT map over hash map? The advantage of B tree map here is actually for allocation. It means that rather having, if the corresponding hash map type we would need would be hash map from this to hashmap from this to that.
02:52:46.300 - 02:53:25.390, Speaker A: This would mean that you have lots of small hashmaps as opposed to just one big B tree map. So this is more allocations, basically. It's not quite true that the logic is this straightforward, and it could even be that the hash maps end up performing better. But this is sort of a little bit nicer in terms of the storage. The B tree map will also guarantee that these are relatively close to each other. Like all the different requesting shards for the same key will be in sequence, which might be nice. It may not end up making a difference.
02:53:25.390 - 02:54:15.054, Speaker A: Yeah, so notice that we're basically here ignoring the tag for now, which is we're continuing with the implicit assumption that unions already had, that it was only ever unioning, that the replay paths were only ever over one set of columns. This is not true in practice, but there's no reason for us to fix that in addition to the bug at this time. Okay, so now let's make this be default. Default rather than what it was, in case we change it later. That can still be Lin. That's fine. That could still be whatever it was.
02:54:15.054 - 02:55:23.470, Speaker A: Okay, so here, let's get back to this one because this is the case for updates which are a little more complicated and then the other replay pieces. That's fine. This can actually be a mem take which exists now. Replay temp is mem take which I implemented. All right, what else do we have? So mem take just is a mem replace with an implementation of default. So this is still going to key by the key, but then in addition it needs to key. Bye.
02:55:23.470 - 02:56:18.220, Speaker A: Right. So this is a b tree map now. So the entry here is actually going to be key and requesting shard. And now in theory this should never be entered. So this is got two up query responses for the same key for the same downstream shard. What? Great. So this is going to be something like downstream shard issued duplicate up about to.
02:56:18.220 - 02:57:16.670, Speaker A: How do we want to phrase this? Downstream shard, double requested key. And then it's going to include some information like the node, the source and the key columns. That's fine in theory. I think that should be all we need for this part. This can now do. I think this can now be a replacement. What is this business on eviction? Oh, eviction is going to be all sorts of annoying.
02:57:16.670 - 02:58:30.700, Speaker A: So here I really don't want to do eviction. So this is where the, if we had a hashmap, then we would have to like iterate over all the things under that key. And since we have a b tree map, what we can do is actually, we might not be able to do this, but I think what we're gonna end up doing is like this to key use size, max value, I guess dot equals. And then this is going to be, we're gonna have to do something silly like collections. B tree map, range bound, what's it called? I'm gonna, the screen is gonna become bright. No, b tree map. See, we got here range bounds.
02:58:30.700 - 02:59:02.722, Speaker A: Oh, I see. That's fine. Yeah. So this is just going to be, instead of get mute, it's going to be rangemute. Right. So this is then going to hit all of the different requesting shards for that key. And so this is where the b tree map comes in handy.
02:59:02.722 - 02:59:44.564, Speaker A: Although you could do the same with a hash map because here when, when a given key needs to be evicted, we need to evict all of the, all of the buffered pockets. I'm not going to talk too much about it because it's complicated. Yeah. And then we only have the update case left. And here actually is gonna, it's gonna kill me. Tuples get awkward here. It's gonna be like let Key is this and this is also gonna be a range mute.
02:59:44.564 - 03:00:46.050, Speaker A: And this is not going to be an if let. This is going to be a four pieces in and this is going to be from key zero to key use max value because here too. So this is, this is the case where we get an update and we need to check all of the pockets, right. So in this case, because we're going to have a distinct, we're going to have a distinct pocket. We're going to have sort of a version of this pocket for J one and we're also going to have a version of this pocket for j two. And when an update comes in, it needs to update the buffered up query response for both the shards. Right.
03:00:46.050 - 03:01:23.070, Speaker A: So it's going to look up by its key and then it needs to update all of them. And that is what we're making this code do. It used to just look up is there anything buffered for this key from the source? And now it's going to not do that anymore. And sadly, for reasons I don't want to fix right now, it means we're gonna have to clone the key and it might have to stay that way. This probably. Oh man, this else can go away. Let's see what this does.
03:01:23.070 - 03:01:51.200, Speaker A: 626. Right. So this is going to be the same for e in this. It doesn't have an else. It's great. 630. No field buffered.
03:01:51.200 - 03:02:49.354, Speaker A: Did I change what the value was here? I did not think so. Alright, I've made some silly mistake. If there's only one replay path at a time, why do we need map at all? Wouldn't it contain like one key all the time? No, the reason it might contain multiple keys is imagine that one shard queries for like key seven and one shard and the same shard later queries for key eight. The two of them need to have separate pockets, those two upper responses. Right. So we actually do need to have potentially multiple things that are being buffered. Oh, I see why this is.
03:02:49.354 - 03:03:45.070, Speaker A: It's because this also gives us the key which we don't care about. And similarly for the other place, which was like five, three, four down here somewhere. Or I guess six, two eight. BT map range. Mute is nice to us and also gives us the key, but we don't actually care which key we're looking at. Ooh, won't let me do that, huh? This makes me so sad. But it's for stupid reasons.
03:03:45.070 - 03:05:05.530, Speaker A: Here, this probably needs to talk about the value is my guess. So with b tree map when you use entry screen is going to come bright again. Entry so what do you get? If you have an entry here and you have an occupied entry, then there's key should just be get this expression has type entry that expected entry found hashmap entry ah yes, that is true. This is now a b tree map entry and it's true, the tag is unused. Alright, so let's now, in theory, we now have the fix, right? It now buffers based on the requesting shard as well. Let's try. I have no idea whether this is going to work, so let's try to run it.
03:05:05.530 - 03:06:11.250, Speaker A: Well, compile it first. It's pretty close to 3 hours. Let's see if the live streaming gods are satisfied with us. Come on. Fixes. Well, it didn't crash, but it's also not finishing. Let's do a quick look see here and see.
03:06:11.250 - 03:07:11.470, Speaker A: See what it's up to. My guess is this is going to be a another long, fun debugging experience that I'm not going to do on stream. Yeah, see that's what I was worried about. Yeah, yeah. So basically what this indicates is that the upquery response never arrives at the view. It's like the view does a read for one which starts an upquery and then the read for one just sort of sits there. It's waiting for the upcury response to arrive before it can answer to the client.
03:07:11.470 - 03:07:55.368, Speaker A: And if that upker response never arrives, then the client's read never completes. This indicates that we are somewhere like that. Basically the buffering never ends, we never release the up query. There might be a bunch of reasons for this. It might be that it's the second shard merger that gets stuck, but this is basically something I have to dig into. But I do think that this is certainly progress. Right? It no longer crashes where it used to, so I think we're actually going to end the stream there, even though it's a sort of weird point where it's not fixed.
03:07:55.368 - 03:09:08.270, Speaker A: But at least I think we've now explained what the bug is talked through, why this is a solution, and then implemented the solution mostly given the constraints we had. And now it's sort of debugging the solution and figuring out what the next steps are, including things like making unions aware of tags. And so I think this should give you a decent sort of overview of the internals of Nori, at least the ones we've talked about today. And also the ways in which, the kind of ways in which doing work on this kind of code base works. You've sort of gotten a shortcut where I know what the problem is and I know what the fix is. And this is usually not the case, but yeah, conduit blocked is basically what happens, like in the async await world or just in general when you have like, this is a problem where something is just buffered forever, and then the way that problem manifests is everything is stuck. Waiting like it's a deadlock.
03:09:08.270 - 03:09:41.564, Speaker A: And debugging them means figuring out why things are stuck. It's not terribly surprising. So I hope that was useful. Hopefully this stream was, even though it's very technical and we sort of dove in pretty deep in a large code base and a complicated one, hopefully it was at least possible to follow. As usual. I'll upload this to YouTube afterwards and that way you can watch it at your own pace and sort of rewind and stuff. If there are any sort of closing questions, then I'm happy to take them now and then.
03:09:41.564 - 03:10:11.880, Speaker A: Whether we do another Noria stream, I don't know yet. It sort of depends on the response to this one and whether another good problem comes up. So this particular bug is one where I thought I might be able to explain it and go through it and fix it in like 3 hours. Most problems in research are not like this. This is sort of an outlier. So if something comes up, then I might. I see someone is also.
03:10:11.880 - 03:11:01.660, Speaker A: Someone is also asking whether I can do another stream to demo the fix after the fix has landed. I might do that. What I might do is when I land the complete fix, I will tweet out a link to the commit. That might be what I end up doing. You are lacking a lot of infrastructure in order to implement this fix properly during the stream. Yeah, I mean, if I were to fix this properly, like, first of all, I wouldn't spend two and a half hours explaining what the bug was and how to fix it. So that would shave some time off, but also we would have some time to, like, I would introduce a lot, probably more like debugging info and stuff, with the expectation that this is where we're gonna end up.
03:11:01.660 - 03:11:20.530, Speaker A: Problems usually lead to more problems. You're not wrong. It's like an endless chain of debugging. All right, if there aren't any more questions, I think we're going to end it there. It's like a solid, what, 3 hours and 15? It's pretty good, I think. I'm happy with that. Hopefully you found it interesting.
03:11:20.530 - 03:11:39.640, Speaker A: Hopefully this sort of short insight into Noria was the kind of thing you had in mind when you were all asking for me to do a stream on Noria. And maybe we'll do it again. I will see you all later. Remember to wash your hands. Remember to stay apart sadly. And then when we get through this, there'll be more streams. I don't know when, but there will be.
03:11:39.640 - 03:11:44.740, Speaker A: So long. Farewell. Good night, everyone. We will see you next stream and.

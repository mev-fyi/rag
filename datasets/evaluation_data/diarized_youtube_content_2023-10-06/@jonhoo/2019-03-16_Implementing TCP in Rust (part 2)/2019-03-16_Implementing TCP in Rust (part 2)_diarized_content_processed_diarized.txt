00:00:01.080 - 00:00:50.275, Speaker A: Hello, welcome back. It's time for another one of our TCP streams. In the last Twitch stream, what we did was we started implementing a user space TCP stack. Not really for performance reasons or anything, even though that is often why people do that, but more because we figured it would be interesting to implement a lower level protocol, look at technical specs and protocol definitions. So we were basically implementing RFC 793, which is the TCP RFC and various other related RFCs. We're doing that using tontap interfaces. So tontap interfaces are basically a way to have the kernel give a user space, process access to RAW packets.
00:00:50.275 - 00:01:25.125, Speaker A: And so this lets us interact with our implementation as though it was running in sort of its own kernel somewhere. I'm not going to reiterate all of the stuff from the first stream in this one, so I sort of assume that. I sort of assume that we. That you've watched part one before this one. So I'm going to put a link somewhere to part one. So you should go watch that if you haven't already. This video will also be uploaded to YouTube as always, so you can always watch this later.
00:01:25.125 - 00:01:56.245, Speaker A: Before we get started on sort of continue our implementation, there are a couple of housekeeping things I want to deal with. So the first one is that this will probably be the last stream for a little while. I have a pretty major deadline coming up towards the end of April, so next stream probably won't be until May. It's a little unfortunate, but sadly life gets in the way. The really. They inject ads into the stream. That's awful.
00:01:56.245 - 00:02:40.427, Speaker A: And number two, I feel like we've been running this for long enough now that it seems appropriate that we try to find a name for this thing. It's sort of easier to just call it Rust Live coding streams. We do some other stuff too, like the video on the how and why of Futures, for example. And I think it would be good to have some umbrella term for what this stream is. So I'm gonna. I'm gonna sort of give a yak shaving project to the chat over the course of the stream to try to figure out a good name for what the stream should be referred to as. I might even go as far as sort of to create a separate Twitter account or something that you could follow just for updates from the stream.
00:02:40.427 - 00:03:44.263, Speaker A: We'll see exactly how that works out. But some kind of name would be useful. And there's a third thing that's kind of stupid. I decided to buy new wheels for my chair And I discovered that my floor is not level. So every now and again I'll just sort of roll away. And so if you see me moving weirdly, then that's why. Okay, so with that housekeeping out of the way, are there any questions from the first stream before we get started on this? Anything that was unclear that you sort of want to know how works? Just so we all start out without having burning questions from the very beginning, I'll give chat a little while just to see if there's anything you want to recap before we start chat.
00:03:44.263 - 00:04:51.243, Speaker A: Currently seems mostly busy talking about how to avoid ads on Twitch, so I'm going to assume that there are no particularly burning questions that people have. And if you do, then just sort of ping me as we go. Okay, so where we ended last time was we wrote this thing called Trust Name, still under development, and we basically just wrote a main function that runs the core TCP protocol. So main will basically just read packets in from the virtual interface that we create. So it creates a virtual interface, it reads packets in from it and sort of keeps track of various connection state and then calls into the TCP implementation. We have the TCP stack for the state that we're currently at. It gives the packet that it received and that's basically all we have so far for the TCP stack.
00:04:51.243 - 00:05:38.757, Speaker A: We have support for setting up and tearing down the connection, but we do not have any support for data yet. I still vote for Thunder as the name. Thunder is pretty cool. I agree. Yeah, so we have support basically for establishing and then tearing down a connection, but nothing in between. The other thing that's actually worth pointing out is following the previous stream, there were a bunch of comments on. On the YouTube, on the YouTube video for the first part where someone pointed out that actually when the RFC talks about sequence numbers being between two different things, there's a well defined way in which that operation works.
00:05:38.757 - 00:06:24.767, Speaker A: And specifically instead of this whole business that we computed and drew out, it turns out what you're actually supposed to do is just check whether one minus the other is more than half of the number space. And this is sort of apparently so well understood that it's not even in the rfc, which is kind of stupid, but such is life. So this has been changed to me. Oh, so that has now been fixed. So if you look at the is between now, it is actually a lot easier, a lot simpler than it was before. Yeah. For RAW packages I would.
00:06:24.767 - 00:07:06.177, Speaker A: If you're wondering how to do that, I would watch the first stream first. Okay. So the question is where we go with this particular stream. This might be a little bit shorter than the normal streams, but we'll see how that works out. I think what we're going to do in this one is the next thing we need to support is being able to send and receive data, because currently all you can do is set up the connection and tear it down, which isn't particularly helpful. So I think we actually need to set up what is effectively an API for being able to send things and receive packets. And we're probably going to model it mostly on what is in the standard library already.
00:07:06.177 - 00:07:43.675, Speaker A: So we're going to end up with something sort of like standard. Net TCP stream and standard. Net tcplistener instead of this. Currently we just have this main function which doesn't really have a good way for you to read or write data. And so how about we just get started with that? I think we're going to start a new file here, something like, let's call it Libraries for now. Have you tried bpf? BPF is not really for this particular thing. There are rust bindings for bpf, I think.
00:07:43.675 - 00:08:22.165, Speaker A: Okay, so we sort of want something along the lines of TCP stream and we want something along the lines of TCP listener. Right. This is the types of the TCP that TCP provides us, the standard library TCP implementation provides us with. And ideally we want to support the standard interfaces as much as we can. So specifically we sort of want to do impl. Read for TCP stream. We want to implement write for TCP stream.
00:08:22.165 - 00:09:10.465, Speaker A: And on tcplistener we want something like a pub. I guess these are going to be published. We want something like an accept that takes a mute self and returns a TCP stream, probably an ioresult TCP stream. So like something along these lines and of course, read just to get the signature for read. Read. Is this so this is an ioresult and. Right.
00:09:10.465 - 00:10:07.425, Speaker A: Is this so, Right. We're going to need something along these lines. So I think our goal for today is basically to find a way to fill out these. Now, we might not actually be able to get read and write to fully work because that's a bunch of internal protocol stuff like congestion control, but we at least want to figure out how to wire this interface into the implementation we already have. If you remember from last time, a listener, a TCP listener doesn't really do all that much, except that actually I should put up my paint program here. Let's see here. So let's do somewhere around, like Here.
00:10:07.425 - 00:10:52.555, Speaker A: So if you recall, the way TCP works is you have sort of a client and a server, although TCP doesn't really call them this, but you sort of have a client and a server. Think of the server as the thing that is listening. And the way the TCP handshake works is the client or whoever wants to connect sends a SIN packet. So this is a TCP packet with the, with the SIN bit set. Let me check that. I agree. And the server, if they're willing to accept the connection, responds with what's known as a SYN acknowledge.
00:10:52.555 - 00:11:23.597, Speaker A: So this is a packet that has both the SYN flag and the ACK flag set. And the way to interpret this is that this ack, this ack is for this sin, and then the client is going to send back an ack, and this ACK is for this sin. So this is saying I got your sin and I'm. I want to connect back to you. And this ACK is for the sin. So this, this is known as the three way. See if I can do.
00:11:23.597 - 00:12:08.261, Speaker A: I don't know if that's easier to read. Probably not the three way handshake in tcp. And what it does is it establishes a two way connection, right? So think of a SIN as I want to talk to you, right? And this ACK is saying okay, and I want to talk to you, okay? As sort of the way to read the sequence of events. And if you are listening on a given port, all that really means is you're willing to send this message. So if the server is not listening on a port, it's just not going to reply to the sin. It could respond with like a reset to just directly say that it's not responding, or it could just not respond at all. They're both sort of fine.
00:12:08.261 - 00:12:47.901, Speaker A: TCP might mandate which one you're supposed to do. And currently what we have our system set up to do is anytime anyone connects to any port, we're going to SYN ACK and set up a connection with them. Whereas in reality what we really want is only if the server has created a TCP listener. Wow, my handwriting on this is terrible. It's terrible otherwise too. But if we've created a TCP listener on like port 80, for example, then if this packet is for port 80, then and only then do we send the SYNACK back. If the SIN comes from some other port like 9,000, right.
00:12:47.901 - 00:13:16.715, Speaker A: If it comes from 9,000 and there is no TCP listener, then we will not respond. There's no reason to, because we don't want to. We haven't said that we want to accept packets on that port. Yeah, I mean, Chad basically just demonstrated how the TCP handshake works. Want to shake hands? Yes. Puts arm up, shakes hand. It's like a very, it's a very sort of weird human protocol if you were to try to act it out.
00:13:16.715 - 00:13:49.361, Speaker A: Okay, so, so what this means is that our TCP listener, all it's really doing is almost like marking a. Marking a port number as being available. And so if a packet comes in from a port that is not marked as available, we drop it. If it is marked as available, then we sort of enter the whole TCP event loop for that channel. And so the TCP listener actually does pre. Not that. Not doesn't do all that much.
00:13:49.361 - 00:14:47.765, Speaker A: The TCP stream on the other hand, is basically the thing that contains all of the state associated with this connection. So once this synac business has been set up, there's a bunch of state you're keeping like sequence numbers and act numbers and window sizes and all of this business, all of that from both sides is going to be incorporated into the TCP stream. So that's basically what we want. And so let's see how that would actually look in code. So if you remember from our main, we have this connections map that is a map from. That is a map from a quad. So a quad identifies a particular connection to a TCP connection.
00:14:47.765 - 00:16:23.845, Speaker A: And if you look down here, what we did down here was if the entry is vacant, so if we get a, if we get a TCP packet for, for a quad that we don't know about, then we just immediately call Accept. We sort of want to change this, right? Like we want to change this to be if it's vacant. So if there's no current connection, and we've said that we're willing to create a connection and so we're probably going to want most of this. The other thing that's a little weird here is the tunnel we have is basically single threaded, right? Whereas we sort of want the user to be able to create multiple different connections all over the place. And so we might need to have this be almost like, almost like a sort of a main event loop that runs on one thread and all of the TCP listeners and streams are going to interact with that thread. That might end up costing us a little bit in terms of performance, but it might be a good way to model the system, at least initially. So for that to work, what we will probably need is we'll need something like A pub struct, endpoint or endpoint might be a bad name for this, but interface maybe or network, let's call it interface for now.
00:16:23.845 - 00:17:09.525, Speaker A: So the idea would be that an interface is a thing that can receive packets and it sort of holds all the connection state information for all the currently open connections. And so if you want a TCP listener, you have to call listen on the interface and that will give you the corresponding TCP listener object. And so the way to think about this is something along the lines of this. That's also a good question. What the types of these are. Actually, let's not put those in just yet. So we're going to have something like impld probably default for interface.
00:17:09.525 - 00:18:07.605, Speaker A: And what that is going to do is this and then create an interface that has connections Nick and Buff. So maybe. Ooh. Actually we need cargo tunnel. We need to declare that we also have a library trust and we also have a bin. I don't know how cargo is going to feel about this. Binary name is going to also be trust.
00:18:07.605 - 00:18:52.095, Speaker A: Let's see if it actually lets me do this. Oh sure. These are for the time being, unimplemented. Aha. And of course these fields need to exist in the first place. So connections we know is going to be one of these. So connections is going to be a default.
00:18:52.095 - 00:19:19.457, Speaker A: Default. I don't actually remember the type for this. So this is a neat little trick that you can play. Oh, actually this I do know the type of. This is a UA 1504. So in this case I don't actually know what the 0u8 1504 I don't actually know what the type of nick here is. And so I'm sort of gonna cheat.
00:19:19.457 - 00:19:51.459, Speaker A: I'm gonna cheat by. Actually this has to be a new. Can't be that. Because we have to be able to return an error. This is going to be an IO results and so this is going to be an. Okay, so the trick here is I don't actually know the type that without packet info returns I could look it up. But instead what I'm going to do is to set the type to be unit and then try to compile and then it's going to tell me this is the type I actually had.
00:19:51.459 - 00:20:25.837, Speaker A: Great. So now we can just replace this with that. Hole driven development. Yeah, basically. Okay, so you create a new interface and what that's going to do is it's going to create that tontap interface for you and it's going to set up all the sort of buffers we need and basically empty connection state. And then I guess this is going to have to be pub. And then we're going to have a pub FN Listen.
00:20:25.837 - 00:21:02.583, Speaker A: So this is basically the same as so TCP listener. You can just call new or bind, I guess, and it sort of implicitly does the right thing. Whereas for us, we're going to have. We're also going to have a bind. But it's just. It's going to take a mute self and a port which is going to be a U16, and it's going to give you back a TCP listener. And we don't actually know what this is going to be yet, but we sort of know that it's going to do something.
00:21:02.583 - 00:21:34.077, Speaker A: That means that now we're going to start answering sins on this port. Right, great. And there are some other things that might carry over from main. In fact, most of this loop is going to still remain here. So you might already see where this gets tricky. Right. When you get a TCP listener, that TCP listener is going to have to do things like interact with the nick.
00:21:34.077 - 00:22:23.550, Speaker A: Right? The nick is where you read packets from or where you write packets to. But if we stuck this mute self, which is a mutable reference to the nic, into the TCP listener, that would mean that you could only have one TCP listener open at any given point in time, which seems kind of problematic. There are a couple of ways we can get around this. One of them would be that we just store like an ARC mutex interface inside everything we give out and then they just sort of multiplex between them. That's also not great, though, because it would mean that. Imagine you have two TCP streams on the same NIC and they both try to take the mutex on interface. And then imagine you have TCP Stream 1 and TCP Stream 2.
00:22:23.550 - 00:22:57.525, Speaker A: TCP Stream 1 gets the mutex and reads a packet. But that packet is for TCP Stream 2. It wouldn't have a way to tell the other stream, oh, I found a packet for you. Right. It just has to read until it gets its own packet. And so we need to find a way to get around that particular issue. One way we might do that is to have the TCP streams really just be like almost channels to some central thread.
00:22:57.525 - 00:24:16.587, Speaker A: It's a little sad because it means that we basically have to copy all the bytes. Like if you write out these bytes, we're actually going to have to copy them into a vector somewhere and then send them off to this other thread, which isn't exactly great. Yeah, I don't have a good answer there. I think one way to do this would be if you want to write, you take the mutex and you call into the event loop until the stuff that you want to write has been written. But that has its own set of problems. Okay, let's go with the channel approach for now and then we can try to figure out if we can optimize this somehow somewhere in the future. So what that means is when you call new, what we're really going to do is we're going to spin up a thread that's going to run in the background and manage all the packet stuff, and then we're just going to return a handle to that.
00:24:16.587 - 00:25:37.255, Speaker A: So here, instead of just having interface, we're going to have like actually that. I sort of want the public struct to be called interface. But all this is really going to contain is a sync MPSC something. Right. So this is going to be just an NPSC sender. Yeah, we're going to run into a sort of weird pattern here where this is actually going to be here enum interface requests, and that is either going to be a write, in which case it's a VEC8, or it's going to be a read, which is then going to include a sender of evacuate and I guess flush here as well. And I wonder whether all of these.
00:25:37.255 - 00:26:45.475, Speaker A: Yeah, so the trick is, imagine that the idea here is basically if you try to write on a TCP stream, what you're really going to do is you're going to send a write message over the channel to the thread that actually runs the interface. And then it's going to do like, it's going to keep running its event loop and at some point it decides that your write is done, but at that point it has to communicate the return value of that right back to you. I mean, that is really awkward. We sort of don't really want that to be how it works because what that would imply is that the writer, if you do a write call, you also include like a channel that the server is going to respond to you on. Because we could do that. It just, it feels a little awkward. Hmm.
00:26:45.475 - 00:27:26.093, Speaker A: The other reason this is unfortunate is just like it adds a lot of overhead to reads and rights. And I feel like we could do better, but let's stick with it for now and then we can always improve it later. So all of these are going to have channel to sort of. Actually this is going to be a usize. So this is going to be how Many bytes were written. This is going to return all the bytes read. And in fact this is also going to have to include a usize, which is the capacity of the buffer so that we don't try to read more bytes than we can.
00:27:26.093 - 00:27:54.587, Speaker A: And it's going to send back at most that many bytes. Okay, so interface then is really just a thing that can send those requests to the interface main event loop. And this I guess is going to be. What are we going to call this? Not going to be public. It's going to be the connection manager. Yeah. And so at that point the C we're gonna.
00:27:54.587 - 00:28:44.115, Speaker A: When you do new, we're gonna create one of these connection managers. Then we're gonna do a thread spawn. I guess we're gonna do a. We're gonna create a send and a receive handle for an N. We're going to move the receiving end into that thread and that's going to be CM run on rx. And I guess we can keep track of the join handle for when we drop at the end. And then this is going to return then an interface.
00:28:44.115 - 00:29:25.445, Speaker A: Let's make this a little nicer for ourselves. That has a transmit handle for where you send the requests and also a join handle that's going to let you. That's going to let you join with the connection manager when you want it to exit at the end. It's going to be a join handle. And I don't know what that type is yet, so it's going to be a hole. So this now is going to have rx, TX and join handle. Does the basic pattern here make sense? Like the rough setup for what we're trying to do? And I guess we have to do bind as well.
00:29:25.445 - 00:30:03.915, Speaker A: Bind does also have to be unbind and bind is also going to have to take one of these and a port. So I guess we can make these a little bit more helpful for ourselves. Specifically, a write is going to be. This is going to be the bytes and this is going to be the ACK channel. So this is not a TCP ack, but like a. An ack in the sense of I have completed your. Right.
00:30:03.915 - 00:30:29.839, Speaker A: A flush just has an ack field bind as a port in an ack unbind. So unbind is what we have to do when you drop a TCP listener. Right. When you drop a TCP listener, we have to make sure that we're no longer bound to that port. But there we don't actually have to wait for the unbind to finish. We can probably Just unbind asynchronously. That's not.
00:30:29.839 - 00:31:44.713, Speaker A: Not really a problem. And a read is max length and red. All right, so we're going to spawn this connection manager on its own thread. It's going to do this run on, which we haven't written yet. So here there's going to be an impul connection manager, there's going to be an FN run on, and it's going to take a sender of these interface requests. It's also going to consume self. And so this is going to be the main event loop for packet processing, right? And really all this is going to do is this is an rx, so it's going to do like four requests in RX and then it's going to have to figure out what it actually does with each of those requests, right? And now implementing these methods actually become relatively straightforward.
00:31:44.713 - 00:32:35.935, Speaker A: So a TCP stream at that point is really just a. An npc. In fact, we could probably use a typealias here. So an interface handle is going to be an MPC sender interface request. So this here is an interface handle and a TCP stream is really just an interface handle at this point. And this is a little sad, right? So in theory, you could imagine that we encapsulate the state associated with each stream inside the TCPSTREAM object itself. That would be a very nice sort of clean separation of concerns, rather than having this sort of connection manager that just stores all the state in a giant hash map.
00:32:35.935 - 00:33:13.831, Speaker A: And so one day we might get to that. For the time being, I think we'll stick to something that's relatively simple. And so this also is really just an interface handle. So when you bind, what you're really going to do is you're going to do self TX send and you're going to send an interface request. And specifically you're going to send a bind request on that port. And you also need an ack. So we're going to do ack.
00:33:13.831 - 00:34:07.425, Speaker A: In RX is a new channel. And this here, what we get back from bind is probably nothing, right? It's just a message that says, I am now going to start accepting packets. So once we get that back, we really just want to do sort of RX receive dot unwrap. We don't care what the value is. Yes, and then we want to return, okay, TCP listener and we give it a copy of the. Of the transmit handle. Right? I haven't said anything about what we do when we receive a bind, but this is sort of the client side of this and you'll see that all the other methods end up looking very much the same.
00:34:07.425 - 00:35:02.485, Speaker A: So a read is really. You send a read request, the max length is going to be buff capacity. Actually buff len and what do you call it? We called it read and here we actually care about the response. So the response is going to be a bunch of bytes. And here it might be that these unwraps are actually not reasonable because you could imagine that you try to receive, but the other side like sent us a reset or something like a connection error happened. So it might be that this eventually is not going to be an unwrap anymore, but for the time being let's leave it as an unwrap. So here we now have a bunch of bytes and what we're going to do is we're going to do.
00:35:02.485 - 00:35:59.335, Speaker A: What's the slice copy thing? Copy slice copy from slice. Isn't there a better one? Copy non overlapping. Fine. We'll do copy from slice. Seems fine. So crucially, we're going to do buff dot copy from slice bytes, right? So that's going to copy all the as many bytes as we can from bytes into buff. Does that return something? No.
00:35:59.335 - 00:36:52.715, Speaker A: And then we're going to return. Okay, and wait, this response, right? Bytes len. So that's the number of bytes that actually got read. And here you could even imagine we do something like assert bytes len is less than buff len. Right? If we ask the server to read at most buff len, the sort of the connection manager to read at most that many bytes, then it shouldn't be returning more bytes than that. Less than or equal, I guess. And similarly now of course, I assume you can start to see the pattern.
00:36:52.715 - 00:37:46.585, Speaker A: Write is going to be the same thing, except this is now ack and this is bytes and that's going to be vec from buff. Ooh, missing a semicolon there too. Why is my linter not working? This is the same. And at some point we'll get back a message about how many bytes were written. Right? So the, the response for write the ack sends a usize, which is the number of bytes that were actually written out. It might not be all of bytes. And here we can sort of assert that N is going to be less than equal to bufflen.
00:37:46.585 - 00:38:13.903, Speaker A: It can't have written out more bytes than we passed it. And then we do okn. That's how many bytes were written. Can there be an issue on receive? Oh yeah, absolutely. So specifically you could imagine the connection gets closed. So this needs to be right you could imagine that you try to read, but the connection was closed. And so therefore the connection manager closes your channel instead of sending you something.
00:38:13.903 - 00:38:45.795, Speaker A: And so this unwrap is definitely not okay. This is just to get sort of the basic flow working. Flush is basically a write, but with no data. So here, this is a flush. Flush only has an ack and nothing else. We don't care about its return value and we just return. Ok, the last question here is Accept.
00:38:45.795 - 00:40:00.805, Speaker A: So we need to figure out how Accept is going to work specifically. I think one thing that's missing here is currently there's no way for the connection manager, when it gets one of these, to know which connection you're trying to operate on. So both Write, Flush, Read, yeah, write, flush and read all need to include some kind of identifier for the underlying stream. And I think the way we're going to do that is, well, we can use the quad. So we have this sort of quad identifier, right? And you can imagine that every time you want to do a write, you have to sort of say which quad you're operating on. So a flush and a read. And this also means that if you try to do an accept, then what you get back is a quad, right? This probably needs to say which port.
00:40:00.805 - 00:40:52.475, Speaker A: So if you want to accept, then if all the connection manager sees as you wanted to accept, it doesn't know which of the ports to try to accept on. And so we need to include that information. And what you get back is a full identifier for that connection that you can then use for read, flush and write. This then means that the TCP stream needs to include a quad so that it knows which TCP stream it's for. And TCP listener needs to include a port which is going to be U16. This also means that down here this is going to include the port. And when you call Accept on a TCP listener, let's move that code up a little.
00:40:52.475 - 00:42:03.321, Speaker A: When you call Accept, it's very similar to doing like a read or something, except that. Except that what you're issuing is an accept, you give the port, which is the port that is. This should be one. All of these in fact should be one. Yes, you send an accept, you include the port, and you, I guess. And what you get back when you read from that channel is you get back a quad that identifies the stream that was accepted, and then you return a TCP stream that's going to be that quad and a clone of the interface handle so that it itself can send more Requests. And of course, this.
00:42:03.321 - 00:42:46.319, Speaker A: Whenever you send something, you have to include the quad. So the way this API is currently structured is definitely not high performance. Right, where we're copying all the writes, when you're doing a read or a write, we're like allocating an extra buffer, copying between them. We have to do all these, like, interface sends, these channels and receives every time you want to. In fact, two of them, right? One to send the request and want to send the response every time you want to do any operation. We have to, like, include this quad with every operation we do. So there's definitely a bunch of overheads here that we might, One might hope that we could eventually get rid of.
00:42:46.319 - 00:43:01.321, Speaker A: But notice that the external API doesn't actually reflect any of that. Right. The internal API is just. There is an interface, right? You have to create one. And once you have an interface, you can bind. You get a TCP listener. You don't get to look at the fields inside the TCP listener.
00:43:01.321 - 00:43:37.745, Speaker A: All you know is you have one of these. It has an accept method that returns a TCP stream. And TCPStream implements read and write. So the internal, the external interface is still what we would have almost no matter what the internals were like. And so we can always later optimize this to get away from this single event loop. All right, so the question now becomes, what do we do in the main loop of the connection manager? Well, we basically have to do what we did in main. Right? We need to look for packets and such.
00:43:37.745 - 00:44:20.665, Speaker A: And I think specifically what we have to do is we sort of need to. We're going to have this sort of main event loop is going to have to deal with a bunch of different things. Specifically, it's going to have to deal with packets coming in over the network, requests coming in over the interface. So these are like interface requests, the ones we just wrote. And it's going to have to deal with timers firing. And so all of that is going to be sort of stuff that it has to look at. It would be kind of cool to do this in async, because, like, Async is just perfectly suited for this.
00:44:20.665 - 00:45:06.885, Speaker A: Let's think about that for a second. Whether that is worthwhile really depends on whether a ton tap is Async, because if it's not, it's not going to be worth it. Oh, Async. Ooh, ooh. So it does support Async. That's pretty cool. Asynchronous is very minimal and probably inefficient.
00:45:06.885 - 00:46:00.199, Speaker A: It's kind of tempting, not going to lie. So the reason I think it's tempting is because we're basically writing an event loop here that needs to wait on multiple different types of things. And doing that in async is just a lot easier. But if there's something like a try receive, there is not. So the problem we're going to run into is imagine that you sort of. There are no current requests coming from the user, and so you. So you have to try to read from the network to see if anything is happening there.
00:46:00.199 - 00:46:50.925, Speaker A: If you don't have a try receive, then you're going to do a receive and then it's going to block until there's another packet. But that could block for forever. It might be the other side doesn't send any packets, and now there might be a bunch of requests building up on the sender that you're not going to get to because you're still blocked on reading the next packet, which is problematic. Right. So the real way to do this. I was sort of hoping I wouldn't have to do that. So the most straightforward way to turn a synchronous interface like this into an asynchronous one is you spawn a thread and it has a channel.
00:46:50.925 - 00:47:38.015, Speaker A: And that's really sad because it's going to copy more bytes. So the. Okay, so here, let me try to draw. This might be easier. So the situation we're running into is as follows. So the kernel is down here, right? And it has like our network interface with packets coming in here. Currently we have our connection manager here, and we have a bunch of like TCP streams and TCP listeners and whatnot up here.
00:47:38.015 - 00:48:15.797, Speaker A: Currently all of these have sort of a shared channel, right? That's the channel we just created into the connection manager. Right. The connection manager also has a single connection down here. The problem we face is what does the main loop of the connection manager look like? Wow. It's supposed to be a arrow, right? What does this look like? Because it can't. It can't block on reading from this because then it wouldn't read from this. It can't block on reading from this because then it would block on this.
00:48:15.797 - 00:49:06.385, Speaker A: Then it wouldn't read from this. So one way in which this can. We can sort of fix this is that we introduce a separate thread over here and it's going to have that connection. So we're not going to have this one. It's going to be the packet manager, if you will. The package manager has a channel to here. So to be clear this is an mpsc, this is a tontap, right? And in the, in the orange world, this is a ton tap, and this is an mpsc.
00:49:06.385 - 00:50:15.185, Speaker A: So multi producer, single consumer channel. The reason this is the reason this works is because on channels, well, on the standard library channels, you can't do what's known as a select. So you can't arbitrarily select between the two, but at least you can do like a try receive on this one and you can do a try receive on this one, right? And so that way you can essentially multiplex between them. Probably what we want is to use crossbeam channel, which is a really cool crate that may or may not end up in the standard library because it has this thing called a select. So select lets you say you can sort of select between channel one and channel two, and this will block until either of them returns, right? And that fits really well into this model. We're just going to select between these two and whichever return first we handle. And in fact, we could do this with a timeout.
00:50:15.185 - 00:50:57.935, Speaker A: And that lets us also deal with timers firing. The way in which this is inefficient though is imagine you're trying to do a read. So the read is going to progress as follows. Let's say that this guy wants to do a read, okay? So they send a read request to here to the connection manager. The connection manager doesn't currently have any data, but at some point some bytes come in here, right? So this reads some bytes. So this now has like a bunch of bytes in a buffer somewhere. It has to send it on.
00:50:57.935 - 00:51:26.473, Speaker A: Yeah, selector. Great. So cross between channel also has those selects the package manager. The packet manager now has to send this buffer to the connection manager. But this is on the stack, right? The bytes we read here on the stack. So it needs to actually copy them over here. So it copies them over to the stuff that it sends to this channel.
00:51:26.473 - 00:52:12.321, Speaker A: The connection manager then gets those bytes, has to do a bunch of parsing, right? Has to run all the protocol stuff. So it internally has like a buffer of unread data for every connection. And these bytes are just going to be extended to that buffer. And now it needs to respond to this read. So it's going to take some part of that buffer that's going to be the next bytes to read. It has to copy those into a new buffer that it can then send over this channel, right? So notice how many extra both channel sends and memory copies and allocations we end up doing in the scheme. It's really not great.
00:52:12.321 - 00:52:50.895, Speaker A: It would work like it would. It would mean that you end up with something that works. But it is pretty unfortunate trying to think if there's a good way to design this differently. I mean, there probably is, but it requires some design. So ultimately, what would have been the sort of best possible design if we could figure out how to do it. Let's do. What color do I want? I want that color.
00:52:50.895 - 00:53:21.311, Speaker A: Okay, so let's start another sort of hypothetical design somewhere over here. So we're going to have a channel. Sorry, we're going to have the kernel. This has to the network interface. We will still have a bunch of TCP streams that logically sort of get. They get sort of multiplexed over this one connection, this one network interface. Right.
00:53:21.311 - 00:54:03.953, Speaker A: That's sort of the core of our problem, is that these have to collectively drive the network interface forward. And each one has a bunch of connection state. That's not the best way to draw that. So this is the connection state for each one, if we want to. Yeah. So each of them has their own private, private state. That's things like the sequence number and the ack number and the window size and whatnot.
00:54:03.953 - 00:54:35.343, Speaker A: So each of them has one of those. And now imagine that you're trying to do a read from here. So this guy trying to read. If this reads, it's going to have to ultimately, like, look at this channel. We have to somehow get data from this to this. The problem is there's a bunch of packets here, right? Like, who knows what kind of packets you're going to get from this interface. And like, this might be for this one, this might be for this one, this might be for this one.
00:54:35.343 - 00:55:06.235, Speaker A: And this maybe like this one is actually the one that goes here to the one that tries to read. And you still need to decide what you're doing with all the intervening packets. You sort of want to process them, right? You. You can't drop. Or you could drop them, but that seems. That's really inefficient. You can sort of stash them for later.
00:55:06.235 - 00:55:52.551, Speaker A: So you could keep sort of a queue. So imagine that this takes a lock, right? Imagine like there's a giant lock that's like protecting all of this lock. Then there could be a giant queue where any packet that you encounter that's not for you, you stick it into that queue and so on. And so when you get to yours, then you process that one. And any subsequent thing that comes into to look for stuff is going to first go through the queue and see if it finds Things that's for it. So the question is, isn't what you're describing basically network specific work stealing? It's. Well, not quite.
00:55:52.551 - 00:56:23.217, Speaker A: So the way in which it's different is that here it's not as though we have multiple network connections. We actually, we have a single. So logically we have a single incoming network connection. Usually when you have work stealing because the kernel, the kernel gives you this impression that you actually have multiple separate streams. Right. It doesn't expose a single network interface to your application. You think that you have multiple sort of separate streams.
00:56:23.217 - 00:56:57.861, Speaker A: You have one thread that. Or you have a bunch of threads that are managing. That's a terrible way to draw it. You have a bunch of threads up here and these threads are just going to like pick up packets from wherever they get them from the kernel. And sometimes the package you read needs to be handled by some particular thread and so they steal things among themselves. But at no point here is there really like a single point you're going through. The other thing that would be a nice bonus is if we didn't have to do this, if we didn't have to stash these packets away.
00:56:57.861 - 00:57:34.993, Speaker A: Because. Because these packets, if we have to stash them away, we have to stick them basically in some memory that's not going to go away. So we're going to have to create like a vacuate for each one and store those. It'd be great if, if this, if this node notices this packet for this peer, it could just sort of do the processing for that node. But that means that this state has to be in here. I mean, maybe that's okay. Maybe this actually keeps.
00:57:34.993 - 00:58:03.239, Speaker A: So inside the lock. You also keep the state for every connection. It still means that any bytes you read here you're going to have to stash for later. Because if, if. Let's see. Okay, so let's call this the red. The red connection.
00:58:03.239 - 00:58:38.495, Speaker A: And this packet is for the red connection. And let's call this the yellow. This is the yellow connection. And this packet is for the yellow connection. So the red connection is going to end up seeing the yellow packet before it sees the red packet. And the problem is the memory in yellow. Ideally we would just sort of give to yellow so that we don't have to copy the bytes anywhere.
00:58:38.495 - 00:59:19.875, Speaker A: But maybe that's not that important. Why not have node specific inboxes you can stick. Stitch memory into? Stick memory into. Yeah, so that's basically the proposal here, is that we have a sort of queue of things that we haven't processed yet maybe instead what we should do. I should not have painted that yellow. Dark blue, dark blue, which is a terrible color to read in this pink. So maybe what we should do instead is keep all the state for every connection in this sort of one map.
00:59:19.875 - 01:00:22.145, Speaker A: So the inside the lock you have all the connection state. And so like we would have, we would end up with like a red connection state and a yellow connection state and whatever other connection states we have. And this would be sort of all of the bytes that have been read that we have gotten packets for on red, but that red has not read itself. And similarly with yellow, okay, so maybe that's a better design that any time. Okay, so the problem with this is imagine that red tries to read and it just doesn't get any packets for itself, right? So this, this is why I didn't do this in the first place. So red is trying to read. So red takes the lock.
01:00:22.145 - 01:00:54.083, Speaker A: At this point, when red has the lock, it starts to walk through these packets, right? Imagine that there is no red packet here. There's no red packet. And so red is just going to keep reading these packets and it still holds the lock, so no one else can read. Even though there might be a bunch of data for yellow, a bunch of data for these blue nodes. Right. Like all of the other connections have gotten a bunch of data, but red still hasn't gotten their packet. So there needs to be a way for red to sort of yield.
01:00:54.083 - 01:01:35.927, Speaker A: Right? Red has to at some point decide, I'm going to let other people go now. And I don't quite know how we're going to do that. So this is why in the, in the other design, this is sort of a non problem, right? Because the connection manager just sort of notifies people as appropriate. It just keeps reading packets. And if it gets something for red, it would notify red. If it gets something for yellow, it would notify yellow. Whereas here we don't really have that same luxury.
01:01:35.927 - 01:02:22.487, Speaker A: You could imagine that red sort of parses a packet and the first packet it sees it's going to yield so that someone else can read it and then it might have to take the lock again. Yeah, it's just going to give up the lock and then try to take the lock again immediately. Basically it's going to read, let's imagine this packet isn't here. So it reads the yellow packet, notices that it isn't for itself, and so it just gives up the lock and notifies yellow, which is presumably waiting for this. This is going to be. We're probably going to end up using something like a cond var here. So a cond var is a way to wake up.
01:02:22.487 - 01:03:02.315, Speaker A: It's a conditional variable, is the way to think about it. So yellow, if it tries to read, it's going to see if it reads. If it fails, it's going to wait on its own convar, which includes releasing the lock. Red is going to notice that yellow wants to be woken up, is going to notify Yellow, and is then going to probably yield and then immediately try to take the lock again because it hasn't satisfied its read yet. It's going to be a lot of contention on this lock because this lock guards the entire connection state. But it might be a better design. It means that we don't need to have all these threads running around.
01:03:02.315 - 01:03:41.395, Speaker A: And so that might actually be better. But it is definitely a little sad. We also run into a weird case of timers because the timers need to run here too somewhere. Although maybe we could have a separate timer thread that also takes this lock. So this is going to be like a timer thing and the timer is going to do things like decide whether it's time to try to retry sending a packet or whatnot. And it's also going to have to take the lock. And all of this, remember, is an artifact of the fact that we only have one underlying connection.
01:03:41.395 - 01:04:22.395, Speaker A: And you can think of this as internally inside of the kernel, right? It's pretending that it has all these channels, right? So every. If you do normal network programming, you just have separate TCP streams and you don't really think about the fact that they're connected somehow. But really sort of under, under the kernel, there really is just a single network interface. It's like one ethernet port or one wifi card, and somehow all of these have to be funneled through that one interface. And the kernel takes care of that and it takes care of that without you really seeing what's going on. And you can imagine that the kernel has to do something sort of similar to this. They might not use a lock.
01:04:22.395 - 01:05:02.485, Speaker A: They might. There might be some like smart lock free data structure you can use here so that you don't have to take this lock. The kernel can sort of always have some threads running that don't need to context switch. But this is like a fundamental problem that we now have to solve in user space. Color A read packets until another 1B comes up and then B reads its packets until. Yes, the basic idea here is going to be you only ever read one packet at a time. So Red reads a packet and we could make it more than one.
01:05:02.485 - 01:06:05.905, Speaker A: Maybe this still becomes problematic. Okay, so the idea was red reads one packet and if that packet is for red, all good, we might be done. If it's not for red, it's going to notify whichever thing it was for and then it's going to sort of wait for a little while and then it's going to take the lock again. It's basically going to yield and then take the lock, which is some overhead, but probably less overhead than all these channels and certainly less sort of byte copying. I just realized though that one other problem we run into here is the. Imagine that you're red and you try to read a packet and that blocks because there are no packets. And the reason there are no packets is because we need to retry.
01:06:05.905 - 01:06:56.661, Speaker A: And so therefore the timer has to fire, but the timer needs to take the lock in order to send anything. So but it can't take the lock because red is holding the lock, blocking for a packet. I think what this means is. Yeah, I don't know how we do that. Hmm. Oh, here's a possibility. Okay, how about this design? How about if any TCP stream.
01:06:56.661 - 01:07:24.089, Speaker A: I'm running out of colors. Orange. Orange is a color. Great. Anytime a TCP stream tries to access this, it is not allowed to try to read a packet. Cannot read. Basically sort of from the Nick, from the.
01:07:24.089 - 01:07:59.295, Speaker A: From this. Right. It's not allowed to read anything from here. It's not allowed to make sort of a blocking call to get more data. Instead, if it sort of looks in its buffers, stick some stuff in its buffers and it will. And if it fails to do that, if it can't actually read anything, then it's going to get one of these convars is going to wait on stuff being available in its slot, if you will. Right.
01:07:59.295 - 01:09:00.941, Speaker A: And then we're going to have one thread that's going to be running on the side and that thread is going to deal both with timers and it's going to be the thing that reads. So it is going to in fact might even be the thing that just owns the. Ah, okay, here, how about this? So that this sort of severs the connection between here we're going to have this thread own the nick and instead of having this be a channel like we. This is sort of a merge between these two designs, we're going to have this thread that's going to be the thing that reads from the nick. And whenever it gets a packet from the nick, it is Going to take this lock, do the processing and put stuff in the appropriate place and wake threads up. So now we've sort of disconnected these two. But the mutex basically lets us not have to copy all the data around.
01:09:00.941 - 01:09:31.751, Speaker A: And because this thread, all it's doing is reading from the. The nick, it doesn't matter that it's blocking. Ooh. But it still needs to deal with timers. I think timers are going to be a pain here, but I kind of like this design. I think timers. The problem with timers is they have to do things with the nick.
01:09:31.751 - 01:09:52.235, Speaker A: Right. They have to. They may have to send a packet or something. Right. But if this thread is blocked on trying to receive a packet, you can't like, you can't do this. Which is why this sort of needs a receive timeout function. I don't know if there's a way to do that though.
01:09:52.235 - 01:10:23.755, Speaker A: Oh, it might be. It might be that the way we do this is going to be really funky. But basically we can get a RAW file descriptor to the underlying thing. Oh, that allows for all sorts of cheating. But basically we can just before we make this call to block. Right, Sorry, this is called read. Right, Read blocks.
01:10:23.755 - 01:11:07.935, Speaker A: And if we wanted to block for at most a certain amount of time, this, this crate doesn't let us do that. Right. It only has a receive method. But man, read. Oh man. To read. But where's the timeout business? So there's a way to set sock, Scott.
01:11:07.935 - 01:11:50.315, Speaker A: Sock. Oh, maybe it's just socket. No, what's the thing for setting. Actually we can do this in a different way if we look at the rust docs for receive timeout. So on a TCP stream, you have received timeout. What does that do internally? Well, that's platform specific that I think we need to go to the real code. So let's see.
01:11:50.315 - 01:12:35.715, Speaker A: Lib, standard sys, unix. Where's Net here? Let's look for receive. Or is it read timeout? Oh, maybe it's this common then. Net. Yeah. So there's this. So basically there's a way that we can.
01:12:35.715 - 01:13:24.045, Speaker A: Because we have this. Because we have this as. As RAW FD and into raw fd, we can get sort of a raw handle to the underlying thing and then we might be able to just set a timeout directly on it so that the read call actually will time out. But in order to do that, we would have to find Xnet0. Set timeout. Okay, and where does that come from here? Set sock option. Yeah.
01:13:24.045 - 01:14:36.171, Speaker A: Right. So we can Basically do the same thing that Rust internally does to set a timeout on a particular channel, because all this is doing, all receive is doing is really just calling read on the underlying file descriptor. And so what we're going to do is we're going to set the same. We're going to set a timeout on this file descriptor so that a read will block for most so and so long as this basically gives us a way to emulate receive timeout, and we'll see whether that works. And so that would mean that when, when this thread that manages sending and receiving packets does a read, it's actually going to do a read timeout to. That's going to be sort of at most the time until the next timer fires. Now, we're probably not going to end up implementing timers in this particular stream or like it might happen in a future TCP stream.
01:14:36.171 - 01:15:19.235, Speaker A: But we need to make sure that the design actually supports having timers because they're critical to getting TCP to work. Okay, so I think what this now suggests is this is somewhat similar to the design we had before, but with fewer threads and fewer channels. So instead what we're going to do is we're going to have. Every TCP stream is really just going to have a pointer to a mutex of all the sort of connection state. This is basically what we had in Connection Manager before. And Connection Manager is going to have everything except for the Nick itself. So this is going to contain Nick, this is going to contain connections.
01:15:19.235 - 01:16:10.405, Speaker A: Right. If we think about the data structure. And then the thread that reads from the NIC is going to populate things into the connection structure by managing the connections. All right, so let's give that a try. It means we have to rejig this a little bit because we no longer need these interface requests, which is good, right? Like, getting rid of that seems fantastic. So what's really now going to happen is when you create a new interface, we're going to create the Nick, right? So that we have to create regardless. We're going to spawn.
01:16:10.405 - 01:17:12.525, Speaker A: We're going to spawn some thread that's going to sort of manage the Nick, and we're going to have, I guess, a interface handle. And an interface handle is really just going to be. It's going to be a type that's going to be an arc Mutex Connection manager. Yes. Probably does not need buff either instead here. So this thread is going to be what holds the Nick. It's going to have a buff.
01:17:12.525 - 01:18:04.777, Speaker A: Just going to be this and it's going to do the stuff that main does, but anytime it has to touch a connection, it actually has to take the lock. So up here we first have to. We have to create the sort of connection struct that everyone's going to look at. So we're going to do connection manager default. And this can presumably just derive default. And in fact this is going to be an ARC new mutex new connection manager default. We might even be able to just say ARC default here, but type inference is going to come kick our ass.
01:18:04.777 - 01:18:49.855, Speaker A: Ooh. Actually we can do CM interface handle is ARC default. Great. All right, so the. This extra thread that we've made, it's going to need a copy of the connection manager, right? It's not currently doing anything, but it's going to have to do that at some point. And the interface now is really just this handle to the connection manager. So interface is a interface handle and a join handle.
01:18:49.855 - 01:19:29.381, Speaker A: So the interface handle is where is where all the stuff for all the connections is. So that's where you're going to have to lock to do reads and writes or accepts for that matter. This is no longer a thing bind now. So bind is really just going to do. It's going to do self.accessance handle.lock and I guess unwrap, right? So it has to lock the interface.
01:19:29.381 - 01:20:42.521, Speaker A: It has to then do something to start accepting SIN packets on the given port, right? So that's going to modify some data structure in CM that we haven't constructed yet. And then it's going to drop CM and then it's going to return this, right? So this is releasing the lock and then it just returns the TCP listener with the port because it needs to be able to identify the connection later. And the interface handle because it needs to be able to lock in order to accept packets. So that's TCP listener. So if it wants to accept, what does it do? Well, it has to take the lock. It then has to see whether there are any sort of pending connections for its port. So the way it's going to do that is it might be.
01:20:42.521 - 01:22:04.745, Speaker A: We can do finer grain locking here, but let's ignore that for a second. So CM is definitely going to have something here like pending. It's going to be a hash map from port to what? To a quad vec. Quad. Yeah, so, so pending here is a list of pending connections to this port, right? So if there are no pending connections, this vec is empty. If you are not listening, then there will be no entry for that port and so now we know what bind has to do. Bind has to do self pending dot insert port vecnew and we're going to hear assert that was bound is none, right? That there wasn't already someone bound to this port.
01:22:04.745 - 01:25:24.985, Speaker A: Or the way we can do this in the sort of better way is collections hashmap entry and then we match on. We match on entry report and if it was. If it is vacant then we insert a vec new and return ok, if it is occupied then we return an error, right? This means the user tried to bind to a port that has already been bound to and then we return IO error new IO error kind I can never remember what the error kinds are. Adder in use port already found like so and this should be cm does that make sense? So for bind we take the lock, we add an entry to pending for our port to say that we're willing to accept connections initially it has no new connections and if it was already bound, like if there was already an entry for that port, then we return an error saying we can't bound to a port that's already been bound. Okay, so the question now becomes what does accept do? Well, except is really just going to be. It's going to look impending so it's going to do cm.get mute port self0 I guess we could be nice and name these but for now we won't and we're gonna say if let some quad is get mute this we actually expect to be sum because we already have a TCP listener open so this is something like port closed while listener still active and then we want to pop this is from the vec actually I guess this should probably be a vec DQ collections back dequeue and hashmap so specifically we want to do a.
01:25:24.985 - 01:27:17.125, Speaker A: You can imagine that this is going to be new connections are going to be pushed to the back and we're going to pop connections off the front. And so if there is a connection for us to pop, then we're going to just return a TCP stream for that quad. Otherwise we actually have to block, right? So here we've been told to accept the connection, but there is no connection to accept. And so here what we really want to do is block to do block. So for now we're going to do this, we're going to have a try except that is going to do return error IO error new IO error kind word block tried to do no connection available to accept, right? We probably want an accept function that will actually block it's just that that's going to require us to write some infrastructure that we haven't done yet. I just want to walk through these first and then we can add all the sort of necessary bits and pieces afterwards for doing actual blocking before we continue. Does this design roughly make sense, like what we ended up on here, why we ended up on that design, what the sort of challenges of it was, and what the general approach we're now going for is? I sort of want to hear from Chat that we.
01:27:17.125 - 01:27:44.261, Speaker A: That I haven't sort of lost you along the way. It's easy when writing this to sort of like, I have a stack internally in my head of what we're doing, but if that doesn't match your stack, then I've sort of lost you along the way. And that would be unfortunate. So let's try to resync just to check that people are still understanding roughly what. What's going on. All right, Sensei. Clo CLO says yes, it does.
01:27:44.261 - 01:28:15.875, Speaker A: Great. So we have one person on board. There are in theory, 51 people in chat. What do the other 50 people think? Or some subset of them, maybe? Everyone has me muted. You're e too busy eating pizza. That sounds pretty great. I wish I was eating pizza.
01:28:15.875 - 01:29:03.779, Speaker A: I'm going to assume that if you're eating pizza, you're understanding everything that's going on. Pizza clearly just like makes your mind aware, right? That's how pizza works. All right, well, there doesn't seem to be any loud complaints, so we're going to continue and feel free to stop me if something does not make sense because remember, if it doesn't, if you think it doesn't make sense to you, it is probably the case that it also doesn't make sense to other people. Like whatever questions you have in your head where enough people here, there are probably other people with those same questions. So please feel free to interrupt if you feel like something isn't. Isn't adding up. All right, so for reading, at this point, the pattern should start to become clear.
01:29:03.779 - 01:29:32.325, Speaker A: We're going to lock. Then we're going to have to see whether there's data available for this connection. So here too, the connection is going to be self. No CM connections. This is going to be CM pending. This is going to be CM connections. GEMUT self zero.
01:29:32.325 - 01:30:03.745, Speaker A: This is going to be a reference. A reference here too. We basically expect there to be a thing because we have a TCP stream. So the TCP stream should still be there. It might be that here you might get connection loss Actually, so let's do an okay or else. Error. New IO error.
01:30:03.745 - 01:30:52.543, Speaker A: Kind not connected. Broken pipe or. No, I think it's broken pipe. Connection aborted. Seems good. CPU stream was pretty much was terminated unexpectedly. Also, why is this not formatting my code 87? What? Oh, great.
01:30:52.543 - 01:31:29.761, Speaker A: Formatting. Nice. Okay, so this here is the connection, right? So this is the connection manager. The connection is just getting access to the connection object for this particular connection. And now we want to do something similar to what we did for Accept, which is if. Well, so this is where it gets tricky because we haven't actually implemented data yet. But if you look at TCP connection here, there's just definitely going to be a.
01:31:29.761 - 01:32:01.237, Speaker A: Like a receive buffer. This is sort of incoming. It's probably going to be a VEC DQ. It's probably going to be a VEC DQ of U8s. So this is going to be bytes that we have read from this connection, but that the user has not yet read. This is like a sort of buffer space. There's also going to be an outgoing buffer.
01:32:01.237 - 01:32:47.335, Speaker A: So this is bytes that the user has given us, but we have not been able or that we have not been able to send yet. And that could be that we've sent it in a packet but the other side hasn't acted yet. In fact, that's probably what it's going to be. This is going to be sort of an act, I guess. Okay, so here what we really want to do is if C dot incoming is empty, then to do we're going to need to block, right? And we don't know how to do that yet. So for now, no bytes to read. So here really what we want to do is block.
01:32:47.335 - 01:33:18.825, Speaker A: If we get down here though, it means that there is data there. And so what we're actually going to do is just read however much data we can up to the size of buff. And so here I'm going to have to look up. So there's a. I want. It's never the expansion I want this. There is a ass slices, that's what I want.
01:33:18.825 - 01:34:04.651, Speaker A: So a vec dequeue, just for context is VEC DQ is a great little tool to have in your toolbox. So a vec dequeue is a ring buffer. And if you don't know what a ring buffer is, you're about to learn. So a vec looks like this, right? So this is zero and this is N, where N is the length of your vector. And if you push onto the vector, you push over here, right? In reality it's a little bit more complicated that than that. Because a vector in Rust actually has. I need to find a better way to erase like this.
01:34:04.651 - 01:34:38.853, Speaker A: It's just silly. I want. When I switch to erase, I want a larger brush. So really the picture is more like this isn't N, this is capacity and this is len. And all the stuff in between here is like stuff that you've written. And if you push, what really happens is you push some, some stuff from here to here. And now let's call this len prime.
01:34:38.853 - 01:35:32.953, Speaker A: So this is now the updated len. But no allocation had to happen because the vector can actually hold this much data, right? So until once you get here, if you then try to push more data, then the vector is going to grow. Now this is really neat. The problem of course is imagine that you want to use this sort of like a queue, right? Like, imagine that you keep pushing stuff to the back, but I want to read stuff from the front. If I try to read. Let's do orange if I want to read like this bit that becomes really annoying in a vector because if I read this, this stuff, this is now free space, right? So I could move zero to here. But if I kept doing that, then eventually I would just like all.
01:35:32.953 - 01:36:18.295, Speaker A: All this stuff is still in memory, the vector is still that long. And so instead what I have to do is if I read this, I have to take everything that follows it and sort of shifted to the left to fill in the space that was voided here. Otherwise I never recover that space. A VEC DQ tries to solve this problem by what green do we want? I want like pastely, like that one. So a vec DEQ is somewhat similar in that it too has a capacity. However, it has. Instead of having just sort of everything starts at zero.
01:36:18.295 - 01:36:44.603, Speaker A: It has a head and a length. Sorry, a head and a tail. So initially the head points to zero and the tail points to zero. If the head and the tail are equal, then the thing is empty. If you push, what really happens is. So this is a push. Then the head starts pointing here and it no longer points to here.
01:36:44.603 - 01:37:05.887, Speaker A: If you push again, the head now points to here. It doesn't point to here anymore. The tail still points here. I might have gotten head and tail messed up here. This is the tail, this is the head. So head as in the start of tail as in the end of. So the start of the data is here.
01:37:05.887 - 01:37:46.467, Speaker A: So this is the head, not the tail. This is the end of the data. So this is the tail, not the head. And so I Might keep pushing stuff and eventually I'm going to end up in a position. Let's just ignore all of this at this point where the tail points here and the head still points to the start. So the question is now what happens? Ooh, that's a terrible color. Now what happens if I want to read this thing? Well, reading this is now trivial because all I have to do is increment the head and any indexing operation just always starts from the head.
01:37:46.467 - 01:38:43.791, Speaker A: So if the head is now here, this now has length 4 because the length is from the head to the tail always if I push, I still push the tail. If I pop, if I pop from the front, then I just increment the head. Right? Where vec dequeues get a little funky is as you move further to the right, you can easily end up in situations like this one where you have your vec DQ and the. No, that's not what I meant to do. Where the. So this is still the capacity. And the tail currently points to here, right? And the head points.
01:38:43.791 - 01:39:15.495, Speaker A: I don't know, here, right? And there's still a bunch of stuff in between here that I've like written to in the past, but currently is not being used by anything. So the head is currently pointing here. And let's say that there are three elements here. So these are currently the three elements of the vecdq. So if I popped three times I would get these three things. But now what happens if I push? Well, what actually happens when I push is the tail wraps around and moves to here. So tail is now going to point to over here.
01:39:15.495 - 01:39:56.055, Speaker A: It's not going to point to here anymore. And now this is an element. And so notice that what this means is that a vec dequeue can sort of become bifurcated, right? It now it's now no longer a single region of memory. The vec dequeue, if you were to read it start to finish, you would first read these bytes and then you would read these bytes. And so this is why in the VEC DQ case over here, you can't de ref into a U8 into a. Sorry, into a slice. You can only dereference into two slices, which is the leading end and the tail end.
01:39:56.055 - 01:40:54.341, Speaker A: Or in other words, it is this bit and then this bit if you push data beyond the allocated size. So basically the same thing happens as in a vector. Let's go with this color. So imagine that we've gotten to the point where the tail is here, right? Well, the tail would never technically be there but imagine that the thing is full and you try to push, it would detect that you're trying to push and that the capacity has been reached. So what it would do is it would do the same thing as you do with a vector. It allocates a new vecue that is twice as long. Imagine that that is twice as long.
01:40:54.341 - 01:41:27.305, Speaker A: Then it takes all of the existing things and sticks them into here. And of course, the way it's going to do that, it's going to take these things and stick them here and then these things because it's full, right, and stick them towards the end. And so now you have all the stuff in order again. And now it's going to set the new. The new head, sorry, the new head to be here and the new tail to be here. And now you can push by pushing to the tail. So it is basically the same cost as a vector.
01:41:27.305 - 01:42:13.131, Speaker A: The only way in which it's different is in a vector. If you need to resize the vector you can copy a single segment of memory, whereas with a vector you have to copy two segments of memory, but the total size is the same. I doubt that you would notice this in practice, except if you were doing lots of resizes. But in general the. Because of the way this resizing works of sort of doubling each time the. We call this amortized cost that you would expect to not see resizes as your data grows because they become rarer and rarer the more data you have. So effectively they're not that different.
01:42:13.131 - 01:43:06.165, Speaker A: And I think very often a vec dequeue is what you want if you want to be able to operate on both ends. If you only ever operate on one end, then a vec is perfectly fine. And the vec has the nice property that you can always get a slice to the entire contents, whereas that is not true for a vec. DQ and so now when we do a read, what we really have to do is do a head tail is. Where were we? C.incoming. ask slices. Actually, I might be able to do even better than that.
01:43:06.165 - 01:43:48.185, Speaker A: Gee, we might be able to just do drain and not have to. I was gonna. I was gonna manually use like the copy from slice manually for head and tail. But I think instead what we'll do is actually we might not be able to do that. I wonder if there's. This gives us an iterator over bytes, which is probably not what we want. Wonder if there's.
01:43:48.185 - 01:44:01.757, Speaker A: No, not really. I mean we could. The. The problem is that we have a. We have a buff Where. Because these are mu. These are U8.
01:44:01.757 - 01:44:41.875, Speaker A: It's not like this is a vector we're going to push to. It's just we're going to overwrite the bytes that are there. So I think we might actually still want the this. So if. Is there a way for me to. I want like truncate start, but I don't know if that's a thing here. Split off is definitely not what I want.
01:44:41.875 - 01:45:13.925, Speaker A: Rotate left. That's definitely not what I want. Huh. What does drain do internally? Yeah, that just walks. That doesn't really help us actually. Let's see what drain does. No, I want match case.
01:45:13.925 - 01:45:54.833, Speaker A: Give me the drain and give me the iterator for drain. So when the iterator is dropped, how does it. Oh, it just directly changes the tail, doesn't it? Yeah, let's worry about that. I don't know how to best use this API at this point because I want to not have to pop bytes individually. Right. Like I. Okay, so here's.
01:45:54.833 - 01:46:42.855, Speaker A: Here's one thing we could do. This is sort of stupid, but let I actually for I in C is 0, N red is 0. While let. This is. I'm just going to show why I think this is stupid. While let some byte is c.incoming. pop front n red plus equals one buff n red is equal to byte.
01:46:42.855 - 01:47:33.259, Speaker A: And I guess if it's going to be a loop instead of that. If n red is equal to buff len then we break. Then we're going to match on this. And if it's sum, then we get a byte, Then we do this. And if it's none, that means there are no more bytes in the incoming buffer. So then we also break. Right.
01:47:33.259 - 01:47:57.105, Speaker A: So this will do the right thing. But it's really stupid. We're copying one byte at a time. I want the equivalent of this code, but without copying one byte at a time. And I think the way we do that is. Well, the problem is we need to be able to remove stuff from the start. I'm actually kind of surprised that there isn't a.
01:47:57.105 - 01:48:40.425, Speaker A: An efficient way to just change the head. I mean, maybe the trick is drain actually. Yeah, that's probably okay. So I think what we actually want to do here is head tail is c.incoming.as slices. And then we're going to do if. Okay, so we know this is non empty.
01:48:40.425 - 01:49:52.715, Speaker A: So we're first going to copy bytes from the head. Let's see. Let mute n read 0. So first we're going to do buff copy from slice head to Read is buff. That doesn't quite work either. Let me write out roughly what I was thinking and then we can discuss C dot incoming dot drain. So I think that is basically equivalent, except that we need to make sure that we don't write more bytes into buff than buff can take.
01:49:52.715 - 01:51:17.935, Speaker A: I think slicing breaks. I think we need H read is going to be compare min ofbuff.len and head.len and we're going to do H read and we're going to do N red plus equals H red and then tail read is going to be buff len minus nred and tail len. So this might be zero, right? It might be that we read all the bytes we needed, but it means that we don't really have to branch here, which, like, might be nice. So this might read no bytes, and then we drain as many bytes as we read. And at this point we can do and red and I'm going to leave it to do for myself here.
01:51:17.935 - 01:51:53.665, Speaker A: That might not make sense right now, but we'll come back to it. Actually, no, that will not need to happen. Great. Okay, so let's take a look at read. Now that we have the whole thing, right, we first try to take the lock, right? Because we need access to the data that's been read. We look up the connection for the TCP stream we're trying to read from. If there's no data, we're going to have to block.
01:51:53.665 - 01:52:42.455, Speaker A: Currently we don't know how to block and so instead we just return would block. If there is data though, then we will read as much data as we can. There's actually also a question here of detect fin and return n read equals zero because we're going to have to detect when the other side of stop sending us data and then read. The contract for read is basically you need to return, okay, zero if the other side is not going to send you anymore. And currently we're not detecting that. And I don't think we have a way to detect that either at the moment. Yeah.
01:52:42.455 - 01:53:31.115, Speaker A: Okay, so if there's no data, then we need to block, and we don't know how to do that yet. Otherwise we're basically just going to read as much as we can from the incoming buffer that still fits within buff and then we're going to return the number of bytes we ended up reading. And of course write is going to end up being very, very similar, except going sort of the opposite direction. Specifically, we're going to have to take the lock. We're going to have to look up the appropriate connection If. Ooh, that's also a good question. So here's a question.
01:53:31.115 - 01:54:14.679, Speaker A: Should write ever block? Right. We could always keep doing writes by just expanding the buffer, the sort of outgoing send buffer. But that might not be what we want. We might want to disallow more than a certain number of packets outstanding, right? So think of it this way. We're gonna go over here, we're gonna switch to the nice blue. So imagine sort of in the very abstract, right, a client and a server as a connection going this way, and there's a connection going this way. So.
01:54:14.679 - 01:55:23.439, Speaker A: So this is after the handshake has happened, right? And in this setup, weird. Did chat go away or is chat still there? Suddenly the chat Service is reporting zero people from like 60, which seems wrong. I'll keep going, but if someone can type something, that'll be helpful. Okay, so you have a client on a server, and there's like, the server is going to have some capacity. Like, it's not going to let you send it, just keep spewing data to it. It's going to say like, okay, great, thanks. So imagine that it has a limit of like, thousand 24 bytes or something.
01:55:23.439 - 01:56:30.335, Speaker A: Like, you are not allowed to send me more than this much before you hear back from me that I have received them. Well, the client still has some application program that's running on it, right? That's sending it data. So imagine that this is like sending just like tons and tons of data way more and way faster than the server is accepting your data. You have a question, right? Either you need to block the application saying you're not allowed to send more data, or you need to buffer up more and more and more data in memory on the client. That is like bytes that you ever see you have accepted from the application but you have not sent out on the wire yet, right? And so the question becomes, which of these two approaches do you want to do? You probably want to block the application at some point, but that basically just means that there has to be a limit to how much, how many bytes you buffer up in the send queue before you say no to the application. And in fact, usually on Linux, for example, you can find this out. So if you type ip.
01:56:30.335 - 01:57:30.307, Speaker A: I thought it was IP link, qlan, Linux qlan, there's a command to get more information about this. Yeah. So actually it's kind of funny to see how what we're building is basically exactly what exists in the kernel, but the kernel tries to be relatively clever on it. Like, there are lots of people who are doing Research on how to manage this queue. Right. And specifically, where's the IP address show? Where's the thing that gives me Q? Well, that's entirely unhelpful. It's like.
01:57:30.307 - 01:58:02.545, Speaker A: NET TCP qlen. All right, I can't find it, but let's ignore that. But there's basically like. It's not quite this parameter, I think, but there's like a. There's a limit in the kernel to how many bytes you are allowed to stick in the buffer before the kernel will start to block you. And so we have the same problem with write. At one point do we see and say sort of enough is enough.
01:58:02.545 - 01:58:40.335, Speaker A: And that's basically what we're going to end up putting here. Right. If C.outgoing. length is more than like send queue size, so we're gonna have some const. Send queue size, it's gonna be 10:24 for the time being, then we're gonna have to block. Right. Too many bytes buffered and we're gonna have to block until some of the bytes that are in the queue have been sent out on the network.
01:58:40.335 - 01:59:19.875, Speaker A: Until the server started basically accepting more of our bytes, we're going to have to block the application. Currently we don't know how to do that. So currently we're just going to return wood block. But this is the case in which we would block. Yeah, great. I also just realized that another thing we're going to want is import TCP stream shutdown. So this is the way in which you can send.
01:59:19.875 - 02:00:07.605, Speaker A: You can sort of tell the other side that you're not going to send any more data. And this is a. Like an Ionet, Is that right? Standard net shutdown unimplemented. This is basically going to send a fin, if you remember, from last stream. Okay. So we're going to try to write out this many bytes into this buffer and it's going to work pretty similarly to what we did in the in read, except it's sort of in reverse. Instead of reading bytes out, we're going to push bytes in and allowed to write.
02:00:07.605 - 02:00:33.447, Speaker A: I guess N write is going to be Send q size -c.outgoing. len. That's how many bytes we're going to be allowed to write. And it's going to be standard min of buff len and that much. Right. So we will write either as many bytes as we have or as many bytes as we're allowed to, whichever is smaller. Right.
02:00:33.447 - 02:00:59.885, Speaker A: Because we can't write out more bytes than we've been given Q lengths with SS dash l no, that's the current size of the queue. I was looking for the. Yes, you are right. So SSTL tlp. Oh, what? That's. Oh, tpn. That's what I want.
02:00:59.885 - 02:01:36.895, Speaker A: So this is showing me actually let's ignore the N and ignore the P. So this is showing me all currently open TCP connections on my machine and for each one how many bytes are in the send buffer and how many bytes are in the receive buffer and. And also things like which TCP state we're in. So this is kind of neat. But this doesn't show me the maximum buffer that the kernel enforces. Still try to figure out how I would do a lock free circular ring buffer in Rust. This would be ideal in this situation.
02:01:36.895 - 02:02:14.705, Speaker A: It wouldn't be quite enough because you still need the wake ups which you don't quite get with the lock free stuff. It. It gets you quite far but not quite enough. I think some finer grain locking might help us here. Okay, so that's how many bytes we're going to write. And of course the actually writing this is pretty easy because we don't need to worry about the head and the tail. Instead we are just going to do C dot, outgoing dot, extend buff from buff to and right.
02:02:14.705 - 02:02:57.645, Speaker A: And then we're gonna do. Oh, I guess. And then we're gonna do. Okay and write because that's how many bytes we wrote out here though we might have to do a to do schedule wake up writer and a flush. So a flush is basically saying block until there are no. Until there are no bytes in the local buffer. Every byte has been act by the server.
02:02:57.645 - 02:03:23.065, Speaker A: And so this is also going to work very similarly except that it's going to be. If it's empty then we're just going to return. Okay. Right. If the outgoing buffer is empty then we're done. Otherwise we're going to have to block and we don't know how to block yet. So we're going to have to figure that out.
02:03:23.065 - 02:04:34.215, Speaker A: And shutdown is basically setting the fin flag, which is not something we have an external interface for yet. But now let's see how far we get in compiling this. Oh, we need a bunch of things, don't we? Main it's going to have these three and we also still have to do all this stuff that main does to manage packets. Oh, it's not standard min, it's standard compare min no field ih that is true. Or you believe there should be a field called that. Let's make things nicer for ourselves. So this is the port and this is the interface handle could arguably just be H.
02:04:34.215 - 02:05:22.121, Speaker A: And TCP stream is similarly going to be the quad. And it might be that we don't actually want this to be a quad. It might be that we just want this to be a like a numeric index or something instead. But for the time being it's a quad. Which I guess also means that it's going to be here and down here in flush and tcplistener is going to be H. And this is gonna be port. No, it's not true.
02:05:22.121 - 02:05:48.825, Speaker A: That's gonna be H. This is gonna be port. Alright, we're getting closer. 66. That is actually IH and this is actually IH because we need to. Oops. We need to distinguish it from the join handle, which is also a handle in this instance.
02:05:48.825 - 02:06:30.035, Speaker A: Mismatch types on line 51 bind. Oh, this is not. This is port and handle. And I guess that also means that accept should also be TCP stream, quad and handle. How about now? Missing fields. Incoming. Oh, because we added fields to this.
02:06:30.035 - 02:07:26.688, Speaker A: So this is online 101. So the incoming and outgoing buffers here are initially going to be empty. Oh, did I not call it unactual? And I guess that also means that here there's no outgoing. It is an act. Oh yeah, we no longer need the NPSC. That's nice. 48cm.
02:07:26.688 - 02:08:17.167, Speaker A: That should be IH, not CM. What else do we have? Mismatch typeline 50 bind. Did I like do something silly? Yep. Mutex and arc. That's fine. Sync mutex and arc158 extend is not an iterator. That's interesting.
02:08:17.167 - 02:09:44.251, Speaker A: So for a VEC dq, what do they want us to do? Why? Don't want to push a bunch of stuff. Okay, so I may just have to do like iter, I guess. Oh, right. We want to be able to access these fields. So incoming and UNAC need to be pub crate for now 56 pending. Pending should be a VEC DQ and 56 should be new. PUB crate means that it is public to any code that is in the same crate as where you put PUB crate.
02:09:44.251 - 02:10:22.865, Speaker A: So it's not public to people who use your crate as a library, for example, but it is public. It is available within your crate. Think of it as sort of like protected in Java. Maybe 167. Oh, this is gonna have to be mute. This is gonna have to be mute. It's gonna have to be mute.
02:10:22.865 - 02:10:41.795, Speaker A: And this is going to have to be mute. How about now 54? And this is going to have to be mute. So close. So close. All right. Main is going to have to change a lot. That's fine.
02:10:41.795 - 02:10:58.833, Speaker A: Bunch of complaints in tcp. That's fine. Those are sort of to be expected. We do want to fix the ones that are in Source Lib though. Okay. I think those are all expected. Great.
02:10:58.833 - 02:11:57.827, Speaker A: So now time to fix main. Right? So we still have this to do of something has to be reading from the nick and currently nothing is reading from the nick, right? So all the stuff that happens in Main currently we want to do here. And so this is going to be something along the lines of packet loop and it's going to be given a nick and the ih. So we're going to have a. I guess we may end up splitting this file into multiple files in not too long. The nick is going to be mutable and it's going to be a tontapace and the IH is an interface handle. And we know that this is going to need to have a buffer of some kind to read the bytes into.
02:11:57.827 - 02:12:58.175, Speaker A: And that's going to be the buffer we all know and love. And inside here it's basically going to do this loop, right? It's gonna receive some stuff, it's gonna parse the stuff, but any time it needs to actually touch the underlying state, the status bar, this is airline. I have a separate video on my YouTube channel. That's how my entire editor is set up. So you should go watch that if you're interested. So what we need this to do is whenever it's about to touch the underlying state, it needs to try to take the lock, right? Because there could be someone else reading at the same time, for example. And that is basically down here we're going to do CM is ih.lock.
02:12:58.175 - 02:13:21.859, Speaker A: unwrap and then we're going to do cm.connections. entry. If there is one. We're just going to do. We're going to process the packet. If. If it's vacant, then the question becomes is someone waiting? Right.
02:13:21.859 - 02:14:09.453, Speaker A: So here it now becomes a question of if. Let some pending is cell no. Is CM dot pending. Get mute TCPH destination port. Right? This is basically checking. Is anyone listening? Do we have a listener for this port? And only if that is true, do we go ahead and do this. And then we both insert into E and we also do pending dot push back because we now accepted that connection.
02:14:09.453 - 02:14:38.723, Speaker A: So we also push the quad. So let's go ahead and store the quad somewhere. Let Q is equal to this. Then we push the queue to Indicate that this is now a connection that exists and of course in this case to do wake up pending accept. Right. So here we just accepted a connection and it might be that. So currently nothing really blocks.
02:14:38.723 - 02:15:28.829, Speaker A: But if an accept call is blocking, waiting for something to appear in pending, we need to wake that up and we haven't really said how we're going to do that yet. The buffer math can all be in the circular buffer and it would return wood block only if there's not enough room in it. And you can avoid all the locking part as well. Yeah, the problem. So I agree with you, the problem is we will not actually be using wood block. We need to actually block and that's where you're going to need something that's a synchronization mechanism for waking people up. It is possible to do that with lock free data structures, but it is not quite as straightforward because imagine that you, you detect that the if you have a lock free ring buffer, you just sort of do a lock free read.
02:15:28.829 - 02:16:03.239, Speaker A: You notice that it's empty. Now what do you do in order to block? You need to block in such a way that someone else can wake you up when there's data there you can still access. Yes. So you're right that you could totally have a push, you could totally have a polling API if you had a lock free ring buffer, but you could not have a blocking one. Which is what you want or it depends. Right. Like we might want to be able to provide both, but they sort of necessitate different designs.
02:16:03.239 - 02:16:38.417, Speaker A: Even in a non blocking design you don't actually want to be polling all the time. You want to get notifications when you should poll. At least that's how sort of the current Async infrastructure works. And that means that you have to be able to somehow give wake ups. Okay, so here we're going to have to do some kind of wake up and we don't quite know how we're going to do that yet or we have some idea but I haven't told you. All right, let's see how it complains about that. So main in some sense main is just going to no longer exist.
02:16:38.417 - 02:17:51.539, Speaker A: But we kind of want main. Right. And so specifically what we're going to do with main is Main is going to do trust interface new let if is let's I like so and then we're going to do I do listen or I dot bind to port 9000. We're also going to do 9001 but we're not going to listen on any Other ports. And then what are we going to do? Then we're going to thread spawn move this. This is going to do loop or actually this is going to do while that. Okay.
02:17:51.539 - 02:18:47.565, Speaker A: Stream. So this is going to look very similar to how you write networking code, which is sort of intentional because we've. We've built it on top of the same kind of design. Actually, while I remember we're going to have to do impulse drop for TCP listener which I haven't talked talked about yet, basically to stop listening on the port. We're also going to have to do the same thing for stream to basically send a fin. And we're also going to have to do the same for interface, I think because the interface has to tear down the network and stuff. All right, so while there's another.
02:18:47.565 - 02:20:21.555, Speaker A: While L1 accept print line God connection on 9000 and then it's just going to drop it and this is going to be got connection on 9001. Okay, so we have some problems in Source Lib line 80 that returns nothing. Ooh, that's a good point. Yeah, like what happens if this errors if on packet errors, for example, I think we're going to have this return a an IO results. Why is this not okay? Oh, it needs to be a reference. Why is 74 not okay? Because this has to be a quad. Why is this not okay? Because expected nothing found result.
02:20:21.555 - 02:20:56.585, Speaker A: Oh, right. This join handle is now for an IO result. This because that's what the packet loop terminates with. And line 79 doesn't need to be moved. Great. And line 80. Oh, this is an artifact of how the borrowing rules work.
02:20:56.585 - 02:21:29.171, Speaker A: I think we're gonna have to do this for that to work. So the problem here, let me recap that. So it says cannot borrow CM as mutable more than once at a time. Specifically it's saying we're borrowing CM connections here and we're borrowing CM pending here. And that's not okay. It's saying um, and you might think well this is weird. Normally it should realize that these two borrows are of different fields and so why does it care? Like borrowing those mutably separately should be fine.
02:21:29.171 - 02:22:04.667, Speaker A: The reason here is CM is a Mutex guard and because of that, because it's a Mutex guard, we're going to D ref and we're using the D mu trait on CM to give us the underlying connection manager. Right, but. But that D ref borrows the entire Mutex guard. And so here it's really saying you can't borrow the entire mutex guard mutably again, because you're already borrowing it here. So what I'm doing here is basically a reborrow. So I'm. I'm dereference.
02:22:04.667 - 02:22:30.117, Speaker A: I'm doing the deref mute here, which gives me a mutable reference directly to the connection manager as opposed to the. The mutex guard. And then it can distinguish that these are different fields. Main is complaining. Why no method named except found. Oh right. Because we call win and.
02:22:30.117 - 02:23:23.021, Speaker A: And try to try accept. Let's just have it be called accept even though it's not Quite right. Mismatch saying five function body does not return. JH1 is this JH2 is this one join JH2 join great. And then I guess. Okay, so this is a really stupid server, right? All it does is just like starts up two services and then prints whenever it gets a connection. But it is a much nicer interface than the giant main function we had before.
02:23:23.021 - 02:23:45.835, Speaker A: This actually makes the interface look somewhat similar to what the real Rust network interface looks like. Some unused things. That's great. And we want to use also thread here. Cannot borrow. L1 is mutable. That's fine.
02:23:45.835 - 02:24:15.045, Speaker A: Right? And we're not actually using the streams for anything for the time being. And we want to make sure that these threads didn't fail. Great. Okay, so now this compiles. It won't actually run correctly because we haven't implemented the blocking. But this is a good step forward. But let's go ahead and implement the drops as well.
02:24:15.045 - 02:25:00.875, Speaker A: So when. When TCP listener gets dropped, we basically want that to be the same as sort of unbinding, right? Like now we're not going to accept any connections on the port that the TCP listener initially was listening on. And the way that's going to work is pretty straightforward really. It's going to be almost exactly what you expect it to be. We take the lock and then we do cm.pending. remove self port. Right? So this is going to be pending.
02:25:00.875 - 02:25:42.103, Speaker A: And we also sort of want to drop all of those connections. So remember that the code that we wrote in tcp. That's not what I meant. So the code we wrote for the packet loop, right? It gets a packet. If it gets a packet for a quad that it didn't have and that port is currently open, it's going to go ahead and accept that connection. But imagine that this means that you might have. It might have accepted a bunch of connections and then we go ahead and drop the TCP listener.
02:25:42.103 - 02:26:59.605, Speaker A: What do we do about all the connections that have been accepted or that we're about to remove from pending. Well, we sort of need to terminate them and the question becomes how. So down here in the drop this is going to be I guess connection for quad impending and here we're going to have to do some something to shut down or terminate all terminate CM connections quad which is something we haven't done yet. So currently we're going to leave that as unimplemented and that unimplemented is only going to be hit if there are any pending. So this is basically the same as like assert pending is empty except that we get to write out what we want this pattern to eventually be. The drop for TCP stream is somewhat similar in that it is going to do. It's going to take the lock, it's going to remove itself.
02:26:59.605 - 02:27:48.115, Speaker A: Expect and this is a similar kind of expect of actually this this is going to be if let some C. Is that right? Because it could be that the other side has terminated the connection. If the other side is terminated the connection and and we just dropped the TCP stream that's not a problem. It's only if we still have the connection open then we need to do the same thing. We need to terminate this connection. But we probably don't want to sort of forcibly terminate it. We just want to like send fin on this.
02:27:48.115 - 02:28:41.385, Speaker A: So this is similar to this bit down here. This is similar to shutdown. So arguably this could be like self dot shutdown type ordeal because it's basically doing the same thing. I guess we can do this here just to leave the to do for ourselves. All right. And I guess maybe we don't need drop for interface Facebook. Well, so for this when the last.
02:28:41.385 - 02:29:24.275, Speaker A: Oh I see. We sort of want some way to do a clean exit, right? So currently the, this, this packet loop thread, remember we. We spawned a thread to do the packet loop. That loop is just going to keep running forever. It doesn't. It doesn't know when to exit. But if you drop every single TCP stream actually if you drop the interface right if you drop this and you've dropped all the TCP streams and TCP listeners, then we sort of want this this thread to shut down.
02:29:24.275 - 02:29:54.855, Speaker A: So I think what we really want to happen here is. Well, we certainly want to do self JH oh, this is where it gets awkward. Also we want to join Unwrap. Unwrap. We also sort of but then we sort of want to drop self.ih right. The problem is this won't actually work.
02:29:54.855 - 02:31:10.275, Speaker A: But this is what we want to do and then we just want the. We also need to make the packet loop somehow recognize. So maybe we do something like on the connection manager like terminated I'm just gonna be a bool or terminate bool so this is gonna do self IH lock unwrap terminate is true and then we sort of wanna wanna wait for that to actually finish running. The problem that there are a couple of problems with this. One of them is that this might be blocked on this receive right. But here we know that we're going to have a timeout regardless. So here to do set a timeout for this receive for buffers, for timers or for TCP timers or cells connection manager terminate so at least we know that once we fix this to do this receive will eventually return and at that point it's going to recognize that it's been told to terminate and it's just going to terminate.
02:31:10.275 - 02:32:23.745, Speaker A: What exactly it terminating means is another potential problem. So down here we might have something like to do if self terminate well and arc get strong refs or something IH is equal to 1 so that would mean that there's the. The loop is the only thing that still has a handle then tear down all connections and return. So this we still don't really know how to do. But this business is a little tricky because we only have immutable reference to self so we can't drop any of the fields inside of it. And self JH it's a join handle. Join also consumes the join handle.
02:32:23.745 - 02:33:35.945, Speaker A: This is a pattern that you run into in drops that are always a little bit annoying. And so one way to fix this is to have interface be an option. It's kind of sad, but it does work. So it's basically this and so it's self IH take prop and take expect interface dropped more than once. Is there an actor crate you could recommend? I haven't really used any of them as far as I'm aware. Actix is sort of the biggest one. Although Actix they seem to be pretty sort of trigger happy on doing unsafe things and I think that's a problem.
02:33:35.945 - 02:34:54.059, Speaker A: But I haven't looked at it enough detail to really say for sure. Apart from that I don't know of any other actor libraries in the Rust ecosystem. Yeah so we were the. What we're doing here is basically just asserting that drop this option is always going to be some until you call drop then they're going to be none and you cannot call drop more than one ones. This has the unfortunate side effect of uniques everywhere where you want to use the IH. So down here, IH as mute unwrap lock clone 133 IH is going to be sum sum IH and JH is going to be sum JH. Yeah, so there's still a bunch of to dos here.
02:34:54.059 - 02:35:40.477, Speaker A: The biggest to do though that I think we sort of need to fix is this blocking business. Because without that, if we try to run this right now. I mean, I can try, but I don't know that it will do anything useful. Probably break in all sorts of horrible ways. Well, that's interesting. What happens if I do 9002? Actually, let's kill that for a second and run T Shark. So we're gonna start this.
02:35:40.477 - 02:36:38.355, Speaker A: We're gonna run T Shark. We're gonna run first on 9,000. So nothing responded on 9,000, which seems like a problem. Not sure why that is. Yeah, definitely not sure why that is. So something is weird even beyond this. So the packet loop, I guess here got packet for known quad, this for unknown quad.
02:36:38.355 - 02:37:24.475, Speaker A: Listening, so accepting. So let's see what this does. So this says God packet for unknown quad. And it's claiming that no one is listening on that port. Which is kind of weird because main should be listening, right? 9000 and 9001. So let's see what actually isn't pending. CM pending.
02:37:24.475 - 02:38:15.185, Speaker A: Pending is empty. That seems problematic. Why is pending empty? Huh? Bound to 9,000. Let's see that these calls actually return. Oh, they might not create interface. No, it should have bound. So this suggests that our binding isn't working.
02:38:15.185 - 02:39:15.293, Speaker A: Bound. I guess down here we're gonna bound and then print out CM pending. And then I guess just to make sure this doesn't drop drop list listener. Oh, I know what's happening. The listener does get dropped. It's because. Okay, so here's why this thread, these two threads are immediately going to start trying to accept connections on on these TCP listeners.
02:39:15.293 - 02:39:39.471, Speaker A: Except though, remember we haven't implemented blocking, so they're just immediately going to return an error with would block. And so it's going to. The thread is immediately going to exit, at which point it drops the TCP listener. So it's no longer listening on that port. So we do need to fix this blocking issue. So let's go ahead and do that. Let's keep those in for now.
02:39:39.471 - 02:40:38.305, Speaker A: Let's get rid of that and let's get rid of that. Okay, so specifically let's fix fix blocking for accept. Because that is basically the Delta, we have to what we had working before, right? So before you could accept and then it would just end the connection. Now we want to do a little bit better than that. Okay, so the question is for accept, how do we get this block to work? Right? Like this is our nemesis right now. And the way we're going to do that is we're going to use what's known as condition variables. So a convar is basically a way to block a threshold thread while waiting for something to happen.
02:40:38.305 - 02:41:20.145, Speaker A: Let me make this a little larger. And so the idea is that you're going to take a lock, you're going to check a condition, and if the condition is not true, you're going to wait on a condition variable that someone else is going to notify you when changes and then you're going to check if the thing is now true, otherwise you're going to wait again. And so the basic pattern is sort of like this. You take a lock, right? You take a lock, you check whether the condition is true. And while it is not, you wait. And the wait implicitly releases the lock until the condition is true again. So here we're going to do.
02:41:20.145 - 02:42:24.811, Speaker A: This is going to be loop or this is going to be. Yes, it's going to be a loop. So this blocking is going to be. So we're going to need a condition variable somewhere. But here we're checking the condition and if the condition is not true, we're going to take CM pending var and give it the CM and say CM is equal to that unwrap. Right? So this pattern is basically we're going to keep releasing the lock and blocking until someone tells us we should wait up on this. Now, there are a couple of ways in which we could implement this.
02:42:24.811 - 02:43:13.125, Speaker A: We could have a single condition variable across all TCP listeners. But that's probably not what we want. We probably want sort of a condition variable per. It might not even matter because the lock is global anyway. But let's go ahead and make this pending variable be per port. So now what we're going to have is in the connection manager, instead of having pending, just be this, we're going to have a pending which is going to have a VEC DQ quad and also a condition variable. And the restrictions are each convar can be used with precisely one mutex.
02:43:13.125 - 02:43:53.575, Speaker A: And I assume that you can use one mutex with multiple convars. They don't say anything to the contrary. So yeah. Okay, great. So this is also going to hold a convar. So it's going to Be. This is going to be quads and this is going to be var, I guess.
02:43:53.575 - 02:44:14.675, Speaker A: And so pending is going to hold a bunch of pending. Does this implement default? Sort of. Hope so. Great. Okay, so this is going to derive default. Let's see whether that. What fails to build right now.
02:44:14.675 - 02:45:14.925, Speaker A: So this is going to be dot quads, right? And this is going to be. Actually, let's do this this way. I don't know if that's okay. I wonder whether the mutex has to be stored. The convoy has to be stored outside of the mutex. Yeah, it does, doesn't it? Well, that's kind of awkward. Can I clone the convar? No, I can't.
02:45:14.925 - 02:45:53.647, Speaker A: Can I? So the issue is we need to. When we wait on a convar, we need to give it the mutex guard. But if the convar is inside what the mutex is guarding, then we can't give it the mutex guard because that would give up our handle on the. On the var. Interesting. Interesting. That tells me that we're gonna do this in a.
02:45:53.647 - 02:46:41.725, Speaker A: This is still gonna be a slightly stupid way to do this, but. So we're gonna have struct and. Oh man, don't know what to call this yet. I'm gonna call it foobar for now and we're gonna change that name quickly as we can. So it's going to have this, the sort of manager which is going to be the mutex and it's going to have a pending var, which is going to be a convar. It's going to have a receive var, although we're going to ignore the other bars for now, but eventually it's going to have those. I don't know what the FUBAR is going to be called yet.
02:46:41.725 - 02:47:31.825, Speaker A: The reason we want to do this is because it means now. So this is going to be self h manager lock and down here we're going to do CM is self h pending var waitcast. Right. So this is now waiting on the pending var is now just in the. In the thing that we have an arc to. It is not inside the mutex itself. Yes.
02:47:31.825 - 02:48:11.693, Speaker A: Which means that this now goes back to being a VEC DQ quad and this is no longer Quads 286. So this now needs to be manager. This needs to be manager. This needs to be manager. This needs to be manager. This needs to be manager. This needs to be manager.
02:48:11.693 - 02:48:40.685, Speaker A: This needs to be manager. This needs to be manager. Great. We need sync convar. The reason it's a little sad to have one convar for all pending is that now you have to notify basically all the TCP listeners whenever any connection is received. So we might want to try to do better than that. Drive defaults.
02:48:40.685 - 02:49:12.991, Speaker A: Great. So now of course, now we have the. Now we have accept. We have a way for accept a block and the loop is going to make sure that even if we get woken up and it's not for our connection, we're just going to realize that this is still not the case and so we're going to block again. The problem of course is we have to have something that notifies us to wakes us up when this, the pending state changes. Right. And that's going to be here in the packet loop.
02:49:12.991 - 02:49:39.995, Speaker A: Right, the packet loop down here. Once it realizes that it has woken, that it has added a pending thing, it is going to have to do essentially. I mean this is why we have this to do here. Right. So this is going to be doing ih.pending var. Notify.
02:49:39.995 - 02:50:18.881, Speaker A: So if you look at convar, it has. It has wait wait till. Which we don't actually need. Not wait timeout not wait timeout not wait timeout notify 1. I think we need. So unfortunately currently we need notify all. So this is going to call IH pending var notify all and we're gonna.
02:50:18.881 - 02:51:19.655, Speaker A: Before we do that we are going to drop the cm. Well that's awkward. We really want to drop the lock here. So I think this is going to be GG drop CMG because we want to drop the guard so that we release the lock so that when these things that are notified are woken up, the lock will already have been released. Oh hey, that compiled. How about that? So let's see what happens now. If I connect to 2000 illegal instruction.
02:51:19.655 - 02:51:56.273, Speaker A: Wow. Not yet implement. Okay, so this got packet for unknown quad but it's listening on 9000 which is what we wanted. Then it got another packet for a known quad. There was a connection on 9000. I forgot to run T Shark and then it ran into not yet implemented online 222 which is dropping the TCP stream and dropping the TCP stream. Currently we're just going to sort of ignore because we know that our underlying TCP implementation currently it will just send a fin immediately.
02:51:56.273 - 02:52:37.463, Speaker A: If you remember this from part one, we set it up such that the moment it gets a connection it sends fin. It just goes I'm done, I'm done. And so we don't actually need to do this yet, but we do want this to eventually happen. So let's Try that again. Start this this time and try to connect. So that's interesting. Oh, this is like a, an old leftover.
02:52:37.463 - 02:53:13.245, Speaker A: Let's, let's run that again. Wait, why is it getting packets for 9,000? That's unfortunate. Oh, it's like the kernel still hanging behind. So that's kind of annoying. So let's have it bound to a different port. Let's just say that it now listens on 6000 and let's get rid of some of this other stuff. It's not terribly important for now.
02:53:13.245 - 02:53:39.227, Speaker A: All we want to see is that this interface works. Okay, so currently it's not getting anything weird. Start. This is now weird traffic going on and we're going to connect on 6000. So it got. It still gets some old packets from 9,000. This is because we didn't shut down that connection correctly.
02:53:39.227 - 02:54:04.101, Speaker A: So the, our Linux kernel is still trying to close that connection. We're just going to ignore that, but we're going to connect on 6000, which is where we're now listening. So 6000 connects. Okay, so we got a packet for the unknown quad 6000. We're listening on that port. Great, because we bound to it. We got a packet then for that and now we say we got a connection.
02:54:04.101 - 02:54:52.085, Speaker A: So this is the setup. Think of this as this is the sin. This is their ack of our SYN ack. Then we got the connection and then this down here is we drop the TCP stream and so therefore the we get rid of the quad, which might not be what we want. So it sent sin, we sent syn acknowledge, it sent ac, we sent finac, it sent ac. Great. So we have closed the outgoing connection.
02:54:52.085 - 02:56:16.481, Speaker A: It hasn't closed the connection to us because I haven't told netcat to stop sending stuff yet. But it did drop the connection because we dropped the stream, which is not really what we wanted because it means that if I now send this, it will just get very confused about the state. So maybe how do we want to do this? Even basically when the TCP stream gets dropped, it's unclear, we really want to forget about it straight away. Drop for TCP stream specifically. I think we don't want to do eventually remove from CM connections, right? Because even after the user drops the TCP stream, there's still a bunch of handshaking that needs to go on. Right? Like the we when we drop the TCP stream, all we're really doing is sending them a fin. They we still have to wait for them to act that otherwise we might have to resend the fin.
02:56:16.481 - 02:56:52.375, Speaker A: And so we don't want to get rid of all the TCP state for that connection until we really know that all the that the peer knows that we shut down. And so therefore we don't actually want to do anything when we drop the stream except for send the fin. And currently we don't have a good way to do that. We do that automatically. So currently we do nothing in drop. So let's go ahead and try that and make that 7,000 this time. All right, so now we're going to connect on 7000.
02:56:52.375 - 02:57:22.765, Speaker A: Okay, so notice now we didn't get any packet for unknown connection after here because we didn't drop. And so now we see the same pattern. Netcat sent syn. We responded with syn ack. It responded with ack to our sin. We immediately send a fin ack and they ack are fin, but they have not sent a fin yet. I can then terminate netcat without sending any data, at which point it sends a finack and we ack.
02:57:22.765 - 02:58:09.863, Speaker A: And at that point the connection is done. Now, notice the kernel isn't doing any retransmissions or anything. It's totally happy with everything just worked out. It really does think that this connection is shut down and we can check this with tn. So there are no connections listed for the tunnel, right? Whereas if you look at if I did this, then now there's a connection listed here, right? Because it hasn't been shut down yet. It's setting close weight because the other site has closed, but we have not yet closed. Once I terminate this, this now closes and the connection goes away.
02:58:09.863 - 02:58:51.483, Speaker A: So that means the entire sort of pipeline now works. And also notice that the this means that accept blocking is now working, right? The accept blocks when we try to do accept and then it gets woken up when there's a connection available. So that is exactly what we wanted to happen. Of course we haven't implemented any of the sort of read or write stuff. We haven't implemented any of the read or write stuff. Let me think a little here. So we have implemented read and write, we just haven't like this incoming buffer and the out the an act buffer are just currently entirely unused.
02:58:51.483 - 03:00:03.847, Speaker A: We are writing data into it and reading stuff out of it. But. But that's all. Maybe we should fix this, because that should be possible to detect specifically in some sense. What I want here is I want the following code to work, stream, dot read to like whatever, it doesn't really matter and then assert E n 0. So basically this is making sure that we can do a read. That read will block until the other side has shut down the connection.
03:00:03.847 - 03:00:39.225, Speaker A: And we're just checking that we only ever get no data. So let's see if we can get that to work. I think we will probably not do all data read and write in the stream. This is more sort of infrastructure stuff for getting the stream in the right place, getting the project in the right place, but being able to block at least on there being no data for you to read or the connection has now been terminated seems useful. So specifically that's this to do here in read. Right. Where I guess it's also this to do in block.
03:00:39.225 - 03:01:28.805, Speaker A: From what language did you come to Rust? So I've worked on a bunch of languages before Rust. I think the biggest ones for me were probably go but I've done a bunch of different stuff. I've done a bunch of C programming too and like C. Okay, so for read we basically need to fill in these two blocks. Right. So let's look at our. Actually before we do that, let's do this add nice net like interface main.
03:01:28.805 - 03:02:50.585, Speaker A: Let's go back to. Right, so now this is the code we sort of want to work. So let's look at how our TCP code actually deals with fins. So on packet is really the tricky part. So here is when we get a fin from them so then we know that any subsequent read. Yeah, there's a weird synchronization thing where Twitch people can see the YouTube chat, but the YouTube chat cannot see the Twitch chat. I don't know why, sadly.
03:02:50.585 - 03:04:18.375, Speaker A: So this is the point at which we receive a packet that has a fin and at that point we know that there's just like no more data and I guess in theory. Oh, let's pull up the state diagram actually from tcp. The where is it? No, no, here we go. Okay, so at some point we receive a fin. So here we receive a fin and here we receive a fin and here we receive a fin. So what that means is if we are ever in the states close wait closing or time wait or of course last ack or closed then we know that we're done. So what we're going to do is on connection we're going to have a pub crate offender.
03:04:18.375 - 03:06:19.031, Speaker A: I think what we want here is a sort of like is close is receive closed and that's going to be if self dot state. I guess if let state time wait is equal to that to do this is also close weight or last ack or closed or closing. Those states also imply that the other side, any state after received fin. So also those which we have just haven't implemented those states yet and otherwise calls false. And so now this is going to be. If C dot is receive closed, end that. So if the receiver is closed and the incoming is empty, then we know that there's just.
03:06:19.031 - 03:07:27.235, Speaker A: We're done, we can just return, okay, zero, right? No more data to read and no need to block because there won't be any more. Right? Like we received a fin and so we know there's no more data coming from the other side. The tricky part is still, of course is if incoming is empty, then we do need to block and we need to figure out how to do that. We're going to do it in a similar way to what we did for Accept, right? So if you remember Accept, we now have this sort of loop down here and so this is going to turn into a loop that is probably going to end up being weird. This is going to be a loop, it's going to return this and continue. Actually we're do. We're going to do it the other way around.
03:07:27.235 - 03:08:09.615, Speaker A: We're going to say like, so if there is, if we're done, then we return zero. If there's data, we return that data. Otherwise we have to wait. And of course this is not going to be a pending var, this is going to be a recession. Receive var. And so now you see why this is sort of problematic, right? You see why having one cond var for like all of the connections is problematic because it means that if any data arrives, we need to wake up anyone who's waiting, which can be pretty costly. So we might want to find a way to sort of split this, split it up so that we have one convar per connection.
03:08:09.615 - 03:08:42.105, Speaker A: But for now let's not do that. So we're going to have a pending var and a receive var. And now so if we do cargo check, that should compile. Why did it not compile 11 mute stream. That's fine. Okay, so that now compiles. But of course, currently no one is ever notifying on the receiver and so if we wait on it, we're never going to be woken up.
03:08:42.105 - 03:09:40.465, Speaker A: That does get a little bit tricky though, because now how do we know whether to wake someone up? Well, we know that it would have to be on packet, so we sort of need on packet to return something telling us what to wake up. So let's go to TCP and find our FN on packet. So currently that returns an IO result, nothing. I think what we're going to have to need to do here is this is going to have to be now ready. So we're going to have to do a pub crate enum now ready and it's going to say whether read or write is now ready. So roughly make sense. So when you call on packet could also be none.
03:09:40.465 - 03:10:24.735, Speaker A: So when you call, when you. When we pass in here a packet that we received, it's going to report back whether the this particular connection is now available for reading is now available for writing or neither or maybe both. Actually let's instead of having it say ready this should be. It's almost like available. So that's going to be available for read. For write. For read write and none.
03:10:24.735 - 03:11:34.403, Speaker A: And so we're going to match on that. And if it is read actually let's. Yeah, if it is read then we are actually let's do this Availability is this if let. What do we call it Available TCP available read or TCP available read write is equal to A. Then check compare before after. I'll explain that in a second. So if read.
03:11:34.403 - 03:12:23.797, Speaker A: If it's now available for reading then we are going to do what we did down here, which is we're going to. Well, regardless, we're going to drop this. We don't need that anymore. Then we're going to notify all in the receiver. If it's available for writing then you could imagine that we're going to do something like send var, right? Currently we don't have such a var, but you could imagine. The reason I want to compare before after here is if it was available for read before this and is available for read after this, the there's no reason to notify anyone, right? Because it was already available for reading. But that is a performance optimization.
03:12:23.797 - 03:13:42.687, Speaker A: It's always safe to notify. So we're going to just notify for now. Of course that's going to break a bunch of stuff. Specifically I think what we're going to want to do here is anytime we're about to return, okay, we need to actually do like self availability. So on connection we're going to have a FN available self that's going to return available and A is going to initially be available none. If I guess if self is received closed or self dot incoming is not empty then A is going to be available read. This is a bitmap.
03:13:42.687 - 03:14:25.805, Speaker A: I want a bitmask crate. What is the bitmask bit? Bit flag. Bit flags. But it's not bit flags that I want. What maybe it is bit flags yeah, except I don't need it to be that I need. I want like flag flags. Anyone remember the name of this crate? The one that gives you basically a way to or together enums.
03:14:25.805 - 03:15:05.395, Speaker A: I feel like it's bit flags. Bit mask I mean maybe really is just bit flags. I mean I don't particularly want. All right, fine, sure. Bit flags. Bit flags it is. So we're going to depend on bit flags is 1.0
03:15:05.395 - 03:15:32.665, Speaker A: and then down here we're going to say that instead of having available be an enum, it's going to be one of these. So structure available. It's going to be a const read. This can be a U8 const write. So I guess 1, 2, 3, 4. No. Yes.
03:15:32.665 - 03:16:22.315, Speaker A: No binary. What am I on about? Yep, that way we don't need these. And now this is going to be. So what does this give me? Great, that one. So I want empty I want a or equals available read and we don't. This is going to be like a to do set available. Right.
03:16:22.315 - 03:17:41.325, Speaker A: And then it's going to return a. And now up in Libworld we're going to say if a.iss is it ISSET? I guess just or TCP available read and this. So does this have a bit. And why doesn't this have an isset? Because that's really what I want. Oh, contains. That's what I want.
03:17:41.325 - 03:18:43.785, Speaker A: Contains this. How do you create unique types in Rust? What do you mean create unique types? All right, let's see whether that compiles. Probably not. This needs to use bit flags flags available as private. This has to be Pubcrate 285 so this has to be self availability. This probably has to be the same. And this has to be the same.
03:18:43.785 - 03:19:35.133, Speaker A: There are also some questions here about whether to do take into account self state. Right. Although this check might be enough for read I'm not entirely sure. It might only have to be taken into account for write 238. Oh no, this should not be public. Alright, let's try that out for size. Well, like closures, they are really unique because their type is created by the compiler.
03:19:35.133 - 03:20:12.183, Speaker A: Except they're probably a clone copy. I'm not sure what you're referring to. So. Oh, you want type that the compiler names for you. I don't think there's. I mean arguably enum variants that are structure sort of like this, but you can name them, they just have other names. I don't think there's a good way to do that.
03:20:12.183 - 03:20:36.065, Speaker A: No. What were you thinking? That you would use such a type 4. It's almost like a. Like an anonymous type. Okay, so we're running and in theory we should run this. And now let's see what happens if we try to connect. All right.
03:20:36.065 - 03:21:24.295, Speaker A: All right. Oh, we forgot to change main to actually print. Oh no, it should have printed red data. It did not. So something is broken. It sent a fin ack, but we did not think that we read any data. So why is that the case now available for reading? Okay, so that would be the hope that that prints out.
03:21:24.295 - 03:22:33.223, Speaker A: Then it should notify. So I guess the other thing is read. Checking on status or read I guess trying read no more data. Status is this. This is received closed and C Incoming is empty, not yet block. So let's see it tries the read, it gets false true. So this got packet for known quad.
03:22:33.223 - 03:23:11.275, Speaker A: Why does it not print anything useful? Specifically it doesn't say this. So that means on packet is not returning read set. Yeah, I don't think there are anonymous types in Rust yet. I could be wrong, but I don't think so. So this means that A does not contain available for read. What does it contain? Availability. A and I'm sure it's going to complain about the port.
03:23:11.275 - 03:24:28.313, Speaker A: So let's do a different port if I do this. Availability empty. Right, that's what we expect. Now this, it still says availability empty even after I terminated the other side. So the question is why? So now we need to look into here and look at availability and the question becomes why is this not returning true? See computing availability. So it should be available for read either if the channel is closed so or either if the other side has sent a fin, in which case we should be in the time wait case or if incoming is not empty. Although we're currently not writing anything to incoming.
03:24:28.313 - 03:25:22.971, Speaker A: So this should always be true. No, this should always be false. This so without the exclamation mark should always be true, but this should always be false. So this means that where this is not returning true, make sure that this has debug asked if closed when in self state. Okay, that's fine. And now end that. Okay, so asked if closed when in fin weight 1.
03:25:22.971 - 03:25:57.295, Speaker A: So in fin weight 1, fin weight 1 is the state where we have sent a fin and it has not yet been act. This is the ack for our fin. So now we're in Finway 2, which is we have sent a fin and it has been actual but they have not yet sent a fin. And here the reader is blocked because, well, there's Nothing for them to read. Specifically closed is false and empty is true, at which point there's nothing to read. So it's blocking. Here is what we get the.
03:25:57.295 - 03:26:53.395, Speaker A: This is where we get the fin. So why is it not transitioning? That's really what's wrong. So we're in Finway 2 and we just received the fin. So why, oh why are we in fin weight 2? That seems wrong. Because that last packet is the fin ack and that fin ack should move us from Finway 2 into time weight because we received a fin. So why is that not the case? Well, guess it's time to figure that out. Not okay, could be one case.
03:26:53.395 - 03:28:11.045, Speaker A: No ack could be another case. Otherwise bad secular state. Okay, so hopefully we get down here, but it doesn't really seem like it. So I guess let's go back to, I don't know, seven. Okay, so the pattern is pretty much what we expect. So the packets are always the same God packet bad sequence. That's probably wrong.
03:28:11.045 - 03:28:42.855, Speaker A: I don't believe you. That that has a bad sequence number. So it's saying that this is a bad sequence number, which seems incorrect. And then it's saying that the second one does not. The second one is not okay. All right, so let's figure out what's going on here. Specifically, it's saying that the first one is not okay.
03:28:42.855 - 03:30:23.625, Speaker A: I'm almost sure that the is between wrapped that has been updated is wrong. But so okay is being set to false. So where is it being set to false? Good old print debugging. 2, 3, 4 and then the 1 oh no, the first one said bad sec which is here. So this should be self send una ackn self send next wrapping add one and and main to 8,000. Okay, so all the initial packets seem to be fine. And it's saying this is a bad sec.
03:30:23.625 - 03:31:44.737, Speaker A: 2 less than 2 less than 3. What's the requirement for that? Again, this is for. The requirement is that this is less than this is less than or equal to that. So this is a bad act. 2, 2, 3. But how I see. I don't think that's okay.
03:31:44.737 - 03:32:55.237, Speaker A: So we're failing this check for this incoming packet. And this is saying that the ack number in the packet which is like the sequence number the other side expects next has to be greater than the last thing we haven't heard act. Why? Something's not right. So this is in when you receive a packet. Right. Event processing. So we specifically want segment arrives if you remember from the previous stream at the bottom of the, of the TCP spec, there's a basically a state machine that you can follow.
03:32:55.237 - 03:33:36.791, Speaker A: And what we're looking for here is if we're in established fin weight or one or fin weight two. So that's this. All right, so this is the acceptability check. And the acceptability check we already. Is already fine. Yeah. So this, this is not the check we're failing.
03:33:36.791 - 03:34:49.805, Speaker A: We're failing the ack field ac bid is on and we are in established fin weight 1 or fin weight 2. If this is really just saying that only if it's between here do we update which things haven't been acknowledged. But we shouldn't stop processing just because of that. Right? Accept data. So if what we get is an unacceptable act, that doesn't mean that we shouldn't handle the packet, it just means that the act shouldn't be used to update our tracker of how much data the other end has received. So for example, we might still want to process the fact that they sent us a fin. Right.
03:34:49.805 - 03:35:35.435, Speaker A: And crucially we don't want to return. Great, let's try that. Yeah. So we get the packet, we notice that it's a fin, we compute the availability, we notice the availability is read because it's now been fin. So we're now setting ourselves available for reading. That wakes up the thread that blocked when trying to do a read. And it recognizes that it can read.
03:35:35.435 - 03:36:15.685, Speaker A: It reads the data, it gets the zero. Excellent. Okay, let's get rid of some of these here. Don't need these anymore. Actually let's keep these because those are probably going to turn in handy. We might want to add like a logging library that we integrate with this because otherwise debugging this is going to just keep being a pain. Connection, turn, connection close, no more data.
03:36:15.685 - 03:37:04.341, Speaker A: Great. So this is still sort of stupid, right? This is still we're trying to read zero data, but at least it means that we can correctly detect when there's no more data coming. So what do we have now of like eprints and stuff? Oh right, we probably don't want that E print bad protocol. Probably want that, probably don't want that. That's fine. Right, so this is still broken, but broken just in the sense that we never write anything to incoming. Right.
03:37:04.341 - 03:37:31.929, Speaker A: So remember from TCP we have this. Assert the data is empty. So if there, if the other side tries to send a data, we're just going to crash anyway. And so that's fine. But the infrastructure we have here should in theory now be enough that we should be able to do reads. And reads are probably easier than writes because reads don't require any retransmissions. Sort of.
03:37:31.929 - 03:39:06.305, Speaker A: You need to retransmit X. But we'll get back to that later. Yeah, okay, so let's go ahead and commit that for fin. All right, let me push that out. I think we might actually want to end it there. I don't want to dive into doing all the timer and data stuff this stream because I feel like this is sort of a nice termination point for cleaning up the entire external API. So I think we're going to end it there and that way we can leave sort of the data aspect of this and sort of that includes things like congestion, window sizes, timeouts, that sort of stuff to cover that entirely in the next stream.
03:39:06.305 - 03:39:38.215, Speaker A: I think that's what we're going to do. I've pushed the code that I have so far, so feel free to sort of play around with it, I think. Yeah, so we'll leave it there. And the next stream, as I mentioned at the beginning, will not be until early May, sometime. I don't know exactly when, but sometime early May. So I guess stay tuned for that. We still haven't figured out a name for the stream.
03:39:38.215 - 03:40:07.015, Speaker A: I'll stick around and chat a little bit after I end the video. But if you have thoughts for, first of all, whether it should. Whether there should be a name, whether there should be sort of a dedicated Twitter account or something like that, and if so, what you think it should be called, then feel free to ping me. I genuinely want, like, potential names for this. But in the meantime, take care, enjoy the start of spring, and I will see you in May. Bye.

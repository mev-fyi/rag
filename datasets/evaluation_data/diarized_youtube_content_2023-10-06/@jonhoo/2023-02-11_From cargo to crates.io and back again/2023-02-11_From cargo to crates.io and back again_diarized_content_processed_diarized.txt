00:00:01.640 - 00:00:47.741, Speaker A: Hi folks, welcome back to another Rust stream. This time it's going to be probably a longer stream and we're going to tackle more of like an implementation problem as opposed to, you know, the crust of Rust style teaching. There are a bunch of these on my channel too, so go look at some of the other ones if you're curious. Unlike many of the previous implementation streams, we're not going to port anything this time. We're just going to write a Rust thing from scratch. And in particular the I don't want to say problem we're going to tackle, but the domain we're going to be working in is how Cargo talks to registries. So, you know, the most well known registry is Crates IO, but Cargo does support alternative registries as well.
00:00:47.741 - 00:02:25.171, Speaker A: And we're going to talk a little bit about how when you run Cargo Publish on the command line, what happens and what's the code path that takes the source you have locally and sends it to Crates IO or to another registry, what happens at that registry? And when someone runs Cargo Build and has a dependency on your thing, how does it get fetched from the registry? And in particular, the reason we're going to talk about all this is we're going to implement basically that loop. And when I say implement, it's not so much that we're going to implement the low level logic of how to issue the HTTP requests, but rather I want to look at the data structures that are involved along these steps and the conversion between them. The reason I want to do this is because currently the definitions of those data structures and the conversion between them lives in a bunch of different crates and a bunch of different, just arguably not even crates, just different repositories that don't really interact with each other. So they don't share that logic, they don't share the definitions. And that both means that there's a potential for them having mismatches between them, but it also means that they don't get to take advantage of knowledge of how the other parts of the system work. So as an example, on Crates IO, when a crate is published, there's metadata the cargo sends along with that publish that includes things like the name of the crate and the version of the crate that's also contained in the file that Cargo uploads. And at the moment Crates I.O.
00:02:25.171 - 00:03:40.013, Speaker A: doesn't actually check that these two are the same and that could end up with just weird things getting in the index or, you know, it doesn't basic sanity checking, but it's just, it would be Nice if Crates IO could just, you know, do these checks. One of the reasons why it would be nice is imagine that over time, Cargo starts sending more information along with the Cargo publish, then you may want to backfill for things that were uploaded before Cargo started, including that information. And in that case, Crates IO basically wants to rerun the Cargo logic. But currently that logic is just entirely contained within Cargo, and it's not in a place where Crates IO can really get at it and rerun it. And so we're going to take a look at the components involved and try to see if we can construct one crate that can be used by Cargo, that can be used by Crates IO, and ideally, they can be used by other registries as well that may want to essentially implement an index themselves. Okay, so let's see where we start. We're going to start by talking about the Cargo side of things.
00:03:40.013 - 00:04:29.125, Speaker A: So when you run Cargo Publish, what happens? Well, really what happens is two things. First, Cargo runs Cargo package, and then it uploads Cargo package to a particular endpoint@cratesio. And we can look at this if we look at the Cargo book. That is the wrong part of the Cargo book. We want to look at publishing on Crates IO. And I don't want to look at the user guide, I want to look at Registry, Registry Web API publish. So we'll talk about Publish in a second.
00:04:29.125 - 00:05:19.319, Speaker A: Let's talk about Cargo package first, because it runs first. So when you run Cargo package, what happens is, effectively Cargo just takes your entire source directory and your cargo toml. When I say source directory, I don't mean src, I mean the entirety of the thing that contains your cargo toml and the files next to it. More concretely, it's everything that's in your Cargo TOML include directive, not things that are in your exclude, and by default, everything next to Cargo toml except things that are in your git ignore. The default rules are weird, but basically it creates a tarball. So a compressed archive, a zip of all those files, and renames that into a Crate file. So, in fact, you can find these on your computer.
00:05:19.319 - 00:06:09.813, Speaker A: So if we check out Cargo Registry cache. Actually, no Cargo registry source GitHub, that's the extracted ones. So I want cache GitHub. Let's ls that okay, so at this path, and we'll talk a little bit about what this means in a second, this is where Cargo will download the crate files for any dependencies that you take. So these are hosted on Crates IO and they are the result of The CARGO package that was run when Cargo Publish was run for the appropriate version. So let's look at some random one of these. Like, let's look at the zip 7.0
00:06:09.813 - 00:06:49.097, Speaker A: crate. Okay, so if we run file on this, it's just going to tell us this is gzip compressed data. And you know, it's a dot crate file, but really it is a tar GC file. And we can look at this like if we run tar TZF of that file. You see, it tells us these are the files that are inside of that archive. And the files here are not terribly surprising. Those are files from source files from benches, the Cargo toml, the Gitignore license and readme.
00:06:49.097 - 00:07:11.965, Speaker A: This is a CI file that just isn't excluded and therefore is included. There are two files that are weird here. There's cargotoml.org which we'll talk about in a second, and there's the cargo VCS info. And if we do this, let's see if I actually remember TAR commands by hand. It's a little unclear. X.
00:07:11.965 - 00:07:39.389, Speaker A: Oh, what's the one for printing it to standard out? I think it's just O dash. I think I can just do dash. O dash, dash, O dash. Great. Oh, maybe I don't even need the dash. I can just do this. Sweet.
00:07:39.389 - 00:08:31.681, Speaker A: So this prints out just the contents of that file within that archive. And you see the stuff that's in here is just the. The SHA one, the git hash of the commit that in this case, this is my crate. So the commit that I was in when I ran Cargo Publish, that published this version of zip, this is essentially metadata about the context in which the publish happened. There's no guarantee that my directory wasn't dirty or that I even pushed this commit anywhere, or that this is even accurate. But it's there. And if we look at Cargo toml, orig, this is the cargo TOML that was present when I ran Cargo Publish for this package version, no modifications, hence the file name orig.
00:08:31.681 - 00:09:20.415, Speaker A: Here it is the original Cargo toml. And that gives us to what is this other file? That's cargo toml, but not the original. And the answer to that is, and you'll see this at the top of any such file, that this file is automatically generated by cargo. It's essentially a normalized CARGO TOML that removes the use of a bunch of features that are available to Cargo more broadly, in part so that the thing that you publish only uses a much smaller set of features for Cargo. So it's more likely to compatible with older versions of Cargo for people who want to download it. And it also has some other modifications, like it removes workspaces, it makes sure that there are no path dependencies in there, no patch statements. So essentially it's sort of a cleaned up version of the Cargo toml.
00:09:20.415 - 00:10:05.953, Speaker A: This might be a thing that we want to stick into this crate that we build that essentially goes from a cargo package directory to a crate file. I'm not sure though, whether that's the part we want to include here. We might want to say that our thing is limited to going from, from a crate to the registry. Okay, so that's all the stuff that happens when you run Cargo Package. It really just generates this file, which is like it modifies the Cargo TOML slightly. It generates this VCS file and then it tars it all up and renames it to Crate. And you can test this yourself.
00:10:05.953 - 00:10:58.763, Speaker A: Like if you're in any given, even in any given crate directory or Cargo package directory and you run Cargo package, it'll do this for you and it'll tell you where it placed your crate file, which is going to be target package name version crate. And you can look at it and see what's inside. It can be interesting sometimes. For example, you might look inside and discover that, oh, there's a bunch of files in here that I've just forgotten to exclude that are only used for CI or something. And you can actually make your crate file much smaller, which is going to make publish faster and it's going to make users on the other end happy as well. Okay, so I said the cargo publish is really equal to Cargo package, plus some kind of curl, effectively, like something that sends it to the actual registry that you're trying to publish to. And that's when we get back to this publish endpoint that registries have to implement.
00:10:58.763 - 00:11:57.243, Speaker A: The endpoint is the crates IO slash. And then this or whatever your registry might be, you do a put, you include some tokens that say that you're allowed. That essentially authenticates you to Crates IO. And you know, it stipulates that the server should validate the crate, make it available for download and add it to the index, and we'll talk about the index in a second. Now, the body of the data sent by Cargo is an integer of the length of the JSON data, metadata of the package as a JSON object, then an integer of the length of the crate file and then the crate file. So the body of the request is essentially a manually encoded multi part HTTP message saying The JSON is this long, then the JSON, the crate file is this long, and then the crate file, all as part of the body. And the crate file is well defined.
00:11:57.243 - 00:12:49.615, Speaker A: It is just a tarball. This metadata, though, is a type, it's a structure, and in fact it's outlined below here. What includes the following is a competent example of the JSON object. And so you'll see there's the name, there's the version, there's an array of direct dependencies and various information about those dependencies, features, authors, and a couple of other fields that are also included. And if you squint at this, you sort of notice that this is really just the same stuff that's in the Cargo TOML in the crate file, which makes you wonder, why is it also included here? And this gets to part of the reason I want to make this crate because much of this is redundant. It's totally possible to generate this JSON solely from a crate file. And that's one of the things that we're going to implement.
00:12:49.615 - 00:13:43.101, Speaker A: My guess is it was done this way so that the remote server doesn't have to also extract the whole crate file and parse Cargo TOML and all of that stuff, and instead they can just parse its JSON, which has all the info. But the crux of this gets back to the server should validate the crate, right? Because realistically what that means is you can't trust that the JSON matches what's in the crate file, certainly not for the name of the version. So you have to do at least some parsing of the cargo tunnel, at which point maybe you should just do the whole thing. And that's what we're aiming one of the things that we're making to do easier here. In fact, I don't think there's anything in here, at least at a first glance, you can't get from the cargo tunnel. And then there's information about the responses. We're not going to care about the response.
00:13:43.101 - 00:14:09.993, Speaker A: Our job here is just to be able to take a crate file and produce this JSON and also to have the definition of this JSON. Now, there is a crate that already provides this. I apologize for the brightness. I'll save you twice in a row here. So there's a crate called Crates I.O. or Crates I.O., I guess, which has just the definitions of each of these API types.
00:14:09.993 - 00:14:35.705, Speaker A: Now, this crate, as far as I can tell, isn't actually used by Crates IO. It is intended for those who want to look like Crates I.O. or want to talk to Crates I.O. why it's not used by Crates I.O. i'm not entirely sure. It might be because it has a bunch of other stuff in here like curl and URL. Because it also implements the talking to part, which obviously Crates IO doesn't need.
00:14:35.705 - 00:15:04.683, Speaker A: Which is why I want the crate that we build to really be standalone. It's not intended to be doing network stuff for you. It is just the definitions of the data formats and the conversions between them. Okay, so the thing you're going to see here in particular is the new crate type, which has all of these fields that we just looked at in the JSON here. So this type is one that we're going to end up replicating in Arc Crate. We could even re export this one. All the fields are pub.
00:15:04.683 - 00:15:52.629, Speaker A: So there's no reason for us to split the ecosystem unnecessarily here. But I would rather do it the other way around where that crate takes the dependency on our crate because I don't want R Crate to take a dependency on this crate and then bring in all of this curl stuff, for example, that feels like unnecessarily expanding the dependency graph. I'm hoping that R Crate will only really take a dependency on SERDE and maybe nothing else. But we'll see. Maybe this error, I haven't decided yet. We'll see how that pans out. Okay, so you're in Cargo Publish, which does a cargo package, which we talked about, and then it runs sort of curl put, which is putting this JSON to the server.
00:15:52.629 - 00:16:53.793, Speaker A: What does the server do in response? Well, that's entirely up to the implementation of the registry on Crates IO, it goes into a database, and in addition to going into a database, it also goes into a git index. So the Crates IO index, which is to say the thing that Cargo actually talks to discover which versions exist of which crates is at the moment a git repository. And you can look at it on GitHub. It's this git repository right here. So whenever you run Cargo Update or something like it, and you see updating. What is this? What's it say? Like fetching Crates IO or updating the index or something like the thing that gives you the progress bar that's annoying to wait for and sometimes takes a really long time, what it's really doing is it's doing a git pull from this git index. And if we look at the commit history, you'll see that there's just endless commits of updating crates like this thing.
00:16:53.793 - 00:17:29.493, Speaker A: This basically means Someone ran Cargo Publish of the pub crawl crate version 0.1.0, and as a result, that caused Crates IO to trigger a commit into this repository. And if we look at it, the thing it actually does is it updates a file at a path that looks like this. We'll talk a little bit about the syntax of these paths. And the context of this file is it's multiple lines. So each version is one line in this file. So if there were multiple versions, in fact, we can.
00:17:29.493 - 00:18:18.495, Speaker A: Let's go look at a file right now. Instead of looking at Pub crawl, let's go look at something like, oh, let's look at zipf again, zi. So the syntax here is for most, for any crate whose name is four letters or longer, it is the first directory is the first two letters, second directory is the second two letters, and then the file name is the full name of the crate. For anything that's three letters, it's three slash and then the name of the crate. So actually, let me go into this one first, zi. So you see here, there's zi. And then under there there's going to be a pf, and under there we find zip and also zips for some reason.
00:18:18.495 - 00:18:50.955, Speaker A: But like you'll also see here, if we try to go to slash three, these are all of the crates that have only three letters in them. And this one has sub directories for the first letter of the crate. So if you go into here, these are all the three letter crates that start with A. For the ones that are two letters, it's just a flat directory of all of those crates. And same thing for one, that's just all of the ones that have one. And you'll see all the letters are taken. So this is going to be the crate called Z.
00:18:50.955 - 00:19:39.525, Speaker A: So that then gets us back to, well, what, what. What's actually in these files. So inside of the index files is one line per version, and each line is a JSON object. And if you sort of squint at this, you'll say, see that this looks an awful lot like the JSON that you're supposed to send to publish, right? Name version depths, which is that same thing we saw over here, depths. And now it's not exactly the same because, for example, over time the exact syntax for what cargo sends up to the registry has changed. Some fields have become optional, some fields have been added. So it's not exactly the same, but it's sort of the same.
00:19:39.525 - 00:20:45.207, Speaker A: And certainly going from what cargo sent, which is all this stuff, to what's in the index should be fairly straightforward. There's one field though that's here, but that's not in the publish, which is, you'll notice here there's no field called checksum. There's name, there's version, there's dependencies, features, and a bunch of other metadata, but there's no checksum. But in here there's a field called checksum, which is a hash of the create file. And so going from just the published JSON to this isn't possible without also having the create file. Hence it should be possible for us to build the whole conversion, assuming we have the original create file. Okay, so this should immediately raise some questions like, okay, what if the format of this changes over time? Don't these files get really large? Don't we get a lot of commits in this? And we're not going to dig too much into that in part because, you know, with HTTP based sparse registries.
00:20:45.207 - 00:21:14.085, Speaker A: There's a blog post about this on the Rust blog. People won't be using the git index all that much anymore. The HTTP index though has roughly the same structure. So it's basically like index crates IO and then these paths. In fact, we should be able to try this. It's index crates IO slash this. Yeah, so now we got exactly that same index file, but we didn't have to do any git checkouts.
00:21:14.085 - 00:21:49.865, Speaker A: And this is what Cargo is transitioning to using currently. You can opt into it, or I think you can opt into it on. You'll be able to opt into it on 168 stable. The default hasn't changed yet, but it will at some point. And so there'll be no more of this updating index resolving deltas business. The other thing to be aware of with this Git registry is it actually gets squashed every so often. So there are way more than 23,000 versions on Crates IO, but it gets squashed whenever the history gets particularly long to avoid keeping the sort of resolving delta step so long.
00:21:49.865 - 00:22:48.283, Speaker A: But in any case, the index is primarily responsible for hosting this list of versions and the crate files that have checksums that match the entries that are in here. And so when Cargo goes to talk to a registry, what it actually mainly does is if in your cargo toml you've declared I have a dependency on zipf, then Cargo will talk to the registry either over either by git cloning it or by sending an HTTP request. Look at this path. Parse that file. Like parse each line of that file. Look for, you know, basically construct the List of versions that are available. Run the resolver to figure out which version among these should I choose based on the dependency declaration in your Cargo toml and then it's going to download the relevant crate file and then it's going to, you know, do the build.
00:22:48.283 - 00:23:40.139, Speaker A: Now one thing that's worth noting is that you might wonder, why are the dependency lists in here? Because when I download a dependency, it's Cargo Tom. That tells me what the dependencies are. The advantage of having the dependencies listed in the index is that you can do a full resolve of your dependencies by only talking to the index and not downloading or extracting any crate files, which makes it a lot faster. So for example, here, when Cargo sees, oh, you have a dependency on zip, it looks at the index, let's say it picks, you know, this version of zip, then it looks at the depths, it sees that, oh, it has a dependency on Rand, let me go fetch the index entry for rand and resolve this version requirement. And then it keeps doing that until it's resolved your entire dependency tree and then it goes and fetches all the. And then it can do the build at the end. Okay, so that is the whole path.
00:23:40.139 - 00:24:17.515, Speaker A: Now, these definitions right here are also represented in a crate in the ecosystem called Crates Index. Now, Crates Index, sort of similar to Crates IO is not just the data definitions. It's actually it knows how to talk to the Crates IO index. In particular, it'll do things like it knows about the cargo home directory and knows how to look there. It knows about how to clone the git index and then do lookups into it. So it has a lot more features than just the definitions. But the thing that we're looking for here is crate.
00:24:17.515 - 00:25:15.085, Speaker A: So a crate is a sort of abstract concept. It maps directly to one of the files in the index and it doesn't have any information in of itself, except it has a list of versions, right, which is that a parsed representation of that long list and every version here. So here the fields aren't public, which is also interesting. But you can see that the sort of getters we have name version dependencies, checksum features, links is yanked and download URL are all the things from the index with the exception of downloadurl, which is which you can programmatically generate. If we look at the source here though, it uses a bunch of other things to reduce the size of the struct and we'll talk about this in a second. But basically this is trying to parse out all the stuff that's in those index entries. And we're going to have basically this definition inside of our crate as well.
00:25:15.085 - 00:26:18.145, Speaker A: Now, one thing that's worth talking about here is the fact that this crate does a lot of this. We'll look at Cargo in a second too. It also does a lot of this of having special implementation or special types that it uses for some of these things to avoid the overhead of, for example, allocating a string for every field in every dependency of every version that it parses. So for example, in Cargo it uses this thing called an interned string. Here it's using small string for packing short strings directly into the pointer. We might need to have our library if we want it to be used by Cargo. For example, it would have to be generic over the string type, potentially more than one string type, but let's say just one string type for now we'd have it be generic over the string type so that cargo could choose to use its own optimized string types rather than being forced to use string the same way that we do.
00:26:18.145 - 00:27:42.279, Speaker A: Okay, so now that we have a general idea of the sort of whole cycle or life cycle here from Publish to Consume, the next thing I want to do is dig in a little bit to the code on the cargo side and the code on the crates IO side to see where this stuff lives, to explore the code a little bit before we start writing our own code. But before I do that, let's do a quick like, are there questions about the lifecycle as I've described it so far, about the various interactions that we've seen, or any of the data formats, or even just what we're building? Let's do like a. Just to make sure we're all on the same page. Isn't JSON not very suited for stream dependency resolution? Like you have to parse the whole JSON before even knowing the dependencies list? In practice it doesn't really matter because the entries in the registry are all very short. It is true that you could have a fairly long list of dependencies, but realistically it's only your direct dependencies that are listed here. So there aren't really projects that have thousands of direct dependencies. And so these JSON lines just aren't very long.
00:27:42.279 - 00:28:20.700, Speaker A: And if you stream deserialize, the amount of time you would save if you were able to start resolving the next one immediately would be basically none. And so having a format that's relatively easy to work with is probably worthwhile here. Will there be redundancies if something like zipfested Dependency of rand. But RAND is also in your toml. So this is generated by cargo for you. This is part of the JSON that it publishes. So if you in your cargo Toml, you say, you know, let's say you are zip 7.
00:28:20.700 - 00:29:11.735, Speaker A: 00 in your cargo Toml, you say rand equals 0.8. Great. So that is in your cargo Toml cargo then packages that up into a crate file and then it puts that to the Crates IO web API. And in doing so it also includes the JSON which says there's a dependency on Rand 08 and it gets that information from your cargo Toml. So it's redundant, but it's also the same, like cargo will derive one from the other. And then when Crates IO receives this and creates this index entry, it takes the stuff that's in the JSON it got from Cargo and then sticks that into the index again here. Why build another crate instead of removing or feature grading curl and such from Crates IO or from the Crates IO crate? It's a good question.
00:29:11.735 - 00:30:08.405, Speaker A: Part of it is because I want to experiment with this and it's easier to experiment on a thing that I built myself. Part of it is because I want more than just what Crates IO gives, right? So I want to not just have the published side, I also want the index side and I want the crate side and I want the conversions between them. So it's a little bit outside of the scope of the Crates IO crate, and it's a little bit outside the scope of the crates index crate. This is sort of a thing that holds all the things in between. What I would hope to see actually is that the Crates index crate and the Crates IO crate take a dependency on this crate that we build for the definitions and then they build convenience wrappers for accessing those things. On top of that, is there any limit on dependency length? Like A, depends on B, depends on C, depends on N. So that's dependency depth.
00:30:08.405 - 00:30:44.735, Speaker A: There's no limit on that. I don't think there's a dependency on a limit on the dependency length either, as in the number of direct dependencies any given crate can have. Neither of them, I don't think, have limits. It's just in practice, no one has a long list of dependencies. And by long I mean like thousands. Why might hosting the index on GitHub be decided? So the reason why the index is hosted on GitHub was mostly because it's really straightforward, right? You just have a git index that you commit to whenever there's a new version it makes it really easy to go back and look at older versions of the index. You have a record, you have like an audit record of every change to the index.
00:30:44.735 - 00:31:44.743, Speaker A: Looking at the deltas of the index between two different points in time is pretty easy. So like, and you know, it, it means that checking out the index locally is just a git clone and you can get, you know, efficient delta updates by doing a git pull. So it, it has a lot of attractive properties and I think it, it made a lot of sense when Crates IO was much smaller. I think now it's getting to the point and this is one of the reasons why sparse registries was, was sort of developed in the first place was it's getting to the point where the git index is becoming, or the index being git is becoming a problem. And the more scalable solution here is to use an HTTP based API, which is what sparse does. If the index is a git repo that they periodically squash, is there a need or mechanism to clean the local clone? You shouldn't need to. Cargo will do this for you.
00:31:44.743 - 00:32:14.653, Speaker A: Cargo manages its own clone of the index. And so this gets back to one of the things I said I was going to get back to earlier, which is this part. Nope. So this path right here, this is the sort of canonical path for the git index. The hash here is basically a hash of the URL of the crates that I.O. index. So it's not going to change.
00:32:14.653 - 00:33:11.979, Speaker A: And if you, if you take, if you use an alternate registry that's also a git registry, they'll end up with a different hash here. So that's how Cargo differentiates them. And you can like, you can inspect this and that's not the one I want. So cache holds the dot crate files, source holds the extracted versions of every create file and then index holds the actual index itself. And you see here, if we run git status or if we run LS files. Am I confused? Oh, index right dot cache. Right.
00:33:11.979 - 00:33:37.077, Speaker A: So get c this LS files. Oh, right. This is a bare checkout of the repository. I think if we do log. Oh, weird. Oh, it's because. Okay, so the reason why we can't do this is because it's not a standard checkout.
00:33:37.077 - 00:34:26.364, Speaker A: They do some things to try to just fetch the head commit rather than fetch the whole history because otherwise it would take very long. So there are a bunch of caveats to this, but this is effectively a checkout of the git repository upstream and Cargo manages it and it cleans it. It Tries to avoid checking out all the commits, all the history, that sort of stuff. And this subdirectory here, cache has the actual entries from the index. So you can see here, you know, zipf, zip. And if we bat that file, pick out that file, you see it's a as JSON. Okay, so let's look at some code.
00:34:26.364 - 00:35:10.195, Speaker A: Let's start out by looking at Cargo. So we're going to end up looking a bunch at the Cargo code base here. But the majority of Cargo's stuff lives in the Source directory. And then there's the Crates subdirectory, which holds sort of utility crates, which includes the Crates IO crate. So that is actually one thing that's effectively owned by the Cargo team already. And I think it is also what Cargo internally uses for interacting with Crates IO. It's just not what Crates IO uses in order to define its own API.
00:35:10.195 - 00:36:00.135, Speaker A: So realistically, if the Crate we build here ends up actually being useful to these teams, it might end up that it ends up being adopted into Cargo, and then either Crates IO goes away or it wraps the crate that we're about to build. So this is where the Crates IO crate comes from and where these definitions are from. So we'll end up copying a bunch of the stuff from here if we go back then to Source. So what we're really after here is the logic around Publish and where those definitions live. Well, the definitions live in there, but where the code for publish lives. So Source bincargo has the definitions for all the various commands. So if we look at Publish, for example, I don't want this symbols thing.
00:36:00.135 - 00:36:25.435, Speaker A: I don't want this thing either. You see, this is just the definition of the. The Publish sub command of Cargo. You see, it uses clap. It's pretty straightforward. It's a slightly modified version where they have their own helpers for a lot of these flags because they're shared among many of the commands. Now, when you look at the exec and you'll see this, for every one of the sub commands, they have a similar kind of structure.
00:36:25.435 - 00:37:02.027, Speaker A: They have a CLI sub command or a CLI function that defines the command. This is sort of a command builder. And then it has exec, which is the actual entry point for executing that command. And you'll see that it doesn't actually do very much. It mostly just arranges arguments and then calls into the Ops module and Publish. So the Ops module lives inside of Source Cargo Ops, and this is where the definitions of all of these commands actually live. The reason for the Split is sometimes a little weird, but it's mainly for reusability.
00:37:02.027 - 00:38:06.439, Speaker A: It means that you can call these methods from potentially multiple binaries. So you can have multiple binaries that share logic for some of the underlying stuff of the CLI command. And it also lets you cleanly separate out the things that have to do with the command line interface, like the actual argument parsing and stuff versus the stuff that there's actual logic and that might be usable by say, other crates or other cargo commands, like external sub commands where people take a library dependency on cargo. So we saw back in, back in here it calls ops publish. So if we go to source Cargo Ops mod, where does publish come from? Publish comes from registry. So you go back here, stick registry and we'll see a publish. So this is the definition of publish.
00:38:06.439 - 00:38:42.433, Speaker A: This is the code that executes when you run a cargo publish after parsing all the registry or the arguments and stuff. And you'll see it mainly finds the sort of parses your cargo config in your workspace manifest. It looks over the members, it looks for the active members, so the package you're currently in. So if you're in a workspace, it tries to find the sub or the crate in that workspace that you're currently in, because that's the one it assumes you want to publish. And then it, you know, checks which registry you actually wanted to publish to. So in this case it defaults to crates IO registry. But you can, you can say in.
00:38:42.433 - 00:39:20.347, Speaker A: In your cargo toml like publish equals and then the name of a registry to say this should be published there rather than to create IO. And then you see it does. It constructs a registry for that publishing and then it calls package one. So this is where it sort of delegates to cargo package to generate the crate file. And what we can look at package one in a second. What that gives you in result is a tarball and that is the dot crate file that we talked about. And then if it's a dry run, then it just doesn't really do anything else.
00:39:20.347 - 00:40:06.363, Speaker A: Like if it's a dry run, it's sort of done at that point. But otherwise it constructs, it gets the SHA of that of that crate file that it just generated. It creates an operation that it's going to send to the crates IO registry and then transmit. Here is the thing that actually uploads to crates IO. So this is the thing that ends up sending both the generates the JSON, sends the JSON and then sends the crate file as the payload to the remote Registry endpoint. And then this bit at the end is the messages you may have started to see. If you run Cargo Publish, which is waiting for the crate to become available.
00:40:06.363 - 00:40:35.873, Speaker A: So this is when you run Publish. There's a bunch of logic that has happened on the Crates IO side. And part of that is just like it has to do a git commit, it has to send it to the database. It has to, I don't know, store the crate file to its backing store, like S3 or something. And at the end of all of that, your version is actually in the index and available to other people. And this loop is just trying to make the command not terminate until it's actually available to other people. So that if you're on the phone with someone, you're like, I ran Cargo Publish.
00:40:35.873 - 00:41:07.537, Speaker A: They're not going to say, I can't use it yet. Like it tell me, telling me that the version doesn't exist. This timeout is going to. Or this loop to check that it's available is going to save you from that. You'll see those are verified dependencies here, which does things like check that you're not trying to publish a crate that has git dependencies, for example, that's not permitted. And transmit is this implementation of sending the. The payload to Crates IO, which you see here.
00:41:07.537 - 00:42:07.875, Speaker A: It computes the list of dependencies, computes list of dependencies, generates this new crate dependency type, which is part of the new crate JSON payload that describes each of the dependencies. It parses out the manifest, parses out the readme, looks at the license file, and then ultimately constructs one of these new crate things which has all of that information that it just extracted from the manifest. And then somewhere down the bottom here, it calls Registry Publish. And this is from the Crates IO crate, which has a publish method that uses curl to actually send the payload. So a bunch of this stuff, like generating these. This, like intermediate stuff are things that we could do in R crate. There's no need for that to be part of Cargo itself because it's a standardized process of going from I have a package to I want the payload.
00:42:07.875 - 00:42:41.377, Speaker A: And then on the receiving side for crates that IO, you'll see there's a bunch of code here too. It's also written in Rust mostly, except for the front end, of course. Prime is salty about me not following him on Twitter. Oh, well, too bad. I'm sorry, I'm very. It's interesting, actually, for Twitter at least. Certainly in the early days, I was very cautious about who I follow simply because otherwise I can't read my timeline.
00:42:41.377 - 00:43:15.465, Speaker A: So I tend to actually, I don't really do this anymore, but I used to actually read every tweet on my timeline, which only scales if you follow a small number of people. I'm sorry. I'm sorry. Primogen. Very sad that your raid didn't really work. I, I only recently set up the, the 10 minute follow chat block because we kept getting just spammers come in and it was really annoying. But it, it does, it does get get sad if people want to raid.
00:43:15.465 - 00:44:15.749, Speaker A: Okay, so let's look at the crates I o side of things like where they receive this JSON payload. So from memory this is source controllers crate publish. So this is the thing that handles, puts to, creates new used by cargo publish to publish a new crate. And you'll see it takes the request, it splits the body using this fact that it knows the length of the JSON and the length of the crate. And so this is the parts of the request that are the JSON and the parts of the request that are the tarball. And then you see it decodes the JSON bytes using this encodable crate upload. No, I don't want that encodable crate upload.
00:44:15.749 - 00:44:52.079, Speaker A: Okay, fine, I'll use it definition over here. So that's defined somewhere else. And you see this is just the same definition that's in the crates IO crate. Just slightly different types for different things. Like for example, you see they have new types around a bunch of these. Not entirely sure why. It might be so that they have more type safety actually so that they ensure that they don't accidentally pass in the name of a dependency instead of the name of the crate.
00:44:52.079 - 00:45:31.725, Speaker A: So this gives you compile time guarantees that you didn't pass the wrong field in the wrong place. Whether this is something we want to adopt in our own crate we can discuss. I mean, I think it is valuable and you can always choose to not use it pretty easily. Yeah, so that's an interesting. I kind of want to keep this file open as well because we're going to want to refer to that later. But you see it parses out the JSON and then it checks for any missing metadata which is disallowed. You must have a description, you must have a license in order to upload.
00:45:31.725 - 00:46:30.573, Speaker A: Connects to the database, constructs a new entry in the database based on the information that's in the JSON metadata, starts a transaction to actually store all the information in the database itself. Checks that you have the Rights to publish, check that the name is actually one that you're allowed to publish to checks rate limiting and whatnot. And reads out the tarball, finds the Checksum, uploads the S3 thing. Yeah, so this is all like the standard stuff that you would expect S3 to do. And at the end here, you see it registers as crate in our local git repo. So this is the thing that actually generates the git commit that eventually ends up in the Crates IO index. And you see it has basically the same fields that we've already talked about, the name, the version, the checksum, et cetera.
00:46:30.573 - 00:47:20.151, Speaker A: But this then is using a different crate, again for the definition of what goes in the index. Let's go and see if we can find that. So this is one of the reasons again, that why I wanted to build this is because all these crates, all these parts of the ecosystem have different definitions for the same thing. So this is the crate type inside Cargo Registry Index Correlates is a subcrate of Crates IO and in Libs RS it has a definition of crate, which is the stuff that ends up going in the index. So here's yet another definition of that. The Primogen's crew are very sad that they had to wait 10 minutes to actually enforce the raid. What you should have done is RAID and then not.
00:47:20.151 - 00:47:57.475, Speaker A: And no one say anything for 10 minutes. And then all of you chat at once, because then it would have been. It would be a double raid. One is lots of people joined, the second is lots of people started chatting. Okay, so now we've explored the space of things that all have this logic, these data definitions. So let's pause there again and see is everyone following? Are there questions about the stuff we've discovered so far or about the plan going next? House is support for using custom registries other than Crates IO. I've never seen it used.
00:47:57.475 - 00:48:51.585, Speaker A: Unlike other ecosystems like npm, I mean, they're totally supported. One of the things that's tricky is you're not generally allowed to have cross registry dependencies. So you can't publish something that Crates IO that has a dependency on something that's in a different registry. I think it's also a little annoying to implement a registry, in part because of this requirement that your indexes get. Most of the companies that provide registry implementations, they tend to have some centralized backing infrastructure for how they implement all of their registry support, whether that's NPM or PYPY or Cargo. But Cargo's registry is git, which means you would have to on the fly generate a git repository based on the stuff that's in your database. And this is very expensive and really cumbersome.
00:48:51.585 - 00:49:32.993, Speaker A: And so I think some of them are probably holding out for the sparse registry stuff where it becomes a lot easier to implement your own registry based on the infrastructure you already have in a way that's scalable and manageable. The privileges crew's attention span span is only four minutes, so therefore they, they couldn't pull off the. The 10 minute delayed raid. Yeah, so. So there, there are a couple of alternate registry implementer implementers. I think I forget the name of them now. Yeah, so someone mentioned Giti.
00:49:32.993 - 00:50:08.305, Speaker A: There's someone starts with a. I want to say anchor, but it's not anchor. There are a couple of them, but realistically they all sort of struggle because they're forced into using a git registry like this. And I mean crates IO is as well. So it's not like they're really at a disadvantage. It's just really cumbersome. The other thing that's annoying actually with registries today is there's not great support for authentication.
00:50:08.305 - 00:50:57.795, Speaker A: There's a very basic setup, but it only really authenticates publishers and not things like reads, which if you're running a private registry, you want to control who's able to access your registry in the first place because you might be uploading commercial things to it. So you don't want anyone to be able to clone. And git doesn't have great authentic or cargo doesn't have great authentication support for private registries, which is one of the things that's currently being worked on is an authentication mechanism for cargo requests that are for reads as well as other operations. So that's some of the reason too. So there's like a bunch of hairiness here, but a lot of it is being worked on right now. I recommend that if you're curious about this stuff, go join the the Cargo zulip and see if you can help out. I think there's a bunch of open issues too for things that might help speed this along.
00:50:57.795 - 00:51:54.077, Speaker A: Some of it is also just like test this out on your own, like for sparse registries, for example, having people test it out in their config, see whether things generally work for them is very useful feedback. Artifactory Muse Alexandria yeah, so there are a couple of alternate registries that people have implemented. Okay, great. Let's actually write some code now. Cargo, New Lib, we call this lib. It's sort of like cargo registry. One of the reasons I don't want to use cargo registry is because I really want to probably in a different stream implement a cargo sub command called cargo cargo registry.
00:51:54.077 - 00:52:19.311, Speaker A: But I don't want to reserve that name here. It is arguably cargo index. Cargo index types. Cargo index. So it's not a. It doesn't let you implement a cargo index. Right.
00:52:19.311 - 00:52:42.625, Speaker A: That's one of the reasons I don't want to call it just cargo index. It has the types for. For interacting with a cargo registry. It has the types that are in the index. Cargo registry types. It's not really that either because, you know, a registry also has to support other endpoints like yanking. They also have to, you know, have the HTTP response types encoded.
00:52:42.625 - 00:53:40.795, Speaker A: It's not cargo types because there's a bunch of things in cargo like types for things like a workspace which this is not going to hold. Cargo schema isn't bad, although this isn't the schema for all of cargo because that would include things like manifests which we're not going to encode. But maybe cargo index schema or registry schema. Index schema. I'm torn between index and registry because the index doesn't know anything about the published JSON really. Right. That's an intermediate data format that never makes it into the index.
00:53:40.795 - 00:54:19.649, Speaker A: But registry is a little bit too broad. But maybe it really is interface. Maybe it is cargo index interface. It is true that cargo dash is a naming convention for cargo sub commands, but at the same time it is the appropriate name here. Right. Because it's not crates IO index interface because this applies to any cargo registry. Cargo space.
00:54:19.649 - 00:54:54.275, Speaker A: That's funny. I mean we could also call it interface for cargo indexes. But that's an awful name for a crate. It. If. If key interface for cargo indexes. Ah.
00:54:54.275 - 00:55:40.495, Speaker A: I think it has to be cargo index interface. Cargo index schema, cargo index, freight types. That's funny. Defs. It could be cargo index types actually, but it also has the conversions. Naming is hard. Car key is pretty funny for cargo index interface.
00:55:40.495 - 00:55:59.773, Speaker A: Cargo index stuff. I. I do like cargo index stuff. Handoff is not bad. I mean, mean. Webster, come help me. I want.
00:55:59.773 - 00:56:50.645, Speaker A: I'm sorry, this is bright. I want the thesaurus entry for handoff. Why does it not have a thesaurus entry for handoff? It's like trans transit cargo insect index transit. Yeah, cargo index transit because it's a transit point. It's all the transits you need in order to interact with the cargo index. Relay is not bad either. But I like transit so it's going to also Transit and cargo are somewhat related, so I like it.
00:56:50.645 - 00:57:20.355, Speaker A: Cargo ups. Okay, so what do we have here? Well, let's start out by saying this is going to depend on serde. Okay, let me use the. Let's be fancy here. See this part, this part. I'm so excited for this to go away. In fact, can we just.
00:57:20.355 - 00:58:11.153, Speaker A: Here's what I'm going to do. Override set beta. In fact, I thought I already had beta and let's do the bill no blog and I think it's on the intern the inside rust blog. New index protocol. Add this. So normally you're supposed to add this to your home cargo config but instead what I'm going to do is just add it to the local directory config and the reason for that is it's not unstable yet. So if I added it to my system wide config, I'd start to get build failures in a bunch of packages because stable doesn't have the feature.
00:58:11.153 - 00:58:44.131, Speaker A: Whereas if I add it locally to this, I'll get it for the local one. So dot cargo config, I'm going to have to make their dot cargo first stick this in here. And now if I do cargo add SERDE feature, boom. Updating creates took no time because it didn't have to do all the git stuff. Nice. I guess that's one satisfied user report. So let's see what it actually added to my cargo Tamil it added the current version with features derived.
00:58:44.131 - 00:59:19.065, Speaker A: Beautiful. Okay, let's go back here. So I don't want these. What I want here is actually to split out the different phases, if you will. Right. So the phases here are there's the sort of dot crate, there is the publish, there is the. And then there's the index.
00:59:19.065 - 01:00:21.975, Speaker A: And let's go ahead and do this and this and this. And let's start with publish. So inside of publish we have two primary definitions, right? In fact we have. Yeah, we have two primary definitions. There is the one in crates IO which is all of this bit. So let's go ahead and tidy this up a little bit. These things we obviously don't have.
01:00:21.975 - 01:01:35.965, Speaker A: And this is all going to complain about things I don't want d ref because that's not a thing that we have. We are going to have to take a dependency on semver, which is the crate that has the implement. Ooh, actually I want features serdi for that, which is a crate that has the definition of semantic versioning versions which appear in a bunch of these places. So we have in the index? No, in publish. I mean, what else? Do we not have another D reference? Dependency kind. Where does dependency kind come from? It comes from models and models. Dependency kind and keyword.
01:01:35.965 - 01:02:45.135, Speaker A: So here is a keyword which I think they used under a different name. They used crate keyword. And this is probably a chrono thing, which is. Yep, chrono native time. Whether we actually use CORONA here remains to be seen. And then what else we got? We wanted the thing from here, dependency kind, which is one of these. Great.
01:02:45.135 - 01:03:41.873, Speaker A: All right, what else is missing? Encodable, Create, version, rec, serialize, serialize. Probably also deserialize for all of these because we're gonna have to do both ways. The reason I'm copying all of these in is because I want to have all the source definitions in one file. So I'm gonna do the same for the ones that are in Cargo. Oh, interesting. Looks like they have manual deserialized implementations here. Maybe there's a crate here.
01:03:41.873 - 01:04:23.603, Speaker A: So these are helpers for validating that features have the appropriate name and stuff. We got to figure out what we do about those, whether we still. Whether we also do validation in here. The reason they do validation on deserialize here is almost certainly because that means that the type that you end up with, you know that if you have that type, it is all. It already conforms with the rules for that string. If you just have a string, you don't know whether it, for example, doesn't have spaces in it for a crate name as an example. Whereas if you in your deserialize, and I'm guessing they already checked this encodable dependency name.
01:04:23.603 - 01:05:34.923, Speaker A: Valid dependency name probably checks for, among other things, whether there's a space in the name which is disallowed. And so it won't even deserialize if it doesn't meet those criteria. So I think we'll probably want to do this too. Now what's interesting here is that Cargo might not want this. So one option is for us to be generic over the types for basically all of the string encodings here. So that cargo can choose to just use intern string crates IO can choose to use their encodable versions, and we don't implement the logic for, you know, sanity checking that these values are the right way. Unclear, actually, because one thing that's sad, right, is we're going to end up with like name S or name T, verse T, feature T, Right, because each of these are a different type.
01:05:34.923 - 01:06:28.685, Speaker A: So it's going to be a lot of generics, which is a little sad, but let's not fix all the compilers here at the moment yet. What, why is there. Why does it claim there are two implementations to serialize? Oh, there we go. Encodable create version cannot be dereference referenced. That's because this has to be self zero instead. There we go. What about two types? Raw create upload and validated create upload with a from or into instance.
01:06:28.685 - 01:07:30.539, Speaker A: So I want to avoid getting trapped in a position where we try to do too much in this crate and therefore no one ends up using it because it does too much. I want this to be a sort of foundational crate that the other two can build on top of. And so encoding too much stuff in here I think is probably the wrong way to go. I rather go the other way of saying this has only the core bits and then additional stuff can be built on top of it with any more additional logic that they might want. Okay, so that's the stuff from crates IO and then we'll want to also pull the stuff from cargo, which lives in cargo. Crates Crates IO librs new crate and new create dependency. Right.
01:07:30.539 - 01:08:39.195, Speaker A: So I guess we can do this and say from crates IO and this is from cargo. And at least in theory these should be equivalent. That's the hope. Right? What's interesting here is like in Cargo, for example, a, the dependency type is new create dependency and the kind of a new create dependency is just a string, whereas in crates IO dependencykind is encoded as an enum of normal builder dev. And you know, it's interesting, we sort of have to decide whether we want to go the cargo way of saying, because we're only constructing this, we're never consuming this, we're just going to have a totally general type here because it's always going to be controlled by us, so there's no need for additional validation on it. Whereas on the crates I O side, they're consumers of it, so who knows what garbage JSON they're going to be sent. They don't know that it's going to come from a real cargo, so they have to verify everything.
01:08:39.195 - 01:09:42.917, Speaker A: So where we fall on this is going to be a little interesting. And you know, the whether this is an enumerate string is going to be one example of that kind of choice that we're going to have to make. Okay, so that's all the stuff in publish. Let's also bring in the stuff from index while we're at it. So that in cargo lives in. Right, I'll keep that open for now, so the entries in an index in Cargo live over in core registry and I want to say it's summary, which is inner. So the question is, where is summary new called from? So summary new, you see, takes like a package id, dependencies, features and links, which is basically the stuff that is already in the index.
01:09:42.917 - 01:10:36.683, Speaker A: But that means by the time summary new is called, it has already been parsed. So let's go ahead and look for summary new, see where that might be called. Resolver version prefs this seems promising. Utilities TOML mod Where's this coming from? Process dependencies this is one long function. What does this parse to? Real manifest. That seems different. That seems like manifest conversion, which this might even be the thing that takes a cargo toml and turns it into the cargo toml that ends up in your crate file.
01:10:36.683 - 01:11:15.425, Speaker A: So it takes the origin creates the non origist index. This is promising. JSON parse Registry package Please be extremely careful with returning errors from this. Okay, so registry package seems like a thing that we care about. A single line in the index representing a single version of a package. Nice. So this seems like the definition that we want.
01:11:15.425 - 01:12:13.797, Speaker A: So this again is from cargo and I guess we can grab like these things from over here. Now here you see it uses intern string, which is the type that cargo uses to essentially deduplicate allocations of strings. So intern string is more or less when you create an intern string, it first basically checks this giant hash map of. Has this exact string already been allocated on the heap somewhere? If so, let me return you just a pointer to that instead. Essentially a globally reference counted string mechanism where the only way you garbage collect is the program terminates. So what's version here? And I guess it's probably semver. Yeah, semver version.
01:12:13.797 - 01:13:02.375, Speaker A: So this is semver version. Now, intern string, we're going to have to figure out what we do about. But let's just make those be string for now because they're more or less equivalent. And again this indicates that we're going to have to be generic over these things at least for if we want CARGO to be able to use these definitions as well, they're going to want to use intern strings and we want to give them that ability. Registry dependency so where does registry dependency defined? That's down here. That has string as well. COW is just from the standard library.
01:13:02.375 - 01:13:49.315, Speaker A: This we make a string. This we make a string. It's interesting here that for some of these they are using cows. So with a reference to the input and this gets at Another use case we might want to cater to, which is if you're decoding JSON, then very often you can deserialize in such a way that the deserialized copy just references the input text. So you don't actually have to allocate a new string, you can just have a STR reference to the original input instead, which is what these end up being, which saves you from a bunch of allocations. So that might be something we want to capture. And then let's look at from Crates IO.
01:13:49.315 - 01:14:18.385, Speaker A: What do we get there? This. Oh, someone asking about this. This is like the new GitHub search stuff, which is sometimes nice, but it also it hijacks things like your control F, which makes me really sad, but. But in general it's a little nice. Like search is much better with this. But I think it's still beta. I want to say it's still beta.
01:14:18.385 - 01:15:13.905, Speaker A: All right, so now we want to find where are the definitions in crates IO used to serve the index. So we've seen the code for this already, actually, because it was in publish Create Publish, Right. We saw somewhere down here the add crate in source worker git index add create job. So two value inner. So this is like a job thing. So this is. Presumably they have a job that regularly does, you know, git commits and whatnot.
01:15:13.905 - 01:16:02.023, Speaker A: But I really want to find what handles something over here. Perform index ad crate. Where's that defined? Let's define over here. The definition here is just entirely search based, as far as I can tell. Yeah, it says right here too, that it just searches for like it knows that this is one word and when you click it, it shows you all the results for searching for that word in isolation. And it tries to guess which ones are definitions and which ones are users because I don't think they have like semantic support for Rust at the moment. Okay, so this locks the index, computes which index file to use for the name.
01:16:02.023 - 01:16:42.645, Speaker A: So this is the part that constructs the like, you know, slash zi slash pf zip. That's going to be that function. But what does it write out? Jason32 writer crate. Okay, so just serializes this crate type and then it writes a new line at the end. Okay, so what we really want is this crate type which comes from Cargo Registry index. So it's really just this bit. So this is the stuff that goes in there.
01:16:42.645 - 01:17:11.175, Speaker A: And dependencies probably defined just below. It's interesting they've implemented ordering for dependencies. I wonder why that's implemented. Oh, interesting. All right, we'll grab those two. Seems reasonable. This is standard compare ordering.
01:17:11.175 - 01:17:40.065, Speaker A: Dependency kind is probably the same dependency kind that we already got from elsewhere, I would hope. Or do they have another definition of dependency kind? Yep, there's a second dependency kind definition right here. Great. And this one's not the same one that's used elsewhere in the crates. IO code base. Fantastic. Okay, so now we have that definition.
01:17:40.065 - 01:18:19.511, Speaker A: And I guess this isn't used, deserializer isn't used, serializer isn't used. And this isn't used because we don't have any manual implementations. All right, and then I guess the last part is create files. And so here we have to be a little not careful, but we have to figure out what matters to us because we could take a dependency on cargo. That's one option. Here we take a dependency on cargo and use cargo to. So we extract the create file.
01:18:19.511 - 01:19:12.267, Speaker A: We use cargo to parse the TOML that's inside of it in order to generate the published JSON. The downside of doing that is it means that cargo can't take a dependency on us because it would be a circular dependency. Right. So using cargo for this is probably not what we want. But at the same time, the cargo TOML manifest format is entirely defined find in cargo. But we only need the definition of the simpler dependency, the simpler cargo TOML manifest, which is the one that appears in the create file. Remember how we have the original which is like a full fledged cargo toml and then we have the generated cargo TOML file, which is supposedly a simplified version.
01:19:12.267 - 01:20:20.955, Speaker A: So the question then becomes where is that defined? That's going to be something like, well, we saw the two real manifest. Actually, let's go to. Let's go look at the cargo. Let's go look at cargo OPS package because that has to have a call somewhere that does that rewrite. And I'm wondering whether there's a type definition just for the like the simplified manifest build AR list. So this is the thing that decides what goes in the archive. So it loops over all the source files and for cargo toml, it pushes into the archive the original man, like under the path original manifest file, which is probably cargo Tom Ridge the contents of the old one and the generated file manifest.
01:20:20.955 - 01:21:01.701, Speaker A: Generated file manifest. Okay, so somewhere up here we have this. And so we want to know when it prints out file contents of a generated manifest. What does that look like? It's down here. Okay, so this is when we're looping over the things that are supposed to go into the create file. If it's a file that's on disk, we just write out the file that's on disk. If it's a generated file and it's a manifestation, then use package toregistrytoml.
01:21:01.701 - 01:21:27.845, Speaker A: Okay, what's toregistrytoml? It's defined in sourcecargocore package toregistrytoml. It takes the manifest of the workspace, the original manifest, and calls prepareforpublish. Alright. And then it calls toml2 string. Pretty. Okay. What does prepare for publish do? Prepare for publish returns a TOML manifest.
01:21:27.845 - 01:22:03.515, Speaker A: Okay, so toml manifest seems like the type we want here. The question is, is toml manifest the whole like cargo manifest definition or is it somewhat simplified? If I find TAML manifest here, it's going to be a giant type, isn't it? TOML manifest. TOML manifest. You can't see what I typed. It's just. It's not very interesting. Oh no.
01:22:03.515 - 01:22:18.553, Speaker A: Yeah, so it's just here in the symbols. I typed TOML manifest and now it won't. Take me to it. Take me to it. All right. Manifest. There we go.
01:22:18.553 - 01:23:28.595, Speaker A: This type is used to deserialize cargo TOML files. Yeah, that's what I was worried about. So what that means is there isn't a separate type for just the simplified manifest that cargo will write out. Because in that manifest, for example, there is no workspace definition. H Prepare for publish. Because this only writes out some of them is the thing. So we could probably come up with the definition here that is only the bits that are actually generated.
01:23:28.595 - 01:23:50.425, Speaker A: Like you see here. You know, this Prepare for publishing method produces a TOML manifest. But there are a bunch of fields that we know are always none. Like project is always none. Dev dependencies 2 are always none. Build dependencies 2 are always none. Replace is none.
01:23:50.425 - 01:24:39.405, Speaker A: Patches none, workspaces none, Badges. Honestly we could probably skip because they're effectively deprecated now anyway. Cargo features. Yeah, I'm torn here about what we do because like we could copy this whole thing and then strip out the things that we know are going to be none. But like some of these are non trivial. Like TOM lib target, for example. Oh, it's just typedef to be toml target.
01:24:39.405 - 01:25:47.683, Speaker A: So maybe these aren't too bad. And for things like, maybe workspace dependency for those for us are just TOML dependencies, they're never going to be a workspace dependency. So that might make things easier. Right, if we go back here, self dependence, self dependencies as reps. But it calls map depths and map depths Defined down here. Well, call filter all. What does all do? Trying to see whether this actually filters out things that are workspace, dependencies.
01:25:47.683 - 01:26:30.165, Speaker A: Dependencies filter maybe workspace defined. Yeah, so the defined type is used when it's not a part of the workspace. So the workspace type is never used. Right. So what this map depth thing is doing is removing anything that is a workspace dependency. Those are filtered out, and so that means we don't have to encode those. Okay, so let's try to see if we can just construct a simplified version of TOML manifest that only includes the bits that are actually.
01:26:30.165 - 01:27:13.225, Speaker A: That are actually settable from in the sort of normalized manifest. Okay, so we're going to need a couple of other definitions here. We're going to need TOML package. We're going to need TOML profiles. Actually, we might not need profiles, but we're going to need toml. TOML package is TOML package always set packages set project is not. Okay, so we need TOMO package.
01:27:13.225 - 01:27:40.795, Speaker A: Ooh, this feels like it's going to be painful. Now there's another option here which is instead of actually semantically parsing this, just using. Just parsing it as like generic toml. So all we get back is like a giant B tree. Like it just a basically like similar to serdejson value. And then we just fish out the things that we want. But it is nice to have it be, you know, structured.
01:27:40.795 - 01:28:33.427, Speaker A: There won't be a definition of this in crates that IO unless they also parse the. We could check whether they also parse the dot crate file, but I have a feeling they don't really. So let's see what this verify tarball thing is. Okay. They decode the tar archive. They see that the contents of the archive are reasonable, but they only check the path. It doesn't look like they actually check the.
01:28:33.427 - 01:29:22.405, Speaker A: The cargo dot toml. I mean, it could be they do it somewhere else, but I don't immediately see anywhere else where they actually. We could of course, search for cargo Tamil, see what we find. Let's render readme, create sidebar. Create publish line 376. Aha. Okay, they do, because this is add dependencies.
01:29:22.405 - 01:30:16.705, Speaker A: This is walk all the dependencies and check that those dependencies are available in the registry. So this is different. This is just checking that you're only taking dependencies that are from the registry. Create metadata. What's in here? Encodable crate. This also seems separate. It might actually not look at the cargo TOML at all, but it's like the check that it does down.
01:30:16.705 - 01:31:13.635, Speaker A: Not here. Where was I just now? The thing that we just looked at that I this one where it checks that the subdirectory path that the only subdirectory path you have is the name of the crate that you just uploaded in its version basically ensures that that is the crate that's being used. Because cargo, when it downloads the crate file, that's the only path it will look at. So if some other file is there, it wouldn't work. But it. It never actually parses the cargo tunnel it looks like, which is presumably because they don't want to have to encode all of this stuff in their crate. All right, so what's maybe workspace field? That's maybe workspace.
01:31:13.635 - 01:32:05.631, Speaker A: What's maybe workspace? That's a serde untagged. That's either defined or not, which means it doesn't matter to us. So anything that says maybe workspace field we can just replace with the inner type string or bool String or vec. Yeah, I love those. Vec string or bool. That's fantastic. Right, we are going to need the TOML crate here.
01:32:05.631 - 01:32:47.379, Speaker A: This is going to be cargo index transit, cargo add toml. It's not. It's fine. Okay, so that's toml package. What else do we have here? Tom lib targets. Let's go back here to see what actually gets set. So Package Matters project does not dev dependencies 2 does not build dependencies to.
01:32:47.379 - 01:33:09.725, Speaker A: Whoops, did I delete the wrong thing? Yes, I did. Whoa. Serdi rename dev dependencies. That's fun. Dev Dependencies 2 does not get set. Build Dependencies 2 does not get set. Replace does not get set.
01:33:09.725 - 01:34:12.267, Speaker A: Patch and workspace do not get set. Okay, so let's go back here to the manifest definition. Did not work for some reason. So I want these typedefs and we're going to need TOML target. I think we're also going to need TOML dependency. Right, so maybe workspace dependency I think is really just workspace dependency. This one is really just the type definition of TOML dependency.
01:34:12.267 - 01:35:04.595, Speaker A: So anything that says maybe workspace dependency is really a TOML dependency. And toml dependency is defined over here. And that of course has its own special deserialized because of course it does import phantom data. That seems fine. Detailed TOML dependency we're also going to have to grab, which is fun. Okay, so we have this. So this is presumably why no one's done this before is because it's to some extent really annoying.
01:35:04.595 - 01:36:13.955, Speaker A: And also like, it's unfortunate to have to replicate all of this data, but it is nice to have a sort of simple representation of what's actually what actually ever goes into the cargo TOML that's in the crate. So that's detailed TOML dependency. But we know that for all of the detailed TOML dependencies we call map depths, which calls map dependency and it maps anything that's detailed and removes path. We know there's no path in there. It removes git, it removes branch, it removes tag and rev. It changes the registry index, which is fine. It leaves everything else alone.
01:36:13.955 - 01:36:39.445, Speaker A: And simple dependencies are turned into detailed dependencies. Okay, so that's interesting. So there are no. There are no simple dependencies. There are only detailed dependencies. Okay, that's nice. So this is actually TOML dependency.
01:36:39.445 - 01:37:07.165, Speaker A: That's nice. There are no intern strings. Maybe workspace field is always just the first thing. Parameter P is never used. Great. So P goes away. Tunnel platform we're gonna need.
01:37:07.165 - 01:38:17.585, Speaker A: So where does Tamil platform come from? Tamil platform. Okay, so we have TOML platform, but toml platform is also remapped. I think I saw where is the platform? Wait, which field even is platform? Target? Because target here gets mapped to TOML platform where dev dependencies 2 and build dependencies 2 are empty. So if we grab this in here, build dependencies to dev dependencies 2 is nothing. Maybe workspace dependency. We already set our TOML dependencies. This can just use rename all to get rid of these.
01:38:17.585 - 01:38:48.991, Speaker A: Okay. And then the things that remain are these string or vec version trim white space. That's fun. That's. That's a pain. Okay, so there's string or bool, String or vec. Okay, so these are just like serdi helpers that I guess we'll have to bring in because we don't really have a choice.
01:38:48.991 - 01:39:27.831, Speaker A: But we can bring them into a sub module. Right? So we can do mod D sir. And we're going to do this. We're going to go to its definition created for me, please. Thank you. And grab in the serde stuff and I guess use standard format and see this should all now compile. It does not cannot find maybe workspace field.
01:39:27.831 - 01:40:09.615, Speaker A: Well, it's not going to be maybe workspace field. It's just going to be one of these. Ah. And version trim white space is not going to have to handle visit map because it's never going to be a TOML workspace field. So it's going to be a string. So it's just Going to be parsed and now it's complaining about. Right, that's fine.
01:40:09.615 - 01:40:42.007, Speaker A: Okay. We're slowly but surely getting there and cleaning this up. Toml profiles is still missing. Toml target is still missing. I'm going to go here and do use desert. It's going to help a little bit. TOML target we still need back.
01:40:42.007 - 01:41:34.915, Speaker A: Doesn't work because why would it? Toml Target, of course, is also non trivial because it has to be. What do we use of tumble targets? Because they also get mapped somewhere here. 14:56 README. Where's the target bit? Right. So targets get mapped. That's curious, actually. Where is TOML target used? Right.
01:41:34.915 - 01:42:14.625, Speaker A: This is a different kind of target to this kind of target. Basic target is a platform and these are targets as in I want to build this binary as opposed to target as in target platform, because that would be complicated. So this is not a target, this is one of these. And those are cloned as is, which means all the fields matter. Path value. All right. What's path value? What? So it's just a string.
01:42:14.625 - 01:43:03.535, Speaker A: Oh, it holds a path buff, but it's serialized and deserialized as a string. Interesting. Okay, that's, that's fine. I guess, I guess it's not just deserialization either because we just brought in a serializer and this is going to be standard path. Path buff and debug is fine. So now we have path value. These are all, of course, annoying.
01:43:03.535 - 01:44:18.583, Speaker A: What's really sad about this, right, is that we're replicating a lot of the definitions without making changes. Like, I was hoping that this would be sufficiently trimmed down that we wouldn't have to. I was hoping it was sufficient we could trim it down sufficiently that the fact that there was some overlap didn't matter because the subset that we're going to use is so small. So I'm hesitant to continue down this path because, I mean, I guess we're almost done, but I don't know if I want to keep all these types in here. Arguably what we should do is look at how many of these things actually make it into the published definition, for example, because, for instance, this doesn't have any information about things like targets, so we don't actually care about extracting that from the TOML manifest. It doesn't have anything about profiles. Neither does the stuff in the index.
01:44:18.583 - 01:45:35.945, Speaker A: I think if we look at it, it has name, version dependencies, checksum features, features, two yanked links, and V. So I think actually before we continue, we're going to prune out all the things that don't go in the upload, which includes all of the targets and the profile cargo features, I'm unsure. And the fact that the targets went away means that disc goes away and that TOML platform goes away. Toml dependency is still there, but we pruned that one down a little bit already. Tumble package we still need because that defines the. That defines the actual cargo package, like the name and the version. Oh, it's private.
01:45:35.945 - 01:46:06.225, Speaker A: What do you mean it's private? Did I not. Oh, this has to be. What I really want is pub. Super. Because I don't actually want these to be. Oh, this does need to be pub. Because it's a type, which I guess means path value also needs to be pub.
01:46:06.225 - 01:46:42.425, Speaker A: Although is path value even here anymore? It is not. So we can get rid of that. That makes me happy. And in fact, even within TOML package. Right. If we look again at what goes to publish, addition isn't here. Authors is build is not, at least at the moment.
01:46:42.425 - 01:47:09.975, Speaker A: Right. It's neither in crate nor is it in V. So actually, let's just look at the ones that are actually complicated. Badges is the main one. So build is not there, so it can go away. Meta build. What on earth is meta build? Meta build.
01:47:09.975 - 01:48:35.583, Speaker A: Do I even want to know what metabuild is like? If I look at a manifest meta build, there's no meta build field. See all references package. What is metabuild? Where does this come from? Meta build. This is very strange. I don't think we're going to need metabuild. Whatever it is, what else goes in there? Published does not go in there and it's not in the index, which means that we don't need to keep it. The auto stuff does not go in there.
01:48:35.583 - 01:48:59.945, Speaker A: I'm a teapot. Does not go in there. Workspace does not go in there. Exclude and include probably don't go in there either. Readme, I think does go in publish. Yeah, readme file. So that one we do need to keep metadata.
01:48:59.945 - 01:49:51.065, Speaker A: Doesn't look like metadata is actually published, which is a little interesting. Does metadata end up in the index? I doubt it, because it's like free form. Okay, so in that case we don't even have to parse metadata. This also means that we no longer have a bunch of these. We have stringer vec from artifact, which. It's a good question, does that end up anywhere? So if we look at the index entries and we look at what goes in dependencies, it has target, it has kind, it has package, but it does not have artifact. That doesn't go in the index.
01:49:51.065 - 01:50:36.245, Speaker A: Does that go in publishing? It does not. It only has target, although it's unclear what. So all of these things are of course named different things. So here when it says target, what is that supposed to be? I guess it's the platform name. It's probably target here. Okay, so in that case, artifact isn't even a thing that we parse out. Neither is lib because remember, this is only the stuff that the stuff that goes in the index.
01:50:36.245 - 01:51:27.167, Speaker A: So the stuff that the registry cares about are only things that are related to ownership, display of metadata and the resolver, which is ultimately what goes in the index. And so things like this produces a C dilib. Lib is not important to the resolver or to the registry and that's why they're not in here. So even though they are in the cargo tunnel, we don't care about them. Which means that because it's not in the index or the registry, Lib isn't necessary. Public. Public doesn't appear to go anywhere here.
01:51:27.167 - 01:52:12.741, Speaker A: So public. So public, I think. So this field is probably something that is going to start to be relevant to the resolver because it, it's basically a flag that marks whether a given dependency is exposed. Is is allowed to be used in any publicly facing types. So actually no, it's not relevant to the resolver. The thing this is going to try to help with, let me see if I can dig up actually the cargo Private dependencies, not pre built dependencies. Okay, let's see if Google can search better Public private dependencies.
01:52:12.741 - 01:52:40.719, Speaker A: This is the RFC I was after. I'll put it in chat too. So this RFC is proposing the ability to say that I have a dependency and I don't want it to leak. I don't want this dependency to be exposed to my consumers. The reason this matters is for backwards compatibility. Imagine that you take a dependency on foo 0.1 and in your API you for example, return a type from foo.
01:52:40.719 - 01:53:07.085, Speaker A: That means that if you upgrade to Voo 0.2, that's a breaking change for your crate because it means the type signature of one of your return values changed from Voo 0.1 bar to Foo 0.2 bar. Those are different types. And so being able to market dependency as private is going to tell cargo when you build. If you discover that this dependency is visible through any of my APIs, then fail the build.
01:53:07.085 - 01:53:47.405, Speaker A: But at the moment at least that's not supported. And also it's not going to affect resolution, as far as I'm aware. So it can go away. Great stuff. And I think Default Features two we also know isn't used. If we go back to the part that maps dependencies back here somewhere, we know that in TOML dependency. In map dependency.
01:53:47.405 - 01:54:39.519, Speaker A: No, in map dependencies, map depths. Over here, Automobile platform config. Oh, it dependencies read self.dependencies oh, this is default features. Map depth calls map dependency. I'm surprised actually, that this doesn't rewrite the features. That feels like a missing feature in Cargo.
01:54:39.519 - 01:55:55.615, Speaker A: So to give a little bit of context here, the reason you see all of these default name of field and name of Field 2 is because in older versions of Cargo, the default features field was encoded as default underscore features for unintentional reasons, which means that there are some index files, there are some manifests that have default underscore features for a dependency, or at least it was accepted in the past, which means that we have to continue to accept it. And so the thing that might be in a. Oh, actually this makes me think that we might have to support it elsewhere. Anyway, it means that we end up parsing out two fields, one by the name of default dash features and one by the name of default underscore features, and then we essentially have to, you know, combine them. Or I think what it actually does is read the one with a dash and if it doesn't exist, look for the one with an underscore. Now, where this gets a little dangerous is it could be that this gets past the crate file that is from eons ago. And so it has the old syntax, it actually has the underscore.
01:55:55.615 - 01:57:11.309, Speaker A: And I do think we might have to handle that. So even though Cargo, when it generates its sort of normalized, normalized output, you see, it never generates a two, it always generates the one, the one with the dash and not the one with the underscore. Old versions of Cargo didn't have that normalization, so they might still generate one with an underscore, which means our library might receive ones with an underscore, which means we have to support them. So that is all just to say the places where we see a. Let's see, where is the TOML manifest definition? We actually do need to handle build dependencies to and dev dependency dependencies to, and we can go back and do this replacement more. So that's fine. So now suddenly our TOM will manifest is much more manageable because it only has the bits that we actually care about.
01:57:11.309 - 01:58:06.385, Speaker A: And I'm going To go ahead and make the claim that we should remove badges. Badges has been deprecated by crates that IO it was generally considered a bad idea. So I'm just going to say we're always going to generate an empty badges list and if someone wants to get mad at me, they can. And so for publish, I guess we'll still send badges, so it'll just be empty. All right, so I think now our create toml manifest parser is compared complete. I think there are still some of these that we don't use that we can trim. Like for example, this stuff, the stuff that goes to the to publish.
01:58:06.385 - 01:58:49.475, Speaker A: None of that talks about default target or force target for the package. I'm guessing Index doesn't either because it. This is more about builds than it is about resolution. So these can all go away. Exclude and include can go away because they're only used by cargo package. So once cargo packages run, there's no need for exclude and include anymore. Default run also isn't relevant to the registry, so that's going to go away.
01:58:49.475 - 01:59:37.325, Speaker A: All this metadata, though, I think probably is. So we'll keep that for now. And now the question is, what do we parse out? We still have string or bool for the readme, but that's all we have. So if we go back up here, we don't need string or vec or I guess we can just do this and see if anything fails, which nothing does. Great. String or bool we do have vex stringer bool we do not. And version trim white space we do still use.
01:59:37.325 - 02:00:20.729, Speaker A: We don't have any manual implementations anymore, we don't have path buff anymore. So this file is now much simpler. Okay, we're almost there with getting all the types in. Chrono is no longer here. This is no longer used. So I realize there's one more source we have for index definitions, which is the crates dash index crate, which we looked at earlier, which is this crate. So this crate, if we go look at its, it's going to be bright.
02:00:20.729 - 02:00:51.635, Speaker A: I apologize. If we look at its dependence, it's used by like cargo edit, cargo, deny, cargo release. It's used by anything that wants to parse stuff that's in the index, Cargo, vet, cargo, public API, you know, a bunch of these things. But crucially, it's not used by Crates, IO or by cargo, but it is used. So this is another instance of version that we're going to have to deal with. And we looked at this a little bit earlier. Its definition is over here.
02:00:51.635 - 02:01:53.779, Speaker A: And Hopefully. Right, so they have their own string type that they use. This is going to be a vec of dependency and they have other optimizations where they choose to use an arc for the feature so that this is cheap to clone. For example, we're going to have to grab dependency out of here, which comes down here. This again is string, string, box, box, string, double indirection to remove size from the struct since the features are rarely set. Right, so this is a vex string. It seems like for this grade they've done a lot of work to try to ensure that the encodings or the in memory representation of a single version of a crate are as small as possible.
02:01:53.779 - 02:02:37.075, Speaker A: Which does make a decent amount of sense because the crates index crate is used often to process crates in batch. Right. So this means you're doing like imagine you want to walk every version of every crate. Well, there are a lot of versions, so you really want all of them to be very compact and so you do what you can to squeeze these as small as possible. That doesn't really matter for Cargo because it's only going to look at a number of versions equal to the size of your dependency resolution, which is decently small. And for Crates IO it's only looking at the one thing it's currently publishing. So it doesn't need to be small, but here it does need to be small.
02:02:37.075 - 02:03:08.185, Speaker A: Oh, there's another one. Oh, great. Docs also parses it. Of course it does. Okay, so they have their own encoding of dependency kind as well because of course dependency kind is defined multiple times. Dependency is defined multiple times. That's all that makes sense.
02:03:08.185 - 02:04:25.175, Speaker A: So we're actually going to do mod creates index, this is mod creates IO and this is mod cargo and we'll stick these in there and then string, this is going to be B tree map. Ah, so there's the dependency here on the hex crate, which I think we do also want. Great. Exists but is inaccessible. Well, we'll see where that comes from at some point. So publish now. We'll do the same.
02:04:25.175 - 02:05:13.365, Speaker A: We'll say this is creates IO, this is cargo and then in dot create it's all cargo. Okay. Whoo. See, we're on cargo check. We're gonna get a bunch of warnings. We're also going to be some errors I think in the right. So this is over in the published stuff from Crates IO because it has all of these.
02:05:13.365 - 02:06:33.705, Speaker A: Oh, because it has all these custom implementations of deserialize that do you know, validation, which includes things like using their various validator methods. I think realistically we're going to get rid of these and we're going to replace this with the ability to choose your own type for each of these. And again, like cargo is going to want this for things like intern string. I could imagine that the crates index crate is going to use small string here and crates IO can use its encodable crate names. Okay, so someone said there's one more implementation of parsing metadata. So that's going to be term, not that Rustland docs, rs, blob master source utils, cargo meta rs so what does this do? This is different. So the reason this is different is because this runs the cargo metadata command, which has its own format for output.
02:06:33.705 - 02:07:20.975, Speaker A: But we're going to ignore that for now because that's. I think what cargo metadata outputs is somewhat related to the TOML manifest, but they're not the same. So we're going to ignore cargo metadata for now. Now there is also a cargo metadata crate, which I think this one could use but doesn't. And the cargo metadata crate has the parsing for all of the output from the cargo metadata command. So we look here at metadata. It has a package package has a lot of the fields that we might be familiar with by now.
02:07:20.975 - 02:08:14.053, Speaker A: And you could imagine that we implemented a conversion between probably be the dot crate stuff and one of these. But this has a bunch like this includes things like default run things that don't matter to the registry. This is essentially a print of the TOML manifest, but in a slightly normalized way. So that was a little different and we're gonna mostly ignore it for now. Okay, so the next step now is gonna be to tidy up these so that we. Why don't we need to parse the license? We do need the license that's in publish and it's in dot crate. I don't think I removed it.
02:08:14.053 - 02:09:17.505, Speaker A: It's under package. So that's TOML package, TOML package, license and license file. So they're in there, they're not in the index. The index doesn't care about licenses, but they are in the published stuff. Okay, so next up now is going to be to tidy up these definitions so that we only have one definition rather than multiple. I realize now that I actually should have not been this dumb and should have kept the information about which of the string types these different libraries actually care about optimizing. Because when we were copying out these definitions, you know, some of them like name was in turn string, but some of them like homepage was not they were always string and I should have kept that information here and just done like interned string is string.
02:09:17.505 - 02:10:18.675, Speaker A: So let me do that real quick because that's going to be nice for us in a second, which is features. Yes. Let's walk this from top. Cargo Features is a vec of string string string string string string string Features is intern string to a vec of intern string. I hate this new search so much. I don't want it to go somewhere I just wanted to highlight. Well, toml profile we don't have maybe workspace tunnel workspace dependency toml package.
02:10:18.675 - 02:11:03.825, Speaker A: So the name in a toml package is an intern string. Addition is not. In fact, that's the only intern string there. Inheritable fields we don't care about because we don't have workspaces. TOML dependency detail TOML dependency. Interestingly enough, it doesn't have intern string for the version. Kind of interesting, but the.
02:11:03.825 - 02:11:36.583, Speaker A: Oh, the map doesn't either. Yeah, it seems very arbitrary. Which ones are actually intern string here, but so there weren't too many. Great. So we did those. And for publish, I don't think it actually used intern string there, but let's go look. New crate uses string for everything.
02:11:36.583 - 02:12:21.575, Speaker A: There's no intern string here. Okay. On the crates I O side, we already kept the special types there, so that's easy. Then for index for cargo, I think we ended up doing some erasure here. So in particular registry package, the name is interned string. So this is going to help inform us which of these need to be generic in the future. Basically turn string features is an intern string.
02:12:21.575 - 02:13:19.635, Speaker A: Features 2 is an intern string. Links is an intern string and for a registry dependency, the name is an intern string. Features is an intern string and package is an intern string. The crates that io1 what did crates IO have for here? It just used string for all these because it only writes it one, so it doesn't really care to optimize it too much. Probably same here for crate and dependency those are just strings. Great. And crates registry index, that's the same.
02:13:19.635 - 02:14:00.159, Speaker A: And over here in crates IO we're going to do a type smallster is just going to be equal to string and we have independency. Name is smallster Rec is smallster. Features is boxbox string. That's fine. This is package is. Wait, did I. Am I looking at the right wrong one? I am looking at the wrong one.
02:14:00.159 - 02:14:21.515, Speaker A: Okay, I'm looking at the wrong one. It should be this one type smallster string. This is small. I'm looking at dependencies this is Smallster. This is smallster. This is boxbox String. This is options mulster.
02:14:21.515 - 02:15:18.525, Speaker A: This is options Moster. I I guess we can keep the box too to make it clear what how they are encoding these box box small stir. And what do we got for the entry itself? That's up here they have Smallster Smallster. This is for them an arc. We're probably going to clean these up. I'm just trying to make it so that we start with the right type definitions so that we can then optimize them later on. Okay.
02:15:18.525 - 02:16:31.385, Speaker A: This is a box hash map of strings. This is an option bach of smallster. That's interesting. That seems false claims that there's no implementation of serialize for ARC of dependencies. I find that hard to believe. Deserialize is not implemented for arc hashmap string vecstring but it's using it right here. And this is just derive serialize deserialize.
02:16:31.385 - 02:17:40.034, Speaker A: So I call shenanigans. Let's look at the repository and see. So what's the cargo toml here? Oh, features equals RC is apparently a thing we need. Great. Okay, great. And then I guess what we can do for publish here is instead of having all of these customers deserializes that do validation, we just delete those and retain the types. So do delete, delete, delete, delete, delete.
02:17:40.034 - 02:18:31.811, Speaker A: And then we say type this equal string. I can't type spaces apparently this is a string. This is one of these. All right, let's do a macro here. I should have included an arrow down at the end of my macro, but I do love macros. Beautiful. Okay, so now does it.
02:18:31.811 - 02:18:57.744, Speaker A: Now build it does. Lots of warnings, but that's fine. We don't worry about these. I guess we can get rid of some of these things now that we got rid of the custom implementations. Multiple fields are never used. That's fine. Okay, so we're now in a position where we have all of the type, all of the different type definitions from the different crates that are using this.
02:18:57.744 - 02:21:17.245, Speaker A: And the next step is going to be to create the definitions that we want to use and the conversions between them. And you know, probably as part of that we want, you know, testing, we want documentation and all that biz. So that's going to be next steps. But first I'm going to have a bio break. I'll be back in a few seconds. It. All right, I'm back.
02:21:17.245 - 02:22:28.215, Speaker A: I walked out of my office and immediately saw both cats sitting there cleaning their asses. Beautiful. Okay, let's see where do we want to start? Do we want to start at the create end or the index end? You can chat, can decide while I eat something. I gotta vote for the crate engine. We'll start there. Part of the future difficulty if this common crate gets used upstream, seems like it might hinder future optimizations if they find it's needed. I guess it can be a major semver bump for adding a new field or a list of fields with a generic string type.
02:22:28.215 - 02:23:38.625, Speaker A: It's a good point. I mean, there's an argument for we make every type here generic. I don't love that idea, but it is a path we could take, right? We could have a one generic for every field and the only thing that we require is that they maybe we don't even really need to require anything, but we want to indicate the type of the field. What do we want our own type? Shouldn't a generic hash map do? So the reason why these different crates have different definitions here for even things like the map or vectors, right? So the crates index crate, for example, uses box slice 1 uses hashmap 1 uses B tree map. It's usually because they have different needs. So I think Cargo, for example, tries to keep the entries ordered for anything that sticks in the registry. Or actually I think Cargo doesn't.
02:23:38.625 - 02:25:45.515, Speaker A: So cargo uses a hash map for what it for the published JSON, but crates IO uses a B tree map for the receiving end because they want to make sure that the crates index entries are sorted so that if they regenerate it, they get the same order of fields to avoid churn in the git diffs. So Cargo wants the faster hash map, whereas the crates IO team wants stable index entries, and the crates index crate wants whatever is the most compact representation, which is like a box hashmap, because a hash map has a bunch of fields, so indirecting it through a box means it's slower to access, but the type is smaller, and so they're optimizing for different things. Now, dot crate should be the easiest because it's only used by Cargo at the moment. I did find it interesting that cargo only uses intern string for the features and for the name of the package, not the names of dependencies, but for the name of the package. I wonder if there's some rationale for that. Like if we go back to this, the toml stuff, right? So if I go to blame here and I say name colon, and I also do this. So what do we get here? Serdeserialized for cow str Allocates by default.
02:25:45.515 - 02:26:30.995, Speaker A: Oh, interesting. Yeah, because my instinct here is that for many of these we might actually want a cow. But that doesn't work for option. But it does work for option though. At least I think it does in newer versions of Serti. If so, we should check that because it. If that's the only reason reason, then I'm also curious, like why name? Why just name.
02:26:30.995 - 02:27:18.285, Speaker A: What was the other one? Features. What Something got very confused here about. Okay, this. The. The search is very confused about how things work right now. Interesting to hear, but they're not. So it was that previous commit.
02:27:18.285 - 02:28:58.095, Speaker A: There's this. But this is a giant implementation. I remember this pr. Like, this is huge. But it doesn't really explain why the change to intern string happened and only happened for features. The reason I'm trying to figure that out is because I'm trying to figure out both. Does it matter? Should we use it in more places? You know, it's tempting to just say this, which I think is supposed to just work, but maybe I'm misremembered.
02:28:58.095 - 02:29:48.535, Speaker A: This is certainly my. My instinct is to do this. The box here is interesting. I guess they don't want to inline the TOML package because it's too large. And then we put certiboro and like all of them. I'm gonna do the same here. Say this takes tick A.
02:29:48.535 - 02:31:23.211, Speaker A: We borrow every single one of them, or we allow every one of them to borrow and same for toml package. So at least in theory, the benefit of this, right, is that if you have a manifest file, you're not going to allocate any strings because all of them are going to be just references to the strings in the input. One thing that's inconvenient with a definition like this, apart from the fact that it has a lifetime, is sometimes you actually want an owned copy. Like you deserialize something out of a, you know, some buffer that's temporary and now you want to copy it around. So. So what you want is you want like you. You have a thing that's ca.
02:31:23.211 - 02:31:54.315, Speaker A: That's, you know, TOM will manifest tick A and you. What you actually want is a toml manifest. That's. That's static that you can like send to another thread or something. So the way that I usually end up doing this when I have methods like this is. I guess let's call this normalized manifest is I have a impl. Normalized manifest.
02:31:54.315 - 02:33:26.195, Speaker A: Pubfn2 owned takes a self and returns a. So it takes a normalized manifest of any lifetime and it gives you a normalized manifest of a static lifetime. And the way that it does that is normalized manifest Cargo features into Iter Map. This is Cow2Owned Collect. So for each field you just sort of figure out how do I turn this into a thing that's static? And you do that for every field. So now if someone does want to make that conversion, they have a convenient way to do so. Be a normalized.
02:33:26.195 - 02:34:06.445, Speaker A: This can just be a package. Just be dependency and package. It doesn't need to be any fancier than that. Like. So this is going to be package two owned. The reason I use the name to owned here is because it's the same thing you have on cows is cargo features. Oh, it's an option vec.
02:34:06.445 - 02:34:53.665, Speaker A: So it's map. So see if here's a vec. So the Mac, the map here is given a cow structure and cow two owned. Oh, into owned. Yes, into owned is what I mean. And then of course you know the. You can also do two owned.
02:34:53.665 - 02:35:32.709, Speaker A: So it's a reference to self, gives you back an owned version of it. By doing self clone into owned you can write a more efficient implementation of it. But for now we're just going to have intoowned a value of type vec Borrow cow store cannot be built from an iterator of elements of type string. Yes it can, by mapping this to cow owned. So the setup here is, you know, we map. This is an option. So we map over it.
02:35:32.709 - 02:35:57.705, Speaker A: So if it's none, it stays none. If it's sum, then we iterate over it. And this is a vector of potentially borrowed strings. We turn it into owned strings with cow into owned and then we map it back into a cow which is now going to be of any lifetime because it's owned. And then we collect it back into a vector which gets stuck into the option. This we haven't implemented yet. That's why we get that error.
02:35:57.705 - 02:36:46.705, Speaker A: Dependencies is going to be a B tree map. So that's going to be something along the lines of self dependencies.mapdintoiter.Collect. we're going to have to fill in the bits in the middle here. It's going to be a map from of key value and it's going to. We're going to map it to cow owned of k dot into owned and whatever the value is, which is going to be v dot into owned which we haven't written yet. So that's for dependency. So I guess we can write that the signature here.
02:36:46.705 - 02:38:47.075, Speaker A: So we're going to have dependency. We haven't written this yet and we'll have the same for package just to get rid of some of the errors that we're going to see further up. Right, so this is going to be this and then map box new and instead of trying to be all functional and fancy here we can just do P like so. And dev dependencies is going to look exactly like this business, except it's going to be dev dependencies and dev dependencies 2 is going to look exactly like this. Build dependencies is going to look exactly like this. And then features is probably structured exactly the same, except the inside is a vec of cows. We're going to have to do a little bit more, but more or less it's the same so f into iter except the value here is going to be into iter collect and it's going to have the same structure as this one where we map it to the own version of the string, map it back into account and then collect.
02:38:47.075 - 02:40:15.065, Speaker A: Oh, joy. What a method to write. Very repetitive, but so now we have a mechanism where we deserialize into a fairly compact representation. It's not interned string, Right? So there is still the argument that if cargo wants to use interned string they don't have the option the way we currently structured it. But it looked like the argument for making these intern strings in the first place was that were they're currently allocating on deserialize but this should not allocate on deserialize because we're using certiborrow so that should be fine. I guess we need to write this. So version here is a little interesting to me because here it's represented as a string, but we know that it is a semver version requirement.
02:40:15.065 - 02:41:17.785, Speaker A: So I actually think that this isn't that it is a semver version rec. The weird thing about doing it this way is that semver version recs are internally a vector of comparators, which means that this is going to allocate on every on every deserialize, which might be sad, but they already have a bunch of other strings in here. So I think I'm not too concerned. I kind of just want to keep this the way it is. So that means this is going to be self dot. Here's another question. Is version here ever none for a dependency? I don't think it can be.
02:41:17.785 - 02:42:11.825, Speaker A: So remember we looked at the dependencies that get generated here and for mapping the dependency list, simples get mapped to sum. I guess there's technically no, check here. That version isn't set. But if you tried to declare a dependency on something where the version isn't set, then it wouldn't have gotten published in the first place. So while the. One of the, one of the things that we're running into here is the fact that the cargo definition for toml manifest is used for a bunch of different things including just parsing the raw TOML that the user has written. But the toml that the user has written can have all sorts of errors in it, like not specifying the version for a dependency.
02:42:11.825 - 02:42:37.925, Speaker A: So we need to be able to parse it and then realize that is the case and give an error. But for anything that actually ends up in a published crate, it should never be empty. So I think we're going to do this. And this is probably the case for other things too. Not for all of them. Right. So for features, for example, it's totally valid to not specify features for dependency.
02:42:37.925 - 02:43:01.935, Speaker A: Does it force them to be some. No, it just clones it at is. Yeah, that makes sense. Great. So now we can write this. A version is going to be self.version. clone many of these which are just really strings is self.regist
02:43:01.935 - 02:44:23.291, Speaker A: doesn't have to clone even registry map cow into to owned cow owned index is going to be the same features is going to look like the one we had up here. This business optional is just self optional that's already static. Default features is going to be self default features. This is going to be the same except two package is going to be like this is an option cow stir and target is going to be the same. Great. And then for package we're going to have to do the same kind of thing here. So most of these are just option cowsters.
02:44:23.291 - 02:45:41.255, Speaker A: So for a lot of them, in fact, in fact, here's what I'm going to do. I'm going to say that for all of these 15 sub good old regular expressions, we're going to substitute that with map cow into owned map cow owned comma. And for some of them that's not going to be right. Right. So for this, for example, it's going to be just going to be this, right? Did I mess up a thing? There we go. Authors is a vector. So it needs the slightly more advanced treatment up here which is this thing.
02:45:41.255 - 02:47:11.685, Speaker A: What else we have readme is string or bool keywords. So keywords is like authors, categories is like keywords. And the string or bool thing we're gonna have to figure out because that should really be like Cow stir or bool like really version is this self version doesn't need any mapping and then I guess this is just going to be self readme for now. Okay. I don't even know if cargo features makes it in here. So the cargo features here, they're not features the way you normally think of features. They're cargo feed.
02:47:11.685 - 02:48:30.885, Speaker A: They're features of cargo that you enable for a particular cargo Toml like for example, you can say things like oh, I want to use like Resolver version 2 and I don't think that ends up anywhere. This has the schema for the index, but it doesn't have the cargo features. So this means that in dot gray cargo features can go away. Package does need to stay although still convinced we actually need the boxing anymore because package is a lot smaller now but it is an option. So like although actually I don't think it is an option because we're not going to have work workspaces here. So this is never going to be an option. It's not going to be an option because in the cargo automobile that goes in a published crate there is only one package.
02:48:30.885 - 02:49:55.905, Speaker A: There's no workspace, there's a single package, which means we know there's a package there, so it's no longer an option, which means this goes away and this is just self package dot INTO owned. Great. I really want to get rid of the dev dependencies 2 stuff. The tricky part here is that I guess we could deal with it in a custom implementation of deserialize actually because from memory, you know, if we go back here, it really just treats build dependencies and build dependencies twos as the same. And so we could do the same here and say rather than have two fields have a just have a custom deserialization here. Now the other way to do this and I wonder if this would come back to bite us. I'm going to go ahead and claim that it won't and do this.
02:49:55.905 - 02:50:41.175, Speaker A: So serdealous is a way to say oh, that also caught a bug that's supposed to be build dependencies. Did I? Didn't I copy that from Cargo? I think I copied that from cargo. Apparently not. Okay, my bad. So this is telling Serdi that this can also be deserialized under this name, which I think is what we want here. And there's always only going to be one or the other. I guess the thing to check here is this is going to be bright.
02:50:41.175 - 02:51:57.445, Speaker A: I think, sorry is field attributes deserialize this field from the given name or from its rust name may be repeated to specify multiple possible names for the same field. And it's only for deserialized. So I think that's the behavior we want here, rather than having all of these twos. So that gets rid of this and this. And we can do the same over here, which is alias to that. And that way we don't need to deal with default features two here. I think that's the only two in dot CREATE files a cargo dot TOML manifest from a dot CREATE file from or for.
02:51:57.445 - 02:53:14.397, Speaker A: So this is now looking pretty reasonable, right? Like the things that go in there ultimately are the definitions of the package, the list of dependencies, list of dev dependencies, list of build dependencies, and the features. And for the definition of a packet, the definition of a dependency, it is the version, it is the registry and the URL of the Registry. I don't believe that the URL of the Registry field is an internal implementation. Detail. When Cargo creates a package, it replaces registry registry index. So the manifest contains the correct URL. So that raises the question of when this writes out the registry, what does it write? Because I definitely saw something about this changing the entry for the registry.
02:53:14.397 - 02:54:00.689, Speaker A: But maybe I'm lying. Package package package package workspace equals none. Package project Something here is a lie. I'm pretty sure we saw something that rewrote the registry name to a registry index in here. Aha. Map dependency. Yeah, Register specifications are elaborated to the index URL.
02:54:00.689 - 02:54:36.055, Speaker A: So it removes the Registry and sets registry index. So that means this field is not there or it's not relevant. The Registry index is. The reason for this is because, and the comment that I just removed said this too, that Registry names are entirely user defined. So you and I can both have the same registry URL configured as different names on our machines. So the name is sort of irrelevant when you publish. All that matters is the canonical URL for the dependency or for the registry of the dependency.
02:54:36.055 - 02:55:23.955, Speaker A: So registry index makes a lot of sense. Features, which are the features we enable of that dependency. Optional is whether it's optional default features is whether or not we enable default features package packages for whether we rename this dependency when we bring it in. And I have a feeling that also gets removed. Actually, that's a good question. If I go to index, does it have package? I feel like it probably does not, because it would be kind of weird if it did. Depths is dependency.
02:55:23.955 - 02:56:01.245, Speaker A: It does have package. Interesting. I'm surprised that it's even necessary for the renames to be known to the Resolver. So when I say renames here, it's the fact that you can do something like num 5 equals version equals version equals 5 package equals num. And what this means is it's going to look for nom. The crate name is going to be nom and it's going to look for version 5. But internally in your crate you can refer to it as num5 rather than nom.
02:56:01.245 - 02:56:51.879, Speaker A: And this is part of the reason you want to do this is so that you can do this kind of thing. And now inside of my package I can do things like use num7 colon colon foo. Oh, hey, spam. So. So that's the kind of thing that it's trying to do with spam, spam, spam, spam, spam them. So that's what it's trying to record with this extra field. But I'm curious why this is even why the resolver why the index needs to know this.
02:56:51.879 - 02:57:58.605, Speaker A: Because the index should only care about the package name because that's the actual dependency that is taken. Maybe it's because otherwise it would be annoying to deal with uniqueness. But that means package does stay in there and target. Why does target go in there? Target is in there because you can have target specific dependencies dependencies. So in your cargo toml you can say something like target x86 64 unknown Linux new dependencies nom equals 7 and what this will do is only bring in the NOM dependency if you are building for this target. And so that needs to be known to the resolver because it needs to resolve your dependency closure and download your crate files and stuff depending on your current target. And so it needs to know the fact that it's a target dependent target dependent dependency.
02:57:58.605 - 02:58:49.077, Speaker A: All right, so I think everything that's left. Oh, right. And for package the addition I don't think goes in here because it shouldn't have to and it doesn't go in publish. So addition we're going to move away the rust version doesn't currently but is going to and so I'm going to leave that in for now. Name of the package obviously goes in there. Version obviously goes in there. Authors does go in there and should be under package metadata really links does go in there right here.
02:58:49.077 - 02:59:38.715, Speaker A: It needs to be known to the resolver because you're only allowed to have one crate in the dependency closure the links to any given shared library and for package metadata, authors so the authors and the description, basically anything that's free text. So authors, description, homepage that Kind of stuff doesn't go to the index, but it does go to publish. Why does it go to publish? It's a little unclear. Like, arguably this could just be extracted from the crate file instead of being read as part of the JSON payload that gets submitted with the crate file. But this is probably partially because Crate Studio doesn't want to have to parse the cargo toml. But maybe now that they can, it no longer needs to come with the JSON payload as well. Well, it's hard to remove after the fact.
02:59:38.715 - 03:00:55.105, Speaker A: So authors description, homepage documentation readme, keywords categories license license file repository resolver. Well, so the resolver version I don't think goes in the publish and I'm. And I'm fairly sure it doesn't go in the index either. So this is. There. There are multiple versions of the resolver. There's the cargo resolver version one and the cargo resolver version two.
03:00:55.105 - 03:02:08.415, Speaker A: And they have. There's a blog post about it. They're like a bunch of. There's a bunch of changes to how Cargo interprets your dependency glass graph, how it unifies version choices across say build and dev and normal dependencies. Now the question here is whether this version field in the index is the same as the version of the resolver or whether it's independently like a versioning for the index line. This feels like it's not related to the resolver, like reading the text. This seems to be more about the ability to make backwards incompatible changes to the index format itself.
03:02:08.415 - 03:03:35.879, Speaker A: So I don't think the resolver version makes it in here. The other thing that's interesting is it looks like the JSON metadata doesn't include information about the index entry version which. Which must mean that. Okay, so then the, then the question becomes where does the V come from? So this would be in crates IO when it generates the index entry V. So that's just from crate. So when it creates the crate for the for a publish not in verify tarball but somewhere up here it did right? New crate encodable crate upload. Somewhere here create exists.
03:03:35.879 - 03:05:02.415, Speaker A: So this is. Looks up the crate by name to check whether this is a new crate or an update. That's fine. Max upload size put somewhere here it must set the version new version right and then add dependencies update create that's updating keywords verify tarball, render and upload features here V or where does V come from? So V is set depending on whether features two is empty or not. So this is something that we're going to have to encode in our like this kind of logic which is going from what was in publish dictates which version we're generating. And so this, this implies then that the V is unrelated to the resolver version and also related in the sense that only with a new resolver would you set features to in the first place. But it's not encoded in the upload information.
03:05:02.415 - 03:06:11.065, Speaker A: Okay, so that means that if we go back to the dot crate, the resolver version here is not relevant and we can get rid of it. Sweets. Okay, so we have dot create and the next step now is the publish. So we're first going to have to agree on like how to, how to model these. And it's going to be something along the lines of I guess create version, it could be called publish. And we're going to implement want to implement from super doc crate normalized manifest for create version. And we also probably want to be able to go the other way around.
03:06:11.065 - 03:07:57.745, Speaker A: No, we can't go the other way around. It's actually, I think it's a, I think it's a one way conversion and we're going to have to implement that at some point and create version we're going to have the same kind of thing where we do tick a. And so now the question becomes what definition of crate version do we want to use? And I think the one where the data structures are the most important is going to be the index one because that's where I think the definitions in the crate index crate are particularly performance sensitive because there are so many instances of it. Whereas this published manifest, there's only really one at a time. So here I think it probably doesn't matter which one we use. I guess we can start with the cargo one and then unify. Oops, that's not what I wanted to do.
03:07:57.745 - 03:08:52.485, Speaker A: I was trying to be smart to make a macro and instead I messed it up. That's also not what I wanted to do. There we go. Did I mess up my macro? There we go. I love Imacros, they're great. I'm tempted to just say we're not going to send badges. We're not going to send badges.
03:08:52.485 - 03:10:15.151, Speaker A: So that's going to be one of these. And we're not going to be fancy, we're just going to call it dependency and love that. I think you can put 30 borrow here. Oh, I guess not. Too bad. Okay, so this is going to be a cow take a stir and certibor sortie borrow certiborus certiborrow certiborrow 30 borrow. And actually this reminds me, there's probably a couple of these where we want skip serializing if.
03:10:15.151 - 03:10:53.115, Speaker A: Skip serializing if. Skip serializing if. Skip serializing if. I'm probably up here too. So the skip serializing if is just. If this thing is none, then don't include the field in the message that you send. Although I don't think we actually do that.
03:10:53.115 - 03:11:31.025, Speaker A: Want to do that for the JSON payload because the receiving end might actually require it. It's interesting that it's specifically set on these, though. So let's create version. These are all borrowed. Everything is happy. All right, so now we got to combine this with the stuff from Crates IO. So they want custom types for the names.
03:11:31.025 - 03:13:16.925, Speaker A: So there are a couple of paths we could take here. Right? One is to say that we expect Crates IO to adopt this data structure throughout their program for anything that's a crate upload, which would imply that here, for example, we need to have our own custom type for vetting that or validating that the format of the name is correct. The alternative is that we say we expect them to deserialize into this, and then after deserializing into this, they can then fallibly convert into their own type, which has special types for all of these. That might be better rather than us trying to have generics for all of these is to say they're going to write a function that's going to be of the form try from, you know, cargo. What do we end up calling this? Cargo Index Transit Publish Crate version for encodable crate upload. They're going to write this, and in there they're going to have all of their mappings of names and versions of whatnot to make sure that they conform to whatever requirements that they might have. But I think that feels nicer than us trying to make all of our fields generic over types that they control.
03:13:16.925 - 03:14:24.123, Speaker A: So I think actually that's the path I want to take. Okay, they have default on keywords and categories, which suggests that for keywords and categories we can have keywords skip serializing if VEC is empty. And we do the same thing for categories, because we know that the Crates IO side has default for them, which also means that we can add default for them. Same thing here. It means that we want default for this and default for this, which also should mean that they have default for those. Oh, they also have default for links, so we'll want to add that here. So what do they have? Oh, interesting.
03:14:24.123 - 03:15:26.539, Speaker A: They don't have a default There, I think that's because option is treated specially. Option already basically implies default. I think so I don't think they would have needed it on links. Default does need to be set on Vex though. We should have tests for this though, to make sure that that conversion actually does the same thing that they expect it to do. Now, dependency kinds is another one of those where we want to think a little bit about what we want to do here. Because as far as cargo is concerned, where is this depths dependency? Dependency kind is just a string, but as far as crates IO is concerned, it has to have a particular set of values.
03:15:26.539 - 03:15:58.425, Speaker A: So. So I think we actually want to keep that mapping that they have. I don't know why they have the numbers. Oh, that's for mapping them to database IDs, which we don't need. So we don't need the repper here. But that way we can say for dependency kind. So this doesn't need to borrow anymore and this is now dependency kind.
03:15:58.425 - 03:16:51.275, Speaker A: Okay, and the other thing that strikes me here is for encodable crate version, that's a semver version, whereas currently cargo just treats it as a string. So I think here too we're going to say semver version. So we're going to require that Cargo sends it as a sember version and that creates IO will receive it as a sember version. Now here too, you know, we could have a cow here to say that if you already have the semblance version somewhere, we're just going to reuse that one for you, but. But let's just leave it owned. I don't. I'm not too concerned about it in the context of publish.
03:16:51.275 - 03:17:21.513, Speaker A: Do we have anything else? That's weird in here. So B tree map. This seems to be an agreement about features. That's probably because of ordering. So I guess actually what I probably want to do here is go field by field. Encodable crate name is a string and we encode it as a string. This we already dealt with.
03:17:21.513 - 03:17:50.215, Speaker A: Depths is a vector of encodable crate dependency. Encodable, right. A vector of dependency, which is what we have up here too. It is a vector of dependency. So dependency has. Let's grab this one. I just want to hoist it up here to see that I haven't like missed any fields or they're encoded differently.
03:17:50.215 - 03:18:12.145, Speaker A: Optional is a bool. Okay, so that one we've dealt with default features is also here and it's a bool. That's fine. Name is an encodable create name which we know is just a string, so that's fine. Features is a vec of encodable features. Vec of strings. Encodable feature is string, so that's fine.
03:18:12.145 - 03:19:13.845, Speaker A: Version rec is encodable create version rec and encodable create version rec is treated as a string by crates IO and version rec here is also a string. This one's also interesting because here I think we can do better because we can say that this is a version rec and actually provide this as a stronger requirement than just a string. Target is an option string. Option string kind they have as an option dependency kind. So I guess this is an option for dependency kind. Although it's interesting because a cargo treats kind as just a string. It's not an option, it's not optional.
03:19:13.845 - 03:20:06.643, Speaker A: So that makes me wonder. Cargo and crates IO have this as string, creates IO has this as option. But I don't think it's actually an option. I think it's required. And I guess for version we should note that cargo has this as string, so that's kind. Registry is an option string, so that's fine. Explicit name in toml encodable dependency name and encodable dependency name is a string which is a string here and it's an option.
03:20:06.643 - 03:20:59.485, Speaker A: So this explicit name in TOML is. It's sort of encoding the inverse of what we talked about for package, right? So I gave the example of this. So in the cargo automobile, the structure is name equals and then stuff package equals something in the publish metadata. The way we encode this is Dependency name num Dependency version 5 Explicit name in toml for the dependency, see num 5. So the mapping is inverted. And we'll see this pretty easily once we go up and define this from. All right, so now it's time to look at these.
03:20:59.485 - 03:21:30.379, Speaker A: So we already looked at name and version and depths. Features is a b tree map of string to vector of string. Encodable feature name to encodable feature, encodable feature name to feature. Those are all strings, so that matches. Description is an option string. That's what we have. Homepage is an option string.
03:21:30.379 - 03:21:50.325, Speaker A: That's what we have. Documentation is an option string. That's what we have. Readme and readme file are both option strings. That's what we have. Encodable keyword list is vec encodable keyword. So it's a vec of string and keywords is a vec of string.
03:21:50.325 - 03:22:07.033, Speaker A: And they have default. We have default and we don't include it if it's empty. So that seems Fine. Categories. I'm going to go with this. The same vec of string. Okay, so these are all fine.
03:22:07.033 - 03:22:35.495, Speaker A: License and license file or option strings. Repository is option string and links is option string. With default it doesn't need default. Default is already none. Okay, so now this mod can go away. And now we got to just implement this bit which is going to be. It's going to emit a create version.
03:22:35.495 - 03:23:32.595, Speaker A: I'm going to call this M because it's going to be tersor. So this is going to be an M.OH. create. All these fields have to be published and all the fields here have to be pub. And all the fields here have to be pub. Oh, so many. So this is going to be m name package.name
03:23:32.595 - 03:24:13.725, Speaker A: I can't spell. This is going to be M package version depths we'll get back to in a second. This is going to be M dot features. It's going to be some M features. It's an option here. So this is going to be unwrap or default. Although features and features 2.
03:24:13.725 - 03:24:53.485, Speaker A: Ah, so this bit we might actually need to. We're going to have to encode this bit for detecting what should go in Features two and what should go in features. This stuff is like magic. That's going to have to go in our conversion from this into index. That's fine. Authors is going to be M package Authors and that's also going to be unwrap or default. Description is going to be M package.description
03:24:53.485 - 03:26:02.465, Speaker A: I love macros so much. Now readme is a string or bool here, so we're gonna have to map it. Readme file Keywords is going to be an unwrap or default and same thing here. That's interesting. So readme has some special mapping here which I think we saw in our Prepare for Publish license file. Ah, I'm in the wrong one. I need to look at registry publish.
03:26:02.465 - 03:27:20.645, Speaker A: No, I need to look at the part of Cargo that actually does the publisher. Where did it go? I knew I had it here somewhere. Not the package part, but the actual publish part, which I thought was over here where we saw transmit. No, this is the mapping of the manifestation. Where on earth did I put transmit? Well, I'm gonna have to go dig up where I had FN transmit. It's over here. I thought I had it open in a tab, but apparently not.
03:27:20.645 - 03:28:17.641, Speaker A: Right, so this is the thing that actually generates the dependency list and the. Right, so the publish here. So what you see for a lot of it is copies of stuff out of the manifest, dependencies is treated specially, features is treated specially, and readme is treated specially. So what is readme here? Readme gets set to exactly what comes out of the manifold manifest. Although that's a string or bool. Oh, right. And the bool here just means readme md.
03:28:17.641 - 03:29:25.235, Speaker A: I'm pretty sure we could look that up too and say, hey, is there mention of readme MD here? That's not what I wanted. Is there a mention of that in source? I want the contents readme md not files called readme MD here. Probably readme for package. If it is set to true, that means readme md. So this is going to be match on that. If it's some string or bool bool true. If it's false, then it's none.
03:29:25.235 - 03:30:28.255, Speaker A: If it's this, then it's cowboy. Well, I guess we can just do readme md.into and none here maps to default read me from package root. I'm curious whether readme does that even get called here? It doesn't get called here. So something must call it when it generates the manifest metadata somewhere. It's interesting. So none is going to be this default read me from package root which tries all the files to see if they exist.
03:30:28.255 - 03:31:17.675, Speaker A: Oh boy. So this one's tricky because it depends on file contents in the create file. Because we actually wanted get set to is file system dependent. And I think the license file is the same actually, because I think if we look at transmit here. Oh, it just complains of the license file doesn't exist. That's fine. But for readme it actually includes the readme contents, which also depends on the.
03:31:17.675 - 03:32:23.281, Speaker A: Yes, a readme file gets set to readme. So actually I lied. It's the yeah, it's this and read me gets set to read me, but read me is like the readme contents. And so this is going to be a little weird to map. We could always just set it to none. Right, but really it's supposed to be this. So that's very much of a.
03:32:23.281 - 03:33:17.109, Speaker A: Very much of a to do here. Why does it. Oh right. So we're going to figure out what to do about the readme. Because if all we're given is the parsed manifestation, we don't have access to the files that were next to the manifest inside of the craytarball. It might be that we just have to say none here. It's interesting too, because it feels weird for this logic to live in cargo on publish as opposed to in the thing that renders reads mes okay.
03:33:17.109 - 03:33:37.825, Speaker A: And then depths is clearly special because it has all this mapping that happens up here. So let's see. Let depths. Let's. It's going to be depths. Let depths equals package dependencies. So that's going to be M.
03:33:37.825 - 03:34:26.673, Speaker A: Ah, equals vac. We're going to do with capacity M. Dependencies.map B tree map Len. Mmm. So what I really want to write here, right, Is something like plus plus. That's what I want to write.
03:34:26.673 - 03:35:25.595, Speaker A: But it's real ugly. Fine, we'll leave it for now. It's fine, it's fine, it's fine. Actually, we can do this in a better way, which is we can do m dependencies. Flat map chain m.dev dependencies flatmapd chain. And the reason why it's better to use chain here is because, at least in theory, chain should be able to realize what the upper bounds or even what the size is of this iterator.
03:35:25.595 - 03:36:06.047, Speaker A: And so we shouldn't need to first collect into a vector dot flatmap. Which means I don't even need flat map. I just need map, which really means it's into Iter.map here too. Into Iter.map. you'll notice that I do this a lot where I just write the code really far out to the right and then I just let rust format make it nicer for me afterwards. There you go.
03:36:06.047 - 03:36:59.895, Speaker A: And then I can start actually doing something reasonable with it. So what do we do for these dependencies? Well, it says skip dev dependency without version. I wonder what this is for. Right. So anything that's transitive, which is not going to matter to us because we're only looking at the things that are in the manifest, which are direct dependencies by definition. Specified rec. Specified rec do.
03:36:59.895 - 03:38:14.093, Speaker A: Okay, well, that's unhelpful. Inner specified rec. I see. Specified rec is just. Does it have a version specified? But anything that's in the normalized manifest must already have version specified, because anything that doesn't would already have been removed as part of the normalization. So we don't need that part registry id here, web apn none means from the same registry. Whereas in cargo.toml
03:38:14.093 - 03:39:17.575, Speaker A: it means. Oh, that's interesting. Okay, so what this is saying is, okay, I'm going to map all of these in a very simple way to be D dependency kind normal. So it's just going to be a tuple. This is dev and this is build, and then we can map across all of them at the end. So this is going to be now dependency. It's very unhappy with me.
03:39:17.575 - 03:39:41.907, Speaker A: That's fine. One of the found closures. Something's unhappy with me. What's this? One of the found closures. Oh, I see. Mismatched types. Right.
03:39:41.907 - 03:40:22.145, Speaker A: So this has to be just like they do over here, A dot collect. That's fine. Now it should stop yelling at me. Okay, so whether it's optional is going to be D dot. So I want to hear let D kind is D, which just means I can do D kind here because arguments are patterns. So kind here is. Now this optional is d dot optional.
03:40:22.145 - 03:41:29.575, Speaker A: Oh, right. D here is actually the name in toml and the dependency definition. So explicit name in toml is name in toml. So this is where that inversion happens. And in fact depths here. Right, right, right, right. So name here is going to be d dot package default feature is going to be D default features version trick is going to be D dot conversion rec, which is just the dot version.
03:41:29.575 - 03:42:37.955, Speaker A: Right. If we go back to dot crate for dependency for dependency version is what gets set into version rec. Target is d dot target registry is D registry URL. Right. What else are we missing here? Features is D features. Expected B tree map. Interesting why I messed up my types here somewhere.
03:42:37.955 - 03:43:12.195, Speaker A: Expected B tree map. Oh, it's because this is an option. So unwrap or default on this. Unwrap on, default on that. Okay, so what do we have here? Is optional. So is optional is defined as inner document optional. Okay, that's relatively unhelpful.
03:43:12.195 - 03:44:37.085, Speaker A: Where does inner dot optional come from? Optional is false. New parse. So where does the serialize dependency Optional Optional Here is the bool. So where does the default get set? I mean, we know the default is false, so if it's not set, it's false, Right? So if optional is not true, then it's false because things are not optional by default. Default features is true by default name. Okay, so this one's going to be a little interesting, I guess for default features it's probably going to be the same kind of thing. It just delegates to the inner Yep, so that's relatively uninteresting.
03:44:37.085 - 03:45:45.855, Speaker A: Package name is inner name. The name of the package that's dependency depends on. Usually this is what's written on the left hand side of the dependency section, but it can also be renamed via the package key. Both of the dependencies below return foo for package name. Right, so this is if the package name is specified, then that is the name of the true name of the dependency. Otherwise it is name in toml features. We want a VAC of features.
03:45:45.855 - 03:46:15.345, Speaker A: And this is just an unwrap or default. That's easy enough. Versionrecus version. Target is target, kind is kind, target is platform. That's fine. This is where that mapping happens to dependency kind. Registry is dep Registry, which we're going to have a look at.
03:46:15.345 - 03:46:59.715, Speaker A: And explicit name in toml is name in toml. So this is actually if. No, this is always the name in toml, right? Or is. So here's a question. This is supposed to be an option. When is it set to none? Supposed to name in Tom? Is this like if they differ? If the package key is used, then this returns the same value as name in toml. Okay, so this is only.
03:46:59.715 - 03:48:09.875, Speaker A: This is only set to sum if package is set. So this is if. Okay, so we can actually make this a little bit nicer for ourselves by saying let explicit name and name be match name in Tom and D dot name D dot package. And then this is now going to be name. It's going to be name. This is going to be explicit name. And here we're going to say if package is some and name is sum, then the explicit name is the name and the name is the package name.
03:48:09.875 - 03:49:26.715, Speaker A: If the pack. If the. If the name is set but package is not, then the explicit name is none and the name is the name that was specified. So to make this a little clearer, perhaps this is a explicit name equals package equals name. This is a explicit name equals nothing. This is always N. And I think those are just the only two cases right.
03:49:26.715 - 03:51:25.665, Speaker A: Now the question is, if you specify, if you use this syntax but use the same name here and here, should it be some or none? Okay, and then what happens to Registry URL? So that's dep Registry, which is an interesting mapping. If the dependency is from a different registry, then include Registry in the dependency. In the index and web API, none means from the same registry, whereas in Cargo toml it means from Crates IO. Right. So here, when we say when Registry index is set to none here, what that means is fetch it from Crates IO if it's set to none in the dependency specification that gets sent to Crates IO, it means this is not from a different registry. That's what they're saying here. So the way we're going to have to structure this is something like depth is to do for now Registry D, which is to say we're going to match on d dot registry if it's at the sum and that means not necessarily from crates IO if it's set to none, that means from Crates IO.
03:51:25.665 - 03:52:18.505, Speaker A: Right. And then this is where it gets complicated, which is if it's from crates IO, then we actually need to. Okay, so here we actually need to know. Ah, this is annoying. So this conversion can't quite be this simple because the JSON payload we send here differs depending on what registry you're sending it to. If you're sending it to Crates IO, then Crates IO dependencies will have none set up as their registry. Oh, that's awful.
03:52:18.505 - 03:53:45.329, Speaker A: It makes me very sad. So this isn't a pure confirmation version. All right, so that means this is going to be something like simple this. And we're going to have to take A is 4 and that's going to be the registry ID, which if it's cratesio URL is Ah, dep. Oh no, I lost my place in the file. This file is too big. Somewhere over here.
03:53:45.329 - 03:54:30.815, Speaker A: Yes. Okay, I found it. Let me do this. So what I want here is for this thing. This then uses the URL of this, which is this URL. Which is this URL. So this then is going to be.
03:54:30.815 - 03:55:47.795, Speaker A: Is from here. Actually this can just be this then R is from target registry. So this is going to be target Target Registry Dependent Source Registry. It's a really weird field. It's going to be if is from is equal for. Is is equal to is for then none else sum is from target register. Target Registry Dependent Source Registry.
03:55:47.795 - 03:57:47.945, Speaker A: Right, and this then is going to be Cow Borrowed. Who? That does make me really sad that it's not a straight up conversion. I still don't know what to do about the readme actually, because like this is also a to do, right? It's like a match on readme readme contents. I don't understand. Why is it complaining about these? Oh, and Stringer bool in dot crate needs to be public, so we're going to do pub use de Sir String Expected option found. Wait, this should be fine to do matches every type. Oh, also, it looks like I don't need Chrono anymore.
03:57:47.945 - 03:58:45.555, Speaker A: That's nice. But what if I swap these? Why is it complaining that the match arms have different types? This to do should match that none. Oh, I wonder if it's okay. So let's read me options. Yeah, it's probably this. So I need something like cow ticketster. No, it still won't let me do it.
03:58:45.555 - 03:59:33.627, Speaker A: Type option that expected enum option. But. But the never type should should be compatible with option. Interesting. What if I do like to do to do. Is it. Is it okay with that? No, that's Interesting.
03:59:33.627 - 04:00:21.855, Speaker A: I don't know why it won't let me compile this code. I guess I can just do this and then do like this. It's not what I want but see this is the reason why I didn't want it is because I then fine. Okay, how about if I do this, is it going to let me do read readme MD if I make this not an option? What? That's fine. And also what do you mean that's a non exhaustive pattern? Some str. Oh, right. Of course.
04:00:21.855 - 04:01:36.795, Speaker A: String path cannot return value. Referencing local data deregistry index. Right. We're because we're consuming this one. But so the reason this gets weird is because registry index here should be a. It's a cow stir but it should have the lifetime of tick A already because that's what we're both giving in and giving back. So I think that's a lot.
04:01:36.795 - 04:02:59.375, Speaker A: Oh, I. I guess it's because it's not borrowed, has to be taken ownership of and then this can be this and this is going to be cow borrowed. Great compiles. I mean, we still don't know what to do about the readme but. But I'm gonna go ahead and ignore that for now because I like ignorance. Okay, let's move to index. Oh, so index is going to be probably the biggest pain here because because of all the optimizations that we've said, I'm inclined to start with the cargo type here because ultimately if you stick something in the index the cargo doesn't understand, then people aren't relying on it because they wouldn't be able to build it.
04:02:59.375 - 04:03:57.265, Speaker A: So the cargo one must be right here, at least when it comes to deserialization. So that's what I want to start with now, the intern string here. So the problem with something like this here is that true, it means that you can continue to reference what's in the JSON byte buffer that you originally parsed. The downside is that might go away. Imagine you're writing the resolver and as part of it you're reading a bunch of index files. You're probably not keeping all of the read files in memory as you go. You're going to read a file, parse it, and then drop the file, but still want to keep the index reference.
04:03:57.265 - 04:05:24.167, Speaker A: So at that point you're going to have to turn this into an owned version of itself. But at that point you're just allocating a string, which is what we want intern string for. So the question then becomes how do we want to represent this. This is also the place where we have the most of like the small stir stuff that is in the crates index crate here. It is kind of tempting to make basically all of them be generic. Now there's a question of should they all require to be the same generic or can they be different? I think they might have to be different because this is another case, right, where like the version here really is supposed to be a semver version. But in the crates index case, I don't think they actually want to store semver versions because they are relatively large.
04:05:24.167 - 04:06:48.385, Speaker A: Right? Like they're a vector of comparisons which are themselves not tiny. I guess a vector is small, but smallster probably does pretty well actually with semantic versioning requirements because very often they're very short strings. So this, this does feel a lot like a case of let every use of this dictate its own type for most of the types. It's also very interesting to me that the cargo uses interned strings for all the features, whereas like Crates Index does not. You know, it uses just straight up strings. It might be because in Cargo the crate name and the crate features end up being like copied in a bunch of places by the resolver because it needs to keep track of what features it's enabled and everything. So they actually get cloned a lot, whereas something like the checksum for example does not.
04:06:48.385 - 04:08:33.425, Speaker A: It gets read and checked once and then it basically gets ignored from that point forward. So my suspicion here is that it makes a lot of sense for Cargo to treat features as interned strings and it doesn't really make sense for creates index because it's already behind a map abstraction, so it's already, already small. I think the way I want to structure this is I'm going to start from the cargo one and I'm going to say that we have a couple of generics. We have name, version and features and. And then I'm going to disagree that this is a string. I'm going to agree with creates index that this is a checksum that is hex encoded yanked as an option. Bool.
04:08:33.425 - 04:09:25.097, Speaker A: Yeah, this doesn't need to be an option and even if it did, it can just have default set. It's interesting that links is treated separately. What does crates index encode links as? It's a small string. Yeah. So I think links then ends up being separate. Again, it's tempting to make it similar to features. I don't think there's a strong reason not to.
04:09:25.097 - 04:10:02.939, Speaker A: But like in Cargo, for example, Car cargo uses the same for I guess Cargo uses the same for them. Ah, but Crates Index does not use the same thing for links as it uses for features. It actually uses the same thing it uses for Name, which Cargo also does. But tying them to name seems weird. So let's do Link and say that links here is going to be this. Okay. And then the next question is for these, for features, it doesn't need to be a B tree map.
04:10:02.939 - 04:10:52.995, Speaker A: I don't think I agree with Crates Index, which says that it's a hash map. But Crate Index wraps this behind an option box to make it smaller. So one question here is whether these optimizations also make sense for cargo. Right? Like Cargo is not going to complain if things get faster. So we don't. We don't need to have an exact mapping to the way that Cargo holds this data at the moment to reduce the size of the start. When the field is unused, that is almost always.
04:10:52.995 - 04:11:34.255, Speaker A: I don't think it's true that it's almost always unused anymore. Because Features two. Oh, right. Features two is only for things that newer Cargo understands. So if we go back to the Crate scio code here, Features two is anything that is a weak dependency and there are relatively few weak dependencies. So usually the list of things that goes into Features two is empty. Right.
04:11:34.255 - 04:12:36.127, Speaker A: So I think I agree with this part that Features two can probably be an option and you know, making it a box, it's wrapped in a box to reduce those. So we'll do. I think we'll do this. I think. I think I like that idea. And then for features, there's a. It uses arc.
04:12:36.127 - 04:13:45.805, Speaker A: I'm curious why it uses ARC for features. I mean, I guess ARC and clone are basically equivalent, really, in this kind of use. The question is how often do you want to clone the set of features? I wonder if there's an explanation for this. Like if we go to Rust Crates Index and we look at source lib, I want to look at the blame for features. This seems to be the thing that moved everything to have arcs lower memory usage by deep duplicating versions data. What confuses me here is where does the deduplication. Oh, I see.
04:13:45.805 - 04:14:18.311, Speaker A: That's sneaky. Okay, so this is primarily useful for Crates Index, which is when it parses the list of versions. The observation here is that for a lot of new Crate version, the list of features is exactly the same. So rather than store them multiple times, you just reference counted and store the reference counted one multiple times. I totally buy that. I totally buy that. That's useful.
04:14:18.311 - 04:16:49.035, Speaker A: And arguably for the dependency list too. So here's what I want to do here. I want to say that it seems totally reasonable for this to be an arc. And it seems totally reasonable for this to be an arc. These are ARC because of these are arc, they can be deduplicated easily by calling code if happen to be reading in all of the versions of a single crate at once. As versions often share dependency and feature as similar versions nearby versions where name implements, serialize and deserialize version I guess feature is really the end links a feature also have to implement or feature feature feature feature why? And this is just oh use standard from debug. Interesting.
04:16:49.035 - 04:17:36.011, Speaker A: Oh, why ARC and not rc? ARC is just more useful than rc. Like if it's rc, then there's no way for people to make it thread safe on their own. But if it's arc, you're paying a little bit more cost if you're in a single threaded context. But in your fear in a single thread context it probably doesn't matter to you anyway. Right? I forgot about this. So this is where we also need serde. Oh boy, sorry.
04:17:36.011 - 04:18:30.265, Speaker A: This is going to be bright. So SERDE has a special thing that you can use if you want to use generics in your type, which is what we want here. It's the bound thing. But that's not what I wanted. I wanted. I was hoping there was a way for me to just say also include this lifetime, but I guess not. Don't really want to have to rewrite the bounds myself.
04:18:30.265 - 04:19:19.769, Speaker A: All right, I'll leave that for in a second. Okay, so name and version are configurable dependencies. Features Features 2 doesn't need the deduplication, so we keep it as a box so that we have ownership of it. Checksum yanked links schema version this really doesn't need to be a U32. This can be a U8. What does crates index. What else this creates Index has is an ARC over dependency such that it is not a vec, it is a slice.
04:19:19.769 - 04:20:39.915, Speaker A: That seems fine because these dependencies don't need to grow and shrink. It doesn't actually need to be a vector and that saves you a little bit of space. That seems reasonable to me. It's interesting that this is an option box, because for links I don't think we need to box here because we can always say that for when crates index uses our crate, they can just set links to be box mulster so that box probably isn't necessary. What do they have for V? They don't even decode V, which is interesting. Okay, so that can go away now. And for dependency, serialize, deserialized debug.
04:20:39.915 - 04:21:34.255, Speaker A: There's an argument here that this no longer needs to be generic over a. Actually, because now all the relevant types are controlled by the caller anyway. Right? Those bounds are generated by serde anyway, so that's fine. This doesn't need to borrow. This doesn't need to. That needs to be generic. Probably over.
04:21:34.255 - 04:22:42.621, Speaker A: Probably over name, probably over feature because you'll want the same string representation in here. So what do we have? What do they use down here? Right. Dependency kind we already have. So we have dependency kind. Does it need to be an option option? This is super.create depend publish dependency kind they use for. It's interesting.
04:22:42.621 - 04:23:38.845, Speaker A: So for the inner features they use a different representation than for the outer ones. Box box slice. Oh yes. I mean this is all optimized for compactness over performance, but it's because usually you have a bunch of these fields you're deserializing, but a lot of them you're not even going to look at and so you would rather them not take up a lot of space. You can walk the memory more efficiently, for example, than you want to have the maximal performance when accessing any given field because you're going to be accessing relatively few things. So. Oh, public is here.
04:23:38.845 - 04:25:32.045, Speaker A: So I suppose that means I lied when I previously said that dependencies weren't public. That's frustrating because it does show up in the index right here. So that means the dependency here, which we got over from crate psio in crate, which is manifest toml all dependencies are private by default. TOM will manifest dependency. So where do we have toml dependency detail? Toml dependency Right. Public here is a no pub public option bool and I think that can. Does that even go into new crate? That's the other thing I want to know.
04:25:32.045 - 04:26:57.561, Speaker A: New crate. So it's not currently even sent as part of the. It's not published, but it does go in the index, which is interesting. So it's not a part of publish, but it is a part of dot created there and public is self public.and in publish it just ignores that because it doesn't go anywhere. And then for index. Right.
04:26:57.561 - 04:27:48.385, Speaker A: So now we're back to index. I'm torn here what to do with. I think you know this. This can certainly be box list of feature. Not sure why it's box box. It's box box because this is a slice, which means it's a dynamically Sized type, which means that box here is actually a fat pointer that holds both the pointer and the length of the slice, which means that this is 2U sizes, whereas a box box is 1U size large. But that could be remedied by doing this.
04:27:48.385 - 04:28:52.673, Speaker A: That has the same effect. Although the vec here, I mean, we could do the computation. Right? So a vec A feature is a use size for the length, a usize for the capacity and a usize for the pointer. A box vec feature is a usize for the pointer only. A box of slice feature is a use size for the pointer and a usize for the length. And a box box feature is a use size for the pointer only. So box vex vec feature and box box slice feature are the same size, but inside of the pointer here.
04:28:52.673 - 04:29:44.335, Speaker A: This is a usize pointer and a usage length. This is a usize pointer and a user size length and a use size capacity. So the hence box box feature. Right. So this one uses less heap memory than this one does. And there's an argument here for that means this should be the same. I'm curious what they do for.
04:29:44.335 - 04:30:22.875, Speaker A: I don't understand why I removed that original code from Registry index. That is over here. Not dependency, but the top level definition. They still use vex strings for the features inside of here. I guess it's because once you arc them, they're. They're less costly. But you know, you, you could trim some by doing this, but maybe it's just not worth it.
04:30:22.875 - 04:31:27.013, Speaker A: Like if you really want to trim here, you can do that. Okay, so back to this. So now there's a question of for requirements, they actually do need to have a different type than the version because one is a semantic version, one is a semantic version requirement and they're. They're just not the same. So for rec, we're going to take rec here and this is going to be recommended and I'm guessing for target as a. For target and for package. For both of them they're using box of small string.
04:31:27.013 - 04:32:07.897, Speaker A: Now I don't think small string helps you here because package and target are both usually fairly long. Are they longer than a U size? So target is usually something like x86, 64 unknown Linux GNU. A use size is 64 bits, which is 8 bytes, which is roughly 8 characters. So 1, 2, 3, 4, 5, 6, 7, 8. Right. So that's not going to capture your target. And same thing for package, package is going to be the name of the crate.
04:32:07.897 - 04:33:03.725, Speaker A: So that one might like if it's Nom for example, if it find into small string. But I guess for package it might make sense like small string might be able to save you some of the time. For Target I don't think it matters. So this now gets back to, you know, to what extent do we want these to be things like the features to be tied back to the input source. And I think actually Cargo has the same need here as creates index diff which is the input that you have. The JSON input is not going to be long lived enough that it makes did you get any value from having this tie back to the lifetime of the JSON file. And so as a result I don't think we actually need to worry about that.
04:33:03.725 - 04:34:16.355, Speaker A: I don't think there's a lot of value here in being able to do input variant or deserialization that's not owned because usually you want this to be longer lived anyway. So in that case the target here, Target I think might as well just be. I mean I guess it could be a box stir, right? So this again saves one use compared to string. And we could make the argument that this is Target is set rarely enough that you want to box box it because you want to save that extra bite anytime it is set, anytime it isn't set, which I'm actually surprised given crates indexes optimization here. Target feels like a good candidate for an extra boxing. Now package packages set frequently. Is is not set very frequently either.
04:34:16.355 - 04:35:51.314, Speaker A: It also feels like it should be tied to name. The question is whether we should box it because it's used rarely. Sure, why not? Now this feature list is interesting because I guess the question is how often do people pass features for their dependencies? And I think that's decently common. But again it's about having the most compact representation for that feature list depending on how often you think you're actually going to access it. I think this is probably fine. Now for targets, do we want to allow people to swap in their own versions here? Do you feel like this actually in certainly in Cargo this might make sense as an intern string because there are very few targets. So I think we're gonna make this be generic.
04:35:51.314 - 04:37:00.095, Speaker A: So that means that now also target not try get target. And so Target goes into here, Target goes into there to Target went there Registry. This one I think is very rarely. This one's very, very rarely set because usually the dependencies of a thing in a registry are from the same registry. It's very rare they're going to point anywhere else. I wonder whether they even bother to Deserialize it here. Yeah, see, they don't even bother deserializing it because it's just, it's so rarely set and in fact, I forget whether Crates IO even allows you to have cross registry dependencies.
04:37:00.095 - 04:37:45.645, Speaker A: But this certainly feels like one of those. Like we should at most be spending a U size on it. I wish we could spend less, but I don't think we can afford four to go quite as far as Crates Index does, because we do actually need to store this information because if it's set, it's relevant. Okay, so we have option, dependency, kind. I don't actually think this needs to be an option, but it doesn't matter. It'll get a niche optimization any way because there are fewer than. Fewer than 256 variants of the xenom.
04:37:45.645 - 04:38:44.467, Speaker A: Okay, and public, what did they say? Public defaults to somewhere over here. Too many tabs now. Public defaults to false. So that means this can be default serde default or actually I guess that means in the. Is really where that goes in fact. Yeah. So public here.
04:38:44.467 - 04:39:22.035, Speaker A: I guess this is reading things out of the index. This is saying if it's not set in the index, then assume that it's false. So in the index it would still be an option because you care whether it's explicitly set to false or explicitly set to true. Because we don't know the default in cargo might actually change. Okay, so now next question is. Right, so these for dependency kind. I guess we might as well be nice to people and bring over some docs here.
04:39:22.035 - 04:40:39.655, Speaker A: And we can also be even better and implement all the different nice things. This skips serializing on package kind and target. Package kind and target. In which case that would mean that we also need to derive default for them. Although I don't think there's actually a meaningful default for kind. But if it's not set, then we want to preserve the fact that it's not set. Okay, great.
04:40:39.655 - 04:41:15.955, Speaker A: So now I think we're aligned with Crates Index so they could switch to ours. Now they have all the information. Next is checking that this all still works with what Crates IO needs. So this is the definition from Crates IO. Oops. See that? That matches up with this. So create name.
04:41:15.955 - 04:41:38.387, Speaker A: They use a string. They use a string for the version. Both of those are fine. We allow them to be generic over them and they can. They can be the same or they can be different vec of dependency. We encode that as an arc of a slice of dependencies, but that should be fine for them. We'll check whether the actual registries are the same later.
04:41:38.387 - 04:42:28.389, Speaker A: Dependency types are defined later for checksum. They store it as a string. We actually parse it as a U832, which should be fine. It does mean that for them to get it out as a string it would have to be parsed out, but that's probably fine. I'm intrigued by the decision to store this as 32U8s because this feels like a thing you might want to box because you're then you're storing a lot less for each one, but you are also using a bunch of memory for every field. Just like 32 bytes is like a non trivial amount of storage. So the checksum that seems fine features.
04:42:28.389 - 04:42:52.595, Speaker A: They stores a map from string to string. We store it as an arc map and they can choose string to string. So that's fine. This bit let's add. Oh, they've actually copy pasted exactly the definition from cargo. So that's nice. And those are the same.
04:42:52.595 - 04:43:29.921, Speaker A: It's an option. It's just that for us it's an option box which seems fine. Yanked for them is an option bool. We've made it a bool that implements default because if the field is missing from the index, the field should always be in the index and if it's not in the index you should interpret it as not being yanked. So I think that's right. Links they have as an option string, we have it as an option link. So they can set that to string, that's fine.
04:43:29.921 - 04:44:10.877, Speaker A: They have skip serialize on it, which we do not. But we should have that because that is the behavior of crates IO when it generates the index as we just saw. And so therefore we should behave the same. The schema version, this is just copy pasted. They use a U32, we use a U8 that seems fine. And we want to skip that if it's set to none and that's all there is to crate. And now let's compare their deficient definition of a dependency to ours.
04:44:10.877 - 04:44:32.493, Speaker A: Name is name, rec is string. For them that's fine. Those match. For features they use a vec of string, we use a box box string of feature which is fine. Those are compatible optional bool that's fine. Default features, that's fine. Target for them is an option string for option for us it's an option box target.
04:44:32.493 - 04:45:04.795, Speaker A: So they could set target to just be, stir and be happy kind for them is an option dependency kind and for us as an option dependency kind that's fine. And we have package, which they also have. We have default, which we don't need. That come from the definition in. In. In here they have default set for package. They.
04:45:04.795 - 04:45:36.885, Speaker A: No, so I just made that up. Okay, great. So that one's done. They have partial eek and eek set. That seems fine. We can have partial eek. Box slice does not implement serialize.
04:45:36.885 - 04:46:21.135, Speaker A: We'll have to look at that in a second. Now they also have an implementation of partial or for dependency, which seems useful. And they have this, which looks like it's mostly the same, except they have ord. They don't have hash. We'll add hash. So that's the union of them. Okay, so partial ORD for registry dependency.
04:46:21.135 - 04:47:35.955, Speaker A: So we want to here do where. Where name impulse, ORD and rec impulse or. Because those are the only things we're actually comparing. Interesting. Why is the requirement on E here? All right, let's see what cargo checks us. I want something more substantial here. Whoa, a lot of stuff.
04:47:35.955 - 04:48:40.523, Speaker A: Can't compare feature with feature partial or why does it need to compare feature with feature? I forget whether or right ord implies E. And up here, by deriving partial eek and eek, we're getting an implicit dependency that features impulse eek because otherwise it can't do the comparison here. So it is interesting that ordering doesn't look at features at all. In old cargo versions, the dependency order appears to matter. If the same defense exists twice, but with different kind fields, the option fields would be ignored. I see, so this is a partial ordering. So they're actually kind of lying here.
04:48:40.523 - 04:49:54.075, Speaker A: Like this is not really okay, because I think all the other fields also need to be ordered by but name, kind and rec. Name, kind and rec. I think all you need to do is this board because then we can take this and say this. By placing the fields in this order, we ensure that the same that by placing the fields in this order, we ensure that we get the right. We ensure that we sort by kind before version. Now we. We ensure that normal dependencies are always first when multiple by the same name exists.
04:49:54.075 - 04:50:59.055, Speaker A: And that is assuming that in dependencykind we have normal defined first, which we do. And this stems from the fact that the derived for ordering is order by the fields in the order that they appear. And I believe that's not a thing they can change. I mean, who knows? But at least in theory, that shouldn't be a thing they can change. I mean, there's a. It should be easy enough to test this. Like if we do, you know, derive partial ord board debug and I do struct S and we have field zero which is us and field one which is us and field two which is a use Then if I do this and I do print line.
04:50:59.055 - 04:51:55.445, Speaker A: I guess MUTV is a vec of things. V I'm going to sort and then I'm going to print out V Then if I now do something like S. Let me make these a little more convenient for myself. F1 F2 F0 is 0. F1 is 1, F2 is 2. Well, that was silly. Let me close the door a little more.
04:51:55.445 - 04:53:02.745, Speaker A: So we would expect here. I guess I can make this a test instead. Okay. Or the good old it works. So what we expect to see that is that it sorts by fields zero first. So if I do you know 54321 I do 1-2345 oh, 012345 I do. I don't know 1212 then I'm expecting that this is equal to.
04:53:02.745 - 04:53:24.875, Speaker A: I forget where the default sorting is. Ascending or descending. Can't compare S with S. Okay, that's fine. Eek. Partial eek. Tools must format Test.
04:53:24.875 - 04:53:56.165, Speaker A: Test run failed. Okay, so it's ascending by default. Oh, this is awful. So this should come before. This should come before. This should come before this. Miso, did you want to come in? Oh, hi Chai.
04:53:56.165 - 04:54:36.305, Speaker A: I'm sorry. Did I lock you out? I'm sorry, you're going to grumble now. Okay, here you go. So zero, this goes up here. So 01, 2, 3, 4, 5. Okay, so that test passes. It could be non deterministic, but it seems to be ordering by the fields in order when you derive ord.
04:54:36.305 - 04:55:29.285, Speaker A: Now can we rely on that? Who knows, But I think we can. Or rather if they were to try to change this, I think they'd run into problem. I think the guarantee here is that the ordering of the fields is equivalent to as if you had a tuple of those fields in that same order. Which means that just by placing them in this order we guarantee that all the normal dependencies come first regardless of the version numbers. And now this is complaining about something. It's complaining that. Well first of all it's complaining about a bunch of unused dependencies or uses like this.
04:55:29.285 - 04:57:04.185, Speaker A: Does it still work if you swap the ordering? That's a great question. So if I do this and put F1 there and run test. Nope, test fails because then now it's ordering by F1. Deserialize is not implemented for box slice. Interesting. Is there another feature of serde I have to turn on here because again here that derive seems to work just fine. So if I go over here and look at the cargo toml their dependency on certain just ourselves C so why don't I get to do the fun thing? They have arc of slice of dependency I have arc of slice of generic dependency but I don't get to have mine.
04:57:04.185 - 04:58:46.275, Speaker A: Why? Name rec feature target oh, the docs on Rust stable says the derived or works like that. Okay, great. They don't have a manual derive, right? They don't have a manual implementation, they just derive serialize and it's the same for dependency for them but. But theirs isn't generic. So that's. That's where I feel like this probably comes from. Name oh, I wonder if it's rec feature target links so I should only need feature or that's the only bound I have that the drive wouldn't realize.
04:58:46.275 - 04:59:58.059, Speaker A: I'm pretty sure that this is survey getting confused. So if I do serde bound equals this it's going to complain about all sorts of things, right? It's going to complain about name deserialize. Can I keep them separate? Oh, that's awful. That's awful. So I'm gonna have to do like this. Can I. Can I avoid giving them all as one big stuff string? Okay, so I'm gonna have to do this and I.
04:59:58.059 - 05:00:50.625, Speaker A: I think I know why this is too but I'll. I'll. Let me just see that it works first. So this is going to be version. Can I at least do this? I should be able to because it's just going to be injected verbatim. So name version rec feature target links oh boy. It's gonna let me do.
05:00:50.625 - 05:02:43.465, Speaker A: I'm not sure why it won't let me do this. So. So the reason why it's complaining here is because I think it's only because of Wreck and Target. So in particular I think I can fix this by saying unused one is phantom data rec and unused two is phantom data target. Really? Name version rec feature oh, interesting. So it's not that why? Oh man, it's very strange. Oh, I also just realized all of these have to be pub Serdi rename equals verge.
05:02:43.465 - 05:04:02.983, Speaker A: Let's make these nice to work with dependencies. I think this is also for what is worth the reason why creates index exposes these only through getters and setters is because that way they can hide the fact that behind the scenes is like an arc and a double box and stuff behind this. Right? So it is tempting for us to do the same thing. But I'm going to make it pub for now. Let's check some links. And this is pub V and I guess we can rename this to be. It's like schema.
05:04:02.983 - 05:04:37.925, Speaker A: Well, it's V but it's schema version. And then this. Oh, is it? Because I didn't make it pub. This is pub, right? Yeah, Publisher. And then this is pub. Pub. Rename Pub Features Pub.
05:04:37.925 - 05:05:43.875, Speaker A: Target Registry package. And what's interesting is it says the trait bind box isn't implemented. So my guess is that serdes derived for ARC depends on serde's derived for box and serdes derived from box. I feel like it just doesn't handle the generics. But why not? Box of that deserialize is not satisfied. I mean, like I. I guess I could do this.
05:05:43.875 - 05:07:25.635, Speaker A: David Tol would scream at me if he saw this. Yeah, I know, I know. So this. Okay, so there's a line in the surde docs that says deserializer lifetimes. Where is it? I thought there was a line here that said something about like if you ever put four next to your thing, you're doing it wrong. Actually, you know what, I wonder whether, stupid as it may seem, I need serday borrow here or something along those lines, because I. I might have to tell it that this is the current field.
05:07:25.635 - 05:08:44.719, Speaker A: This isn't about the lifetimes either. Yeah, I'm unsure why this wouldn't implement deserialize because it should be the case that this bound should be like inferred by serde here. I guess, like this is a trivial thing to test, right? We write a test that we can deserialize this when the type instances are reasonable. Okay, let's just assume that's right for now to see if we can make some progress. So now thing we want to do is we want to implement a conversion from newmanifest to this and from the publish metadata to this. And it'll be interesting actually to see whether we can. So if everything works the way we hope, we should be able to implement from publish crate version for whatever we call this thing, which is registry package, which is.
05:08:44.719 - 05:10:56.675, Speaker A: I don't really love entry for entry and I guess this is going to take all the same generics as over here where name is going to have to implement like from cow, take a str and same thing for version and same thing for all the other ones. Actually rack, feature, target and links and feature also has to implement ord. Oh, cargo expand isn't a good idea. That might Actually tell us what's going wrong. So the name is going to be v.name.intov.version.into features and features 2. So that's the part that we were looking at over here is V features into iter schema version.
05:10:56.675 - 05:11:32.845, Speaker A: So that's schema version dealt with and Features two dealt with. It's very unhappy with me with the bounce up here. We'll get to that in a second. So this should just be features. This should be v.ah. so the checksum we don't have because that's not in the create version stuff. Yanked is though.
05:11:32.845 - 05:12:54.039, Speaker A: No, yanked is also not in that. If you have a crate version, the assumption is always that it is not yanked because yank is an operation on the registry. So anytime someone publishes you a crate version, it is not yanked because it was just published. And links is going to be V link map. And really this should be into name. Generally you're supposed to use into for bounds. This could also been been a mechanical change, I suppose, like so that's features.
05:12:54.039 - 05:13:38.705, Speaker A: So checksum we can't dependencies we should be able to. So actually here I'm going to go back here and say that we're going to make this also be nicer. Rename equals verge and then say this is version. Rename equals depths. And say that this is dependencies. And then this is going to be V dot dependencies map. Right.
05:13:38.705 - 05:14:41.317, Speaker A: And this is going to be an arc new this dot map, whatever it ends up being dot collect. And this is going to have to be a registry dependency. And let's see if we can come up with all the fields that go in here based on what's in the publish that we got. Well, this should be D dot name. This should be D kind. This should be D version, although create version dependency dependencies. So for dependencies down here, this is version rec.
05:14:41.317 - 05:15:41.017, Speaker A: Currently let's make that nicer to rename. I'm surprised that this is named version underscore rec. Is that right? It really is. Wow. Okay, so that's going to be requirements, right? And in the index. So here we have to invert again, right? Because this wants package and name and doesn't want the explicit name in toml bit. So back to another map like this we're going to say let name and package is match on d.name&d.
05:15:41.017 - 05:16:43.465, Speaker A: Explicit name in Toml. So this is going to be either name and sum. So let's see. So it's either that or it is this. So if there's no explicit name Then the. Then the name is N and the package is none. And if there's a name and explicit name, then the name is the thing in the explicit toml and the package is the thing that was the name.
05:16:43.465 - 05:17:21.245, Speaker A: Nice. So that's name and package dealt with. Now, registry here. The question now is whether we also need to invert Registry. I honestly have no idea what is. What does it stick inside of that? So it's the version string checksum features and features two, which we already dealt with. Yanked is false.
05:17:21.245 - 05:17:39.135, Speaker A: All right, we already. This is the outer fields. So yanked is false. Links we dealt with. Features we dealt with. Great. So for the dependency stuff that mapping happens, get depths.
05:17:39.135 - 05:18:34.209, Speaker A: Get depths is add dependencies. What does add dependencies do? It fetches all the stuff from the database. So this is the same inversion we do. And for generating a dependency, that's just the version requirement from the thing that came in. The feature list is just the feature list mapped to strings, which is already what we have. Optional is=d. Optional.
05:18:34.209 - 05:19:22.895, Speaker A: Default features is d. Default features. Target is d target Registry. Registry doesn't even get set here. So this suggests that Crates IO just does not allow cross registry dependencies because in its index entries it never writes out Registry. So presumably then in the upload path somewhere around here. I wonder if it looks through the dependency list and checks that none of them have Registry set or maybe just assumes that they don't.
05:19:22.895 - 05:20:22.315, Speaker A: Well, it's whatever comes back from add dependencies. Yeah. Here dependencies hosted on another registry. Cross registered dependencies are not permitted on Crates IO, which is a little awkward for us because it means we don't really know what this mapping should be. It's not clear whether Cargo expects the thing that's in the index to remember how there's a difference between how it's treated in the in the Cargo TOML dependency definition and how it's defined in the metadata that we send in the JSON payload. In one, the registry isn't set if it's crates IO. In the other it isn't set if it's the current registry.
05:20:22.315 - 05:21:34.905, Speaker A: I feel like it's probably the current registry that applies here too, which is the same thing that's in D because that's what the registry received and public is probably just D public. And now it's complaining and it's complaining about the same thing implicitly elighted. Oh, the trait box is not satisfied. Deserialize is not implemented for box of that. I want to know why. Oh, I haven't called into on all of these, have I? Right, right, right, right, right. So I'm going to have to do.
05:21:34.905 - 05:22:26.735, Speaker A: Oh boy. Yeah, all of these are going to need into calls. We'll deal with that in a second. So, yeah, this all comes back to this bit. So if I run Carago expand, what do I get? Oh boy, this is long, long, long, long, long. I need to know what to search for, because otherwise it's going to be impossible to deal with this. For entry.
05:22:26.735 - 05:23:07.687, Speaker A: All right. I.M.L. serialized for entry. I.M.L. deserialize for entry. So it correctly adds the dead bound to all of the generics. Now, where's the part where deserializes the field that we worry about, which is field number 012.
05:23:07.687 - 05:24:21.935, Speaker A: Okay, so field two where it's that handle field two depths is field two field one field two. Next element is an arc of that. Okay, so I guess then we need to look at the implementation for registry dependency. That also seems reasonable. It implements deserialize when all of its generic arguments implement deserialize over the target. De why is a requirement on target to be default? I want to know what this default business is. Oh, no, default.
05:24:21.935 - 05:24:57.503, Speaker A: Aha. I don't know if that did it, but I think. I think that might actually have done it, that there was a requirement. The default ended up meaning that target had to implement default. But we don't require that here. And it's a surday bound, right? Surday default. So it's not a problem for rust itself that target didn't implement default here, even though we contain one.
05:24:57.503 - 05:25:53.775, Speaker A: But for the implementation of deserial, I sort of thought it was. And I guess this means that when you declare default on something that's an option, it assumes that it should be sum of default of the target type rather than none. That's weird. All right, Well, I guess that fixed it. Cargo expand to the rescue, I suppose. All right, what else do we have? Version from version is not satisfied V. Oh, actually, I guess there's no need for the into because.
05:25:53.775 - 05:27:06.355, Speaker A: Well, so this is weird. I guess the conversion here is just this, right? All of these are just this. There's no generics involved because we're just saying we can construct a crate version from an entry. If you have a crate version, we can construct an entry where all of the things are just the same kinds of references that you had in your create version JSON. If you wanted to convert those to more special types for yourself, that's fine. But for the conversion like the we want the one to one Conversion found version expected couster. Oh right.
05:27:06.355 - 05:27:51.165, Speaker A: Name version. So the thing that comes out of version here is a semver version and the thing that comes out of requirements is a sember version Rec dependencies is not an iterator. Sure it is. Oh boy. ARC new size for values. This is going to be a collect dot into box slice. Box slice.
05:27:51.165 - 05:28:40.405, Speaker A: And then this is going to be an arc from. So the kind here that's going to map to a sum. The features here, right. Were insane people and decided to have this be into boxed slice box new target map box new map box. My lying. Right. This is double boxed for reasons.
05:28:40.405 - 05:29:47.305, Speaker A: In fact, this one is to box string to box str map. So we're going to map the registry to a boxster like this. And this is into owned two boxster. So this gives us a string because R here is a cowster this gives us a string and then this is dot two. There's definitely supposed to be a boxed stir. Yeah, String in into boxster. Okay.
05:29:47.305 - 05:30:12.327, Speaker A: And then we box that again. That seems fine. Package is supposed to be an option of a box of a name. Ah. Because usually this is going to be nothing. Okay. Public, right.
05:30:12.327 - 05:31:39.805, Speaker A: Public is not currently in the JSON and therefore it has to be none. Even if it might be some in the original crate. It's not a part of the JSON upload fields like so features, this is where we need to do our fancy mapping which is just arc features is arc new of features and features 2 is features 2 dot map box new. And the checksum we still don't have. So this is where this conversion doesn't work, which is we can only do this conversion if you also give us the checksum. So we're going to have to do this. And this is going to be a PUBFN new which takes a crate version and a checksum.
05:31:39.805 - 05:32:49.123, Speaker A: And the checksum is going to be a U832 like so. All right, so now we have that conversion and that means we have from dot create to publish to index. Now in theory we could also define a conversion, I think from crate directly to entry. So this is from publish. And then we could also have a from manifest, which could be useful for things like the internal testing and cargo. Right. From manifest, which is a dot create normalized manifest.
05:32:49.123 - 05:33:52.235, Speaker A: And that also needs to check some. And it's going to have a similar kind of thing where we do this. Now this is going to have V package name V package version. We no longer need to do this mapping because here the Mapping is direct. So name is just going to be v.nod. name name and dependency. So that's going to be name and package is going to be d dot package.
05:33:52.235 - 05:34:52.013, Speaker A: What does it compare complaining about here? Expect a struct b tree map. Right. That's because this is an option unwrapper default. Ah, right. So this here is where we need to do the same chaining that we did over in Publish because dev dependencies are different from build dependencies are different from regular dependencies. So we could have a helper for this instead which says over here that impl this dependencies. This is where it would be really nice to have partial borrows because so we can even have.
05:34:52.013 - 05:36:09.835, Speaker A: You can either have this take a reference to self in which case it can't actually take out the elements. It could consume self but then you can't consume anything else from self. What we really want to do is say this is only going to consume the fields dependencies, build dependencies and dev dependencies. We can't. We don't actually have a mechanism for doing so. But what we can do is take dependencies and say that that is going to give you a impliterator item is going to be I guess cow ticketstr which is the name of the package, a dependency which is a tick a and a dependency kind. That's what the iterator of this is going to give you and it's going to return this sales.discredencies.take
05:36:09.835 - 05:38:06.815, Speaker A: unwrapper default self dev dependencies.take. unwrapper default self build dependencies.take. unwrapper Default this is going to be super super publish dependency kind and name in tomld so we're going to map that to like so so now we have a thing that when you call this is going to sort of steal all the dependencies and give us back this one chain dependency list instead which now we should be able to make use of in Publish. This should be able to do m takedependencies and stick all those into here. And I guess I need to make this pub create this is now requirements and then we collect that. Great. So now we can reuse that same method over in index which is it is going to say let dependencies is v.takedepatible.map
05:38:06.815 - 05:38:52.625, Speaker A: like so. And I guess we can do arc from that as well if we really wanted to. And then this is just going to be dependencies and then we avoid duplicating all that stuff. This is now going to be name D And kind. Kind. This is version. I guess optional is called something else over here because of course it is.
05:38:52.625 - 05:39:54.281, Speaker A: So in dot CREATE what is it optional dependency called? No, it's called optional. Ah, but here it is an option boolean and here it is a actual bool. So in the index the optional field isn't optional, which means unwrap or false things are not optional by default. And this is unwrap or true because default features are on by default here. This is another place where we, we have some logic in publish for remapping the registry. Ah, so this is where we're gonna need. This is.
05:39:54.281 - 05:40:53.665, Speaker A: This is the really weird part which is this conversion needs to know which registry are you generating this index entry on behalf of in order to figure out what to put in the Registry field. So VR Registry, which is a stir. So it's actually a little tempting here to run this logic via the conversion of publish. The reason I'm not doing that is because there's some information that is only in the manifest that isn't in the publish info, namely the public private thing. But maybe it's just not worth doing this conversion this way because we're. We're duplicating a bunch of business logic here. Like the.
05:40:53.665 - 05:41:17.923, Speaker A: The defaults for. For optional and default features. This is kind of clunky. Although at the same time it's. It is very nice to be able to do it this way I guess. You know the thing actually, you know what we do here? I know what we do here. We do this.
05:41:17.923 - 05:42:44.015, Speaker A: We say in Registry is super Publish create version new V and checks V and via Registry and then we return return self from publish in Registry. Aha. We can even do. Here's the tricky part which is the entry is this. And then we actually get to carry over info that's not present in publish representation which is then entry dot. Oh, this is also going to be annoying because really what we want to say here is like for every dependency we want to go through and say whether or not it is public depending on whether was public in the original manifest, which is going to be something like depths is entry.arc get mute this.
05:42:44.015 - 05:43:46.641, Speaker A: Expect we haven't shared the entry yet. So that is a. This is now a mutable reference to the list of dependencies. And then now we should be able to walk the list of dependencies which is probably going to be best done here. And then we're going to match on the kind is always set by create version new, which I believe to be true right in we always Set the kind here. The kind comes from the kind here. Actually.
05:43:46.641 - 05:44:26.529, Speaker A: Why is this even an option? This isn't an option, but in the index it's an option. But we always set kind here to be sum. Okay. So that means it's always sum here. So this is either going to be in V dot. Oh, balls. But it's.
05:44:26.529 - 05:45:06.349, Speaker A: That's consumed. So what I was going to do was this, right? And then we could walk, we could do org depth list. And these are all, I think, as ref. It's like if let sum. Or a depth list is. Or depth list. And here we could actually use let else.
05:45:06.349 - 05:45:59.125, Speaker A: So we can do let some else continue. It's my first use of let else expected, comma. Interesting. But okay, so I need to do. I guess. Oh, that's funky. So I need to do like.
05:45:59.125 - 05:46:49.625, Speaker A: I guess this is a shortcoming of the syntax. So I do org depth list, else continue. So that gives me the org dep list. Because if it's not in here, that means. Or at the same time, doesn't it have to be the case that any dependencies that we have here must be in the original? So I think that's true. Expect. Yeah, it shouldn't be possible for that to not be the case.
05:46:49.625 - 05:48:29.905, Speaker A: Like if you have a dependency listed in the index entry we got we generated, then that must be because the input had an entry for that dependency listing in the first place. So looking up that dependency entry should never fail. And then we can do org dep list of dep name public depth public. So here's what I wanted to do. Provide the argument, right? Check some. Now, the reason this doesn't work and the reason why I think the borrow checker is about to yell at me, right? The reason why the borrow checker is going to yell at me. There we go.
05:48:29.905 - 05:49:28.845, Speaker A: Is because here we're trying to borrow into V, but we gave away ownership of V over here and that consumed the dependency list, among other things. So we don't get to do that. I also haven't defined into owned for this, but that shouldn't be necessary. So we don't get to do this. We would have to like walk to capture all of these ahead of time or we would have to re implement the transition logic explicitly, which I don't think we want to do. So we're just going to not deal with it for now. This is going to be tick A.
05:49:28.845 - 05:50:18.545, Speaker A: This is going to be tick A. And in published line 61 cannot borrow M as mutable. That's fine. Who. Okay, so now we have the whole pipeline working, at least in theory, so we should be able now to do something like take a. What I want to do, right, is write tests for this, using Cargo as a library to generate these and using these other crates as well. But if I take a dev dependency on them, they can't depend on me.
05:50:18.545 - 05:52:00.385, Speaker A: I forget whether Cargo allows this. Can you take a dev dependency on something that takes a normal dependency on you? It's not technically a cycle. I forget whether Cargo allows this path. Dependencies, multiple locations, target dependencies. Dependencies are not propagated to other packages which depend on this package. So this line makes me think that it's okay for me to take a dev dependency on Cargo, even if Cargo ends up taking a dependency on me. Now, it doesn't explicitly say that cycles are allowed, but like if I do 68, the real question is, if I do this, can Cargo now depend on me? Oh yeah, I guess I could.
05:52:00.385 - 05:53:08.761, Speaker A: Cargo, New Lib. Ah, Cargo index, Transit, Trans situation. This is when you don't use the sparse registries. I'm so excited. For sparse registries by default or just to have it on stable. I'm so excited. I don't know if I can use Cargo AD because Cargo AD might not realize that it's not a cyclical dependency.
05:53:08.761 - 05:54:09.959, Speaker A: I'm not sure, but this worked. All targets. I guess I should just override this to be beta too. Really? I mean, the resolver didn't complain. It seems like it just works. Sweet. Because that.
05:54:09.959 - 05:55:10.725, Speaker A: That means that I should be able to do round trip, so I should be able to run. I guess actually I could have done this entirely without. Without taking a library dependency on Cargo. Technically. Right. Because I could have just run like, you know, the equivalent of Cargo new. Like to actually do this by command, but setting up the testing harness for this is going to be kind of annoying.
05:55:10.725 - 05:56:43.295, Speaker A: But I guess realistically it would be something like creator. Yeah, I want like temporary directories and stuff here, but I also want Crazio equals whatever version crates IO is at 0. 35 and I want crates index which is at 0 19. And I guess the way to go about this is to take a dependency on something like temp. I can never remember what. Whether it's temp Temp file. Looks like it's tempter.
05:56:43.295 - 05:56:53.915, Speaker A: No. Temp file. Yes. Okay, great. Temp file. Sweet. Yes.
05:56:53.915 - 05:58:08.313, Speaker A: Okay, so I'm going to take a dev dependency on temp file equals 3.3 and I want tempd temp file tempdir unwrap and then inside of there. I want to run cargo ops new. I hate having to construct cargo configs. Maybe should be explicitly documented that you can do those cycles. Hey, send a PR to the cargo team. Sure.
05:58:08.313 - 05:58:52.105, Speaker A: They'll be happy to have PRs that add docs. Yeah. So I guess the way I would do this through new is so constructing a cargo config. So if you use the cargo config crate, you'll find that you end up using the cargo config type a lot. It is the configuration for cargo and it is effectively the result of all of your cargo. All of the cargo configuration files that apply when cargo is used in a particular directory. So you can do just new.
05:58:52.105 - 05:59:13.745, Speaker A: And when you do new, it is cargo new as of this particular directory. So you pass it something. So there's. There's default. And when you construct it with default, what you get back is the current. Using the current directory, let cargo do its thing. What I want to do is I want to pass in a path instead.
05:59:13.745 - 06:00:00.375, Speaker A: So I'm going to use new instead of default. And then you have to pass a shell, which I think is just default. And you have to pass the current working directory, which is going to be T and the home directory, which is going to be home. But I could just use T here too, I suppose. In fact, I'm going to do T path join. Create path join. In fact, I'm just going to do T path and T path will join cargo home.
06:00:00.375 - 06:00:41.815, Speaker A: And you might think that once you've done this and now you have a cargo config, but you have not. You also need to configure the cargo config. Why is this not. I guess it's not an unwrap and it's not T, it's D. And this is complaining because it expected a path buff. This needs to be into path buff. Into ah to path buff.
06:00:41.815 - 06:01:22.915, Speaker A: I apologize. Now configure takes a bajillion arguments. Verbose, false, quiet, false, color, none, frozen, false, lock. So configure is basically the command line arguments to cargo. So new is where are you? And configure are the arguments to cargo as you have deemed them offline. False targeter has not been overridden. There are no unstable flags and there is no cli config.
06:01:22.915 - 06:02:18.895, Speaker A: Unwrap. And it's complaining about my use of none because it wants a reference to an option. And it is complaining about my verbosity of false because verbosity is EU32. Okay, so now we basically have an environment in which to run cargo. And so now we can run the equivalent of cargo new, which is version control none kind new project kind lib. Whoa, it's very confused. What.
06:02:18.895 - 06:03:27.815, Speaker A: What does it want here? Use cargo ops. What Discard cargo, not expose this. But it's a field in one of its options. The cargo library interface is not always the easiest to work with. Well, how about that? New project kind isn't a public type, so I can't construct one of these. It's in the cargo use cargo ops car. Ah, it's not public because the cargo ops, the module for cargo new isn't pub.
06:03:27.815 - 06:04:11.915, Speaker A: So the type is pub. The new project kind type is pub. You see right here. But the module it's in is not pub. So this is one of those unreachable pubs. Which means that we're now at the awkward point where I can't call cargo new. So if someone wants to fire up a quick PR to the cargo project to make the cargo new module pub or re export this type somewhere around here, probably here just re export new project kind as part of the other re exports from cargo new.
06:04:11.915 - 06:04:44.195, Speaker A: It's a great one line PR to cargo. Go do it right now. Watching on four PRs in like a second. Well, that's awkward. Can I default Default? No. This is the secret way to get around when you run into situations like this. Sometimes that inner type does not exposed implements default.
06:04:44.195 - 06:05:56.499, Speaker A: And when it does, you can just default default. But I can't do that either. Can I do this? No, it doesn't let me do that either. Well then that makes me very sad because I don't want to now run cargo from the command line. I guess what I'll do is just wait. Don't I have a checkout of cargo somewhere? Dev others cargo pole. Let's do a patch.
06:05:56.499 - 06:07:03.575, Speaker A: Create IO cargo equals path equals home. John dev others cargo like so. And then we change what file was this source Cargo ops mod. And we also expose here new version kind. No new new project kind. And now if I do this, I should be able to do new project kind. Ah, Nope, nope, nope.
06:07:03.575 - 06:07:51.115, Speaker A: Patch 070. That's because cargo is a couple of versions ahead. That's fine. I suppose I could change this to be stash 0.680 stash pop. And now this can stay the way it was. Was cargo Check all targets.
06:07:51.115 - 06:08:38.587, Speaker A: That seems like that missing export is a pretty big oversight. If I didn't trust you, I think there's a different approved approach to accomplishing this. How do other projects do this. So okay, there are a couple of parts to this. Cargo as a library is not planned. It is the things that happen to be asked for by people over time mostly. So there's a bunch of stuff that like the Cargo Library API is not really well documented, it's often awkward to work with and this is stuff that like if you want to try to make it better, please do it would be fantastic.
06:08:38.587 - 06:09:25.963, Speaker A: But it requires a lot of work and Cargo does change a lot internally over time. And so keeping that library API stable is tricky and figuring out exactly what to expose, it's not usually an approved way to do things because the Cargo Library API is just generally discouraged from use in the first place. I think the general sense from the cargo team is prefer to use the command line tools if you can because those are stable. Don't rely on the library API. I don't want to do that here, but that's the intention. The reason why this particular thing wasn't caught is because the lint to detect unreachable public items isn't documented anywhere or I've been streaming for too long. It's not that it's not documented anywhere.
06:09:25.963 - 06:09:49.059, Speaker A: It's not on by default. It is allow by default. Oh, Weihong, thanks. Weiheng is going to fix the problem. One of the cargo maintainers who's in chat and is just going to fix it while we're at it, which is fantastic. The unreachable publint is not worn by default at the moment. And the reason is because it's kind of incomplete.
06:09:49.059 - 06:10:35.475, Speaker A: Sometimes it can be really hard to tell whether something is unreachable by design or not. So whether you should lint or not, whether it's actually unreachable is complicated to compute. And so the lint is just too. It has too many buggy cases to have it actually worn by default. So it's allowed by default, which it has been for a long time, which means that things like this slip through. Okay, so now we should be able to do this and use Cargo Ops new project kind. Thank you.
06:10:35.475 - 06:11:16.575, Speaker A: And it also wants config, which is easy enough. We have one of those. This is why you named a defenestration. Well, defenestration is the name of my computer, which I often do want to throw out a window. Auto detect kind. I don't know what auto detect kind is for. False auto detect kind.
06:11:16.575 - 06:12:52.713, Speaker A: Oh, I see. False lib is the kind I want. Path path, absolute path to the directory for the new package. So the question is, does that Include the name or does it not? I feel like path is probably expected to be the current directory. If I go back to no source bin cargo commands new path set. So path is the argument that you pass to new. And that's interesting.
06:12:52.713 - 06:14:07.965, Speaker A: So new options. See, I think they're lying in somewhere here it says absolute path to the directory for the new package. And I do not think that's true because I think path and based on this, path is the argument you pass to cargo new and you can run cargo new foo. It does not have to be an absolute path. So I think path here is going to be d.path. join, you know, round trip. The name of the crate and name is going to be none, as in we're allowing that to be inferred from the path addition.
06:14:07.965 - 06:15:13.107, Speaker A: We're not passing in. We want whatever the recent one is. Registry none. We don't want a custom one dot unwrap package is going to be there. Okay, so now I should be able to run cargo ops package, in fact package one. So now I want a workspace which is going to be cargo work, core workspace. Aha.
06:15:13.107 - 06:16:02.891, Speaker A: Find workspace root no, in not find workspace root workspace new. The manifest path is going to be package join cargo toml and we're going to pass in the config and we're going to unwrap, and that's going to give us a workspace. The only reason I know these by hand is because I've done a lot of using the cargo library API. Nice. We have at least two people writing the pr. Okay, so we have a workspace. Now it's complaining about this.
06:16:02.891 - 06:17:03.235, Speaker A: That's fine. So once we have a workspace, then we should now be able to pass that workspace and workspace current, which is just going to be the main package because there's not really a workspace and package opts unwrap. So that's going to be the tarball. And I happen to know it's going to need a second unwrap. The reason for this is because what package one returns is an option file lock. And the option here is because if you run package with list, it'll list the things that would package, but it doesn't generate a tarball. Hence the return here is an option.
06:17:03.235 - 06:17:30.345, Speaker A: So you'll see the list option which we're going to set to false config and why that has to be passed in separately here for package one rather than being passed as an argument to package is a little unclear, but it does check Metadata we're going to set to false. Allow dirty. We're going to set to true. Verify. We're going to set to false so it doesn't build jobs. We're going to use the default keep going. We're going to set to false.
06:17:30.345 - 06:18:50.787, Speaker A: So keep going is if the build fails, then keep trying to build to give me more failures to package is going to be packages default, which is this is basically if you were to pass the dash P flag and I just want to not pass the dash P flag, which is default targets is going to be vecnew because I don't have any particular targets and CLI features is just going to be default, which I thought you could do, but maybe you can't new all. I don't want to compile it with all features. Okay, so now we have a tarball. And now we need to grab out the manifest from the tarball for verify. Yeah. So verify means by default it's on. And what verify means is before you run package, try to build the current package to make sure that it can actually be built so that you're not publishing something that other people can't build.
06:18:50.787 - 06:19:46.875, Speaker A: And the build here is a little special. It runs with your default configuration rather than any custom configuration you might have in your home directory. It doesn't respect patches, so it basically tries to do a build as if someone else were doing the build. So it's verify. Here is should you also do the verify step. Okay, so now we need to extract the cargo TOML from the packaged thing, which we can do by extracting the tarball, which we already saw an example of that over in crates IO which was over here somewhere somewhere over the rainbow. Cargo tunnel.
06:19:46.875 - 06:20:49.885, Speaker A: Where you at? So they take a dependency on. Whoa, that's a lot of stuff. Fleet 2. So these are things to actually extract a one of these dot crate files. We're also going to need tar tar yar and then we can probably just copy paste their code here, which is decoder read of tarball dot path. Oh, actually I think I can just do tarball dot file. No Maybe.
06:20:49.885 - 06:21:56.945, Speaker A: And then I should be able to do this. And then I should be able to do this. So I'm grabbing out the each entry from the archive and if the if entry path.n with cargo toml then I want to do the test. I'll get back to do the test in a second. Why doesn't it give me GC decoder? Please give me GC decoder. Thank you.
06:21:56.945 - 06:23:23.507, Speaker A: Path is entry. Do unwrap Right. So how do they grab the bytes out of this? Which is what I really want now. Aha. So then we're going to do let mute manifest entry. Read to string unwrap. So now the interesting part comes which is we want to do now we have a manifest.
06:23:23.507 - 06:24:42.745, Speaker A: So we should now be able to do use cargo index transit pass sit. So we should now be able to do let sit create normalized manifest is equal to. Oh here we're going to need to from string of manifest unwrap sp expected unit struct right like so implementation of deserialize is not general enough. Scary. Oh, I think actually this is just manifest parse unwrap. But fine, we'll do. Nope.
06:24:42.745 - 06:26:00.695, Speaker A: Oh actually I do want toml edit. So why did I even bring toml in? Not sure. I think I only need that as a dev dependency and then I think I also need it with derive with like serde. Yeah, features equals 30 like so. And now we should be able to do D from str. Why is it complaining? Must implement deserialize for any lifetime, but it actually implements for that lifetime. Ooh, so this sounds like we missed a borrow somewhere.
06:26:00.695 - 06:27:05.595, Speaker A: It's either we missed a borrow or SERDE isn't correctly propagating the borrows into these subtypes. Let's go look at the SERDE docs to see if I messed this up. Field attributes serde borrow. No, that should be fine. So did I miss a borrow independence dependency? I think I missed a borrow independence either. Did I miss a borrowing package? I did. Keywords needs to borrow.
06:27:05.595 - 06:28:08.935, Speaker A: Oh, would have been so good if that just fixed it. Borrow borrow borrow could also be its not a missing borrow, but usually it is. But now I can't spot one. Alternatively, it might be something about our little weird string or bool thing. So first and foremost this should be this. Really. Not that it really matters, but.
06:28:08.935 - 06:29:32.685, Speaker A: Oh right, that was on readme. So this needs to be dot into owned. So I need an impul string or boolean. So this just maps to the same bool and this maps to into owned cow owned owned event to owned. Oh, this should be string. Yeah, it's entirely just a convention to have these kinds of methods. There's no.
06:29:32.685 - 06:30:39.255, Speaker A: There's no built in string or bool into owned. Now that doesn't fix the problem though. I wish it did. Must implement DC res. So I wonder why, like if I do this, will it let me do? Will it let me be happy? I have. I've angered the borrow gods. Oh, it Might be version it might be the version trim white space thing.
06:30:39.255 - 06:35:42.901, Speaker A: Yeah, this should implement visits doc 30 show me the visitor trait for deserialize there is visit borrowed string and I want that. Actually, that shouldn't matter because this one is doing an owned parsing anyway Implementation deserialize is not general enough all right, let's see if. If the expansion here helps us so 4 normalized manifest why is there even a tick a here? That's what I want to know Go this is very strange because as far as I can tell there's nothing here that would make this be unable to borrow its input Like I just want to see whether this makes it happy Shouldn't. Okay, so that didn't do it. So it's. I don't think it's the. The custom deserialize I think what I want to see is whether this.
06:35:42.901 - 06:40:36.015, Speaker A: There's no. There's. There shouldn't be any reason why the. The additional nesting here makes a difference Wait a second, I think I remember now why I think there's a special interaction between cow and the borrow annotations that makes it not work when it's inside an option I mean, this should be easy enough to test out, right? So if we did drive fuser to derive deserialize use Tom Edit and then we do something like drive deserialize str and then I do, you know, let X equals toml Edit Dilutation of deserialized is not general enough that doesn't seem right oh, fun. This is just a limitation of toml or of the toml deserializer See, that's what I thought that this is actually I think Tom will edit D from stir requires the t implements deserialize owned not just deserialize why does it require that deserialize owned closed close of 490 okay, so that's interesting. So toml edit doesn't support this and doesn't plan to hmm. So that's not what I wanted but in theory we should be able to do this why doesn't it so the normalized manifest we don't have deserialized owned for that's interesting.
06:40:36.015 - 06:43:38.405, Speaker A: The next question now is why doesn't it implement deserialized owned Also because it should be the case that our our types here like why wouldn't this also implement deserialized owned for us? Because I think if I remember correctly for the surday de serialize owned implement deserialized Owen for T where t implements deserialized de for any de which should already be the case. Like just as a sanity check, I put that the wrong way around. Deserialize owned. Okay, so normalized manifest doesn't implement deserialized owned. So that implies that it doesn't meet the bound, that it doesn't implement deserialize for any or for all rather lifetimes. Which is weird because it really should. That makes me sad.
06:43:38.405 - 06:44:45.975, Speaker A: Okay, so we. We have two options here, or we have a couple of options here. One is use an older version of toml that does support borrowing deserialization. Another option is for the normalized manifest to give up on using borrowed strings or borrowed anythings. And a third option is to make normalized manifest generic over its string types. And the reason why we might want generic over the string types is because cargo, if you remember in over here somewhere, TOML manifest. So for TOM will manifest.
06:44:45.975 - 06:45:53.815, Speaker A: Yeah, so for toml manifest, it does use interned strings. Interestingly enough, it uses it for feature and for package names, and only those. Which means that. Let's see actually whether workspace, dependency, TOML dependency detail. TOM will dependency. That one does not. Huh.
06:45:53.815 - 06:47:04.085, Speaker A: Toml manifest. So it's the name inside of a package, but not the names of its dependencies and the names of features and the. And not features of dependencies or names of dependencies. Weird. So I mean, that's frustrating. I guess what we'll do then is name and features and say this is. So package is going to have name and features.
06:47:04.085 - 06:48:16.205, Speaker A: Dependencies are just going to be strings because that's all we get. Alternatively, we could refuse to borrow, but I'm just gonna. I guess I'll just make them strings. An intern string is a technique or a type that is in cargo, which is if you create an intern string, it first does a lookup into a hash map of whether it has seen that string before and gives you a pointer to the previously allocated string if it was previously allocated feature feature and I guess not feature on package. And these don't get interned, which seems weird. I'm just going to go ahead and disagree with that and claim that those should also be interned if the name is interned. And for dependency, that's now going to take.
06:48:16.205 - 06:49:12.535, Speaker A: Actually dependencies don't have. I'm still going to claim that these are going to take intern strings cows all the way down. Yeah, that's right. So dependencies are going to inherit feature. So there are no more borrows, there's no more need for into owned because there's no. Because there's no borrowing in the first place. This now gives you name and feature.
06:49:12.535 - 06:49:34.465, Speaker A: This is now a string. No borrow. No borrow. No borrow. This is a string. No borrow. This is a string.
06:49:34.465 - 06:50:39.323, Speaker A: Note, this doesn't use borrowing deserialization because Tom will edit it, doesn't support it. Package is generic over name, which is not borrow, it's a string. This is string. No, and all of these are strings. And no more into owned here. And string or bool is no longer generic here. It's just going to be a string of string.
06:50:39.323 - 06:52:38.075, Speaker A: No more into owned here, no more cows over there, and no more into owned here. And that means publish now needs to be generic here over name and feature, where name implements into cal tickets str and feature implements into cow str. That's the main thing that matters. And it's probably going to complain at me somewhere here, right? Index is going to have the same problem where it's going to require name and feature. And this one's kind of funny because here we could actually take, if we didn't go via the conversion to create version, we could reuse the name and feature up here. But we're not going to do that because we don't want to implement the whole contents of that now there's more of a reason to like. So where is it going to yell at me now? It's going to yell at me.
06:52:38.075 - 06:53:23.375, Speaker A: Add 132. That's because all of these have now changed because none of these are the same anymore. So this now needs to be enter into iter.map. collect where it's no, it's now key and value needs to be K dot into and this needs to be. I guess this is actually a vector. V's.intensiveiter.map clone no collect into into.
06:53:23.375 - 06:54:20.295, Speaker A: And we're gonna have to do the same for this conversion. Although this one is just into into Description is map into, into documentation, homepage, license, license file, repository and links. Keywords is going to be this and categories is going to be this. So all of them get converted using into. This is into. And this has to be converted the same way the other one does. Just this way.
06:54:20.295 - 06:55:23.165, Speaker A: All right, we're getting pretty close here now. Hopefully name is into, this is into. Whoa. Actually, those probably don't need to be converted here. They need to be converted up here because here we swap them sometimes but not others. So this has to be into. And this has to be into.
06:55:23.165 - 06:56:47.035, Speaker A: PP is ring. Okay, so that's going to be something like cow own now. There we go. Oh, boy. Okay, dot crate 29. What do we got here, right? We're going to require here that feature is ored because otherwise we can't iterate over the B tree map, which then means we're going to have to change that in publish where features or and an index where feature is board. Okay 35.
06:56:47.035 - 06:57:20.085, Speaker A: It returns string. What do you mean it returns string? All right, it returns string. Great. So now we're back to via cargo. And now this should be able to do this and we should be able to say string string. Beautiful. Okay, great stuff.
06:57:20.085 - 06:59:04.965, Speaker A: Okay, we now have this line compiling and now at least in theory, we should be able to say the publish create version Create version is just generic over A. So we should be able to sign any Here should be set publish create version new pass in the M and the registry that it's for which we're going to go ahead and say is not that one GitHub.com which I think we have somewhere here, this URL and then the index entry and let's say this is string sember version version rec string string string string string string string is index entry new and you know, we'll just do u 00:32 we don't care about the hash here. Ah, from publish. Am I lying? From publish. Ah, P. Great.
06:59:04.965 - 07:00:07.965, Speaker A: Expected entry String string string string string Got cow. Ah, right. This already dictates all the values. And so now it should be the case that we should be able to check that at every step of the way here. And certainly at the end we should be able to check that I, which is the index entry here is equal to and what did we call the thing? We called the thing round trip I.name and I.version should be 0.1.0
07:00:07.965 - 07:02:16.245, Speaker A: because that's what cargo new generates, which means it should be sember version new 010 all right, cargo test. And I guess technically what we also want to do is that each step of the way here, say here, we should be able to do JSON is serdi Jason, did I already stick in a JSON converter here? No, serdijson to string of P and I should be able to hear say crates IO new crate is serd JSON fromster of JSON. Right. That that shot should be the case that whatever we generate actually is parsable by crates IO and it should also be the case that if we go back to JSON from P2 and then we do P3 is one of these, it should be the case that that's a reasonable round trip where P and P3 are equal. And this certainly should Implement debug and that means dependency doesn't implement debug, which we really want it to do. Equals cannot be applied. Seems pretty reasonable to have this implement eek impartial eq.
07:02:16.245 - 07:03:09.013, Speaker A: Same for dependency. There's nothing particularly weird in here. It's all just strings. So we expect that round trip to work. We also expect for the index for. Let's see, is the cargo registry thing public Registry data does look like it Registry package. Yeah but it doesn't look like I can do anything with a registry package, but I should be able to parse one.
07:03:09.013 - 07:04:13.233, Speaker A: So if I do this cargo, where was it Sources Registry. I can't spell Registry package is no this bit that should certainly work. And similarly the same thing should be the case for it doesn't implement serialize. Right. Yeah. Crates index version I2 and then I should be able to go back to Jason from i2get i3 which is going to be a index entry. It's going to be that from string.
07:04:13.233 - 07:04:56.771, Speaker A: And then I should be able to assert equals I to I3. And now I think it should be able to infer all of those because I'm saying equals at the end I should get roundtrip. Okay, so now we have the whole string of tests that in theory should pass and in practice of course is not not yet implemented as depends on file contents in dot crate. Right. So this is the readme stuff which we still haven't dealt with. And I don't. I honestly don't know what we do here.
07:04:56.771 - 07:05:48.423, Speaker A: Like I think what I want to do is for now just say this is none none and it's just unimplemented and go ahead and say to do. Okay, so something else fails. Missing field keywords at line 73. So crates IO requires that keywords is present which we don't currently do. So in our publish keywords we currently skip it if the vector is empty, which we're apparently not allowed to do. I'm guessing the same applies to categories. Also worth keeping in mind, you know, this is.
07:05:48.423 - 07:07:09.035, Speaker A: This is a package with no dependencies and nothing. So there's going to be other badges. Knew it was going to come back and bite us. I want like, I want this, I guess because I don't actually want to do badges. Badges none. All right, what else we got? And I'll type null expected a map. Of course you do DT map new and here we're also going to say serdefault.
07:07:09.035 - 07:07:45.483, Speaker A: So because it can't be an option, why use an option over a simple empty Hash map. Yeah. Or in this case an empty B tree map. What I. What I arguably could do here is like a vector of nothings has the same structure. Well, that. That worked.
07:07:45.483 - 07:08:26.345, Speaker A: We did get a round trip. The ReadMe thing is, is definitely frustrating because. Right. Because without this cargo wouldn't be able to use what we built. I mean, I guess we could just say you have to pass in the readme. Right. And say that's going to be.
07:08:26.345 - 07:09:39.065, Speaker A: It's ReadMe and ReadMe contents and ReadMe and ReadMe contents are, you know about cows. It's an option cow ticket stir. That's certainly one way to get around it. Right. So now the via stuff is going to have to change a little bit because it's going to require that we pass this in. But we can do none none here. Publish is going to be Sad.
07:09:39.065 - 07:10:37.527, Speaker A: Why? Because Index 95 doesn't know what to do with it. And this is frustrating because when we come from Publish, we don't care about the readme for the index, but that just means that we can pass in none none here. None None. Sounds like a bit of a song. Okay, so now we have a full round trip and we've demonstrated that it is compatible with the crates that I will create and the crates index create. We haven't tested this for anything beyond a trivial archive, like for example, or trivial crate. Rather, once you add dependencies and stuff, things get obviously a lot more complicated.
07:10:37.527 - 07:11:42.285, Speaker A: So we would want tests here. That test does the round trip work even if you add dependencies? Dependencies would be a good thing to test, but at least this is a pretty good start. The thing that would also be nice to test here is the integration with Crates IO, but because their types aren't public in a way where we can test them here, it's not trivial for us to do so. But the hope, of course, is that this is possible to slot in for them. And what's also interesting here, I think, is we could turn this into a test harness pretty easily by making this. Instead of being this being a test, this could be a function that takes two closures, one to run here, so right after new but before opening the workspace, and one to run here, which is additional checks to run after you've checked that the round trips all worked. And that way we could write a bunch of tests around that.
07:11:42.285 - 07:13:45.565, Speaker A: And in fact, let's just do that refactoring right now to say simplest, which is going to be round trip of nothing nothing. So this is going to be generic over a setup And I guess that will be given something like a path and a check. It's going to be impl FN1s. I don't even know what it'll be given. I guess we can actually give it all of the types, right? So we can give it a dot create normalized manifest string string. We can give a publish crate version and we can give a index entry string semver version semverversion rec string string string. Although actually, actually these are going to be not string but cow str and yes, we're going to want cow because now I should be able here to run clone.
07:13:45.565 - 07:14:30.153, Speaker A: Really? That's certainly something we'll want. Did I not add derive clone to these? Because they're going to have to be clone. This is going to have to be clone. And same for crate. It's going to have to be clone and the dependencies already cloned. Okay. Aha.
07:14:30.153 - 07:15:30.105, Speaker A: No more string or boolean. So now this can just ignore the path and down here we're going to do something like check mp. I did that work. Dot Crate is complaining about this. That's fine. 101. I was lied to.
07:15:30.105 - 07:17:12.335, Speaker A: Cannot do type path. That's easy enough. And this takes three arguments. Oh, and I don't call setup, which I need to call here. Right? So now it should be possible to do, you know, I don't know, something like here where path, you know, DEP1 add a dependency to p slash cargo toml and then here to do check that I contains index index entry contains appropriate dependency specifier. But I don't think I'm going to actually write more tests for this today because I need to eat. But that seems pretty promising.
07:17:12.335 - 07:18:09.575, Speaker A: Okay, what I'll do is I will do something like I can remove expanded, I'll git ignore my dot cargo and I will get ADD. All right? And my patch will hopefully not be necessary for anyone else. Actually, here's what I'll do. Add p commit first thing that maybe works, question mark. And I'll. I'll push that to a git repo and publish it and stuff. But hey, we built a thing.
07:18:09.575 - 07:19:02.915, Speaker A: There's obviously a bunch more work to do, right? Like we would want to try to make changes to cargo to make use of this, make changes to crates I o to make use of this, make changes to the crates IO package to make use of this, make changes to the crates index package to make use of this. There's a bunch more documentation, a bunch more testing that's needed. But at least now we have the basic types and the conversions between them all in one crate, and then hopefully that might actually turn out to be useful. And feel free to dig into this and try to add more tests and play around with it. Whether it actually gets picked up, I'm not sure. But even if it doesn't, this is a decent introduction to how that entire pipeline works and all the weird little transformation that happen along the way. Now, I need water and food, but thank you all for joining.
07:19:02.915 - 07:19:35.221, Speaker A: Hopefully this was at least somewhat interesting to participate in and I'm hoping this will give you a little bit of an exciting feel. If we're going to dig a little bit into cargo, into some of these crates, maybe into this one. And I think that's where we're going to end it off. Are there any questions at the end? It's been a very long journey, so I wouldn't blame you if you're all tired and don't want to ask questions. But if there are any, fire away. Add fuzzing to this. You know, fuzzing for this is a great idea.
07:19:35.221 - 07:20:13.345, Speaker A: One of the things that's. That's problematic with the current state of affairs is that because these connections aren't built in a way where they're sort of standalone, it's very hard to test them. It's hard to test interoperability, it's hard to fuzz them because they're all like super ingrained into cargo, for example. So this crate should be possible to do fuss testing on, prop testing on, just general round trip testing on. So absolutely, please add that. That would be amazing. All right, doesn't look like any great questions, or let me rephrase, it doesn't look like they're a great number.
07:20:13.345 - 07:20:28.905, Speaker A: Number of big questions or any big questions. All your questions are great. So I'm going to end it all there. Thank you for joining. I don't know whether there'll be a part two of this, but maybe we'll see. It depends whether this ends up going somewhere. All right, bye, folks.

00:00:01.480 - 00:00:46.145, Speaker A: Hi folks, welcome back to another stream. This is one that has been on the schedule for a while and I completely forgot that it was on the schedule. And so when I realized a few hours ago, I was like, well, I guess we're going to spend this to go through the remainder of GitHub notifications. If you remember, when we started we were at what, 140 or something in the first stream and now we're down to there are only 40 left. So I'm hoping that in today's stream we'll be able to get through most of the remainder so that I can stop having to play catch up with all of these so much and we'll see how far we get. I mean, we're gonna do the same thing as last time. We're gonna start from the back, walk our way through the notification towards the newer ones and just deal with them as we go.
00:00:46.145 - 00:01:33.625, Speaker A: I've gone through and gotten rid of anything that's just like me subscribing to things because I want to read them so that these are actually like things to do. I've done that for past streams too, so the numbers shouldn't be too skewed. So let's just start opening these and see what we find. It's funny because now we're starting to get to. We're starting to get to PRs that people have opened during the first of the open source streams. So some of these are like I put out a comment in one of the previous rooms saying someone should implement this and then these. We're now getting to the PRs of people doing that, which is kind of fun.
00:01:33.625 - 00:02:20.715, Speaker A: Let's see. So this is in Fontaccini, which is the web browser automation library. There doesn't need to wait till you register for the entry added event as defined by the DevTools protocol. So be fine if I can instead call something like get logs on the client. But that doesn't seem to exist either. Currently only implements the web driver spec and not the Chrome DevTools protocol. For that I think you need to use Steve Pride's 34 crate, which has some support for it.
00:02:20.715 - 00:03:26.893, Speaker A: Great, so that's easy. I'd like to keep this library focused on just one protocol and then have some higher layer combine the implementations, combine, have dev tools be in a different crate that can be tested and such on its own, and then have some higher layer crate like 34 do the combining close with comment. That's true. Yeah. If I make a typo encode, then file a PR so that I Can do it on stream. Great. Oh, so this is the discussion of differential flame graphs that we talked about last time, about how the output is a little bit confusing, I guess.
00:03:26.893 - 00:03:52.855, Speaker A: It's hard to tell exactly what happened. The current implementation matches the output of the real flame graph and from what I can tell is the intended behavior. Many discussion about this. Finally wrote an invitation. Makes sense. It works with this text. Profile 1 takes direct profile 2, generate a glass using 2 colorize the graph using the 2 minus 1 delta.
00:03:52.855 - 00:04:47.167, Speaker A: I see. Okay. So one of the complaints in the original issue here is that if you have a call stack, this is the thing that this is the library that generates flame graphs called Inferno. So in this flame graph, parent is showing the sum of the frames and the children. So sometimes the frame for parent might be wider than first plus second child to imply that some code ran in parent itself. Some code ran in first child, some code ran in second child. And the complaint here is it might be easier to see in the text if you have a setup like this.
00:04:47.167 - 00:05:20.281, Speaker A: The amount of time spent in first child here is 10. The amount of time spent in the second child here is 10. The amount of time spent in the parent is 0. But the amount spent in the in parent and its children is 20. And in this change here afterwards, first child takes 30, second child takes 30. So that's why they're both marked as red here. But in some sense parent has gotten slower too, right? Because it now takes 60 total, whereas previously it took 20 total.
00:05:20.281 - 00:06:00.899, Speaker A: And the question becomes, should we highlight parent as being slower or not? Currently we don't. Right. So we say the parent has not gotten any slower. The things that have gotten slower are the children. And one of the proposals here was to change that behavior to highlight parent as having gotten slower as well. But it seems like that's intentional. The intent from the original author is that the that it shows or the color shows the amount slower that function has gotten independent of its children.
00:06:00.899 - 00:06:16.411, Speaker A: So that it doesn't get penalized for its children or penalized for. Penalized. Penalized for its children. Getting slower. Hmm. Oops. That's not at all what I wanted to do.
00:06:16.411 - 00:06:38.237, Speaker A: I have no idea what I just did. Okay, that goes away. This goes away. And then we're back here. I press some key combination that I don't know. What did tiling mean? Imagine goes. You're not wrong.
00:06:38.237 - 00:07:44.585, Speaker A: It's also partially because I use the same keyboard now for my work macOS setup and my home Linux setup, and the key bindings are different. So I press keys that do different things and it's frustrating. I'm torn here because the current output is also pretty hard to intuit the meaning of. Maybe the trick here is going to be um. A to rep is going to be mainly around how we present the information in the hover pop up. So when you hover over these frames you get a little thing that shows here you see parent 60 samples and currently that information is pretty terse. It's hard to really understand what it means on.
00:07:44.585 - 00:08:48.821, Speaker A: On frames that have children. I wonder if we could include the slowdown. I feel like with some labels for which thing got how much slower might actually help a lot. I take. So Brendan is the person who developed the original Flame Graph that we then ported to Rust. This choice is probably the one that gives more useful data, even if it is not the most intuitive one. This is something that this person also I think was submitting a PR for which we might get to later.
00:08:48.821 - 00:09:25.355, Speaker A: So this is just. Nothing has landed yet to change this behavior. All right, okay. This is for. This is for the IMAP crate. And so the basic premise here. Let me pull up the IMAP crate.
00:09:25.355 - 00:10:02.239, Speaker A: The basic premise for the IMAP create is. Let me pull up the actual newest version. Version alpha. When you first want to connect with a client, what you do is you. Where's the connect function? Am I blind? Client builder. There we go. So for client builder, you give like the host on the port you want to connect to and then you do like native tls.
00:10:02.239 - 00:10:47.731, Speaker A: If what you want is a client that uses native TLS as in like OpenSSL for example, on Linux. Or you can call dot Russells and you get back a client that uses Russell's to establish a TLS connection. And the way this actually works in practice is that the client type that you get back is generic over the type of stream that underpins it. Like it's generic over the C, which also lets you pass in your own C and everything. And that's nice, but it also means that there's a bunch of generics that get passed around. And it's like unclear how much this matters, especially for imap. You don't really care about the high performance here and you probably don't really care about exactly which type is being used under the hood.
00:10:47.731 - 00:11:38.965, Speaker A: And once we expose generics here, they sort of tend to bubble up everywhere. Like everyone needs to pass these around everywhere or they need to use like a type alias in their own crate in order to force that this value is always the same thing. So the Proposal that came in, and this is from October 2022, was a client builder and indeed a client that just gets rid of the C parameter. So it still lets you configure which backend you use, but it uses dynamic dispatch instead of static dispatch. So instead of generics to make the interface nicer while still preserving the same capabilities. And so we've had a lot of conversations back and forth, and this is like an interesting one to follow. I think it's a change that's been going on for a while about exactly what should we land and how.
00:11:38.965 - 00:12:32.709, Speaker A: And let me show you what it ends up looking like. So it looks like this. You have a client builder. You can call TLS on it to say, I want this to connect with tls and then you can call dot connect on that to say now actually connect to the host. This is just a test. This one though, I can pull up. And so some of the discussions we've had is like, how exactly do you mask this kind of choice that happens in the builder? Because the builder still has to be able to say like, should I use Russell's, should I use open ssl, Should I use Star tls, or just assume TLS directly or not use TLS at all? Like assume a plain connection.
00:12:32.709 - 00:13:43.445, Speaker A: And so we want to be able to represent these kinds of configurations of the connection without necessarily having to be generic over these types. And so you'll see what we landed on is we have these two enums that describe the connection mode and the kind of TLS that you want. And then down here on Client Builder, what the builder holds is a field that specifies how you should connect, what your kind of TLS should be, and configurations for TLS that we sort of want to expose independent of which backend we use. So we want to be able to have you turn on and off TLS certificate verification without having to dig deep into exactly which TLS library we're using under the hood. It's a little misleading that this variable is called no TLS verify and is set to false. Like I would kind of rather it be set to tls be called TLS verify and default to true. Let's see.
00:13:43.445 - 00:15:01.947, Speaker A: Okay, so we've chosen to deprecate these old builder methods for setting start tls and we say instead prefer to just set the mode directly. Seems fine, right? So one of the other discussions here is, you'll notice up here there's something called Connection mode auto. And with Connection mode auto, the idea is that we will use which port you set and the Capabilities of the server to decide whether to use tls. I want to see if I could find. Yeah, so if the port is 993 then use TLS. Otherwise connect and then detect start TLS, which seems fine. And then we have this danger method for disabling TLS Verify.
00:15:01.947 - 00:16:13.295, Speaker A: I don't love the double negation here. Oh, these keybindings are killing me today. The double negation here strikes me as unfortunate. Can we name the field and the method just danger tls Danger TLS Verify and TLS Verify and have the latter default to true instead. Start review. And then I notice a typo up here too. While we were at it, server says there we go.
00:16:13.295 - 00:17:20.535, Speaker A: Interesting. Is it tough to reject the PR thinking all the work that the issuer have invested? It is. I mean this PR they started with basically and this is often a good way to approach this, they started with a relatively small PR that was just like, hey, how about we do it like this? And then we've sort of iterated on it a bunch and you kind of want people to come to you with ideas early on because that way it doesn't feel as bad to shut them down. If like this PR we've been going back and forth for like almost a year and a half now and if I now then said actually let's not do this, that would be now, then I would feel really bad. But I also don't think that's the case here. Like I genuinely think this is a good idea and if I hadn't, I would have told them earlier. One of the things I did say in the beginning, I think for this one was like this, you know, it might be that this isn't the path to take, but let's see how it works out.
00:17:20.535 - 00:18:29.195, Speaker A: And then we iterated some more and then we were like, okay, this is actually the path we should take. Great. To force the use of start tls. That's fine. Talked about that negation. And then this changes the connection mode to be TLS if it was set to TCP and then it says the TLS kind but why doesn't it do that for the other ones? So long discussion here, like oh, I see. So the native TLS is different from tls.
00:18:29.195 - 00:19:43.349, Speaker A: So TLS is saying required that the connection is encrypted. Start TLS is saying required that we use start tls Native TLS is saying when you do TLS and require that you do tls, then use this TLS library. And then Russell's is the same. Oh yeah, that's a good suggestion. Yeah, I don't love this. Yeah. So they're basically proposing the same thing that, that I was about to say, which is all of these helper methods of like native TLS Russells, they're maybe convenient, but they're also a little weird.
00:19:43.349 - 00:20:47.115, Speaker A: Like it's, it's weird that the like the TLS function sets the mode, but the native TLS function sets the kind. Like it gets really weird. Okay, let's resolve that to get it out of the way. I think I'm sold. I think we should just have mode and kind directly. The this also end up confusing because it's hard to tell that TLS sets the mode, but native TLS sets the kind. Having just mode and kind is clearer, I think.
00:20:47.115 - 00:22:08.703, Speaker A: Shouldn't native TLS imply that it should use tls? Yeah, so. So that is one of the things that currently does. And I think that also means that up here in the thing that says TLS kind. If we're now getting rid of the helpers, I think we should have this also specifically set mode to be TLS if it is set to. If it is currently set to tcp. Even though it may be confusing if someone does. Yeah, because I don't want to run into the case where someone sets somewhere else in their code, somewhere that's hard to find.
00:22:08.703 - 00:22:36.121, Speaker A: Sets mode TCP and then they call TLS kind setting, you know, Russell's or open ssl. And then it turns out it's not using TLS because of that setting of mode. And I think it should use TLS rather than start tls. I think that's right. Yeah. And that's going to get rid of a bunch of this. It's going to make it nicer.
00:22:36.121 - 00:23:24.265, Speaker A: I agree. And then there's a connect and connect is going to call connect with. That's easy enough. Domain and the TCP socket client and connection. Right. So connect with I believe takes down here as a closure that's given the TCP stream and it needs to return something that implements read and write and this set read timeout which we use for a bunch of other things and then we turn that into a dynamic dispatch object. So you'll see that down here match on the mode.
00:23:24.265 - 00:23:51.245, Speaker A: Yeah. So here if the mode is auto, then if the port is 993, we do handshake here. Handshake is a. Is just the handler that we get in. So we do a handshake against tcp. Otherwise we do a connection over. We just do a plain text connection to the Server read the greeting, look at the service capabilities.
00:23:51.245 - 00:25:07.955, Speaker A: If Start TLS is there, then we do a handshake on the TCP connection. Otherwise we just return the TCP connection directly and you'll notice that your handshake really just means apply encryption, which is a little weird. Like it's. It's weird to me that sometimes it doesn't evoke that function. So this gets invoked in order to construct TLS over the connection, which I think means that it's impossible for it to get here. Like I think that should be a to unreachable because in the case of auto you might call the handshake. Yeah, this is.
00:25:07.955 - 00:25:36.437, Speaker A: This ends up being wrong. Like if you have this set to auto but you don't have any TLS library enabled as a feature, then this will do the wrong thing. The handshake is final, just return. Okay, that's fine. But if the port is not 993 and we detect start TLS, then we're going to run the command start TLS even though we did not have any TCP binding. So this ends up wrong. I think this is wrong.
00:25:36.437 - 00:29:24.975, Speaker A: If the user hasn't enabled any of the TLS providing features, it'll call through to handshake but shake then just returns oktcp even though we've told the server to switch to an encrypted channel. You probably need a config here to not send star TLS if we don't have TLS capability. This is a knit but I'd kind of like for handshake to be called something like TLS centric and for and then for us to ensure in connect with that we never call it if we don't have TLS capability feature have any TLS capability features enabled, which would then make this be a unreachable rather than okay tcp. What do you think? Yeah, like this I don't actually think is true because it might all it might get called if the server the connection does not end up as tls. Like this framing is wrong because handshake will be called if the server has star TLS or if the port is set to993 even if you don't have TLS features enabled isn't quite true because we may call handshake currently at least if even if no TLS enabling features are on, which would mean it's called despite the connection not ending up as tls and then TCP just means boxing the connection. That's fine. Start TLS means just do TLS that's fine.
00:29:24.975 - 00:29:54.825, Speaker A: And TLS means do the handshake. Great. Build TLS connection. So this is the thing that. This is like a helper that uses the appropriately configured library to. To wrap the TCP stream in a thing that does the actual TLS encryption and decryption. So in the case of.
00:29:54.825 - 00:30:35.995, Speaker A: In the case of Russell's, that means constructing a client config safe defaults root certificates, creating a config and then connecting. Okay. For native tls. Native TLS connector builder. So these parts are internal to the libraries. We're basically hiding this from users, which is nice. What happens with any if Russell's is enabled, then any calls Russell's.
00:30:35.995 - 00:31:18.025, Speaker A: Otherwise any calls native. Okay, so we're defaulting to Russell's. That seems fine. And is that documented up here on the enum? Where's the enum here? TLS kind server back in is available. Restless used if both are enabled. Great. Okay, that looks reasonable.
00:31:18.025 - 00:32:15.827, Speaker A: And then this is that connection thing. So this connection trait is just read plus write plus send plus set read timeout. And the only reason why we have this trait is so that we can create a trait object or a dynamic dispatch object, if you will, for the collection of those functions or of those traits. So you can't do boxed in, read plus write plus whatever. You can only do boxed in and then one trait and then any number of marker traits. So we need to have a trait here that we can then do dynamic dispatch over in order to get the union of those traits. But we don't actually want anyone to implement this because the trait itself is sort of like we want to control which connection types people uses with.
00:32:15.827 - 00:32:58.825, Speaker A: And maybe we don't need to, but we have. So this is the reason why we do it. We seal the trait so that we can just do a blanket implementation for any type that implements all of them. So if you have a type that implements all of them, it automatically also implements this trait and then we use that as the dynamic dispatch object. So a connection now, which is the thing that a client holds, instead of being generic over C, it now just internally holds a connection. And that connection is dynamic dispatch object into something that's read and write. And then this, the sealed thing is a rust pattern that lets you make it so that it's impossible for someone else to also implement the trait.
00:32:58.825 - 00:34:20.793, Speaker A: Great. Not TLS and connect seems fine. What's the default up here? I want to double check that I'm not. No, not source client Client builder. New defaults to mode, auto and TLS kind Any okay, so auto. So it'll generally work for people, but it might not default to enforcing tls. There's a question whether in this day and age we should actually like just require straight TLS by default and then require the use of a more dangerous constructor.
00:34:20.793 - 00:36:05.849, Speaker A: If you're willing to tolerate plain text, I'm tempted to have two constructors for. Or no, rather I am tempted to have mode default to connection mode. TLS really is what most sane clients should be using. Even Start TLS has its problems. Users can then always override that behavior if they know they want to connect to a less secure server. Maybe we have a helper method called dot compatible or something that will set auto plus any letter maintainer. Oh, nice.
00:36:05.849 - 00:36:39.213, Speaker A: I've used your thing. That's what we do. We discourage plain text connections. Yeah, that's the same thing I want to do here. I want to make it harder to do the insecure thing. Not impossible. Yeah, so the Start TLS mode for us will also error if Start TLS was not able.
00:36:39.213 - 00:37:30.611, Speaker A: Auto will not. But here you see, if you try to do Start tls, then it does a Start TLS call to the server, regardless of what the capabilities are, and then it does a handshake and expects to be able to do a TLS handshake. So we have the same expectation. Oh yeah, it shouldn't be unsafe. So I'm not proposing that this constructor is unsafe or that setting that setting like auto or even plain text should be. Should be just an actually like marked with the unsafe keyword in rust that I don't think it's valuable because it's not. It's not memory unsafe.
00:37:30.611 - 00:38:10.997, Speaker A: I also think I want this. I think I prefer the wording the name placer for this. Great. These tests I've read through before, so that's fine. I'll close that. And this is mostly just changing all these sessions to be connection. I wonder why they even need to be connection.
00:38:10.997 - 00:38:42.935, Speaker A: I thought we made this not be generic anymore. Oh, it's still. Let's see if I can dig up an example of this. So if you look at client, we haven't actually made client not be generic. So you can still use like the new constructor, for example, to construct a client over anything. It doesn't have to be a TCP stream. So we're not requiring that you use this dynamic dispatch through the connection type.
00:38:42.935 - 00:39:44.155, Speaker A: We're just making it so that when you use the builder and you have all these different TLS variants, the TLS types don't leak out. You can always, if you really want to construct these these streams from the bottom. Which makes me wonder whether, whether we should update client the definition of client to set that the default value for C. Let me find where's the definition of client? It's up here somewhere. Yeah, it's further down, isn't it? Yes, A session here. I think maybe we should add a equals connection so that if you don't specify the generic then you get the type that you're going to be getting back from the builder anyway. We're so, so close.
00:39:44.155 - 00:41:35.245, Speaker A: More nits, but they're small. I also think we might want to add equals connection to the t generic type parameter on both connection and just so that in the common case where people use the type use the builder, they don't have to specify connection everywhere, having it generic over the stream as a huge upside that it should be really easy to test the parser by just using something like cursor evacuate. We already do that actually, but you don't need to have generics for that because remember how the IMAP connection trait is blanket implemented for any type that implements read and write. So that means that you can construct a connection like a box din IMAP connection from something like a cursor vec. And so you can still use that for testing. We would just say that, you know, the new new from inner takes anything that's generic over all of those sub traits and then boxes it up and then sticks that in the connection field. So you don't actually need the generic for that.
00:41:35.245 - 00:42:36.315, Speaker A: Great. Done. Nice. This is right. So this is. Sometimes people are building their own libraries or even binaries on top of the IMAP crate and they want the ability to just like essentially test their code without having to talk to a real IMAP server, which means that they have to be able to construct the types that the IMAC pro returns. So if we look at over here in look for something like fetch.
00:42:36.315 - 00:43:29.977, Speaker A: So on the session type, which is you're connected to an IMAP session, you can call fetch and that gives you back this fetches thing, which gives you an iterator over fetch things which have messages that are in the inbox. But if you are trying to test the thing that's built on top of imap, what you'd really like to be able to do is construct this thing yourself so that you can construct one of these without having to run an IMAP server and then pass it to your code that expects to get one of these. So basically the ability to not quite mock out imap, but at least be able to produce the same types that the IMAP library is going to produce, but in a way where you control the contents. And so that's what this PR is adding. Great. It's fixed. So there's now a separate.
00:43:29.977 - 00:44:26.911, Speaker A: You see source Lib just adds a testing module and then there's a sub module for the different kind of types that we have or categories of types. And then you see the main thing that it presents is at the moment is this parse method that just re exposes internal methods we have that takes a sequence of bytes like an IMAP string and turns it in to one of the real objects. Our parse methods are no longer pub, they used to be, but they were kind of. They had kind of wonky signatures, things like which how they deal with unsolicited messages and stuff. And all of that is not really stuff we want to commit to in the public API. So that's why they were no longer pub. But then these functions have the very straightforward interface and it allows people to give.
00:44:26.911 - 00:44:56.321, Speaker A: Like if you got this string from the server, then it would be parsed into this. So it doesn't. It's not a convenient builder for one of these return things. If we look at fetches, it's not a convenient way to construct one of these fetches, but at least it's possible. Right. All you need to give is the IMAP protocol input and it will parse into the appropriate thing that you would have gotten if you really had an IMAP server. Yeah.
00:44:56.321 - 00:45:57.435, Speaker A: And then this sort of lots of public sub modules thing is a nice way to namespace this. So now people can do things like testing colon, colon names, colon, colon parse, extended names, ACL response. This seems fine to me. Yeah, we might expand this over time and do things like actually provide builders for these. But I don't think we need to do that straight away. Enables test helper features to enable the test helpers feature to expose helper methods to build mock response structures for testing your code that uses the IMAP crate. Yeah, that's for a different pr.
00:45:57.435 - 00:46:20.437, Speaker A: Great. Looks great. Now prove rolling CI failed. That's fine. So that's some cargo update somewhere. Don't actually worry about that. And I don't think I care about the commit history here.
00:46:20.437 - 00:47:10.239, Speaker A: So we're going to squash this. Exposes parse methods, confirm, squash and merge. Beautiful. So that might go out in an alpha or something. Idle concurrency issues. So this one we talked about in a previous stream, which is someone wants to fetch the messages from the server and then do what's known as an idle call. So you can send us a message to the server called an idle call and then the server is going to just keep the connection open and send you a message when a new email is in the inbox or in the selected mailbox.
00:47:10.239 - 00:48:06.017, Speaker A: But there's a sort of race condition here where if an email comes in between when you call fetched and when you call imap, when you call idle, then that one is not included in your fetch because that happened before. But it's also not a new email as far as idle is concerned, because it doesn't arrive after the idle call and therefore it doesn't get sent. And this just turns out to be like a fundamental race condition in IMAP in the protocol. Apparently some servers just like if something comes in between, they just know to include it with the idle, but this is just unspeced. Interesting. Interesting. Yeah.
00:48:06.017 - 00:49:00.535, Speaker A: So they should just be sent later. Yeah, it might be that these end up exposed as unsolicited responses, which we also expose in the API. I'm going to go ahead and close this as I don't think there's much the IMAP crate could do here. But if you think of something, please do let us know. Do you personally use the IMAP crate for anything? Yeah, so I use it for this little daemon I run that gives me email notifications because I don't run an actual email program. I use mutt, which with Mutt I just. I don't see my mailbox.
00:49:00.535 - 00:49:40.845, Speaker A: Nothing is running email wise until I open it. But that means I don't get email notifications, which is frustrating. So I've written this little tool called Buzz Buzz, which just runs a little system tray application that gives you a notification when you have email and that uses the M Upgrade Add Inferno collapse GHC Prof. To handle GHC's profiles. Because this format is not directly Rust related, I'm not sure if you'd prefer this to be part of this report or be a separate crate listing ghc. The Haskell compiler is its own format for profiling traces and this adds collapsing for it. Nice.
00:49:40.845 - 00:51:03.885, Speaker A: Yeah, this is interesting actually. Like sure, it's not Rust related, but the goal of Inferno is to be a reimplementation of Flame Graph, so it's not intended to only work for Rust code. Okay, so that's GHC profile count, bytes count ticks. Well, this isn't right. If these are mutually exclusive, that needs to be represented is bytes and R Bytes and ticks mutually exclusive. If so, we should use conflicts with equals bytes and vice versa to enforce that through clap. And so the user gets a nice error if they try.
00:51:03.885 - 00:52:02.545, Speaker A: I'd like a bit more detail here. Count which bytes. What does. What does this mean, concretely? Also, we should also document that this flag is incompatible with ticks. And we should document what happens if neither bytes nor ticks are passed. Actually, I want that to be separate. So down here we should document what happens if neither bytes nor ticks are passed.
00:52:02.545 - 00:52:54.945, Speaker A: Probably in the doc string four the entire opt type so that it appears when the user runs. Aha. We have the author of the PR in chat. Great. I'll still leave the comments. They're useful. Main initialize logger.
00:52:54.945 - 00:54:35.651, Speaker A: This part seems fine. All right, and then we got a parser start line. Why is percent time and percent alloc repeated here? And also there is no ticks or bytes column. Why are and twice? Also, shouldn't there be a ticks and a bytes column? That seems odd. Seems fine here too. I think I'd like a bit more detail here because while this is accurate, this is the column we're pulling the data from. It's not particularly helpful to someone who is trying to decide which source is best suited for whatever they want to do.
00:54:35.651 - 00:55:36.965, Speaker A: They would have to go look at the format definitions for GHC Prof. Elsewhere and then come back, which is a little unfortunate. Current cost. The first character and last plus one. I don't follow this comment. What exactly is this? There are three fields in the struct. All of them use size.
00:55:36.965 - 00:56:36.293, Speaker A: Okay, so collapse is like the main bit to any implementation of a new format for Flame Graph. So this is the thing that takes like the output from the profiler and turns it into the sort of this. There are this many samples of the code being in this frame. So it like collapses, which, hence the name. It collapses the giant profiling trace and turns it into this thing called this many times or this many samples, rather consume the header. Oh, that's interesting. Okay, so what they're doing here is in order to detect whether it's the header line rather than just like string.
00:56:36.293 - 00:57:25.511, Speaker A: Comparing this to the header line, they're splitting the line by white space, taking the first N elements and seeing whether that iterator is equal to the iterator over these. That's not wrong. What's this break from? Oh, I see. So they break here. Oh, nice. Okay, so they're reading like they're basically looking for the header in the file and one might hope that it's first. But that's not always the case.
00:57:25.511 - 00:59:20.315, Speaker A: There might be some empty lines in the beginning or something. So I guess what they're doing is looping through the lines, seeing if it's the header line and if it's not, is this uncommon enough, the header not being the first line, that we should issue a warning question mark or at least print something at say, debug level. But if they find the header line, then this is why those are repeated. Module L dot find. So module is. So this is the character offset of the start line 2012 of the string module in the header line. But why does that matter? Like usually these, these formats are, you know, white space, white space oriented, for example.
00:59:20.315 - 00:59:57.585, Speaker A: So like this is saying that the module field is the third column or second if you start counting at zero of the file. But. But why the character offset? Because presumably later lines might have, you know, text at the beginning that isn't all the same width. So this strikes me as odd bytes. Columns are weirdly aligned. Might help to check out the format. You might not be wrong.
00:59:57.585 - 01:00:35.095, Speaker A: Oh, weird. They're actually like aligned. Wait, show me a test file. Now this is the expected output. I want the expected input like this one. Oh, so there is expected stuff before the header line. What's also interesting here is that this is.
01:00:35.095 - 01:01:02.545, Speaker A: This doesn't actually have all those. Oh, this is the first one. That's actually the. Okay, this stuff we want to skip over. And this is the header line. So let me first then get rid of this because clearly that's not true. It's pretty common for there to be lots of things down there.
01:01:02.545 - 01:01:39.417, Speaker A: But this is still white space separated. It's just also aligned, which is wild. Like who aligns this output? I suppose so. Here's an interesting observation though. The fact that it's aligned means that you don't need to worry about spaces in the value of any given column. So imagine that you have a. The path to your file has a space in it, like my documents or something.
01:01:39.417 - 01:02:36.995, Speaker A: Right. Then in a white space separated format, you have a problem because that space is now a field separator. Whereas if we actually don't go by count the number of white space separated fields and instead go by the absolute character count, then you know, if there's a space in here, it doesn't really matter because we start counting at this offset anyway and count until, you know, there. Yeah, in fact, like no location info, if you did white space split here, you would get completely wrong counts. Oh, so weird. Okay, okay, it's not. The code isn't as wild as I thought.
01:02:36.995 - 01:03:38.975, Speaker A: This strikes me as weird. I would just use module here. I think start line two is mostly just obscuring what this does. So this finds the offset of percent time. What? Ticks and bytes columns are weirdly aligned. So find the end of the column before. That's crazy.
01:03:38.975 - 01:04:37.243, Speaker A: I would like to propose here that we do percent alloc lens and same thing here. I think ticks dot len. Actually, I want to take that back, I think because I do want to make that change. But this comment is now unhelpful. Let's do this in a better way. Delete. Let's do instead these suggestion like this.
01:04:37.243 - 01:05:28.125, Speaker A: And then I'd like to do. Like to do better than unwrap here. If the user has asked to source from a column that doesn't exist in the input file, we should return an error, not panic. Okay, so once we found this header. Oh, I still want to see what. What's the deal with ticks and bytes? This one doesn't have ticks and bytes, so it's percent. So give me one that has ticks.
01:05:28.125 - 01:06:06.401, Speaker A: These. These are all results. Aha. Ticks Prof. Ticks and bytes. Cost center is left aligned. Or cost cost is left aligned.
01:06:06.401 - 01:06:34.335, Speaker A: Center is right aligned. What? No, wait, this. Okay. Cost center is one field and it's set to whatever this thing is. And it's indented but not left or right aligned. Module is left aligned. Source is left aligned.
01:06:34.335 - 01:06:57.505, Speaker A: No, is hard to say. Left aligned. I think Entries is right aligned. Present time is right lined. ALEC is right aligned. Time is left aligned. ALEC is left aligned.
01:06:57.505 - 01:07:26.797, Speaker A: Ticks and bytes are centered. That's awful. Why? Why? Yeah, I mean, we can zoom out to have it not do that. Okay, that does. I mean, I don't. I don't know that I like it any better. I see.
01:07:26.797 - 01:08:05.155, Speaker A: Okay, fine. Okay, so they're not centered, they're right aligned. But then. Okay, so this brings me back to the question of the code. Like, why are they saying that? Okay, let me get rid of some of these in between. Why are they saying up here that ticks and bytes columns are weirdly aligned? So find the end of the column before. That only makes sense to me if.
01:08:05.155 - 01:08:38.881, Speaker A: If the value of bytes can go left of the start of the word bytes, which I think is what they're getting at. So when it says weirdly aligned, what they mean is right aligned. So you don't want to start. If I'm guessing correctly, you don't want to start Parsing bytes at this byte offset because bytes is right aligned, so there might be digits here that matter. So that's why you want to find the end of this column rather than the start of that one. So this is just saying that they're right aligned. It's not.
01:08:38.881 - 01:09:05.815, Speaker A: They're not really weirdly aligned. Yeah, it's very much intended for human output, I think that's right. Yeah, indeed. Yeah. So this is right right aligned. So here's what I'm going to propose up here. Then I would just say that they are right aligned.
01:09:05.815 - 01:09:52.295, Speaker A: Weirdly aligned. Sounds like they're weirder than they really are. Ticks is right aligned, but bytes is not really. Yeah, it is. Bytes is right aligned, at least in this file. Right. The right side of the numbers aligns with the right end of bytes and ticks is the same.
01:09:52.295 - 01:10:29.945, Speaker A: Right. Unless. Give me the file for this is ticks. Do we have one for bytes? There isn't a input file for bytes, so it's this one. But here ticks is zero for everything. Do we have one where tix is not zero for everything? Result. Ticks Prof.
01:10:29.945 - 01:11:05.423, Speaker A: So there's not a bytes Prof. It's a little weird that the file called ticks Prof. Has non zero bytes but not non zero ticks, but these. Oh, that one's non zero. But these are definitely right aligned, from what I can tell, at least. Okay, so after we find the header, then we skip one line. Okay.
01:11:05.423 - 01:11:39.975, Speaker A: Why do we skip one line format? Come tell me there's just an empty line. Okay, thanks. Great. That's fine. And now process the data. Okay, so this occurrences type is a convenience thing we do for people who write collapsers. That's basically kind of like a fancy hash map where you can stick things in there and it'll keep track of how many occurrences are in the parents and stuff as well.
01:11:39.975 - 01:12:25.265, Speaker A: So you read each line. If the line is empty, if the input. If we reach the end of input, then we break. That's fine. Parse the string line, trim. The end line is empty, then we break. Is it impossible in this format for there to be empty lines in the data, as in between rows of profiling information? Because then this would break early.
01:12:25.265 - 01:13:01.603, Speaker A: Otherwise we call self online. Okay, Write the results back. Reset the state. Why does it need to reset the state? I think this is something we do elsewhere as well. I don't remember exactly why we have to do this, but that's fine. Okay, so online. Yeah, so the lines look like that.
01:13:01.603 - 01:13:44.597, Speaker A: And this is awful because it means you have to like, the indentation tells you whether this is a child or not. So when we get a line, we find the number of spaces. Yeah, of course. This is awful. Previously. So what is the stack here? What does this actually hold? There's a vector of strings. Oh, right.
01:13:44.597 - 01:14:11.945, Speaker A: So. So there's one in one space for each level deep in the stack. So the length of the stack is the depth of the previous thing you looked at. So if the new depth is less than the current depth, then we pop this. Then that means we're in a different parent. So we pop the stack. Truncate.
01:14:11.945 - 01:15:09.285, Speaker A: But don't you need to handle the. Normally you need to like close the stack frame, but maybe not in this case. Otherwise. Yes, we're expecting that either you can drop down any number of stack depths or you're. Or you're at the same depth. But what about one higher? Oh, I have an off by one. So this is looking for the first non space characters.
01:15:09.285 - 01:15:35.739, Speaker A: So is the initial one main? Great. So this one is zero offset. So indent characters is going to be zero. The previous length is going to be zero. So they're going to be equal. Great. Then we push main onto the stack and then we walk one down.
01:15:35.739 - 01:16:13.239, Speaker A: So now indent characters is going to be one and the stack length is going to be one. Because we're a child. Okay, interesting. Yeah, so that's. That checks out be non ASCII names to take care of the character offset, not the byte offset. So now we also get into this depends on how the alignment code in the thing that produces this output works. Like does it.
01:16:13.239 - 01:17:31.355, Speaker A: What does it align by graphemes? Because that's not what characters gives you. Here you skip by call, start skip while. So you skip leading white space. Wait, but this is wrong though, because this would fail to capture contents with spaces in them. So I think this has to not have this take while and instead trim at the end. This won't work for fields that have spaces in them. I think you need to collect all of them.
01:17:31.355 - 01:18:03.285, Speaker A: Collect until the end and then trim. Right. So the cost is the string range based on which source column they chose. If that can be parsed as an F64. If it can't, then the cost field is wrong. That's fine. And then we read the cost center in the module.
01:18:03.285 - 01:19:12.485, Speaker A: Cost includes self plus calls. Okay, so that means this format is inclusive of children, which is a weird sentence. Where's the percent input file here? Individual and inherited. I don't understand why all these numbers are zero. This doesn't seem right because. So up here we grab which field for time? We grab the first time field, and the first time field is individual time, which I assume is self cost, so not including children. Otherwise this is very weirdly named field.
01:19:12.485 - 01:19:47.655, Speaker A: There's function and modules, so there can't be spaces. Oh, it doesn't include source. That's true, I suppose. Even so, it's nice to have the code just. Also, if you happen to eventually start parsing the source as well, it'd be nice for it to handle that case correctly too, which I think is fine. Right? Like you. Oh, it's because you don't record the end of the column.
01:19:47.655 - 01:21:21.825, Speaker A: To do that, you'd need to also store the end index of a column, read to the end and then trim. Right. Probably not worth it, but worth flagging in case this is ever used. Flagging in a comment in case this. In case someone ever thinks this might be appropriate for fields with spaced values. I don't think this is true for time. At least the first percent time column is listed as individual, which makes me think it doesn't include child calls.
01:21:21.825 - 01:22:07.005, Speaker A: Maybe true for tick spites, though. Don't lose the one decimal place. Oh, I see. This input always includes one decimal place. But do we. I don't understand. Do we pull that back out? So up here we store the current cost as a U size.
01:22:07.005 - 01:22:38.385, Speaker A: I see. So this is saying. So it's no longer a percentage here, really. Right. Because if you're multiplying this by 10, then yes, you don't lose the percentage. But it also doesn't add up to 100 anymore. But that's fine.
01:22:38.385 - 01:23:56.085, Speaker A: So it'll. It'll be a little misleading because someone puts in percent time and what they can get out is. What's it called? I don't know what it's called in English, but like the thing that's more than percent as in it's a thousandth and not a tenth. So let's try to push file trim. I probably wouldn't call this file, given there's a separate field called source, which really is file module. Maybe identical stacks from other threads can appear. Yeah, so this is something the perf actually handles in a different way.
01:23:56.085 - 01:24:20.415, Speaker A: In perf, the thread name is part of the stack, and I don't know whether we want to include that here, but maybe the thread name isn't even included. That's fine. If. So I'm confused about. This is. Oh, right. So this is for collapse.
01:24:20.415 - 01:24:49.635, Speaker A: So that's just. If it finds the start line that's fine. And then we have a bunch of tests with ticks, including selecting ticks and selecting bytes. This seems fine. All of these input files are fine. I don't really want to. There's no meaningful way in which I can look at those.
01:24:49.635 - 01:25:17.445, Speaker A: It would be good though, to actually plot one of these. Like do an end to end test that produces an SVG to see that actually produces something that looks kind of sane. Like, one way to do this is. I guess we can look at this. Prof. And so that's ticks. Let's look at tick bytes, see what it produces.
01:25:17.445 - 01:25:45.935, Speaker A: Main dot, main. Oh, right. Because what it does is it takes the module and then appends the function with a dot. That's fine. Whoa. Why? Oh, right. Because in Haskell you can actually have things with ticks in them.
01:25:45.935 - 01:26:06.355, Speaker A: Yeah. So you can have a tick at the end. Yeah, yeah, yeah. Because it's valid in identifiers, which is really nice. Okay. And so it produces this with account. So that seems pretty reasonable.
01:26:06.355 - 01:26:36.605, Speaker A: One of my concerns here is that the. It ends up very long, but that might just be something you can't really get away with with Haskell here with these paths being long. So that seems fine to me. Okay. Yeah. I would love to see a test that actually turns this into an SVG as well, just so we can. It's easier to see whether it looks right than it is to try to parse it out of one of these.
01:26:36.605 - 01:28:40.735, Speaker A: Could you also add a test that goes all the way to a flame to an svg? So we have a test result that's easier to visually inspect as well. But otherwise this looks good. Although I saw someone mention in chat that GHC has a dash PJ option that outputs Jason, and I think that's worth looking into, but I think this is pretty close, actually. I do want to include my note about down here. This assumes that GHC's thing that produces aligned output aligns by UTF8 code point, but that's area by Unicode codepoint. But that's not necessarily the case. It could be aligning by glyph or grapheme instead, or grapheme cluster instead, in which case this would not give us the right result.
01:28:40.735 - 01:29:31.765, Speaker A: Someone mentioned that ghc has a dash PJ fly to produce JSON output. Maybe it's worth digging into whether we should just use that instead. Because I do actually really worry about this alignment point, because who knows whether they're going to keep this. Like, if they, if they, if they treat this format as being just for humans. That also Means that they might change it at any time. Like they might just change the alignment of the ticks field. Not to mention this would make us resistant to if GHE changes this seemingly human facing format.
01:29:31.765 - 01:30:39.129, Speaker A: I don't think any of the other collapse tests went to svg. I think you're right. This was actually more just because I think it would be useful. That's fine, I'll leave it out. It's just it would be useful to visually inspect the svg, but if you have looked at the SVG and looks reasonable, that's fine for me. One thing we should definitely Check out is GHC's PJ flag for JSON output if that can make this job easier and more robust. Also, could you run one of these through all the way to an SVG just to give it a visual correctness check as well? If you haven't already.
01:30:39.129 - 01:31:28.107, Speaker A: That is great. Done. Oh great. This is one of the things we talked about in a previous one where someone posted some errata for the for rust for restations around the syntax I use for awaiting sockets and saying it doesn't quite align with what the real like Tokyo library for TCP listeners for example looks like. But so this they seem satisfied with that description. So that's great. Oh, I'm so glad.
01:31:28.107 - 01:32:34.115, Speaker A: The next thing I want is I want Inferno to directly parse perf data files rather than the output of perf script and that's going to significantly speed it up. Even more error when iterating over histograms with only zeros. So this is in the HDR histogram crate. This one we also talked about last time. Okay, so the problem is if you have a histogram where you have recorded zero values and then you try to iterate over all the recorded values, it tells you that there are no values in the histogram which is false. You've recorded zeros and we had some speculation about why that might be. Problem does not seem to be the more function which is meant to indicate more records with zero counts past the max but pick returning none as we give it a count of zero.
01:32:34.115 - 01:33:43.973, Speaker A: Doing plus equals zero is a particular case. As if we only do this, we never update the minute the max. The zero is both the min and the max and thus both the first and the last item in the iteration. And we have some code that checks whether we've already picked the index with the last non zero count in the histogram. Total count index is zero and this tells us to skip. Let's see. Okay, so the Fix is one line.
01:33:43.973 - 01:34:32.445, Speaker A: That's nice. Right. So we have this iterator for histogram iterator. So this is the. There's basically this. This type that knows how to iterate through all the buckets of the histogram and it's generic over this type P, which is a. A way to specialize that iterator to only count certain things or group the things in the iterator so that we can do things like iterate by percentile, iterate by bucket, iterate by fixed steps, or iterate by recorded values.
01:34:32.445 - 01:35:07.530, Speaker A: And that's all encapsulated in this picky iterator trait. But this is for the general iterator that knows how to walk the histograms. So while we're not at the end. Okay, that's easy. Have we reached the end? If the current index is equal to. I need the definition of this current index is equal to the number of distinct values which should be false. The number of distinct values should be 1.
01:35:07.530 - 01:36:48.195, Speaker A: Right. Because 0 is a distinct value. So we don't hit that. Have we already picked the index with the last non0 count in the histogram? We already picked the index with the last non zero count. If the last picked index greater than or equal to the max value index. Interesting. So this doesn't seem quite right because this condition up here is whether we are.
01:36:48.195 - 01:37:49.497, Speaker A: We should go into this. If we are in the oh in and have picked the index with the last non zero count. Yeah. I'm wondering where the last picked index should be an option here because otherwise I worry that you kind of never get out of the case of it being equal to zero. And so this is why I think it's the implementation of more that's wrong. Which is what we got to in the beginning here. Right.
01:37:49.497 - 01:38:51.293, Speaker A: The proposal I gave here was I think it's the more implementation which always returns false here. That's wrong. Because if more returned true, we wouldn't take this path and we also wouldn't take the else. And then we would go down here to figure out if the picker thinks we should yield this value, which means that we would call pick. So I actually think this isn't the right fix. So why are they saying that's not the fix but pick count returning none as we give it a count of zero. Oh, what? So they're saying that pick does get called.
01:38:51.293 - 01:39:31.735, Speaker A: It just gets called with a count of zero. So this is in fact invoked but total count to index zero. I see. And that's because total Count to index starts as zero but doesn't get updated until here. And we never get into this one because we're in that condition. Okay. And we wouldn't get into this one if.
01:39:31.735 - 01:40:45.087, Speaker A: If we just went with more being true. So what this has me worried about is what happens. I think this will mean that you, if you try iter recorded over a histogram that has no entries that you would suddenly see like one value yielded. Maybe you won't because pick would have its count be zero. So maybe this actually is right. But it does feel like maybe it should be option because otherwise you'll never go into this case at zero, which isn't. Which is also not right.
01:40:45.087 - 01:42:05.665, Speaker A: It could be that you should actually walk the first bucket more than once, which this wouldn't do because the first bucket is sort of excluded from having this path taken. But what would be the effect of that? The effect of that would be on. The only way you would see this is if you had very wide buckets and you tried to iterate by a fixed interval that's smaller than the bucket size. Because then you need to call. You need to not take this path because you haven't moved on to the next bucket yet. You're still in the same bucket and you. You want to be calling more.
01:42:05.665 - 01:42:54.007, Speaker A: I think not the first bucket. The last. Ah, but last picked index value index. Right. But zero is the only case where min and max would be equal. It just. It feels wrong.
01:42:54.007 - 01:43:57.231, Speaker A: I can't quite put my finger on it. No. Maybe the case I gave is the one where this doesn't work. Like you have a bucket size that's this wide and you ask for an iterator that walks in fixed widths of this size and then you have no recorded values. Then we would actually want it to call more multiple times within the bucket. But this wouldn't do that for the first of the buckets. Which I think then means that we might want this to be the last picked index to be an option and only exclude this path if it's set to none.
01:43:57.231 - 01:45:03.635, Speaker A: And then we set it to sum down here to make sure we actually essentially ignore that condition from then on. So let's say we want to ensure we trigger the picker logic at least once to keep the amount of the loop prefer to fix than make the initial value last pixel in an invalid index being used as a can't be negative. And I don't see a performant API compatible way to make it something else. But I'm also fairly new to rust so no doubt someone can come up with something better. That's kind. Yeah, I've done this too actually. So this sorry for being slow is often not the right framing if you're an open source maintainer because you don't owe other people your time.
01:45:03.635 - 01:45:51.415, Speaker A: So the sort of thanks for your patience is a better way to take it. At this point I don't feel bad. Like in some sense I shouldn't be writing sorry because I don't feel bad about it. I know that it's for good reason, but it is true. Okay, so if we did want to make this an option, what would happen? I think it's fine for the Iterator to hold an op. Make last picked index be an option here because it is not a public field of this type. So I think that's what we're going to do.
01:45:51.415 - 01:47:19.775, Speaker A: The thorough here is instead to make last picked index an option option. Use that way you can explicitly indicate that it hasn't been set yet. It's not a part of the public API, so you don't have to worry about breaking backwards compatibility. What's also nice is that once you change the type of that value in the. What's this type called? Histogram iterator. The struct histogram Iterator type definition. The compiler will guide you to all the places where the code has to be updated to reflect this change.
01:47:19.775 - 01:48:09.445, Speaker A: I think you're right, that more is not to blame. And I agree with you. It should probably be renamed one day. Great. All right, great. So I can mark that as done, which also means that I can mark that PR as done. But that's not even on the page yet.
01:48:09.445 - 01:48:30.743, Speaker A: I can refresh it, I suppose. Let me go back and get that. Yeah, this one. Great. Update license field following SPDX2.1 license expression standard. Oh, that's true.
01:48:30.743 - 01:49:09.345, Speaker A: Slash is ambiguous in SPDX. That's fine. Okay, great. Approve. Oh, I should probably for this one also have done. Oh, that did run the checks. Okay, so this one, I'll wait for these to land and then I'll do a release of Fontaccini afterwards just to get it updated on crates IO as well.
01:49:09.345 - 01:49:41.815, Speaker A: This one, Beautiful. Great. So now I can land this. This is a change to the We Were wondering site. This requires that I do a bunch of manual work to publish the changes so that I'll do that offline because that's more work. Put that back over here. And same with this one, I'll do a release of that once I have a chance.
01:49:41.815 - 01:50:09.115, Speaker A: Immutable. Iterator so this is a change to stream unordered. We also dealt with this on stream a while back, I guess exactly two weeks ago. I have a feeling the first life is unsafe. Very much out of my depth in this level. So full review of this function is in order. All other functions remain identical minus some internal rearranging.
01:50:09.115 - 01:51:25.745, Speaker A: Nice. Okay, let's go and see what this looks like. Now enter pin mute with token. Okay, so there used to be a pub struct iter pin mute and there still is. And interpin mute with token is a new one. Oh, this is just. They've reordered where these structs are, which makes the diff a little annoying to read.
01:51:25.745 - 01:51:51.425, Speaker A: So this one I see. And this used to be this with these fields, but now it holds one of those instead. Okay, that's fine. Intermute with token. And this is the same thing like this now just holds one of those. But the definition of the type as far as the public API is concerned is the same. So that's fine.
01:51:51.425 - 01:52:37.161, Speaker A: That's totally fine. No need to call it out in the public box. So let's just suggest that we remove those lines. Okay. And then this is the same so iter with. Whoa. Iter pin ref.
01:52:37.161 - 01:53:56.025, Speaker A: Where did iter pin ref go? Where is it? Or pinref gone? Because we can't remove that type because it's published. Fortunately, we cannot remove this type. Oh, was it a 2 slash comment? Well, the first line is a 3 slash comment and then it's a 2 slash, so that's fine. But this iter pinref Am I just blind? Iter pin ref. We're going to have to keep this type as well, because it's part of the public API. Unless GitHub is just trying to be helpful and not actually showing me the full diff. But I don't think that's true.
01:53:56.025 - 01:54:47.315, Speaker A: Iter with token and same with iter. Actually, am I blind? Like is. Are they defining these somewhere else that I'm not looking? Ah, they weren't pub use. That's interesting. So if we look at stream unordered here and we look at. Yes, only the itermut and iter pin mute are actually exposed. But I think they are in the public API.
01:54:47.315 - 01:55:29.735, Speaker A: Oh, I guess they're not. Only iter mute and iter pin mute are. Then why are they even marked pub? Interesting. Okay, well that means that this. This I can get rid of. So there's now iter with token. That's fine.
01:55:29.735 - 01:56:13.795, Speaker A: And that's the thing that used to Be iter pin reference self item grabs the id, pulls out the id. Yeah. So we now have an iterator. So this is a straightforward change of the iter pin mute one that grabs out the ID and now includes that in what we iterate over iterpin mute. That looks great. Iterator for intermute is now mapping out just the stream. So that's fine.
01:56:13.795 - 01:56:57.787, Speaker A: Iterator for itermute with token where S is get mute. That's fine. This all seems reasonable so far. Do we know that these are exact size iterators? Like were the old iterators exact size iterators? I guess we do have the length. Yeah. Okay, great. So the size hint that we give out is self len.
01:56:57.787 - 01:57:57.707, Speaker A: Some self len. Okay, great. So exact size iterator is correct. Iterator for iter with token is supposed to yield a reference to S and a U size. And this is in the used to be iter pin reference. So this code. Interesting.
01:57:57.707 - 01:58:56.325, Speaker A: So this old iterator. So I'm just going to. I'm going to assume that my old unsafe code is sound rather than try to reevaluate whether the old code is sound. So if the old code was sound and it yielded pin of S and this is just yielding S. So this is taking the S out of the pin pin here again. So you can always project sref that's fine. Can you get as if you have a.
01:58:56.325 - 02:00:09.195, Speaker A: If you have a pin reference to T then you can get ref to get the reference and that is does not require unpin. So it's totally safe to go from a pin shared reference to a shared reference because clearly. Great. So I don't know why the original even bothered pinning these Again, it shouldn't be necessary. This can just return the stream and if it's the case that as we do up here, if it's the case that it's allowed to return references into these streams with you know, the lifetime that we are using here, then it should also be just as safe for it to be shared. This reference though I'm worried about. So here I think we have to do the same thing.
02:00:09.195 - 02:02:14.265, Speaker A: Let's do the same thing here as we changed with itermute which is to not assign to do not construct a reference inside task that might not be okay once we later in the same function instead just repeat a task in the two places it's used. Otherwise that looks fine. Great. Yeah. So the intermute method is just going to use this wrapper around that which just projects out the projects away the token this seems fine. This seems fine. But I think I want the documentation here.
02:02:14.265 - 02:02:52.605, Speaker A: Can you add to the documentation here to point out that this also yields the. I guess it's sort of implied by the name, doesn't really need to be called out. Okay, yeah. I also would love to have some of these types not be pub, like the. The. Although I think now they're. They actually are all published.
02:02:52.605 - 02:03:33.885, Speaker A: It just previously they weren't, so I think that's okay. Like now all these, these four are the only ones that are defined and they're all actually pub. And I was going to say, you know, the documentation here could say includes the token for each stream, but that's very much implied by the name of the function. And I would love to change the. Change these around, but that would require a major release. So that iter pin mute gives you a thing that also includes the token because you can always just project it away yourself. Iter with token.
02:03:33.885 - 02:05:27.823, Speaker A: So this is going to be like iter pin mute with token. Okay, so let's look at this one. So the original one does self headall getmute and it's only here that we dereference it. Why is this using. Oh, we can't use get mute. I'm confused why this even works. Because head all, if we go back to what is the original code here? Source lip iter pin mute all.
02:05:27.823 - 02:06:07.411, Speaker A: Or do we have head all? What? Oh, that's stream entry. I want stream unordered. Where's the definition of stream unordered Here? Head all is an atomic pointer. Task S. Yeah, okay, I see. Yeah. So here, because we have a mutable reference to self, even though this is an atomic pointer, we don't have to do an atomic load of that pointer because we know that we're the only ones pointing to it.
02:06:07.411 - 02:06:47.031, Speaker A: So we can use get mute on the atomic pointer to just read its value. No synchronization is necessary. And then we dereference what we get back together at the task. Right. The challenge they have is if you have a shared reference to self, then you can't do this. You have to actually load this value. And so this is where you run into a race condition where you might read the atomic pointer to the head and then.
02:06:47.031 - 02:07:26.645, Speaker A: And now you have a reference to the head. And then someone goes and swaps out the head behind the scenes and like deallocates the old one. But you're still have. You still have a reference to it. And then down here we now dereference that pointer, but it might no longer be Pointing to anything that's allocated. So the question then becomes yeah, it's this function that you're going to want to use. Yep, this function implements exactly that.
02:07:26.645 - 02:08:54.865, Speaker A: Oh no, no. My key bindings are confusing. You know the helper just below it takes care of exactly reading out the task pointer and length for you based on a and that one's not unsafe. That should in turn let you make this function entirely safe. Add a view Comment and what do we have here? This is a test iter that inserts five tokens and then checks that all of the tokens. Oh, I don't think we want this test. So this test is going to be order dependent.
02:08:54.865 - 02:10:25.249, Speaker A: I don't think we want to guarantee anything about the order in which token yields the streams. Let's collect the tokens into something like a B tree set instead and that way you can just. Or just sort. Just call sort on the back before you compare it and you should be significant. Oh, why do they change this? I think they said something about that in their comment. They said there's an async Bingo. Tokyo that now exists and conflicts with the Tokyo.
02:10:25.249 - 02:11:15.901, Speaker A: That's great. That's fine. All right, I think then I'm happy. Quite good. Left a note about how you can avoid the unsafe and then we're almost there. Done. We're making our way through this one is must be failing for unrelated reasons.
02:11:15.901 - 02:11:38.755, Speaker A: That's because we've since improved the test suite. This one I can just merge. There we go. Great. Great. That's just a follow comment. I can go away.
02:11:38.755 - 02:12:14.353, Speaker A: Nice. All right, what else we got? Keep them coming. We might. We might not get through all of these. Let's do some that are easy like these nits and bumps Then they get them out of the way. This is in Rustington. What even was that? That was the wordle silver.
02:12:14.353 - 02:13:40.681, Speaker A: Oh, this was the right oh, this is for the flight IO distributed systems challenges and this was just something like oh in the earlier implementations we didn't have this helper yet so we were just calling serdejson ourselves. That seems fine. Thanks. Submit review I don't even know if this has CI. That's okay, it's not important. I believe the drive feature is mentioned erroneously in the last sentence of the second paragraph on page 70. Probably doesn't should talk about some feature in instead found this in the second printing of the book.
02:13:40.681 - 02:14:24.483, Speaker A: So prefix error file with print 02 Is there a second printing? It's a good question. I don't know if the second printing has errata has the errata from print one applied to it? That's a very good question. I'm going to have to follow up with no starch in here. What things they may have fixed or not. It's equivalent to if true, only if there are. Oh yeah. I mean, this is clearly.
02:14:24.483 - 02:15:11.123, Speaker A: Right. Good catch. You're totally right. I honestly don't know whether they've made errata changes for print for the second print run or not. I'll check. However, I believe this error is in. Is there in the original print as well.
02:15:11.123 - 02:16:04.289, Speaker A: So let's keep this as Print 01 to indicate that it's present all the way back to that version. Sweet. But that is indeed incorrect. Okay, I'll leave that open. Right, so this is in left right about the ability to have fallible operations. So the ability to. Left right is a.
02:16:04.289 - 02:17:05.983, Speaker A: This data structure where you. You keep, for example, two maps, Writes go to one map, reads go from the other map and then you. If the writer wants to expose the changes they've made, they swap the two maps, wait for the readers to drain from the old map, and then start writing to it. But it means the reads can basically progress without synchronization. And what they want here is the ability to have operations against that the writer can do that might fail. And the observation around why this was difficult is that imagine that you have a writer that's writing to one map and they perform an operation that they. And then the way evmap or left right actually works is that when you perform an operation as a writer, what you actually do is you just queue up the operation for when one of the maps has no readers.
02:17:05.983 - 02:17:56.834, Speaker A: So it's not actually performed straight away. What that means is you wouldn't actually be told that the operation has failed until one of the two sides empties of readers and it starts to apply the operational log. And at that point it's unclear what you do if one of the operations like in the middle of the queue failed, that there's no really reasonable way for you to recover. I have a service that allows multiple users to send and receive updates to the same data structure. In my particular use case, these are tournaments using WebSockets, a user sends an update message, the server processes it, and on success the same message is forwarded to all the users so they can apply to their local states. The received message can fail for a number of reasons. The user was out of sync, the server receives an Improper malicious message, etc.
02:17:56.834 - 02:18:40.547, Speaker A: Each multi user session is managed by Tokyo Tasks reduce The DBE bound latency. The site maintains an in memory copy of the tournament. This ensures that the session can always process incoming messages without waiting on the dbe. It persist tournaments to the DBE via a separate task that's responsible for persisting all tournaments. After every successful update from a user, we send a message to the persistent task to indicate that the tournament has been updated and needs to be saved. Ideally, the persistence task holds left right reader handles to every tournament and will read from them only when it receives a message that the tournament has been updated. Instead, there is a system of intertask communication for retrieving clones to the tournament.
02:18:40.547 - 02:19:40.377, Speaker A: Using left right would both simplify the persistence problem and reduce the number of copies of the tournament that needs to be made. Yeah, okay. So. So what's interesting here is that. What's interesting here is that you could totally use left right for this. I guess what I'm curious about is why the write operation has to be fallible itself. Like why can't you read and then check whether the operation would succeed? And if it would succeed, then you do the right.
02:19:40.377 - 02:21:36.535, Speaker A: That's the way I would actually solve this problem. You don't actually need the rights to be fallible. Thanks for the context. I may be missing something obvious, but couldn't you just do a read of the tournament state, check whether the operation would succeed, and then only do the infallible write operation? If that is indeed the case, then there'd be no need for fallible rights to be a thing. The reason why rights are enqueued rather than applied directly is to allow is so that when you call refresh, which is the sort of swap of the maps is actually so that left right gets to overlap the time. Well, I'm trying to find the right way to express this. So what actually happens in EVMAP is that when you call refresh, so when you swap the two maps, you have to wait for all the readers to drain.
02:21:36.535 - 02:22:29.257, Speaker A: Well, you have two options. Either you wait for all the readers to go away from the me. Let me rephrase this. This might be easier to draw actually. But let's see, you can only apply operations the moment at the once one of the two maps is empty of readers and you have two ways to do that. The naive one is that when you call reference refresh, you swap the pointers and now all the writes are visible and then you wait in refresh until all of the readers have drained from the old map and started using the new map. And only once.
02:22:29.257 - 02:23:21.739, Speaker A: That's the Case you return from refresh and now writes can be applied directly to the map that is out of readers. So that's great. The problem with this is that while you're calling refresh, like while refresh is waiting for readers to depart, the current process is blocked, or the current thread is blocked. It can't do anything while we're waiting for the readers to drain. By putting a queue in here, you can actually overlap that time. You can get sort of like, let's call it IO parallelism, even though that's not really what it is. So what evmap does instead is at the end of refresh, it doesn't guarantee that there are no readers in one of the maps when refresh returns.
02:23:21.739 - 02:24:01.321, Speaker A: All it guarantees is that all writes are visible to readers, but it actually ends with doing the swap, the pointer swap, and then it just returns. So at this point they're going to be readers in both maps, but it returns control to the caller, so the thread is no longer blocked. It can keep doing other operations. Those might be writes, whatever they might be. And then when you call refresh, only then do you wait for the readers to drain. And then you apply all the writes from the queue. And so that way the time between calls to refresh is also the time that you wait for readers to drain.
02:24:01.321 - 02:25:56.635, Speaker A: And so now you get to do the sort of waiting in parallel with the thread executing. But that only works because the writes don't have to happen straight away. They get sort of pushed back until the next refresh enqueued and applied only on a refresh rather than apply directly. Is that it allows left right to. It allows left right to parallel paralyzes like the wrong word is that it allows left Right to return early from refresh. Time spent waiting for readers to depart one side is time when the writing thread also gets to execute. It's a little hard to explain without a diagram, but it allows Left Right to spend less time blocking the current thread overall.
02:25:56.635 - 02:26:31.515, Speaker A: Okay. Readme typo accessed. Great. Approve. Oops, that's easy. Approve and run comment typo. Yeah, so technically one of these files is generated from the other, but that's fine.
02:26:31.515 - 02:27:10.883, Speaker A: Fixing them separately is also okay. Bums Russell's PKI from 0101 to 0102 this doesn't matter, but I guess this is a high severity alert. The reason this doesn't matter is because Fantuchin is a library. So we only have the lock file checked in because it's better for CI essentially. Like, I think it's important for CI, but that's fine. We can. We can take this so that dependabot is happier and same thing for imap.
02:27:10.883 - 02:27:35.705, Speaker A: It's a library. It doesn't matter that this is checked in, but we can merge it. Great. So this is done. This is done. That one's still running two different PRs. Switching to quick check one.
02:27:35.705 - 02:28:12.439, Speaker A: The difference to nine is this fixes the capacity property test by discarding large sizes. Okay, so what do we have here? Cargo lock changes. That's fine. Quick check moved from 09 to 1.0. Okay, that's the main change. This one I actually pointed them at. So the width capacity Quick Check was intended to see that this VC type, it's like a vector.
02:28:12.439 - 02:29:04.985, Speaker A: This is in a crate called atone, that's like amortized resize vectors. And this Quick check was just to try to allocate vectors of different sizes and see that they all produce something reasonable. And previously, as in quick check 0.9, when you gave it a Usize, it wouldn't generally produce very large values, but now it will. It will produce like any number in the arbitrary range of U sizes. Which means that we would try to allocate a vector with capacity like 100 bajillion. But by setting the cap argument here to be U8 and then casting it to Usize, we now know that the capacity is going to be passed in is only between 0 and 255 inclusive, which is a much more reasonable range and still exercises probably everything we care about.
02:29:04.985 - 02:29:33.359, Speaker A: This is just the syntax for generating things changed, which is fine. They're generating the same types U32 arbitrary. U32 arbitrary. Perfect. Looks great now. Thanks. Approve Submit review and this PR is doing the same thing, but.
02:29:33.359 - 02:30:16.005, Speaker A: And I think I know what they're doing here. This one is discarding the result if the capacity is too high. I don't actually want to use discard. So there's some downsides to discarding test runs with prop test or with Quick Check, which is that it means that it has to generate a lot of test cases that then get thrown away. Whereas when we say U8, it doesn't have to throw away any test cases because they all actually get applied. So this one is basically saying generate a random usice and if it's greater than 100, which is pretty likely, then generate another Usize and then just keep doing that. And I don't think we actually want to go down that path.
02:30:16.005 - 02:31:09.725, Speaker A: Thanks, But I think I prefer the U8 approach. Discarding quick Check runs in this way Is usually not ideal because it means that quick check spends loads of time generating test cases that then are just thrown away close with comment. Sweet. This one can now be squashed and merged. Beautiful. So that one is now done. Which also means that.
02:31:09.725 - 02:31:37.995, Speaker A: Where is that? This one? This one can now be closed because it was already fixed by that other pr. This one is now. Fine, merge. We'll squash it. It shouldn't really matter for this. Like so. And we'll squash a merge.
02:31:37.995 - 02:31:53.545, Speaker A: This one as well. Squash a merge. Beautiful. Beautiful. Wait, what? What? Merge attempt failed. I don't think that matters. There's no conflict here.
02:31:53.545 - 02:32:25.573, Speaker A: Great, thanks. Okay, what do we got? What are we at? 22. Let's do. Oh, these. We talked a bunch about these. Okay, so in Fontaine, which is this browser automation thing, a lot of the tests are currently things that hit Wikipedia and then try to do various browser things on Wikipedia, which is really unfortunate. Right.
02:32:25.573 - 02:32:58.175, Speaker A: You don't really want it to be set up in this way because it means that if Wikipedia changed their HTML, everything breaks. And we have to update our test suite, which is not great. Okay, so we now have. Okay, we have two different PRs that both implement the same thing. Thing. Oh, this person just downloaded the Wikipedia page. Nice.
02:32:58.175 - 02:33:17.265, Speaker A: What did this person do? 12 test be converted with that issue and currently pass on Firefox and Chrome. Both is in two commits. The first demonstrated changes. Second moves the test to local rs. Two tests that I would like input on. Wait for navigation Test redirect from a file to Wikipedia. This is a bit awkward with local URLs.
02:33:17.265 - 02:33:44.265, Speaker A: The URL after a local redirection may be dependent on where the test was performed. Our proposed solution is to redirect to sample page HTML in redirect test and change it to ends with sample page. I think that's fine. The other does handle cookie tests. Oh, right. Yeah. Setting cookies when you access local pages is pretty annoying.
02:33:44.265 - 02:34:36.775, Speaker A: I think it's fine to have the cookie test be external because that's not something that the external sites are likely to change all that much. Yeah, that's fine. Great. All right, so let's look at whether they did the same. Host a local web server. That's basically what it does. So I already have a test harness for running local tests in Fontaccini, and it basically sets up a local web server that serves just static files.
02:34:36.775 - 02:35:34.951, Speaker A: Oh, right. They said they have two commits, one that just moves the file. Okay, that's fine. I believe you place Wikipedia links with local files. Sample page URL. Why is this Just called works. So this one still called current URL.
02:35:34.951 - 02:36:13.527, Speaker A: We still do find css. We take locator by id. It doesn't look like we have something that uses link text. Oh, this one uses link text. Great. Seems fine. Yeah.
02:36:13.527 - 02:36:51.565, Speaker A: So this too, it looks like they've maybe just downloaded the HTML, which is shouldn't be a problem. I think from a licensing point of view. I think Wikipedia is Creative Commons as long as it's non commercial and that is the case. So I think we're okay. Yeah. So these are pretty straightforward changes and they simplified some of these. That's nice.
02:36:51.565 - 02:37:29.021, Speaker A: Footer. Yep. That goes away. It simplifies the test. A little local tester for all of these. Okay. This page now has just a little bit more stuff in it.
02:37:29.021 - 02:38:05.157, Speaker A: That's fine. Why change the indentation though? Doesn't really matter, I suppose. But why change in the indentation makes it so much harder to look at. But it doesn't really matter what's here anyway. Great. I think I'm happy with that. Yeah.
02:38:05.157 - 02:38:57.505, Speaker A: This one just downloads all of them, which I don't really want to do. So. Well, here's what I'm going to do. We're taking this on. I'm going to stick with 228 though. I'm going to semi randomly go with partially because it came earlier, partially becomes came in slightly earlier and partially because they've also trimmed down some of the HTML which just. Just to check that I'm not saying something false if I open this page.
02:38:57.505 - 02:39:53.137, Speaker A: That's what I thought. Trimmed down the HTML to not actually hold the true Wikipedia, which we don't really need for tests. Tests close with comment. Great, interesting. I can go away. Sweet. All of the tests use the local HTML file that were already in the test directory.
02:39:53.137 - 02:40:01.805, Speaker A: Yeah, exactly. So there's a bunch of. Oh, this is the same person. Great, we have you in chat. Hi, welcome. Or nice to have you here. I suppose you might have been here all along.
02:40:01.805 - 02:40:36.241, Speaker A: Yes, there are a bunch of local HTML files already. So if I go to Fontaccini the repo and go to tests test HTML like there's already a bunch of files here that we're using for a bunch of the other tests that have already been converted to be local. It's just that there are some tests that haven't been converted yet. Here's what I'll do. I'm happy to just approve this. This all looks great. This looks great.
02:40:36.241 - 02:40:51.325, Speaker A: Thank you. I'm telling you. Thank you in person as well, so to speak. But it's nice to do it on the PR as well. You can frame it and put it on the wall or something. This looks great. Thank you.
02:40:51.325 - 02:41:40.261, Speaker A: As for the two questions, I think it's totally fine to switch the redirect test to use ends with. It's not beautiful, but it still ends up testing what we care about. And let's just keep the cookie test remote for now. We may just not be able to get around that. Approve and then I'm guessing this. Oh. Who knows why these fail.
02:41:40.261 - 02:42:16.595, Speaker A: The Windows test is like super flaky. Rerun Fail jobs. Rerun jobs. Thank you. I wonder why Nightly documentation failed. Here's what I'll do. I'll go ahead and merge this as is and then we can do the wait for navigation test change in a separate mini print comment.
02:42:16.595 - 02:42:33.555, Speaker A: And I just want. I want to keep some merge. Excellent. Last time of me having to fix fantasy things. Just the test cases just because Wikipedia changed. Beautiful. Thank you.
02:42:33.555 - 02:43:07.219, Speaker A: All right. Wait, did I not mark. This is done. Okay, great. Implement wheel support. Expose remote and minor follow up wheel support. Oh, this was just.
02:43:07.219 - 02:43:26.975, Speaker A: You need to merge. That's fine. Prove and run that. Is there anything I could do better? In general? No. I really like that. I like that you split the commits too. Splitting the commit into changes in the same file versus move to a different file really helps in reviewing.
02:43:26.975 - 02:44:20.733, Speaker A: Best I can think of, and this is very minor, is in your. In your issue description, which I've now closed of course, because I'm a dumbass. Here, pull requests. So here, this is the trick in GitHub. If you link directly to the lines while opening the file view rather than the diff view. So you view the file at the given commit and then mark the lines and paste that link. Then GitHub will actually expand the code in here and let you click through it to get to it.
02:44:20.733 - 02:44:56.081, Speaker A: So it's a little nicer. Also, don't be worried about taking a stance if you think that this is the best way that we can do it. Even if you're unsure, then just make a commit that makes that change as well and just push it in there. And then I as the author can then either go, yes, let's just merge that as well, or go, actually, let's change this part of the pr. Don't feel like you have to only do the safe things and ask for permissions for the others. Like a PR gets to go through multiple rounds. So it doesn't.
02:44:56.081 - 02:45:40.015, Speaker A: It's okay for you to put things in there. They're Opinionated, for example, Usually you also don't need these justifications. So in general, at least when I review a pr, I will. If something strikes me as particularly weird, I'll ask and usually then ask you to include a comment. For example, to make it clear not just in the pr but to future people who read the code what went wrong or not what went wrong, but why. This code looks a little funky, but smaller changes like this I don't need a justification for. It seems totally fine.
02:45:40.015 - 02:46:08.765, Speaker A: Oh, write this comment. I noticed that there's some redundant test case and I believe could Overall yeah, please do. I would love to have more coverage on this. Okay, wheel support. So this one we can probably just merge once. This is good. I love finding PRs like this where I've already done the work and all I have to do is click the button.
02:46:08.765 - 02:48:12.685, Speaker A: What's this? Right, so this is the ability for Fontoccini clients to after connecting to a WebDriver host, ask or look up what capabilities that host advertised when you connected. Why is new session response not clone like so? Because one of the things I proposed was rather than just storing the capabilities inside of the struct that holds the connection so it's easier to look up, why don't we store the entire response from the server whenever it whatever we sort of get back in the handshake and New session response. Really? Oh, is that a new type they made? Oh, it's from web driver. Web driver new service response. It doesn't implement clone. Why doesn't this type implement clone? This feels like they just forgot or no one asked them to. Okay, fine.
02:48:12.685 - 02:48:32.095, Speaker A: Yeah, stick it in an arc. That's totally fine. There's no obvious default new session response. The response is exposed with a getter session creation response. I agree. That looks too much like a creator. Beautiful.
02:48:32.095 - 02:50:18.565, Speaker A: I think value There was a serde JSON value. Yeah, gets the response get the response obtained when opening the session returns none if no session has yet been opened. Ah, but this. Yeah, unfortunately I don't think we can do this because we can't directly expose types from another crate. We can't actually directly return the type from webdriver here, as that would mean upgrading webdriver to a new major version would also require a new major version of Fantoni. Instead we have the this module, which is where we have all these types that are really the same as the webdriver types. This is what the WD module is for.
02:50:18.565 - 02:52:07.745, Speaker A: In there we have our own replicas of the webdriver types that are under our control and that we can return there. We can also derive clone so that you won't need the architect anymore. So new session response that now stores the whole thing. Wait, is both the fields are pub too? Of course they are. Just a note for when you add that type though make sure to mark it as non exhaustive. We can add fields to it in the future if the webdriver crate does request changes. Sweet.
02:52:07.745 - 02:52:53.025, Speaker A: Done. Close, close, close, close. What do you think reporting numbers from the standard AWS EC2 instance more reproducible in some sense more useful in a cloud driven world. I think we should do that. This is a bunch of benchmarks for ORD search which is like an optimized way to do binary search search over sorted collections and someone recently revamped a bunch of the benchmarks and now want to run them on, you know, a host to see how the numbers have changed. But the reality of benchmarks is that which host you run it on also matters. So you really want to run it on multiple different hosts and compare the numbers.
02:52:53.025 - 02:55:03.333, Speaker A: I think we should do that though I don't think it's quite enough or that's not the right way to frame it. I think we should do that in practice. Performance is highly variable on all these shared cloud hosts. So often you get numbers that aren't all that reliable and reproducible actually for very low level things like this are very low cycle count things like this as a result measurements from real dedicated those are often more useful or representative in practice I would love to get which is all to say that we should gather results from as many different types of hosts as we can and report aggr report both aggregate and report a summary of the results across hosts. Like in practice when you run performance benchmarks on EC2 hosts very often like it's not that the performance is bad necessarily, it's just that it's highly variable. It really depends on what the other instances that are co hosted with yours are doing at the time. So it's not.
02:55:03.333 - 02:56:41.129, Speaker A: It's not really the case that if you report the numbers on EC2, especially for something that's very like CPU and intensive like this, that the numbers truly translate very well. Whoa, that's disturbing. Oh, this is more May need to merge main again actually to get 9097 no one zero seven Ah, what's the PR I just merged to get rid of in the to get. Oh I was way off 228 improvements from 228 can never decide which laugh I want to use they're all very different. Done. Okay, explain why more returns always falls on the record picker. More is really more with zero counts.
02:56:41.129 - 02:57:27.225, Speaker A: But here as this is the record figure, we never visit empty bins and this would never be more. If we yield a record by defining the current bin cannot be empty. Taking the time to add this, it's almost certainly going to be helpful to some poor soul, maybe, maybe even me in the future. I love documentation. Squash and merge. Great. Done.
02:57:27.225 - 02:58:22.663, Speaker A: Switch Cargo Bench for Criterion. Right, so this is also an ORD search for us to move it from using the Cargo bench, which is like nightly only and stuff, to using Criterion where actually does benchmarks. Well, let's see. Just to reflect the changes in nine. Yeah, that makes sense. I was saying how we do some tests where we look at how large the data is and we try to make data sets that fit in the fastest but also smallest cache of the CPU, the next one up, the next one up, etc. And then we label the benchmarks based on which cache we're targeting.
02:58:22.663 - 02:59:50.109, Speaker A: But their point here is good that like in reality the cache sizes vary a lot between CPUs, so it's not clear that these names and these sizes actually map correctly. So Criterion is just going to give us a graph instead. We're like size on the x axis and performance on the Y axis is a fair point. And I'm sold. Resolve conversation saturated calculations. So for U8 and Max equals that the resulting sequence will be. Oh yeah, that's a good point.
02:59:50.109 - 03:00:35.869, Speaker A: So, so we have these tests. Let me see if I can pull up the example of this. So we have these tests where we try to sort basically search a bunch of sorted lists of numbers and we try to generate some lists that have duplicates and some that do not. And we want to search them both. And this one is you want a hit rate of about 50%. So we generate twice as many numbers or we search only half the numbers in the set. This one we try to stick a bunch of the same number into the collection by just taking the number and then dividing it by 256 because that way you're going to collapse a bunch of the numbers.
03:00:35.869 - 03:02:20.443, Speaker A: But yeah, this is a very good point that currently because of this min up here, as we increase the number, we're capping it. So and then we're just doing division by the same number. So we're just going to end up with the same number repeated. We should change this one and the one down here, which one and the one in construction to Instead use int mod 16 times 16 starter view request changes Once that last bit is fixed, I think we're good to land this Tada. This kind of comment is actually mostly for myself. It's so that I know that I've looked at this and think it's okay proven run Do I answer questions during the stream? Sure, depends on the question, but in general yes. I think I'm about to end though.
03:02:20.443 - 03:03:04.375, Speaker A: We've been going for a while static Unique domains I want to deal with separately. This type was not interesting. That's a feature I've been waiting for. That's as a change to a semester lecture thing that I can do later. Fix all targets bump MSRV14 we're so close. We have variable names foo in a test oh great. This makes me very happy.
03:03:04.375 - 03:04:31.325, Speaker A: Someone went through and fixed all the Fixed all the clippy lints. Okay okay. I think this now doesn't need the surrounding no, same here. This I love it when people go through and do things like this. Makes me very happy. They're also very easy to review these kinds of changes. Replace Yep, replace takes an array as a pattern Clippy disallowed names I want to know what this lint is because this I'm skeptical of clippy lint documentation oh, that's very bright.
03:04:31.325 - 03:05:44.955, Speaker A: Disallowed names Check for the usage of disallowed names such as foo. These names are usually placeholder names. Should be avoided. Bar is not here since it has legitimate uses. That's really funny, but where are we using food like now? I'm curious. A variable is named foo in a test that feels like a Related issues I feel like this is a bug with the lint. Like it should be totally fine to have a variable called foo in a test if we're taking the time to do this.
03:05:44.955 - 03:06:31.515, Speaker A: I've been wanting to sort those warnings out for a while. Two small bits that I think we could change further but otherwise this looks great. Yeah, I want to see this the offending fu as well. I'm curious what that foo is if I. I guess I can search for foo like here for example. Yeah, this is. This seems totally fine.
03:06:31.515 - 03:07:17.035, Speaker A: I want someone to file a ticket with Clippy saying that this lint should not apply to tests. Yes, definitely the right call to disable that lint. Feels like a bug in the lint. Really to be disallowing these names in test code. Great question answered. Yeah. Do you answer questions during the stream? Yes.
03:07:17.035 - 03:07:56.295, Speaker A: Are you going to Euro Rust? Um, I haven't decided yet. But I think so. Um, how do you feel about people resolving your comments? Shouldn't it be the reviewer resolving comments when they're happy with the resolution? Yeah. So this is actually really frustrating with GitHub PRs because I don't want the people who make the changes to mark the. Mark my comments as resolved because realistically I'm just gonna have to go through and expand all of them and check if I agree. And anyway, so this is why I've been using. I'm not using it now, but there's a website called Reviewable.
03:07:56.295 - 03:08:28.949, Speaker A: I think it's enabled on the OpenSSH repository. I know. Review. Yeah, Reviewable. So this is a really neat tool that I've used a bit which actually does like good reviews. So it lets you say, like I've reviewed this subset of the commits. Every change or every comment has to be resolved by both parties, not just by one or the other.
03:08:28.949 - 03:09:12.552, Speaker A: So you can't resolve something completely and hide it from the other person. So I like that a lot better. I get pretty frustrated with the GitHub one. It's usually fine for smaller PRs, but once you get large it becomes a mess to deal with. Okay, what do we got left? Bump MSRV since clap bumps at MSR to 170. Inferno no longer builds on 164 and it's a minimum of 170 terminal and rustics. Okay.
03:09:12.552 - 03:09:28.705, Speaker A: Okay. Restoration 170 so we can list it in the cargo toml. That's nice. We had rest of rid of is terminal. Okay. Because we can use this terminal from Studio. That's nice.
03:09:28.705 - 03:10:41.293, Speaker A: Sweet. That's so new. I don't think that's worth it. That's such a new version. It is a drop of dependency. But 170 is very new. Like this is.
03:10:41.293 - 03:11:42.555, Speaker A: This is bumping. So 164 is from 164 is from September of 2022 and 170 is from June of this year. So this is a bump of nine months. It doesn't like it. I don't think that's worth it. Now the good news here is that Inferno, the binary ships with a lock file that pins cargo pins clap to before 4.4. So that will still build with the MSRB.
03:11:42.555 - 03:13:25.282, Speaker A: It's just that the newest version, like if you ran cargo update then wouldn't build with msrb. But if we make these source changes to get rid to start using these terminal traits, then Inferno itself also becomes. Inferno itself starts to require 170. So it's no longer possible for consumers to pick an older clap and still have it build. Yeah, I don't think I want to do this. Think I want to bump inferno's MSRV to 170 yet it is too new for the time being and I don't think dropping the is terminal dependency is that valuable in reality Value in reality. The fact that CLAP 4.4
03:13:25.282 - 03:15:12.247, Speaker A: no longer supports OneNote 64 doesn't actually preclude preclude anyone from building Inferno with One64 as long as they come up with the right lock file which while annoying is possible is at least possible if we land the these changes then users of Inferno have to use a newer Rust or pin an older version of Inferno. I I haven't formally set an MSRV policy for this crate, but I've informally set an MSRB policy for this crate. But in general I'd be looking at 12 to 18 months probably. I think 170 includes a security fix if I've seen correctly. So that doesn't actually matter for Inferno the library. What I want to do with Inferno is I want to make sure that people can build it with an older Rust if that is all they have. Including this change wouldn't make anyone upgrade.
03:15:12.247 - 03:15:55.325, Speaker A: Or I mean it might give them an error saying Rust is too old. But usually people are pretty good at keeping the rust up to date if they're able. But I want it to be the case that if you're stuck on an older version of Rust, then you can still build the newest version of Inferno. And so that's why I don't want to bump the msrv. Okay, that's just the coverage report. I can go away. Someone followed up on this during the stream, which is I think someone who's watching the stream right now.
03:15:55.325 - 03:16:25.445, Speaker A: Okay, this one I can review later. CI is still running. Address bar at the bottom. It's just a custom Firefox CSS. It's in my dot files repo on GitHub I think it's called. It's GitHub.com John who configs and it's under GUI Mozilla Firefox/chrome user Chrome CSS.
03:16:25.445 - 03:16:56.357, Speaker A: You are on stream. Nice. I think most of the remaining ones are actually things that I'm just like following is this which is probably going to have some more changes. It's this where CI is still running this which is probably going to be some more stuff. These which I'm all just following this which is probably a little larger. So I don't want to deal with that one right now. I think we did it.
03:16:56.357 - 03:17:17.205, Speaker A: I think we basically caught up. I'm no longer overwhelmed by notifications. GitHub Great. And I think time wise, we did pretty well. I think this is roughly where I want it to end anyway. Okay, so that's the. That's the end for today, I think.
03:17:17.205 - 03:17:41.305, Speaker A: Thank you for coming out. I hope this was interesting. I'm probably now going to sort of switch modes a little bit and not do as many of these now that we're caught up. I might still do one every now and again, but I'll switch modes more back to doing the sort of crust of rust and implementation rust streams going forward. So I'm excited. I'll see you all there. And yeah, streams.

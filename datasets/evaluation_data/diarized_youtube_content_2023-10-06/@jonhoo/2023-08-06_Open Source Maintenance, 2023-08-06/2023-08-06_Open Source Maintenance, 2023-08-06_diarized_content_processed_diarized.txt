00:00:00.960 - 00:00:37.132, Speaker A: Hi, folks, welcome to another stream. This one's entirely impromptu. I didn't announce this one in advance. This was more I, you know, I have been traveling, or moving rather, for a while now, and so I haven't been keeping up with my GitHub notifications. And so I need to do open source maintenance work. Like, I have a bunch of open source projects that I want to make sure stay alive and stay healthy. And so I now have, I did some cleanup, actually, before this, where I marked a bunch of notifications, or I went through a bunch of notifications that were like read only.
00:00:37.132 - 00:01:21.200, Speaker A: Like, I subscribed to a bunch of rust issues that I'm just curious about progress on, for example. So I was at around like 500 unread notifications, and now I'm down to 118. And some of these new ones on top are also just like subscriptions where I follow a tracking issue, for example. They're nothing things that we actively need to do, but nonetheless, there's a bunch of just work that needs to happen in open source. And as a maintainer of some of these projects, that means I have to go in and do stuff. And I was going to do that this morning and figured out, why don't I make it into a stream? This might be a different kind of stream. I've done one or two of these in the past, but it's not going to be a stream where I carefully take you through a problem or an implementation of some kind.
00:01:21.200 - 00:02:18.340, Speaker A: We're just going to sort of dive into notifications and start working on projects that I know fairly well. But hopefully it'll still be interesting. If you feel like there's anything where you don't quite understand what I'm doing, or more importantly, why I'm doing it, then please ask and I'll try to give you some insight into this. But my hope is that this is maybe useful to people in the sense that you get to sort of see a glimpse on the other side of open source contributing side, but the receiving end and seeing the kind of work that goes into it. And hopefully it makes you interested in doing some of that yourself. But the other hope is that maybe it gives you a bit of a better understanding of where the maintainers come from in the projects that you already interact with. So it's a secret stream, but it will hopefully be useful nonetheless.
00:02:18.340 - 00:02:40.200, Speaker A: All right. And because I recently changed my setup, let me double check that. I'm actually recording. I am. Great. All right, so the way that I go through notifications is I go from the back, because those are the people who have waited the longest. There's an argument that you can do the ones that are newest because that way you keep the latency experienced by the most number of people lowest in general.
00:02:40.200 - 00:03:02.310, Speaker A: But I like going from the back. These three ones are work in progress. I'm going to ignore those. And we're really just going to walk this list, bottom up and see how far we get. I'm guessing I'll do this for about, let's say three ish hours. We'll see how far we get. Great.
00:03:02.310 - 00:03:46.550, Speaker A: All right, so what we'll do is we'll open a bunch of these and make our way through. Implement wheel support in Fontacini. Okay, so Fontacini is this project that implements the Webdriver spec for browsers. So lets you sort of like selenium, lets do remote control browsers. And this is probably just adding an implementation. Like it's pretty easy to add new features from the spec or just features we haven't implemented yet into, into the crate. Let's get rid of these annotations.
00:03:46.550 - 00:04:34.384, Speaker A: So they're adding just to show you what it looks like. So you have a bunch of different types of actions that you can pass to the browser. And currently you notice there's no mouse wheel action. And so what they're doing is they're adding a new you type wheel action containing wheel actions for the wheel device. And the kind of things I'm looking for here is like, does this fit the general structure of the crate? This is a useful addition. Does the documentation look about right wheel actions? But. All right, so this is a wheel actions is a vector of wheel action.
00:04:34.384 - 00:04:58.920, Speaker A: Yeah. So this is pretty common where you want to be able to do sequences of actions and send them as one thing, sort of a part of the spec essentially. It'd be interesting. Uniquely identify this input source. That's fine. Pushes a new action, links to the spec. Good.
00:04:58.920 - 00:05:53.700, Speaker A: Pauses between offset the scrollers pixels. All right, what about these field names? Oh, this is where is the cursor when you scroll? And this is how much do you scroll in X direction. And how much do you scroll in Y direction. That feels fine. This is a private impl that turns it into, we're using this other crate by Mozilla that encodes the protocol messages in the spec. And so this turns the type that we have in our API into that sort of internal type as millies. That's, well, I forget whether asmillies.
00:05:53.700 - 00:06:45.980, Speaker A: Oh, that does include the seconds. Okay, great. A scroll turns into the same with duration. Ah. So origin here we probably want to keep. So when you scroll, you can choose what the coordinates are relative to, whether they're relative to the viewport, like the entire view of the browser, or whether they're relative to absolute coordinates on a page. It feels unfortunate that this now doesn't allow you to specify any other origin.
00:06:45.980 - 00:07:51.900, Speaker A: Huh. And input source for wheel actions. This is just so that you can chain multiple different types of actions. So you can, say, move the cursor here, do a scroll, click as one big action sequence. Okay. This is one of the questions that often come up in, in situations like this is like, do I want to block this pr on making this change? I think in reality, the change I want here is actually, I want this to be non exhaustive so that we have the ability to add other events here or other fields to this, like the origin. So that's actually the main thing I want to add here.
00:07:51.900 - 00:09:16.220, Speaker A: So let's do this. Let's do, let's add non exhaustive. And then I also like to, I like to link to the dog, the docs whenever I mention a feature like this, because it's not always like, even though I know this feature very well, it's not clear that the contributor necessarily knows it. The attributes to this, so that we can add additional fields or variance in the future without breaking. Actually, I don't know if we can add non exhaustive here because people do have to be able to construct a scroll. That, that's a good question, actually. Does it prevent? Yeah, no, you also separately add it to variants.
00:09:16.220 - 00:10:26.470, Speaker A: Hmm. Non exhaustive types cannot be constructed outside of the defining crate. I want to see whether when pattern matching on a non exhaustive enum matching on the variant does not contribute towards exhaustiveness of the arms. That doesn't help me. I forget what the rule is here. We might actually have to check this. So cargo nufu, we're gonna source lib rs and we're gonna have a non exhaustive pub enum foo, and it's going to have a variant bar that has field, one string and then source main.
00:10:26.470 - 00:11:29.576, Speaker A: And then I want to see whether I can here construct a foo bar. Like, is this legal or is that caught by non exhaustive? That's legal. Okay, so, but if I add it here, then it can't. Okay, so, so that we can add additional, so it's not true that we can add field, but we can add additional variants, like maybe scroll from absolutely. To have a different origin without breaking backwards compatibility. And then this is a knit and I forget whether this is true. I guess I can test that out too.
00:11:29.576 - 00:12:28.400, Speaker A: So if I do foo bar and I do cargo dock open, yeah. Cargo dock open, yeah. So you'll notice the difference here between if I do this and then I have a different type, I guess baz and I put an extra empty line between here. See how for bazooka bar does not appear in the short version, but when you go into it you see it. So basically single line breaks have no semantic meaning, they're basically ignored. They're treated as whitespace, whereas double newlines means new paragraph. And so usually when you have documentation, like over here, you want to have an extra new line between, so that the first line is the summary of the documentation item and the next line is just will only be seen if you open it.
00:12:28.400 - 00:13:37.826, Speaker A: Add an extra new line between these so that the first line is treated as a shown in the containing module type listing. Otherwise this will be treated as all being a single paragraph like so. So otherwise this looks good. The bump to Webdriver, I believe is fine. I think we no longer have any webdriver types in our public API, and this was a very intentional piece of work that we did and required a bunch of work to make this be the case. But if we hadn't made that change, then bumping Webdriver would actually require a version bump of function itself, a major version bump. Because if you have public types of this crate in your public API, then if I bump this, I'm effectively changing my own API as well.
00:13:37.826 - 00:15:03.310, Speaker A: And therefore we can only do this bump safely within the major version because we know we've contained it. This is where really I would like to mark this as a private dependency, but cargo doesn't have those yet. Sorry for the very late view to this, it mostly looks good. Just some minor comments. Main thing is leaving a space for us to potentially add a way to use a different scroll origin in the future request changes submit review if you're already blocking the pr and non exhaustive, why not have them allow customization of the pointer origin? I could do that, but I don't really want to bog this down into discussing how we should handle origin. That's how you end up with PRS, never landing or just taking enormously long to do so. Instead, non exhaustive is, I think, a decent way to fix this pr and still leaving an open space for us to improve that in the future.
00:15:03.310 - 00:15:41.890, Speaker A: This contributor has limited interest and resources as well, and if I make them go through a bunch of steps that they don't themselves need. Chances are they're just going to abandon the printhead. Do not use the suggest changes button in GitHub. I sometimes do that where I highlight it and then make the actual change. In this case, I like to give the text. I vary whether I do it or not. Funtuccine only supports Mozilla, right? No, it supports any browser that supports webdriver.
00:15:41.890 - 00:16:21.070, Speaker A: So it includes with Chrome, for example. All right, one notification down. Okay, so this is a suggestion for errata, for rust, for restations. There's a repo for the book. It doesn't have the contents of the book, but it has like the website, which includes Errata. And let's see, what are they proposing? You say the second workaround is to make each of you feels takeable. You can take an option by replacing it with none.
00:16:21.070 - 00:17:37.990, Speaker A: This approach is overtake because empty. Let's see, clear separation between discussing option take and mem take. Yeah, how should we rephrase this? So here I'm going to use suggest changes because I actually want to rewrite it. So there's a section in the book that talks about cases where you have types that you need to. I think this is a context of types that you need to drop in your destructor. But more generally you have a mutable reference to something, but you actually want to take, you want an owned reference to it. And the way that you can do that is to make a field takeable.
00:17:37.990 - 00:18:45.460, Speaker A: So one that can be replaced with a sort of empty value or default value by using mem take or mem swap for that matter, or mem replace. And I think the current text isn't entirely clear about the distinction between using dot take on an option which leaves none in its place, which doesn't feel like a default value, even though it is, and mem take, which leaves, I mean, we can look at the mem take, so mem not tail take. Mem take takes a mutable reference to a t and it leaves in place a default value for t. If t implements the default trait and then gives you back the t that was behind the mutable reference. And technically these are the same. Like if you mem take immutable reference to an option, it has the same semantics as option take, but I think the current text is not entirely clear around that. And that's sort of the complaint here.
00:18:45.460 - 00:19:54.528, Speaker A: That reads in part and take an option by replacing it with a none. Take a vector hashmap, empty values. Um, I think the, the real complaint here, right, is that when I say empty here. What I really mean is implements default and for option it that happens to be none would have which happens to actually be empty. Like arguably these are empty for many types. Like default for hashmap is an empty hashmap, but it's not always empty. Like default for for numbers is zero, for example.
00:19:54.528 - 00:21:17.290, Speaker A: And so that's not an empty value, it's just a null value. Default really is the appropriate name. You can take an option by replacing it with none. For example, you can take a vec or hashmap have sane default values like an empty map or none because tedious if you must wrap nearly every field in an option and then modify every axis of those. Right, so that's not what I meant to do. This paragraph is technically correct, but somewhat hard to follow because empty and default are not necessarily the same thing. Some types implement default but do not have an empty, but that value is not technically empty.
00:21:17.290 - 00:22:57.840, Speaker A: Use for example, the sen, the sentence should instead readdez have same default values. So I think that's a better way to do this in a actually, let's make it a little clearer. If you must wrap nearly every field in some something like an option, because it's not that you have to wrap them in an option, it's that you have to wrap them in something that allows them to be taken and something defaultable. I think something like an option is good enough here. So that's the suggestion I want to make there taking so long on this feel about this proposed change comment. Great. Moving on.
00:22:57.840 - 00:24:43.466, Speaker A: Ie mode of Microsoft Edge fixes 214 I think I remember this, the IE mode of the edge browser. Right? So in fentuccine there is a way to, or in Webdriver in general, you can pass an additional set of options to the browser as part of connecting to it to configure additional aspects of how the browser operates, like things like should it run without a browser window, for example, should it conform to the spec, which is one of the options that Chrome has. And here someone's trying to use it with Microsoft Edge and they want to pass in this additional option to tell Internet Explorer to use edge Chromium. And that doesn't work because no matching capability sets found. And that is because fantasini currently always injects a couple of extra options. Specifically, there's a Google Chrome options where we tell it to follow the spec that we always inject into that list of capabilities, and that causes ie to crash because it goes, I don't know about that option. So the change here is basically to make it so that previously we always inject this Google Chrome options w three c.
00:24:43.466 - 00:25:35.490, Speaker A: True. And this change is saying only if the browser name isn't Internet Explorer. And this is stupid, right? Like this is just a bug in Internet Explorer really, because this colon thing here I believe is a part of the spec saying these are extensions that should be ignored if you don't know what they mean. And I guess Internet Explorer just doesn't do that. So this is just saying we'll still inject this always, unless you're an Internet explorer where we know that this breaks. Yes, it used to be that we only do this if the browser name that is passed in is chrome and I want to do it the other way around. It's that only if the browser name isn't Internet explorer, which is the only one we know is problematic.
00:25:35.490 - 00:26:16.870, Speaker A: Great. So this then actually looks fine now. I think I'm happy with this. They made this change and I don't know why CI is being sad here, but I actually think I'm okay with this. This seems like an innocuous enough change. And then the question is whether I can kick this to rerun CI. I don't really want to.
00:26:16.870 - 00:26:58.290, Speaker A: I'm just going to merge. This is fine. Sometimes I think what happened here is I updated all of the CI scripts in this repo after when this person made the change. So the CI jobs that ran are all different ones and the new ones aren't run. But this change is straightforward enough that in fact we can look at it right here. If I do w equals one to ignore whitespace, we see the change truly is just this browser name change only if the browser name is not equal to Internet Explorer. Yeah, that's fine.
00:26:58.290 - 00:27:48.180, Speaker A: Okay, so in this case I'm just going to overwrite this and merge anyway. And does this have lots of commits? It has three commits. It does really not need to have three commits. Let's squash it. Squash and merge. Okay, let's make this a little more helpful. So we want this commit message to say fixes 214, that is, Internet explorer struggles with this, so don't pass it to ie.
00:27:48.180 - 00:28:14.540, Speaker A: But there was no checks here for some reason. That's fine. All right, great. Thank you. And then I should do a release of Fonta Cheney, which I'll do in a second. I'll doing a release of it I'll do probably after the stream because it's nothing that interesting. And I want to group multiple changes if there are any.
00:28:14.540 - 00:28:44.170, Speaker A: Okay, next one. Inferno 2023. Still fighting with Internet Explorer. That's very true. Are you okay with prs not having tests? Usually I want tests. In this case, I don't think we are even able to run Internet Explorer in our test suite of. So it's not really a, it's not really a thing that we can do.
00:28:44.170 - 00:29:58.076, Speaker A: Single stack detection could be wrong even if the event contains multiple colons. Okay, so this is an inferno, which is our port of flame graph. And. Okay, so someone's running a perf over a go project where it looks like one of the functions has a colon in the name. Interesting. So in inferno, what we do is we parse the output of perf script, and we do that by essentially looking at the format and trying to tease out like, which things are function names, which things are program names. And sometimes that's kind of ambiguous, like if you have this colon here, and then try to separate this from single line stacks like this one, where you also have colon.
00:29:58.076 - 00:30:33.572, Speaker A: Colon. But these are not function names. So this is something like, it's like the executable name, the process know the time. I forget what this is. That is the process id, and that is the thread id. And then this is the function. This is the, this is the top of the stack.
00:30:33.572 - 00:31:07.050, Speaker A: So this is the, the function where the probe happened. And then this is the stack trace of that call, and this is the address of that function. So what's the difference here? This is a single stack case. So this is name of the program time. That square thing is optional. Process ID, thread id, single stack case. Let me look at these.
00:31:07.050 - 00:32:41.582, Speaker A: So perf script is not super ideal to parse some event lines include a stack line. If the stack has only one frame, the first should not be handled as a stack, whereas the latter two both should. The event will be followed by the stack trim until we counter a space or a colon, whichever comes first, and then evaluate from there. I understand that's going to find this. Oh, this colon. Oh, bi colons. What do we do here? Splitting in three by colons.
00:32:41.582 - 00:33:22.840, Speaker A: So that's this colon and that colon. And then this is looking at, looking for the first following colon and looking at whether it's empty after that. Yeah, and in this case it's empty after this colon. In these cases it's not. And so in this case that's problematic. No, you should be able to tell that this is that because something follows, because we're going to split by this colon and then we're going to look at everything that follows here. Poorly delimited formats.
00:33:22.840 - 00:34:33.978, Speaker A: I think maybe the trick here is going to be to split by whitespace. You can't split on colon space because this line doesn't have a colon space, for example. So I think the thing to do here is to split on. Yeah, the real problem is this split n. I think this has to be different. I think this has to be a split n two. So you split by this colonization and then you split by, and then you are split by colon.
00:34:33.978 - 00:35:08.200, Speaker A: No, because colons in the file name. This here is a file name and this. And I think that can also include a line number which has a colon in it, like its file name. Colon line number. So I don't think we can r split there either. I forget whether there can be fields in between here. Oh, there isn't a grammar for perf script.
00:35:08.200 - 00:36:29.664, Speaker A: That's one of the problems perf script just prints out. Like if I go to perf help, I apparently don't have perfect. Let's make it so that I have perfect. I think it just prints them out one after the other, which is entirely unhelpful. But trying to see if there's a. Yeah, I didn't think so. We could use regex here too.
00:36:29.664 - 00:37:22.720, Speaker A: But one is that actually slows things down. Perf scripts can be pretty enormous, and regexes are going to be a fair amount slower here, which is one of the reasons why we don't use regexes here in the first place. The reg ex also doesn't help you. You still need to know what to match on. And if you know what to match on, you can write it without a regex. The program name can also include a colonization, that's true, but it can also contain a space, which is all to say it's a terrible format. The question here is also what is more likely.
00:37:22.720 - 00:38:09.650, Speaker A: Like, for example, it's not uncommon to have colons and file names just be kind of disliked, like f of MPeG. For example, if you have a colon in file names, it just like barfs on it. And you need to, you, you have to give like dot, slash first or something. Not that that helps us here, but let's, let's ignore problems that already exist, like colons and file names will already not be supported. How can we fix this case? And I, the way you do it is you split n by two. We're already skipping what comes first. We're already splitting.
00:38:09.650 - 00:38:56.830, Speaker A: We're getting rid of everything up to here because we're skip n skip skip one. I mean, so we're gathering everything that's up to here. That's what's in event. And I guess the argument is that's not what should be an event. What should be an event is because the event can contain in colons also. I feel like it should trim here. Oh, we are split by space and then we take the last element.
00:38:56.830 - 00:40:25.720, Speaker A: So that's how we get to this. Yeah, I wonder whether, okay, so what did this person propose who's looked into it without either trying to parse the rest of the line as a stack line? Best effort and allowing that to fail or trying to look at to see if the next line is a regular stack line or an event line? Yes, I don't think you need to do that. I think that the way to go about this is actually an r split because I believe that the thing that comes after cycles here is like a sequence of flags. So I think you can just, when we split by the colons here, instead of splitting by colon in this way, you split once by colon. So you get everything after this colonization. And then you trim and you split whitespace, and then you get the second field. And then you r split by colon.
00:40:25.720 - 00:41:57.380, Speaker A: So that gives you r split nde two by colon, which is r split once by colon. So that gives you that splits by this colon. And so if the name contains a colon, then it won't make a difference. Okay, so I think that's the strategy. How about we change how this how works slightly instead of split n three colon, something like pseudocode is easier, I think, here. So we'll grab, let's just grab all this stuff and see if we can't make it a little better. Yes, yes.
00:41:57.380 - 00:43:02.350, Speaker A: Okay, so we would split once by colon, dot map. I guess this would be, sure bicolons. So this would be actually no longer bicolons would be after colon, after first, and then event is going to be after first colon, dot trim, dot split whitespace, dot nth. And we're going to have the nth be. So looking at that line we had over here, here are a couple of other examples. That's fine. After this first colon.
00:43:02.350 - 00:43:42.540, Speaker A: Oh, this number is optional. That's good. That's great. Oh, no, this is fine. Actually. What we'll do is we'll do find field. Field ends with a colon.
00:43:42.540 - 00:44:35.414, Speaker A: And then, so that's going to be, so we're going to split by the first colon down here. So splitting by the first colon. And then we're splitting, we're trimming and then we're splitting by whitespace. So that's going to give us this, this and then this. And then, you know, this, for example. And we're going to keep taking from that split until we get something that ends with a colonization, which is going to be this one. This one.
00:44:35.414 - 00:45:40.554, Speaker A: And even if this number isn't here, it's still going to find the first one that ends with a colon. And then we're going to say, so that's going to be the full event. And then the event is going to be full event dot map. And we're going to map that to, we're going to map that to s dot r split once on colonization. Sorry, I mean trim end matches colon. We know it ends with a colon. So trim end matches Colon is going to get rid of that one.
00:45:40.554 - 00:46:28.960, Speaker A: Technically we could do strip suffix and we can expect that one because we know it known to end in colon. And then we are split once to get the, the next colon back. Right. So if we get rid of this one, then we look for this one. And if there isn't one, then we know we have the event. Otherwise we take what's left. So we do rsplit ones dot map and rsplit once, I believe, still returns these in like the order you would expect.
00:46:28.960 - 00:47:22.156, Speaker A: R split once. That is, it returns a tuple where the, the first thing is what's before the thing you found. Yeah, you, you could imagine rsplit returning them in reverse order, but it does nothing. So we do rsplit once we do map of event and flags, and then we're only going to return the events. And if there isn't ones, unwrap or else s. So if the, if there is no other colon in the event, then we return the entire event. So I guess we can make this a little bit more helpful too.
00:47:22.156 - 00:48:25.270, Speaker A: So we can say this perf script does not produce easy to parse lines. In particular, lots of fields can contain characters. We might consider delimiters. We know that every line has at least one colon between the process thread info and the event info. So grab the, the process thread info usually doesn't have colons in it. Technically. The program name can, though.
00:48:25.270 - 00:50:30.218, Speaker A: Can though we ignore that possibility for now. To do so here, we extract the event info. The event itself has many space separated fields. We want the event name, I guess is really the, or is it, is it event type? I think it's event type cycles or function name, which is always, which always ends in a colon. So find the first field for which that's the case. And then the event type can itself contain colons, but it also has an optional, in fact, this might, this might break us. And this is maybe what the point person was pointing out, but it also has an optional, in fact.
00:50:30.218 - 00:53:13.282, Speaker A: What even does that mean? If we go to the colon, where are the fields? If we go back to the example we had the colon u here, it's basically impossible to separate out whether cycles colon u means cycles with the u flag, or whether it means there's a function named cycles colon u. Which makes me wonder, what does u means? Like I want to know the cycles field. Where is that synthesize cycles? No, that's very unhelpful. Perf script event name, maybe? It's not going to be helpful, is it? What is the meaning of perf script output? Let's see if stack overflow has some answers. Pid, CpU and time, yes, but what are the other ones? Yeah, event is the one I'm after. I'm pretty sure this might be actually somewhere else where the ha events. But what does the colon you mean? Yeah, so see this is only at the user level.
00:53:13.282 - 00:53:49.500, Speaker A: User and kernel. Aha. Here this, listen, they're modifiers. All modifiers can be combined at will. But clearly it's also not just that because there's also colon p. And in fact you see this in the example we have here where one of them has like, where was it? Here. Colon up.
00:53:49.500 - 00:55:02.872, Speaker A: What does that mean? Mmm. Is there one that has p colon p p up. Unhelpful. But it seems like these modifiers, like there's only a small number of them. I just wish there was a thing that told me which modifiers there are, because then what we could do is then what we could use is actually we could filter out only those modifiers, most common modifiers. Okay, so perf event modifiers, event modifiers, users restrict which events are counted. U for user space, k for kernel, h for hypervisor, g for guest counting, h for host counting.
00:55:02.872 - 00:56:25.320, Speaker A: The p modifier can be used to specify how precise it should be be, and can be specified multiple times. Okay, so what that means is an optional modifier list at the end. That modifier list can only consist of the characters of u, k, h, g, h, p, where only p may appear more than once. We want to strip the modifiers at the end if they're there, and keep any other colons intact. Is it possible that the example output you have doesn't comply with the spec? That is possible. And we see this some of the time where for some formats they just, we just randomly get other things. But it doesn't seem like that's the case.
00:56:25.320 - 00:57:37.160, Speaker A: Okay, so in that case, we want to take that full event string event with mods. Event with mods is this. And in fact here we can do that map up here, now that I think about it, just to keep it closer to where it actually happens. So we want to do if. So let's do match s r split once. If that's none, then we return s. If that's sum and there's a pre and post.
00:57:37.160 - 00:58:46.380, Speaker A: If post dot something, then we only use pre and otherwise then we return the entire s, I think is what we want. So the post something here is going to be if it only consists of those modifiers seeing psd, w, and e on different sites with man pages. Ooh, interesting. Where are you seeing these? Let's see if Google can be more helpful. Oh, there are more modifiers, aren't there? What happens if I do perfhelp list? What do I get? Oh yeah, I get more ones. Okay. C perf help list.
00:58:46.380 - 01:00:25.560, Speaker A: So it's u k h I g h p sdwe alright, so then what we're going to do is if event is likely event modifier post, then only pre, and then we're going to create this function right here. Now, there are a couple of ways to write this. One. I think the way that I want to do it is actually, I really want this to be not a thing we have to do on every line. That makes me kind of sadeena. There are a couple of ways we can do this. We could collect all the characters into a hashmap to get a count for each one.
01:00:25.560 - 01:01:15.020, Speaker A: We could sort the characters of the string, and that way we can just check them in order. But all of these feel like I don't really want to create a hash map each time, because this is in a pretty critical loop of parsing. Walking the string is tempting, but we still need to keep some state for whether we've seen a given character. So I think actually maybe sorting the characters of the string is the way to go. The problem, of course, is that this string, oh, actually, we know that this string is supposed to be ASCII. So we can do if s dot is aScII. I think there's a stir as AScII.
01:01:15.020 - 01:02:10.910, Speaker A: Yeah. Oh, it's a nightly feature. Of course it is. Aha. There is an is ASCII, then return false, otherwise. Sissbytes and I think this actually means that I need a mutable reference to it, which is fine. It's not the end of the world to have to into vec the other thing we can do is if s len is greater than 123-44-5678 910 eleven.
01:02:10.910 - 01:03:06.110, Speaker A: Did I do that right? Yeah. Twelve minus one for p is 1111 plus. How many times is p allowed to appear? It's allowed to appear three times. So if it's more than this, all modifiers plus three p's longer than all modifiers plus three p's. Otherwise use a bit set. We could do this as a bit set. You're right.
01:03:06.110 - 01:03:22.910, Speaker A: It's a little stupid, but you're right. We could totally. All right. All right. Let's do this. Let's be fancy because of course. No, I think it's eleven three.
01:03:22.910 - 01:03:35.060, Speaker A: Right. This is. Oops. This is twelve characters. So that means there's eleven without the p. So it's eleven plus three. That's allowed.
01:03:35.060 - 01:05:06.320, Speaker A: Yeah. So bit set zero. And then we're going to have to do. We could do a bit set here, but let's do mod. I guess this makes me sad, but this is 10 ukhighppsdw and E P isn't going to be there. 123-456-7879 and ten. And then we're going to do four c in s match circumental.
01:05:06.320 - 01:05:50.720, Speaker A: So it's going to be. If we see a u, then if bitset and u is equal to zero, then I have to be careful here too, because these are. I think I'm actually going to call all, all of these mod so that they don't accidentally overwrite with single letter variable names. Bytes is probably faster. You're right. We can do bytes. That's fine.
01:05:50.720 - 01:06:17.524, Speaker A: We've already checked that it's ASCII. So if that is zero, then bit seth or equals modu. And then it's this. This is also a place where a macro might be nice. Actually. Here's. Here's what I'm going to do.
01:06:17.524 - 01:06:53.290, Speaker A: Watch this record. K h I g h p. I didn't put enough of them. Damn it. All right, let's do this. Qa Khighpsdwe and then I can go over here. I can do the same thing here.
01:06:53.290 - 01:07:27.040, Speaker A: Like so. Love vim macros. Like so. And if it's a p, then I guess we also need a let mute P's is zero. Technically we use the same bit set, but I'm going to not do that. If peas is less than three, then P's plus equals one. And anything else return false.
01:07:27.040 - 01:08:45.100, Speaker A: And if we get all the way down here, then true. Right. This is definitely something that we'll want to test for rsplit one's on colon. We've already trimmed away the trailing colon. And then the other thing we're going to need is this bit. So the way that we detect whether something is a single stack line is whether there is something that follows this colon. So up here when we're splitting on whitespace, we want everything after the first field that ends with a colon.
01:08:45.100 - 01:09:38.800, Speaker A: And so the way we'll do that is we'll let this be an iterator. We'll do event with mods is iterator find and then we'll do rest. Is iterator. There's a way, I think, when you do, if you have a split whitespace. So when you call split whitespace, you get back one of these and it has a remainder. Ah, it's a nightly feature. Of course it's a nightly feature.
01:09:38.800 - 01:11:21.328, Speaker A: I want this feature would be nice to use, but instead we then have to do, we're gonna have to walk this one. That's real sad. Do you need the bit set? We need the bit set because if one character appears more than once, then it's also not a valid modifier set. Instead of all the ifs, wouldn't it be faster to set unconditionally and do an old, old bit set, not equal to new bitset? Oh, instead of these, probably. I don't think the performance here matters that much. Like, I don't think we want to allocate necessarily in this loop if we can avoid it. But I don't think we also need to like figure out the bit fiddling perfectly to avoid conditionals like branches in that loop I think are.
01:11:21.328 - 01:13:29.266, Speaker A: Okay, well, this is going to be really annoying, isn't it? We're actually going to have to without remainder, this gets really annoying because what we really want to get right is everything after this colon, wherever we first find this field, I really want iterator remainder here. I think what we'll do is we'll do something kind of stupid. We'll say that if we'll do s dot. So the full string dot position, what's the. There is a way, I'm pretty sure, on string to find. I'm lying. It's on the other string.
01:13:29.266 - 01:13:54.560, Speaker A: It's on this. I believe there's a way to search for a string. Search for the position of a string. I want. Yeah, I want find s dot find. So this find is a string find. This find is an I iterator find.
01:13:54.560 - 01:14:59.160, Speaker A: And they're different because of course they are. So I want to find event with mods. And I know that that's found because we found it above and I want to add event with mods. Lenore. So that's the position. So rest is going to be s rest dot and we're going to trim that because it's going to start with a white space. And now we can do some event with mods and rest.
01:14:59.160 - 01:16:12.150, Speaker A: Great. So this was going to find the first field that ends with a colonization. And then it's going to look at, find that field again in the string, find its, its absolute position, find the end of it by adding the length of the string. And then string splice everything after that point in the string into rest. And so that way this is going to produce both the, what we think the actual event is and the remainder of the string after that field. And so now down here this is going to be this and rest. And I suppose actually we can do let event unrest is actually we could even untangle that up here.
01:16:12.150 - 01:17:40.400, Speaker A: No, I don't want to do that. I want to preserve it through here. And I suppose what we want to look for here is if the rest is empty. If event one is non empty, then we have post event what if the event name appears as a substring of another field? It can, but this comes back to what the actual contents of these lines are. So in practice that's not really going to happen because the order of the fields in the output here is actually, is actually the field before that is generally just a number. It's not, it's not a string. So it's really unlikely that's going to be the case.
01:17:40.400 - 01:19:28.860, Speaker A: Unlikely to have this find is unlikely to have false positives since the event name is usually only preceded by an integer field numeric field. I don't know if it's actually an integer. Make sure only valid modifiers appear and only and only in allowed quantities. Okay. And now what we'll go back is, after some digging, how about something like this? And I don't want to just make this change myself because there are people who care about this problem and might be able to fiddle with this add test submit actual pr. So this is more outlining a solution for them. How about something like this to replace the first part of onevent line inside immediately inside the first.
01:19:28.860 - 01:20:20.990, Speaker A: So this way hopefully they can continue to follow along. Preceded not proceeded. Did I really spell proceeded? My bad. Oh my scroll wheel is not working right today. Where's my oh yeah, preceded update. So hopefully now they can continue to push forward on this while I go do other things like clicking done and moving on to the next issue. Let's close all these tabs.
01:20:20.990 - 01:21:17.140, Speaker A: So maybe now you see why very often doing open source work ends up moving much more slowly than you'd like. Because each one of these require a bunch of attention. Make it more obvious to a new contributor that flamegraph git sub module needs to be initialized before running tests. Okay, so this is also in inferno. In inferno, we also run all of the flame graph tests, and we do that by having the flame graph project be a git sub module. But if you forget to initialize those sub modules, a bunch of the tests fail because that sub module doesn't exist. Yeah, they get this error, no search, file, or directory, which is annoying.
01:21:17.140 - 01:22:16.320, Speaker A: It should get more obvious errors. So I'm guessing they're going to change the test so that this is a great addition and improve improvement to the and sorry for the delay. Approve. What is it? Oh, it's coverage. That's fine. There are. This can be squashed.
01:22:16.320 - 01:22:41.740, Speaker A: That's fine. Complain loudly, if not beautiful. Merge done. All right, next. Okay, this is for EV map. This is a data structure. We did a video on this one ages ago.
01:22:41.740 - 01:23:21.468, Speaker A: It's like a concurrency data structure that's specifically optimized for if you have many concurrent readers. I was about to start using this package because I have a single writer multi reader setup where the write operation cannot wait for readers. So a traditional rv, lockpad, or mutex can be annoying. Description says the event has lock free writes, but I don't see how that would work. Both flush and refresh will block the writer until the readers are done. I would want a situation where writers can freely add operations without ever having to wait. And as soon as there are no more readers, the reader side is updated, but on the reader's time, not on the writer's time.
01:23:21.468 - 01:23:43.754, Speaker A: It seems like lock free writes. You're intending to say writes don't prevent reads. It's as ambiguous as I took it to mean. Yeah, it is true that EV map isn't really lock free writes. Well, it depends, because it is lock free writes. It's just they're not visible until you call. Flush or refresh.
01:23:43.754 - 01:24:17.348, Speaker A: And flush and refresh are not weight free, but point well taken. So the tricky part here is. So the very basic premise of EV map is that you keep two maps, one that writers write to and one that readers read from. And when a writer wants to expose the writes that they've done, there's a single pointer that all the readers go through. And so you swap that pointer to the other map. And so now all the readers start seeing your updated map. But some readers might still be working with the read they or the pointer they're previously read.
01:24:17.348 - 01:24:54.280, Speaker A: So the writer now needs to wait for all the readers to shift over to this map before the writer now has exclusive access to this map and can start updating that one instead. And so it's that, that wait for the readers to move is the reason why. Flush and refresh. Refresh block there. You know, it's possible to add a mechanism here where you can like try refresh. So if all the readers have moved, then it, then it returns immediately. Otherwise it returns saying the readers haven't all moved yet.
01:24:54.280 - 01:26:02.668, Speaker A: So that's basically what they're proposing here with try refresh or try flush. The challenge with having the refresh happen in the background, which is really what they're asking for here, is that it fundamentally is a blocking operation. You're actually waiting for all the readers to move along and something has to block. We could have a separate thread that runs, but the question is, what does the writer do in the meantime? Like, if the writer wants to do a refresh, what do they do if they're not blocking? Because when you do a refresh, the idea is that once refresh returns, you're allowed to do writes to the map. But if refresh doesn't block and some other thread is going to do the refresh in the background, if you start doing writes, where do those rights go? There's nowhere for them to go. Technically, EV map has a sort of operational log where those rights could go. And then you just need to remember that you need to apply it to both maps.
01:26:02.668 - 01:27:51.440, Speaker A: But it gets really convoluted because now what if you call refresh again and the previous refresh still hasn't completed? I don't know if you want to get into this, into this game. Could it be done with three maps? I think you just have the same problem, because what if you refresh while the, while there are readers in maps one, two and three, then now you still, then now you need a fourth map. And I think that's not, that's probably not great. Yeah. Okay, so you're technically correct, which is the best kind of correct, rights to the map? Are we free? One could argue that rights to the map are, wait, free because, well, they are, but the pure write operation is. But once you take into account having to also expose them to readers, then they're not wait, free anymore. I think updating the description is a good idea.
01:27:51.440 - 01:30:30.130, Speaker A: As for the larger feature, this one is actually quite tricky. Adding a try refresh and try flush makes a lot of sense to me. Happy to take a look at pr if you have a chance. As for the larger feature of having of essentially scheduling a refresh to happen whenever it becomes possible, this one's actually quite tricky. The big question is what to do with writes with modifications to the map while such a between when refresh returns but still hasn't but the readers still haven't actually moved on, and when and when the readers have actually moved on and one of the maps is available for writes, you could stick them in the op log, but handling the logic of that oplog then becomes significantly more complicated, especially once you take into account that another refresh could happen while readers are still now in both maps. Oops. Regarding the code to identify perf modifiers, do the modifiers always appear in the same order? I don't know, which is why I think it's reasonable to do what we did is just parse it with a bit set.
01:30:30.130 - 01:31:10.130, Speaker A: Okay, done. Branchless index update and find gt okay, so this is is a completely different crate. Arguably I should do this per crate. It might save me some stack space, but I still like the idea of treating them in sort of q order. Word search is a crate that I wrote ages ago that is basically an implementation of a way to do. Here I'll pull up the description. It's easier, so I don't get it wrong.
01:31:10.130 - 01:32:06.346, Speaker A: Approximate lookups and ordered collections. So given a set, set a of n values and a query value of x, it finds the smallest value in a that is greater than or equal to x. And so it's, it's a little bit weird. It's basically binary search. So the idea is that you have a set of values and it's sorted and you're trying to find the smallest value that is greater than n. Binary search over a sorted vector. And there's a research paper that basically outlines what is supposed to be a very fast implementation of that algorithm of binary search using sort of vectorized operations and branchless operations and stuff.
01:32:06.346 - 01:32:53.390, Speaker A: So basically, if you have a modern processor, how should you solve this problem? And, you know, in theory we could experiment with this inside of the binary search implementation, the standard library. But in practice it feels nice to do it in a separate crate and then improve it over time. And then maybe if it gets good enough, we could incorporate it back into stdin. And unfortunately, when I implemented this, I found that it was slower than binary search. If you look at the performance results here, generally it's actually slower than what you would get with Vec binary search. And so I sort of abandoned in the middle, but someone else did some experiments with this where they basically wrote their own implementation and then found mine. And then we started having a chat and they discovered that there were some things that could actually be implemented.
01:32:53.390 - 01:33:44.712, Speaker A: Implemented quite right. In my implementation of this, that makes a huge difference. So it turns out that my implementation of find greater than or equal, which is the sort of core implementation of the library, isn't fully branchless. There's a branch prediction is the main bottleneck, which makes sense. The following expression is not optimized by the compiler. Oh, that's interesting. So one of the things that this implementation relies on, or that the paper relies on, is that on x 86 you have these things called conditional moves, and conditional moves are, they're not branches.
01:33:44.712 - 01:34:22.170, Speaker A: Rewinding a little bit. One of the things that makes programs slow, there are many things, but one of them is branch prediction. So if you have a branch like you've got an if, then the CPU, when it runs, ideally wants to continue to run it doesn't like if. If there are two possible. If you don't have branches, if you just have a linear line of operations, the CPU knows exactly what's going to happen next, so we can just keep executing. And that means that it can execute things out of order, it can execute multiple things in parallel, it can execute way more efficiently. If you have a branch, the CPU has a problem, because it doesn't know whether it's going to run this code or that code.
01:34:22.170 - 01:35:06.042, Speaker A: And usually there are two ways to deal with this. One is the CPU waits until it has all the information it needs to determine which branch to take. The other is essentially speculative execution. So you have a, you have something in the CPU called the branch predictor, which tries to predict which branch is going to be taken, and the CPU uses that to predict the branch and just start executing that branch. And if it turns out that the prediction was wrong, you get a branch misprediction, in which case you have to unwind the work you did and then continue down the other branch instead. And mis predictions are very expensive because you wasted cycles on doing something you didn't need to do and on undoing it later. So you really want to avoid branch mispredictions.
01:35:06.042 - 01:36:17.198, Speaker A: But even it's even better if you can get rid of the branches altogether. And these conditional move operations are not branches they're, they're essentially a way built into the CPU of saying evaluate whether this thing is true or not. And depending on whether it was true or false, take this value or that value. And so it's not really a branch, it's something that CPU can execute as a single instruction, and it doesn't have, there's no branch in the logic flow, it's just a value that's conditional on some computation. And in this case you often write them as a simple if followed by two different values, and then you rely on the CPU or the compiler really turning this into a conditional move operation, which is a SIm single assembly instruction, rather than turning it into a branch, which is indicated by a jump like the JE and the JB here. And what this person is pointing out is that this code, which should turn into a conditional move, actually turns into a jump. And indeed, usually the compiler is able to optimize these, but for whatever reason it doesn't.
01:36:17.198 - 01:36:43.576, Speaker A: In this case, solution is quite simple. So we, so what we're doing here is we're trying to figure out whether to add one or two. And in this case they're saying just do two plus one. The two plus I plus one plus usize from x is greater than value. I see. Because x is greater than values. That's the inverse of this condition is a boolean.
01:36:43.576 - 01:37:31.448, Speaker A: And when you do u size from Boolean, you get zero or one. So we, I mean, we can test this just to make sure. So if we do here use from false we get zero, and useize from true we get one. So this is a way to utilize use size from booleans to basically get zero or one, which is what we want to add here. And so now you see here the original versus the branchless. See the branchless takes way less time here overall. And in fact you can see the diff here and percentages.
01:37:31.448 - 01:38:03.740, Speaker A: You see the speed up is pretty universal. This one is slower, which is interesting. I wonder why three benchmarks become worse. Could be unaligned memory access. We're now l one memory bound, which is a good place to be in, but generally the speed things up a lot. And now half of the benchmarks are faster than sorted vector. So the binary search in the standard library.
01:38:03.740 - 01:38:47.630, Speaker A: Beautiful. So let's look at the diff. The diff is indeed exactly right. It's a great catch. Thank you. To your other good right up. Approve, submit.
01:38:47.630 - 01:39:15.040, Speaker A: Excellent. Do we want to squash this? This is already nice. This is already just one commit. Beautiful merge. Done. A new remote child owned struct to avoid the self ref issue. Okay, so this is in the Openssh crate.
01:39:15.040 - 01:39:57.736, Speaker A: The OpenSSh crate is basically rust bindings to opensShe. It's not quite bindings, it's really, you spin up an openssh muxing server, which is basically you let openssh handle all the crypto. Like it sets up all the connections. This is for clients, not servers. It sets up the connection and everything. And then there's a protocol that you can use to interact with the muxing server. So you can send it things like execute this remote command, or I read this from standard in or send this to standard in, rather read this from standard out from the remote process.
01:39:57.736 - 01:40:50.640, Speaker A: And so that way this crate doesn't have to do any crypto, it doesn't have to do any authentication, authorization, anything like that. It just needs to start and control the muxing server. Remote child owned okay, so the setup here is, let me pull up the open message and I forget if I have an alpha. I do not. Okay, so when you spin up a remote process, like you want to execute something on the other end of a connection, what you get back is a remote child, which is a similar to in rust. When you do, when you spawn a process, you get back a standard process child. Remote child is the equivalent of that type, which refers then to the currently executing process on the remote server.
01:40:50.640 - 01:42:10.900, Speaker A: If it is possible for SFTP to hold a session spawn command. Right? Okay, so the challenge here is that the remote child only lives for as long as the session lives, right? So if you have a connection to a remote host and you have a remote child running on that host, if the connection goes down or if you close the connection, rather the child should also not be usable anymore. And we enforce that using the type system in rust. So we say that the remote child mutably borrows or immutably borrows the session. You can see this by the fact that the remote child has a lifetime associated with it, and you can call session on it to get back the session that the child was spawned from. Now the problem with this is it's really annoying to pass around these session things, or rather anything with a lifetime really, because now you need to, like, you can't give them to a different thread. You can't.
01:42:10.900 - 01:43:13.150, Speaker A: It gets annoying once you have this remote child that tied to a reference to something else because you can't move that something else because then the reference becomes invalid and the borrow checker yells at you and you can't move the remote child to a place where it might outlive the session. And so I think the proposal here is that we have a type remote child owned, which owns its session. And the reason that's okay is because if you look at session and you look at something like command, you see they all take a reference, a shared reference to self, not immutable reference to self. And in reality, if we go and look at the source, right, it's a session impulse. Let's look at the actual impulse is process the one I want. That's not quite what I want either. I might have to look at the actual code.
01:43:13.150 - 01:43:58.100, Speaker A: So we have two different implementations of how to talk to SSH. One is through the SSH command line tool, and the other is through a native implementation of the SSH protocol, like the muxing protocol. Realistically, we're probably going to get rid of the process based one at some point, once the native mux one is stable enough. But if you look at the process implementation and look at session, session is really just two paths, because the muxing client is just running in the background. There's nothing for us to really own. There's nothing in the session object except the paths to the sort of control for the mux. And so this one is sort of trivially clonable.
01:43:58.100 - 01:45:04.282, Speaker A: There's a little bit of question about how we deal with cleanup, but you could imagine this being an arc session pretty easily, and I think the same is true for the native mux implementation. So if you look at this, it is also just a path to the control and the temporary directory that holds some, essentially the state of that muxing client. And so these sessions in theory are cloneable. I don't think we want them to be cloneable, because then cleanup becomes annoying. But they're certainly easy to put in an arc, right? Because they all take shared references anyway. And so the proposal here, I think, is basically, let's, instead of keep passing sessions everywhere, let's pass arc sessions, and then we can still use references to have a non cloning way to spawn childs and stuff. But you can imagine then that you could turn a remote child into an owned remote child, one that doesn't have a lifetime by just having all the same fields and really just cloning the arc of the session so that way that remote child can continue living.
01:45:04.282 - 01:47:01.450, Speaker A: And the way that'll work, of course, is that even if the original session is dropped, like the original session variable is dropped, the remote child own has its own clone of that session, which means the session won't be dropped. We're not going to terminate the muxer and therefore the remote child gets to keep living. Unfortunately, I think this makes a lot of sense. The way to go about it is probably to start carrying around arc session instead of just s session, and then a variant of remote child that clones that arc session instead of keeping a. Should be a pretty trivial change, I think, beyond having to duplicate a bunch of the remote child code. So of course the downside here is that if we want a remote child and remote child owned, now we have two types that have to, they have to have all the same methods, they have to have all the same contents and logic. And so now we kind of need to be like either use some kind of macro to avoid duplicating all that code, or just duplicating all of the code and maybe deprecating remote child.
01:47:01.450 - 01:49:03.090, Speaker A: If you can think of a clever way in which we can avoid duplicating much of the code, that would be nice, but not a requirement. Do you think we should also deprecate remote child with the plan to make remote child owned the only remote child in the future? My main concern would be that they'll end up unexpectedly leaving sessions open because they're still storing a more child somewhere, when in reality they they might want the borrow checker to tell them that that is the case. This is relevant for modern cpu's oh, or search. Absolutely. This matters especially because binary search is such a low level operation and it's such a, it's often used in hot loops for anything that uses binary search, for example, you end up calling this over and over, and as a result, even nanosecond optimizations to this ends up having pretty large ramifications. And so as you saw, you can see a speed up of three x compared to the binary search and vector. And that matters.
01:49:03.090 - 01:50:05.900, Speaker A: Where's the term mux comes from? I've heard in tmux for multiplexer. Yeah, it's from multiplexer, and it's used for, I don't know what the word multiplexer. I don't know how multiplexer turned into mux, but that is the general translation, and it multiplexes multiple streams, usually input and output streams. Can I be evil and suggest the openssh create to also work on windows? The reason why it doesn't work on windows at the moment is because Openssh doesn't have a mux client like a mux daemon. Or rather the mux daemon feature of OpensSh does not exist on windows, at least didn't until recently. Maybe that's changed, in which case we would totally do it. Okay, done.
01:50:05.900 - 01:50:42.210, Speaker A: Okay, we made it through the first couple of issues that I opened, and we were at what, 118 and we're now at 110. So no, actually I think there are more now because some of them are unread. All right, let's go back to the last page. And now you understand how this works. Okay, so this one, I guess I forgot to mark it. Done. Okay, and now we've been going for what, two and a half hours or something.
01:50:42.210 - 01:50:57.934, Speaker A: This is what open source maintenance is like. Oh, same person. Okay, this is back in search. PR contains two changes, I believe, making bite tracks more robust. The suggestions are debatable. Great. I made Dup.
01:50:57.934 - 01:52:52.850, Speaker A: No, dupe methods is inline. Never at the moment they are not inlined by the compiler, but this can change dup. I need to bring this back into. What is this? This is, I need to page this back in. I haven't looked at ord search in a while. So for the benchmarking, I think dupe is for duplication, like it's whether there are duplicates or nothing, which. Why are they saying the dupe should never be inlined? I don't think it matters whether dupe and no duper inline, because all they do is test setup and then bench construction, which is down here.
01:52:52.850 - 01:53:57.680, Speaker A: Yeah, like dupe isn't used down here, is it? Make, like, what do we end up calling here? We end up calling make. The only thing that changes is the value of Mapper. So second to last argument of bench search and second to last argument of bench construction, Mapper. Oh, Mapper is called in there. Oh, I see. So the thing they're marking as, it's these that should be marked as, but these are already marked as inline. I don't understand this argument.
01:53:57.680 - 01:55:10.870, Speaker A: These. Oh, to make sure we have the same machine code for the setup. I don't know if that makes a difference. Oh, for the different sizes. I see. So you could end up with the benchmarking suite, you could end up with a compiler building, optimizing a dupe test differently depending on the sizes of the payload. But I don't know if that's actually a problem because in reality when you run the code that's going to be the case anyway.
01:55:10.870 - 01:56:29.810, Speaker A: Yeah, the compiler will generate different machine code for the different payload sizes. Although this can show better benchmarking results. This strategy is not representative of real applications because it's almost never the case that we know the size of the payload at compile time. Size comes from cache size oh, okay, I see where the argument comes from. Okay, so we pass in a cache here and the cache dictates basically the number of elements in the array that we're going to search. So the idea here is that we want to benchmark things that fit in the l one cache of the cpu, the l two cache of the cpu, and the l three cache of the cpu. If this is ever inlined, what you can end up with the l one benchmark and the l two benchmark.
01:56:29.810 - 01:57:27.110, Speaker A: They're gonna be, they're gonna generate different implementations based on the known size of the cache, which is not normally something, you know. So I think I agree with this. I removed the issum from recovering foreign code. This guy's find Gt's actually inline by the compiler. In most cases there's no significant changes. There is one where there's a performance drop. Okay, so this is, there's a bit of code where in the benchmark down here when we search for something we call dot issum.
01:57:27.110 - 01:58:31.108, Speaker A: And I think the reason why I called is sum here was I wanted to make sure that the value inside of the sum was actually being looked at. But in practice that's not really true. What ends up happening is that the compiler smartly realizes, well, you're just taking the, the, whether it's sum or none, which means that the actual value inside of the sum doesn't matter, which means that I can avoid computing it. And so it ends up skipping these last part of the computation, because it does still need to compute sum or none. But it doesn't need to compute this value. So it only needs, well, it should still need j because it still needs to decide none or some. But I think I agree that it's better to skip these sum here, because Blackbox is going to make sure that the compiler believes that it has to fully produce the value, including the value inside of sum.
01:58:31.108 - 01:59:14.710, Speaker A: So I think this is totally reasonable. One of them got a lot slower. Which one? This one? L three. Okay, I mean that's, that's fine, that seems fine. Same benchmarks. Starting to believe there's some systematic issue with the benchmark itself. I fully agree with both of these, thanks.
01:59:14.710 - 02:00:14.040, Speaker A: Now hang on, that's in search. I feel like we should also do the same for construction. Shouldn't we also mark the construction dupe? No dupe as inline. Never. Though I see you have just a few tenths of notifications. Do you use a separate account for your work? I usually have thousands. No work.
02:00:14.040 - 02:01:24.220, Speaker A: It's because work for me doesn't happen on GitHub generally? If I did, I would probably have a bunch more. Wouldn't it be smarter to just black box the input? Black boxing the input doesn't help here because it would be, if it's inline, then black boxing it. I suppose we could black box the argument so we could. An alternative here would be to black box. This size here would be to black box. The two lines that read compiler doesn't get to make use of that knowledge. Maybe we should do that in addition to forcing no inline.
02:01:24.220 - 02:02:46.600, Speaker A: Even so, though I'm inclined to merge this because the changes are still reasonable. It's just that we might make additional changes. Port stack collapse recursive okay, this is back in inferno, a standalone script script to be run on some preclex input. All right, what does this do? Is there any way of collapsing recursive calls? Wait, I want to see an example of this. Oh, I see, it's if you have functions that are calling itself, you want to simplify. What's a good, let's pull up a random flame graph here. Flame graph, show me.
02:02:46.600 - 02:03:34.946, Speaker A: Okay, so here's what a flame graph looks like, and for example, over here you can see that we have call stub calls interpreter, interpreter calls interpreter interpreter calls interpreter, and then interpreter calls this. When you have recursive methods like this, there are two things that happen. First, there's just a lot of noise, like you end up with very tall stacks when you don't really need them to be tall stacks. But the other thing that's important is imagine that you have a recursive function that sometimes diverges. So sometimes like, let's say you have a function food, that's recursive, and sometimes it calls bar after three iterations, sometimes it call or three recursions, and sometimes it calls bar after five recursions. Then now you're going to end up with a flame graph that splits. So it's going to have two sort of columns, one with three foos and then a bar, and one with five foos and then a bar.
02:03:34.946 - 02:04:27.350, Speaker A: And then everything above the bars are the same because they're probably the same sort of branching points. The inputs were just different. And so collapsing the recursion there, basically making all the recursive calls be a single call, means you're also collapsing those, those columns and hopefully getting a better, better end result. And so what this script does then is precisely that it turns a stack like this. So main calls recursive, recursive calls, recursive, recursive, et cetera, until they call helper into just main calls, recursive calls helper. So this person, I'm going to pr up initial thoughts. So this is the issue describing and we'll look at the pr in a second.
02:04:27.350 - 02:05:46.210, Speaker A: Yeah, core recursive functions would be nice to deduplicate to, but it's, that one's trickier. Nice. Yeah, core recursion is tricky. I think the way you would have to treat this is like if you see BC BC BC, then you were to collapse it to BC. But the moment they start diverging, I don't think you want to do that anymore. Okay, so they made it a standalone script. So Inferno comes with inferno collapse perf, for example, which takes the output of per script and turns it into these kinds of lines of the stack, semicolon separated followed by space followed by the number of calls, the number of samples from that stack.
02:05:46.210 - 02:06:38.820, Speaker A: So it turns perf script, which is that long jumble things we tried to parse earlier into that kind of regular stack syntax, collapsed syntax as they call it. And the argument here is we could either have it so that the collapsed perf takes like a merge recursive flag or something, or we could say you generate some foo dot collapsed with this and then you run collapse recursive as sort of a post processor on that file. So that's what they mean by standalone here. And I think standalone makes a lot of sense. So I don't think we need that as flags. So what do they do? They added binary. That seems fine.
02:06:38.820 - 02:07:31.038, Speaker A: Number of threads to use. I don't think this even needs to be using folder. So in inferno we have a data structure, kind of like basically a little component that makes it easier to write a thing that produces a collapsed thing. But I guess it makes, I think it makes sense to reuse it, maybe. So you can construct one of these folders and then you basically write things into the folder and it produces the right syntax. And I guess this is a folder, it's just that its input is also folder or is also collapsed. That seems fine.
02:07:31.038 - 02:08:10.456, Speaker A: This is just the binary interface to it, collapse file to standard out from folder. And I think this is pretty common. I think all of our, we have a bunch of different collapsers for different tools like vtune versus Prof. Dtrace, et cetera. Perf is the most well developed one and I'm just trying to find the oops, that's not what I want. I want binary collapse perf. You see most of this is command line parsing and then it calls folder from.
02:08:10.456 - 02:08:38.856, Speaker A: So the syntax of these is pretty similar. It's mostly just parsing the configuration. So this seems fine. It takes a path, a number of threads. Okay, collapse direct recursive backtracks. Direct, oh, direct in the sense of a function calls itself stacklist and merge direct recursive calls, for example, collapses this into that. Okay, that seems reasonable.
02:08:38.856 - 02:09:21.242, Speaker A: That's just the summary for the module. Okay, so the only option is number of threads. That seems fine for now that you can imagine here that we had options for core recursion. For example, a middleware folder that receives and outputs the folded stack format. Collapsing direct recursive backtracks. Oh, so this is the, this is the folder, which is the, the thing that implements the trait. That's fine.
02:09:21.242 - 02:10:30.206, Speaker A: We can ignore that from options. That's fine. Why is zero one that's fine? You can't run a folder with no threads. Yeah, so this collapse private is the trait that we use for this component that handles some of the generation of this collapsed format. For you, it's already collapsed, so there are no headers. Collapse single threaded for a line in, okay, so iterates over the lines, parses out the parts, close collapse stack. Every line is an independent stack.
02:10:30.206 - 02:11:10.378, Speaker A: Yeah. The way that this format, unlike the, the perf script format, is very straightforward. Like every line is a stack. So there's just, there's nothing else to parse. It's just if you hit a line end, it means you're done with that stack. And occurrences here is this component that helps count. So this is saying insert or add what we, you know, we take this stack line we call collapse stack, which is what turns the, the one with the recursive calls into one without one with the same count, it's not going to be guessable.
02:11:10.378 - 02:12:09.140, Speaker A: So guessable here is used for, we have this tool called inferno collapse guess. And with guess you just give it, you can pass like perf script into it, you can pass vtune into it and it'll just call the appropriate collapser you. It's worth as questionable, I think. But it's certainly true that we never really want to guess that the format is to use the recursive collapser. So that seems fine. Line parts is we just split by space and we grab the count and the stack. So this can really now be, this can just be r split once.
02:12:09.140 - 02:12:56.342, Speaker A: Now I think just a review collapse stack takes a stack if it's not recursive. Yeah, this is nice. So if it's not recursive, then we don't have to do and we don't have to allocate a new string that has the modified stack in it is recursive, just splits by semicolon. And if the previous one is ever equal to the current one, that we have recursion. Otherwise we do not. Great, looks fine. There is recursion.
02:12:56.342 - 02:13:38.190, Speaker A: So we allocate a new string starting with the length of the existing stack. That seems reasonable. And, and then we push only if the frame isn't equal. Remove the trailing semicolon. Yeah, I was about to say. And then we turn that into a cow. We have some tests.
02:13:38.190 - 02:14:34.780, Speaker A: Collapsing the empty string does nothing. Collapsing single, does nothing. Not recursive, does nothing. Nice, nice. This one is debatable. Whether, if you have multiple spaces, whether the collapse format dictates that this is the last white space, or whether it's like the last sequence of whitespace or the last single whitespace, the trailing space here is questionable. I genuinely don't know.
02:14:34.780 - 02:15:36.300, Speaker A: Whether the collapsed format is string of white is, dictates that the count is only ever offset by a single space. Maybe avoid testing that specifically here and just keep a single space before 42 and then test for collapse recursive. So this the test collapse recursive thing. I wonder actually whether flamegraph has tests for this test. Probably does not. It does not. Okay.
02:15:36.300 - 02:16:15.250, Speaker A: Yeah, so I'm guessing they added some. Yeah, so there's some test files here that just has stacks and we're expecting this one, for example, to turn into this. So main not recursive, turns into four. Main recursive helper one and two turns into main recursive helper three. And then we check that this works when invoked with one thread, with two threads, whether through the API or whether through the command. This looks great. I like this.
02:16:15.250 - 02:17:35.168, Speaker A: Two minor knits. And then I think we're to land this. Beautiful, beautiful, beautiful, beautiful. Done. Couldn't the pattern matching avoid duplication by adding a guard? Let's go back and see. You mean the pattern matching in here, right. This, you can't have a guard on something that is only present in one place pattern, so you can't write none or some l.
02:17:35.168 - 02:18:44.910, Speaker A: If l. I don't think that works. I think the guard is handled for the entire arm and not for a sub pattern. Unfortunately. This could be optimized a little bit like you could do, you could do something like last dot map, or technically you could reduce the duplication here with something like if last dot map or true l, not equal to frame. Not terribly important though. But yeah, it's a good call.
02:18:44.910 - 02:19:46.580, Speaker A: Okay, ord search benchmark payload in the case of order collection Bt reset contain references while sorted VEC operates on primitives directly. This is incorrect because it punishes ordered collection b tree set with one more level of memory and direction. In this pr I've removed references from make this and make Bt reset payload generators performance improved significantly. All results are reported, including changes from five ordered collection. Wait, I'm confused now. Ordered collection oh, as in this the ordered collection here is this across almost all benchmarks. Nice.
02:19:46.580 - 02:21:48.340, Speaker A: Okay, let's look at this. If this is copied, this can just use dot copied I believe, but that's fine. Interesting. So previously the argument here is that previously the benchmarks would let sorted vec have a vector of t's. Like if we had a vector of u sizes, for example, it would actually contain it would be a vector of u sizes, whereas b treeset and r type here are would be collections of references to you size. So you end up with an additional indirection that's entirely unnecessary, which unnecessarily penalizes us too. Good catch.
02:21:48.340 - 02:23:10.170, Speaker A: Faster across the board. Should probably update the readme as well now that we have such different results. Approve. I don't think the copied thing is worth blocking on here. Single commit, single commit great merge and then we can do here. I think this could also use oh no, I know I can't use copied rust copied. It can't use copied because copied operates on operates on an iterator over shared references.
02:23:10.170 - 02:23:52.052, Speaker A: But what we have here is a because they call into iter here instead of iter. What you end up with is a mutable iterator of a vector which yields mutable references and so the type signatures wouldn't match. But I believe. I think you can simplify this slightly by using iter instead of intuitter copied. Okay, word search this is from someone else. Nice. Let's see what they say.
02:23:52.052 - 02:24:26.900, Speaker A: Criterion is a more full featured statistics driven benchmarking tool, and it creates nice graphs. That is true. I like criterion. I wanted to investigate the claim that it's slower. Regardless, I think it'd be interesting to rebench my discovery of computers anno 2023, see how things stand. Word search sorted back mbt reset I agree, that is going to be interesting. SPR is a work in progress.
02:24:26.900 - 02:25:40.410, Speaker A: Let's see this PR merge for several reasons. Yeah, I do. It does makes me sad that the yeah I do kind of want to move to criterion. I totally agree. Execution time median is stable, then 100 milliseconds it stops execution. Still want to see this happen. So if you're up for pick happen, especially with all the improvements that has made recently, any chance you have time to pick it back up? This is also something you'll see pretty often is here.
02:25:40.410 - 02:26:29.750, Speaker A: I could just do this myself. I could just port the benchmark suite of word search to use criterion and it wouldn't have take me all that long, but I would rather the person who originally started this do it instead for two reasons. First of all, it's not clear that it's the best use of my time. As you can see, there are a lot of things to go through here that require my input, specifically, not just anyone who knows rust, but I have to go deal with a bunch of these things and no one else can do that work for me. So I'd rather spend my time there than here on work that allows other people could do. And the second one is it encourages someone who already has shown some interest in this code base to continue to develop that interest. And so hopefully they might and then become a contributor and eventually maybe a maintainer.
02:26:29.750 - 02:27:15.240, Speaker A: Because for many of these projects I am the only maintainer and I would love to see other people come in and help and essentially not take them away from me. But if I can let other people have the agency to do things with this crate, then it can get better without me being a blocker for it. So I very much here want to encourage other people to do that work. It's not really selfish at all, even though it might come across that way. Done. This is in factory rs. Okay, so this is, there is a, this is a job server, so something called factory.
02:27:15.240 - 02:27:51.210, Speaker A: And factory is a job processing tool. It's basically a job queue that there are a bunch of previous implementations of this. I forget sidekick is the other one that many people know about. Factory is basically the replacement for sidekick. And many years ago I wrote a client implementation of the factory protocol. So you can submit jobs to factory and you can also implement workers over factory. And I never actually used it myself, I just found it interesting and I like implementing protocols.
02:27:51.210 - 02:28:18.760, Speaker A: And here, this has already been fixed. Oh, I see. And someone just left a note about how to do it in case someone find the issue but didn't see in the documentation. Okay, great. Thank you for sharing your knowledge. Nothing for me to do. This library is fascinating, actually.
02:28:18.760 - 02:29:48.530, Speaker A: This library I've had to do very little with, and it seems to just kind of take along like I haven't modified it since September of 2022 and I think people are using, using it. It almost certainly could use some dependency updates. So if anyone wants to do some dependency updates on factory, feel free. But otherwise it seems to be ticking along. Finally, is this a good project to help people learn? Rust which project? I've gone through a lot of them so far. Rust IMAP replace NPC sender receiver bye VecDEc or VeCDQ okay, so this is a long discussion I've had in the past. Okay, so this is in the IMAP crate, which implements the IMAP mail protocol on the client side, that is, and in the, in the client protocol, like based on the RFC, it's possible for the server to send messages to a client that aren't related to the client's request.
02:29:48.530 - 02:30:29.328, Speaker A: So if you're writing an IMAP client, generally you're going to send commands to the server. Like show me all the messages in the inbox and the server is going to reply with a list of messages. So, so far so good. But the server has also allowed you to send unsolicited messages. So when you send, you know, tell me about messages in the inbox, it might start sending you a list of the messages and then randomly send you a message that says like new email arrived, and then continue with the listing. And that new email arrived message is an unsolicited message, and those can arrive at almost any point during your connection. So as a client library, we need to handle those.
02:30:29.328 - 02:31:26.506, Speaker A: The way we currently handle them is that we have a, we have a sender and a receiver channel. So whenever we detect one of these, we send on the sender and we give the, in the client API, we give out the receiver so that a consumer of the library can choose to handle these unsolicited messages however they might wish. Now it turns out that because we store the sender, we, the client ends up not being send and synced. And I forget exactly why. It's nothing send, but it's certainly not sync. Well, for some reason the client ends up not being send and sync because we hold on to these channels. Oh, it's because we hold both the send and the receive side, and then it ends up not being send or sync.
02:31:26.506 - 02:32:14.540, Speaker A: And this is really annoying because you really want the ability to take a client and like give it to another thread, for example. And so the solution here is, turns out because of the pattern in which we use this channel, it doesn't really need to be a channel at all, it just needs to be a queue. And when you have a queue, when you want a queue, you can just use the vector type from the standard library. So at the conclusion of this discussion was let's just replace the implementation or replace the use of this channel with a vector instead. So hopefully this shouldn't be too bad. That seems fine. I'm fine with that.
02:32:14.540 - 02:33:17.760, Speaker A: Cargo lock. I'm going to ignore source client. So we're going to keep a vec deck and anywhere where we currently pass in immutable reference to the sender, we're going to pass in immutable reference to the vectec, get rid of these annotations. That all seems very reasonable. And then where is the place where we give out the receiver? Oh yeah, that's just a public, it's a public field on the session. So that allows people to read out of this. But that means this is a breaking change because of course it is.
02:33:17.760 - 02:35:06.622, Speaker A: But we're about to cut a, well, we have been about to cut a new major version of IMap for a while, so I think that's okay. In case we want to change this again in the future. I wonder if we should stop having this be a pub field and instead of instead have a get unsolicited method or something like it, maybe one that way the exact type we use here isn't exposed in the API and thus can be changed. So we would want something like impulse session and then we probably have pub fn next unsolicited which returns an option unsolicited response. And we would have a all unsolicited which returns a vector of unsolicited response. What do you think? Start reviewing. All right.
02:35:06.622 - 02:35:39.380, Speaker A: And the types of everything has to change because they're now getting a different type in. This is, oh, this just creates one. This is for a test so it just creates one internally for the test. That's fine. This changes. Looks fine. That looks fine.
02:35:39.380 - 02:36:23.400, Speaker A: What do we got in parse? This is all just type changes. Type change. The send becomes a pushback. That's fine. Wait, this should be a push back. Now I'm paranoid. Let's go back and see that these indeed are also pushed back.
02:36:23.400 - 02:37:01.190, Speaker A: This is an extension that just passes it elsewhere so that's fine. This also just passes it elsewhere so that's fine. Let's push back. Pop front, pop front, pop front is none. Instead of iserror on receive. That seems reasonable. That is indeed how the API is changed.
02:37:01.190 - 02:37:41.758, Speaker A: Try receivers. Prop front. Aren't type changes like this just the best? Great. Rest of this looks fine. Is factory a good one to factory might be a good first place to start with rust. Actually the code is not super complicated. So if you're looking for something to just play around with, factory might be a good one.
02:37:41.758 - 02:38:06.860, Speaker A: I don't know, Fang. I don't know how it compares. Yeah, unsolicited messages have tripped me up a bunch of times, both client and surferside. Missing semicolon on a line. I don't think they're missing semicolon. CI would catch that. Okay, this is fine, this is fine.
02:38:06.860 - 02:38:44.890, Speaker A: Oops. It's fine, this is fine. I think it's only the parser, which is the one we looked at, that does pushing, pop front, push back. It takes from the front of one queue and pushes to the back of the other, which is equivalent to appending the queues. Great. Pop front, push back. And this is a deprecation in Chrono, which is fine.
02:38:44.890 - 02:39:42.730, Speaker A: I'm okay with taking that change as part of this. This one bit in there that I think is wrong, otherwise looks good. Submit. Beautiful. Done. Still can't run multiple tasks in parallel using a session. And that is because every session borrows self is self mute.
02:39:42.730 - 02:41:34.270, Speaker A: Yeah, so this person wants to concurrently use an IMAP connection across multiple threads. And that indeed will not work because we only have a single TCP channel. And so ultimately you need to synchronize on that TCP channel because you can't really have multiple in flight operations over IMAP over a single connection because the IMAP protocol, like if we look at RFC IMAP 3501, if we go look at some examples from the protocol, like if you do select inbox, these are the messages you get back. And notice that if we had concurrency here, if one thread sent this, and then the server sent like these two, and then the client sent from a different thread sent another operation, there's no way to tell that the response, whether the next response line is for the first connection, the first operation that's done, finished, or for the new client operation from the other thread. So these stars, which are just sort of line continuations, wouldn't allow you to operate concurrently anyway, fundamental to the IMAP protocol, it doesn't allow for multiple concurrent requests. So you need to either use a mutex or separate for each client. Unfortunately.
02:41:34.270 - 02:42:27.580, Speaker A: Unfortunately. Okay, fresh. Okay, so this, we finished this, we finished this, we finished chrome driver not respecting headless browser name. It won't process the ARG at all otherwise. Okay, interesting. I guess you need to specifically tell the browser that specifically need to say that you want Chrome in order to pass headless. That's interesting.
02:42:27.580 - 02:43:28.280, Speaker A: Maintainer access to all crates. Interesting. Yeah, that seems fine. Openssh rest. This is one of those projects where I. Who am I inviting? This person? This is one of those places where I haven't fully handed off openssh yet, but nobody Zoo is doing a lot of the contributions to the crate these days. And I still do reviews and whatnot, and I still do the actual releases.
02:43:28.280 - 02:44:19.930, Speaker A: But we created a GitHub organization specifically to make it easier to have multiple of these subcraits, for example. And they're doing a bunch of work on the crate that I'm now not doing. And I'm okay with that. I want other people to help with this because I don't have the capacity to do it all myself. So let me. This is always a tricky thing when you're a maintainer, which is like, here's someone that I trust to make changes to the crate who's asking me to add another person that I haven't interacted with to give them access to make changes to the crate. I think in the world of open source, like in closed source world, you would never do this, right? But in open source world I think you kind of have to, you need to generally be willing to bring more, be lenient and bring in new people into the fold.
02:44:19.930 - 02:44:54.430, Speaker A: It's sort of a trust but verify kind of situation where, you know, I'm still going to get notifications. When there are changes to the Opensshgrade, for example, I still make the releases so I can sort of monitor how this goes. And if I feel like this person should also like is fine, then I'll stop thinking about it and otherwise I'll be paranoid for a little while. But that's okay. So invite. Member this person invite and security key. I have a security key.
02:44:54.430 - 02:45:57.130, Speaker A: Let's see. Can you hear the keys jinglingen number? Great. Wouldn't extend be more efficient to concat vectues? That is an excellent point. Let's go back and do that. So it's going to be iMap pull requests. Where does that live? That lives over in. I think that was actually in a test now that I think about it.
02:45:57.130 - 02:46:47.430, Speaker A: But it might be in fetch. It's not in fetch somewhere where the few more lines like this one maybe. No, I don't think it was in parse, but maybe it was. It's not imparse. Was it here? Yeah, this is just in tests, so I'm fine with that. I don't think that's important. Oh, is the iMap for second revision RFC nicer? I should look at that.
02:46:47.430 - 02:47:23.250, Speaker A: I've done too much supply chain work. Oh yeah, I'm paranoid about giving people permissions to things rest. It's incredibly information dense. Oh, so this is an issue filed for the book. However, it's incredible information dense and touches on many niche corners of language with descriptions and advice only. Is there a repo of worked examples? Hi there. Oops.
02:47:23.250 - 02:48:31.830, Speaker A: Glad you like it. No, there is not currently any such repository. The book is intentionally quite dense. I wanted it to act more like a series of pointers for what to explore and learn more about, rather than an exhaustive and inevitably eventually outdated reference. If you want to start an example repository, though, I'm sure many people would be interested in collaborating on it. Close with comment done. We're under 100.
02:48:31.830 - 02:49:11.570, Speaker A: Sweet. Oh, and there's a bunch of dependabot things. Let's do this one first. This crate I'm not really maintaining anymore. Okay, this is deprecations, so I don't really want to land that one as is. Oops, I don't know what to do about this one. I'm torn because this is it is a really cool crate.
02:49:11.570 - 02:49:48.972, Speaker A: So it basically implements the MySQL client protocol, no server protocol, so you can write a thing that looks like a MySQl server. So anything that speaks MySQL is able to operate with your thing and you can build whatever you want behind it. So it is really cool, but it sort of languished because it's not something I've really been working with. If someone was to take a stab at picking up this crate like it is a really cool crate, you can build cool things with it. It mostly just needs a few updates to bring it to the latest MySQL version. And I think a couple of other things too, if I remember correctly. Yeah, mysql.
02:49:48.972 - 02:50:40.932, Speaker A: The openssl one shouldn't really matter. I guess I can take that. Why does it even want to bump openssl here? Oh, OpensSL is the thing that has the deprecation. So in that case, I'm fine taking the MySQL1 too. Except of course that it doesn't pass tests, which seems problematic, or only on certain platforms. It doesn't pass minimal versions, and it doesn't pass Mac OS latest minimal versions fails on something with bind gen. And this is almost certainly the OpenSSL bump.
02:50:40.932 - 02:51:17.908, Speaker A: So this is fine. I'll take a, I'll take that one. So this really means I should do a new major version release of that, because MySQL is in the public API. That's fine. Bumping openssl here. I think is also. And now it only fails on macOS and Ubuntu beta.
02:51:17.908 - 02:51:48.910, Speaker A: Why does it fill in Ubuntu beta? Oh, because of the deprecation. Okay, great, that's fine. I will merge that too. If someone wants to take a stab at the CI failures in MySQl server, then please do delete branch. Quick check in atone. Okay, so Atone is a different library. Atone is a library that is a, it's like a vector or more like a Vectek that.
02:51:48.910 - 02:52:26.602, Speaker A: So the way that these data sources often work is, you know, they have a limited capacity because you allocate a vector that's like this long, and then if you push more items than are on the list, it allocates a vector that's twice as long, and then it moves all the elements into the newer vector. And now you can push the new things and you have more space. The problem with this is that you end up with latency spikes. Anytime you have to double the capacity and move all the elements, you get delayed by more and more time. Because like, imagine you have a thing with a million elements, and now you allocate a thing that has space for 2 million. You have to copy a million elements over. That's a lot of work to have to do.
02:52:26.602 - 02:53:09.332, Speaker A: And so you start seeing latency spikes in your application that happen less and less often, but take longer and longer time. And so what atone does is it essentially, instead of moving all the elements at once, it keeps both the small and the large element or array around until, and then moves a few items at a time every time you push. And then only when the small element array, when all the elements of the small array have been moved over, only then does it deallocate them. So it allows you to smooth out that latency cost. Let's see. Quick check. Nice.
02:53:09.332 - 02:53:48.322, Speaker A: No breaking changes in quick check. That's interesting. Is that actually true? Readme no change log. Not a changelog. Huh? Releases? There aren't any releases. Tax version one. The commitment bumps, the version numbers.
02:53:48.322 - 02:54:23.240, Speaker A: Okay, that's relatively unhelpful. That's as of January 8, 21. Really? I don't think I'm that far behind. There's zero nine two. Remove sendbound, remove rand as a public dependency. MSRV bump note compatibility. Okay, sweet.
02:54:23.240 - 02:55:24.056, Speaker A: I mean, it doesn't pass. Why doesn't it pass? Yeah, yeah, that's what I was worried about. I wish there was a, an actual changelog for this upgrade. Okay, so something more here has to happen in order to do this bump. This also is a good thing for someone to try out if you're curious about quick check because here there already are a bunch of quick checks like property tests that you should be able to just tweak slightly to make them work with. Quick check 1.0. So if anyone wants to pick this one up, I'm not going to do this one on stream.
02:55:24.056 - 02:56:17.492, Speaker A: I think anyone wants to pick this up. I'll put it in chat. It might be a good candidate. Doesn't that prevent the allocator from just resizing where it's possible it does, but the latency spikes are too costly for applications. Are latency sensitive? Oh for two factor auth. I use just a yubikey one of these things. Sweet.
02:56:17.492 - 02:57:30.780, Speaker A: So hopefully maybe someone picks this up. I'm going to mark it as unread. This is on Fonticini updates hyper russells to zero two four changed native TL's oh yeah, native TL's should bring in open should bring in OpensSL. Why? As it was, it was forcing any user of the funtochini crate to depend on openssl even if you weren't using the native TL's feature. Interesting. That shouldn't make a difference, but alright, that seems fine to me. Great merge.
02:57:30.780 - 02:58:59.120, Speaker A: Oh, I see what happened. It's because it wasn't marked as optional down here and now it's marked as optional. I think this isn't even actually needed because the openSSL entry there, but it's because cargo requires at least one feature to name any optional dependency. So that's why when I use perf script with dtrace, this is because you're trying to use perf script with the dtrace collapser. You'll want to use the perf collapser instead. So perfect. Sure.
02:58:59.120 - 02:59:55.280, Speaker A: Okay, done. Yeah, so someone posted it pointed out in chat like this has been a four hour stream and we're still at 96. We started at 118 and we're now at 96 notifications. And I'm sure if I went to the front page of some of the ones that I commented on now already have more comments on them that I haven't dealt with yet. So like, you know, oh, there's more imap ones. Previous to 251 I was able to call parse to create mock response objects using my application testing mock and write test for their code. It calls the iMap prep without having an iMap server setup.
02:59:55.280 - 03:01:34.940, Speaker A: Oh, I see. Yeah, so this is someone who wants to test their code that runs on top of the IMAP crate. And the challenge is that they don't have a way to construct values of the IMAP types which you need in order to test your program. You might need to like generate a random like fetch response. And we don't want to make the types fully pub because they need to be non exhaustive because sometimes we add more fields. Having a way to expose builders isn't a bad idea. I think it makes a lot of sense to expose builders for generating objects for test purposes.
03:01:34.940 - 03:02:34.920, Speaker A: We just need to be careful that we don't open up potential backwards compatibility hazards where we won't be able to add fields to structs or change their internal composition in the future. Done. Allows building response objects for testing applications. Uses crates. Okay, so it adds a testing module to use. Add a dev dependency iMap extension. Adding the feature test helpers.
03:02:34.920 - 03:03:19.780, Speaker A: Right. We should probably add that also to, I forget whether we already have that here, actually. Do we already say all features on Docs Rs? We don't, do we? Nope. Tokyo. I know Tokyo does this. Why I'm pulling it up. So there's a, no, there's a little section you can add to cargo tomlike for docs Rs to tell it to generate your documentation with all features enabled.
03:03:19.780 - 03:04:23.480, Speaker A: And I think we're going to want that. Let's also add this thing so that docs rs will document the crate with all features enabled. Okay, so that part's fine. This needs code block around it with. I don't know how you would do this. Like I guess it's markdown and then I want to nest this. Yeah.
03:04:23.480 - 03:05:53.450, Speaker A: Oh, can you use quadruple backticks in the outer block? Nice. These feel like they're probably not relevant to the instructions. We want to keep the example somewhat simple for people. There's no need to include all this extra complexity. Right. So this just lets you call the parsers. Arguably what we want is something better than just you can give us the raw input and we'll parse it for you.
03:05:53.450 - 03:07:27.546, Speaker A: Right. It'd be nice if there was actually a way to construct these as well, but I guess this is a decent start. This and all the other other examples in markdown. So you're saying I can do this and that'll work. Nice works so that they run as tests. And then we should also actually invoke the function and check that the response is what we expect. Catch more things that shouldn't be pub, although I wonder whether they even should be published.
03:07:27.546 - 03:10:17.222, Speaker A: Maybe they, this is a good start, although I feel like what we'd really like to get to is full builders for all these so that folks who want to test don't have to generate full Imap protocol messages and can instead just use a builder to construct the value they need for testing. Definitely something for another pr though, and I think I want these. It would be nice if these were in sub modules instead, so that we have a place to add builders later. I'm thinking something like mod capabilities pubfn parse input. I also think we should use impl InTQ eight instead, so that byte strings will just work and not require dot into. And finally, since this is just for testing and to help ensure that's the case, what do you think of always dot unwrapping inside of these rather than exposing the result makes it less attractive to use them for anything else. What's your take on doc tests versus separate tests? Which one is better? They serve different purposes.
03:10:17.222 - 03:11:25.930, Speaker A: Doc tests are intended to be visible to users, so they should be testing things that they should be demonstrating something of value to the people reading them. And anything else should go in a unit test. Anything that is like testing internal invariants, anything that's testing, you know, multiple different combinations of things where the user doesn't really need to know or care about all the combinations. All of that should not be doc tests because it doesn't need to be doc tests are for demonstrating use or corner cases of interest to the user so that they serve different uses. Taking this up, left some notes. So you used quick tests, any resources on all these different ways to test code and where to learn about them or how to use them. I mean, I talk about this in rust for restations.
03:11:25.930 - 03:12:25.680, Speaker A: You could read about it in there, but the basic premise here is there are a bunch of different testing strategies and you use them for different things. I don't know of one resource that talks about all of them. My book does to some extent, but these are more categories of testing. You have simulation testing, something like loom. For example, you have regular testing where you exhaustively specify the behavior of the tests. You have chaos testing, which is where you just sort of run the test multiple times and you modify semi random parameters or parameters in the environment to see whether you can generate it to do the wrong thing. Like run this test 100 times with like random inputs, and then you have fuss testing and the more advanced sort of property testing, where you have a framework for generating inputs and you check that the assertions of the code don't get triggered by it.
03:12:25.680 - 03:13:19.700, Speaker A: And all of these are valuable. They're valuable in different ways. It's not as though you should do one or the other. Add in a client builder that abstracts away connecting to TL's or non TL's connections. And what TL's provider is used allows a more transparent and versatile usage of the library as one can simply compile it as is and then use the builder to configure where we connect and how we connect without having to be concerned about what type is used for a client and session. Yeah, this is a long debate been having. I don't even remember where this ended up.
03:13:19.700 - 03:14:12.598, Speaker A: Oh, this has a lot of context for me to switch back into. I think I'm going to not do this one on stream. Basically the premise here, just as a summary, is in the IMAP client today. When you want to connect a client, you have to pass in like a TL's connector and you get back a client TL's stream, TCP stream. So it's like the fact that you're using TL's and which library you're using for TL's is encoded into the type. That's nice from a performance perspective. And it's nice kind of from a security perspective because it means that you can enforce that compile time.
03:14:12.598 - 03:15:07.290, Speaker A: Well, you get the benefit of monomorphization for the I o and also you get to see from the type and check it compile time that you are in fact using TL's. The downside is that it's really annoying to work with now you have different types for different types of connections. If you want to change TL's, then now you need need to be generic over things. If you want to build a library on top of iMap, you need to be generic over this internal type. It also means that it's kind of harder to do the right thing a little bit because you need to configure a bunch of things. It doesn't just kind of work, you need to choose an implementation, choose a type. And so the proposal here is to basically get rid of this generic inside of client and have a client just be a client and nothing, be generic over its inner connection type and then have that essentially be an enum internally in the client.
03:15:07.290 - 03:15:40.940, Speaker A: For what kind of connection do we truly have so that the user doesn't have to think about it. And there's been a lot of debate about exactly how we should do this and it ended up like we needed to. This is, this has been going on this pr for like a year, a year and a half. And so we've constantly have to like rebase it on top of other changes to the library. At the core of it is essentially dynamic dispatch. Like we have a trait that implements the things that we need and then everywhere we just keep a. Let me see if I can dig this up.
03:15:40.940 - 03:16:21.650, Speaker A: I don't have an example of this right now, but we basically keep a connection which is like a box din of box din of this thing. So that allows us to read and write and I do things like set timeouts on the connection and that way. Yeah, down here boxed in IMAp connection. And so that way we're just doing dynamic dispatch, which is usually okay anyway because when you're doing I o like this, you're not really, you're not compute bound, like you're not bound by whether you're doing monomorphization. The I O is the bottleneck. And so it's okay to use like type erasure here. The boxed in is not going to have a meaningful performance impact.
03:16:21.650 - 03:17:06.110, Speaker A: But doing a incremental review of this I don't think I'm gonna do on stream because there's as you can see like a lot of context to catch up on. So I'm gonna leave this one as unread for now. All right, let's do one more and then I need to go have lunch. Two more. Because that I think is just a user request that might be easy to deal with. Haphazard has a lot of context to it so I'm going to ignore that. This is for my configs, which we can ignore this.
03:17:06.110 - 03:17:36.628, Speaker A: I kind of don't want to deal with those right now. Differential output tooltips are okay, fine, we'll take these. All right. And then those are the last three we're gonna take today. And then I'll have lunch. What is your criterion for doing things on screen or not? There's not really a criterion. It's more that I need to eat and so I don't want to take anything.
03:17:36.628 - 03:18:52.400, Speaker A: I don't want to do anything now that I know is going to take a while because then I won't eat for longer. It's currently 02:00 p.m. where I am so it's way past lunchtime. Do you think cargo will get support for custom testing frameworks? I hope so, but it's something we've been wanting for a while and it's actually kind of tricky to land something that works well. Yeah, I can see YouTube chat returning prototype array shows in console log but nothing from Println. Okay, where do we have execute? See that in the chrome debugger after I click the icon. Empty result lines from the funticini.
03:18:52.400 - 03:20:44.560, Speaker A: Oh, who knows, man be all sorts of things. I don't think this is a bug. In Fontacini, it might be a race condition in the code where the value is empty by the time you get to the return. It might be that the value is empty at the time of the return, but by the time you look at the console, it has resolved. Next thing to do would probably be to enable debug verbose mode in your webdriver to see what actually goes over the wire. And I'm going to close it because this is a support request. Okay, these are talking about differential outputs in the flame graphs.
03:20:44.560 - 03:21:45.860, Speaker A: So differential flame graphs are. Let me see if I can pull up an example of them. Differential flame graphs. Is there an example of these in here, though? That's what I want to see. Okay, so a differential flame graph looks like this. So the idea is that you give in, you give in two flame graphs, one, or you're given two collapsed, really, one before and one after. And the flame graph that gets rendered shows you how much faster or slower each stack got.
03:21:45.860 - 03:22:26.300, Speaker A: So like this is showing you that main got, or whatever that red line is got this much slower than the other thing. They can be a little hard to read, which I think is what the point here is. So if you have something where base only both. Okay. Modified. So this is the before and the after. Right.
03:22:26.300 - 03:23:23.760, Speaker A: So when you generate a differential flame graph for this, there are like tooltips over each little bar that shows you the backwards looking. Oh, I have to page a lot of this back in. I think backwards looking is. I don't know what they mean by backwards looking. I think it's whether you take this as a and this is b or this is b and this is a. Okay, so what actually happened here? What actually happened here is that base only went down by 50 units, so it went down by 100%. Both ones stayed the same.
03:23:23.760 - 03:24:12.170, Speaker A: Both two went up by 25. So it really went up by 100% and changed only went up by infinite percent. Both 112.5%. Oh. Cause it's computing based on like the total number of samples, 1% overall time. But that's not what most people care about. They care about absolute change.
03:24:12.170 - 03:24:58.566, Speaker A: Yeah. A reasonable semantic is multiplier from old to new, consistent across both directions. The example above, base two be new equals two times old. Yep. And we need to know if you care about backwards compatibility. My feeling is the current behavior is useless enough that just removing it would be fine. Cause a separate bug.
03:24:58.566 - 03:26:00.870, Speaker A: But it looks like maybe the scaling factor option is broken. Oh, that's okay. So that's that separate issue. All right. I think you're completely right that this is confusing, and I like your proposal to make it multipliers instead and consists consistent across directions. Consistent inverted across directions. Totally fine with removing the current info and replacing with this better info.
03:26:00.870 - 03:27:27.318, Speaker A: Consider a diff of these two. Parent first child ten parent second child ten parent 230 and parent first child 32nd child 30. Parent 230 says parent two is unchanged even though it's actually gotten larger. Yeah, this is, that's interesting. Um, I wonder why this is also a good issue for someone to try to tackle. Actually, this is probably the, just a simple bug somewhere in the collapsing code. Let's go see if we can spot that real quick.
03:27:27.318 - 03:28:54.060, Speaker A: So that's over in source differential mod. Then it's somewhere over here in write. Stack it. Hmm. I think I need to see what the diff produces here. So if we do all Prof. And we do new Prof.
03:28:54.060 - 03:30:01.610, Speaker A: And then we run for node, if folded, what do we get out? 30 to 30. Ten to 30. Ten to 30. Okay, so that seems reasonable. So then it's going to be in the, in the actual flame graph generation. Yeah, it's over. I think I know what's going on.
03:30:01.610 - 03:30:49.350, Speaker A: I think I know what's going on. It is when we, so when we render these, what we do is we're sort of accumulating data as we want. So you can't render parent until you've rendered both the child or until you've parsed both the children, because the children tell you how large the parent is. But I think when we render the parent, we only keep the sample number. We don't keep the, we don't keep both numbers. And I think that's up. It's under merge, actually.
03:30:49.350 - 03:32:09.256, Speaker A: Frames and samples differential. Okay, so here we have a delta and a max. We split by semicolon, and then we call flow and we pass in delta. Okay, so in flow, where's flow? Flow, delta, remove common prefix. Oh, right. This is like a super funky algorithm here for dealing with these files, because you like, detect whether you have a common prefix with a previous that you parsed. So here you detect that the prefix, there's no shared prefix between this and the line before.
03:32:09.256 - 03:32:42.830, Speaker A: And only at that point do you emit the contents for parent two. And then when you get to here, you notice the shared prefix is the same between parent. Between the previous line and this one. So only here do you emit the stack frame for first child, and then you emit the stack chain for second child when you get to the empty next line. And similarly, that's also when you generate the frame for parent. So there's like a. Yeah, this is where we look for the shared depth.
03:32:42.830 - 03:34:03.640, Speaker A: We iterate onwards from where they share. It could be here, could be wherever this thing is. Where's the thing when it closes? Something I'm missing here. Where's flow mutable temp immutable frames? Okay, so frames. Ah, yeah. So this is where it loops over all the things that are previous to where we are. Yeah, it's in here where we need to add to the delta knots that I'm pretty sure it's this one.
03:34:03.640 - 03:34:49.840, Speaker A: I'm not going to try to actually fix this right now, but I might be able to point this person in the right direction some more. I think this isn't the rendering, but the actual diff collapse computation. Specifically. I wonder if it's related to this comment. Okay, done. I think that's where I'm gonna stop for now. We, we're down to 91.
03:34:49.840 - 03:35:24.834, Speaker A: That's pretty good. I need to go eat so that my brain will work again. But I have, as you can see, I have more open source stuff to catch up on, so I might just, I might start just doing more of these whenever I want to continue to catch up on notifications. If you all found this useful. I mean, there are a bunch of you here, so I guess I'll ask you all, do you think this was useful? Because we've been going through a bunch of different random projects, doing all sorts of different things, mostly smaller tasks and keeping up. But was it interesting, useful, helpful, inspiring? Then let me know. Okay.
03:35:24.834 - 03:35:47.260, Speaker A: Some people seem to think that it was twitch. People do. Which means YouTube people will tell me in about 10 seconds. Okay, I'm glad to hear it. Well then I will try to do more of these going forward when I have to catch up on open source stuff. I probably won't do it again after lunch. I need to, my brain needs to relax.
03:35:47.260 - 03:36:05.060, Speaker A: But there will be more of these at some point in the future. Okay, thank you all. Thanks for coming out. I hope that was interesting. And if you're watching this on demand, maybe there's also also another one of these that's already out. Otherwise. I'll see you later.
03:36:05.060 - 03:36:06.280, Speaker A: Bye.

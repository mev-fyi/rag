00:00:06.760 - 00:00:27.010, Speaker A: Hello, folks. Welcome back. It's been, it's been quite a long time since last stream. I did my thesis defense, which is up on YouTube. I'll put it in one of these corners as, like, a little YouTube card. But apart from that, I haven't done, like, a coding stream in quite some time, and even this one. So this will be a.
00:00:27.010 - 00:01:14.730, Speaker A: A crust of rust stream specifically, so it'll be a shorter stream where we'll be talking about sorting algorithms. In rust in particular, we'll try to implement a few of them. And the reason I wanted to do this specifically is because sorting algorithms are something that you come across in all sorts of languages. People use them for coding interviews, even though it's a terrible idea and you shouldn't do that. But even, just like in almost every CS education, you learn about them in all sorts of language tutorials, you learn about sorting because are so common and, like, it's unclear whether they're useful. Like, it's very unlikely you'll actually have to implement your own sorting algorithm for anything real that you build. But the fact that they're so common means that they're a good comparison point between languages.
00:01:14.730 - 00:02:32.936, Speaker A: And so the purpose of this crust of rustream isn't really to teach you sorting. You can read up on these algorithms on your own. Instead, the goal with this is to show you how these algorithms would be implemented in rust in a sort of idiomatic way so that you can compare that to languages you might be familiar with. And then over the course of that, my guess is that while implementing these algorithms, we might end up sort of stumbling over a bunch of different interesting rust topics. So, unlike some of the previous streams where I've been focusing on a particular rust feature, this one is more focused on a broader set of problems for us to sort of code up and then see what we learn along the way. As before here, I'll sort of take questions as we go, because it might be that there are things, there are features of rust that I use while we're doing this that you are curious about and want to see how work or why I did it that particular way, I will say so. I took a poll on Twitter as to whether this should be the topic of the stream, or whether I should do another stream stream topic, which is specifically implementing an improvement to a concurrent data structure.
00:02:32.936 - 00:02:58.898, Speaker A: I maintain I'm going to do that one, too. That'll be a longer coding stream. That will probably happen in a week or two. I'm not quite sure yet. All right, so let's, let's dive into this. And, and we can't really start the discussion before we talk about the or trait. So the or trait in rust is the way that you expressed types that be can be compared relative to one another.
00:02:58.898 - 00:03:35.694, Speaker A: Now, if you look at the ord trait, you'll see that or requires that the type is eek. So eek is sort of complete equality and partial or. And partial order is a partial ordering. It says that the type is partially ordered, and you see that partial or is generic over the thing that it can be compared with. So, for example, you imagine that some type can be compared to many other similar types. So, for example, a U 16 can be compared to a U 32. And so therefore, there's a.
00:03:35.694 - 00:04:29.510, Speaker A: It is possible to order them relative to one another even though they are not the same type. And that's what the parameter to partial or here is for. Or you'll see that it actually requires that you implement partial order of selfdevelop. And if you read the description of ord a little more, you see that the requirement for specifically is that the type forms of total order. And you can see the exact definition here, but basically, the way to differentiate between or and partial or is a partial, or might say for some two elements, these do not have a relationship to one another. Like, is the string 42 greater than or less than the number eight or the string foobar? Or the number eight is one greater or less than the other? It's. It's unclear, right? They don't really have an order.
00:04:29.510 - 00:05:13.790, Speaker A: With Ord. You require that a given type must be comparable with itself, of course, but also you require that comparison to basically always have an answer to the question is, is a greater than or less than or equal to BDE? It can't just say it must always have an answer. That's roughly what total order means. Total order also requires that things are transitive, but this is not a property we'll really avail ourselves of here. The reason that we're using or instead of partial or for the purposes of sorting is because if we did partial or. It's really hard to order a thing if the order of some things in that set doesn't matter. And so we're actually going to use Ord.
00:05:13.790 - 00:06:06.348, Speaker A: This does have some weird properties, because there are certain types in rust that you might expect to be orderable, but are not specifically the floating point number types. Those implement partial or, but not ord. And the reason for this is that floating point numbers also have this, like, ah, the name escapes me now, but they have a special value nan, not a number, which is used to express sort of floating point operations that don't have a well defined answer. And those, if you have a nan and compare it to some other floating point number, it's unclear how they relate to one another. So f 64 and f 32 do not implement ort. Yeah. Floats are also not eek for the same reason.
00:06:06.348 - 00:06:59.350, Speaker A: Specifically that if you have two not a numbers, they're not equal one another, which is weird, in which it's weird for two things that are equal to not compare equal, but it's because not a number. If you do one mathematical operation that gives nan and another mathematical operation that gives nan, they're not necessarily the same nan. That's why it works that way. Okay, so we're going to be relying on the Ord trait. And if we scroll up here a bit and look for sort of sort methods, you see that there are a bunch of sorting mechanism mechanisms already implemented for you in rust. The prime of these is if you have a slice you can call sort and requires that the t is ored, and it just sorts the slice in place. Now, you'll see here that it says the sort is stable.
00:06:59.350 - 00:08:14.970, Speaker A: If you're not familiar with sorting algorithms, a sort that's stable just means that if you have two elements in the list or in the. In the slice that are equal, it won't swap them while doing the sort. This might seem like a property that's weird to care about, because you might think, if, if I have a list of numbers and two of them are eight, why would I care whether it rearranges those eight or not? And it's true that for sort of primitive types, this rarely makes a difference. But you can imagine you have some complex type that, where you have two elements in the list that compare equal but are not the same, and you actually care about the ordering because, say, one happened before the other in some other sense, but they are equal as far as sorting is concerned, and you don't want them to be reordered. In general, sorts that are, you sometimes pay a little bit more for a sort that's stable, because the sorting algorithm is more constrained in what operations it can do. You'll see that there's a sort unstable as well, that does not have this guarantee that it's stable, and that allows, allows it to either use less memory or be faster. So we'll look at that.
00:08:14.970 - 00:08:52.370, Speaker A: You'll see also that there's a note here about the current implementation, and the current implementation is an iterative merge sort inspired by Tim sort. I don't know where that will necessarily be implementing the rust sort function, like the specific implementation they have. We might get to look at Tim sort. It sort of depends on how long the other things take. I'm not sure yet. You'll also see that there's a sort by. So the idea here is that sort is if you have a slice of elements, you just want to sort directly.
00:08:52.370 - 00:10:03.930, Speaker A: Sort by is if you have a slice of elements where you want to sort them by a custom comparison function. So one example of this might be that you only want to sort them by a field of that struct rather than the full struct itself. It might be that you want to do a reverse sort, right? You want to sort it backwards, in which case you sort of want to do the standard comparison between the elements, but sort of flip the result. Doing a reverse sort is probably the most common use of sort by. This is also sort by key, which is specifically for the case where you want to sort by a field or something like that, where you just provide a function that maps from the type in the slice to some other type that is itself orede, and then it sorts by that, by whatever that that function returns. Ultimately, we'll probably just implement sort, because all these other ones are expressible in terms of what we implement with sort. And what we're going to do is essentially define a sort trait, and then we're going to implement that trait using a bunch of different sorting mechanisms.
00:10:03.930 - 00:10:57.884, Speaker A: And there are a lot of them. So here's the Wikipedia page on sorting algorithms, and you'll see that, like, there are a lot of them and they have fairly different properties. Some of them are just straight up bad. And but many of them, there's sort of a trade off between, you see here whether they're stable, how much memory they use, their average complexity. So this is, how many comparisons does it need to do for an, for, if you like, took every possible slice, if you will, how long would it take on average to sort it? Where n, here is the length of that slice. The best case is what is the fastest it can possibly run. So it might be, for example, that for certain algorithms, if the slice is already sorted, they do, they just walk the list and check that it's sorted and then do no work.
00:10:57.884 - 00:12:02.190, Speaker A: So that would be the best case is sort of the fastest it can run the best case input. And the worst case is like, imagine that the slice was, was adversarial, adversarially ordered before you called sort, what is the longest the algorithm might take? And of course, you want an algorithm where the, the worst case is as good as possible and where all these values are as good as possible. But ideally, like the best case and the worst case are the same as the average case and the average case is low. And you'll see that in general, it tends to be that the best you get to is n log n for the average. And there's some mathematical reasons why that Sort of has to be the case. But you see that some of them have a best case of n, which is usually the fact that if they're, if the slice is already sorted, these algorithms do very little work. But you see the, the worst case often gets quite bad, right? Like n squared is a very large number, whereas n log n is not that large.
00:12:02.190 - 00:12:43.102, Speaker A: So I think what we're going to do is walk this sort of in terms of the order. You tend to learn about these things. So we're going to start with everyone's favorite bubble sort. And bubble sort is real stupid. Like, it's not very good in terms of complexity. Its average performance is n squared, which is not great, but it is very, very straightforward, and I'll show you why. The other thing I want to do on the stream is sort of implement a very simple benchmark for these that just counts the number of comparisons that each algorithm makes and then prints that out.
00:12:43.102 - 00:13:29.700, Speaker A: So it prints sort of the length of the input and how many comparisons each algorithm did for that input. And then we should be able to very easily see just how much work, how much more work one is than the other. Bubble sword is real stupid. Yeah, it's true. All right, so let's do a cargo new, I guess, lib, and we're going to call it. What are we going to call this sorting library? We're going to call it descending. See, it's gonna sort in ascending order, but descending is a funnier name.
00:13:29.700 - 00:13:42.168, Speaker A: Bogosord is pretty great. Sortify. Sorta. Fy is also very funny. Oh, sort the letters in sort. That's good. I like that.
00:13:42.168 - 00:14:22.700, Speaker A: So that's what, o r s t, right? Yeah. Or that's great. I love that it's sorted. All right, so here's what we're going to do. We're going to mod bubble sort and we're going to have a trait here that's going to be just sort. Or I guess actually we're gonna have a trait sorter. And the sorter is going to be given a.
00:14:22.700 - 00:15:39.040, Speaker A: I guess actually this is going to be an instance method because the sorters themselves do not, we don't expect them to have any state. So sort is really just going to be given a, a t and it's going to be given a mutable slice of t where t implements ord. And I guess this is going to be the slice. And then what we can do is we can have a sort function if we wanted to be really fancy, right? We have like an extension trait on slice that lets them lets something sort using a sorter. I think instead what we're going to do is just have a freestanding sort function that people can call. And so this is going to take a t and an s and the slice is going to be a mute t where t is ordezen and s is a sorter. And all it's really going to do is do s, colon, colon, sort.
00:15:39.040 - 00:16:23.590, Speaker A: This is our public function and this is our sorting trait. And then now all we have to do is implement the sorter trait for each of our algorithms. And I the, we can just call sort on whatever we wanted. And of course we could have here the sort of, what are we going to call this? Like type. Actually let's go down here and write this as a test. So we're going to have a struct standard sorter and we're going to implement sorter. It's going to be fine.
00:16:23.590 - 00:16:57.720, Speaker A: We're going to implement sorter for standard sorter. I used to have a, I forget what the implementation of this was. Coc command. No, coc action. Oh, that's too bad. I used to have it set up so that I could just like press a hotkey for automatically adding the methods for the trait. But I forget what the hotkey is and I don't want to look it up because it takes too long.
00:16:57.720 - 00:17:29.580, Speaker A: How much harder would it be to implement these for iter? Iter mute. It's actually much harder to do it for iter because you don't know how many elements you're going to get. Like realistically, it's really hard to, it's fairly hard to sort of stream. It significantly limits what algorithms you can use unless you collect the stream into a vector and then you sort the vector. Right. So it's unclear. That buys you very much.
00:17:29.580 - 00:18:37.890, Speaker A: And this is why in the standard library too, you generally see sort on, on slice. And all this is really going to do is just call slice sort. Right. I guess here we have to use super, right. So we're ever going to have a test here that checks that I guess we're going to have like things is going to be a vec of 4231 and then we're going to call things dot. Actually, we're going to call sort of mute things and we're going to do that with the standard sorter. And then we're going to assert that things is now equal to 1234.
00:18:37.890 - 00:19:08.020, Speaker A: This is sort of a sanity check that the setup we have is roughly right. So let's CD into Orst and run cargo dust. Oh right. I don't have bubble sort yet, so let's comment that out. How's the font size? Do you want it to be smaller? Yeah. Random access is also very useful in sorting. You basically need that.
00:19:08.020 - 00:19:40.000, Speaker A: So you could use exact size iterator. You would then know how many elements to expect, but ultimately you would need to have all of them before you could really start sorting them in a reasonable way. Right. The challenge is that the later elements might end up shuffling a bunch of things around. You'd basically be forced to do sort of something like an insertion sort, which is pretty bad, a bit smaller. All right, let's do that. Better.
00:19:40.000 - 00:20:12.290, Speaker A: Let's do that. All right, so that works for us. So now let's go and implement bubble sort. Actually, let's do, do we want to call it bubble sort or just bubble? Let's do bubble sort. That's fine. So we want to use super sorter. We want us sort of pub struct bubble sort.
00:20:12.290 - 00:20:53.660, Speaker A: And notice that these are all, these are all just unit structs because the sorter itself doesn't have any state. You could imagine that the sorter had like configuration that was stored in it, but it doesn't really have state. Why does Vim say object object in the status bar? I'm not sure. It might be that I have my rust analyzer is outdated or something. It definitely normally doesn't do that. I also don't know why it says like a heart rust analyzer. I think like something in my setup is broken, but who knows why.
00:20:53.660 - 00:21:40.116, Speaker A: Alright, so we're going to implement sorter for bubble sort. And let me just copy that method from over here. And so this is the thing that we have to implement. Right. And so the question is what goes here? My chat window is like no longer auto scrolling, which is pretty annoying. Um, I have coc set to a stand, um, manually compiled rust analyzer because I want to run it on like the latest nightly. Um, okay, so bubble sort.
00:21:40.116 - 00:22:47.340, Speaker A: Bubble sort is a real stupid sort where all it really does is, um, it just walks the array and swaps anything that's out of order. You may be familiar with this already. So what we're going to do is sort of, we're just going to have a loop. We're going to set swapped equals false at the top of the loop. Then we're going to walk all the elements of the slice and this is just going to be zero to slice len. And if slice I is greater than slice j, then we're going to just do slice dot swap in j and set swapped equals true. In fact, we can do this while swapped swapped equals false.
00:22:47.340 - 00:23:31.770, Speaker A: Alright, so this is why people love bubble sort. It's not quite correct yet. It has some boundary problems that we're gonna have to fix. But bubble sort is really, really just, it's really straightforward to implement. Oh man, why is this? There we go. So all we're going to do with bubble sort is just walk the slice and anytime we see something be out of order, we're going to swap them and we're going to keep doing this until we've walked the whole thing and we never had to swap anything. Right, very straightforward but also super slow.
00:23:31.770 - 00:25:06.270, Speaker A: You'll notice that there's a, there's one challenge here which is that I plus one might be out of range. And the way we deal with this is just if I is slice dot len minus one, then we continue. And the reason, the reason for this is because we, when you're looking at the last element, there's nothing for you to compare it with and it's already become compared with its predecessor because that was when we were at I minus one, which actually means that we can just do this same thing and now this will always be in range. Right, so is this going to stop on the first swap? No. So while we, we continue, while we have swapped something, right, and we keep setting swap to true whenever we do do a swap. And so we're going to keep looping until we have walked the whole thing without setting swap to true, at which point the while will end. I mean we can check this, right, so down here can have a little test.
00:25:06.270 - 00:25:51.566, Speaker A: It works. And this will use the bubble sort, super sort. And in theory, if we run cargo test now, great, bubble sort sorts, we can, even if we wanted to make this sort of be an odd length and see that it still sorts. Why is my chat not auto scrolling? This is really awkward. Don't quite understand what's going on there. Let's hope it just fixes itself. Oh yeah, you're right.
00:25:51.566 - 00:26:21.632, Speaker A: If we wanted to. We could do one to slice len and then do like I minus one to I. This has the same effect and is maybe shorter. Unclear that. It's nice. The YouTube stream delay is real slow. So slice swap is sort of the thing that's kind of interesting here.
00:26:21.632 - 00:26:56.546, Speaker A: It means you don't have to read out one and then set the other and then set the other back. Like you don't need a temp variable. And I think internally it does use mem swap. Right. So why does this require the underscore? This requires the underscore because we have two type parameters to this function. One is the type of the thing we want to sort and the other is the sorting algorithm. The only thing we could really do here is we could make these be reversed.
00:26:56.546 - 00:27:34.354, Speaker A: The problem is that here, because we're trying to name the, we're trying to nape the sorting type here, rust won't let you. If you're going to name the generic parameters, you have to enumerate all of them. You can give underscore for the ones that you don't want to name and have it be inferred by the type system, but you do have to put placeholders for it. Oh, this is extremely annoying. Let's see if this helps. Okay, so we have bubble sort. Let's move on to the next sort.
00:27:34.354 - 00:27:57.738, Speaker A: Let's go back here. So we did bubble sort. Bubble sort is really bad, but it works pretty well. And in, in the sense that the implementation is very straightforward. Our next contender, this then is insertion sort. Insertion sort is also, as it says, it is much less efficient on large lists than more advanced algorithms. But it has a simple implementation.
00:27:57.738 - 00:28:31.900, Speaker A: Love that. All right, so what is the algorithm for insertion sort? Well, insertion sort is. I won't make you read all of this, but it might be easier to show in code. Insertion sort. Insertion sort. And let's just copy all this in here. So insertion sort is also fairly straightforward.
00:28:31.900 - 00:29:15.384, Speaker A: The strategy we're going to take here is that we are going to sort of keep. We're going to divide the slice into sorted and not sorted, where the sorted part is sorted and the not sorted is not sorted. And sorted is initially empty. Not sorted is initially the entire list. And then we're going to do is we're going to take one element from not sorted and we're going to place it in the correct place in the sorted list. And then we're going to do that until there are no more not sorted left. Why not sorter sort directly without the freestanding function we could do that.
00:29:15.384 - 00:29:47.524, Speaker A: So we could do like insertion sort, sort mute things. This also works and is sort of nicer. The downside of this one is that you need to have the sorter trait in scope. So this will only work if you have a use sorter. Sorter, I believe. But you're right, it is, it is a lot nicer. That's fine.
00:29:47.524 - 00:30:27.384, Speaker A: It obviously doesn't sort yet, but you're right, this is much nicer. Let's do that instead. And I guess we'll do it in lib two, the s not being capitalized. Yeah, fine. We can do that. I guess let's do that for bubble sort as well. All right.
00:30:27.384 - 00:30:56.470, Speaker A: You happy now? It can't be partial eek because partially it doesn't let you order things. And it can't be partial ord because as I mentioned at the beginning, you can't really order a slice if some elements just say meh, I don't know what the order should be here. And it's sort of unpredictable which ones. Right. Sort doesn't look like a word already. I know. Right.
00:30:56.470 - 00:31:26.816, Speaker A: Okay. So you iterate over search result in vim with the n key. So what we're going to do is sort of have a, some, some threshold. I, let's say that is unsorted and unsorted is initially going to be zero. So the idea is that everything beyond unsorted is going to be unsorted and everything before unsorted is going to be well sorted. And in fact, what we can do is we can immediately start this as one. Right.
00:31:26.816 - 00:32:13.860, Speaker A: Because a list of one element is always sorted. We don't have to sort that first element. So what we're now going to do is we're going to walk all the elements we're going to say for unsorted in one, two sorted Len. So we actually need to keep this as a variable because the iterator variable. Oops, slice dot, Len. Because the iterator variable can, can keep track of where that index is already. And at this point, slice unsorted and onward is unsorted, is not sorted.
00:32:13.860 - 00:33:22.094, Speaker A: Take slice unsorted and place in sorted location in slice up to unsorted. That roughly makes sense what we're planning to do here. And this is a little weird, right? Because imagine that, that you have like, let's say that it looks something like this, right? So we have one, two, three because everything before there is sorted and then one, three, four, and then the last element is two, right? So now we're going to pick up the two and we're going to place it in sorted in the right place. So the two needs to go here. That means that everything else has to be shifted over. So there are a couple of ways you can do this. The easiest way to do this is just to keep moving the element you just took left until the next element is smaller.
00:33:22.094 - 00:33:40.798, Speaker A: Right. So what we do here is we end up removing the barrier, right. Because we're moving the element into the, into the sorted side. So it's going to go over here. I guess let's indicate that this way. And then we're just going to keep swapping it. Oops.
00:33:40.798 - 00:34:44.196, Speaker A: To, we're going to keep swapping it to the left until the next element is smaller than the current element. Right. So while slice I is unsorted, while slice I minus one is greater than I. And again, you'll, you'll recall this, I while I is greater than zero and that, and should say slice. Right. So we're just going to keep shifting it left until it no longer needs to go left. That just sounds like bubble sort going through an identity crisis.
00:34:44.196 - 00:35:09.830, Speaker A: So it's not quite right. So bubble sort is even worse than this because bubble sort walks the array and it just swaps things that are out of order each time. Whereas the insertion sort doesn't really swap everything. It doesn't walk the whole thing. Right. It walks backwards from the thing that you're now placing. And so it, it only does the swaps that it sort of needs to do.
00:35:09.830 - 00:36:04.980, Speaker A: And, okay, so you might wonder, okay, so some people are saying like, isn't this more of a bubble sort than an insertion sort? It's, it does have a little bit of the semblance of a, of a bubble sort. But what this is really doing is doing the shifting at the same time. Oh yeah, you're right. I minus equals one. So imagine that we just picked up this two and tried to place it here. What we would have to do is shift the remaining elements all over by one, right. And I mean, okay, there's an alternative way to do this, right, which is to walk the array until you find the location that you need to put it in.
00:36:04.980 - 00:36:51.102, Speaker A: And then like, mem copy all the things from that position forward, one over. And that would also work. It's a non overlapping mem copy, so it's not that efficient anyway, because ultimately what it ends up doing here, let me see if I can draw this actually here. Oh yeah. Insertion sort works a lot better if you're, someone mentioned this in chat, too. If the storage mechanism you have if it's not a slice, but if it's a linked list, then insertion sort is great because you don't need to do all this shifting over. You just find where it goes and you stick it there.
00:36:51.102 - 00:37:31.926, Speaker A: You just like if you have a linked list, right, you just pull them apart and stick it in the middle. The problem with a slice is that you need to move all the things over. So let me try to draw this out. So we have this list and it has a bunch of elements. It has 1342, let's say five, right? And it's sorted up to this point. And so now we're trying to move this barrier over to here, right. So what we're going to do is we're going to pick up, we're going to pick up the two and we realize that we have to move it to here.
00:37:31.926 - 00:38:32.662, Speaker A: Now there are two ways to go about this, right? One is to go over here, right? Like so one is to walk the list left to right until we find the slot where it has to go into, right. So it's like oh, it has to go here and then sort of store two somewhere to the side and then take these elements and shift them all right by one, right. So that's going to turn into this goes here and this goes here. So that's one swap, two swap. The other is what we currently implemented, which is swap this left, then swap it left again. So they both end up being two swaps. And the biggest difference between these is that this one walks from the left and looks at each element to the sort of left of the target location.
00:38:32.662 - 00:39:31.160, Speaker A: Whereas our swap goes from the right. It's, you don't know in advance whether walking from the left or the right is going to be more efficient because you don't know where this element is going to go. They're going to have slightly different runtime characteristics based on the data, but in terms of complexity they're the same. Would it be cheating to use binary search plus insert? Yeah, I mean we could totally do that. It is true that you can be more, you can be a little bit more efficient here with a binary insert to reduce the number of comparisons you have to do, it still has to swap all the elements. Right. So what's being proposed here is that like let's do like if not Smarteendez, then do this, else do this.
00:39:31.160 - 00:40:29.670, Speaker A: Smart equals false. Alright, so this one is going to use, use binary search to find index, then use dot insert to splice in I. So here what we have to do is do slice dot binary search. So binary search is a method that's provided by the standard library on slices, which gives you a type and a type that implements ORd and it's going to tell you where that item should go. Oh, my hair is being weird today. So if we do a slice dot binary search for slice of unsorted, this is going to give either an I or an I. Let me explain why these are different in a second.
00:40:29.670 - 00:41:21.990, Speaker A: And this is going to tell you where that value should go in slice, assuming that slice is sorted and it's going to use binary search to get there. So a binary search, if you're not familiar with it, is like you look at the, you look at the, if you have a slice is this long, you look at the element in the middle. And if the thing you're comparing is larger than the thing in the middle, then you now look at the middle of the second half. If it's smaller, you look at the middle of the first half. That way you do log n comparisons rather than n comparisons in terms of trying to find that location. And then we use slice dot insert. So if we pull back here for a second, this might give me really unhelpful.
00:41:21.990 - 00:42:02.092, Speaker A: Oh, that's only implemented on Vec. I think slice has a splice method. No, I think there's a. So the reason why maybe there isn't. Well, that's awkward. Yeah. So the reason why there's, so there's an insert method on vector and what it does is it does all this shifting for you.
00:42:02.092 - 00:42:49.320, Speaker A: So you say like, I want this element to go in position three and then everything beyond position three gets pushed over in the implementation by using some like smarter mechanism than just swapping. The reason why this is only implemented on vector is imagine that you told it, I want to stick this element here and pushing all of the remaining elements out ended up, you ended up exceeding the capacity of the vector, then it might have to reallocate, right. Allocate more memory so that those elements can fit. In this case, we know that that's not case. We, we wanted to overwrite the element like we wanted to sort of drop off the element that shifts to the right because we know that that is the element that we've picked up and are inserting. But slice doesn't have a method like that. So we would have to do all the swaps anyway.
00:42:49.320 - 00:43:36.310, Speaker A: So here we would do like, well, I don't even know that I want to write this code, but it basically would do this sort of swap loop except they wouldn't have to do the comparison. It would only have to do the actual swaps. You're right, this should be dot dot unsorted. So for that reason I think we're gonna just ignore the smart implementation for now. It's true that it would be, it would use log nde. Well n log n. It would be n log n instead of n squared, which would be good, but you still end up with n squared swaps.
00:43:36.310 - 00:43:55.510, Speaker A: So like it's still pretty costly. Like this is not the way to get better. Sorting is not to optimize insertion sort. Ooh, there's a rotate right. Ooh. Okay. So rotate right might work.
00:43:55.510 - 00:44:26.694, Speaker A: Slice, rotate right. Ooh, that's pretty good. In fact, then we can do even better. So let's use rotate right. So rotate right shifts all the elements in the slice over by one. But with a wraparound and this you can do without resizing because you're going to wrap them around. Right.
00:44:26.694 - 00:45:21.272, Speaker A: So we're going to slice everything over by one. But here what we can do is actually be a little sneaky. We can say we want to rotate everything right, starting from the target location and ending at the element that we're moving. And what that's going to do is it's going to shift all the elements that, that are before the element we want to put at the beginning or put at the eye we found over. That's going to cause the last element, which is the one that is currently unsorted to go to the front, which is the position that we wanted to end up in. Oh, is rotate right only on nightly? That's interesting. No, it's not a nightly.
00:45:21.272 - 00:45:41.974, Speaker A: Great. So we can use it. Okay. So that brings us to why does binary search return okay. And error, it returns okay. So, okay so imagine that you're, you have a list like 135, right. And then you do binary search for two.
00:45:41.974 - 00:45:56.682, Speaker A: Well let's do, let's do three first. And you do binary search for three. This is going to return one. Right. Because the three is at the one at index one. Right. I guess let's make these ABC.
00:45:56.682 - 00:46:21.388, Speaker A: It might be easier. ABC is bad ac B and we're going to search for c. That's going to return one. But you can also search for elements that aren't there. So if I search for b, this is actually going to return a. This is going to return error of zero. Let me just double check that.
00:46:21.388 - 00:47:08.208, Speaker A: I'm not lying to you. Sorry. Error of one. So this value is the, if you get an error, it's I didn't find an element that matched. But if you were to insert this element, this is the index at which it should be, right? So in this first case, it's, we found an element that has the exact same value, in which case we can put it before or after. It doesn't matter because it's equal. This would matter in terms of whether it's stable, but it wouldn't matter for the purpose of leaving the array sorted for the error cases saying this is where it should be.
00:47:08.208 - 00:47:37.882, Speaker A: Like all the preceding elements are smaller and all the succeeding elements, including the one I just gave you, are larger. And so those are all the ones we're going to shift over. So let's, let's see if this works. Let's do a test run. Okay, so with smart equals false. What about with smart equals true. Great.
00:47:37.882 - 00:48:20.240, Speaker A: So both the smart and non smart version works. So this is where we can actually have values on this, right? So we can say smart. It's going to be a bool, although that would mean that sort has to take. So we actually need to change our sort sorting implementation a little bit here. We need to say that the trait takes a reference to self, which means that let's have this just go away. This is going to take a self and just not use that parameter. This is going to do that.
00:48:20.240 - 00:49:08.244, Speaker A: And for bubble sort, this isn't going to make a difference because we don't really have a configuration for it. It takes a self parameter, but it doesn't use it. And this becomes bubble sort. So the change here from a double colon to a dot is that previously it was, you can think of it as like a class method from other languages, but it used to be an associated method of this type of, whereas now it is a method of the type. So now actually we're constructing a bubble sort value and then we're calling the sort method on that value. And these are different. What happens if you binary search on an unsorted slice? You basically get a random index.
00:49:08.244 - 00:49:45.352, Speaker A: It's not quite random, but, but essentially. And now for insertion sort. What is nice about this is that we get a self. And so now down here we can say if not smart, and if smart. Some people are asking whether there's a better way to write this match. I don't think there's an easy way to like unwrap both and assume they're the same type. You could probably do, you could do this with unwrap or else.
00:49:45.352 - 00:50:27.340, Speaker A: So you could do unwrap or else I, this will do the same thing. But, but I like the fact that this actually documents what the two branches are. So you don't actually need to use a match here. Right. Like let me write it down here. It might be cleaner than trying to see it all the way to the far right unwrap or else I, I it's the same thing. But, but I prefer this version because it's more explicit in terms of like how it performs is probably about the same.
00:50:27.340 - 00:51:11.590, Speaker A: All right, so now we have insertion sort. We have an error somewhere. Right. This has to be dot smart is true. It works dumb and it works smarteen. Great. Isn't the static function when you don't need an instance of the object to call that method? Yeah, so you can think of it as a static method.
00:51:11.590 - 00:51:43.050, Speaker A: In the future. You'll also be able to do this with or let patterns, which I think someone mentioned in chat too. So you'll be able to write soon. And I'm very excited for this is you'll be able to write this whatever, like slice, unsorted, et cetera and the same. And it basically lets you do so you can already or patterns. Right. So you could write this as this.
00:51:43.050 - 00:52:11.300, Speaker A: You can already have or patterns in match statements, but you'll be able to do it in let statements too, which is really neat. Oh, the PhD mug. Yeah, my girlfriend got me this after when I graduated. So it says doctor Jang set on one side. Oh, maybe can't see it. And then it says fucking done on the other side. It's great.
00:52:11.300 - 00:53:03.132, Speaker A: All right, I insertion sort. Let's move on to selection sort. And actually this time let's copy insertion sort to selection sort and insertion to selection. Alright, so selection sort, I guess let's go back to the wikipedias. A selection sort is also n squared, so it's inefficient. It's generally worse than insertion sort, but it is very simple. One thing that is nice about selection sort is that you can do it like entirely in place.
00:53:03.132 - 00:53:33.490, Speaker A: You don't need to use any additional memory. And when I say additional memory, what I mean here is that behind the scenes when you're doing this like swapping, you often have to like store something to a temporary variable. And in general that just like doesn't matter. Like you have to store something of size t in addition and you store it on the stack. But there's some cases where you're so memory constrained that you just can't store extra elements. And with selection sort you don't actually have to do that. So the idea behind.
00:53:33.490 - 00:54:13.546, Speaker A: The idea behind selection sort is that we're actually just going to walk. We're going to, we're going to pick this, you're going to find the smallest element of the list and we're going to stick at the front. Then we're going to find the smallest element in the remainder of the list and we're going to stick it at the front. And then we're going to find the smallest element of the remainder of the list. And we're going to stick it at the front and then at the end. You've now sorted the array, right. So obviously this is super slow, but it doesn't use any extra memory and it's fairly simple.
00:54:13.546 - 00:54:44.250, Speaker A: So let's look at what this looks like. So we're going to do for unsorted in one to slice. And just like with insertion sort, we're going to keep the prefix sorted and the suffix is not sorted. But here the implementation we're going to have is going to be a little different. Selection sort does not have any arguments. It is in some sense always dumb. Obviously these tests are bad.
00:54:44.250 - 00:55:15.020, Speaker A: Like, this should be like prop test or something, because this is entirely stupid. This only tests a particular case. Whereas with something, a prop test or quick check or something, you could actually have it generate arbitrary vectors and make sure that they all end up sorted. You can also swap with XOR, as chat is pointing out, but for something like the rotate. Right. You can't necessarily, or it gets really convoluted if you wanted to do with just xors. So usually you end up using temporaries.
00:55:15.020 - 00:56:31.530, Speaker A: All right, so our plan here is going to be smallest in rest is going to be the sort of if we really wanted to cheat here, right, we do slice unsorted to the end min and this is going to be. Yep. And then we're gonna slice dot swap unsorted with smallest in rest as this. I guess this should not be min, but like the min I. Fine, we'll do this the slow way. So smallest invest is going to be. We're going to assume that it's the current element and then we're going to walk the, the rest of the list for I in unsorted to slice len.
00:56:31.530 - 00:57:24.640, Speaker A: Technically this is going to be plus one. And if slice I is less than smallest in rest, then smallest in rest is going to be I. And if unsorted, not equal to smallest and rest, then we're going to swap them. Huh, that's nice. Yeah. So this, what we're doing here, we can start from one. We don't have to start from zero because the slice of length one is always sorted.
00:57:24.640 - 00:57:45.600, Speaker A: Oh, you're right. It's not. It has to be the smallest element. You're completely right. This is different from insertion sort in that we're going to be moving, we're not going to be moving elements to the appropriate place in the slice. We're going to assume that it always is the largest of the sorted. So think of it this way.
00:57:45.600 - 00:58:38.530, Speaker A: The smallest in the remainder is going to be the largest of the thing that's sorted. And therefore we need to make sure that the first element is the smallest of the whole slice. And that's why we can't just assume that the first one is already sorted. And so here, what we really do is we just walk the whole list and continuously check for the smallest element in the remainder and shift that to the beginning of the remainder. And then we keep shrinking the remainder. What I was looking for earlier is, I think there is a, let's see, unsorted. So there's a, there is a, I think this rest analyzer is giving me the wrong thing here.
00:58:38.530 - 00:59:13.408, Speaker A: I guess not. I was pretty sure there was a min, but I guess not. Oh, it's on iterator. Yeah. So slice is an iterator, right. So you can call dot min, and that gives you an option, smallest element. The reason it's an option is because the slice might be empty, but this gives you the smallest value, not the smallest index.
00:59:13.408 - 01:00:16.540, Speaker A: Now, we could, in theory, do this with some, like a little bit of magic wrapping by using the enumerate function on iterator. So I might as well show that too. So a sort of different way. Let's do, or is to do dot it, er, dot enumerate, dot min by key dot unwrap, or I guess expect slice is non empty. So this is smallest, smallest in rest. Actually, this is going to be the I and the value, and we're going to have smallest in rest be the index. Right.
01:00:16.540 - 01:01:37.062, Speaker A: I'll explain this code in a second. No, that's almost certainly a lie. Why is that failing? Uh, lifetime may not live long enough. That is very interesting indeed. Wait, I need to see this error properly from cargo. Oh, that's why. Okay, so what we're doing here is, and the annotations from rust analyzer are actually going to be a little bit helpful here.
01:01:37.062 - 01:02:24.256, Speaker A: So we take the remainder of the slice, right. Everything from unsorted and onwards, we create an iterator. Over it we call enumerate, which is a method on iterator. That changes the iterator from b just over the value to being an iterator over the index and the value. So a tuple of index and value, and then we call min by key, which gives us the smallest, it walks the entire iterator and it gives you the smallest element according to whichever value you get from calling the provided closure on each element. And in this case, what the closure does is it fishes out just the value, right, because every value in the iterator after enumerate is a tuple of the index and the value. And we only want to find the minimum by the value.
01:02:24.256 - 01:03:08.452, Speaker A: We don't find the minimum by the index, for example. And so we fish out just the value. And this technically gives an option back because, well, it's, it has to, because the iterator might be empty, but we know that it's not empty, so we can expect. And the, the lifetime issue I was seeing was because min by key gives you a reference to each element. And the reason it gives you a reference rather than the element itself is because min by key is going to walk all the elements and then return one to you. So it can't give ownership into this closure. But v is also a reference itself, and it's a reference into slice.
01:03:08.452 - 01:04:32.338, Speaker A: And the reference to the tuple only lives for the duration of the iteration because it's an reference to a value that was yielded by the iterator. But what we're trying to return is a reference into slice, right? And after the iterator returns the iterator values, which is what this reference is, the iterator values no longer live, so we can't return it. And that's what the compiler was complaining about. So what I'm doing here is I'm telling the closure to dereference the tuple and then fetch out the v, as opposed to giving a reference to the second element of the tuple. This might be easier to show if I just said min by key gets a t. And previously what we're doing were, was the way I was writing it, right? I wrote it as just this, and the compiler was complaining, right? This was an error, because what I, what that is equivalent to doing is this, right? So that gives that same error. So this is clearly a reference to the tuple itself.
01:04:32.338 - 01:05:37.200, Speaker A: It's not a reference into slights, it's a reference to a reference. And by rewriting it to be this, what I'm really saying is this, think of it as an ampersand in a pattern is the same as a removal of an ampersand in the value is one way to think about it. And smallest in rest here is also going to be an index into this slice, which starts at unsorted. So we actually need to adjust the slightly to be unsorted plus smallest in rest. And then what we can do here is, just for the sake of our own sanity, is like assert equal smallest in rest and smallest in rest two, and let's see what that does. Great. So that works.
01:05:37.200 - 01:06:29.370, Speaker A: So the question now is, do we prefer this very explicit way, or do we prefer sort of the functional iterator way? In terms of performance, I think they're going to be likely the same. The compiler is pretty good about optimizing iterators, but it's also pretty good about optimizing for loops. For loops. Are iteration iterations rust? So I think what we're going to do is keep the iterator version because it's a little nicer. And I think it's not cheating to rely on min by key, because in order to implement sorting, because min by key is not a sort. Remember that this one was mostly. Some people are saying like, I prefer the second version.
01:06:29.370 - 01:07:14.420, Speaker A: The second version is very straightforward in terms of just like you can really see what it's doing. This one is very much, it's much more readable. It's just this part is a little wonky, but if you read it, your brain is going to ignore this part, right. And just be like, yeah, it probably does what I expect. So I think we're going to keep it this way. And in fact, if what we could do here, if we really wanted to, was map the I and the value to be unsorted plus I and then this can be this and this can be this. It's a map here because it's an option before we expect out.
01:07:14.420 - 01:07:35.200, Speaker A: All right. Okay, so we have now selection sort. Beautiful. So bubble sort, insertion sort, selection sort, and standard library sort. Great. So far these have been like fairly straightforward sorting mechanisms. And so now we're going to start to look at the ones that are not quite as stupid.
01:07:35.200 - 01:08:17.970, Speaker A: So we switch back here. The next one, and probably one many people have heard about, is quick sort, which is its own kind of cool. Does the compiler take advantage of assert statements? No. Well, actually, no. I think it does, because the assert turns into a conditional with an exit on the branch where the conditional doesn't hold. So the compiler can assume that the conditional holds in the following code how much it takes advantage of this. I'm not sure.
01:08:17.970 - 01:09:29.847, Speaker A: All right, so we're going to do quick sort. This is, we're going to base this on selection sort, I guess. All right, so quick sort is. Quicksort is more of sort of a beast than the others because it's not, it's not quite as straightforward, but it's not that complicated. So the way Quicksort works is you pick, you pick an element basically at random in the list, and then you walk the list and you put everything that is smaller than that element to one side and everything that's larger, that element to the other side. And then you just continue to do this sort of recursively down until all of them are sorted. So for quick sort, it might be, might be helpful to write a little helper method.
01:09:29.847 - 01:09:57.220, Speaker A: And we'll get to that in a second. So the idea is that you have, like, unsorted, you have a pivot and you have an unsorted. And the pivot can be chosen at randomly. It can be. It can be the first element, it could be the last element, it could be the middle element. There's actually been some research on, like, how do you best choose the pivot? And you can get some pretty good improvements by choosing a good pivot. In this case, I think we're just going to choose sort of randomly.
01:09:57.220 - 01:10:32.020, Speaker A: And so the way we're going to do this is I'm going to write this in an allocating way first, and then we can look at having it do be in place instead. But the allocating version is going to be easier to understand. So we're going to do that first. So what we're going to do is we're going to have, we're actually going to call quick sort. We're going to have a function called quicksort, and we're going to call that on slice, on the whole slice. And you'll see why in a second. Basically, this needs to be recursive.
01:10:32.020 - 01:10:57.920, Speaker A: So quick sort takes a t. That's ored. It takes a slice of mu t. And here's what it's gonna do. Let's do like this. It's gonna select a pivot which is gonna be slice. Let's do zero.
01:10:57.920 - 01:11:27.510, Speaker A: Seems fine. Oh, actually, I realized, I think someone pointed this out and I was just too foolish to realize selection sort. Oh, no, it won't matter. I was thinking. I was maybe it'll be here. No, I just realized the list were asked to sort could be empty. But I think all of these will deal correctly with that case.
01:11:27.510 - 01:12:45.040, Speaker A: Okay, so we're going to pick a pivot, and then we're going to have like, let's call them left and right. And then we're going to do is we're going to walk, walk all the elements of slice. And if slice of I is less than or equal to the pivot, then left, dot, push slice, I else write, push slice. I write. So all the things that are smaller than or equal to the pivot are going to go in the left, and all the things that are greater than the pivot are going to go in the right. And then we're going to quick sort left, and then we're going to quick sort right, and then we're sort of going to merge them together. Now, this is technically all you need for a quick sort, right? There's no difference between T colon Ord and where t equals ordinal or T color Nord.
01:12:45.040 - 01:13:15.560, Speaker A: So this is all quickstart really does. And it, you'll notice that it's recursive. And the recursive part here is what makes it interesting. We're gonna, left and right are going to keep shrinking, right. They're going to become smaller and smaller and smaller, and at some point they'll only be one element long, at which point they're sorted. So we can actually do here if slice, dot, actually, we can even match on it. Match slice len.
01:13:15.560 - 01:13:54.360, Speaker A: If it's one, then we return because the slice is already sorted. If it's two, then if slice zero is greater than slice one, then swap zero and one and then return. Otherwise, do this bit. Right. So this is sort of the, the base case for the recursion that at some point you end up with this list that's so small that it's trivial to sort. And then you just sort of propagate it back up. And then we're going to merge the two lists.
01:13:54.360 - 01:14:21.580, Speaker A: Now, you'll notice that this is actually really inefficient, right? Because we have to allocate this left and we have to allocate right, and then we have to do this like merge step. And this all seems really annoying. And you'll also notice it doesn't compile. And the reason is because we keep trying to move these elements around, which isn't really. Okay. Oh, right. We also need a zero, so zero or one.
01:14:21.580 - 01:15:07.848, Speaker A: Right. We're trying to move out of the slice, but we're not allowed to move out of slice. So we would have to do some, like, tricks to either move the references or like, have, have left and right only hold indices. And this gets really annoying, but at least now you have an idea for like at a high level. What does the algorithm do? So what we're going to do is we're actually going to implement quick sort as a, as a, an in place sort, so we don't need the vector for left and a vector for right. Instead, what we can do is, is just have left and right be the left side and the right side of the slice and we keep growing them from the sides. So let's see what that looks like.
01:15:07.848 - 01:15:43.622, Speaker A: We still need to pick a pivot for now. I'm gonna, this is still not gonna compile eventually, but we'll get to that. So here's what we're gonna do. Actually, I have an idea, but I'm going to ignore that for now. Here's what we're going to for I in zero to slice line. In fact, we can have this be from one. And the reason we can have this be from one is that the pivot, if the pivot always goes to the left, we don't need to move it.
01:15:43.622 - 01:16:54.440, Speaker A: And in fact this is going to be one of the ways in which we avoid the borrow checker errors here is we're going to do, is it partitiondex? Let me check whether that's the case. No, that's not what I want. I want split. Split mute. No, I want maybe just split at split at mute. Great, split at mute of one. So what this is going to do is pivot equals pivot zero.
01:16:54.440 - 01:18:03.956, Speaker A: So we're essentially sort of stealing the first element out of the slice. And what split it mute lets us do is get a mutable reference to the two sub slices where one subslice is going to be one element long and hold the pivot and one subsize is going to be the rest of the thing that we're actually going to sort and keep in mind, right, that the pivot is already in the correct end of the slice. We're going to, instead of having a left vector and a right vector, we're going to have the left side of the slice be things that are less than or equal to the pivot and the right side of the slice be the things that are greater than the pivot. Well, then the pivot is already on the right side. Yeah, we will, we will write benchmarks in a second. Okay, so now we have a reference to the pivot, but we're still allowed to modify the slice. Right? And this is important because if we took an immutable reference to the pivot, then we wouldn't be able to modify the slice if we didn't do the split at mute business because the borrow checker would complain that you already have a reference into the slice.
01:18:03.956 - 01:18:25.680, Speaker A: So you can't also modify it. Because if you also modify it, who's to say that you're not also modifying the pivot value which you have a reference to? Right. It's on the right side. The left side. Oh, maybe my camera is reversed. Might very well be. Okay, that's not at all what I wanted to do.
01:18:25.680 - 01:19:31.410, Speaker A: Okay, so now what we're going to do is we're going to walk the slice and you're going to see in a second this for loop is actually going to change in a bit. But I'll show you why. And what we're going to do is, again, if slice of I is less than equal to the pivot, then what we want it to do is then we just want it to stay in place already on the correct side. So this indicates that we need some like left side and some right side indicator. Right. Then since we're walking this from left to right, if the next element is or is less than or equal to the pivot, then it's already on the left side and we don't need to do anything with it. Otherwise we're going to have to move element to the right side.
01:19:31.410 - 01:19:58.860, Speaker A: Right, because it's on the wrong side. This gets really complicated because now the current element we're looking at needs to go over to the other side. But that means we have to do a swap. And at that, after the swap, we have to continue looking at this side. Right, which gets weird. So the for loop won't really serve as well here because the for loop would just move on to the next element. But we, given that we did a swap, we actually need to look at this element again.
01:19:58.860 - 01:20:26.010, Speaker A: So what we're going to split first? Mute. Ooh, nice. I did not know there was a split first mute. Nice. Slice is not empty. That is indeed much nicer. Oh, it's using slice pattern matching.
01:20:26.010 - 01:20:57.340, Speaker A: That's cool. Yeah, we could have done that here too. So what we're going to do instead, instead of having this for I and slice is we're going to have a while loop. And for now, let's just make it be a loop. And we're going to do is we're going to look at the, think of it as everything below the left index is on the left side. Everything above the right index is on the right side. Right.
01:20:57.340 - 01:21:46.010, Speaker A: So what we're going to do is we're just going to continuously look at the element that's on the left and see whether it needs to go on the other side. So if slice left is less than or equal to the pivot, then it's already on the right on the correct side. And we don't need to move it otherwise. We need to move this element to the right side. Well, now that this is no longer a for loop, let me just tidy up this a little bit. Now that this is no longer a for loop, this becomes a lot easier. What we can do is we can do a slice swap of the left with the right, and then we do write minus equals one.
01:21:46.010 - 01:22:28.440, Speaker A: Does that make sense? So think of this from a useful way to think about, especially these kind of iterative methods, is just like walk through what actually happens. So imagine that we have a slice and we've already extracted our pivot. So imagine that we just have a pivot somewhere, and we have the remainder of the slice of left is zero and right is the end of the slice. Okay, we look at the, I guess I don't know which side is left for you. Ah, let me draw instead. Aha. All right, so we have our pivot over here, right? And then we have the remainder of the slice.
01:22:28.440 - 01:23:24.920, Speaker A: I drew this far too long. So we're going to keep is we're going to have a left and we're going to have a right. And think of right as pointing to the end of an element of and left is pointing to the left, the start of an element. And so initially, left is empty because it's all the elements before left. And right is empty because it's all the elements after right. So maybe it's more useful to think of these as like pointing to the middle, but it doesn't really matter. Right is everything after the element, not including the element itself, is left, and left is everything left of the element, not including the element itself.
01:23:24.920 - 01:23:52.242, Speaker A: And now the, the iterator code, right is going to look at the element at left. So this element is not in left, but it's at left. So it's going to look at this element, and if that element is less than or equal to the pivot, then it should be in left. So all we're going to do is we're going to like move left. Let me say color. This color is the next iteration. Color.
01:23:52.242 - 01:24:22.816, Speaker A: Now, left is going to point here, right, and everything to the left of where left points is in left. So the pink one is now in left and everything to the right of right is in right. And there are no elements to the right of right. So right is empty. So now it looks at this element and imagine that this element is not less than or equal to the pivot. So that value needs to go into right. Well, what we're going to do is we're going to swap this element with that element, whatever element is over here.
01:24:22.816 - 01:24:46.410, Speaker A: Right. And then we're going to shift, we're going to decrement. Right. So right is now going to point to here. Right. And blue is going to end up over here. And at this point, some other element, let's say green, is going to be here instead of blue.
01:24:46.410 - 01:25:06.278, Speaker A: Right. And now, again, everything to the right of right is in right. So blue is now in right, as it should be. And now we continue to look at where left is pointing. Left is still pointing here. So now we look at green, which is the one that used to be at the end. And if green is less than or equal to the pivot.
01:25:06.278 - 01:25:23.888, Speaker A: And then we keep going. So the question now becomes, what's the termination condition here? Right. Right. To the right of right, right, yeah, exactly. Blue and green kind of looks the same. Yeah, sorry about that. Hopefully it was clear from the explanation.
01:25:23.888 - 01:25:51.350, Speaker A: Picking colors on the fly is hard. I should really just set up like a good plat, but. So the question becomes, when do we terminate? Well, we terminate when left becomes the same as right. So at some point there is no more elements to. There are no more elements to look at. This might not be true. This might be an off by one.
01:25:51.350 - 01:26:22.296, Speaker A: Again, when doing these kind of thinking, it's useful to think about the boundary conditions, like what happens at the beginning and the end. So let's say that we have just two element list. Left points here, right points here. We look at this element, we shift left over. This is in left. These are now equal. But we have not looked at this element yet.
01:26:22.296 - 01:27:16.930, Speaker A: So it might be in left or it might be in right. So this is not the termination condition. We need to do one more iteration. So them being equal does not mean that you should exit. You should exit after they were just equal. So this should actually be while left is less than or equal to right. The moment left becomes more than right, then we're done.
01:27:16.930 - 01:27:50.612, Speaker A: We don't need to leave a hole for the pivot. The pivot is already on the correct side. Okay. And this is probably complaining that we're trying to compare immutable reference to. There we go. So slice left gives you a t and you're trying to compare a t to a mutable. Reference to a t.
01:27:50.612 - 01:28:13.336, Speaker A: We need to compare by reference. Okay, so now we have an in place sort of pivoting. Notice that this on its own is not sufficient. Right. That's just gonna like split the thing into things that are smaller than the pivot and things that are larger than the pivot. I am not swapping beyond the length of the slice. Right.
01:28:13.336 - 01:28:36.980, Speaker A: Is slice Len minus one. So. Nope, I think that's, I think it's currently correct. This does not actually sort right. All it does is it moves all the things less than the pivot to the left and all the things that are greater than the pivot to the right. But, but those things are not themselves sorted. So we still need to do a quick sort of the left and the right.
01:28:36.980 - 01:29:22.494, Speaker A: So how is this going to work? Well, we basically need to recurse. What's nice here is we don't have to do the merge step because the merge is sort of going to happen on its own because we're essentially sorting the sub slices in place. What this means is that there is no merge step to do. When all the recursion finishes, the, the whole array is sorted. So the only question becomes how do we know what to, what to pass into? Quick sort here. One tricky part here is this slice business should really be rest because we need to refer to the slice down here. Oops.
01:29:22.494 - 01:30:01.566, Speaker A: Should say arrest. And this should say rest. And now what we're going to do is we're going to quick sort let left and right is going to be the splice and we're going to split it. And the question becomes where we're going to split it. Well, we know that everything that is less than anything before left is in left, right, and everything that's after right is in right and split at mute. So split at mute takes a mid, I think they call it oops, not MIT. And it gives you two slices.
01:30:01.566 - 01:31:30.896, Speaker A: One is a mute of everything up to but not including mid, and the other is mutable to everything from mid and onwards. And so this is going to be left, right. So if we provide left here, that's going to be everything up to but not including left, which is indeed what is in left and everything else is in right. And I misspelled right. Could you add an extra if else branch to just move the right counter without a spot swap if it's already on the right of side? Yeah. So there's one cool extra step we can do here, right, which is if the thing on the right is greater than the pivot then we can just decrement, pivot, decrement the right, avoid unnecessary swaps back and forth. So the reason why this extra clause is useful is.
01:31:30.896 - 01:32:07.896, Speaker A: Imagine that, I guess, let's go back to the drawing. How am I going to demonstrate this? So let's imagine we have a very small slice here. So it has just like. Let's put some numbers in here. Let's just say it's 135. So initially, left points here, right points here. That's nothing.
01:32:07.896 - 01:32:32.954, Speaker A: I need an extra number in here. That's annoying. I think I even need an extra box. So let's make this be four boxes. Let's say this is 1425. So left points here, right points here. So initially we're going to find that one is in the correct location.
01:32:32.954 - 01:32:58.610, Speaker A: So we're going to move this to point here. Right. So this is left, this is left, this is right. Then we're going to look at the four and say, well, four has to go in right. So we're going to go ahead and swap these two. Right. And so what we're, the position we're now in is 1524 with left pointing here and right pointing here.
01:32:58.610 - 01:33:40.950, Speaker A: But this was sort of a useless swap because the next thing we're going to do is swap five back into right. So five now got swapped twice, even though it was already on the right side. And this extra if clause avoids us having to do that, it basically tries to, it tries to move left and right without having to do swaps until that's no longer possible. So that's a little bit better. Why are we splitting again if we already sorted rest? We haven't sorted rest. We've just sort of, I mean, it is. We've just sort of done like a binary partition.
01:33:40.950 - 01:34:20.620, Speaker A: It's not fully sorted instead of while less than or equal to a loop. And if left equals right break. No, I don't think you could use an if left equals right break because you want to break after processing the case where left was equal to right. I mean, you could. It would just be a. It wouldn't really be that nice. Oh, yeah, you're right.
01:34:20.620 - 01:35:02.998, Speaker A: Actually, we can also do left plus equals one. So left holds a right and right holds the left. Swap them. So we actually make progress on both sides when we do that swap, but it just saves us one iteration. Really great. Yeah. So once we've done that sort of partitioning, then we look at the two partitions and we recursively call quick sort.
01:35:02.998 - 01:35:41.600, Speaker A: Now, there are variants of quicksort where if you, if like the, the slice you end up with is sufficiently small, like smaller than three or something. Then you do like a selection sort or insertion sort or something, because those are efficient. If you have small lists that way you don't have, because this, the actual, this part of quick sort is kind of slow. And so if you have a small enough list, you can use another sorting algorithm. But I think we're just going to leave it the way it currently is. Even this to clause is unnecessary. All right, so let's see whether that does the right thing.
01:35:41.600 - 01:36:14.892, Speaker A: It does not. Great. Initialize left equals one. So left, remember, is an index into rest. It is not an index into slice. Oh, actually that's where this is currently wrong. It needs to split at left plus one, the pivot right.
01:36:14.892 - 01:36:46.370, Speaker A: So left, left is an index into rest. It's not an index into slice. And rest is slice plus starts at slice plus one because of the pivot. So we do need to add one to that. Oh, quickstart has overflowed its stack. That seems not great. That suggests that these are not shrinking.
01:36:46.370 - 01:37:56.816, Speaker A: Yeah, yeah. The problem we're running into here is that, okay, so basically what this means is infinite recursion, which I think happens because we're always choosing the pivot to be the same element. And it might be that the pivot is the largest element, in which case everything will always end up in left. So left will never shrink. And therefore we just keep, we just keep growing. We keep calling quicksort on like the entire slice and it never gets any smaller because write is always empty. So what we need to do, well, there are a couple of ways to do this.
01:37:56.816 - 01:38:52.194, Speaker A: One is to pick the pivot randomly. I think realistically what we need is we need to make sure that the pivot is not the max value. No, we just need to make sure that the pivot does not go in. The same problem is that we can't just put the pivot in the right either, because if we put the pivot in the right, you have the same problem if the pivot is chosen as the smallest element. I think the problem we're running into actually, is that we don't move the pivot. So the pivot, the same pivot ends up being used over and over again. The way we can get around this, I forget actually.
01:38:52.194 - 01:39:27.440, Speaker A: Let's see what the page says for quicksort. For choosing the pivot, equal vows can go either way. After this partitioning, the pivot is in its final position. I see. It should not include the pivot. Why is that I see. So the real algorithm actually does exclude the pivot.
01:39:27.440 - 01:40:12.900, Speaker A: Hmm. Typically that's the last element of the array. That's interesting. Hmm. Yeah. You don't have the pivot in either of them. Oh, right.
01:40:12.900 - 01:40:45.582, Speaker A: It's. I know, I know. Why? Okay, so the pivot is supposed to end up in the final sorted place in the array. But the way we've done it is that we chose the pivot to be the first element of, and then we didn't move the pivot at the end. So the pivot is still included in both the sub slices. So one way that we can do this is place the pivot at its final location explicitly. And the final location for the pivot is to place it after all the things in left and before all the things in right.
01:40:45.582 - 01:41:21.106, Speaker A: Because that's how we partitioned this in the first place. Right. So the way we do this is just, we do one last swap, which swaps zero, which is the pivot with, with, I want to say, left minus one. Right. So it, it swaps it with the last element in left. So the last element in left. Right.
01:41:21.106 - 01:41:55.650, Speaker A: So everything to the left of left is in left. So the last element of left is swapped with the pivot. And now we have the pivot placed so that everything that is less than, at less than or equal to it, it's to the left of it, and everything that's greater than is to the right of it, which must mean that it's in its final sorted location. And now this split at mute. That, that, that gives us the left and the right. We know that the pivot, the left now has the pivot at its end, which is where it should be. So we can exclude that from left.
01:41:55.650 - 01:42:51.656, Speaker A: So we can actually do this by, in a couple of different ways. The ease, the nicest one is probably just mute left. Actually, we can also swap it to. So let's just split this at left and then have this be everything. This might seem a little weird, but remember that right is where the right hand side starts. So if we split at left after swapping the pivot, what we're really splitting is we're splitting at the pivot left split at mute. Oh, wait, no, this should still be left minus one.
01:42:51.656 - 01:43:46.858, Speaker A: Let me think here. Oh, right. Left is already. Okay, let me first do left is left plus one and let right is right plus one and write to point into to account for the pivot at zero. In theory, you could have the math down here just sort of work out, but this just makes it nicer. To think about. So now we swap the pivot into the end of left, which is going to be left minus one, because everything to the left is in left and everything to the left of left is in left.
01:43:46.858 - 01:44:25.382, Speaker A: So if you want to swap the last element to left, it has to be left minus one. And when we split, we want to split. We want to split where right starts. If we split where right starts, then everything to the left of that. Actually, no, this has to be minus one because we don't want it to include the pivot which is at the end of left. And now, rather than having to slice this to not include the last element, we slice this to not include the first element. To avoid this, you can choose the pivot at the middle of the slice.
01:44:25.382 - 01:45:02.398, Speaker A: Then, then you about you avoid some moves. I don't think that's true. If you chose the pivot in the middle, you might run into a position where you have to shift the pivot around, which sounds even more annoying. Partition at indexed use instead of split at mute will nicely exclude the pivot. Oh, is that what partition at index does? Really? I don't know. I feel like partition at partition, Dex. Yeah, but that's cheating.
01:45:02.398 - 01:46:00.000, Speaker A: Also, it's nightly. I mean, partition at index just does quick sort for you, which is not what we want. And then here, what we could do is like have a, an assert for our own sake that left last is less than right dot first, or I guess less than or equal. Great. Why is this? Oh, I guess we don't actually use right below here. Okay, so now we have a working quick sort. Great.
01:46:00.000 - 01:47:04.380, Speaker A: So you see what I mean by this is a more complicated algorithm than bubble sort or insertion sort or selection sort, but it is also a lot more efficient. And in fact, let's try to evaluate a little bit how different these are right now. So let's go ahead and add a benchmark. So we're going to do is we're going to edit benches, let's do main rs. Now there are many ways to actually do this evaluation, and I'm not gonna, I don't think I'm going to pull in anything like criterion here. Instead, what I'm, what I'm interested in is comparing how many comparisons these different algorithms do, which is a good proxy for, for their complexity. It's not quite equal to their complexity, but it gets there.
01:47:04.380 - 01:47:56.140, Speaker A: The other thing I realized is that for insertion sort, this needs to be a public field if we want to be able to actually access it. These should be pubviews. So now if you look at the oh man benches main. So we want to use or star. And the way we're going to go about evaluating this is we're going to have our own little sorting type. So like sort of, or I guess. Yeah, sort evaluator.
01:47:56.140 - 01:48:41.082, Speaker A: It's going to be generic over t and we're going to derive. Actually, we're not going to show that in a second. It's going to hold a t, but it's also going to have hold a comps, which is going to be a sync, atomic, atomic usage. And actually we're going to want our key here too. And I think you probably see where this is going. I'm going to implement, I have to implement all these traits manually. That's pretty annoying.
01:48:41.082 - 01:49:41.040, Speaker A: So we have to implement partial eek for sort evaluator. The reason we have to implement all these manually is because I want all of them to compare only the t and just ignore comps. But what comes is going to do is every time we compare an element we're going to increment the counter and this gives us a nice way to like run a sort and then at the end see how many comparisons did it do. Okay, so eek, I think is an empty trait. Partial eek is not. Let's pull that up here. So we have to implement this thing, which is easy enough.
01:49:41.040 - 01:50:28.520, Speaker A: This is just going to be self dot t equals other dot t. But we are going to do self compech, add one. All right. I also need ordering. I'm not going to actually talk about how ordering works here. And right hand side is just going to do self. Can I avoid that? Yeah, great.
01:50:28.520 - 01:51:08.094, Speaker A: And then we have to do the same thing for Ord. This is like a little bit annoying boilerplate. And for partial or will we also count swaps? No. So there isn't really a good way to count swaps because no method is called when two values are swapped. So we don't really have a way to count that. We would need the like implementation to cooperate with us. Like we could have like a trigger that it's supposed to call.
01:51:08.094 - 01:52:20.594, Speaker A: But that seems somewhat annoying. Oh, no. We're also going to end up with two types called ordering because there's atomic ordering and then there's standard compare ordering. And these are of course different types. So I'm just going to do this instead. And this again is going to be basically the same thing as here, but it's going to do self, dot t, partial other and for ord, for orge. This is just going to forward to self dot t.com
01:52:20.594 - 01:53:27.558, Speaker A: other now you might wonder, well, why don't we add in this case, oh, other dot t. Other dot t. The reason we don't do that is because usually compare forwards to partial compare. I guess in this case actually we know that we're really testing or so, or does the right thing to deal with here even eek, we don't actually need to count. Was this faster than just using criterion? So the reason I don't want to use criterion here is both because it pulls in a bunch more complexity that I don't think is that interesting in this case and because criterion wouldn't measure this. So with criterion what you get is an estimate of runtime and it's not. We could measure the runtime here, but I specifically want to look at the complexity which is related to runtime but not quite the same.
01:53:27.558 - 01:54:01.996, Speaker A: And this gives us an estimate of, of the runtime. It's true. We could use relaxed actually, because this is all single threaded. In fact we could use rc too. But it doesn't matter because we're not measuring the runtime performance. So what I'm imagining here is we're going to do like for n in, let's say. So what sizes do we want to evaluate, like arrays of size zero, 110, 101,010 thousand.
01:54:01.996 - 01:55:04.700, Speaker A: And then we're going to do is we're going to have like multiple iterations, let's say ten iterations of each one. For each one we're going to construct a list of values. And of course this is not actually going to be a vector where all the values are the same. I'm just, this is just a placeholder for now. And then what we're going to do is sort of, I guess let up here counter is going to be arc new atomic, use new zero. And each of the values in this array is going to wrap some value, but all of them are going to point to the same single atomic, you size. So we get a full number of comparisons and then we're going to do is we're going to reset that counter, store zero.
01:55:04.700 - 01:56:01.720, Speaker A: Fine. This, I guess this will have to be relaxed, relaxed. We're going to store zero in that counter before we start each iterate, each, each actual sort. So let's start with something like bubble sort. We're going to do bubble sort, dot sort, and we're going to give it a mu, two values now, because the reason why I construct values at the top here is we actually want to run the different algorithms on the same array of values in the same order because otherwise we can't really compare how many comparisons they do. So we're going to do sort of a, for each one we're going to do a let values equals values, dot clone, reset the counter and sort values. We're going to drop that clone of values.
01:56:01.720 - 01:56:57.544, Speaker A: I guess let took equals this. And in fact this could be much nicer. Like we could have this be a little closure that takes, takes a sorter and does this for us. And then took is going to be bench of bubble sort and then we can also do insertion sort. Smart, true. We can do insertion sort. Smart false.
01:56:57.544 - 01:57:52.860, Speaker A: We can do selection sort and we can do quick sort. And this is going to be. Is there a performance difference between using atomic size and cell u size if you only use one thread? There is a little bit like we, we totally could use something like cell here, in fact. Sure, why not? So we'll use cell and rc instead of these. And the reason we can do this is because we don't actually need this to be thread safe. And then this is just going to be self.com dot store self comps load plus one.
01:57:52.860 - 01:58:28.490, Speaker A: No, it's get and set, I think. Great. And this is going to be RC new cell, new zero. And this is going to be get. Actually, this is going to be set nice. This complaints because. Right, this, this is actually going to be a.
01:58:28.490 - 01:59:02.980, Speaker A: Oh, right. No, this is going to be sorter here and this is going to be a ref. Let's have this be a din Sorteregh. That seems nice. Sorter cannot be made into an object. Oh, it's not object safe. That's annoying.
01:59:02.980 - 02:00:18.830, Speaker A: All right, fine. We can write this as a separate function too. It just makes me sad. So that means it's going to take a t that implements or it's going to take an s that implements sorter. And it's going to take, it's going to take the s, it's going to take a slice of t and it's going to take a reference to a cell of you size and it's going to return a usize and then inside it's going to do this thing. Oh, I thought there was a from slice, but maybe I'm wrong. I guess we can just do values iter, cloned, collect.
02:00:18.830 - 02:00:55.760, Speaker A: Right. So this also needs to implement clone. That's what I wanted to avoid, but at least now we can do this takes three arguments. And now for each one we're going to have to give it values. Oops. Values and counter. Values counter.
02:00:55.760 - 02:01:35.750, Speaker A: I'll use counter values. Counter. Great. The reason it's not, the reason the trait is not object safe is because we have a method that's generic in it. We can't box a sorter because the trait is not object safe because it has a generic method on it. I'm probably not going to go through what object safe means because it's somewhat complicated and it, this stream is already going a little long. Can't you simply sort, sort evaluator instead of t? That is what we're going to do.
02:01:35.750 - 02:02:10.180, Speaker A: Actually, this is going to be a sort evaluator of t, which also means that we need to derive clone for this, which is fine. And I guess, yep. Oh, right. You're right. We can just use two vec. I'll use two. Great.
02:02:10.180 - 02:02:59.040, Speaker A: All right, so now the question becomes how do we construct the thing that we're actually going to test? And here the easiest thing is probably to pull in the rand crate. Is rand even at 1.0 yet it might not be zero. Seven. All right, so we're going to do this. I think there's like a rand to just generate a hole thread Rng. It implements Rng core, which gives us.
02:02:59.040 - 02:04:07.680, Speaker A: Where's the Rng trade? There's been so much modifications of this. Great. There we go. Rng. I want to Gen, I think it can just generate a vector, but even if it can't vac with capacity n and then we're going to do four and zero to ndez values, push sort evaluator. And the t is going to be, I guess we need a, we need an rng, which means we need to use rand prelude star. So we're just going to generate a bunch of random values.
02:04:07.680 - 02:05:00.304, Speaker A: I guess we can rand dodge. And the comparisons is just going to be a clone of counter, which I guess technically they want us to write clone this. And here we want it to generate a usage. Just say we're going to sort numbers for now. All right. And now we can actually have this print out a bunch of values. Specifically it should print out bubble, then it's going to print out the n and then it's going to print out how long, how many comparisons that took.
02:05:00.304 - 02:05:45.268, Speaker A: Similarly here, this is going to be insertion smart. This is going to be insertion dumb, this is going to be selection. And this is going to be quick. All right, cargo bench, see what we get. Yeah. Prop test would let us generate these two. Ooh, why did it, is it just bench? Oh, I need to declare it.
02:05:45.268 - 02:06:26.510, Speaker A: I path equals no, I don't think I should have to. I thought Bench would just do this. I mean, that's fine. We can just move benches to be source bin and then move source bin main to be source bin. Bench. Ooh, quicksword panicked. That's good.
02:06:26.510 - 02:07:17.480, Speaker A: The length is two, but the index is a very large number. And quick sort at 24. So it seems like quicksort is not quite done. Line 24. Interesting. A write can underflow. Can left ever overflow? Yeah, that's not ideal.
02:07:17.480 - 02:08:20.860, Speaker A: Mmm. How do we want to deal with this, though? I guess left won't really overflow. That seems unlikely, but write can underflow. I think the way I want to deal with this is to have them be kind of want to have them be eye sizes rather than trying to deal with the. Rather than deal with the underflow. Write can definitely underflow here. Imagine that all the elements get added to write.
02:08:20.860 - 02:09:17.340, Speaker A: Right will end up moving 00:01 and then we do one more execution. Although I guess this is so the while condition should check that if right ever becomes no, right becomes equal to left and right becomes zero. So we continue executing. We decrement right. Right underflows. Yeah, right underflows. Left is still less than right.
02:09:17.340 - 02:10:34.426, Speaker A: We execute this line and right is now a big number. So I mean, there are a couple of ways to deal with this. The easiest one is, is to just have these be eye sizes, but that's also not great. It can't be a saturating sub either, because we need to detect the case when left and right cross. That's when we're done. So I think the. Yeah, I guess that's true.
02:10:34.426 - 02:11:33.680, Speaker A: I guess one easy way to do this is while right is greater than or equal to zero. And this, but that I get, okay, this is, this is awful. But that would be the way to do it because underflow, which also in debug mode would not work. Because in debug mode this panics. No, we do have to decrement, right? Because otherwise we don't detect detect the way exit. So it, it's not like the, the decrement is not wrong. The decrement does need to be there.
02:11:33.680 - 02:12:33.330, Speaker A: It's just that the decrement causes it to not realize that we have to exit. So like right wrapping sub one. Like, it's awful. But I also realized one, one other thing we can do over in the benchmark, oops. Bench. Is that we only need to generate this once for every n and then each of the iterations we can just do values shuffle and that will work just as fine. It won't work in debug mode, because in debug mode, rust panics on overflow and underflow.
02:12:33.330 - 02:13:26.460, Speaker A: Yeah, so, so the other alternative is some people are wrong file. The other people thing that some people are pointing out is, can't you just check here? Like if right is zero, then break. So that, that is another way to do it. I don't know if it's nicer. I mean, okay, so it would be write minus equals one. This would stay right equal, minus equals one. It would be, if right is zero, then break, and it'll be the same here, it's more verbose.
02:13:26.460 - 02:14:25.610, Speaker A: But, you know, we could also use check sub. It still ends up being pretty verbose. Okay, so this now runs, although quick check appearancely is doing no comparisons, which seems not quite right. In fact, it's reporting no comparisons for insertion dumb or quick or bubble. That's because they all use partial compare. So the less than operator and the greater than operator in rust both call partial compare, not compare. So there are two ways to solve this.
02:14:25.610 - 02:15:21.580, Speaker A: One is to not use those operators and use call compare directly. And the other is to move this into partial compare. Oh my. Why is this being annoying? This is the file I want, so we can move this into partial. Orlando, actually, yeah, that's the way to go about it. Do this and then have this do self dot partial compare other dot unwrap. Is there a reason the loop body needs to run? If left equals right, yes.
02:15:21.580 - 02:16:01.548, Speaker A: We're not done. If left equals right, that means there's one element we haven't looked at yet. Is incrementing left correct? Yeah, incrementing left is fine because it's not going to overflow. In theory, left could overflow, but it's, but like, overflow is a very large number. Underflow is not a very large number because anything, any small array is going to trigger it. Can you check the list is sorted after bench just to be sure? Sure. Values.
02:16:01.548 - 02:16:44.380, Speaker A: I think there's an is sorted. Yeah. Oh, it's not fine. Oh, that's for I in one, two values. Len. Technically it's this, but that's a nightly thing. So instead we're up to do it ourselves and we want to assert that values I is greater than or equal to values I minus one.
02:16:44.380 - 02:17:20.030, Speaker A: Yep, that seems to be the case. I think we should have write equal length instead of length minus one. No. Can't you increment on both or, since the ord implementation will never call or on the wrapper, but only on t. Oh, we could do that. Too. You're right, because this ends up redirecting or ends up calling directly to the t.
02:17:20.030 - 02:17:53.420, Speaker A: We can do this. You're right. And in fact we can do the same thing for equality. Won't checking if the array is sorted also increment the counter? Yeah, you're right. You're completely right. Let account is this and then we check in that we count. Oops.
02:17:53.420 - 02:18:32.802, Speaker A: All right, so this is now at least giving numbers. Currently those are a lot of numbers and they're not very easy to get at. So let's stick them in like values dot de. How bad is it using nightly for binary? I just prefer to not use nightly if I don't need to. But it's not bad to use nightly. It's just like inconvenient usually. Now, I guess to end this, let's, I was sort of hoping we would get to merge sort and heap sort because they're kind of interesting at the same time.
02:18:32.802 - 02:19:23.180, Speaker A: I think we've covered a bunch of potentially interesting like rust topics, so I don't think we need to like the goal of this again is not really sorting algorithms, it's more about how we implement them. But I do want to plot these just to give you a sense of what this looks like. So let's see if, what's the easiest way for me to do this so we could cat that into GNU plot? P e plot using one. I'm using two, colon three. Title one. Let's see if that does what I wanted to do. No, that did not really help.
02:19:23.180 - 02:20:30.930, Speaker A: I thought there was a way for you to tell Gnu plot to use a given field as the title. No. Yes. I want to avoid having to write a complicated script, but maybe I can't really get away from it. All right, fine, we'll do it in another way. Let's just write a simple r script because r scripts are nice. So we're going to do t is read table values dot de.
02:20:30.930 - 02:21:07.850, Speaker A: In fact, let's stick some headers on here and say this is, this is algorithm and, and comparisons. We want to include ggplot two and then we want ggplot two. Let me have the pull up the quick start here somewhere. That's not, oh, quick guide. Great. That's not a quick guide. You're lying to me.
02:21:07.850 - 02:21:35.490, Speaker A: That's terrible. All right, so library, I very rarely write our code. I just have this like same plotting script that I keep just copying over and over again. But it does produce really nice visualizations. This is not an official guide, this is a bad guide. Give me the real guide. Here we go.
02:21:35.490 - 02:22:30.200, Speaker A: That's what I want. So I want t and I want the xenore to be n, I want the y to be comparisons. And I want the color to be the algorithm. And I want it with points. No fine library. Ggplot two. This was not intended to become a r tutorial.
02:22:30.200 - 02:23:00.906, Speaker A: It shows what. Great. So it pulled in t correctly. And now I want this line up here. Object n not found. Is that not what I called that column? Oh, that's because I'm stupid. Headers.
02:23:00.906 - 02:23:32.468, Speaker A: True. Huh? R e table. We now pivoted to the crust of r. Yeah, I know, right? You mistyped algorithm. I probably did that too. Is it titles? There's definitely a header. I'll go write.
02:23:32.468 - 02:23:51.480, Speaker A: I've written right. So many times that. Beautiful. All right. And let's have this also with geompoint plus geom. Smooth. Right.
02:23:51.480 - 02:24:21.940, Speaker A: This might not be very easy to see because the font size is kind of bad. But here what we have is along the x axis is the length of the array, the y axis is how many comparisons did you do? And then this shows the, the sort of the relationship between the two. Right. And you can see that this is not, this is not good for bubble sort. Right. You can see how bad bubble sort is. Right.
02:24:21.940 - 02:24:59.950, Speaker A: You can also see that the, let's see. So insertion dumb and insertion smart are almost the same. And this should not be surprising, right? Oh, my head is in the way. Sorry. Let me go ahead and do me. Oh, I'm still, where is the, well, that's fine. I can just do this instead.
02:24:59.950 - 02:25:40.192, Speaker A: Aha. That should be easier to look at. So you see that the difference between insertion sort smart and dumb is basically zero. This shouldn't be terribly surprising. So if you remember back to what the algorithm actually does, the algorithm was just, we do a binary search for finding the insertion point, but we still need to, we still need to do all the swaps, actually. Maybe. That's weird.
02:25:40.192 - 02:26:07.726, Speaker A: Yeah. The number of, the number of comparisons you do is still just very, very large. The fact that you do less for each insert doesn't end up mattering as much as the overall algorithms. Just have to do a lot of comparisons. Bubble sort, of course, terrible. Selection sort is worse than insertion sort, which is also what Wikipedia told us it would be. But the implementation was simpler.
02:26:07.726 - 02:26:28.410, Speaker A: It uses less memory. Right. So that's nice and quick. Sort, you see, is just way, way smaller. Right. We can, we can totally compare this with the standard library sort too, if we want here. So let's add a benchmark of the standard library sort.
02:26:28.410 - 02:27:20.858, Speaker A: So standard Sorteregh. So I'm gonna go ahead here and do this. Right. So let me read that in again and then plot it. You want to log y. So let's go ahead and look at what that is. I forget, I think it's just gg log.
02:27:20.858 - 02:28:07.290, Speaker A: Yeah. Scale y log ten. Scale y log ten. Oh, did I do something silly again? I must have, but I don't quite know what. Oh, right. Last time I modified values to have a header. So that's algorithm n and comparisons.
02:28:07.290 - 02:28:39.200, Speaker A: Alright, so this is log scale. So that makes it a little hard to read. Quick sort is now duplicated. Header is gone. Yeah. Headers is missing. Oh yeah.
02:28:39.200 - 02:29:11.070, Speaker A: We can make the x axis logarithmic in instead. Actually let's do, let's maybe do both. So we're going to do scale x log ten as well. Ten. Okay, so this is at this point a very weird plot. But keep in mind here that a straight line here. I guess the smoothing is at this point fairly unhelpful.
02:29:11.070 - 02:29:53.150, Speaker A: Where do we have, right, so the colors have changed. So we have quick sort down here. The standard library sort is down here. Selection sort, bubble sort, insertion dumb. Insertion smart is down here. Why that seems weird? Oh, it's, yeah, it's because, okay, so yeah, let me turn off the smoothing. I'll leave it.
02:29:53.150 - 02:30:28.452, Speaker A: Okay, so insertion sort smart, the reason it looks like insertion sort smart is so good here is because this is, remember, only measuring the number of computers comparisons. It is not measuring the number of swaps. Right. So it's not really the complexity of the algorithm, it's just the complexity in terms of number of comparisons. And if you remember for insertion sort, the insertion sort dumb, right. Does a comparison for every swap. Insertion sort smart does very few comparisons, but it does the same number of swaps.
02:30:28.452 - 02:31:04.200, Speaker A: So really the figure here is giving us a skewed image of what's going on because we can't also measure the swaps themselves. Now of course if we did this with runtime, we'd get a picture that was much noisier, but it would include the cost of things like swaps. There are algorithms to do zero compares. They, well, sort of, those are counting algorithms that generally only works for things like numbers. And they can get complexities below n login. Yeah, the smoothing function is not great for this particular use case. Nice.
02:31:04.200 - 02:31:56.580, Speaker A: We can totally compare the actual runtime too. Here, let me type that up real quick. So we're going to have this outside a usize and an f 64 let time is time instant. Now took is time elapsed and then we want count and took the s six of 64. And now we can do this, this, this, this. I should really have written just like a quick macro for this, but I did not. I was a fool.
02:31:56.580 - 02:32:57.810, Speaker A: Took zero, took 101-01-0101 run this again. I think my computer has enough course that this shouldn't really matter because it's a single chord experiment anyway. Algorithm n comparisons and time. So now let's first, let's stop this insane scaling and keep GM smooth. Probably we want the y axis now to be time. Whoa, this, this smoothing is just like not helping. Let's, let's get rid of that smooth.
02:32:57.810 - 02:33:38.290, Speaker A: I guess technically this is a scattered, I forget, maybe they don't have scatter. So this is going to be much harder to read. So this is now log y scale still. So all the lines would have gone like this if they were smoothed. Yeah. So the runtime is very, very hard to read. But here you'll see that both quick sort and the standard library sort are generally much faster insertion.
02:33:38.290 - 02:34:40.050, Speaker A: Smart is faster than the dumb insertion sort because it has to do fewer comparisons, but it's nowhere near what the standard library in quicksort managed to do. So here we see that the, the delta here, right, is that we're also counting the swaps, but we do get a much noisier signal. You see how easy that was to switch up, though, which is nice. All right, let's do a log x as well and see scale x log ten. Nice. So Geomline will not do what you want here because there are multiple points for every x point. So geomline will do something weird, although it'll actually, it might not look too bad, but it's not really what you want.
02:34:40.050 - 02:35:08.660, Speaker A: Yeah, it ends up drawing a line. It ends up drawing a line between the data points for the same x coordinate too. But regardless. Yeah, so here you see just how much of a difference is, right. Remember that this is log y scale. So the difference here is quite large. But you're right, like insertion, the smart insertion sort is much better than the dumb insertion sort.
02:35:08.660 - 02:35:38.930, Speaker A: Nice. Okay. I think that's all I wanted to go through today. I think, like, it could be interesting to implement more sorting algorithms, but I suggest that's something you just sort of take on yourself. Like, it's just fun to implement these algorithms anyway, and it teaches you a bunch of just nice things about how to write rust code. What I'll do is I'll post this as a git repository. I'll publish it on GitHub.
02:35:38.930 - 02:36:31.590, Speaker A: And feel free to like, if you have additional implementations of algorithms, just like post them. And we'll keep a little repository there for people to look at. Are there any questions before we sort of end for the day? This ended up longer than I had planned, but you know, it's because it's fun. Can we try an all decreasing slice? I think quick gets pretty bad with that. So currently we're sort of randomizing them, which means that the, the range you see, right, you could think of the bottom is more like best and the top is more like worse in the middle is sort of the average, but we need way more data points to actually sample the whole thing. We could generate sort of known worse than best case scenarios, but I don't think it adds too much value to this particular stream. Right.
02:36:31.590 - 02:37:01.776, Speaker A: Remember, this is not really a stream on comparing sorting algorithms, because, like, you would probably use something like Tim sort instead. You wouldn't actually use any of these, you say, I think Tim sort is really like a merge sort combined with quicksort or merge plus selection sort. I forget. So I don't think it's worth digging too much into these. It's more about the rust code we ended up writing. Sweet. All right, thanks everyone.
02:37:01.776 - 02:37:42.108, Speaker A: Thanks for watching. I hope that was interesting. In a week or two, I will do a stream on this modification I want to make to EV map. That will be a much more complicated stream in some sense. This is sort of a more of an introduction introductory stream to rust, or for those who are not that familiar with rust in and of itself. Whereas the EV map stream will be more like the older streams I did with our, like, pure implementation streams, it will probably be longer, and it will deal specifically with like concurrent data structures and abstraction around them. I think it'll be really interesting, but it'll be a different flavor to this one, so keep an eye out.
02:37:42.108 - 02:37:51.660, Speaker A: I'll post on Twitter whenever I know when I end up doing it. And of course, as usual, I'll post the recording on YouTube afterwards. All right, until next time. See you all. Bye.

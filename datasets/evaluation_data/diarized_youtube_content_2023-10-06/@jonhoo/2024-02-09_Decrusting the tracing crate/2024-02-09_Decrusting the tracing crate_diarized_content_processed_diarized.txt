00:00:02.000 - 00:00:53.109, Speaker A: Hello folks, welcome back to another stream. This time it's another decrusted where we, you know, pick a crate from the Rust ecosystem and we sort of do a deep dive, not just on the high levels of how it works, but dig a little bit deeper into, like, what is the internal architecture, a little bit of the program, like trying to really understand why the crate works the way it does. Build up the correct mental model for how to work with that crate so that you can do things, you know, beyond the basics, you can debug when you get stuck. And this time we're going to look at the tracing crate. And if you haven't already looked at the tracing crate, then first of all, I'm sorry, it is a really good crate to work with. But second of all, at a very high level, tracing is a logging crate. Now, it's actually a bunch more than that.
00:00:53.109 - 00:01:47.185, Speaker A: But at a very conceptual level, it's a logging crate. It allows you to emit events that represents, you know, things that happen in your program and then it allows things to other sort of components in the system to subscribe to those events and do something with them. For example, your events could be log messages, and the thing that the subscriber does when it receives them could be to write them to your console. So a traditional logger, where tracing is not a logging framework is that it doesn't actually need to do logging. It is more of a general purpose system for doing instrumentation of your code such that it can emit events that represent, well, events in the execution of your program and subscribers which subscribe to those events and do something meaningful with them. And that could be things like report them as metrics. It could be things like logging to open telemetry.
00:01:47.185 - 00:02:20.897, Speaker A: It could be things like, you know, produce histograms. It doesn't really matter. Like, tracing is agnostic to the types of your events and what you do with those events. And crucially, the two are disconnected. So in your program, what you write is you annotate it with these events and the subscribers are sort of plug and play and you don't need to. If you want to add a subscriber, for example, that does something different with your events, you don't have to change all of your application code. It can stay the same and the subscriber will just pick up on those same events later.
00:02:20.897 - 00:02:45.493, Speaker A: And don't worry, we're going to dig a lot into the details here. But sort of at a high level, that's what tracing does. It connects events in your application with something that does something with those events when they happen. The docs for tracing are actually pretty good. I recommend you give them a look and read through them. If you ever sort of are curious about this on your own. It's actually worth reading the docs of tracing.
00:02:45.493 - 00:03:34.575, Speaker A: It does go into a fair amount of what we'll talk about in the video today, but sometimes it can be useful to work through it a little bit more sort of directly the way we're going to do now, and really talk through what's happening beyond just reading the text. Tracing has two sides, like I mentioned already. There's the application side, which is what emits events, and then there's the subscriber side, which is the thing that receives or acts upon events. And we'll talk about these separately. So for the first sort of part of the stream, we're going to be talking about the application side, the thing that emits events. On this side, you have two primary things you need to know about spans and events. A span is essentially a sort of logical grouping of related events.
00:03:34.575 - 00:04:54.045, Speaker A: And a span could be anything from the execution of one particular test, the handling of one particular request, the session of a particular user, it could be processing a particular file, and spans could be nested. So you could say that, you know, during the execution of this HTTP request, for this part of it, we were processing this file, for this part of it, we were talking to this API. And during the period where we talked to this API for this part of that, we were, I don't know, issuing HTTP requests and waiting for the response or streaming something, whatever it might be. So you can have these nested scopes almost of regions of time of your execution of your program, where something is happening and events are always recorded in the context of some set of spans, where that set of spans might be empty or it might be, you know, however deeply nested you are. So to make this a little bit more concrete, imagine that you have here, I'll. I'll even pull up a file because, you know, that's what we do, just cargo, new bin. What are we going to call this one? Eventful.
00:04:54.045 - 00:05:30.071, Speaker A: Nice. Okay. Nope, Streams Eventful. So inside of here I'm going to cargo ad tracing. I'm also going to add subscriber, which we're not going to talk about quite yet. And inside of main here I'm going to use tracing and I'm going to bring into scope the sort of main macros you use when handling events, which are going to be the info and warn and error and Debug and trace. So these are all macros that allow you to emit particular events in your program.
00:05:30.071 - 00:06:25.845, Speaker A: So at a very basic level you can do things like info this happened and info that happened. My keyboard skills today are not good. And you know, as far as we've gotten right now this just looks like logging, right? Because you're emitting info level logs that say this happened and that happened. Okay, so where spans get into this is you can have span. So span is also a macro. So I can create a span that represents will be a good example of this. Let's say that we loop over a bunch of files that are passed in through the arguments of the program, right? This is semi hypothetical.
00:06:25.845 - 00:07:25.935, Speaker A: Like I'm not actually going to write out all the code for doing this. So for file in the args to the program, what we're going to do is we're going to create a span for that file. So this is going to be something like file and I suppose it's also going to include a level and we'll talk about what the levels for spans actually mean. Pulling level here and, and then what I can do with the span is I can enter the span and this gives back a guard similar to taking a mutex. And while you're inside of that span, while you have entered that span, you can now emit events like opening the file, right? Which is going to be file, open file. I'll unwrap. For now it doesn't really matter.
00:07:25.935 - 00:08:27.617, Speaker A: Reading file contents maybe which is, you know, bytes is going to be file read mute bytes is back new. I don't actually want to write the whole thing here. Unwrap. And then maybe I have another info done reading or parsing. You know, I'm going to do some kind of parsing in here and then I'm going to be done with that done with file. And I'll bring in this so that it stops complaining on me and this so that it stops complaining at me. And crucially what I've done here is I have created a span for every file and then I have these info blocks that are or these events that are related to that span.
00:08:27.617 - 00:09:19.617, Speaker A: And so when the output for this is printed, for instance, if you use a printing subscriber, the message that is printed here is associated with the span. And the way that looks like depends on the subscriber. The standard subscriber is going to do something like emit the information for the span and then the information from here. And maybe this is actually useful to, to show you so I'm going to do this just so I can actually show you what this might look like. And I'm going to not actually do any of the operations. And if I now run cargo run, you'll see that what I get out here is a bunch of info lines. And we'll talk about what some of these other fields here mean.
00:09:19.617 - 00:09:59.705, Speaker A: But we see the time, we see the level file here is the name that we gave the span, right? So this is just file. And this actually needs to be a. This is a unique identifier for the span. It doesn't actually need to be unique, but it is a name for the span that's set statically. And I can also assign additional fields here so I can do things like F name, like file name is equal to file. And maybe here I'll do, you know, foo. Actually, no, I can just do this right here, can't I? A, B, C, D.
00:09:59.705 - 00:10:23.157, Speaker A: So you'll see here that now these. These same events are emitted for every file. But for each one we're also given this additional annotation of the file name here is A. The file name here is B. The file name is C. The file name here is D. And you might wonder, well, why is the span useful? Why couldn't I just, you know, include the file here? And you could, but you would have to include it with every logging statement.
00:10:23.157 - 00:11:03.023, Speaker A: When in reality these are sort of associated with this span. And so we can set that information once and have it be associated with all of the events that come out of it. And we could also have a span out here. So I could say span, level, info main and I could guard a span enter. And now you'll see if I run this, we're inside of main, and inside of main, we're inside the spam called file. So these can nest. Where this becomes really important is especially in things like concurrent or asynchronous programs where you don't necessarily do all of these things in order.
00:11:03.023 - 00:12:06.365, Speaker A: So as an example, imagine that instead of looping over these serially, I actually wanted to loop over them in parallel. So I would do something like, you know, thread, spawn, move. You know, if I were to do something like this, then you can imagine that the output I'm. It requires a bunch of wiring to make this not do stupid things, but just conceptually, if I spawned a thread for each of these, then what you would end up with is a bunch of these events would just be interleaved and it would be hard to track which one was related to which file, whereas with spans that's not actually a problem because we have a span profile and the logging information, the events are associated with that span. And so for asynchronous programs, this becomes so much more important. There are also helpers for getting rid of the level here. So there's like Infospan, for instance, that you can use here instead of this.
00:12:06.365 - 00:12:52.405, Speaker A: They end up being equivalent. Now going back to this. So as you saw here, you can additionally include additional attributes with spans and you can do the same thing with events. So I can say here, for example, it's a good example of something I might print here. I guess reading file Con. No, parsing would be good, would be like bytes is equal to, in this case zero, because we didn't actually read any bytes. And here it might be, you know, parsed is equal to unit doesn't want to do that.
00:12:52.405 - 00:13:32.711, Speaker A: That's fine, let's do true. And so now you'll see that these additional attributes that I added to my OR fields that I added to my events are printed as part of that event. Now, this might not seem particularly interesting when we look at just the text output of this, right? Because it's really just printing. It's just appending it all together and then printing it out. But the reason why this is valuable is because subscribers are exposed to the full structure of this. So they are told there's a text part, there's a message, if you will, part of this event. But in addition, it also has these fields with these keys and these values.
00:13:32.711 - 00:14:22.313, Speaker A: And the reason that is important is it means that you can have subscribers that use that richer piece of information in order to decide what to log or how to log. For instance, you could have a subscriber that doesn't emit human readable text, but instead emits JSON objects where all of these fields are separate objects. So that after the fact, the sort of logging output that you get is actually structured and you can parse it and you can get these fields back out. Similarly, you can imagine something like if there's a parsed field, then only include that field if the value is equal to true. The restriction on the keys here are mostly none. They need to be like valid identifiers, but they can also add dots in them. So you could say bytes number, for instance, and tracing would be totally fine with that.
00:14:22.313 - 00:15:09.805, Speaker A: Here, bytes number equals zero. But in addition, you can put any value here that implements the value trait. So if we go back here to tracing and we scroll all the way down, you see there's a value trait. And the value trait here basically needs to be able to record its own information as a, as a field. And it's implemented for a lot of the standard library types. In addition, crucially, it is implemented for anything that is an error and also for anything that implements debug or display through a little modifier. So let's say here that I have a struct foo and I'm going to derive debug for it.
00:15:09.805 - 00:16:28.985, Speaker A: And I have fields a, maybe a bool and B, which is maybe a U32. It doesn't really matter. Then if I now here, let's say after parsing I end up with a foo true and 42, then what I can do here is I can say I want to have the value being printed out here be foo and by putting a question mark in front of it. What that's telling tracing is when you log this or when you emit this event, use the debug implementation of foo. So turn it into a string, essentially using debug, and then have that be the field that gets recorded. And so if I were to run this now, you would see that here I get out the debug representation of foo and you can do the same thing with display using percentage. Foo doesn't implement that here, but if you add something else that did implement display, like for example, a path, right? So a std path path where you call dot display and you get back a thing that implements display, you could then use that with percentage here to get the string representation out.
00:16:28.985 - 00:17:11.275, Speaker A: Okay, let me pause there. I've talked for a while about attributes and fields and spans and events. Let's see if people are following whether there are things that are confusing in here. Okay, the span subscribes to info or do they both admit to the tracing subscriber? So the way this works is a subscriber, which we'll get into those way more later. But a subscriber is notified every time a span is opened, every time a span is closed. So every time, basically every time a span is entered and exited. And it is also notified when a span is.
00:17:11.275 - 00:17:38.974, Speaker A: It's informed that a span exists is the best way I can describe. And again, we'll look at the interface from the subscriber side later. And then it's also notified whenever there's an event. And if there is an event, it's notified about the spans that are currently open or it has insight into which spans are open at the time of the event. Right. Which spans have been entered. This ties into Another question here, around the guards.
00:17:38.974 - 00:18:25.593, Speaker A: So it is indeed the case that when the guard is dropped, the span is exited. So an event that happens after the guard is dropped is not considered part of that event. And we can see that down here. Like if I and it will be dropped automatically at the end of the scope, right? But if I go, if I drop the guard here and then I do a hello infolog here, then you'll see that the hello is not part of file because the guard was dropped, but it is part of main because the main guard is still present. And it's important here that this is not just an underscore because underscore will drop the thing immediately. So it has to be assigned to an actual variable. And the reason we use the underscore here is because otherwise we would get a warning saying that this variable is unused.
00:18:25.593 - 00:19:28.193, Speaker A: The underscore tells Russell we're expecting it to be unused. What happens if you were to add a field to the parent span, thinking along the lines of having a request id? Yeah, so the file name here is a good example of that, right? We have a field on the parent span and that becomes available an available piece of information for the subscriber for every event within that span. What happens if the span is a different level to the log? Okay, so this is a pretty common question, which is what does the level of the span have to do with the level of the. Of the events? And we can try this out pretty easily. So let's say that I now make this a level worn and I Lee and I say this is also a warn. So let's just see what happens. You'll see that the nothing actually happened when the span became a warn, but you'll see that the event that became a warn is emitted with sort of the warning level.
00:19:28.193 - 00:20:24.747, Speaker A: And so you might wonder, well, why are the. Why do the spans even have levels? And the answer to that comes into play when you start talking about how you can configure configure the subscribers, in particular the formatting subscriber, which is the one we're using here, the prints to console. You can configure it and you can configure any subscriber this way to only care or only be notified of events of a particular level or spans of a particular level. And so for instance, if I were to make this, I'm going to get rid of this little noise down here. If I make this a trace, for instance, and then run cargo run, you'll notice that the trace does not appear Here. And that is because the default configuration for the format subscriber that we generated here within it is it only prints things at info level or higher. And that applies to both spans and to events, but the two are independent.
00:20:24.747 - 00:21:30.167, Speaker A: So if I now did, uh, let's say that I make this span turning this back into span, and I make this a trace level span, what that means is that span disappears completely if the logging level we're using ignores things that are or only emits things that are info or higher. Because that span, for the all intents and purposes for that subscriber, does not exist because its level is too high. But the events within that span are independent of the span, right? Like this event still happened. It's just that when it looks up the stack, so to speak, it doesn't see the span because it never existed, but it does see this span. And so this event is still emitted even though the span did not exist. The only thing that changes when you change the level of a span is just when is that contextual information recorded. It does not change whether the events within the span actually get emitted or get considered by the, by the subscriber.
00:21:30.167 - 00:22:08.515, Speaker A: And similarly if we, let's say I made this also be trace. So now there are no spans at info level, which is the default level. And then the result is we get all the events, but we just don't get any spans for them. And this can be useful. If for example level info, this can be useful so that you can change the amount of contextual information that's included for debugging purposes. For example, by changing the debug levels so you don't have to actually change any of your events. You just want to get more context for every event in your program.
00:22:08.515 - 00:22:41.727, Speaker A: Then you can use the levels to achieve that. Okay, let's see here. Would it not make sense to have an enter macro? I don't know what you mean by an enter macro. I'm not sure what it would do. But spans have other mechanisms than just guards like this. So one of the things you can do is you can call.in scope and what in scope does is that it takes a closure.
00:22:41.727 - 00:23:18.755, Speaker A: And while you're in that closure, the span is entered and when the closure finishes, the span is exited. So when we run this, we're going to get the exact same output that we did when we brought out the guard. So there's just two different ways of doing the same thing. The reason I call it a guard, it's a common word to describe something that when you Drop it, you lose access to something. So the guard is sort of a. It's standing on your behalf, right? It's standing with you and protecting you. But only for the duration that it is alive for something like user sessions.
00:23:18.755 - 00:23:48.719, Speaker A: How do you open multiple spans that are not children of each other? Ask. It's a great question. The. It's actually something where. Let me go back to the guard here. So let's say that we go back to my threaded example here and in fact, let me just actually run this join handle is. Let's do vac new join handle push.
00:23:48.719 - 00:24:27.713, Speaker A: A little bit of extra noise that we just have to have here. I guess this should be join handles. When you spawn a thread, the program does not automatically wait for that thread to exit. So if we didn't have this additional step here of join, so joining each of the handles that we get back, then main would exit. It would go through the loop, spawn a bunch of threads, and then it would reach the end of Main. The whole program would exit, which means all the threads would also exit. So we need to have this keeping track of the join handles and joining them so that we wait for all the threads to complete.
00:24:27.713 - 00:25:05.779, Speaker A: If I run this now you see that suddenly. Now these. These operations are emitted out of order, right? Like they're in all interspersed because all these threads are running concurrently. And now these spans are coexisting, right? So you have an instance of the file span for each file and they are siblings, right? They're not. They have no connections to each other. They happen to share the same span above them. Although if you look closely, and I'll get to this in a second, you'll see that here main is not included in the span stack.
00:25:05.779 - 00:25:44.653, Speaker A: And I'll talk about that shortly. I just want to address any additional questions on this part first before we talk about threads. Spans basically have a span ID and a span parent id. Yeah, that's right. So the way to think about this is that spans know if they have a parent, and events also know whether they have a parent and you can sort of walk the stack up there. In practice, it's not quite like that. In practice, what really happens is whether you enter a span or not could be a dynamic runtime decision.
00:25:44.653 - 00:26:17.317, Speaker A: So it's not a static property of a span whether or not it has a parent. The only thing that the subscriber gets to see and it gets to see whenever a span is entered and whenever a span is exited. And as a result it could be the one execution of your program. This particular span gets open and then the event gets submitted. And in a different execution, that span is never opened, in which case the event's parent ID is not set. So it's not actually. It's not actually encoded as a tree where the event has a pointer to its span.
00:26:17.317 - 00:26:52.705, Speaker A: Instead it's. It's implicit by observing the sequence of enters and exits before the event is. Is emitted. Can you put large things in a span or does it have to get cloned because of the thread safety or something? Ah, so this is also a very good question. If I here put like a blob is like a vacuum with capacity, some giant capacity. Right Then question mark. Bull.
00:26:52.705 - 00:27:46.203, Speaker A: Great. So is this gonna, you know, significantly slow down my program? The reality here is that the information that comes out of this is going to be tracked as part of the span, but does not get cloned for every event, at least not by tracing. Instead, what happens is, when the span is entered, this information is conveyed to the subscriber and it can do whatever it wants with it. And then when the events are emitted, this information is not part of the call to the subscriber. So it's up to the subscriber whether this additional information should be kept around. Basically the event. When the subscriber hears about the event, it can know which spans it's related to, and it can know the current fields of those spans and get references to them essentially, and then choose to do what it wants with them.
00:27:46.203 - 00:28:47.033, Speaker A: If it just wants to print them, it doesn't need to clone them. Okay, let's see, what else do we have here of questions? Instead of having an underscore variable that we can enter, can use a closure or something? Yeah, so that's the in scope call that I showed earlier. Is it possible to configure the level at compilation time so that unnecessary verbose macros are discarded by the compiler? Yeah, so tracing is actually really smart about. Let me get rid of this about avoiding doing things if the levels indicate that no one is interested in that particular span. So you can do this at compile time. If we go here and look at the feature flags. Where is my here feature flags? No, that's not what I wanted.
00:28:47.033 - 00:29:24.951, Speaker A: I want here. So you'll see that there's a bunch of features you can set on the crate that specify what the max level of events that should be emitted should be at compile time and anything that is below that level. So. Or this is max level. Right? So it is the level under which nothing should be emitted. So if you Set for example max level warn as a compile time or as a feature of the crate, then anything that's below warn level will simply never happen. It will just be excluded at compile time at no cost.
00:29:24.951 - 00:30:01.141, Speaker A: But even if you set max level trace like you basically you say that all of these could happen. Tracing is quite good about eliminating early calls to something like trace. So give an example of this. One of the ways in which you can configure a subscriber is using something called an end filter. And we'll get a lot into layering subscribers and filters later. But you can often set rust log equals trace. For example, to you see, I set this environment variable rust log and here I set it to trace.
00:30:01.141 - 00:30:55.435, Speaker A: You can set it to a lot of fancy things that we'll look at later to say that I want everything at trace level and above to be emitted. And now suddenly you see these trace calls also get emitted. So here there was no compile time exclusion of them because then evidently this would be impossible. I didn't change any compile time settings. So this was entirely determined at runtime whether or not this should be emitted. But the cool thing is that if I do this, tracing is smart enough to have a Basically it has a very, very cheap check at every event where the macro is defined like the code that the macro expands to, that checks whether that event's level would actually be consumed by any subscriber. And if there are no subscribers that care about that level, then nothing more happens.
00:30:55.435 - 00:31:31.079, Speaker A: Like the fields do not get packaged up, they don't get shipped to the subscriber, the subscriber doesn't get called at all. It's just eliminated super early. And so while you can set this at compile time as sort of a max level, it often is not necessary. The performance implications are usually not too bad of doing it dynamically. Okay. Any tools to read the output easier? Yeah, there is, there is. For example.
00:31:31.079 - 00:32:16.745, Speaker A: Oh, if I get rid of this for a second just to get back these. There is a way where in which you can get the tracing subscriber here to print basically a tree representation rather than a flat listing. So if we go here, look at tracing subscriber. I wish that linked to the docs instead, but it does not. And then we go into format. Then I thought there was a way to configure this to say tree. Where's the subscriber builder? Or is it just a completely separate subscriber? I forget.
00:32:16.745 - 00:32:39.611, Speaker A: Ah, pretty. Is it pretty? That gives me a tree. I forget now Yeah, I think it's pretty. So in that case I need to go here version is this features. Oh, the tree is separate. That's what I thought. Okay.
00:32:39.611 - 00:33:00.093, Speaker A: Yeah, because pretty is just. It's just prettier. But it's not. It's not the same. But it is called trace. Is it tracing trend? Oh, there we go. I don't remember what it's called now.
00:33:00.093 - 00:33:40.847, Speaker A: Well, it's not terribly important there. There is a way where you can have a subscriber that instead of just printing a flat log, it will actually print a tree representations of the spans, which can be really nice. Okay. Is it possible to create a span that isn't part of the current tree? How do you break free out of a parent? So let's say in here that you wanted this pan, but you don't want it to be associated with main. There are ways to do this. So if we go look at the span macro here, an event does the same thing. So span.
00:33:40.847 - 00:34:13.734, Speaker A: You'll see that there are a couple of things you can set. You can set target. We'll get back to target in a second. Because a parent, you can set the level and then you can set name and then these fields and the parent here is the critical one. So the parent that you set parent is. So for the parent, you can specifically say. I don't want this to be associated with any given Spanish as my sort of parent span here.
00:34:13.734 - 00:35:02.685, Speaker A: And so if we look up here at where is the. Yeah, so if the target and parent span are not overridden, they will default to the module path as the target. And the current span is determined by the subscriber. And I believe you can set the parent to like none. But I don't actually now remember what the syntax for that is. Maybe it's documented on event. I thought you could set it to unit, but maybe I am mistaken.
00:35:02.685 - 00:35:47.869, Speaker A: I guess you can always set it to span empty or new root or something. Ah, span none. And this has to go before the level and span like so. So I can set the parent span of the span to not to be the none. Spanish meaning it won't have a parent. And so when I now run this, you see all these files don't have a main associated with them anymore. You said the listener only gets the entering and exiting of spans.
00:35:47.869 - 00:37:19.755, Speaker A: Can I get confused with multithreading? It's a great question that I'm about to answer. How do you efficiently get tracing arguments to include it in an event so they won't be fetched if the Log level isn't to be printed. Ah, so if you have, if you have some field for a macro that's expensive to compute, right? So imagine you wanted to do like foo is some expensive operation like this, and you don't want this to be computed. If the level isn't used, then we can actually go look at the trace macro here and then we'll go look at the event part of that. Where's my macro rules event? And you'll see here in the definition of this macro, the fields in here are actual field list that you specified and down here the value set, which is the thing that actually computes the fields, is only expanded. That list of arguments is only expanded inside of this Check for if enabled. So if the macro, if the level is not enabled, then the fields are not, they're not evaluated.
00:37:19.755 - 00:38:00.837, Speaker A: And so therefore that expensive thing would not be computed. So it's totally fine to have this kind of thing and the expensive operation would not be evaluated. That expression would not be evaluated if the trace level was not enabled, including if it was dynamically enabled or disabled. How does this work in async functions? If I open up a span at the start of an async function, will it only be associated with events called in that same future? Also, great question. Also related to threading, which I'll get to in a second. Oh, you can do colon none. Interesting.
00:38:00.837 - 00:38:33.113, Speaker A: I guess that works too. Nice is a way to hand off a span to some fire and forget background task while the main thread that started the span continues. Yes. So if you have a span, the span is just a. It's just a type. Like if we go here, like span is just a struct and it implements clone. And so if you create a span on some thread, you can then clone the span and hand it into another thread.
00:38:33.113 - 00:39:27.513, Speaker A: Or a different future, you could send it on a channel so that that other thing that receives it can then resume emitting events within that span. The span is not constrained to the place that you created it. Can a tracing subscriber obtain immutable reference to one of the values provided? No, I don't think so. Okay, so now let's go into this sort of async and threading. How does that work? So let me bring back this code, get rid of the parent stuff, bring back this, and bring back this. Okay, so when we ran this code with threading, we noticed that the main span disappeared. And the reason why it does that is because when you enter a span, that information about what you entered is a thread local piece of information.
00:39:27.513 - 00:40:17.195, Speaker A: So you, you cause the current thread to enter the span. This means that anything that happens on a different span, sorry, on a different thread, will not pick up the information from that span. It will not be aware that it's within that span. So even though we entered here, what we really did is we entered the span on the main thread when we spawn these threads, those are different threads and they are not aware of the, the span that is currently being used on the main thread. So every thread gets its own current, current span information. And so that's why this information, this, this enter in here affects all of the events within it. And tracing does not get confused about like one event in one thread versus one event in another.
00:40:17.195 - 00:41:02.765, Speaker A: Because the information about which span we're in is per thread. And that's also why this does not translate into this thread down here. Now, there are ways in which we can do, make this do the right thing. So for instance, if we look at the methods on span, you'll see here that there is. Sorry, that's not the thing I wanted. What I wanted was because spans are clone, you can absolutely here say, you know, span is span clone. And then here do let guard is span enter.
00:41:02.765 - 00:42:15.417, Speaker A: So here we're, we're reentering the main span on this thread. And so the span can be entered on multiple threads at the same time. And now if you run this, you'll see that the main span here came back because now we have entered the span on this thread as well, on each thread as well. So that's one way to go about it, right? You just clone the span and you use it in all the places that derive from that span. The other way to do this is very often you don't really want to create your own spans this way. So let's, let's try to move this logic over here into its own function. So I do on thread, and it's going to take a file which is going to be a string down here and up here I'm going to do on thread of file, right? So what I've done now is I've moved this function into its own, into its own function.
00:42:15.417 - 00:43:09.685, Speaker A: And now first of all, I can get rid of this thing right here, this span right here. Because tracing provides you with an instrument macro that you can use to automatically create spans on functions. So here I can say instrument. And now tracing will automatically create a span for this function that includes all of its arguments as fields. So if I run this now, you see it now prints on thread Instead of printing file that we called it previously, like it names it after the function, but other than that includes the information of the arguments. And that span is auto entered when that function is called. So that's neat, but it's still missing main here, right? And the reason for that is because this thread still does not know that it should be in the scope of the main span.
00:43:09.685 - 00:43:45.375, Speaker A: Up here, when you're writing normal threading code, there's not an easy way to work around this, but there is a very convenient way to do it. In async world, there is span. You know, we could do span is span clone. And then in here we could do span.in scope on thread. Right? So we're basically entering it within the thread as well. That's the most straightforward way to do it with threading.
00:43:45.375 - 00:44:30.011, Speaker A: But I'll show you in a second how this interacts with async. All right, questions on this part before I move on. Does this also apply to Tokyo Task? I'll talk about futures in a second. Is this what span follows from is used for? No, so follows from is a little bit different. So it's not a parent child relationship. Follows from is more of a sort of hint to the subscriber that this span happened after some other span. And there's not that.
00:44:30.011 - 00:45:29.025, Speaker A: Like it's not an encapsulation relationship where the outer span, the inner spans, time is a part of the outer spans. I don't whether this gets used, I think depends entirely on the subscriber. I don't think this information is actually used by the formatting subscriber, at least as far as I remember. Yeah, sibling relationship, if you will. But. But it's specifically intended to communicate the one sort of happens before the after, right? Hence the name follows from. So it's usually used for things like you have one thread or one task that creates a bunch of other tasks, and the span for each of those other tasks, you might say, follows from the span of the thing that created those tasks in the first place.
00:45:29.025 - 00:47:01.225, Speaker A: Okay, so now the question becomes how does this translate to futures? So let's now go here and do cargo Add Tokyo features full. And so now our FN is going to be Async FN main with Tokyo main. And so now this is going to be Tokyo Spawn. Instead, I'm just sort of translating this to async code and I'll get rid of the little cheats that we did. And this is now an Async FN unused implementer of future. Right? And this system await okay, so this is now converted into async, right? And we still use the instrument macro. And if I now run this, you'll see that it actually still produces the same stuff, right? Like nothing actually changed.
00:47:01.225 - 00:48:02.315, Speaker A: And that's because the instrument macro here is aware of async functions and know how to treat them properly. But let's now try to go back to the way that we used to have this. So with manually opening our span like this. So if I run this, you'll actually see that it still produces reasonable outputs. But where this gets really awkward is that remember that these, these enters into spans are thread local. And Tokio fundamentally is a work stealing executor, which means that if you have a future, it might run on one thread for a while and then if it yields, like if an await call ends up doing having to wait, the future will be suspended and then be resumed on a different thread. But therein lies the problem, right? That the, the thread that just yielded control, it doesn't know to drop the guard.
00:48:02.315 - 00:48:42.945, Speaker A: So that thread is still going to think that it's in the span even though some other future is going to be run next. So that other future is now going to be potentially running on the other thread. And it gets real confusing and you might end up with events being associated with the wrong spans. But also when the, when the future eventually resumes on a different thread, that other thread doesn't have the current span set because that other thread didn't run span enter. And so suddenly the events in that when the future is resumed might not be associated with any span. So this just is completely wrong. We're not going to see that here because there are no await points.
00:48:42.945 - 00:49:24.015, Speaker A: But if I for example, here try to put in Tokyo task yield now, we might see it if I run it. Just run a lot of yields now and see what happens. See if I can cause this to get disconnected. Let's have this also include file. Oh, this is a handy shortcut by the way. Instead of writing file equals percent file, you just write percent file and I'll do the same thing. The same works if the type directly implements value.
00:49:24.015 - 00:50:20.735, Speaker A: So now that I'm adding the file field here, right, it should be the case that the file from the span always matches the file from the event. Let's see if that's indeed the case. Seems to be true here, so I might not be confusing it enough. Do a bunch more yields, see if I can make it confused. I really wanted to use have other threads pick up the future here. Maybe Instead, I'll do sleep. And obviously now I don't want to do this.
00:50:20.735 - 00:51:00.123, Speaker A: See if I can now make it be confused. Yeah, so here, for example, you see the span is for filename A, but the file in the event is B. So it got associated with the wrong span. And you'll even see that there's some events that aren't associated with the span at all. And again, it's because of this problem that the guard is really kind of guarding some thread local state in here. When you call enter, you're making the current TokyoWorker executor thread be in that span. And when you exit down here, you're making the current Tokyo executor thread exit the span.
00:51:00.123 - 00:51:26.795, Speaker A: And then all these events are whichever span the current Tokyo executor thread is in. But because futures can move between threads, this gets all wrong. And so that might make you wonder, okay, why did this work? Right, if I run this, this is not going to be confused. So here you see C maps to C, B maps to B. None of them are missing their span. I can run it again. You'll observe the same kind of output.
00:51:26.795 - 00:52:09.147, Speaker A: And the reason for this is when you use the instrument macro like this, the instrument macro will actually take the future that comes out of this function and make it so that every time the poll function is called on that future. So this is like the deeper mechanics of future. Basically every time the future is resumed, it enters the span, and every time the future yields, it exits the span. And so that way, rather than making the. You're basically tying the parts. Only the parts where the future is actually executing only those parts do associate with the worker thread with the span, and not any other time. The other way you can get to this is if you go back to what we had here.
00:52:09.147 - 00:52:41.971, Speaker A: Let's say that we still construct the span up here. So we don't want to use the instrument macro. Instead we want to have this. We want to have the span created up here. Now, this of course is going to have the same problem, right? The during the execution of this, we might yield the thread, we might get confused. But there is another way to do this, which is there's also the instrument trait in here. And the instrument trait allows you to attach spans to a future.
00:52:41.971 - 00:53:32.337, Speaker A: So here I can say, you know, on thread here returns the future, it's an async function. So I can do dot instrument and pass it a span. And that will do the same thing as what the instrument annotation on this asynchronous function did earlier, which is every time the future is resumed, it'll enter the span, and every time the future is about to yield, it'll exit the Spanish, which then again has the same effect of the spans are not correctly attributed to every time you're within that future. Okay, that's a lot of threading and tasking questions. Does the use of instrument with recursive functions keep the span parents alive? Yeah. So if you have a. If you have a recursive function, you'll end up with a span for every invocation, and those spans will be nested.
00:53:32.337 - 00:54:55.169, Speaker A: So you'll end up with a potentially pretty deep nested set of spans for every level of recursion. What is the practical application of these spans for Rust users? So, so the point of the spans is that you can have events that are related to each other, like all of the events that happened while processing this particular file, or all of the events that happened while processing this particular user request, or while, you know, interfacing with this particular TCP connection. So it lets you, like, imagine something goes wrong, like there's a crash of some kind, and now you know that the crash happened while processing that HTTP request. But your server is handling like thousands of requests a second, so your logs are super long. What you really want is you want to extract just the events that happened for that request. Well, the association with spans will help help you here, because you can take the log and then you can prune it down to only the events that happened within the context of the span where the crash happened, and everything else goes away. So what you're saying is that there should be task local variables.
00:54:55.169 - 00:55:43.045, Speaker A: I mean, there are task local variables, right? This is the thing that exists. And you could imagine that the guard went there. It gets more awkward to implement a library like tracing based on that. But in theory, yes, it's possible. So with instrument, does the span get saved as part of the generated future? Yes, that's exactly right. So if you look at the signature for the instrument method here, it returns an instrumented self, right? So the self here being the future, and instrumented being a wrapper type that also implements future. And in fact, if we go look at it, the instrumented type that you get back from instrumented is really just a span plus an inner, which is the inner future.
00:55:43.045 - 00:56:24.211, Speaker A: And if we look at the implementation of future for instrumented, what it does is it. Well, this is PIN stuff, but it calls span.enter and then it calls poll, right? Which is the way you resume a future and when poll returns, then this poll will return which will drop this guard which will exit the span. That's the entirety of instrumented. There's no more magic to it. Couldn't they have avoided all this by abusing the borrow checker, forcing you to pass the span to the macros? So you could do that, right? You could force the span and you can. Right.
00:56:24.211 - 00:56:56.467, Speaker A: Like there's a. The. The parent attribute that you can use for these events do allow you to specifically say what the span parent is. The downside of doing this is now you have to pass the span everywhere and it pollutes all your function calls because they all need to take a span parameter and it just. It gets really annoying. So the implicit state is usually nicer, but it does have this one foot gun. Is instrument then only or mostly useful when working with futures? Sort of.
00:56:56.467 - 00:57:53.795, Speaker A: So even. Even in the threaded case, so when we weren't using async, having the instrument on a function is still useful because it gives you a sort of automatic span for that function. And if you tend to assume that functions are, you know, bodies of related computation, then it kind of makes sense that you want to span for the function anyway and the instrument in macro will create that for you rather than you have to write, you know, let span equals span, set the fields and then enter the span. So I think it is still useful even in the non asic context. The instrument function, like the instrument trait that adds this helper method on futures, that one is only useful when you're using futures. Only in async context is it okay for a parent span to go out of scope in terms of offloading them elsewhere? Yeah, I mean parent scopes, parent spans can go out of scope. That's fine.
00:57:53.795 - 00:59:25.695, Speaker A: All that generally matters for both for opening spans and for emitting events is which which spans are currently entered. So the moment you have entered them, you can then exit the parent span. And now if you emit an event, that parent span will just not be considered one of the spans that are entered at the time. Is it possible to print the span enter and exits to see the async mechanism clearly? I think there is a way to emit to turn on the logging output of tracing itself and it shows you information like this. But I don't remember off the top of my head how you do that. Can you have an overarching spam that can peers through the inner asyncs like a span that tracks a user session in a server request? Yeah, I mean that's sort of what this Is right. You can imagine that instead of file this like accepts new connections or something and it sets a span that is like in a user request and the user is, you know, some user id and then handle user request right of, you know, whatever the request is and instrument it with the span.
00:59:25.695 - 01:00:29.195, Speaker A: And now any event within that future, including nested futures, is going to be associated with this span. How do you instrument every method globally? Are there global decorator macros? No, there's not a way to say Every function should always get a spam by default. Not a thing. And it would be hard to even do in rust because you don't really have a way to write code that is told about every function definition. It would have to be like a full text pre processor, even like proc macros to require that there is actually an annotation on the function. What happens if a subscriber blocks when it's notified of an event that was produced in async context? We'll talk about that when we get to subscribers. How not to include the parent span with the instrumented macro.
01:00:29.195 - 01:01:13.795, Speaker A: If you use the instrument macro, let's go back here to the tracing docs. So if we look at instrument, you'll notice that you can set things like you can name the span, you can set the target. We'll get back to in a little bit later. You can skip fields saying like don't include this as one of the fields on the span. And I believe you can also set the parent. Yeah, parent equals none to say I don't want this to be associated with whatever span is outside of here. Um, I'll add one more thing here, which is, let's say that I did this guard is span.enter.
01:01:13.795 - 01:01:45.723, Speaker A: because I had a bunch of code here that I wanted to run on. Then what do I do down here? Is there a way where I can still instrument this thing using the span? I can't pass span here because span is owned. Right. And so I would need to. I would need to do span clone. And you can do that or you can do in current span which is also a. It's like a helper method on the instrument to trait that just looks at what the current span is, clones it and then uses that as the instrument of things.
01:01:45.723 - 01:02:22.419, Speaker A: So this can be a handy way to combine these if you ever end up having to. How can tracing trace itself? Wouldn't it produce infinite tracing? Cycle tracing doesn't trace itself, but it has a way to basically emit just straight messages for debugging. So it's not really. Tracing. Tracing itself. Oh, hey Stephen. Visualizing entering and exiting span.
01:02:22.419 - 01:03:12.955, Speaker A: You can make the subscriber print the enter and exit events as well. Oh, maybe I can do that easily. Subscriber builder default init. So this is just instead of using the init method directly, which in fact I can show you the init method directly calls tryinit. Tryinit calls subscriber make a builder and then adds a bunch of standard layers to it. We could replicate all of this and then have it also do subscriber builder.in it and then I would want to also replicate all of this code, which is a little bit annoying.
01:03:12.955 - 01:04:40.205, Speaker A: I can do this tracingsubscriber.in it. What am I missing? Oh, is it tryinit? I need to like tryinit unwrap. Wait, why? Why is it allowed to use crate? That's unfair. Oh, maybe I need to tracing subscriber features and filter something else I'm missing here. Subscriber builder. Why? Oh, I might need dot finish.
01:04:40.205 - 01:05:28.987, Speaker A: What? It's confused somehow.finish. Try init. Why is it not letting me do that? Format subscriber. Oh, default envelopes. The max level of error. That's why. Which is why rust log equals trace for example.
01:05:28.987 - 01:06:09.183, Speaker A: Great. Okay, so now we're getting those outputs. And with this I should be able to do with span events Format span. Why is it being annoying about this full. So if I now run this. Yeah. So here now you can see all of the enter and exit events and also close events, which is when the last instance of a span goes out of scope.
01:06:09.183 - 01:07:02.195, Speaker A: So you can see all of the little events and all the spans. Is there a way to compile the program to emit all tracing functionality? Yeah, so you can set max level off. So if you look here at the this one, there's a max level off which just turns off all tracing and statically at compile time too. I do incurrent span before every await. Is that necessary or am I misunderstanding what it does? So in current span you should only ever need this bit right here. You should only ever need if there's a. If there is a span enter that you want to capture, that's the only time that should really matter.
01:07:02.195 - 01:07:48.115, Speaker A: Because the span if the span comes from something like instrument here or the span comes on like an incurrent span that's in the future around you, that will take care of entering the span and so you won't need to do it as well. The exception to this is if you want to do something like Tokyo Spawn, because Tokyo Spawn is going to run on a different task. And so now you. It's basically going to construct a new top level future. And so now there's no longer a future outside of you that's going to enter the span on your behalf. So then you do need to instrument it at the time when you create the future. So for this we do have to use in current span, but that's really the only case.
01:07:48.115 - 01:08:35.974, Speaker A: And I want to get rid of these again because those are annoying. Okay, so now we have a sense for how these events work. We know roughly, you know, how they relate to spans, how you open and close spans. So let's now go back to the docs here and look and see if there's anything we've particularly missed. We haven't talked about targets yet, which I'm aware of, so I'll touch on that in a second. But let's see here. So we have events, we have spans, we have events, events of fields, they have levels, subscribers we'll get to later.
01:08:35.974 - 01:09:05.155, Speaker A: Spans can be entered, they can be instrumented. Events are within the context of a span. There are additional attributes like level and parent and target and name. Recording fields we've talked about, we've talked about debug and display. Okay. Shorthand macros, those are fine. We've talked about those.
01:09:05.155 - 01:09:50.490, Speaker A: Log compatibility, I think I'm going to skip over, or rather just mention briefly. So the tracing crate has support for compatibility with the log crate, and it has support for compatibility in both directions. So the log crate is a very commonly used logging library, especially before tracing came around. So tracing can both have log events from log from the log crate be emitted using a tracing subscriber. And it can also have tracing log invocations. So like tracing events be emitted into a log consumer. So both directions are possible.
01:09:50.490 - 01:10:25.395, Speaker A: So this means both. You could have a library that's written using tracing, and if an application that uses log wants to use that crate, it can still actually get events out through log. And similarly, if you have an application that uses tracing and you have a library you want to use that uses log, those can both. Those situations can both work. You can usually not have both turned on at the same time because then you. Or at least you're not going to want to, because you end up with weird cycles where you. It's not actually a cycle, but you end up with double logging a lot of your things.
01:10:25.395 - 01:11:12.489, Speaker A: Okay, Right. And then there's a. So you saw that I here instantiated a new tracing subscriber that's only a thing that you should need to do in the place where you want to emit the output of tracing, right where you want to consume the events that are produced. So if you're running a library, for example, you should almost certainly not have a subscriber in there. The library should only ever be emitting spans and events and not actually be consuming anything or instantiating a subscriber. You should leave that to the application. If you're an application author, you do want to instantiate a subscriber, maybe potentially multiple.
01:11:12.489 - 01:12:20.753, Speaker A: We'll talk about that later. But you're also free to emit your own tracing spans and events. Okay, that's log related crates. So these related crates are mostly about different kinds of subscribers, which again, we'll get to in a second. And it's about additional helpers for emitting certain types of events or events in certain contexts. So tracing futures, for example, allows not just attaching things to futures, which you can do with instrument, but also to streams and executors and that kind of stuff. Most of these other ones are either subscribers or like, for example, Axum Insights and Tracing Actix Web are all crates that add tracing events and spans to existing frameworks so that you can, for instance, you know, plug and play in a middleware in Axum, so that every request automatically gets its own tracing span.
01:12:20.753 - 01:13:26.825, Speaker A: So it's that kind of integration. But those are all separate from the tracing crate itself, which just provides a sort of mechanism for emitting these spans and events and tracking them and the subscriber machinery that we'll talk about in a second. Okay, so the last bit I then want to touch on before we go to subscribers is this notion of a target target is not particularly complicated. It's just the reason I wanted to separate it is because it just feels kind of disconnected from the rest. So, so every span and every event has an associated target, and the target of a span or an event defaults to the module that the event or span occurs in. So if we look back here, we're in main of a crate named eventful, and in that case the target is just going to be eventful because we're in the. We're in the root tier.
01:13:26.825 - 01:14:44.107, Speaker A: If I went in here and said, you know, mod foo and I put on thread inside of a mod foo and then here do foo on thread and I make this be pub super and then I guess I will use super. So, so if I now run this, then the target in here is going to be eventful, colon, colon, foo. Because that is the path to where those events happen, the module path. And you'll see that here it appears in the sort of grayed out bit in the middle. And what target is useful for is mostly related to filtering. Basically the target is exposed to the subscriber as a sort of this is where the event happened. And the reason this can be useful is that you can do things like eventful equals trace, hyper equals info, right? So if I was using hyper in here, what this would mean is that any event or span that happens inside of the hyper crates module, which I don't have, the hyper crate, is not in use here.
01:14:44.107 - 01:15:35.587, Speaker A: So it would be nothing. But anything that occurs under there should happen in only at info level and above. Whereas anything that's in my crates, anything that's ineventful should be trace level. And so here, you know, I could imagine that for my own application I actually want to really trace deep into what's happening, but I don't want to give this that I had before rust log equals trace because if I do that, what I end up with is trace from all of the libraries that my code uses, right? It's trace all the way down and applies globally in the program. Whereas by using the targets I can scope these definitions to only where I need. So imagine that I start debugging my application. This produces a lot of information too.
01:15:35.587 - 01:16:33.855, Speaker A: So I might want to say, well, for eventful I want info level, or maybe I want debug, right, Because I'm debugging. But for eventful, colon, colon foo I want trace. And so now I get trace events from inside eventful foo, but I only get debug level things for the rest of eventful and for hyper I would only get info. And so this allows you to sort of scope out which events are relevant to you. The other reason that or the other cool thing about targets is that you can override them. So imagine for instance that I wanted to keep metrics might be a good example here. So I want something like target metric and I want name to be parsed and then I want to log bytes is 42 and maybe I don't even want a message for this one.
01:16:33.855 - 01:17:06.553, Speaker A: Oh, maybe there aren't. Maybe name has to come first. Macros are awkward beasts. So what I'm doing here is I'm setting the target. So instead I'm saying instead of using the module path here, use this as the name of the target. And here metric is just an example. But you could imagine for instance, that you take all the metrics in your program and set them to have target metric.
01:17:06.553 - 01:17:42.895, Speaker A: And so that way people can turn on and off the metrics independently of where they're located because the metrics are their own target. So here I could say, you know, what level is this one? So let's, let's make this metric be debug. So let's say that for eventful, I actually want info. Start there. So eventful is info. So that means I'm not going to get this metric out because metric was a debug level thing. So there's no debug levels in my output here, but I can say metric equals debug.
01:17:42.895 - 01:18:41.465, Speaker A: And now you see, I do get the debugs for the metrics here, but if I made this also be debugging, so this one I'm not overriding the target for. Then you'll see for this one there's no, the, the, the parsing output here. There's no parsing message that has come out here because that's debug, but it's not a metric. So that's where tracing is useful. Sorry, target is useful is for specifically saying this event or this span is like related to a different facet of the application almost. It's almost like a different dimension compared to the sort of name of the span, for instance. Okay, if that made sense, let's, let's first check questions.
01:18:41.465 - 01:19:23.165, Speaker A: But if that all makes sense, then we're going to switch gears and start talking about subscribers, sort of the other half of tracing. Okay, let's then switch to the other half of tracing. This can go away. This can go away. Okay, can you have multiple targets? No. Every event and span needs to have only one target. I wonder if tracing can access the token stream in case we want to log out line numbers and such.
01:19:23.165 - 01:19:59.243, Speaker A: We'll get to that in a second. But no, tracing does not expose token streams. It is not in fact a procedural macro at all. In fact, if you. We did this earlier, right? But if I go to definition on trace, it is a declarative macro with just a lot of branches. And if I go to macro rules event, the entire event macro is also just a giant declarative macro. And one of the primary reasons for this is declarative macros are way faster for compile times.
01:19:59.243 - 01:20:35.975, Speaker A: Procedural macros tend to add quite a bit of delay because you need to compile a program to run over your program before you can compile it. And that, that adds a non trivial amount of latency. But so as a result it doesn't. It's not given access to the token stream. However, subscribers do get access to certain compile time information or static information about the events. And we'll see that in a second. All right, let me drink some water so I don't die.
01:20:35.975 - 01:21:33.665, Speaker A: Okay, so back up here to subscribers. So the core of the, the core of subscribers is perhaps unsurprisingly, the subscriber trait. So if we go look at the subscriber trait, it has a bunch of methods, only some of them you need to implement. And these are all of the things that a subscriber must handle in order to be used as the subscriber for a program. In tracing, you have two ways to set the subscriber. There is and I'll show you this. How do I want to do this down here? So I find the module subscriber and you'll see that there.
01:21:33.665 - 01:22:09.907, Speaker A: Let's ignore set default for a second. There is set global default and there is with default. Set global default is a method that will choose which subscriber is used everywhere in your program. So it's not a thread local. It's not local to a closure. It sets it in a global static that every event, every span will go check this global static to figure out what the subscriber is that they should send their information to. When you set a global default subscriber, that is the thing that everything will use.
01:22:09.907 - 01:22:47.169, Speaker A: If you call this method again with a different subscriber, everything will switch to use that other subscriber instead. So these do not stack. There is only ever one subscriber in this setting. There is also with default, and what with default does is you, it takes a closure. And during the execution of that closure, the current thread, and this is, this is thread local. The current thread will think that the global subscriber is the one that's passed in. And this is why this doesn't actually use the word global, it uses default.
01:22:47.169 - 01:23:34.795, Speaker A: Right? So the way to think about this is that when you emit an event or a span, it goes to the default subscriber and the default subscriber is the one that is set for the current thread through with default. Or if no such subscriber is set the global default. And so as a result, from the perspective of any given event or span, there is only ever a single subscriber. There are never multiple subscribers to choose from. There's only ever one, and that is the one that receives information about the spans and the events. So if you now look at the subscriber trait, what you'll see Here is there's a function enabled and I think there's docs for this further down. The docs here are pretty good as well.
01:23:34.795 - 01:24:59.175, Speaker A: Enabled is a method that will be called on the subscriber once for every call site. So basically for every single appearance of span, event, info trace, debug, warn, error and similarly for all the spans, like basically all of the tracing event and span macros for every single one, every single appearance of one in the in the source code enabled will be called once for the subscriber. And the subscriber gets to choose whether that particular call site is enabled or not. Essentially do I care about that event? And if the subscriber answers no, if it returns a false here, then that event will just never be triggered. So we looked at the code for this earlier and I'll show you here again down here. So this is the event macro, which is what all like the info trace, debug, all of them expand to this macro. You'll see that it constructs this call site thing which is a static and then it checks the crate level enabled is is checking the compile time flag for the maximum level.
01:24:59.175 - 01:25:59.895, Speaker A: And assuming it's not excluded by that, then it will call interest, which among other thing is going to use is called enabled on the subscriber to see whether the subscriber believes that this particular call site is enabled. And if it is not like this whole code that expands the fields and everything just does not happen. So it's a very easy way to exclude subsets of events completely. And if we go back and look at what information enabled gets, it gets one of these metadata things. And a metadata describes a span or event, but it describes only the information that is known statically. So here you'll see it gives the name of the spanner event and the name. If we go down here, if the name is not set for an event, let me go down here and find one where the name is not set.
01:25:59.895 - 01:27:06.825, Speaker A: Where is the fallback for these target, parent level, message. Aha. So if the name is not set for an event, then the name of the event is event space and then the file and the line. So basically the information about the exact location of the event is the name of an event, unless you have overridden it was something else, but ignoring that for a second. So you see, it constructs this set of static information, which is the name of the event which is statically known the kind in this case it's event. It could also be span the target which we specified the level which is also known statically, right? Like it's written in the source code, it's not determined at runtime and the set of fields. And in particular, what you'll notice here is that it emits.
01:27:06.825 - 01:27:59.055, Speaker A: Well, this is actually handled by the call side macro, which we can go look at in a second. It only extracts the names of the fields, and the names of the fields are all known statically, right? So here, bytes.number is in the source code, it is written down, it is statically known. The value here might not be. So if we look at something like this instruction, right? Parsed here is statically known, but the actual value of foo, this might be a create foo function for all we know. It's entirely determined at runtime dynamically, and so it can't be known statically. So the only thing that the subscriber gets in this metadata is the name, the target, the level, and the names of the fields that are defined by the span of the event and of course, whether it is an event and a Spanish.
01:27:59.055 - 01:29:15.295, Speaker A: And in addition, there are a couple of other pieces of information, like the file in which the invocation occurs, the line number in which the invocation occurs, and the module pass in which the invocation occurs that may or may not be available. And you'll see here that on that metadata, this is what the subscriber has available to it to decide whether or not a given event or a given span is enabled, should be, is relevant to the subscriber, and should be turned on, and should emit events during the execution of the program. And so you can, you can from this, see that like, pretty clearly you can implement something like only emit events where the level is at least this much, because level is one of the things you get access to in the metadata. And so if the level is lower than the lowest enabled level you just emit, you return false from enabled. If every event has its associated static metadata, doesn't it greatly increase the final binary size? It kind of does. So this is an important point. Every single macro, sorry, every single event and span does have its own static here.
01:29:15.295 - 01:30:29.035, Speaker A: And the size of that static is like, you know, it's the size of one of these metadata things. So it's not tiny, but at the same time, the actual number of events and spans that you have is realistically probably pretty small. And so this doesn't tend, it does increase your binary size, it's true, but probably not enough that it really matters, but it is true. Now, the big advantage of doing this by having the static is that you can, you can make the call to the subscriber once about whether it's interested in a given event and you can cache that information and use it to just not even call anything the next time or the next million times the event is submitted, because you checked it once statically. And so that ends up being a pretty huge performance boost for subscribers that are selective about what events they want. So what you're trading is a little bit of binary size for a significant performance speed up. I'm not going to cover hotel stuff, no, I'm going to mention hotel, but that's probably the extent of it.
01:30:29.035 - 01:31:26.955, Speaker A: Okay, so our subscriber gets access to this metadata to basically say whether or not a given span or event should be enabled. In addition, it's notified whenever a new span is created. And for this it is given the set of attributes that were passed to the span. And so the attributes here are the metadata, of course, like you always get access to the metadata for every event and every span because again, they're statically known. In addition, here you now also get the values for the, those fields of the span, right? Because this happens at runtime. This is a new span is actually being created and you instantly of a span is being created. So you now you are at runtime and you're given access to the values and you'll see that the value set that you get back, you can here you can visit all the fields in the value set.
01:31:26.955 - 01:32:31.723, Speaker A: And you'll notice this is a little weird, right? Like it's not, it's not a hash map where you can look it up by field or anything. You have to pass in one of these visit things. And this is similar to sort of the SERDI visitor pattern. I mean, this is general pattern of visitors. The SERDE also uses where you pass in something that implements this trait where it, the, the tracing code is going to walk the list of values and for each value it's going to call the appropriate method. So for example, if it encounters an F64, then it's going to call the F64 the record F64 method on the value you provide as part of this, this record method on the value set. And the reason it's done this way is because it means that we don't have to allocate anything, right? There's no allocation of a hash map needed because you statically know the list of fields so you can walk them and for each one you just call the appropriate method.
01:32:31.723 - 01:33:32.125, Speaker A: And so again, no allocation is needed inside of tracing. So it gives you a reference to the field. The field being the sort of the name of the field that we're walking and the value being the actual value we came across. And you'll see here that these are the value types that implement the value trait. So this is the reason why back here in this we could pass in, for example, bytes equals 42, because this implements the value trait and it would end up being a record U64 call in here. But if you use something like a, like down here, like a question mark, foo, then it does record debug, which is going to pass in a reference to the thing that implements debug, and similarly for errors for display. So if I did this and foo did implement display, what it would actually do is it would.
01:33:32.125 - 01:33:55.947, Speaker A: With the display, I believe it would turn it into a string, so it would actually allocate and then it would pass you the reference to str. But for debug, it just gives you a reference to the debug thing. See if display is actually mentioned here. Oh, display value. It might not. Yeah, it might actually not do. I see it does use record debug.
01:33:55.947 - 01:34:36.375, Speaker A: That's weird. Didn't debug. I think it's lying. Oh, I think what's going on here is that if something implements display, it is wrapped in this type and this type implements debug by calling display. That's my guess, yeah. Okay, so this implements debug by calling display. And so therefore you can use the same record here for both types that implement display and types that implement debug, because ultimately they're just a thing that you can give a formatter to and they can emit themselves into the formatter.
01:34:36.375 - 01:35:23.963, Speaker A: Why is the tracing value trait sealed? Like I can't create structs to use as values and have to flatten my structures by hand before logging. Yeah. So as David. We have David Barsky in chat, who's one of the sort of maintainers of tracing. So if I get stuck, then he can give us the correct answers. But as he says, the reason why you can't really implement value yourself, if we go look at it, you see it has this colon sealed, which is a trick you can use in the Rust trait system to make it so that no one can implement this trait apart from yourself, like in the current crate. And the reason for that is because I think they want to allow themselves to implement value for more types.
01:35:23.963 - 01:36:02.107, Speaker A: But if they want to reserve that. Right. Then you have a problem because if you've opened up the value trait so Anyone can implement it, someone else could end up implementing it for the same type that we wanted to implement it for, and then you run into problems. So that's, that's part one. And the, the other one is because I think over time the goal is actually to use a different trait than value. There's a, there's a crate called valuable question mark. Valuable, yeah, which is like a, basically a more general purpose mechanism for the same thing.
01:36:02.107 - 01:36:38.675, Speaker A: The value does of, like give me a way to visit a value of an arbitrary type. And so they kind of want to use this type instead of the value trait themselves. And so sealing it is another way to ensure that people aren't relying too heavily on the value trait. Okay, so this all stemmed for the information that you get when a new span is created. You get the information that is available about that span, which is both the static information and the dynamic runtime information. And the thing you're expected to return is an id. If we go look at the ID here, it's really just like a unique identifier.
01:36:38.675 - 01:37:23.519, Speaker A: And you see you can create one from a U64 and the expectation is that it can be turned back into U64. The rule here is that this ID needs to uniquely identify that Spanish among all of the spans that currently exist. And the reason why this matters is because you see here record. I'm going to not talk about record right now because I haven't talked about placeholder fields and spans, which I guess I will talk about shortly. But if we look at something like enter and exit. Right, so enter and exit are called whenever a span is entered and whenever a span is exited. And the only information the subscriber gets is the ID of the span that was entered or exited.
01:37:23.519 - 01:38:17.805, Speaker A: And so as a result, it has to be the case that every time a new span is created, the ID that it returns has to be unique among all of the spans that exist. And then when you enter, you know that like this ID maps exactly to the one span that was created here. And the reason I phrase it that way, as opposed to saying it has to be globally unique, is that after a span is dropped, I forget whether it's drop or. Yeah, it's close. So this close method is called whenever a span ID has been dropped and it's supposed to return. True, if there are now zero IDs that refer to that span. And when that is the case, it'll call this drop span.
01:38:17.805 - 01:39:21.287, Speaker A: And there's a little bit of deprecation going on here. And some of the docs are a little hard to tune out. But the basic idea is that at some point there are no more instances of a span like you know, that that span will never be entered again. And the moment that happens. So basically whenever try close returns true, then it is actually safe to reuse that ID because there are now no spans that have that id, and so it is safe to give it to a new span, because when you get that ID from enter, you know, it must be the new span and not the old span, because the old span didn't exist anywhere. So hence the ID does not actually need to be globally unique forever, it just needs to be unique among all the currently active spans. Does it generate a random number or does it use some sync primitive to make them in a stack like pattern? Does it use something else? Well, so notice that subscriber here is a trait, it is not an implementation.
01:39:21.287 - 01:40:17.519, Speaker A: And actually writing a type that implements this trait is non trivial. And what we'll see that when we get to the tracing subscriber crate, which provides a lot of the mechanisms for trying to build your own subscriber record follows from is the sort of inverse implementation of the follows from method that we saw on spans. Event gets called whenever there's an event and event, unsurprisingly, the sort of value that's passed to event is a thing that holds a bunch of fields. Static metadata is root. I think it's just whether it has any spans above it. And record here is the way where you can give a visit to walk all the field values of that event. And you see here you can also ask whether the event has an explicitly specified parent.
01:40:17.519 - 01:41:18.195, Speaker A: So again, the event does not actually keep a parent pointer, right? It is up to the implementer of subscriber to keep track of which spans are currently entered whenever this method gets called. So this method is just if this event specifically has like parent colon some span, that information comes in here, but it's not a general purpose like what is your span parent pointer. And this is because it's not actually a requirement that spans are nested in a hierarchy, they are allowed to move. So sometimes the span might have a different parent than a different time when it's invoked. And these, these methods up here are mostly not used as in they're used by the macros that generate events. But it's pretty rare that you'll be calling them directly yourself. Okay, so let me then talk briefly about record because I did not talk about it earlier.
01:41:18.195 - 01:42:16.835, Speaker A: So if we read the docs for record, you'll See, it says record a set of values on a span. This method will be invoked when a value is recorded on a span. What does that mean? Well, if we go back here, we go to span. You'll see that on a span. Actually, maybe a better example is in the routine here. If I go down to recording fields constant, a span may declare fields with the special value of empty. So you'll see here partying equals field colon colon empty, which indicates that the value for that field does not currently exist but may be recorded later.
01:42:16.835 - 01:43:04.415, Speaker A: And so here you see I create a span. There's no value for the parting field, but later on I can say, okay, now this span that this. The value for this field of the span is known and I can record it now. It's a little weird, but the way to think about this is imagine you want to span. Create a span as early as possible for something like HTTP connection. And you know that every HTTP connection is going to be associated with, let's say some authorization token, right? And the authorization token maps to some unique like application ID or something. Then the moment you get the HTTP connection opened, you don't know what the application ID is yet because you haven't parsed the headers.
01:43:04.415 - 01:43:56.915, Speaker A: So you might open the span at that point and then start emitting events for things. I'm going to parse the set of headers now and you want those events to be associated with the span. And then when you know what the application ID is, then you can record it in the span so that the span from that point forward also includes that information. And you don't want to create a new span because this is all one span, which is this HTTP connection. You just want to sort of add some fidelity or add some extra information to the span that you already have. So that's where record is useful. And that is also what this record method does on subscriber is it tells you for this span, the following values were just recorded by a call to the record method on Spanish.
01:43:56.915 - 01:45:19.565, Speaker A: What if the subscriber just ignores suspend info? Can it just ignore IDs and always return zero? Or is uniqueness used by the tracing crate? The tracing crate does not enforce any uniqueness here on the IDs. So if you have a subscriber that just always returns zero for every new span, tracing doesn't really care. But what that means is the subscriber is not going to be able to understand which spans you're actually in because every, every time a span is entered, it's just going to Be told, well, I entered span zero and it doesn't know which span that is because for every span like all of the spans have an ID of zero. So that's a problem for the subscriber, but I don't think it's a subscriber for. I don't think it's a problem for tracing. Okay, so how does one go about implementing this trait? Like if you want to have a subscriber, what do you do? Oh, that is not what I meant to do, but luckily I can fix it. Dockstar and Tracing Tracing Subscriber so the tracing subscriber crate is a separate crate but also maintained by the tracing folks that provides utilities for and implementations of subscribers.
01:45:19.565 - 01:45:56.867, Speaker A: It's sort of split into a couple of different segments. So one of them is the. We'll see this if you look at the set of modules. So the format module is the main thing that people use tracing subscriber for, which is. And we'll go look at it right now. It provides a subscriber for formatting and logging tracing data. And so this is the thing that we've been using so far where it knows how to take event shaped things from tracing and span shape things from tracing and produce this kind of output.
01:45:56.867 - 01:47:09.797, Speaker A: And it has a couple of configuration options for like maybe you don't want the timestamps included or maybe you don't want colors to be used or bold to be used. Maybe you don't want span information or all of this integration with Rust Log, all of that is like part of the format subscriber. It has all this built in, you can configure it but ultimately it is a way to just sort of quickly get from events and spans to print me something to console. And often that's all you need, right? Like you just want to use tracing as a logging library. Tracing format subscriber or the the subscriber from the format module of tracing subscriber is usually going to be basically all that you need is a super convenient way to get it set up, which is you just call tracingsubscriber formatmodule the init method. And it will create a subscriber, a format subscriber with reasonable defaults. And it will also call the method that we saw earlier, this set global default method on tracing to say to set that format subscriber as the global default.
01:47:09.797 - 01:47:58.295, Speaker A: So every event, every span is going to mit their information to this format subscriber which is then going to print it. So that's sort of the most obvious Part of Tracing Subscriber. We're not going to spend too much time on this one because this one is fairly straightforward. Like it just prints the console and you have a bunch of configuration for like what syntax you want to use. You want it to print JSON? Do you want to like include levels, targets, thread IDs, thread names? You can do other things. Like if we go here to Subscriber Builder, it has a bunch of methods for things like without time or with span events that we looked at earlier, which shows you all the entries and exits. But ultimately it's just like you're configuring a pretty printer for events.
01:47:58.295 - 01:48:58.055, Speaker A: And so it's not super interesting from the perspective of understanding how tracing works. Where it is interesting is if we go back to here is that you'll see if you sort of squint at the documentation that it talks about a couple of other modules like N Filter and down here it says composing with layers. There's something about like N filter, layers, format layer. Okay, so. So there's clearly something else going on here, which is that the Format Subscriber is not a monolith. It's not a giant implementation that has like implementations of the subscriber and span tracking and how to parse environment variables and like all of these other bits. It's really a component that reuses a bunch of other bits and you can reuse those other bits for your own subscribers as well.
01:48:58.055 - 01:50:22.677, Speaker A: And that is where we get to the other parts of the Tracing subscriber crate in particular Filter and Layer and Registry. Let's look at regis. How do I want to do this? Let's talk about layer first. Yeah, we'll talk about layer first. Ah, there's one thing I want to mention because the question came up earlier as well. Before we dive into layers, which is on the subscriber trait, what happens if inside of the implementation of Subscriber you try to do something like write to a file or take a mutex, right? Like something that might actually block. Is that a problem? Well, this question came up a lot earlier too, when we were originally looking at this async code up here and someone asked, well, if we're an async context here, and then the subscriber when it gets this event calls some blocking code, like some non async code, what happens? And the answer is that tracing doesn't do anything special here, like if you're an async context or not in async context.
01:50:22.677 - 01:50:45.317, Speaker A: It doesn't. The subscriber isn't aware, right. The subscriber just sees this method call, which is a blocking method call. Right. There's no async here. And it's expected to do what it can do. And so the question becomes, what do you do in here if you needed to do something that takes a longer period of time? Well, inside a function event, you're allowed to write code that's slow.
01:50:45.317 - 01:51:21.931, Speaker A: You're allowed to write code that takes forever, but that code is executed in line with the event invocation. And we can see this actually if we go here to. We go here to the event macro rules macro, you'll see down here that it calls event child of. If we go to event child of. Let me see if I can dig that up. Oh, it's. That's going to be annoying, isn't it? Let's pick it up over here.
01:51:21.931 - 01:51:54.745, Speaker A: Maybe. Might be easier to look. Ah, one important point. If you ever go to the GitHub of tracing, the master branch is not the branch you want to be looking for or looking at. If you're looking for the code that's actually on Crates IO and I missed this yesterday, there's a giant warning in the readme, which is go look at this branch if you want to look at what's on Crates IO. So we're going to go to this branch and then we'll go to tracing core, which has the core bits of. Of tracing, like the definition of event and span.
01:51:54.745 - 01:52:23.295, Speaker A: We'll look at event and then we'll go here to new child of. No, that's not what I want to look at. I want to look at. I want to look at. Yeah, yeah, here. So child of, you'll see that it does. It creates a new event.
01:52:23.295 - 01:52:44.137, Speaker A: And the say dispatch is the other method for this, which is arguably the nicer one to look at. It's when there's not a parent set. So dispatch will create a new event. It will call get default, which gets whatever is the current default subscriber. So that could either be the thread local one or the global one. And then it calls. It takes that current right.
01:52:44.137 - 01:53:15.315, Speaker A: So current right here is the subscriber, a reference to the subscriber. And it calls the event method. There is no more magic to it. It literally just calls the event method. And as a result, if that event method takes a long time to execute, then this call to dispatch will take a long time to execute, which means that this call right here to event child of, which is really just dispatch. And this thing which actually calls dispatch takes a long time to execute, which means that the macro takes a long time to execute. So there's no magic here.
01:53:15.315 - 01:54:33.207, Speaker A: And so as a result, when you write a subscriber, you want to think carefully about how you manage how long you take to dispatch an event. So for example, if you're writing a subscriber and you want to like asynchronously write to disk or something, then you probably need some means to have a fast path for handling events that is not blocked on doing file access or network access. Usually this comes in the form of either something like a ring buffer where you're, when you get in an event, you just like added to some lock free ring buffer somewhere and you have a different thread that walks that and writes it to disk. Or you could just use a channel. A channel is also the most convenient way to bridge between synchronous and asynchronous code. Right? So you could say your implementation of Fnevent is just, you know, package up the event into something that's owned, right? This is just a reference of something that's owned and then ship that over a channel and then you have some other background task that reads from that channel and emits to, you know, a network service or to disk or whatever. And so that way your actual event logic is going to be pretty fast while your, you know, the expensive operation is something you can batch in the background.
01:54:33.207 - 01:55:47.187, Speaker A: So just be aware of that, that the subscriber really is on the critical path of every single invocation of creating an event. Okay, so with that warning behind us, we can now talk about layer. So as the docs here say for layer, the layer trait is a composable abstraction for building subscribers. As the name implies, the idea is that you layer a bunch of things and collectively they are a subscriber. And in our mental model of this, we can think of layers as like if an event comes in, then it's going to invoke some method on the top layer and then that event is going to go to the next layer and the next layer and the next layer and the next layer. And then when it's done going through the layers and the event has been handled right, so it's sort of like a event multiplexer is one way to think about it. Now in reality, the fact that they are layers is actually pretty important.
01:55:47.187 - 01:56:33.851, Speaker A: Well, we'll see this in a little bit of a second. But the. Let's look at the trait first. So the trait here is generic over a subscriber, which might strike you as a little Weird. Like, if our goal is to build a subscriber, why does the layer already require a subscriber? And the answer to that is, if you look at what a layer gets, a layer is more like an event handler. So it is told, you know, when a newspan was created, it's told when a record happens, it's told when an event happens, it's told about an enter, it's told about an exit, but it's not expected to do state management. You see all of these methods, don't.
01:56:33.851 - 01:57:11.057, Speaker A: You don't return an id, for example, right? For, for something like on Newspan, the expectation is that there's some subscriber at the bottom that deals with all of that for you. And you just have. You just get to like observe the events as they go by and observe the spans as they go by. And so that's what that inner subscriber is. And that's why we go back here. That's what this registry thing is. So a registry is a implementation of the subscriber trait that really just does the state management.
01:57:11.057 - 01:58:11.985, Speaker A: It all it really does is keep track of SPAN IDs, keep track of the values that are associated with each span and act as well a registry for spans. So that down here you'll see that lookup span and subscriber. So you see it implements the subscriber trait and then it also lets you. So it's going to assign SPAN IDs on your behalf and make sure that like, you know, span IDs are unique in the way that they need to be. And you'll see that it also implements this mechanism where you can pass in an ID to the registry. So for example, you know, in your layers on Enter, all you get is an id. Well, you can call the span data method on the registry to get back the data that is known about that span, right? So you could imagine the like in OnEnter or in Onexit, you actually want to look up some of the values of that span or the fields of that span or something.
01:58:11.985 - 01:59:08.405, Speaker A: And you can do that through this registry. It keeps track of the data from Newspan on your behalf, as an example. And this allows the layers to actually be a fair bit simpler because all of the span tracking stuff, which is sort of, this would be the same for almost any implementation is taken care of for you. So you'll see that for all these methods you get access to the same arguments that the subscriber gets access to. Like, you know, the values that have been recorded for an event for Instance, but you also get access to this context and the context is really just a reference to the subscriber. So it gives you information about the current span, not just the subscriber, but like the state tracked by the subscriber. So which span we're currently in metadata about the event.
01:59:08.405 - 01:59:55.415, Speaker A: You can look up things like what is the current span? Where current span here is actually like what is the most, what is the latest enter that I've seen. So, so this gives you much more information like stateful information about where about the current state of events and spans. And it can do that because the registry implements the state tracking for you. And if we look at the, the subscriber trade again, you'll notice that it's not really stateful at all. Right. All the methods receive a shared reference to self and like in Enter, you don't get any information about what you're entering apart from the id. So, so all of that state tracking is handled by the registry for you.
01:59:55.415 - 02:00:55.799, Speaker A: Okay, so what does that mean? What kind of layers might you actually implement? Well, you could have layers to do all sorts of things. The, the most obvious kind of layer is one that will like write to disk, right? Or well write to a network. So you don't actually need the subscriber to do that. You just need something along the way of the layers to observe an event and then decide to print it to disk. And so if we go look at the format subscriber that we looked at earlier format layer, so you see that there's the format subscriber is really a collection of layers, one of which is nfilter, which is we'll get to later. And one of them is the layer that actually prints out to console. And it's because the registry takes care of the state tracking.
02:00:55.799 - 02:01:42.031, Speaker A: And then this layer just does formatting and printing. And so you could easily implement your own layer that you know emits in some other format. Or again, this is where a lot of those other helper crates, like, you know, someone mentioned OTEL earlier. So this is like opentelemetry. You could have an opentelemetry layer that will, you know, look at the spans and the events, decide how to encode them to conform to OpenTelemetry and then send them over a network socket or something that would just be a layer. And in the layer trait all you would have to implement is, you see all of these methods are provided so you don't need to implement them. You would only implement on event and inside of onevent you would decide to emit you know, open telemetry for that event.
02:01:42.031 - 02:02:38.095, Speaker A: Maybe only if the target is equal to metric, for instance. Okay, there's a lot more to talk about layers, but let me pause there. After having introduced them, how can I be sure the tracing events are not lost? I'm guessing there's no delivery guarantees, so things can get lost. Is there a way to prevent that? Also remember that the way that tracing dispatches an event, like when the event macro is used or any of its derivatives, or the span macro is used or any of its derivatives, it just calls the subscriber method, you know, newspaper, enter and event. And it's entirely up to the subscriber what to do. Those calls are not lossy. It's not like tracing will like, you know, you get so many seconds to execute or so many milliseconds to execute the event method and then we'll just cut you off.
02:02:38.095 - 02:03:13.825, Speaker A: It just calls it blockingly. And it's up to the subscriber, the implementation of the subscriber, what they do. And so for instance, there is a subscriber that basically implements like a ring buffer or a queue with a fixed size. So if the subscriber starts falling behind, it will just start dropping log events. But you could also have a subscriber that doesn't do that, that starts to slow down the code that emits the events. Whenever it detects that the, the output doesn't keep up, it will just slow down the code. It'll just exert back pressure by blocking.
02:03:13.825 - 02:03:52.231, Speaker A: So both of these are possible. You could have an infinite queue that you just keep pushing to. That's okay too. Tracing doesn't dictate what the subscriber does with the events or how it deals with things like overloaded system. Would structured logging take place in layers? Yes. So as an example, right. So in the onevent method of a layer, you see here, the event that you get, you know, you get a description of the event and you can walk all the fields of it.
02:03:52.231 - 02:04:40.613, Speaker A: So you have all the structured information, right? So you can call record, or I guess this would be record and it will then that that visitor will be invoked for every field, like every field value pair. And so this is how you would then emit structured logging out of that. So yes, that would entirely be a layer. Thanks David, always helpful to have you. So the nice thing of course with layers is that you can compose them. So I can have, you know, layer one and L2 and I can put them on top of each other and now one will be called and Then the other one will be called. There are a couple of things to be aware of when you do that.
02:04:40.613 - 02:06:02.659, Speaker A: The first is if we look at the implementation of layer, one of the methods that you can override is enabled. So you can say this layer is or is not enabled for a particular call site. If we go here, and notice here, we can return true if the layer is interested in a span or event with the given metadata. So remember, the metadata is sort of the static description of the event or span, and it's similar to the subscriber enabled method. And by default, of course, it always returns true because you want the subscriber to be allowed to do to choose whether to decide able. What's interesting is that this method, and hopefully that's actually kind of intuitive, if you return false from this method, the whole chain sort of stops, right? So if you return false from enabled, that means that you've said this entire block of, you know, layers with a registry at the bottom is not interested in this event. And so if any layer in the stack returns false, then the whole stack, like that represents everything below it in the stack and tracing will then assume, okay, so I should not emit this event.
02:06:02.659 - 02:07:00.763, Speaker A: So this is effectively a global enabling or disabling of a span or an event. It is not just whether this layer cares, it is this layer and all the ones below. Because again, from the point of view of tracing, there is only one subscriber, and that subscriber is the sum total of the stack of layers and the registry. And so returning false from enable means the subscriber does not care about this event and therefore tracing will just stop emitting it entirely. There are ways to get per layer filtering, and we'll talk about that in a second, but this enabled bit is a way to turn things completely on or off. Which then brings us to one of the most common layers that you'll see over here, which is the ENV filter layer. And we'll talk about why it's in the filter modules in a second.
02:07:00.763 - 02:08:00.601, Speaker A: Filters are sort of special, but the envilter layer is one that can be used for global filtering. And we'll talk about per layer filtering later. And the way that works is it's just going to be a layer in your stack of layers, and its enabled method is determined by what is the level and target of the incoming event, like the event. I'm being asked whether is enabled and what is the value of the environment variable rust log. And if the event that I'm seeing or the span that I'M seeing is, you know, not included in the set set by rust log, then I will return false, otherwise I will return true. And so that's how it ends up just globally enabling or disabling events and spans depending on that environment variable. And there's a bunch we can say about how nfilter works.
02:08:00.601 - 02:09:26.253, Speaker A: The documentation here is really good. You I already mentioned how you can do some like cool things where you can, you know, give different crates, different targets with different levels, but you can do a whole lot more with nfilter things like spans, like set the level for spans whose field of this name has a value of this. Like you can do really cool, intricate patterns here to really nail down. I want only exactly these spans and these events in my output that can be super useful, but I don't think it's that useful for us to go through it here on stream because the documentation is really good for how you construct those directives for what to enable or disable what events and spans to enable and disable when using the end filter layer. And the nice thing about nfilter being a separate layer is that if you write your own subscriber or you're using some subscriber that someone else has written, like OpenTelemetry, then you can combine the OpenTelemetry layer with the envilter layer. And now it'll just work like if you set the rust log environment variable that will affect which events make it to the opentelemetry layer, which is exactly what you wanted. Or you can use per layer filtering, which we'll get to a second to sort of fork where events go.
02:09:26.253 - 02:10:01.759, Speaker A: We'll talk about that soon. So usually we only want to implement a layer and not the whole subscriber trait. Yes, exactly right. It is fairly rare that you want to implement subscriber directly. There are a couple of cases where you really need to do like the state tracking of spans yourself, in which case you would implement the subscriber trait. But usually the layer trait is the thing you want to implement. Okay, so we've talked about how layers stack and the enabled thing is sort of the most important thing to be aware of.
02:10:01.759 - 02:10:37.129, Speaker A: All of the other ones are pretty straightforward, right? Like on Newspan it's going to be called all the way down the stack. Onrecord is going to be called all the way like on every. It will be called for every layer and also for the subscribers of the registry at the bottom. Similar for on event, on Exit, et cetera. Event enabled and enabled are Global Register call site we don't really need to talk about. But this is basically register call site is going to be called once for every single call site. So we talked about call sites earlier.
02:10:37.129 - 02:11:20.375, Speaker A: They're basically every place where you have one of the tracing macros, so the span macros or the event macros. Every single place where you have one of those is a call site. And for each one the register call site method will be called so that you as a layer are aware that that span or that event even exists. So that is not like one instance of the event. Like if it was in a loop, it would not. The register call side would be called once, not once per iteration of the loop. It's just so that your, your subscriber gets to know about the all the statically known locations in your code.
02:11:20.375 - 02:12:08.715, Speaker A: And the thing that this returns, this interest method is just, it's like a struct that is either never, sometimes or always. And the idea here is that you can say when the call site is first registered, you as a layer can say I'm never interested in this event, I'm sometimes interested in this event when sometimes we can ignore from now or I'm always interested. And that's sort of a dual to enabled. It has a very similar function to enabled. And the exact distinctions are not worth digging into too much here. Okay, you'll see this dispatch type mentioned a couple of times. Dispatch is really just a type erased subscriber.
02:12:08.715 - 02:12:52.345, Speaker A: So imagine you construct your subscriber of whatever type and you want to record it or you want to set it as the global default or the local default. Using with default the static, the single static we have that tracks, you know, the current subscriber. That static needs to have a type. And that type can't be generic because it's a static. And so that static actually has a holds an ARC ARC dispatch or ARC DIN subscriber. And dispatch is an instance of that. And a dispatch really just is a subscriber that has been type erased so that there's no generics involved.
02:12:52.345 - 02:14:10.385, Speaker A: So you shouldn't need to think too much about dispatchers. The main thing to know about a dispatch is that you can take a dispatch and you can call downcastref to try to cast the dispatcher a reference to the dispatcher back into the subscriber type, which is sometimes useful if you want to access particular information about the current subscriber if you happen to know which concrete subscriber type it is. Okay, so all of this is just sort of standard layering things where Every layer is just invoked in sequence. But there is one part here that is important to include, which is this idea of with filter. And we'll go back up here to per layer filtering for this. So per layer filtering is a way for you to say, you know, actually, do I want to do this first? Yeah, just before I get into this, imagine that you want to log both to the console and to a file and to hotel. Right? You could do that by just having all of those layers in your stack.
02:14:10.385 - 02:14:47.675, Speaker A: There's nothing that says you can only one output layer, right? Layers are just layers and you can stack them as much as you want. And so there's nothing you can just stick all of them into your layer stack. But this is where the tie into per layer filtering comes in. Because you could imagine that, you know, the hotel layer you only want to emit metrics. The console layer, you only want to emit like info level and above. And the disk, the disk layer, maybe you want to include debug but not trace. And so what this really means is you want different filters for the different layers.
02:14:47.675 - 02:15:36.403, Speaker A: And when we talked about the enabled method on layer, remember how I said if you return false from this, the entire event is turned off. It's like because the stack is now saying we as a subscriber, like the subscriber that's made up of the layered stack does not care about this event. So clearly that is not workable. Right, because it would mean that if the hotel layer, for example, did not care about anything that's not a metric, it would return false for enabled. But that would disable all of the non metric events for every layer, which is not what we want. Hence this idea of per layer filtering. And the idea of per layer filtering is that you create a layer that is a filter and a separate layer stack.
02:15:36.403 - 02:16:13.945, Speaker A: And this is where I might have to draw. And now let's see how all my drawing program is going to work in this. I have not used it on this computer before, I think at all. So let's see, see how my, how much worse my drawing skills have gotten. So, and also whether it works. So over here it's working so far over here we have our subscriber. So this whole thing is a subscriber.
02:16:13.945 - 02:17:25.954, Speaker A: And inside of the subscriber, the way it actually sort of looks internally is a layer, and this is a layer, and this is a layer, and this is a layer, and this is a layer. And down at the bottom we have the registry. And the way to think about this in terms of the types, right, is that the type here is, you know, layer, I don't know, seven. Like let's say this, the type of this thing is layer 7, generic over registry, right? And remember that the layer trait is generic over an S where S implements Registry. So clearly this thing implements layer because this thing implements Registry, sorry, implements a subscriber. And that means this whole thing implements subscriber because layer implements subscriber when the S in the layer implements subscriber. And so the type here is, you know, layer six of layer seven of Registry.
02:17:25.954 - 02:18:31.474, Speaker A: Terrible writing. But this thing implements subscriber because this thing implements subscriber, which is because of this. And then it sort of stacks all the way up here. Now the idea with per level lay per layer filtering is that for one of these layers, what if we sort of expanded it and said that this is actually its own little subscriber, its own little layer. And what we want is to have this be internally should have a bunch of filters maybe up top here and then a bunch of layers there. And the idea is when a method call comes down here, we want the method call to go in here and then down here, and it might get filtered by one of these. And then these layers will not be called, but it should still proceed to the other layers after having gone through this one.
02:18:31.474 - 02:19:26.765, Speaker A: So that's the, that's the basic thinking, that the filters are sort of local to this whole thing, but in the context of the whole stack, this whole thing is just one layer in the. In the outer bit. And so as a result, this filter right here, for instance, is not actually a filter for the whole stack. It is just a filter for this sort of substack. Yeah, I know I could have written bigger, but, you know, such is life. So does that make sense? So the filters that we add in here are sort of local to this mini layer or mini layer stack, this small pancake, if you will, small a short stack. And they're not a part of the big stack, the tall stack, and therefore will not affect the lower layers.
02:19:26.765 - 02:20:10.477, Speaker A: What this also means is that for some of the methods, the. The on, like on event, for example, on event, when it's called on a filter, the filter will always pass through the the on event to the next layer down, but it just might not pass it through the layers inside of the stack. And you might wonder, well, how does this work? It looks really weird. It does look really weird. But crucially, some methods like enabled will not be excluded if they don't pass through the filter. So let's Go look at what the code for this actually looks like because that might be instructive. Pancakes.
02:20:10.477 - 02:20:33.325, Speaker A: I know, right? I could have pancakes right now. That sounds tasty. Okay, so let's go look at layer with filter. Filtered. If we now go look at filtered, what does filtered look like? Okay, it has a filter and a layer. That's fine. And whatever this magic pulse downcast marker is, we're gonna ignore that for now.
02:20:33.325 - 02:21:22.607, Speaker A: Let me see if I can find. No, I want the. I want the imp search maybe. Oh no, it's going to search on the wrong branch. Okay, fine. Maybe I'll just go dev others. Get clone Tokyo rstracing git tracing checkout V01X CD tracing subscriber and then search.
02:21:22.607 - 02:21:52.881, Speaker A: Whoops. Search for this thing. Source Filter layer. Filters modrs line 703. Okay, so let's look here at. So remember, filtered has. Oh, my computer's gonna be unhappy about this because it needs to parse the entire workspace.
02:21:52.881 - 02:22:52.825, Speaker A: There we go. So filtered this, the struct that we get back. When we construct one of these filtered layers, it holds the filter and the layer separately. And something like on register dispatch or on layer, we just call into the inner layer and enable. We're going to ignore a little bit for now because it's a little complicated, but if we look at something like on event. Oh, did enable. How do I want to explain this? I'm trying to think what the best way is to explain this in a way that's useful.
02:22:52.825 - 02:23:44.431, Speaker A: Actually, maybe I do want to follow the docs here. Yeah, let's follow the docs first and then look at the code. So there are these two traits. There's layer and filter. And filter is a super straightforward one. If we look at here, like nfilter for example, if we look at the methods on it, you'll see that it implements the filter trait. And the filter trait is mostly just the enabled method, right? Which is, you know, it's a filter.
02:23:44.431 - 02:24:50.629, Speaker A: Like does this filter the thing through or not? As the only thing that you really need to do need to express if you are a filter. And the idea is that if you combine a filter with a layer, then that layer and you know, anything that lies below that layer will be subject to the results of that filter. But if you then take that whole stack and you slot it into a larger stack, then the next layer, after the combined filter and layer layer, that one will still pass through and ignore the filter. And you can construct filters from all sorts of things. It doesn't have to be like a fancy struct that implements a trait. Like you can have a filter function, for example. So the filter module of tratingSubscriber has a filter function method that just is given the metadata for a given, you know, the statically known information about an event in a span.
02:24:50.629 - 02:25:25.039, Speaker A: And this is supposed to return true if that thing is interesting as part of the filter and false otherwise. So in this case, for example, it checks whether the target is equal to HTTP access. You could imagine a similar kind of filter for, you know, has target set to metric. And in fact, I think they give an example of that, but maybe not. And so here you see an example of how they might, how you might combine these kinds of layers. So the info layers here are layer A, layer B. And those are filtered based on only things that have level info.
02:25:25.039 - 02:26:22.889, Speaker A: But that whole stack, and this is the sort of thing I was drawing earlier, that whole stack of layers you can insert as a single layer in the whole, in the overall subscriber. And similarly here, you know, layer C can have its own set of filters. And that filter will only apply to the things inside of layer C, just like this filter will only apply to these filters here. They're inside that packaged layer and will not apply cross layers. And the way that it actually accomplishes this is. And this is the part I was looking for earlier is not that it is 703. Where's the method that calls layer? So Onevent, for example, is just like, did I enable this event? If so, then call the event on the layer.
02:26:22.889 - 02:27:07.895, Speaker A: Right? So this is the filtering part of if it's not filtered or if it is filtered, then don't call on event and vice versa. But crucially, the part where it actually constructs the layer on layer. So this is where there's a little bit of magic. This is this magic pulse downcast marker. I don't actually know what this thing does internally. I think it just keeps track of what the real value for the filter is and it does some like type erasure. But the basic construction here is that you the layer.
02:27:07.895 - 02:27:33.915, Speaker A: I'm struggling to find the right way to convey this. Ah, okay. I know how to do this. I'm not gonna do it through the types because I don't think that's gonna be helpful. But I will do it through the drawing. So here I'm even gonna switch color. Well, I'm gonna try anyway.
02:27:33.915 - 02:28:10.777, Speaker A: Ah, okay, that's. I want, I want my color to change. Maybe now? No, Can I go down here? Okay, great. Let's Do. Okay, why. Why will it not let me change colors? Well, I guess then maybe it has to be yellow color palette. Sure, let's do that.
02:28:10.777 - 02:29:06.575, Speaker A: Color palette, bright blue. Okay, so the key thing to remember here is that the type here, this type. So this is the sort of type boundary here. There's an implementation of a type here of layer, and this one is allowed to not emit events, but there's also a type for this overall thing. And this overall thing is the thing that slots in here and that handles the outside calls. And so this outside type can choose to call into the inner one and then call into the outer one. Because this is the filter and this is the next layer when the.
02:29:06.575 - 02:30:11.785, Speaker A: When the whole thing is stacked into the overall one. I don't know if that helps you, but. But the. I think the mental model is clear, which is if you insert a stack of pancakes that has filters internally in it into this larger stack of pancakes, then the filters apply only to the local stack of pancakes and not to the next layer in the larger stack. And I'm going to not try to show you the code because I think one of the challenges with the tracing code base is that it is very optimized to aggressively get rid of events and spans as early as possible if no one cares about them. And so the code ends up being more complicated here than the sort of mental model that's needed to work with them, as evidenced by types like this. And so I'm not going to try to dive into how it accomplishes this, but just trust me that it does, I guess.
02:30:11.785 - 02:31:27.593, Speaker A: Okay, I'm going to take questions there, given that I rambled for a bit and see whether I can help clarify any of the things I rambled about. I guess one clear question is, does the distinction between a global filter and a per layer filter makes sense? Is that distinction clear? Maybe. Hopefully. I've not lost connection with chat. No, it's still there. It's just everyone is super confused. Okay, you can use the same filter type as a global one and a pair layer one.
02:31:27.593 - 02:32:43.327, Speaker A: Yes. So it's actually, if you think about it, I mentioned that you can attach a filter to a sort of local pancake stack, right? But the global stack is the same kind of type, but it's also just a stack of layers. So if you put anything that implements filter on top of the global stack, then it filters all events for all layers. And so you can actually construct these interesting hierarchies right where the chain doesn't need to be only too deep there's like Inception over here, right? So you can have this layer, for example, this layer could itself be a substack. And that substack also has a bunch of layers and also has it own its own filter on top. And that the red filter will apply to all of the layers in here, but will not apply to the other blue layers and will not obviously apply to any of the yellow layers. And so you can, you can stack them this way such that again, if you imagine something like hotel versus Console versus file, right? The, the filter that you use over here, you could this, you know, if this was the hotel, I should do that blue.
02:32:43.327 - 02:33:44.905, Speaker A: But that's fine. If this was the hotel one, then this might be a thing that filters based on metrics being the target. And then in here you might have a different one that filters on info and that is the one that goes to the format layer. And similarly down here you could have one that filters on debug and goes to the file logger and inside hotel, maybe you want like the metrics that are marked info and higher to go out at a higher fidelity or something than the ones that are lower. And so you could have sub filters under there as well. So you can stack them all the way down. Can you modify some layer filter at runtime, for example, can you runtime change logging lever for some layer? So kind of.
02:33:44.905 - 02:34:56.465, Speaker A: And I'll show you this bit down here and I think that's over in tracing. Oh, it's called re rebuild. Is it in here then rebuild. So there is a method to basically say my subscriber has changed. Like I've changed the settings of it. Re evaluate the whether every event should be enabled or not. And I'm just trying to find what that method is called.
02:34:56.465 - 02:35:54.947, Speaker A: But now of course I cannot find it. I think it's over in subscriber. So one option is you can call set global default. Apparently no set default. No, it's. It's not an internal method, is it? Let me see if I can find it here. Tracing core call sites, rebuilding cached interest.
02:35:54.947 - 02:36:55.279, Speaker A: This is the one I'm after. Okay, so this is in the call site module of tracing Core. I've mentioned what call sites are and there's a way where you can rebuild the sort of cached information about which events and which spans are enabled disabled. Like basically which ones some subscribers interested in. And it is by calling this rebuild interest cash method. So if you modify your subscriber in such a way that it's let's say more restrictive or less restrictive Then you can call this method in order for the I think you even have to call this method unless you go through a couple of other methods that do it automatically for you so that all of the call sites are going to recognize that, oh, I was disabled, so I was doing the shortcut for, you know, do nothing. But now I need to reconsider whether I'm enabled or not on the next time I call.
02:36:55.279 - 02:37:33.225, Speaker A: So calling this is quite expensive, right? It. It recomputes a bunch of levels and it's like it's a very expensive operation. It basically needs to reevaluate every call site. So it's pretty expensive. But it is the method that you call if your subscriber configuration changes. And I think this says here too, like this function intended for runtime reconfiguration of filters on traces, where the filter recalculation is much less frequent than trace events are. So basically it's rare that you change the configuration.
02:37:33.225 - 02:38:05.239, Speaker A: If you have a case where your configuration actually changes very often, you don't want to be calling this method because it's so expensive. Instead you want your subscriber to just not disable things. So essentially you want it to indicate this interest sometimes rather than interest never. And that way. So this is the sort of distinction between interests that we talked about briefly and enabled. So if interest is never, then the call site is disabled entirely. If interest is always, then the enabled method is never called.
02:38:05.239 - 02:39:21.991, Speaker A: And if interest is sometimes, then enabled is called for every event. And so for something like nfilter, it statically says the interest is never for things that don't meet the environment variable because it knows that the environment variable will not change over time. But if you had something that was fully dynamically configured, it would have to return interest sometimes so that the enabled method is called every time there's an event. But of course now dispatching events is more expensive because each one needs to call this enabled method. And so it depends on how frequently you change the configuration, whether you want it to be the interest and the call to enable to be cached and then call this rebuild interest cache whenever the configuration changes or whether you want enable just be called every time there's a reload module in tracing subscriber as well. Interesting, where no. So this module is slightly different.
02:39:21.991 - 02:40:07.261, Speaker A: This is to basically allow a hot swappable layer. So you can have a. If you use this like for example, for a level filter, then you can swap out to the instance of the level filter dynamically at runtime. Now that in that particular case it has the same effect, right, because you're swapping a level filter warn to level filter info. And when you do that you have to rebuild the interest cache. But that is a more specific case of the problem, right, where you have one instance of a layer and you just want to swap out that layer. That doesn't necessarily mean that your filtering is more or less, is more or less restrictive, right? Imagine you have a layer for instance, that doesn't do any filtering.
02:40:07.261 - 02:41:07.545, Speaker A: It just like writes to disk whatever it gets. Then if you swap it out with something that writes to a different file, for instance, so this is going to be used for a rotational file logger. Then just because you swapped out the subscriber does not mean you need to rebuild the interest cache. So reload is a more general purpose mechanism for just having layers where you can swap out the instance of that layer over time. Okay, see, so I touched on that, touched on this, touch on that. I talked about async, talked about blocking, talked about the level suspends and events layers filters subscribers. I think, I think that's all the things I wanted to cover.
02:41:07.545 - 02:42:32.441, Speaker A: But let me look through the tracing subscriber docs and see if there's anything particularly interesting that I missed. There's no STD support, which is nice. What do we have in utility that's not particularly interesting? Fields, field visitors. I think the last thing I want to talk about is just a couple of maybe interesting subscribers, but I'll leave that to the very end. But I think I'm done on sort of tracing core topics. How do you actually change the properties of the filter with the rebuild cache? Oh, so if you can get access to a subscriber, right? So you can get access to the subscriber by calling here Subscriber racing dispatcher. So again I mentioned when you set the subscriber, it gets type erased into a dispatch and then the dispatch is what's stored in the static.
02:42:32.441 - 02:43:49.991, Speaker A: So you can call the get default method inside of the dispatch module. And when you do that you get back or you pass in a closure and that closure gets given a reference to the current dispatch dispatcher. And then on the dispatcher you can call downcast in order to cast the dispatcher back into a reference to the subscriber type. Right? So that would be, you know, the type of your whole little layering stack. And when you then have the type of your layering stack, then over here when you have that layer stack and we look at the type like layered, you'll see that Layered in turn allows you to downcast into either the type of the like a layer is fundamentally, you know, the top and the rest, right? And downcast ref will let you either downcast into the type of the head of the layer to the top layer, or it will call downcast ref on the rest. And so as a result you can downcast into the type of any given layer. And so that gives you then a reference to a particular layer in the stack.
02:43:49.991 - 02:44:25.761, Speaker A: And you can nest these, right as if you have. If you have these sort of substacks that are injected in as batches of layers. So ultimately you can always find your way from the dispatch all the way into an individual layer. And then when you have that individual layer, you only have a shared reference to it, right? Because it's stored in a static. But if you have something like an atomic bool in there, you could change that atomic bool or atomic U size using atomic operations in order to. Or you could be a mutex for that matter in order to change the configurations of that layer. Although again, like you, you really.
02:44:25.761 - 02:45:21.295, Speaker A: And tracing does make this hard. You really don't want to be changing the like a layer that is a part of your subscriber at runtime very often. If you do, chances are you either want something like reload, like a swap the instance of this layer or you know, it's. It's going to impact your performance if you, if you require that kind of, that kind of non static setup like nfilter can be extremely efficient even though it's not compile time because it can say once for every call site, I am not interested in this call site and I never will be. And so that allows it to be extremely efficient. Whereas if it had to check all the time because like the environment variable could change because it was stored in, I don't know, some mutex guarded string, then that M filter would be very expensive to compute. So subscribers can have layers and layers can have their own layers.
02:45:21.295 - 02:45:52.225, Speaker A: Not quite so subscribers don't really have layers. The way to think about it is the subscriber trait is implemented for any type where the top thing implements layer and the bottom thing implements subscriber. That's the. That's the whole deal. So the subscriber trait is implemented for anything that is a layer plus a subscriber. And because that applies recursively, you can stack layers. But the.
02:45:52.225 - 02:46:54.723, Speaker A: And one instance of something that implements a layer is a stack of layers because they. The interface sort of combines nicely. So to recap inside all of These layer impulse you really should not block, right? They should send a message or write to a ring buffer for file writing, et cetera. Well, I mean, it depends on what you mean by block, right? Like, all CPU instructions take some amount of time, and there's no hard rule for how many CPU instructions or how much wall clock time you're allowed to spend inside of event dispatching. But all of the time you spend in there is going to be cost paid at every event site. So how much you're willing to pay there is entirely up to you. Usually you want it to be quite fast because there are a lot of events in a program and ideally, you know, people instrument your program with events all over the place.
02:46:54.723 - 02:48:00.969, Speaker A: So you really want it to be quite cheap. If you start like blocking on file rights or I O, that's probably too slow. Can you talk about the usage of this crate like the frequency of tracing, debug, warn, et cetera? How much do you rely on logging versus debugging? So on tracing versus debug versus info versus warn versus Error, there's no great answer to this. Usually the way I think about this is like tracing I use if I already know that there's a problem in this area of the code. Debug I use if I'm trying to figure out whether there might be something weird with this part of the code. Info is commonplace operations that are useful for understanding what the application is doing. Warn is something weird happened, but it's not, nothing's on fire, nothing's wrong.
02:48:00.969 - 02:48:45.901, Speaker A: It's just something was weird and then error is something is wrong. That's like roughly the mental model that I have. And it's tempting to make a lot more things debug or a lot more things trace just so that they don't show up in your logs all the way. But really what that's, that's suggesting is you should be tuning your rust log environment variable more. Very often, people just sort of run with the default rust log environment variable value, which is it's not set, which defaults to info. And so therefore logging things at info level in libraries, for instance, produces a bunch of output for applications that use that library. And so the library sort of makes them debug instead so that applications don't have to hide it.
02:48:45.901 - 02:49:40.997, Speaker A: But that means that libraries end up being sort of limited to just using debug and trace, which feels weird. And so my general model tends to be use all the levels and then the owners should be on application developers to set the levels such that they Only get the logging, the login that they they require. When it comes to logging versus debugging, it's a good answer. Like the way it's a good question. I think of logging as something that I use more after the fact, right? Like something went wrong and I want to figure out how we got there. If I'm actively debugging an application, I'm more likely to just like insert my own print statements and stuff. Now, it is true that if you have really good logging or tracing in your application, you might not need print statements.
02:49:40.997 - 02:51:07.505, Speaker A: It might be sufficient just like enable trace for that module and everything's good. Usually though, I find that there's always a little bit more that I want to dig out. But enabling more verbose logging is often good enough and useful. If I had two subscribers, one for stdout and one for 2e, how do I disable the default subscriber to standard out when I launch the 2e? Oh, I mean that one's easy. So there is only ever one global subscriber and you can override the global dispatcher whenever you want. So what you do is you set the when your application start, you set the format subscriber, the console logger, to be your global subscriber and then when the 2e starts, then you override the global dispatcher to be the 2e dispatcher instead. Said how would you structure or separate between tracing for me while developing and logging for the user? For programs that you ship to the user, like a game server or something, not a service monitored by devs, there's not a really good answer to that, right? Like levels don't communicate things that are intended for a user versus things that are intended for a developer.
02:51:07.505 - 02:52:00.189, Speaker A: The levels map a little bit to it. Like the user probably doesn't need debug and trace output. But I don't have a great answer for you here. The closest I can get to is you could imagine that you have a field on events and spans that say user like user equals true. And then you have a filter that will like in release mode, that filter is set to only allow through events that have the user field set to true. And in debug mode it just passes through all events and so that way you can explicitly annotate like this event is user facing, this event is user facing. And if you're in debug build, then those attributes or those fields are just ignored.
02:52:00.189 - 02:52:26.965, Speaker A: But in a release build, only those ones are emitted and so those are the only ones that users will ever see. That's my best guess for how I'd accomplish something like that. Okay, so let's end then on the sort of list of interesting subscribers or things to use. We've already talked about the format subscriber. We've talked about Registry, which is a subscriber. It just doesn't do anything. There are a bunch of others that you should be aware of.
02:52:26.965 - 02:53:06.847, Speaker A: So one of them is tracing logs. So this is the one that provides compatibility with the log crate. So it makes it so that every event you emit from tracing actually produces a tracing log event. Sorry, this is the one that goes the other way around. This is the one where dependencies use logs. So they use the log macros to log things. The tracing log allows those events to also be picked up by as tracing events by tracing subscribers.
02:53:06.847 - 02:54:01.969, Speaker A: There's one that's also the inverse that I can't immediately find. Now Tracing Appender is a subscriber that writes to file. It supports both blocking writes while the events go on and non blocking is using like a ring buffer type thing. There's also tracing open telemetry which supports writing out to open telemetry traces. There's tracing timing, which is one I wrote that basically produces histograms of the time spent between each two events within each span. So like it can tell you across all HTTP requests. This is the time distribution of things spent in like let's say you have a part that's handling an HTTP connection which is parsing the headers.
02:54:01.969 - 02:54:53.905, Speaker A: Tracing timing is going to take the time between the start of the span and the finished parsing headers event and give you a histogram of how much time it took to execute that bit of code across all spans. So across all HTTP connections. And it'll do the same between the parse headers event and whatever the next event is. Like check authorization token. And I'll show you a histogram of that time and then the same for every inter event region. So that can be really helpful for trying to nail down where your performance problems or where your performance budget is going. Tracing Honeycomb outputs to Honeycomb Bio we talked a little bit about these sort of AXM and Actix web type integrations that automatically annotate spans and events for Actix Web and Axum applications.
02:54:53.905 - 02:56:06.051, Speaker A: There's one more right there's sentry tracing, of course, and then there's this one which is the thing I was looking for earlier. Tracing cloudwatch which sends to cloudwatch but tracing forest. No, that's not the one I was Thinking of, I'm trying to find David's tree logger, but now I cannot for the life of me find it. Oh, is it. Is it just tracing tree? Why is that not in this list? That's what I want to know. Ah, so tracing tree is a subscriber that also just prints to console, but it actually prints you like a tree, like output, showing you the sequence, the sort of nested set of spans that you're in when a given event is output. And so it's a neat way to get a more structured look at the output.
02:56:06.051 - 02:56:48.915, Speaker A: It's probably not what you would use for like ongoing logging output, but it can be really nice. And I think. I think that is all the things I wanted to talk about when it comes to tracing. Are there any sort of questions at the end here of anything that's still unclear? You're not sure how you do in tracing or any parts of the sort of pieces that you're curious about have fit together? How does the tree react to multithreading? Go find out. You mean tracing tree, right? In that case, I genuinely don't know. I think you would have to. You would have to go test it out.
02:56:48.915 - 02:57:19.407, Speaker A: I think it prints the tree for each event independently and I think it probably takes a lock on the output, but I'm not sure. Okay. It doesn't look like there are any questions at the end here, so I think. I think that's it. I think we did tracing finally. It's been requested so many times and finally now we're through it. Well, I hope this was useful.
02:57:19.407 - 02:57:22.695, Speaker A: I hope you found it interesting and I'll see you in a later video.
